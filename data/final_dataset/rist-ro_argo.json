{"home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.__init__": [[25, 42], ["ImageDataset.ImageDataset.__init__", "NPY.NPY.dataset_id", "numpy.load", "numpy.load", "NPY.NPY.preprocess_x_y", "NPY.NPY.preprocess_x_y", "numpy.load", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.preprocess_x_y", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.preprocess_x_y", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "self", ".", "_params", "[", "'binary'", "]", "\n", "\n", "self", ".", "_train_set_x", "=", "np", ".", "load", "(", "params", "[", "\"train_set_x\"", "]", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "load", "(", "params", "[", "\"test_set_x\"", "]", ")", "\n", "\n", "self", ".", "_train_set_y", "=", "np", ".", "load", "(", "params", "[", "\"train_set_y\"", "]", ")", "if", "\"train_set_y\"", "in", "params", "else", "None", "\n", "self", ".", "_test_set_y", "=", "np", ".", "load", "(", "params", "[", "\"test_set_y\"", "]", ")", "if", "\"test_set_y\"", "in", "params", "else", "None", "\n", "\n", "self", ".", "_image_shape", "=", "self", ".", "_train_set_x", "[", "0", "]", ".", "shape", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "preprocess_x_y", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "preprocess_x_y", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.preprocess_x_y": [[49, 77], ["x.copy", "y.copy", "NPY.NPY.class_filter", "NPY.NPY.sub_sample", "numpy.clip", "numpy.prod", "preprocessed_x.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "preprocess_x_y", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "preprocessed_x", "=", "x", ".", "copy", "(", ")", "\n", "preprocessed_y", "=", "y", ".", "copy", "(", ")", "if", "(", "y", "is", "not", "None", ")", "else", "None", "\n", "\n", "# filter classes", "\n", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "preprocessed_x", ",", "preprocessed_y", "=", "self", ".", "class_filter", "(", "preprocessed_x", ",", "preprocessed_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "preprocessed_x", ",", "preprocessed_y", "=", "self", ".", "sub_sample", "(", "preprocessed_x", ",", "preprocessed_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "preprocessed_x", "=", "np", ".", "clip", "(", "preprocessed_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n", "", "if", "self", ".", "_params", "[", "'vect'", "]", ":", "\n", "            ", "length", "=", "np", ".", "prod", "(", "self", ".", "_image_shape", ")", "\n", "preprocessed_x", "=", "preprocessed_x", ".", "reshape", "(", "(", "-", "1", ",", "length", ")", ")", "\n", "\n", "", "return", "preprocessed_x", ",", "preprocessed_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.dataset_id": [[78, 133], ["NPY.check_params_impl", "list", "range", "str", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "\n", "NPY", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'NPY-'", "+", "params", "[", "\"id\"", "]", "\n", "\n", "# binary or continuous", "\n", "id_binary", "=", "{", "0", ":", "'-c'", ",", "1", ":", "'-d'", "}", "\n", "id", "+=", "id_binary", "[", "params", "[", "'binary'", "]", "]", "\n", "\n", "# stochastic", "\n", "#id += '-st' + str(params[\"stochastic\"])", "\n", "\n", "# subclasses", "\n", "#", "\n", "if", "(", "'classes'", "in", "params", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "10", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in NPY\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.sub_sample": [[134, 153], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_train", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_train", "=", "np", ".", "random", ".", "permutation", "(", "len_train", ")", "\n", "new_len_train", "=", "int", "(", "len_train", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.input_size": [[154, 157], ["numpy.prod"], "methods", ["None"], ["", "@", "property", "\n", "def", "input_size", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "prod", "(", "self", ".", "_train_set_x", "[", "0", "]", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.output_size": [[158, 162], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "# TODO check if this is ok or not", "\n", "        ", "return", "self", ".", "y_shape", "if", "self", ".", "_params", "[", "'classes'", "]", "==", "(", ")", "else", "len", "(", "self", ".", "_params", "[", "'classes'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.color_images": [[163, 166], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.image_shape": [[168, 171], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_image_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.__init__": [[15, 28], ["datasets.BrainDataset.BrainDataset.__init__", "MixedBrainDataset.MixedBrainDataset.dataset_id", "MixedBrainDataset.MixedBrainDataset.load_float_brains", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_float_brains"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dirs", "=", "self", ".", "_params", "[", "'data_dirs'", "]", "\n", "self", ".", "_training_data_proportion", "=", "self", ".", "_params", "[", "'training_data_proportion'", "]", "if", "'training_data_proportion'", "in", "params", "else", "[", "1.0", "for", "_", "in", "range", "(", "len", "(", "self", ".", "_data_dirs", ")", ")", "]", "\n", "\n", "# options for each dataset", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_float_brains", "(", "self", ".", "_data_dirs", ",", "self", ".", "_training_data_proportion", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.dataset_id": [[29, 40], ["super().dataset_id", "params.keys", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "id", "=", "'MixedBrainDataset'", "\n", "\n", "id", "+=", "super", "(", ")", ".", "dataset_id", "(", "params", ")", "\n", "if", "'training_data_proportion'", "in", "params", ".", "keys", "(", ")", ":", "\n", "            ", "id", "+=", "\"-p\"", "+", "\"_\"", ".", "join", "(", "[", "str", "(", "val", ")", "for", "val", "in", "params", "[", "'training_data_proportion'", "]", "]", ")", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.load_float_brains": [[41, 76], ["zip", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.asarray", "numpy.asarray", "numpy.asarray", "print", "print", "print", "print", "print", "numpy.append", "numpy.append", "numpy.append", "len", "MixedBrainDataset.MixedBrainDataset.load_file_names", "MixedBrainDataset.MixedBrainDataset.load_file_names", "MixedBrainDataset.MixedBrainDataset.load_file_names", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_float_brains", "(", "self", ",", "data_dirs", ",", "proportions", ")", ":", "\n", "        ", "datasets_tuple", "=", "[", "]", "\n", "datasets_tuple_validation", "=", "[", "]", "\n", "datasets_tuple_test", "=", "[", "]", "\n", "for", "data_dir", ",", "proportion", "in", "zip", "(", "data_dirs", ",", "proportions", ")", ":", "\n", "            ", "datasets_tuple", "=", "np", ".", "append", "(", "datasets_tuple", ",", "self", ".", "load_file_names", "(", "data_dir", ",", "'train'", ",", "\n", "proportion", "=", "proportion", ")", ")", "\n", "datasets_tuple_validation", "=", "np", ".", "append", "(", "datasets_tuple_validation", ",", "\n", "self", ".", "load_file_names", "(", "data_dir", ",", "'validation'", ")", ")", "\n", "datasets_tuple_test", "=", "np", ".", "append", "(", "datasets_tuple_test", ",", "self", ".", "load_file_names", "(", "data_dir", ",", "'test'", ")", ")", "\n", "\n", "", "datasets_tuple", "=", "np", ".", "tile", "(", "datasets_tuple", ",", "(", "2", ",", "1", ")", ")", "\n", "datasets_tuple_validation", "=", "np", ".", "tile", "(", "datasets_tuple_validation", ",", "(", "2", ",", "1", ")", ")", "\n", "datasets_tuple_test", "=", "np", ".", "tile", "(", "datasets_tuple_test", ",", "(", "2", ",", "1", ")", ")", "\n", "datasets_tuple", "=", "np", ".", "asarray", "(", "datasets_tuple", ")", "\n", "datasets_tuple_validation", "=", "np", ".", "asarray", "(", "datasets_tuple_validation", ")", "\n", "datasets_tuple_test", "=", "np", ".", "asarray", "(", "datasets_tuple_test", ")", "\n", "\n", "print", "(", "'---------DATASET TUPLE------------'", ",", "datasets_tuple", ".", "shape", ")", "\n", "train_set_x", ",", "train_set_y", "=", "datasets_tuple", "\n", "\n", "print", "(", "'---------DATASET TUPLE VALIDATION------------'", ",", "datasets_tuple_validation", ".", "shape", ")", "\n", "validation_set_x", ",", "validation_set_y", "=", "datasets_tuple_validation", "\n", "\n", "print", "(", "'---------DATASET TUPLE TEST------------'", ",", "datasets_tuple_test", ".", "shape", ")", "\n", "test_set_x", ",", "test_set_y", "=", "datasets_tuple_test", "\n", "\n", "print", "(", "'--------------X SHAPE-----------------'", ")", "\n", "channels_no", "=", "len", "(", "self", ".", "_modalities", ")", "if", "self", ".", "_modalities", "!=", "None", "else", "1", "\n", "self", ".", "_train_set_x_shape", "=", "np", ".", "load", "(", "datasets_tuple", "[", "0", ",", "0", "]", ")", ".", "shape", "+", "(", "channels_no", ",", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "            ", "self", ".", "_train_set_x_shape", "=", "(", "self", ".", "_resize", ",", "self", ".", "_resize", ",", "channels_no", ")", "\n", "", "print", "(", "self", ".", "_train_set_x_shape", ")", "\n", "\n", "return", "train_set_x", ",", "train_set_y", ",", "validation_set_x", ",", "validation_set_y", ",", "test_set_x", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.load_file_names": [[78, 91], ["os.walk", "numpy.asarray", "fnmatch.filter", "int", "numpy.asarray.append", "numpy.asarray.append", "str", "len"], "methods", ["None"], ["", "def", "load_file_names", "(", "self", ",", "root", ",", "data_type", ",", "proportion", "=", "1.0", ")", ":", "\n", "        ", "file_names", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", "+", "'/'", "+", "data_type", ")", ":", "\n", "            ", "if", "self", ".", "_modalities", "is", "not", "None", ":", "\n", "                ", "reg_filter", "=", "'*_'", "+", "str", "(", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ")", "+", "'_*'", "\n", "for", "f", "in", "fnmatch", ".", "filter", "(", "files", ",", "reg_filter", ")", ":", "\n", "                    ", "file_names", ".", "append", "(", "root", "+", "'/'", "+", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "f", "in", "files", ":", "\n", "                    ", "file_names", ".", "append", "(", "root", "+", "'/'", "+", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "", "file_names", "=", "np", ".", "asarray", "(", "file_names", ")", "\n", "file_names", "=", "file_names", "[", ":", "int", "(", "proportion", "*", "len", "(", "file_names", ")", ")", "]", "\n", "return", "file_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.get_label": [[92, 97], ["None"], "methods", ["None"], ["", "def", "get_label", "(", "self", ",", "filename", ")", ":", "\n", "        ", "if", "'HCP'", "in", "filename", ":", "\n", "            ", "return", "0", "\n", "", "if", "'BRATS'", "in", "filename", ":", "\n", "            ", "return", "1", "\n", "# todo implement when the tumour mask is given and the label is [1,1]", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.dataset_map": [[100, 133], ["MixedBrainDataset.MixedBrainDataset.get_output_types", "MixedBrainDataset.MixedBrainDataset.get_output_shapes", "list", "dataset.map.map.map", "numpy.empty", "MixedBrainDataset.MixedBrainDataset.get_label", "zip", "enumerate", "MixedBrainDataset.MixedBrainDataset.load_slice_from_file", "numpy.array.reshape", "numpy.int32", "tuple", "str.replace", "MixedBrainDataset.MixedBrainDataset.load_slice_from_file", "numpy.array", "tensorflow.py_func", "str", "str", "numpy.array", "str", "PIL.Image.fromarray().resize", "PIL.Image.fromarray().resize", "PIL.Image.fromarray", "PIL.Image.fromarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.get_label", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file"], ["", "", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "result", "=", "np", ".", "empty", "(", "output_shapes", "[", "0", "]", ",", "np", ".", "float32", ")", "\n", "modality_filename", "=", "filename", "\n", "if", "self", ".", "_modalities", "is", "not", "None", ":", "\n", "                ", "for", "i", ",", "modality", "in", "enumerate", "(", "self", ".", "_modalities", ")", ":", "\n", "                    ", "modality_filename", "=", "str", ".", "replace", "(", "str", "(", "filename", ")", ",", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ",", "\n", "modalities", "[", "modality", "]", ")", "\n", "image", "=", "self", ".", "load_slice_from_file", "(", "str", "(", "modality_filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                        ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "result", "[", ":", ",", ":", ",", "i", "]", "=", "image", "\n", "", "", "else", ":", "\n", "                ", "image", "=", "self", ".", "load_slice_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                    ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "result", "=", "image", ".", "reshape", "(", "[", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "", "label", "=", "self", ".", "get_label", "(", "modality_filename", ")", "\n", "return", "result", ",", "np", ".", "int32", "(", "label", ")", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.get_output_shapes": [[135, 143], ["numpy.load().astype", "tuple", "len", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "channels_no", "=", "len", "(", "self", ".", "_modalities", ")", "if", "self", ".", "_modalities", "is", "not", "None", "else", "1", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "channels_no", ",", ")", ",", "(", ")", "]", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "            ", "output_shapes", "=", "(", "(", "self", ".", "_resize", ",", "self", ".", "_resize", ",", "channels_no", ")", ",", "(", ")", ")", "\n", "\n", "", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.get_output_types": [[145, 150], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "int32", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.x_shape_train": [[152, 155], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.x_shape_eval": [[162, 165], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.n_labels": [[166, 170], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the number of labeles in this dataset\"\"\"", "\n", "return", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MixedBrainDataset.MixedBrainDataset.data_dirs": [[171, 174], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_dirs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_data_dirs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.__init__": [[17, 36], ["datasets.BrainDataset.BrainDataset.__init__", "LabeledBrainDataset.LabeledBrainDataset.dataset_id", "LabeledBrainDataset.LabeledBrainDataset.load_float_brains", "LabeledBrainDataset.LabeledBrainDataset._params.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_float_brains"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_labels_file", "=", "self", ".", "_params", "[", "'labels_file'", "]", "\n", "self", ".", "_split_file", "=", "self", ".", "_params", "[", "'split_file'", "]", "\n", "\n", "if", "'slices'", "in", "self", ".", "_params", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_slices", "=", "self", ".", "_params", "[", "'slices'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_slices", "=", "None", "\n", "# options for each dataset", "\n", "\n", "", "self", ".", "_no_of_classes", "=", "self", ".", "_params", "[", "'no_of_classes'", "]", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_float_brains", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.dataset_id": [[37, 46], ["super().dataset_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "id", "=", "''", "\n", "\n", "id", "+=", "super", "(", ")", ".", "dataset_id", "(", "params", ")", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.load_float_brains": [[47, 73], ["LabeledBrainDataset.LabeledBrainDataset.load_file_names", "LabeledBrainDataset.LabeledBrainDataset.load_file_names", "LabeledBrainDataset.LabeledBrainDataset.load_file_names", "print", "print", "print", "print", "print", "len", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_float_brains", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "datasets_tuple", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'train'", ")", "\n", "datasets_tuple_validation", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'validation'", ")", "\n", "datasets_tuple_test", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'test'", ")", "\n", "# pdb.set_trace()", "\n", "\n", "print", "(", "'---------DATASET TUPLE------------'", ",", "datasets_tuple", ".", "shape", ")", "\n", "train_set_x", ",", "train_set_y", "=", "datasets_tuple", "\n", "\n", "print", "(", "'---------DATASET TUPLE VALIDATION------------'", ",", "datasets_tuple_validation", ".", "shape", ")", "\n", "validation_set_x", ",", "validation_set_y", "=", "datasets_tuple_validation", "\n", "\n", "print", "(", "'---------DATASET TUPLE TEST------------'", ",", "datasets_tuple_test", ".", "shape", ")", "\n", "test_set_x", ",", "test_set_y", "=", "datasets_tuple_test", "\n", "\n", "print", "(", "'--------------X SHAPE-----------------'", ")", "\n", "channels_no", "=", "len", "(", "self", ".", "_modalities", ")", "if", "self", ".", "_modalities", "!=", "None", "else", "1", "\n", "self", ".", "_train_set_x_shape", "=", "np", ".", "load", "(", "datasets_tuple", "[", "0", ",", "0", "]", ")", ".", "shape", "+", "(", "channels_no", ",", ")", "\n", "# self._train_set_y_shape = self.get_label(datasets_tuple[1, 0]).shape", "\n", "# self._train_set_y_shape = (4,)", "\n", "# self._train_set_y_shape = (1,)", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "            ", "self", ".", "_train_set_x_shape", "=", "(", "self", ".", "_resize", ",", "self", ".", "_resize", ",", "channels_no", ")", "\n", "", "print", "(", "self", ".", "_train_set_x_shape", ")", "\n", "\n", "return", "train_set_x", ",", "train_set_y", ",", "validation_set_x", ",", "validation_set_y", ",", "test_set_x", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.load_file_names": [[75, 108], ["numpy.asarray", "open", "os.walk", "json.load", "fnmatch.filter", "f.find", "f.find", "str", "original_files.append", "label_files.append", "str", "re.findall", "original_files.append", "label_files.append", "int", "original_files.append", "label_files.append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_file_names", "(", "self", ",", "root", ",", "data_type", ")", ":", "\n", "        ", "original_files", "=", "[", "]", "\n", "label_files", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "_split_file", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "files_to_find", "=", "json", ".", "load", "(", "file", ")", "[", "data_type", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "                ", "if", "self", ".", "_modalities", "is", "not", "None", ":", "\n", "                    ", "reg_filter", "=", "'*_'", "+", "str", "(", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ")", "+", "'_*'", "\n", "for", "f", "in", "fnmatch", ".", "filter", "(", "files", ",", "reg_filter", ")", ":", "\n", "                        ", "idx", "=", "f", ".", "find", "(", "'_'", "+", "str", "(", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ")", ")", "\n", "# idx = f.find('_')", "\n", "label_file_name", "=", "f", "[", ":", "idx", "]", "\n", "if", "label_file_name", "in", "files_to_find", ":", "\n", "                            ", "fullname", "=", "root", "+", "'/'", "+", "f", "\n", "if", "self", ".", "_slices", "is", "not", "None", ":", "\n", "                                ", "slice", "=", "re", ".", "findall", "(", "'_([0-9][0-9]*)'", ",", "f", ")", "\n", "if", "self", ".", "_slices", "[", "0", "]", "<=", "int", "(", "slice", "[", "0", "]", ")", "<=", "self", ".", "_slices", "[", "1", "]", ":", "\n", "                                    ", "original_files", ".", "append", "(", "fullname", ")", "\n", "label_files", ".", "append", "(", "label_file_name", ")", "\n", "", "", "else", ":", "\n", "                                ", "original_files", ".", "append", "(", "fullname", ")", "\n", "label_files", ".", "append", "(", "label_file_name", ")", "\n", "", "", "", "", "else", ":", "\n", "                    ", "for", "f", "in", "files", ":", "\n", "                        ", "idx", "=", "f", ".", "find", "(", "'_'", ")", "\n", "label_file_name", "=", "f", "[", ":", "idx", "]", "\n", "if", "label_file_name", "in", "files_to_find", ":", "\n", "                            ", "fullname", "=", "root", "+", "'/'", "+", "f", "\n", "# idx = f.find('_' + str(modalities['T2']))", "\n", "original_files", ".", "append", "(", "fullname", ")", "\n", "label_files", ".", "append", "(", "label_file_name", ")", "\n", "", "", "", "", "", "dataset_tuple", "=", "[", "original_files", ",", "label_files", "]", "\n", "return", "np", ".", "asarray", "(", "dataset_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.get_label": [[109, 120], ["open", "json.load", "[].astype", "numpy.nonzero"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_label", "(", "self", ",", "filename", ")", ":", "\n", "# label = -1", "\n", "        ", "with", "open", "(", "self", ".", "_labels_file", ",", "'r'", ")", "as", "json_file", ":", "\n", "            ", "labels_dict", "=", "json", ".", "load", "(", "json_file", ")", "\n", "# pdb.set_trace()", "\n", "# if filename in labels_dict:", "\n", "label", "=", "np", ".", "nonzero", "(", "labels_dict", "[", "filename", "]", ")", "[", "0", "]", ".", "astype", "(", "np", ".", "int32", ")", "[", "0", "]", "\n", "# if label == 3:", "\n", "#     label = np.array([2], dtype=np.int32)[0]", "\n", "# return np.nonzero(labels_dict[filename])[0].astype(np.int32)[0]", "\n", "return", "label", "\n", "# return np.asarray(labels_dict[filename], dtype=np.int32)", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.dataset_map": [[126, 162], ["LabeledBrainDataset.LabeledBrainDataset.get_output_types", "LabeledBrainDataset.LabeledBrainDataset.get_output_shapes", "list", "dataset.map.map.map", "numpy.empty", "LabeledBrainDataset.LabeledBrainDataset.get_label", "zip", "enumerate", "LabeledBrainDataset.LabeledBrainDataset.load_slice_from_file", "numpy.array.reshape", "tuple", "str.replace", "LabeledBrainDataset.LabeledBrainDataset.load_slice_from_file", "str", "numpy.array", "tensorflow.py_func", "str", "str", "numpy.array", "PIL.Image.fromarray().resize", "PIL.Image.fromarray().resize", "PIL.Image.fromarray", "PIL.Image.fromarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.get_label", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file"], ["", "", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "label_filename", "=", "full_data", "[", "n", "]", "[", "1", "]", "\n", "result", "=", "np", ".", "empty", "(", "output_shapes", "[", "0", "]", ",", "np", ".", "float32", ")", "\n", "if", "self", ".", "_modalities", "!=", "None", ":", "\n", "                ", "for", "i", ",", "modality", "in", "enumerate", "(", "self", ".", "_modalities", ")", ":", "\n", "                    ", "modality_filename", "=", "str", ".", "replace", "(", "str", "(", "filename", ")", ",", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ",", "\n", "modalities", "[", "modality", "]", ")", "\n", "image", "=", "self", ".", "load_slice_from_file", "(", "str", "(", "modality_filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                        ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "result", "[", ":", ",", ":", ",", "i", "]", "=", "image", "\n", "", "", "else", ":", "\n", "# image = self.load_slice_from_file(self._data_dir + '/' + str(filename))", "\n", "                ", "image", "=", "self", ".", "load_slice_from_file", "(", "str", "(", "filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                    ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "result", "=", "image", ".", "reshape", "(", "[", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "", "label", "=", "self", ".", "get_label", "(", "label_filename", ")", "\n", "# label = np.reshape(label, [label.shape[0], label.shape[1], 1])", "\n", "return", "result", ",", "label", "\n", "# return result", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.get_output_shapes": [[164, 174], ["numpy.load().astype", "tuple", "len", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "channels_no", "=", "len", "(", "self", ".", "_modalities", ")", "if", "self", ".", "_modalities", "is", "not", "None", "else", "1", "\n", "# label = self.get_label(datasets_tuple[1][0]).astype(np.float32)", "\n", "# label = float(self.get_label(datasets_tuple[1][0]))", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "channels_no", ",", ")", ",", "(", ")", "]", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "            ", "output_shapes", "=", "(", "(", "self", ".", "_resize", ",", "self", ".", "_resize", ",", "channels_no", ")", ",", "(", ")", ")", "\n", "\n", "", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.get_output_types": [[176, 184], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "int32", "]", ")", "\n", "# label = self.get_label(datasets_tuple[1][0]).astype(np.float32)", "\n", "# label = float(self.get_label(datasets_tuple[1][0]))", "\n", "# output_types = tuple([tf.as_dtype(image.dtype), tf.as_dtype(label.dtype)])", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.label_to_name": [[185, 191], ["None"], "methods", ["None"], ["", "def", "label_to_name", "(", "self", ",", "label", ")", ":", "\n", "        ", "label_to_name_M_dict", "=", "{", "0", ":", "\"22-25\"", ",", "\n", "1", ":", "\"26-30\"", ",", "\n", "2", ":", "\"31-35\"", ",", "\n", "3", ":", "\"36+\"", "}", "\n", "return", "label_to_name_M_dict", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.x_shape": [[196, 200], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "x_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.x_shape_train": [[202, 205], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.x_shape_eval": [[212, 215], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.y_shape": [[217, 225], ["getattr", "ValueError"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "train_set_y", "=", "getattr", "(", "self", ",", "'train_set_y'", ",", "None", ")", "\n", "if", "train_set_y", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"this dataset does not have y set\"", ")", "\n", "# return self._train_set_y_shape", "\n", "", "return", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.n_labels": [[227, 234], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the number of labeles in this dataset\"\"\"", "\n", "if", "not", "self", ".", "_n_labels", ":", "\n", "            ", "self", ".", "_n_labels", "=", "self", ".", "_no_of_classes", "\n", "\n", "", "return", "self", ".", "_n_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LabeledBrainDataset.LabeledBrainDataset.labels": [[235, 242], ["numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the list of labels in this dataset\"\"\"", "\n", "if", "not", "self", ".", "_labels", ":", "\n", "            ", "self", ".", "_labels", "=", "np", ".", "asarray", "(", "[", "0", ",", "1", ",", "2", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "", "return", "self", ".", "_labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.__init__": [[53, 71], ["datasets.AudioDataset.AudioDataset.__init__", "HbiStet.HbiStet.dataset_id", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_sample_lenght", "=", "396900", "+", "412", "# 128 padded 0s  # used to be 88384 for sample rate 44100", "\n", "self", ".", "_sample_rate", "=", "44100", "\n", "self", ".", "_label", "=", "(", "self", ".", "_params", "[", "'label'", "]", "if", "self", ".", "_params", "[", "'label'", "]", "in", "ALL_LABELS_IMPLEMENTED", "else", "None", ")", "\n", "\n", "# self._n_labels = len(self._params['features']) if 'features' in self._params else 0", "\n", "self", ".", "_x_sample_shape_train", "=", "[", "self", ".", "_crop_length_train", ",", "1", "]", "\n", "self", ".", "_x_sample_shape_eval", "=", "[", "self", ".", "_sample_lenght", ",", "1", "]", "\n", "self", ".", "_y_sample_shape", "=", "None", "# (self._n_labels,)", "\n", "\n", "self", ".", "_n_labels", "=", "len", "(", "LABEL_TO_INT_DICT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.dataset_id": [[76, 95], ["HbiStet.check_params_impl", "params.get"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "HbiStet", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'HbiStet'", "\n", "\n", "# TODO I know this is bad but if id is a static method and not an object method I have no idea how to handle this better,", "\n", "# TODO soon we should refactor the id to be multilayer of abstraction as in Networks and Models.", "\n", "if", "params", "[", "'shuffle_buffer'", "]", "!=", "HbiStet", ".", "default_params", "[", "'shuffle_buffer'", "]", ":", "\n", "            ", "_id", "+=", "'-sh%.2e'", "%", "params", "[", "'shuffle_buffer'", "]", "\n", "\n", "", "if", "params", ".", "get", "(", "'anomaly_detection'", ",", "False", ")", ":", "\n", "            ", "_id", "+=", "'-anomaly_detection'", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.get_var_labels": [[96, 101], ["numpy.intersect1d", "len", "len"], "methods", ["None"], ["", "def", "get_var_labels", "(", "self", ",", "param", ")", ":", "\n", "        ", "var_params", "=", "np", ".", "intersect1d", "(", "ALL_LABELS", ",", "param", ")", "\n", "\n", "assert", "len", "(", "var_params", ")", "==", "len", "(", "param", ")", ",", "\"It seems like you might have a mistake in you label name\"", "\n", "return", "var_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet._parse_function": [[102, 119], ["tensorflow.parse_single_example", "tensorflow.expand_dims", "datasets.AudioDataset.AudioDataset.str_label_to_int", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset.str_label_to_int"], ["", "@", "staticmethod", "\n", "def", "_parse_function", "(", "example_proto", ",", "y_label", "=", "None", ")", ":", "\n", "        ", "features", "=", "{", "\n", "LABEL", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "NAME", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "AUDIO", ":", "tf", ".", "VarLenFeature", "(", "dtype", "=", "tf", ".", "float32", ")", ",", "#max 396900", "\n", "}", "\n", "parsed_features", "=", "tf", ".", "parse_single_example", "(", "example_proto", ",", "features", ")", "\n", "\n", "# Expand dims for channels", "\n", "audio", "=", "tf", ".", "expand_dims", "(", "tf", ".", "concat", "(", "parsed_features", "[", "AUDIO", "]", ".", "values", ",", "axis", "=", "0", ")", ",", "axis", "=", "-", "1", ")", "\n", "label", "=", "AudioDataset", ".", "str_label_to_int", "(", "parsed_features", "[", "y_label", "]", ",", "LABEL_TO_INT_DICT", ")", "\n", "\n", "if", "y_label", ":", "\n", "            ", "return", "(", "audio", ",", "label", ",", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "audio", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.get_dataset_iterator": [[120, 182], ["tensorflow.data.TFRecordDataset", "dataset.repeat.repeat.map", "dataset.repeat.repeat.cache", "dataset.repeat.repeat.map().map", "dataset.repeat.repeat.map().map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "HbiStet.HbiStet._parse_function", "len", "Exception", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "functools.partial", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi._parse_function"], ["", "", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ",", "perturb", ")", ":", "\n", "\n", "        ", "is_perturbed", "=", "False", "\n", "filename", "=", "\"\"", "\n", "\n", "# create Dataset objects using the data previously downloaded", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/train3-istet-float-shuffled.tfrecords\"", "\n", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/validation3-istet-float-shuffled.tfrecords\"", "\n", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/test_all-2.tfrecords\"", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "# CREATE TF DATASET with map and py_func", "\n", "", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "[", "filename", "]", ")", "\n", "\n", "NPROCS", "=", "20", "\n", "if", "self", ".", "_label", ":", "\n", "            ", "parse_func", "=", "lambda", "x", ":", "self", ".", "_parse_function", "(", "x", ",", "y_label", "=", "self", ".", "_label", ")", "\n", "", "else", ":", "\n", "            ", "parse_func", "=", "self", ".", "_parse_function", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "parse_func", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "# PREPROCESS DATA (AUGMENT IF NEEDED)", "\n", "if", "augment", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ",", "self", ".", "_crop_length_train", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", ".", "map", "(", "self", ".", "augment_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "if", "dataset_str", "==", "TEST", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ",", "self", ".", "_crop_length_train", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", ".", "map", "(", "self", ".", "augment_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# handle perturbation", "\n", "", "if", "is_perturbed", "and", "len", "(", "self", ".", "_data_perturbation", ")", ">", "0", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "perturb_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "duplicate_x_element_if_needed", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# SHUFFLE, REPEAT and BATCH", "\n", "", "if", "shuffle", ":", "\n", "            ", "LARGE_NUMBER", "=", "self", ".", "_shuffle_buffer", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "LARGE_NUMBER", "+", "1", ")", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.int_to_str_label": [[183, 188], ["LABEL_TO_INT_DICT.items"], "methods", ["None"], ["", "def", "int_to_str_label", "(", "self", ",", "int_label", ":", "int", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "LABEL_TO_INT_DICT", ".", "items", "(", ")", ":", "\n", "            ", "if", "int_label", "==", "value", ":", "\n", "                ", "return", "key", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.n_samples_train": [[189, 192], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "95", "\n", "# full size: 176 - 52(test) -29(valid) = 95", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.x_shape_train": [[194, 198], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.x_shape_eval": [[199, 203], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.y_shape": [[204, 208], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HbiStet.HbiStet.sample_rate": [[209, 213], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_sample_rate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.__init__": [[21, 41], ["numpy.random.seed", "numpy.eye", "numpy.zeros", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.linalg.cholesky", "numpy.dot", "numpy.dot", "numpy.eye"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed"], ["def", "__init__", "(", "self", ",", "dim_x", ",", "dim_z", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "self", ".", "n_x", "=", "dim_x", "\n", "self", ".", "n_z", "=", "dim_z", "\n", "\n", "# z ~ N(0, I):", "\n", "self", ".", "sigma_z", "=", "np", ".", "eye", "(", "dim_z", ")", "\n", "self", ".", "mu_z", "=", "np", ".", "zeros", "(", "dim_z", ")", "\n", "\n", "# X|Z=z ~ N(Wz+b, Sigma_x_z)", "\n", "self", ".", "W", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "size", "=", "(", "dim_x", ",", "dim_z", ")", ")", "\n", "self", ".", "b", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "dim_x", ")", "\n", "aux_sigma", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "size", "=", "(", "dim_x", ",", "dim_x", ")", ")", "\n", "self", ".", "sigma_x_z", "=", "np", ".", "dot", "(", "aux_sigma", ",", "aux_sigma", ".", "T", ")", "+", "0.5", "*", "np", ".", "eye", "(", "dim_x", ")", "\n", "\n", "# Cholesky factor of the covariance of the observed variable X (needed for sampling)", "\n", "self", ".", "chol_sigma_x_z", "=", "np", ".", "linalg", ".", "cholesky", "(", "self", ".", "sigma_x_z", ")", "\n", "\n", "# X + N(b, W*W^T + Sigma_x, z)", "\n", "self", ".", "sigma_x", "=", "np", ".", "dot", "(", "self", ".", "W", ",", "self", ".", "W", ".", "T", ")", "+", "self", ".", "sigma_x_z", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset": [[43, 50], ["numpy.random.normal", "numpy.random.normal", "numpy.dot", "numpy.dot"], "methods", ["None"], ["", "def", "create_dataset", "(", "self", ",", "n_samples", ")", ":", "\n", "        ", "\"\"\" Sample n_samples from X ~ N(mu_x, Sigma_x), generated by first sampling from Z\n        \"\"\"", "\n", "z", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "size", "=", "(", "n_samples", ",", "self", ".", "n_z", ")", ")", "\n", "eps", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "size", "=", "(", "n_samples", ",", "self", ".", "n_x", ")", ")", "\n", "data", "=", "np", ".", "dot", "(", "z", ",", "self", ".", "W", ".", "T", ")", "+", "self", ".", "b", "+", "np", ".", "dot", "(", "eps", ",", "self", ".", "chol_sigma_x_z", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.compute_posterior": [[52, 60], ["numpy.linalg.solve", "scipy.stats.multivariate_normal.pdf", "numpy.dot", "numpy.dot", "numpy.dot", "numpy.linalg.inv"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.solve"], ["", "def", "compute_posterior", "(", "self", ",", "x", ",", "z", ")", ":", "\n", "        ", "\"\"\" Compute the posterior and its parameters: p(z|x), mu_z_x, sigma_z_x\n        \"\"\"", "\n", "solver", "=", "np", ".", "linalg", ".", "solve", "(", "self", ".", "sigma_x", ",", "x", "-", "self", ".", "b", ")", "\n", "mu_z_x", "=", "self", ".", "mu_z", "+", "np", ".", "dot", "(", "self", ".", "W", ".", "T", ",", "solver", ")", "\n", "sigma_z_x", "=", "self", ".", "sigma_z", "-", "np", ".", "dot", "(", "self", ".", "W", ".", "T", ",", "np", ".", "dot", "(", "np", ".", "linalg", ".", "inv", "(", "self", ".", "sigma_x", ")", ",", "self", ".", "W", ")", ")", "\n", "pdf", "=", "multivariate_normal", ".", "pdf", "(", "z", ",", "mu_z_x", ",", "sigma_z_x", ")", "\n", "return", "pdf", ",", "mu_z_x", ",", "sigma_z_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.compute_log_likelihood": [[62, 67], ["scipy.stats.multivariate_normal.pdf", "numpy.mean", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "compute_log_likelihood", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" True log likelihood of the data\n        \"\"\"", "\n", "p_x", "=", "multivariate_normal", ".", "pdf", "(", "x", ",", "self", ".", "b", ",", "self", ".", "sigma_x", ")", "\n", "return", "np", ".", "mean", "(", "np", ".", "log", "(", "p_x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.load": [[69, 81], ["syn_multivar_gaussian.MultivariateGaussianData", "syn_multivar_gaussian.MultivariateGaussianData.create_dataset"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset"], ["", "", "def", "load", "(", "n_x", ",", "n_z", ",", "n_samples_train", ",", "n_samples_test", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "multivarGaussData", "=", "MultivariateGaussianData", "(", "n_x", ",", "n_z", ")", "\n", "generatedX", "=", "multivarGaussData", ".", "create_dataset", "(", "n_samples_train", "+", "n_samples_test", ")", "\n", "data", "[", "\"gaussian_class\"", "]", "=", "multivarGaussData", "\n", "data", "[", "\"train_set_x\"", "]", "=", "generatedX", "[", ":", "n_samples_train", "]", "\n", "data", "[", "\"test_set_x\"", "]", "=", "generatedX", "[", "n_samples_train", ":", "]", "\n", "data", "[", "\"n_samples_train\"", "]", "=", "n_samples_train", "\n", "data", "[", "\"n_samples_test\"", "]", "=", "n_samples_test", "\n", "data", "[", "\"input_size\"", "]", "=", "n_x", "\n", "data", "[", "\"binary\"", "]", "=", "0", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.__init__": [[73, 143], ["ImageDataset.ImageDataset.__init__", "CMB_multifilters.CMB_multifilters.dataset_id", "CMB_multifilters.CMB_multifilters.compute_min_max_data", "CMB_multifilters.CMB_multifilters.load_dataset", "CMB_multifilters.CMB_multifilters.load_dataset", "CMB_multifilters.CMB_multifilters.load_dataset", "Exception", "open", "json.loads", "numpy.load", "os.path.exists", "os.path.isdir", "f.read"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.compute_min_max_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_json_filename", "=", "\"params.json\"", "\n", "fraction_dataset", "=", "params", "[", "'fraction_dataset'", "]", "\n", "\n", "# self._csv_filename = \"labels_file.csv\"", "\n", "if", "fraction_dataset", "==", "100", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data.csv'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data_{}.csv'", ".", "format", "(", "fraction_dataset", ")", "\n", "# label_df_Train = pd.read_csv(self._csv_filename_Train, sep=\"\\t\")", "\n", "\n", "", "self", ".", "_csv_filename_Test", "=", "'Test_CMB_data.csv'", "\n", "# label_df_Test = pd.read_csv(self._csv_filename_Test, sep=\"\\t\")", "\n", "\n", "self", ".", "_csv_filename_Validation", "=", "'Validation_CMB_data.csv'", "\n", "# label_df_Validation = pd.read_csv(self._csv_filename_Validation, sep=\"\\t\")", "\n", "\n", "# self._all_parameter_list = ['h', 'omega_b', 'omega_cdm', 'A_s', 'n_s', 'tau_reio']", "\n", "self", ".", "_parameters_list", "=", "params", "[", "\"parameters\"", "]", "\n", "self", ".", "_fraction_dataset", "=", "params", "[", "\"fraction_dataset\"", "]", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_normalize_labels", "=", "self", ".", "_params", "[", "'normalize_labels'", "]", "\n", "self", ".", "_normalize_images", "=", "self", ".", "_params", "[", "'normalize_images'", "]", "\n", "\n", "\n", "# check if the data directory is present", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_data_dir", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_data_dir", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Dataset directory {}'", "\n", "' not found'", ".", "format", "(", "self", ".", "_data_dir", ")", "\n", ")", "\n", "\n", "#self._debug_mode = params['debug_mode']", "\n", "\n", "#self._augment_data = params['augm_data']", "\n", "#self._only_center = params['only_center']", "\n", "", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "self", ".", "_json_filename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "picture_size", "=", "128", "#conf_dict[\"pic_size\"]", "\n", "#self._x_sample_shape = (picture_size, picture_size, 3)", "\n", "#self._y_sample_shape = (self._n_params,)", "\n", "\n", "#self._var_params = self.conf_dict['params'] # TODO Check that is sorted like self.parameter_list", "\n", "\n", "# useful for lazy load, however I need to reimplement some methods to make it work", "\n", "# self._loaded_from_disk = False", "\n", "\n", "#self._train_set_x = None", "\n", "#self._train_set_y = None", "\n", "#self._test_set_x = None", "\n", "#self._test_set_y = None", "\n", "\n", "#self._n_samples_train = None", "\n", "#self._n_samples_test = None", "\n", "self", ".", "_labels_min", ",", "self", ".", "_labels_max", ",", "self", ".", "_data_min", ",", "self", ".", "_data_max", "=", "self", ".", "compute_min_max_data", "(", "norm_labels", "=", "self", ".", "_normalize_labels", ",", "\n", "norm_data", "=", "self", ".", "_normalize_images", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "load_dataset", "(", "TRAIN", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "load_dataset", "(", "VALIDATION", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset", "(", "TEST", ")", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "self", ".", "_x_sample_shape", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "self", ".", "_train_set_x", "[", "0", "]", ")", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.dataset_id": [[148, 182], ["Exception", "os.path.basename", "str", "str", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "# CMB.check_params_impl(params)", "\n", "\n", "p_dist_abbr", "=", "{", "'uniform'", ":", "'U'", ",", "\n", "'lattice'", ":", "'L'", "}", "\n", "\n", "raise", "Exception", "(", "\"ERROR: you cannot run me if my name is wrong! :) fix me :) \"", ")", "\n", "\n", "id", "=", "'CMBPol'", "\n", "id", "+=", "os", ".", "path", ".", "basename", "(", "params", "[", "'data_dir'", "]", ")", "\n", "id", "+=", "'-d%'", "+", "str", "(", "params", "[", "'fraction_dataset'", "]", ")", "\n", "id", "+=", "'-pdim'", "+", "str", "(", "len", "(", "params", "[", "'parameters'", "]", ")", ")", "\n", "id", "+=", "'-n'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_images'", "]", "==", "True", "else", "'0'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_labels'", "]", "==", "True", "else", "'0'", "\n", "#id += '-au1' if self._augment_data == True  else '-au0'", "\n", "#id += '-oc1' if self._only_center == True else '-oc0'", "\n", "\n", "\n", "# id += '-' + p_dist_abbr[params['par_distr']]", "\n", "# id += '-pprr' + str(params['pic_per_run_rot'])", "\n", "# id += '-ppre' + str(params['pic_per_run_equator'])", "\n", "\n", "# id note (keep last)", "\n", "#if params['id_note']:", "\n", "#    id += params['id_note']", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.read_metadata": [[184, 194], ["pandas.read_csv", "open", "json.loads", "f.read"], "methods", ["None"], ["", "def", "read_metadata", "(", "self", ",", "json_basename", ",", "csv_basename", ")", ":", "\n", "#load json file", "\n", "        ", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "json_basename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "csv_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "csv_basename", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "return", "conf_dict", ",", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.get_output_shapes": [[196, 201], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "#output_shapes = tuple([image.shape + (1,), datasets_tuple[1].shape[1]])", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", ",", "datasets_tuple", "[", "1", "]", ".", "shape", "[", "1", "]", "]", ")", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.get_output_types": [[202, 207], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "as_dtype", "(", "datasets_tuple", "[", "1", "]", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.dataset_map": [[211, 238], ["CMB_multifilters.CMB_multifilters.get_output_types", "CMB_multifilters.CMB_multifilters.get_output_shapes", "list", "dataset.map.map.map", "numpy.load", "zip", "numpy.load.astype", "tuple", "tensorflow.py_func"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "channels", "=", "output_shapes", "[", "0", "]", "[", "2", "]", "\n", "norm_bool", "=", "self", ".", "_normalize_images", "\n", "data_min", "=", "self", ".", "_data_min", "\n", "data_max", "=", "self", ".", "_data_max", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "label", "=", "full_data", "[", "n", "]", "[", "1", "]", "\n", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "filename", ")", "\n", "if", "norm_bool", ":", "\n", "                ", "image", "=", "2", "*", "(", "image", "-", "data_min", ")", "/", "(", "data_max", "-", "data_min", ")", "-", "1.", "\n", "\n", "\n", "", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "label", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.load_dataset": [[240, 328], ["CMB_multifilters.CMB_multifilters.read_metadata", "len", "print", "df_dataset[].values.astype", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.read_metadata"], ["", "def", "load_dataset", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "\"\"\"\n        load the dataset in memory and set in the object\n\n        Args:\n            train_test_ratio: (float) percentage of the dataset in train\n\n        \"\"\"", "\n", "json_filename", "=", "self", ".", "_json_filename", "\n", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Train", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Validation", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Test", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"`dataset_str` can be only: train, validation or test.\"", ")", "\n", "\n", "# get info from the metadata", "\n", "", "conf_dict", ",", "labels_filter_df", "=", "self", ".", "read_metadata", "(", "json_filename", ",", "csv_filename", ")", "\n", "#self._picture_size = self.conf_dict['pic_size']", "\n", "n_parameters", "=", "len", "(", "conf_dict", ")", "\n", "\n", "#if self._only_center:", "\n", "#    labels_filter_df = labels_filter_df[labels_filter_df['is_center']]", "\n", "\n", "#if not self._augment_data:", "\n", "#    # no rotations", "\n", "#    is_no_rotation = labels_filter_df['rot_angle'] == 0", "\n", "#    labels_filter_df = labels_filter_df[is_no_rotation]", "\n", "\n", "#    # no flips", "\n", "#    index_no_flip = ~labels_filter_df['flip']", "\n", "#    labels_filter_df = labels_filter_df[index_no_flip]", "\n", "\n", "\n", "'''\n        if self._debug_mode:\n            debug_dimension = 500\n            labels_filter_df = labels_filter_df.iloc[:debug_dimension]\n        '''", "\n", "\n", "# dataset_x = labels_filter_df.sample(frac=1)", "\n", "df_dataset", "=", "labels_filter_df", "\n", "num_files", "=", "df_dataset", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'{} are going to be loaded in memory'", ".", "format", "(", "num_files", ")", ")", "\n", "\n", "filename_dataset", "=", "df_dataset", "[", "'filename'", "]", ".", "values", "\n", "labels_dataset", "=", "df_dataset", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "\n", "if", "self", ".", "_normalize_labels", ":", "\n", "            ", "labels_dataset", "=", "2", "*", "(", "labels_dataset", "-", "self", ".", "_labels_min", ")", "/", "(", "self", ".", "_labels_max", "-", "self", ".", "_labels_min", ")", "-", "1.", "\n", "\n", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "# dim_train = int(num_files * train_ratio)", "\n", "# dim_validation = int(num_files * validation_ratio)", "\n", "# dim_test = num_files - dim_train - dim_validation", "\n", "#", "\n", "# # training", "\n", "# df_train = dataset_x.iloc[0 : dim_train]", "\n", "# filename_training = df_train['filename'].values", "\n", "# labels_training = df_train[['omega_cdm', 'A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     max_training = np.max(labels_training, axis=0)", "\n", "#     min_training = np.min(labels_training, axis=0)", "\n", "#     labels_training = (labels_training - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_validation = dataset_x.iloc[dim_train : (dim_train+dim_validation)]", "\n", "# filename_validation = df_validation['filename'].values", "\n", "# labels_validation = df_validation[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_validation = (labels_validation - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_test = dataset_x.iloc[(dim_train+dim_validation):]", "\n", "# filename_test = df_test['filename'].values", "\n", "# labels_test = df_test[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_test = (labels_test - min_training)/(max_training - min_training)", "\n", "#", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "\n", "", "return", "filename_dataset", ",", "labels_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.compute_min_max_data": [[329, 358], ["pandas.read_csv", "numpy.min", "numpy.max", "label_df[].values.astype", "numpy.min", "numpy.max", "numpy.load", "all_min_0.append", "all_max_0.append", "numpy.min", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "compute_min_max_data", "(", "self", ",", "norm_labels", "=", "False", ",", "norm_data", "=", "False", ")", ":", "\n", "        ", "all_max_0", "=", "[", "]", "\n", "all_min_0", "=", "[", "]", "\n", "csv_filename", "=", "self", ".", "_data_dir", "+", "'/labels_file.csv'", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "labels_min", "=", "None", "\n", "labels_max", "=", "None", "\n", "data_min", "=", "[", "]", "\n", "data_max", "=", "[", "]", "\n", "\n", "if", "norm_data", ":", "\n", "            ", "filenames", "=", "label_df", "[", "'filename'", "]", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "                ", "patch1", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "\"/\"", "+", "filename", ")", "\n", "all_min_0", ".", "append", "(", "np", ".", "min", "(", "patch1", ")", ")", "\n", "all_max_0", ".", "append", "(", "np", ".", "max", "(", "patch1", ")", ")", "\n", "\n", "\n", "", "data_min", "=", "np", ".", "min", "(", "all_min_0", ")", "\n", "data_max", "=", "np", ".", "max", "(", "all_max_0", ")", "\n", "\n", "", "if", "norm_labels", ":", "\n", "            ", "labels", "=", "label_df", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "labels_min", "=", "np", ".", "min", "(", "labels", ",", "axis", "=", "0", ")", "\n", "labels_max", "=", "np", ".", "max", "(", "labels", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "labels_min", ",", "labels_max", ",", "data_min", ",", "data_max", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.labels_min_training": [[359, 371], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_min_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#", "\n", "#if  self._dataset_x_min is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "\n", "        ", "return", "self", ".", "_labels_min_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.labels_max_training": [[372, 383], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_max_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#\u00a7", "\n", "#if  self._dataset_x_max is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "        ", "return", "self", ".", "_labels_max_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.x_shape_train": [[384, 388], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters.CMB_multifilters.x_shape_eval": [[389, 441], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the evaluation\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_train(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_eval(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "#return mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels, mnist.test.images, mnist.test.labels", "\n", "\n", "\n", "#start_time_data = timeit.default_timer()", "\n", "\n", "#shape_X = (n_files,) + self._x_sample_shape", "\n", "#shape_Y = (n_files,) + self._y_sample_shape", "\n", "\n", "# construct the datasets", "\n", "#X = np.empty(shape_X)", "\n", "#Y = np.empty(shape_Y)", "\n", "\n", "#for ix, row in  labels_filter_df.iterrows():", "\n", "#    tmp_numpy = np.load(self._data_dir + \"/\" + row['filename'])", "\n", "#", "\n", "#    X[ix, :, :, 0] = tmp_numpy", "\n", "#    Y[ix] = row[self._var_params]", "\n", "\n", "# print time for the load", "\n", "#step_time = timeit.default_timer()", "\n", "#print(\"time needed to load: \", step_time - start_time_data)", "\n", "\n", "# shuffle the dataset", "\n", "'''\n        randomized_dataset_index = np.random.permutation(n_files)\n        X = X[randomized_dataset_index]\n        Y = Y[randomized_dataset_index]\n\n\n\n\n\n\n        dim_train = int(n_files * train_test_ratio)\n        self._train_set_x, self._train_set_y = X[:dim_train] , Y[:dim_train]\n        self._test_set_x, self._test_set_y = X[dim_train:], Y[dim_train:]\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.PerturbedDecorator.PerturbedDecorator.__init__": [[11, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "perturbed_id", ")", ":", "\n", "        ", "self", ".", "_perturbed_id", "=", "perturbed_id", "\n", "self", ".", "_train_set_x_fileName", "=", "None", "\n", "self", ".", "_validation_set_x_fileName", "=", "None", "\n", "self", ".", "_test_set_x_fileName", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.PerturbedDecorator.PerturbedDecorator.train_set_x_fileName": [[21, 24], ["None"], "methods", ["None"], ["", "@", "train_set_x_fileName", ".", "setter", "\n", "def", "train_set_x_fileName", "(", "self", ",", "train_set_x_fileName", ")", ":", "\n", "        ", "self", ".", "_train_set_x_fileName", "=", "train_set_x_fileName", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.PerturbedDecorator.PerturbedDecorator.validation_set_x_fileName": [[29, 32], ["None"], "methods", ["None"], ["", "@", "validation_set_x_fileName", ".", "setter", "\n", "def", "validation_set_x_fileName", "(", "self", ",", "validation_set_x_fileName", ")", ":", "\n", "        ", "self", ".", "_validation_set_x_fileName", "=", "validation_set_x_fileName", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.PerturbedDecorator.PerturbedDecorator.test_set_x_fileName": [[37, 40], ["None"], "methods", ["None"], ["", "@", "test_set_x_fileName", ".", "setter", "\n", "def", "test_set_x_fileName", "(", "self", ",", "test_set_x_fileName", ")", ":", "\n", "        ", "self", ".", "_test_set_x_fileName", "=", "test_set_x_fileName", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.PerturbedDecorator.PerturbedDecorator.__call__": [[41, 87], ["numpy.load", "numpy.load", "numpy.load", "PerturbedDecorator.PerturbedDecorator.preprocess_x_y", "PerturbedDecorator.PerturbedDecorator.preprocess_x_y", "PerturbedDecorator.PerturbedDecorator.preprocess_x_y"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.preprocess_x_y", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.preprocess_x_y", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NPY.NPY.preprocess_x_y"], ["", "def", "__call__", "(", "self", ",", "cls", ")", ":", "\n", "\n", "        ", "class", "PerturbedDataset", "(", "cls", ")", ":", "\n", "\n", "            ", "perturbed_cls", "=", "cls", "\n", "\n", "# every time this class is defined as a new class", "\n", "# thus being static is not an issue", "\n", "perturbed_train_set_x_fileName", "=", "self", ".", "_train_set_x_fileName", "\n", "perturbed_validation_set_x_fileName", "=", "self", ".", "_validation_set_x_fileName", "\n", "perturbed_test_set_x_fileName", "=", "self", ".", "_test_set_x_fileName", "\n", "perturbed_id", "=", "self", ".", "_perturbed_id", "\n", "\n", "_perturbed_train_set_x", "=", "None", "\n", "_perturbed_validation_set_x", "=", "None", "\n", "_perturbed_test_set_x", "=", "None", "\n", "\n", "@", "property", "\n", "def", "perturbed_train_set_x", "(", "self", ")", ":", "\n", "                ", "if", "self", ".", "_perturbed_train_set_x", "is", "None", "and", "self", ".", "perturbed_train_set_x_fileName", ":", "\n", "                    ", "perturbed_train_set_x", "=", "np", ".", "load", "(", "self", ".", "perturbed_train_set_x_fileName", ")", "\n", "self", ".", "_perturbed_train_set_x", "=", "self", ".", "preprocess_x_y", "(", "perturbed_train_set_x", ",", "None", ")", "[", "0", "]", "# return only x, ignore y", "\n", "\n", "", "return", "self", ".", "_perturbed_train_set_x", "\n", "\n", "", "@", "property", "\n", "def", "perturbed_validation_set_x", "(", "self", ")", ":", "\n", "                ", "if", "self", ".", "_perturbed_validation_set_x", "is", "None", "and", "self", ".", "perturbed_validation_set_x_fileName", ":", "\n", "                    ", "perturbed_validation_set_x", "=", "np", ".", "load", "(", "self", ".", "perturbed_validation_set_x_fileName", ")", "\n", "self", ".", "_perturbed_validation_set_x", "=", "self", ".", "preprocess_x_y", "(", "perturbed_validation_set_x", ",", "None", ")", "[", "0", "]", "# return only x, ignore y", "\n", "\n", "", "return", "self", ".", "_perturbed_validation_set_x", "\n", "\n", "", "@", "property", "\n", "def", "perturbed_test_set_x", "(", "self", ")", ":", "\n", "                ", "if", "self", ".", "_perturbed_test_set_x", "is", "None", "and", "self", ".", "perturbed_test_set_x_fileName", ":", "\n", "                    ", "perturbed_test_set_x", "=", "np", ".", "load", "(", "self", ".", "perturbed_test_set_x_fileName", ")", "\n", "self", ".", "_perturbed_test_set_x", "=", "self", ".", "preprocess_x_y", "(", "perturbed_test_set_x", ",", "None", ")", "[", "0", "]", "# return only x, ignore y", "\n", "\n", "", "return", "self", ".", "_perturbed_test_set_x", "\n", "\n", "", "@", "property", "\n", "def", "id", "(", "self", ")", ":", "\n", "                ", "return", "self", ".", "_params", "[", "\"dataName\"", "]", "+", "\"-\"", "+", "self", ".", "perturbed_id", "\n", "\n", "", "", "return", "PerturbedDataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Leaf.Leaf.__init__": [[34, 49], ["Dataset.Dataset.__init__", "Leaf.Leaf.dataset_id", "Leaf.Leaf.read_labels", "Leaf.Leaf.load_data"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.read_labels", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "\n", "# get info from the metadata", "\n", "self", ".", "labels_df", "=", "self", ".", "read_labels", "(", ")", "\n", "\n", "self", ".", "_binary_input", "=", "True", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Leaf.Leaf.dataset_id": [[50, 60], ["Leaf.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "Leaf", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'Leaf'", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Leaf.Leaf.read_labels": [[61, 75], ["pandas.read_csv", "pandas.read_csv"], "methods", ["None"], ["", "def", "read_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return:\n        \"\"\"", "\n", "# load csv file", "\n", "train_csv_filename", "=", "self", ".", "_data_dir", "+", "'/train.csv'", "\n", "test_csv_filename", "=", "self", ".", "_data_dir", "+", "'/test.csv'", "\n", "train_label_df", "=", "pd", ".", "read_csv", "(", "train_csv_filename", ")", "\n", "test_label_df", "=", "pd", ".", "read_csv", "(", "test_csv_filename", ")", "\n", "\n", "label_df", "=", "{", "\n", "\"train\"", ":", "train_label_df", ",", "\n", "\"test\"", ":", "test_label_df", "}", "\n", "return", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Leaf.Leaf.load_data": [[76, 114], ["numpy.take", "numpy.asarray", "numpy.take", "numpy.random.permutation", "numpy.expand_dims", "numpy.asarray", "numpy.take", "numpy.random.permutation", "numpy.expand_dims", "numpy.load().astype", "numpy.load().astype", "numpy.load", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_data", "(", "self", ")", ":", "\n", "# Original size of data is huuuge", "\n", "# fileName = self._data_dir + '/images.npy'", "\n", "        ", "fileName", "=", "self", ".", "_data_dir", "+", "'/images_small.npy'", "\n", "order_fileName", "=", "self", ".", "_data_dir", "+", "'/order_images.npy'", "\n", "\n", "order", "=", "np", ".", "load", "(", "order_fileName", ")", ".", "astype", "(", "np", ".", "int32", ")", "-", "1", "\n", "X", "=", "np", ".", "load", "(", "fileName", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255", "\n", "X", "=", "np", ".", "take", "(", "X", ",", "order", ",", "axis", "=", "0", ")", "\n", "n_files", "=", "X", ".", "shape", "[", "0", "]", "\n", "\n", "# train", "\n", "train_Y", "=", "np", ".", "asarray", "(", "self", ".", "labels_df", "[", "\"train\"", "]", "[", "\"id\"", "]", "-", "1", ")", "\n", "\n", "train_X", "=", "np", ".", "take", "(", "X", ",", "train_Y", ",", "axis", "=", "0", ")", "\n", "train_files", "=", "train_X", ".", "shape", "[", "0", "]", "\n", "\n", "randomized_dataset_index", "=", "np", ".", "random", ".", "permutation", "(", "train_files", ")", "\n", "train_X", "=", "np", ".", "expand_dims", "(", "train_X", "[", "randomized_dataset_index", "]", ",", "axis", "=", "-", "1", ")", "\n", "train_Y", "=", "train_Y", "[", "randomized_dataset_index", "]", "\n", "\n", "# test", "\n", "test_Y", "=", "np", ".", "asarray", "(", "self", ".", "labels_df", "[", "\"test\"", "]", "[", "\"id\"", "]", "-", "1", ")", "\n", "\n", "test_X", "=", "np", ".", "take", "(", "X", ",", "test_Y", ",", "axis", "=", "0", ")", "\n", "test_files", "=", "test_X", ".", "shape", "[", "0", "]", "\n", "\n", "randomized_dataset_index", "=", "np", ".", "random", ".", "permutation", "(", "test_files", ")", "\n", "test_X", "=", "np", ".", "expand_dims", "(", "test_X", "[", "randomized_dataset_index", "]", ",", "axis", "=", "-", "1", ")", "\n", "test_Y", "=", "test_Y", "[", "randomized_dataset_index", "]", "\n", "\n", "val_split", "=", "train_files", "-", "self", ".", "_params", "[", "'test_and_validation'", "]", "\n", "\n", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "=", "train_X", "[", ":", "val_split", "]", ",", "train_X", "[", "val_split", ":", "]", ",", "test_X", "\n", "# train_set_y, validation_set_y, test_set_y = train_Y[:val_split], train_Y[val_split:], test_Y", "\n", "train_set_y", ",", "validation_set_y", ",", "test_set_y", "=", "None", ",", "None", ",", "None", "\n", "\n", "return", "train_set_x", ",", "train_set_y", ",", "validation_set_x", ",", "validation_set_y", ",", "test_set_x", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Leaf.Leaf.color_images": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Leaf.Leaf.image_shape": [[119, 122], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "(", "32", ",", "50", ",", "1", ")", "# the last number is the channel", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.__init__": [[73, 144], ["ImageDataset.ImageDataset.__init__", "LSS.LSS.dataset_id", "LSS.LSS.compute_min_max_data", "LSS.LSS.load_dataset", "LSS.LSS.load_dataset", "LSS.LSS.load_dataset", "Exception", "open", "json.loads", "os.path.exists", "os.path.isdir", "f.read"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.compute_min_max_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_json_filename", "=", "\"paramslss.json\"", "\n", "fraction_dataset", "=", "params", "[", "'fraction_dataset'", "]", "\n", "\n", "# self._csv_filename = \"labels_file.csv\"", "\n", "if", "fraction_dataset", "==", "100", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_LSS_data.csv'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_LSS_data_{}.csv'", ".", "format", "(", "fraction_dataset", ")", "\n", "# label_df_Train = pd.read_csv(self._csv_filename_Train, sep=\"\\t\")", "\n", "\n", "", "self", ".", "_csv_filename_Test", "=", "'Test_LSS_data.csv'", "\n", "# label_df_Test = pd.read_csv(self._csv_filename_Test, sep=\"\\t\")", "\n", "\n", "self", ".", "_csv_filename_Validation", "=", "'Validation_LSS_data.csv'", "\n", "# label_df_Validation = pd.read_csv(self._csv_filename_Validation, sep=\"\\t\")", "\n", "\n", "# self._all_parameter_list = ['h', 'omega_b', 'omega_cdm', 'A_s', 'n_s', 'tau_reio']", "\n", "self", ".", "_parameters_list", "=", "params", "[", "\"parameters\"", "]", "\n", "self", ".", "_fraction_dataset", "=", "params", "[", "\"fraction_dataset\"", "]", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_normalize_labels", "=", "self", ".", "_params", "[", "'normalize_labels'", "]", "\n", "self", ".", "_normalize_images", "=", "self", ".", "_params", "[", "'normalize_images'", "]", "\n", "\n", "\n", "# check if the data directory is present", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_data_dir", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_data_dir", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Dataset directory {}'", "\n", "' not found'", ".", "format", "(", "self", ".", "_data_dir", ")", "\n", ")", "\n", "\n", "#self._debug_mode = params['debug_mode']", "\n", "\n", "#self._augment_data = params['augm_data']", "\n", "#self._only_center = params['only_center']", "\n", "", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "self", ".", "_json_filename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "picture_size", "=", "conf_dict", "[", "\"pic_size\"", "]", "\n", "self", ".", "_x_sample_shape", "=", "(", "picture_size", ",", "picture_size", ",", "1", ")", "\n", "#self._y_sample_shape = (self._n_params,)", "\n", "\n", "#self._var_params = self.conf_dict['params'] # TODO Check that is sorted like self.parameter_list", "\n", "\n", "# useful for lazy load, however I need to reimplement some methods to make it work", "\n", "# self._loaded_from_disk = False", "\n", "\n", "#self._train_set_x = None", "\n", "#self._train_set_y = None", "\n", "#self._test_set_x = None", "\n", "#self._test_set_y = None", "\n", "\n", "#self._n_samples_train = None", "\n", "#self._n_samples_test = None", "\n", "self", ".", "_labels_min", ",", "self", ".", "_labels_max", ",", "self", ".", "_data_min", ",", "self", ".", "_data_max", "=", "self", ".", "compute_min_max_data", "(", "norm_labels", "=", "self", ".", "_normalize_labels", ",", "\n", "norm_data", "=", "self", ".", "_normalize_images", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "load_dataset", "(", "TRAIN", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "load_dataset", "(", "VALIDATION", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset", "(", "TEST", ")", "\n", "\n", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "# self._shuffling_cache = 3000", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.dataset_id": [[148, 180], ["os.path.basename", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "# CMB.check_params_impl(params)", "\n", "\n", "p_dist_abbr", "=", "{", "'uniform'", ":", "'U'", ",", "\n", "'lattice'", ":", "'L'", "}", "\n", "\n", "id", "=", "'LSS'", "\n", "id", "+=", "os", ".", "path", ".", "basename", "(", "params", "[", "'data_dir'", "]", ")", "\n", "id", "+=", "'-d%'", "+", "str", "(", "params", "[", "'fraction_dataset'", "]", ")", "\n", "\n", "id", "+=", "'-n'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_images'", "]", "==", "True", "else", "'0'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_labels'", "]", "==", "True", "else", "'0'", "\n", "#id += '-au1' if self._augment_data == True  else '-au0'", "\n", "#id += '-oc1' if self._only_center == True else '-oc0'", "\n", "\n", "# id += '-pdim' + str(params['params_dim'])", "\n", "# id += '-' + p_dist_abbr[params['par_distr']]", "\n", "# id += '-pprr' + str(params['pic_per_run_rot'])", "\n", "# id += '-ppre' + str(params['pic_per_run_equator'])", "\n", "\n", "# id note (keep last)", "\n", "#if params['id_note']:", "\n", "#    id += params['id_note']", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.read_metadata": [[182, 192], ["pandas.read_csv", "open", "json.loads", "f.read"], "methods", ["None"], ["", "def", "read_metadata", "(", "self", ",", "json_basename", ",", "csv_basename", ")", ":", "\n", "#load json file", "\n", "        ", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "json_basename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "csv_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "csv_basename", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "return", "conf_dict", ",", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.get_output_shapes": [[194, 199], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "1", ",", ")", ",", "datasets_tuple", "[", "1", "]", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.get_output_types": [[200, 205], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "as_dtype", "(", "datasets_tuple", "[", "1", "]", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "", "def", "cropND", "(", "self", ",", "img", ",", "bounding", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.cropND": [[205, 210], ["tuple", "tuple", "tuple", "map", "map", "map"], "methods", ["None"], ["", "def", "cropND", "(", "self", ",", "img", ",", "bounding", ")", ":", "\n", "        ", "start", "=", "tuple", "(", "map", "(", "lambda", "a", ",", "da", ":", "a", "//", "2", "-", "da", "//", "2", ",", "img", ".", "shape", ",", "bounding", ")", ")", "\n", "end", "=", "tuple", "(", "map", "(", "operator", ".", "add", ",", "start", ",", "bounding", ")", ")", "\n", "slices", "=", "tuple", "(", "map", "(", "slice", ",", "start", ",", "end", ")", ")", "\n", "return", "img", "[", "slices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.dataset_map": [[214, 254], ["LSS.LSS.get_output_types", "list", "dataset.map.map.map", "numpy.load", "numpy.expand_dims", "zip", "scipy.ndimage.gaussian_filter", "numpy.random.uniform", "numpy.rot90.astype", "tuple", "numpy.flipud", "tensorflow.py_func", "numpy.fliplr", "numpy.log", "numpy.rot90", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.rot90", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "norm_bool", "=", "self", ".", "_normalize_images", "\n", "data_min", "=", "self", ".", "_data_min", "\n", "data_max", "=", "self", ".", "_data_max", "\n", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "label", "=", "full_data", "[", "n", "]", "[", "1", "]", "\n", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "filename", ")", "\n", "if", "norm_bool", ":", "\n", "#image = 2*(image-data_min)/(data_max-data_min) - 1", "\n", "\n", "                ", "image", "=", "gaussian_filter", "(", "image", ",", "sigma", "=", "1.2", ")", "\n", "image", "=", "5", "*", "(", "2", "*", "np", ".", "log", "(", "image", "-", "data_min", "+", "1", ")", "/", "np", ".", "log", "(", "data_max", "-", "data_min", "+", "1", ")", "-", "1.", "/", "4.", ")", "\n", "s_random", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "1", ")", "\n", "if", "s_random", ">=", "0.25", ":", "\n", "                    ", "image", "=", "np", ".", "flipud", "(", "image", ")", "\n", "", "elif", "0.5", ">", "s_random", ">", "0.25", ":", "\n", "                    ", "image", "=", "np", ".", "fliplr", "(", "image", ")", "\n", "", "elif", "0.75", ">", "s_random", ">=", "0.5", ":", "\n", "                    ", "image", "=", "np", ".", "rot90", "(", "image", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "#image=self.cropND(image, (128,128))", "\n", "", "", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "label", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.load_dataset": [[256, 344], ["LSS.LSS.read_metadata", "len", "print", "df_dataset[].values.astype", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.read_metadata"], ["", "def", "load_dataset", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "\"\"\"\n        load the dataset in memory and set in the object\n\n        Args:\n            train_test_ratio: (float) percentage of the dataset in train\n\n        \"\"\"", "\n", "json_filename", "=", "self", ".", "_json_filename", "\n", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Train", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Validation", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Test", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"`dataset_str` can be only: train, validation or test.\"", ")", "\n", "\n", "# get info from the metadata", "\n", "", "conf_dict", ",", "labels_filter_df", "=", "self", ".", "read_metadata", "(", "json_filename", ",", "csv_filename", ")", "\n", "#self._picture_size = self.conf_dict['pic_size']", "\n", "n_parameters", "=", "len", "(", "conf_dict", ")", "\n", "\n", "#if self._only_center:", "\n", "#    labels_filter_df = labels_filter_df[labels_filter_df['is_center']]", "\n", "\n", "#if not self._augment_data:", "\n", "#    # no rotations", "\n", "#    is_no_rotation = labels_filter_df['rot_angle'] == 0", "\n", "#    labels_filter_df = labels_filter_df[is_no_rotation]", "\n", "\n", "#    # no flips", "\n", "#    index_no_flip = ~labels_filter_df['flip']", "\n", "#    labels_filter_df = labels_filter_df[index_no_flip]", "\n", "\n", "\n", "'''\n        if self._debug_mode:\n            debug_dimension = 500\n            labels_filter_df = labels_filter_df.iloc[:debug_dimension]\n        '''", "\n", "\n", "# dataset_x = labels_filter_df.sample(frac=1)", "\n", "df_dataset", "=", "labels_filter_df", "\n", "num_files", "=", "df_dataset", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'{} are going to be loaded in memory'", ".", "format", "(", "num_files", ")", ")", "\n", "\n", "filename_dataset", "=", "df_dataset", "[", "'filename'", "]", ".", "values", "\n", "labels_dataset", "=", "df_dataset", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "\n", "if", "self", ".", "_normalize_labels", ":", "\n", "            ", "labels_dataset", "=", "2", "*", "(", "labels_dataset", "-", "self", ".", "_labels_min", ")", "/", "(", "self", ".", "_labels_max", "-", "self", ".", "_labels_min", ")", "-", "1.", "\n", "\n", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "# dim_train = int(num_files * train_ratio)", "\n", "# dim_validation = int(num_files * validation_ratio)", "\n", "# dim_test = num_files - dim_train - dim_validation", "\n", "#", "\n", "# # training", "\n", "# df_train = dataset_x.iloc[0 : dim_train]", "\n", "# filename_training = df_train['filename'].values", "\n", "# labels_training = df_train[['omega_cdm', 'A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     max_training = np.max(labels_training, axis=0)", "\n", "#     min_training = np.min(labels_training, axis=0)", "\n", "#     labels_training = (labels_training - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_validation = dataset_x.iloc[dim_train : (dim_train+dim_validation)]", "\n", "# filename_validation = df_validation['filename'].values", "\n", "# labels_validation = df_validation[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_validation = (labels_validation - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_test = dataset_x.iloc[(dim_train+dim_validation):]", "\n", "# filename_test = df_test['filename'].values", "\n", "# labels_test = df_test[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_test = (labels_test - min_training)/(max_training - min_training)", "\n", "#", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "\n", "", "return", "filename_dataset", ",", "labels_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.compute_min_max_data": [[345, 375], ["pandas.read_csv", "numpy.min", "numpy.max", "label_df[].values.astype", "numpy.min", "numpy.max", "numpy.load", "scipy.ndimage.gaussian_filter", "all_min.append", "all_max.append", "numpy.min", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "compute_min_max_data", "(", "self", ",", "norm_labels", "=", "False", ",", "norm_data", "=", "False", ")", ":", "\n", "        ", "all_max", "=", "[", "]", "\n", "all_min", "=", "[", "]", "\n", "csv_filename", "=", "self", ".", "_data_dir", "+", "'/latin_hypercube.csv'", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "labels_min", "=", "None", "\n", "labels_max", "=", "None", "\n", "data_min", "=", "None", "\n", "data_max", "=", "None", "\n", "\n", "if", "norm_data", ":", "\n", "            ", "filenames", "=", "label_df", "[", "'filename'", "]", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "                ", "patch1", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "\"/\"", "+", "filename", ")", "\n", "patch1", "=", "gaussian_filter", "(", "patch1", ",", "sigma", "=", "1.2", ")", "\n", "\n", "all_min", ".", "append", "(", "np", ".", "min", "(", "patch1", ")", ")", "\n", "all_max", ".", "append", "(", "np", ".", "max", "(", "patch1", ")", ")", "\n", "\n", "", "data_min", "=", "np", ".", "min", "(", "all_min", ")", "\n", "data_max", "=", "np", ".", "max", "(", "all_max", ")", "\n", "\n", "", "if", "norm_labels", ":", "\n", "            ", "labels", "=", "label_df", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "labels_min", "=", "np", ".", "min", "(", "labels", ",", "axis", "=", "0", ")", "\n", "labels_max", "=", "np", ".", "max", "(", "labels", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "labels_min", ",", "labels_max", ",", "data_min", ",", "data_max", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.labels_min_training": [[376, 388], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_min_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#", "\n", "#if  self._dataset_x_min is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "\n", "        ", "return", "self", ".", "_labels_min_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.labels_max_training": [[389, 400], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_max_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#\u00a7", "\n", "#if  self._dataset_x_max is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "        ", "return", "self", ".", "_labels_max_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.x_shape_train": [[401, 405], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS.LSS.x_shape_eval": [[406, 458], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the evaluation\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_train(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_eval(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "#return mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels, mnist.test.images, mnist.test.labels", "\n", "\n", "\n", "#start_time_data = timeit.default_timer()", "\n", "\n", "#shape_X = (n_files,) + self._x_sample_shape", "\n", "#shape_Y = (n_files,) + self._y_sample_shape", "\n", "\n", "# construct the datasets", "\n", "#X = np.empty(shape_X)", "\n", "#Y = np.empty(shape_Y)", "\n", "\n", "#for ix, row in  labels_filter_df.iterrows():", "\n", "#    tmp_numpy = np.load(self._data_dir + \"/\" + row['filename'])", "\n", "#", "\n", "#    X[ix, :, :, 0] = tmp_numpy", "\n", "#    Y[ix] = row[self._var_params]", "\n", "\n", "# print time for the load", "\n", "#step_time = timeit.default_timer()", "\n", "#print(\"time needed to load: \", step_time - start_time_data)", "\n", "\n", "# shuffle the dataset", "\n", "'''\n        randomized_dataset_index = np.random.permutation(n_files)\n        X = X[randomized_dataset_index]\n        Y = Y[randomized_dataset_index]\n\n\n\n\n\n\n        dim_train = int(n_files * train_test_ratio)\n        self._train_set_x, self._train_set_y = X[:dim_train] , Y[:dim_train]\n        self._test_set_x, self._test_set_y = X[dim_train:], Y[dim_train:]\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.__init__": [[63, 120], ["ImageDataset.ImageDataset.__init__", "Frey.Frey.dataset_id", "scipy.io.loadmat", "ff[].T.reshape", "X_train.reshape", "X_test.reshape", "os.path.exists", "os.makedirs", "os.path.isfile", "print", "urllib.request.urlretrieve", "X_train.astype", "X_test.astype", "Frey.Frey.sub_sample", "Frey.Frey.sub_sample", "numpy.clip", "numpy.clip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "self", ".", "_params", "[", "'binary'", "]", "\n", "\n", "self", ".", "data_dir", "=", "\"datasets/Freyfaces_data\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "data_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "data_dir", ")", "\n", "\n", "", "fileName", "=", "self", ".", "data_dir", "+", "'/frey_rawface.mat'", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "fileName", ")", ":", "\n", "# see http://dohmatob.github.io/research/2016/10/22/VAE.html", "\n", "            ", "origin", "=", "(", "\n", "'http://www.cs.nyu.edu/~roweis/data/frey_rawface.mat'", "\n", ")", "\n", "print", "(", "'Downloading data from %s'", "%", "origin", ")", "\n", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "origin", ",", "fileName", ")", "\n", "\n", "", "if", "self", ".", "_binary_input", "==", "0", "or", "(", "self", ".", "_binary_input", "==", "0", "and", "self", ".", "_params", "[", "'stochastic'", "]", "==", "1", ")", ":", "\n", "            ", "dtype", "=", "'float32'", "\n", "", "else", ":", "\n", "            ", "dtype", "=", "'int32'", "\n", "\n", "", "self", ".", "img_rows", "=", "28", "\n", "self", ".", "img_cols", "=", "20", "\n", "\n", "ff", "=", "loadmat", "(", "fileName", ",", "squeeze_me", "=", "True", ",", "struct_as_record", "=", "False", ")", "\n", "ff", "=", "ff", "[", "\"ff\"", "]", ".", "T", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "img_rows", ",", "self", ".", "img_cols", ")", ")", "\n", "\n", "n_pixels", "=", "self", ".", "img_rows", "*", "self", ".", "img_cols", "\n", "X_train", "=", "ff", "[", ":", "1600", "]", "\n", "X_test", "=", "ff", "[", "1600", ":", "1900", "]", "\n", "X_train", "=", "X_train", ".", "astype", "(", "dtype", ")", "/", "255.", "\n", "X_test", "=", "X_test", ".", "astype", "(", "dtype", ")", "/", "255.", "\n", "self", ".", "_train_set_x", "=", "X_train", ".", "reshape", "(", "(", "len", "(", "X_train", ")", ",", "n_pixels", ")", ")", "\n", "self", ".", "_test_set_x", "=", "X_test", ".", "reshape", "(", "(", "len", "(", "X_test", ")", ",", "n_pixels", ")", ")", "\n", "\n", "# choose a subset", "\n", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.dataset_id": [[125, 164], ["Frey.check_params_impl", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "Frey", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'Frey'", "\n", "\n", "# binary or continuous", "\n", "id_binary", "=", "{", "0", ":", "'-c'", ",", "1", ":", "'-d'", "}", "\n", "id", "+=", "id_binary", "[", "params", "[", "'binary'", "]", "]", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subsampling", "\n", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.sub_sample": [[165, 184], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_train", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_train", "=", "np", ".", "random", ".", "permutation", "(", "len_train", ")", "\n", "new_len_train", "=", "int", "(", "len_train", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.class_filter": [[185, 210], ["numpy.in1d", "Frey.Frey.class_filter.replace_with_position"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "class_filter", "(", "data_set_x", ",", "data_set_y", ",", "classes", ",", "position_label", ")", ":", "\n", "        ", "\"\"\"\n        return the dataset with labels in the list classes\n\n        :param data_set_x: data\n        :param data_set_y: labels\n        :param classes:    list of classes\n        :param position_label:  list of classes\n        :return: (dataset_x, dataset_y) with filtered elemnts not in classes\n        \"\"\"", "\n", "\n", "ix_mtch_class_train", "=", "np", ".", "in1d", "(", "data_set_y", ",", "classes", ")", "\n", "data_set_x", "=", "data_set_x", "[", "ix_mtch_class_train", "]", "\n", "data_set_y", "=", "data_set_y", "[", "ix_mtch_class_train", "]", "\n", "if", "position_label", ":", "\n", "\n", "            ", "def", "replace_with_position", "(", "label_set", ",", "classes", ")", ":", "\n", "                ", "label_set_new", "=", "np", ".", "copy", "(", "label_set", ")", "\n", "for", "ix", ",", "class_", "in", "enumerate", "(", "classes", ")", ":", "label_set_new", "[", "label_set", "==", "class_", "]", "=", "ix", "\n", "return", "label_set_new", "\n", "\n", "", "data_set_y", "=", "replace_with_position", "(", "data_set_y", ",", "classes", ")", "\n", "\n", "", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.input_size": [[221, 224], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "input_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "img_rows", "*", "self", ".", "img_cols", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.output_size": [[225, 228], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.color_images": [[229, 232], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Frey.Frey.image_shape": [[233, 236], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "img_rows", ",", "self", ".", "img_cols", ",", "1", ")", "# 1 is the number of channels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.__init__": [[59, 109], ["ImageDataset.ImageDataset.__init__", "CelebA.CelebA.dataset_id", "CelebA.CelebA.read_labels", "CelebA.CelebA.load_dataset_from_disk", "numpy.prod", "CelebA.process_params", "len", "CelebA.CelebA.get_var_params", "CelebA.CelebA.sub_sample", "CelebA.CelebA.sub_sample", "CelebA.CelebA.sub_sample", "numpy.clip", "numpy.clip", "numpy.clip", "Exception", "CelebA.CelebA._train_set_x.reshape", "CelebA.CelebA._validation_set_x.reshape", "CelebA.CelebA._test_set_x.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.read_labels", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.load_dataset_from_disk", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.get_var_params", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "CelebA", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "self", ".", "_binary_input", "=", "0", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "\n", "# get info from the metadata", "\n", "self", ".", "labels_df", "=", "self", ".", "read_labels", "(", ")", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_picture_size", "=", "64", "\n", "\n", "# Number of channels in each image, 3 channels: Red, Green, Blue.", "\n", "self", ".", "_num_channels", "=", "3", "\n", "\n", "self", ".", "_n_params", "=", "len", "(", "self", ".", "_params", "[", "'params'", "]", ")", "if", "'params'", "in", "self", ".", "_params", "else", "0", "\n", "self", ".", "_x_sample_shape", "=", "(", "self", ".", "_picture_size", ",", "self", ".", "_picture_size", ",", "self", ".", "_num_channels", ")", "\n", "self", ".", "_y_sample_shape", "=", "(", "self", ".", "_n_params", ",", ")", "\n", "\n", "self", ".", "_var_params", "=", "self", ".", "get_var_params", "(", "self", ".", "_params", "[", "'params'", "]", ")", "if", "'params'", "in", "self", ".", "_params", "else", "[", "]", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset_from_disk", "(", ")", "\n", "\n", "# choose a subset", "\n", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n", "", "dim", "=", "np", ".", "prod", "(", "self", ".", "x_shape", ")", "\n", "if", "self", ".", "_params", "[", "'vect'", "]", ":", "\n", "            ", "raise", "Exception", "(", "\"I refuse to flatten CelebA! Take me as I am. I am a dataset with my own dignity and my own channels. All the Best.\"", ")", "# Riccardo", "\n", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "dim", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "dim", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.read_labels": [[110, 120], ["pandas.read_csv"], "methods", ["None"], ["", "", "def", "read_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "#load csv file", "\n", "csv_filename", "=", "self", ".", "_data_dir", "+", "'/concatenated_labels.csv'", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ")", "\n", "\n", "return", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.load_dataset_from_disk": [[121, 145], ["numpy.asarray", "numpy.random.permutation", "numpy.load().astype", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_dataset_from_disk", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            load the CelebA\n            and its labels\n        \"\"\"", "\n", "X", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "\"/all.npy\"", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255", "\n", "n_files", "=", "X", ".", "shape", "[", "0", "]", "\n", "\n", "Y", "=", "np", ".", "asarray", "(", "self", ".", "labels_df", "[", "self", ".", "_var_params", "]", ")", "\n", "\n", "randomized_dataset_index", "=", "np", ".", "random", ".", "permutation", "(", "n_files", ")", "\n", "X", "=", "X", "[", "randomized_dataset_index", "]", "\n", "Y", "=", "Y", "[", "randomized_dataset_index", "]", "\n", "\n", "test_split", "=", "n_files", "-", "self", ".", "_params", "[", "'test_and_validation'", "]", "\n", "validation_split", "=", "test_split", "-", "self", ".", "_params", "[", "'test_and_validation'", "]", "\n", "\n", "trainVal", ",", "test_set_x", "=", "X", "[", ":", "test_split", ",", ":", "]", ",", "X", "[", "test_split", ":", ",", ":", "]", "\n", "train_set_x", ",", "validation_set_x", "=", "trainVal", "[", ":", "validation_split", ",", ":", "]", ",", "trainVal", "[", "validation_split", ":", ",", ":", "]", "\n", "\n", "trainVal", ",", "test_set_y", "=", "Y", "[", ":", "test_split", ",", ":", "]", ",", "Y", "[", "test_split", ":", ",", ":", "]", "\n", "train_set_y", ",", "validation_set_y", "=", "trainVal", "[", ":", "validation_split", ",", ":", "]", ",", "trainVal", "[", "validation_split", ":", ",", ":", "]", "\n", "\n", "return", "train_set_x", ",", "validation_set_x", ",", "test_set_x", ",", "train_set_y", ",", "validation_set_y", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.dataset_id": [[146, 201], ["CelebA.check_params_impl", "list", "range", "str", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "\n", "CelebA", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'CelebA'", "\n", "\n", "# binary or continuous", "\n", "#id_binary = {0:'-c',1:'-d'}", "\n", "#id += id_binary[params['binary']]", "\n", "\n", "# stochastic", "\n", "#id += '-st' + str(params[\"stochastic\"])", "\n", "\n", "# subclasses", "\n", "#", "\n", "if", "(", "'classes'", "in", "params", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "10", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in MNIST\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "(", "'clip_high'", "in", "params", ")", "and", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "(", "'clip_low'", "in", "params", ")", "and", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "(", "'id_note'", "in", "params", ")", "and", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.get_var_params": [[202, 207], ["numpy.intersect1d", "len", "len"], "methods", ["None"], ["", "def", "get_var_params", "(", "self", ",", "param", ")", ":", "\n", "        ", "var_params", "=", "np", ".", "intersect1d", "(", "ALL_LABELS", ",", "param", ")", "\n", "\n", "assert", "len", "(", "var_params", ")", "==", "len", "(", "param", ")", ",", "\"It seems like you might have a mistake in you label name\"", "\n", "return", "var_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.sub_sample": [[210, 229], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_data", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_data", "=", "np", ".", "random", ".", "permutation", "(", "len_data", ")", "\n", "new_len_data", "=", "int", "(", "len_data", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.output_size": [[249, 252], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "0", "# 10 if self._params['classes'] == () else len(self._params['classes'])", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CelebA.CelebA.color_images": [[253, 256], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPLabeled.HCPLabeled.__init__": [[21, 27], ["datasets.LabeledBrainDataset.LabeledBrainDataset.__init__", "HCPLabeled.HCPLabeled.load_float_brains"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_float_brains"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_float_brains", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPLabeled.HCPLabeled.dataset_id": [[28, 37], ["super().dataset_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "id", "=", "'HCPLabeled'", "\n", "id", "+=", "super", "(", ")", ".", "dataset_id", "(", "params", ")", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPLabeled.HCPLabeled.x_shape_train": [[39, 42], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPLabeled.HCPLabeled.x_shape_eval": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.__init__": [[73, 142], ["ImageDataset.ImageDataset.__init__", "CMB_Pol.CMB_Pol.dataset_id", "CMB_Pol.CMB_Pol.compute_min_max_data", "CMB_Pol.CMB_Pol.load_dataset", "CMB_Pol.CMB_Pol.load_dataset", "CMB_Pol.CMB_Pol.load_dataset", "Exception", "open", "json.loads", "os.path.exists", "os.path.isdir", "f.read"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.compute_min_max_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_json_filename", "=", "\"params.json\"", "\n", "fraction_dataset", "=", "params", "[", "'fraction_dataset'", "]", "\n", "\n", "# self._csv_filename = \"labels_file.csv\"", "\n", "if", "fraction_dataset", "==", "100", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data.csv'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data_{}.csv'", ".", "format", "(", "fraction_dataset", ")", "\n", "# label_df_Train = pd.read_csv(self._csv_filename_Train, sep=\"\\t\")", "\n", "\n", "", "self", ".", "_csv_filename_Test", "=", "'Test_CMB_data.csv'", "\n", "# label_df_Test = pd.read_csv(self._csv_filename_Test, sep=\"\\t\")", "\n", "\n", "self", ".", "_csv_filename_Validation", "=", "'Validation_CMB_data.csv'", "\n", "# label_df_Validation = pd.read_csv(self._csv_filename_Validation, sep=\"\\t\")", "\n", "\n", "# self._all_parameter_list = ['h', 'omega_b', 'omega_cdm', 'A_s', 'n_s', 'tau_reio']", "\n", "self", ".", "_parameters_list", "=", "params", "[", "\"parameters\"", "]", "\n", "self", ".", "_fraction_dataset", "=", "params", "[", "\"fraction_dataset\"", "]", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_normalize_labels", "=", "self", ".", "_params", "[", "'normalize_labels'", "]", "\n", "self", ".", "_normalize_images", "=", "self", ".", "_params", "[", "'normalize_images'", "]", "\n", "\n", "\n", "# check if the data directory is present", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_data_dir", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_data_dir", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Dataset directory {}'", "\n", "' not found'", ".", "format", "(", "self", ".", "_data_dir", ")", "\n", ")", "\n", "\n", "#self._debug_mode = params['debug_mode']", "\n", "\n", "#self._augment_data = params['augm_data']", "\n", "#self._only_center = params['only_center']", "\n", "", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "self", ".", "_json_filename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "picture_size", "=", "conf_dict", "[", "\"pic_size\"", "]", "\n", "self", ".", "_x_sample_shape", "=", "(", "picture_size", ",", "picture_size", ",", "3", ")", "\n", "#self._y_sample_shape = (self._n_params,)", "\n", "\n", "#self._var_params = self.conf_dict['params'] # TODO Check that is sorted like self.parameter_list", "\n", "\n", "# useful for lazy load, however I need to reimplement some methods to make it work", "\n", "# self._loaded_from_disk = False", "\n", "\n", "#self._train_set_x = None", "\n", "#self._train_set_y = None", "\n", "#self._test_set_x = None", "\n", "#self._test_set_y = None", "\n", "\n", "#self._n_samples_train = None", "\n", "#self._n_samples_test = None", "\n", "self", ".", "_labels_min", ",", "self", ".", "_labels_max", ",", "self", ".", "_data_min", ",", "self", ".", "_data_max", "=", "self", ".", "compute_min_max_data", "(", "norm_labels", "=", "self", ".", "_normalize_labels", ",", "\n", "norm_data", "=", "self", ".", "_normalize_images", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "load_dataset", "(", "TRAIN", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "load_dataset", "(", "VALIDATION", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset", "(", "TEST", ")", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.dataset_id": [[147, 179], ["os.path.basename", "str", "str", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "# CMB.check_params_impl(params)", "\n", "\n", "p_dist_abbr", "=", "{", "'uniform'", ":", "'U'", ",", "\n", "'lattice'", ":", "'L'", "}", "\n", "\n", "id", "=", "'CMBPol'", "\n", "id", "+=", "os", ".", "path", ".", "basename", "(", "params", "[", "'data_dir'", "]", ")", "\n", "id", "+=", "'-d%'", "+", "str", "(", "params", "[", "'fraction_dataset'", "]", ")", "\n", "id", "+=", "'-pdim'", "+", "str", "(", "len", "(", "params", "[", "'parameters'", "]", ")", ")", "\n", "id", "+=", "'-n'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_images'", "]", "==", "True", "else", "'0'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_labels'", "]", "==", "True", "else", "'0'", "\n", "#id += '-au1' if self._augment_data == True  else '-au0'", "\n", "#id += '-oc1' if self._only_center == True else '-oc0'", "\n", "\n", "\n", "# id += '-' + p_dist_abbr[params['par_distr']]", "\n", "# id += '-pprr' + str(params['pic_per_run_rot'])", "\n", "# id += '-ppre' + str(params['pic_per_run_equator'])", "\n", "\n", "# id note (keep last)", "\n", "#if params['id_note']:", "\n", "#    id += params['id_note']", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.read_metadata": [[181, 191], ["pandas.read_csv", "open", "json.loads", "f.read"], "methods", ["None"], ["", "def", "read_metadata", "(", "self", ",", "json_basename", ",", "csv_basename", ")", ":", "\n", "#load json file", "\n", "        ", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "json_basename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "csv_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "csv_basename", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "return", "conf_dict", ",", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.get_output_shapes": [[193, 198], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "#output_shapes = tuple([image.shape + (1,), datasets_tuple[1].shape[1]])", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", ",", "datasets_tuple", "[", "1", "]", ".", "shape", "[", "1", "]", "]", ")", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.get_output_types": [[199, 204], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "as_dtype", "(", "datasets_tuple", "[", "1", "]", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.dataset_map": [[208, 235], ["CMB_Pol.CMB_Pol.get_output_types", "list", "dataset.map.map.map", "numpy.load", "zip", "range", "numpy.load.astype", "tuple", "tensorflow.py_func"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "norm_bool", "=", "self", ".", "_normalize_images", "\n", "data_min", "=", "self", ".", "_data_min", "\n", "data_max", "=", "self", ".", "_data_max", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "label", "=", "full_data", "[", "n", "]", "[", "1", "]", "\n", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "filename", ")", "\n", "if", "norm_bool", ":", "\n", "                ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                    ", "image", "[", "i", "]", "=", "2", "*", "(", "image", "[", "i", "]", "-", "data_min", "[", "0", "]", ")", "/", "(", "data_max", "[", "0", "]", "-", "data_min", "[", "0", "]", ")", "-", "1", "\n", "#image = np.expand_dims(image, axis=-1)", "\n", "\n", "", "", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "label", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.load_dataset": [[237, 325], ["CMB_Pol.CMB_Pol.read_metadata", "len", "print", "df_dataset[].values.astype", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.read_metadata"], ["", "def", "load_dataset", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "\"\"\"\n        load the dataset in memory and set in the object\n\n        Args:\n            train_test_ratio: (float) percentage of the dataset in train\n\n        \"\"\"", "\n", "json_filename", "=", "self", ".", "_json_filename", "\n", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Train", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Validation", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Test", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"`dataset_str` can be only: train, validation or test.\"", ")", "\n", "\n", "# get info from the metadata", "\n", "", "conf_dict", ",", "labels_filter_df", "=", "self", ".", "read_metadata", "(", "json_filename", ",", "csv_filename", ")", "\n", "#self._picture_size = self.conf_dict['pic_size']", "\n", "n_parameters", "=", "len", "(", "conf_dict", ")", "\n", "\n", "#if self._only_center:", "\n", "#    labels_filter_df = labels_filter_df[labels_filter_df['is_center']]", "\n", "\n", "#if not self._augment_data:", "\n", "#    # no rotations", "\n", "#    is_no_rotation = labels_filter_df['rot_angle'] == 0", "\n", "#    labels_filter_df = labels_filter_df[is_no_rotation]", "\n", "\n", "#    # no flips", "\n", "#    index_no_flip = ~labels_filter_df['flip']", "\n", "#    labels_filter_df = labels_filter_df[index_no_flip]", "\n", "\n", "\n", "'''\n        if self._debug_mode:\n            debug_dimension = 500\n            labels_filter_df = labels_filter_df.iloc[:debug_dimension]\n        '''", "\n", "\n", "# dataset_x = labels_filter_df.sample(frac=1)", "\n", "df_dataset", "=", "labels_filter_df", "\n", "num_files", "=", "df_dataset", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'{} are going to be loaded in memory'", ".", "format", "(", "num_files", ")", ")", "\n", "\n", "filename_dataset", "=", "df_dataset", "[", "'filename'", "]", ".", "values", "\n", "labels_dataset", "=", "df_dataset", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "\n", "if", "self", ".", "_normalize_labels", ":", "\n", "            ", "labels_dataset", "=", "2", "*", "(", "labels_dataset", "-", "self", ".", "_labels_min", ")", "/", "(", "self", ".", "_labels_max", "-", "self", ".", "_labels_min", ")", "-", "1.", "\n", "\n", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "# dim_train = int(num_files * train_ratio)", "\n", "# dim_validation = int(num_files * validation_ratio)", "\n", "# dim_test = num_files - dim_train - dim_validation", "\n", "#", "\n", "# # training", "\n", "# df_train = dataset_x.iloc[0 : dim_train]", "\n", "# filename_training = df_train['filename'].values", "\n", "# labels_training = df_train[['omega_cdm', 'A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     max_training = np.max(labels_training, axis=0)", "\n", "#     min_training = np.min(labels_training, axis=0)", "\n", "#     labels_training = (labels_training - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_validation = dataset_x.iloc[dim_train : (dim_train+dim_validation)]", "\n", "# filename_validation = df_validation['filename'].values", "\n", "# labels_validation = df_validation[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_validation = (labels_validation - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_test = dataset_x.iloc[(dim_train+dim_validation):]", "\n", "# filename_test = df_test['filename'].values", "\n", "# labels_test = df_test[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_test = (labels_test - min_training)/(max_training - min_training)", "\n", "#", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "\n", "", "return", "filename_dataset", ",", "labels_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.compute_min_max_data": [[326, 367], ["pandas.read_csv", "numpy.min", "numpy.max", "label_df[].values.astype", "numpy.min", "numpy.max", "numpy.load", "all_min_0.append", "all_max_0.append", "numpy.min", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "compute_min_max_data", "(", "self", ",", "norm_labels", "=", "False", ",", "norm_data", "=", "False", ")", ":", "\n", "        ", "all_max_0", "=", "[", "]", "\n", "all_min_0", "=", "[", "]", "\n", "all_max_1", "=", "[", "]", "\n", "all_min_1", "=", "[", "]", "\n", "all_max_2", "=", "[", "]", "\n", "all_min_2", "=", "[", "]", "\n", "csv_filename", "=", "self", ".", "_data_dir", "+", "'/labels_file.csv'", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "labels_min", "=", "None", "\n", "labels_max", "=", "None", "\n", "data_min", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "data_max", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "\n", "if", "norm_data", ":", "\n", "            ", "filenames", "=", "label_df", "[", "'filename'", "]", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "                ", "patch1", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "\"/\"", "+", "filename", ")", "\n", "all_min_0", ".", "append", "(", "np", ".", "min", "(", "patch1", "[", ":", ",", ":", ",", "0", "]", ")", ")", "\n", "all_max_0", ".", "append", "(", "np", ".", "max", "(", "patch1", "[", ":", ",", ":", ",", "0", "]", ")", ")", "\n", "#all_min_1.append(np.min(patch1[:,:,1]))", "\n", "#all_max_1.append(np.max(patch1[:,:,1]))", "\n", "#all_min_2.append(np.min(patch1[:,:,2]))", "\n", "#all_max_2.append(np.max(patch1[:,:,2]))", "\n", "\n", "\n", "", "data_min", "[", "0", "]", "=", "np", ".", "min", "(", "all_min_0", ")", "\n", "data_max", "[", "0", "]", "=", "np", ".", "max", "(", "all_max_0", ")", "\n", "#data_min[1] = np.min(all_min_1)", "\n", "#data_max[1] = np.max(all_max_1)", "\n", "#data_min[2] = np.min(all_min_2)", "\n", "#data_max[2] = np.max(all_max_2)", "\n", "\n", "", "if", "norm_labels", ":", "\n", "            ", "labels", "=", "label_df", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "labels_min", "=", "np", ".", "min", "(", "labels", ",", "axis", "=", "0", ")", "\n", "labels_max", "=", "np", ".", "max", "(", "labels", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "labels_min", ",", "labels_max", ",", "data_min", ",", "data_max", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.labels_min_training": [[368, 380], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_min_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#", "\n", "#if  self._dataset_x_min is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "\n", "        ", "return", "self", ".", "_labels_min_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.labels_max_training": [[381, 392], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_max_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#\u00a7", "\n", "#if  self._dataset_x_max is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "        ", "return", "self", ".", "_labels_max_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.x_shape_train": [[393, 397], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_Pol.CMB_Pol.x_shape_eval": [[398, 450], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the evaluation\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_train(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_eval(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "#return mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels, mnist.test.images, mnist.test.labels", "\n", "\n", "\n", "#start_time_data = timeit.default_timer()", "\n", "\n", "#shape_X = (n_files,) + self._x_sample_shape", "\n", "#shape_Y = (n_files,) + self._y_sample_shape", "\n", "\n", "# construct the datasets", "\n", "#X = np.empty(shape_X)", "\n", "#Y = np.empty(shape_Y)", "\n", "\n", "#for ix, row in  labels_filter_df.iterrows():", "\n", "#    tmp_numpy = np.load(self._data_dir + \"/\" + row['filename'])", "\n", "#", "\n", "#    X[ix, :, :, 0] = tmp_numpy", "\n", "#    Y[ix] = row[self._var_params]", "\n", "\n", "# print time for the load", "\n", "#step_time = timeit.default_timer()", "\n", "#print(\"time needed to load: \", step_time - start_time_data)", "\n", "\n", "# shuffle the dataset", "\n", "'''\n        randomized_dataset_index = np.random.permutation(n_files)\n        X = X[randomized_dataset_index]\n        Y = Y[randomized_dataset_index]\n\n\n\n\n\n\n        dim_train = int(n_files * train_test_ratio)\n        self._train_set_x, self._train_set_y = X[:dim_train] , Y[:dim_train]\n        self._test_set_x, self._test_set_y = X[dim_train:], Y[dim_train:]\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.BTSC.__init__": [[41, 53], ["ImageDataset.ImageDataset.__init__", "BTSC.BTSC.dataset_id", "BTSC.BTSC.load_data"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "default_data_dir", "=", "'/ssd_data/datasets/BTSC'", "\n", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", "self", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.BTSC.dataset_id": [[55, 66], ["BTSC.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "BTSC", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'BTSC'", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.BTSC.load_data": [[67, 98], ["BTSC.load_train", "numpy.random.RandomState().permutation", "numpy.random.RandomState().permutation", "BTSC.load_test", "numpy.random.RandomState().permutation", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "os.stat", "os.path.join", "os.path.join", "os.mkdir", "numpy.random.RandomState", "numpy.random.RandomState", "numpy.random.RandomState"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.load_train", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.load_test", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "btsc_dir", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "stat", "(", "btsc_dir", ")", "\n", "", "except", ":", "\n", "            ", "os", ".", "mkdir", "(", "btsc_dir", ")", "\n", "\n", "", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", "=", "load_train", "(", "os", ".", "path", ".", "join", "(", "btsc_dir", ",", "'Training'", ")", ")", "\n", "\n", "random_indices_train", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "8", ")", ".", "permutation", "(", "X_train", ".", "shape", "[", "0", "]", ")", "\n", "X_train", "=", "X_train", "[", "random_indices_train", "]", ";", "Y_train", "=", "Y_train", "[", "random_indices_train", "]", "\n", "\n", "random_indices_val", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "9", ")", ".", "permutation", "(", "X_val", ".", "shape", "[", "0", "]", ")", "\n", "X_val", "=", "X_val", "[", "random_indices_val", "]", ";", "Y_val", "=", "Y_val", "[", "random_indices_val", "]", "\n", "\n", "X_test", ",", "Y_test", "=", "load_test", "(", "os", ".", "path", ".", "join", "(", "btsc_dir", ",", "'Testing'", ")", ")", "\n", "random_indices_test", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "10", ")", ".", "permutation", "(", "X_test", ".", "shape", "[", "0", "]", ")", "\n", "X_test", "=", "X_test", "[", "random_indices_test", "]", ";", "Y_test", "=", "Y_test", "[", "random_indices_test", "]", "\n", "\n", "# normalize data consistently (in case they would not already be)", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "X_train", ",", "X_val", ",", "X_test", "]", ")", "\n", "X_train", "=", "normalize", "(", "X_train", ",", "all_min", ",", "all_max", ")", "\n", "X_val", "=", "normalize", "(", "X_val", ",", "all_min", ",", "all_max", ")", "\n", "X_test", "=", "normalize", "(", "X_test", ",", "all_min", ",", "all_max", ")", "\n", "\n", "#         make_hist_of_classes(Y_train, \"Train\")", "\n", "#         make_hist_of_classes(Y_val, \"Validation\")", "\n", "#         make_hist_of_classes(Y_test, \"Test\")", "\n", "\n", "return", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", ",", "X_test", ",", "Y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.preprocess_img": [[100, 106], ["skimage.color.rgb2hsv", "skimage.exposure.equalize_hist", "skimage.color.hsv2rgb"], "function", ["None"], ["", "", "def", "preprocess_img", "(", "img", ")", ":", "\n", "# Histogram normalization in y", "\n", "    ", "hsv", "=", "color", ".", "rgb2hsv", "(", "img", ")", "\n", "hsv", "[", ":", ",", ":", ",", "2", "]", "=", "exposure", ".", "equalize_hist", "(", "hsv", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "img", "=", "color", ".", "hsv2rgb", "(", "hsv", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.track_no": [[107, 109], ["None"], "function", ["None"], ["", "def", "track_no", "(", "path", ")", ":", "# returns the track number (as a string of 5 chars) of a given .ppm path ", "\n", "    ", "return", "path", "[", "-", "15", ":", "-", "10", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.five_char": [[110, 119], ["ValueError", "int", "str", "numpy.log10"], "function", ["None"], ["", "def", "five_char", "(", "n", ")", ":", "# returns a string of 5 char corresponding to n; e.g. 5->'00005', 23->'00023' ", "\n", "    ", "if", "(", "n", "<", "0", "or", "n", ">=", "10", "**", "5", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"The number should be between 0 and 99999\"", ")", "\n", "", "elif", "(", "n", "==", "0", ")", ":", "\n", "        ", "return", "\"00000\"", "\n", "", "else", ":", "\n", "        ", "no_digits", "=", "int", "(", "np", ".", "log10", "(", "n", ")", ")", "+", "1", "\n", "no_zeros", "=", "5", "-", "no_digits", "\n", "return", "'0'", "*", "no_zeros", "+", "str", "(", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.load_train": [[121, 205], ["os.path.join", "print", "h5py.File", "print", "numpy.random.seed", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "sorted", "numpy.unique", "max", "numpy.random.choice", "print", "numpy.random.shuffle", "h5py.File", "hf.create_dataset", "hf.create_dataset", "hf.create_dataset", "hf.create_dataset", "glob.glob", "class_tracks.append", "int", "str", "len", "BTSC.five_char", "os.path.join", "int", "BTSC.preprocess_img", "skimage.transform.resize", "skimage.transform.resize", "train_imgs.append", "train_labels.append", "BTSC.preprocess_img", "skimage.transform.resize", "skimage.transform.resize", "val_imgs.append", "val_labels.append", "BTSC.track_no", "len", "int", "int", "skimage.io.imread", "print", "skimage.io.imread", "print", "BTSC.track_no", "BTSC.track_no"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.five_char", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.preprocess_img", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.preprocess_img", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.track_no", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.track_no", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.track_no"], ["", "", "def", "load_train", "(", "data_dir", ")", ":", "\n", "    ", "h5filename", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'BTSC_Train_and_Validation_correct-split'", "+", "str", "(", "IMG_SIZE", ")", "+", "'.h5'", ")", "\n", "\n", "try", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "h5filename", ",", "'r'", ")", "as", "hf", ":", "\n", "            ", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", "=", "hf", "[", "'train_imgs'", "]", "[", ":", "]", ",", "hf", "[", "'train_labels'", "]", "[", ":", "]", ",", "hf", "[", "'val_imgs'", "]", "[", ":", "]", ",", "hf", "[", "'val_labels'", "]", "[", ":", "]", "\n", "\n", "", "print", "(", "\"Loaded images from {:}\"", ".", "format", "(", "h5filename", ")", ")", "\n", "\n", "", "except", "(", "IOError", ",", "OSError", ",", "KeyError", ")", ":", "\n", "        ", "print", "(", "\"Error in reading {:}. Processing all images...\"", ".", "format", "(", "h5filename", ")", ")", "\n", "img_root_dir", "=", "data_dir", "\n", "train_imgs", "=", "[", "]", "\n", "train_labels", "=", "[", "]", "\n", "val_imgs", "=", "[", "]", "\n", "val_labels", "=", "[", "]", "\n", "\n", "#         track_val = 0", "\n", "#         track_total = 0", "\n", "#         for i in range(NUM_CLASSES):        ", "\n", "#             class_img_paths = glob.glob(os.path.join(img_root_dir, five_char(i) + '/*.ppm'))", "\n", "\n", "#             tracknr = []", "\n", "#             for img in class_img_paths:", "\n", "#                 tracknr.append(track_no(img))", "\n", "#             print(\"Class \" + str(i) + \" has \" + str(len(class_img_paths)) + \" images and \" + str(len(set(tracknr))) + \" tracks\")", "\n", "\n", "#             track_total += len(set(tracknr))", "\n", "#             track_val += max(1, int(len(set(tracknr))*0.2))", "\n", "#         print(\"No validation tracks: \", track_val, \" Total no: \", track_total)", "\n", "#         import pdb;pdb.set_trace()", "\n", "\n", "np", ".", "random", ".", "seed", "(", "42", ")", "\n", "for", "cl", "in", "range", "(", "NUM_CLASSES", ")", ":", "\n", "            ", "current_dir", "=", "img_root_dir", "+", "\"/\"", "+", "five_char", "(", "cl", ")", "+", "\"/\"", "\n", "class_img_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "current_dir", ",", "'*.ppm'", ")", ")", ")", "\n", "\n", "class_tracks", "=", "[", "]", "\n", "for", "img_path", "in", "class_img_paths", ":", "\n", "                ", "class_tracks", ".", "append", "(", "int", "(", "track_no", "(", "img_path", ")", ")", ")", "\n", "\n", "", "unique_tracks", "=", "np", ".", "unique", "(", "class_tracks", ")", "\n", "no_tracks_val", "=", "max", "(", "1", ",", "int", "(", "len", "(", "unique_tracks", ")", "*", "0.2", ")", ")", "\n", "tracks_val", "=", "np", ".", "random", ".", "choice", "(", "unique_tracks", ",", "no_tracks_val", ",", "replace", "=", "False", ")", "\n", "\n", "print", "(", "\"Class \"", ",", "str", "(", "cl", ")", ",", "', No tracks: '", ",", "len", "(", "unique_tracks", ")", ",", "', Val tracks: '", ",", "tracks_val", ")", "\n", "\n", "np", ".", "random", ".", "shuffle", "(", "class_img_paths", ")", "\n", "\n", "class_val_paths", "=", "[", "p", "for", "p", "in", "class_img_paths", "if", "int", "(", "track_no", "(", "p", ")", ")", "in", "tracks_val", "]", "\n", "class_train_paths", "=", "[", "p", "for", "p", "in", "class_img_paths", "if", "int", "(", "track_no", "(", "p", ")", ")", "not", "in", "tracks_val", "]", "\n", "\n", "for", "img_path", "in", "class_train_paths", ":", "\n", "                ", "try", ":", "\n", "                    ", "img", "=", "preprocess_img", "(", "io", ".", "imread", "(", "img_path", ")", ")", "\n", "img", "=", "skimage", ".", "transform", ".", "resize", "(", "img", ",", "(", "IMG_SIZE", ",", "IMG_SIZE", ")", ",", "mode", "=", "'constant'", ")", "\n", "train_imgs", ".", "append", "(", "img", ")", "\n", "train_labels", ".", "append", "(", "cl", ")", "\n", "", "except", "(", "IOError", ",", "OSError", ")", ":", "\n", "                    ", "print", "(", "'missed'", ",", "img_path", ")", "\n", "pass", "\n", "\n", "", "", "for", "img_path", "in", "class_val_paths", ":", "\n", "                ", "try", ":", "\n", "                    ", "img", "=", "preprocess_img", "(", "io", ".", "imread", "(", "img_path", ")", ")", "\n", "img", "=", "skimage", ".", "transform", ".", "resize", "(", "img", ",", "(", "IMG_SIZE", ",", "IMG_SIZE", ")", ",", "mode", "=", "'constant'", ")", "\n", "val_imgs", ".", "append", "(", "img", ")", "\n", "val_labels", ".", "append", "(", "cl", ")", "\n", "", "except", "(", "IOError", ",", "OSError", ")", ":", "\n", "                    ", "print", "(", "'missed'", ",", "img_path", ")", "\n", "pass", "\n", "\n", "", "", "", "X_train", "=", "np", ".", "array", "(", "train_imgs", ",", "dtype", "=", "'float32'", ")", "\n", "Y_train", "=", "np", ".", "array", "(", "train_labels", ",", "dtype", "=", "'int32'", ")", "\n", "X_val", "=", "np", ".", "array", "(", "val_imgs", ",", "dtype", "=", "'float32'", ")", "\n", "Y_val", "=", "np", ".", "array", "(", "val_labels", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "with", "h5py", ".", "File", "(", "h5filename", ",", "'w'", ")", "as", "hf", ":", "\n", "            ", "hf", ".", "create_dataset", "(", "'train_imgs'", ",", "data", "=", "X_train", ")", "\n", "hf", ".", "create_dataset", "(", "'train_labels'", ",", "data", "=", "Y_train", ")", "\n", "hf", ".", "create_dataset", "(", "'val_imgs'", ",", "data", "=", "X_val", ")", "\n", "hf", ".", "create_dataset", "(", "'val_labels'", ",", "data", "=", "Y_val", ")", "\n", "\n", "", "", "return", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.load_test": [[208, 240], ["numpy.asarray", "numpy.asarray", "os.path.join", "skimage.transform.resize", "skimage.transform.resize", "os.listdir", "os.path.isdir", "os.path.join", "skimage.io.imread", "images.append", "np.asarray.append", "os.path.join", "os.listdir", "f.endswith", "BTSC.preprocess_img", "int", "skimage.io.imread"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.preprocess_img"], ["", "def", "load_test", "(", "data_dir", ")", ":", "#normally data_dir='/ssd_data/datasets/BTSC + Training/Testing'", "\n", "    ", "\"\"\"Loads a data set and returns two lists:\n\n    images: a list of Numpy arrays, each representing an image.\n    labels: a list of numbers that represent the images labels.\n    \"\"\"", "\n", "\n", "# Get all subdirectories of data_dir. Each represents a label.", "\n", "\n", "directories", "=", "[", "d", "for", "d", "in", "os", ".", "listdir", "(", "data_dir", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", ")", ")", "]", "\n", "# Loop through the label directories and collect the data in", "\n", "# two lists, labels and images.", "\n", "labels", "=", "[", "]", "\n", "images", "=", "[", "]", "\n", "for", "d", "in", "directories", ":", "\n", "        ", "label_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", ")", "\n", "file_names", "=", "[", "os", ".", "path", ".", "join", "(", "label_dir", ",", "f", ")", "\n", "for", "f", "in", "os", ".", "listdir", "(", "label_dir", ")", "if", "f", ".", "endswith", "(", "\".ppm\"", ")", "]", "\n", "# For each label, load it's images and add them to the images list.", "\n", "# And add the label number (i.e. directory name) to the labels list.", "\n", "for", "f", "in", "file_names", ":", "\n", "            ", "img_np", "=", "io", ".", "imread", "(", "f", ")", "\n", "images", ".", "append", "(", "preprocess_img", "(", "io", ".", "imread", "(", "f", ")", ")", ")", "\n", "labels", ".", "append", "(", "int", "(", "d", ")", ")", "\n", "\n", "", "", "images_newsize", "=", "[", "skimage", ".", "transform", ".", "resize", "(", "image", ",", "(", "IMG_SIZE", ",", "IMG_SIZE", ")", ",", "mode", "=", "'constant'", ")", "\n", "for", "image", "in", "images", "]", "\n", "images_newsize", "=", "np", ".", "asarray", "(", "images_newsize", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "labels", "=", "np", ".", "asarray", "(", "labels", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "return", "images_newsize", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BTSC.make_hist_of_classes": [[252, 259], ["matplotlib.hist", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.close", "numpy.arange", "str", "str", "numpy.random.randint", "len"], "function", ["None"], ["", "def", "make_hist_of_classes", "(", "y", ",", "text", ")", ":", "\n", "    ", "plt", ".", "hist", "(", "y", ",", "bins", "=", "np", ".", "arange", "(", "NUM_CLASSES", ")", "+", "1", ",", "density", "=", "True", ",", "color", "=", "'m'", ")", "\n", "plt", ".", "title", "(", "\"Distribution of Classes on \"", "+", "text", ")", "\n", "plt", ".", "xlabel", "(", "'Class'", ")", "\n", "plt", ".", "ylabel", "(", "'Percentage'", ")", "\n", "plt", ".", "savefig", "(", "\"/data1/temp/\"", "+", "text", "+", "str", "(", "len", "(", "y", ")", ")", "+", "str", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "100", ")", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.__init__": [[73, 117], ["ImageDataset.ImageDataset.__init__", "OMNIGLOT.OMNIGLOT.dataset_id", "OMNIGLOT.OMNIGLOT.load_data", "os.path.exists", "os.makedirs", "OMNIGLOT.OMNIGLOT.class_filter", "OMNIGLOT.OMNIGLOT.class_filter", "OMNIGLOT.OMNIGLOT.sub_sample", "OMNIGLOT.OMNIGLOT.sub_sample", "numpy.clip", "numpy.clip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "self", ".", "_params", "[", "'binary'", "]", "\n", "\n", "self", ".", "data_dir", "=", "\"datasets/OMNIGLOT_data\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "data_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "data_dir", ")", "\n", "\n", "", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_y", "=", "self", ".", "load_data", "(", ")", "\n", "\n", "# continuous omniglot", "\n", "if", "self", ".", "_binary_input", "==", "0", "or", "(", "self", ".", "_binary_input", "==", "0", "and", "self", ".", "_params", "[", "'stochastic'", "]", "==", "1", ")", ":", "\n", "            ", "dtype", "=", "'f'", "\n", "", "else", ":", "\n", "            ", "dtype", "=", "'i'", "\n", "\n", "\n", "# filter classes", "\n", "", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.load_data": [[119, 145], ["scipy.io.loadmat", "OMNIGLOT.OMNIGLOT.resize_to_pic", "OMNIGLOT.OMNIGLOT.resize_to_pic", "numpy.argmax", "numpy.argmax", "os.path.isfile", "print", "urllib.request.urlretrieve", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.resize_to_pic", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.resize_to_pic"], ["", "", "def", "load_data", "(", "self", ")", ":", "\n", "        ", "fileName", "=", "self", ".", "data_dir", "+", "'/chardata.mat'", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "fileName", ")", ":", "\n", "# see https://github.com/casperkaae/parmesan/blob/master/parmesan/datasets.py", "\n", "            ", "origin", "=", "(", "\n", "'https://github.com/yburda/iwae/raw/'", "\n", "'master/datasets/OMNIGLOT/chardata.mat'", "\n", ")", "\n", "print", "(", "'Downloading data from %s'", "%", "origin", ")", "\n", "\n", "data", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "origin", ",", "fileName", ")", "\n", "\n", "", "mat", "=", "loadmat", "(", "fileName", ")", "\n", "\n", "_train_set_x", "=", "self", ".", "resize_to_pic", "(", "np", ".", "array", "(", "mat", "[", "'data'", "]", ".", "T", ",", "dtype", "=", "'f'", ")", ")", "\n", "_test_set_x", "=", "self", ".", "resize_to_pic", "(", "np", ".", "array", "(", "mat", "[", "'testdata'", "]", ".", "T", ",", "dtype", "=", "'f'", ")", ")", "\n", "_train_set_y", "=", "np", ".", "argmax", "(", "np", ".", "array", "(", "mat", "[", "'target'", "]", ".", "T", ",", "dtype", "=", "'f'", ")", ",", "axis", "=", "1", ")", "\n", "_test_set_y", "=", "np", ".", "argmax", "(", "np", ".", "array", "(", "mat", "[", "'testtarget'", "]", ".", "T", ",", "dtype", "=", "'f'", ")", ",", "axis", "=", "1", ")", "\n", "\n", "return", "(", "_train_set_x", ",", "_test_set_x", ",", "_train_set_y", ",", "_test_set_y", ")", "\n", "\n", "\n", "\n", "implemented_params_keys", "=", "[", "'dataName'", ",", "'binary'", ",", "'stochastic'", ",", "'classes'", ",", "\n", "'position_label'", ",", "'subsampling'", ",", "'clip_high'", ",", "'clip_low'", ",", "\n", "'data_dir'", ",", "'id_note'", "]", "# all the admitted keys", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.resize_to_pic": [[146, 149], ["ds.reshape"], "methods", ["None"], ["", "def", "resize_to_pic", "(", "self", ",", "ds", ")", ":", "\n", "        ", "orig_shape", "=", "ds", ".", "shape", "\n", "return", "ds", ".", "reshape", "(", "orig_shape", "[", "0", "]", ",", "*", "self", ".", "image_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.dataset_id": [[151, 206], ["OMNIGLOT.check_params_impl", "str", "list", "params.keys", "range", "str", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "OMNIGLOT", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'OMNIGLOT'", "\n", "\n", "# binary or continuous", "\n", "id_binary", "=", "{", "0", ":", "'-c'", ",", "1", ":", "'-d'", "}", "\n", "id", "+=", "id_binary", "[", "params", "[", "'binary'", "]", "]", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subclasses", "\n", "# TODO: argo may split the list of classes into subprocesses, easy solution: write a string in place of a list.", "\n", "#", "\n", "if", "(", "'classes'", "in", "params", ".", "keys", "(", ")", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "50", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in OMNIGLOT\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.sub_sample": [[207, 226], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_train", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_train", "=", "np", ".", "random", ".", "permutation", "(", "len_train", ")", "\n", "new_len_train", "=", "int", "(", "len_train", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.class_filter": [[227, 252], ["numpy.in1d", "OMNIGLOT.OMNIGLOT.class_filter.replace_with_position"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "class_filter", "(", "data_set_x", ",", "data_set_y", ",", "classes", ",", "position_label", ")", ":", "\n", "        ", "\"\"\"\n        return the dataset with labels in the list classes\n\n        :param data_set_x: data\n        :param data_set_y: labels\n        :param classes:    list of classes\n        :param position_label:  list of classes\n        :return: (dataset_x, dataset_y) with filtered elemnts not in classes\n        \"\"\"", "\n", "\n", "ix_mtch_class_train", "=", "np", ".", "in1d", "(", "data_set_y", ",", "classes", ")", "\n", "data_set_x", "=", "data_set_x", "[", "ix_mtch_class_train", "]", "\n", "data_set_y", "=", "data_set_y", "[", "ix_mtch_class_train", "]", "\n", "if", "position_label", ":", "\n", "\n", "            ", "def", "replace_with_position", "(", "label_set", ",", "classes", ")", ":", "\n", "                ", "label_set_new", "=", "np", ".", "copy", "(", "label_set", ")", "\n", "for", "ix", ",", "class_", "in", "enumerate", "(", "classes", ")", ":", "label_set_new", "[", "label_set", "==", "class_", "]", "=", "ix", "\n", "return", "label_set_new", "\n", "\n", "", "data_set_y", "=", "replace_with_position", "(", "data_set_y", ",", "classes", ")", "\n", "\n", "", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.input_size": [[263, 266], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "input_size", "(", "self", ")", ":", "\n", "        ", "return", "784", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.output_size": [[267, 270], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "50", "if", "self", ".", "_params", "[", "'classes'", "]", "==", "[", "]", "else", "len", "(", "self", ".", "_params", "[", "'classes'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.color_images": [[271, 274], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.OMNIGLOT.OMNIGLOT.image_shape": [[275, 278], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "(", "28", ",", "28", ",", "1", ")", "# 1 is the number of channels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.__init__": [[87, 156], ["ImageDataset.ImageDataset.__init__", "MNIST.MNIST.dataset_id", "MNIST.MNIST.load_float_mnist", "MNIST.MNIST.class_filter", "MNIST.MNIST.class_filter", "MNIST.MNIST.class_filter", "MNIST.MNIST.sub_sample", "MNIST.MNIST.sub_sample", "MNIST.MNIST.sub_sample", "numpy.clip", "numpy.clip", "numpy.clip", "MNIST.MNIST._train_set_x.reshape", "MNIST.MNIST._validation_set_x.reshape", "MNIST.MNIST._test_set_x.reshape", "MNIST.MNIST._train_set_x.reshape", "MNIST.MNIST._validation_set_x.reshape", "MNIST.MNIST._test_set_x.reshape", "MNIST.MNIST.load_binary_stochastic_mnist", "MNIST.MNIST.load_binary_det_mnist"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.miniMNIST.miniMNIST.load_float_mnist", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.load_binary_stochastic_mnist", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.load_binary_det_mnist"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "self", ".", "_params", "[", "'binary'", "]", "\n", "self", ".", "_pm_one", "=", "self", ".", "_params", "[", "'pm_one'", "]", "\n", "\n", "# continuous mnist", "\n", "if", "self", ".", "_binary_input", "==", "0", ":", "\n", "            ", "default_data_dir", "=", "'datasets/MNIST_data'", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_float_mnist", "(", "self", ".", "data_dir", ")", "\n", "# binary mnist", "\n", "", "else", ":", "\n", "            ", "default_data_dir", "=", "\"datasets/MNIST_raw\"", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "if", "self", ".", "_params", "[", "'stochastic'", "]", "==", "1", ":", "\n", "                ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_binary_stochastic_mnist", "(", "self", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_binary_det_mnist", "(", "self", ".", "data_dir", ",", "pm", "=", "self", ".", "_pm_one", ")", "\n", "\n", "# filter classes", "\n", "", "", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "\n", "position_label", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n", "", "if", "self", ".", "_params", "[", "'vect'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "784", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "784", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "784", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.dataset_id": [[161, 221], ["MNIST.check_params_impl", "str", "list", "range", "str", "int", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "\n", "MNIST", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'MNIST'", "\n", "\n", "# binary or continuous", "\n", "id_binary", "=", "{", "\n", "0", ":", "'-c'", ",", "\n", "1", ":", "'-d'", "}", "\n", "id", "+=", "id_binary", "[", "params", "[", "'binary'", "]", "]", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subclasses", "\n", "#", "\n", "if", "(", "'classes'", "in", "params", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "10", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in MNIST\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "if", "not", "params", "[", "'pm_one'", "]", ":", "\n", "            ", "id", "+=", "'-pm%d'", "%", "int", "(", "params", "[", "'pm_one'", "]", ")", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.load_float_mnist": [[222, 249], ["read_data_sets", "read_data_sets.train.images.astype", "read_data_sets.validation.images.astype", "read_data_sets.test.images.astype", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "read_data_sets.train.labels.astype", "read_data_sets.validation.labels.astype", "read_data_sets.test.labels.astype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize"], ["", "@", "staticmethod", "\n", "def", "load_float_mnist", "(", "data_dir", "=", "'datasets/MNIST_data'", ",", "train_test_ratio", "=", "None", ")", ":", "\n", "        ", "\"\"\" return MNIST data in a format suited for tensorflow.\n\n            The script input_data is available under this URL:\n            https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/examples/tutorials/mnist/input_data.py\n        \"\"\"", "\n", "assert", "(", "not", "train_test_ratio", ")", ",", "\"not implemented yet\"", "\n", "\n", "from", "tensorflow", ".", "contrib", ".", "learn", ".", "python", ".", "learn", ".", "datasets", ".", "mnist", "import", "read_data_sets", "\n", "mnist", "=", "read_data_sets", "(", "data_dir", ",", "one_hot", "=", "False", ")", "\n", "\n", "train_set_x", "=", "mnist", ".", "train", ".", "images", ".", "astype", "(", "np", ".", "float32", ")", "\n", "validation_set_x", "=", "mnist", ".", "validation", ".", "images", ".", "astype", "(", "np", ".", "float32", ")", "\n", "test_set_x", "=", "mnist", ".", "test", ".", "images", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "# normalize data consistently (in case they would not already be)", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "]", ")", "\n", "train_set_x", "=", "normalize", "(", "train_set_x", ",", "all_min", ",", "all_max", ")", "\n", "validation_set_x", "=", "normalize", "(", "validation_set_x", ",", "all_min", ",", "all_max", ")", "\n", "test_set_x", "=", "normalize", "(", "test_set_x", ",", "all_min", ",", "all_max", ")", "\n", "\n", "train_set_y", "=", "mnist", ".", "train", ".", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "validation_set_y", "=", "mnist", ".", "validation", ".", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "test_set_y", "=", "mnist", ".", "test", ".", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "return", "train_set_x", ",", "train_set_y", ",", "validation_set_x", ",", "validation_set_y", ",", "test_set_x", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.load_binary_stochastic_mnist": [[250, 285], ["numpy.reshape.astype", "numpy.reshape.astype", "numpy.reshape.astype", "train_set_y.astype.astype.astype", "validation_set_y.astype.astype.astype", "test_set_y.astype.astype.astype", "gzip.open", "f.seek", "pickle.load", "numpy.reshape", "numpy.reshape", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "@", "staticmethod", "\n", "def", "load_binary_stochastic_mnist", "(", "data_dir", ",", "train_test_ratio", "=", "None", ")", ":", "\n", "        ", "\"\"\" stochastic\n\n             the path is fixed\n             see https://github.com/shuuki4/DRAW-tensorflow/blob/master/DRAW.py\n             training process for MNIST\n\n         \"\"\"", "\n", "assert", "(", "not", "train_test_ratio", ")", ",", "\"not implemented yet\"", "\n", "\n", "mnist_data_path", "=", "data_dir", "+", "\"/mnist.pkl.gz\"", "\n", "with", "gzip", ".", "open", "(", "mnist_data_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "seek", "(", "0", ")", "\n", "train_set", ",", "validation_set", ",", "test_set", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "# binarized MNIST", "\n", "train_set_x", "=", "train_set", "[", "0", "]", "\n", "train_set_y", "=", "train_set", "[", "1", "]", "\n", "validation_set_x", "=", "validation_set", "[", "0", "]", "\n", "validation_set_y", "=", "validation_set", "[", "1", "]", "\n", "test_set_x", "=", "test_set", "[", "0", "]", "\n", "test_set_y", "=", "test_set", "[", "1", "]", "\n", "# reshape", "\n", "train_set_x", "=", "np", ".", "reshape", "(", "train_set_x", ",", "[", "train_set_x", ".", "shape", "[", "0", "]", ",", "784", "]", ")", "\n", "validation_set_x", "=", "np", ".", "reshape", "(", "validation_set_x", ",", "[", "validation_set_x", ".", "shape", "[", "0", "]", ",", "784", "]", ")", "\n", "test_set_x", "=", "np", ".", "reshape", "(", "test_set_x", ",", "[", "test_set_x", ".", "shape", "[", "0", "]", ",", "784", "]", ")", "\n", "\n", "", "train_set_x", "=", "train_set_x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "validation_set_x", "=", "validation_set_x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "test_set_x", "=", "test_set_x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "train_set_y", "=", "train_set_y", ".", "astype", "(", "np", ".", "int32", ")", "\n", "validation_set_y", "=", "validation_set_y", ".", "astype", "(", "np", ".", "int32", ")", "\n", "test_set_y", "=", "test_set_y", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "return", "train_set_x", ",", "train_set_y", ",", "validation_set_x", ",", "validation_set_y", ",", "test_set_x", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.load_binary_det_mnist": [[286, 314], ["torchfile.load", "torchfile.load", "torchfile.load", "print", "os.path.exists", "os.mkdir", "train_set_x.astype.astype.astype", "validation_set_x.astype.astype.astype", "test_set_x.astype.astype.astype", "train_set_x.astype.astype.astype", "validation_set_x.astype.astype.astype", "test_set_x.astype.astype.astype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "@", "staticmethod", "\n", "def", "load_binary_det_mnist", "(", "data_dir", ",", "train_test_ratio", "=", "None", ",", "pm", "=", "True", ")", ":", "\n", "        ", "\"\"\" load the mnist from torchfiles in the path labels are not available\n         \"\"\"", "\n", "assert", "(", "not", "train_test_ratio", ")", ",", "\"not implemented yet\"", "\n", "import", "torchfile", "\n", "\n", "mnist_data_path", "=", "data_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "mnist_data_path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "mnist_data_path", ")", "\n", "# dataset from:", "\n", "# train: http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat", "\n", "# validation: http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat", "\n", "# test: http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat", "\n", "", "train_set_x", "=", "torchfile", ".", "load", "(", "mnist_data_path", "+", "\"/train.t7\"", ")", "\n", "validation_set_x", "=", "torchfile", ".", "load", "(", "mnist_data_path", "+", "\"/valid.t7\"", ")", "\n", "test_set_x", "=", "torchfile", ".", "load", "(", "mnist_data_path", "+", "\"/test.t7\"", ")", "\n", "# no labels available here", "\n", "print", "(", "'[WARNING] - This dataset has no lables'", ")", "\n", "if", "pm", ":", "\n", "            ", "train_set_x", "=", "train_set_x", ".", "astype", "(", "np", ".", "float32", ")", "*", "2", "-", "1", "\n", "validation_set_x", "=", "validation_set_x", ".", "astype", "(", "np", ".", "float32", ")", "*", "2", "-", "1", "\n", "test_set_x", "=", "test_set_x", ".", "astype", "(", "np", ".", "float32", ")", "*", "2", "-", "1", "\n", "", "else", ":", "\n", "            ", "train_set_x", "=", "train_set_x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "validation_set_x", "=", "validation_set_x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "test_set_x", "=", "test_set_x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "return", "train_set_x", ",", "None", ",", "validation_set_x", ",", "None", ",", "test_set_x", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.sub_sample": [[315, 334], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_data", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_data", "=", "np", ".", "random", ".", "permutation", "(", "len_data", ")", "\n", "new_len_data", "=", "int", "(", "len_data", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.label_to_name": [[335, 348], ["None"], "methods", ["None"], ["", "def", "label_to_name", "(", "self", ",", "label", ")", ":", "\n", "        ", "label_to_name_M_dict", "=", "{", "\n", "0", ":", "\"Zero\"", ",", "\n", "1", ":", "\"One\"", ",", "\n", "2", ":", "\"Two\"", ",", "\n", "3", ":", "\"Three\"", ",", "\n", "4", ":", "\"Four\"", ",", "\n", "5", ":", "\"Five\"", ",", "\n", "6", ":", "\"Six\"", ",", "\n", "7", ":", "\"Seven\"", ",", "\n", "8", ":", "\"Eight\"", ",", "\n", "9", ":", "\"Nine\"", "}", "\n", "return", "label_to_name_M_dict", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.output_size": [[349, 352], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "10", "if", "self", ".", "_params", "[", "'classes'", "]", "==", "(", ")", "else", "len", "(", "self", ".", "_params", "[", "'classes'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.color_images": [[353, 356], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.dataset_map": [[358, 375], ["super().dataset_map", "super().dataset_map.map", "super().dataset_map.map", "tensorflow.distributions.Bernoulli().sample", "tensorflow.distributions.Bernoulli().sample", "tensorflow.distributions.Bernoulli", "tensorflow.distributions.Bernoulli"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_map", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "\n", "# call parent", "\n", "        ", "dataset", "=", "super", "(", "MNIST", ",", "self", ")", ".", "dataset_map", "(", "dataset", ",", "datasets_tuple", ")", "\n", "\n", "# sample from x if this is the case", "\n", "if", "self", ".", "_binary_input", "and", "self", ".", "_params", "[", "'stochastic'", "]", ":", "\n", "# the dataset is a tuple x, y", "\n", "            ", "if", "self", ".", "_pm_one", ":", "\n", "                ", "return", "dataset", ".", "map", "(", "\n", "lambda", "x", ",", "y", ":", "(", "tf", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "x", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "sample", "(", ")", "*", "2.0", "-", "1", ",", "y", ")", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "else", ":", "\n", "                ", "return", "dataset", ".", "map", "(", "lambda", "x", ",", "y", ":", "(", "tf", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "x", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "sample", "(", ")", ",", "y", ")", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "dataset", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IRIS.IRIS.__init__": [[36, 65], ["Dataset.Dataset.__init__", "IRIS.IRIS.dataset_id", "IRIS.IRIS.load_data", "IRIS.IRIS.class_filter", "IRIS.IRIS.class_filter", "IRIS.IRIS.class_filter", "IRIS.IRIS.sub_sample", "IRIS.IRIS.sub_sample", "IRIS.IRIS.sub_sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "False", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", ")", "\n", "\n", "# filter classes", "\n", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IRIS.IRIS.dataset_id": [[70, 108], ["IRIS.check_params_impl", "str", "list", "range", "str", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "\n", "IRIS", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'IRIS'", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subclasses", "\n", "if", "(", "'classes'", "in", "params", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "10", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in SVHN\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# id note (keep last)", "\n", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IRIS.IRIS.load_data": [[109, 125], ["sklearn.datasets.load_iris", "numpy.random.permutation", "sklearn.datasets.load_iris.data[].astype", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", ")", ":", "\n", "\n", "# see https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html", "\n", "        ", "iris", "=", "datasets", ".", "load_iris", "(", ")", "\n", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "iris", ".", "target", ")", ")", "\n", "\n", "data", "=", "iris", ".", "data", "[", "perm", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "target", "=", "iris", ".", "target", "[", "perm", "]", "\n", "\n", "# points in the train_set", "\n", "n", "=", "120", "\n", "\n", "# extra is ignored, since the images are too simple", "\n", "return", "data", "[", ":", "n", "]", ",", "target", "[", ":", "n", "]", ",", "data", "[", "n", ":", "]", ",", "target", "[", "n", ":", "]", ",", "data", "[", "n", ":", "]", ",", "target", "[", "n", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IRIS.IRIS.sub_sample": [[126, 145], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_data", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_data", "=", "np", ".", "random", ".", "permutation", "(", "len_data", ")", "\n", "new_len_data", "=", "int", "(", "len_data", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.__init__": [[30, 107], ["Dataset.Dataset.__init__", "AlphaDatasetIt.IMDBReviews.dataset_id", "os.path.basename", "word_embedding.test.core.load_embeddings.load_dict", "word_embedding.test.core.load_embeddings.load_emb_base", "numpy.linalg.inv", "os.path.join", "word_embedding.test.core.load_embeddings.load_embeddings_ldv_hdf", "numpy.matmul().transpose", "numpy.expand_dims", "numpy.array", "tensorflow_datasets.load", "tensorflow_datasets.Split.TEST.subsplit", "tensorflow_datasets.load", "tensorflow_datasets.load", "IMDBReviews.process_params", "os.path.normpath", "word_embedding.test.core.load_embeddings.get_alpha_ldv_name", "word_embedding.test.core.measures.center_and_normalize_riemannian", "numpy.zeros", "numpy.concatenate", "numpy.matmul", "numpy.eye", "numpy.transpose", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_dict", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_emb_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_embeddings_ldv_hdf", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "IMDBReviews", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "emb_dir", "=", "self", ".", "_params", "[", "\"emb_dir\"", "]", "\n", "alpha", "=", "self", ".", "_params", "[", "\"alpha\"", "]", "\n", "theta", "=", "self", ".", "_params", "[", "\"theta\"", "]", "\n", "point", "=", "self", ".", "_params", "[", "\"point\"", "]", "\n", "normalization", "=", "self", ".", "_params", "[", "\"norm\"", "]", "\n", "self", ".", "_aggregate", "=", "self", ".", "_params", "[", "\"aggregate\"", "]", "\n", "\n", "self", ".", "_emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "# corpus, vstr, nstr = emb_id.split('-')", "\n", "\n", "vocab", ",", "ivocab", ",", "vocab_size", "=", "load_dict", "(", "emb_dir", ")", "\n", "self", ".", "_dictionary", "=", "vocab", "\n", "\n", "# ALPHA BASE", "\n", "alphas", ",", "I", "=", "load_emb_base", "(", "emb_dir", ",", "point", ")", "\n", "I_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I", ")", "\n", "\n", "fullname", "=", "os", ".", "path", ".", "join", "(", "emb_dir", ",", "get_alpha_ldv_name", "(", "alpha", ",", "theta", "+", "\"_embeddings\"", ",", "point", ")", ")", "\n", "ldv", "=", "load_embeddings_ldv_hdf", "(", "fullname", ")", "\n", "\n", "plog", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "transpose", "(", "ldv", ")", ")", ".", "transpose", "(", ")", "\n", "self", ".", "_emb_size", "=", "plog", ".", "shape", "[", "1", "]", "\n", "\n", "if", "normalization", "is", "not", "None", ":", "\n", "            ", "if", "normalization", "==", "\"I\"", ":", "\n", "                ", "norm_matrix", "=", "np", ".", "eye", "(", "self", ".", "_emb_size", ")", "\n", "", "elif", "normalization", "==", "\"F\"", ":", "\n", "                ", "norm_matrix", "=", "I", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Only Identity (I) or Fisher (F) normalization are allowed.. or no normalization (None)\"", ")", "\n", "\n", "", "plog", "=", "center_and_normalize_riemannian", "(", "plog", ",", "norm_matrix", ",", "center", "=", "False", ")", "\n", "\n", "", "unk_emb", "=", "np", ".", "expand_dims", "(", "np", ".", "zeros", "(", "plog", ".", "shape", "[", "1", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "_embeddings", "=", "np", ".", "array", "(", "np", ".", "concatenate", "(", "(", "plog", ",", "unk_emb", ")", ",", "axis", "=", "0", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "train_dataset", ",", "info", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "\"train\"", ",", "as_supervised", "=", "True", ",", "with_info", "=", "True", ")", "\n", "self", ".", "_n_samples_train", "=", "info", ".", "splits", "[", "'train'", "]", ".", "num_examples", "\n", "# val/test equal split", "\n", "self", ".", "_n_samples_validation", "=", "info", ".", "splits", "[", "'test'", "]", ".", "num_examples", "/", "2.", "\n", "self", ".", "_n_samples_test", "=", "info", ".", "splits", "[", "'test'", "]", ".", "num_examples", "/", "2.", "\n", "\n", "# # new S3 API, still not supported by imdb reviews", "\n", "# validation_dataset = tfds.load('imdb_reviews/plain_text', split=\"test[:50%]\", as_supervised=True)", "\n", "# test_dataset = tfds.load('imdb_reviews/plain_text', split=\"test[-50%:]\", as_supervised=True)", "\n", "\n", "# legacy API", "\n", "validation_split", ",", "test_split", "=", "tfds", ".", "Split", ".", "TEST", ".", "subsplit", "(", "k", "=", "2", ")", "\n", "validation_dataset", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "validation_split", ",", "as_supervised", "=", "True", ")", "\n", "test_dataset", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "test_split", ",", "as_supervised", "=", "True", ")", "\n", "\n", "self", ".", "_raw_datasets", "=", "{", "\n", "TRAIN", ":", "train_dataset", ",", "\n", "VALIDATION", ":", "validation_dataset", ",", "\n", "TEST", ":", "test_dataset", "\n", "}", "\n", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "\n", "self", ".", "_dataset_cache", "=", "self", ".", "_params", "[", "\"dataset_cache\"", "]", "\n", "\n", "if", "self", ".", "_aggregate", ":", "\n", "            ", "self", ".", "_x_sample_shape", "=", "(", "self", ".", "_emb_size", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_x_sample_shape", "=", "(", "None", ",", "self", ".", "_emb_size", ")", "\n", "\n", "# binary classification (I treat it as softmax for simplicity), the output must be 2", "\n", "", "self", ".", "_y_sample_shape", "=", "(", ")", "\n", "self", ".", "_y_one_hot_sample_shape", "=", "(", "2", ",", ")", "\n", "\n", "self", ".", "_padded_shape", "=", "(", "self", ".", "_x_sample_shape", ",", "self", ".", "_y_sample_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.dataset_id": [[108, 143], ["IMDBReviews.check_params_impl", "os.path.basename", "os.path.normpath", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "IMDBReviews", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'IMDBReviews'", "\n", "emb_dir", "=", "params", "[", "\"emb_dir\"", "]", "\n", "alpha", "=", "params", "[", "\"alpha\"", "]", "\n", "theta", "=", "params", "[", "\"theta\"", "]", "\n", "point", "=", "params", "[", "\"point\"", "]", "\n", "emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "_id", "+=", "\"-\"", "+", "emb_id", "\n", "\n", "try", ":", "\n", "            ", "_id", "+=", "\"-a{:.2f}\"", ".", "format", "(", "alpha", ")", "\n", "", "except", ":", "\n", "            ", "_id", "+=", "\"-a{:}\"", ".", "format", "(", "alpha", ")", "\n", "\n", "", "_id", "+=", "\"-\"", "+", "theta", "\n", "_id", "+=", "\"-\"", "+", "point", "\n", "\n", "normalization", "=", "params", "[", "\"norm\"", "]", "\n", "if", "normalization", "is", "not", "None", ":", "\n", "            ", "if", "normalization", "not", "in", "[", "\"I\"", ",", "\"F\"", "]", ":", "\n", "                ", "raise", "Exception", "(", "\"Only Identity (I) or Fisher (F) normalization are allowed..\"", ")", "\n", "", "_id", "+=", "\"-\"", "+", "normalization", "\n", "\n", "", "aggregate", "=", "params", "[", "\"aggregate\"", "]", "\n", "\n", "if", "aggregate", ":", "\n", "            ", "_id", "+=", "\"-aggr\"", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.n_samples_train": [[144, 147], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_n_samples_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.x_shape_train": [[148, 152], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.x_shape_eval": [[153, 157], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.y_shape": [[158, 162], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_y_one_hot_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.n_labels": [[163, 167], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the number of labeles in this dataset\"\"\"", "\n", "return", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.labels": [[168, 172], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the list of labels in this dataset\"\"\"", "\n", "return", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews._preprocess": [[173, 181], ["numpy.array", "numpy.mean", "numpy.array", "word_embedding.preprocess.preprocess_lib.preproc_a"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_preprocess", "(", "self", ",", "excerpt", ",", "label", ")", ":", "\n", "        ", "indexes", "=", "np", ".", "array", "(", "[", "self", ".", "_dictionary", "[", "w", "]", "if", "w", "in", "self", ".", "_dictionary", "else", "-", "1", "for", "w", "in", "preproc_a", "(", "excerpt", ")", "]", ")", "\n", "\n", "xdata", "=", "self", ".", "_embeddings", "[", "indexes", "]", "\n", "if", "self", ".", "_aggregate", ":", "\n", "            ", "xdata", "=", "np", ".", "mean", "(", "xdata", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "xdata", ",", "np", ".", "array", "(", "label", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetIt.IMDBReviews.get_dataset_iterator": [[182, 225], ["dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.padded_batch", "zip", "dataset.repeat.repeat.cache", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.padded_batch.make_one_shot_iterator", "dataset.repeat.padded_batch.make_initializable_iterator", "tuple", "node.set_shape", "tensorflow.py_func"], "methods", ["None"], ["", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ")", ":", "\n", "\n", "        ", "dataset", "=", "self", ".", "_raw_datasets", "[", "dataset_str", "]", "\n", "\n", "output_types", "=", "(", "tf", ".", "float32", ",", "tf", ".", "int32", "\n", "\n", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ",", "y", ":", "tuple", "(", "tf", ".", "py_func", "(", "self", ".", "_preprocess", ",", "\n", "[", "x", ",", "y", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "output_shapes", "=", "(", "self", ".", "_x_sample_shape", ",", "self", ".", "_y_sample_shape", ")", "\n", "\n", "def", "_set_shapes", "(", "*", "nodes", ")", ":", "\n", "            ", "for", "node", ",", "outshape", "in", "zip", "(", "nodes", ",", "output_shapes", ")", ":", "\n", "                ", "node", ".", "set_shape", "(", "outshape", ")", "\n", "", "return", "nodes", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "_set_shapes", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "if", "self", ".", "_dataset_cache", ":", "\n", "            ", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "            ", "if", "self", ".", "_shuffling_cache", "is", "None", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_n_samples_train", "+", "1", "\n", "", "else", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffling_cache", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffling_cache", ")", "\n", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "\n", "", "batched_dataset", "=", "dataset", ".", "padded_batch", "(", "batch_size", ",", "padded_shapes", "=", "self", ".", "_padded_shape", ")", "\n", "\n", "if", "repeat", ":", "\n", "# create iterator to retrieve batches", "\n", "            ", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.__init__": [[55, 71], ["datasets.AudioDataset.AudioDataset.__init__", "NSynth.NSynth.dataset_id", "NSynth.process_params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "NSynth", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_sample_lenght", "=", "64000", "\n", "self", ".", "_sample_rate", "=", "16000", "\n", "self", ".", "_label", "=", "(", "self", ".", "_params", "[", "'label'", "]", "if", "self", ".", "_params", "[", "'label'", "]", "in", "ALL_LABELS_IMPLEMENTED", "else", "None", ")", "\n", "\n", "# self._n_labels = len(self._params['features']) if 'features' in self._params else 0", "\n", "self", ".", "_x_sample_shape_train", "=", "[", "self", ".", "_crop_length_train", ",", "1", "]", "\n", "self", ".", "_x_sample_shape_eval", "=", "[", "self", ".", "_sample_lenght", ",", "1", "]", "\n", "self", ".", "_y_sample_shape", "=", "None", "# (self._n_labels,)", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.dataset_id": [[76, 92], ["NSynth.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "NSynth", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'NSynth'", "\n", "\n", "# TODO I know this is bad but if id is a static method and not an object method I have no idea how to handle this better,", "\n", "# TODO soon we should refactor the id to be multilayer of abstraction as in Networks and Models.", "\n", "if", "params", "[", "'shuffle_buffer'", "]", "!=", "NSynth", ".", "default_params", "[", "'shuffle_buffer'", "]", ":", "\n", "            ", "_id", "+=", "'-sh%.2e'", "%", "params", "[", "'shuffle_buffer'", "]", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.get_var_labels": [[93, 98], ["numpy.intersect1d", "len", "len"], "methods", ["None"], ["", "def", "get_var_labels", "(", "self", ",", "param", ")", ":", "\n", "        ", "var_params", "=", "np", ".", "intersect1d", "(", "ALL_LABELS", ",", "param", ")", "\n", "\n", "assert", "len", "(", "var_params", ")", "==", "len", "(", "param", ")", ",", "\"It seems like you might have a mistake in you label name\"", "\n", "return", "var_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth._parse_function": [[99, 119], ["tensorflow.parse_single_example", "tensorflow.expand_dims", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_parse_function", "(", "example_proto", ",", "y_label", "=", "None", ")", ":", "\n", "        ", "features", "=", "{", "\n", "NOTE", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "PITCH", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "VELOCITY", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "AUDIO", ":", "tf", ".", "FixedLenFeature", "(", "[", "64000", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "QUALITIES", ":", "tf", ".", "FixedLenFeature", "(", "[", "10", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "INSTR_SOURCE", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "INSTR_FAMILY", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "}", "\n", "parsed_features", "=", "tf", ".", "parse_single_example", "(", "example_proto", ",", "features", ")", "\n", "\n", "# add channel info for standardized input", "\n", "audio", "=", "tf", ".", "expand_dims", "(", "parsed_features", "[", "AUDIO", "]", ",", "axis", "=", "-", "1", ")", "\n", "# audio = parsed_features[\"audio\"]", "\n", "if", "y_label", ":", "\n", "            ", "return", "(", "audio", ",", "parsed_features", "[", "y_label", "]", ",", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "audio", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.get_dataset_iterator": [[120, 181], ["tensorflow.data.TFRecordDataset", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "NSynth.NSynth._parse_function", "functools.partial", "functools.partial", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi._parse_function"], ["", "", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ")", ":", "\n", "\n", "        ", "is_perturbed", "=", "False", "\n", "filename", "=", "\"\"", "\n", "\n", "# create Dataset objects using the data previously downloaded", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/nsynth-train.tfrecord\"", "\n", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/nsynth-valid.tfrecord\"", "\n", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/nsynth-test.tfrecord\"", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "# CREATE TF DATASET with map and py_func", "\n", "", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "[", "filename", "]", ")", "\n", "\n", "NPROCS", "=", "20", "\n", "if", "self", ".", "_label", ":", "\n", "            ", "parse_func", "=", "lambda", "x", ":", "self", ".", "_parse_function", "(", "x", ",", "y_label", "=", "self", ".", "_label", ")", "\n", "", "else", ":", "\n", "            ", "parse_func", "=", "self", ".", "_parse_function", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "parse_func", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# PREPROCESS DATA (CROP IF NEEDED, this is needed only for the train loop)", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "# dataset = dataset.cache()", "\n", "\n", "# PREPROCESS DATA (AUGMENT IF NEEDED)", "\n", "", "if", "augment", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_augment_element", ",", "is_perturbed", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# SHUFFLE, REPEAT and BATCH", "\n", "# we shuffle the data and sample repeatedly batches for the training loop", "\n", "", "if", "shuffle", ":", "\n", "            ", "if", "self", ".", "_shuffling_cache", "is", "None", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffle_buffer", "+", "1", "\n", "", "else", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffling_cache", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffling_cache", ")", "\n", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", ",", "is_perturbed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.n_samples_train": [[182, 186], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "# From https://magenta.tensorflow.org/datasets/nsynth#files", "\n", "        ", "return", "289205", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.x_shape_train": [[187, 191], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.x_shape_eval": [[192, 196], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.y_shape": [[197, 201], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NSynth.NSynth.sample_rate": [[202, 206], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_sample_rate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.__init__": [[50, 68], ["datasets.AudioDataset.AudioDataset.__init__", "DigiScope.DigiScope.dataset_id", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_sample_lenght", "=", "111468", "+", "148", "# 128 padded 0s  # used to be 88384 for sample rate 44100", "\n", "self", ".", "_sample_rate", "=", "44100", "\n", "self", ".", "_label", "=", "(", "self", ".", "_params", "[", "'label'", "]", "if", "self", ".", "_params", "[", "'label'", "]", "in", "ALL_LABELS_IMPLEMENTED", "else", "None", ")", "\n", "\n", "# self._n_labels = len(self._params['features']) if 'features' in self._params else 0", "\n", "self", ".", "_x_sample_shape_train", "=", "[", "self", ".", "_crop_length_train", ",", "1", "]", "\n", "self", ".", "_x_sample_shape_eval", "=", "[", "self", ".", "_sample_lenght", ",", "1", "]", "\n", "self", ".", "_y_sample_shape", "=", "None", "# (self._n_labels,)", "\n", "\n", "self", ".", "_n_labels", "=", "len", "(", "LABEL_TO_INT_DICT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.dataset_id": [[72, 91], ["DigiScope.check_params_impl", "params.get"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "DigiScope", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'DigiScope'", "\n", "\n", "# TODO I know this is bad but if id is a static method and not an object method I have no idea how to handle this better,", "\n", "# TODO soon we should refactor the id to be multilayer of abstraction as in Networks and Models.", "\n", "if", "params", "[", "'shuffle_buffer'", "]", "!=", "DigiScope", ".", "default_params", "[", "'shuffle_buffer'", "]", ":", "\n", "            ", "_id", "+=", "'-sh%.2e'", "%", "params", "[", "'shuffle_buffer'", "]", "\n", "\n", "", "if", "params", ".", "get", "(", "'anomaly_detection'", ",", "False", ")", ":", "\n", "            ", "_id", "+=", "'-anomaly_detection'", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.get_var_labels": [[92, 97], ["numpy.intersect1d", "len", "len"], "methods", ["None"], ["", "def", "get_var_labels", "(", "self", ",", "param", ")", ":", "\n", "        ", "var_params", "=", "np", ".", "intersect1d", "(", "ALL_LABELS", ",", "param", ")", "\n", "\n", "assert", "len", "(", "var_params", ")", "==", "len", "(", "param", ")", ",", "\"It seems like you might have a mistake in you label name\"", "\n", "return", "var_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope._parse_function": [[98, 115], ["tensorflow.parse_single_example", "tensorflow.expand_dims", "datasets.AudioDataset.AudioDataset.str_label_to_int", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset.str_label_to_int"], ["", "@", "staticmethod", "\n", "def", "_parse_function", "(", "example_proto", ",", "y_label", "=", "None", ")", ":", "\n", "        ", "features", "=", "{", "\n", "LABEL", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "NAME", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "AUDIO", ":", "tf", ".", "VarLenFeature", "(", "dtype", "=", "tf", ".", "float32", ")", ",", "# max111468", "\n", "}", "\n", "parsed_features", "=", "tf", ".", "parse_single_example", "(", "example_proto", ",", "features", ")", "\n", "\n", "# Expand dims for channels", "\n", "audio", "=", "tf", ".", "expand_dims", "(", "tf", ".", "concat", "(", "parsed_features", "[", "AUDIO", "]", ".", "values", ",", "axis", "=", "0", ")", ",", "axis", "=", "-", "1", ")", "\n", "label", "=", "AudioDataset", ".", "str_label_to_int", "(", "parsed_features", "[", "y_label", "]", ",", "LABEL_TO_INT_DICT", ")", "\n", "\n", "if", "y_label", ":", "\n", "            ", "return", "(", "audio", ",", "label", ",", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "audio", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.get_dataset_iterator": [[116, 178], ["tensorflow.data.TFRecordDataset", "dataset.repeat.repeat.map", "dataset.repeat.repeat.cache", "DigiScope.DigiScope._params.get", "dataset.repeat.repeat.map().map", "dataset.repeat.repeat.map().map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "Exception", "DigiScope.DigiScope._parse_function", "len", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "functools.partial", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi._parse_function"], ["", "", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ",", "perturb", ")", ":", "\n", "\n", "        ", "is_perturbed", "=", "False", "\n", "filename", "=", "\"\"", "\n", "\n", "# create Dataset objects using the data previously downloaded", "\n", "if", "dataset_str", "==", "TRAIN", "or", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "if", "self", ".", "_params", ".", "get", "(", "\"anomaly_detection\"", ",", "False", ")", ":", "\n", "                ", "filename", "=", "self", ".", "_data_dir", "+", "\"/anomaly_detection/{}3-digi-float-shuffled.tfrecords\"", ".", "format", "(", "dataset_str", ")", "\n", "", "else", ":", "\n", "                ", "filename", "=", "self", ".", "_data_dir", "+", "\"/{}3-digi-float-shuffled.tfrecords\"", ".", "format", "(", "dataset_str", ")", "\n", "\n", "", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/b-test_all-2-labels.tfrecords\"", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "# CREATE TF DATASET with map and py_func", "\n", "", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "[", "filename", "]", ")", "\n", "\n", "NPROCS", "=", "20", "\n", "if", "self", ".", "_label", ":", "\n", "            ", "parse_func", "=", "lambda", "x", ":", "self", ".", "_parse_function", "(", "x", ",", "y_label", "=", "self", ".", "_label", ")", "\n", "", "else", ":", "\n", "            ", "parse_func", "=", "self", ".", "_parse_function", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "parse_func", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "# PREPROCESS DATA (AUGMENT IF NEEDED)", "\n", "if", "augment", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ",", "self", ".", "_crop_length_train", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", ".", "map", "(", "self", ".", "augment_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "if", "dataset_str", "==", "TEST", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ",", "self", ".", "_crop_length_train", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", ".", "map", "(", "self", ".", "augment_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# handle perturbation", "\n", "", "if", "is_perturbed", "and", "len", "(", "self", ".", "_data_perturbation", ")", ">", "0", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "perturb_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "duplicate_x_element_if_needed", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# SHUFFLE, REPEAT and BATCH", "\n", "", "if", "shuffle", ":", "\n", "            ", "LARGE_NUMBER", "=", "self", ".", "_shuffle_buffer", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "LARGE_NUMBER", "+", "1", ")", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.int_to_str_label": [[179, 184], ["LABEL_TO_INT_DICT.items"], "methods", ["None"], ["", "def", "int_to_str_label", "(", "self", ",", "int_label", ":", "int", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "LABEL_TO_INT_DICT", ".", "items", "(", ")", ":", "\n", "            ", "if", "int_label", "==", "value", ":", "\n", "                ", "return", "key", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.n_samples_train": [[185, 188], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "352", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.x_shape_train": [[191, 195], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.x_shape_eval": [[196, 200], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.y_shape": [[201, 205], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DigiScope.DigiScope.sample_rate": [[206, 210], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_sample_rate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Perturbations.context_encoding": [[7, 40], ["image.get_shape().as_list", "numpy.random.randint", "numpy.random.randint", "numpy.meshgrid", "numpy.zeros", "tensorflow.stack", "tensorflow.tensor_scatter_nd_update", "Exception", "range", "range", "numpy.ones", "image.get_shape", "int", "int", "rows.flatten", "columns.flatten"], "function", ["None"], ["def", "context_encoding", "(", "image", ",", "size", ")", ":", "\n", "#if isinstance(images, list):", "\n", "#    return tuple([image for image in images])", "\n", "#else:", "\n", "#pdb.set_trace()", "\n", "\n", "    ", "'''\n    matrix = np.zeros([28, 28, 1])\n    matrix[0:14, 0:14, :] = 1\n    mask = tf.convert_to_tensor(matrix, dtype=tf.int32)\n\n    indexes = tf.where(tf.equal(mask, 1))\n    '''", "\n", "\n", "#indices = tf.constant([[0, 0, 0], [0, 1, 0] [1, 0, 0], [1, 1, 0]])", "\n", "\n", "w", ",", "h", ",", "c", "=", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "\n", "if", "c", "!=", "1", ":", "\n", "        ", "raise", "Exception", "(", "\"contextual encoding not implemented for color images, feel free to implement it\"", ")", "\n", "\n", "", "x", "=", "np", ".", "random", ".", "randint", "(", "w", "-", "size", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "h", "-", "size", ")", "\n", "\n", "rows", ",", "columns", "=", "np", ".", "meshgrid", "(", "range", "(", "x", ",", "x", "+", "size", ")", ",", "range", "(", "y", ",", "y", "+", "size", ")", ")", "\n", "\n", "channel", "=", "np", ".", "zeros", "(", "size", "**", "2", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "[", "int", "(", "r", ")", "for", "r", "in", "rows", ".", "flatten", "(", ")", "]", ",", "[", "int", "(", "c", ")", "for", "c", "in", "columns", ".", "flatten", "(", ")", "]", ",", "channel", "]", ",", "axis", "=", "1", ")", "\n", "\n", "updates", "=", "np", ".", "ones", "(", "size", "**", "2", ",", "dtype", "=", "np", ".", "int32", ")", "*", "-", "1", "# black square", "\n", "ce_image", "=", "tf", ".", "tensor_scatter_nd_update", "(", "image", ",", "indices", ",", "updates", ")", "\n", "\n", "return", "ce_image", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.__init__": [[27, 106], ["Dataset.Dataset.__init__", "IMDBReviews.IMDBReviews.dataset_id", "os.path.basename", "word_embedding.test.core.load_embeddings.load_dict", "word_embedding.test.core.load_embeddings.load_emb_base", "numpy.linalg.inv", "word_embedding.test.core.load_embeddings.get_embpath", "word_embedding.test.core.load_embeddings.load_embeddings_ldv_hdf", "numpy.matmul().transpose", "numpy.expand_dims", "numpy.array", "tensorflow_datasets.load", "tensorflow_datasets.Split.TEST.subsplit", "tensorflow_datasets.load", "tensorflow_datasets.load", "IMDBReviews.process_params", "os.path.normpath", "word_embedding.test.core.measures.center_and_normalize_riemannian", "numpy.zeros", "numpy.concatenate", "numpy.matmul", "numpy.eye", "numpy.transpose", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_dict", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_emb_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_embpath", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_embeddings_ldv_hdf", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "IMDBReviews", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "emb_dir", "=", "self", ".", "_params", "[", "\"emb_dir\"", "]", "\n", "alpha_tuple", "=", "self", ".", "_params", "[", "\"alpha\"", "]", "\n", "theta", "=", "self", ".", "_params", "[", "\"theta\"", "]", "\n", "point", "=", "self", ".", "_params", "[", "\"point\"", "]", "\n", "normalization", "=", "self", ".", "_params", "[", "\"norm\"", "]", "\n", "self", ".", "_aggregate", "=", "self", ".", "_params", "[", "\"aggregate\"", "]", "\n", "\n", "self", ".", "_emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "# corpus, vstr, nstr = emb_id.split('-')", "\n", "\n", "vocab", ",", "ivocab", ",", "vocab_size", "=", "load_dict", "(", "emb_dir", ")", "\n", "self", ".", "_dictionary", "=", "vocab", "\n", "\n", "# ALPHA BASE", "\n", "alphas", ",", "I", "=", "load_emb_base", "(", "emb_dir", ",", "point", ")", "\n", "I_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I", ")", "\n", "\n", "embpath", "=", "get_embpath", "(", "alpha_tuple", ",", "theta", ",", "point", ",", "emb_dir", ")", "\n", "\n", "# fullname = os.path.join(emb_dir, get_alpha_ldv_name(alpha, theta+\"_embeddings\", point))", "\n", "ldv", "=", "load_embeddings_ldv_hdf", "(", "embpath", ")", "\n", "\n", "plog", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "transpose", "(", "ldv", ")", ")", ".", "transpose", "(", ")", "\n", "self", ".", "_emb_size", "=", "plog", ".", "shape", "[", "1", "]", "\n", "\n", "if", "normalization", "is", "not", "None", ":", "\n", "            ", "if", "normalization", "==", "\"I\"", ":", "\n", "                ", "norm_matrix", "=", "np", ".", "eye", "(", "self", ".", "_emb_size", ")", "\n", "", "elif", "normalization", "==", "\"F\"", ":", "\n", "                ", "norm_matrix", "=", "I", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Only Identity (I) or Fisher (F) normalization are allowed.. or no normalization (None)\"", ")", "\n", "\n", "", "plog", "=", "center_and_normalize_riemannian", "(", "plog", ",", "norm_matrix", ",", "center", "=", "False", ")", "\n", "\n", "", "unk_emb", "=", "np", ".", "expand_dims", "(", "np", ".", "zeros", "(", "plog", ".", "shape", "[", "1", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "_embeddings", "=", "np", ".", "array", "(", "np", ".", "concatenate", "(", "(", "plog", ",", "unk_emb", ")", ",", "axis", "=", "0", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "train_dataset", ",", "info", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "\"train\"", ",", "as_supervised", "=", "True", ",", "with_info", "=", "True", ")", "\n", "self", ".", "_n_samples_train", "=", "info", ".", "splits", "[", "'train'", "]", ".", "num_examples", "\n", "# val/test equal split", "\n", "self", ".", "_n_samples_validation", "=", "info", ".", "splits", "[", "'test'", "]", ".", "num_examples", "/", "2.", "\n", "self", ".", "_n_samples_test", "=", "info", ".", "splits", "[", "'test'", "]", ".", "num_examples", "/", "2.", "\n", "\n", "# # new S3 API, still not supported by imdb reviews", "\n", "# validation_dataset = tfds.load('imdb_reviews/plain_text', split=\"test[:50%]\", as_supervised=True)", "\n", "# test_dataset = tfds.load('imdb_reviews/plain_text', split=\"test[-50%:]\", as_supervised=True)", "\n", "\n", "# legacy API", "\n", "validation_split", ",", "test_split", "=", "tfds", ".", "Split", ".", "TEST", ".", "subsplit", "(", "k", "=", "2", ")", "\n", "validation_dataset", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "validation_split", ",", "as_supervised", "=", "True", ")", "\n", "test_dataset", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "test_split", ",", "as_supervised", "=", "True", ")", "\n", "\n", "self", ".", "_raw_datasets", "=", "{", "\n", "TRAIN", ":", "train_dataset", ",", "\n", "VALIDATION", ":", "validation_dataset", ",", "\n", "TEST", ":", "test_dataset", "\n", "}", "\n", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "\n", "self", ".", "_dataset_cache", "=", "self", ".", "_params", "[", "\"dataset_cache\"", "]", "\n", "\n", "if", "self", ".", "_aggregate", ":", "\n", "            ", "self", ".", "_x_sample_shape", "=", "(", "self", ".", "_emb_size", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_x_sample_shape", "=", "(", "None", ",", "self", ".", "_emb_size", ")", "\n", "\n", "# binary classification (I treat it as softmax for simplicity), the output must be 2", "\n", "", "self", ".", "_y_sample_shape", "=", "(", ")", "\n", "self", ".", "_y_one_hot_sample_shape", "=", "(", "2", ",", ")", "\n", "\n", "self", ".", "_padded_shape", "=", "(", "self", ".", "_x_sample_shape", ",", "self", ".", "_y_sample_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.dataset_id": [[107, 154], ["IMDBReviews.check_params_impl", "os.path.basename", "os.path.normpath", "ValueError", "Exception", "int", "int", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "IMDBReviews", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'IMDBReviews'", "\n", "emb_dir", "=", "params", "[", "\"emb_dir\"", "]", "\n", "alpha_tuple", "=", "params", "[", "\"alpha\"", "]", "\n", "theta", "=", "params", "[", "\"theta\"", "]", "\n", "point", "=", "params", "[", "\"point\"", "]", "\n", "emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "_id", "+=", "\"-\"", "+", "emb_id", "\n", "\n", "alpha_id", ",", "alpha_kwargs", "=", "alpha_tuple", "\n", "_id", "+=", "\"-a\"", "\n", "if", "alpha_id", "==", "'float'", ":", "\n", "            ", "_id", "+=", "\"float_v{:.2f}\"", ".", "format", "(", "alpha_kwargs", "[", "'value'", "]", ")", "\n", "", "elif", "alpha_id", "==", "'limit'", ":", "\n", "            ", "_id", "+=", "\"limit\"", "\n", "_id", "+=", "\"_t{:d}\"", ".", "format", "(", "alpha_kwargs", "[", "'ntop'", "]", ")", "\n", "_id", "+=", "\"_w{:d}\"", ".", "format", "(", "int", "(", "bool", "(", "alpha_kwargs", "[", "'weighted'", "]", ")", ")", ")", "\n", "_id", "+=", "\"_f{:d}\"", ".", "format", "(", "int", "(", "bool", "(", "alpha_kwargs", "[", "'fraction'", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Option `{:}`not recognized for alpha_id. Only `float` or `limit` are allowed.\"", ".", "format", "(", "alpha_id", ")", ")", "\n", "\n", "#try:", "\n", "#     _id += \"-a{:.2f}\".format(alpha)", "\n", "# except:", "\n", "#     _id += \"-a{:}\".format(alpha)", "\n", "\n", "", "_id", "+=", "\"-\"", "+", "theta", "\n", "_id", "+=", "\"-\"", "+", "point", "\n", "\n", "normalization", "=", "params", "[", "\"norm\"", "]", "\n", "if", "normalization", "is", "not", "None", ":", "\n", "            ", "if", "normalization", "not", "in", "[", "\"I\"", ",", "\"F\"", "]", ":", "\n", "                ", "raise", "Exception", "(", "\"Only Identity (I) or Fisher (F) normalization are allowed..\"", ")", "\n", "", "_id", "+=", "\"-norm\"", "+", "normalization", "\n", "\n", "", "aggregate", "=", "params", "[", "\"aggregate\"", "]", "\n", "\n", "if", "aggregate", ":", "\n", "            ", "_id", "+=", "\"-aggr\"", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.n_samples_train": [[155, 158], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_n_samples_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.x_shape_train": [[159, 163], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.x_shape_eval": [[164, 168], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.y_shape": [[169, 173], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_y_one_hot_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.n_labels": [[174, 178], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the number of labeles in this dataset\"\"\"", "\n", "return", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.labels": [[179, 183], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the list of labels in this dataset\"\"\"", "\n", "return", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews._preprocess": [[184, 192], ["numpy.array", "numpy.mean", "numpy.array", "word_embedding.preprocess.preprocess_lib.preproc_a"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_preprocess", "(", "self", ",", "excerpt", ",", "label", ")", ":", "\n", "        ", "indexes", "=", "np", ".", "array", "(", "[", "self", ".", "_dictionary", "[", "w", "]", "if", "w", "in", "self", ".", "_dictionary", "else", "-", "1", "for", "w", "in", "preproc_a", "(", "excerpt", ")", "]", ")", "\n", "\n", "xdata", "=", "self", ".", "_embeddings", "[", "indexes", "]", "\n", "if", "self", ".", "_aggregate", ":", "\n", "            ", "xdata", "=", "np", ".", "mean", "(", "xdata", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "xdata", ",", "np", ".", "array", "(", "label", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviews.IMDBReviews.get_dataset_iterator": [[193, 236], ["dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.padded_batch", "zip", "dataset.repeat.repeat.cache", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.padded_batch.make_one_shot_iterator", "dataset.repeat.padded_batch.make_initializable_iterator", "tuple", "node.set_shape", "tensorflow.py_func"], "methods", ["None"], ["", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ")", ":", "\n", "\n", "        ", "dataset", "=", "self", ".", "_raw_datasets", "[", "dataset_str", "]", "\n", "\n", "output_types", "=", "(", "tf", ".", "float32", ",", "tf", ".", "int32", "\n", "\n", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "x", ",", "y", ":", "tuple", "(", "tf", ".", "py_func", "(", "self", ".", "_preprocess", ",", "\n", "[", "x", ",", "y", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "output_shapes", "=", "(", "self", ".", "_x_sample_shape", ",", "self", ".", "_y_sample_shape", ")", "\n", "\n", "def", "_set_shapes", "(", "*", "nodes", ")", ":", "\n", "            ", "for", "node", ",", "outshape", "in", "zip", "(", "nodes", ",", "output_shapes", ")", ":", "\n", "                ", "node", ".", "set_shape", "(", "outshape", ")", "\n", "", "return", "nodes", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "_set_shapes", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "if", "self", ".", "_dataset_cache", ":", "\n", "            ", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "            ", "if", "self", ".", "_shuffling_cache", "is", "None", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_n_samples_train", "+", "1", "\n", "", "else", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffling_cache", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffling_cache", ")", "\n", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "\n", "", "batched_dataset", "=", "dataset", ".", "padded_batch", "(", "batch_size", ",", "padded_shapes", "=", "self", ".", "_padded_shape", ")", "\n", "\n", "if", "repeat", ":", "\n", "# create iterator to retrieve batches", "\n", "            ", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATS.BRATS.__init__": [[15, 19], ["datasets.BrainDataset.BrainDataset.__init__", "BRATS.BRATS.load_float_brains"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_float_brains"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "=", "self", ".", "load_float_brains", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATS.BRATS.dataset_id": [[20, 29], ["super().dataset_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "id", "=", "'BRATS'", "\n", "id", "+=", "super", "(", ")", ".", "dataset_id", "(", "params", ")", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATS.BRATS.x_shape_train": [[31, 34], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATS.BRATS.x_shape_eval": [[36, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.__init__": [[30, 50], ["datasets.ImageDataset.ImageDataset.__init__", "BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.dataset_id", "BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_float_brats", "BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all._params.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_float_brats"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "default_data_dir", "=", "'/ssd_data/BRATS_data/all_slices_separately_one'", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "# self._data_dir = default_data_dir", "\n", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "self", ".", "_machine", "=", "self", ".", "_params", "[", "'machine'", "]", "\n", "\n", "if", "'resize'", "in", "self", ".", "_params", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_resize", "=", "self", ".", "_params", "[", "'resize'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_resize", "=", "None", "\n", "\n", "\n", "", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "=", "self", ".", "load_float_brats", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.dataset_id": [[51, 68], ["BRATScnnLazyLoading_perSlice_all.check_params_impl", "params.keys", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "BRATScnnLazyLoading_perSlice_all", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'BRATScnnLazyLoading_perSlice'", "\n", "id", "+=", "'-'", "+", "params", "[", "'options'", "]", "\n", "if", "params", "[", "'machine'", "]", ":", "\n", "            ", "id", "+=", "'-'", "+", "params", "[", "'machine'", "]", "\n", "\n", "", "if", "'resize'", "in", "params", ".", "keys", "(", ")", ":", "\n", "            ", "id", "+=", "'-'", "+", "str", "(", "params", "[", "'resize'", "]", ")", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_float_brats": [[69, 92], ["BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_file_names", "print", "BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_file_names", "print", "BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_file_names", "print", "print", "print", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_float_brats", "(", "self", ",", "data_dir", ")", ":", "\n", "# data_dir = '/ssd_data/BRATS_data/all_slices_separately_one'", "\n", "\n", "        ", "datasets_tuple", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'train'", ")", "\n", "print", "(", "'---------DATASET TUPLE------------'", ",", "datasets_tuple", ".", "shape", ")", "\n", "\n", "train_set_x", "=", "datasets_tuple", "\n", "\n", "datasets_tuple_validation", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'validation'", ")", "\n", "print", "(", "'---------DATASET TUPLE VALIDATION------------'", ",", "datasets_tuple_validation", ".", "shape", ")", "\n", "\n", "validation_set_x", "=", "datasets_tuple_validation", "\n", "\n", "datasets_tuple_test", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'test'", ")", "\n", "print", "(", "'---------DATASET TUPLE TEST------------'", ",", "datasets_tuple_test", ".", "shape", ")", "\n", "\n", "test_set_x", "=", "datasets_tuple_test", "\n", "\n", "print", "(", "'--------------X SHAPE-----------------'", ")", "\n", "self", ".", "_train_set_x_shape", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", ")", ".", "shape", "+", "(", "1", ",", ")", "\n", "print", "(", "self", ".", "_train_set_x_shape", ")", "\n", "\n", "return", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_slices_from_files": [[93, 105], ["os.walk", "numpy.asarray", "os.path.abspath", "numpy.load", "slice.astype.astype.astype", "numpy.asarray.append", "os.path.join", "slice.astype.astype.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slices_from_files", "(", "self", ",", "root", ")", ":", "\n", "        ", "slices", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "fullname", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ")", "\n", "slice", "=", "np", ".", "load", "(", "fullname", ")", "\n", "slice", "=", "slice", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slice", "=", "slice", "/", "(", "slice", ".", "max", "(", ")", ")", "\n", "slices", ".", "append", "(", "slice", ")", "\n", "", "", "slices", "=", "np", ".", "asarray", "(", "slices", ")", "\n", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_file_names": [[114, 126], ["os.walk", "numpy.asarray", "fnmatch.filter", "numpy.asarray.append", "numpy.asarray.append", "str"], "methods", ["None"], ["", "def", "load_file_names", "(", "self", ",", "root", ",", "data_type", ")", ":", "\n", "        ", "file_names", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", "+", "'/'", "+", "data_type", ")", ":", "\n", "            ", "if", "self", ".", "_machine", "!=", "''", ":", "\n", "                ", "reg_filter", "=", "'*_'", "+", "str", "(", "machines", "[", "self", ".", "_machine", "]", ")", "+", "'_*'", "\n", "for", "f", "in", "fnmatch", ".", "filter", "(", "files", ",", "reg_filter", ")", ":", "\n", "                    ", "file_names", ".", "append", "(", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "f", "in", "files", ":", "\n", "                    ", "file_names", ".", "append", "(", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "", "file_names", "=", "np", ".", "asarray", "(", "file_names", ")", "\n", "return", "file_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_map_filename_slice": [[127, 135], ["os.walk", "numpy.asarray", "range", "numpy.asarray.append"], "methods", ["None"], ["", "def", "load_map_filename_slice", "(", "self", ",", "root", ")", ":", "\n", "        ", "map_fn_s", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "for", "slice", "in", "range", "(", "0", ",", "130", ")", ":", "\n", "                    ", "map_fn_s", ".", "append", "(", "(", "f", ",", "slice", ")", ")", "\n", "", "", "", "map_fn_s", "=", "np", ".", "asarray", "(", "map_fn_s", ")", "\n", "return", "map_fn_s", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_slices_from_file": [[136, 142], ["numpy.load", "numpy.asarray.astype", "numpy.asarray", "numpy.asarray.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slices_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slices", "=", "np", ".", "load", "(", "file", ")", "\n", "slices", "=", "slices", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slices", "=", "slices", "/", "(", "slices", ".", "max", "(", ")", ")", "\n", "slices", "=", "np", ".", "asarray", "(", "slices", ")", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_slice_from_file": [[143, 148], ["numpy.load", "numpy.asarray.astype", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slice_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slice", "=", "np", ".", "load", "(", "file", ")", "\n", "slice", "=", "slice", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slice", "=", "np", ".", "asarray", "(", "slice", ")", "\n", "return", "slice", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.dataset_map": [[150, 169], ["BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.get_output_types", "list", "dataset.map.map.map", "BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_slice_from_file", "numpy.array.reshape", "zip", "numpy.array", "tuple", "str", "PIL.Image.fromarray().resize", "tensorflow.py_func", "PIL.Image.fromarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "image", "=", "self", ".", "load_slice_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "reshaped_img", "=", "image", ".", "reshape", "(", "[", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "return", "reshaped_img", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.get_output_shapes": [[170, 177], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "1", ",", ")", "]", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "            ", "output_shapes", "=", "(", "(", "self", ".", "_resize", ",", "self", ".", "_resize", ",", "1", ")", ",", ")", "\n", "\n", "", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.get_output_types": [[178, 183], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.get_raw_elements": [[184, 201], ["numpy.asarray", "images.reshape.reshape.reshape", "getattr", "getattr", "BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.load_slices_from_file", "images.reshape.reshape.append", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slices_from_file"], ["", "def", "get_raw_elements", "(", "self", ",", "dataset_str", ",", "index_list", "=", "None", ")", ":", "\n", "        ", "attribute_name", "=", "dataset_str", "+", "\"_set_x\"", "\n", "# print('-----------ATTRIBUTE NAME-----------', attribute_name)", "\n", "# print(getattr(self, attribute_name)[index_list])", "\n", "# pdb.set_trace()", "\n", "images", "=", "[", "]", "\n", "if", "index_list", "is", "not", "None", ":", "\n", "            ", "for", "file", "in", "getattr", "(", "self", ",", "attribute_name", ")", "[", "index_list", "]", ":", "\n", "                ", "image", "=", "self", ".", "load_slices_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "file", ")", ")", "\n", "# print(image.shape)", "\n", "images", ".", "append", "(", "image", ")", "\n", "", "images", "=", "np", ".", "asarray", "(", "images", ")", "\n", "images", "=", "images", ".", "reshape", "(", "[", "images", ".", "shape", "[", "0", "]", ",", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", ",", "1", "]", ")", "\n", "x_data", "=", "images", "\n", "", "else", ":", "\n", "            ", "x_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "", "return", "x_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.x_shape_train": [[315, 318], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice_all.BRATScnnLazyLoading_perSlice_all.x_shape_eval": [[320, 323], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.__init__": [[51, 73], ["datasets.AudioDataset.AudioDataset.__init__", "Sinusoids.Sinusoids.dataset_id", "Sinusoids.Sinusoids.load_data", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "True", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_sample_lenght", "=", "SAMPLE_LENGTH", "*", "10", "# 128 padded 0s  # used to be 88384 for sample rate 44100", "\n", "self", ".", "_sample_rate", "=", "44100", "\n", "self", ".", "_shuffle_buffer", "=", "self", ".", "_params", "[", "'shuffle_buffer'", "]", "\n", "self", ".", "_type", "=", "self", ".", "_params", "[", "'type'", "]", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", "self", ".", "_type", ")", "\n", "\n", "self", ".", "_x_sample_shape_train", "=", "[", "self", ".", "_crop_length_train", ",", "1", "]", "\n", "self", ".", "_x_sample_shape_eval", "=", "[", "self", ".", "_sample_lenght", ",", "1", "]", "\n", "self", ".", "_y_sample_shape", "=", "None", "# (self._n_labels,)", "\n", "\n", "self", ".", "_n_labels", "=", "len", "(", "LABEL_TO_INT_DICT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.get_dataset_iterator": [[74, 160], ["tensorflow.data.Dataset.range", "Sinusoids.Sinusoids.get_output_shapes", "Sinusoids.Sinusoids.dataset_map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.cache", "zip", "dataset.repeat.repeat.map().map", "dataset.repeat.repeat.map().map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "hasattr", "node.set_shape", "len", "hasattr", "Exception", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "hasattr", "functools.partial", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_map"], ["", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ",", "perturb", ")", ":", "\n", "        ", "is_perturbed", "=", "False", "\n", "datasets_tuple", "=", "None", "\n", "\n", "# create Dataset objects", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "train_set_x", ",", ")", "\n", "if", "hasattr", "(", "self", ",", "\"perturbed_train_set_x\"", ")", "and", "self", ".", "perturbed_train_set_x", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "perturbed_train_set_x", ",", ")", "\n", "is_perturbed", "=", "True", "\n", "", "if", "self", ".", "_train_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "train_set_y", ",", ")", "\n", "\n", "", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "validation_set_x", ",", ")", "\n", "if", "hasattr", "(", "self", ",", "\"perturbed_validation_set_x\"", ")", "and", "self", ".", "perturbed_validation_set_x", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "perturbed_validation_set_x", ",", ")", "\n", "is_perturbed", "=", "True", "\n", "", "if", "self", ".", "_validation_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "validation_set_y", ",", ")", "\n", "\n", "", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "test_set_x", ",", ")", "\n", "if", "hasattr", "(", "self", ",", "\"perturbed_test_set_x\"", ")", "and", "self", ".", "perturbed_test_set_x", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "perturbed_test_set_x", ",", ")", "\n", "is_perturbed", "=", "True", "\n", "", "if", "self", ".", "_test_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "test_set_y", ",", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "", "NPROCS", "=", "20", "\n", "n_samples", "=", "datasets_tuple", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "range", "(", "n_samples", ")", "\n", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "\n", "dataset", "=", "self", ".", "dataset_map", "(", "dataset", ",", "datasets_tuple", ")", "\n", "\n", "def", "_set_shapes", "(", "*", "nodes", ")", ":", "\n", "            ", "for", "node", ",", "outshape", "in", "zip", "(", "nodes", ",", "output_shapes", ")", ":", "\n", "                ", "node", ".", "set_shape", "(", "outshape", ")", "\n", "", "return", "nodes", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "_set_shapes", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "# AUGMENT DATA (AUGMENT IF NEEDED)", "\n", "if", "augment", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ",", "self", ".", "_crop_length_train", ")", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", ".", "map", "(", "self", ".", "augment_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "if", "dataset_str", "==", "TEST", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ",", "self", ".", "_crop_length_train", ")", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", ".", "map", "(", "self", ".", "augment_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# handle perturbation", "\n", "", "if", "is_perturbed", "and", "len", "(", "self", ".", "_data_perturbation", ")", ">", "0", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "perturb_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "duplicate_x_element_if_needed", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# SHUFFLE, REPEAT and BATCH", "\n", "# we shuffle the data and sample repeatedly batches for training", "\n", "", "if", "shuffle", ":", "\n", "            ", "if", "self", ".", "_shuffling_cache", "is", "None", ":", "\n", "                ", "shuffling_cache", "=", "n_samples", "+", "1", "\n", "", "else", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffling_cache", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffling_cache", ")", "\n", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.dataset_id": [[161, 182], ["Sinusoids.check_params_impl", "params.keys", "ValueError", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "Sinusoids", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'SIN'", "\n", "\n", "if", "'type'", "not", "in", "params", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Type has to be defined for Sinusoids \"", ")", "\n", "", "if", "params", "[", "'type'", "]", "in", "TYPES", ":", "\n", "            ", "_id", "+=", "'-tp'", "+", "params", "[", "'type'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Type not recognized for Sinusoids, available types: {}\"", ".", "format", "(", "TYPES", ")", ")", "\n", "\n", "", "crop_length", "=", "params", "[", "'crop_length'", "]", "\n", "if", "crop_length", "!=", "Sinusoids", ".", "default_params", "[", "'crop_length'", "]", ":", "\n", "            ", "_id", "+=", "'-cl'", "+", "str", "(", "crop_length", ")", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.generate_dataset": [[183, 260], ["range", "len", "numpy.asarray", "numpy.asarray", "Sinusoids.generate_mix_with_conditioning", "numpy.asarray.reshape", "numpy.arange", "numpy.sin", "Sinusoids.Sinusoids.generate_dataset.get_sin"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.generate_mix_with_conditioning"], ["", "@", "staticmethod", "\n", "def", "generate_dataset", "(", "nr_of_samples", ",", "dataset_type", ")", ":", "\n", "        ", "if", "dataset_type", "==", "TYPE_MIX_CONDITIONED", ":", "\n", "            ", "return", "Sinusoids", ".", "generate_mix_with_conditioning", "(", "nr_of_samples", ")", "\n", "\n", "# The dataset is defined in the Tutorial on Helmholtz Machines by Kevin G Kirby", "\n", "", "dataset_x", "=", "[", "]", "\n", "dataset_y", "=", "[", "]", "\n", "\n", "def", "get_sin", "(", "ampl", "=", "1.0", ",", "freq", "=", "1.0", ",", "offset", "=", "0.0", ",", "length", "=", "100", ")", ":", "\n", "            ", "x", "=", "np", ".", "arange", "(", "0.0", ",", "length", ",", "0.1", ")", "/", "freq", "\n", "sin", "=", "np", ".", "sin", "(", "offset", "+", "x", ")", "*", "ampl", "\n", "return", "sin", "\n", "\n", "", "def", "get_sin_from_sample", "(", "sample", ")", ":", "\n", "            ", "a", "=", "sample", "%", "20", "/", "20", "+", "0.1", "\n", "a", "=", "1", "# Signal compression", "\n", "magnification", "=", "0.55", "# previously 5 , the less the wav will have higher frequency", "\n", "f", "=", "(", "int", "(", "sample", "/", "20", ")", "%", "20", "+", "1", ")", "*", "magnification", "+", "1", "\n", "# print(a, f, o)", "\n", "return", "get_sin", "(", "ampl", "=", "a", ",", "freq", "=", "f", ",", "offset", "=", "0", ",", "length", "=", "SAMPLE_LENGTH", ")", ",", "a", ",", "f", "\n", "\n", "", "for", "i", "in", "range", "(", "nr_of_samples", ")", ":", "\n", "            ", "if", "dataset_type", "==", "TYPE_CLEAN", ":", "\n", "                ", "s", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "sin", ",", "a", ",", "f", "=", "get_sin_from_sample", "(", "s", ")", "\n", "", "elif", "dataset_type", "==", "TYPE_SAW_TOOTH", ":", "\n", "                ", "num_tooths", "=", "np", ".", "random", ".", "randint", "(", "10", ",", "35", ")", "\n", "t", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "SAMPLE_LENGTH", "*", "10", ")", "\n", "sin", "=", "signal", ".", "sawtooth", "(", "2", "*", "np", ".", "pi", "*", "num_tooths", "*", "t", "-", "np", ".", "pi", ")", "\n", "a", ",", "f", "=", "0.0", ",", "0.0", "\n", "", "elif", "dataset_type", "==", "TYPE_FADE_OUT", ":", "\n", "                ", "s", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "sin", ",", "a", ",", "f", "=", "get_sin_from_sample", "(", "s", ")", "\n", "fader_f", "=", "np", ".", "linspace", "(", "0.", ",", "1.", ",", "len", "(", "sin", ")", ")", "\n", "sin", "=", "sin", "*", "fader_f", "\n", "", "elif", "dataset_type", "==", "TYPE_FADE_IN", ":", "\n", "                ", "s", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "sin", ",", "a", ",", "f", "=", "get_sin_from_sample", "(", "s", ")", "\n", "fader_b", "=", "np", ".", "linspace", "(", "1.", ",", "0.", ",", "len", "(", "sin", ")", ")", "\n", "sin", "=", "sin", "*", "fader_b", "\n", "", "elif", "dataset_type", "==", "TYPE_MIX", ":", "\n", "                ", "s1", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "s2", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "sin1", ",", "a1", ",", "f1", "=", "get_sin_from_sample", "(", "s1", ")", "\n", "sin2", ",", "a2", ",", "f2", "=", "get_sin_from_sample", "(", "s2", ")", "\n", "sin", "=", "sin1", "*", "sin2", "\n", "a", ",", "f", "=", "(", "0.0", ",", "0.0", ")", "\n", "", "elif", "dataset_type", "==", "TYPE_FADE", ":", "\n", "                ", "s1", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "s2", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "sin1", ",", "a1", ",", "f1", "=", "get_sin_from_sample", "(", "s1", ")", "\n", "sin2", ",", "a2", ",", "f2", "=", "get_sin_from_sample", "(", "s2", ")", "\n", "fader_f", "=", "np", ".", "linspace", "(", "0.", ",", "1.", ",", "len", "(", "sin1", ")", ")", "\n", "fader_b", "=", "np", ".", "linspace", "(", "1.", ",", "0.", ",", "len", "(", "sin1", ")", ")", "\n", "sin", "=", "sin1", "*", "fader_f", "+", "sin2", "*", "fader_b", "\n", "a", ",", "f", "=", "(", "0.0", ",", "0.0", ")", "\n", "", "elif", "dataset_type", "==", "TYPE_SWITCH", ":", "\n", "                ", "s1", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "s2", "=", "np", ".", "random", ".", "randint", "(", "400", ")", "\n", "sin1", ",", "a1", ",", "f1", "=", "get_sin_from_sample", "(", "s1", ")", "\n", "sin2", ",", "a2", ",", "f2", "=", "get_sin_from_sample", "(", "s2", ")", "\n", "halfway", "=", "int", "(", "len", "(", "sin1", ")", "/", "2", ")", "\n", "sin", "=", "[", "*", "sin1", "[", ":", "halfway", "]", ",", "*", "sin2", "[", "halfway", ":", "]", "]", "\n", "a", ",", "f", "=", "(", "0.0", ",", "0.0", ")", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Type not recognized for Sinusoids, available types: {}\"", ".", "format", "(", "TYPES", ")", ")", "\n", "", "dataset_x", "+=", "[", "sin", "]", "\n", "dataset_y", "+=", "[", "[", "a", ",", "f", "]", "]", "\n", "\n", "", "len_sample", "=", "len", "(", "dataset_x", "[", "0", "]", ")", "\n", "dataset_x", "=", "np", ".", "asarray", "(", "dataset_x", ")", "\n", "dataset_y", "=", "np", ".", "asarray", "(", "dataset_y", ")", "\n", "\n", "# make them the right length pictures", "\n", "return", "dataset_x", ".", "reshape", "(", "(", "nr_of_samples", ",", "len_sample", ",", "1", ")", ")", ",", "dataset_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.generate_mix_with_conditioning": [[261, 282], ["enumerate", "len", "numpy.zeros", "Sinusoids.generate_dataset", "dataset_x.append", "numpy.append", "numpy.concatenate", "numpy.append.astype", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.generate_dataset"], ["", "@", "staticmethod", "\n", "def", "generate_mix_with_conditioning", "(", "nr_samples", ")", ":", "\n", "# generate multiple types of sin waves: fade_in, fade_out, clean, saw_tooth", "\n", "        ", "types", "=", "[", "TYPE_CLEAN", ",", "TYPE_FADE_IN", ",", "TYPE_FADE_OUT", ",", "TYPE_SAW_TOOTH", "]", "\n", "samples_per_type", "=", "nr_samples", "//", "len", "(", "types", ")", "\n", "dataset_x", "=", "[", "]", "\n", "dataset_y", "=", "[", "]", "\n", "\n", "for", "type_id", ",", "type", "in", "enumerate", "(", "types", ")", ":", "\n", "            ", "one_hot", "=", "np", ".", "zeros", "(", "(", "samples_per_type", ",", "len", "(", "types", ")", ")", ",", "dtype", "=", "'uint8'", ")", "\n", "one_hot", "[", ":", ",", "type_id", "]", "=", "1", "\n", "waves", ",", "_", "=", "Sinusoids", ".", "generate_dataset", "(", "samples_per_type", ",", "type", ")", "\n", "dataset_x", ".", "append", "(", "waves", ")", "\n", "\n", "# if dataset_y is None:", "\n", "#     dataset_y = one_hot", "\n", "# else:", "\n", "# dataset_y = np.append(dataset_y, one_hot, axis=0)", "\n", "dataset_y", "=", "np", ".", "append", "(", "dataset_y", ",", "[", "type_id", "]", "*", "samples_per_type", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "dataset_x", ",", "axis", "=", "0", ")", ",", "dataset_y", ".", "astype", "(", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.load_data": [[283, 302], ["Sinusoids.generate_dataset", "numpy.random.permutation", "sinusoids[].astype", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.generate_dataset"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "dataset_type", "=", "TYPE_CLEAN", ")", ":", "\n", "# see https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html", "\n", "        ", "sinusoids", ",", "features", "=", "Sinusoids", ".", "generate_dataset", "(", "DATASET_SIZE", ",", "dataset_type", "=", "dataset_type", ")", "\n", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "DATASET_SIZE", ")", "\n", "\n", "data_x", "=", "sinusoids", "[", "perm", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# data_y = features[perm].astype(np.float32)", "\n", "data_y", "=", "features", "[", "perm", "]", "#.astype(np.float32)", "\n", "\n", "partition", "=", "int", "(", "DATASET_SIZE", "/", "6", ")", "\n", "# extra is ignored, since the images are too simple", "\n", "return", "data_x", "[", ":", "DATASET_SIZE", "-", "partition", "]", ",", "data_y", "[", ":", "DATASET_SIZE", "-", "partition", "]", ",", "data_x", "[", "DATASET_SIZE", "-", "partition", ":", "]", ",", "data_y", "[", "DATASET_SIZE", "-", "partition", ":", "]", ",", "data_x", "[", "DATASET_SIZE", "-", "partition", ":", "]", ",", "data_y", "[", "DATASET_SIZE", "-", "partition", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.n_samples_train": [[303, 306], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "DATASET_SIZE", "# 39737 used to be with 44140", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.x_shape_train": [[309, 313], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.x_shape_eval": [[314, 318], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.y_shape": [[319, 323], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.sample_rate": [[324, 328], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Sinusoids.Sinusoids.int_to_str_label": [[329, 334], ["LABEL_TO_INT_DICT.items"], "methods", ["None"], ["", "def", "int_to_str_label", "(", "self", ",", "int_label", ":", "int", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "LABEL_TO_INT_DICT", ".", "items", "(", ")", ":", "\n", "            ", "if", "int_label", "==", "value", ":", "\n", "                ", "return", "key", "\n", "", "", "return", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.__init__": [[23, 31], ["datasets.LabeledBrainDataset.LabeledBrainDataset.__init__", "BRATSLabeled.BRATSLabeled.load_float_brains"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_float_brains"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_no_of_classes", "=", "4", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_float_brains", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.dataset_id": [[32, 41], ["super().dataset_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "id", "=", "'BRATSLabeled'", "\n", "id", "+=", "super", "(", ")", ".", "dataset_id", "(", "params", ")", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.x_shape_train": [[43, 46], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.x_shape_eval": [[48, 51], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.get_label": [[53, 59], ["open", "json.load", "[].astype", "numpy.nonzero"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_label", "(", "self", ",", "filename", ")", ":", "\n", "# label = -1", "\n", "        ", "with", "open", "(", "self", ".", "_labels_file", ",", "'r'", ")", "as", "json_file", ":", "\n", "            ", "labels_dict", "=", "json", ".", "load", "(", "json_file", ")", "\n", "label", "=", "np", ".", "nonzero", "(", "labels_dict", "[", "filename", "]", ")", "[", "0", "]", ".", "astype", "(", "np", ".", "int32", ")", "[", "0", "]", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATSLabeled.BRATSLabeled.load_file_names": [[61, 98], ["numpy.asarray", "open", "os.walk", "json.load", "fnmatch.filter", "f.find", "f.find", "f.find", "str", "original_files.append", "label_files.append", "str", "re.findall", "original_files.append", "label_files.append", "int", "original_files.append", "label_files.append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "", "def", "load_file_names", "(", "self", ",", "root", ",", "data_type", ")", ":", "\n", "        ", "original_files", "=", "[", "]", "\n", "label_files", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "_split_file", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "files_to_find", "=", "json", ".", "load", "(", "file", ")", "[", "data_type", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "                ", "if", "self", ".", "_modalities", "is", "not", "None", ":", "\n", "                    ", "reg_filter", "=", "'*_'", "+", "str", "(", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ")", "+", "'_*'", "\n", "for", "f", "in", "fnmatch", ".", "filter", "(", "files", ",", "reg_filter", ")", ":", "\n", "# idx = f.find('_' + str(modalities[self._modalities[0]]))", "\n", "# idx = f.find('_')", "\n", "# label_file_name = f[:idx]", "\n", "                        ", "start_idx", "=", "f", ".", "find", "(", "'Brats'", ")", "\n", "end_idx", "=", "f", ".", "find", "(", "'_'", "+", "str", "(", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ")", ")", "\n", "label_file_name", "=", "f", "[", "start_idx", ":", "end_idx", "]", "\n", "if", "label_file_name", "in", "files_to_find", ":", "\n", "                            ", "fullname", "=", "root", "+", "'/'", "+", "f", "\n", "if", "self", ".", "_slices", "is", "not", "None", ":", "\n", "                                ", "slice", "=", "re", ".", "findall", "(", "'_([0-9][0-9]*)'", ",", "f", ")", "\n", "if", "self", ".", "_slices", "[", "0", "]", "<=", "int", "(", "slice", "[", "0", "]", ")", "<=", "self", ".", "_slices", "[", "1", "]", ":", "\n", "                                    ", "original_files", ".", "append", "(", "fullname", ")", "\n", "label_files", ".", "append", "(", "label_file_name", ")", "\n", "", "", "else", ":", "\n", "                                ", "original_files", ".", "append", "(", "fullname", ")", "\n", "label_files", ".", "append", "(", "label_file_name", ")", "\n", "", "", "", "", "else", ":", "\n", "                    ", "for", "f", "in", "files", ":", "\n", "                        ", "idx", "=", "f", ".", "find", "(", "'_'", ")", "\n", "label_file_name", "=", "f", "[", ":", "idx", "]", "\n", "if", "label_file_name", "in", "files_to_find", ":", "\n", "                            ", "fullname", "=", "root", "+", "'/'", "+", "f", "\n", "# idx = f.find('_' + str(modalities['T2']))", "\n", "original_files", ".", "append", "(", "fullname", ")", "\n", "label_files", ".", "append", "(", "label_file_name", ")", "\n", "# pdb.set_trace()", "\n", "", "", "", "", "", "dataset_tuple", "=", "[", "original_files", ",", "label_files", "]", "\n", "return", "np", ".", "asarray", "(", "dataset_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NewsgroupsArr.NewsgroupsArr.__init__": [[15, 28], ["AlphaDatasetArr.AlphaDatasetArr.__init__", "params.get", "word_embedding.test.core.load_20newsgroup.read_20newsgroup", "NewsgroupsArr.NewsgroupsArr._preprocess_arrays", "NewsgroupsArr.NewsgroupsArr._preprocess_arrays", "NewsgroupsArr.NewsgroupsArr._preprocess_arrays", "NewsgroupsArr.NewsgroupsArr._set_shapes", "NewsgroupsArr.process_params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_20newsgroup.read_20newsgroup", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess_arrays", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess_arrays", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess_arrays", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._set_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "NewsgroupsArr", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "random_state", "=", "params", ".", "get", "(", "'split_seed'", ",", "42", ")", "\n", "\n", "train_data", ",", "train_target", ",", "validation_data", ",", "validation_target", ",", "test_data", ",", "test_target", "=", "read_20newsgroup", "(", "\n", "ratio_datasets", "=", "[", "0.7", ",", "0.15", ",", "0.15", "]", ",", "random_state", "=", "random_state", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "_preprocess_arrays", "(", "train_data", ",", "train_target", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "_preprocess_arrays", "(", "validation_data", ",", "validation_target", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "_preprocess_arrays", "(", "test_data", ",", "test_target", ")", "\n", "\n", "self", ".", "_set_shapes", "(", "n_samples_train", "=", "self", ".", "_train_set_x", ".", "shape", "[", "0", "]", ",", "n_labels", "=", "20", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.NewsgroupsArr.NewsgroupsArr.dataset_id": [[30, 43], ["NewsgroupsArr.check_params_impl", "AlphaDatasetArr.AlphaDatasetArr.AlphaDatasetArr.dataset_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "NewsgroupsArr", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'20newsgroupsArr'", "\n", "\n", "_id", "+=", "AlphaDatasetArr", ".", "dataset_id", "(", "self", ",", "params", ")", "\n", "_id", "+=", "'-s{:d}'", ".", "format", "(", "params", "[", "'split_seed'", "]", ")", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset.__init__": [[20, 27], ["datasets.Dataset.Dataset.__init__", "AudioDataset.process_params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "AudioDataset", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_crop_length_train", "=", "self", ".", "_params", "[", "'crop_length'", "]", "\n", "# Width and height of each image.", "\n", "self", ".", "_shuffle_buffer", "=", "self", ".", "_params", "[", "'shuffle_buffer'", "]", "\n", "self", ".", "_channels", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset._crop_element": [[28, 74], ["len", "AudioDataset.AudioDataset._crop_x", "AudioDataset.AudioDataset._crop_x", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset._crop_x", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset._crop_x"], ["", "def", "_crop_element", "(", "self", ",", "is_perturbed", ",", "crop_len", ",", "*", "observation", ")", ":", "\n", "        ", "\"\"\"\n        crop element\n\n        Args:\n            is_perturbed (bool): if it is True, we expect observation = (x, x_perturbed, [y]). Where y is optional\n                                if it is False, we expect observation = (x, [y]). Where y is optional\n            *observation (list of tf.Tensor): a list of tensors.\n\n        Returns:\n            type: Description of returned object.\n\n        \"\"\"", "\n", "\n", "nargs", "=", "len", "(", "observation", ")", "\n", "y", "=", "None", "\n", "x_perturbed", "=", "None", "\n", "\n", "if", "is_perturbed", ":", "\n", "            ", "x", "=", "observation", "[", "0", "]", "\n", "x_perturbed", "=", "observation", "[", "1", "]", "\n", "if", "nargs", "==", "3", ":", "\n", "                ", "y", "=", "observation", "[", "2", "]", "\n", "", "elif", "nargs", ">", "3", ":", "\n", "                ", "raise", "Exception", "(", "\"observation of the dataset is a tuple with more than 3 elements.\\\n                                    But it is perturbed and it should be of length either 2 or 3\"", ")", "\n", "", "", "else", ":", "\n", "            ", "x", "=", "observation", "[", "0", "]", "\n", "if", "nargs", "==", "2", ":", "\n", "                ", "y", "=", "observation", "[", "1", "]", "\n", "", "elif", "nargs", ">", "2", ":", "\n", "                ", "raise", "Exception", "(", "\"observation of the dataset is a tuple with more than 2 elements.\\\n                                    But it is not perturbed and it should be of length either 1 or 2\"", ")", "\n", "\n", "", "", "x_crop", "=", "self", ".", "_crop_x", "(", "x", ",", "crop_len", ")", "\n", "\n", "cropped_observation", "=", "(", "x_crop", ",", ")", "\n", "\n", "if", "x_perturbed", "is", "not", "None", ":", "\n", "            ", "x_perturbed_crop", "=", "self", ".", "_crop_x", "(", "x_perturbed", ",", "crop_len", ")", "\n", "cropped_observation", "+=", "(", "x_perturbed_crop", ",", ")", "\n", "\n", "", "if", "y", "is", "not", "None", ":", "\n", "            ", "cropped_observation", "+=", "(", "y", ",", ")", "\n", "\n", "", "return", "cropped_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset._crop_x": [[75, 86], ["tensorflow.math.maximum", "tensorflow.cond", "tensorflow.random_crop", "tensorflow.cast", "tensorflow.pad", "tensorflow.shape"], "methods", ["None"], ["", "def", "_crop_x", "(", "self", ",", "x", ",", "crop_len", ")", ":", "\n", "        ", "wav", "=", "x", "\n", "# wav_sliced = tf.slice(wav, [0], [64000])", "\n", "\n", "# if signal is smaller than crop_len", "\n", "missing", "=", "tf", ".", "math", ".", "maximum", "(", "0", ",", "crop_len", "-", "tf", ".", "shape", "(", "wav", ")", "[", "0", "]", ")", "\n", "wav", "=", "tf", ".", "cond", "(", "missing", ">", "0", ",", "lambda", ":", "tf", ".", "pad", "(", "wav", ",", "[", "[", "0", ",", "missing", "]", ",", "[", "0", ",", "0", "]", "]", ",", "'CONSTANT'", ")", ",", "lambda", ":", "wav", ")", "# post padding", "\n", "\n", "crop", "=", "tf", ".", "random_crop", "(", "wav", ",", "[", "crop_len", ",", "self", ".", "_channels", "]", ")", "\n", "crop", "=", "tf", ".", "cast", "(", "crop", ",", "tf", ".", "float32", ")", "\n", "return", "crop", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset.str_label_to_int": [[87, 101], ["label_to_int_dict.items", "tensorflow.strings.to_number", "tensorflow.strings.regex_replace", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "str_label_to_int", "(", "label", ",", "label_to_int_dict", ")", ":", "\n", "        ", "'''\n        converts the given label according to the label_to_int_dict\n         Args:\n             label (Tensor): scalar tensor of shape ()\n             label_to_int_dict (dict): dict that specifies the mapping\n        '''", "\n", "\n", "for", "key", ",", "value", "in", "label_to_int_dict", ".", "items", "(", ")", ":", "\n", "            ", "key", "=", "'^{}$'", ".", "format", "(", "key", ")", "# to match whole string and not replace just a substring", "\n", "label", "=", "tf", ".", "strings", ".", "regex_replace", "(", "label", ",", "key", ",", "str", "(", "value", ")", ")", "\n", "\n", "", "return", "tf", ".", "strings", ".", "to_number", "(", "label", ",", "out_type", "=", "tf", ".", "dtypes", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset.int_to_str_label": [[102, 104], ["NotImplementedError"], "methods", ["None"], ["", "def", "int_to_str_label", "(", "self", ",", "int_label", ":", "int", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Please implement this method in the desired subclass before use!'", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.__init__": [[52, 64], ["Dataset.Dataset.__init__", "ThreeByThreeLines.ThreeByThreeLines.dataset_id", "ThreeByThreeLines.ThreeByThreeLines.load_data"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "True", "\n", "\n", "self", ".", "_pm_one", "=", "params", "[", "'pm_one'", "]", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.dataset_id": [[65, 78], ["ThreeByThreeLines.check_params_impl", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "ThreeByThreeLines", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'3by3'", "\n", "if", "not", "params", "[", "'pm_one'", "]", ":", "\n", "            ", "id", "+=", "'-pm%d'", "%", "int", "(", "params", "[", "'pm_one'", "]", ")", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.generate_dataset": [[79, 96], ["numpy.asarray", "len", "numpy.asarray.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "generate_dataset", "(", "nr_of_samples", ")", ":", "\n", "# The dataset is defined in the Tutorial on Helmholtz Machines by Kevin G Kirby", "\n", "        ", "dataset", "=", "[", "]", "\n", "\n", "nr_of_freequent", "=", "2", "*", "nr_of_samples", "\n", "nr_of_infreequent", "=", "nr_of_samples", "\n", "\n", "dataset", "+=", "freequent_patterns", "*", "nr_of_freequent", "\n", "dataset", "+=", "less_freequent_patterns", "*", "nr_of_infreequent", "\n", "\n", "dataset", "=", "np", ".", "asarray", "(", "dataset", ")", "\n", "\n", "len_of_dataset", "=", "len", "(", "dataset", ")", "\n", "\n", "# make them 3*3 pictures", "\n", "return", "dataset", ".", "reshape", "(", "(", "len_of_dataset", ",", "3", ",", "3", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.load_data": [[97, 113], ["ThreeByThreeLines.ThreeByThreeLines.generate_dataset", "len", "numpy.random.permutation", "threeByThree[].astype", "ThreeByThreeLines.ThreeByThreeLines._pm_cast", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.generate_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._pm_cast"], ["", "def", "load_data", "(", "self", ")", ":", "\n", "# see https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html", "\n", "        ", "threeByThree", "=", "self", ".", "generate_dataset", "(", "DATASET_SIZE", ")", "\n", "\n", "len_of_dataset", "=", "len", "(", "threeByThree", ")", "\n", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "len_of_dataset", ")", "\n", "\n", "data", "=", "threeByThree", "[", "perm", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "data", "=", "self", ".", "_pm_cast", "(", "data", ")", "\n", "\n", "partition", "=", "int", "(", "len_of_dataset", "/", "6", ")", "\n", "# extra is ignored, since the images are too simple", "\n", "return", "data", "[", ":", "len_of_dataset", "-", "partition", "]", ",", "None", ",", "data", "[", "len_of_dataset", "-", "partition", ":", "]", ",", "None", ",", "data", "[", "\n", "len_of_dataset", "-", "partition", ":", "]", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.color_images": [[120, 123], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.image_shape": [[124, 127], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "(", "3", ",", "3", ",", "1", ")", "# the last number is the channel", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.likelihood": [[129, 135], ["numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "@", "property", "\n", "def", "likelihood", "(", "self", ")", ":", "\n", "        ", "patterns_and_likelihoods", "=", "[", "(", "(", "np", ".", "asarray", "(", "i", ")", "+", "1", ")", "/", "2", ",", "freequent_patterns_freqquency", ")", "for", "i", "in", "freequent_patterns", "]", "\n", "patterns_and_likelihoods", "+=", "[", "(", "(", "np", ".", "asarray", "(", "i", ")", "+", "1", ")", "/", "2", ",", "less_freequent_patterns_freqquency", ")", "for", "i", "in", "less_freequent_patterns", "]", "\n", "\n", "return", "patterns_and_likelihoods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines.get_horizontal_pattern": [[136, 148], ["ThreeByThreeLines.ThreeByThreeLines.get_horizontal_pattern.get_numbers"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_horizontal_pattern", "(", "n", "=", "3", ")", ":", "\n", "        ", "def", "get_numbers", "(", "n", ")", ":", "\n", "            ", "return", "np", ".", "arange", "(", "1", ",", "2", "**", "n", "-", "1", ")", "\n", "\n", "", "x", "=", "get_numbers", "(", "n", ")", "\n", "x", "=", "[", "(", "'{0:0'", "+", "str", "(", "n", ")", "+", "'b}'", ")", ".", "format", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "x", "=", "[", "np", ".", "tile", "(", "i", ",", "n", ")", "for", "i", "in", "x", "]", "\n", "\n", "vertical_lines", "=", "np", ".", "asarray", "(", "[", "list", "(", "map", "(", "lambda", "j", ":", "[", "int", "(", "k", ")", "for", "k", "in", "j", "]", ",", "i", ")", ")", "for", "i", "in", "x", "]", ")", "\n", "horizontal_lines", "=", "np", ".", "transpose", "(", "vertical_lines", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "return", "vertical_lines", "*", "2", "-", "1", ",", "horizontal_lines", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ThreeByThreeLines.ThreeByThreeLines._pm_cast": [[149, 154], ["numpy.asarray"], "methods", ["None"], ["", "def", "_pm_cast", "(", "self", ",", "lis", ")", ":", "\n", "        ", "if", "self", ".", "_pm_one", ":", "\n", "            ", "return", "lis", "\n", "", "else", ":", "\n", "            ", "return", "(", "np", ".", "asarray", "(", "lis", ")", "+", "1", ")", "/", "2", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.__init__": [[26, 67], ["Dataset.Dataset.__init__", "os.path.basename", "word_embedding.test.core.load_embeddings.load_dict", "word_embedding.test.core.load_embeddings.load_emb_base", "numpy.linalg.inv", "word_embedding.test.core.load_embeddings.get_embpath", "word_embedding.test.core.load_embeddings.load_embeddings_ldv_hdf", "numpy.matmul().transpose", "numpy.expand_dims", "numpy.array", "AlphaDatasetArr.process_params", "os.path.normpath", "word_embedding.test.core.measures.center_and_normalize_riemannian", "numpy.zeros", "numpy.concatenate", "numpy.matmul", "numpy.eye", "numpy.transpose", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_dict", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_emb_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_embpath", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_embeddings_ldv_hdf", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "AlphaDatasetArr", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "emb_dir", "=", "self", ".", "_params", "[", "\"emb_dir\"", "]", "\n", "alpha_tuple", "=", "self", ".", "_params", "[", "\"alpha\"", "]", "\n", "theta", "=", "self", ".", "_params", "[", "\"theta\"", "]", "\n", "point", "=", "self", ".", "_params", "[", "\"point\"", "]", "\n", "normalization", "=", "self", ".", "_params", "[", "\"norm\"", "]", "\n", "self", ".", "_aggregate", "=", "self", ".", "_params", "[", "\"aggregate\"", "]", "\n", "\n", "self", ".", "_emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "# corpus, vstr, nstr = emb_id.split('-')", "\n", "\n", "vocab", ",", "ivocab", ",", "vocab_size", "=", "load_dict", "(", "emb_dir", ")", "\n", "self", ".", "_dictionary", "=", "vocab", "\n", "\n", "# ALPHA BASE", "\n", "alphas", ",", "I", "=", "load_emb_base", "(", "emb_dir", ",", "point", ")", "\n", "I_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I", ")", "\n", "\n", "embpath", "=", "get_embpath", "(", "alpha_tuple", ",", "theta", ",", "point", ",", "emb_dir", ")", "\n", "\n", "ldv", "=", "load_embeddings_ldv_hdf", "(", "embpath", ")", "\n", "\n", "plog", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "transpose", "(", "ldv", ")", ")", ".", "transpose", "(", ")", "\n", "self", ".", "_emb_size", "=", "plog", ".", "shape", "[", "1", "]", "\n", "\n", "if", "normalization", "is", "not", "None", ":", "\n", "            ", "if", "normalization", "==", "\"I\"", ":", "\n", "                ", "norm_matrix", "=", "np", ".", "eye", "(", "self", ".", "_emb_size", ")", "\n", "", "elif", "normalization", "==", "\"F\"", ":", "\n", "                ", "norm_matrix", "=", "I", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"Only Identity (I) or Fisher (F) normalization are allowed.. or no normalization (None)\"", ")", "\n", "\n", "", "plog", "=", "center_and_normalize_riemannian", "(", "plog", ",", "norm_matrix", ",", "center", "=", "False", ")", "\n", "\n", "", "unk_emb", "=", "np", ".", "expand_dims", "(", "np", ".", "zeros", "(", "plog", ".", "shape", "[", "1", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "_embeddings", "=", "np", ".", "array", "(", "np", ".", "concatenate", "(", "(", "plog", ",", "unk_emb", ")", ",", "axis", "=", "0", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._set_shapes": [[68, 83], ["None"], "methods", ["None"], ["", "def", "_set_shapes", "(", "self", ",", "n_samples_train", ",", "n_labels", ")", ":", "\n", "\n", "        ", "self", ".", "_n_labels", "=", "n_labels", "\n", "self", ".", "_n_samples_train", "=", "n_samples_train", "\n", "\n", "if", "self", ".", "_aggregate", ":", "\n", "            ", "self", ".", "_x_sample_shape", "=", "(", "self", ".", "_emb_size", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_x_sample_shape", "=", "(", "None", ",", "self", ".", "_emb_size", ")", "\n", "\n", "# binary classification (I treat it as softmax for simplicity), the output must be 2", "\n", "", "self", ".", "_y_sample_shape", "=", "(", ")", "\n", "self", ".", "_y_one_hot_sample_shape", "=", "(", "self", ".", "_n_labels", ",", ")", "\n", "\n", "self", ".", "_padded_shape", "=", "(", "self", ".", "_x_sample_shape", ",", "self", ".", "_y_sample_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.alpha_id_str": [[85, 100], ["ValueError", "int", "int", "bool", "bool"], "methods", ["None"], ["", "def", "alpha_id_str", "(", "self", ",", "alpha_tuple", ")", ":", "\n", "        ", "alpha_id", ",", "alpha_kwargs", "=", "alpha_tuple", "\n", "_id", "=", "'-a'", "\n", "\n", "if", "alpha_id", "==", "'float'", ":", "\n", "            ", "_id", "+=", "\"float_v{:.2f}\"", ".", "format", "(", "alpha_kwargs", "[", "'value'", "]", ")", "\n", "", "elif", "alpha_id", "==", "'limit'", ":", "\n", "            ", "_id", "+=", "\"limit\"", "\n", "_id", "+=", "\"_t{:d}\"", ".", "format", "(", "alpha_kwargs", "[", "'ntop'", "]", ")", "\n", "_id", "+=", "\"_w{:d}\"", ".", "format", "(", "int", "(", "bool", "(", "alpha_kwargs", "[", "'weighted'", "]", ")", ")", ")", "\n", "_id", "+=", "\"_f{:d}\"", ".", "format", "(", "int", "(", "bool", "(", "alpha_kwargs", "[", "'fraction'", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Option `{:}`not recognized for alpha_id. Only `float` or `limit` are allowed.\"", ".", "format", "(", "alpha_id", ")", ")", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.dataset_id": [[101, 132], ["AlphaDatasetArr.check_params_impl", "os.path.basename", "AlphaDatasetArr.AlphaDatasetArr.alpha_id_str", "os.path.normpath", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.alpha_id_str"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "AlphaDatasetArr", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "emb_dir", "=", "params", "[", "\"emb_dir\"", "]", "\n", "alpha_tuple", "=", "params", "[", "\"alpha\"", "]", "\n", "theta", "=", "params", "[", "\"theta\"", "]", "\n", "point", "=", "params", "[", "\"point\"", "]", "\n", "emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "_id", "=", "\"-\"", "+", "emb_id", "\n", "\n", "_id", "+=", "self", ".", "alpha_id_str", "(", "alpha_tuple", ")", "\n", "\n", "_id", "+=", "\"-\"", "+", "theta", "\n", "_id", "+=", "\"-\"", "+", "point", "\n", "\n", "normalization", "=", "params", "[", "\"norm\"", "]", "\n", "if", "normalization", "is", "not", "None", ":", "\n", "            ", "if", "normalization", "not", "in", "[", "\"I\"", ",", "\"F\"", "]", ":", "\n", "                ", "raise", "Exception", "(", "\"Only Identity (I) or Fisher (F) normalization are allowed..\"", ")", "\n", "", "_id", "+=", "\"-norm\"", "+", "normalization", "\n", "\n", "", "aggregate", "=", "params", "[", "\"aggregate\"", "]", "\n", "\n", "if", "aggregate", ":", "\n", "            ", "_id", "+=", "\"-aggr\"", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.x_shape_train": [[133, 137], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.x_shape_eval": [[138, 142], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.y_shape": [[143, 147], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_y_one_hot_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.n_labels": [[148, 152], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the number of labels in this dataset\"\"\"", "\n", "return", "self", ".", "_n_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr.labels": [[153, 157], ["numpy.arange"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the list of labels in this dataset\"\"\"", "\n", "return", "np", ".", "arange", "(", "self", ".", "_n_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess": [[158, 172], ["numpy.array", "len", "numpy.mean", "numpy.array", "Exception", "word_embedding.preprocess.preprocess_lib.preproc_a"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_preprocess", "(", "self", ",", "excerpt", ",", "label", ")", ":", "\n", "        ", "indexes", "=", "np", ".", "array", "(", "[", "self", ".", "_dictionary", "[", "w", "]", "if", "w", "in", "self", ".", "_dictionary", "else", "-", "1", "for", "w", "in", "preproc_a", "(", "excerpt", ")", "]", ")", "\n", "if", "len", "(", "indexes", ")", "==", "0", ":", "\n", "            ", "return", "None", ",", "None", "\n", "\n", "", "try", ":", "\n", "            ", "xdata", "=", "self", ".", "_embeddings", "[", "indexes", "]", "\n", "", "except", ":", "\n", "            ", "raise", "Exception", "(", "\"could not parse excerpt: `{:}`, \\n\\n indexes found were: `{:}`\"", ".", "format", "(", "excerpt", ",", "indexes", ")", ")", "\n", "\n", "", "if", "self", ".", "_aggregate", ":", "\n", "            ", "xdata", "=", "np", ".", "mean", "(", "xdata", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "xdata", ",", "np", ".", "array", "(", "label", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess_arrays": [[173, 184], ["list", "zip", "numpy.array", "numpy.array", "map"], "methods", ["None"], ["", "def", "_preprocess_arrays", "(", "self", ",", "data", ",", "target", ")", ":", "\n", "# pool = multiprocessing.Pool(processes=NPROCS)", "\n", "\n", "        ", "preprocessed_tuples", "=", "list", "(", "map", "(", "self", ".", "_preprocess", ",", "data", ",", "target", ")", ")", "\n", "\n", "preprocessed_tuples", "=", "[", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "preprocessed_tuples", "if", "x", "is", "not", "None", "]", "\n", "\n", "prep_data", ",", "prep_target", "=", "zip", "(", "*", "preprocessed_tuples", ")", "\n", "prep_data", "=", "np", ".", "array", "(", "prep_data", ")", "\n", "prep_target", "=", "np", ".", "array", "(", "prep_target", ")", "\n", "return", "prep_data", ",", "prep_target", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.miniMNIST.miniMNIST.__init__": [[37, 108], ["MNIST.MNIST.__init__", "miniMNIST.miniMNIST.dataset_id", "miniMNIST.miniMNIST.load_float_mnist", "Exception", "miniMNIST.miniMNIST.class_filter", "miniMNIST.miniMNIST.class_filter", "miniMNIST.miniMNIST.class_filter", "miniMNIST.miniMNIST.sub_sample", "miniMNIST.miniMNIST.sub_sample", "miniMNIST.miniMNIST.sub_sample", "numpy.clip", "numpy.clip", "numpy.clip", "miniMNIST.miniMNIST._train_set_x.reshape", "miniMNIST.miniMNIST._validation_set_x.reshape", "miniMNIST.miniMNIST._test_set_x.reshape", "miniMNIST.miniMNIST._train_set_x.reshape", "miniMNIST.miniMNIST._validation_set_x.reshape", "miniMNIST.miniMNIST._test_set_x.reshape", "miniMNIST.miniMNIST.load_binary_stochastic_mnist", "miniMNIST.miniMNIST.load_binary_det_mnist"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.miniMNIST.miniMNIST.load_float_mnist", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.load_binary_stochastic_mnist", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.MNIST.MNIST.load_binary_det_mnist"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "self", ".", "_params", "[", "'binary'", "]", "\n", "\n", "self", ".", "_pm_one", "=", "self", ".", "_params", "[", "'pm_one'", "]", "\n", "\n", "# continuous mnist", "\n", "if", "self", ".", "_binary_input", "==", "0", ":", "\n", "            ", "default_data_dir", "=", "'datasets/MNIST_data'", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_float_mnist", "(", "self", ".", "data_dir", ")", "\n", "# binary mnist", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"not implemented\"", ")", "\n", "\n", "default_data_dir", "=", "\"datasets/miniMNIST_raw\"", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "if", "self", ".", "_params", "[", "'stochastic'", "]", "==", "1", ":", "\n", "                ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_binary_stochastic_mnist", "(", "self", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_binary_det_mnist", "(", "self", ".", "data_dir", ")", "\n", "\n", "# filter classes", "\n", "", "", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n", "", "if", "self", ".", "_params", "[", "'vect'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "196", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "196", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "196", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "14", ",", "14", ",", "1", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "14", ",", "14", ",", "1", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "14", ",", "14", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.miniMNIST.miniMNIST.dataset_id": [[113, 170], ["miniMNIST.check_params_impl", "str", "list", "range", "str", "int", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "\n", "miniMNIST", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'miniMNIST'", "\n", "\n", "# binary or continuous", "\n", "id_binary", "=", "{", "0", ":", "'-c'", ",", "1", ":", "'-d'", "}", "\n", "id", "+=", "id_binary", "[", "params", "[", "'binary'", "]", "]", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subclasses", "\n", "#", "\n", "if", "(", "'classes'", "in", "params", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "10", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in MNIST\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "", "if", "not", "params", "[", "'pm_one'", "]", ":", "\n", "            ", "id", "+=", "'-pm%d'", "%", "int", "(", "params", "[", "'pm_one'", "]", ")", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.miniMNIST.miniMNIST.load_float_mnist": [[171, 208], ["read_data_sets", "numpy.load().astype", "numpy.load().astype", "numpy.load().astype", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "read_data_sets.train.labels.astype", "read_data_sets.validation.labels.astype", "read_data_sets.test.labels.astype", "numpy.load", "numpy.load", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "@", "staticmethod", "\n", "def", "load_float_mnist", "(", "data_dir", "=", "'datasets/MNIST_data'", ",", "train_test_ratio", "=", "None", ")", ":", "\n", "        ", "\"\"\" return MNIST data in a format suited for tensorflow.\n\n            The script input_data is available under this URL:\n            https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/examples/tutorials/mnist/input_data.py\n        \"\"\"", "\n", "assert", "(", "not", "train_test_ratio", ")", ",", "\"not implemented yet\"", "\n", "\n", "\n", "from", "tensorflow", ".", "contrib", ".", "learn", ".", "python", ".", "learn", ".", "datasets", ".", "mnist", "import", "read_data_sets", "\n", "mnist", "=", "read_data_sets", "(", "data_dir", ",", "one_hot", "=", "False", ")", "\n", "\n", "'''\n        # old\n        train_set_x = mnist.train.images.astype(np.float32)\n        validation_set_x = mnist.validation.images.astype(np.float32)\n        test_set_x = mnist.test.images.astype(np.float32)\n        '''", "\n", "\n", "# new", "\n", "mini_data_dir", "=", "'/ssd_data/datasets/miniMNIST'", "\n", "train_set_x", "=", "np", ".", "load", "(", "mini_data_dir", "+", "'/train_set_x.npy'", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "validation_set_x", "=", "np", ".", "load", "(", "mini_data_dir", "+", "'/validation_set_x.npy'", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "test_set_x", "=", "np", ".", "load", "(", "mini_data_dir", "+", "'/test_set_x.npy'", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "# normalize data consistently (in case they would not already be)", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "]", ")", "\n", "train_set_x", "=", "normalize", "(", "train_set_x", ",", "all_min", ",", "all_max", ")", "\n", "validation_set_x", "=", "normalize", "(", "validation_set_x", ",", "all_min", ",", "all_max", ")", "\n", "test_set_x", "=", "normalize", "(", "test_set_x", ",", "all_min", ",", "all_max", ")", "\n", "\n", "train_set_y", "=", "mnist", ".", "train", ".", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "validation_set_y", "=", "mnist", ".", "validation", ".", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "test_set_y", "=", "mnist", ".", "test", ".", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "return", "train_set_x", ",", "train_set_y", ",", "validation_set_x", ",", "validation_set_y", ",", "test_set_x", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.GTSRB.__init__": [[45, 57], ["ImageDataset.ImageDataset.__init__", "GTSRB.GTSRB.dataset_id", "GTSRB.GTSRB.load_data"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "default_data_dir", "=", "'/ssd_data/datasets/GTSRB'", "\n", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", "self", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.GTSRB.dataset_id": [[59, 70], ["GTSRB.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "GTSRB", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'GTSRB'", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.GTSRB.load_data": [[99, 131], ["GTSRB.load_train", "numpy.random.RandomState().permutation", "numpy.random.RandomState().permutation", "numpy.random.RandomState().permutation", "numpy.random.RandomState().permutation", "GTSRB.load_test", "numpy.random.RandomState().permutation", "numpy.random.RandomState().permutation", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "os.stat", "os.stat", "os.stat", "os.stat", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "numpy.random.RandomState", "numpy.random.RandomState", "numpy.random.RandomState", "numpy.random.RandomState", "numpy.random.RandomState", "numpy.random.RandomState"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.load_train", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.load_test", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "gtsrb_dir", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "stat", "(", "gtsrb_dir", ")", "\n", "", "except", ":", "\n", "            ", "os", ".", "mkdir", "(", "gtsrb_dir", ")", "\n", "\n", "", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", "=", "load_train", "(", "gtsrb_dir", ")", "\n", "\n", "random_indices_train", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "8", ")", ".", "permutation", "(", "X_train", ".", "shape", "[", "0", "]", ")", "\n", "X_train", "=", "X_train", "[", "random_indices_train", "]", ";", "Y_train", "=", "Y_train", "[", "random_indices_train", "]", "\n", "\n", "random_indices_val", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "9", ")", ".", "permutation", "(", "X_val", ".", "shape", "[", "0", "]", ")", "\n", "X_val", "=", "X_val", "[", "random_indices_val", "]", ";", "Y_val", "=", "Y_val", "[", "random_indices_val", "]", "\n", "\n", "X_test", ",", "Y_test", "=", "load_test", "(", "gtsrb_dir", ")", "\n", "random_indices_test", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "10", ")", ".", "permutation", "(", "X_test", ".", "shape", "[", "0", "]", ")", "\n", "X_test", "=", "X_test", "[", "random_indices_test", "]", ";", "Y_test", "=", "Y_test", "[", "random_indices_test", "]", "\n", "\n", "# normalize data consistently (in case they would not already be)", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "X_train", ",", "X_val", ",", "X_test", "]", ")", "\n", "X_train", "=", "normalize", "(", "X_train", ",", "all_min", ",", "all_max", ")", "\n", "X_val", "=", "normalize", "(", "X_val", ",", "all_min", ",", "all_max", ")", "\n", "X_test", "=", "normalize", "(", "X_test", ",", "all_min", ",", "all_max", ")", "\n", "\n", "\n", "#         make_hist_of_classes(Y_train, \"Train\")", "\n", "#         make_hist_of_classes(Y_val, \"Validation\")", "\n", "#         make_hist_of_classes(Y_test, \"Test\")", "\n", "\n", "return", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", ",", "X_test", ",", "Y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.get_class": [[135, 137], ["int", "img_path.split"], "function", ["None"], ["", "", "def", "get_class", "(", "img_path", ")", ":", "\n", "    ", "return", "int", "(", "img_path", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.track_no": [[138, 140], ["None"], "function", ["None"], ["", "def", "track_no", "(", "path", ")", ":", "# returns the track number (as a string of 5 chars) of a given .ppm path ", "\n", "    ", "return", "path", "[", "-", "15", ":", "-", "10", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.five_char": [[141, 150], ["ValueError", "int", "str", "numpy.log10"], "function", ["None"], ["", "def", "five_char", "(", "n", ")", ":", "# returns a string of 5 char corresponding to n; e.g. 5->'00005', 23->'00023' ", "\n", "    ", "if", "(", "n", "<", "0", "or", "n", ">=", "10", "**", "5", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"The number should be between 0 and 99999\"", ")", "\n", "", "elif", "(", "n", "==", "0", ")", ":", "\n", "        ", "return", "\"00000\"", "\n", "", "else", ":", "\n", "        ", "no_digits", "=", "int", "(", "np", ".", "log10", "(", "n", ")", ")", "+", "1", "\n", "no_zeros", "=", "5", "-", "no_digits", "\n", "return", "'0'", "*", "no_zeros", "+", "str", "(", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.preprocess_img": [[152, 169], ["skimage.color.rgb2hsv", "skimage.exposure.equalize_hist", "skimage.color.hsv2rgb", "min", "skimage.transform.resize"], "function", ["None"], ["", "", "def", "preprocess_img", "(", "img", ")", ":", "\n", "# Histogram normalization in y", "\n", "    ", "hsv", "=", "color", ".", "rgb2hsv", "(", "img", ")", "\n", "hsv", "[", ":", ",", ":", ",", "2", "]", "=", "exposure", ".", "equalize_hist", "(", "hsv", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "img", "=", "color", ".", "hsv2rgb", "(", "hsv", ")", "\n", "\n", "# central scrop", "\n", "min_side", "=", "min", "(", "img", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "centre", "=", "img", ".", "shape", "[", "0", "]", "//", "2", ",", "img", ".", "shape", "[", "1", "]", "//", "2", "\n", "img", "=", "img", "[", "centre", "[", "0", "]", "-", "min_side", "//", "2", ":", "centre", "[", "0", "]", "+", "min_side", "//", "2", ",", "\n", "centre", "[", "1", "]", "-", "min_side", "//", "2", ":", "centre", "[", "1", "]", "+", "min_side", "//", "2", ",", "\n", ":", "]", "\n", "\n", "# rescale to standard size", "\n", "img", "=", "transform", ".", "resize", "(", "img", ",", "(", "IMG_SIZE", ",", "IMG_SIZE", ")", ")", "\n", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.load_train": [[207, 273], ["os.path.join", "os.path.join", "print", "h5py.File", "print", "os.path.join", "os.path.join", "numpy.random.seed", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "sorted", "int", "numpy.random.randint", "print", "numpy.random.shuffle", "h5py.File", "hf.create_dataset", "hf.create_dataset", "hf.create_dataset", "hf.create_dataset", "glob.glob", "GTSRB.track_no", "GTSRB.five_char", "os.path.join", "os.path.join", "str", "GTSRB.preprocess_img", "train_imgs.append", "train_labels.append", "GTSRB.preprocess_img", "val_imgs.append", "val_labels.append", "GTSRB.track_no", "GTSRB.five_char", "GTSRB.track_no", "GTSRB.five_char", "skimage.io.imread", "print", "skimage.io.imread", "print", "str", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.track_no", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.five_char", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.preprocess_img", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.preprocess_img", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.track_no", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.five_char", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.track_no", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.five_char"], ["", "def", "load_train", "(", "gtsrb_dir", "=", "'/ssd_data/datasets/GTSRB'", ")", ":", "\n", "    ", "h5filename", "=", "os", ".", "path", ".", "join", "(", "gtsrb_dir", ",", "'GTSRB_Train_and_Validation_correct-split'", "+", "str", "(", "IMG_SIZE", ")", "+", "'.h5'", ")", "\n", "\n", "try", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "h5filename", ",", "'r'", ")", "as", "hf", ":", "\n", "            ", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", "=", "hf", "[", "'train_imgs'", "]", "[", ":", "]", ",", "hf", "[", "'train_labels'", "]", "[", ":", "]", ",", "hf", "[", "'val_imgs'", "]", "[", ":", "]", ",", "hf", "[", "'val_labels'", "]", "[", ":", "]", "\n", "", "print", "(", "\"Loaded images from {:}\"", ".", "format", "(", "h5filename", ")", ")", "\n", "\n", "", "except", "(", "IOError", ",", "OSError", ",", "KeyError", ")", ":", "\n", "        ", "print", "(", "\"Error in reading {:}. Processing all images...\"", ".", "format", "(", "h5filename", ")", ")", "\n", "img_root_dir", "=", "os", ".", "path", ".", "join", "(", "gtsrb_dir", ",", "'Final_Training/Images/'", ")", "\n", "train_imgs", "=", "[", "]", "\n", "train_labels", "=", "[", "]", "\n", "val_imgs", "=", "[", "]", "\n", "val_labels", "=", "[", "]", "\n", "\n", "#         for i in range(43):        ", "\n", "#             print(len(glob.glob(os.path.join(img_root_dir, five_char(i) + '/*.ppm')))%30)", "\n", "#         print(\"--------------------\")", "\n", "#         for j in range(23):", "\n", "#             print(len(glob.glob(os.path.join(img_root_dir, '00033/' + five_char(j) + '*.ppm')))) track 19 has 29 imgs", "\n", "\n", "np", ".", "random", ".", "seed", "(", "42", ")", "\n", "for", "cl", "in", "range", "(", "NUM_CLASSES", ")", ":", "\n", "            ", "current_dir", "=", "img_root_dir", "+", "five_char", "(", "cl", ")", "+", "\"/\"", "\n", "class_img_paths", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "current_dir", ",", "'*.ppm'", ")", ")", ")", "\n", "\n", "max_tr", "=", "int", "(", "track_no", "(", "class_img_paths", "[", "-", "1", "]", ")", ")", "#get the track number of the last image", "\n", "val_tr", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "max_tr", ")", "\n", "print", "(", "\"Class \"", "+", "str", "(", "cl", ")", "+", "', Val track '", "+", "str", "(", "val_tr", ")", "+", "', Max track '", "+", "str", "(", "max_tr", ")", ")", "\n", "\n", "np", ".", "random", ".", "shuffle", "(", "class_img_paths", ")", "\n", "\n", "class_val_paths", "=", "[", "p", "for", "p", "in", "class_img_paths", "if", "track_no", "(", "p", ")", "==", "five_char", "(", "val_tr", ")", "]", "\n", "class_train_paths", "=", "[", "p", "for", "p", "in", "class_img_paths", "if", "track_no", "(", "p", ")", "!=", "five_char", "(", "val_tr", ")", "]", "\n", "\n", "for", "img_path", "in", "class_train_paths", ":", "\n", "                ", "try", ":", "\n", "                    ", "img", "=", "preprocess_img", "(", "io", ".", "imread", "(", "img_path", ")", ")", "\n", "train_imgs", ".", "append", "(", "img", ")", "\n", "train_labels", ".", "append", "(", "cl", ")", "\n", "", "except", "(", "IOError", ",", "OSError", ")", ":", "\n", "                    ", "print", "(", "'missed'", ",", "img_path", ")", "\n", "pass", "\n", "\n", "", "", "for", "img_path", "in", "class_val_paths", ":", "\n", "                ", "try", ":", "\n", "                    ", "img", "=", "preprocess_img", "(", "io", ".", "imread", "(", "img_path", ")", ")", "\n", "val_imgs", ".", "append", "(", "img", ")", "\n", "val_labels", ".", "append", "(", "cl", ")", "\n", "", "except", "(", "IOError", ",", "OSError", ")", ":", "\n", "                    ", "print", "(", "'missed'", ",", "img_path", ")", "\n", "pass", "\n", "\n", "", "", "", "X_train", "=", "np", ".", "array", "(", "train_imgs", ",", "dtype", "=", "'float32'", ")", "\n", "Y_train", "=", "np", ".", "array", "(", "train_labels", ",", "dtype", "=", "'int32'", ")", "\n", "X_val", "=", "np", ".", "array", "(", "val_imgs", ",", "dtype", "=", "'float32'", ")", "\n", "Y_val", "=", "np", ".", "array", "(", "val_labels", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "with", "h5py", ".", "File", "(", "h5filename", ",", "'w'", ")", "as", "hf", ":", "\n", "            ", "hf", ".", "create_dataset", "(", "'train_imgs'", ",", "data", "=", "X_train", ")", "\n", "hf", ".", "create_dataset", "(", "'train_labels'", ",", "data", "=", "Y_train", ")", "\n", "hf", ".", "create_dataset", "(", "'val_imgs'", ",", "data", "=", "X_val", ")", "\n", "hf", ".", "create_dataset", "(", "'val_labels'", ",", "data", "=", "Y_val", ")", "\n", "\n", "", "", "return", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.load_test": [[276, 308], ["os.path.join", "os.path.join", "print", "h5py.File", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv", "zip", "numpy.array", "numpy.array", "str", "list", "list", "os.path.join", "os.path.join", "np.array.append", "np.array.append", "h5py.File", "hf.create_dataset", "hf.create_dataset", "GTSRB.preprocess_img", "skimage.io.imread"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.syn_multivar_gaussian.MultivariateGaussianData.create_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.preprocess_img"], ["", "def", "load_test", "(", "gtsrb_dir", "=", "'/ssd_data/datasets/GTSRB'", ")", ":", "\n", "    ", "h5filename", "=", "os", ".", "path", ".", "join", "(", "gtsrb_dir", ",", "'GTSRB_Test'", "+", "str", "(", "IMG_SIZE", ")", "+", "'.h5'", ")", "\n", "\n", "try", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "h5filename", ",", "'r'", ")", "as", "hf", ":", "\n", "            ", "X", ",", "Y", "=", "hf", "[", "'imgs'", "]", "[", ":", "]", ",", "hf", "[", "'labels'", "]", "[", ":", "]", "\n", "", "print", "(", "\"Loaded images from {:}\"", ".", "format", "(", "h5filename", ")", ")", "\n", "\n", "", "except", "(", "IOError", ",", "OSError", ",", "KeyError", ")", ":", "\n", "        ", "print", "(", "\"Error in reading {:}. Processing all images...\"", ".", "format", "(", "h5filename", ")", ")", "\n", "\n", "img_root_dir", "=", "os", ".", "path", ".", "join", "(", "gtsrb_dir", ",", "'Final_Test/Images/'", ")", "\n", "csvfilename", "=", "os", ".", "path", ".", "join", "(", "img_root_dir", ",", "'GT-final_test.csv'", ")", "\n", "\n", "test", "=", "pd", ".", "read_csv", "(", "csvfilename", ",", "sep", "=", "';'", ")", "\n", "\n", "# Load test dataset", "\n", "X", "=", "[", "]", "\n", "Y", "=", "[", "]", "\n", "for", "file_name", ",", "class_id", "in", "zip", "(", "list", "(", "test", "[", "'Filename'", "]", ")", ",", "list", "(", "test", "[", "'ClassId'", "]", ")", ")", ":", "\n", "            ", "img_path", "=", "os", ".", "path", ".", "join", "(", "img_root_dir", ",", "file_name", ")", "\n", "X", ".", "append", "(", "preprocess_img", "(", "io", ".", "imread", "(", "img_path", ")", ")", ")", "\n", "Y", ".", "append", "(", "class_id", ")", "\n", "\n", "", "X", "=", "np", ".", "array", "(", "X", ",", "dtype", "=", "'float32'", ")", "\n", "Y", "=", "np", ".", "array", "(", "Y", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "with", "h5py", ".", "File", "(", "h5filename", ",", "'w'", ")", "as", "hf", ":", "\n", "            ", "hf", ".", "create_dataset", "(", "'imgs'", ",", "data", "=", "X", ")", "\n", "hf", ".", "create_dataset", "(", "'labels'", ",", "data", "=", "Y", ")", "\n", "\n", "", "", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB.make_hist_of_classes": [[312, 319], ["matplotlib.hist", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.close", "numpy.arange", "str", "str", "numpy.random.randint", "len"], "function", ["None"], ["", "def", "make_hist_of_classes", "(", "y", ",", "text", ")", ":", "\n", "    ", "plt", ".", "hist", "(", "y", ",", "bins", "=", "np", ".", "arange", "(", "NUM_CLASSES", ")", "+", "1", ",", "density", "=", "True", ",", "color", "=", "'m'", ")", "\n", "plt", ".", "title", "(", "\"Distribution of Classes on \"", "+", "text", ")", "\n", "plt", ".", "xlabel", "(", "'Class'", ")", "\n", "plt", ".", "ylabel", "(", "'Percentage'", ")", "\n", "plt", ".", "savefig", "(", "\"/data1/temp/\"", "+", "text", "+", "str", "(", "len", "(", "y", ")", ")", "+", "str", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "100", ")", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.__init__": [[46, 100], ["datasets.ImageDataset.ImageDataset.__init__", "CaltechSilhouettes.CaltechSilhouettes.dataset_id", "str", "datasets.download.maybe_download_and_extract", "int", "CaltechSilhouettes.CaltechSilhouettes.load_dataset_from_disk", "numpy.prod", "CaltechSilhouettes.process_params", "len", "CaltechSilhouettes.CaltechSilhouettes.sub_sample", "CaltechSilhouettes.CaltechSilhouettes.sub_sample", "CaltechSilhouettes.CaltechSilhouettes.sub_sample", "numpy.clip", "numpy.clip", "numpy.clip", "CaltechSilhouettes.CaltechSilhouettes._train_set_x.reshape", "CaltechSilhouettes.CaltechSilhouettes._validation_set_x.reshape", "CaltechSilhouettes.CaltechSilhouettes._test_set_x.reshape", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.maybe_download_and_extract", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.load_dataset_from_disk", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "CaltechSilhouettes", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "self", ".", "_binary_input", "=", "0", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_type", "=", "str", "(", "self", ".", "_params", "[", "'type'", "]", ")", "\n", "if", "self", ".", "_type", "==", "TYPE28", ":", "\n", "            ", "self", ".", "_data_url", "=", "'https://people.cs.umass.edu/~marlin/data/caltech101_silhouettes_28_split1.mat'", "\n", "", "elif", "self", ".", "_type", "==", "TYPE16", ":", "\n", "            ", "self", ".", "_data_url", "=", "'https://people.cs.umass.edu/~marlin/data/caltech101_silhouettes_16_split1.mat'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"You chose '{}' which is an invalid type for Caltech Silhouettes. Only valid types: {}\"", ".", "format", "(", "\n", "self", ".", "_type", ",", "TYPES", ")", ")", "\n", "", "self", ".", "_data_extract", "=", "maybe_download_and_extract", "(", "self", ".", "_data_url", ",", "self", ".", "_data_dir", ")", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_picture_size", "=", "int", "(", "self", ".", "_type", ")", "\n", "\n", "# Number of channels in each image, 3 channels: Red, Green, Blue.", "\n", "self", ".", "_num_channels", "=", "1", "\n", "\n", "self", ".", "_n_params", "=", "len", "(", "self", ".", "_params", "[", "'params'", "]", ")", "if", "'params'", "in", "self", ".", "_params", "else", "0", "\n", "self", ".", "_x_sample_shape", "=", "(", "self", ".", "_picture_size", ",", "self", ".", "_picture_size", ",", "self", ".", "_num_channels", ")", "\n", "self", ".", "_y_sample_shape", "=", "(", "self", ".", "_n_params", ",", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset_from_disk", "(", ")", "\n", "\n", "# choose a subset", "\n", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n", "", "dim", "=", "np", ".", "prod", "(", "self", ".", "x_shape", ")", "\n", "if", "self", ".", "_params", "[", "'vect'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "dim", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "dim", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.load_dataset_from_disk": [[101, 121], ["scipy.io.loadmat", "numpy.asarray().reshape", "dic[].astype", "numpy.asarray().reshape", "dic[].astype", "numpy.asarray().reshape", "dic[].astype", "numpy.asarray", "numpy.asarray", "numpy.asarray", "list", "list", "list", "map", "map", "map", "dic[].astype", "dic[].astype", "dic[].astype"], "methods", ["None"], ["", "", "def", "load_dataset_from_disk", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            load the CaltechSilhouettes\n            and its labels\n        \"\"\"", "\n", "\n", "dic", "=", "loadmat", "(", "self", ".", "_data_extract", ")", "\n", "\n", "self", ".", "_class_names", "=", "dic", "[", "\"classnames\"", "]", "\n", "train_set_x", "=", "np", ".", "asarray", "(", "list", "(", "map", "(", "rescale", ",", "dic", "[", "\"train_data\"", "]", ".", "astype", "(", "np", ".", "float32", ")", ")", ")", ")", ".", "reshape", "(", "\n", "[", "-", "1", ",", "*", "self", ".", "_x_sample_shape", "]", ")", "\n", "train_set_y", "=", "dic", "[", "\"train_labels\"", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "validation_set_x", "=", "np", ".", "asarray", "(", "list", "(", "map", "(", "rescale", ",", "dic", "[", "\"val_data\"", "]", ".", "astype", "(", "np", ".", "float32", ")", ")", ")", ")", ".", "reshape", "(", "\n", "[", "-", "1", ",", "*", "self", ".", "_x_sample_shape", "]", ")", "\n", "validation_set_y", "=", "dic", "[", "\"val_labels\"", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "test_set_x", "=", "np", ".", "asarray", "(", "list", "(", "map", "(", "rescale", ",", "dic", "[", "\"test_data\"", "]", ".", "astype", "(", "np", ".", "float32", ")", ")", ")", ")", ".", "reshape", "(", "\n", "[", "-", "1", ",", "*", "self", ".", "_x_sample_shape", "]", ")", "\n", "test_set_y", "=", "dic", "[", "\"test_labels\"", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "return", "train_set_x", ",", "validation_set_x", ",", "test_set_x", ",", "train_set_y", ",", "validation_set_y", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.dataset_id": [[122, 164], ["CaltechSilhouettes.check_params_impl", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "CaltechSilhouettes", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'CaltechSilhouettes'", "\n", "\n", "# binary or continuous", "\n", "# id_binary = {0:'-c',1:'-d'}", "\n", "# id += id_binary[params['binary']]", "\n", "\n", "# stochastic", "\n", "# id += '-st' + str(params[\"stochastic\"])", "\n", "\n", "# types", "\n", "if", "(", "'type'", "in", "params", ")", "and", "params", "[", "'type'", "]", ":", "\n", "            ", "id", "+=", "'-Ty'", "+", "str", "(", "params", "[", "'type'", "]", ")", "\n", "\n", "# subsampling", "\n", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "(", "'clip_high'", "in", "params", ")", "and", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "(", "'clip_low'", "in", "params", ")", "and", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "(", "'id_note'", "in", "params", ")", "and", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.sub_sample": [[165, 184], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_data", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_data", "=", "np", ".", "random", ".", "permutation", "(", "len_data", ")", "\n", "new_len_data", "=", "int", "(", "len_data", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.output_size": [[185, 188], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "0", "# 10 if self._params['classes'] == () else len(self._params['classes'])", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.color_images": [[189, 192], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.CaltechSilhouettes.image_shape": [[193, 196], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_x_sample_shape", "# the last number is the channel", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CaltechSilhouettes.rescale": [[12, 14], ["None"], "function", ["None"], ["def", "rescale", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.GTSRB_SS.__init__": [[42, 54], ["ImageDataset.ImageDataset.__init__", "GTSRB_SS.GTSRB_SS.dataset_id", "GTSRB_SS.GTSRB_SS.load_data"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "default_data_dir", "=", "'/ssd_data/Traffic_signs_test/'", "\n", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", "self", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.GTSRB_SS.dataset_id": [[56, 67], ["Traffic_signs_test.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "Traffic_signs_test", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'GTSRB_SS'", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.GTSRB_SS.load_data": [[68, 97], ["GTSRB_SS.import_data", "GTSRB_SS.import_data", "GTSRB_SS.import_data", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "os.stat", "os.stat", "os.stat", "os.stat", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.import_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.import_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.import_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "gtsrb_dir", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "stat", "(", "gtsrb_dir", ")", "\n", "", "except", ":", "\n", "            ", "os", ".", "mkdir", "(", "gtsrb_dir", ")", "\n", "\n", "# import pdb;pdb.set_trace()", "\n", "#X_shuffled, Y_shuffled = load_train(gtsrb_dir)", "\n", "#val_frac = 0.15", "\n", "#X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_shuffled, Y_shuffled,", "\n", "#                                                                          test_size=val_frac, shuffle=False)", "\n", "", "X_train", ",", "Y_train", "=", "import_data", "(", "gtsrb_dir", ",", "\"train\"", ")", "\n", "X_test", ",", "Y_test", "=", "import_data", "(", "gtsrb_dir", ",", "\"test\"", ")", "\n", "X_val", ",", "Y_val", "=", "import_data", "(", "gtsrb_dir", ",", "\"valid\"", ")", "\n", "\n", "\n", "\n", "\n", "#X_test, Y_test = load_test(gtsrb_dir)", "\n", "\n", "# normalize data consistently (in case they would not already be)", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "X_train", ",", "X_val", ",", "X_test", "]", ")", "\n", "X_train", "=", "normalize", "(", "X_train", ",", "all_min", ",", "all_max", ")", "\n", "X_val", "=", "normalize", "(", "X_val", ",", "all_min", ",", "all_max", ")", "\n", "X_test", "=", "normalize", "(", "X_test", ",", "all_min", ",", "all_max", ")", "\n", "\n", "return", "X_train", ",", "Y_train", ",", "X_val", ",", "Y_val", ",", "X_test", ",", "Y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.get_class": [[100, 102], ["int", "img_path.split"], "function", ["None"], ["", "", "def", "get_class", "(", "img_path", ")", ":", "\n", "    ", "return", "int", "(", "img_path", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.preprocess_img": [[104, 121], ["skimage.color.rgb2hsv", "skimage.exposure.equalize_hist", "skimage.color.hsv2rgb", "min", "skimage.transform.resize"], "function", ["None"], ["", "def", "preprocess_img", "(", "img", ")", ":", "\n", "# Histogram normalization in y", "\n", "    ", "hsv", "=", "color", ".", "rgb2hsv", "(", "img", ")", "\n", "hsv", "[", ":", ",", ":", ",", "2", "]", "=", "exposure", ".", "equalize_hist", "(", "hsv", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "img", "=", "color", ".", "hsv2rgb", "(", "hsv", ")", "\n", "\n", "# central scrop", "\n", "min_side", "=", "min", "(", "img", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "centre", "=", "img", ".", "shape", "[", "0", "]", "//", "2", ",", "img", ".", "shape", "[", "1", "]", "//", "2", "\n", "img", "=", "img", "[", "centre", "[", "0", "]", "-", "min_side", "//", "2", ":", "centre", "[", "0", "]", "+", "min_side", "//", "2", ",", "\n", "centre", "[", "1", "]", "-", "min_side", "//", "2", ":", "centre", "[", "1", "]", "+", "min_side", "//", "2", ",", "\n", ":", "]", "\n", "\n", "# rescale to standard size", "\n", "img", "=", "transform", ".", "resize", "(", "img", ",", "(", "IMG_SIZE", ",", "IMG_SIZE", ")", ")", "\n", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.GTSRB_SS.import_data": [[124, 130], ["os.path.join", "os.path.join", "open", "pickle.load", "numpy.float32"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "import_data", "(", "gtsrb_dir", "=", "'/ssd_data/'", ",", "data", "=", "\"train\"", ")", ":", "\n", "    ", "data_file", "=", "os", ".", "path", ".", "join", "(", "gtsrb_dir", ",", "'{}'", ".", "format", "(", "data", ")", "+", "'.p'", ")", "\n", "with", "open", "(", "data_file", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "        ", "data_file_numpy", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "X", ",", "Y", "=", "np", ".", "float32", "(", "data_file_numpy", "[", "'features'", "]", ")", ",", "data_file_numpy", "[", "'labels'", "]", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.download._print_download_progress": [[28, 43], ["sys.stdout.write", "sys.stdout.flush", "float"], "function", ["None"], ["def", "_print_download_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "    ", "\"\"\"\n    Function used for printing the download progress.\n    Used as a call-back function in maybe_download_and_extract().\n    \"\"\"", "\n", "\n", "# Percentage completion.", "\n", "pct_complete", "=", "float", "(", "count", "*", "block_size", ")", "/", "total_size", "\n", "\n", "# Status-message. Note the \\r which means the line should overwrite itself.", "\n", "msg", "=", "\"\\r- Download progress: {0:.1%}\"", ".", "format", "(", "pct_complete", ")", "\n", "\n", "# Print it.", "\n", "sys", ".", "stdout", ".", "write", "(", "msg", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.download.maybe_download_and_extract": [[48, 99], ["os.path.join", "url.split", "os.path.exists", "urllib.request.urlretrieve", "print", "print", "os.path.join.endswith", "print", "os.path.exists", "os.makedirs", "print", "zipfile.ZipFile().extractall", "print", "os.path.join.endswith", "print", "tarfile.open().extractall", "print", "zipfile.ZipFile", "tarfile.open"], "function", ["None"], ["", "def", "maybe_download_and_extract", "(", "url", ",", "download_dir", ")", ":", "\n", "    ", "\"\"\"\n    Download and extract the data if it doesn't already exist.\n    Assumes the url is a tar-ball file.\n\n    :param url:\n        Internet URL for the tar-file to download.\n        Example: \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n\n    :param download_dir:\n        Directory where the downloaded file is saved.\n        Example: \"data/CIFAR-10/\"\n\n    :return:\n        Nothing.\n    \"\"\"", "\n", "\n", "# Filename for saving the file downloaded from the internet.", "\n", "# Use the filename from the URL and add it to the download_dir.", "\n", "filename", "=", "url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "download_dir", ",", "filename", ")", "\n", "\n", "# Check if the file already exists.", "\n", "# If it exists then we assume it has also been extracted,", "\n", "# otherwise we need to download and extract it now.", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file_path", ")", ":", "\n", "# Check if the download directory exists, otherwise create it.", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "download_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "download_dir", ")", "\n", "\n", "# Download the file from the internet.", "\n", "", "file_path", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "url", "=", "url", ",", "\n", "filename", "=", "file_path", ",", "\n", "reporthook", "=", "_print_download_progress", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"Download finished.\"", ")", "\n", "\n", "if", "file_path", ".", "endswith", "(", "\".zip\"", ")", ":", "\n", "            ", "print", "(", "\"Extracting files.\"", ")", "\n", "# Unpack the zip-file.", "\n", "zipfile", ".", "ZipFile", "(", "file", "=", "file_path", ",", "mode", "=", "\"r\"", ")", ".", "extractall", "(", "download_dir", ")", "\n", "print", "(", "\"Done.\"", ")", "\n", "", "elif", "file_path", ".", "endswith", "(", "(", "\".tar.gz\"", ",", "\".tgz\"", ")", ")", ":", "\n", "            ", "print", "(", "\"Extracting files.\"", ")", "\n", "# Unpack the tar-ball.", "\n", "tarfile", ".", "open", "(", "name", "=", "file_path", ",", "mode", "=", "\"r:gz\"", ")", ".", "extractall", "(", "download_dir", ")", "\n", "print", "(", "\"Done.\"", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"Data has apparently already been downloaded and unpacked.\"", ")", "\n", "", "return", "file_path", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.__init__": [[73, 143], ["ImageDataset.ImageDataset.__init__", "CMB_multifilters_21.CMB_multifilters_21.dataset_id", "CMB_multifilters_21.CMB_multifilters_21.compute_min_max_data", "CMB_multifilters_21.CMB_multifilters_21.load_dataset", "CMB_multifilters_21.CMB_multifilters_21.load_dataset", "CMB_multifilters_21.CMB_multifilters_21.load_dataset", "Exception", "open", "json.loads", "numpy.load", "os.path.exists", "os.path.isdir", "f.read"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.compute_min_max_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_json_filename", "=", "\"params.json\"", "\n", "fraction_dataset", "=", "params", "[", "'fraction_dataset'", "]", "\n", "\n", "# self._csv_filename = \"labels_file.csv\"", "\n", "if", "fraction_dataset", "==", "100", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data.csv'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data_{}.csv'", ".", "format", "(", "fraction_dataset", ")", "\n", "# label_df_Train = pd.read_csv(self._csv_filename_Train, sep=\"\\t\")", "\n", "\n", "", "self", ".", "_csv_filename_Test", "=", "'Test_CMB_data.csv'", "\n", "# label_df_Test = pd.read_csv(self._csv_filename_Test, sep=\"\\t\")", "\n", "\n", "self", ".", "_csv_filename_Validation", "=", "'Validation_CMB_data.csv'", "\n", "# label_df_Validation = pd.read_csv(self._csv_filename_Validation, sep=\"\\t\")", "\n", "\n", "# self._all_parameter_list = ['h', 'omega_b', 'omega_cdm', 'A_s', 'n_s', 'tau_reio']", "\n", "self", ".", "_parameters_list", "=", "params", "[", "\"parameters\"", "]", "\n", "self", ".", "_fraction_dataset", "=", "params", "[", "\"fraction_dataset\"", "]", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_normalize_labels", "=", "self", ".", "_params", "[", "'normalize_labels'", "]", "\n", "self", ".", "_normalize_images", "=", "self", ".", "_params", "[", "'normalize_images'", "]", "\n", "\n", "\n", "# check if the data directory is present", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_data_dir", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_data_dir", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Dataset directory {}'", "\n", "' not found'", ".", "format", "(", "self", ".", "_data_dir", ")", "\n", ")", "\n", "\n", "#self._debug_mode = params['debug_mode']", "\n", "\n", "#self._augment_data = params['augm_data']", "\n", "#self._only_center = params['only_center']", "\n", "", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "self", ".", "_json_filename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "picture_size", "=", "conf_dict", "[", "\"pic_size\"", "]", "\n", "#self._x_sample_shape = (picture_size, picture_size, 3)", "\n", "#self._y_sample_shape = (self._n_params,)", "\n", "\n", "#self._var_params = self.conf_dict['params'] # TODO Check that is sorted like self.parameter_list", "\n", "\n", "# useful for lazy load, however I need to reimplement some methods to make it work", "\n", "# self._loaded_from_disk = False", "\n", "\n", "#self._train_set_x = None", "\n", "#self._train_set_y = None", "\n", "#self._test_set_x = None", "\n", "#self._test_set_y = None", "\n", "\n", "#self._n_samples_train = None", "\n", "#self._n_samples_test = None", "\n", "self", ".", "_labels_min", ",", "self", ".", "_labels_max", ",", "self", ".", "_data_min", ",", "self", ".", "_data_max", "=", "self", ".", "compute_min_max_data", "(", "norm_labels", "=", "self", ".", "_normalize_labels", ",", "\n", "norm_data", "=", "self", ".", "_normalize_images", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "load_dataset", "(", "TRAIN", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "load_dataset", "(", "VALIDATION", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset", "(", "TEST", ")", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "self", ".", "_x_sample_shape", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "self", ".", "_train_set_x", "[", "0", "]", ")", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.dataset_id": [[148, 181], ["str", "str", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "# CMB.check_params_impl(params)", "\n", "\n", "p_dist_abbr", "=", "{", "'uniform'", ":", "'U'", ",", "\n", "'lattice'", ":", "'L'", "}", "\n", "\n", "# raise Exception(\"ERROR: you cannot run me if my name is wrong! :) fix me :) \")", "\n", "id", "=", "'21cm'", "\n", "# id += os.path.basename(params['data_dir'])", "\n", "id", "+=", "'-d'", "+", "str", "(", "params", "[", "'fraction_dataset'", "]", ")", "\n", "id", "+=", "'-pdim'", "+", "str", "(", "len", "(", "params", "[", "'parameters'", "]", ")", ")", "\n", "id", "+=", "'-n'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_images'", "]", "==", "True", "else", "'0'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_labels'", "]", "==", "True", "else", "'0'", "\n", "#id += '-au1' if self._augment_data == True  else '-au0'", "\n", "#id += '-oc1' if self._only_center == True else '-oc0'", "\n", "\n", "\n", "# id += '-' + p_dist_abbr[params['par_distr']]", "\n", "# id += '-pprr' + str(params['pic_per_run_rot'])", "\n", "# id += '-ppre' + str(params['pic_per_run_equator'])", "\n", "\n", "# id note (keep last)", "\n", "#if params['id_note']:", "\n", "#    id += params['id_note']", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.read_metadata": [[183, 193], ["pandas.read_csv", "open", "json.loads", "f.read"], "methods", ["None"], ["", "def", "read_metadata", "(", "self", ",", "json_basename", ",", "csv_basename", ")", ":", "\n", "#load json file", "\n", "        ", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "json_basename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "csv_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "csv_basename", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "return", "conf_dict", ",", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.get_output_shapes": [[195, 200], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "#output_shapes = tuple([image.shape + (1,), datasets_tuple[1].shape[1]])", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", ",", "datasets_tuple", "[", "1", "]", ".", "shape", "[", "1", "]", "]", ")", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.get_output_types": [[201, 206], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "as_dtype", "(", "datasets_tuple", "[", "1", "]", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.dataset_map": [[210, 241], ["CMB_multifilters_21.CMB_multifilters_21.get_output_types", "CMB_multifilters_21.CMB_multifilters_21.get_output_shapes", "list", "dataset.map.map.map", "numpy.load", "zip", "scipy.ndimage.gaussian_filter", "scipy.ndimage.gaussian_filter.astype", "tuple", "tensorflow.py_func"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "channels", "=", "output_shapes", "[", "0", "]", "[", "2", "]", "\n", "norm_bool", "=", "self", ".", "_normalize_images", "\n", "data_min", "=", "self", ".", "_data_min", "\n", "data_max", "=", "self", ".", "_data_max", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "label", "=", "full_data", "[", "n", "]", "[", "1", "]", "\n", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "filename", ")", "\n", "if", "norm_bool", ":", "\n", "#image = 2*(image-data_min)/(data_max-data_min) - 1.", "\n", "#image = np.delete(image, np.argwhere(image == 0.))", "\n", "\n", "                ", "image", "=", "gaussian_filter", "(", "image", ",", "sigma", "=", "0.7", ")", "\n", "image", "=", "(", "image", "-", "data_min", ")", "/", "data_max", "\n", "\n", "\n", "", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "label", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.load_dataset": [[243, 331], ["CMB_multifilters_21.CMB_multifilters_21.read_metadata", "len", "print", "df_dataset[].values.astype", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.read_metadata"], ["", "def", "load_dataset", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "\"\"\"\n        load the dataset in memory and set in the object\n\n        Args:\n            train_test_ratio: (float) percentage of the dataset in train\n\n        \"\"\"", "\n", "json_filename", "=", "self", ".", "_json_filename", "\n", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Train", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Validation", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Test", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"`dataset_str` can be only: train, validation or test.\"", ")", "\n", "\n", "# get info from the metadata", "\n", "", "conf_dict", ",", "labels_filter_df", "=", "self", ".", "read_metadata", "(", "json_filename", ",", "csv_filename", ")", "\n", "#self._picture_size = self.conf_dict['pic_size']", "\n", "n_parameters", "=", "len", "(", "conf_dict", ")", "\n", "\n", "#if self._only_center:", "\n", "#    labels_filter_df = labels_filter_df[labels_filter_df['is_center']]", "\n", "\n", "#if not self._augment_data:", "\n", "#    # no rotations", "\n", "#    is_no_rotation = labels_filter_df['rot_angle'] == 0", "\n", "#    labels_filter_df = labels_filter_df[is_no_rotation]", "\n", "\n", "#    # no flips", "\n", "#    index_no_flip = ~labels_filter_df['flip']", "\n", "#    labels_filter_df = labels_filter_df[index_no_flip]", "\n", "\n", "\n", "'''\n        if self._debug_mode:\n            debug_dimension = 500\n            labels_filter_df = labels_filter_df.iloc[:debug_dimension]\n        '''", "\n", "\n", "# dataset_x = labels_filter_df.sample(frac=1)", "\n", "df_dataset", "=", "labels_filter_df", "\n", "num_files", "=", "df_dataset", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'{} are going to be loaded in memory'", ".", "format", "(", "num_files", ")", ")", "\n", "\n", "filename_dataset", "=", "df_dataset", "[", "'filename'", "]", ".", "values", "\n", "labels_dataset", "=", "df_dataset", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "\n", "if", "self", ".", "_normalize_labels", ":", "\n", "            ", "labels_dataset", "=", "2", "*", "(", "labels_dataset", "-", "self", ".", "_labels_min", ")", "/", "(", "self", ".", "_labels_max", "-", "self", ".", "_labels_min", ")", "-", "1.", "\n", "\n", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "# dim_train = int(num_files * train_ratio)", "\n", "# dim_validation = int(num_files * validation_ratio)", "\n", "# dim_test = num_files - dim_train - dim_validation", "\n", "#", "\n", "# # training", "\n", "# df_train = dataset_x.iloc[0 : dim_train]", "\n", "# filename_training = df_train['filename'].values", "\n", "# labels_training = df_train[['omega_cdm', 'A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     max_training = np.max(labels_training, axis=0)", "\n", "#     min_training = np.min(labels_training, axis=0)", "\n", "#     labels_training = (labels_training - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_validation = dataset_x.iloc[dim_train : (dim_train+dim_validation)]", "\n", "# filename_validation = df_validation['filename'].values", "\n", "# labels_validation = df_validation[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_validation = (labels_validation - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_test = dataset_x.iloc[(dim_train+dim_validation):]", "\n", "# filename_test = df_test['filename'].values", "\n", "# labels_test = df_test[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_test = (labels_test - min_training)/(max_training - min_training)", "\n", "#", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "\n", "", "return", "filename_dataset", ",", "labels_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.compute_min_max_data": [[332, 361], ["pandas.read_csv", "numpy.mean", "numpy.std", "label_df[].values.astype", "numpy.min", "numpy.max", "numpy.load", "all_min_0.append", "all_max_0.append", "numpy.mean", "numpy.std"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "compute_min_max_data", "(", "self", ",", "norm_labels", "=", "False", ",", "norm_data", "=", "False", ")", ":", "\n", "        ", "all_max_0", "=", "[", "]", "\n", "all_min_0", "=", "[", "]", "\n", "csv_filename", "=", "self", ".", "_data_dir", "+", "'/labels_file.csv'", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "labels_min", "=", "None", "\n", "labels_max", "=", "None", "\n", "data_min", "=", "[", "]", "\n", "data_max", "=", "[", "]", "\n", "\n", "if", "norm_data", ":", "\n", "            ", "filenames", "=", "label_df", "[", "'filename'", "]", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "                ", "patch1", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "\"/\"", "+", "filename", ")", "\n", "all_min_0", ".", "append", "(", "np", ".", "mean", "(", "patch1", ")", ")", "\n", "all_max_0", ".", "append", "(", "np", ".", "std", "(", "patch1", ")", ")", "\n", "\n", "\n", "", "data_min", "=", "np", ".", "mean", "(", "all_min_0", ")", "\n", "data_max", "=", "np", ".", "std", "(", "all_max_0", ")", "\n", "\n", "", "if", "norm_labels", ":", "\n", "            ", "labels", "=", "label_df", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "labels_min", "=", "np", ".", "min", "(", "labels", ",", "axis", "=", "0", ")", "\n", "labels_max", "=", "np", ".", "max", "(", "labels", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "labels_min", ",", "labels_max", ",", "data_min", ",", "data_max", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.labels_min_training": [[362, 374], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_min_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#", "\n", "#if  self._dataset_x_min is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "\n", "        ", "return", "self", ".", "_labels_min_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.labels_max_training": [[375, 386], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_max_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#\u00a7", "\n", "#if  self._dataset_x_max is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "        ", "return", "self", ".", "_labels_max_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.x_shape_train": [[387, 391], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB_multifilters_21.CMB_multifilters_21.x_shape_eval": [[392, 444], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the evaluation\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_train(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_eval(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "#return mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels, mnist.test.images, mnist.test.labels", "\n", "\n", "\n", "#start_time_data = timeit.default_timer()", "\n", "\n", "#shape_X = (n_files,) + self._x_sample_shape", "\n", "#shape_Y = (n_files,) + self._y_sample_shape", "\n", "\n", "# construct the datasets", "\n", "#X = np.empty(shape_X)", "\n", "#Y = np.empty(shape_Y)", "\n", "\n", "#for ix, row in  labels_filter_df.iterrows():", "\n", "#    tmp_numpy = np.load(self._data_dir + \"/\" + row['filename'])", "\n", "#", "\n", "#    X[ix, :, :, 0] = tmp_numpy", "\n", "#    Y[ix] = row[self._var_params]", "\n", "\n", "# print time for the load", "\n", "#step_time = timeit.default_timer()", "\n", "#print(\"time needed to load: \", step_time - start_time_data)", "\n", "\n", "# shuffle the dataset", "\n", "'''\n        randomized_dataset_index = np.random.permutation(n_files)\n        X = X[randomized_dataset_index]\n        Y = Y[randomized_dataset_index]\n\n\n\n\n\n\n        dim_train = int(n_files * train_test_ratio)\n        self._train_set_x, self._train_set_y = X[:dim_train] , Y[:dim_train]\n        self._test_set_x, self._test_set_y = X[dim_train:], Y[dim_train:]\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviewsArr.IMDBReviewsArr.__init__": [[14, 24], ["AlphaDatasetArr.AlphaDatasetArr.__init__", "IMDBReviewsArr.IMDBReviewsArr._read_imdb", "IMDBReviewsArr.IMDBReviewsArr._preprocess_arrays", "IMDBReviewsArr.IMDBReviewsArr._preprocess_arrays", "IMDBReviewsArr.IMDBReviewsArr._preprocess_arrays", "IMDBReviewsArr.IMDBReviewsArr._set_shapes", "IMDBReviewsArr.process_params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviewsArr.IMDBReviewsArr._read_imdb", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess_arrays", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess_arrays", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._preprocess_arrays", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AlphaDatasetArr.AlphaDatasetArr._set_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "IMDBReviewsArr", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "train_data", ",", "train_target", ",", "validation_data", ",", "validation_target", ",", "test_data", ",", "test_target", "=", "self", ".", "_read_imdb", "(", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "_preprocess_arrays", "(", "train_data", ",", "train_target", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "_preprocess_arrays", "(", "validation_data", ",", "validation_target", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "_preprocess_arrays", "(", "test_data", ",", "test_target", ")", "\n", "\n", "self", ".", "_set_shapes", "(", "n_samples_train", "=", "self", ".", "_train_set_x", ".", "shape", "[", "0", "]", ",", "n_labels", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviewsArr.IMDBReviewsArr.dataset_id": [[26, 38], ["IMDBReviewsArr.check_params_impl", "AlphaDatasetArr.AlphaDatasetArr.AlphaDatasetArr.dataset_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "IMDBReviewsArr", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'IMDBReviewsArr'", "\n", "\n", "_id", "+=", "AlphaDatasetArr", ".", "dataset_id", "(", "self", ",", "params", ")", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.IMDBReviewsArr.IMDBReviewsArr._read_imdb": [[39, 59], ["tensorflow_datasets.load", "tensorflow_datasets.Split.TEST.subsplit", "tensorflow_datasets.load", "tensorflow_datasets.load", "zip", "zip", "zip", "tensorflow_datasets.as_numpy", "tensorflow_datasets.as_numpy", "tensorflow_datasets.as_numpy"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "_read_imdb", "(", "self", ")", ":", "\n", "        ", "train_dataset", ",", "info", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "\"train\"", ",", "as_supervised", "=", "True", ",", "with_info", "=", "True", ")", "\n", "# n_samples_train = info.splits['train'].num_examples", "\n", "# val/test equal split", "\n", "# n_samples_validation = info.splits['test'].num_examples / 2.", "\n", "# n_samples_test = info.splits['test'].num_examples / 2.", "\n", "\n", "# # new S3 API, still not supported by imdb reviews", "\n", "# validation_dataset = tfds.load('imdb_reviews/plain_text', split=\"test[:50%]\", as_supervised=True)", "\n", "# test_dataset = tfds.load('imdb_reviews/plain_text', split=\"test[-50%:]\", as_supervised=True)", "\n", "\n", "# legacy API", "\n", "validation_split", ",", "test_split", "=", "tfds", ".", "Split", ".", "TEST", ".", "subsplit", "(", "k", "=", "2", ")", "\n", "validation_dataset", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "validation_split", ",", "as_supervised", "=", "True", ")", "\n", "test_dataset", "=", "tfds", ".", "load", "(", "'imdb_reviews/plain_text'", ",", "split", "=", "test_split", ",", "as_supervised", "=", "True", ")", "\n", "\n", "train_data", ",", "train_target", "=", "zip", "(", "*", "[", "excerpt", "for", "excerpt", "in", "tfds", ".", "as_numpy", "(", "train_dataset", ")", "]", ")", "\n", "validation_data", ",", "validation_target", "=", "zip", "(", "*", "[", "excerpt", "for", "excerpt", "in", "tfds", ".", "as_numpy", "(", "validation_dataset", ")", "]", ")", "\n", "test_data", ",", "test_target", "=", "zip", "(", "*", "[", "excerpt", "for", "excerpt", "in", "tfds", ".", "as_numpy", "(", "test_dataset", ")", "]", ")", "\n", "return", "train_data", ",", "train_target", ",", "validation_data", ",", "validation_target", ",", "test_data", ",", "test_target", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.__init__": [[24, 42], ["datasets.ImageDataset.ImageDataset.__init__", "HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.dataset_id", "HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_float_brats", "HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all._params.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_float_brats"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "default_data_dir", "=", "'/ssd_data/HCP_data/all_slices_separately_one'", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "# self._data_dir = default_data_dir", "\n", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "\n", "if", "'resize'", "in", "self", ".", "_params", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_resize", "=", "self", ".", "_params", "[", "'resize'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_resize", "=", "None", "\n", "\n", "", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "=", "self", ".", "load_float_brats", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.dataset_id": [[43, 57], ["HCPcnnLazyLoading_perSlice_all.check_params_impl", "params.keys", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "HCPcnnLazyLoading_perSlice_all", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'HCPcnnLazyLoading_perSlice'", "\n", "id", "+=", "'-'", "+", "params", "[", "'options'", "]", "\n", "if", "'resize'", "in", "params", ".", "keys", "(", ")", ":", "\n", "            ", "id", "+=", "'-'", "+", "str", "(", "params", "[", "'resize'", "]", ")", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_float_brats": [[58, 81], ["HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_file_names", "print", "HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_file_names", "print", "HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_file_names", "print", "print", "print", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_float_brats", "(", "self", ",", "data_dir", ")", ":", "\n", "# data_dir = '/ssd_data/BRATS_data/all_slices_separately_one'", "\n", "\n", "        ", "datasets_tuple", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'train'", ")", "\n", "print", "(", "'---------DATASET TUPLE------------'", ",", "datasets_tuple", ".", "shape", ")", "\n", "\n", "train_set_x", "=", "datasets_tuple", "\n", "\n", "datasets_tuple_test", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'test'", ")", "\n", "print", "(", "'---------DATASET TUPLE TEST------------'", ",", "datasets_tuple_test", ".", "shape", ")", "\n", "\n", "test_set_x", "=", "datasets_tuple_test", "\n", "\n", "datasets_tuple_validation", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'validation'", ")", "\n", "print", "(", "'---------DATASET TUPLE VALIDATION------------'", ",", "datasets_tuple_test", ".", "shape", ")", "\n", "\n", "validation_set_x", "=", "datasets_tuple_validation", "\n", "\n", "print", "(", "'--------------X SHAPE-----------------'", ")", "\n", "self", ".", "_train_set_x_shape", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", ")", ".", "shape", "+", "(", "1", ",", ")", "\n", "print", "(", "self", ".", "_train_set_x_shape", ")", "\n", "\n", "return", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_slices_from_files": [[82, 93], ["os.walk", "numpy.asarray", "os.path.abspath", "numpy.load", "slice.astype.astype.astype", "numpy.asarray.append", "os.path.join", "slice.astype.astype.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slices_from_files", "(", "self", ",", "root", ")", ":", "\n", "        ", "slices", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "fullname", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ")", "\n", "slice", "=", "np", ".", "load", "(", "fullname", ")", "\n", "slice", "=", "slice", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slice", "=", "slice", "/", "(", "slice", ".", "max", "(", ")", ")", "\n", "slices", ".", "append", "(", "slice", ")", "\n", "", "", "slices", "=", "np", ".", "asarray", "(", "slices", ")", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_file_names": [[102, 109], ["os.walk", "numpy.asarray", "numpy.asarray.append"], "methods", ["None"], ["", "def", "load_file_names", "(", "self", ",", "root", ",", "data_type", ")", ":", "\n", "        ", "file_names", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", "+", "'/'", "+", "data_type", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "file_names", ".", "append", "(", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "file_names", "=", "np", ".", "asarray", "(", "file_names", ")", "\n", "return", "file_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_map_filename_slice": [[110, 118], ["os.walk", "numpy.asarray", "range", "numpy.asarray.append"], "methods", ["None"], ["", "def", "load_map_filename_slice", "(", "self", ",", "root", ")", ":", "\n", "        ", "map_fn_s", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "for", "slice", "in", "range", "(", "0", ",", "130", ")", ":", "\n", "                    ", "map_fn_s", ".", "append", "(", "(", "f", ",", "slice", ")", ")", "\n", "", "", "", "map_fn_s", "=", "np", ".", "asarray", "(", "map_fn_s", ")", "\n", "return", "map_fn_s", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_slices_from_file": [[119, 125], ["numpy.load", "numpy.asarray.astype", "numpy.asarray", "numpy.asarray.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slices_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slices", "=", "np", ".", "load", "(", "file", ")", "\n", "slices", "=", "slices", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slices", "=", "slices", "/", "(", "slices", ".", "max", "(", ")", ")", "\n", "slices", "=", "np", ".", "asarray", "(", "slices", ")", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_slice_from_file": [[126, 131], ["numpy.load", "numpy.asarray.astype", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slice_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slice", "=", "np", ".", "load", "(", "file", ")", "\n", "slice", "=", "slice", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slice", "=", "np", ".", "asarray", "(", "slice", ")", "\n", "return", "slice", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.dataset_map": [[133, 152], ["HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.get_output_types", "list", "dataset.map.map.map", "HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_slice_from_file", "numpy.array.reshape", "zip", "numpy.array", "tuple", "str", "PIL.Image.fromarray().resize", "tensorflow.py_func", "PIL.Image.fromarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "image", "=", "self", ".", "load_slice_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "reshaped_img", "=", "image", ".", "reshape", "(", "[", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "return", "reshaped_img", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.get_output_shapes": [[153, 160], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "1", ",", ")", "]", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "            ", "output_shapes", "=", "(", "(", "self", ".", "_resize", ",", "self", ".", "_resize", ",", "1", ")", ",", ")", "\n", "\n", "", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.get_output_types": [[161, 166], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.get_raw_elements": [[167, 184], ["numpy.asarray", "images.reshape.reshape.reshape", "getattr", "getattr", "HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.load_slices_from_file", "images.reshape.reshape.append", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slices_from_file"], ["", "def", "get_raw_elements", "(", "self", ",", "dataset_str", ",", "index_list", "=", "None", ")", ":", "\n", "        ", "attribute_name", "=", "dataset_str", "+", "\"_set_x\"", "\n", "# print('-----------ATTRIBUTE NAME-----------', attribute_name)", "\n", "# print(getattr(self, attribute_name)[index_list])", "\n", "# pdb.set_trace()", "\n", "images", "=", "[", "]", "\n", "if", "index_list", "is", "not", "None", ":", "\n", "            ", "for", "file", "in", "getattr", "(", "self", ",", "attribute_name", ")", "[", "index_list", "]", ":", "\n", "                ", "image", "=", "self", ".", "load_slices_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "file", ")", ")", "\n", "# print(image.shape)", "\n", "images", ".", "append", "(", "image", ")", "\n", "", "images", "=", "np", ".", "asarray", "(", "images", ")", "\n", "images", "=", "images", ".", "reshape", "(", "[", "images", ".", "shape", "[", "0", "]", ",", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", ",", "1", "]", ")", "\n", "x_data", "=", "images", "\n", "", "else", ":", "\n", "            ", "x_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "", "return", "x_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.x_shape_train": [[296, 299], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCPcnnLazyLoading_perSlice_all.HCPcnnLazyLoading_perSlice_all.x_shape_eval": [[301, 304], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.load_dataset": [[100, 162], ["PerturbedDecorator.PerturbedDecorator.add_default_parameters", "PerturbedDecorator.PerturbedDecorator.", "Dataset.load_class", "PerturbedDecorator.PerturbedDecorator.PerturbedDecorator", "PerturbedDecorator.PerturbedDecorator.PerturbedDecorator.", "Exception", "Exception", "params.keys", "params.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.add_default_parameters", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class"], ["@", "staticmethod", "\n", "def", "load_dataset", "(", "params", ",", "return_params_with_default_values", "=", "False", ",", "base_path", "=", "''", ")", ":", "\n", "        ", "\"\"\"\n            return the dataset object\n\n            Parameters\n            ----------\n            params : dict\n                the config dictionary that must contain the key \"dataName\"\n                which selects the dataset and the dataset object, e.g.:\n                 - 'MNIST' - is the standard DL dataset\n                 - 'cifar10' -\n                 - 'boston'  - Boston house dataset, for regression tasks\n\n            return_params_with_default_values : boole\n                if true returns also the updated params with the default values\n\n            Returns\n            -------\n            dataset\n                the object\n\n            params_with_default_values (optional)\n                updated params with default values\n\n        \"\"\"", "\n", "\n", "if", "not", "base_path", "==", "''", ":", "\n", "            ", "base_path", "+=", "\".\"", "\n", "\n", "", "try", ":", "\n", "# load the dataset class that should be in the module dataName.py", "\n", "            ", "dataset_class", "=", "load_class", "(", "base_path", "+", "\"datasets.\"", "+", "params", "[", "\"dataName\"", "]", "+", "\".\"", "+", "params", "[", "\"dataName\"", "]", ")", "\n", "", "except", ":", "\n", "            ", "raise", "Exception", "(", "'Dataset \"{}\" not recognized or bugged'", ".", "format", "(", "params", "[", "\"dataName\"", "]", ")", ")", "\n", "\n", "# add default values to params", "\n", "", "params_with_default_values", "=", "dataset_class", ".", "add_default_parameters", "(", "params", ")", "\n", "params", "=", "params_with_default_values", "\n", "\n", "\n", "# TODO: COMMENT IT AND ADD IT TO THE DOCSTRING", "\n", "if", "\"perturbed\"", "in", "params", "and", "params", "[", "\"perturbed\"", "]", "==", "1", ":", "\n", "\n", "            ", "if", "\"perturbed_id\"", "not", "in", "params", ":", "\n", "                ", "raise", "Exception", "(", "\"You are supposed to specify a new perturbed_id, since this is supposed to be an perturbed dataset\"", ")", "\n", "\n", "", "decorator", "=", "PerturbedDecorator", "(", "params", "[", "\"perturbed_id\"", "]", ")", "\n", "if", "\"perturbed_train_set_x\"", "in", "params", ".", "keys", "(", ")", ":", "\n", "                ", "decorator", ".", "train_set_x_fileName", "=", "params", "[", "\"perturbed_train_set_x\"", "]", "\n", "", "if", "\"perturbed_test_set_x\"", "in", "params", ".", "keys", "(", ")", ":", "\n", "                ", "decorator", ".", "test_set_x_fileName", "=", "params", "[", "\"perturbed_test_set_x\"", "]", "\n", "# decore the class", "\n", "", "dataset_class", "=", "decorator", "(", "dataset_class", ")", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "", "dataset_object", "=", "dataset_class", "(", "params", ")", "\n", "\n", "if", "return_params_with_default_values", ":", "\n", "            ", "return", "params_with_default_values", ",", "dataset_object", "\n", "", "else", ":", "\n", "            ", "return", "dataset_object", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.__init__": [[163, 188], ["params.copy", "params.update", "params.update", "Dataset.Dataset.dataset_id", "params.get", "params.get"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "# provides default options if not already specified", "\n", "        ", "self", ".", "_params_original", "=", "params", ".", "copy", "(", ")", "\n", "params", ".", "update", "(", "self", ".", "default_params", ")", "\n", "params", ".", "update", "(", "self", ".", "_params_original", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_params", "=", "params", "\n", "\n", "self", ".", "_labels", "=", "0", "\n", "self", ".", "_n_labels", "=", "0", "\n", "\n", "self", ".", "_data_augmentation", "=", "params", ".", "get", "(", "\"dataAugmentation\"", ",", "[", "]", ")", "\n", "self", ".", "_data_perturbation", "=", "params", ".", "get", "(", "\"dataPerturbation\"", ",", "[", "]", ")", "\n", "\n", "self", ".", "_binary_input", "=", "False", "\n", "self", ".", "_train_set_x", "=", "None", "\n", "self", ".", "_train_set_y", "=", "None", "\n", "self", ".", "_validation_set_x", "=", "None", "\n", "self", ".", "_validation_set_y", "=", "None", "\n", "self", ".", "_test_set_x", "=", "None", "\n", "self", ".", "_test_set_y", "=", "None", "\n", "\n", "self", ".", "_caching_bool", "=", "True", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_default_params": [[189, 193], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_default_params", "(", ")", ":", "\n", "        ", "\"\"\" returns the dictionary with default values\"\"\"", "\n", "return", "Dataset", ".", "default_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.add_default_parameters": [[195, 202], ["cls.default_params.copy", "cls.default_params.copy.update"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "add_default_parameters", "(", "cls", ",", "params", ")", ":", "\n", "        ", "\"\"\" append to the dictionary params the default values if not present \"\"\"", "\n", "def_values", "=", "cls", ".", "default_params", ".", "copy", "(", ")", "\n", "def_values", ".", "update", "(", "params", ")", "\n", "\n", "return", "def_values", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params": [[203, 243], ["cls.default_params.copy", "cls.default_params.copy.update"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "process_params", "(", "cls", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        Preprocessing of the parameters from config and argo.\n\n        In practice it updates the default values with the ones produced by\n        argo from the config file.\n\n        Parameters\n        ----------\n        params : dict\n            parameters extreacted from the config file\n\n        Returns\n        -------\n        full_params : dict\n            the params dictionary where missing values are replace by default\n            ones.\n\n        \"\"\"", "\n", "\n", "full_params", "=", "cls", ".", "default_params", ".", "copy", "(", ")", "\n", "\n", "# check the dimension", "\n", "# if len(full_params) + 2 < len(params): # run are introduced dynamically", "\n", "#    print(\"Warning: argo passed more options then those in default\")", "\n", "\n", "# update the params dictionary", "\n", "full_params", ".", "update", "(", "params", ")", "\n", "\n", "# # unpack full_params", "\n", "# for k in full_params.keys():", "\n", "#     if type(full_params[k]) == list:", "\n", "#         if len(full_params[k]) != 1:", "\n", "#             raise Exception(", "\n", "#                 'The option {} is not a single valued list'.format(k))", "\n", "#         else:", "\n", "#             full_params[k] = full_params[k][0]", "\n", "\n", "return", "full_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.dataset_id": [[246, 253], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "abstractmethod", "\n", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\" return the id once processed the parameters in params \"\"\"", "\n", "#ids, parameters = Dataset.process_params(params)", "\n", "#return ids", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl": [[254, 262], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "check_params_impl", "(", "cls", ",", "params", ")", ":", "\n", "        ", "\"\"\"check if there are parameters that have not been implemented yet\"\"\"", "\n", "# for prop in params.keys():", "\n", "#     if prop not in cls.implemented_params_keys:", "\n", "#         print('[Warning] - the param {} - is not yet implemented'\\", "\n", "#               ' in the dataset {}'.format(prop, str(cls)))", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.class_filter": [[263, 289], ["numpy.in1d", "Dataset.Dataset.class_filter.replace_with_position"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "class_filter", "(", "dataset_x", ",", "dataset_y", ",", "classes", ",", "position_label", ")", ":", "\n", "        ", "\"\"\"\n        return the dataset with labels in the list classes\n\n        :param dataset_x: data\n        :param dataset_y: labels\n        :param classes:    list of classes\n        :param position_label:  list of classes\n        :return: (dataset_x, dataset_y) with filtered elemnts not in classes\n        \"\"\"", "\n", "\n", "ix_match_class_dataset", "=", "np", ".", "in1d", "(", "dataset_y", ",", "classes", ")", "\n", "dataset_x", "=", "dataset_x", "[", "ix_match_class_dataset", "]", "\n", "dataset_y", "=", "dataset_y", "[", "ix_match_class_dataset", "]", "\n", "\n", "if", "position_label", ":", "\n", "\n", "            ", "def", "replace_with_position", "(", "label_set", ",", "classes", ")", ":", "\n", "                ", "label_set_new", "=", "np", ".", "copy", "(", "label_set", ")", "\n", "for", "ix", ",", "class_", "in", "enumerate", "(", "classes", ")", ":", "label_set_new", "[", "label_set", "==", "class_", "]", "=", "ix", "\n", "return", "label_set_new", "\n", "\n", "", "dataset_y", "=", "replace_with_position", "(", "dataset_y", ",", "classes", ")", "\n", "\n", "", "return", "dataset_x", ",", "dataset_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.dataset_map": [[292, 321], ["Dataset.Dataset.get_output_types", "list", "dataset.map.map.map", "tuple", "zip", "tensorflow.py_func"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "def", "get_function", "(", "n", ")", ":", "\n", "            ", "return", "full_data", "[", "n", "]", "\n", "\n", "", "def", "apply_py_function", "(", "n", ")", ":", "\n", "#if isinstance(output_types[0], list):", "\n", "#    #pdb.set_trace()", "\n", "#    #return (tf.py_func(get_function, [n], output_types[0]),) + tuple(tf.py_func(get_function, [n], output_types[1:]))", "\n", "#    return tuple(tf.py_func(get_function, [n], output_types))", "\n", "#else:", "\n", "#    pdb.set_trace()", "\n", "            ", "return", "tuple", "(", "tf", ".", "py_func", "(", "get_function", ",", "[", "n", "]", ",", "output_types", ")", ")", "\n", "\n", "#if isinstance(output_types[0], list):", "\n", "#    full_data = list(zip(tuple([a, b] for a,b in zip(*datasets_tuple[0])), *datasets_tuple[1:]))", "\n", "#else:", "\n", "#    # I need a list of iterators", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "#dataset = dataset.map(", "\n", "#    lambda n: tuple(tf.py_func(get_function, [n], output_types)),", "\n", "#    num_parallel_calls=NPROCS)", "\n", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "apply_py_function", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_output_shapes": [[322, 329], ["tuple"], "methods", ["None"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "#if not isinstance(datasets_tuple[0], list):", "\n", "        ", "output_shapes", "=", "tuple", "(", "ds", "[", "0", "]", ".", "shape", "for", "ds", "in", "datasets_tuple", ")", "\n", "#else:", "\n", "#    output_shapes = ([ds[0].shape for ds in datasets_tuple[0]], ) + tuple(ds[0].shape for ds in datasets_tuple[1:])", "\n", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_output_types": [[330, 340], ["tuple", "tensorflow.as_dtype"], "methods", ["None"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "ds", "[", "0", "]", ".", "dtype", ")", "for", "ds", "in", "datasets_tuple", "]", ")", "\n", "\n", "#if not isinstance(datasets_tuple[0], list):", "\n", "#    output_types = tuple(tf.as_dtype(ds[0].dtype) for ds in datasets_tuple)", "\n", "#else:", "\n", "#    output_types = ([tf.as_dtype(ds[0].dtype) for ds in datasets_tuple[0]], ) + tuple(tf.as_dtype(ds[0].dtype) for ds in datasets_tuple[1:])", "\n", "#    #output_types = (tf.as_dtype(datasets_tuple[0][0].dtype), ) + tuple(tf.as_dtype(ds[0].dtype) for ds in datasets_tuple[1:])", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_dataset_iterator": [[341, 468], ["isinstance", "tensorflow.data.Dataset.range", "Dataset.Dataset.get_output_shapes", "Dataset.Dataset.dataset_map", "dataset.repeat.repeat.map", "Exception", "zip", "dataset.repeat.repeat.cache", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "isinstance", "len", "Exception", "zip", "node.set_shape", "n.set_shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_map"], ["", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ",", "perturb", ")", ":", "\n", "#is_perturbed = False", "\n", "        ", "datasets_tuple", "=", "None", "\n", "\n", "# create datasets_tuple objects", "\n", "# if is_perturbed, then I return ((x, x_perturbed), y)", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "train_set_x", ",", ")", "\n", "#if len(self._data_perturbation)>0:", "\n", "#    datasets_tuple = ([datasets_tuple[0], self.train_set_x] ,)                ", "\n", "'''\n            if hasattr(self,\"perturbed_train_set_x\") and self.perturbed_train_set_x is not None:\n                datasets_tuple = (datasets_tuple + (self.perturbed_train_set_x, ) ,)\n                is_perturbed = True\n                raise Exception(\"'perturbed_train_set_x' is now obsolte, talk to Luigi\")\n            '''", "\n", "if", "self", ".", "_train_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "train_set_y", ",", ")", "\n", "\n", "", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "validation_set_x", ",", ")", "\n", "#if len(self._data_perturbation)>0:", "\n", "#    datasets_tuple = (datasets_tuple + (self.validation_set_x, ) ,)", "\n", "\n", "'''\n            if hasattr(self,\"perturbed_validation_set_x\") and self.perturbed_validation_set_x is not None:\n                datasets_tuple = (datasets_tuple + (self.perturbed_validation_set_x, ) , )\n                is_perturbed = True\n                raise Exception(\"'perturbed_validation_set_x' is now obsolte, talk to Luigi\")\n            '''", "\n", "if", "self", ".", "_validation_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "validation_set_y", ",", ")", "\n", "\n", "", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "test_set_x", ",", ")", "\n", "#if len(self._data_perturbation)>0:", "\n", "#    datasets_tuple = (datasets_tuple + (self.test_set_x, ) ,)", "\n", "\n", "'''\n            if hasattr(self,\"perturbed_test_set_x\") and self.perturbed_test_set_x is not None:\n                datasets_tuple = (datasets_tuple + (self.perturbed_test_set_x, ), )\n                is_perturbed = True\n                raise Exception(\"'perturbed_test_set_x' is now obsolte, talk to Luigi\")\n            '''", "\n", "if", "self", ".", "_test_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "test_set_y", ",", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "", "if", "isinstance", "(", "datasets_tuple", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"not supported\"", ")", "\n", "n_samples", "=", "datasets_tuple", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "n_samples", "=", "datasets_tuple", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "# creates a dataset of step separated range of values.", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "range", "(", "n_samples", ")", "\n", "\n", "#print(n_samples)", "\n", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "\n", "#print(output_shapes)", "\n", "\n", "dataset", "=", "self", ".", "dataset_map", "(", "dataset", ",", "datasets_tuple", ")", "\n", "\n", "# do not add \"_\" or this will raise issues when loading the model", "\n", "def", "set_shapes", "(", "*", "nodes", ")", ":", "\n", "            ", "for", "node", ",", "outshape", "in", "zip", "(", "nodes", ",", "output_shapes", ")", ":", "\n", "                ", "if", "isinstance", "(", "node", ",", "tuple", ")", ":", "\n", "                    ", "for", "n", ",", "os", "in", "zip", "(", "node", ",", "output_shape", ")", ":", "\n", "                        ", "n", ".", "set_shape", "(", "os", ")", "\n", "", "", "else", ":", "\n", "                    ", "node", ".", "set_shape", "(", "outshape", ")", "\n", "", "", "return", "nodes", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "set_shapes", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "# Luigi: super cow speed? what do you mean?", "\n", "if", "self", ".", "_caching_bool", ":", "\n", "            ", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "# data augmentation", "\n", "", "if", "augment", ":", "\n", "# the line below is more elegant, however not compatible with loading PBs (Luigi)", "\n", "#dataset = dataset.map(partial(self.augment_element, is_perturbed), num_parallel_calls=NPROCS)", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "augment_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "duplicate_x_element_if_needed", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# make sure I have some perturbation, otherwise I don't duplicate the tensor", "\n", "", "if", "perturb", "and", "len", "(", "self", ".", "_data_perturbation", ")", ">", "0", ":", "\n", "#if perturb:", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "perturb_element", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "", "else", ":", "\n", "#print(\"XXXXXXXXXXXXXXXXXXXXXXXXXX\")", "\n", "#print(dataset)", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "duplicate_x_element_if_needed", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "#print(dataset)", "\n", "#pdb.set_trace()", "\n", "\n", "\n", "# we shuffle the data and sample repeatedly batches for training", "\n", "", "if", "shuffle", ":", "\n", "            ", "if", "self", ".", "_shuffling_cache", "is", "None", ":", "\n", "                ", "shuffling_cache", "=", "n_samples", "+", "1", "\n", "", "else", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffling_cache", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffling_cache", ")", "\n", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "# initializer = None", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "# initializer = iterator.initializer", "\n", "\n", "# batched_dataset = batched_dataset.prefetch(500)", "\n", "\n", "# get a training batch of images and labels", "\n", "", "return", "iterator", "#, is_perturbed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.perturb_element": [[469, 515], ["len", "getattr.", "getattr", "tensorflow.random_uniform", "Exception", "tensorflow.less", "tensorflow.cond", "method.split", "Dataset.Dataset.perturb_element.apply_perturbation"], "methods", ["None"], ["", "def", "perturb_element", "(", "self", ",", "*", "observation", ")", ":", "\n", "\n", "        ", "nargs", "=", "len", "(", "observation", ")", "\n", "\n", "raw_x", "=", "observation", "[", "0", "]", "[", "0", "]", "\n", "aug_x", "=", "observation", "[", "0", "]", "[", "1", "]", "\n", "perturb_x", "=", "aug_x", "\n", "\n", "#if isinstance(observation[0], tuple):", "\n", "#    x = observation[0][0]", "\n", "#    x_perturbed = observation[0][1]", "\n", "#else:", "\n", "#    x = observation[0]", "\n", "#    x_perturbed = x", "\n", "\n", "if", "nargs", "==", "2", ":", "\n", "            ", "y", "=", "observation", "[", "1", "]", "\n", "", "elif", "nargs", ">", "2", ":", "\n", "            ", "raise", "Exception", "(", "\"observation of the dataset is a tuple with more than 2 elements.\"", ")", "\n", "\n", "", "def", "apply_perturbation", "(", "function", ",", "kwargs_tuple", ",", "x", ")", ":", "\n", "            ", "return", "function", "(", "x", ",", "**", "kwargs_tuple", ")", "\n", "\n", "", "for", "pert", "in", "self", ".", "_data_perturbation", ":", "\n", "\n", "            ", "method", ",", "kwargs_tuple", ",", "frequency_perturbation", "=", "pert", "\n", "function", "=", "getattr", "(", "Perturbations", ",", "method", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ")", "\n", "\n", "# determining if I will apply the perturbation", "\n", "uniform_sample", "=", "tf", ".", "random_uniform", "(", "[", "]", ",", "0.", ",", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "#shape, min, max", "\n", "\n", "if", "frequency_perturbation", ">", "0.0", ":", "\n", "                ", "cond", "=", "tf", ".", "less", "(", "uniform_sample", ",", "frequency_perturbation", ")", "\n", "\n", "perturb_x", "=", "tf", ".", "cond", "(", "cond", ",", "\n", "lambda", ":", "apply_perturbation", "(", "function", ",", "\n", "kwargs_tuple", ",", "\n", "perturb_x", ")", ",", "\n", "lambda", ":", "perturb_x", ")", "\n", "\n", "", "", "perturbed_observation", "=", "(", "(", "raw_x", ",", "aug_x", ",", "perturb_x", ")", ",", ")", "\n", "\n", "if", "y", "is", "not", "None", ":", "\n", "            ", "perturbed_observation", "+=", "(", "y", ",", ")", "\n", "\n", "", "return", "perturbed_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.duplicate_x_element_if_needed": [[519, 552], ["len", "isinstance", "Exception"], "methods", ["None"], ["", "def", "duplicate_x_element_if_needed", "(", "self", ",", "*", "observation", ")", ":", "\n", "\n", "        ", "nargs", "=", "len", "(", "observation", ")", "\n", "y", "=", "None", "\n", "\n", "current_x", "=", "observation", "[", "0", "]", "\n", "if", "isinstance", "(", "current_x", ",", "tuple", ")", ":", "\n", "            ", "duplicated_x", "=", "current_x", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "duplicated_x", "=", "current_x", "\n", "current_x", "=", "(", "current_x", ",", ")", "\n", "\n", "#if isinstance(observation[0], tuple):", "\n", "#    x = observation[0][0]", "\n", "#    x_perturbed = observation[0][1]", "\n", "#else:", "\n", "#    x = observation[0]", "\n", "#    x_perturbed = x", "\n", "\n", "", "if", "nargs", "==", "2", ":", "\n", "            ", "y", "=", "observation", "[", "1", "]", "\n", "", "elif", "nargs", ">", "2", ":", "\n", "            ", "raise", "Exception", "(", "\"observation of the dataset is a tuple with more than 2 elements.\"", ")", "\n", "\n", "", "perturbed_observation", "=", "(", "current_x", "+", "(", "duplicated_x", ",", ")", ",", ")", "\n", "\n", "if", "y", "is", "not", "None", ":", "\n", "            ", "perturbed_observation", "+=", "(", "y", ",", ")", "\n", "\n", "# print(perturbed_observation)", "\n", "#if isinstance(observation[0], tuple):", "\n", "#    pdb.set_trace()", "\n", "", "return", "perturbed_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.augment_element": [[554, 612], ["len", "getattr.", "getattr", "tensorflow.random_uniform", "tensorflow.less", "tensorflow.cond", "method.split", "Dataset.Dataset.augment_element.apply_augmentation"], "methods", ["None"], ["", "def", "augment_element", "(", "self", ",", "*", "observation", ")", ":", "\n", "        ", "nargs", "=", "len", "(", "observation", ")", "\n", "y", "=", "None", "\n", "x_perturbed", "=", "None", "\n", "\n", "assert", "nargs", "<=", "2", ",", "\"The function expects x or (x,y) in input\"", "\n", "\n", "raw_x", "=", "observation", "[", "0", "]", "\n", "aug_x", "=", "raw_x", "\n", "if", "nargs", "==", "2", ":", "\n", "            ", "y", "=", "observation", "[", "1", "]", "\n", "\n", "", "def", "apply_augmentation", "(", "function", ",", "kwargs_tuple", ",", "x", ")", ":", "\n", "# if x_perturbed is None:", "\n", "           ", "x", "=", "function", "(", "x", ",", "**", "kwargs_tuple", ")", "\n", "return", "x", "\n", "# else:", "\n", "#     xs = function([x, x_perturbed], **kwargs_tuple)", "\n", "#     return xs", "\n", "\n", "", "for", "aug", "in", "self", ".", "_data_augmentation", ":", "\n", "\n", "            ", "method", ",", "kwargs_tuple", ",", "frequency_augmentation", "=", "aug", "\n", "function", "=", "getattr", "(", "Augmentations", ",", "method", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ")", "\n", "\n", "# determining if I will apply the data augmentation", "\n", "uniform_sample", "=", "tf", ".", "random_uniform", "(", "[", "]", ",", "0.", ",", "1.", ",", "dtype", "=", "tf", ".", "float32", ")", "#shape, min, max", "\n", "\n", "if", "frequency_augmentation", ">", "0.0", ":", "\n", "                ", "cond", "=", "tf", ".", "less", "(", "uniform_sample", ",", "frequency_augmentation", ")", "\n", "#if x_perturbed is None:", "\n", "aug_x", "=", "tf", ".", "cond", "(", "cond", ",", "\n", "lambda", ":", "apply_augmentation", "(", "function", ",", "\n", "kwargs_tuple", ",", "\n", "aug_x", ")", ",", "\n", "lambda", ":", "aug_x", ")", "\n", "# this has not been tested", "\n", "#else:", "\n", "#    (x, x_perturbed) = tf.cond(cond,", "\n", "#                               lambda: apply_augmentation(function,", "\n", "#                                                          kwargs_tuple,", "\n", "#                                                          x,", "\n", "#                                                          x_perturbed),", "\n", "#                               lambda: (x, x_perturbed))", "\n", "\n", "#if x_perturbed is None:", "\n", "#    augmented_observation = (x,)", "\n", "#else:", "\n", "#    augmented_observation = ((x, x_perturbed), )", "\n", "\n", "", "", "augmented_observation", "=", "(", "(", "raw_x", ",", "aug_x", ")", ",", ")", "\n", "\n", "if", "y", "is", "not", "None", ":", "\n", "            ", "augmented_observation", "+=", "(", "y", ",", ")", "\n", "\n", "#print(augmented_observation)", "\n", "\n", "", "return", "augmented_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_dataset_with_handle": [[695, 843], ["Dataset.Dataset.get_dataset_iterator", "datasets.append", "Dataset.Dataset.get_dataset_iterator", "datasets.append", "Dataset.Dataset.get_dataset_iterator", "datasets.append", "Dataset.Dataset.get_dataset_iterator", "datasets.append", "Dataset.Dataset.get_dataset_iterator", "datasets.append", "Dataset.Dataset.get_dataset_iterator", "datasets.append", "Dataset.Dataset.get_dataset_iterator", "datasets.append", "tensorflow.placeholder", "enumerate", "tuple", "tensorflow.data.Iterator.from_string_handle", "tensorflow.data.Iterator.from_string_handle.get_next", "zip", "shapes_equals_list.append", "zip", "numpy.all", "isinstance", "tensorflow.data.Iterator.from_string_handle.string_handle", "shapes_equals.append", "zip", "tuple.append", "zip", "tuple.append", "ds_iterators.items", "ds_iterators.items", "numpy.equal", "zip", "new_shape.append", "tuple", "new_shape.append", "new_shape.append", "ns.append", "ns.append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator"], ["def", "get_dataset_with_handle", "(", "self", ",", "batch_size_train", ",", "batch_size_eval", ")", ":", "\n", "\n", "        ", "datasets", "=", "[", "]", "\n", "#perturbed_bools = []", "\n", "\n", "# create iterators for all datasets", "\n", "train_loop_iterator", "=", "self", ".", "get_dataset_iterator", "(", "batch_size_train", ",", "\"train\"", ",", "\n", "shuffle", "=", "1", ",", "\n", "repeat", "=", "1", ",", "\n", "augment", "=", "1", ",", "\n", "perturb", "=", "1", ")", "\n", "datasets", ".", "append", "(", "train_loop_iterator", ")", "\n", "# no need to add this", "\n", "#perturbed_bools.append(train_loop_is_perturbed)", "\n", "\n", "train_iterator", "=", "self", ".", "get_dataset_iterator", "(", "batch_size_eval", ",", "\"train\"", ",", "\n", "shuffle", "=", "0", ",", "\n", "repeat", "=", "0", ",", "\n", "augment", "=", "1", ",", "\n", "perturb", "=", "1", ")", "\n", "datasets", ".", "append", "(", "train_iterator", ")", "\n", "#perturbed_bools.append(train_is_perturbed)", "\n", "\n", "validation_iterator", "=", "self", ".", "get_dataset_iterator", "(", "batch_size_eval", ",", "\"validation\"", ",", "\n", "shuffle", "=", "0", ",", "\n", "repeat", "=", "0", ",", "\n", "augment", "=", "1", ",", "\n", "perturb", "=", "1", ")", "\n", "datasets", ".", "append", "(", "validation_iterator", ")", "\n", "#perturbed_bools.append(validation_is_perturbed)", "\n", "\n", "test_iterator", "=", "self", ".", "get_dataset_iterator", "(", "batch_size_eval", ",", "\"test\"", ",", "\n", "shuffle", "=", "0", ",", "\n", "repeat", "=", "0", ",", "\n", "augment", "=", "0", ",", "\n", "perturb", "=", "0", ")", "\n", "datasets", ".", "append", "(", "test_iterator", ")", "\n", "#perturbed_bools.append(test_is_perturbed)", "\n", "\n", "# create sheffled iterators", "\n", "train_shuffled_iterator", "=", "self", ".", "get_dataset_iterator", "(", "batch_size_eval", ",", "\"train\"", ",", "\n", "shuffle", "=", "1", ",", "\n", "repeat", "=", "0", ",", "\n", "augment", "=", "1", ",", "\n", "perturb", "=", "1", ")", "\n", "datasets", ".", "append", "(", "train_shuffled_iterator", ")", "\n", "#perturbed_bools.append(train_shuffled_is_perturbed)", "\n", "validation_shuffled_iterator", "=", "self", ".", "get_dataset_iterator", "(", "batch_size_eval", ",", "\"validation\"", ",", "\n", "shuffle", "=", "1", ",", "\n", "repeat", "=", "0", ",", "\n", "augment", "=", "1", ",", "\n", "perturb", "=", "1", ")", "\n", "datasets", ".", "append", "(", "validation_shuffled_iterator", ")", "\n", "#perturbed_bools.append(validation_shuffled_is_perturbed)", "\n", "\n", "test_shuffled_iterator", "=", "self", ".", "get_dataset_iterator", "(", "batch_size_eval", ",", "\"test\"", ",", "\n", "shuffle", "=", "1", ",", "\n", "repeat", "=", "0", ",", "\n", "augment", "=", "0", ",", "\n", "perturb", "=", "0", ")", "\n", "datasets", ".", "append", "(", "test_shuffled_iterator", ")", "\n", "#perturbed_bools.append(test_shuffled_is_perturbed)", "\n", "\n", "'''\n        if all(perturbed_bools):\n            is_perturbed = True\n        elif not any(perturbed_bools):\n            is_perturbed = False\n        else:\n            raise Exception(\"datasets must be all perturbed or none perturbed. Found %s\"%str(perturbed_bools))\n        '''", "\n", "\n", "handle", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "\n", "#TODO check that output_types match", "\n", "agreed_types", "=", "train_iterator", ".", "output_types", "\n", "# I will need to check that all the datasets have the same output_shapes,", "\n", "# otherwise if they do not agree on a dimension it will be put at None", "\n", "# (we want to allow for variable input shapes if the networks permit this, e.g. a fully convolutional) (Riccardo)", "\n", "\n", "agreed_shapes", "=", "[", "]", "\n", "\n", "shapes_ref_list", "=", "datasets", "[", "0", "]", ".", "output_shapes", "\n", "shapes_equals_list", "=", "[", "]", "\n", "\n", "for", "d", "in", "datasets", ":", "\n", "            ", "shapes_list", "=", "d", ".", "output_shapes", "\n", "shapes_equals", "=", "[", "]", "\n", "for", "shape", ",", "shape_ref", "in", "zip", "(", "shapes_list", ",", "shapes_ref_list", ")", ":", "\n", "# element-wise equality", "\n", "                ", "shapes_equals", ".", "append", "(", "np", ".", "equal", "(", "shape", ",", "shape_ref", ")", ")", "\n", "#if isinstance(shape, tuple):", "\n", "#    pdb.set_trace()", "\n", "#    shapes_equals.append(np.equal([s.as_list() for s in shape], [s.as_list() for s in shape_ref]))", "\n", "#else:", "\n", "#    shapes_equals.append(np.equal(shape.as_list(), shape_ref.as_list()))", "\n", "", "shapes_equals_list", ".", "append", "(", "shapes_equals", ")", "\n", "\n", "", "for", "i_s", ",", "bools", "in", "enumerate", "(", "zip", "(", "*", "shapes_equals_list", ")", ")", ":", "\n", "            ", "shape_ref", "=", "shapes_ref_list", "[", "i_s", "]", "\n", "# element-dim_boolswise", "\n", "#pdb.set_trace()", "\n", "dim_bools", "=", "np", ".", "all", "(", "bools", ",", "axis", "=", "0", ")", "\n", "\n", "if", "isinstance", "(", "shape_ref", ",", "tuple", ")", ":", "\n", "                ", "new_shape", "=", "[", "]", "\n", "for", "sf", ",", "db", "in", "zip", "(", "shape_ref", ",", "dim_bools", ")", ":", "\n", "                    ", "ns", "=", "[", "]", "\n", "for", "dim", ",", "bool", "in", "zip", "(", "sf", ",", "db", ")", ":", "\n", "#pdb.set_trace()", "\n", "                        ", "if", "bool", ":", "\n", "                            ", "ns", ".", "append", "(", "dim", ")", "\n", "", "else", ":", "\n", "                            ", "ns", ".", "append", "(", "None", ")", "\n", "\n", "", "", "new_shape", ".", "append", "(", "ns", ")", "\n", "\n", "", "agreed_shapes", ".", "append", "(", "tuple", "(", "new_shape", ")", ")", "\n", "", "else", ":", "\n", "                ", "new_shape", "=", "[", "]", "\n", "for", "dim", ",", "bool", "in", "zip", "(", "shape_ref", ",", "dim_bools", ")", ":", "\n", "#pdb.set_trace()", "\n", "                    ", "if", "bool", ":", "\n", "                        ", "new_shape", ".", "append", "(", "dim", ")", "\n", "", "else", ":", "\n", "                        ", "new_shape", ".", "append", "(", "None", ")", "\n", "\n", "", "", "agreed_shapes", ".", "append", "(", "new_shape", ")", "\n", "\n", "", "", "agreed_shapes", "=", "tuple", "(", "agreed_shapes", ")", "\n", "\n", "# create general iterator from handle", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_string_handle", "(", "handle", ",", "agreed_types", ",", "agreed_shapes", ")", "\n", "\n", "batch_x", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "ds_iterators", "=", "{", "TRAIN_LOOP", ":", "train_loop_iterator", ",", "\n", "TRAIN", ":", "train_iterator", ",", "\n", "VALIDATION", ":", "validation_iterator", ",", "\n", "TEST", ":", "test_iterator", ",", "\n", "TRAIN_SHUFFLED", ":", "train_shuffled_iterator", ",", "\n", "VALIDATION_SHUFFLED", ":", "validation_shuffled_iterator", ",", "\n", "TEST_SHUFFLED", ":", "test_shuffled_iterator", "}", "\n", "\n", "ds_initializers", "=", "{", "key", ":", "iterator", ".", "initializer", "for", "(", "key", ",", "iterator", ")", "in", "ds_iterators", ".", "items", "(", ")", "if", "key", "!=", "TRAIN_LOOP", "}", "\n", "ds_handles", "=", "{", "key", ":", "iterator", ".", "string_handle", "(", ")", "for", "(", "key", ",", "iterator", ")", "in", "ds_iterators", ".", "items", "(", ")", "}", "\n", "\n", "return", "batch_x", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "#, is_perturbed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_raw_elements": [[847, 855], ["Dataset.check_dataset_keys_not_loop", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["", "def", "get_raw_elements", "(", "self", ",", "dataset_str", ",", "index_list", "=", "None", ")", ":", "\n", "        ", "check_dataset_keys_not_loop", "(", "dataset_str", ")", "\n", "attribute_name", "=", "dataset_str", "+", "\"_set_x\"", "\n", "if", "index_list", "is", "not", "None", ":", "\n", "            ", "x_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "[", "index_list", "]", "\n", "", "else", ":", "\n", "            ", "x_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "", "return", "x_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_raw_labels": [[858, 867], ["Dataset.check_dataset_keys_not_loop", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["", "def", "get_raw_labels", "(", "self", ",", "dataset_str", ",", "index_list", "=", "None", ")", ":", "\n", "        ", "check_dataset_keys_not_loop", "(", "dataset_str", ")", "\n", "attribute_name", "=", "dataset_str", "+", "\"_set_y\"", "\n", "if", "index_list", "is", "not", "None", ":", "\n", "            ", "y_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "[", "index_list", "]", "\n", "", "else", ":", "\n", "            ", "y_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "\n", "", "return", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements": [[869, 888], ["session.run", "len", "numpy.max", "session.run", "len", "numpy.concatenate", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "get_elements", "(", "self", ",", "node", ",", "ds_handle_node", ",", "ds_handle_value", ",", "ds_initializer", ",", "session", ",", "index_list", "=", "None", ")", ":", "\n", "        ", "session", ".", "run", "(", "ds_initializer", ")", "\n", "\n", "return_list", "=", "[", "]", "\n", "while", "index_list", "==", "None", "or", "len", "(", "return_list", ")", "<=", "np", ".", "max", "(", "index_list", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "r", "=", "session", ".", "run", "(", "[", "node", "]", ",", "feed_dict", "=", "{", "ds_handle_node", ":", "ds_handle_value", "}", ")", "\n", "\n", "if", "len", "(", "return_list", ")", "==", "0", ":", "\n", "                    ", "return_list", "=", "np", ".", "array", "(", "r", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                    ", "return_list", "=", "np", ".", "concatenate", "(", "(", "return_list", ",", "np", ".", "array", "(", "r", ")", "[", "0", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "index_list", "is", "None", ":", "\n", "            ", "return", "return_list", "\n", "", "else", ":", "\n", "            ", "return", "return_list", "[", "index_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.id": [[889, 897], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "id", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns th id of the Dataset\n\n        :return: the id\n        \"\"\"", "\n", "return", "self", ".", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.binary_input": [[898, 901], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "binary_input", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_binary_input", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.n_samples": [[902, 907], ["Dataset.check_dataset_keys_not_loop", "getattr"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["", "def", "n_samples", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "check_dataset_keys_not_loop", "(", "dataset_str", ")", "\n", "attribute_name", "=", "\"n_samples_\"", "+", "dataset_str", "\n", "n", "=", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.n_samples_train": [[908, 911], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_train_set_x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.n_samples_validation": [[912, 918], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_validation", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_validation_set_x", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "_validation_set_x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.n_samples_test": [[919, 925], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "n_samples_test", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_test_set_x", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "_test_set_x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.train_set_x": [[926, 929], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "train_set_x", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.train_set_y": [[930, 936], ["ValueError"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_set_y", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_train_set_y", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Labels not available\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_train_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.validation_set_x": [[937, 943], ["Exception"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "validation_set_x", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_validation_set_x", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Validation set not available\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_validation_set_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.validation_set_y": [[944, 953], ["Exception", "Exception"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "validation_set_y", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_validation_set_x", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Validation set not available\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "_validation_set_y", "is", "None", ":", "\n", "                ", "raise", "Exception", "(", "\"Labels not available\"", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_validation_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.test_set_x": [[954, 960], ["Exception"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "test_set_x", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_test_set_x", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Test set not available\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_test_set_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.test_set_y": [[961, 970], ["Exception", "ValueError"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "test_set_y", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_test_set_x", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Test set not available\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "_test_set_y", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Labels not available\"", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.x_shape": [[971, 975], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "x_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "x_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.x_shape_train": [[976, 980], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "train_set_x", "[", "0", "]", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.x_shape_eval": [[982, 986], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for evaluation\"\"\"", "\n", "return", "self", ".", "train_set_x", "[", "0", "]", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.y_shape": [[987, 995], ["getattr", "ValueError"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "train_set_y", "=", "getattr", "(", "self", ",", "'train_set_y'", ",", "None", ")", "\n", "if", "train_set_y", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"this dataset does not have y set\"", ")", "\n", "\n", "", "return", "train_set_y", "[", "0", "]", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.set_labels_attr": [[996, 1004], ["numpy.unique", "len"], "methods", ["None"], ["", "def", "set_labels_attr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        compute and set the labels attributes\n\n        in particular  self.labels, self.n_labels\n         \"\"\"", "\n", "self", ".", "_labels", "=", "np", ".", "unique", "(", "self", ".", "train_set_y", ")", "\n", "self", ".", "_n_labels", "=", "len", "(", "self", ".", "_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.n_labels": [[1005, 1012], ["Dataset.Dataset.set_labels_attr"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.set_labels_attr"], ["", "@", "property", "\n", "def", "n_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the number of labeles in this dataset\"\"\"", "\n", "if", "not", "self", ".", "_n_labels", ":", "\n", "            ", "self", ".", "set_labels_attr", "(", ")", "\n", "\n", "", "return", "self", ".", "_n_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.labels": [[1013, 1020], ["Dataset.Dataset.set_labels_attr"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.set_labels_attr"], ["", "@", "property", "\n", "def", "labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the list of labels in this dataset\"\"\"", "\n", "if", "not", "self", ".", "_labels", ":", "\n", "            ", "self", ".", "set_labels_attr", "(", ")", "\n", "\n", "", "return", "self", ".", "_labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop": [[54, 62], ["isinstance", "ValueError", "str", "str"], "function", ["None"], ["def", "check_dataset_keys_not_loop", "(", "datasets_keys", ")", ":", "\n", "    ", "allowed_keys_list", "=", "[", "TRAIN", ",", "VALIDATION", ",", "TEST", ",", "TRAIN_SHUFFLED", ",", "VALIDATION_SHUFFLED", ",", "TEST_SHUFFLED", "]", "\n", "if", "not", "isinstance", "(", "datasets_keys", ",", "list", ")", ":", "\n", "        ", "datasets_keys", "=", "[", "datasets_keys", "]", "\n", "\n", "", "for", "ds_key", "in", "datasets_keys", ":", "\n", "        ", "if", "ds_key", "not", "in", "allowed_keys_list", ":", "\n", "            ", "raise", "ValueError", "(", "\"specified string '%s' is not allowed, provide one of: %s \"", "%", "(", "str", "(", "ds_key", ")", ",", "str", "(", "allowed_keys_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.load_class": [[64, 83], ["importlib.import_module", "getattr", "module_plus_class.split", "module_plus_class.split"], "function", ["None"], ["", "", "", "def", "load_class", "(", "module_plus_class", ")", ":", "\n", "    ", "\"\"\"\n    from a module  import and return a class\n\n    Parameters\n    ----------\n    module_plus_class : str\n        in the form \"Module.Class\"\n\n    Returns\n    -------\n    class\n        Returns the class\n\n    \"\"\"", "\n", "\n", "my_module", "=", "importlib", ".", "import_module", "(", "\".\"", ".", "join", "(", "module_plus_class", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "my_class", "=", "getattr", "(", "my_module", ",", "module_plus_class", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ")", "\n", "return", "my_class", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.__init__": [[73, 144], ["ImageDataset.ImageDataset.__init__", "LSS_3D.LSS_3D.dataset_id", "LSS_3D.LSS_3D.compute_min_max_data", "LSS_3D.LSS_3D.load_dataset", "LSS_3D.LSS_3D.load_dataset", "LSS_3D.LSS_3D.load_dataset", "Exception", "open", "json.loads", "os.path.exists", "os.path.isdir", "f.read"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.compute_min_max_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "self", ".", "_box_size", "=", "params", "[", "\"box_size\"", "]", "\n", "self", ".", "_json_filename", "=", "\"paramslss_{}.json\"", ".", "format", "(", "self", ".", "_box_size", ")", "\n", "fraction_dataset", "=", "params", "[", "'fraction_dataset'", "]", "\n", "\n", "# self._csv_filename = \"labels_file.csv\"", "\n", "if", "fraction_dataset", "==", "100", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_LSS_data_{}.csv'", ".", "format", "(", "self", ".", "_box_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_LSS_data_{}_{}.csv'", ".", "format", "(", "self", ".", "_box_size", ",", "fraction_dataset", ")", "\n", "# label_df_Train = pd.read_csv(self._csv_filename_Train, sep=\"\\t\")", "\n", "\n", "", "self", ".", "_csv_filename_Test", "=", "'Test_LSS_data_{}.csv'", ".", "format", "(", "self", ".", "_box_size", ")", "\n", "# label_df_Test = pd.read_csv(self._csv_filename_Test, sep=\"\\t\")", "\n", "\n", "self", ".", "_csv_filename_Validation", "=", "'Validation_LSS_data_{}.csv'", ".", "format", "(", "self", ".", "_box_size", ")", "\n", "# label_df_Validation = pd.read_csv(self._csv_filename_Validation, sep=\"\\t\")", "\n", "\n", "# self._all_parameter_list = ['h', 'omega_b', 'omega_cdm', 'A_s', 'n_s', 'tau_reio']", "\n", "self", ".", "_parameters_list", "=", "params", "[", "\"parameters\"", "]", "\n", "self", ".", "_fraction_dataset", "=", "params", "[", "\"fraction_dataset\"", "]", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_normalize_labels", "=", "self", ".", "_params", "[", "'normalize_labels'", "]", "\n", "self", ".", "_normalize_images", "=", "self", ".", "_params", "[", "'normalize_images'", "]", "\n", "\n", "\n", "# check if the data directory is present", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_data_dir", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_data_dir", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Dataset directory {}'", "\n", "' not found'", ".", "format", "(", "self", ".", "_data_dir", ")", "\n", ")", "\n", "\n", "#self._debug_mode = params['debug_mode']", "\n", "\n", "#self._augment_data = params['augm_data']", "\n", "#self._only_center = params['only_center']", "\n", "", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "self", ".", "_json_filename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "picture_size", "=", "conf_dict", "[", "\"pic_size\"", "]", "\n", "self", ".", "_x_sample_shape", "=", "(", "picture_size", ",", "picture_size", ",", "picture_size", ",", "1", ")", "\n", "#self._y_sample_shape = (self._n_params,)", "\n", "\n", "#self._var_params = self.conf_dict['params'] # TODO Check that is sorted like self.parameter_list", "\n", "\n", "# useful for lazy load, however I need to reimplement some methods to make it work", "\n", "# self._loaded_from_disk = False", "\n", "\n", "#self._train_set_x = None", "\n", "#self._train_set_y = None", "\n", "#self._test_set_x = None", "\n", "#self._test_set_y = None", "\n", "\n", "#self._n_samples_train = None", "\n", "#self._n_samples_test = None", "\n", "self", ".", "_labels_min", ",", "self", ".", "_labels_max", ",", "self", ".", "_data_min", ",", "self", ".", "_data_max", "=", "self", ".", "compute_min_max_data", "(", "norm_labels", "=", "self", ".", "_normalize_labels", ",", "\n", "norm_data", "=", "self", ".", "_normalize_images", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "load_dataset", "(", "TRAIN", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "load_dataset", "(", "VALIDATION", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset", "(", "TEST", ")", "\n", "\n", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "# self._shuffling_cache = 3000", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.dataset_id": [[148, 180], ["os.path.basename", "str", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "# CMB.check_params_impl(params)", "\n", "\n", "p_dist_abbr", "=", "{", "'uniform'", ":", "'U'", ",", "\n", "'lattice'", ":", "'L'", "}", "\n", "\n", "id", "=", "'LSS-'", "\n", "id", "+=", "os", ".", "path", ".", "basename", "(", "params", "[", "'data_dir'", "]", ")", "\n", "id", "+=", "'-d%'", "+", "str", "(", "params", "[", "'fraction_dataset'", "]", ")", "\n", "id", "+=", "'-box_'", "+", "str", "(", "params", "[", "'box_size'", "]", ")", "\n", "id", "+=", "'-n'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_images'", "]", "==", "True", "else", "'0'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_labels'", "]", "==", "True", "else", "'0'", "\n", "#id += '-au1' if self._augment_data == True  else '-au0'", "\n", "#id += '-oc1' if self._only_center == True else '-oc0'", "\n", "\n", "# id += '-pdim' + str(params['params_dim'])", "\n", "# id += '-' + p_dist_abbr[params['par_distr']]", "\n", "# id += '-pprr' + str(params['pic_per_run_rot'])", "\n", "# id += '-ppre' + str(params['pic_per_run_equator'])", "\n", "\n", "# id note (keep last)", "\n", "#if params['id_note']:", "\n", "#    id += params['id_note']", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.read_metadata": [[182, 192], ["pandas.read_csv", "open", "json.loads", "f.read"], "methods", ["None"], ["", "def", "read_metadata", "(", "self", ",", "json_basename", ",", "csv_basename", ")", ":", "\n", "#load json file", "\n", "        ", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "json_basename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "csv_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "csv_basename", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "return", "conf_dict", ",", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.get_output_shapes": [[194, 199], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "1", ",", ")", ",", "datasets_tuple", "[", "1", "]", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.get_output_types": [[200, 205], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "as_dtype", "(", "datasets_tuple", "[", "1", "]", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.dataset_map": [[209, 236], ["LSS_3D.LSS_3D.get_output_types", "list", "dataset.map.map.map", "numpy.load", "numpy.expand_dims", "zip", "numpy.expand_dims.astype", "tuple", "tensorflow.py_func", "numpy.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "norm_bool", "=", "self", ".", "_normalize_images", "\n", "data_min", "=", "self", ".", "_data_min", "\n", "data_max", "=", "self", ".", "_data_max", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "label", "=", "full_data", "[", "n", "]", "[", "1", "]", "\n", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "filename", ")", "\n", "if", "norm_bool", ":", "\n", "#image = 2*(image-data_min)/(data_max-data_min) - 1", "\n", "                ", "image", "=", "5", "*", "(", "2", "*", "np", ".", "log", "(", "image", "-", "data_min", "+", "1", ")", "/", "np", ".", "log", "(", "data_max", "-", "data_min", "+", "1", ")", "-", "1.", "/", "4.", ")", "\n", "", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "label", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.load_dataset": [[238, 326], ["LSS_3D.LSS_3D.read_metadata", "len", "print", "df_dataset[].values.astype", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.read_metadata"], ["", "def", "load_dataset", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "\"\"\"\n        load the dataset in memory and set in the object\n\n        Args:\n            train_test_ratio: (float) percentage of the dataset in train\n\n        \"\"\"", "\n", "json_filename", "=", "self", ".", "_json_filename", "\n", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Train", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Validation", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Test", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"`dataset_str` can be only: train, validation or test.\"", ")", "\n", "\n", "# get info from the metadata", "\n", "", "conf_dict", ",", "labels_filter_df", "=", "self", ".", "read_metadata", "(", "json_filename", ",", "csv_filename", ")", "\n", "#self._picture_size = self.conf_dict['pic_size']", "\n", "n_parameters", "=", "len", "(", "conf_dict", ")", "\n", "\n", "#if self._only_center:", "\n", "#    labels_filter_df = labels_filter_df[labels_filter_df['is_center']]", "\n", "\n", "#if not self._augment_data:", "\n", "#    # no rotations", "\n", "#    is_no_rotation = labels_filter_df['rot_angle'] == 0", "\n", "#    labels_filter_df = labels_filter_df[is_no_rotation]", "\n", "\n", "#    # no flips", "\n", "#    index_no_flip = ~labels_filter_df['flip']", "\n", "#    labels_filter_df = labels_filter_df[index_no_flip]", "\n", "\n", "\n", "'''\n        if self._debug_mode:\n            debug_dimension = 500\n            labels_filter_df = labels_filter_df.iloc[:debug_dimension]\n        '''", "\n", "\n", "# dataset_x = labels_filter_df.sample(frac=1)", "\n", "df_dataset", "=", "labels_filter_df", "\n", "num_files", "=", "df_dataset", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'{} are going to be loaded in memory'", ".", "format", "(", "num_files", ")", ")", "\n", "\n", "filename_dataset", "=", "df_dataset", "[", "'filename'", "]", ".", "values", "\n", "labels_dataset", "=", "df_dataset", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "\n", "if", "self", ".", "_normalize_labels", ":", "\n", "            ", "labels_dataset", "=", "2", "*", "(", "labels_dataset", "-", "self", ".", "_labels_min", ")", "/", "(", "self", ".", "_labels_max", "-", "self", ".", "_labels_min", ")", "-", "1.", "\n", "\n", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "# dim_train = int(num_files * train_ratio)", "\n", "# dim_validation = int(num_files * validation_ratio)", "\n", "# dim_test = num_files - dim_train - dim_validation", "\n", "#", "\n", "# # training", "\n", "# df_train = dataset_x.iloc[0 : dim_train]", "\n", "# filename_training = df_train['filename'].values", "\n", "# labels_training = df_train[['omega_cdm', 'A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     max_training = np.max(labels_training, axis=0)", "\n", "#     min_training = np.min(labels_training, axis=0)", "\n", "#     labels_training = (labels_training - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_validation = dataset_x.iloc[dim_train : (dim_train+dim_validation)]", "\n", "# filename_validation = df_validation['filename'].values", "\n", "# labels_validation = df_validation[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_validation = (labels_validation - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_test = dataset_x.iloc[(dim_train+dim_validation):]", "\n", "# filename_test = df_test['filename'].values", "\n", "# labels_test = df_test[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_test = (labels_test - min_training)/(max_training - min_training)", "\n", "#", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "\n", "", "return", "filename_dataset", ",", "labels_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.compute_min_max_data": [[327, 356], ["pandas.read_csv", "numpy.min", "numpy.max", "label_df[].values.astype", "numpy.min", "numpy.max", "numpy.load", "all_min.append", "all_max.append", "numpy.min", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "compute_min_max_data", "(", "self", ",", "norm_labels", "=", "False", ",", "norm_data", "=", "False", ")", ":", "\n", "        ", "all_max", "=", "[", "]", "\n", "all_min", "=", "[", "]", "\n", "csv_filename", "=", "self", ".", "_data_dir", "+", "'/latin_hypercube_{}.csv'", ".", "format", "(", "self", ".", "_box_size", ")", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "labels_min", "=", "None", "\n", "labels_max", "=", "None", "\n", "data_min", "=", "None", "\n", "data_max", "=", "None", "\n", "\n", "if", "norm_data", ":", "\n", "            ", "filenames", "=", "label_df", "[", "'filename'", "]", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "                ", "patch1", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "\"/\"", "+", "filename", ")", "\n", "\n", "all_min", ".", "append", "(", "np", ".", "min", "(", "patch1", ")", ")", "\n", "all_max", ".", "append", "(", "np", ".", "max", "(", "patch1", ")", ")", "\n", "\n", "", "data_min", "=", "np", ".", "min", "(", "all_min", ")", "\n", "data_max", "=", "np", ".", "max", "(", "all_max", ")", "\n", "\n", "", "if", "norm_labels", ":", "\n", "            ", "labels", "=", "label_df", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "labels_min", "=", "np", ".", "min", "(", "labels", ",", "axis", "=", "0", ")", "\n", "labels_max", "=", "np", ".", "max", "(", "labels", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "labels_min", ",", "labels_max", ",", "data_min", ",", "data_max", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.labels_min_training": [[357, 369], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_min_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#", "\n", "#if  self._dataset_x_min is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "\n", "        ", "return", "self", ".", "_labels_min_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.labels_max_training": [[370, 381], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_max_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#\u00a7", "\n", "#if  self._dataset_x_max is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "        ", "return", "self", ".", "_labels_max_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.x_shape_train": [[382, 386], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.LSS_3D.LSS_3D.x_shape_eval": [[387, 439], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the evaluation\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_train(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_eval(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "#return mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels, mnist.test.images, mnist.test.labels", "\n", "\n", "\n", "#start_time_data = timeit.default_timer()", "\n", "\n", "#shape_X = (n_files,) + self._x_sample_shape", "\n", "#shape_Y = (n_files,) + self._y_sample_shape", "\n", "\n", "# construct the datasets", "\n", "#X = np.empty(shape_X)", "\n", "#Y = np.empty(shape_Y)", "\n", "\n", "#for ix, row in  labels_filter_df.iterrows():", "\n", "#    tmp_numpy = np.load(self._data_dir + \"/\" + row['filename'])", "\n", "#", "\n", "#    X[ix, :, :, 0] = tmp_numpy", "\n", "#    Y[ix] = row[self._var_params]", "\n", "\n", "# print time for the load", "\n", "#step_time = timeit.default_timer()", "\n", "#print(\"time needed to load: \", step_time - start_time_data)", "\n", "\n", "# shuffle the dataset", "\n", "'''\n        randomized_dataset_index = np.random.permutation(n_files)\n        X = X[randomized_dataset_index]\n        Y = Y[randomized_dataset_index]\n\n\n\n\n\n\n        dim_train = int(n_files * train_test_ratio)\n        self._train_set_x, self._train_set_y = X[:dim_train] , Y[:dim_train]\n        self._test_set_x, self._test_set_y = X[dim_train:], Y[dim_train:]\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.FashionMNIST.FashionMNIST.__init__": [[40, 99], ["ImageDataset.ImageDataset.__init__", "FashionMNIST.FashionMNIST.dataset_id", "FashionMNIST.FashionMNIST.load_data", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "FashionMNIST.FashionMNIST.class_filter", "FashionMNIST.FashionMNIST.class_filter", "FashionMNIST.FashionMNIST.class_filter", "FashionMNIST.FashionMNIST.sub_sample", "FashionMNIST.FashionMNIST.sub_sample", "FashionMNIST.FashionMNIST.sub_sample", "numpy.clip", "numpy.clip", "numpy.clip", "FashionMNIST.FashionMNIST._train_set_x.reshape", "FashionMNIST.FashionMNIST._validation_set_x.reshape", "FashionMNIST.FashionMNIST._test_set_x.reshape", "FashionMNIST.FashionMNIST._train_set_x.reshape", "FashionMNIST.FashionMNIST._validation_set_x.reshape", "FashionMNIST.FashionMNIST._test_set_x.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "False", "\n", "\n", "default_data_dir", "=", "'/data1/datasets/FashionMNIST'", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", ")", "\n", "\n", "#normalize data", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "]", ")", "\n", "self", ".", "_train_set_x", "=", "normalize", "(", "self", ".", "_train_set_x", ",", "all_min", ",", "all_max", ")", "\n", "self", ".", "_validation_set_x", "=", "normalize", "(", "self", ".", "_validation_set_x", ",", "all_min", ",", "all_max", ")", "\n", "self", ".", "_test_set_x", "=", "normalize", "(", "self", ".", "_test_set_x", ",", "all_min", ",", "all_max", ")", "\n", "\n", "\n", "# filter classes", "\n", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n", "", "if", "self", ".", "_params", "[", "'vect'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "784", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "784", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "784", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "_train_set_x", "=", "self", ".", "_train_set_x", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "_validation_set_x", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "_test_set_x", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.FashionMNIST.FashionMNIST.dataset_id": [[104, 154], ["FashionMNIST.check_params_impl", "str", "list", "range", "str", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "\n", "FashionMNIST", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'FashionMNIST'", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subclasses", "\n", "if", "(", "'classes'", "in", "params", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "10", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in FashionMNIST\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.FashionMNIST.FashionMNIST.load_data": [[155, 164], ["tensorflow.examples.tutorials.mnist.input_data.read_data_sets"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", ")", ":", "\n", "# this needs to be rewritten based on the warning you get in TF", "\n", "        ", "data", "=", "input_data", ".", "read_data_sets", "(", "'/ssd_data/datasets/fashionMNIST'", ",", "\n", "source_url", "=", "'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'", ")", "\n", "\n", "return", "data", ".", "train", ".", "images", ",", "data", ".", "train", ".", "labels", ",", "data", ".", "validation", ".", "images", ",", "data", ".", "validation", ".", "labels", ",", "data", ".", "test", ".", "images", ",", "data", ".", "test", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.FashionMNIST.FashionMNIST.sub_sample": [[165, 184], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_data", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_data", "=", "np", ".", "random", ".", "permutation", "(", "len_data", ")", "\n", "new_len_data", "=", "int", "(", "len_data", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.FashionMNIST.FashionMNIST.label_to_name": [[185, 197], ["None"], "methods", ["None"], ["", "def", "label_to_name", "(", "self", ",", "label", ")", ":", "\n", "        ", "label_to_name_F_dict", "=", "{", "0", ":", "\"T-shirt/top\"", ",", "\n", "1", ":", "\"Trouser\"", ",", "\n", "2", ":", "\"Pullover\"", ",", "\n", "3", ":", "\"Dress\"", ",", "\n", "4", ":", "\"Coat\"", ",", "\n", "5", ":", "\"Sandal\"", ",", "\n", "6", ":", "\"Shirt\"", ",", "\n", "7", ":", "\"Sneaker\"", ",", "\n", "8", ":", "\"Bag\"", ",", "\n", "9", ":", "\"Ankle boot\"", "}", "\n", "return", "label_to_name_F_dict", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ImageDataset.ImageDataset.__init__": [[13, 15], ["Dataset.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.ImageDataset.ImageDataset.image_shape": [[17, 20], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "x_shape", "# 1 is the number of channels", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.load": [[8, 31], ["dict", "synthetic_regr.generate_dataset", "len", "int", "int", "int", "int", "int", "int", "len"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.generate_dataset"], ["", "def", "load", "(", "params", ")", ":", "\n", "\n", "# strip from parameters unsupported features", "\n", "    ", "supported_options", "=", "(", "'dataset_type'", ",", "'n_features'", ",", "'n_points'", ",", "'extrema'", ",", "'seed'", ",", "'custom_x'", ",", "'custom_y'", ")", "\n", "fun_params", "=", "dict", "(", "(", "k", ",", "params", "[", "k", "]", ")", "for", "k", "in", "supported_options", "if", "k", "in", "params", ")", "\n", "\n", "# Generate the dataset:", "\n", "x", ",", "y", "=", "generate_dataset", "(", "**", "fun_params", ")", "\n", "\n", "\n", "percentage_train", "=", "0.7", "if", "'percentage_train'", "not", "in", "params", "else", "params", "[", "'percentage_train'", "]", "\n", "n_points", "=", "len", "(", "y", ")", "\n", "dase", "=", "{", "\"n_samples_train\"", ":", "int", "(", "percentage_train", "*", "n_points", ")", ",", "\n", "\"n_samples_test\"", ":", "n_points", "-", "int", "(", "percentage_train", "*", "n_points", ")", ",", "\n", "\"train_set_x\"", ":", "x", "[", ":", "int", "(", "percentage_train", "*", "n_points", ")", "]", ",", "\n", "\"train_set_y\"", ":", "y", "[", ":", "int", "(", "percentage_train", "*", "n_points", ")", "]", ",", "\n", "\"test_set_x\"", ":", "x", "[", "int", "(", "percentage_train", "*", "n_points", ")", ":", "]", ",", "\n", "\"test_set_y\"", ":", "y", "[", "int", "(", "percentage_train", "*", "n_points", ")", ":", "]", ",", "\n", "\"input_size\"", ":", "x", ".", "shape", "[", "1", "]", ",", "\n", "\"output_size\"", ":", "y", ".", "shape", "[", "1", "]", "if", "len", "(", "y", ".", "shape", ")", ">", "1", "else", "1", ",", "\n", "\"binary\"", ":", "0", "}", "\n", "\n", "return", "dase", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.generate_dataset": [[35, 92], ["synthetic_regr.sample_features", "numpy.random.seed", "numpy.random.normal", "numpy.ones", "numpy.ones", "numpy.matmul", "numpy.ones", "numpy.sin", "numpy.sum", "len"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.sample_features", "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed"], ["", "def", "generate_dataset", "(", "\n", "dataset_type", "=", "'sin_sym'", ",", "\n", "n_features", "=", "2", ",", "n_dep_variables", "=", "1", ",", "\n", "n_points", "=", "1000", ",", "\n", "extrema", "=", "(", "0", ",", "1", ")", ",", "\n", "seed", "=", "-", "1", ",", "\n", "custom_x", "=", "None", ",", "custom_y", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    generate a dataset for regression of arbitrary dimension.\n    Linear, polinomial and exponential or generate tge dataset dictionary from custom values\n\n    :param dataset_type:    choose the tipe of function::\n                            'white_noise' - dependent variable normally distributed\n                            'linear'      - a linear plane of the form :math:`y = A x + b`, A and B are filled with ones\n                            'sin_sym'     - a very non linear sinusoidal shape :math:`y = b \\sin (x^2)`\n                            'custom_xy'   - create a dataset from custom_x and custom_y\n    :param n_features:      dimension of the input space\n    :param n_dep_variables: dimension of the output space\n    :param n_points:        number of points to be generated\n    :param extrema:         the sampling space of the dependent variables.\n                            if (min,max) it describes the coordinates of the vertices of the (hyper-)cube\n                            if ((min_1,max_1),...,(min_n_features,max_n_features)) set the coordinates of the (hyper-)parallelepiped\n    :param seed:            set the seed\n\n    :param custom_x         generate dataset once provided x\n    :param custom_y         generate dataset once provided y\n\n    :return:                an array of feature data and an array of the dependent variables\n\n\n    TODO: Possible improvments, add parameters to the functios\n\n    \"\"\"", "\n", "\n", "if", "seed", "!=", "-", "1", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "", "x_points", "=", "sample_features", "(", "n_features", ",", "n_points", ",", "extrema", ",", "seed", ")", "\n", "if", "dataset_type", "==", "'white_noise'", ":", "\n", "        ", "y_points", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "(", "n_points", ",", "n_dep_variables", ")", ")", "\n", "\n", "", "elif", "dataset_type", "==", "'linear'", ":", "\n", "        ", "A", "=", "np", ".", "ones", "(", "shape", "=", "(", "x_points", ".", "shape", "[", "1", "]", ",", "n_dep_variables", ")", ")", "\n", "b", "=", "np", ".", "ones", "(", "shape", "=", "(", "n_dep_variables", ")", ")", "\n", "y_points", "=", "(", "np", ".", "matmul", "(", "x_points", ",", "A", ")", "+", "b", ")", "\n", "\n", "", "elif", "dataset_type", "==", "'sin_sym'", ":", "\n", "        ", "b", "=", "np", ".", "ones", "(", "shape", "=", "(", "n_dep_variables", ")", ")", "\n", "y_points", "=", "np", ".", "sin", "(", "np", ".", "sum", "(", "x_points", "**", "2", ",", "axis", "=", "1", ")", ")", "\n", "\n", "", "elif", "dataset_type", "==", "'custom_xy'", ":", "\n", "        ", "assert", "(", "custom_x", ".", "shape", "[", "0", "]", "==", "len", "(", "y", ")", ")", ",", "'input and target do not match'", "\n", "x_points", "=", "custom_x", "\n", "y_points", "=", "custom_y", "\n", "\n", "\n", "", "return", "x_points", ",", "y_points", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.synthetic_regr.sample_features": [[94, 136], ["numpy.array", "numpy.random.seed", "numpy.random.uniform", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed"], ["", "def", "sample_features", "(", "\n", "n_features", "=", "2", ",", "\n", "n_points", "=", "1000", ",", "\n", "extrema", "=", "(", "0", ",", "1", ")", ",", "\n", "seed", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"\n    generate samples of the feature space or x space\n\n    :param n_features:      dimension of the input space\n    :param n_dep_variables: dimension of the output space\n    :param n_points:        number of points to be generated\n    :param extrema:         the sampling space of the dependent variables.\n                            if (min,max) it describes the coordinates of the vertices of the (hyper-)cube\n                            if ((min_1,max_1),...,(min_n_features,max_n_features)) set the coordinates of the (hyper-)parallelepiped\n    :param seed:            set the seed\n\n    :return:                an array of x points\n                            rows are single points in the x space\n    \"\"\"", "\n", "if", "seed", "!=", "-", "1", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "\n", "", "extrema_np", "=", "np", ".", "array", "(", "extrema", ")", "\n", "if", "extrema_np", ".", "shape", "==", "(", "2", ",", ")", ":", "\n", "# extrema with form (min,max)", "\n", "        ", "min_x", ",", "max_x", "=", "extrema", "\n", "\n", "# every row represents a datapoint", "\n", "x_points", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "min_x", ",", "high", "=", "max_x", ",", "size", "=", "(", "n_points", ",", "n_features", ")", ")", "\n", "", "else", ":", "\n", "# extrema with form ((min_1,max_1),...,(min_n_features,max_n_features))", "\n", "        ", "assert", "(", "extrema_np", ".", "shape", "[", "1", "]", "==", "2", ")", ",", "'extrema with wrong shape'", "\n", "if", "n_features", "!=", "2", ":", "\n", "            ", "assert", "(", "n_features", "==", "extrema_np", ".", "shape", "[", "0", "]", ")", ",", "'extrema is not compatible with n_features'", "\n", "\n", "", "n_features", "=", "extrema_np", ".", "shape", "[", "0", "]", "\n", "\n", "x_points", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "extrema_np", "[", ":", ",", "0", "]", ",", "high", "=", "extrema_np", "[", ":", ",", "1", "]", ",", "size", "=", "(", "n_points", ",", "n_features", ")", ")", "\n", "\n", "\n", "", "return", "x_points", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SVHN.SVHN.__init__": [[43, 96], ["ImageDataset.ImageDataset.__init__", "SVHN.SVHN.dataset_id", "SVHN.SVHN.load_data", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "SVHN.SVHN.class_filter", "SVHN.SVHN.class_filter", "SVHN.SVHN.class_filter", "SVHN.SVHN.sub_sample", "SVHN.SVHN.sub_sample", "SVHN.SVHN.sub_sample", "numpy.clip", "numpy.clip", "numpy.clip", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "False", "\n", "\n", "default_data_dir", "=", "'/ssd_data/datasets/SVHN'", "\n", "self", ".", "data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", "self", ".", "data_dir", ")", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "\n", "#normalize data", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "]", ")", "\n", "self", ".", "_train_set_x", "=", "normalize", "(", "self", ".", "_train_set_x", ",", "all_min", ",", "all_max", ")", "\n", "self", ".", "_validation_set_x", "=", "normalize", "(", "self", ".", "_validation_set_x", ",", "all_min", ",", "all_max", ")", "\n", "self", ".", "_test_set_x", "=", "normalize", "(", "self", ".", "_test_set_x", ",", "all_min", ",", "all_max", ")", "\n", "\n", "# filter classes", "\n", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n", "", "if", "self", ".", "_params", "[", "'vect'", "]", ":", "\n", "            ", "raise", "Exception", "(", "\"Not implemented\"", ")", "\n", "#size = no.prod(self._train_set_x.shape[1:])", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SVHN.SVHN.dataset_id": [[110, 160], ["SVHN.check_params_impl", "str", "list", "range", "str", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "\n", "SVHN", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'SVHN'", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subclasses", "\n", "if", "(", "'classes'", "in", "params", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "10", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in SVHN\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SVHN.SVHN.load_data": [[161, 222], ["scipy.io.loadmat", "scipy.io.loadmat", "os.stat", "os.path.exists", "print", "urllib.request.urlretrieve", "os.path.exists", "print", "urllib.request.urlretrieve", "numpy.moveaxis().astype", "numpy.moveaxis().astype", "os.mkdir", "numpy.moveaxis", "numpy.moveaxis"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "save_to_path", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "stat", "(", "save_to_path", ")", "\n", "", "except", ":", "\n", "            ", "os", ".", "mkdir", "(", "save_to_path", ")", "\n", "\n", "#filename = save_to_path + \"/train.tar.gz\"", "\n", "#if not os.path.exists(save_to_path + \"/train\"):", "\n", "#    print(\"Downloading train.tar.gz ...\")", "\n", "#    urllib.request.urlretrieve(\"http://ufldl.stanford.edu/housenumbers/train.tar.gz\", filename)", "\n", "#    print(\"Extracting train.tar.gz ...\")", "\n", "#    tar = tarfile.open(filename)", "\n", "#    tar.extractall(path=save_to_path)", "\n", "#    tar.close()", "\n", "\n", "# see http://ufldl.stanford.edu/housenumbers/", "\n", "\n", "", "filename", "=", "save_to_path", "+", "\"/train_32x32.mat\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "print", "(", "\"Downloading train_32x32.mat ...\"", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\"", ",", "filename", ")", "\n", "\n", "", "filename", "=", "save_to_path", "+", "\"/test_32x32.mat\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "print", "(", "\"Downloading test_32x32.mat ...\"", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "\"http://ufldl.stanford.edu/housenumbers/test_32x32.mat\"", ",", "filename", ")", "\n", "\n", "# My uncomment", "\n", "# filename = save_to_path + \"/extra_32x32.mat\"", "\n", "# if not os.path.exists(filename):", "\n", "#     print(\"Downloading extra_32x32.mat ...\")", "\n", "#     urllib.request.urlretrieve(\"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\", filename)", "\n", "\n", "", "train", "=", "load", "(", "save_to_path", "+", "\"/train_32x32.mat\"", ")", "\n", "test", "=", "load", "(", "save_to_path", "+", "\"/test_32x32.mat\"", ")", "\n", "# My uncomment", "\n", "#extra = load(save_to_path + \"/extra_32x32.mat\")", "\n", "\n", "#train['y'].shape", "\n", "#(73257, 1)", "\n", "#train['X'].shape", "\n", "#(32, 32, 3, 73257)", "\n", "\n", "# change axis", "\n", "train", "[", "'X'", "]", "=", "np", ".", "moveaxis", "(", "train", "[", "'X'", "]", ",", "3", ",", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255", "\n", "test", "[", "'X'", "]", "=", "np", ".", "moveaxis", "(", "test", "[", "'X'", "]", ",", "3", ",", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255", "\n", "# My uncomment", "\n", "#extra['X'] = np.moveaxis(extra['X'], 3, 0).astype(np.float32) / 255", "\n", "\n", "train", "[", "'X'", "]", "=", "2", "*", "train", "[", "'X'", "]", "-", "1", "\n", "test", "[", "'X'", "]", "=", "2", "*", "test", "[", "'X'", "]", "-", "1", "\n", "# My uncomment", "\n", "#extra['X'] = 2 * extra['X'] - 1", "\n", "\n", "# points in the train_set", "\n", "n", "=", "50000", "\n", "\n", "# extra is ignored, since the images are too simple", "\n", "return", "train", "[", "'X'", "]", "[", ":", "n", "]", ",", "train", "[", "'y'", "]", "[", ":", "n", "]", "[", ":", ",", "0", "]", "-", "1", ",", "train", "[", "'X'", "]", "[", "n", ":", "]", ",", "train", "[", "'y'", "]", "[", "n", ":", "]", "[", ":", ",", "0", "]", "-", "1", ",", "test", "[", "'X'", "]", ",", "test", "[", "'y'", "]", "[", ":", ",", "0", "]", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SVHN.SVHN.sub_sample": [[223, 242], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_data", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_data", "=", "np", ".", "random", ".", "permutation", "(", "len_data", ")", "\n", "new_len_data", "=", "int", "(", "len_data", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_data", "[", ":", "new_len_data", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.__init__": [[22, 45], ["datasets.ImageDataset.ImageDataset.__init__", "BrainDataset.BrainDataset.dataset_id", "BrainDataset.BrainDataset._params.keys", "BrainDataset.BrainDataset._params.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "\n", "default_data_dir", "=", "''", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "\n", "if", "'resize'", "in", "self", ".", "_params", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_resize", "=", "self", ".", "_params", "[", "'resize'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_resize", "=", "None", "\n", "\n", "", "if", "'modalities'", "in", "self", ".", "_params", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_modalities", "=", "self", ".", "_params", "[", "'modalities'", "]", "\n", "\n", "if", "self", ".", "_modalities", "[", "0", "]", "==", "'SEG'", ":", "\n", "                ", "self", ".", "use_mask", "=", "True", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_modalities", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.dataset_id": [[46, 64], ["BrainDataset.check_params_impl", "params.keys", "params.keys", "params.keys", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "BrainDataset", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "''", "\n", "if", "'options'", "in", "params", ".", "keys", "(", ")", ":", "\n", "            ", "id", "+=", "'-'", "+", "params", "[", "'options'", "]", "\n", "\n", "", "if", "'modalities'", "in", "params", ".", "keys", "(", ")", ":", "\n", "            ", "id", "+=", "'-'", "+", "'_'", ".", "join", "(", "params", "[", "'modalities'", "]", ")", "\n", "\n", "", "if", "'resize'", "in", "params", ".", "keys", "(", ")", ":", "\n", "            ", "id", "+=", "'-'", "+", "str", "(", "params", "[", "'resize'", "]", ")", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_float_brains": [[65, 87], ["BrainDataset.BrainDataset.load_file_names", "print", "BrainDataset.BrainDataset.load_file_names", "print", "BrainDataset.BrainDataset.load_file_names", "print", "print", "print", "len", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_float_brains", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "datasets_tuple", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'train'", ")", "\n", "print", "(", "'---------DATASET TUPLE------------'", ",", "datasets_tuple", ".", "shape", ")", "\n", "\n", "train_set_x", "=", "datasets_tuple", "\n", "\n", "datasets_tuple_validation", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'validation'", ")", "\n", "print", "(", "'---------DATASET TUPLE VALIDATION------------'", ",", "datasets_tuple_validation", ".", "shape", ")", "\n", "\n", "validation_set_x", "=", "datasets_tuple_validation", "\n", "\n", "datasets_tuple_test", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'test'", ")", "\n", "print", "(", "'---------DATASET TUPLE TEST------------'", ",", "datasets_tuple_test", ".", "shape", ")", "\n", "\n", "test_set_x", "=", "datasets_tuple_test", "\n", "\n", "print", "(", "'--------------X SHAPE-----------------'", ")", "\n", "channels_no", "=", "len", "(", "self", ".", "_modalities", ")", "if", "self", ".", "_modalities", "!=", "None", "else", "1", "\n", "self", ".", "_train_set_x_shape", "=", "np", ".", "load", "(", "data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", ")", ".", "shape", "+", "(", "channels_no", ",", ")", "\n", "print", "(", "self", ".", "_train_set_x_shape", ")", "\n", "\n", "return", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_file_names": [[88, 100], ["os.walk", "numpy.asarray", "fnmatch.filter", "numpy.asarray.append", "numpy.asarray.append", "str"], "methods", ["None"], ["", "def", "load_file_names", "(", "self", ",", "root", ",", "data_type", ")", ":", "\n", "        ", "file_names", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", "+", "'/'", "+", "data_type", ")", ":", "\n", "            ", "if", "self", ".", "_modalities", "!=", "None", ":", "\n", "                ", "reg_filter", "=", "'*_'", "+", "str", "(", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ")", "+", "'_*'", "\n", "for", "f", "in", "fnmatch", ".", "filter", "(", "files", ",", "reg_filter", ")", ":", "\n", "                    ", "file_names", ".", "append", "(", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "f", "in", "files", ":", "\n", "                    ", "file_names", ".", "append", "(", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "", "file_names", "=", "np", ".", "asarray", "(", "file_names", ")", "\n", "return", "file_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_slice_from_file": [[101, 106], ["numpy.load", "numpy.asarray.astype", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slice_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slice", "=", "np", ".", "load", "(", "file", ")", "\n", "slice", "=", "slice", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slice", "=", "np", ".", "asarray", "(", "slice", ")", "\n", "return", "slice", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_slices_from_file": [[107, 112], ["numpy.load", "numpy.asarray.astype", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slices_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slices", "=", "np", ".", "load", "(", "file", ")", "\n", "slices", "=", "slices", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slices", "=", "np", ".", "asarray", "(", "slices", ")", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.dataset_map": [[114, 150], ["BrainDataset.BrainDataset.get_output_types", "BrainDataset.BrainDataset.get_output_shapes", "list", "dataset.map.map.map", "numpy.empty", "tuple", "zip", "enumerate", "BrainDataset.BrainDataset.load_slice_from_file", "numpy.array.reshape", "tensorflow.py_func", "str.replace", "BrainDataset.BrainDataset.load_slice_from_file", "numpy.array", "str", "numpy.array", "str", "PIL.Image.fromarray().resize", "str", "PIL.Image.fromarray().resize", "PIL.Image.fromarray", "PIL.Image.fromarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "result", "=", "np", ".", "empty", "(", "output_shapes", "[", "0", "]", ",", "np", ".", "float32", ")", "\n", "if", "self", ".", "_modalities", "is", "not", "None", ":", "\n", "                ", "for", "i", ",", "modality", "in", "enumerate", "(", "self", ".", "_modalities", ")", ":", "\n", "                    ", "modality_filename", "=", "str", ".", "replace", "(", "str", "(", "filename", ")", ",", "modalities", "[", "self", ".", "_modalities", "[", "0", "]", "]", ",", "\n", "modalities", "[", "modality", "]", ")", "\n", "image", "=", "self", ".", "load_slice_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "modality_filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                        ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "result", "[", ":", ",", ":", ",", "i", "]", "=", "image", "\n", "", "", "else", ":", "\n", "                ", "image", "=", "self", ".", "load_slice_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "filename", ")", ")", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "                    ", "image", "=", "np", ".", "array", "(", "\n", "PIL", ".", "Image", ".", "fromarray", "(", "image", ")", ".", "resize", "(", "[", "self", ".", "_resize", ",", "self", ".", "_resize", "]", ")", ")", "\n", "", "result", "=", "image", ".", "reshape", "(", "[", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "", "return", "result", "\n", "\n", "", "def", "apply_py_function", "(", "n", ")", ":", "\n", "            ", "return", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "[", "n", "]", ",", "output_types", ")", ")", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "apply_py_function", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "#dataset = dataset.map(", "\n", "#    lambda n: tuple(tf.py_func(load_function,", "\n", "#                               [n], output_types)", "\n", "#                    ), num_parallel_calls=NPROCS)", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.get_output_shapes": [[151, 162], ["len", "numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "channels_no", "=", "len", "(", "self", ".", "_modalities", ")", "if", "self", ".", "_modalities", "is", "not", "None", "else", "1", "\n", "\n", "# if we resize, there's no need to load an image and get its shape", "\n", "if", "self", ".", "_resize", "is", "not", "None", ":", "\n", "            ", "output_shapes", "=", "(", "(", "self", ".", "_resize", ",", "self", ".", "_resize", ",", "channels_no", ")", ",", ")", "\n", "", "else", ":", "\n", "            ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "channels_no", ",", ")", "]", ")", "\n", "\n", "", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.get_output_types": [[163, 168], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.get_raw_elements": [[169, 182], ["numpy.asarray", "images.reshape.reshape.reshape", "getattr", "getattr", "BrainDataset.BrainDataset.load_slices_from_file", "images.reshape.reshape.append", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slices_from_file"], ["", "def", "get_raw_elements", "(", "self", ",", "dataset_str", ",", "index_list", "=", "None", ")", ":", "\n", "        ", "attribute_name", "=", "dataset_str", "+", "\"_set_x\"", "\n", "images", "=", "[", "]", "\n", "if", "index_list", "is", "not", "None", ":", "\n", "            ", "for", "file", "in", "getattr", "(", "self", ",", "attribute_name", ")", "[", "index_list", "]", ":", "\n", "                ", "image", "=", "self", ".", "load_slices_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "file", ")", ")", "\n", "images", ".", "append", "(", "image", ")", "\n", "", "images", "=", "np", ".", "asarray", "(", "images", ")", "\n", "images", "=", "images", ".", "reshape", "(", "[", "images", ".", "shape", "[", "0", "]", ",", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", ",", "1", "]", ")", "\n", "x_data", "=", "images", "\n", "", "else", ":", "\n", "            ", "x_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "", "return", "x_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.__init__": [[32, 45], ["Dataset.Dataset.__init__", "TwoByTwoLines.TwoByTwoLines.dataset_id", "TwoByTwoLines.TwoByTwoLines.load_data"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "True", "\n", "self", ".", "_size", "=", "params", "[", "'size'", "]", "\n", "\n", "self", ".", "_pm_one", "=", "params", "[", "'pm_one'", "]", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", "self", ".", "_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.dataset_id": [[46, 60], ["TwoByTwoLines.check_params_impl", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "TwoByTwoLines", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'2by2'", "\n", "if", "params", "[", "'size'", "]", "!=", "2", ":", "\n", "            ", "id", "+=", "'-sz%d'", "%", "params", "[", "'size'", "]", "\n", "", "if", "not", "params", "[", "'pm_one'", "]", ":", "\n", "            ", "id", "+=", "'-pm%d'", "%", "int", "(", "params", "[", "'pm_one'", "]", ")", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.load_data": [[61, 89], ["TwoByTwoLines.TwoByTwoLines.get_horizontal_pattern", "numpy.asarray", "len", "print", "dataset[].astype.reshape", "numpy.random.permutation", "dataset[].astype", "int", "list", "list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.get_horizontal_pattern"], ["", "def", "load_data", "(", "self", ",", "n", ")", ":", "\n", "        ", "ver", ",", "hor", "=", "self", ".", "get_horizontal_pattern", "(", "n", "=", "n", ")", "\n", "\n", "if", "self", ".", "_pm_one", ":", "\n", "            ", "ver", ",", "hor", "=", "ver", "*", "2", "-", "1", ",", "hor", "*", "2", "-", "1", "\n", "\n", "", "dataset", "=", "[", "]", "\n", "\n", "dataset", "+=", "list", "(", "hor", ")", "*", "DATASET_SIZE", "\n", "dataset", "+=", "list", "(", "ver", ")", "*", "DATASET_SIZE", "\n", "#", "\n", "# dataset = np.ones((4*DATASET_SIZE,4))", "\n", "dataset", "=", "np", ".", "asarray", "(", "dataset", ")", "\n", "\n", "len_of_dataset", "=", "len", "(", "dataset", ")", "\n", "print", "(", "\"LEN OF DATASET!!! \"", ",", "len_of_dataset", ")", "\n", "dataset", "=", "dataset", ".", "reshape", "(", "(", "len_of_dataset", ",", "n", ",", "n", ",", "1", ")", ")", "\n", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "len_of_dataset", ")", "\n", "dataset", "=", "dataset", "[", "perm", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "partition", "=", "int", "(", "len_of_dataset", "/", "6", ")", "\n", "# extra is ignored, since the images are too simple", "\n", "return", "dataset", "[", ":", "len_of_dataset", "-", "partition", "]", ",", "None", ",", "dataset", "[", "len_of_dataset", "-", "partition", ":", "]", ",", "None", ",", "dataset", "[", "len_of_dataset", "-", "partition", ":", "]", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.color_images": [[96, 99], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.image_shape": [[100, 103], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "_size", ",", "self", ".", "_size", ",", "1", ")", "# the last number is the channel", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.likelihood": [[105, 113], ["TwoByTwoLines.get_horizontal_pattern", "len", "i.ravel"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.get_horizontal_pattern"], ["", "@", "property", "\n", "def", "likelihood", "(", "self", ")", ":", "\n", "        ", "ver", ",", "hor", "=", "TwoByTwoLines", ".", "get_horizontal_pattern", "(", "n", "=", "self", ".", "_size", ")", "\n", "patterns", "=", "[", "*", "ver", ",", "*", "hor", "]", "\n", "len_p", "=", "len", "(", "patterns", ")", "\n", "patterns_and_likelihoods", "=", "[", "(", "i", ".", "ravel", "(", ")", ",", "1", "/", "len_p", ")", "for", "i", "in", "patterns", "]", "\n", "\n", "return", "patterns_and_likelihoods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.TwoByTwoLines.TwoByTwoLines.get_horizontal_pattern": [[114, 126], ["TwoByTwoLines.TwoByTwoLines.get_horizontal_pattern.get_numbers"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_horizontal_pattern", "(", "n", "=", "3", ")", ":", "\n", "        ", "def", "get_numbers", "(", "n", ")", ":", "\n", "            ", "return", "np", ".", "arange", "(", "1", ",", "2", "**", "n", "-", "1", ")", "\n", "\n", "", "x", "=", "get_numbers", "(", "n", ")", "\n", "x", "=", "[", "(", "'{0:0'", "+", "str", "(", "n", ")", "+", "'b}'", ")", ".", "format", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "x", "=", "[", "np", ".", "tile", "(", "i", ",", "n", ")", "for", "i", "in", "x", "]", "\n", "\n", "vertical_lines", "=", "np", ".", "asarray", "(", "[", "list", "(", "map", "(", "lambda", "j", ":", "[", "int", "(", "k", ")", "for", "k", "in", "j", "]", ",", "i", ")", ")", "for", "i", "in", "x", "]", ")", "\n", "horizontal_lines", "=", "np", ".", "transpose", "(", "vertical_lines", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "return", "vertical_lines", ",", "horizontal_lines", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.__init__": [[73, 142], ["ImageDataset.ImageDataset.__init__", "CMB.CMB.dataset_id", "CMB.CMB.compute_min_max_data", "CMB.CMB.load_dataset", "CMB.CMB.load_dataset", "CMB.CMB.load_dataset", "Exception", "open", "json.loads", "os.path.exists", "os.path.isdir", "f.read"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.compute_min_max_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_json_filename", "=", "\"params.json\"", "\n", "fraction_dataset", "=", "params", "[", "'fraction_dataset'", "]", "\n", "\n", "# self._csv_filename = \"labels_file.csv\"", "\n", "if", "fraction_dataset", "==", "100", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data.csv'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_csv_filename_Train", "=", "'Train_CMB_data_{}.csv'", ".", "format", "(", "fraction_dataset", ")", "\n", "# label_df_Train = pd.read_csv(self._csv_filename_Train, sep=\"\\t\")", "\n", "\n", "", "self", ".", "_csv_filename_Test", "=", "'Test_CMB_data.csv'", "\n", "# label_df_Test = pd.read_csv(self._csv_filename_Test, sep=\"\\t\")", "\n", "\n", "self", ".", "_csv_filename_Validation", "=", "'Validation_CMB_data.csv'", "\n", "# label_df_Validation = pd.read_csv(self._csv_filename_Validation, sep=\"\\t\")", "\n", "\n", "# self._all_parameter_list = ['h', 'omega_b', 'omega_cdm', 'A_s', 'n_s', 'tau_reio']", "\n", "self", ".", "_parameters_list", "=", "params", "[", "\"parameters\"", "]", "\n", "self", ".", "_fraction_dataset", "=", "params", "[", "\"fraction_dataset\"", "]", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "self", ".", "_normalize_labels", "=", "self", ".", "_params", "[", "'normalize_labels'", "]", "\n", "self", ".", "_normalize_images", "=", "self", ".", "_params", "[", "'normalize_images'", "]", "\n", "\n", "\n", "# check if the data directory is present", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_data_dir", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "_data_dir", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Dataset directory {}'", "\n", "' not found'", ".", "format", "(", "self", ".", "_data_dir", ")", "\n", ")", "\n", "\n", "#self._debug_mode = params['debug_mode']", "\n", "\n", "#self._augment_data = params['augm_data']", "\n", "#self._only_center = params['only_center']", "\n", "", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "self", ".", "_json_filename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "picture_size", "=", "conf_dict", "[", "\"pic_size\"", "]", "\n", "self", ".", "_x_sample_shape", "=", "(", "picture_size", ",", "picture_size", ",", "1", ")", "\n", "#self._y_sample_shape = (self._n_params,)", "\n", "\n", "#self._var_params = self.conf_dict['params'] # TODO Check that is sorted like self.parameter_list", "\n", "\n", "# useful for lazy load, however I need to reimplement some methods to make it work", "\n", "# self._loaded_from_disk = False", "\n", "\n", "#self._train_set_x = None", "\n", "#self._train_set_y = None", "\n", "#self._test_set_x = None", "\n", "#self._test_set_y = None", "\n", "\n", "#self._n_samples_train = None", "\n", "#self._n_samples_test = None", "\n", "self", ".", "_labels_min", ",", "self", ".", "_labels_max", ",", "self", ".", "_data_min", ",", "self", ".", "_data_max", "=", "self", ".", "compute_min_max_data", "(", "norm_labels", "=", "self", ".", "_normalize_labels", ",", "\n", "norm_data", "=", "self", ".", "_normalize_images", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "load_dataset", "(", "TRAIN", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "load_dataset", "(", "VALIDATION", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_dataset", "(", "TEST", ")", "\n", "self", ".", "_caching_bool", "=", "False", "\n", "self", ".", "_shuffling_cache", "=", "None", "\n", "# self._shuffling_cache = 3000", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.dataset_id": [[146, 178], ["os.path.basename", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "# CMB.check_params_impl(params)", "\n", "\n", "p_dist_abbr", "=", "{", "'uniform'", ":", "'U'", ",", "\n", "'lattice'", ":", "'L'", "}", "\n", "\n", "id", "=", "'CMB'", "\n", "id", "+=", "os", ".", "path", ".", "basename", "(", "params", "[", "'data_dir'", "]", ")", "\n", "id", "+=", "'-d%'", "+", "str", "(", "params", "[", "'fraction_dataset'", "]", ")", "\n", "\n", "id", "+=", "'-n'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_images'", "]", "==", "True", "else", "'0'", "\n", "id", "+=", "'1'", "if", "params", "[", "'normalize_labels'", "]", "==", "True", "else", "'0'", "\n", "#id += '-au1' if self._augment_data == True  else '-au0'", "\n", "#id += '-oc1' if self._only_center == True else '-oc0'", "\n", "\n", "# id += '-pdim' + str(params['params_dim'])", "\n", "# id += '-' + p_dist_abbr[params['par_distr']]", "\n", "# id += '-pprr' + str(params['pic_per_run_rot'])", "\n", "# id += '-ppre' + str(params['pic_per_run_equator'])", "\n", "\n", "# id note (keep last)", "\n", "#if params['id_note']:", "\n", "#    id += params['id_note']", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.read_metadata": [[180, 190], ["pandas.read_csv", "open", "json.loads", "f.read"], "methods", ["None"], ["", "def", "read_metadata", "(", "self", ",", "json_basename", ",", "csv_basename", ")", ":", "\n", "#load json file", "\n", "        ", "json_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "json_basename", "\n", "with", "open", "(", "json_filename", ")", "as", "f", ":", "\n", "            ", "conf_dict", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "csv_filename", "=", "self", ".", "_data_dir", "+", "\"/\"", "+", "csv_basename", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "return", "conf_dict", ",", "label_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.get_output_shapes": [[192, 197], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "1", ",", ")", ",", "datasets_tuple", "[", "1", "]", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.get_output_types": [[198, 203], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", ",", "tf", ".", "as_dtype", "(", "datasets_tuple", "[", "1", "]", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.dataset_map": [[207, 233], ["CMB.CMB.get_output_types", "list", "dataset.map.map.map", "numpy.load", "numpy.expand_dims", "zip", "numpy.expand_dims.astype", "tuple", "tensorflow.py_func"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "norm_bool", "=", "self", ".", "_normalize_images", "\n", "data_min", "=", "self", ".", "_data_min", "\n", "data_max", "=", "self", ".", "_data_max", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "label", "=", "full_data", "[", "n", "]", "[", "1", "]", "\n", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "filename", ")", "\n", "if", "norm_bool", ":", "\n", "                ", "image", "=", "2", "*", "(", "image", "-", "data_min", ")", "/", "(", "data_max", "-", "data_min", ")", "-", "1", "\n", "", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "label", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset": [[235, 323], ["CMB.CMB.read_metadata", "len", "print", "df_dataset[].values.astype", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.read_metadata"], ["", "def", "load_dataset", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "\"\"\"\n        load the dataset in memory and set in the object\n\n        Args:\n            train_test_ratio: (float) percentage of the dataset in train\n\n        \"\"\"", "\n", "json_filename", "=", "self", ".", "_json_filename", "\n", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Train", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Validation", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "csv_filename", "=", "self", ".", "_csv_filename_Test", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"`dataset_str` can be only: train, validation or test.\"", ")", "\n", "\n", "# get info from the metadata", "\n", "", "conf_dict", ",", "labels_filter_df", "=", "self", ".", "read_metadata", "(", "json_filename", ",", "csv_filename", ")", "\n", "#self._picture_size = self.conf_dict['pic_size']", "\n", "n_parameters", "=", "len", "(", "conf_dict", ")", "\n", "\n", "#if self._only_center:", "\n", "#    labels_filter_df = labels_filter_df[labels_filter_df['is_center']]", "\n", "\n", "#if not self._augment_data:", "\n", "#    # no rotations", "\n", "#    is_no_rotation = labels_filter_df['rot_angle'] == 0", "\n", "#    labels_filter_df = labels_filter_df[is_no_rotation]", "\n", "\n", "#    # no flips", "\n", "#    index_no_flip = ~labels_filter_df['flip']", "\n", "#    labels_filter_df = labels_filter_df[index_no_flip]", "\n", "\n", "\n", "'''\n        if self._debug_mode:\n            debug_dimension = 500\n            labels_filter_df = labels_filter_df.iloc[:debug_dimension]\n        '''", "\n", "\n", "# dataset_x = labels_filter_df.sample(frac=1)", "\n", "df_dataset", "=", "labels_filter_df", "\n", "num_files", "=", "df_dataset", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'{} are going to be loaded in memory'", ".", "format", "(", "num_files", ")", ")", "\n", "\n", "filename_dataset", "=", "df_dataset", "[", "'filename'", "]", ".", "values", "\n", "labels_dataset", "=", "df_dataset", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "\n", "if", "self", ".", "_normalize_labels", ":", "\n", "            ", "labels_dataset", "=", "2", "*", "(", "labels_dataset", "-", "self", ".", "_labels_min", ")", "/", "(", "self", ".", "_labels_max", "-", "self", ".", "_labels_min", ")", "-", "1.", "\n", "\n", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "# dim_train = int(num_files * train_ratio)", "\n", "# dim_validation = int(num_files * validation_ratio)", "\n", "# dim_test = num_files - dim_train - dim_validation", "\n", "#", "\n", "# # training", "\n", "# df_train = dataset_x.iloc[0 : dim_train]", "\n", "# filename_training = df_train['filename'].values", "\n", "# labels_training = df_train[['omega_cdm', 'A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     max_training = np.max(labels_training, axis=0)", "\n", "#     min_training = np.min(labels_training, axis=0)", "\n", "#     labels_training = (labels_training - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_validation = dataset_x.iloc[dim_train : (dim_train+dim_validation)]", "\n", "# filename_validation = df_validation['filename'].values", "\n", "# labels_validation = df_validation[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_validation = (labels_validation - min_training)/(max_training - min_training)", "\n", "#", "\n", "# # testing", "\n", "# df_test = dataset_x.iloc[(dim_train+dim_validation):]", "\n", "# filename_test = df_test['filename'].values", "\n", "# labels_test = df_test[['omega_cdm','A_s']].values.astype(np.float32)", "\n", "# if self._normalize_data:", "\n", "#     labels_test = (labels_test - min_training)/(max_training - min_training)", "\n", "#", "\n", "#COMMENTED BEFORE REFACTORING", "\n", "\n", "", "return", "filename_dataset", ",", "labels_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.compute_min_max_data": [[324, 353], ["pandas.read_csv", "numpy.min", "numpy.max", "label_df[].values.astype", "numpy.min", "numpy.max", "numpy.load", "all_min.append", "all_max.append", "numpy.min", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "compute_min_max_data", "(", "self", ",", "norm_labels", "=", "False", ",", "norm_data", "=", "False", ")", ":", "\n", "        ", "all_max", "=", "[", "]", "\n", "all_min", "=", "[", "]", "\n", "csv_filename", "=", "self", ".", "_data_dir", "+", "'/labels_file.csv'", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "csv_filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "labels_min", "=", "None", "\n", "labels_max", "=", "None", "\n", "data_min", "=", "None", "\n", "data_max", "=", "None", "\n", "\n", "if", "norm_data", ":", "\n", "            ", "filenames", "=", "label_df", "[", "'filename'", "]", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "                ", "patch1", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "\"/\"", "+", "filename", ")", "\n", "\n", "all_min", ".", "append", "(", "np", ".", "min", "(", "patch1", ")", ")", "\n", "all_max", ".", "append", "(", "np", ".", "max", "(", "patch1", ")", ")", "\n", "\n", "", "data_min", "=", "np", ".", "min", "(", "all_min", ")", "\n", "data_max", "=", "np", ".", "max", "(", "all_max", ")", "\n", "\n", "", "if", "norm_labels", ":", "\n", "            ", "labels", "=", "label_df", "[", "self", ".", "_parameters_list", "]", ".", "values", ".", "astype", "(", "np", ".", "float32", ")", "\n", "labels_min", "=", "np", ".", "min", "(", "labels", ",", "axis", "=", "0", ")", "\n", "labels_max", "=", "np", ".", "max", "(", "labels", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "labels_min", ",", "labels_max", ",", "data_min", ",", "data_max", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.labels_min_training": [[354, 366], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_min_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#", "\n", "#if  self._dataset_x_min is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "\n", "        ", "return", "self", ".", "_labels_min_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.labels_max_training": [[367, 378], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels_max_training", "(", "self", ")", ":", "\n", "#if not self._loaded_from_disk:", "\n", "#    self.load_dataset_from_disk()", "\n", "#\u00a7", "\n", "#if  self._dataset_x_max is None:", "\n", "#    raise Exception(\"No normalization procedure has been done. If you want\"", "\n", "#                    \"dataset_x_min and dataset_x_max, normalize the labels with the\"", "\n", "#                    \"normalize_label flag = True.\")", "\n", "#else:", "\n", "        ", "return", "self", ".", "_labels_max_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.x_shape_train": [[379, 383], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the train loop\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.x_shape_eval": [[384, 436], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample for the evaluation\"\"\"", "\n", "return", "self", ".", "_x_sample_shape", "\n", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_train(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "# # overriding", "\n", "# @property", "\n", "# def x_shape_eval(self):", "\n", "#     return self._train_set_x_shape", "\n", "#", "\n", "#return mnist.train.images, mnist.train.labels, mnist.validation.images, mnist.validation.labels, mnist.test.images, mnist.test.labels", "\n", "\n", "\n", "#start_time_data = timeit.default_timer()", "\n", "\n", "#shape_X = (n_files,) + self._x_sample_shape", "\n", "#shape_Y = (n_files,) + self._y_sample_shape", "\n", "\n", "# construct the datasets", "\n", "#X = np.empty(shape_X)", "\n", "#Y = np.empty(shape_Y)", "\n", "\n", "#for ix, row in  labels_filter_df.iterrows():", "\n", "#    tmp_numpy = np.load(self._data_dir + \"/\" + row['filename'])", "\n", "#", "\n", "#    X[ix, :, :, 0] = tmp_numpy", "\n", "#    Y[ix] = row[self._var_params]", "\n", "\n", "# print time for the load", "\n", "#step_time = timeit.default_timer()", "\n", "#print(\"time needed to load: \", step_time - start_time_data)", "\n", "\n", "# shuffle the dataset", "\n", "'''\n        randomized_dataset_index = np.random.permutation(n_files)\n        X = X[randomized_dataset_index]\n        Y = Y[randomized_dataset_index]\n\n\n\n\n\n\n        dim_train = int(n_files * train_test_ratio)\n        self._train_set_x, self._train_set_y = X[:dim_train] , Y[:dim_train]\n        self._test_set_x, self._test_set_y = X[dim_train:], Y[dim_train:]\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.__init__": [[42, 58], ["datasets.AudioDataset.AudioDataset.__init__", "SpeechCommands.SpeechCommands.dataset_id", "SpeechCommands.process_params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "SpeechCommands", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_sample_lenght", "=", "16000", "+", "384", "# 384 padded 0s sometimes", "\n", "self", ".", "_sample_rate", "=", "16000", "\n", "self", ".", "_label", "=", "(", "self", ".", "_params", "[", "'label'", "]", "if", "self", ".", "_params", "[", "'label'", "]", "in", "ALL_LABELS_IMPLEMENTED", "else", "None", ")", "\n", "\n", "# self._n_labels = len(self._params['features']) if 'features' in self._params else 0", "\n", "self", ".", "_x_sample_shape_train", "=", "[", "self", ".", "_crop_length_train", ",", "1", "]", "\n", "self", ".", "_x_sample_shape_eval", "=", "[", "self", ".", "_sample_lenght", ",", "1", "]", "\n", "self", ".", "_y_sample_shape", "=", "None", "# (self._n_labels,)", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.dataset_id": [[63, 77], ["SpeechCommands.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "SpeechCommands", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'SpeechC'", "\n", "\n", "if", "params", "[", "'shuffle_buffer'", "]", "!=", "SpeechCommands", ".", "default_params", "[", "'shuffle_buffer'", "]", ":", "\n", "            ", "_id", "+=", "'-sh%.2e'", "%", "params", "[", "'shuffle_buffer'", "]", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.get_var_labels": [[78, 83], ["numpy.intersect1d", "len", "len"], "methods", ["None"], ["", "def", "get_var_labels", "(", "self", ",", "param", ")", ":", "\n", "        ", "var_params", "=", "np", ".", "intersect1d", "(", "ALL_LABELS", ",", "param", ")", "\n", "\n", "assert", "len", "(", "var_params", ")", "==", "len", "(", "param", ")", ",", "\"It seems like you might have a mistake in you label name\"", "\n", "return", "var_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands._parse_function": [[84, 105], ["tensorflow.parse_single_example", "tensorflow.parse_single_example", "tensorflow.expand_dims", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.concat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_parse_function", "(", "example_proto", ",", "y_label", "=", "None", ")", ":", "\n", "        ", "features", "=", "{", "\n", "SPEAKER", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "WORD", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "HASH", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "FILENAME", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "AUDIO", ":", "tf", ".", "VarLenFeature", "(", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "# AUDIO: tf.FixedLenFeature([111468], dtype=tf.float32),", "\n", "}", "\n", "parsed_features", "=", "tf", ".", "parse_single_example", "(", "example_proto", ",", "features", ")", "\n", "\n", "# add channel info for standardized input", "\n", "parsed_features", "=", "tf", ".", "parse_single_example", "(", "example_proto", ",", "features", ")", "\n", "\n", "# Expand dims for channels", "\n", "audio", "=", "tf", ".", "expand_dims", "(", "tf", ".", "concat", "(", "parsed_features", "[", "AUDIO", "]", ".", "values", ",", "axis", "=", "0", ")", ",", "axis", "=", "-", "1", ")", "\n", "if", "y_label", ":", "\n", "            ", "return", "(", "audio", ",", "parsed_features", "[", "y_label", "]", ",", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "audio", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.get_dataset_iterator": [[107, 163], ["tensorflow.data.TFRecordDataset", "dataset.repeat.repeat.map", "dataset.repeat.repeat.cache", "dataset.repeat.repeat.map().map", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "SpeechCommands.SpeechCommands._parse_function", "functools.partial", "Exception", "dataset.repeat.repeat.map", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi._parse_function"], ["", "", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ")", ":", "\n", "\n", "        ", "is_perturbed", "=", "False", "\n", "filename", "=", "\"\"", "\n", "\n", "# create Dataset objects using the data previously downloaded", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/train-sc-float-shuffled.tfrecords\"", "\n", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/validation-sc-float-shuffled.tfrecords\"", "\n", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/test-sc-float-shuffled.tfrecords\"", "\n", "\n", "# TODO: BIIIG TODO I forgot to add the _backgroundnoises_ to the samples. That should be a perturbation step", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "# CREATE TF DATASET with map and py_func", "\n", "", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "[", "filename", "]", ")", "\n", "\n", "NPROCS", "=", "20", "\n", "if", "self", ".", "_label", ":", "\n", "            ", "parse_func", "=", "lambda", "x", ":", "self", ".", "_parse_function", "(", "x", ",", "y_label", "=", "self", ".", "_label", ")", "\n", "", "else", ":", "\n", "            ", "parse_func", "=", "self", ".", "_parse_function", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "parse_func", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "\n", "# PREPROCESS DATA (AUGMENT IF NEEDED)", "\n", "if", "augment", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", ".", "map", "(", "partial", "(", "self", ".", "_preprocess_element", ",", "is_perturbed", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# SHUFFLE, REPEAT and BATCH", "\n", "", "if", "shuffle", ":", "\n", "            ", "LARGE_NUMBER", "=", "self", ".", "_shuffle_buffer", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "LARGE_NUMBER", "+", "1", ")", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", ",", "is_perturbed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.n_samples_train": [[164, 167], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "84843", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.x_shape_train": [[170, 174], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.x_shape_eval": [[175, 179], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.y_shape": [[180, 184], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.SpeechCommands.SpeechCommands.sample_rate": [[185, 189], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_sample_rate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.normalize": [[3, 6], ["None"], "function", ["None"], ["def", "normalize", "(", "tensor", ",", "min_orig", ",", "max_orig", ",", "min_out", "=", "-", "1.", ",", "max_out", "=", "1.", ")", ":", "\n", "    ", "delta", "=", "max_out", "-", "min_out", "\n", "return", "delta", "*", "(", "tensor", "-", "min_orig", ")", "/", "(", "max_orig", "-", "min_orig", ")", "+", "min_out", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np": [[7, 19], ["numpy.min", "numpy.max", "all_min.append", "all_max.append", "numpy.min", "numpy.max"], "function", ["None"], ["", "def", "min_max_data_np", "(", "arrays", ")", ":", "\n", "    ", "all_max", "=", "[", "]", "\n", "all_min", "=", "[", "]", "\n", "\n", "for", "arr", "in", "arrays", ":", "\n", "        ", "all_min", ".", "append", "(", "np", ".", "min", "(", "arr", ")", ")", "\n", "all_max", ".", "append", "(", "np", ".", "max", "(", "arr", ")", ")", "\n", "\n", "", "data_min", "=", "np", ".", "min", "(", "all_min", ")", "\n", "data_max", "=", "np", ".", "max", "(", "all_max", ")", "\n", "\n", "return", "data_min", ",", "data_max", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.__init__": [[110, 200], ["ImageDataset.ImageDataset.__init__", "CIFAR10.CIFAR10.dataset_id", "CIFAR10.CIFAR10.maybe_download_and_extract", "CIFAR10.CIFAR10.load_training_data", "CIFAR10.CIFAR10.load_validation_test_data", "CIFAR10.CIFAR10.patch_data", "CIFAR10.CIFAR10.patch_data", "CIFAR10.CIFAR10.patch_data", "utils.min_max_data_np", "utils.normalize", "utils.normalize", "utils.normalize", "CIFAR10.CIFAR10.class_filter", "CIFAR10.CIFAR10.class_filter", "CIFAR10.CIFAR10.class_filter", "CIFAR10.CIFAR10.sub_sample", "CIFAR10.CIFAR10.sub_sample", "CIFAR10.CIFAR10.sub_sample", "numpy.clip", "numpy.clip", "numpy.clip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.maybe_download_and_extract", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.load_training_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.load_validation_test_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.patch_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.patch_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.patch_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.utils.min_max_data_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_binary_input", "=", "0", "\n", "\n", "########################################################################", "\n", "# Various constants for the size of the images.", "\n", "# Use these constants in your own program.", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_img_size", "=", "32", "\n", "\n", "# Number of channels in each image, 3 channels: Red, Green, Blue.", "\n", "self", ".", "_num_channels", "=", "3", "\n", "\n", "# Length of an image when flattened to a 1-dim array.", "\n", "self", ".", "_img_size_flat", "=", "self", ".", "_img_size", "*", "self", ".", "_img_size", "*", "self", ".", "_num_channels", "\n", "\n", "# Number of classes.", "\n", "self", ".", "_num_classes", "=", "10", "\n", "\n", "########################################################################", "\n", "# Various constants used to allocate arrays of the correct size.", "\n", "\n", "# Number of files for the training-set.", "\n", "self", ".", "_num_files_train", "=", "5", "\n", "\n", "# Number of images for each batch-file in the training-set.", "\n", "self", ".", "_images_per_file", "=", "10000", "\n", "\n", "# Total number of images in the training-set.", "\n", "# This is used to pre-allocate arrays for efficiency.", "\n", "self", ".", "_num_images_train", "=", "self", ".", "_num_files_train", "*", "self", ".", "_images_per_file", "\n", "\n", "self", ".", "_params", "[", "'binary'", "]", "=", "0", "\n", "\n", "self", ".", "_data_dir", "=", "\"/ssd_data/datasets/CIFAR10\"", "\n", "self", ".", "_data_url", "=", "'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'", "\n", "self", ".", "_data_extract", "=", "self", ".", "_data_dir", "+", "\"/cifar-10-batches-py\"", "\n", "\n", "self", ".", "maybe_download_and_extract", "(", ")", "\n", "\n", "imgs_train", ",", "cls_train", "=", "self", ".", "load_training_data", "(", ")", "\n", "imgs_validation", ",", "cls_validation", ",", "imgs_test", ",", "cls_test", "=", "self", ".", "load_validation_test_data", "(", ")", "\n", "\n", "self", ".", "_train_set_x", "=", "self", ".", "patch_data", "(", "imgs_train", ",", "self", ".", "_img_size", ")", "\n", "self", ".", "_validation_set_x", "=", "self", ".", "patch_data", "(", "imgs_validation", ",", "self", ".", "_img_size", ")", "\n", "self", ".", "_test_set_x", "=", "self", ".", "patch_data", "(", "imgs_test", ",", "self", ".", "_img_size", ")", "\n", "self", ".", "_train_set_y", "=", "cls_train", "\n", "self", ".", "_validation_set_y", "=", "cls_validation", "\n", "self", ".", "_test_set_y", "=", "cls_test", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "\n", "#normalize data", "\n", "all_min", ",", "all_max", "=", "min_max_data_np", "(", "[", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "]", ")", "\n", "self", ".", "_train_set_x", "=", "normalize", "(", "self", ".", "_train_set_x", ",", "all_min", ",", "all_max", ")", "\n", "self", ".", "_validation_set_x", "=", "normalize", "(", "self", ".", "_validation_set_x", ",", "all_min", ",", "all_max", ")", "\n", "self", ".", "_test_set_x", "=", "normalize", "(", "self", ".", "_test_set_x", ",", "all_min", ",", "all_max", ")", "\n", "\n", "# filter classes", "\n", "if", "self", ".", "_params", "[", "'classes'", "]", ":", "\n", "            ", "position_label", "=", "self", ".", "_params", "[", "'position_label'", "]", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "class_filter", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'classes'", "]", ",", "position_label", ")", "\n", "\n", "# choose a subset", "\n", "", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "#clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_validation_set_x", "=", "np", ".", "clip", "(", "self", ".", "_validation_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.dataset_id": [[205, 256], ["CIFAR10.check_params_impl", "str", "list", "params.keys", "range", "str", "map", "set", "set", "params[].sort"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "CIFAR10", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'CIFAR10'", "\n", "\n", "# stochastic", "\n", "id", "+=", "'-st'", "+", "str", "(", "params", "[", "\"stochastic\"", "]", ")", "\n", "\n", "# subclasses", "\n", "# TODO: argo may split the list of classes into subprocesses, easy solution: write a string in place of a list.", "\n", "#", "\n", "if", "(", "'classes'", "in", "params", ".", "keys", "(", ")", ")", "and", "(", "params", "[", "'classes'", "]", "!=", "(", ")", ")", ":", "\n", "            ", "all_dg", "=", "list", "(", "range", "(", "50", ")", ")", "# list of available digits", "\n", "# check the list is a list of digits", "\n", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                ", "if", "params", "[", "'classes'", "]", "is", "not", "None", ":", "\n", "                    ", "assert", "(", "set", "(", "params", "[", "'classes'", "]", ")", "<=", "set", "(", "all_dg", ")", ")", ",", "\"classes contains labels not present in CIFAR10\"", "\n", "", "", "id", "+=", "(", "'-sc'", "+", "''", ".", "join", "(", "map", "(", "str", ",", "params", "[", "'classes'", "]", ".", "sort", "(", ")", ")", ")", ")", "# append requested classes to the id", "\n", "\n", "# if position label is not activated", "\n", "if", "not", "params", "[", "'position_label'", "]", ":", "\n", "                ", "id", "+=", "'npl'", "\n", "\n", "# subsampling", "\n", "", "", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.sub_sample": [[257, 276], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_train", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_train", "=", "np", ".", "random", ".", "permutation", "(", "len_train", ")", "\n", "new_len_train", "=", "int", "(", "len_train", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.class_filter": [[277, 302], ["numpy.in1d", "CIFAR10.CIFAR10.class_filter.replace_with_position"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "class_filter", "(", "data_set_x", ",", "data_set_y", ",", "classes", ",", "position_label", ")", ":", "\n", "        ", "\"\"\"\n        return the dataset with labels in the list classes\n\n        :param data_set_x: data\n        :param data_set_y: labels\n        :param classes:    list of classes\n        :param position_label:  list of classes\n        :return: (dataset_x, dataset_y) with filtered elemnts not in classes\n        \"\"\"", "\n", "\n", "ix_mtch_class_train", "=", "np", ".", "in1d", "(", "data_set_y", ",", "classes", ")", "\n", "data_set_x", "=", "data_set_x", "[", "ix_mtch_class_train", "]", "\n", "data_set_y", "=", "data_set_y", "[", "ix_mtch_class_train", "]", "\n", "if", "position_label", ":", "\n", "\n", "            ", "def", "replace_with_position", "(", "label_set", ",", "classes", ")", ":", "\n", "                ", "label_set_new", "=", "np", ".", "copy", "(", "label_set", ")", "\n", "for", "ix", ",", "class_", "in", "enumerate", "(", "classes", ")", ":", "label_set_new", "[", "label_set", "==", "class_", "]", "=", "ix", "\n", "return", "label_set_new", "\n", "\n", "", "data_set_y", "=", "replace_with_position", "(", "data_set_y", ",", "classes", ")", "\n", "\n", "", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._get_file_path": [[322, 329], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["def", "_get_file_path", "(", "self", ",", "filename", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Return the full path of a data-file for the data-set.\n        If filename==\"\" then return the directory of the files.\n        \"\"\"", "\n", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "_data_dir", ",", "\"cifar-10-batches-py/\"", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._unpickle": [[330, 347], ["CIFAR10.CIFAR10._get_file_path", "print", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "_unpickle", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Unpickle the given file and return the data.\n        Note that the appropriate dir-name is prepended the filename.\n        \"\"\"", "\n", "\n", "# Create full path for the file.", "\n", "file_path", "=", "self", ".", "_get_file_path", "(", "filename", ")", "\n", "\n", "print", "(", "\"Loading data: \"", "+", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "file", ":", "\n", "# In Python 3.X it is important to set the encoding,", "\n", "# otherwise an exception is raised here.", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "file", ",", "encoding", "=", "'bytes'", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._convert_images": [[348, 366], ["raw_float.reshape", "images.transpose.transpose.transpose", "numpy.array"], "methods", ["None"], ["", "def", "_convert_images", "(", "self", ",", "raw", ")", ":", "\n", "        ", "\"\"\"\n        Convert images from the CIFAR-10 format and\n        return a 4-dim array with shape: [image_number, height, width, channel]\n        where the pixels are floats between 0.0 and 1.0.\n        \"\"\"", "\n", "\n", "# Convert the raw images from the data-files to floating-points.", "\n", "raw_float", "=", "np", ".", "array", "(", "raw", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", "\n", "# pdb.set_trace()", "\n", "\n", "# Reshape the array to 4-dimensions.", "\n", "images", "=", "raw_float", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "_num_channels", ",", "self", ".", "_img_size", ",", "self", ".", "_img_size", "]", ")", "\n", "\n", "# Reorder the indices of the array.", "\n", "images", "=", "images", ".", "transpose", "(", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._load_data": [[367, 388], ["CIFAR10.CIFAR10._unpickle", "numpy.array", "CIFAR10.CIFAR10._convert_images"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._unpickle", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._convert_images"], ["", "def", "_load_data", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Load a pickled data-file from the CIFAR-10 data-set\n        and return the converted images (see above) and the class-number\n        for each image.\n        \"\"\"", "\n", "\n", "# Load the pickled data-file.", "\n", "data", "=", "self", ".", "_unpickle", "(", "filename", ")", "\n", "\n", "# Get the raw images.", "\n", "raw_images", "=", "data", "[", "b'data'", "]", "\n", "\n", "# Get the class-numbers for each image. Convert to numpy-array.", "\n", "cls", "=", "np", ".", "array", "(", "data", "[", "b'labels'", "]", ")", "\n", "#pdb.set_trace()", "\n", "\n", "# Convert the images.", "\n", "images", "=", "self", ".", "_convert_images", "(", "raw_images", ")", "\n", "\n", "return", "images", ",", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.maybe_download_and_extract": [[396, 420], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "CIFAR10.CIFAR10._data_url.split", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "urllib.request.urlretrieve", "print", "os.stat", "os.stat", "os.stat", "os.stat", "print", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "tarfile.open().extractall", "sys.stdout.write", "sys.stdout.flush", "tarfile.open", "float", "float"], "methods", ["None"], ["", "def", "maybe_download_and_extract", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Download and extract the CIFAR-10 data-set if it doesn't already exist\n        in data_path (set this variable first to the desired path).\n        \"\"\"", "\n", "\n", "dest_directory", "=", "self", ".", "_data_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dest_directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dest_directory", ")", "\n", "", "filename", "=", "self", ".", "_data_url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dest_directory", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "            ", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "(", "\n", "filename", ",", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "self", ".", "_data_url", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Successfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "\n", "#filepath = os.path.join(dest_directory, filename)", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_data_extract", ")", ":", "\n", "            ", "tarfile", ".", "open", "(", "filepath", ",", "'r:gz'", ")", ".", "extractall", "(", "dest_directory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.load_class_names": [[421, 435], ["CIFAR10.CIFAR10._unpickle", "x.decode"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._unpickle", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode"], ["", "", "def", "load_class_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load the names for the classes in the CIFAR-10 data-set.\n        Returns a list with the names. Example: names[3] is the name\n        associated with class-number 3.\n        \"\"\"", "\n", "\n", "# Load the class-names from the pickled file.", "\n", "raw", "=", "self", ".", "_unpickle", "(", "filename", "=", "\"batches.meta\"", ")", "[", "b'label_names'", "]", "\n", "\n", "# Convert from binary strings.", "\n", "names", "=", "[", "x", ".", "decode", "(", "'utf-8'", ")", "for", "x", "in", "raw", "]", "\n", "\n", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.load_training_data": [[436, 471], ["numpy.zeros", "numpy.zeros", "range", "CIFAR10.CIFAR10._load_data", "len", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._load_data"], ["", "def", "load_training_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load all the training-data for the CIFAR-10 data-set.\n        The data-set is split into 5 data-files which are merged here.\n        Returns the images, class-numbers and one-hot encoded class-labels.\n        \"\"\"", "\n", "\n", "# Pre-allocate the arrays for the images and class-numbers for efficiency.", "\n", "images", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "_num_images_train", ",", "self", ".", "_img_size", ",", "self", ".", "_img_size", ",", "self", ".", "_num_channels", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "cls", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "_num_images_train", "]", ",", "dtype", "=", "int", ")", "\n", "\n", "# Begin-index for the current batch.", "\n", "begin", "=", "0", "\n", "\n", "# For each data-file.", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_files_train", ")", ":", "\n", "# Load the images and class-numbers from the data-file.", "\n", "            ", "images_batch", ",", "cls_batch", "=", "self", ".", "_load_data", "(", "filename", "=", "\"data_batch_\"", "+", "str", "(", "i", "+", "1", ")", ")", "\n", "\n", "# Number of images in this batch.", "\n", "num_images", "=", "len", "(", "images_batch", ")", "\n", "\n", "# End-index for the current batch.", "\n", "end", "=", "begin", "+", "num_images", "\n", "\n", "# Store the images into the array.", "\n", "images", "[", "begin", ":", "end", ",", ":", "]", "=", "images_batch", "\n", "\n", "# Store the class-numbers into the array.", "\n", "cls", "[", "begin", ":", "end", "]", "=", "cls_batch", "\n", "\n", "# The begin-index for the next batch is the current end-index.", "\n", "begin", "=", "end", "\n", "\n", "", "return", "images", ",", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.load_validation_test_data": [[472, 493], ["CIFAR10.CIFAR10._load_data", "len", "numpy.random.seed", "numpy.random.permutation", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10._load_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed"], ["", "def", "load_validation_test_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load all the test-data for the CIFAR-10 data-set.\n        Returns the images, class-numbers and one-hot encoded class-labels.\n        \"\"\"", "\n", "\n", "images", ",", "cls", "=", "self", ".", "_load_data", "(", "filename", "=", "\"test_batch\"", ")", "\n", "\n", "#return images, cls, one_hot_encoded(class_numbers=cls, num_classes=num_classes)", "\n", "\n", "rnd_seed", "=", "42", "\n", "n_images", "=", "len", "(", "images", ")", "\n", "np", ".", "random", ".", "seed", "(", "rnd_seed", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "n_images", ")", "\n", "images", "=", "images", "[", "perm", "]", "\n", "cls", "=", "cls", "[", "perm", "]", "\n", "percentage_train", "=", "0.5", "\n", "k", "=", "int", "(", "n_images", "*", "percentage_train", ")", "\n", "\n", "#return images, cls, one_hot_encoded(class_numbers=cls, num_classes=num_classes)", "\n", "return", "images", "[", ":", "k", "]", ",", "cls", "[", ":", "k", "]", ",", "images", "[", "k", ":", "]", ",", "cls", "[", "k", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CIFAR10.CIFAR10.patch_data": [[495, 502], ["numpy.zeros", "numpy.random.randint", "range"], "methods", ["None"], ["", "def", "patch_data", "(", "self", ",", "data", ",", "patch_size", ")", ":", "\n", "        ", "patch_data", "=", "np", ".", "zeros", "(", "shape", "=", "(", "data", ".", "shape", "[", "0", "]", ",", "patch_size", ",", "patch_size", ",", "self", ".", "_num_channels", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "patch_index", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "_img_size", "-", "patch_size", "+", "1", ",", "size", "=", "(", "data", ".", "shape", "[", "0", "]", ",", "2", ")", ")", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "patch_data", "[", "i", "]", "=", "data", "[", "i", ",", "patch_index", "[", "i", ",", "0", "]", ":", "patch_index", "[", "i", ",", "0", "]", "+", "patch_size", ",", "\n", "patch_index", "[", "i", ",", "1", "]", ":", "patch_index", "[", "i", ",", "1", "]", "+", "patch_size", ",", ":", "]", "\n", "", "return", "patch_data", "#.reshape(data.shape[0], patch_size*patch_size*self._num_channels)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.__init__": [[64, 98], ["ImageDataset.ImageDataset.__init__", "DSprites.DSprites.dataset_id", "len", "DSprites.DSprites.load_data", "DSprites.DSprites.sub_sample", "DSprites.DSprites.sub_sample", "numpy.clip", "numpy.clip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "self", ".", "_normalize_data", "=", "self", ".", "_params", "[", "'normalize'", "]", "\n", "\n", "self", ".", "data_dir", "=", "\"/ssd_data/datasets/dSprites/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\"", "\n", "\n", "self", ".", "img_rows", "=", "64", "\n", "self", ".", "img_cols", "=", "64", "\n", "self", ".", "factors_frequencies", "=", "[", "3", ",", "6", ",", "40", ",", "32", ",", "32", "]", "\n", "self", ".", "num_factors", "=", "len", "(", "self", ".", "factors_frequencies", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_validation_set_y", ",", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "load_data", "(", ")", "\n", "\n", "# choose a subset", "\n", "if", "self", ".", "_params", "[", "'subsampling'", "]", ":", "\n", "            ", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_train_set_x", ",", "self", ".", "_train_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", "=", "self", ".", "sub_sample", "(", "self", ".", "_test_set_x", ",", "self", ".", "_test_set_y", ",", "self", ".", "_params", "[", "'subsampling'", "]", ")", "\n", "\n", "\n", "# clip", "\n", "", "clip_low", "=", "self", ".", "_params", "[", "'clip_low'", "]", "\n", "clip_high", "=", "self", ".", "_params", "[", "'clip_high'", "]", "\n", "if", "(", "clip_low", "is", "not", "None", ")", "or", "(", "clip_high", "is", "not", "None", ")", ":", "\n", "            ", "m", "=", "clip_low", "if", "clip_low", "is", "not", "None", "else", "0", "\n", "M", "=", "clip_high", "if", "clip_high", "is", "not", "None", "else", "1", "\n", "self", ".", "_train_set_x", "=", "np", ".", "clip", "(", "self", ".", "_train_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "self", ".", "_test_set_x", "=", "np", ".", "clip", "(", "self", ".", "_test_set_x", ",", "a_min", "=", "m", ",", "a_max", "=", "M", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.load_data": [[103, 141], ["numpy.load", "len", "numpy.random.permutation", "imgs.astype.astype.astype", "int", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["def", "load_data", "(", "self", ")", ":", "\n", "        ", "dtype", "=", "np", ".", "float32", "\n", "dtype_labels", "=", "np", ".", "int64", "\n", "\n", "dataset_zip", "=", "np", ".", "load", "(", "self", ".", "data_dir", ",", "encoding", "=", "'bytes'", ")", "\n", "imgs", "=", "dataset_zip", "[", "'imgs'", "]", "\n", "imgs", "=", "imgs", "[", ":", ",", ":", ",", ":", ",", "None", "]", "# make into 4d tensor", "\n", "\n", "# shuffle data", "\n", "n_data", "=", "len", "(", "imgs", ")", "\n", "labels", "=", "dataset_zip", "[", "'latents_classes'", "]", "\n", "\n", "randomized_dataset_index", "=", "np", ".", "random", ".", "permutation", "(", "n_data", ")", "\n", "\n", "imgs", "=", "imgs", "[", "randomized_dataset_index", "]", "\n", "labels", "=", "labels", "[", "randomized_dataset_index", "]", "\n", "\n", "# convert to float32", "\n", "imgs", "=", "imgs", ".", "astype", "(", "dtype", ")", "\n", "\n", "if", "self", ".", "_normalize_data", ":", "\n", "# convert to -1, 1", "\n", "            ", "imgs", "=", "imgs", "*", "2", "-", "1", "\n", "\n", "#split in train-validation-test", "\n", "", "validation_split", "=", "(", "1", "-", "(", "self", ".", "_params", "[", "\"test_proportion\"", "]", "+", "self", ".", "_params", "[", "\"validation_proportion\"", "]", ")", ")", "*", "n_data", "\n", "test_split", "=", "validation_split", "+", "self", ".", "_params", "[", "\"test_proportion\"", "]", "*", "n_data", "\n", "\n", "validation_split", ",", "test_split", "=", "int", "(", "validation_split", ")", ",", "int", "(", "test_split", ")", "\n", "\n", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "=", "imgs", "[", ":", "validation_split", ",", ":", "]", ",", "imgs", "[", "validation_split", ":", "test_split", ",", ":", "]", ",", "imgs", "[", "test_split", ":", ",", ":", "]", "\n", "train_set_y", ",", "validation_set_y", ",", "test_set_y", "=", "labels", "[", ":", "validation_split", ",", ":", "]", ",", "labels", "[", "validation_split", ":", "test_split", ",", ":", "]", ",", "labels", "[", "test_split", ":", ",", ":", "]", "\n", "\n", "return", "train_set_x", ",", "train_set_y", ",", "validation_set_x", ",", "validation_set_y", ",", "test_set_x", ",", "test_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.dataset_id": [[143, 175], ["DSprites.check_params_impl", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "# TODO: missing features are  train/test?", "\n", "DSprites", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'DSprites'", "\n", "\n", "# subsampling", "\n", "if", "params", "[", "'subsampling'", "]", ":", "\n", "            ", "id", "+=", "'-ss'", "+", "str", "(", "params", "[", "'subsampling'", "]", ")", "\n", "\n", "# clip", "\n", "# TODO The parameters of clip should be the values to which you clip", "\n", "", "clip_high", "=", "False", "\n", "if", "params", "[", "'clip_high'", "]", ":", "\n", "            ", "id", "+=", "'-cH'", "\n", "clip_high", "=", "True", "\n", "\n", "", "if", "params", "[", "'clip_low'", "]", ":", "\n", "            ", "id", "+=", "'-cL'", "\n", "if", "clip_high", ":", "\n", "                ", "id", "+=", "\"H\"", "\n", "\n", "# id note (keep last)", "\n", "", "", "if", "params", "[", "'id_note'", "]", ":", "\n", "            ", "id", "+=", "params", "[", "'id_note'", "]", "\n", "\n", "", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.sub_sample": [[176, 195], ["len", "numpy.random.permutation", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sub_sample", "(", "data_set_x", ",", "data_set_y", ",", "subsampling", ")", ":", "\n", "        ", "\"\"\"\n        return a value every \"subsampling\"\n\n        :param data_set_x\n        :param data_set_y\n        :param subsampling: integer < dim(data_set)\n        :return: dataset_x, dataset_y\n        \"\"\"", "\n", "\n", "len_train", "=", "len", "(", "data_set_x", ")", "\n", "reshuf_index_train", "=", "np", ".", "random", ".", "permutation", "(", "len_train", ")", "\n", "new_len_train", "=", "int", "(", "len_train", "/", "subsampling", ")", "\n", "\n", "data_set_x", "=", "data_set_x", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "data_set_y", "=", "data_set_y", "[", "reshuf_index_train", "[", ":", "new_len_train", "]", "]", "\n", "\n", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.class_filter": [[196, 221], ["numpy.in1d", "DSprites.DSprites.class_filter.replace_with_position"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "class_filter", "(", "data_set_x", ",", "data_set_y", ",", "classes", ",", "position_label", ")", ":", "\n", "        ", "\"\"\"\n        return the dataset with labels in the list classes\n\n        :param data_set_x: data\n        :param data_set_y: labels\n        :param classes:    list of classes\n        :param position_label:  list of classes\n        :return: (dataset_x, dataset_y) with filtered elemnts not in classes\n        \"\"\"", "\n", "\n", "ix_mtch_class_train", "=", "np", ".", "in1d", "(", "data_set_y", ",", "classes", ")", "\n", "data_set_x", "=", "data_set_x", "[", "ix_mtch_class_train", "]", "\n", "data_set_y", "=", "data_set_y", "[", "ix_mtch_class_train", "]", "\n", "if", "position_label", ":", "\n", "\n", "            ", "def", "replace_with_position", "(", "label_set", ",", "classes", ")", ":", "\n", "                ", "label_set_new", "=", "np", ".", "copy", "(", "label_set", ")", "\n", "for", "ix", ",", "class_", "in", "enumerate", "(", "classes", ")", ":", "label_set_new", "[", "label_set", "==", "class_", "]", "=", "ix", "\n", "return", "label_set_new", "\n", "\n", "", "data_set_y", "=", "replace_with_position", "(", "data_set_y", ",", "classes", ")", "\n", "\n", "", "return", "data_set_x", ",", "data_set_y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.input_size": [[222, 225], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "input_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "img_rows", "*", "self", ".", "img_cols", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.output_size": [[226, 229], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.color_images": [[230, 233], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "color_images", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.DSprites.DSprites.image_shape": [[234, 237], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "image_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "img_rows", ",", "self", ".", "img_cols", ",", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCP.HCP.__init__": [[15, 19], ["datasets.BrainDataset.BrainDataset.__init__", "HCP.HCP.load_float_brains"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BrainDataset.BrainDataset.load_float_brains"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "=", "self", ".", "load_float_brains", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCP.HCP.dataset_id": [[20, 29], ["super().dataset_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id"], ["", "def", "dataset_id", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "id", "=", "'HCP'", "\n", "\n", "id", "+=", "super", "(", ")", ".", "dataset_id", "(", "params", ")", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCP.HCP.x_shape_train": [[31, 34], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.HCP.HCP.x_shape_eval": [[36, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.__init__": [[23, 33], ["datasets.ImageDataset.ImageDataset.__init__", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_id", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_float_brats"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_float_brats"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "params", ")", "\n", "\n", "default_data_dir", "=", "'/ssd_data/BRATS_data/all_slices_separately_one'", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "if", "'data_dir'", "in", "params", "else", "default_data_dir", "\n", "# self._data_dir = default_data_dir", "\n", "\n", "self", ".", "_train_set_x", ",", "self", ".", "_validation_set_x", ",", "self", ".", "_test_set_x", "=", "self", ".", "load_float_brats", "(", "self", ".", "_data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_id": [[34, 46], ["BRATScnnLazyLoading_perSlice.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "BRATScnnLazyLoading_perSlice", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "id", "=", "'BRATScnnLazyLoading_perSlice'", "\n", "id", "+=", "'-'", "+", "params", "[", "'options'", "]", "\n", "\n", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_float_brats": [[47, 66], ["BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "print", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "print", "print", "print", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_float_brats", "(", "self", ",", "data_dir", ")", ":", "\n", "# data_dir = '/ssd_data/BRATS_data/all_slices_separately_one'", "\n", "\n", "        ", "datasets_tuple", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'hgg'", ")", "\n", "print", "(", "'---------DATASET TUPLE------------'", ",", "datasets_tuple", ".", "shape", ")", "\n", "\n", "train_set_x", "=", "datasets_tuple", "\n", "\n", "datasets_tuple_test", "=", "self", ".", "load_file_names", "(", "data_dir", ",", "'test'", ")", "\n", "print", "(", "'---------DATASET TUPLE TEST------------'", ",", "datasets_tuple_test", ".", "shape", ")", "\n", "\n", "validation_set_x", "=", "datasets_tuple_test", "\n", "test_set_x", "=", "datasets_tuple_test", "\n", "\n", "print", "(", "'--------------X SHAPE-----------------'", ")", "\n", "self", ".", "_train_set_x_shape", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", ")", ".", "shape", "+", "(", "1", ",", ")", "\n", "print", "(", "self", ".", "_train_set_x_shape", ")", "\n", "\n", "return", "train_set_x", ",", "validation_set_x", ",", "test_set_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slices_from_files": [[67, 78], ["os.walk", "numpy.asarray", "os.path.abspath", "numpy.load", "slice.astype.astype.astype", "numpy.asarray.append", "os.path.join", "slice.astype.astype.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slices_from_files", "(", "self", ",", "root", ")", ":", "\n", "        ", "slices", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "fullname", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ")", "\n", "slice", "=", "np", ".", "load", "(", "fullname", ")", "\n", "slice", "=", "slice", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slice", "=", "slice", "/", "(", "slice", ".", "max", "(", ")", ")", "\n", "slices", ".", "append", "(", "slice", ")", "\n", "", "", "slices", "=", "np", ".", "asarray", "(", "slices", ")", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_file_names": [[87, 94], ["os.walk", "numpy.asarray", "numpy.asarray.append"], "methods", ["None"], ["", "def", "load_file_names", "(", "self", ",", "root", ",", "data_type", ")", ":", "\n", "        ", "file_names", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", "+", "'/'", "+", "data_type", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "file_names", ".", "append", "(", "data_type", "+", "'/'", "+", "f", ")", "\n", "", "", "file_names", "=", "np", ".", "asarray", "(", "file_names", ")", "\n", "return", "file_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_map_filename_slice": [[95, 103], ["os.walk", "numpy.asarray", "range", "numpy.asarray.append"], "methods", ["None"], ["", "def", "load_map_filename_slice", "(", "self", ",", "root", ")", ":", "\n", "        ", "map_fn_s", "=", "[", "]", "\n", "for", "path", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "root", ")", ":", "\n", "            ", "for", "f", "in", "files", ":", "\n", "                ", "for", "slice", "in", "range", "(", "0", ",", "130", ")", ":", "\n", "                    ", "map_fn_s", ".", "append", "(", "(", "f", ",", "slice", ")", ")", "\n", "", "", "", "map_fn_s", "=", "np", ".", "asarray", "(", "map_fn_s", ")", "\n", "return", "map_fn_s", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slices_from_file": [[104, 110], ["numpy.load", "numpy.asarray.astype", "numpy.asarray", "numpy.asarray.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slices_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slices", "=", "np", ".", "load", "(", "file", ")", "\n", "slices", "=", "slices", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slices", "=", "slices", "/", "(", "slices", ".", "max", "(", ")", ")", "\n", "slices", "=", "np", ".", "asarray", "(", "slices", ")", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file": [[111, 116], ["numpy.load", "numpy.asarray.astype", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_slice_from_file", "(", "self", ",", "file", ")", ":", "\n", "        ", "slice", "=", "np", ".", "load", "(", "file", ")", "\n", "slice", "=", "slice", ".", "astype", "(", "np", ".", "float32", ")", "\n", "slice", "=", "np", ".", "asarray", "(", "slice", ")", "\n", "return", "slice", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_map": [[118, 134], ["BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "list", "dataset.map.map.map", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.reshape", "zip", "tuple", "str", "tensorflow.py_func"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slice_from_file"], ["", "def", "dataset_map", "(", "self", ",", "dataset", ",", "datasets_tuple", ")", ":", "\n", "        ", "output_types", "=", "self", ".", "get_output_types", "(", "datasets_tuple", ")", "\n", "\n", "def", "load_function", "(", "n", ")", ":", "\n", "            ", "filename", "=", "full_data", "[", "n", "]", "[", "0", "]", "\n", "image", "=", "self", ".", "load_slice_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "filename", ")", ")", "\n", "reshaped_img", "=", "image", ".", "reshape", "(", "[", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "return", "reshaped_img", "\n", "\n", "", "full_data", "=", "list", "(", "zip", "(", "*", "datasets_tuple", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "n", ":", "tuple", "(", "tf", ".", "py_func", "(", "load_function", ",", "\n", "[", "n", "]", ",", "output_types", ")", "\n", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes": [[135, 140], ["numpy.load().astype", "tuple", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_shapes", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_shapes", "=", "tuple", "(", "[", "image", ".", "shape", "+", "(", "1", ",", ")", "]", ")", "\n", "\n", "return", "output_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_types": [[141, 146], ["numpy.load().astype", "tuple", "numpy.load", "tensorflow.as_dtype"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "get_output_types", "(", "self", ",", "datasets_tuple", ")", ":", "\n", "        ", "image", "=", "np", ".", "load", "(", "self", ".", "_data_dir", "+", "'/'", "+", "datasets_tuple", "[", "0", "]", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "output_types", "=", "tuple", "(", "[", "tf", ".", "as_dtype", "(", "image", ".", "dtype", ")", "]", ")", "\n", "\n", "return", "output_types", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_raw_elements": [[147, 164], ["numpy.asarray", "images.reshape.reshape.reshape", "getattr", "getattr", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slices_from_file", "images.reshape.reshape.append", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.load_slices_from_file"], ["", "def", "get_raw_elements", "(", "self", ",", "dataset_str", ",", "index_list", "=", "None", ")", ":", "\n", "        ", "attribute_name", "=", "dataset_str", "+", "\"_set_x\"", "\n", "# print('-----------ATTRIBUTE NAME-----------', attribute_name)", "\n", "# print(getattr(self, attribute_name)[index_list])", "\n", "# pdb.set_trace()", "\n", "images", "=", "[", "]", "\n", "if", "index_list", "is", "not", "None", ":", "\n", "            ", "for", "file", "in", "getattr", "(", "self", ",", "attribute_name", ")", "[", "index_list", "]", ":", "\n", "                ", "image", "=", "self", ".", "load_slices_from_file", "(", "self", ".", "_data_dir", "+", "'/'", "+", "str", "(", "file", ")", ")", "\n", "# print(image.shape)", "\n", "images", ".", "append", "(", "image", ")", "\n", "", "images", "=", "np", ".", "asarray", "(", "images", ")", "\n", "images", "=", "images", ".", "reshape", "(", "[", "images", ".", "shape", "[", "0", "]", ",", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", ",", "1", "]", ")", "\n", "x_data", "=", "images", "\n", "", "else", ":", "\n", "            ", "x_data", "=", "getattr", "(", "self", ",", "attribute_name", ")", "\n", "", "return", "x_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_dataset_iterator": [[165, 265], ["print", "tensorflow.data.Dataset.range", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "print", "print", "BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.cache", "zip", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "hasattr", "node.set_shape", "hasattr", "Exception", "hasattr"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_output_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.dataset_map"], ["", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ")", ":", "\n", "        ", "is_perturbed", "=", "False", "\n", "datasets_tuple", "=", "None", "\n", "\n", "# create Dataset objects using the data previously downloaded", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "train_set_x", ",", ")", "\n", "if", "hasattr", "(", "self", ",", "\"perturbed_train_set_x\"", ")", "and", "self", ".", "perturbed_train_set_x", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "perturbed_train_set_x", ",", ")", "\n", "is_perturbed", "=", "True", "\n", "", "if", "self", ".", "_train_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "train_set_y", ",", ")", "\n", "\n", "", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "validation_set_x", ",", ")", "\n", "if", "hasattr", "(", "self", ",", "\"perturbed_validation_set_x\"", ")", "and", "self", ".", "perturbed_validation_set_x", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "perturbed_validation_set_x", ",", ")", "\n", "is_perturbed", "=", "True", "\n", "", "if", "self", ".", "_validation_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "validation_set_y", ",", ")", "\n", "\n", "", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "datasets_tuple", "=", "(", "self", ".", "test_set_x", ",", ")", "\n", "if", "hasattr", "(", "self", ",", "\"perturbed_test_set_x\"", ")", "and", "self", ".", "perturbed_test_set_x", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "perturbed_test_set_x", ",", ")", "\n", "is_perturbed", "=", "True", "\n", "", "if", "self", ".", "_test_set_y", "is", "not", "None", ":", "\n", "                ", "datasets_tuple", "=", "datasets_tuple", "+", "(", "self", ".", "test_set_y", ",", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "# # CREATE TF DATASET from slices", "\n", "# # from_tensor_slices is storing dataset in the graph thus making checkpoints huge", "\n", "# dataset = tf.data.Dataset.from_tensor_slices(datasets_tuple)", "\n", "# # CREATE TF DATASET from slices", "\n", "\n", "# # CREATE TF DATASET from generator", "\n", "# def generator():", "\n", "#     for sample in zip(*datasets_tuple):", "\n", "#         yield sample", "\n", "#", "\n", "# output_types = tuple([tf.as_dtype(ds[0].dtype) for ds in datasets_tuple])", "\n", "# output_shapes = tuple([ds[0].shape for ds in datasets_tuple])", "\n", "#", "\n", "# dataset = tf.data.Dataset.from_generator(generator, output_types=output_types,", "\n", "#                                             output_shapes=output_shapes)", "\n", "# # CREATE TF DATASET from generator", "\n", "#", "\n", "\n", "# CREATE TF DATASET with map and py_func", "\n", "\n", "", "n_samples", "=", "datasets_tuple", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "print", "(", "'------------MY N SAMPLES------------'", ",", "n_samples", ")", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "range", "(", "n_samples", ")", "\n", "\n", "output_shapes", "=", "self", ".", "get_output_shapes", "(", "datasets_tuple", ")", "\n", "print", "(", "'--------------output_shapes----------------'", ")", "\n", "print", "(", "output_shapes", ")", "\n", "\n", "# why should anything be None in datasets_tuple? it is not clear that it would work with the oytput_shapes...", "\n", "# output_types = tuple([tf.as_dtype(ds[0].dtype) for ds in datasets_tuple if ds is not None])", "\n", "# output_shapes = tuple([ds[0].shape for ds in datasets_tuple if ds is not None])", "\n", "\n", "dataset", "=", "self", ".", "dataset_map", "(", "dataset", ",", "datasets_tuple", ")", "\n", "\n", "def", "_set_shapes", "(", "*", "nodes", ")", ":", "\n", "            ", "for", "node", ",", "outshape", "in", "zip", "(", "nodes", ",", "output_shapes", ")", ":", "\n", "                ", "node", ".", "set_shape", "(", "outshape", ")", "\n", "", "return", "nodes", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "_set_shapes", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "# CREATE TF DATASET with map and py_func", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "# PREPROCESS DATA (AUGMENT IF NEEDED)", "\n", "# if augmentation_bool:", "\n", "#     dataset = dataset.map(partial(self._preprocess_element, is_perturbed), num_parallel_calls=NPROCS)", "\n", "\n", "# SHUFFLE, REPEAT and BATCH", "\n", "# we shuffle the data and sample repeatedly batches for training", "\n", "if", "shuffle", ":", "\n", "            ", "dataset", "=", "dataset", ".", "shuffle", "(", "n_samples", "+", "1", ")", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "# initializer = None", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "# initializer = iterator.initializer", "\n", "\n", "# batched_dataset = batched_dataset.prefetch(500)", "\n", "\n", "# get a training batch of images and labels", "\n", "", "return", "iterator", ",", "is_perturbed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.x_shape_train": [[267, 270], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.x_shape_eval": [[272, 275], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_train_set_x_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load": [[8, 31], ["sklearn.datasets.load_boston", "numpy.random.permutation", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["def", "load", "(", ")", ":", "\n", "    ", "boston", "=", "load_boston", "(", ")", "\n", "\n", "ds", "=", "{", "}", "\n", "\n", "n_points", "=", "boston", ".", "data", ".", "shape", "[", "0", "]", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "n_points", ")", "\n", "\n", "percentage_train", "=", "0.7", "\n", "\n", "ds", "[", "\"n_samples_train\"", "]", "=", "int", "(", "percentage_train", "*", "n_points", ")", "\n", "ds", "[", "\"n_samples_test\"", "]", "=", "n_points", "-", "int", "(", "percentage_train", "*", "n_points", ")", "\n", "ds", "[", "\"train_set_x\"", "]", "=", "boston", ".", "data", "[", ":", "int", "(", "percentage_train", "*", "n_points", ")", "]", "\n", "ds", "[", "\"train_set_y\"", "]", "=", "boston", ".", "target", "[", ":", "int", "(", "percentage_train", "*", "n_points", ")", "]", "\n", "ds", "[", "\"test_set_x\"", "]", "=", "boston", ".", "data", "[", "int", "(", "percentage_train", "*", "n_points", ")", ":", "]", "\n", "ds", "[", "\"test_set_y\"", "]", "=", "boston", ".", "target", "[", "int", "(", "percentage_train", "*", "n_points", ")", ":", "]", "\n", "\n", "ds", "[", "\"input_size\"", "]", "=", "13", "\n", "ds", "[", "\"output_size\"", "]", "=", "1", "\n", "\n", "ds", "[", "\"binary\"", "]", "=", "0", "\n", "\n", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.__init__": [[48, 65], ["datasets.AudioDataset.AudioDataset.__init__", "WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "WavFromGeneralMidi.process_params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.process_params"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "WavFromGeneralMidi", ".", "process_params", "(", "params", ")", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "dataset_id", "(", "self", ".", "_params", ")", "\n", "\n", "self", ".", "_data_dir", "=", "self", ".", "_params", "[", "'data_dir'", "]", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "_sample_lenght", "=", "32128", "+", "128", "# 128 padded 0s  # used to be 88384 for sample rate 44100", "\n", "self", ".", "_sample_rate", "=", "16000", "\n", "self", ".", "_shuffle_buffer", "=", "self", ".", "_params", "[", "'shuffle_buffer'", "]", "\n", "self", ".", "_label", "=", "(", "self", ".", "_params", "[", "'label'", "]", "if", "self", ".", "_params", "[", "'label'", "]", "in", "ALL_LABELS_IMPLEMENTED", "else", "None", ")", "\n", "\n", "# self._n_labels = len(self._params['features']) if 'features' in self._params else 0", "\n", "self", ".", "_x_sample_shape_train", "=", "[", "self", ".", "_crop_length_train", ",", "1", "]", "\n", "self", ".", "_x_sample_shape_eval", "=", "[", "self", ".", "_sample_lenght", ",", "1", "]", "\n", "self", ".", "_y_sample_shape", "=", "None", "# (self._n_labels,)", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.dataset_id": [[70, 86], ["WavFromGeneralMidi.check_params_impl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.check_params_impl"], ["", "@", "staticmethod", "\n", "def", "dataset_id", "(", "params", ")", ":", "\n", "        ", "\"\"\"\n        This method interprets the parameters and generate an id\n        \"\"\"", "\n", "\n", "WavFromGeneralMidi", ".", "check_params_impl", "(", "params", ")", "\n", "\n", "_id", "=", "'WavFromGeneralMidi'", "\n", "\n", "# TODO I know this is bad but if id is a static method and not an object method I have no idea how to handle this better,", "\n", "# TODO soon we should refactor the id to be multilayer of abstraction as in Networks and Models.", "\n", "if", "params", "[", "'shuffle_buffer'", "]", "!=", "WavFromGeneralMidi", ".", "default_params", "[", "'shuffle_buffer'", "]", ":", "\n", "            ", "_id", "+=", "'-sh%.2e'", "%", "params", "[", "'shuffle_buffer'", "]", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_var_labels": [[87, 92], ["numpy.intersect1d", "len", "len"], "methods", ["None"], ["", "def", "get_var_labels", "(", "self", ",", "param", ")", ":", "\n", "        ", "var_params", "=", "np", ".", "intersect1d", "(", "ALL_LABELS", ",", "param", ")", "\n", "\n", "assert", "len", "(", "var_params", ")", "==", "len", "(", "param", ")", ",", "\"It seems like you might have a mistake in you label name\"", "\n", "return", "var_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi._parse_function": [[93, 113], ["tensorflow.parse_single_example", "tensorflow.expand_dims", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.concat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_parse_function", "(", "example_proto", ",", "y_label", "=", "None", ")", ":", "\n", "        ", "features", "=", "{", "\n", "INSTR_FAMILY", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "INSTR_NAME", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "PITCH", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "VOL", ":", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "AUDIO", ":", "tf", ".", "FixedLenFeature", "(", "[", "32128", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "}", "\n", "parsed_features", "=", "tf", ".", "parse_single_example", "(", "example_proto", ",", "features", ")", "\n", "\n", "# add channel info for standardized input", "\n", "\n", "# We have to add 128 0's for the length to be devisible by 512, which is a common hop_size for this network", "\n", "audio", "=", "tf", ".", "expand_dims", "(", "tf", ".", "concat", "(", "[", "parsed_features", "[", "AUDIO", "]", ",", "[", "0", "]", "*", "128", "]", ",", "axis", "=", "0", ")", ",", "axis", "=", "-", "1", ")", "\n", "# audio = parsed_features[\"audio\"]", "\n", "if", "y_label", ":", "\n", "            ", "return", "(", "audio", ",", "parsed_features", "[", "y_label", "]", ",", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "audio", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.get_dataset_iterator": [[114, 176], ["tensorflow.data.TFRecordDataset", "dataset.repeat.repeat.map", "dataset.repeat.repeat.cache", "dataset.repeat.repeat.map", "dataset.repeat.repeat.map", "dataset.repeat.repeat.shuffle", "dataset.repeat.repeat.repeat", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_one_shot_iterator", "dataset.repeat.repeat.batch", "dataset.repeat.batch.make_initializable_iterator", "WavFromGeneralMidi.WavFromGeneralMidi._parse_function", "functools.partial", "functools.partial", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi._parse_function"], ["", "", "def", "get_dataset_iterator", "(", "self", ",", "batch_size", ",", "dataset_str", ",", "shuffle", ",", "repeat", ",", "augment", ")", ":", "\n", "\n", "        ", "is_perturbed", "=", "False", "\n", "filename", "=", "\"\"", "\n", "\n", "# create Dataset objects using the data previously downloaded", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/train-wav16-from-general-midi-sounds-float-shuffled.tfrecords\"", "\n", "\n", "", "elif", "dataset_str", "==", "VALIDATION", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/validation-wav16-from-general-midi-sounds-float-shuffled.tfrecords\"", "\n", "\n", "", "elif", "dataset_str", "==", "TEST", ":", "\n", "            ", "filename", "=", "self", ".", "_data_dir", "+", "\"/test-wav16-from-general-midi-sounds-float-shuffled.tfrecords\"", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"dataset not recognized (accepted values are: train, validation and test)\"", ")", "\n", "\n", "# CREATE TF DATASET with map and py_func", "\n", "", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "[", "filename", "]", ")", "\n", "\n", "NPROCS", "=", "20", "\n", "if", "self", ".", "_label", ":", "\n", "            ", "parse_func", "=", "lambda", "x", ":", "self", ".", "_parse_function", "(", "x", ",", "y_label", "=", "self", ".", "_label", ")", "\n", "", "else", ":", "\n", "            ", "parse_func", "=", "self", ".", "_parse_function", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "parse_func", ",", "\n", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# PREPROCESS DATA (CROP IF NEEDED, this is needed only for the train loop)", "\n", "if", "dataset_str", "==", "TRAIN", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_crop_element", ",", "is_perturbed", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# caching before shuffling and batching for super cow speed", "\n", "", "dataset", "=", "dataset", ".", "cache", "(", ")", "\n", "\n", "# PREPROCESS DATA (AUGMENT IF NEEDED)", "\n", "if", "augment", ":", "\n", "            ", "dataset", "=", "dataset", ".", "map", "(", "partial", "(", "self", ".", "_preprocess_element", ",", "is_perturbed", ")", ",", "num_parallel_calls", "=", "NPROCS", ")", "\n", "\n", "# SHUFFLE, REPEAT and BATCH", "\n", "# we shuffle the data and sample repeatedly batches for the training loop", "\n", "", "if", "shuffle", ":", "\n", "            ", "if", "self", ".", "_shuffling_cache", "is", "None", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffle_buffer", "+", "1", "\n", "", "else", ":", "\n", "                ", "shuffling_cache", "=", "self", ".", "_shuffling_cache", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "shuffling_cache", ")", "\n", "\n", "", "if", "repeat", ":", "\n", "            ", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "# create iterator to retrieve batches", "\n", "iterator", "=", "batched_dataset", ".", "make_one_shot_iterator", "(", ")", "\n", "", "else", ":", "\n", "            ", "batched_dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "iterator", "=", "batched_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "", "return", "iterator", ",", "is_perturbed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.n_samples_train": [[177, 180], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_samples_train", "(", "self", ")", ":", "\n", "        ", "return", "39820", "# 39737 used to be with 44140", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.x_shape_train": [[183, 187], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_train", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.x_shape_eval": [[188, 192], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "x_shape_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an input sample\"\"\"", "\n", "return", "self", ".", "_x_sample_shape_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.y_shape": [[193, 197], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "y_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.WavFromGeneralMidi.WavFromGeneralMidi.sample_rate": [[198, 202], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"return the shape of an output sample\"\"\"", "\n", "return", "self", ".", "_sample_rate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightness": [[5, 11], ["tensorflow.random_uniform", "isinstance", "tuple", "tensorflow.image.adjust_brightness", "tensorflow.image.adjust_brightness"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightness", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightness"], ["def", "adjust_brightness", "(", "images", ",", "max_delta", ")", ":", "\n", "    ", "delta", "=", "tf", ".", "random_uniform", "(", "[", "1", "]", ",", "-", "max_delta", ",", "max_delta", ",", "dtype", "=", "tf", ".", "float32", ")", "#shape, min, max", "\n", "if", "isinstance", "(", "images", ",", "list", ")", ":", "\n", "        ", "return", "tuple", "(", "[", "tf", ".", "image", ".", "adjust_brightness", "(", "image", ",", "delta", ")", "for", "image", "in", "images", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "image", ".", "adjust_brightness", "(", "images", ",", "delta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightnessAsym": [[12, 39], ["tensorflow.random_uniform", "isinstance", "isinstance", "Exception", "tuple", "tensorflow.slice", "tensorflow.slice", "tensorflow.image.adjust_brightness", "tensorflow.concat", "tuple", "tensorflow.image.adjust_brightness", "tensorflow.image.adjust_brightness", "images.shape[].as_list", "images.shape[].as_list", "tensorflow.image.adjust_brightness"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightness", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightness", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightness", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.adjust_brightness"], ["", "", "def", "adjust_brightnessAsym", "(", "images", ",", "min_delta", ",", "max_delta", ",", "mask", "=", "0", ")", ":", "\n", "    ", "delta", "=", "tf", ".", "random_uniform", "(", "[", "1", "]", ",", "min_delta", ",", "max_delta", ",", "dtype", "=", "tf", ".", "float32", ")", "#shape, min, max", "\n", "\n", "if", "mask", "==", "1", ":", "\n", "\n", "        ", "if", "isinstance", "(", "images", ",", "list", ")", ":", "\n", "\n", "            ", "raise", "Exception", "(", "\"talk to Luigi\"", ")", "\n", "return", "tuple", "(", "[", "tf", ".", "image", ".", "adjust_brightness", "(", "image", ",", "delta", ")", "for", "image", "in", "images", "]", ")", "\n", "", "else", ":", "\n", "\n", "# do not apply the transformation to the mask", "\n", "\n", "            ", "init_dims", "=", "[", "0", "for", "s", "in", "images", ".", "shape", "[", ":", "-", "1", "]", ".", "as_list", "(", ")", "]", "\n", "end_dims", "=", "[", "-", "1", "for", "s", "in", "images", ".", "shape", "[", ":", "-", "1", "]", ".", "as_list", "(", ")", "]", "\n", "\n", "mask", "=", "tf", ".", "slice", "(", "images", ",", "init_dims", "+", "[", "0", "]", ",", "end_dims", "+", "[", "1", "]", ")", "\n", "image", "=", "tf", ".", "slice", "(", "images", ",", "init_dims", "+", "[", "1", "]", ",", "end_dims", "+", "[", "-", "1", "]", ")", "\n", "\n", "image", "=", "tf", ".", "image", ".", "adjust_brightness", "(", "image", ",", "delta", ")", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "mask", ",", "image", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "isinstance", "(", "images", ",", "list", ")", ":", "\n", "            ", "return", "tuple", "(", "[", "tf", ".", "image", ".", "adjust_brightness", "(", "image", ",", "delta", ")", "for", "image", "in", "images", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "tf", ".", "image", ".", "adjust_brightness", "(", "images", ",", "delta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.flip_up_down": [[41, 46], ["isinstance", "tuple", "tensorflow.image.flip_up_down", "tensorflow.image.flip_up_down"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.flip_up_down", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.flip_up_down"], ["", "", "", "def", "flip_up_down", "(", "images", ")", ":", "\n", "    ", "if", "isinstance", "(", "images", ",", "list", ")", ":", "\n", "        ", "return", "tuple", "(", "[", "tf", ".", "image", ".", "flip_up_down", "(", "image", ")", "for", "image", "in", "images", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "image", ".", "flip_up_down", "(", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.flip_left_right": [[47, 52], ["isinstance", "tuple", "tensorflow.image.flip_left_right", "tensorflow.image.flip_left_right"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.flip_left_right", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.flip_left_right"], ["", "", "def", "flip_left_right", "(", "images", ")", ":", "\n", "    ", "if", "isinstance", "(", "images", ",", "list", ")", ":", "\n", "        ", "return", "tuple", "(", "[", "tf", ".", "image", ".", "flip_left_right", "(", "image", ")", "for", "image", "in", "images", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "image", ".", "flip_left_right", "(", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.rot90": [[53, 58], ["isinstance", "tuple", "tensorflow.image.rot90", "tensorflow.image.rot90"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.rot90", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Augmentations.rot90"], ["", "", "def", "rot90", "(", "images", ")", ":", "\n", "    ", "if", "isinstance", "(", "images", ",", "list", ")", ":", "\n", "        ", "return", "tuple", "(", "[", "tf", ".", "image", ".", "rot90", "(", "image", ")", "for", "image", "in", "images", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "image", ".", "rot90", "(", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.argo.runPointwiseHooks.load_and_run_hook": [[39, 130], ["tf.reset_default_graph", "ArgoLauncher.process_conf_file", "config.update", "Dataset.load_dataset", "argo.core.utils.argo_utils.load_class", "model_parameters.update", "model_parameters.update", "argo.core.utils.argo_utils.load_class.", "ArgoTFDeepLearningModelClass.init", "ArgoTFDeepLearningModelClass._init_session_saver", "ArgoTFDeepLearningModelClass.create_session", "ArgoTFDeepLearningModelClass.restore", "ArgoTFDeepLearningModelClass.get_raw_session().run", "ArgoTFDeepLearningModelClass._get_steps", "ArgoTFDeepLearningModelClass.sess.run", "ArgoTFDeepLearningModelClass.sess.run", "config.pop", "os.path.split", "os.path.split", "ArgoTFDeepLearningModelClass.hooks.remove", "os.path.dirname", "os.path.dirname", "ArgoTFDeepLearningModelClass.get_raw_session", "hook._timer.reset", "hook._timer.update_last_triggered_step", "to_remove.append", "type", "numpy.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.init", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._init_session_saver", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_session", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.reset"], ["def", "load_and_run_hook", "(", "conf_file", ",", "global_step", ")", ":", "\n", "    ", "import", "tensorflow", "as", "tf", "\n", "from", "datasets", ".", "Dataset", "import", "Dataset", "\n", "from", "argo", ".", "core", ".", "ArgoLauncher", "import", "ArgoLauncher", "\n", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "# ######################################################", "\n", "# # LOAD THE WHOLE MODEL WITH ITS OWN MONITOREDSESSION #", "\n", "# ######################################################", "\n", "#", "\n", "dataset_conf", ",", "model_parameters", ",", "config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "conf_file", ")", "\n", "config", ".", "update", "(", "hooksconfig", ")", "\n", "\n", "#remove hooks that I do not want to trigger", "\n", "config", "[", "\"save_summaries\"", "]", "=", "False", "\n", "config", "[", "\"save_model\"", "]", "=", "False", "\n", "config", "[", "\"stats_period\"", "]", "=", "17e300", "# an insanely large number, one of the biggest int before inf", "\n", "hooks_to_remove", "=", "[", "'LoggingMeanTensorsHook'", ",", "\n", "'GradientsHook'", ",", "\n", "]", "\n", "for", "key", "in", "hooks_to_remove", ":", "\n", "        ", "config", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "dataset", "=", "Dataset", ".", "load_dataset", "(", "dataset_conf", ")", "\n", "\n", "ArgoTFDeepLearningModelClass", "=", "load_class", "(", "model_parameters", "[", "\"model\"", "]", ",", "base_path", "=", "model_class_base_path", ")", "\n", "# add information about the dataset for the launchable construction, needed in view of future keras compatibility", "\n", "# try catch to allow compatibility for datasets which do not have labels (see Dataset interface)", "\n", "try", ":", "\n", "        ", "output_shape", "=", "dataset", ".", "y_shape", "\n", "", "except", "ValueError", ":", "\n", "        ", "output_shape", "=", "None", "\n", "\n", "", "dataset_info", "=", "{", "\"output_shape\"", ":", "output_shape", ",", "\n", "\"input_shape\"", ":", "dataset", ".", "x_shape_train", "}", "\n", "\n", "model_parameters", ".", "update", "(", "dataset_info", ")", "\n", "\n", "model_dir", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "dirname", "(", "conf_file", ")", ")", "[", "0", "]", "\n", "\n", "try", ":", "\n", "        ", "output_shape", "=", "dataset", ".", "y_shape", "\n", "", "except", "ValueError", ":", "\n", "        ", "output_shape", "=", "None", "\n", "\n", "", "dataset_info", "=", "{", "\"output_shape\"", ":", "output_shape", ",", "\n", "\"input_shape\"", ":", "dataset", ".", "x_shape_train", "}", "\n", "\n", "model_parameters", ".", "update", "(", "dataset_info", ")", "\n", "\n", "model", "=", "ArgoTFDeepLearningModelClass", "(", "model_parameters", ",", "model_dir", ",", "gpu", "=", "gpu", ",", "seed", "=", "seed", ")", "\n", "model", ".", "init", "(", "dataset", ")", "\n", "\n", "# network = model._network", "\n", "# network.init_saver()", "\n", "\n", "x_shape", "=", "(", "1", ",", ")", "+", "model", ".", "x_shape", "[", "'train'", "]", "\n", "\n", "# # I want input shape but I don't want to pass by the handle, which might have more None shapes (if loop dataset has cropping)", "\n", "# train_loop_iter, _ = dataset.get_dataset_iterator(1, \"train\", shuffle=1, repeat=1, augment=1)", "\n", "# x_shape = train_loop_iter.get_next()[0].shape.as_list()", "\n", "# for i,d in enumerate(x_shape):", "\n", "#     if d is None:", "\n", "#         x_shape[i] = 1", "\n", "\n", "model", ".", "_init_session_saver", "(", ")", "\n", "model", ".", "create_session", "(", "model_parameters", ",", "config", ")", "\n", "#if global_step is None it will restore the last checkpoint in the folder model._checkpoint_dir, you can pass global_step to restore a particular chackpoint", "\n", "model", ".", "restore", "(", "global_step", "=", "global_step", ")", "\n", "# this is needed in case global_step was None, to load last step", "\n", "global_step", "=", "model", ".", "get_raw_session", "(", ")", ".", "run", "(", "model", ".", "global_step", ")", "\n", "\n", "# I force the trigger for the hooks in the config file", "\n", "max_steps", "=", "model", ".", "_get_steps", "(", "fix_period", ",", "model", ".", "_time_reference_str", ")", "\n", "\n", "# need extra list cos cannot remove elements while iterating", "\n", "to_remove", "=", "[", "]", "\n", "for", "hook", "in", "model", ".", "hooks", ":", "\n", "        ", "if", "type", "(", "hook", ")", ".", "__name__", "in", "hook_keys", ":", "\n", "            ", "hook", ".", "_timer", ".", "reset", "(", ")", "\n", "hook", ".", "_timer", ".", "update_last_triggered_step", "(", "global_step", "-", "max_steps", ")", "\n", "", "else", ":", "\n", "            ", "to_remove", ".", "append", "(", "hook", ")", "\n", "\n", "", "", "for", "h", "in", "to_remove", ":", "\n", "        ", "model", ".", "hooks", ".", "remove", "(", "h", ")", "\n", "\n", "# two times to trigger the hooks, since first step they are disabled by design", "\n", "", "gs", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "global_step", ",", "feed_dict", "=", "{", "model", ".", "raw_x", ":", "np", ".", "zeros", "(", "x_shape", ")", "}", ")", "\n", "gs", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "global_step", ",", "feed_dict", "=", "{", "model", ".", "raw_x", ":", "np", ".", "zeros", "(", "x_shape", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.argo.plotStats.index_of": [[7, 12], ["enumerate"], "function", ["None"], ["def", "index_of", "(", "str_value", ",", "list_", ")", ":", "\n", "    ", "for", "i", ",", "value", "in", "enumerate", "(", "list_", ")", ":", "\n", "        ", "if", "str_value", "in", "value", ":", "\n", "            ", "return", "i", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.argo.plotStats.interesting_features_from_name": [[14, 23], ["model_name.split", "final_model_features.append"], "function", ["None"], ["", "def", "interesting_features_from_name", "(", "model_name", ",", "features", "=", "[", "'wu'", ",", "'hl'", ",", "'oc'", ",", "'sc'", ",", "'lc'", ",", "'lp'", ",", "'vl'", ",", "'hc'", "]", ")", ":", "\n", "    ", "model_features", "=", "model_name", ".", "split", "(", "'-'", ")", "\n", "final_model_features", "=", "[", "]", "\n", "for", "model_feature", "in", "model_features", ":", "\n", "        ", "for", "feature", "in", "features", ":", "\n", "            ", "if", "feature", "in", "model_feature", ":", "\n", "                ", "final_model_features", ".", "append", "(", "model_feature", ")", "\n", "\n", "", "", "", "return", "'__'", ".", "join", "(", "final_model_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.argo.runHooksConf.load_and_run_hook": [[111, 188], ["tf.reset_default_graph", "ArgoLauncher.process_conf_file", "config.update", "Dataset.load_dataset", "argo.core.utils.argo_utils.load_class", "argo.core.utils.argo_utils.load_class.", "ArgoTFDeepLearningModelClass.init", "ArgoTFDeepLearningModelClass._init_session_saver", "ArgoTFDeepLearningModelClass.create_session", "tf_logging.info", "config.pop", "config.pop", "config.pop", "os.path.split", "os.path.split", "tuple", "tf_logging.info", "ArgoTFDeepLearningModelClass.get_raw_session().run", "ArgoTFDeepLearningModelClass._get_steps", "ArgoTFDeepLearningModelClass.sess.run", "ArgoTFDeepLearningModelClass.sess.run", "os.path.dirname", "os.path.dirname", "ArgoTFDeepLearningModelClass.restore", "ArgoTFDeepLearningModelClass.hooks.remove", "str", "print", "ArgoTFDeepLearningModelClass.get_raw_session", "hook._timer.reset", "hook.before_training", "hook._timer.update_last_triggered_step", "to_remove.append", "type", "numpy.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.init", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._init_session_saver", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.reset", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.before_training"], ["def", "load_and_run_hook", "(", "conf_file", ",", "global_steps_list", ")", ":", "\n", "    ", "import", "tensorflow", "as", "tf", "\n", "from", "datasets", ".", "Dataset", "import", "Dataset", "\n", "from", "argo", ".", "core", ".", "ArgoLauncher", "import", "ArgoLauncher", "\n", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "# ######################################################", "\n", "# # LOAD THE WHOLE MODEL WITH ITS OWN MONITOREDSESSION #", "\n", "# ######################################################", "\n", "#", "\n", "dataset_conf", ",", "model_parameters", ",", "config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "conf_file", ")", "\n", "if", "'WavReconstructHook'", "not", "in", "hooks", ":", "\n", "        ", "config", ".", "pop", "(", "'WavReconstructHook'", ")", "\n", "", "if", "'WavGenerateHook'", "not", "in", "hooks", ":", "\n", "        ", "config", ".", "pop", "(", "'WavGenerateHook'", ")", "\n", "\n", "", "config", ".", "update", "(", "hooks", ")", "\n", "\n", "# remove hooks that I do not want to trigger", "\n", "config", "[", "\"save_summaries\"", "]", "=", "False", "\n", "config", "[", "\"save_model\"", "]", "=", "False", "\n", "config", "[", "\"stats_period\"", "]", "=", "17e300", "# an insanely large number, one of the biggest int before inf", "\n", "hooks_to_remove", "=", "[", "\n", "'LoggingMeanTensorsHook'", ",", "\n", "'GradientsHook'", ",", "\n", "]", "\n", "for", "key", "in", "hooks_to_remove", ":", "\n", "        ", "config", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "dataset", "=", "Dataset", ".", "load_dataset", "(", "dataset_conf", ")", "\n", "ArgoTFDeepLearningModelClass", "=", "load_class", "(", "model_parameters", "[", "\"model\"", "]", ",", "base_path", "=", "model_class_base_path", ")", "\n", "\n", "model_dir", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "dirname", "(", "conf_file", ")", ")", "[", "0", "]", "\n", "model", "=", "ArgoTFDeepLearningModelClass", "(", "model_parameters", ",", "model_dir", ",", "gpu", "=", "gpu", ",", "seed", "=", "seed", ")", "\n", "model", ".", "init", "(", "dataset", ")", "\n", "\n", "# network = model._network", "\n", "# network.init_saver()", "\n", "\n", "x_shape", "=", "(", "1", ",", ")", "+", "tuple", "(", "model", ".", "x_shape", "[", "'train'", "]", ")", "\n", "\n", "model", ".", "_init_session_saver", "(", ")", "\n", "model", ".", "create_session", "(", "model_parameters", ",", "config", ")", "\n", "\n", "# if global_step is None it will restore the last checkpoint in the folder model._checkpoint_dir, you can pass global_step to restore a particular chackpoint", "\n", "for", "global_step", "in", "global_steps_list", ":", "\n", "        ", "tf_logging", ".", "info", "(", "'...Running global step... '", "+", "str", "(", "global_step", ")", ")", "\n", "try", ":", "\n", "            ", "model", ".", "restore", "(", "global_step", "=", "global_step", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "print", "(", "'-----LOAD EXCEPTION: could not LOAD model at step'", ",", "global_step", ")", "\n", "continue", "\n", "# this is needed in case global_step was None, to load last step", "\n", "", "global_step", "=", "model", ".", "get_raw_session", "(", ")", ".", "run", "(", "model", ".", "global_step", ")", "\n", "\n", "# I force the trigger for the hooks in the config file", "\n", "max_steps", "=", "model", ".", "_get_steps", "(", "fix_period", ",", "model", ".", "_time_reference_str", ")", "\n", "\n", "# need extra list cos cannot remove elements while iterating", "\n", "to_remove", "=", "[", "]", "\n", "for", "hook", "in", "model", ".", "hooks", ":", "\n", "            ", "if", "type", "(", "hook", ")", ".", "__name__", "in", "hook_keys", ":", "\n", "                ", "hook", ".", "_timer", ".", "reset", "(", ")", "\n", "hook", ".", "before_training", "(", "model", ".", "sess", ")", "\n", "hook", ".", "_timer", ".", "update_last_triggered_step", "(", "global_step", "-", "max_steps", ")", "\n", "", "else", ":", "\n", "                ", "to_remove", ".", "append", "(", "hook", ")", "\n", "\n", "", "", "for", "h", "in", "to_remove", ":", "\n", "            ", "model", ".", "hooks", ".", "remove", "(", "h", ")", "\n", "\n", "# two times to trigger the hooks, since first step they are disabled by design", "\n", "", "gs", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "global_step", ",", "feed_dict", "=", "{", "model", ".", "raw_x", ":", "np", ".", "zeros", "(", "x_shape", ")", "}", ")", "\n", "gs", "=", "model", ".", "sess", ".", "run", "(", "model", ".", "global_step", ",", "feed_dict", "=", "{", "model", ".", "raw_x", ":", "np", ".", "zeros", "(", "x_shape", ")", "}", ")", "\n", "\n", "", "tf_logging", ".", "info", "(", "'Finished with model...'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.scripts.testingVAE.l2_reconstr_error": [[64, 71], ["numpy.zeros", "range", "numpy.average", "vae.reconstruct", "numpy.linalg.norm", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.reconstruct"], ["def", "l2_reconstr_error", "(", "X", ",", "no_passes", ")", ":", "\n", "    ", "errors", "=", "np", ".", "zeros", "(", "(", "no_passes", ",", "np", ".", "shape", "(", "X", ")", "[", "0", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "no_passes", ")", ":", "\n", "        ", "reconstr", ",", "_", ",", "_", ",", "_", ",", "_", "=", "vae", ".", "reconstruct", "(", "X", ")", "\n", "l2_error", "=", "np", ".", "linalg", ".", "norm", "(", "X", "-", "reconstr", ",", "ord", "=", "2", ",", "axis", "=", "1", ")", "\n", "errors", "[", "i", "]", "=", "l2_error", "\n", "", "return", "np", ".", "average", "(", "errors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.scripts.calibrate.make_list": [[18, 20], ["isinstance"], "function", ["None"], ["def", "make_list", "(", "l", ")", ":", "\n", "    ", "return", "l", "if", "isinstance", "(", "l", ",", "list", ")", "else", "[", "l", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.scripts.calibrate.write_conf_file": [[21, 25], ["open", "open.write", "open.close", "pprint.pformat"], "function", ["None"], ["", "def", "write_conf_file", "(", "outputname", ",", "conf", ")", ":", "\n", "    ", "f", "=", "open", "(", "outputname", ",", "'w'", ")", "\n", "f", ".", "write", "(", "pprint", ".", "pformat", "(", "conf", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.scripts.calibrate.write_final_log": [[26, 33], ["open", "open.write", "open.write", "open.close", "str", "datetime.timedelta"], "function", ["None"], ["", "def", "write_final_log", "(", "outputname", ",", "startTime", ",", "endTime", ")", ":", "\n", "    ", "f", "=", "open", "(", "outputname", ",", "'w'", ")", "\n", "elapsed", "=", "endTime", "-", "startTime", "\n", "f", ".", "write", "(", "\"time: \"", "+", "str", "(", "timedelta", "(", "seconds", "=", "elapsed", ")", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Done\"", ")", "\n", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.block_inception_a": [[34, 53], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d"], "function", ["None"], ["def", "block_inception_a", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Inception-A block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionA'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "        ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.block_reduction_a": [[55, 73], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d"], "function", ["None"], ["", "", "", "def", "block_reduction_a", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Reduction-A block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockReductionA'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.block_inception_b": [[75, 97], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d"], "function", ["None"], ["", "", "", "def", "block_inception_b", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Inception-B block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionB'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "192", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "224", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0c_1x7'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "224", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0d_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0e_1x7'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "        ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.block_reduction_b": [[99, 119], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d"], "function", ["None"], ["", "", "", "def", "block_reduction_b", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Reduction-B block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockReductionB'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "192", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.block_inception_c": [[121, 145], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d"], "function", ["None"], ["", "", "", "def", "block_inception_c", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Inception-C block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionC'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "448", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_3x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "512", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_1x3'", ")", "\n", "branch_2", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0d_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0e_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "        ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.inception_v4_base": [[147, 255], ["ValueError", "tensorflow.variable_scope", "slim.arg_scope", "slim.conv2d", "inception_v4.inception_v4_base.add_and_check_final"], "function", ["None"], ["", "", "", "def", "inception_v4_base", "(", "inputs", ",", "final_endpoint", "=", "'Mixed_7d'", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Inception V4 network up to the given final endpoint.\n\n  Args:\n    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n    final_endpoint: specifies the endpoint to construct the network up to.\n      It can be one of [ 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n      'Mixed_3a', 'Mixed_4a', 'Mixed_5a', 'Mixed_5b', 'Mixed_5c', 'Mixed_5d',\n      'Mixed_5e', 'Mixed_6a', 'Mixed_6b', 'Mixed_6c', 'Mixed_6d', 'Mixed_6e',\n      'Mixed_6f', 'Mixed_6g', 'Mixed_6h', 'Mixed_7a', 'Mixed_7b', 'Mixed_7c',\n      'Mixed_7d']\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the logits outputs of the model.\n    end_points: the set of end_points from the inception model.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "\n", "def", "add_and_check_final", "(", "name", ",", "net", ")", ":", "\n", "    ", "end_points", "[", "name", "]", "=", "net", "\n", "return", "name", "==", "final_endpoint", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV4'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# 299 x 299 x 3", "\n", "      ", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "32", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_1a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 149 x 149 x 32", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_2a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 32", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_2b_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2b_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 64", "\n", "with", "tf", ".", "variable_scope", "(", "'Mixed_3a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_0a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_3a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 73 x 73 x 160", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Mixed_4a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "96", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "64", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "64", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "96", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_4a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 71 x 71 x 192", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Mixed_5a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_5a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 35 x 35 x 384", "\n", "# 4 x Inception-A blocks", "\n", "", "for", "idx", "in", "range", "(", "4", ")", ":", "\n", "        ", "block_scope", "=", "'Mixed_5'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_a", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 35 x 35 x 384", "\n", "# Reduction-A block", "\n", "", "net", "=", "block_reduction_a", "(", "net", ",", "'Mixed_6a'", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_6a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 17 x 17 x 1024", "\n", "# 7 x Inception-B blocks", "\n", "for", "idx", "in", "range", "(", "7", ")", ":", "\n", "        ", "block_scope", "=", "'Mixed_6'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_b", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 17 x 17 x 1024", "\n", "# Reduction-B block", "\n", "", "net", "=", "block_reduction_b", "(", "net", ",", "'Mixed_7a'", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_7a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 8 x 8 x 1536", "\n", "# 3 x Inception-C blocks", "\n", "for", "idx", "in", "range", "(", "3", ")", ":", "\n", "        ", "block_scope", "=", "'Mixed_7'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_c", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "", "", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.inception_v4": [[257, 334], ["tensorflow.variable_scope", "slim.arg_scope", "inception_v4.inception_v4_base", "slim.arg_scope", "tensorflow.variable_scope", "kernel_size.is_fully_defined", "slim.dropout", "slim.flatten", "slim.fully_connected", "tensorflow.nn.softmax", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "slim.conv2d", "slim.flatten", "slim.fully_connected", "tf.reduce_mean.get_shape", "slim.avg_pool2d", "tensorflow.reduce_mean", "slim.fully_connected.get_shape"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_v4.inception_v4_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax"], ["", "def", "inception_v4", "(", "inputs", ",", "num_classes", "=", "1001", ",", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionV4'", ",", "\n", "create_aux_logits", "=", "True", ")", ":", "\n", "  ", "\"\"\"Creates the Inception V4 model.\n\n  Args:\n    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n    num_classes: number of predicted classes. If 0 or None, the logits layer\n      is omitted and the input features to the logits layer (before dropout)\n      are returned instead.\n    is_training: whether is training or not.\n    dropout_keep_prob: float, the fraction to keep before final layer.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n    create_aux_logits: Whether to include the auxiliary logits.\n\n  Returns:\n    net: a Tensor with the logits (pre-softmax activations) if num_classes\n      is a non-zero integer, or the non-dropped input to the logits layer\n      if num_classes is 0 or None.\n    end_points: the set of end_points from the inception model.\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV4'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "      ", "net", ",", "end_points", "=", "inception_v4_base", "(", "inputs", ",", "scope", "=", "scope", ")", "\n", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# Auxiliary Head logits", "\n", "        ", "if", "create_aux_logits", "and", "num_classes", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'AuxLogits'", ")", ":", "\n", "# 17 x 17 x 1024", "\n", "            ", "aux_logits", "=", "end_points", "[", "'Mixed_6h'", "]", "\n", "aux_logits", "=", "slim", ".", "avg_pool2d", "(", "aux_logits", ",", "[", "5", ",", "5", "]", ",", "stride", "=", "3", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a_5x5'", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "aux_logits", ",", "128", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_1b_1x1'", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "aux_logits", ",", "768", ",", "\n", "aux_logits", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_2a'", ")", "\n", "aux_logits", "=", "slim", ".", "flatten", "(", "aux_logits", ")", "\n", "aux_logits", "=", "slim", ".", "fully_connected", "(", "aux_logits", ",", "num_classes", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Aux_logits'", ")", "\n", "end_points", "[", "'AuxLogits'", "]", "=", "aux_logits", "\n", "\n", "# Final pooling and prediction", "\n", "# TODO(sguada,arnoegw): Consider adding a parameter global_pool which", "\n", "# can be set to False to disable pooling here (as in resnet_*()).", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "# 8 x 8 x 1536", "\n", "          ", "kernel_size", "=", "net", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", "\n", "if", "kernel_size", ".", "is_fully_defined", "(", ")", ":", "\n", "            ", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "kernel_size", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a'", ")", "\n", "", "else", ":", "\n", "            ", "net", "=", "tf", ".", "reduce_mean", "(", "net", ",", "[", "1", ",", "2", "]", ",", "keep_dims", "=", "True", ",", "\n", "name", "=", "'global_pool'", ")", "\n", "", "end_points", "[", "'global_pool'", "]", "=", "net", "\n", "if", "not", "num_classes", ":", "\n", "            ", "return", "net", ",", "end_points", "\n", "# 1 x 1 x 1536", "\n", "", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "scope", "=", "'Dropout_1b'", ")", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ",", "scope", "=", "'PreLogitsFlatten'", ")", "\n", "end_points", "[", "'PreLogitsFlatten'", "]", "=", "net", "\n", "# 1536", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "net", ",", "num_classes", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Logits'", ")", "\n", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "'Predictions'", ")", "\n", "", "", "", "return", "logits", ",", "end_points", "\n", "", "", "inception_v4", ".", "default_image_size", "=", "299", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.int64_feature": [[30, 42], ["tensorflow.train.Feature", "isinstance", "tensorflow.train.Int64List"], "function", ["None"], ["def", "int64_feature", "(", "values", ")", ":", "\n", "  ", "\"\"\"Returns a TF-Feature of int64s.\n\n  Args:\n    values: A scalar or list of values.\n\n  Returns:\n    A TF-Feature.\n  \"\"\"", "\n", "if", "not", "isinstance", "(", "values", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "    ", "values", "=", "[", "values", "]", "\n", "", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.bytes_list_feature": [[44, 54], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "bytes_list_feature", "(", "values", ")", ":", "\n", "  ", "\"\"\"Returns a TF-Feature of list of bytes.\n\n  Args:\n    values: A string or list of strings.\n\n  Returns:\n    A TF-Feature.\n  \"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.float_list_feature": [[56, 66], ["tensorflow.train.Feature", "tensorflow.train.FloatList"], "function", ["None"], ["", "def", "float_list_feature", "(", "values", ")", ":", "\n", "  ", "\"\"\"Returns a TF-Feature of list of floats.\n\n  Args:\n    values: A float or list of floats.\n\n  Returns:\n    A TF-Feature.\n  \"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.bytes_feature": [[68, 78], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "bytes_feature", "(", "values", ")", ":", "\n", "  ", "\"\"\"Returns a TF-Feature of bytes.\n\n  Args:\n    values: A string.\n\n  Returns:\n    A TF-Feature.\n  \"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "values", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.float_feature": [[80, 92], ["tensorflow.train.Feature", "isinstance", "tensorflow.train.FloatList"], "function", ["None"], ["", "def", "float_feature", "(", "values", ")", ":", "\n", "  ", "\"\"\"Returns a TF-Feature of floats.\n\n  Args:\n    values: A scalar of list of values.\n\n  Returns:\n    A TF-Feature.\n  \"\"\"", "\n", "if", "not", "isinstance", "(", "values", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "    ", "values", "=", "[", "values", "]", "\n", "", "return", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.image_to_tfexample": [[94, 101], ["tensorflow.train.Example", "tensorflow.train.Features", "dataset_utils.bytes_feature", "dataset_utils.bytes_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.bytes_feature", "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.bytes_feature", "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.int64_feature"], ["", "def", "image_to_tfexample", "(", "image_data", ",", "image_format", ",", "height", ",", "width", ",", "class_id", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/encoded'", ":", "bytes_feature", "(", "image_data", ")", ",", "\n", "'image/format'", ":", "bytes_feature", "(", "image_format", ")", ",", "\n", "'image/class/label'", ":", "int64_feature", "(", "class_id", ")", ",", "\n", "'image/height'", ":", "int64_feature", "(", "height", ")", ",", "\n", "'image/width'", ":", "int64_feature", "(", "width", ")", ",", "\n", "}", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.download_and_uncompress_tarball": [[104, 123], ["os.path.join", "six.moves.urllib.request.urlretrieve", "print", "os.stat", "print", "tarfile.open().extractall", "tarball_url.split", "sys.stdout.write", "sys.stdout.flush", "tarfile.open", "float", "float"], "function", ["None"], ["", "def", "download_and_uncompress_tarball", "(", "tarball_url", ",", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Downloads the `tarball_url` and uncompresses it locally.\n\n  Args:\n    tarball_url: The URL of a tarball file.\n    dataset_dir: The directory where the temporary files are stored.\n  \"\"\"", "\n", "filename", "=", "tarball_url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "\n", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "    ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "(", "\n", "filename", ",", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "tarball_url", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Successfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "tarfile", ".", "open", "(", "filepath", ",", "'r:gz'", ")", ".", "extractall", "(", "dataset_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.write_label_file": [[125, 139], ["os.path.join", "tensorflow.gfile.Open", "f.write"], "function", ["None"], ["", "def", "write_label_file", "(", "labels_to_class_names", ",", "dataset_dir", ",", "\n", "filename", "=", "LABELS_FILENAME", ")", ":", "\n", "  ", "\"\"\"Writes a file with the list of class names.\n\n  Args:\n    labels_to_class_names: A map of (integer) labels to class names.\n    dataset_dir: The directory in which the labels file should be written.\n    filename: The filename where the class names are written.\n  \"\"\"", "\n", "labels_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "labels_filename", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "for", "label", "in", "labels_to_class_names", ":", "\n", "      ", "class_name", "=", "labels_to_class_names", "[", "label", "]", "\n", "f", ".", "write", "(", "'%d:%s\\n'", "%", "(", "label", ",", "class_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.has_labels": [[141, 152], ["tensorflow.gfile.Exists", "os.path.join"], "function", ["None"], ["", "", "", "def", "has_labels", "(", "dataset_dir", ",", "filename", "=", "LABELS_FILENAME", ")", ":", "\n", "  ", "\"\"\"Specifies whether or not the dataset directory contains a label map file.\n\n  Args:\n    dataset_dir: The directory in which the labels file is found.\n    filename: The filename where the class names are written.\n\n  Returns:\n    `True` if the labels file exists and `False` otherwise.\n  \"\"\"", "\n", "return", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.read_label_file": [[154, 175], ["os.path.join", "f.read().decode.split", "filter", "tensorflow.gfile.Open", "f.read().decode", "line.index", "f.read", "int"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode"], ["", "def", "read_label_file", "(", "dataset_dir", ",", "filename", "=", "LABELS_FILENAME", ")", ":", "\n", "  ", "\"\"\"Reads the labels file and returns a mapping from ID to class name.\n\n  Args:\n    dataset_dir: The directory in which the labels file is found.\n    filename: The filename where the class names are written.\n\n  Returns:\n    A map from a label (integer) to class name.\n  \"\"\"", "\n", "labels_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "labels_filename", ",", "'rb'", ")", "as", "f", ":", "\n", "    ", "lines", "=", "f", ".", "read", "(", ")", ".", "decode", "(", ")", "\n", "", "lines", "=", "lines", ".", "split", "(", "'\\n'", ")", "\n", "lines", "=", "filter", "(", "None", ",", "lines", ")", "\n", "\n", "labels_to_class_names", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "    ", "index", "=", "line", ".", "index", "(", "':'", ")", "\n", "labels_to_class_names", "[", "int", "(", "line", "[", ":", "index", "]", ")", "]", "=", "line", "[", "index", "+", "1", ":", "]", "\n", "", "return", "labels_to_class_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.open_sharded_output_tfrecords": [[177, 200], ["exit_stack.enter_context", "range", "tensorflow.python_io.TFRecordWriter"], "function", ["None"], ["", "def", "open_sharded_output_tfrecords", "(", "exit_stack", ",", "base_path", ",", "num_shards", ")", ":", "\n", "  ", "\"\"\"Opens all TFRecord shards for writing and adds them to an exit stack.\n\n  Args:\n    exit_stack: A context2.ExitStack used to automatically closed the TFRecords\n      opened in this function.\n    base_path: The base path for all shards\n    num_shards: The number of shards\n\n  Returns:\n    The list of opened TFRecords. Position k in the list corresponds to shard k.\n  \"\"\"", "\n", "tf_record_output_filenames", "=", "[", "\n", "'{}-{:05d}-of-{:05d}'", ".", "format", "(", "base_path", ",", "idx", ",", "num_shards", ")", "\n", "for", "idx", "in", "range", "(", "num_shards", ")", "\n", "]", "\n", "\n", "tfrecords", "=", "[", "\n", "exit_stack", ".", "enter_context", "(", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "file_name", ")", ")", "\n", "for", "file_name", "in", "tf_record_output_filenames", "\n", "]", "\n", "\n", "return", "tfrecords", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.imagenet.create_readable_names_for_imagenet_labels": [[66, 120], ["six.moves.urllib.request.urlretrieve", "len", "six.moves.urllib.request.urlretrieve", "open().readlines", "len", "s.strip", "s.strip().split", "open().readlines", "open", "len", "s.strip", "open"], "function", ["None"], ["def", "create_readable_names_for_imagenet_labels", "(", ")", ":", "\n", "  ", "\"\"\"Create a dict mapping label id to human readable string.\n\n  Returns:\n      labels_to_names: dictionary where keys are integers from to 1000\n      and values are human-readable names.\n\n  We retrieve a synset file, which contains a list of valid synset labels used\n  by ILSVRC competition. There is one synset one per line, eg.\n          #   n01440764\n          #   n01443537\n  We also retrieve a synset_to_human_file, which contains a mapping from synsets\n  to human-readable names for every synset in Imagenet. These are stored in a\n  tsv format, as follows:\n          #   n02119247    black fox\n          #   n02119359    silver fox\n  We assign each synset (in alphabetical order) an integer, starting from 1\n  (since 0 is reserved for the background class).\n\n  Code is based on\n  https://github.com/tensorflow/models/blob/master/research/inception/inception/data/build_imagenet_data.py#L463\n  \"\"\"", "\n", "\n", "# pylint: disable=g-line-too-long", "\n", "base_url", "=", "'https://raw.githubusercontent.com/tensorflow/models/master/research/inception/inception/data/'", "\n", "synset_url", "=", "'{}/imagenet_lsvrc_2015_synsets.txt'", ".", "format", "(", "base_url", ")", "\n", "synset_to_human_url", "=", "'{}/imagenet_metadata.txt'", ".", "format", "(", "base_url", ")", "\n", "\n", "filename", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "synset_url", ")", "\n", "synset_list", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", "]", "\n", "num_synsets_in_ilsvrc", "=", "len", "(", "synset_list", ")", "\n", "assert", "num_synsets_in_ilsvrc", "==", "1000", "\n", "\n", "filename", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "synset_to_human_url", ")", "\n", "synset_to_human_list", "=", "open", "(", "filename", ")", ".", "readlines", "(", ")", "\n", "num_synsets_in_all_imagenet", "=", "len", "(", "synset_to_human_list", ")", "\n", "assert", "num_synsets_in_all_imagenet", "==", "21842", "\n", "\n", "synset_to_human", "=", "{", "}", "\n", "for", "s", "in", "synset_to_human_list", ":", "\n", "    ", "parts", "=", "s", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "assert", "len", "(", "parts", ")", "==", "2", "\n", "synset", "=", "parts", "[", "0", "]", "\n", "human", "=", "parts", "[", "1", "]", "\n", "synset_to_human", "[", "synset", "]", "=", "human", "\n", "\n", "", "label_index", "=", "1", "\n", "labels_to_names", "=", "{", "0", ":", "'background'", "}", "\n", "for", "synset", "in", "synset_list", ":", "\n", "    ", "name", "=", "synset_to_human", "[", "synset", "]", "\n", "labels_to_names", "[", "label_index", "]", "=", "name", "\n", "label_index", "+=", "1", "\n", "\n", "", "return", "labels_to_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.imagenet.get_split": [[122, 199], ["os.path.join", "slim.tfexample_decoder.TFExampleDecoder", "slim.dataset.Dataset", "ValueError", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "slim.tfexample_decoder.Image", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.BoundingBox", "slim.tfexample_decoder.Tensor", "dataset_utils.has_labels", "dataset_utils.read_label_file", "imagenet.create_readable_names_for_imagenet_labels", "dataset_utils.write_label_file"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.has_labels", "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.read_label_file", "home.repos.pwc.inspect_result.rist-ro_argo.networks.imagenet.create_readable_names_for_imagenet_labels", "home.repos.pwc.inspect_result.rist-ro_argo.networks.dataset_utils.write_label_file"], ["", "def", "get_split", "(", "split_name", ",", "dataset_dir", ",", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Gets a dataset tuple with instructions for reading ImageNet.\n\n  Args:\n    split_name: A train/test split name.\n    dataset_dir: The base directory of the dataset sources.\n    file_pattern: The file pattern to use when matching the dataset sources.\n      It is assumed that the pattern contains a '%s' string so that the split\n      name can be inserted.\n    reader: The TensorFlow reader type.\n\n  Returns:\n    A `Dataset` namedtuple.\n\n  Raises:\n    ValueError: if `split_name` is not a valid train/test split.\n  \"\"\"", "\n", "if", "split_name", "not", "in", "_SPLITS_TO_SIZES", ":", "\n", "    ", "raise", "ValueError", "(", "'split name %s was not recognized.'", "%", "split_name", ")", "\n", "\n", "", "if", "not", "file_pattern", ":", "\n", "    ", "file_pattern", "=", "_FILE_PATTERN", "\n", "", "file_pattern", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "file_pattern", "%", "split_name", ")", "\n", "\n", "# Allowing None in the signature so that dataset_factory can use the default.", "\n", "if", "reader", "is", "None", ":", "\n", "    ", "reader", "=", "tf", ".", "TFRecordReader", "\n", "\n", "", "keys_to_features", "=", "{", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/format'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "'jpeg'", ")", ",", "\n", "'image/class/label'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ",", "default_value", "=", "-", "1", ")", ",", "\n", "'image/class/text'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/object/bbox/xmin'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/bbox/ymin'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/bbox/xmax'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/bbox/ymax'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/class/label'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "'image'", ":", "slim", ".", "tfexample_decoder", ".", "Image", "(", "'image/encoded'", ",", "'image/format'", ")", ",", "\n", "'label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/label'", ")", ",", "\n", "'label_text'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/text'", ")", ",", "\n", "'object/bbox'", ":", "slim", ".", "tfexample_decoder", ".", "BoundingBox", "(", "\n", "[", "'ymin'", ",", "'xmin'", ",", "'ymax'", ",", "'xmax'", "]", ",", "'image/object/bbox/'", ")", ",", "\n", "'object/label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/object/class/label'", ")", ",", "\n", "}", "\n", "\n", "decoder", "=", "slim", ".", "tfexample_decoder", ".", "TFExampleDecoder", "(", "\n", "keys_to_features", ",", "items_to_handlers", ")", "\n", "\n", "labels_to_names", "=", "None", "\n", "if", "LOAD_READABLE_NAMES", ":", "\n", "    ", "if", "dataset_utils", ".", "has_labels", "(", "dataset_dir", ")", ":", "\n", "      ", "labels_to_names", "=", "dataset_utils", ".", "read_label_file", "(", "dataset_dir", ")", "\n", "", "else", ":", "\n", "      ", "labels_to_names", "=", "create_readable_names_for_imagenet_labels", "(", ")", "\n", "dataset_utils", ".", "write_label_file", "(", "labels_to_names", ",", "dataset_dir", ")", "\n", "\n", "", "", "return", "slim", ".", "dataset", ".", "Dataset", "(", "\n", "data_sources", "=", "file_pattern", ",", "\n", "reader", "=", "reader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "_SPLITS_TO_SIZES", "[", "split_name", "]", ",", "\n", "items_to_descriptions", "=", "_ITEMS_TO_DESCRIPTIONS", ",", "\n", "num_classes", "=", "_NUM_CLASSES", ",", "\n", "labels_to_names", "=", "labels_to_names", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.pbtxt.inception_v4_get_network_fn": [[63, 107], ["functools.wraps", "hasattr", "inception_v4.inception_v4_arg_scope", "slim.arg_scope", "func"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.func"], ["def", "inception_v4_get_network_fn", "(", "num_classes", ",", "weight_decay", "=", "0.0", ",", "is_training", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a network_fn such as `logits, end_points = network_fn(images)`.\nOA\n  Args:\n    num_classes: The number of classes to use for classification. If 0 or None,\n      the logits layer is omitted and its input features are returned instead.\n    weight_decay: The l2 coefficient for the model weights.\n    is_training: `True` if the model is being used for training and `False`\n      otherwise.\n\n  Returns:\n    network_fn: A function that applies the model to a batch of images. It has\n      the following signature:\n          net, end_points = network_fn(images)\n      The `images` input is a tensor of shape [batch_size, height, width, 3]\n      with height = width = network_fn.default_image_size. (The permissibility\n      and treatment of other sizes depends on the network_fn.)\n      The returned `end_points` are a dictionary of intermediate activations.\n      The returned `net` is the topmost layer, depending on `num_classes`:\n      If `num_classes` was a non-zero integer, `net` is a logits tensor\n      of shape [batch_size, num_classes].\n      If `num_classes` was 0 or `None`, `net` is a tensor with the input\n      to the logits layer of shape [batch_size, 1, 1, num_features] or\n      [batch_size, num_features]. Dropout has not been applied to this\n      (even if the network's original classification does); it remains for\n      the caller to do this or not.\n\n  Raises:\n    ValueError: If network `name` is not recognized.\n  \"\"\"", "\n", "#  if name not in inception_networks:", "\n", "#   raise ValueError('Name of network unknown %s' % name)", "\n", "func", "=", "inception_v4", "\n", "# pdb.set_trace()", "\n", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "network_fn", "(", "images", ",", "**", "kwargs", ")", ":", "\n", "    ", "arg_scope", "=", "inception_v4_arg_scope", "(", "weight_decay", "=", "weight_decay", ")", "\n", "with", "slim", ".", "arg_scope", "(", "arg_scope", ")", ":", "\n", "      ", "return", "func", "(", "images", ",", "num_classes", "=", "num_classes", ",", "is_training", "=", "is_training", ",", "\n", "**", "kwargs", ")", "\n", "", "", "if", "hasattr", "(", "func", ",", "'default_image_size'", ")", ":", "\n", "    ", "network_fn", ".", "default_image_size", "=", "func", ".", "default_image_size", "\n", "\n", "", "return", "network_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.pbtxt.main": [[108, 139], ["tensorflow.logging.set_verbosity", "ValueError", "tensorflow.Graph().as_default", "imagenet.get_split", "pbtxt.inception_v4_get_network_fn", "tensorflow.placeholder", "inception_v4_get_network_fn.", "graph.as_graph_def", "tensorflow.contrib.quantize.create_eval_graph", "tensorflow.io.write_graph", "tensorflow.Graph", "os.path.dirname", "os.path.basename", "tensorflow.python.platform.gfile.GFile", "f.write", "graph.as_graph_def.SerializeToString"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.networks.imagenet.get_split", "home.repos.pwc.inspect_result.rist-ro_argo.networks.pbtxt.inception_v4_get_network_fn"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "if", "not", "FLAGS", ".", "output_file", ":", "\n", "    ", "raise", "ValueError", "(", "'You must supply the path to save to with --output_file'", ")", "\n", "", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "#dataset = dataset_factory.get_dataset(FLAGS.dataset_name, 'train',", "\n", "#                                       FLAGS.dataset_dir)", "\n", "    ", "image_net", "=", "imagenet", ".", "get_split", "(", "'train'", ",", "FLAGS", ".", "dataset_dir", ",", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", "\n", "inception_network_fn", "=", "inception_v4_get_network_fn", "(", "\n", "num_classes", "=", "(", "image_net", ".", "num_classes", "-", "FLAGS", ".", "labels_offset", ")", ",", "\n", "is_training", "=", "False", ")", "\n", "#pdb.set_trace()", "\n", "image_size", "=", "inception_network_fn", ".", "default_image_size", "\n", "input_shape", "=", "[", "FLAGS", ".", "batch_size", ",", "image_size", ",", "image_size", ",", "3", "]", "\n", "placeholder", "=", "tf", ".", "placeholder", "(", "name", "=", "'input'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "input_shape", ")", "\n", "inception_network_fn", "(", "placeholder", ")", "\n", "\n", "if", "FLAGS", ".", "quantize", ":", "\n", "      ", "tf", ".", "contrib", ".", "quantize", ".", "create_eval_graph", "(", ")", "\n", "\n", "", "graph_def", "=", "graph", ".", "as_graph_def", "(", ")", "\n", "if", "FLAGS", ".", "write_text_graphdef", ":", "\n", "      ", "tf", ".", "io", ".", "write_graph", "(", "\n", "graph_def", ",", "\n", "os", ".", "path", ".", "dirname", "(", "FLAGS", ".", "output_file", ")", ",", "\n", "os", ".", "path", ".", "basename", "(", "FLAGS", ".", "output_file", ")", ",", "\n", "as_text", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "with", "gfile", ".", "GFile", "(", "FLAGS", ".", "output_file", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "graph_def", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.freeze_graph.main": [[84, 114], ["tensorflow.python.tools.freeze_graph.freeze_graph", "ValueError", "ValueError"], "function", ["None"], ["", "def", "main", "(", "_", ")", ":", "\n", "\n", "    ", "if", "not", "FLAGS", ".", "output_node_names", ":", "\n", "        ", "raise", "ValueError", "(", "'You must supply the output nodes from which the activation needs to be calculated --output_node_names'", ")", "\n", "\n", "", "if", "FLAGS", ".", "checkpoint_version", "==", "1", ":", "\n", "        ", "checkpoint_version", "=", "saver_pb2", ".", "SaverDef", ".", "V1", "\n", "", "elif", "FLAGS", ".", "checkpoint_version", "==", "2", ":", "\n", "        ", "checkpoint_version", "=", "saver_pb2", ".", "SaverDef", ".", "V2", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid checkpoint version (must be '1' or '2'): %d\"", "%", "\n", "flags", ".", "checkpoint_version", ")", "\n", "# pdb.set_trace()", "\n", "", "freeze_graph", ".", "freeze_graph", "(", "\n", "input_graph", "=", "FLAGS", ".", "input_graph", ",", "\n", "input_saver", "=", "FLAGS", ".", "input_saver", ",", "\n", "input_binary", "=", "FLAGS", ".", "input_binary", ",", "\n", "output_node_names", "=", "FLAGS", ".", "output_node_names", ",", "\n", "restore_op_name", "=", "FLAGS", ".", "restore_op_name", ",", "\n", "filename_tensor_name", "=", "FLAGS", ".", "filename_tensor_name", ",", "\n", "output_graph", "=", "FLAGS", ".", "output_graph", ",", "\n", "clear_devices", "=", "FLAGS", ".", "clear_devices", ",", "\n", "initializer_nodes", "=", "FLAGS", ".", "initializer_nodes", ",", "\n", "variable_names_whitelist", "=", "FLAGS", ".", "variable_names_whitelist", ",", "\n", "variable_names_blacklist", "=", "FLAGS", ".", "variable_names_blacklist", ",", "\n", "input_meta_graph", "=", "FLAGS", ".", "input_meta_graph", ",", "\n", "input_saved_model_dir", "=", "FLAGS", ".", "input_saved_model_dir", ",", "\n", "saved_model_tags", "=", "FLAGS", ".", "saved_model_tags", ",", "\n", "checkpoint_version", "=", "checkpoint_version", ",", "\n", "input_checkpoint", "=", "outputFileName", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.inception_utils.inception_arg_scope": [[32, 83], ["slim.arg_scope", "slim.arg_scope", "slim.l2_regularizer", "slim.variance_scaling_initializer"], "function", ["None"], ["def", "inception_arg_scope", "(", "weight_decay", "=", "0.00004", ",", "\n", "use_batch_norm", "=", "True", ",", "\n", "batch_norm_decay", "=", "0.9997", ",", "\n", "batch_norm_epsilon", "=", "0.001", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "batch_norm_updates_collections", "=", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "\n", "batch_norm_scale", "=", "False", ")", ":", "\n", "  ", "\"\"\"Defines the default arg scope for inception models.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n    use_batch_norm: \"If `True`, batch_norm is applied after each convolution.\n    batch_norm_decay: Decay for batch norm moving average.\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\n      in batch norm.\n    activation_fn: Activation function for conv2d.\n    batch_norm_updates_collections: Collection for the update ops for\n      batch norm.\n    batch_norm_scale: If True, uses an explicit `gamma` multiplier to scale the\n      activations in the batch normalization layer.\n\n  Returns:\n    An `arg_scope` to use for the inception models.\n  \"\"\"", "\n", "batch_norm_params", "=", "{", "\n", "# Decay for the moving averages.", "\n", "'decay'", ":", "batch_norm_decay", ",", "\n", "# epsilon to prevent 0s in variance.", "\n", "'epsilon'", ":", "batch_norm_epsilon", ",", "\n", "# collection containing update_ops.", "\n", "'updates_collections'", ":", "batch_norm_updates_collections", ",", "\n", "# use fused batch norm if possible.", "\n", "'fused'", ":", "None", ",", "\n", "'scale'", ":", "batch_norm_scale", ",", "\n", "}", "\n", "if", "use_batch_norm", ":", "\n", "    ", "normalizer_fn", "=", "slim", ".", "batch_norm", "\n", "normalizer_params", "=", "batch_norm_params", "\n", "", "else", ":", "\n", "    ", "normalizer_fn", "=", "None", "\n", "normalizer_params", "=", "{", "}", "\n", "# Set weight_decay for weights in Conv and FC layers.", "\n", "", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_initializer", "=", "slim", ".", "variance_scaling_initializer", "(", ")", ",", "\n", "activation_fn", "=", "activation_fn", ",", "\n", "normalizer_fn", "=", "normalizer_fn", ",", "\n", "normalizer_params", "=", "normalizer_params", ")", "as", "sc", ":", "\n", "      ", "return", "sc", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.GenerationNetwork.GenerationNetwork.__init__": [[10, 19], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "final_size", ",", "clip_probs", ",", "pm", ",", "initializers", "=", "{", "}", ",", "regularizers", "=", "{", "}", ",", "name", "=", "\"gen_net\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_layers", "=", "layers", "\n", "self", ".", "_final_size", "=", "final_size", "\n", "self", ".", "_initializers", "=", "initializers", "\n", "self", ".", "_regularizers", "=", "regularizers", "\n", "self", ".", "_clip_probs", "=", "clip_probs", "\n", "self", ".", "_pm", "=", "pm", "\n", "self", ".", "reverse_layers", "=", "[", "self", ".", "_final_size", "]", "+", "[", "*", "self", ".", "_layers", "[", ":", "-", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.GenerationNetwork.GenerationNetwork._build": [[20, 54], ["list", "print", "argo.core.network.Bernoulli.Bernoulli.sample", "GenerationNetwork.GenerationNetwork._hg.append", "enumerate", "argo.core.network.BernoulliPlusMinusOne.BernoulliPlusMinusOne", "argo.core.network.Bernoulli.Bernoulli", "argo.core.network.Bernoulli.Bernoulli.", "argo.core.network.Bernoulli.Bernoulli.", "tensorflow.stop_gradient", "tensorflow.stop_gradient"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "_build", "(", "self", ",", "h", ",", "h_distr", "=", "None", ",", "hr", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            h (tf.tensor): input node.\n        \"\"\"", "\n", "\n", "gen_layer", "=", "h", "\n", "self", ".", "_hg", "=", "[", "(", "h_distr", ",", "gen_layer", ")", "]", "\n", "distr", "=", "None", "\n", "for", "i", ",", "layer_size", "in", "list", "(", "enumerate", "(", "self", ".", "reverse_layers", ")", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "print", "(", "\"GENNET: creating layer {} with layersize: {}\"", ".", "format", "(", "i", ",", "layer_size", ")", ")", "\n", "\n", "if", "self", ".", "_pm", ":", "\n", "                ", "layer", "=", "BernoulliPlusMinusOne", "(", "output_size", "=", "layer_size", ",", "initializers", "=", "self", ".", "_initializers", ",", "\n", "regularizers", "=", "self", ".", "_regularizers", ",", "\n", "clip_value", "=", "self", ".", "_clip_probs", ",", "dtype", "=", "h", ".", "dtype", ",", "name", "=", "\"l_g_{}\"", ".", "format", "(", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "layer", "=", "Bernoulli", "(", "output_size", "=", "layer_size", ",", "initializers", "=", "self", ".", "_initializers", ",", "\n", "regularizers", "=", "self", ".", "_regularizers", ",", "\n", "clip_value", "=", "self", ".", "_clip_probs", ",", "dtype", "=", "h", ".", "dtype", ",", "name", "=", "\"l_g_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "", "if", "hr", "is", "not", "None", ":", "\n", "                ", "distr", "=", "layer", "(", "tf", ".", "stop_gradient", "(", "hr", "[", "i", "+", "1", "]", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "distr", "=", "layer", "(", "tf", ".", "stop_gradient", "(", "gen_layer", ")", ")", "\n", "\n", "", "gen_layer", "=", "distr", ".", "sample", "(", ")", "\n", "\n", "self", ".", "_hg", ".", "append", "(", "(", "distr", ",", "gen_layer", ")", ")", "\n", "\n", "", "x_reconstruct", "=", "gen_layer", "\n", "x_reconstruct_distr", "=", "distr", "\n", "\n", "return", "x_reconstruct", ",", "x_reconstruct_distr", ",", "self", ".", "_hg", "[", ":", ":", "-", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.RecognitionNetwork.RecognitionNetwork.__init__": [[10, 17], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "clip_probs", ",", "pm", ",", "initializers", "=", "{", "}", ",", "regularizers", "=", "{", "}", ",", "name", "=", "\"rec_net\"", ")", ":", "\n", "        ", "super", "(", "RecognitionNetwork", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_layers", "=", "layers", "\n", "self", ".", "_initializers", "=", "initializers", "\n", "self", ".", "_regularizers", "=", "regularizers", "\n", "self", ".", "_clip_probs", "=", "clip_probs", "\n", "self", ".", "_pm", "=", "pm", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.RecognitionNetwork.RecognitionNetwork._build": [[18, 48], ["enumerate", "print", "argo.core.network.Bernoulli.Bernoulli.sample", "RecognitionNetwork.RecognitionNetwork._hr.append", "argo.core.network.BernoulliPlusMinusOne.BernoulliPlusMinusOne", "argo.core.network.Bernoulli.Bernoulli", "argo.core.network.Bernoulli.Bernoulli.", "argo.core.network.Bernoulli.Bernoulli.", "tensorflow.stop_gradient", "tensorflow.stop_gradient"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "_build", "(", "self", ",", "x", ",", "hg", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (tf.tensor): input node.\n\n        \"\"\"", "\n", "rec_layer", "=", "x", "\n", "\n", "self", ".", "_hr", "=", "[", "(", "None", ",", "rec_layer", ")", "]", "\n", "for", "i", ",", "layer_size", "in", "enumerate", "(", "self", ".", "_layers", ")", ":", "\n", "            ", "print", "(", "\"RECNET: creating layer {} with layersize: {}\"", ".", "format", "(", "i", ",", "layer_size", ")", ")", "\n", "\n", "if", "self", ".", "_pm", ":", "\n", "                ", "layer", "=", "BernoulliPlusMinusOne", "(", "output_size", "=", "layer_size", ",", "initializers", "=", "self", ".", "_initializers", ",", "regularizers", "=", "self", ".", "_regularizers", ",", "clip_value", "=", "self", ".", "_clip_probs", ",", "\n", "dtype", "=", "x", ".", "dtype", ",", "name", "=", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "layer", "=", "Bernoulli", "(", "output_size", "=", "layer_size", ",", "initializers", "=", "self", ".", "_initializers", ",", "regularizers", "=", "self", ".", "_regularizers", ",", "clip_value", "=", "self", ".", "_clip_probs", ",", "\n", "dtype", "=", "x", ".", "dtype", ",", "name", "=", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "", "if", "hg", "is", "not", "None", ":", "\n", "                ", "distr", "=", "layer", "(", "tf", ".", "stop_gradient", "(", "hg", "[", "i", "]", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "distr", "=", "layer", "(", "tf", ".", "stop_gradient", "(", "rec_layer", ")", ")", "\n", "\n", "", "rec_layer", "=", "distr", ".", "sample", "(", ")", "\n", "\n", "self", ".", "_hr", ".", "append", "(", "(", "distr", ",", "rec_layer", ")", ")", "\n", "\n", "", "h", "=", "rec_layer", "\n", "return", "h", ",", "self", ".", "_hr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.HMNetwork.HMNetwork.create_id": [[27, 36], ["super().create_id", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "        ", "layers_ids", "=", "\"_\"", ".", "join", "(", "map", "(", "str", ",", "self", ".", "_layers", ")", ")", "\n", "\n", "_id", "=", "'-l_'", "+", "layers_ids", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.HMNetwork.HMNetwork.__init__": [[37, 53], ["argo.core.network.ArgoNetworkWithDefaults.ArgoNetworkWithDefaults.__init__", "HMNetwork.HMNetwork.get_regularizers"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "clip_probs", "=", "0", ",", "pm", "=", "True", ",", "name", "=", "\"hm_network\"", ")", ":", "\n", "        ", "\"\"\"Short summary.\n\n        Args:\n            self._opts (dict): parameters of the task.\n            name (str): name of the Sonnet module.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "None", ")", "\n", "\n", "self", ".", "_network_architecture", "=", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "\n", "self", ".", "_layers", "=", "self", ".", "_network_architecture", "[", "\"layers\"", "]", "\n", "self", ".", "_clip_probs", "=", "clip_probs", "\n", "self", ".", "_pm", "=", "pm", "\n", "\n", "self", ".", "_regs", "=", "self", ".", "get_regularizers", "(", "self", ".", "_default_weights_reg", ",", "self", ".", "_default_bias_reg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.HMNetwork.HMNetwork._build": [[54, 129], ["tensorflow.tile", "core.networks.RecognitionNetwork.RecognitionNetwork", "core.networks.GenerationNetwork.GenerationNetwork", "tensorflow.placeholder_with_default", "h_prior_plus_minus_one.sample", "tensorflow.tile.shape.as_list", "sonnet.BatchFlatten", "numpy.prod", "tensorflow.name_scope", "core.networks.RecognitionNetwork.RecognitionNetwork.", "core.networks.GenerationNetwork.GenerationNetwork.", "tensorflow.reshape", "tensorflow.name_scope", "h_prior_plus_minus_one.sample", "core.networks.GenerationNetwork.GenerationNetwork.", "core.networks.RecognitionNetwork.RecognitionNetwork.", "tensorflow.reshape", "HMNetwork.HMNetwork.get_regularizers", "HMNetwork.HMNetwork.get_regularizers", "argo.core.network.BernoulliPlusMinusOne.BernoulliPlusMinusOne", "tensorflow.zeros", "argo.core.network.Bernoulli.Bernoulli", "tensorflow.zeros", "HMNetwork.HMNetwork.get_regularizers", "HMNetwork.HMNetwork.get_regularizers", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers"], ["", "def", "_build", "(", "self", ",", "x", ",", "b_size", ",", "n_z_samples", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (tf.tensor): input node.\n        \"\"\"", "\n", "\n", "input_shape", "=", "x", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "\n", "x", "=", "BatchFlatten", "(", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "tile", "(", "x", ",", "[", "n_z_samples", ",", "1", "]", ")", "\n", "\n", "rec_mod", "=", "RecognitionNetwork", "(", "self", ".", "_layers", ",", "\n", "clip_probs", "=", "self", ".", "_clip_probs", ",", "\n", "pm", "=", "self", ".", "_pm", ",", "\n", "initializers", "=", "{", "\n", "\"w\"", ":", "self", ".", "_default_weights_init", ",", "\n", "\"b\"", ":", "self", ".", "_default_bias_init", "}", ",", "\n", "regularizers", "=", "self", ".", "get_regularizers", "(", "self", ".", "_default_weights_reg", ",", "\n", "self", ".", "_default_bias_reg", ")", ")", "\n", "gen_mod", "=", "GenerationNetwork", "(", "self", ".", "_layers", ",", "\n", "np", ".", "prod", "(", "input_shape", ")", ",", "\n", "pm", "=", "self", ".", "_pm", ",", "\n", "initializers", "=", "{", "\n", "\"w\"", ":", "self", ".", "_default_weights_init", ",", "\n", "\"b\"", ":", "self", ".", "_default_bias_init", "}", ",", "\n", "regularizers", "=", "self", ".", "get_regularizers", "(", "self", ".", "_default_weights_reg", ",", "\n", "self", ".", "_default_bias_reg", ")", ",", "\n", "clip_probs", "=", "self", ".", "_clip_probs", ")", "\n", "\n", "mega_batch_size", "=", "b_size", "*", "n_z_samples", "\n", "size_prior", "=", "tf", ".", "placeholder_with_default", "(", "mega_batch_size", ",", "shape", "=", "None", ")", "\n", "\n", "if", "self", ".", "_pm", ":", "\n", "            ", "h_prior_plus_minus_one", "=", "BernoulliPlusMinusOne", "(", "output_size", "=", "self", ".", "_layers", "[", "-", "1", "]", ",", "\n", "initializers", "=", "{", "\n", "\"w\"", ":", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "\"b\"", ":", "self", ".", "_default_bias_init", "}", ",", "\n", "regularizers", "=", "self", ".", "get_regularizers", "(", "\n", "bias_reg", "=", "self", ".", "_default_bias_reg", ")", ",", "\n", "clip_value", "=", "self", ".", "_clip_probs", ",", "\n", "dtype", "=", "x", ".", "dtype", ",", "\n", "name", "=", "\"top_bias\"", ")", "(", "tf", ".", "zeros", "(", "[", "size_prior", ",", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "h_prior_plus_minus_one", "=", "Bernoulli", "(", "output_size", "=", "self", ".", "_layers", "[", "-", "1", "]", ",", "\n", "initializers", "=", "{", "\n", "\"w\"", ":", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "\"b\"", ":", "self", ".", "_default_bias_init", "}", ",", "\n", "regularizers", "=", "self", ".", "get_regularizers", "(", "\n", "bias_reg", "=", "self", ".", "_default_bias_reg", ")", ",", "\n", "clip_value", "=", "self", ".", "_clip_probs", ",", "\n", "dtype", "=", "x", ".", "dtype", ",", "\n", "name", "=", "\"top_bias\"", ")", "(", "tf", ".", "zeros", "(", "[", "size_prior", ",", "1", "]", ")", ")", "\n", "\n", "", "h_prior_sample", "=", "h_prior_plus_minus_one", ".", "sample", "(", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"wake\"", ")", ":", "\n", "            ", "h_inferred", ",", "self", ".", "_hrw", "=", "rec_mod", "(", "x", ")", "\n", "\n", "x_reconstruct", ",", "x_reconstruct_distr", ",", "self", ".", "_hgw", "=", "gen_mod", "(", "h_prior_sample", ",", "h_distr", "=", "h_prior_plus_minus_one", ",", "\n", "hr", "=", "self", ".", "_hrw", ")", "\n", "\n", "x_reconstruct", "=", "tf", ".", "reshape", "(", "x_reconstruct", ",", "[", "-", "1", "]", "+", "input_shape", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"sleep\"", ")", ":", "\n", "            ", "h_prior_sample2", "=", "h_prior_plus_minus_one", ".", "sample", "(", ")", "\n", "\n", "x_inferred", ",", "x_inferred_distr", ",", "self", ".", "_hgs", "=", "gen_mod", "(", "h_prior_sample2", ",", "h_distr", "=", "h_prior_plus_minus_one", ")", "\n", "\n", "h_reconstruct", ",", "self", ".", "_hrs", "=", "rec_mod", "(", "x_inferred", ",", "hg", "=", "self", ".", "_hgs", ")", "\n", "\n", "x_inferred", "=", "tf", ".", "reshape", "(", "x_inferred", ",", "[", "-", "1", "]", "+", "input_shape", ")", "\n", "\n", "", "return", "{", "\n", "\"wake\"", ":", "(", "h_inferred", ",", "x_reconstruct", ",", "x_reconstruct_distr", ",", "self", ".", "_hrw", ",", "self", ".", "_hgw", ")", ",", "\n", "\"sleep\"", ":", "(", "h_reconstruct", ",", "x_inferred", ",", "x_inferred_distr", ",", "self", ".", "_hrs", ",", "self", ".", "_hgs", ")", ",", "\n", "\"prior\"", ":", "(", "h_prior_plus_minus_one", ",", "h_prior_sample2", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.networks.HMNetwork.HMNetwork.get_regularizers": [[131, 138], ["None"], "methods", ["None"], ["", "def", "get_regularizers", "(", "self", ",", "weights_reg", "=", "None", ",", "bias_reg", "=", "None", ")", ":", "\n", "        ", "regs", "=", "{", "}", "\n", "if", "weights_reg", ":", "\n", "            ", "regs", "[", "\"w\"", "]", "=", "weights_reg", "\n", "", "if", "bias_reg", ":", "\n", "            ", "regs", "[", "\"b\"", "]", "=", "bias_reg", "\n", "", "return", "regs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_id": [[203, 220], ["super().create_id", "utils.argo_utils.get_clipping_id", "os.path.abspath", "optimizers.TFOptimizers.TFOptimizers.create_id", "str", "os.path.abspath.split", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_clipping_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "'-st'", "+", "str", "(", "self", ".", "_opts", "[", "\"stochastic\"", "]", ")", "+", "'-stp'", "+", "str", "(", "self", ".", "_opts", "[", "\"stochastic_noise_param\"", "]", ")", "+", "'-bs'", "+", "str", "(", "self", ".", "_opts", "[", "\"batch_size_train\"", "]", ")", "+", "'-tr'", "+", "TFOptimizers", ".", "create_id", "(", "self", ".", "_opts", "[", "\"optimizer\"", "]", ")", "+", "'-c'", "+", "get_clipping_id", "(", "self", ".", "_opts", "[", "\"grad_clipping\"", "]", ")", "\n", "\n", "if", "\"note\"", "in", "self", ".", "_opts", ":", "\n", "            ", "_id", "+=", "'-N'", "+", "self", ".", "_opts", "[", "\"note\"", "]", "\n", "", "if", "\"pretrained_checkpoint\"", "in", "self", ".", "_opts", ":", "\n", "            ", "longname", "=", "os", ".", "path", ".", "abspath", "(", "self", ".", "_opts", "[", "\"pretrained_checkpoint\"", "]", ")", "\n", "shortname", "=", "\"\"", ".", "join", "(", "[", "i", "[", "0", "]", "for", "i", "in", "longname", ".", "split", "(", "\"/\"", ")", "[", "1", ":", "]", "]", ")", "\n", "_id", "+=", "'-PC'", "+", "shortname", "\n", "", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.__init__": [[221, 315], ["DeepLearningModel.DeepLearningModel.__init__", "tensorflow.set_random_seed", "KeyError", "TFDeepLearningModel.TFDeepLearningModel._opts[].keys", "len", "ValueError", "TFDeepLearningModel.TFDeepLearningModel._opts[].keys", "TFDeepLearningModel.TFDeepLearningModel._opts[].keys", "TFDeepLearningModel.TFDeepLearningModel._opts[].keys", "TFDeepLearningModel.TFDeepLearningModel._opts[].keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "\n", "# this needs to be called before the parent constructor", "\n", "#self._regularizers = opts.get(\"regularizers\", {})", "\n", "#pdb.set_trace()", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "seed", ")", "\n", "\n", "# moved up the hierarchy", "\n", "# self.dirName = dirName + \"/\" + self._id", "\n", "\n", "self", ".", "_check_ops", "=", "check_ops", "\n", "self", ".", "_numerics_ops", "=", "None", "\n", "\n", "self", ".", "_gpu", "=", "gpu", "\n", "\n", "self", ".", "sess", "=", "None", "\n", "self", ".", "_saver", "=", "None", "\n", "self", ".", "global_step", "=", "None", "\n", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "\n", "#restore checkpoint", "\n", "self", ".", "_restore_chkptfile", "=", "(", "None", "if", "\"pretrained_checkpoint\"", "not", "in", "self", ".", "_opts", "else", "self", ".", "_opts", "[", "\"pretrained_checkpoint\"", "]", ")", "\n", "#checkpoints", "\n", "self", ".", "_checkpoint_dir", "=", "self", ".", "dirName", "+", "\"/saved_models/\"", "\n", "#tensorboard", "\n", "self", ".", "_tensorboard_dir", "=", "self", ".", "dirName", "+", "\"/tensorboard/\"", "\n", "\n", "self", ".", "summary_keys", "=", "[", "tf", ".", "GraphKeys", ".", "SUMMARIES", "]", "\n", "self", ".", "summary_nodes", "=", "{", "ck", ":", "[", "]", "for", "ck", "in", "self", ".", "summary_keys", "}", "\n", "self", ".", "summary_writers", "=", "{", "ck", ":", "[", "]", "for", "ck", "in", "self", ".", "summary_keys", "}", "\n", "\n", "self", ".", "stochastic", "=", "self", ".", "_opts", "[", "\"stochastic\"", "]", "\n", "if", "self", ".", "stochastic", "==", "0", ":", "\n", "#no noise is added", "\n", "            ", "pass", "\n", "", "elif", "self", ".", "stochastic", "==", "1", ":", "\n", "            ", "self", ".", "_clip_after_noise", "=", "True", "\n", "", "elif", "self", ".", "stochastic", "==", "2", ":", "\n", "            ", "self", ".", "_clip_after_noise", "=", "False", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"stochastic can be: 0 no noise, 1 noise and clip after,\"", "\n", "\"2 noise and do not clip after. Found stochastic {}\"", ".", "format", "(", "self", ".", "stochastic", ")", ")", "\n", "\n", "", "self", ".", "stochastic_noise_param", "=", "self", ".", "_opts", "[", "\"stochastic_noise_param\"", "]", "\n", "\n", "# # TODO never rescale", "\n", "if", "\"rescale\"", "in", "self", ".", "_opts", ":", "\n", "            ", "raise", "KeyError", "(", "\"the key `rescale` is not supported anymore. Rescaling is not allowed, remove it from the conf.\"", ")", "\n", "# self.rescale = opts[\"rescale\"] # rescale the inputs if they are continuous", "\n", "\n", "", "self", ".", "batch_size", "=", "{", "}", "\n", "self", ".", "batch_size", "[", "\"train\"", "]", "=", "self", ".", "_opts", "[", "\"batch_size_train\"", "]", "\n", "self", ".", "batch_size", "[", "\"eval\"", "]", "=", "self", ".", "_opts", "[", "\"batch_size_eval\"", "]", "\n", "\n", "# important nodes", "\n", "self", ".", "x", "=", "None", "\n", "self", ".", "y", "=", "None", "\n", "self", ".", "x_shape", "=", "{", "}", "\n", "\n", "self", ".", "optimizer_tuple", "=", "self", ".", "_opts", "[", "\"optimizer\"", "]", "\n", "#self.compute_natural_gradient = opts[\"natural_gradient\"]", "\n", "\n", "#self.learning_rate = opts[\"training_algorithm\"][\"learning_rate\"]", "\n", "\n", "#self.training_algorithm = opts[\"training_algorithm\"][\"algorithm\"]", "\n", "#self.learning_rate = opts[\"training_algorithm\"][\"learning_rate\"]", "\n", "\n", "self", ".", "_grad_clipping_tuple", "=", "self", ".", "_opts", "[", "\"grad_clipping\"", "]", "\n", "\n", "# important nodes", "\n", "self", ".", "loss", "=", "None", "\n", "self", ".", "regularizers", "=", "[", "]", "\n", "\n", "# create regularizers", "\n", "if", "(", "\"regularizers\"", "not", "in", "self", ".", "_opts", ")", "or", "(", "\"weights\"", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", ".", "keys", "(", ")", "or", "\"bias\"", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", ".", "keys", "(", ")", "or", "\"custom\"", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", ".", "keys", "(", ")", ")", "or", "len", "(", "self", ".", "_opts", "[", "\"regularizers\"", "]", ".", "keys", "(", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "custom_regularizers", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "custom_regularizers", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "custom_regularizers", "[", "key", "]", "=", "[", "]", "\n", "\n", "", "", "self", ".", "update_ops", "=", "[", "]", "\n", "# list of kl_losses on the weights in case of bayesian learning", "\n", "self", ".", "kl_losses", "=", "[", "]", "\n", "\n", "self", ".", "datasets_initializers", "=", "{", "}", "\n", "self", ".", "datasets_handles_nodes", "=", "{", "}", "\n", "self", ".", "datasets_handles", "=", "{", "}", "\n", "\n", "# passed to ChechpoitSaverHook", "\n", "self", ".", "_pb_output_nodes", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.init": [[321, 370], ["TFDeepLearningModel.TFDeepLearningModel.create_feedable_placeholders", "TFDeepLearningModel.TFDeepLearningModel.create_global_steps", "TFDeepLearningModel.TFDeepLearningModel.create_input_nodes", "TFDeepLearningModel.TFDeepLearningModel.set_optimizer", "TFDeepLearningModel.TFDeepLearningModel.create_network", "TFDeepLearningModel.TFDeepLearningModel.create_loss", "TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers", "TFDeepLearningModel.TFDeepLearningModel.create_regularizers_and_updates", "TFDeepLearningModel.TFDeepLearningModel.set_training_op", "isinstance", "TFDeepLearningModel.TFDeepLearningModel.loss.items", "tensorflow.check_numerics", "tensorflow.check_numerics", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_feedable_placeholders", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_global_steps", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.create_input_nodes", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.set_optimizer", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_network", "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_loss", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_regularizers_and_updates", "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.set_training_op"], ["", "def", "init", "(", "self", ",", "dataset", ")", ":", "\n", "\n", "        ", "self", ".", "binary", "=", "dataset", ".", "binary_input", "\n", "\n", "#TODO these two are probably useless... if you need the input shape just do tf.shape(self.raw_x) for some networks the input could change from train to eval", "\n", "#TODO if there is a way to avoid using explicitly the input dimension it is probably better...", "\n", "self", ".", "x_shape", "[", "\"train\"", "]", "=", "dataset", ".", "x_shape_train", "\n", "self", ".", "x_shape", "[", "\"eval\"", "]", "=", "dataset", ".", "x_shape_eval", "\n", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n", "self", ".", "create_feedable_placeholders", "(", ")", "\n", "\n", "# create global steps", "\n", "self", ".", "create_global_steps", "(", "dataset", ".", "n_samples_train", ")", "\n", "\n", "self", ".", "create_input_nodes", "(", "dataset", ")", "\n", "\n", "# set optimizer", "\n", "self", ".", "set_optimizer", "(", ")", "\n", "\n", "#self.create_is_training_node()", "\n", "\n", "self", ".", "create_network", "(", ")", "\n", "\n", "#TODO-ARGO2 create loss, regularizer, optimizer and global step are typical of a training algorithm", "\n", "#TODO-ARGO2 how do we handle other cases that do not have a train? I think we should define", "\n", "#TODO-ARGO2 TrainableTFDeepLearningModel and redefine init", "\n", "\n", "# define self.loss and check it is finite", "\n", "self", ".", "create_loss", "(", ")", "\n", "\n", "self", ".", "create_custom_regularizers", "(", ")", "\n", "\n", "# define self.regularizers and self.update_ops", "\n", "self", ".", "create_regularizers_and_updates", "(", ")", "\n", "\n", "# set the training operation for self.loss + self.regularizers + self.custom_regularizers", "\n", "self", ".", "set_training_op", "(", ")", "\n", "\n", "# not used at the moment, could be useful at a certain point", "\n", "# self.create_random_update_op()", "\n", "\n", "# there are case in which multiple losses exit", "\n", "if", "isinstance", "(", "self", ".", "loss", ",", "dict", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "self", ".", "loss", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "loss", "[", "k", "]", "=", "tf", ".", "check_numerics", "(", "v", ",", "\"self.loss\"", "+", "str", "(", "k", ")", "+", "\" is not finite\"", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "loss", "=", "tf", ".", "check_numerics", "(", "self", ".", "loss", ",", "\"self.loss is not finite\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_datasets_with_handles": [[374, 386], ["dataset.get_dataset_with_handle"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_dataset_with_handle"], ["", "", "def", "create_datasets_with_handles", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "=", "dataset", ".", "get_dataset_with_handle", "(", "self", ".", "batch_size", "[", "\"train\"", "]", ",", "self", ".", "batch_size", "[", "\"eval\"", "]", ")", "\n", "self", ".", "datasets_initializers", "=", "ds_initializers", "\n", "self", ".", "datasets_handles_nodes", "=", "ds_handles", "\n", "self", ".", "ds_handle", "=", "handle", "\n", "self", ".", "datasets_nodes", "=", "datasets_nodes", "# this is needed, since ds_raw_x may be modified in create_input_nodes to remove the mask", "\n", "\n", "self", ".", "ds_raw_x", "=", "datasets_nodes", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "ds_aug_x", "=", "datasets_nodes", "[", "0", "]", "[", "1", "]", "\n", "self", ".", "ds_perturb_x", "=", "datasets_nodes", "[", "0", "]", "[", "2", "]", "\n", "\n", "return", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_feedable_placeholders": [[387, 399], ["tensorflow.placeholder_with_default"], "methods", ["None"], ["", "def", "create_feedable_placeholders", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        DO NOT USE FOR MODEL SPECIFIC PLACEHOLDERS (e.g. losses or samples..)\n        Create feedables. This function is setting additional placeholder\n        (it probably should never be used since placeholders should be set 3in the right places)\n\n        Sets:\n            feedable placeholders with general purpose\n\n        \"\"\"", "\n", "\n", "self", ".", "is_training", "=", "tf", ".", "placeholder_with_default", "(", "False", ",", "shape", "=", "(", ")", ",", "name", "=", "\"is_training\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_network": [[403, 413], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "create_network", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        It gets the input nodes from the dataset and creates the network\n        starting from the input nodes created by `create_input_nodes`\n\n        Sets:\n            network nodes depending on the specific child class\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_input_nodes": [[414, 424], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "create_input_nodes", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        create input nodes for the network\n        starting from the dataset\n\n        Sets:\n            input nodes depending on the specific child class\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_loss": [[425, 437], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "create_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"create loss nodes for the network\n        based on the nodes that create_networks has created,\n        this method will create the loss nodes\n\n        Sets:\n            self.loss\n            other additional loss nodes to be monitored during train can be set\n\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers": [[439, 449], ["isinstance", "TFDeepLearningModel.TFDeepLearningModel._create_custom_regularizers", "isinstance", "TFDeepLearningModel.TFDeepLearningModel.custom_regularizers.keys", "Exception", "TFDeepLearningModel.TFDeepLearningModel._create_custom_regularizers"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_custom_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_custom_regularizers"], ["", "def", "create_custom_regularizers", "(", "self", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "self", ".", "custom_regularizers", ",", "list", ")", ":", "\n", "            ", "self", ".", "_create_custom_regularizers", "(", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "custom_regularizers", ",", "dict", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "custom_regularizers", ".", "keys", "(", ")", ":", "\n", "# add regularizers for discriminator", "\n", "                ", "self", ".", "_create_custom_regularizers", "(", "key", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"self.custom_regularizers should be a list or a dict\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_custom_regularizers": [[450, 500], ["regularizers.keys", "Regularizers.Regularizers.Regularizers.instantiate_regularizer", "custom_regularizers.append", "TFDeepLearningModel.TFDeepLearningModel.check_regularizers"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Regularizers.Regularizers.instantiate_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.check_regularizers"], ["", "", "def", "_create_custom_regularizers", "(", "self", ",", "network", "=", "None", ")", ":", "\n", "        ", "if", "network", "is", "None", ":", "\n", "            ", "regularizers", "=", "self", ".", "_opts", "[", "\"regularizers\"", "]", "\n", "custom_regularizers", "=", "self", ".", "custom_regularizers", "\n", "", "else", ":", "\n", "            ", "regularizers", "=", "self", ".", "_opts", "[", "\"regularizers\"", "]", "[", "network", "]", "\n", "custom_regularizers", "=", "self", ".", "custom_regularizers", "[", "network", "]", "\n", "\n", "", "'''\n        if \"custom\" in regularizers.keys():\n            \n            for regularizer_tuple in regularizers[\"custom\"]:\n\n                regularizer_name = regularizer_tuple[0]\n                regularizer_tuple[1][\"model\"] = self\n                custom_regularizer = Regularizers.instantiate_regularizer(regularizer_tuple, module_path = \"\")\n                ''\n                regularizer_name = regularizer_tuple[0]\n                regularizer_kwargs = regularizer_tuple[1]\n                regularizer_kwargs[\"model\"] = self\n                \n                try:\n                    # load customized regularizers from core/Regularizers.py\n                    reg_module = importlib.import_module(\"core.Regularizers\", '.'.join(__name__.split('.')[:-1]))\n                    custom_regularizer, _, _ = eval_method_from_tuple(reg_module, (regularizer_name, regularizer_kwargs))\n                except AttributeError as e:\n                    # try to load from argo\n                    try:\n                        # load customized regularizers from core/argo/core/Regularizers.py\n                        reg_module = importlib.import_module(\".Regularizers\", '.'.join(__name__.split('.')[:-1]))\n                        custom_regularizer, _, _ = eval_method_from_tuple(reg_module, (regularizer_name, regularizer_kwargs))\n\n                    except AttributeError as e:\n                        raise AttributeError(\"regularizer %s not found\" % regularizer_name) from e\n                ''\n\n                custom_regularizers.append(custom_regularizer)\n                self.check_regularizers(regularizer_name, network)\n        '''", "\n", "\n", "if", "\"custom\"", "in", "regularizers", ".", "keys", "(", ")", ":", "\n", "\n", "            ", "for", "regularizer_tuple", "in", "regularizers", "[", "\"custom\"", "]", ":", "\n", "\n", "                ", "regularizer_name", "=", "regularizer_tuple", "[", "0", "]", "\n", "regularizer_tuple", "[", "1", "]", "[", "\"model\"", "]", "=", "self", "\n", "custom_regularizer", "=", "Regularizers", ".", "instantiate_regularizer", "(", "regularizer_tuple", ",", "module_path", "=", "\"\"", ")", "\n", "\n", "custom_regularizers", ".", "append", "(", "custom_regularizer", ")", "\n", "self", ".", "check_regularizers", "(", "regularizer_name", ",", "network", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.check_regularizers": [[503, 505], ["None"], "methods", ["None"], ["", "", "", "def", "check_regularizers", "(", "self", ",", "regularizer_name", ",", "network", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_regularizers_and_updates": [[513, 535], ["tensorflow.get_collection", "tensorflow.get_collection", "list", "tensorflow.get_collection", "len", "len", "itertools.chain.from_iterable", "TFDeepLearningModel.TFDeepLearningModel._opts[].keys", "len"], "methods", ["None"], ["def", "create_regularizers_and_updates", "(", "self", ")", ":", "\n", "\n", "        ", "wb_regularizers", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "# see keras_utils.py: activity_and_contractive_regularizers", "\n", "ac_regularizers", "=", "tf", ".", "get_collection", "(", "AC_REGULARIZATION", ")", "\n", "# if (not wb_regularizers) and (not ac_regularizers):", "\n", "#     wb_regularizers = [tf.constant(0.)]", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "if", "len", "(", "wb_regularizers", ")", ">", "0", ":", "\n", "            ", "self", ".", "regularizers", "+=", "wb_regularizers", "\n", "", "if", "len", "(", "ac_regularizers", ")", ">", "0", ":", "\n", "            ", "self", ".", "regularizers", "+=", "ac_regularizers", "\n", "\n", "# self.regularizers += ([self.custom_regularizers[r] for r in self._opts[\"regularizers\"].keys() if len(self.custom_regularizers[r])>0])", "\n", "# we need to flatten the list if we have both custom regularizers and another type of regularizers", "\n", "# (weight/bias or contractive)", "\n", "", "self", ".", "regularizers", "+=", "list", "(", "chain", ".", "from_iterable", "(", "[", "self", ".", "custom_regularizers", "[", "r", "]", "\n", "for", "r", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", ".", "keys", "(", ")", "\n", "if", "len", "(", "self", ".", "custom_regularizers", "[", "r", "]", ")", ">", "0", "]", ")", ")", "\n", "\n", "self", ".", "update_ops", "+=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_global_steps": [[544, 553], ["numpy.ceil", "tensorflow.train.get_or_create_global_step", "tensorflow.cast", "tensorflow.add_to_collection", "tensorflow.floor", "tensorflow.cast"], "methods", ["None"], ["", "def", "create_global_steps", "(", "self", ",", "n_points_train_set", ")", ":", "\n", "        ", "self", ".", "n_batches_per_epoch", "=", "np", ".", "ceil", "(", "n_points_train_set", "/", "self", ".", "batch_size", "[", "\"train\"", "]", ")", "\n", "\n", "self", ".", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "self", ".", "global_epoch", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "cast", "(", "self", ".", "global_step", ",", "tf", ".", "float32", ")", "/", "\n", "self", ".", "n_batches_per_epoch", ")", ",", "\n", "tf", ".", "int64", ",", "\"global_epoch\"", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_epoch\"", ",", "self", ".", "global_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_random_update_op": [[556, 571], ["tensorflow.get_collection", "tensorflow.group", "tensorflow.nn.moments", "tensorflow.distributions.Normal", "tensorflow.distributions.Normal.sample", "update_opts.append", "tensorflow.reshape", "var.get_shape", "var.assign", "tensorflow.sqrt"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "create_random_update_op", "(", "self", ")", ":", "\n", "\n", "        ", "vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "\n", "update_opts", "=", "[", "]", "\n", "for", "var", "in", "vars", ":", "\n", "\n", "            ", "_", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "tf", ".", "reshape", "(", "var", ",", "[", "-", "1", "]", ")", ",", "axes", "=", "[", "0", "]", ")", "\n", "\n", "normal", "=", "tf", ".", "distributions", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "tf", ".", "sqrt", "(", "variance", ")", "/", "10", ")", "\n", "white_noise", "=", "normal", ".", "sample", "(", "var", ".", "get_shape", "(", ")", ")", "\n", "\n", "update_opts", ".", "append", "(", "var", ".", "assign", "(", "var", "+", "white_noise", ")", ")", "\n", "\n", "", "self", ".", "random_update_op", "=", "tf", ".", "group", "(", "update_opts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._clip_gradients": [[573, 644], ["tensorflow.global_norm", "tensorflow.clip_by_global_norm", "range", "len", "tensorflow.clip_by_norm", "zip", "Exception", "tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "_clip_gradients", "(", "self", ",", "grads_and_vars", ",", "grad_clipping_tuple", ")", ":", "\n", "\n", "        ", "clipping_method", ",", "clipping_kwargs", "=", "grad_clipping_tuple", "\n", "\n", "grads_and_vars_not_none", "=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "grads", "=", "[", "g", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "variables", "=", "[", "v", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "\n", "#self.grad_norms = [tf.norm(g) for g in grads]", "\n", "\n", "#else:", "\n", "#    self.new_logits = self.logits", "\n", "\n", "self", ".", "grads", "=", "grads", "\n", "self", ".", "grads_norm", "=", "tf", ".", "global_norm", "(", "grads", ")", "\n", "\n", "#see https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#processing_gradients_before_applying_them", "\n", "#if clipping_method == \"clip_by_global_norm\":", "\n", "#", "\n", "#    print_ops = [tf.print(\"global norm \" + str(tf.norm(g))) for g in grads]", "\n", "#    with tf.control_dependencies(print_ops):", "\n", "#        clipped_grads, global_norm = tf.clip_by_global_norm(grads, clipping_kwargs[\"value\"])", "\n", "#    self.clipped_grads_and_vars = [(clipped_grads[i], variables[i]) for i in range(len(grads))]", "\n", "\n", "\n", "#see https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#processing_gradients_before_applying_them", "\n", "if", "clipping_method", "==", "\"clip_by_global_norm\"", ":", "\n", "\n", "#clip_by_global_norm requires all the grads as argument, not only grad[i]", "\n", "            ", "grads_and_vars_not_none", "=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "grads", "=", "[", "g", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "variables", "=", "[", "v", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "\n", "#print_ops = [tf.print(\"loss=\", self.loss)] + [tf.print(\"norms_g\", tf.norm(g)) for g in grads] + [tf.print(\"g\", g) for g in grads] + [tf.print(\"p\", self.prob)] + [tf.print(\"invFisher\", self.invFisher)] + [tf.print(\"invA\", self.invA)] + [tf.print(\"invB\", self.invB)]", "\n", "\n", "#print_ops = [tf.print(\"partA =\", self.partA, summarize=-1), tf.print(\"partB =\", self.partB, summarize=-1), tf.print(\"prob_sliced =\", self.prob_sliced, summarize=-1), tf.print(\"natural_gradient_theta =\", self.natural_gradient_loss_theta, summarize=-1), tf.print(\"euclidean gradient =\", self.euclidean_gradient, summarize=-1), tf.print(\"TA =\", self.TA, summarize=-1), tf.print(\"Tup =\", self.Tup, summarize=-1) , tf.print(\"Tdown =\", self.Tdown, summarize=-1) , tf.print(\"TB =\", self.TB, summarize=-1)] + [tf.print(\"norms_g\", tf.norm(g), summarize=-1) for g in grads]", "\n", "#with tf.control_dependencies(print_ops):", "\n", "clip_value", "=", "clipping_kwargs", "[", "\"value\"", "]", "\n", "clipped_grads", ",", "global_norm", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "clip_value", ")", "\n", "clipped_grads_and_vars", "=", "[", "(", "clipped_grads", "[", "i", "]", ",", "variables", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "grads", ")", ")", "]", "\n", "\n", "", "elif", "clipping_method", "==", "\"clip_by_norm\"", ":", "\n", "\n", "            ", "grads_and_vars_not_none", "=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "\n", "grads", "=", "[", "g", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "variables", "=", "[", "v", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "\n", "# How t handle numerical issues", "\n", "# 1) set nan/inf to zero", "\n", "# grads = [tf.where(tf.is_finite(g), g, tf.zeros_like(g)) for (g, v) in grads_and_vars_not_none]", "\n", "# 2) set nan/inf to noisy gradient,", "\n", "#grads = [tf.where(tf.is_finite(g), g, tfd.Normal(loc=0.0, scale=tf.sqrt(tf.nn.moments(tf.reshape(v,[-1]),axes=[0])[1])/10 + 0.01).sample(g.get_shape())) for (g, v) in grads_and_vars_not_none]", "\n", "\n", "clip_value", "=", "clipping_kwargs", "[", "\"value\"", "]", "\n", "clipped_grads_and_vars", "=", "[", "(", "tf", ".", "clip_by_norm", "(", "g", ",", "clip_value", ")", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "zip", "(", "grads", ",", "variables", ")", "]", "\n", "\n", "", "elif", "clipping_method", "==", "\"clip_by_value\"", ":", "\n", "\n", "            ", "clip_value", "=", "clipping_kwargs", "[", "\"value\"", "]", "\n", "clipped_grads_and_vars", "=", "[", "(", "tf", ".", "clip_by_value", "(", "g", ",", "-", "clip_value", ",", "clip_value", ")", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "\n", "", "elif", "not", "clipping_method", ":", "\n", "\n", "            ", "grads_and_vars_not_none", "=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "clipped_grads_and_vars", "=", "grads_and_vars_not_none", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"clipping method not recognized: \"", "+", "clipping_method", ")", "\n", "\n", "", "return", "clipped_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.set_optimizer": [[661, 665], ["tensorflow.variable_scope", "optimizers.TFOptimizers.TFOptimizers.instantiate_optimizer"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.TFOptimizers.instantiate_optimizer"], ["def", "set_optimizer", "(", "self", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'optimizer'", ")", ":", "\n", "            ", "self", ".", "_optimizer", ",", "self", ".", "_learning_rate", "=", "TFOptimizers", ".", "instantiate_optimizer", "(", "self", ",", "self", ".", "optimizer_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.set_training_op": [[666, 726], ["TFDeepLearningModel.TFDeepLearningModel._optimizer.compute_gradients", "TFDeepLearningModel.TFDeepLearningModel._clip_gradients", "TFDeepLearningModel.TFDeepLearningModel._optimizer.apply_gradients", "tensorflow.group", "tensorflow.group", "len", "tensorflow.add_n", "tensorflow.check_numerics", "tensorflow.check_numerics", "tensorflow.global_norm", "tensorflow.global_norm", "tensorflow.norm", "tensorflow.norm"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._clip_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.apply_gradients"], ["", "", "def", "set_training_op", "(", "self", ")", ":", "\n", "\n", "#def flatten_weights(weights_list):", "\n", "#    weights_tensor = []", "\n", "#    for w in weights_list:", "\n", "#        print(w)", "\n", "#        a = tf.reshape(w, [-1, ])", "\n", "#        weights_tensor.append(a)", "\n", "#", "\n", "#    return tf.concat(weights_tensor, axis=0)", "\n", "\n", "        ", "'''\n        #########################################\n        # Euclidean gradient computed in two steps, through the Jacobian\n        #########################################\n\n        #self.probabilities = tf.nn.softmax(self.logits)\n        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = tf.cast(self.y, tf.int32), logits = self.logits) + self.regularizer\n        #middle_man = self.logits # self.natural_loss #\n\n        #n = self.probabilities.get_shape().as_list()[1]\n        self.euclidean_gradient = tf.gradients(loss, self.logits)[0] # from [g] to g\n\n        trainable_vars = tf.trainable_variables()\n        jacobians = jacobian(self.logits, trainable_vars) # [tf.reduce_sum(i, axis=0) for i in jacobian(self.logits, trainable_vars)]\n\n        #self.nat_grad = [tf.reduce_mean(i, axis=0) for i in self.jacobian]\n\n        # proper way to compute the contraction\n        self.euclidean_gradient = [tf.reduce_mean(tf.einsum(get_contraction(i), i, self.euclidean_gradient), axis=0) for i in jacobians]\n        # OLD self.nat_grad = [tf.reduce_mean(tf.tensordot(i, self.nat_grad_theta, [[1], [1]]), axis=[0,  1, -1]) for i in self.jacobian]\n\n        self.euclidean_grad_norms = [tf.norm(g) for g in self.euclidean_gradient]\n\n        '''", "\n", "\n", "total_loss", "=", "self", ".", "loss", "\n", "# add regularizers in case there are any", "\n", "if", "len", "(", "self", ".", "regularizers", ")", ">", "0", ":", "\n", "            ", "total_loss", "+=", "tf", ".", "add_n", "(", "self", ".", "regularizers", ",", "name", "=", "\"regularization\"", ")", "\n", "\n", "# 1st part of minimize: compute_gradient", "\n", "", "self", ".", "grads_and_vars", "=", "self", ".", "_optimizer", ".", "compute_gradients", "(", "total_loss", ")", "\n", "\n", "# clip gradients", "\n", "clipped_grads_and_vars", "=", "self", ".", "_clip_gradients", "(", "self", ".", "grads_and_vars", ",", "self", ".", "_grad_clipping_tuple", ")", "\n", "\n", "# compute norms in case they need to be logged", "\n", "self", ".", "gradient_norms", "=", "[", "tf", ".", "norm", "(", "g", ")", "+", "NUMTOL", "for", "(", "g", ",", "v", ")", "in", "clipped_grads_and_vars", "]", "\n", "self", ".", "weight_norms", "=", "[", "tf", ".", "norm", "(", "v", ")", "+", "NUMTOL", "for", "(", "g", ",", "v", ")", "in", "clipped_grads_and_vars", "]", "\n", "# check that gradients are finite", "\n", "grads", "=", "[", "tf", ".", "check_numerics", "(", "g", ",", "\"grads is not finite\"", ")", "for", "(", "g", ",", "v", ")", "in", "clipped_grads_and_vars", "]", "\n", "variables", "=", "[", "tf", ".", "check_numerics", "(", "v", ",", "\"grads is not finite\"", ")", "for", "(", "g", ",", "v", ")", "in", "clipped_grads_and_vars", "]", "\n", "self", ".", "gradient_weight_global_norms", "=", "[", "tf", ".", "global_norm", "(", "grads", ")", ",", "tf", ".", "global_norm", "(", "variables", ")", "]", "\n", "\n", "# 2nd part of minimize: apply_gradient", "\n", "optimizer_step", "=", "self", ".", "_optimizer", ".", "apply_gradients", "(", "clipped_grads_and_vars", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "update_ops", "=", "tf", ".", "group", "(", "*", "self", ".", "update_ops", ")", "\n", "self", ".", "training_op", "=", "tf", ".", "group", "(", "update_ops", ",", "optimizer_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.set_check_ops": [[728, 734], ["tensorflow.add_check_numerics_ops"], "methods", ["None"], ["", "def", "set_check_ops", "(", "self", ")", ":", "\n", "        ", "self", ".", "_check_ops", "=", "1", "\n", "\n", "# TODO argo2 This is not working anymore with the new session", "\n", "#with self.sess.graph.as_default():", "\n", "self", ".", "_numerics_ops", "=", "tf", ".", "add_check_numerics_ops", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.release": [[735, 739], ["super().release", "TFDeepLearningModel.TFDeepLearningModel.sess.close", "tensorflow.reset_default_graph"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.release"], ["", "def", "release", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "release", "(", ")", "\n", "self", ".", "sess", ".", "close", "(", ")", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.set_summaries": [[740, 763], ["tensorflow.get_collection", "tensorflow.compat.v1.summary.FileWriter"], "methods", ["None"], ["", "def", "set_summaries", "(", "self", ")", ":", "\n", "        ", "\"\"\"This function sets summaries and summaryFileWriters, it needs to be invoked before\n        training to keep track of the summaries.\n        (cannot be invoked in create_and_init_network because the FileWriter will corrupt data in the logfolder\n        at each initialization)\n        \"\"\"", "\n", "\n", "# wb_regularizers = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)", "\n", "# ac_regularizers = tf.get_collection(AC_REGULARIZATION)", "\n", "#", "\n", "# reg_nodes = wb_regularizers + ac_regularizers", "\n", "\n", "# for rn in reg_nodes:", "\n", "#     tf.summary.scalar(rn.name, rn,", "\n", "#                     collections=[tf.GraphKeys.SUMMARIES, 'regularization_summaries'])", "\n", "\n", "# for each key I get the collection of summary nodes", "\n", "# I set up a filewriter for each summary node", "\n", "self", ".", "summary_nodes", "=", "{", "sk", ":", "tf", ".", "get_collection", "(", "sk", ")", "for", "sk", "in", "self", ".", "summary_keys", "}", "\n", "\n", "for", "sk", "in", "self", ".", "summary_keys", ":", "\n", "            ", "self", ".", "summary_writers", "[", "sk", "]", "=", "[", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriter", "(", "self", ".", "_tensorboard_dir", "+", "sn", ".", "name", ")", "\n", "for", "sn", "in", "self", ".", "summary_nodes", "[", "sk", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_hooks": [[765, 848], ["TFDeepLearningModel.TFDeepLearningModel._check_time_reference", "config.get", "TFDeepLearningModel.TFDeepLearningModel._get_steps", "hooks.append", "hooks.append", "hooks.append", "config.get", "config.get", "int", "tensorflow.train.StopAtStepHook", "TFDeepLearningModel.TFDeepLearningModel._create_general_info_hook", "TFDeepLearningModel.TFDeepLearningModel._create_regularizers_hook", "config.get", "TFDeepLearningModel.TFDeepLearningModel._init_session_saver", "TFDeepLearningModel.TFDeepLearningModel._get_steps", "hooks.append", "TFDeepLearningModel.TFDeepLearningModel._get_steps", "TFDeepLearningModel.TFDeepLearningModel.set_summaries", "hooks.append", "isinstance", "hooks.append", "hooks.CheckpointSaverHook.CheckpointSaverHook", "tensorflow.train.SummarySaverHook", "hooks.ImagesInputHook.ImagesInputHook", "hooks.FisherMatrixHook.FisherMatrixHook", "zip", "config.get"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._check_time_reference", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_general_info_hook", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_regularizers_hook", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._init_session_saver", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.set_summaries"], ["", "", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "\n", "        ", "hooks", "=", "[", "]", "\n", "\n", "# get general arguments for the models hook", "\n", "self", ".", "_time_reference_str", "=", "config", "[", "\"time_reference\"", "]", "\n", "self", ".", "_check_time_reference", "(", "self", ".", "_time_reference_str", ")", "\n", "self", ".", "_plot_offset", "=", "config", ".", "get", "(", "\"plot_offset\"", ",", "0", ")", "\n", "self", ".", "_default_model_hooks_kwargs", "=", "{", "\"time_reference\"", ":", "self", ".", "_time_reference_str", "}", "\n", "\n", "self", ".", "_plot_model_hooks_kwargs", "=", "{", "\"time_reference\"", ":", "self", ".", "_time_reference_str", ",", "\n", "\"plot_offset\"", ":", "self", ".", "_plot_offset", "}", "\n", "\n", "self", ".", "_n_steps_stats", "=", "self", ".", "_get_steps", "(", "config", "[", "\"stats_period\"", "]", ",", "self", ".", "_time_reference_str", ")", "\n", "\n", "# stop hook", "\n", "tot_steps", "=", "int", "(", "self", ".", "_opts", "[", "'epochs'", "]", "+", "1", ")", "*", "self", ".", "n_batches_per_epoch", "\n", "hooks", ".", "append", "(", "tf", ".", "train", ".", "StopAtStepHook", "(", "last_step", "=", "tot_steps", ")", ")", "\n", "\n", "# general info hook (no average on validation but only on train loop)", "\n", "hooks", ".", "append", "(", "self", ".", "_create_general_info_hook", "(", "config", ")", ")", "\n", "\n", "# regularizers hook (no average on validation but only on train loop)", "\n", "hooks", ".", "append", "(", "self", ".", "_create_regularizers_hook", "(", "config", ")", ")", "\n", "\n", "# checkpoint hooks", "\n", "self", ".", "_save_model", "=", "config", "[", "\"save_model\"", "]", "\n", "if", "self", ".", "_save_model", ":", "\n", "            ", "max_to_keep", "=", "config", ".", "get", "(", "\"save_max_to_keep\"", ",", "5", ")", "\n", "self", ".", "_init_session_saver", "(", "max_to_keep", ")", "\n", "self", ".", "_checkpoint_basename", "=", "\"model.ckpt\"", "\n", "save_steps", "=", "self", ".", "_get_steps", "(", "config", "[", "\"save_model_period\"", "]", ",", "self", ".", "_time_reference_str", ")", "\n", "\n", "hooks", ".", "append", "(", "CheckpointSaverHook", "(", "self", ".", "_checkpoint_dir", ",", "\n", "save_steps", "=", "save_steps", ",", "\n", "saver", "=", "self", ".", "_saver", ",", "\n", "checkpoint_basename", "=", "self", ".", "_checkpoint_basename", ",", "\n", "pb_output_nodes", "=", "self", ".", "_pb_output_nodes", ",", "\n", "save_pb_at_end", "=", "config", ".", "get", "(", "\"save_pb\"", ",", "0", ")", "\n", ")", ")", "\n", "\n", "# summary hook", "\n", "", "if", "config", "[", "\"save_summaries\"", "]", ":", "\n", "            ", "save_steps_summaries", "=", "self", ".", "_get_steps", "(", "config", "[", "\"save_summaries_period\"", "]", ",", "self", ".", "_time_reference_str", ")", "\n", "\n", "self", ".", "set_summaries", "(", ")", "\n", "\n", "summary_hooks", "=", "[", "tf", ".", "train", ".", "SummarySaverHook", "(", "save_steps", "=", "save_steps_summaries", ",", "\n", "output_dir", "=", "self", ".", "_tensorboard_dir", "+", "sn", ".", "name", ",", "\n", "summary_op", "=", "sn", ",", "\n", "summary_writer", "=", "fw", ")", "\n", "for", "sk", "in", "self", ".", "summary_keys", "for", "sn", ",", "fw", "in", "zip", "(", "self", ".", "summary_nodes", "[", "sk", "]", ",", "self", ".", "summary_writers", "[", "sk", "]", ")", "]", "\n", "\n", "hooks", "+=", "summary_hooks", "\n", "\n", "# images input hook", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"ImagesInputHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "ImagesInputHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "#gradient_hook = self._create_gradient_hook(config)", "\n", "#if gradient_hook is not None:", "\n", "#    hooks.append(gradient_hook)", "\n", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"FisherMatrixHook\"", ",", "None", ")", "\n", "if", "kwargs", "and", "isinstance", "(", "self", ".", "_optimizer", ",", "NaturalGradientOptimizer", ")", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "#'datasets_keys' : [TRAIN_LOOP],", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "FisherMatrixHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_gradient_hook": [[849, 907], ["numpy.array", "config.get", "list", "numpy.floor", "TFDeepLearningModel.TFDeepLearningModel._get_steps", "hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "range", "str", "len", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps"], ["", "def", "_create_gradient_hook", "(", "self", ",", "config", ")", ":", "\n", "\n", "# gradienthook", "\n", "        ", "tensors_to_average", "=", "[", "\n", "[", "[", "self", ".", "gradient_weight_global_norms", "[", "0", "]", "]", ",", "\n", "self", ".", "gradient_norms", "\n", "]", ",", "\n", "[", "[", "self", ".", "gradient_weight_global_norms", "[", "1", "]", "]", ",", "\n", "self", ".", "weight_norms", "\n", "]", ",", "\n", "]", "\n", "\n", "layer_names", "=", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "self", ".", "gradient_norms", ")", ")", ")", ")", "\n", "layer_names", "=", "np", ".", "floor", "(", "layer_names", "/", "2", ")", "+", "1", "\n", "layer_names", "=", "[", "\"L\"", "+", "str", "(", "int", "(", "l", ")", ")", "for", "l", "in", "layer_names", "]", "\n", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "\"gradient_global_norms\"", "]", ",", "\n", "layer_names", "\n", "]", ",", "\n", "[", "[", "\"weight_global_norms\"", "]", ",", "\n", "layer_names", "\n", "]", ",", "\n", "]", "\n", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\"fileName\"", ":", "\"gradient_global_norms\"", ",", "\"logscale-y\"", ":", "1", ",", "\"compose-label\"", ":", "0", "}", ",", "\n", "{", "\"fileName\"", ":", "\"gradient_norms\"", ",", "\"logscale-y\"", ":", "1", ",", "\"compose-label\"", ":", "0", "}", "\n", "]", ",", "\n", "[", "{", "\"fileName\"", ":", "\"weight_global_norms\"", ",", "\"logscale-y\"", ":", "1", ",", "\"compose-label\"", ":", "0", "}", ",", "\n", "{", "\"fileName\"", ":", "\"weight_norms\"", ",", "\"logscale-y\"", ":", "1", ",", "\"compose-label\"", ":", "0", "}", "\n", "]", ",", "\n", "]", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"GradientsHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "gradient_period", "=", "config", "[", "\"GradientsHook\"", "]", "[", "\"period\"", "]", "\n", "gradient_steps", "=", "self", ".", "_get_steps", "(", "gradient_period", ",", "self", ".", "_time_reference_str", ")", "\n", "hook", "=", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"gradient\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "gradient_steps", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "# trigger_plot=True,", "\n", "print_to_screen", "=", "False", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "# config.get(\"plot_start_epoch\", 1),", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", "\n", "return", "hook", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers_id": [[911, 942], ["regularizers.keys", "utils.argo_utils.load_module", "utils.argo_utils.load_module.create_id", "__name__.split", "Regularizers.Regularizers.Regularizers.create_id", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_module", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["", "", "def", "create_custom_regularizers_id", "(", "self", ",", "network", "=", "None", ")", ":", "\n", "\n", "        ", "if", "network", "is", "None", ":", "\n", "            ", "regularizers", "=", "self", ".", "_opts", "[", "\"regularizers\"", "]", "\n", "", "else", ":", "\n", "            ", "regularizers", "=", "self", ".", "_opts", "[", "\"regularizers\"", "]", "[", "network", "]", "\n", "\n", "", "ids", "=", "\"\"", "\n", "if", "\"custom\"", "in", "regularizers", ".", "keys", "(", ")", ":", "\n", "#import pdb;pdb.set_trace()", "\n", "            ", "for", "regularizer_tuple", "in", "regularizers", "[", "\"custom\"", "]", ":", "\n", "\n", "                ", "regularizer_name", "=", "regularizer_tuple", "[", "0", "]", "\n", "\n", "try", ":", "\n", "                    ", "base_path", "=", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "3", "]", ")", "\n", "regularizer_module", "=", "load_module", "(", "\"Regularizers\"", ",", "base_path", "=", "base_path", ")", "\n", "id", "=", "regularizer_module", ".", "create_id", "(", "regularizer_tuple", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# try to load from argo", "\n", "                    ", "try", ":", "\n", "                        ", "id", "=", "Regularizers", ".", "create_id", "(", "regularizer_tuple", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                        ", "raise", "Exception", "(", "\"regularizer %s not found\"", "%", "regularizer_name", ")", "from", "e", "\n", "\n", "", "", "if", "ids", "==", "\"\"", ":", "\n", "                    ", "ids", "=", "id", "\n", "", "else", ":", "\n", "                    ", "ids", "=", "ids", "+", "\"_\"", "+", "id", "\n", "\n", "", "", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_regularizers_hook": [[944, 996], ["tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "_create_regularizers_hook", "(", "self", ",", "config", ")", ":", "\n", "\n", "        ", "wb_regularizers", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "# see keras_utils.py: activity_and_contractive_regularizers", "\n", "ac_regularizers", "=", "tf", ".", "get_collection", "(", "AC_REGULARIZATION", ")", "\n", "custom_regularizers", "=", "tf", ".", "get_collection", "(", "CUSTOM_REGULARIZATION", ")", "\n", "\n", "if", "wb_regularizers", ":", "\n", "            ", "wb_regularizers_names", "=", "[", "r", ".", "name", "for", "r", "in", "wb_regularizers", "]", "\n", "", "else", ":", "\n", "            ", "wb_regularizers", "=", "[", "tf", ".", "zeros", "(", "[", "1", "]", ")", "]", "\n", "wb_regularizers_names", "=", "[", "\"none\"", "]", "\n", "", "wb_regularizers_fileNames", "=", "{", "\"fileName\"", ":", "\"wb_regularizers\"", "}", "\n", "\n", "if", "ac_regularizers", ":", "\n", "            ", "ac_regularizers_names", "=", "[", "r", ".", "name", "for", "r", "in", "ac_regularizers", "]", "\n", "", "else", ":", "\n", "            ", "ac_regularizers", "=", "[", "tf", ".", "zeros", "(", "[", "1", "]", ")", "]", "\n", "ac_regularizers_names", "=", "[", "\"none\"", "]", "\n", "", "ac_regularizers_fileNames", "=", "{", "\"fileName\"", ":", "\"ac_regularizers\"", "}", "\n", "\n", "if", "custom_regularizers", ":", "\n", "            ", "custom_regularizers_names", "=", "[", "r", ".", "name", "for", "r", "in", "custom_regularizers", "]", "\n", "", "else", ":", "\n", "            ", "custom_regularizers", "=", "[", "tf", ".", "zeros", "(", "[", "1", "]", ")", "]", "\n", "custom_regularizers_names", "=", "[", "\"none\"", "]", "\n", "", "custom_regularizers_fileNames", "=", "{", "\"fileName\"", ":", "\"custom_regularizers\"", "}", "\n", "\n", "# logging hooks", "\n", "tensors_to_average", "=", "[", "[", "wb_regularizers", "]", ",", "[", "ac_regularizers", ",", "custom_regularizers", "]", "]", "\n", "tensors_to_average_names", "=", "[", "[", "wb_regularizers_names", "]", ",", "[", "ac_regularizers_names", ",", "custom_regularizers_names", "]", "]", "\n", "tensors_to_average_plots", "=", "[", "[", "wb_regularizers_fileNames", "]", ",", "\n", "[", "ac_regularizers_fileNames", ",", "custom_regularizers_fileNames", "]", "]", "\n", "\n", "\n", "hook", "=", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"regularizers\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "print_to_screen", "=", "False", ",", "\n", "# trigger_plot = True,", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", "return", "hook", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._create_general_info_hook": [[998, 1026], ["hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook"], "methods", ["None"], ["", "def", "_create_general_info_hook", "(", "self", ",", "config", ")", ":", "\n", "# logging hooks", "\n", "        ", "tensors_to_average", "=", "[", "\n", "[", "[", "self", ".", "_learning_rate", "]", "]", "\n", "]", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "\"learning_rate\"", "]", "]", ",", "\n", "]", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\"fileName\"", ":", "\"learning_rate\"", "}", "]", "\n", "]", "\n", "\n", "hook", "=", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"info\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "print_to_screen", "=", "False", ",", "\n", "# trigger_plot = True,", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "]", "\n", ")", "\n", "return", "hook", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_session": [[1029, 1093], ["TFDeepLearningModel.TFDeepLearningModel.create_hooks", "TFDeepLearningModel.TFDeepLearningModel.get_raw_session().run", "tensorflow.ConfigProto", "tensorflow.ConfigProto", "TFDeepLearningModel.TFDeepLearningModel.set_check_ops", "TFDeepLearningModel.TFDeepLearningModel._fix_checkpoint_abs_to_rel", "tensorflow.train.ChiefSessionCreator", "tensorflow.train.MonitoredSession", "tensorflow.Session", "TFDeepLearningModel.TFDeepLearningModel._save_graph", "TFDeepLearningModel.TFDeepLearningModel._network.init_saver", "TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "TFDeepLearningModel.TFDeepLearningModel.run", "TFDeepLearningModel.TFDeepLearningModel._network.restore"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.set_check_ops", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._fix_checkpoint_abs_to_rel", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._save_graph", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.init_saver", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore"], ["", "def", "create_session", "(", "self", ",", "opts", ",", "config", ",", "monitorSession", "=", "True", ")", ":", "\n", "\n", "# save to set the right behavior in self.get_raw_session()", "\n", "        ", "self", ".", "monitorSession", "=", "monitorSession", "\n", "\n", "# set some important options", "\n", "if", "self", ".", "_gpu", "==", "-", "1", ":", "\n", "            ", "sess_config", "=", "tf", ".", "ConfigProto", "(", "device_count", "=", "{", "'GPU'", ":", "0", "}", ",", "\n", "allow_soft_placement", "=", "True", ")", "\n", "", "else", ":", "\n", "#config = tf.ConfigProto(log_device_placement=True)", "\n", "            ", "sess_config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "\n", "", "sess_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "# self.sess = tf.Session(config=config)", "\n", "# self.sess = tf.InteractiveSession()", "\n", "\n", "# not needed anymore, moved in hooks...", "\n", "# self.set_summaries()", "\n", "\n", "if", "self", ".", "_check_ops", ":", "\n", "            ", "self", ".", "set_check_ops", "(", ")", "\n", "\n", "", "self", ".", "hooks", "=", "self", ".", "create_hooks", "(", "config", ")", "\n", "\n", "#TODO-ARGO2 if we would use a SingularMonitoredSession, it is possible to directly pass it to a saver for custom user saving..", "\n", "#TODO-ARGO2 How to handle this with the more stable Monitored Session? Maybe a TFTrainableDeepLearningModel", "\n", "#TODO-ARGO2 by the way it is possible to define a custom Monitored session", "\n", "#TODO-ARGO2 (to handle only hooks without fancy session stuffs http://davideng.me/2017/10/11/designing-a-custom-monitored-training-session.html", "\n", "\n", "\n", "if", "monitorSession", ":", "\n", "# MonitoredSession", "\n", "# this will restore all the variables from the latest checkpoint if it exists", "\n", "            ", "self", ".", "_fix_checkpoint_abs_to_rel", "(", "self", ".", "_checkpoint_dir", ")", "# need to ensure checkpoint has relative path saved", "\n", "\n", "chiefsess_creator", "=", "tf", ".", "train", ".", "ChiefSessionCreator", "(", "config", "=", "sess_config", ",", "checkpoint_dir", "=", "self", ".", "_checkpoint_dir", ")", "\n", "\n", "if", "self", ".", "_restore_chkptfile", "is", "not", "None", ":", "\n", "                ", "self", ".", "_network", ".", "init_saver", "(", ")", "\n", "# this is restoring variables ", "\n", "", "self", ".", "sess", "=", "tf", ".", "train", ".", "MonitoredSession", "(", "session_creator", "=", "chiefsess_creator", ",", "hooks", "=", "self", ".", "hooks", ")", "\n", "\n", "# Restore from some checkpoint", "\n", "if", "self", ".", "_restore_chkptfile", "is", "not", "None", ":", "\n", "                ", "raw_sess", "=", "self", ".", "get_raw_session", "(", ")", "\n", "if", "raw_sess", ".", "run", "(", "self", ".", "global_step", ")", "==", "0", ":", "\n", "                    ", "self", ".", "_network", ".", "restore", "(", "raw_sess", ",", "self", ".", "_restore_chkptfile", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "sess_config", ")", "\n", "#all_variables = tf.get_collection_ref(tf.GraphKeys.GLOBAL_VARIABLES)", "\n", "#self.sess.run(tf.variables_initializer(all_variables))", "\n", "\n", "", "if", "self", ".", "_save_model", ":", "\n", "            ", "self", ".", "_save_graph", "(", ")", "\n", "\n", "# SingularMonitoredSession", "\n", "# self.sess = tf.train.SingularMonitoredSession(checkpoint_dir=self._checkpoint_dir,", "\n", "#                                              hooks=self.hooks, config=sess_config)", "\n", "\n", "\n", "#I do not want to trigger hooks for this!!", "\n", "", "self", ".", "datasets_handles", "=", "self", ".", "get_raw_session", "(", ")", ".", "run", "(", "self", ".", "datasets_handles_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session": [[1098, 1107], ["Exception", "TFDeepLearningModel.TFDeepLearningModel.sess._tf_sess"], "methods", ["None"], ["", "def", "get_raw_session", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "sess", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"The session is None\"", ")", "\n", "\n", "", "if", "self", ".", "monitorSession", ":", "\n", "            ", "return", "self", ".", "sess", ".", "_tf_sess", "(", ")", "\n", "", "else", ":", "\n", "# suppose regular Session()", "\n", "            ", "return", "self", ".", "sess", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.train": [[1109, 1172], ["print", "getattr", "TFDeepLearningModel.TFDeepLearningModel.sess.should_stop", "getattr.", "str", "TFDeepLearningModel.TFDeepLearningModel.sess.run", "TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "Exception", "print", "Exception", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "\n", "# epoch = 0", "\n", "# # start timer for TF", "\n", "# start_tf = timeit.default_timer()", "\n", "\n", "# INITIALIZATION OPERATIONS HERE", "\n", "# Also: I always perform a global_step evaluation to eventually \"wake up\" the", "\n", "# stop condition of StopAtStepHook if needed (otherwise it would do an extra step over its limit each time)", "\n", "# (possible bug in tf?)", "\n", "# initializer = self.dataset_initializers[\"train\"]", "\n", "# args = [initializer] if initializer is not None else []", "\n", "# args += [self.global_step]", "\n", "# self.get_raw_session().run(args)", "\n", "\n", "        ", "for", "hook", "in", "self", ".", "hooks", ":", "\n", "            ", "before_training", "=", "getattr", "(", "hook", ",", "'before_training'", ",", "None", ")", "\n", "if", "before_training", "is", "not", "None", ":", "\n", "                ", "before_training", "(", "self", ".", "get_raw_session", "(", ")", ")", "\n", "\n", "#i = 0", "\n", "\n", "# count of the nan / inf", "\n", "", "", "k", "=", "0", "\n", "# MAX nan / inf", "\n", "MAX_K", "=", "100", "\n", "\n", "print", "(", "\"Graph size: \"", "+", "str", "(", "self", ".", "graph_size", ")", ")", "\n", "\n", "# loops over the batches", "\n", "while", "not", "self", ".", "sess", ".", "should_stop", "(", ")", ":", "\n", "# import pdb;pdb.set_trace()", "\n", "            ", "try", ":", "\n", "#import pdb; pdb.set_trace()", "\n", "# sess = self.get_raw_session()", "\n", "# sess.run(self._network.get_all_variables()[6])", "\n", "# g, g_norm, x, y, loss, grads_and_vars, _, global_epoch = self.sess.run([self.grads, self.grads_norm, self.x, self.y, self.loss, self.grads_and_vars , self.training_op, self.global_epoch],", "\n", "\n", "\n", "# loss must be evaluated and fetched to raise InvalidArgumentError if nan, see https://github.com/tensorflow/tensorflow/issues/11098", "\n", "                ", "_", ",", "_", ",", "global_epoch", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "training_op", ",", "self", ".", "loss", ",", "self", ".", "global_epoch", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "ds_handle", ":", "self", ".", "datasets_handles", "[", "TRAIN_LOOP", "]", ",", "\n", "self", ".", "is_training", ":", "True", "}", ")", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "# self.sess.run([self.z],feed_dict = {self.ds_handle : self.datasets_handles[TRAIN_LOOP],self.is_training : True})[0].shape", "\n", "# pdb.set_trace()", "\n", "\n", "#self.invFisher, self.prob,", "\n", "#print(i, loss)", "\n", "#if i==180:", "\n", "#    pdb.set_trace()", "\n", "#i = i + 1", "\n", "\n", "", "except", "tf", ".", "errors", ".", "InvalidArgumentError", ":", "\n", "\n", "                ", "raise", "Exception", "(", "\"an error has occurred during training, check stack trace UP HERE\"", ")", "\n", "\n", "k", "=", "k", "+", "1", "\n", "print", "(", "\"an error has occurred during training, this happened \"", "+", "str", "(", "k", ")", "+", "\" times over \"", "+", "str", "(", "MAX_K", ")", ")", "\n", "if", "k", "==", "MAX_K", ":", "\n", "                    ", "raise", "Exception", "(", "\"an error has occurred during training, check stack trace UP HERE\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._init_session_saver": [[1195, 1203], ["os.makedirs", "tensorflow.train.Saver"], "methods", ["None"], ["", "", "", "", "def", "_init_session_saver", "(", "self", ",", "max_to_keep", ",", "variables", "=", "None", ")", ":", "\n", "        ", "\"\"\" A saver with all the variables for the session is instantiated and set in self._saver, with variables,\n        by default variables is None, all variables in the graph will be saved.\n        It is probably a good idea since the whole session must be later be restored by the ChiefSession\n        \"\"\"", "\n", "os", ".", "makedirs", "(", "self", ".", "_checkpoint_dir", ",", "exist_ok", "=", "True", ")", "\n", "#variables = tf.trainable_variables()", "\n", "self", ".", "_saver", "=", "tf", ".", "train", ".", "Saver", "(", "variables", ",", "max_to_keep", "=", "max_to_keep", ",", "save_relative_paths", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._save_graph": [[1204, 1211], ["tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter.flush", "tensorflow.get_default_graph"], "methods", ["None"], ["", "def", "_save_graph", "(", "self", ")", ":", "\n", "        ", "writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "logdir", "=", "self", ".", "_checkpoint_dir", ",", "\n", "# graph=self.sess.graph,", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ",", "\n", "filename_suffix", "=", "\"-graph\"", "\n", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._assemble_checkpoint_name": [[1212, 1215], ["os.path.join"], "methods", ["None"], ["", "def", "_assemble_checkpoint_name", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "\"model.ckpt\"", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._latest_checkpoint": [[1216, 1223], ["os.path.basename", "open", "os.path.basename.strip", "os.path.basename", "fs.readline().split", "fs.readline"], "methods", ["None"], ["", "def", "_latest_checkpoint", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "        ", "with", "open", "(", "checkpoint_dir", "+", "'checkpoint'", ")", "as", "fs", ":", "\n", "            ", "potentiallyabsolutepath", "=", "fs", ".", "readline", "(", ")", ".", "split", "(", ")", "[", "1", "]", "\n", "\n", "", "potentiallyabsolutepath", "=", "os", ".", "path", ".", "basename", "(", "potentiallyabsolutepath", ".", "strip", "(", "'\"'", ")", ")", "\n", "path", "=", "checkpoint_dir", "+", "os", ".", "path", ".", "basename", "(", "potentiallyabsolutepath", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._fix_checkpoint_abs_to_rel": [[1224, 1239], ["os.path.isfile", "open", "open.close", "open", "open.readlines", "line.split", "os.path.basename", "open.write", "os.path.basename.strip", "os.path.basename"], "methods", ["None"], ["", "def", "_fix_checkpoint_abs_to_rel", "(", "self", ",", "checkpoint_dir", ")", ":", "\n", "        ", "checkpointfilename", "=", "checkpoint_dir", "+", "'checkpoint'", "\n", "exists", "=", "os", ".", "path", ".", "isfile", "(", "checkpointfilename", ")", "\n", "if", "exists", ":", "\n", "            ", "with", "open", "(", "checkpointfilename", ")", "as", "fs", ":", "\n", "                ", "lines", "=", "fs", ".", "readlines", "(", ")", "\n", "\n", "", "fs", "=", "open", "(", "checkpointfilename", ",", "'w'", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "which_model", ",", "potentiallyabsolutepath", "=", "line", ".", "split", "(", ")", "\n", "potentiallyabsolutepath", "=", "os", ".", "path", ".", "basename", "(", "potentiallyabsolutepath", ".", "strip", "(", "'\"'", ")", ")", "\n", "rel_path", "=", "'\\\"'", "+", "os", ".", "path", ".", "basename", "(", "potentiallyabsolutepath", ")", "+", "'\\\"'", "\n", "fs", ".", "write", "(", "\" \"", ".", "join", "(", "[", "which_model", ",", "rel_path", "]", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "fs", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.checkpoint_name": [[1240, 1251], ["TFDeepLearningModel.TFDeepLearningModel._assemble_checkpoint_name", "TFDeepLearningModel.TFDeepLearningModel._latest_checkpoint", "Exception", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._assemble_checkpoint_name", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._latest_checkpoint"], ["", "", "def", "checkpoint_name", "(", "self", ",", "global_step", ")", ":", "\n", "        ", "if", "global_step", ":", "\n", "            ", "path", "=", "self", ".", "_assemble_checkpoint_name", "(", "self", ".", "_checkpoint_dir", ")", "\n", "path", "+=", "\"-\"", "+", "str", "(", "global_step", ")", "\n", "", "else", ":", "\n", "            ", "path", "=", "self", ".", "_latest_checkpoint", "(", "self", ".", "_checkpoint_dir", ")", "\n", "\n", "", "if", "not", "path", ":", "\n", "            ", "raise", "Exception", "(", "\"could not find saved checkpoints in %s\"", "%", "self", ".", "_checkpoint_dir", ")", "\n", "\n", "", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.save": [[1252, 1259], ["Exception", "TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "TFDeepLearningModel.TFDeepLearningModel._assemble_checkpoint_name", "TFDeepLearningModel.TFDeepLearningModel._saver.save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._assemble_checkpoint_name", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "def", "save", "(", "self", ",", "global_step", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "_saver", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"saver must be initialized before attempt to save\"", ")", "\n", "", "else", ":", "\n", "            ", "session", "=", "self", ".", "get_raw_session", "(", ")", "\n", "path", "=", "self", ".", "_assemble_checkpoint_name", "(", ")", "\n", "self", ".", "_saver", ".", "save", "(", "session", ",", "path", ",", "global_step", "=", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.restore": [[1260, 1276], ["TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "Exception", "TFDeepLearningModel.TFDeepLearningModel.checkpoint_name", "TFDeepLearningModel.TFDeepLearningModel._saver.restore"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.checkpoint_name", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore"], ["", "", "def", "restore", "(", "self", ",", "global_step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Restore the model variables.\n\n        Args:\n            global_step (type): the step from which to restore. By default it is None\n                    and the latest checkpoint in self.checkpoint_dir will be restored\n        \"\"\"", "\n", "\n", "path", "=", "\"\"", "\n", "session", "=", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "if", "self", ".", "_saver", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"saver must be initialized before attempt to restore\"", ")", "\n", "", "else", ":", "\n", "            ", "path", "=", "self", ".", "checkpoint_name", "(", "global_step", ")", "\n", "self", ".", "_saver", ".", "restore", "(", "session", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.graph_size": [[1277, 1280], ["len", "TFDeepLearningModel.TFDeepLearningModel.sess.graph.as_graph_def"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "graph_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "[", "n", ".", "name", "for", "n", "in", "self", ".", "sess", ".", "graph", ".", "as_graph_def", "(", ")", ".", "node", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._check_time_reference": [[1281, 1285], ["ValueError"], "methods", ["None"], ["", "def", "_check_time_reference", "(", "self", ",", "time_ref", ")", ":", "\n", "        ", "time_choices", "=", "[", "EPOCHS", ",", "STEPS", "]", "\n", "if", "not", "time_ref", "in", "time_choices", ":", "\n", "            ", "raise", "ValueError", "(", "\"time_reference in the frequency tuple can only be in %s\"", "%", "time_choices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps": [[1286, 1300], ["TFDeepLearningModel.TFDeepLearningModel._check_time_reference", "float", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._check_time_reference"], ["", "", "def", "_get_steps", "(", "self", ",", "n", ",", "time_reference", ")", ":", "\n", "# try:", "\n", "#     n, time_ref = frequency", "\n", "# except:", "\n", "#     raise Exception(\"cannot unpack tuple %s, expected a couple (n, time_ref),\"", "\n", "#                     \"where time_ref can either be `epochs` or `steps`\" % frequency)", "\n", "\n", "        ", "self", ".", "_check_time_reference", "(", "time_reference", ")", "\n", "n", "=", "float", "(", "n", ")", "\n", "\n", "if", "time_reference", "==", "EPOCHS", ":", "\n", "            ", "n", "=", "n", "*", "self", ".", "n_batches_per_epoch", "\n", "\n", "", "return", "int", "(", "n", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.load_model": [[34, 83], ["ArgoLauncher.ArgoLauncher.process_conf_file", "utils.argo_utils.load_class", "TFDeepLearningModel.update_model_params", "utils.argo_utils.load_class.", "ArgoTFDeepLearningModelClass.init", "ArgoTFDeepLearningModelClass.create_session", "ArgoTFDeepLearningModelClass.restore", "datasets.Dataset.Dataset.load_dataset", "os.path.split", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.update_model_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.init", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_session", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset"], ["def", "load_model", "(", "conf_file", ",", "global_step", "=", "None", ",", "dataset", "=", "None", ",", "gpu", "=", "0", ",", "seed", "=", "0", ",", "model_class_base_path", "=", "''", ",", "monitorSession", "=", "True", ")", ":", "\n", "    ", "\"\"\"Load a TFDeepLearningModel and optionally save its network\n\n    Args:\n        conf_file (str): the conf file of the model where to find the experiment.\n        dataset (datasets.Dataset): (optional) the argo Dataset of the model for the training. If not passed it will be reloaded.\n        global_step (int): the global step to load the checkpoint (if None the last checkpoint present will be loaded).\n        gpu (int) : the gpu on which the model will create the session\n        seed (int) : the seed that the model will set\n        model_class_base_path (str): the base path where to look for the model class\n\n    Returns:\n        TFDeepLearningModel: The loaded Argo TFDeepLearningModel.\n        datasets.Dataset: the argo Dataset of the model for the training.\n\n    \"\"\"", "\n", "\n", "dataset_conf", ",", "model_parameters", ",", "config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "conf_file", ")", "\n", "\n", "if", "not", "dataset", ":", "\n", "        ", "dataset", "=", "Dataset", ".", "load_dataset", "(", "dataset_conf", ")", "\n", "\n", "", "ArgoTFDeepLearningModelClass", "=", "load_class", "(", "model_parameters", "[", "\"model\"", "]", ",", "base_path", "=", "model_class_base_path", ")", "\n", "\n", "update_model_params", "(", "model_parameters", ",", "dataset", ")", "\n", "\n", "# baseDir = config[\"dirName\"]+\"/\"+dataset.id", "\n", "model_dir", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "dirname", "(", "conf_file", ")", ")", "[", "0", "]", "\n", "model", "=", "ArgoTFDeepLearningModelClass", "(", "model_parameters", ",", "model_dir", ",", "gpu", "=", "gpu", ",", "seed", "=", "seed", ")", "\n", "model", ".", "init", "(", "dataset", ")", "\n", "# network = model._network", "\n", "# network.init_saver()", "\n", "\n", "model", ".", "create_session", "(", "model_parameters", ",", "config", ",", "monitorSession", "=", "monitorSession", ")", "\n", "\n", "#if global_step is None it will restore the last checkpoint in the folder model._checkpoint_dir, you can pass global_step to restore a particular chackpoint", "\n", "model", ".", "restore", "(", "global_step", "=", "global_step", ")", "\n", "\n", "# if save_net:", "\n", "#     sess = model.get_raw_session()", "\n", "#", "\n", "#     if network_dir:", "\n", "#         path = network_dir+\"/\"+get_full_id(dataset, model)+'/'+network.name", "\n", "#     else:", "\n", "#         path = model.dirName+'/networks/'+network.name", "\n", "#", "\n", "#     network.save(sess, path, global_step=global_step)", "\n", "\n", "return", "model", ",", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.load_model_without_session": [[85, 122], ["ArgoLauncher.ArgoLauncher.process_conf_file", "utils.argo_utils.load_class", "TFDeepLearningModel.update_model_params", "utils.argo_utils.load_class.", "ArgoTFDeepLearningModelClass.init", "ArgoTFDeepLearningModelClass.checkpoint_name", "datasets.Dataset.Dataset.load_dataset", "os.path.split", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.update_model_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.init", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.checkpoint_name", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset"], ["", "def", "load_model_without_session", "(", "conf_file", ",", "global_step", "=", "None", ",", "dataset", "=", "None", ",", "gpu", "=", "0", ",", "seed", "=", "0", ",", "model_class_base_path", "=", "''", ")", ":", "\n", "    ", "\"\"\"Load a TFDeepLearningModel without session\n\n    Args:\n        conf_file (str): the conf file of the model where to find the experiment.\n        dataset (datasets.Dataset): (optional) the argo Dataset of the model for the training. If not passed it will be reloaded.\n        global_step (int): the global step to load the checkpoint (if None the last checkpoint present will be loaded).\n        gpu (int) : the gpu on which the model will create the session\n        seed (int) : the seed that the model will set\n        model_class_base_path (str): the base path where to look for the model class\n\n    Returns:\n        TFDeepLearningModel: The loaded Argo TFDeepLearningModel.\n        datasets.Dataset: the argo Dataset of the model for the training.\n\n    \"\"\"", "\n", "\n", "dataset_conf", ",", "model_parameters", ",", "config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "conf_file", ")", "\n", "\n", "if", "not", "dataset", ":", "\n", "        ", "dataset", "=", "Dataset", ".", "load_dataset", "(", "dataset_conf", ")", "\n", "\n", "", "ArgoTFDeepLearningModelClass", "=", "load_class", "(", "model_parameters", "[", "\"model\"", "]", ",", "base_path", "=", "model_class_base_path", ")", "\n", "\n", "update_model_params", "(", "model_parameters", ",", "dataset", ")", "\n", "\n", "# baseDir = config[\"dirName\"]+\"/\"+dataset.id", "\n", "model_dir", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "dirname", "(", "conf_file", ")", ")", "[", "0", "]", "\n", "model", "=", "ArgoTFDeepLearningModelClass", "(", "model_parameters", ",", "model_dir", ",", "gpu", "=", "gpu", ",", "seed", "=", "seed", ")", "\n", "model", ".", "init", "(", "dataset", ")", "\n", "\n", "# network = model._network", "\n", "# network.init_saver()", "\n", "\n", "checkpoint_name", "=", "model", ".", "checkpoint_name", "(", "global_step", ")", "\n", "\n", "return", "model", ",", "dataset", ",", "checkpoint_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.load_network": [[124, 165], ["ArgoLauncher.ArgoLauncher.process_conf_file", "TFDeepLearningModel.update_model_params", "ArgoTFDeepLearningModelClass", "ArgoTFDeepLearningModelClass.checkpoint_name", "os.path.split", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.update_model_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.checkpoint_name"], ["", "def", "load_network", "(", "ArgoTFDeepLearningModelClass", ",", "conf_file", ",", "dataset", ",", "global_step", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load the network of a specific model and the corresponding checkpoint.\n    The Network needs to be applied (to generate the variables, that are instantiated in the _build of Sonnet)\n    and then restored from the checkpoint.\n\n    e.g.\n    ```\n    network, checkpoint_name = load_network(ClassificationModel, model_dir,\n                                        dataset, model_params, config)\n    logits = network(x)\n    network.restore(sess, checkpoint_name)\n    ```\n\n    Args:\n        ArgoTFDeepLearningModelClass (Class): the TFDeepLearningModel class to load.\n        conf_file (str): the conf file of the model where to find the experiment.\n        dataset (datasets.Dataset): (optional) the argo Dataset of the model for the training. If not passed it will be reloaded.\n        global_step (int): (optional) the global step to load the checkpoint (if None the last checkpoint present will be loaded).\n\n    Returns:\n        ArgoAbstractNetwork: the Argo Network to load\n        str: checkpoint_name\n    \"\"\"", "\n", "\n", "dataset_conf", ",", "model_parameters", ",", "config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "conf_file", ")", "\n", "# parallelism = 0 # 0 is equivalent to single", "\n", "\n", "# if dataset is not None:", "\n", "#     print(\"load_network: `dataset` IS DEPRECATED, will be removed soon\")", "\n", "# if model_class_base_path is not '':", "\n", "#     print(\"load_network: `model_class_base_path` IS DEPRECATED, will be removed soon\")", "\n", "#", "\n", "\n", "update_model_params", "(", "model_parameters", ",", "dataset", ")", "\n", "\n", "model_dir", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "dirname", "(", "conf_file", ")", ")", "[", "0", "]", "\n", "model", "=", "ArgoTFDeepLearningModelClass", "(", "model_parameters", ",", "model_dir", ")", "\n", "\n", "network", "=", "model", ".", "_network", "\n", "checkpoint_name", "=", "model", ".", "checkpoint_name", "(", "global_step", ")", "\n", "return", "network", ",", "checkpoint_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.update_model_params": [[167, 177], ["model_parameters.update"], "function", ["None"], ["", "def", "update_model_params", "(", "model_parameters", ",", "dataset", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "output_shape", "=", "dataset", ".", "y_shape", "\n", "", "except", "ValueError", ":", "\n", "        ", "output_shape", "=", "None", "\n", "\n", "", "dataset_info", "=", "{", "\"output_shape\"", ":", "output_shape", ",", "\n", "\"input_shape\"", ":", "dataset", ".", "x_shape_train", "}", "\n", "\n", "model_parameters", ".", "update", "(", "dataset_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ProcessTask.__init__": [[30, 40], ["multiprocessing.Process.__init__", "print", "str", "os.getpid"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tasks_queue", ",", "gpu_allocation_queue", ",", "launcher", ")", ":", "#, return_queue", "\n", "        ", "super", "(", "ProcessTask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "print", "(", "\"Creating consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", ")", "\n", "\n", "self", ".", "tasks_queue", "=", "tasks_queue", "\n", "self", ".", "gpu_allocation_queue", "=", "gpu_allocation_queue", "\n", "self", ".", "lock", "=", "None", "\n", "self", ".", "dependencies", "=", "None", "\n", "self", ".", "launcher", "=", "launcher", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ProcessTask.set_dependencies": [[41, 44], ["None"], "methods", ["None"], ["", "def", "set_dependencies", "(", "self", ",", "dependencies", ",", "lock", ")", ":", "\n", "        ", "self", ".", "dependencies", "=", "dependencies", "\n", "self", ".", "lock", "=", "lock", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ProcessTask.run": [[45, 84], ["ArgoLauncher.ProcessTask.tasks_queue.get", "ArgoLauncher.ProcessTask.gpu_allocation_queue.get", "print", "ArgoLauncher.ProcessTask.gpu_allocation_queue.put", "ArgoLauncher.ProcessTask.tasks_queue.task_done", "print", "print", "ArgoLauncher.ProcessTask.tasks_queue.task_done", "ArgoLauncher.ProcessTask.launcher.task_execute", "str", "open", "time.strftime", "open.write", "open.write", "traceback.format_exc", "open.write", "open.close", "print", "str", "str", "time.gmtime", "str", "os.getpid", "os.getpid", "os.getpid", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.task_execute"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "# this accessed in a safe way by the ProcessTask", "\n", "            ", "task_and_config", "=", "self", ".", "tasks_queue", ".", "get", "(", ")", "\n", "\n", "if", "task_and_config", "is", "None", ":", "\n", "# Poison pill means shutdown", "\n", "                ", "print", "(", "\"Exiting from consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", ")", "\n", "self", ".", "tasks_queue", ".", "task_done", "(", ")", "\n", "break", "\n", "\n", "", "(", "task", ",", "config", ")", "=", "task_and_config", "\n", "\n", "gpu", "=", "self", ".", "gpu_allocation_queue", ".", "get", "(", ")", "\n", "print", "(", "\"Running on GPU \"", "+", "str", "(", "gpu", ")", ")", "\n", "\n", "executed", "=", "False", "\n", "#import pdb;pdb.set_trace()", "\n", "try", ":", "\n", "                ", "executed", "=", "self", ".", "launcher", ".", "task_execute", "(", "task", ",", "config", ",", "gpu", ",", "\n", "self", ".", "dependencies", ",", "\n", "self", ".", "lock", ",", "\n", "\"Consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", ")", "\n", "", "except", "Exception", "as", "exc", ":", "\n", "                ", "errfile", "=", "self", ".", "launcher", ".", "_launchable", ".", "dirName", "+", "'/error.log'", "\n", "\n", "errstream", "=", "open", "(", "errfile", ",", "'a'", ")", "\n", "errtime", "=", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\\n\"", ",", "gmtime", "(", ")", ")", "\n", "errstream", ".", "write", "(", "\"\\nError occurred at: \"", "+", "errtime", ")", "\n", "errstream", ".", "write", "(", "\"Failed to execute job: \\n\"", "+", "str", "(", "exc", ")", "+", "\"\\n\"", ")", "\n", "trace", "=", "traceback", ".", "format_exc", "(", ")", "\n", "errstream", ".", "write", "(", "trace", ")", "\n", "errstream", ".", "close", "(", ")", "\n", "\n", "print", "(", "\"Failed to execute job: \\n\"", "+", "str", "(", "exc", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "self", ".", "gpu_allocation_queue", ".", "put", "(", "gpu", ")", "\n", "self", ".", "tasks_queue", ".", "task_done", "(", ")", "\n", "print", "(", "\"Consumer PID = \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", "+", "\" has processed the job\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ProcessDistributedTask.__init__": [[98, 112], ["multiprocessing.Process.__init__", "print", "str", "os.getpid"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tasks_queue", ",", "gpu_allocation_queue", ",", "launcher", ",", "node_number", ",", "ip", ")", ":", "#, return_queue", "\n", "        ", "super", "(", "ProcessDistributedTask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "print", "(", "\"Creating consumer from \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", ")", "\n", "\n", "self", ".", "tasks_queue", "=", "tasks_queue", "\n", "self", ".", "gpu_allocation_queue", "=", "gpu_allocation_queue", "\n", "#self.return_queue = return_queue", "\n", "\n", "#self.task_execute = task_execute", "\n", "self", ".", "launcher", "=", "launcher", "\n", "\n", "self", ".", "node_number", "=", "node_number", "\n", "self", ".", "ip", "=", "ip", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ProcessDistributedTask.run": [[113, 139], ["ArgoLauncher.ProcessDistributedTask.tasks_queue.get", "ArgoLauncher.ProcessDistributedTask.gpu_allocation_queue.get", "print", "ArgoLauncher.ProcessDistributedTask.launcher.task_execute_remote", "ArgoLauncher.ProcessDistributedTask.gpu_allocation_queue.put", "ArgoLauncher.ProcessDistributedTask.tasks_queue.task_done", "print", "print", "ArgoLauncher.ProcessDistributedTask.tasks_queue.task_done", "str", "str", "str", "os.getpid", "os.getpid", "os.getpid", "str"], "methods", ["None"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "task_and_config", "=", "self", ".", "tasks_queue", ".", "get", "(", ")", "\n", "\n", "if", "task_and_config", "is", "None", ":", "\n", "# Poison pill means shutdown", "\n", "                ", "print", "(", "\"Exiting from consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", ")", "\n", "self", ".", "tasks_queue", ".", "task_done", "(", ")", "\n", "break", "\n", "\n", "", "(", "task", ",", "config", ")", "=", "task_and_config", "\n", "\n", "gpu", "=", "self", ".", "gpu_allocation_queue", ".", "get", "(", ")", "\n", "print", "(", "\"Planned to run on GPU \"", "+", "str", "(", "gpu", ")", "+", "\" at \"", "+", "self", ".", "ip", ")", "\n", "\n", "# replace in config specific inforation about the node/GPU", "\n", "config", "[", "\"nodes\"", "]", "=", "[", "config", "[", "\"nodes\"", "]", "[", "self", ".", "node_number", "]", "]", "\n", "config", "[", "\"nodes\"", "]", "[", "0", "]", "[", "\"used_GPUs\"", "]", "=", "{", "gpu", "}", "\n", "config", "[", "\"nodes\"", "]", "[", "0", "]", "[", "\"cores_per_GPU\"", "]", "=", "1", "\n", "\n", "#self.task_execute(task, config, gpu, \"Consumer \" + str(os.getpid()))", "\n", "self", ".", "launcher", ".", "task_execute_remote", "(", "task", ",", "config", ",", "gpu", ",", "self", ".", "ip", ",", "\"Consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", ")", "\n", "self", ".", "gpu_allocation_queue", ".", "put", "(", "gpu", ")", "\n", "\n", "self", ".", "tasks_queue", ".", "task_done", "(", ")", "\n", "print", "(", "\"Consumer done PID = \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.execute": [[144, 147], ["Exception"], "methods", ["None"], ["    ", "@", "abstractmethod", "\n", "def", "execute", "(", "self", ",", "model", ",", "dataset", ",", "opts", ",", "config", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Implement execute() in your launcher\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.initialize": [[148, 152], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "launchable", ",", "config", ")", ":", "\n", "        ", "\"\"\"For more complicated operations (of the Launcher) that require some preinitialization.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher._load_model_class": [[154, 163], ["utils.argo_utils.load_class", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class"], ["", "def", "_load_model_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "try", ":", "\n", "# try to get the module from core", "\n", "            ", "load_model_class", "=", "load_class", "(", "class_name", ",", "base_path", "=", "\"core\"", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "\"problem loading model: %s, exception: %s\"", "%", "(", "class_name", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "load_model_class", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.lock_resources": [[164, 172], ["None"], "methods", ["None"], ["", "def", "lock_resources", "(", "self", ",", "lock", ",", "dependencies", ",", "task_opts", ",", "task_config", ")", ":", "\n", "# nothing to be done, this function should be overwritten by child Launchers", "\n", "#", "\n", "# start of safe zone", "\n", "#lock.acquire()", "\n", "# end of safe zone", "\n", "#lock.release()", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.unlock_resources": [[173, 181], ["None"], "methods", ["None"], ["", "def", "unlock_resources", "(", "self", ",", "lock", ",", "dependencies", ",", "task_opts", ",", "task_config", ")", ":", "\n", "# nothing to be done, this function should be overwritten by child Launchers", "\n", "#", "\n", "# start of safe zone", "\n", "#lock.acquire()", "\n", "# end of safe zone", "\n", "#lock.release()", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.task_execute": [[182, 361], ["tf.reset_default_graph", "datasets.Dataset.Dataset.load_dataset", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "print", "numpy.random.seed", "ArgoLauncher.ArgoLauncher._load_model_class", "model_params.update", "getattr", "ArgoLauncher.ArgoLauncher.", "ArgoLauncher.get_full_id", "print", "os.path.isfile", "os.makedirs", "ArgoLauncher.write_conf_file", "ArgoLauncher.ArgoLauncher.initialize", "time.strftime", "time.time", "ArgoLauncher.ArgoLauncher.execute", "time.strftime", "time.time", "ArgoLauncher.ArgoLauncher._launchable.release", "gc.collect", "print", "print", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.close", "print", "print", "str", "print", "ArgoLauncher.ArgoLauncher.lock_resources", "print", "print", "print", "str", "print", "time.gmtime", "time.gmtime", "ArgoLauncher.ArgoLauncher.unlock_resources", "str", "str", "str", "str", "str", "str", "str", "str", "os.getpid", "os.getpid", "os.getpid", "os.getpid"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher._load_model_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.get_full_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.write_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.initialize", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialLauncher.AdversarialLauncher.execute", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.release", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.lock_resources", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.unlock_resources"], ["", "def", "task_execute", "(", "self", ",", "dm_params", ",", "config", ",", "gpu", "=", "-", "1", ",", "dependencies", "=", "None", ",", "lock", "=", "None", ",", "message_prefix", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        this method takes care of executing a task passed as a parameter\n        the task is defined in opts, while config contains other information necessary to\n        run the task, including information about loggers\n\n        Args:\n            config:\n            gpu:\n            dependencies:\n            lock:\n            message_prefix:\n\n        Returns:\n\n        \"\"\"", "\n", "\n", "# There is a reason to import tensorflow only here, but I don't remember it", "\n", "# since I am a responsible person, I provide you a link to satisfy your curiosity", "\n", "# see https://zhuanlan.zhihu.com/p/24311810", "\n", "# (oppps unfortunately it's in Chinese ;-( )", "\n", "# Since I am extremely nice (and feel guilty) I provide a translation", "\n", "#", "\n", "#It should be noted that some side effects occur when Cuda tools such as import theano", "\n", "#or import tensorflow are called, and the side effects are copied to the child processes", "\n", "#as they are and errors then occur, such as:", "\n", "#", "\n", "#     could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED", "\n", "#", "\n", "# The solution is to ensure that the parent process does not introduce these tools,", "\n", "# but after the child process is created, let the child process each introduced.", "\n", "\n", "import", "tensorflow", "as", "tf", "\n", "# I have to reset the graph here, because there might be leftover from previous jobs", "\n", "# it happens if you use tf.variable_scope(. ,reuse=None) somewhere you see the error", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "dataset_params", ",", "model_params", "=", "dm_params", "\n", "\n", "#TODO this has to be fixed when the optimization module will be created", "\n", "dataset", "=", "Dataset", ".", "load_dataset", "(", "dataset_params", ")", "\n", "\n", "# I need to copy configs here in case some algorithms are adding stuffs to the dictionaries,", "\n", "# e.g. regularizers etcetera... Since python is passed by reference they get modified before writing", "\n", "# to file resulting in unreadable confs from experiment folders. Please leave it here (Riccardo)", "\n", "model_params_orig", "=", "copy", ".", "deepcopy", "(", "model_params", ")", "\n", "dataset_params_orig", "=", "copy", ".", "deepcopy", "(", "dataset_params", ")", "\n", "config_orig", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "\n", "# this messages_prefix is used to debug purposes, in particular to distinguish the prints", "\n", "# coming from different consumers. It is a prefix added to each print", "\n", "if", "message_prefix", "!=", "\"\"", ":", "\n", "            ", "message_prefix", "+=", "\" \"", "\n", "\n", "# setting the seed for numpy for the task, which is specified in opts[\"seed\"], specified", "\n", "# set in the function create_opts_list where the Cartesian product is computed", "\n", "", "print", "(", "message_prefix", "+", "\"setting seed=\"", "+", "str", "(", "model_params", "[", "\"seed\"", "]", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "model_params", "[", "\"seed\"", "]", ")", "\n", "\n", "# create the full_id, which includes", "\n", "# ALGORITHM-NAME_DATASET-NAME-WITH-OPTIONS_ALGORITHM-OPTIONS", "\n", "# notice that this method may be overwritten by some Launchers, such as", "\n", "# TestAdvExamplesLauncher, which implements more sophisticated naming convetions for the", "\n", "# algorithm", "\n", "\n", "# get the class to load", "\n", "launchableClass", "=", "self", ".", "_load_model_class", "(", "model_params", "[", "\"model\"", "]", ")", "\n", "\n", "# add information about the dataset for the launchable construction, needed in view of future keras compatibility", "\n", "# try catch to allow compatibility for datasets which do not have labels (see Dataset interface)", "\n", "try", ":", "\n", "            ", "output_shape", "=", "dataset", ".", "y_shape", "\n", "", "except", "ValueError", ":", "\n", "            ", "output_shape", "=", "None", "\n", "\n", "", "dataset_info", "=", "{", "\"output_shape\"", ":", "output_shape", ",", "\n", "\"input_shape\"", ":", "dataset", ".", "x_shape_train", "}", "\n", "\n", "model_params", ".", "update", "(", "dataset_info", ")", "\n", "\n", "baseDir", "=", "config", "[", "\"dirName\"", "]", "+", "\"/\"", "+", "dataset", ".", "id", "\n", "\n", "# TODO why check_ops is so high in the hierarchy?", "\n", "check_ops", "=", "getattr", "(", "config", ",", "\"check_ops\"", ",", "False", ")", "\n", "\n", "self", ".", "_launchable", "=", "launchableClass", "(", "model_params", ",", "baseDir", ",", "check_ops", "=", "check_ops", ",", "gpu", "=", "gpu", ",", "seed", "=", "model_params", "[", "'seed'", "]", ")", "\n", "\n", "\n", "dirName", "=", "self", ".", "_launchable", ".", "dirName", "\n", "full_id", "=", "get_full_id", "(", "dataset", ",", "self", ".", "_launchable", ")", "\n", "\n", "print", "(", "message_prefix", "+", "\"got a new job, checking \"", "+", "full_id", ")", "\n", "\n", "# check if the algorithm has been executed previously and if successfully completed", "\n", "# this is certified by the existence of a log file in dirName", "\n", "log_file", "=", "dirName", "+", "'/experiment.log'", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "log_file", ")", ":", "\n", "\n", "# if not, I need to prepare to execute the algorithm, by first creating the necessary", "\n", "# directories, such as those to save modes and log general purpose quantities, in case", "\n", "# this is specified in the config", "\n", "\n", "# if lock is None, there is no need to lock_resouces, since there is not parallelism", "\n", "            ", "if", "lock", ":", "\n", "                ", "print", "(", "message_prefix", "+", "\"consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", "+", "\" checking locks for \"", "+", "full_id", ")", "\n", "lock_resources", "=", "self", ".", "lock_resources", "(", "lock", ",", "dependencies", ",", "model_params", ",", "config", ")", "\n", "", "else", ":", "\n", "                ", "lock_resources", "=", "True", "\n", "\n", "# in case lock_resoucers is false, then I cannot run the algorithm, thus I return false", "\n", "", "if", "not", "lock_resources", ":", "\n", "                ", "print", "(", "message_prefix", "+", "\"consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", "+", "\" lock not available \"", "+", "full_id", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "                ", "print", "(", "message_prefix", "+", "\"consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", "+", "\" available or locked \"", "+", "full_id", ")", "\n", "\n", "# create directories where the conf and txt files are saved, notice that in case of more sophisticated algorithms", "\n", "# the function can be overwritten by the child Launcher, as in TestAdvExamplesLauncher", "\n", "# dirName, launchable_id = self.create_path_directories(path)", "\n", "", "os", ".", "makedirs", "(", "dirName", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# choose between running on GPU or CPU", "\n", "if", "gpu", "==", "-", "1", ":", "\n", "                ", "print", "(", "message_prefix", "+", "\"running on cpu\"", ")", "\n", "device", "=", "'/cpu:0'", "\n", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "str", "(", "gpu", ")", "\n", "print", "(", "message_prefix", "+", "\"running on gpu = \"", "+", "str", "(", "gpu", ")", ")", "\n", "device", "=", "'/gpu:'", "+", "'0'", "\n", "\n", "# create a single conf file which allows to execute only the specific instance extracted", "\n", "# by the Cartesian product, independently from the contents of the original conf file", "\n", "", "ArgoLauncher", ".", "write_conf_file", "(", "dirName", "+", "'/experiment.conf'", ",", "\n", "dataset_params_orig", ",", "\n", "model_params_orig", ",", "\n", "config_orig", ")", "\n", "\n", "# instantiate algorithm to be run", "\n", "\n", "self", ".", "initialize", "(", "self", ".", "_launchable", ",", "config", ")", "\n", "\n", "# start timer", "\n", "start", "=", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\\n\"", ",", "gmtime", "(", ")", ")", "\n", "startTime", "=", "time", ".", "time", "(", ")", "\n", "assert", "(", "self", ".", "_launchable", "is", "not", "None", ")", ",", "\"the Launchable object has to be instantiated before executing\"", "\n", "\n", "self", ".", "execute", "(", "self", ".", "_launchable", ",", "dataset", ",", "model_params", ",", "config", ")", "\n", "\n", "# stop timer", "\n", "end", "=", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\\n\"", ",", "gmtime", "(", ")", ")", "\n", "endTime", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "_launchable", ".", "release", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "print", "(", "\"Released\"", ")", "\n", "\n", "print", "(", "message_prefix", "+", "\"consumer \"", "+", "str", "(", "os", ".", "getpid", "(", ")", ")", "+", "\" unlocking resources for \"", "+", "full_id", ")", "\n", "if", "lock", ":", "\n", "                ", "self", ".", "unlock_resources", "(", "lock", ",", "dependencies", ",", "model_params", ",", "config", ")", "\n", "\n", "\n", "", "f", "=", "open", "(", "log_file", ",", "'w'", ")", "\n", "f", ".", "write", "(", "\"started at \"", "+", "start", ")", "\n", "f", ".", "write", "(", "\"done at \"", "+", "end", ")", "\n", "f", ".", "write", "(", "\"duration \"", "+", "str", "(", "endTime", "-", "startTime", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"seed used is \"", "+", "str", "(", "model_params", "[", "\"seed\"", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"gpu \"", "+", "str", "(", "gpu", ")", "+", "\"\\n\"", ")", "\n", "\n", "f", ".", "close", "(", ")", "\n", "\n", "print", "(", "message_prefix", "+", "\"completed job \"", "+", "full_id", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "message_prefix", "+", "\"found completed job \"", "+", "full_id", ")", "\n", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_args": [[363, 384], ["len", "Exception", "cls.process_conf_file", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file"], ["", "@", "classmethod", "\n", "def", "process_args", "(", "cls", ",", "argv", ")", ":", "\n", "        ", "usage_message", "=", "\"Usage: python3 ArgoLauncher.py [paramFile.conf]\"", "\" [single|pool|distributed|stats]\"", "\n", "if", "len", "(", "argv", ")", "<", "3", ":", "\n", "            ", "raise", "Exception", "(", "usage_message", ")", "\n", "\n", "", "file_name_path", "=", "argv", "[", "1", "]", "\n", "\n", "if", "argv", "[", "2", "]", "==", "\"single\"", ":", "\n", "            ", "parallelism", "=", "0", "\n", "", "elif", "argv", "[", "2", "]", "==", "\"pool\"", ":", "\n", "            ", "parallelism", "=", "1", "\n", "", "elif", "argv", "[", "2", "]", "==", "\"distributed\"", ":", "\n", "            ", "parallelism", "=", "2", "\n", "", "elif", "argv", "[", "2", "]", "==", "\"stats\"", ":", "\n", "            ", "parallelism", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "usage_message", ")", "\n", "\n", "", "return", "cls", ".", "process_conf_file", "(", "file_name_path", ")", "+", "(", "parallelism", ",", ")", "#network, ip)", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file": [[385, 409], ["os.path.isfile", "Exception", "open", "eval", "numpy.random.seed", "numpy.random.randint().tolist", "fstream.read", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed"], ["", "@", "staticmethod", "\n", "def", "process_conf_file", "(", "file_name_path", ")", ":", "\n", "        ", "\"\"\"Read from a config file\n\n        Args:\n            file_name_path (string): path to the config file.\n\n        Returns:\n            dict: parameters for the initialization of the Dataset class\n            dict: parameters for the algorithm (in list form, not cartesian product yet)\n            dict: parameters related to the execution of the processes (machine architecture, gpus, etc..)\n\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "file_name_path", ")", ":", "\n", "            ", "raise", "Exception", "(", "'File \"'", "+", "file_name_path", "+", "\"' does not exists\\n\"", ")", "\n", "", "with", "open", "(", "file_name_path", ",", "'r'", ")", "as", "fstream", ":", "\n", "# load the three dictionaries", "\n", "            ", "dataset_params", ",", "launchable_params", ",", "config", "=", "eval", "(", "fstream", ".", "read", "(", ")", ")", "\n", "\n", "\n", "np", ".", "random", ".", "seed", "(", "config", "[", "\"seed\"", "]", ")", "\n", "config", "[", "\"seeds\"", "]", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "10000", ",", "config", "[", "\"runs\"", "]", ")", ".", "tolist", "(", ")", "\n", "\n", "", "return", "dataset_params", ",", "launchable_params", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.create_opts_list": [[412, 457], ["list", "range", "len", "range", "dict", "dict", "itertools.product", "model_params.keys", "range", "zip", "itertools.product", "zip", "itertools.product", "model_params.keys", "dataset_params.keys", "copy.deepcopy", "map", "map", "model_params.values", "dataset_params.values"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_opts_list", "(", "dataset_params", ",", "model_params", ",", "config", ")", ":", "\n", "        ", "\"\"\"\n        Check if the key run exist in model_params.\n        If not compute all possible combinations in the model_params (cartesian product of lists of parameters).\n\n        Args:\n            dataset_params (dict): parameters of the Dataset.\n            model_params (dict): Parameters for the LaunchableClass.\n            config (dict): Part of the config file related to the execution (on this one,\n                            no cartesian product will be done).\n\n        Returns:\n            list of dicts : list of launchable parameters\n            list of dicts : list of config for the main algorithm and all the sub-algorithms, if any.\n\n        \"\"\"", "\n", "\n", "model_params_list", "=", "[", "dict", "(", "zip", "(", "model_params", ".", "keys", "(", ")", ",", "p", ")", ")", "for", "p", "in", "product", "(", "*", "map", "(", "make_list", ",", "model_params", ".", "values", "(", ")", ")", ")", "]", "\n", "dataset_params_list", "=", "[", "dict", "(", "zip", "(", "dataset_params", ".", "keys", "(", ")", ",", "p", ")", ")", "for", "p", "in", "product", "(", "*", "map", "(", "make_list", ",", "dataset_params", ".", "values", "(", ")", ")", ")", "]", "\n", "\n", "dmopts", "=", "list", "(", "product", "(", "dataset_params_list", ",", "model_params_list", ")", ")", "\n", "# In case \"run\" is among the keys, this is the case in which the *.conf constains a run entry,", "\n", "# which implies the conf used is a saved conf from argo, which refers to a specific", "\n", "# run of out the runs", "\n", "if", "\"run\"", "in", "model_params", ".", "keys", "(", ")", ":", "\n", "            ", "return", "dmopts", ",", "config", "\n", "\n", "", "multiple_dmopts_list", "=", "[", "]", "\n", "for", "r", "in", "range", "(", "config", "[", "\"runs\"", "]", ")", ":", "\n", "            ", "multiple_dmopts_list", "=", "multiple_dmopts_list", "+", "[", "copy", ".", "deepcopy", "(", "l", ")", "for", "l", "in", "dmopts", "]", "\n", "\n", "", "len_list", "=", "len", "(", "dmopts", ")", "\n", "# NB: this is not the way you do things, since dictionarie share references", "\n", "# multiple_dmopts_list = model_params_list * config[\"runs\"]", "\n", "\n", "\n", "for", "r", "in", "range", "(", "config", "[", "\"runs\"", "]", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len_list", ")", ":", "\n", "                ", "index", "=", "len_list", "*", "r", "+", "i", "\n", "# I add seed and run to the model_params, leaving dataset_params untouched", "\n", "multiple_dmopts_list", "[", "index", "]", "[", "1", "]", "[", "\"seed\"", "]", "=", "config", "[", "\"seeds\"", "]", "[", "r", "]", "\n", "multiple_dmopts_list", "[", "index", "]", "[", "1", "]", "[", "\"run\"", "]", "=", "r", "\n", "\n", "", "", "return", "multiple_dmopts_list", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.write_conf_file": [[458, 469], ["open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.close", "pprint.pformat", "pprint.pformat", "pprint.pformat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "write_conf_file", "(", "outputname", ",", "dataset_params", ",", "model_params", ",", "config", ")", ":", "\n", "        ", "f", "=", "open", "(", "outputname", ",", "'w'", ")", "\n", "f", ".", "write", "(", "\"[\\n\"", ")", "\n", "f", ".", "write", "(", "pprint", ".", "pformat", "(", "dataset_params", ")", ")", "\n", "f", ".", "write", "(", "\",\\n\"", ")", "\n", "f", ".", "write", "(", "pprint", ".", "pformat", "(", "model_params", ")", ")", "\n", "f", ".", "write", "(", "\",\\n\"", ")", "\n", "f", ".", "write", "(", "pprint", ".", "pformat", "(", "config", ")", ")", "\n", "f", ".", "write", "(", "\"\\n]\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.run": [[472, 670], ["ArgoLauncher.ArgoLauncher.create_opts_list", "print", "multiprocessing.JoinableQueue", "multiprocessing.JoinableQueue", "range", "multiprocessing.Lock", "multiprocessing.Manager", "multiprocessing.Manager.dict", "range", "multiprocessing.JoinableQueue", "enumerate", "sum", "range", "len", "ArgoLauncher.ProcessTask", "ProcessDistributedTask.set_dependencies", "ProcessDistributedTask.start", "poolSizes.append", "multiprocessing.JoinableQueue", "range", "gpu_allocation_queues.append", "range", "multiprocessing.JoinableQueue.put", "multiprocessing.JoinableQueue.join", "print", "multiprocessing.JoinableQueue.put", "multiprocessing.JoinableQueue.join", "multiprocessing.JoinableQueue.put", "len", "ArgoLauncher.ProcessDistributedTask", "ProcessDistributedTask.start", "ArgoLauncher.ArgoLauncher.task_execute", "multiprocessing.JoinableQueue.put", "copy.deepcopy", "list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.create_opts_list", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ProcessTask.set_dependencies", "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.task_execute"], ["", "def", "run", "(", "self", ",", "dataset_params", ",", "model_params", ",", "config", ",", "parallelism", ")", ":", "\n", "        ", "\"\"\"\n        this is the main method called to start the execution\n        consider this the entry point to understand the code\n\n        1) The launcher creates a queue of tasks which depends on the conf file\n        2) The launcher creates a pool of consumers. A consumer is a Process\n            whose role is to take a task from the list and execute it if\n            necessary. Each consumer work on a GPU. Multiple consumers can work\n            on the same GPU if cores_per_GPU > 1\n\n\n        Args:\n            dataset: the dataset used in the experiments, notice that is\n                required only to run the experiment, but not to create the\n                ArgoLauncher object, that's why it does not appear in the\n                constructor of ArgoLauncher\n            model_params: (dict)\n            config: (dict)\n            parallelism: (0,1,2)\n                parallelism = 0, a single process is run on the first GPU from\n                (single)         the list of used_GPUs in the conf file for\n                                 nodes[0], the process is run on localhost\n                                 (independently from nodes[0][\"IP\"])\n                parallelism = 1, a pool of consumers (i.e., processes) is created, of size equal to\n                (pool)           len(used_GPUs)*cores_per_GPU, all processes are run on localhost\n                                 (independently from nodes[0][\"ID\"])\n                parallelism = 2  a pool of processes is created on localhost, with consumers associated\n                (distributed)    to each node in the list \"nodes\" from the conf file, the size of the pool\n                                 equal the sum over the nodes i, of len(used_GPUs of node i)*cores_per_GPU\n                                 of node i. All nodes are supposed to write in the same folder, which must\n                                 be accessible from localhost. Refer to the code in ProcessDistributedTask,\n                                 for details about how the communication between the node is implemented\n                                 (hint: basically no communication is required, nodes are just slaves)\n\n\n        \"\"\"", "\n", "\n", "# default size of the pool of consumers", "\n", "poolSize", "=", "1", "\n", "\n", "# if parallelism is 1, then I need to create a pool of processes to execute the tasks", "\n", "if", "parallelism", "==", "1", ":", "\n", "\n", "# I need to manage two queues, of for the tasks to be executed,", "\n", "# and one for the available GPUs, this is due to the fact that each consumer has to pick", "\n", "# up an available GPU where the task is run", "\n", "\n", "# TODO", "\n", "# I THINK THIS IS WRONG", "\n", "# In principle (most likely) the queue of GPUs is not required and we could initialize the", "\n", "# consumer with a redefined GPU", "\n", "\n", "# queue for the tasks, which is empty at the moment", "\n", "            ", "tasks_queue", "=", "multiprocessing", ".", "JoinableQueue", "(", ")", "\n", "# queue for the GPU to be allocated", "\n", "gpu_allocation_queue", "=", "multiprocessing", ".", "JoinableQueue", "(", ")", "\n", "\n", "# compute new pool size", "\n", "poolSize", "=", "len", "(", "config", "[", "\"nodes\"", "]", "[", "0", "]", "[", "\"used_GPUs\"", "]", ")", "*", "config", "[", "\"nodes\"", "]", "[", "0", "]", "[", "\"cores_per_GPU\"", "]", "\n", "\n", "# add to the pool the available GPUs", "\n", "for", "i", "in", "range", "(", "config", "[", "\"nodes\"", "]", "[", "0", "]", "[", "\"cores_per_GPU\"", "]", ")", ":", "\n", "                ", "for", "j", "in", "config", "[", "\"nodes\"", "]", "[", "0", "]", "[", "\"used_GPUs\"", "]", ":", "\n", "                    ", "gpu_allocation_queue", ".", "put", "(", "j", ")", "\n", "\n", "# here I create a lock used by the ProcessTask to access a dictionary of dependences of each algorithm,", "\n", "# which is used to avoid that multiple algorithm running in parallel could train the same dependence in case", "\n", "# it has not been trained before. This is the for instance the behavior of TestAdvExamplesLauncher.", "\n", "", "", "lock", "=", "multiprocessing", ".", "Lock", "(", ")", "\n", "manager", "=", "multiprocessing", ".", "Manager", "(", ")", "\n", "dependencies", "=", "manager", ".", "dict", "(", ")", "\n", "\n", "# here I create the pool of executors, of size poolSize", "\n", "for", "k", "in", "range", "(", "poolSize", ")", ":", "\n", "# it is ok to pass self to the processtask, since the message passing protocol use pickle (I guess) else use launcher=deepcopy(self)", "\n", "#TODO-ARGO2: why the launcher itself does not specify the multiprocessing interface?", "\n", "\n", "                ", "launcher", "=", "self", "\n", "# the consumer, which is of type ProcessTask, takes the two queues, and a newly", "\n", "# created launcher object. See comments in ProcessTask for more details", "\n", "t", "=", "ProcessTask", "(", "tasks_queue", ",", "gpu_allocation_queue", ",", "launcher", ")", "#,return_queue", "\n", "t", ".", "set_dependencies", "(", "dependencies", ",", "lock", ")", "\n", "# start the consumers, which are now waiting for tasks to appear in the task queue.", "\n", "# Notice that at the moment tasks_queue is empty", "\n", "t", ".", "start", "(", ")", "\n", "\n", "# If parallelism is 2, then I need to create multiple queues for GPUs, one per each node", "\n", "# from \"nodes\" in the conf file. Notice that the tasks_queue is unique", "\n", "", "", "if", "parallelism", "==", "2", ":", "\n", "            ", "tasks_queue", "=", "multiprocessing", ".", "JoinableQueue", "(", ")", "\n", "gpu_allocation_queue", "=", "[", "]", "\n", "\n", "poolSizes", "=", "[", "]", "\n", "gpu_allocation_queues", "=", "[", "]", "\n", "\n", "for", "node", "in", "config", "[", "\"nodes\"", "]", ":", "\n", "                ", "p", "=", "len", "(", "node", "[", "\"used_GPUs\"", "]", ")", "*", "node", "[", "\"cores_per_GPU\"", "]", "\n", "poolSizes", ".", "append", "(", "p", ")", "\n", "\n", "q", "=", "multiprocessing", ".", "JoinableQueue", "(", ")", "\n", "for", "i", "in", "range", "(", "node", "[", "\"cores_per_GPU\"", "]", ")", ":", "\n", "                    ", "for", "j", "in", "node", "[", "\"used_GPUs\"", "]", ":", "\n", "                        ", "q", ".", "put", "(", "j", ")", "\n", "", "", "gpu_allocation_queues", ".", "append", "(", "q", ")", "\n", "\n", "", "for", "i", ",", "node", "in", "enumerate", "(", "config", "[", "\"nodes\"", "]", ")", ":", "\n", "                ", "for", "t", "in", "range", "(", "poolSizes", "[", "i", "]", ")", ":", "\n", "# launcher = self.__class__(self.launchableClass, dataset)", "\n", "\n", "                    ", "launcher", "=", "self", "\n", "\n", "t", "=", "ProcessDistributedTask", "(", "tasks_queue", ",", "gpu_allocation_queues", "[", "i", "]", ",", "launcher", ",", "i", ",", "node", "[", "\"IP\"", "]", ")", "#,return_queue", "\n", "t", ".", "start", "(", ")", "\n", "\n", "# this is to count how many poison pills I will need", "\n", "", "", "poolSize", "=", "sum", "(", "poolSizes", ")", "\n", "\n", "# Now that consumers have been creates, I take care of the tasks, by adding them tasks_queue,", "\n", "# so taht the consumer can start to do their job", "\n", "\n", "# By calling create_opts_list, I create the list of tasks by computing the Cartesian product", "\n", "# between the lists of the entries in the model_params dictionary", "\n", "\n", "# Notice that this function can be overwritten by a child Launcher, in case the algorithm", "\n", "# needs other algorithm to work. In this case in the conf file, model_params has a reference to", "\n", "# other conf files, and thus each element in the opts_list could be a tuple and not a", "\n", "# single element. Refer to TestAdvExamplesLauncher for an example of such behavior.", "\n", "# The returned_config in this case becomes a tuple of config files, which includes the config", "\n", "# of the algorithms used by the main algorithm to which model_params and config refer.", "\n", "", "dmopts_list", ",", "returned_config", "=", "self", ".", "create_opts_list", "(", "dataset_params", ",", "model_params", ",", "config", ")", "\n", "\n", "# for each task in the list, either add it to the tasks_queue, or excecuted it now if", "\n", "# parallism is 0", "\n", "for", "task", "in", "dmopts_list", ":", "\n", "# if I am running with queues, I add the task to the unique tasks_queue (for both pool", "\n", "# or distributed)", "\n", "            ", "if", "parallelism", "==", "1", "or", "parallelism", "==", "2", ":", "\n", "# notice that if I don't copy the task (which is a dictionary) the iterator changes", "\n", "# the task at each iteration, and this had consequences in changing also the tasks", "\n", "# already added in the queue. This is because everything is a reference in Python", "\n", "                ", "tasks_queue", ".", "put", "(", "(", "copy", ".", "deepcopy", "(", "task", ")", ",", "returned_config", ")", ")", "\n", "# otherwise I execute directly the task with no Processes", "\n", "", "elif", "parallelism", "==", "0", ":", "\n", "# #TODO-ARGO2 self.__class__(...) this is very bad practice... :( can it be avoided?", "\n", "# # notice that also here I create a new object of type self", "\n", "# launcher = self.__class__(self.launchableClass, dataset)", "\n", "                ", "launcher", "=", "self", "\n", "# notice that I choose the first available GPU from nodes[0]", "\n", "launcher", ".", "task_execute", "(", "task", ",", "returned_config", ",", "gpu", "=", "list", "(", "config", "[", "\"nodes\"", "]", "[", "0", "]", "[", "\"used_GPUs\"", "]", ")", "[", "0", "]", ")", "\n", "\n", "# now, there is one last task for each comsumer to be done", "\n", "# all of them they have done their job, and they are disposable, so we can give them", "\n", "# \"the pill\". They will know what to do.. (harakiri)", "\n", "", "", "if", "parallelism", "==", "1", "or", "parallelism", "==", "2", ":", "\n", "# here we need to wait for the queue to be empty, becausa tasks may be queued as they are", "\n", "# processed", "\n", "            ", "for", "task", "in", "dmopts_list", ":", "\n", "                ", "tasks_queue", ".", "join", "(", ")", "\n", "print", "(", "\"Task done\"", ")", "\n", "\n", "# at his point, all task have been completed, thus I can kill the processes", "\n", "\n", "# poison pill for each consumer", "\n", "", "for", "i", "in", "range", "(", "poolSize", ")", ":", "\n", "                ", "tasks_queue", ".", "put", "(", "None", ")", "\n", "# I wait for somebody to execute the order", "\n", "# Notice that I don't know will do it first, what I need is to join a number of times", "\n", "# equal to poolSize", "\n", "tasks_queue", ".", "join", "(", ")", "\n", "\n", "", "", "print", "(", "\"Everything is done\"", ")", "\n", "\n", "'''\n        # kill all threads in each queue, since I have a queue for each computing node\n        if parallelism==2:\n            # poison pill for each consumer\n            for i, node in enumerate(config[\"nodes\"]):\n                for i in range(poolSizes[i]):\n                    tasks_queue.put(None)\n                    tasks_queue.join()\n        '''", "\n", "\n", "'''\n        elif network==1:\n            # server\n\n            # create server architecture\n\n            # lanch clients on ssh\n            for ip in config[\"nodes\"]:\n                prin\n\n        elif network==2:\n            # client\n        else:\n            raise Exception(\"Network option not recognized\")\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.get_full_id": [[21, 26], ["None"], "function", ["None"], ["def", "get_full_id", "(", "dataset", ",", "launchable", ")", ":", "\n", "    ", "\"\"\" This is the full id of an experiment. As a convention, the dataset is specifying a folder and\n    the launchable object is specifying the name of the model used for training.\n    \"\"\"", "\n", "return", "dataset", ".", "id", "+", "'/'", "+", "launchable", ".", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsBySTP.get_field": [[68, 85], ["len", "re.search", "re.search", "ValueError", "re.search.group", "re.search.group"], "function", ["None"], ["def", "get_field", "(", "string", ",", "field_spec", ")", ":", "\n", "    ", "l", "=", "len", "(", "field_spec", ")", "\n", "if", "l", "==", "0", "or", "l", ">", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not implemented tuple length `{:}`, found field spec `{:}`\"", ".", "format", "(", "l", ",", "field_spec", ")", ")", "\n", "", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "field_spec", "[", "0", "]", "+", "'([\\._A-Za-z0-9\\,]+)'", "+", "'(-|$)'", ",", "string", ")", "\n", "if", "m", "is", "None", ":", "\n", "        ", "ss1", "=", "'0'", "\n", "", "else", ":", "\n", "        ", "ss1", "=", "m", ".", "group", "(", "2", ")", "\n", "", "if", "l", "==", "1", ":", "\n", "        ", "return", "ss1", "\n", "", "m", "=", "re", ".", "search", "(", "'(_|^)'", "+", "field_spec", "[", "1", "]", "+", "'([\\.A-Za-z0-9\\,]+)'", "+", "'(_|$)'", ",", "ss1", ")", "\n", "if", "m", "is", "None", ":", "\n", "        ", "ss2", "=", "'0'", "\n", "", "else", ":", "\n", "        ", "ss2", "=", "m", ".", "group", "(", "2", ")", "\n", "", "return", "ss2", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsBySTP.plot_grouped_curves": [[86, 103], ["matplotlib.legend", "df.groupby", "matplotlib.errorbar", "matplotlib.plot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "plot_grouped_curves", "(", "df", ",", "x", ",", "y", ",", "groupfield", ",", "pre_label", ")", ":", "\n", "    ", "garr", "=", "[", "(", "label", ",", "df", ")", "for", "label", ",", "df", "in", "df", ".", "groupby", "(", "groupfield", ")", "]", "\n", "for", "groupval", ",", "df", "in", "garr", ":", "\n", "        ", "plabel", "=", "pre_label", "+", "'-'", "+", "groupfield", "+", "\"{:}\"", ".", "format", "(", "groupval", ")", "\n", "xdata", "=", "df", "[", "x", "]", "\n", "pkwargs", "=", "{", "\n", "'alpha'", ":", "ALPHA", ",", "\n", "'label'", ":", "plabel", "\n", "}", "\n", "if", "y", "+", "'_avg'", "in", "df", ".", "columns", "and", "y", "+", "'_std'", "in", "df", ".", "columns", ":", "\n", "            ", "ydata", "=", "df", "[", "y", "+", "'_avg'", "]", "\n", "yerr", "=", "df", "[", "y", "+", "'_std'", "]", "\n", "plt", ".", "errorbar", "(", "xdata", ",", "ydata", ",", "yerr", "=", "yerr", ",", "**", "pkwargs", ")", "\n", "", "else", ":", "\n", "            ", "ydata", "=", "df", "[", "y", "]", "\n", "plt", ".", "plot", "(", "xdata", ",", "ydata", ",", "**", "pkwargs", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsBySTP.make_ds_plot": [[104, 136], ["matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "ds_dir.split", "list", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "pandas.DataFrame", "os.path.join", "set", "len", "sorted", "plotStatsBySTP.plot_grouped_curves", "str", "glob.glob", "plotStatsBySTP.get_field", "plotStatsBySTP.get_field", "pandas.read_csv", "os.path.join", "os.path.splitext", "match.split", "numpy.isclose", "df.append.append", "match.split", "[].split", "float", "match.split", "match.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsByEps.plot_grouped_curves", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field"], ["", "", "def", "make_ds_plot", "(", "ds_dir", ",", "csv_dirs_dict", ",", "y", ",", "eps", ",", "plot_dir", ")", ":", "\n", "    ", "x", "=", "'stp'", "\n", "nice_ds_name", "=", "ds_dir", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "for", "net_dir", ",", "transf_dir", "in", "csv_dirs_dict", "[", "ds_dir", "]", ":", "\n", "        ", "stats_csv", "=", "'statistics/stats-test-eps'", "+", "str", "(", "eps", ")", "+", "'.csv'", "\n", "dir_list", "=", "[", "base_csv_dir", ",", "ds_dir", ",", "net_dir", ",", "transf_dir", ",", "attack_dir", ",", "stats_csv", "]", "\n", "matches", "=", "list", "(", "set", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", ")", ")", "\n", "groupfield", "=", "'d'", "\n", "plt", ".", "title", "(", "nice_ds_name", "+", "' eps={:}'", ".", "format", "(", "eps", ")", ")", "\n", "plt", ".", "xlabel", "(", "x", ")", "\n", "plt", ".", "ylabel", "(", "nice_yaxis_names", "[", "y", "]", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "{", "'ph'", ":", "[", "]", "}", ")", "\n", "recv", "=", "''", "\n", "if", "len", "(", "matches", ")", ">", "0", ":", "\n", "            ", "for", "match", "in", "sorted", "(", "matches", ")", ":", "\n", "                ", "transf_string", "=", "os", ".", "path", ".", "splitext", "(", "match", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ")", "[", "0", "]", "\n", "recv", "=", "get_field", "(", "match", ".", "split", "(", "'/'", ")", "[", "-", "4", "]", ",", "(", "'rec'", ",", ")", ")", "\n", "dsv", "=", "match", ".", "split", "(", "'/'", ")", "[", "-", "6", "]", "\n", "epsv", "=", "get_field", "(", "match", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.csv'", ")", "[", "0", "]", ",", "(", "'eps'", ",", ")", ")", "\n", "if", "not", "np", ".", "isclose", "(", "eps", ",", "float", "(", "epsv", ")", ")", ":", "\n", "                    ", "continue", "\n", "", "match_df", "=", "pd", ".", "read_csv", "(", "match", ",", "sep", "=", "' '", ")", "\n", "if", "df", ".", "empty", ":", "\n", "                    ", "df", "=", "match_df", "\n", "", "else", ":", "\n", "                    ", "df", "=", "df", ".", "append", "(", "match_df", ".", "iloc", "[", "0", "]", ")", "\n", "", "", "plot_grouped_curves", "(", "df", ",", "x", ",", "y", ",", "groupfield", ",", "recv", ")", "\n", "\n", "", "", "fields", "=", "[", "nice_ds_name", ",", "x", ",", "y", ",", "'eps{:.2f}'", ".", "format", "(", "eps", ")", "]", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "plot_dir", ",", "'-'", ".", "join", "(", "fields", ")", "+", "'.png'", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotAllComparisonsCurves.latex_friendly": [[14, 18], ["str"], "function", ["None"], ["def", "latex_friendly", "(", "x", ")", ":", "\n", "    ", "char_x", "=", "str", "(", "x", ")", "\n", "new_char_x", "=", "char_x", "[", "0", "]", "+", "'-'", "+", "char_x", "[", "2", ":", "]", "\n", "return", "new_char_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DeepLearningModel.DeepLearningModel.__init__": [[10, 12], ["Launchable.Launchable.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "seed", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DeepLearningModel.DeepLearningModel.train": [[13, 16], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "train", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DeepLearningModel.DeepLearningModel.save": [[21, 24], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "save", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DeepLearningModel.DeepLearningModel.restore": [[25, 28], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "restore", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ImagesGenerateHook.ImagesGenerateHook.__init__": [[22, 39], ["Hooks.EveryNEpochsTFModelImagesHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "n_gen_samples", ",", "\n", "#n_images_rows,", "\n", "n_images_columns", ",", "\n", "dirName", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "+", "'/generated_images'", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dirName", "=", "self", ".", "_dirName", ")", "\n", "\n", "self", ".", "_n_images_columns", "=", "n_images_columns", "\n", "self", ".", "_n_gen_samples", "=", "n_gen_samples", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create ImagesGenerateHook for %d samples\"", "%", "self", ".", "_n_gen_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ImagesGenerateHook.ImagesGenerateHook.do_when_triggered": [[41, 66], ["tf_logging.info", "pdb.set_trace", "ImagesGenerateHook.ImagesGenerateHook._model.generate", "ImagesSaver.ImagesSaver.ImagesSaver", "int", "range", "ImagesSaver.ImagesSaver.ImagesSaver.save_images", "numpy.ceil", "range", "range", "panel[].append", "len", "str().zfill", "len", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.generate", "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["", "def", "do_when_triggered", "(", "self", ",", "global_step", ",", "time_ref", ",", "run_context", ",", "run_values", ",", "time_ref_str", "=", "\"ep\"", ")", ":", "\n", "#tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for ImagesGenerateHook\"", ")", "\n", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "images", "=", "self", ".", "_model", ".", "generate", "(", "batch_size", "=", "self", ".", "_n_gen_samples", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "\n", "images_saver", "=", "ImagesSaver", "(", "self", ".", "_dirName", ")", "\n", "\n", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "\n", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", ")", "]", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                ", "panel", "[", "i", "]", ".", "append", "(", "images", "[", "c", "]", ")", "\n", "if", "c", "==", "len", "(", "images", ")", "-", "1", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "c", "=", "c", "+", "1", "\n", "\n", "", "", "", "images_saver", ".", "save_images", "(", "panel", ",", "\n", "fileName", "=", "\"generated_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", ",", "\n", "title", "=", "self", ".", "_fileName", ",", "\n", "fontsize", "=", "9", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.OptimizationModel.OptimizationModel.__init__": [[8, 10], ["Model.Model.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "seed", "=", "0", ")", ":", "\n", "        ", "Model", ".", "__init__", "(", "self", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.OptimizationModel.OptimizationModel.optimize": [[11, 14], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function": [[11, 37], ["utils.argo_utils.eval_method_from_tuple", "importlib.import_module", "Exception", "importlib.import_module", "__name__.split", "importlib.import_module", "__name__.split", "__name__.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["    ", "@", "staticmethod", "\n", "def", "instantiate_cost_function", "(", "cost_function_tuple", ",", "module_path", "=", "\"\"", ")", ":", "\n", "\n", "        ", "cost_function_name", "=", "cost_function_tuple", "[", "0", "]", "\n", "cost_function_kwargs", "=", "cost_function_tuple", "[", "1", "]", "\n", "\n", "try", ":", "\n", "\n", "# first try to load from core", "\n", "            ", "try", ":", "\n", "                ", "cost_function_module", "=", "importlib", ".", "import_module", "(", "\"core.\"", "+", "cost_function_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "# it if fails, try to laod from module_path.core", "\n", "", "except", "ImportError", ":", "\n", "                ", "try", ":", "\n", "                    ", "cost_function_module", "=", "importlib", ".", "import_module", "(", "\"core.cost.\"", "+", "cost_function_name", ",", "\n", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "", "except", "ImportError", ":", "\n", "                    ", "cost_function_module", "=", "importlib", ".", "import_module", "(", "module_path", "+", "\".core.\"", "+", "cost_function_name", ",", "\n", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "", "", "cost_function", "=", "eval_method_from_tuple", "(", "cost_function_module", ",", "cost_function_tuple", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "\"problem with module: %s, kwargs: %s, exception %s\"", "%", "(", "cost_function_name", ",", "cost_function_kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "cost_function", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DirectedGraph.DirectedGraph.__init__": [[10, 64], ["argo.core.utils.argo_utils.load_method_from_tuple", "argo.core.utils.argo_utils.load_method_from_tuple", "getattr", "argo.core.utils.argo_utils.load_method_from_tuple", "argo.core.utils.argo_utils.load_method_from_tuple", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opts", ")", ":", "\n", "#GET DEFAULTS FOR LAYERS CREATION", "\n", "#initializers", "\n", "        ", "default_weights_init", "=", "load_method_from_tuple", "(", "tf", ",", "opts", "[", "\"weights_init\"", "]", ")", "\n", "default_bias_init", "=", "load_method_from_tuple", "(", "tf", ",", "opts", "[", "\"bias_init\"", "]", ")", "\n", "\n", "#activation function", "\n", "default_activation_fct", "=", "getattr", "(", "tf", ".", "nn", ",", "opts", "[", "\"activation\"", "]", ")", "\n", "\n", "#regularizers", "\n", "default_weights_reg", "=", "load_method_from_tuple", "(", "tf", ",", "opts", "[", "\"weights_reg\"", "]", ")", "\n", "default_bias_reg", "=", "load_method_from_tuple", "(", "tf", ",", "opts", "[", "\"bias_reg\"", "]", ")", "\n", "\n", "# these are default parameters, \"potentially\" they could be overwritten", "\n", "# by possible properties in the specific layers in \"network_archicture\"", "\n", "\n", "self", ".", "_default_layers_kwargs", "=", "{", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'flatten'", "]", "=", "{", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'dense'", "]", "=", "{", "\n", "\"activation\"", ":", "default_activation_fct", ",", "\n", "\"kernel_initializer\"", ":", "default_weights_init", ",", "\n", "\"bias_initializer\"", ":", "default_bias_init", ",", "\n", "\"kernel_regularizer\"", ":", "default_weights_reg", ",", "\n", "\"bias_regularizer\"", ":", "default_bias_reg", ",", "\n", "\"activity_regularizer\"", ":", "None", ",", "\n", "\"kernel_constraint\"", ":", "None", ",", "\n", "\"bias_constraint\"", ":", "None", "\n", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'conv2d'", "]", "=", "{", "\n", "**", "self", ".", "_default_layers_kwargs", "[", "'dense'", "]", ",", "\n", "# filters,", "\n", "# kernel_size,", "\n", "\"strides\"", ":", "(", "1", ",", "1", ")", ",", "\n", "\"padding\"", ":", "'valid'", "\n", "# \"data_format\" : 'channels_last',", "\n", "# \"dilation_rate\" : (1, 1)", "\n", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'max_pooling2d'", "]", "=", "{", "\n", "\"pool_size\"", ":", "(", "2", ",", "2", ")", ",", "\n", "\"strides\"", ":", "2", "\n", "}", "\n", "\n", "first_net_option", "=", "opts", "[", "\"network_architecture\"", "]", "[", "0", "]", "\n", "if", "isinstance", "(", "first_net_option", ",", "str", ")", ":", "\n", "            ", "self", ".", "_network_architecture", "=", "opts", "[", "\"network_architecture\"", "]", "[", "1", ":", "]", "\n", "self", ".", "_network_name", "=", "first_net_option", "\n", "", "else", ":", "\n", "# parameters which define the network topology", "\n", "            ", "self", ".", "_network_architecture", "=", "opts", "[", "\"network_architecture\"", "]", "\n", "self", ".", "_network_name", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DirectedGraph.DirectedGraph.create_logits": [[66, 96], ["enumerate", "tf.get_default_graph().get_collection", "getattr", "getattr.", "tf.get_default_graph", "str"], "methods", ["None"], ["", "", "def", "create_logits", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Create the logits nodes of the network.\n\n        Sets:\n            to the created corresponding tf variables\n\n        Args:\n            x (tf.placeholder): input node.\n            weights (list of np.array): weights of the network.\n            biases (list of np.array): biases of the network.\n\n        Returns:\n            tf.node: logits node.\n\n        \"\"\"", "\n", "\n", "net", "=", "x", "\n", "\n", "for", "i", ",", "layer_tuple", "in", "enumerate", "(", "self", ".", "_network_architecture", ")", ":", "\n", "            ", "layer_name", ",", "layer_kwargs", "=", "layer_tuple", "\n", "layer_fn", "=", "getattr", "(", "tf", ".", "layers", ",", "layer_name", ")", "\n", "tot_kwargs", "=", "{", "\n", "**", "self", ".", "_default_layers_kwargs", "[", "layer_name", "]", ",", "\n", "**", "layer_kwargs", ",", "\n", "\"name\"", ":", "\"layer\"", "+", "str", "(", "i", ")", "+", "\"-\"", "+", "layer_name", "\n", "}", "\n", "net", "=", "layer_fn", "(", "net", ",", "**", "tot_kwargs", ")", "\n", "\n", "", "self", ".", "variables", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_collection", "(", "'variables'", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DirectedGraph.DirectedGraph.algorithm_topology_id": [[97, 123], ["isinstance", "argo.core.utils.argo_utils.get_method_id", "argo.core.utils.argo_utils.get_method_id", "argo.core.utils.argo_utils.get_method_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id"], ["", "@", "classmethod", "\n", "def", "algorithm_topology_id", "(", "cls", ",", "opts", ")", ":", "\n", "        ", "\"\"\"\n        generator of part of the id related to the topology of the network\n        Args:\n            opts:\n\n        Returns:\n\n        \"\"\"", "\n", "\n", "\n", "first_net_option", "=", "opts", "[", "\"network_architecture\"", "]", "[", "0", "]", "\n", "topology_id", "=", "\"-\"", "\n", "if", "isinstance", "(", "first_net_option", ",", "str", ")", ":", "\n", "            ", "topology_id", "+=", "first_net_option", "\n", "", "else", ":", "\n", "            ", "topology_id", "+=", "'_'", ".", "join", "(", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "opts", "[", "\"network_architecture\"", "]", "\n", "if", "layer_tuple", "[", "0", "]", "is", "not", "'flatten'", ")", "\n", "\n", "", "topology_id", "+=", "'-wi'", "+", "get_method_id", "(", "opts", "[", "\"weights_init\"", "]", ")", "+", "'-bi'", "+", "get_method_id", "(", "opts", "[", "\"bias_init\"", "]", ")", "+", "'-a'", "+", "opts", "[", "\"activation\"", "]", "\n", "\n", "return", "topology_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DirectedGraph.DirectedGraph.default_activation_function": [[124, 127], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "default_activation_function", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "activation_fct", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.DirectedGraph.DirectedGraph.number_layers": [[128, 131], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "number_layers", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_network_architecture", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Regularizers.Regularizers.instantiate_regularizer": [[11, 31], ["importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "Exception", "__name__.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["    ", "@", "staticmethod", "\n", "def", "instantiate_regularizer", "(", "regularizer_tuple", ",", "module_path", "=", "\"\"", ")", ":", "\n", "\n", "        ", "regularizer_name", "=", "regularizer_tuple", "[", "0", "]", "\n", "regularizer_kwargs", "=", "regularizer_tuple", "[", "1", "]", "\n", "\n", "try", ":", "\n", "# first try to load from core", "\n", "#try:", "\n", "            ", "regularizer_module", "=", "importlib", ".", "import_module", "(", "\".regularizers.\"", "+", "regularizer_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "3", "]", ")", ")", "\n", "# it if fails, try to laod from module_path.core", "\n", "#except ImportError:", "\n", "#    regularizer_module = importlib.import_module(module_path + \".core.\" + regularizer_name, '.'.join(__name__.split('.')[:-1]))", "\n", "\n", "custom_regularizer", ",", "_", ",", "_", "=", "eval_method_from_tuple", "(", "regularizer_module", ",", "regularizer_tuple", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "\"problem with module: %s, kwargs: %s, exception %s\"", "%", "(", "regularizer_name", ",", "regularizer_kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "custom_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotAllComparisonsCurvesBySm.latex_friendly": [[14, 18], ["str"], "function", ["None"], ["def", "latex_friendly", "(", "x", ")", ":", "\n", "    ", "char_x", "=", "str", "(", "x", ")", "\n", "new_char_x", "=", "char_x", "[", "0", "]", "+", "'-'", "+", "char_x", "[", "2", "]", "\n", "return", "new_char_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TrainingLauncher.TrainingLauncher.execute": [[7, 17], ["model.init", "model.create_session", "model.train"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.init", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_session", "home.repos.pwc.inspect_result.rist-ro_argo.core.DeepLearningModel.DeepLearningModel.train"], ["    ", "def", "execute", "(", "self", ",", "model", ",", "dataset", ",", "opts", ",", "config", ")", ":", "\n", "        ", "model", ".", "init", "(", "dataset", ")", "\n", "\n", "model", ".", "create_session", "(", "opts", ",", "config", ")", "\n", "\n", "# import numpy as np", "\n", "# sess = model.get_raw_session()", "\n", "# raw_x_np, x_np = sess.run([model.raw_x, model.x], feed_dict={model.ds_handle: model.datasets_handles[\"train_loop\"], model.is_training:True})", "\n", "\n", "model", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsByEps.get_field": [[65, 82], ["len", "re.search", "re.search", "ValueError", "re.search.group", "re.search.group"], "function", ["None"], ["def", "get_field", "(", "string", ",", "field_spec", ")", ":", "\n", "    ", "l", "=", "len", "(", "field_spec", ")", "\n", "if", "l", "==", "0", "or", "l", ">", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not implemented tuple length `{:}`, found field spec `{:}`\"", ".", "format", "(", "l", ",", "field_spec", ")", ")", "\n", "", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "field_spec", "[", "0", "]", "+", "'([\\._A-Za-z0-9\\,]+)'", "+", "'(-|$)'", ",", "string", ")", "\n", "if", "m", "is", "None", ":", "\n", "        ", "ss1", "=", "'0'", "\n", "", "else", ":", "\n", "        ", "ss1", "=", "m", ".", "group", "(", "2", ")", "\n", "", "if", "l", "==", "1", ":", "\n", "        ", "return", "ss1", "\n", "", "m", "=", "re", ".", "search", "(", "'(_|^)'", "+", "field_spec", "[", "1", "]", "+", "'([\\.A-Za-z0-9\\,]+)'", "+", "'(_|$)'", ",", "ss1", ")", "\n", "if", "m", "is", "None", ":", "\n", "        ", "ss2", "=", "'0'", "\n", "", "else", ":", "\n", "        ", "ss2", "=", "m", ".", "group", "(", "2", ")", "\n", "", "return", "ss2", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsByEps.plot_grouped_curves": [[83, 100], ["matplotlib.legend", "df.groupby", "matplotlib.errorbar", "matplotlib.plot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "plot_grouped_curves", "(", "df", ",", "x", ",", "y", ",", "groupfield", ",", "pre_label", ")", ":", "\n", "    ", "garr", "=", "[", "(", "label", ",", "df", ")", "for", "label", ",", "df", "in", "df", ".", "groupby", "(", "groupfield", ")", "]", "\n", "for", "groupval", ",", "df", "in", "garr", ":", "\n", "        ", "plabel", "=", "pre_label", "+", "'-'", "+", "groupfield", "+", "\"{:}\"", ".", "format", "(", "groupval", ")", "\n", "xdata", "=", "df", "[", "x", "]", "\n", "pkwargs", "=", "{", "\n", "'alpha'", ":", "ALPHA", ",", "\n", "'label'", ":", "plabel", "\n", "}", "\n", "if", "y", "+", "'_avg'", "in", "df", ".", "columns", "and", "y", "+", "'_std'", "in", "df", ".", "columns", ":", "\n", "            ", "ydata", "=", "df", "[", "y", "+", "'_avg'", "]", "\n", "yerr", "=", "df", "[", "y", "+", "'_std'", "]", "\n", "plt", ".", "errorbar", "(", "xdata", ",", "ydata", ",", "yerr", "=", "yerr", ",", "**", "pkwargs", ")", "\n", "", "else", ":", "\n", "            ", "ydata", "=", "df", "[", "y", "]", "\n", "plt", ".", "plot", "(", "xdata", ",", "ydata", ",", "**", "pkwargs", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsByEps.make_ds_plot": [[101, 124], ["matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "ds_dir.split", "list", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "pandas.DataFrame", "os.path.join", "set", "len", "sorted", "glob.glob", "plotStatsByEps.get_field", "pandas.read_csv", "plotStatsByEps.plot_grouped_curves", "os.path.join", "match.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotStatsByEps.plot_grouped_curves"], ["", "", "def", "make_ds_plot", "(", "ds_dir", ",", "csv_dirs_dict", ",", "y", ",", "stp", ",", "plot_dir", ")", ":", "\n", "    ", "x", "=", "'eps'", "\n", "nice_ds_name", "=", "ds_dir", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "for", "net_dir", ",", "transf_dir", "in", "csv_dirs_dict", ":", "\n", "        ", "stats_csv", "=", "'statistics/stats-test.csv'", "\n", "dir_list", "=", "[", "base_csv_dir", ",", "ds_dir", ",", "net_dir", ",", "transf_dir", ",", "attack_dir", ",", "stats_csv", "]", "\n", "matches", "=", "list", "(", "set", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", ")", ")", "\n", "groupfield", "=", "'scale'", "\n", "plt", ".", "title", "(", "nice_ds_name", "+", "' stp={:}'", ".", "format", "(", "stp", ")", ")", "\n", "plt", ".", "xlabel", "(", "x", ")", "\n", "plt", ".", "ylabel", "(", "nice_yaxis_names", "[", "y", "]", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "{", "'ph'", ":", "[", "]", "}", ")", "\n", "recv", "=", "''", "\n", "if", "len", "(", "matches", ")", ">", "0", ":", "\n", "            ", "for", "match", "in", "sorted", "(", "matches", ")", ":", "\n", "                ", "recv", "=", "get_field", "(", "match", ".", "split", "(", "'/'", ")", "[", "-", "4", "]", ",", "(", "'rec'", ",", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "match", ",", "sep", "=", "' '", ")", "\n", "plot_grouped_curves", "(", "df", ",", "x", ",", "y", ",", "groupfield", ",", "recv", ")", "\n", "\n", "", "", "", "fields", "=", "[", "nice_ds_name", ",", "x", ",", "y", ",", "'eps{:.2f}'", ".", "format", "(", "stp_val", ")", "]", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "plot_dir", ",", "'-'", ".", "join", "(", "fields", ")", "+", "'.png'", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.my_loss_full_logits": [[21, 28], ["tensorflow.nn.softmax", "tensorflow.reduce_sum", "logits.get_shape().as_list", "tensorflow.log", "logits.get_shape", "tensorflow.one_hot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.make_list": [[30, 32], ["isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.create_list_colors": [[33, 37], ["matplotlib.cm.tab10", "numpy.arange"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.load_sonnet_module": [[38, 62], ["tf_logging.info", "importlib.import_module", "utils.eval_method_from_tuple", "str", "hasattr", "utils.eval_method_from_tuple", "Exception", "hasattr", "__name__.split", "Exception"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.get_ac_collection_name": [[63, 68], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.compose_name": [[69, 73], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.tf_cov_times_n_points": [[80, 89], ["tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.create_reset_metric": [[90, 129], ["scope.replace.replace", "tensorflow.variable_scope", "tensorflow.contrib.framework.get_variables", "metric", "tensorflow.contrib.framework.get_variables", "tensorflow.variables_initializer", "Exception"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.create_concat_opts": [[131, 183], ["scope.replace.replace", "tensorflow.variable_scope", "node.shape.as_list", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.cond", "tensorflow.variables_initializer", "len", "RuntimeError", "tensorflow.equal", "tensorflow.zeros", "tensorflow.constant", "tensorflow.assign", "tensorflow.assign_add", "tensorflow.assign", "tensorflow.assign_add", "tensorflow.concat"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.sample_discrete_from_continuous": [[185, 188], ["tensorflow.distributions.Bernoulli", "tf.distributions.Bernoulli.sample"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.tf_sample_discrete_from_continuous": [[189, 191], ["numpy.random.binomial"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.add_gaussian_noise_and_clip": [[192, 198], ["numpy.random.normal", "numpy.clip"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.tf_add_gaussian_noise_and_clip": [[199, 205], ["tensorflow.distributions.Normal().sample", "tensorflow.clip_by_value", "tensorflow.distributions.Normal", "tensorflow.zeros_like", "tensorflow.ones_like", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.rescale": [[207, 210], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.tf_rescale": [[211, 214], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip": [[215, 217], ["numpy.clip"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.tf_clip": [[218, 220], ["tensorflow.clip_by_value"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.np_softplus": [[222, 227], ["numpy.log", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.get_short_dtype": [[230, 243], ["ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.get_short_regularization_name": [[274, 287], ["ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.regularization_info": [[290, 303], ["layer_dict.get", "utils.get_short_regularization_name", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_short_regularization_name"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.get_method_id": [[368, 503], ["method_tuple[].split", "str", "re.sub().replace().split", "re.sub", "re.sub", "re.sub().replace", "str", "str", "str", "str", "re.sub", "str", "str", "str", "int", "listWithPoints", "str", "listWithPoints", "str", "listWithPoints", "int", "str", "listWithPoints", "str", "str", "int", "listWithPoints", "str", "listWithPoints", "listWithPoints", "listWithPoints", "listWithPoints", "listWithPoints", "utils.regularization_info", "method_name_short[].lower", "str", "str", "str", "isinstance", "str", "str", "str", "str", "str", "print", "print", "ValueError"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.regularization_info"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.get_clipping_id": [[504, 511], ["str"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.eval_method_from_tuple": [[512, 532], ["utils.load_method_fn_from_method_path", "load_method_fn_from_method_path."], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_method_fn_from_method_path"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.load_method_fn_from_method_path": [[534, 562], ["method_path.split", "importlib.import_module", "getattr"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.load_class": [[564, 583], ["class_path.rsplit", "importlib.import_module", "getattr", "class_path.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.eval_file": [[584, 587], ["open", "eval", "fstream.read"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.core.argoLogging.get_logger": [[18, 67], ["_logger_lock.acquire", "logging.getLogger", "_logging.getLogger.setLevel", "_logger_lock.release", "logging.Formatter", "logging.StreamHandler", "_logging.StreamHandler.setFormatter", "_logging.getLogger.addHandler", "logging.getLogger", "_logging.getLogger.setLevel"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.release"], ["def", "get_logger", "(", ")", ":", "\n", "    ", "global", "_logger", "\n", "\n", "# Use double-checked locking to avoid taking lock unnecessarily.", "\n", "if", "_logger", ":", "\n", "        ", "return", "_logger", "\n", "\n", "", "_logger_lock", ".", "acquire", "(", ")", "\n", "\n", "try", ":", "\n", "        ", "if", "_logger", ":", "\n", "            ", "return", "_logger", "\n", "\n", "# Scope the TensorFlow logger to not conflict with users' loggers.", "\n", "", "logger", "=", "_logging", ".", "getLogger", "(", ")", "\n", "# import pdb;pdb.set_trace()", "\n", "# Don't further configure the TensorFlow logger if the root logger is", "\n", "# already configured. This prevents double logging in those cases.", "\n", "if", "not", "_logging", ".", "getLogger", "(", ")", ".", "handlers", ":", "\n", "# Determine whether we are in an interactive environment", "\n", "            ", "_interactive", "=", "False", "\n", "try", ":", "\n", "# This is only defined in interactive shells.", "\n", "                ", "if", "sys", ".", "ps1", ":", "_interactive", "=", "True", "\n", "", "except", "AttributeError", ":", "\n", "# Even now, we may be in an interactive shell with `python -i`.", "\n", "                ", "_interactive", "=", "sys", ".", "flags", ".", "interactive", "\n", "\n", "# If we are in an interactive environment (like Jupyter), set loglevel", "\n", "# to INFO and pipe the output to stdout.", "\n", "", "if", "_interactive", ":", "\n", "                ", "logger", ".", "setLevel", "(", "INFO", ")", "\n", "_logging_target", "=", "sys", ".", "stdout", "\n", "", "else", ":", "\n", "                ", "_logging_target", "=", "sys", ".", "stderr", "\n", "\n", "", "formatter", "=", "_logging", ".", "Formatter", "(", "' %(message)s'", ")", "\n", "# Add the output handler.", "\n", "_handler", "=", "_logging", ".", "StreamHandler", "(", "_logging_target", ")", "\n", "_handler", ".", "setFormatter", "(", "formatter", ")", "\n", "# _handler.setFormatter(_logging.Formatter(_logging.BASIC_FORMAT, None))", "\n", "logger", ".", "addHandler", "(", "_handler", ")", "\n", "\n", "", "logger", ".", "setLevel", "(", "INFO", ")", "\n", "_logger", "=", "logger", "\n", "return", "_logger", "\n", "\n", "", "finally", ":", "\n", "        ", "_logger_lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.__init__": [[13, 24], ["utils.argo_utils.update_conf_with_defaults", "numpy.random.seed", "Launchable.Launchable.create_id", "Launchable.Launchable.run_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.update_conf_with_defaults", "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.run_id"], ["def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "seed", "=", "0", ")", ":", "\n", "\n", "        ", "self", ".", "_opts_original", "=", "opts", "\n", "self", ".", "_opts", "=", "update_conf_with_defaults", "(", "opts", ",", "self", ".", "default_params", ")", "\n", "\n", "self", ".", "_id", "=", "self", ".", "create_id", "(", ")", "+", "self", ".", "run_id", "(", "opts", "[", "\"run\"", "]", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "self", ".", "_seed", "=", "seed", "\n", "\n", "self", ".", "dirName", "=", "dirName", "+", "\"/\"", "+", "self", ".", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.create_id": [[26, 29], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "create_id", "(", "self", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.run_id": [[30, 33], ["str"], "methods", ["None"], ["", "def", "run_id", "(", "self", ",", "run", ")", ":", "\n", "        ", "_id", "=", "'-r'", "+", "str", "(", "run", ")", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.id": [[39, 46], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns th id of the Launchable\n        :return: the id\n        \"\"\"", "\n", "return", "self", ".", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.init": [[47, 49], ["None"], "methods", ["None"], ["", "def", "init", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.release": [[65, 68], ["None"], "methods", ["None"], ["", "def", "release", "(", "self", ")", ":", "\n", "        ", "\"\"\"Release the resources of all the loggers.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.add_default_parameters": [[77, 116], ["cls.default_params.copy", "cls.default_params.copy.update"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "add_default_parameters", "(", "cls", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        Preprocessing of the parameters from config and argo.\n\n        In practice it updates the default values with the ones produced by\n        argo from the config file.\n\n        Parameters\n        ----------\n        params : dict\n            parameters extreacted from the config file\n\n        Returns\n        -------\n        full_params : dict\n            the model_params dictionary where missing values are replace by default\n            ones.\n\n        \"\"\"", "\n", "\n", "full_params", "=", "cls", ".", "default_params", ".", "copy", "(", ")", "\n", "# check the dimension", "\n", "#if len(full_params) + 2 < len(model_params): # run are introduced dynamically", "\n", "#    print(\"Warning: argo passed more options then those in default\")", "\n", "\n", "# update the model_params dictionary", "\n", "full_params", ".", "update", "(", "params", ")", "\n", "\n", "# # unpack full_params", "\n", "# for k in full_params.keys():", "\n", "#     if type(full_params[k]) == list:", "\n", "#         if len(full_params[k]) != 1:", "\n", "#             raise Exception(", "\n", "#                 'The option {} is not a single valued list'.format(k))", "\n", "#         else:", "\n", "#             full_params[k] = full_params[k][0]", "\n", "\n", "return", "full_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Launchable.Launchable.seed": [[117, 120], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "seed", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_seed", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.create_id": [[44, 61], ["super().create_id", "HM.HM._network.create_id", "HM.HM._cost_function.create_id", "argo.core.optimizers.NrSamples.get_n_s_id", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NrSamples.get_n_s_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "self", ".", "launchable_name", "\n", "\n", "# add to the ID the information of the cost function", "\n", "_id", "+=", "'-c'", "+", "self", ".", "_cost_function", ".", "create_id", "(", "self", ".", "_opts", "[", "\"cost_function\"", "]", ")", "\n", "\n", "_id", "+=", "'-s'", "+", "NrSamples", ".", "get_n_s_id", "(", "self", ".", "_opts", "[", "\"samples\"", "]", ")", "\n", "_id", "+=", "'-cp'", "+", "str", "(", "self", ".", "_opts", "[", "\"clip_probs\"", "]", ")", "\n", "if", "not", "self", ".", "_opts", "[", "\"pm_one\"", "]", ":", "\n", "            ", "_id", "+=", "'-pm'", "+", "str", "(", "self", ".", "_opts", "[", "\"pm_one\"", "]", ")", "\n", "\n", "", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "network_id", "=", "self", ".", "_network", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "+", "network_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.__init__": [[62, 78], ["core.networks.HMNetwork.HMNetwork", "argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "argo.core.network.AbstractAutoEncoder.AbstractAutoEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "# NB need to create the network before the super init because id generation depends on the network", "\n", "        ", "self", ".", "_pm_one", "=", "(", "opts", "[", "\"pm_one\"", "]", "if", "\"pm_one\"", "in", "opts", "else", "self", ".", "default_params", "[", "\"pm_one\"", "]", ")", "\n", "self", ".", "_clip_probs", "=", "opts", "[", "\"clip_probs\"", "]", "\n", "self", ".", "_network", "=", "HMNetwork", "(", "opts", ",", "self", ".", "_clip_probs", ",", "pm", "=", "self", ".", "_pm_one", ",", "name", "=", "\"hhm_network\"", ")", "\n", "\n", "self", ".", "_cost_function", "=", "CostFunctions", ".", "instantiate_cost_function", "(", "opts", "[", "\"cost_function\"", "]", ",", "\n", "module_path", "=", "\"helmholtz-machine\"", ")", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n", "self", ".", "samples", "=", "self", ".", "_opts", "[", "\"samples\"", "]", "\n", "\n", "# important nodes", "\n", "self", ".", "_gaussian_model_latent", "=", "None", "\n", "self", ".", "_model_visible", "=", "None", "\n", "self", ".", "x_reconstruction_node", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.create_hooks": [[79, 245], ["super().create_hooks", "super().create_hooks.append", "super().create_hooks.append", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "core.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2", "super().create_hooks.append", "core.hooks.ImagesGenerateHook.ImagesGenerateHook", "argo.core.hooks.ImagesInputHook.ImagesInputHook", "core.hooks.ImageReconstructHook.ImagesReconstructHook", "core.hooks.ThreeByThreeHook.ThreeByThreeHook", "isinstance", "super().create_hooks.append", "HM.HM._prior.mean", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "argo.core.hooks.ImportanceSamplingHook.ImportanceSamplingHook"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "        ", "hooks", "=", "super", "(", ")", ".", "create_hooks", "(", "config", ")", "\n", "\n", "tensors_to_average", "=", "[", "\n", "[", "[", "self", ".", "cost", "]", "]", ",", "[", "[", "self", ".", "_prior", ".", "mean", "(", ")", "]", ",", "[", "self", ".", "n_z_samples", "]", "]", ",", "\n", "\n", "]", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "\"loss_wake\"", "]", "]", ",", "[", "[", "\"prior_mean\"", "]", ",", "[", "\"samples\"", "]", "\n", "]", ",", "\n", "\n", "]", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "\n", "{", "\n", "\"fileName\"", ":", "\"loss\"", "}", ",", "\n", "]", ",", "\n", "[", "\n", "{", "\n", "\"fileName\"", ":", "\"mean\"", "}", ",", "\n", "{", "\n", "\"fileName\"", ":", "\"samples\"", "}", "\n", "]", "\n", "\n", "]", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", ")", "\n", "\n", "tensors_to_average", "=", "[", "\n", "self", ".", "loss_nodes_to_log", ",", "\n", "]", "\n", "tensors_to_average_names", "=", "[", "\n", "self", ".", "loss_nodes_to_log_names", ",", "\n", "]", "\n", "tensors_to_average_plots", "=", "[", "\n", "self", ".", "loss_nodes_to_log_filenames", ",", "\n", "]", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log2\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "print_to_screen", "=", "False", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", ")", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"HMFisherMatrixHook2\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "HMFisherMatrixHook2", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "_optimizer", ".", "_d_p", "is", "not", "None", ":", "\n", "                ", "t_to_average", "=", "[", "\n", "[", "[", "self", ".", "_optimizer", ".", "_diagonal_pad", "]", "]", "\n", "]", "\n", "t_to_average_names", "=", "[", "\n", "[", "[", "\"diagonal_pad\"", "]", "]", ",", "\n", "]", "\n", "t_to_average_plots", "=", "[", "\n", "[", "{", "\n", "\"fileName\"", ":", "\"diagonal_pad\"", "}", "]", "\n", "]", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"dp\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "t_to_average", ",", "\n", "tensors_to_average_names", "=", "t_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "t_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "print_to_screen", "=", "False", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "]", "\n", ")", "\n", ")", "\n", "\n", "", "", "kwargs", "=", "config", ".", "get", "(", "\"ImagesGenerateHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "ImagesGenerateHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "pm_one", "=", "self", ".", "_pm_one", ",", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"ImagesInputHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "ImagesInputHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "pm_one", "=", "self", ".", "_pm_one", ",", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"ImagesReconstructHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "ImagesReconstructHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "pm_one", "=", "self", ".", "_pm_one", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"ThreeByThreeHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "ThreeByThreeHook", "(", "model", "=", "self", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"LogpImportanceSamplingHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "if", "not", "isinstance", "(", "kwargs", ",", "list", ")", ":", "\n", "                ", "kwargs", "=", "[", "kwargs", "]", "\n", "", "for", "kw", "in", "kwargs", ":", "\n", "                ", "kws", "=", "{", "**", "self", ".", "_plot_model_hooks_kwargs", ",", "\n", "**", "kw", "}", "\n", "hooks", ".", "append", "(", "ImportanceSamplingHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "[", "self", ".", "importance_sampling_node", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", ",", "TEST", "]", ",", "\n", "**", "kws", "\n", ")", "\n", ")", "\n", "", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM._create_gradient_hook": [[246, 349], ["config.get", "HM.HM._get_steps", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "name.split", "name.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps"], ["", "def", "_create_gradient_hook", "(", "self", ",", "config", ")", ":", "\n", "\n", "# gradienthook", "\n", "        ", "tensors_to_average", "=", "[", "\n", "[", "[", "self", ".", "gradient_weight_global_norms", "[", "PHASE_WAKE", "]", "[", "0", "]", "]", ",", "\n", "self", ".", "gradient_norms", "[", "PHASE_WAKE", "]", ",", "\n", "]", ",", "\n", "[", "\n", "[", "self", ".", "gradient_weight_global_norms", "[", "PHASE_SLEEP", "]", "[", "0", "]", "]", ",", "\n", "self", ".", "gradient_norms", "[", "PHASE_SLEEP", "]", "\n", "]", ",", "\n", "[", "[", "self", ".", "gradient_weight_global_norms", "[", "PHASE_WAKE", "]", "[", "1", "]", "]", ",", "\n", "self", ".", "weight_norms", "[", "PHASE_WAKE", "]", ",", "\n", "]", ",", "\n", "[", "\n", "[", "self", ".", "gradient_weight_global_norms", "[", "PHASE_SLEEP", "]", "[", "1", "]", "]", ",", "\n", "self", ".", "weight_norms", "[", "PHASE_SLEEP", "]", "\n", "]", ",", "\n", "]", "\n", "\n", "layer_names_wake", "=", "[", "\"L\"", "+", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "for", "name", "in", "self", ".", "gradient_names", "[", "PHASE_WAKE", "]", "]", "\n", "\n", "layer_names_sleep", "=", "[", "\"L\"", "+", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "for", "name", "in", "self", ".", "gradient_names", "[", "PHASE_SLEEP", "]", "]", "\n", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "\"gradient_global_norms_wake\"", "]", ",", "\n", "layer_names_wake", ",", "\n", "]", ",", "\n", "[", "\n", "[", "\"gradient_global_norms_sleep\"", "]", ",", "\n", "layer_names_sleep", "\n", "]", ",", "\n", "[", "[", "\"weight_global_norms_wake\"", "]", ",", "\n", "layer_names_wake", ",", "\n", "]", ",", "\n", "[", "\n", "[", "\"weight_global_norms_sleep\"", "]", ",", "\n", "layer_names_sleep", "\n", "]", ",", "\n", "]", "\n", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\n", "\"fileName\"", ":", "\"gradient_global_norms_wake\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", ",", "\n", "{", "\n", "\"fileName\"", ":", "\"gradient_norms_wake\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", ",", "]", ",", "\n", "[", "\n", "{", "\n", "\"fileName\"", ":", "\"gradient_global_norms_sleep\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", ",", "\n", "{", "\n", "\"fileName\"", ":", "\"gradient_norms_sleep\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", "\n", "]", ",", "\n", "[", "{", "\n", "\"fileName\"", ":", "\"weight_global_norms_wake\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", ",", "\n", "{", "\n", "\"fileName\"", ":", "\"weight_norms_wake\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", ",", "]", ",", "\n", "[", "\n", "{", "\n", "\"fileName\"", ":", "\"weight_global_norms_sleep\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", ",", "\n", "{", "\n", "\"fileName\"", ":", "\"weight_norms_sleep\"", ",", "\n", "\"logscale-y\"", ":", "1", ",", "\n", "\"compose-label\"", ":", "0", "}", "\n", "]", ",", "\n", "]", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"GradientsHook\"", ",", "None", ")", "\n", "hook", "=", "None", "\n", "if", "kwargs", ":", "\n", "            ", "gradient_period", "=", "config", "[", "\"GradientsHook\"", "]", "[", "\"period\"", "]", "\n", "gradient_steps", "=", "self", ".", "_get_steps", "(", "gradient_period", ",", "self", ".", "_time_reference_str", ")", "\n", "hook", "=", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"gradient\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "gradient_steps", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "# trigger_plot = True,", "\n", "print_to_screen", "=", "False", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "]", "\n", ")", "\n", "\n", "", "return", "hook", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.create_network": [[350, 385], ["HM.HM._network", "tensorflow.shape", "[].mean", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "HM.HM._create_importance_sampling_node", "HM.HM._model_inferred_distr.reconstruction_node", "HM.HM._model_inferred_distr.sample", "HM.HM._model_reconstuction_distr.reconstruction_node", "HM.HM._model_reconstuction_distr.sample", "HM.HM.x.shape[].as_list", "HM.HM.x.shape[].as_list", "HM.HM.x.shape[].as_list", "HM.HM.x.shape[].as_list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._create_importance_sampling_node", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "create_network", "(", "self", ")", ":", "\n", "\n", "# create autoencoder network", "\n", "        ", "dictionary", "=", "self", ".", "_network", "(", "self", ".", "x", ",", "self", ".", "b_size", ",", "self", ".", "n_z_samples", ")", "\n", "self", ".", "h_inferred", ",", "self", ".", "x_reconstruct", ",", "self", ".", "x_reconstruct_distr", ",", "self", ".", "_hrw", ",", "self", ".", "_hgw", "=", "dictionary", "[", "PHASE_WAKE", "]", "\n", "\n", "self", ".", "h_reconstruct", ",", "self", ".", "x_inferred", ",", "self", ".", "x_inferred_distr", ",", "self", ".", "_hrs", ",", "self", ".", "_hgs", "=", "dictionary", "[", "PHASE_SLEEP", "]", "\n", "\n", "x_inferred_shape", "=", "tf", ".", "shape", "(", "self", ".", "x_inferred", ")", "\n", "\n", "self", ".", "_model_latent_mean", "=", "self", ".", "_hrw", "[", "-", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "\n", "self", ".", "_model_reconstuction_distr", "=", "self", ".", "x_reconstruct_distr", "\n", "self", ".", "_model_inferred_distr", "=", "self", ".", "x_inferred_distr", "\n", "\n", "self", ".", "x_inferred_node", "=", "tf", ".", "reshape", "(", "self", ".", "_model_inferred_distr", ".", "reconstruction_node", "(", ")", ",", "\n", "[", "-", "1", "]", "+", "self", ".", "x", ".", "shape", "[", "1", ":", "]", ".", "as_list", "(", ")", ")", "\n", "self", ".", "x_inferred_node", "=", "self", ".", "x_inferred_node", "\n", "\n", "self", ".", "x_inferred_sample", "=", "tf", ".", "reshape", "(", "self", ".", "_model_inferred_distr", ".", "sample", "(", ")", ",", "\n", "[", "-", "1", "]", "+", "self", ".", "x", ".", "shape", "[", "1", ":", "]", ".", "as_list", "(", ")", ")", "\n", "self", ".", "x_inferred_sample", "=", "self", ".", "x_inferred_sample", "\n", "\n", "self", ".", "x_reconstruction_node", "=", "tf", ".", "reshape", "(", "self", ".", "_model_reconstuction_distr", ".", "reconstruction_node", "(", ")", ",", "\n", "[", "-", "1", "]", "+", "self", ".", "x", ".", "shape", "[", "1", ":", "]", ".", "as_list", "(", ")", ")", "\n", "self", ".", "x_reconstruction_node", "=", "self", ".", "x_reconstruction_node", "\n", "\n", "self", ".", "x_reconstruction_sample", "=", "tf", ".", "reshape", "(", "self", ".", "_model_reconstuction_distr", ".", "sample", "(", ")", ",", "\n", "[", "-", "1", "]", "+", "self", ".", "x", ".", "shape", "[", "1", ":", "]", ".", "as_list", "(", ")", ")", "\n", "self", ".", "x_reconstruction_sample", "=", "self", ".", "x_reconstruction_sample", "\n", "\n", "self", ".", "_prior", ",", "self", ".", "_prior_samples", "=", "dictionary", "[", "\"prior\"", "]", "\n", "\n", "# for the moment we always create the IS node", "\n", "self", ".", "importance_sampling_node", "=", "self", ".", "_create_importance_sampling_node", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.encode": [[386, 392], ["sess.run", "HM.HM.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "encode", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "h_inferred", ",", "self", ".", "_model_latent_mean", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "n_z_samples", ":", "1", ",", "\n", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.decode": [[394, 401], ["sess.run", "HM.HM.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "decode", "(", "self", ",", "Z", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data.\"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "x_inferred_node", ",", "self", ".", "x_inferred", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "_prior_samples", ":", "Z", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.generate": [[402, 412], ["sess.run", "HM.HM.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "generate", "(", "self", ",", "batch_size", "=", "1", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Generate data by sampling from latent space.\n\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "x_inferred_node", ",", "self", ".", "x_inferred", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "b_size", ":", "batch_size", ",", "\n", "self", ".", "n_z_samples", ":", "1", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.reconstruct": [[413, 419], ["sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "reconstruct", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use VAE to reconstruct given data. \"\"\"", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "x_reconstruction_node", ",", "self", ".", "x_reconstruct", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "n_z_samples", ":", "1", ",", "\n", "self", ".", "raw_x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.get_hm_optimizer_step": [[420, 448], ["HM.HM._clip_gradients", "HM.HM._optimizer.apply_gradients", "HM.HM._optimizer.compute_gradients", "HM.HM._optimizer.compute_gradients", "tensorflow.check_numerics", "tensorflow.check_numerics", "tensorflow.global_norm", "tensorflow.global_norm", "tensorflow.norm", "tensorflow.norm"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._clip_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.apply_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients"], ["", "def", "get_hm_optimizer_step", "(", "self", ",", "phase", ",", "global_step", "=", "None", ")", ":", "\n", "# You can use this if you want to use gradient descent", "\n", "# 1st part of minimize: compute_gradient", "\n", "        ", "if", "phase", "==", "PHASE_WAKE", ":", "\n", "# This is just for debug reasons, you may remove it later", "\n", "            ", "self", ".", "grads_and_vars_w", "=", "self", ".", "_optimizer", ".", "compute_gradients", "(", "phase", ",", "self", ".", "loss", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "self", ".", "grads_and_vars", "=", "self", ".", "grads_and_vars_w", "\n", "", "else", ":", "\n", "            ", "self", ".", "grads_and_vars_s", "=", "self", ".", "_optimizer", ".", "compute_gradients", "(", "phase", ",", "self", ".", "loss", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "self", ".", "grads_and_vars", "=", "self", ".", "grads_and_vars_s", "\n", "\n", "# clip gradients", "\n", "", "clipped_grads_and_vars", "=", "self", ".", "_clip_gradients", "(", "self", ".", "grads_and_vars", ",", "self", ".", "_grad_clipping_tuple", ")", "\n", "\n", "# compute norms in case they need to be logged", "\n", "self", ".", "gradient_names", "[", "phase", "]", "=", "[", "g", ".", "name", "for", "(", "g", ",", "_", ")", "in", "self", ".", "grads_and_vars", "]", "\n", "self", ".", "gradient_norms", "[", "phase", "]", "=", "[", "tf", ".", "norm", "(", "g", ")", "+", "NUMTOL", "for", "(", "g", ",", "_", ")", "in", "clipped_grads_and_vars", "]", "\n", "self", ".", "weight_norms", "[", "phase", "]", "=", "[", "tf", ".", "norm", "(", "v", ")", "+", "NUMTOL", "for", "(", "g", ",", "v", ")", "in", "clipped_grads_and_vars", "]", "\n", "\n", "# check that gradients are finite", "\n", "grads", "=", "[", "tf", ".", "check_numerics", "(", "g", ",", "\"grads is not finite\"", ")", "for", "(", "g", ",", "v", ")", "in", "clipped_grads_and_vars", "]", "\n", "variables", "=", "[", "tf", ".", "check_numerics", "(", "v", ",", "\"grads is not finite\"", ")", "for", "(", "g", ",", "v", ")", "in", "clipped_grads_and_vars", "]", "\n", "self", ".", "gradient_weight_global_norms", "[", "phase", "]", "=", "[", "tf", ".", "global_norm", "(", "grads", ")", ",", "tf", ".", "global_norm", "(", "variables", ")", "]", "\n", "\n", "# 2nd part of minimize: apply_gradient, THIS IS NOT self.global_step on purpose", "\n", "optimizer_step", "=", "self", ".", "_optimizer", ".", "apply_gradients", "(", "clipped_grads_and_vars", ",", "global_step", "=", "global_step", ")", "\n", "\n", "return", "optimizer_step", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.set_training_op": [[450, 470], ["HM.HM.get_hm_optimizer_step", "HM.HM.get_hm_optimizer_step", "tensorflow.group", "tensorflow.group", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.get_hm_optimizer_step", "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.get_hm_optimizer_step"], ["", "def", "set_training_op", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "gradients", "=", "{", "}", "\n", "self", ".", "gradient_names", "=", "{", "}", "\n", "self", ".", "gradient_norms", "=", "{", "}", "\n", "self", ".", "weight_norms", "=", "{", "}", "\n", "self", ".", "gradient_weight_global_norms", "=", "{", "}", "\n", "\n", "optimizer_step_wake", "=", "self", ".", "get_hm_optimizer_step", "(", "PHASE_WAKE", ")", "\n", "optimizer_step_sleep", "=", "self", ".", "get_hm_optimizer_step", "(", "PHASE_SLEEP", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "# grouping the training operations", "\n", "\n", "# grads = [g for g,v in [*self.grads_and_vars_w, *self.grads_and_vars_s]]", "\n", "# vars = [v for g,v in [*self.grads_and_vars_w, *self.grads_and_vars_s]]", "\n", "\n", "# import ipdb; ipdb.set_trace()", "\n", "# printy = tf.print(self.global_step,self.b_size, [(g.name, g) for g in grads], \"vars\\n\\n\", [(v.name, v) for v in vars],\"norms:\",tf.reduce_mean(self.gradient_norms[PHASE_SLEEP]+self.gradient_norms[PHASE_WAKE]) ,\"\\n\\n\")", "\n", "update_ops", "=", "tf", ".", "group", "(", "*", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", ")", "\n", "self", ".", "training_op", "=", "tf", ".", "group", "(", "update_ops", ",", "optimizer_step_wake", ",", "optimizer_step_sleep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.create_loss": [[471, 481], ["HM.HM._cost_function", "tensorflow.identity"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity"], ["", "def", "create_loss", "(", "self", ")", ":", "\n", "# Cross entropy loss", "\n", "\n", "        ", "cost", ",", "self", ".", "loss_nodes_to_log", ",", "self", ".", "loss_nodes_to_log_names", ",", "self", ".", "loss_nodes_to_log_filenames", "=", "self", ".", "_cost_function", "(", "\n", "self", ")", "\n", "\n", "self", ".", "loss", "=", "{", "}", "\n", "self", ".", "loss", "[", "PHASE_WAKE", "]", "=", "self", ".", "loss_nodes_to_log", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "loss", "[", "PHASE_SLEEP", "]", "=", "self", ".", "loss_nodes_to_log", "[", "1", "]", "[", "0", "]", "\n", "self", ".", "cost", "=", "(", "cost", "if", "cost", "is", "not", "None", "else", "tf", ".", "identity", "(", "self", ".", "loss", "[", "PHASE_WAKE", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM.create_input_nodes": [[482, 494], ["super().create_input_nodes", "argo.core.optimizers.NrSamples.process_n_samples", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.create_input_nodes", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NrSamples.process_n_samples"], ["", "def", "create_input_nodes", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        creates input nodes for an autoencoder from the dataset\n\n        Sets:\n            x, x_target\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "create_input_nodes", "(", "dataset", "=", "dataset", ")", "\n", "\n", "self", ".", "b_size", "=", "tf", ".", "shape", "(", "self", ".", "x", ")", "[", "0", "]", "\n", "self", ".", "n_z_samples", "=", "NrSamples", ".", "process_n_samples", "(", "self", ".", "samples", ",", "self", ".", "global_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.HM.HM._create_importance_sampling_node": [[495, 525], ["tensorflow.zeros", "tensorflow.zeros", "range", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_logsumexp", "len", "tensorflow.reduce_sum", "distr_p.log_prob", "tensorflow.reduce_sum", "distr_q.log_prob"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "_create_importance_sampling_node", "(", "self", ")", ":", "\n", "        ", "batch_size", "=", "self", ".", "b_size", "\n", "n_samples", "=", "self", ".", "n_z_samples", "\n", "mega_batch_size", "=", "batch_size", "*", "n_samples", "\n", "\n", "gen_layers", "=", "self", ".", "_hgw", "\n", "rec_layers", "=", "self", ".", "_hrw", "\n", "\n", "ps", "=", "tf", ".", "zeros", "(", "(", "mega_batch_size", ")", ")", "\n", "qs", "=", "tf", ".", "zeros", "(", "(", "mega_batch_size", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_layers", ")", ")", ":", "\n", "            ", "samples_q", "=", "rec_layers", "[", "i", "]", "[", "1", "]", "\n", "\n", "distr_p", "=", "gen_layers", "[", "i", "]", "[", "0", "]", "\n", "log_probs_p_all", "=", "tf", ".", "reduce_sum", "(", "distr_p", ".", "log_prob", "(", "samples_q", ")", ",", "axis", "=", "-", "1", ")", "\n", "ps", "+=", "log_probs_p_all", "\n", "\n", "if", "i", "!=", "0", ":", "\n", "                ", "distr_q", "=", "rec_layers", "[", "i", "]", "[", "0", "]", "\n", "log_probs_q_all", "=", "tf", ".", "reduce_sum", "(", "distr_q", ".", "log_prob", "(", "samples_q", ")", ",", "axis", "=", "-", "1", ")", "\n", "qs", "+=", "log_probs_q_all", "\n", "\n", "# Reshape", "\n", "", "", "log_p_all", "=", "tf", ".", "reshape", "(", "ps", ",", "[", "n_samples", ",", "batch_size", "]", ")", "\n", "log_q_all", "=", "tf", ".", "reshape", "(", "qs", ",", "[", "n_samples", ",", "batch_size", "]", ")", "\n", "# Approximate log(p(x))", "\n", "logp_is", "=", "tf", ".", "reduce_logsumexp", "(", "log_p_all", "-", "log_q_all", ",", "axis", "=", "0", ")", "\n", "\n", "return", "logp_is", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CMBNetwork.CMBNetwork.create_id": [[22, 30], ["super().create_id", "argo.core.utils.utils_modules.get_network_module_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.get_network_module_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "\"-\"", "+", "get_network_module_id", "(", "self", ".", "_opts", "[", "\"network_architecture\"", "]", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CMBNetwork.CMBNetwork.__init__": [[31, 47], ["argo.core.network.ArgoNetworkWithDefaults.ArgoNetworkWithDefaults.__init__", "importlib.import_module", "getattr", "__name__.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", ")", ":", "# , remove_node_from_logits = False", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ")", "\n", "self", ".", "_network_architecture", "=", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "\n", "self", ".", "_module_name", ",", "self", ".", "_module_kwargs", "=", "self", ".", "_network_architecture", "\n", "\n", "self", ".", "_output_size", "=", "self", ".", "_opts", "[", "\"output_shape\"", "]", "[", "0", "]", "\n", "self", ".", "_input_shape", "=", "self", ".", "_opts", "[", "\"input_shape\"", "]", "\n", "\n", "self", ".", "_activation", "=", "self", ".", "_network_defaults", "[", "\"activation\"", "]", "\n", "self", ".", "_initializers", "=", "{", "'w'", ":", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "'b'", ":", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", "}", "\n", "self", ".", "_regularizers", "=", "{", "'w'", ":", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "'b'", ":", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", "}", "\n", "\n", "utils_module", "=", "importlib", ".", "import_module", "(", "\".argo.core.utils.utils_modules\"", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "self", ".", "_module_class", "=", "getattr", "(", "utils_module", ",", "self", ".", "_module_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CMBNetwork.CMBNetwork._build": [[58, 69], ["CMBNetwork.CMBNetwork._module_class", "CMBNetwork.CMBNetwork.module"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "x", ",", "is_training", "=", "None", ",", "**", "extra_kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "module", "=", "self", ".", "_module_class", "(", "**", "self", ".", "_module_kwargs", ",", "\n", "activation", "=", "self", ".", "_activation", ",", "\n", "initializers", "=", "self", ".", "_initializers", ",", "\n", "regularizers", "=", "self", ".", "_regularizers", ",", "\n", "output_size", "=", "self", ".", "_output_size", "\n", ")", "\n", "\n", "\n", "return", "self", ".", "module", "(", "x", ",", "is_training", "=", "is_training", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AlphaCrossEntropy.AlphaCrossEntropy.__init__": [[9, 14], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "multiclass_metrics", "=", "False", ",", "alpha_parameter", "=", "None", ",", "name", "=", "\"CrossEntropy\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_multiclass_metrics", "=", "multiclass_metrics", "\n", "#import pdb; pdb.set_trace()", "\n", "self", ".", "_alpha_parameter", "=", "alpha_parameter", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AlphaCrossEntropy.AlphaCrossEntropy.create_id": [[15, 22], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "        ", "_id", "=", "\"CE\"", "\n", "alpha", "=", "cost_fuction_kwargs", "[", "\"alpha_parameter\"", "]", "\n", "if", "alpha", ":", "\n", "            ", "_id", "+=", "\"_alp{}_\"", ".", "format", "(", "alpha", ")", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AlphaCrossEntropy.AlphaCrossEntropy._build": [[23, 150], ["tensorflow.shape", "tensorflow.tile", "tensorflow.one_hot", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "argo.core.utils.argo_utils.create_panels_lists", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "AlphaCrossEntropy.AlphaCrossEntropy._build.alphaloss"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_panels_lists"], ["", "def", "_build", "(", "self", ",", "model", ",", "drop_one_logit", "=", "False", ")", ":", "\n", "\n", "        ", "y", "=", "model", ".", "y", "\n", "shaper", "=", "tf", ".", "shape", "(", "y", ")", "\n", "# if len(y.shape)==1:", "\n", "#     y = tf.expand_dims(y, axis=-1)", "\n", "\n", "kl_losses", "=", "model", ".", "kl_losses", "\n", "total_KL", "=", "tf", ".", "reduce_sum", "(", "kl_losses", ")", "/", "model", ".", "dataset", ".", "n_samples_train", "\n", "alpha", "=", "self", ".", "_alpha_parameter", "\n", "n_samples", "=", "model", ".", "n_samples_ph", "\n", "\n", "logits", "=", "model", ".", "prediction_distr", ".", "logits", "\n", "probs", "=", "model", ".", "prediction_distr", ".", "probs", "\n", "n_labels", "=", "logits", ".", "shape", "[", "1", "]", "\n", "y_tile", "=", "tf", ".", "tile", "(", "y", ",", "[", "n_samples", "]", ")", "\n", "y_true", "=", "tf", ".", "one_hot", "(", "y_tile", ",", "n_labels", ")", "\n", "\n", "\n", "\n", "\n", "\n", "def", "alphaloss", "(", "y_true", ",", "logits", ")", ":", "\n", "            ", "logits_reshaped", "=", "tf", ".", "reshape", "(", "logits", ",", "(", "n_samples", ",", "shaper", "[", "0", "]", ",", "n_labels", ")", ")", "\n", "y_true_reshaped", "=", "tf", ".", "reshape", "(", "y_true", ",", "(", "n_samples", ",", "shaper", "[", "0", "]", ",", "n_labels", ")", ")", "\n", "y_true_reshaped", "=", "tf", ".", "cast", "(", "y_true_reshaped", ",", "tf", ".", "float32", ")", "\n", "log_solfmax", "=", "logits_reshaped", "-", "tf", ".", "reduce_max", "(", "logits_reshaped", ",", "axis", "=", "2", ",", "keepdims", "=", "True", ")", "\n", "log_solfmaxT", "=", "log_solfmax", "-", "tf", ".", "reduce_logsumexp", "(", "log_solfmax", ",", "axis", "=", "2", ",", "keepdims", "=", "True", ")", "\n", "log_cross_entropy", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "y_true_reshaped", ",", "log_solfmaxT", ")", ",", "-", "1", ")", "\n", "loss", "=", "-", "1.", "/", "alpha", "*", "(", "tf", ".", "reduce_logsumexp", "(", "alpha", "*", "log_cross_entropy", ",", "0", ")", "-", "tf", ".", "log", "(", "tf", ".", "cast", "(", "n_samples", ",", "tf", ".", "float32", ")", ")", ")", "\n", "return", "loss", "\n", "\n", "", "if", "alpha", "is", "None", ":", "\n", "            ", "loss_per_sample", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "tf", ".", "cast", "(", "y_tile", ",", "tf", ".", "int32", ")", ",", "\n", "logits", "=", "logits", ")", "\n", "", "else", ":", "\n", "            ", "loss_per_sample", "=", "alphaloss", "(", "y_true", ",", "logits", ")", "\n", "\n", "\n", "\n", "", "ce", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ")", "\n", "loss", "=", "ce", "+", "total_KL", "\n", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "y_tile", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "\n", "# First panel will be at screen during training", "\n", "list_of_vpanels_of_plots", "=", "[", "\n", "[", "\n", "# {", "\n", "#     'nodes' : [loss],", "\n", "#     'names': [\"loss\"],", "\n", "#     'fileName' : \"loss\"", "\n", "# },", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "ce", "]", ",", "\n", "'names'", ":", "[", "\"ce\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"ce\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "total_KL", "]", ",", "\n", "'names'", ":", "[", "\"kl\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"kl\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "accuracy", "]", ",", "\n", "'names'", ":", "[", "\"accuracy\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"accuracy\"", "}", "\n", "}", ",", "\n", "\n", "]", ",", "\n", "[", "\n", "{", "\n", "'nodes'", ":", "[", "1", "-", "accuracy", "]", ",", "\n", "'names'", ":", "[", "\"error\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"error\"", ",", "\"logscale-y\"", ":", "1", "}", "\n", "}", ",", "\n", "\n", "]", "\n", "]", "\n", "\n", "\n", "# nodes_to_log = [[ce],", "\n", "#                 [total_KL],", "\n", "#                 [1 - accuracy],", "\n", "#                 [accuracy]]", "\n", "#", "\n", "# nodes_to_log_names = [[\"ce\"], [\"kl\"], [\"error\"], [\"accuracy\"]]", "\n", "# nodes_to_log_filenames = [{\"fileName\": \"ce\"},", "\n", "#                           {\"fileName\": \"kl\"},", "\n", "#                           {\"fileName\": \"error\", \"logscale-y\": 1},", "\n", "#                           {\"fileName\": \"accuracy\"}]", "\n", "\n", "if", "self", ".", "_multiclass_metrics", ":", "\n", "            ", "y_pred", "=", "tf", ".", "one_hot", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "n_labels", ")", "\n", "y_true", "=", "tf", ".", "one_hot", "(", "y_tile", ",", "n_labels", ")", "\n", "f1_micro", ",", "f1_macro", ",", "f1_weighted", "=", "tf_f1_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "auc", ",", "auc_update", "=", "tf", ".", "metrics", ".", "auc", "(", "\n", "labels", "=", "tf", ".", "cast", "(", "y_true", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "# predictions=tf.nn.softmax(logits)", "\n", "predictions", "=", "probs", "\n", ")", "\n", "\n", "raise", "Exception", "(", "\"set panels correctly here first!\"", ")", "\n", "# nodes_to_log += [[auc_update],", "\n", "#                 [f1_micro, f1_macro, f1_weighted]]", "\n", "#", "\n", "# nodes_to_log_names += [[\"auc\"], [\"f1_micro\", \"f1_macro\", \"f1_weighted\"]]", "\n", "# nodes_to_log_filenames += [", "\n", "#                             {\"fileName\": \"auc\"},", "\n", "#                             {\"fileName\": \"f1_score\"}", "\n", "#                             # {\"fileName\": \"f1_micro\"},", "\n", "#                             # {\"fileName\": \"f1_macro\"},", "\n", "#                             # {\"fileName\": \"f1_weighted\"}", "\n", "#                           ]", "\n", "\n", "\n", "\n", "", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "=", "create_panels_lists", "(", "list_of_vpanels_of_plots", ")", "\n", "\n", "return", "loss", ",", "loss_per_sample", ",", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropyWithLogitsOneDropped.CrossEntropyWithLogitsOneDropped.__init__": [[16, 19], ["argo.core.network.Network.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "multiclass_metrics", "=", "False", ",", "name", "=", "\"CrossEntropyWithLogitsOneDropped\"", ")", ":", "# drop_one_logit=0,", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_multiclass_metrics", "=", "multiclass_metrics", "\n", "# self._drop_one_logit = drop_one_logit", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropyWithLogitsOneDropped.CrossEntropyWithLogitsOneDropped.create_id": [[21, 27], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "_id", "=", "\"CEdrop\"", "# + str(cost_fuction_kwargs.get(\"drop_one_logit\",0))", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropyWithLogitsOneDropped.CrossEntropyWithLogitsOneDropped._build": [[28, 120], ["tensorflow.concat", "tensorflow.nn.softmax", "tensorflow.slice", "tensorflow.concat", "tensorflow.clip_by_value", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.one_hot", "tensorflow.one_hot", "argo.core.utils.argo_utils.tf_f1_score", "tensorflow.metrics.auc", "logits.get_shape().as_list", "tensorflow.cast", "tensorflow.cast", "tensorflow.argmax", "tensorflow.zeros_like", "tensorflow.reshape", "tensorflow.log", "tensorflow.equal", "tensorflow.cast", "tensorflow.equal", "tensorflow.cast", "tensorflow.nn.softmax", "logits.get_shape", "tensorflow.slice", "tensorflow.one_hot", "tensorflow.argmax", "tensorflow.cast", "tensorflow.argmax", "tensorflow.cast", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_f1_score", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax"], ["", "def", "_build", "(", "self", ",", "prediction_model", ",", "drop_one_logit", "=", "False", ")", ":", "\n", "\n", "# dims = np.prod(ae.x_shape)", "\n", "# this has changed since some models can feed data with different shapes for train and eval", "\n", "# if this break ask me.. (Riccardo) -> I fixed, self.raw_x is replaces by ae.raw_x", "\n", "\n", "        ", "'''\n        flatten = snt.BatchFlatten()(prediction_model.logits)\n        dim_output = prediction_model.dataset.n_labels\n\n\n        # use the same default values as for the network\n        default_weights_init = prediction_model._network._default_weights_init\n        default_bias_init = prediction_model._network._default_bias_init\n        initializers = {}\n        initializers['w'] = default_weights_init\n        initializers['b'] = default_bias_init\n\n        default_weights_reg = prediction_model._network._default_weights_reg\n        default_bias_reg = prediction_model._network._default_bias_reg\n        regularizers = {}\n        regularizers['w'] = default_weights_reg\n        regularizers['b'] = default_bias_reg\n\n        logits = snt.Linear(dim_output, initializers=initializers, regularizers=regularizers)(flatten)\n        '''", "\n", "\n", "y", "=", "prediction_model", ".", "y", "\n", "logits", "=", "prediction_model", ".", "logits", "\n", "n_labels", "=", "logits", ".", "shape", "[", "1", "]", "\n", "\n", "if", "drop_one_logit", ":", "\n", "            ", "n", "=", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "logits_add_one_logit", "=", "tf", ".", "concat", "(", "[", "logits", ",", "\n", "tf", ".", "zeros_like", "(", "tf", ".", "slice", "(", "logits", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "1", "]", ")", ")", "]", ",", "\n", "1", ")", "\n", "\n", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "logits_add_one_logit", ")", "\n", "probabilities_sliced", "=", "tf", ".", "slice", "(", "probabilities", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "n", "]", ")", "\n", "new_probabilities", "=", "tf", ".", "concat", "(", "[", "probabilities_sliced", ",", "\n", "tf", ".", "reshape", "(", "1", "-", "tf", ".", "reduce_sum", "(", "probabilities_sliced", ",", "axis", "=", "1", ")", ",", "[", "-", "1", ",", "1", "]", ")", "]", ",", "\n", "1", ")", "\n", "\n", "clipped_probabilies", "=", "tf", ".", "clip_by_value", "(", "new_probabilities", ",", "NUMTOL", ",", "1", "-", "NUMTOL", ")", "\n", "# https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html", "\n", "loss_per_sample", "=", "tf", ".", "reduce_sum", "(", "-", "tf", ".", "one_hot", "(", "y", ",", "depth", "=", "n", "+", "1", ")", "*", "tf", ".", "log", "(", "clipped_probabilies", ")", ",", "axis", "=", "1", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ")", "\n", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "logits_add_one_logit", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "y", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "loss_per_sample", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "tf", ".", "cast", "(", "y", ",", "tf", ".", "int32", ")", ",", "\n", "logits", "=", "logits", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ")", "\n", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "y", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "", "nodes_to_log", "=", "[", "[", "1", "-", "accuracy", "]", ",", "\n", "[", "accuracy", "]", "]", "\n", "nodes_to_log_names", "=", "[", "[", "\"error\"", "]", ",", "[", "\"accuracy\"", "]", "]", "\n", "nodes_to_log_filenames", "=", "[", "{", "\"fileName\"", ":", "\"error\"", ",", "\"logscale-y\"", ":", "1", "}", ",", "\n", "{", "\"fileName\"", ":", "\"accuracy\"", "}", "]", "\n", "\n", "if", "self", ".", "_multiclass_metrics", ":", "\n", "            ", "y_pred", "=", "tf", ".", "one_hot", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "n_labels", ")", "\n", "y_true", "=", "tf", ".", "one_hot", "(", "y", ",", "n_labels", ")", "\n", "f1_micro", ",", "f1_macro", ",", "f1_weighted", "=", "tf_f1_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "auc", ",", "auc_update", "=", "tf", ".", "metrics", ".", "auc", "(", "\n", "labels", "=", "tf", ".", "cast", "(", "y_true", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "predictions", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", ")", "\n", "\n", "nodes_to_log", "+=", "[", "[", "auc_update", "]", ",", "\n", "[", "f1_micro", ",", "f1_macro", ",", "f1_weighted", "]", "]", "\n", "\n", "nodes_to_log_names", "+=", "[", "[", "\"auc\"", "]", ",", "[", "\"f1_micro\"", ",", "\"f1_macro\"", ",", "\"f1_weighted\"", "]", "]", "\n", "nodes_to_log_filenames", "+=", "[", "\n", "{", "\"fileName\"", ":", "\"auc\"", "}", ",", "\n", "{", "\"fileName\"", ":", "\"f1_score\"", "}", "\n", "# {\"fileName\": \"f1_micro\"},", "\n", "# {\"fileName\": \"f1_macro\"},", "\n", "# {\"fileName\": \"f1_weighted\"}", "\n", "]", "\n", "\n", "", "return", "loss", ",", "loss_per_sample", ",", "nodes_to_log", ",", "nodes_to_log_names", ",", "nodes_to_log_filenames", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropyWithLogits.CrossEntropyWithLogits.__init__": [[10, 14], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "multiclass_metrics", "=", "False", ",", "nbp", "=", "False", ",", "name", "=", "\"CrossEntropyWithLogits\"", ")", ":", "# drop_one_logit=0,", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_multiclass_metrics", "=", "multiclass_metrics", "\n", "self", ".", "_nbp", "=", "nbp", "\n", "#self._drop_one_logit = drop_one_logit", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropyWithLogits.CrossEntropyWithLogits.create_id": [[16, 22], ["cost_fuction_kwargs.get"], "methods", ["None"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "        ", "_id", "=", "\"CE\"", "#+ str(cost_fuction_kwargs.get(\"drop_one_logit\",0))", "\n", "if", "cost_fuction_kwargs", ".", "get", "(", "\"nbp\"", ",", "False", ")", ":", "\n", "            ", "_id", "+=", "\"_nbp\"", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropyWithLogits.CrossEntropyWithLogits._build": [[23, 135], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "argo.core.utils.argo_utils.create_panels_lists", "CrossEntropyWithLogits.CrossEntropyWithLogits._build.nbp"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_panels_lists"], ["", "def", "_build", "(", "self", ",", "prediction_model", ")", ":", "#, drop_one_logit=False):", "\n", "\n", "        ", "y", "=", "prediction_model", ".", "y", "\n", "logits", "=", "prediction_model", ".", "logits", "\n", "n_labels", "=", "logits", ".", "shape", "[", "1", "]", "\n", "\n", "\n", "# do not delete yet (Luigi)", "\n", "'''\n        if drop_one_logit:\n            n = logits.get_shape().as_list()[1]\n        else:\n        '''", "\n", "\n", "loss_per_sample", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "tf", ".", "cast", "(", "y", ",", "tf", ".", "int32", ")", ",", "\n", "logits", "=", "logits", ")", "\n", "if", "self", ".", "_nbp", ":", "\n", "\n", "            ", "@", "tf", ".", "custom_gradient", "\n", "def", "nbp", "(", "x", ")", ":", "\n", "#pdb.set_trace()", "\n", "                ", "def", "grad", "(", "dy", ")", ":", "\n", "                    ", "I_theta", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", ")", "\n", "\n", "#tf.tensordot(tf.linalg.inv(I_theta),dy, axes=0) #tf.dot(tf.linalg.inv(I_theta),dy)", "\n", "#print_op = tf.Print(tf.shape(dy), [tf.shape(dy)])", "\n", "#with tf.control_dependencies([print_op]):", "\n", "#    return dy #tf.matmul(tf.diag(tf.linalg.inv(I_theta)), dy)", "\n", "#return tf.matmul(tf.linalg.inv(I_theta), dy)", "\n", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "return", "tf", ".", "matmul", "(", "I_theta", ",", "dy", ")", "\n", "\n", "", "return", "tf", ".", "identity", "(", "x", ")", ",", "grad", "\n", "\n", "", "loss_per_sample", "=", "nbp", "(", "loss_per_sample", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ")", "\n", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "y", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "\n", "# First panel will be at screen during training", "\n", "list_of_vpanels_of_plots", "=", "[", "\n", "[", "\n", "# {", "\n", "#     'nodes' : [loss],", "\n", "#     'names': [\"loss\"],", "\n", "#     'fileName' : \"loss\"", "\n", "# },", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "loss", "]", ",", "\n", "'names'", ":", "[", "\"ce\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"ce\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "accuracy", "]", ",", "\n", "'names'", ":", "[", "\"accuracy\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"accuracy\"", "}", "\n", "}", ",", "\n", "\n", "]", ",", "\n", "[", "\n", "{", "\n", "'nodes'", ":", "[", "1", "-", "accuracy", "]", ",", "\n", "'names'", ":", "[", "\"error\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"error\"", ",", "\"logscale-y\"", ":", "1", "}", "\n", "}", ",", "\n", "\n", "]", "\n", "]", "\n", "\n", "\n", "# nodes_to_log = [[1 - accuracy],", "\n", "#                 [accuracy]]", "\n", "# nodes_to_log_names = [[\"err\"], [\"acc\"]]", "\n", "# nodes_to_log_filenames = [{\"fileName\": \"error\", \"logscale-y\": 1},", "\n", "#                           {\"fileName\": \"accuracy\"}]", "\n", "\n", "\n", "if", "self", ".", "_multiclass_metrics", ":", "\n", "            ", "y_pred", "=", "tf", ".", "one_hot", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "n_labels", ")", "\n", "y_true", "=", "tf", ".", "one_hot", "(", "y", ",", "n_labels", ")", "\n", "f1_micro", ",", "f1_macro", ",", "f1_weighted", "=", "tf_f1_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "auc", ",", "auc_update", "=", "tf", ".", "metrics", ".", "auc", "(", "\n", "labels", "=", "tf", ".", "cast", "(", "y_true", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "predictions", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", ")", "\n", "\n", "raise", "Exception", "(", "\"set panels correctly here first!\"", ")", "\n", "\n", "# nodes_to_log += [[auc_update],", "\n", "#                 [f1_micro, f1_macro, f1_weighted]]", "\n", "#", "\n", "# nodes_to_log_names += [[\"auc\"], [\"f1_micro\", \"f1_macro\", \"f1_weighted\"]]", "\n", "# nodes_to_log_filenames += [", "\n", "#                             {\"fileName\": \"auc\"},", "\n", "#                             {\"fileName\": \"f1_score\"}", "\n", "#                             # {\"fileName\": \"f1_micro\"},", "\n", "#                             # {\"fileName\": \"f1_macro\"},", "\n", "#                             # {\"fileName\": \"f1_weighted\"}", "\n", "#                           ]", "\n", "\n", "", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "=", "create_panels_lists", "(", "list_of_vpanels_of_plots", ")", "\n", "\n", "return", "loss", ",", "loss_per_sample", ",", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.RenyiCostFunction.RenyiCostFunction.__init__": [[23, 28], ["VAECostFunction.VAECostFunction.VAECostFunction.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "binarized", ",", "synthetic", ",", "gaussian_model_observed", ",", "gaussian_model_latent", ")", ":", "\n", "        ", "VAECostFunction", ".", "__init__", "(", "self", ",", "binarized", ",", "synthetic", ")", "\n", "self", ".", "_gaussian_model_observed", "=", "gaussian_model_observed", "\n", "self", ".", "_gaussian_model_latent", "=", "gaussian_model_latent", "\n", "self", ".", "_cost_logger_class", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.RenyiCostFunction.RenyiCostFunction.compute": [[29, 69], ["RenyiCostFunction.RenyiCostFunction._gaussian_model_latent.log_pdf", "tensorflow.reshape", "tensorflow_probability.distributions.MultivariateNormalDiag()._log_prob", "tensorflow.reshape", "tensorflow.reduce_max", "RenyiCostFunction.RenyiCostFunction._gaussian_model_observed.log_pdf", "tensorflow.reshape", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "AssertionError", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow.reduce_mean", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.zeros", "tensorflow.ones", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "compute", "(", "self", ",", "alpha", ",", "x", ",", "x_replicate", ",", "x_reconstr_mean_samples", ",", "z", ")", ":", "\n", "        ", "\"\"\" implement Renyi cost function as in the paper Renyi Divergence Variational Inference,\n            formula [5], with alpha in (0, 1)\n            alpha = 0 => log p(x)\n            alpha -> 1 => KL lower bound\n        \"\"\"", "\n", "# log conditional p(x|z)", "\n", "if", "self", ".", "_binary", "==", "1", ":", "\n", "            ", "self", ".", "log_p_x_z", "=", "-", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "labels", "=", "x_replicate", ",", "\n", "logits", "=", "x_reconstr_mean_samples", ")", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "_synthetic", "==", "1", "\n", "self", ".", "log_p_x_z", "=", "self", ".", "_gaussian_model_observed", ".", "log_pdf", "(", "x_replicate", ")", "\n", "self", ".", "log_p_x_z", "=", "tf", ".", "reshape", "(", "self", ".", "log_p_x_z", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_s", "]", ")", "\n", "if", "not", "self", ".", "_synthetic", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Renyi bound not yet implemented for continuous real dataset (e.g. MNISTcontinuos\"", ")", "\n", "\n", "\n", "# TODO TO BE DELETED", "\n", "# ignore first parameter, which is the log_pdfs_latent", "\n", "#_, z = self._gaussian_model_latent.sampling(n_z_samples)", "\n", "\n", "# log posterior q(z|x)", "\n", "", "", "log_q_z_x", "=", "self", ".", "_gaussian_model_latent", ".", "log_pdf", "(", "z", ")", "\n", "log_q_z_x", "=", "tf", ".", "reshape", "(", "log_q_z_x", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_s", "]", ")", "\n", "\n", "# log prior p(z)", "\n", "n_z", "=", "self", ".", "_gaussian_model_latent", ".", "_n_z", "\n", "log_p_z", "=", "tfd", ".", "MultivariateNormalDiag", "(", "tf", ".", "zeros", "(", "n_z", ")", ",", "tf", ".", "ones", "(", "n_z", ")", ")", ".", "_log_prob", "(", "z", ")", "\n", "log_p_z", "=", "tf", ".", "reshape", "(", "log_p_z", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_s", "]", ")", "\n", "\n", "# exponent for Renyi expectation -- to avoid numerical issues we use exp of log", "\n", "# use log sum exp trick", "\n", "exponent", "=", "(", "1", "-", "alpha", ")", "*", "(", "self", ".", "log_p_x_z", "+", "log_p_z", "-", "log_q_z_x", ")", "\n", "max_exponent", "=", "tf", ".", "reduce_max", "(", "exponent", ",", "1", ",", "keep_dims", "=", "True", ")", "\n", "renyi_sum", "=", "tf", ".", "log", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "exp", "(", "exponent", "-", "max_exponent", ")", ",", "1", ")", ")", "+", "tf", ".", "reduce_mean", "(", "max_exponent", ",", "1", ")", "\n", "renyi_sum", "=", "-", "renyi_sum", "/", "(", "1", "-", "alpha", ")", "\n", "\n", "return", "renyi_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.__init__": [[22, 52], ["Calibrator.Calibrator.create_log_dir_name", "Calibrator.Calibrator.create_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.create_log_dir_name", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_session"], ["    ", "def", "__init__", "(", "self", ",", "ffconffile", ",", "global_step", ",", "method", ",", "covcal", ",", "flow_params", ",", "optimizer_tuple", ",", "ci_name", ",", "alpha", "=", "0", ",", "\n", "n_samples", "=", "1", ",", "sess", "=", "None", ",", "gpu", "=", "0", ",", "seed", "=", "100", ",", "base_dir", "=", "'/data1/calibration'", ")", ":", "\n", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "if", "sess", "is", "None", ":", "\n", "            ", "self", ".", "create_session", "(", "gpu", "=", "gpu", ",", "seed", "=", "seed", ")", "\n", "\n", "", "self", ".", "_log_dir", "=", "self", ".", "create_log_dir_name", "(", "base_dir", ",", "ffconffile", ",", "method", ",", "covcal", ",", "alpha", ",", "flow_params", ",", "optimizer_tuple", ")", "\n", "\n", "self", ".", "_optimizer_tuple", "=", "optimizer_tuple", "\n", "self", ".", "_optimizer_name", "=", "optimizer_tuple", "[", "0", "]", "\n", "self", ".", "_optimizer_kwargs", "=", "optimizer_tuple", "[", "1", "]", "\n", "self", ".", "_n_samples", "=", "n_samples", "\n", "\n", "self", ".", "_alpha_parameter", "=", "alpha", "\n", "self", ".", "_use_alpha", "=", "(", "alpha", "!=", "0", ")", "\n", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "covcal", "=", "covcal", "\n", "\n", "self", ".", "_flow_params", "=", "flow_params", "\n", "self", ".", "_ffconffile", "=", "ffconffile", "\n", "self", ".", "_global_step", "=", "global_step", "\n", "self", ".", "_gpu", "=", "gpu", "\n", "self", ".", "_seed", "=", "seed", "\n", "self", ".", "_base_dir", "=", "base_dir", "\n", "\n", "# CONFIDENCE INTERVAL", "\n", "self", ".", "_ci_class", "=", "ci_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.create_log_dir_name": [[54, 70], ["os.path.join", "ffconffile.split", "ffconffile.split", "argo.core.optimizers.TFOptimizers.TFOptimizers.create_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["", "def", "create_log_dir_name", "(", "self", ",", "base_dir", ",", "ffconffile", ",", "method", ",", "covcal", ",", "alpha_parameter", ",", "flow_params", ",", "optimizer_tuple", ")", ":", "\n", "        ", "dsname", "=", "ffconffile", ".", "split", "(", "'/'", ")", "[", "-", "3", "]", "\n", "ffname", "=", "ffconffile", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "base_dir", ",", "dsname", ",", "ffname", ",", "method", ",", "covcal", ")", "\n", "\n", "if", "flow_params", "is", "not", "None", ":", "\n", "            ", "log_dir", "+=", "\"-f\"", "+", "flow_params", "[", "'name'", "]", "\n", "log_dir", "+=", "\"_n{:d}\"", ".", "format", "(", "flow_params", "[", "'num_bijectors'", "]", ")", "\n", "log_dir", "+=", "\"_hc{:d}\"", ".", "format", "(", "flow_params", "[", "'hidden_channels'", "]", ")", "\n", "\n", "", "log_dir", "+=", "'_alpha_{}'", ".", "format", "(", "alpha_parameter", ")", "\n", "\n", "log_dir", "+=", "'-tr'", "+", "TFOptimizers", ".", "create_id", "(", "optimizer_tuple", ")", "\n", "\n", "return", "log_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.create_session": [[71, 81], ["tensorflow.set_random_seed", "tensorflow.ConfigProto", "tensorflow.Session"], "methods", ["None"], ["", "def", "create_session", "(", "self", ",", "gpu", "=", "0", ",", "seed", "=", "0", ")", ":", "\n", "# CREATE SESSION", "\n", "        ", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "# tf.reset_default_graph()", "\n", "\n", "os", ".", "environ", "[", "\"CUDA_DEVICE_ORDER\"", "]", "=", "\"PCI_BUS_ID\"", "\n", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "'{:d}'", ".", "format", "(", "gpu", ")", "\n", "sess_config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "sess_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "sess_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.release": [[82, 85], ["Calibrator.Calibrator.sess.close", "tensorflow.reset_default_graph"], "methods", ["None"], ["", "def", "release", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "close", "(", ")", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.prepare_for_calibration": [[86, 393], ["argo.core.TFDeepLearningModel.load_model_without_session", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "tensorflow.get_collection", "isinstance", "Calibrator.Calibrator.sess.run", "tensorflow.squeeze", "tensorflow.get_variable", "argo.core.optimizers.LearningRates.process_learning_rate", "Calibrator.Calibrator.prepare_training", "argo.core.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS", "Calibrator.load_ConfidenceIntervals_Class", "load_ConfidenceIntervals_Class.", "model._network.get_keras_losses", "tensorflow.add_n", "tensorflow.add_n", "tensorflow.get_collection", "Exception", "argo.core.flows.build_flow.build_flow", "Calibrator.Calibrator.prediction_distr.batch_shape_tensor", "tensorflow.get_variable", "calibration_variables_init.append", "calibration_variables_opt.append", "print", "pprint.pprint.pprint", "print", "tensorflow.get_collection", "print", "pprint.pprint.pprint", "print", "Calibrator.Calibrator.distr_for_calibration.sample", "tensorflow.reduce_sum", "tensorflow.get_collection", "Calibrator.create_mu_bar_sigma_bar", "tensorflow_probability.distributions.MultivariateNormalFullCovariance", "tensorflow_probability.distributions.MultivariateNormalTriL", "Exception", "tensorflow.variable_scope", "tensorflow_probability.distributions.TransformedDistribution", "tensorflow_probability.distributions.MultivariateNormalFullCovariance.sample", "tensorflow.initializers.constant", "tensorflow.initializers.constant", "Calibrator.create_tril_var", "calibration_variables_init.append", "Calibrator.create_mu_bar_sigma_bar", "tensorflow.einsum", "tensorflow_probability.distributions.MultivariateNormalFullCovariance", "tensorflow.linalg.trace", "tensorflow.cast", "calibration_variables_opt.append", "calibration_variables_opt.append", "calibration_variables_init.append", "print", "tensorflow.get_collection", "print", "pprint.pprint.pprint", "print", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.load_model_without_session", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.process_learning_rate", "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.prepare_training", "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.load_ConfidenceIntervals_Class", "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork.get_keras_losses", "home.repos.pwc.inspect_result.rist-ro_argo.flows.build_flow.build_flow", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.create_mu_bar_sigma_bar", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.create_tril_var", "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.create_mu_bar_sigma_bar"], ["", "def", "prepare_for_calibration", "(", "self", ",", "dataset_eval_names", "=", "[", "TRAIN", ",", "VALIDATION", ",", "TEST", "]", ",", "dataset_ci_names", "=", "[", "VALIDATION", ",", "TEST", "]", ",", "ci_period", "=", "30", ",", "**", "ci_kwargs", ")", ":", "\n", "\n", "# LOAD THE MODEL BUT NOT THE MONITORED SESSION SINCE WE WANT TO CONTROL THE SESSION", "\n", "        ", "model", ",", "dataset", ",", "checkpoint_name", "=", "load_model_without_session", "(", "self", ".", "_ffconffile", ",", "global_step", "=", "self", ".", "_global_step", ",", "model_class_base_path", "=", "\"core\"", ")", "\n", "# RESTORE THE WEIGHTS", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "None", ",", "max_to_keep", "=", "None", ",", "save_relative_paths", "=", "True", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "checkpoint_name", ")", "\n", "\n", "# INPUTS", "\n", "#before any form of preprocessing and augmentation (if present)", "\n", "self", ".", "raw_x", "=", "model", ".", "raw_x", "\n", "\n", "#when you will have noise, use model._x before tiling, instead of model.raw_x", "\n", "# self.x = tf.tile(self.raw_x, [self._n_samples, 1, 1, 1])", "\n", "self", ".", "x", "=", "model", ".", "x", "\n", "self", ".", "y", "=", "model", ".", "y", "\n", "\n", "self", ".", "argo_model", "=", "model", "\n", "self", ".", "_n_samples_ph", "=", "model", ".", "n_samples_ph", "\n", "\n", "# NETWORK", "\n", "network", "=", "model", ".", "_network", "\n", "\n", "self", ".", "n_batches_per_epoch", "=", "model", ".", "n_batches_per_epoch", "\n", "self", ".", "is_training", "=", "model", ".", "is_training", "\n", "\n", "#update batch renorm", "\n", "update_batch_renorm", "=", "False", "\n", "if", "self", ".", "method", "==", "'finetune'", ":", "\n", "            ", "update_batch_renorm", "=", "True", "\n", "\n", "", "self", ".", "extra_feed_kwargs_calibration", "=", "{", "self", ".", "is_training", ":", "update_batch_renorm", "}", "# consider setting this to false or not set it for calibrations which are not 'finetuning'", "\n", "# self.extra_feed_kwargs_calibration = {}", "\n", "\n", "wb_regularizers", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "\n", "if", "isinstance", "(", "network", ",", "KerasNetwork", ")", ":", "\n", "# FOR KERAS", "\n", "            ", "reg_losses", ",", "kl_losses", ",", "update_ops", "=", "model", ".", "_network", ".", "get_keras_losses", "(", "model", ".", "x", ")", "\n", "\n", "self", ".", "total_reg", "=", "tf", ".", "add_n", "(", "wb_regularizers", "+", "reg_losses", ",", "name", "=", "\"regularization\"", ")", "\n", "self", ".", "total_KL", "=", "tf", ".", "reduce_sum", "(", "kl_losses", ")", "/", "model", ".", "dataset", ".", "n_samples_train", "\n", "self", ".", "update_ops", "=", "update_ops", "+", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "\n", "net_model", "=", "model", ".", "_network", ".", "_net_model", "\n", "distr_model", "=", "model", ".", "_network", ".", "_distr_model", "\n", "model_had_flow", "=", "model", ".", "_network", ".", "_flow", "is", "not", "None", "\n", "\n", "", "else", ":", "\n", "# FOR SONNET", "\n", "            ", "distr_model", "=", "model", ".", "_network", ".", "module", ".", "_distr_model", "\n", "net_model", "=", "None", "# TODO implement for sonnet", "\n", "\n", "self", ".", "total_reg", "=", "tf", ".", "add_n", "(", "wb_regularizers", ",", "name", "=", "\"regularization\"", ")", "\n", "self", ".", "total_KL", "=", "0.", "\n", "self", ".", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "\n", "", "self", ".", "distr_model", "=", "distr_model", "\n", "self", ".", "net_model", "=", "net_model", "\n", "self", ".", "model_had_flow", "=", "model_had_flow", "\n", "if", "self", ".", "model_had_flow", "and", "self", ".", "covcal", "!=", "\"fix\"", ":", "\n", "            ", "raise", "Exception", "(", "\"If model had flows already, only fix covcal method is supported\"", ")", "\n", "\n", "", "self", ".", "calibration_tril", "=", "distr_model", ".", "calibration_tril", "\n", "self", ".", "calibration_tril_params", "=", "distr_model", ".", "_calibration_tril_params", "\n", "\n", "\n", "self", ".", "prediction_distr", "=", "model", ".", "prediction_distr", "\n", "\n", "self", ".", "distr_for_calibration", "=", "None", "\n", "self", ".", "variables_for_calibration", "=", "None", "\n", "\n", "# FLOW", "\n", "flow_size", "=", "self", ".", "y", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "_flow", "=", "None", "\n", "if", "self", ".", "_flow_params", "is", "not", "None", ":", "\n", "            ", "self", ".", "_flow", "=", "build_flow", "(", "self", ".", "_flow_params", ",", "flow_size", ")", "\n", "\n", "# DATASET SECTION", "\n", "", "self", ".", "datasets_initializers", "=", "model", ".", "datasets_initializers", "\n", "self", ".", "ds_handle", "=", "model", ".", "ds_handle", "\n", "self", ".", "datasets_handles", "=", "self", ".", "sess", ".", "run", "(", "model", ".", "datasets_handles_nodes", ")", "\n", "self", ".", "_parameters_list", "=", "model", ".", "dataset", ".", "_parameters_list", "\n", "\n", "#here we will set the variables to optimize on and the distribution for which optimize the nll likelihood", "\n", "# we will set", "\n", "# self.distr_for_calibration", "\n", "# self.variables_for_calibration", "\n", "# self.logger with the tensors to log", "\n", "# tensor_nodes to log", "\n", "method", "=", "self", ".", "method", "\n", "covcal", "=", "self", ".", "covcal", "\n", "\n", "dtype", "=", "self", ".", "prediction_distr", ".", "dtype", "\n", "# bs is actually bs * ns, if a differentiation is needed the bs must be taken by raw_x before tiling", "\n", "bs", "=", "self", ".", "prediction_distr", ".", "batch_shape_tensor", "(", ")", "[", "0", "]", "\n", "ps", "=", "self", ".", "prediction_distr", ".", "event_shape", "[", "0", "]", "\n", "\n", "calibration_variables_opt", "=", "[", "]", "\n", "calibration_variables_init", "=", "[", "]", "\n", "\n", "distr_for_calibration", "=", "None", "\n", "sc_cal", "=", "None", "\n", "distr_model", "=", "self", ".", "distr_model", "\n", "\n", "# huge if, it determines distr and vars for optimization (could be made more elegant with some classes...)", "\n", "if", "covcal", "==", "'scalar'", ":", "\n", "            ", "calibration_scalar", "=", "tf", ".", "get_variable", "(", "\"calibration_scalar\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "1.", ")", ")", "\n", "\n", "calibration_variables_init", ".", "append", "(", "calibration_scalar", ")", "\n", "calibration_variables_opt", ".", "append", "(", "calibration_scalar", ")", "\n", "\n", "if", "method", "==", "'mcsampling'", ":", "\n", "                ", "mu_bar", ",", "sigma_bar", "=", "create_mu_bar_sigma_bar", "(", "self", ".", "x", ",", "self", ".", "argo_model", ",", "bs", ",", "ps", ",", "nsamples", "=", "10", ")", "\n", "\n", "distr_for_calibration", "=", "tfp", ".", "distributions", ".", "MultivariateNormalFullCovariance", "(", "loc", "=", "mu_bar", ",", "\n", "covariance_matrix", "=", "calibration_scalar", "*", "sigma_bar", ")", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "model_loc", "=", "self", ".", "prediction_distr", ".", "parameters", "[", "\"loc\"", "]", "\n", "model_scale_tril", "=", "self", ".", "prediction_distr", ".", "parameters", "[", "\"scale_tril\"", "]", "\n", "\n", "distr_for_calibration", "=", "tfp", ".", "distributions", ".", "MultivariateNormalTriL", "(", "loc", "=", "model_loc", ",", "scale_tril", "=", "calibration_scalar", "*", "model_scale_tril", ")", "\n", "\n", "if", "method", "==", "'lastlayermu'", ":", "\n", "                    ", "last_layer_weights", "=", "distr_model", ".", "dense_loc", ".", "weights", "\n", "calibration_variables_opt", "+=", "last_layer_weights", "\n", "\n", "", "elif", "method", "==", "'lastlayer'", ":", "\n", "                    ", "last_layer_weights", "=", "distr_model", ".", "dense_loc", ".", "weights", "+", "distr_model", ".", "dense_diag_params", ".", "weights", "+", "distr_model", ".", "dense_out_of_diag_params", ".", "weights", "\n", "\n", "calibration_variables_opt", "+=", "last_layer_weights", "\n", "\n", "", "elif", "method", "==", "'finetune'", ":", "\n", "                    ", "last_layer_weights", "=", "distr_model", ".", "dense_loc", ".", "weights", "+", "distr_model", ".", "dense_diag_params", ".", "weights", "+", "distr_model", ".", "dense_out_of_diag_params", ".", "weights", "\n", "\n", "calibration_variables_opt", "+=", "last_layer_weights", "\n", "calibration_variables_opt", "+=", "self", ".", "net_model", ".", "trainable_variables", "\n", "\n", "", "", "sc_cal", "=", "calibration_scalar", "\n", "\n", "\n", "", "elif", "covcal", "==", "'tril'", "or", "covcal", "==", "'fix'", ":", "\n", "# we need to create a new tril variable only for mcsampling method", "\n", "            ", "if", "method", "==", "'mcsampling'", ":", "\n", "\n", "                ", "calibration_tril", ",", "calibration_tril_params", "=", "create_tril_var", "(", "ps", ",", "dtype", ")", "\n", "calibration_variables_init", ".", "append", "(", "calibration_tril_params", ")", "\n", "if", "covcal", "==", "'tril'", ":", "\n", "                    ", "calibration_variables_opt", ".", "append", "(", "calibration_tril_params", ")", "\n", "\n", "", "mu_bar", ",", "sigma_bar", "=", "create_mu_bar_sigma_bar", "(", "self", ".", "x", ",", "self", ".", "argo_model", ",", "bs", ",", "ps", ",", "nsamples", "=", "10", ")", "\n", "\n", "cal_sigma_bar", "=", "tf", ".", "einsum", "(", "'ih,bhk,jk->bij'", ",", "calibration_tril", ",", "sigma_bar", ",", "calibration_tril", ")", "\n", "\n", "distr_for_calibration", "=", "tfp", ".", "distributions", ".", "MultivariateNormalFullCovariance", "(", "loc", "=", "mu_bar", ",", "\n", "covariance_matrix", "=", "cal_sigma_bar", ")", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "distr_for_calibration", "=", "self", ".", "prediction_distr", "\n", "\n", "calibration_tril", "=", "distr_model", ".", "calibration_tril", "\n", "\n", "if", "covcal", "==", "'tril'", ":", "\n", "# if it is `tril` I want to optimize these, if it is `fix`, no.", "\n", "                    ", "calibration_tril_params", "=", "distr_model", ".", "_calibration_tril_params", "\n", "calibration_variables_opt", ".", "append", "(", "calibration_tril_params", ")", "\n", "calibration_variables_init", ".", "append", "(", "calibration_tril_params", ")", "\n", "\n", "", "if", "method", "==", "'lastlayermu'", ":", "\n", "                    ", "last_layer_weights", "=", "distr_model", ".", "dense_loc", ".", "weights", "\n", "calibration_variables_opt", "+=", "last_layer_weights", "\n", "\n", "", "elif", "method", "==", "'lastlayer'", ":", "\n", "                    ", "last_layer_weights", "=", "distr_model", ".", "dense_loc", ".", "weights", "+", "distr_model", ".", "dense_diag_params", ".", "weights", "+", "distr_model", ".", "dense_out_of_diag_params", ".", "weights", "\n", "\n", "calibration_variables_opt", "+=", "last_layer_weights", "\n", "\n", "", "elif", "method", "==", "'finetune'", ":", "\n", "                    ", "last_layer_weights", "=", "distr_model", ".", "dense_loc", ".", "weights", "+", "distr_model", ".", "dense_diag_params", ".", "weights", "+", "distr_model", ".", "dense_out_of_diag_params", ".", "weights", "\n", "\n", "calibration_variables_opt", "+=", "last_layer_weights", "\n", "calibration_variables_opt", "+=", "self", ".", "net_model", ".", "trainable_variables", "\n", "\n", "", "if", "self", ".", "model_had_flow", ":", "\n", "                    ", "print", "(", "\"\\n FOUND FLOW I will recalibrate flow \\n\"", ")", "\n", "flow_name", "=", "model", ".", "_network", ".", "_flow_params", "[", "'name'", "]", "\n", "if", "flow_name", "==", "\"NVP\"", ":", "\n", "                        ", "flow_scope", "=", "\"real_nvp_default_template\"", "\n", "", "elif", "flow_name", "in", "[", "\"IAF\"", ",", "\"MAF\"", "]", ":", "\n", "                        ", "flow_scope", "=", "\"masked_autoregressive_default_template\"", "\n", "", "else", ":", "\n", "                        ", "raise", "Exception", "(", "\"Don't know this flow: `{:}`  not supported\"", ".", "format", "(", "flow_name", ")", ")", "\n", "\n", "", "_flow_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "flow_scope", ")", "\n", "\n", "if", "not", "_flow_vars", ":", "\n", "                        ", "raise", "Exception", "(", "\"Could not find variables for model flow\"", ")", "\n", "\n", "", "print", "(", "\"found flow variables:\"", ")", "\n", "pprint", "(", "_flow_vars", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n", "# don't reinitialize", "\n", "calibration_variables_opt", "+=", "_flow_vars", "\n", "\n", "", "", "sc_cal", "=", "tf", ".", "linalg", ".", "trace", "(", "calibration_tril", ")", "/", "tf", ".", "cast", "(", "ps", ",", "tf", ".", "float32", ")", "\n", "#np.save(log_dir+'calibration_tril.npy',calibration_tril)", "\n", "\n", "\n", "# TODO TEST create two optimizers, one for the \"calibration handle\" (scalar or tril) and another one for \"other calibration variables\"", "\n", "\n", "", "self", ".", "calibration_variables_init", "=", "calibration_variables_init", "\n", "self", ".", "calibration_variables_opt", "=", "calibration_variables_opt", "#[n for n in calibration_variables_opt if not('calibration' in n.name)] # calibration_variables_opt", "\n", "\n", "# apply calibration flow if needed", "\n", "if", "self", ".", "_flow", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "model_had_flow", ":", "\n", "                ", "raise", "Exception", "(", "\"model had flow already, apply additional flow is not yet supported.\"", ")", "\n", "\n", "", "print", "(", "\"\\n ADDING FLOW I will calibrate with `{:}` flow\\n\"", ".", "format", "(", "self", ".", "_flow_params", "[", "\"name\"", "]", ")", ")", "\n", "pprint", "(", "self", ".", "_flow_params", ")", "\n", "print", "(", "\"\"", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'flow'", ")", ":", "\n", "                ", "distr_for_calibration", "=", "tfp", ".", "distributions", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "distr_for_calibration", ",", "\n", "bijector", "=", "self", ".", "_flow", ")", "\n", "#it is needed to instantiate the variables, because I need to collect variables to initialize the afterwards", "\n", "distr_for_calibration", ".", "sample", "(", "1", ")", "\n", "\n", "", "_flow_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "'flow'", ")", "\n", "print", "(", "\"found flow variables:\"", ")", "\n", "pprint", "(", "_flow_vars", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n", "self", ".", "calibration_variables_init", "+=", "_flow_vars", "\n", "self", ".", "calibration_variables_opt", "+=", "_flow_vars", "\n", "\n", "", "self", ".", "distr_for_calibration", "=", "distr_for_calibration", "\n", "self", ".", "distr_sample", "=", "tf", ".", "squeeze", "(", "self", ".", "distr_for_calibration", ".", "sample", "(", "1", ")", ",", "axis", "=", "0", ")", "\n", "\n", "# no need of these, pass directly distr_for_calibration to ConfidenceIntervals Class", "\n", "# self.sample_dis=self.distr_for_calibration.sample()", "\n", "# self.mean_dis=self.distr_for_calibration.mean()", "\n", "# self.var_dis=self.distr_for_calibration.variance()", "\n", "# self.covar_dis=self.distr_for_calibration.covariance()", "\n", "\n", "\n", "# DEFINE LOSS and OPTIMIZER", "\n", "# self._global_step_restore_int = sess.run(model.global_step)", "\n", "self", ".", "cal_global_step", "=", "tf", ".", "get_variable", "(", "\"cal_global_step\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "dtype", "=", "tf", ".", "int64", ",", "\n", "trainable", "=", "False", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0", ")", ")", "\n", "\n", "lr", "=", "process_learning_rate", "(", "self", ".", "_optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "self", ".", "cal_global_step", ")", "\n", "self", ".", "_optimizer_kwargs", "[", "\"learning_rate\"", "]", "=", "lr", "\n", "\n", "self", ".", "cal_loss", ",", "self", ".", "nll", ",", "self", ".", "training_op", ",", "self", ".", "optimizer", ",", "self", ".", "optimizer_variables", "=", "self", ".", "prepare_training", "(", "self", ".", "distr_for_calibration", ",", "\n", "self", ".", "y", ",", "\n", "self", ".", "_optimizer_tuple", ",", "\n", "self", ".", "cal_global_step", ",", "\n", "self", ".", "calibration_variables_opt", ")", "\n", "\n", "self", ".", "sc_cal", "=", "sc_cal", "\n", "self", ".", "lr", "=", "lr", "\n", "tensors_nodes", "=", "[", "self", ".", "cal_loss", ",", "self", ".", "nll", ",", "sc_cal", ",", "lr", "]", "\n", "tensors_names", "=", "[", "\"cal_loss\"", ",", "\"nll\"", ",", "\"sc_cal\"", ",", "\"lr\"", "]", "\n", "\n", "self", ".", "logger", "=", "LoggerHelperMultiDS", "(", "self", ".", "_log_dir", ",", "\"calibration\"", ",", "\n", "tensors_names", ",", "\n", "tensors_nodes", ",", "\n", "self", ".", "ds_handle", ",", "\n", "self", ".", "datasets_initializers", ",", "\n", "self", ".", "datasets_handles", ",", "\n", "dataset_eval_names", ")", "\n", "\n", "self", ".", "dataset_ci_names", "=", "dataset_ci_names", "\n", "self", ".", "ci_period", "=", "ci_period", "\n", "# create the nodes for sampling etcetera", "\n", "CI_Class", "=", "load_ConfidenceIntervals_Class", "(", "self", ".", "_ci_class", ")", "\n", "self", ".", "ci_obj", "=", "CI_Class", "(", "self", ".", "_log_dir", ",", "\n", "self", ".", "datasets_initializers", ",", "\n", "self", ".", "datasets_handles", ",", "\n", "self", ".", "ds_handle", ",", "\n", "self", ".", "_n_samples_ph", ",", "\n", "self", ".", "distr_sample", ",", "\n", "self", ".", "raw_x", ",", "\n", "self", ".", "x", ",", "\n", "self", ".", "y", ",", "\n", "self", ".", "_parameters_list", ",", "\n", "**", "ci_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.prepare_training": [[395, 434], ["tensorflow.shape", "tensorflow.tile", "tensorflow.reduce_mean", "argo.core.utils.argo_utils.eval_method_from_tuple", "Calibrator.create_training_op", "argo.core.utils.argo_utils.eval_method_from_tuple.variables", "distr.log_prob", "tensorflow.scalar_mul", "tensorflow.reshape", "tensorflow.reduce_logsumexp", "tensorflow.scalar_mul", "tensorflow.reshape", "tensorflow.reduce_mean", "distr.log_prob", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.create_training_op", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "prepare_training", "(", "self", ",", "distr", ",", "y", ",", "optimizer_tuple", ",", "global_step", ",", "var_list", ")", ":", "\n", "\n", "        ", "shaper", "=", "tf", ".", "shape", "(", "y", ")", "\n", "y_tile", "=", "tf", ".", "tile", "(", "y", ",", "[", "self", ".", "_n_samples_ph", ",", "1", "]", ")", "\n", "nll_batch", "=", "-", "distr", ".", "log_prob", "(", "y_tile", ")", "\n", "\n", "# if self._use_alpha:", "\n", "#     if self._alpha_parameter !=0:", "\n", "#         loss_per_minibatch = tf.scalar_mul(self._alpha_parameter,distr.log_prob(y_tile))", "\n", "#         #import pdb; pdb.set_trace()", "\n", "#         loss_per_minibatch_reshaped=tf.reshape(loss_per_minibatch, (self._n_samples_ph, shaper[0]))", "\n", "#         loss_per_minibatch_avg=tf.reduce_logsumexp(loss_per_minibatch_reshaped,axis=0)", "\n", "#         loss_per_sample=tf.scalar_mul(-1./self._alpha_parameter,loss_per_minibatch_avg)", "\n", "#     else:", "\n", "#         loss_per_minibatch = nll_batch", "\n", "#         loss_per_minibatch_reshaped = tf.reshape(loss_per_minibatch, (self._n_samples_ph, shaper[0]))", "\n", "#         loss_per_sample=tf.reduce_mean(loss_per_minibatch_reshaped,axis=0)", "\n", "#", "\n", "# else:", "\n", "#     loss_per_sample = nll_batch", "\n", "\n", "if", "self", ".", "_use_alpha", "and", "self", ".", "_alpha_parameter", "!=", "0", ":", "\n", "            ", "loss_per_minibatch", "=", "tf", ".", "scalar_mul", "(", "self", ".", "_alpha_parameter", ",", "distr", ".", "log_prob", "(", "y_tile", ")", ")", "\n", "loss_per_minibatch_reshaped", "=", "tf", ".", "reshape", "(", "loss_per_minibatch", ",", "(", "self", ".", "_n_samples_ph", ",", "shaper", "[", "0", "]", ")", ")", "\n", "loss_per_minibatch_avg", "=", "tf", ".", "reduce_logsumexp", "(", "loss_per_minibatch_reshaped", ",", "axis", "=", "0", ")", "\n", "loss_per_sample", "=", "tf", ".", "scalar_mul", "(", "-", "1.", "/", "self", ".", "_alpha_parameter", ",", "loss_per_minibatch_avg", ")", "\n", "", "else", ":", "\n", "            ", "loss_per_minibatch", "=", "nll_batch", "\n", "loss_per_minibatch_reshaped", "=", "tf", ".", "reshape", "(", "loss_per_minibatch", ",", "(", "self", ".", "_n_samples_ph", ",", "shaper", "[", "0", "]", ")", ")", "\n", "loss_per_sample", "=", "tf", ".", "reduce_mean", "(", "loss_per_minibatch_reshaped", ",", "axis", "=", "0", ")", "\n", "\n", "", "cal_loss", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ",", "name", "=", "\"cal_loss\"", ")", "+", "self", ".", "total_KL", "+", "self", ".", "total_reg", "\n", "\n", "nll", "=", "tf", ".", "reduce_mean", "(", "nll_batch", ",", "name", "=", "\"nll\"", ")", "\n", "#cal_nll = tf.reduce_mean(-distr.log_prob(y), name=\"nll\")", "\n", "optimizer", "=", "eval_method_from_tuple", "(", "tf", ".", "train", ",", "optimizer_tuple", ")", "\n", "training_op", "=", "create_training_op", "(", "optimizer", ",", "cal_loss", ",", "global_step", ",", "var_list", "=", "var_list", ",", "update_ops", "=", "self", ".", "update_ops", ")", "\n", "optimizer_variables", "=", "optimizer", ".", "variables", "(", ")", "\n", "return", "cal_loss", ",", "nll", ",", "training_op", ",", "optimizer", ",", "optimizer_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.calibrate": [[437, 468], ["sess.run", "sess.run", "Calibrator.Calibrator.logger.reset", "print", "tqdm.tqdm.tqdm", "tensorflow.variables_initializer", "tensorflow.variables_initializer", "range", "Calibrator.Calibrator.make_one_epoch", "Calibrator.Calibrator.logger.log", "Calibrator.Calibrator.logger.reset", "Calibrator.Calibrator.logger.plot_groupby", "Calibrator.Calibrator.logger.plot_groupby", "Calibrator.Calibrator.logger.plot", "Calibrator.Calibrator.logger.plot", "Calibrator.Calibrator.ci_obj.do_when_triggered"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.reset", "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.make_one_epoch", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.reset", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.plot_groupby", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.plot_groupby", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook.do_when_triggered"], ["", "def", "calibrate", "(", "self", ",", "nepochs", "=", "30", ",", "sess", "=", "None", ")", ":", "\n", "\n", "        ", "if", "sess", "is", "None", ":", "\n", "            ", "sess", "=", "self", ".", "sess", "\n", "\n", "", "sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "self", ".", "optimizer_variables", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "[", "self", ".", "cal_global_step", "]", "+", "self", ".", "calibration_variables_init", ")", ")", "\n", "\n", "\n", "#TRAINING LOOP FOR CALIBRATION", "\n", "# sess_extra_args = self.logger.get_sess_run_args()", "\n", "self", ".", "logger", ".", "reset", "(", "sess", ")", "\n", "\n", "print", "(", "\"calibrating: {:}\"", ".", "format", "(", "self", ".", "_log_dir", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "nepochs", ")", ",", "\"calibrating\"", ",", "dynamic_ncols", "=", "True", ")", ":", "\n", "\n", "# self.make_one_epoch_loop(self.training_op, [], extra_feed_kwargs = self.extra_feed_kwargs_calibration)", "\n", "            ", "self", ".", "make_one_epoch", "(", "self", ".", "training_op", ",", "[", "]", ",", "TRAIN_SHUFFLED", ",", "extra_feed_kwargs", "=", "self", ".", "extra_feed_kwargs_calibration", ")", "\n", "\n", "# for DATASET_STR in calibration_datasets:", "\n", "#     self.make_one_epoch(self.training_op, [], DATASET_STR, extra_feed_kwargs = self.extra_feed_kwargs_calibration)", "\n", "\n", "#every n steps do mcmc", "\n", "self", ".", "logger", ".", "log", "(", "sess", ",", "i", "+", "1", ")", "\n", "self", ".", "logger", ".", "reset", "(", "sess", ")", "\n", "self", ".", "logger", ".", "plot_groupby", "(", "'dataset'", ",", "suffix", "=", "\"nll\"", ",", "x", "=", "'epoch'", ",", "y", "=", "'nll'", ")", "\n", "self", ".", "logger", ".", "plot_groupby", "(", "'dataset'", ",", "suffix", "=", "\"cal_loss\"", ",", "x", "=", "'epoch'", ",", "y", "=", "'cal_loss'", ")", "\n", "self", ".", "logger", ".", "plot", "(", "suffix", "=", "'sc_cal'", ",", "x", "=", "'epoch'", ",", "y", "=", "'sc_cal'", ")", "\n", "self", ".", "logger", ".", "plot", "(", "suffix", "=", "'lr'", ",", "x", "=", "'epoch'", ",", "y", "=", "'lr'", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "self", ".", "ci_period", "==", "0", ":", "\n", "                ", "self", ".", "ci_obj", ".", "do_when_triggered", "(", "sess", ",", "self", ".", "dataset_ci_names", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.make_one_epoch": [[470, 491], ["sess.run", "sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "", "def", "make_one_epoch", "(", "self", ",", "training_op", ",", "nodes", ",", "DATASET_STR", ",", "extra_feed_kwargs", "=", "{", "}", ",", "sess", "=", "None", ")", ":", "\n", "        ", "if", "sess", "is", "None", ":", "\n", "            ", "sess", "=", "self", ".", "sess", "\n", "\n", "", "sess", ".", "run", "(", "self", ".", "datasets_initializers", "[", "DATASET_STR", "]", ")", "\n", "# pbar = tqdm(desc='make one epoch')", "\n", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "_", ",", "nodes_np", "=", "sess", ".", "run", "(", "[", "training_op", ",", "\n", "nodes", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "ds_handle", ":", "self", ".", "datasets_handles", "[", "DATASET_STR", "]", ",", "\n", "self", ".", "_n_samples_ph", ":", "self", ".", "_n_samples", ",", "\n", "**", "extra_feed_kwargs", "\n", "}", "\n", ")", "\n", "# pbar.update(1)", "\n", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.Calibrator.make_one_epoch_loop": [[492, 504], ["range", "sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "", "def", "make_one_epoch_loop", "(", "self", ",", "training_op", ",", "nodes", ",", "extra_feed_kwargs", "=", "{", "}", ",", "sess", "=", "None", ")", ":", "\n", "        ", "if", "sess", "is", "None", ":", "\n", "            ", "sess", "=", "self", ".", "sess", "\n", "\n", "# pbar = tqdm(desc='make one epoch')", "\n", "", "for", "step", "in", "range", "(", "self", ".", "n_batches_per_epoch", ")", ":", "\n", "            ", "_", ",", "nodes_np", "=", "sess", ".", "run", "(", "[", "training_op", ",", "\n", "nodes", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "ds_handle", ":", "self", ".", "datasets_handles", "[", "TRAIN_LOOP", "]", ",", "\n", "self", ".", "_n_samples_ph", ":", "self", ".", "_n_samples", ",", "\n", "**", "extra_feed_kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.create_tril_var": [[508, 521], ["int", "int", "tensorflow.get_variable", "tensorflow.contrib.distributions.fill_triangular", "tensorflow.initializers.constant"], "function", ["None"], ["", "", "", "def", "create_tril_var", "(", "output_size", ",", "dtype", ")", ":", "\n", "    ", "output_size", "=", "output_size", ".", "value", "\n", "n_out_of_diag_elems", "=", "int", "(", "output_size", "*", "(", "output_size", "-", "1", ")", "/", "2", ")", "\n", "\n", "n_tril", "=", "int", "(", "n_out_of_diag_elems", "+", "output_size", ")", "\n", "calibration_tril_params", "=", "tf", ".", "get_variable", "(", "\"calibration_tril_params\"", ",", "\n", "shape", "=", "(", "n_tril", ",", ")", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "value", "=", "1.", ")", ")", "\n", "\n", "calibration_tril", "=", "tf", ".", "contrib", ".", "distributions", ".", "fill_triangular", "(", "calibration_tril_params", ",", "\n", "name", "=", "\"calibration_tril\"", ")", "\n", "return", "calibration_tril", ",", "calibration_tril_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.create_mu_bar_sigma_bar": [[522, 532], ["tensorflow.tile", "model._network", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow_probability.stats.covariance", "tensorflow.ensure_shape", "model._network.sample"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "create_mu_bar_sigma_bar", "(", "x", ",", "model", ",", "bs", ",", "ps", ",", "nsamples", "=", "3", ")", ":", "\n", "    ", "x_repeat", "=", "tf", ".", "tile", "(", "x", ",", "[", "nsamples", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "repeated_distr", "=", "model", ".", "_network", "(", "x_repeat", ",", "is_training", "=", "model", ".", "is_training", ")", "\n", "repeated_sample", "=", "tf", ".", "reshape", "(", "repeated_distr", ".", "sample", "(", ")", ",", "[", "nsamples", ",", "bs", ",", "ps", "]", ")", "\n", "mu_bar", "=", "tf", ".", "reduce_mean", "(", "repeated_sample", ",", "axis", "=", "0", ")", "\n", "sigma_bar", "=", "tfp", ".", "stats", ".", "covariance", "(", "repeated_sample", ",", "sample_axis", "=", "0", ",", "event_axis", "=", "-", "1", ")", "\n", "\n", "sigma_bar", "=", "tf", ".", "ensure_shape", "(", "sigma_bar", ",", "[", "None", ",", "ps", ",", "ps", "]", ")", "\n", "\n", "return", "mu_bar", ",", "sigma_bar", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.create_training_op": [[533, 551], ["optimizer.compute_gradients", "tensorflow.clip_by_global_norm", "optimizer.apply_gradients", "tensorflow.group", "tensorflow.group", "range", "len"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.apply_gradients"], ["", "def", "create_training_op", "(", "optimizer", ",", "total_loss", ",", "global_step", ",", "var_list", "=", "None", ",", "update_ops", "=", "[", "]", ",", "clip_value", "=", "100", ")", ":", "\n", "# 1st part of minimize: compute_gradient", "\n", "#TODO check var_list is what we expect", "\n", "    ", "grads_and_vars", "=", "optimizer", ".", "compute_gradients", "(", "total_loss", ",", "var_list", "=", "var_list", ")", "\n", "\n", "# clip gradients", "\n", "grads_and_vars_not_none", "=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "grads", "=", "[", "g", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "variables", "=", "[", "v", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "clipped_grads", ",", "global_norm", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "clip_value", ")", "\n", "clipped_grads_and_vars", "=", "[", "(", "clipped_grads", "[", "i", "]", ",", "variables", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "grads", ")", ")", "]", "\n", "\n", "# 2nd part of minimize: apply_gradient", "\n", "optimizer_step", "=", "optimizer", ".", "apply_gradients", "(", "clipped_grads_and_vars", ",", "global_step", "=", "global_step", ")", "\n", "\n", "update_ops", "=", "tf", ".", "group", "(", "*", "update_ops", ")", "\n", "training_op", "=", "tf", ".", "group", "(", "update_ops", ",", "optimizer_step", ")", "\n", "return", "training_op", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Calibrator.load_ConfidenceIntervals_Class": [[552, 555], ["importlib.import_module", "getattr", "__name__.split"], "function", ["None"], ["", "def", "load_ConfidenceIntervals_Class", "(", "class_name", ")", ":", "\n", "    ", "module", "=", "importlib", ".", "import_module", "(", "\".hooks.\"", "+", "class_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "return", "getattr", "(", "module", ",", "class_name", ")", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAECostFunction.WavenetAECostFunction.__init__": [[8, 11], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"WNAE_L2\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAECostFunction.WavenetAECostFunction.create_id": [[12, 16], ["None"], "methods", ["None"], ["", "def", "create_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "self", ".", "name", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAECostFunction.WavenetAECostFunction._build": [[17, 28], ["tensorflow.squeeze", "tensorflow.reduce_mean", "tensorflow.cast", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "wavenet_ae", ")", ":", "\n", "\n", "# x_indices = tf.cast(tf.reshape(wavenet_ae._network.x_quantized, [-1]), tf.int32) + 128", "\n", "        ", "x_indices", "=", "tf", ".", "cast", "(", "wavenet_ae", ".", "_network", ".", "x_quantized", ",", "tf", ".", "int32", ")", "+", "128", "\n", "x_indices", "=", "tf", ".", "squeeze", "(", "x_indices", ",", "axis", "=", "-", "1", ")", "\n", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "wavenet_ae", ".", "x_reconstruction_logits_tf", ",", "labels", "=", "x_indices", ",", "\n", "name", "=", "'nll'", ")", ",", "name", "=", "'loss'", ")", "\n", "\n", "return", "loss", ",", "[", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAECostFunction.WavenetAECostFunction.loss_per_sample": [[29, 36], ["tensorflow.cast", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "loss_per_sample", "(", "self", ",", "reconstr_logits", ",", "x_target_quantized", ")", ":", "\n", "        ", "x_target_quantized", "=", "tf", ".", "cast", "(", "x_target_quantized", ",", "tf", ".", "int32", ")", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "reconstr_logits", ",", "\n", "labels", "=", "x_target_quantized", ",", "\n", "name", "=", "'nll'", ")", "\n", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.LatentTraversalsHook.LatentTraversalsHook.__init__": [[16, 40], ["argo.core.hooks.EveryNEpochsTFModelImagesHook.EveryNEpochsTFModelImagesHook.__init__", "tf_logging.info", "LatentTraversalsHook.LatentTraversalsHook._images_indexes.items", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "images_indexes", ",", "\n", "n_images_columns", ",", "\n", "radius", ",", "\n", "step", ",", "\n", "dirName", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "+", "'/latent_traversals'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dirName", "=", "self", ".", "_dirName", ")", "\n", "\n", "self", ".", "_fileName", "=", "\"latent_traversal\"", "\n", "\n", "self", ".", "_images_indexes", "=", "images_indexes", "\n", "self", ".", "_n_images_columns", "=", "n_images_columns", "\n", "self", ".", "_radius", "=", "radius", "\n", "self", ".", "_step", "=", "step", "\n", "tf_logging", ".", "info", "(", "\"Create LatentTraversalsHook for: \\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "ds_key", "+", "\": \"", "+", "\", \"", ".", "join", "(", "map", "(", "str", ",", "idxs", ")", ")", "for", "ds_key", ",", "idxs", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.LatentTraversalsHook.LatentTraversalsHook.load_images": [[41, 51], ["datasets.Dataset.check_dataset_keys_not_loop", "list", "LatentTraversalsHook.LatentTraversalsHook._images_indexes.keys", "LatentTraversalsHook.LatentTraversalsHook._model.dataset.get_elements", "LatentTraversalsHook.LatentTraversalsHook._images_indexes.items"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements"], ["", "def", "load_images", "(", "self", ",", "session", ")", ":", "\n", "        ", "check_dataset_keys_not_loop", "(", "list", "(", "self", ".", "_images_indexes", ".", "keys", "(", ")", ")", ")", "\n", "\n", "images", "=", "{", "ds_key", ":", "(", "index_list", ",", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "x", ",", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "\n", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "session", ",", "\n", "index_list", ")", ")", "for", "(", "ds_key", ",", "index_list", ")", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "_images", "=", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.LatentTraversalsHook.LatentTraversalsHook.do_when_triggered": [[52, 93], ["tf_logging.info", "LatentTraversalsHook.LatentTraversalsHook.load_images", "numpy.arange", "numpy.concatenate", "numpy.zeros", "range", "LatentTraversalsHook.LatentTraversalsHook._images_indexes.items", "LatentTraversalsHook.LatentTraversalsHook._model._gaussian_model_latent.batch_shape.as_list", "enumerate", "LatentTraversalsHook.LatentTraversalsHook._model.encode", "numpy.repeat", "LatentTraversalsHook.LatentTraversalsHook._model.decode", "list", "reconstructed_images.reshape.reshape.reshape", "argo.core.utils.ImagesSaver.ImagesSaver", "argo.core.utils.ImagesSaver.ImagesSaver.save_images", "numpy.flip", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_images", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for LatentTraversalsHook\"", ")", "\n", "\n", "self", ".", "load_images", "(", "run_context", ".", "session", ")", "\n", "\n", "# create values to be added to latent variables", "\n", "offset_range", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "_radius", "+", "1", ")", "\n", "half_offsets", "=", "offset_range", "*", "self", ".", "_step", "\n", "offsets", "=", "np", ".", "concatenate", "(", "[", "-", "np", ".", "flip", "(", "half_offsets", ")", ",", "[", "0", "]", ",", "half_offsets", "]", ")", "\n", "z_dim", "=", "self", ".", "_model", ".", "_gaussian_model_latent", ".", "batch_shape", ".", "as_list", "(", ")", "[", "1", "]", "\n", "num_traversals", "=", "offsets", ".", "shape", "[", "0", "]", "\n", "\n", "offset_matrix", "=", "np", ".", "zeros", "(", "[", "num_traversals", "*", "z_dim", ",", "z_dim", "]", ")", "\n", "for", "i", "in", "range", "(", "z_dim", ")", ":", "\n", "            ", "offset_matrix", "[", "i", "*", "num_traversals", ":", "(", "i", "+", "1", ")", "*", "num_traversals", ",", "i", "]", "=", "offsets", "\n", "\n", "\n", "", "for", "(", "ds_key", ",", "index_list", ")", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", ":", "\n", "            ", "for", "cnt", ",", "img_idx", "in", "enumerate", "(", "index_list", ")", ":", "\n", "                ", "image", "=", "self", ".", "_images", "[", "ds_key", "]", "[", "1", "]", "[", "None", ",", "cnt", ",", "...", "]", "\n", "\n", "encodings", "=", "self", ".", "_model", ".", "encode", "(", "image", ",", "run_context", ".", "session", ")", "\n", "# change the means and decode without sampling", "\n", "means", "=", "encodings", "[", "1", "]", "\n", "\n", "tiled_means", "=", "np", ".", "repeat", "(", "means", ",", "num_traversals", "*", "z_dim", ",", "axis", "=", "0", ")", "\n", "\n", "traversal_means", "=", "tiled_means", "+", "offset_matrix", "\n", "\n", "reconstructed_images", "=", "self", ".", "_model", ".", "decode", "(", "traversal_means", ",", "run_context", ".", "session", ")", "\n", "all_dims_but_first", "=", "list", "(", "reconstructed_images", ".", "shape", "[", "1", ":", "]", ")", "\n", "reconstructed_images", "=", "reconstructed_images", ".", "reshape", "(", "[", "z_dim", ",", "num_traversals", "]", "+", "all_dims_but_first", ")", "\n", "\n", "images_saver", "=", "ImagesSaver", "(", "self", ".", "_dirName", ")", "\n", "\n", "images_saver", ".", "save_images", "(", "reconstructed_images", ",", "\n", "fileName", "=", "\"latent_traversal_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "\n", "self", ".", "_time_ref_shortstr", "+", "\"_\"", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "+", "\"_idx_\"", "+", "\n", "str", "(", "img_idx", ")", ",", "\n", "title", "=", "self", ".", "_fileName", ",", "\n", "fontsize", "=", "9", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.SR.SR.__init__": [[10, 15], ["argo.core.Network.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "samples", "=", "1000", ",", "baseline", "=", "0", ",", "name", "=", "\"SR\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_samples", "=", "samples", "\n", "self", ".", "_baseline", "=", "baseline", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.SR.SR.create_id": [[16, 19], ["str", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "        ", "return", "\"SR_s\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"samples\"", "]", ")", "+", "\"_\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"baseline\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.SR.SR._build": [[20, 66], ["tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.clip_by_value", "tensorflow.norm", "model_visible.log_prob", "tensorflow.reduce_sum", "tensorflow.python.ops.array_ops.stop_gradient", "tensorflow.multiply", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.norm", "tensorflow.reduce_prod", "model_visible.sample", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "_build", "(", "self", ",", "ae", ")", ":", "\n", "\n", "        ", "model_visible", "=", "ae", ".", "_model_visible", "\n", "x_target", "=", "ae", ".", "x_target", "\n", "reconstruction", "=", "ae", ".", "x_reconstruction_node", "\n", "\n", "# this has changed since some models can feed data with different shapes for train and eval", "\n", "# x_shape is also a dict alternatively... if this break ask me.. (Riccardo)", "\n", "# dims = np.prod(ae.x_shape)", "\n", "dims", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "self", ".", "raw_x", ")", "[", "1", ":", "]", ")", ",", "\n", "tf", ".", "float32", ")", "\n", "# dims = np.prod(ae.x_shape[\"train\"])", "\n", "\n", "# sample", "\n", "x_prime", "=", "tf", ".", "cast", "(", "model_visible", ".", "sample", "(", "sample_shape", "=", "[", "self", ".", "_samples", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "x_target", "=", "tf", ".", "cast", "(", "x_target", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "#x_prime = tf.check_numerics(x_prime, \"x_prime is not finite\")", "\n", "#x_target = tf.check_numerics(x_target, \"x_target is not finite\")", "\n", "\n", "x_prime", "=", "tf", ".", "clip_by_value", "(", "x_prime", ",", "NUMTOL", ",", "1", "-", "NUMTOL", ")", "\n", "\n", "norm", "=", "tf", ".", "norm", "(", "tf", ".", "reshape", "(", "x_target", "-", "x_prime", ",", "[", "self", ".", "_samples", ",", "-", "1", ",", "dims", "]", ")", ",", "axis", "=", "2", ")", "\n", "\n", "all_log_probs", "=", "model_visible", ".", "log_prob", "(", "x_prime", ")", "\n", "#all_log_probs = tf.check_numerics(all_log_probs, \"all_log_probs is not finite\")", "\n", "\n", "log_likelihood", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "reshape", "(", "all_log_probs", ",", "[", "self", ".", "_samples", ",", "-", "1", ",", "ae", ".", "x_shape", "[", "0", "]", ",", "ae", ".", "x_shape", "[", "1", "]", "]", ")", ",", "axis", "=", "[", "2", ",", "3", "]", ")", "\n", "#log_likelihood = tf.check_numerics(log_likelihood, \"log_likelihood is not finite\")", "\n", "\n", "if", "self", ".", "_baseline", ":", "\n", "            ", "loss_factor", "=", "norm", "-", "tf", ".", "reduce_mean", "(", "norm", ",", "axis", "=", "0", ")", "# subtract baseline", "\n", "", "else", ":", "\n", "            ", "loss_factor", "=", "norm", "\n", "\n", "", "loss_factor", "=", "array_ops", ".", "stop_gradient", "(", "loss_factor", ")", "\n", "loss_batch", "=", "tf", ".", "multiply", "(", "log_likelihood", ",", "loss_factor", ")", "\n", "\n", "mean_per_reconstructions", "=", "tf", ".", "reduce_mean", "(", "loss_batch", ",", "axis", "=", "1", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "mean_per_reconstructions", ")", "\n", "\n", "# compute true cost function (L2)", "\n", "norms", "=", "tf", ".", "norm", "(", "tf", ".", "reshape", "(", "x_target", "-", "reconstruction", ",", "[", "-", "1", ",", "dims", "]", ")", ",", "axis", "=", "1", ")", "\n", "l2", "=", "1", "/", "2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "norms", ")", ")", "\n", "\n", "return", "loss", ",", "[", "l2", "]", ",", "[", "\"L2\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.UnfusedCrossEntropyWithLogits.UnfusedCrossEntropyWithLogits.__init__": [[15, 17], ["argo.core.network.Network.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"UnfusedCrossEntropyWithLogits\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.UnfusedCrossEntropyWithLogits.UnfusedCrossEntropyWithLogits.create_id": [[18, 23], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "        ", "_id", "=", "\"UCE\"", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.UnfusedCrossEntropyWithLogits.UnfusedCrossEntropyWithLogits._build": [[24, 40], ["tensorflow.nn.softmax", "tensorflow.clip_by_value", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "logits.get_shape().as_list", "tensorflow.cast", "tensorflow.log", "tensorflow.equal", "logits.get_shape", "tensorflow.one_hot", "tensorflow.argmax", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "_build", "(", "self", ",", "prediction_model", ",", "drop_one_logit", "=", "False", ")", ":", "\n", "\n", "        ", "y", "=", "prediction_model", ".", "y", "\n", "logits", "=", "prediction_model", ".", "logits", "\n", "\n", "n", "=", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "clipped_probabilities", "=", "tf", ".", "clip_by_value", "(", "probabilities", ",", "NUMTOL", ",", "1", "-", "NUMTOL", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "-", "tf", ".", "one_hot", "(", "y", ",", "depth", "=", "n", ")", "*", "tf", ".", "log", "(", "clipped_probabilities", ")", ",", "axis", "=", "1", ")", "\n", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "y", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "return", "loss", ",", "[", "[", "1", "-", "accuracy", "]", "]", ",", "[", "[", "\"error\"", "]", "]", ",", "[", "{", "\"fileName\"", ":", "\"error\"", ",", "\"logscale-y\"", ":", "1", "}", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.RenyiBound.RenyiBound.__init__": [[24, 28], ["VAEFunction.VAEFunction.VAEFunction.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "gaussian_model_observed", ",", "gaussian_model_latent", ")", ":", "\n", "        ", "VAEFunction", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_gaussian_model_observed", "=", "gaussian_model_observed", "\n", "self", ".", "_gaussian_model_latent", "=", "gaussian_model_latent", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.RenyiBound.RenyiBound.compute": [[29, 73], ["RenyiBound.RenyiBound._gaussian_model_observed.log_pdf", "tensorflow.reshape", "RenyiBound.RenyiBound._gaussian_model_latent.log_pdf", "tensorflow.reshape", "tensorflow_probability.distributions.MultivariateNormalDiag()._log_prob", "tensorflow.reshape", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow.reduce_logsumexp", "tensorflow.zeros", "tensorflow.ones"], "methods", ["None"], ["", "def", "compute", "(", "self", ",", "alpha", ",", "x_replicate", ",", "x_reconstruced_mean", ",", "z", ")", ":", "\n", "        ", "\"\"\" implement Renyi cost function as in the paper Renyi Divergence Variational Inference,\n            formula [5], with alpha in (0, 1)\n            alpha = 0 => log p(x)\n            alpha -> 1 => KL lower bound\n        \"\"\"", "\n", "'''\n        # log conditional p(x|z)\n        if self._binary==1:\n            self.log_p_x_z = -tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(\n                                                         labels=x_replicate,\n                                                         logits=x_reconstructed_mean), 2)\n        else:\n            #assert self._synthetic==1\n        '''", "\n", "\n", "self", ".", "log_p_x_z", "=", "self", ".", "_gaussian_model_observed", ".", "log_pdf", "(", "x_replicate", ")", "\n", "self", ".", "log_p_x_z", "=", "tf", ".", "reshape", "(", "self", ".", "log_p_x_z", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_n_samples", "]", ")", "\n", "\n", "'''\n        if not self._synthetic:\n            raise AssertionError(\"Renyi bound not yet implemented for continuous real dataset (e.g. MNISTcontinuos\")\n        '''", "\n", "\n", "# log posterior q(z|x)", "\n", "log_q_z_x", "=", "self", ".", "_gaussian_model_latent", ".", "log_pdf", "(", "z", ")", "\n", "log_q_z_x", "=", "tf", ".", "reshape", "(", "log_q_z_x", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_n_samples", "]", ")", "\n", "\n", "# log prior p(z)", "\n", "dim_z", "=", "self", ".", "_gaussian_model_latent", ".", "_dim", "\n", "log_p_z", "=", "tfd", ".", "MultivariateNormalDiag", "(", "tf", ".", "zeros", "(", "dim_z", ")", ",", "tf", ".", "ones", "(", "dim_z", ")", ")", ".", "_log_prob", "(", "z", ")", "\n", "log_p_z", "=", "tf", ".", "reshape", "(", "log_p_z", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_n_samples", "]", ")", "\n", "\n", "# exponent for Renyi expectation -- to avoid numerical issues we use exp of log", "\n", "# use log sum exp trick", "\n", "# TODOestimatefunction: recompute this using the tf function", "\n", "exponent", "=", "(", "1", "-", "alpha", ")", "*", "(", "self", ".", "log_p_x_z", "+", "log_p_z", "-", "log_q_z_x", ")", "\n", "\n", "#max_exponent= tf.reduce_max(exponent, 1, keep_dims=True)", "\n", "#renyi_sum = tf.log(tf.reduce_mean(tf.exp(exponent - max_exponent), 1)) + tf.reduce_mean(max_exponent, 1)", "\n", "\n", "renyi_sum", "=", "-", "tf", ".", "reduce_logsumexp", "(", "exponent", ")", "/", "(", "1", "-", "alpha", ")", "\n", "\n", "return", "renyi_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavReconstructHook.WavReconstructHook.__init__": [[15, 58], ["argo.core.hooks.AbstractWavHook.AbstractWavHook.__init__", "datasets.Dataset.check_dataset_keys_not_loop", "tf_logging.info", "list", "sample_indices_by_dataset.keys", "sample_indices_by_dataset.items", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "sample_indices_by_dataset", "=", "{", "\n", "VALIDATION", ":", "[", "]", "}", ",", "\n", "hop_legth_cqt", "=", "128", ",", "\n", "dataset_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "save_wav", "=", "False", ",", "\n", "reconstruct_from_mean", "=", "True", ",", "\n", "batch_size", "=", "20", ",", "\n", "_plot", "=", "True", ",", "\n", "spider_plot_time_splits", "=", "None", ",", "\n", "anomaly_detection_params", "=", "None", ",", "\n", "compute_reconstruction_metrics", "=", "True", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "dataset_keys", ",", "hop_legth_cqt", "=", "hop_legth_cqt", ",", "dirName", "=", "dirName", ")", "\n", "\n", "self", ".", "_plot", "=", "_plot", "\n", "self", ".", "reconstruct_from_mean", "=", "reconstruct_from_mean", "\n", "self", ".", "save_wav", "=", "save_wav", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "spider_plot_time_splits", "=", "spider_plot_time_splits", "\n", "self", ".", "_sample_indices_by_dataset", "=", "sample_indices_by_dataset", "\n", "\n", "self", ".", "compute_reconstruction_metrics", "=", "compute_reconstruction_metrics", "\n", "\n", "self", ".", "anomaly_detection_params", "=", "anomaly_detection_params", "\n", "\n", "if", "compute_reconstruction_metrics", ":", "\n", "            ", "self", ".", "reconstr_metrics_file_names", "=", "{", "\n", "TRAIN", ":", "dirName", "+", "'/reconstr_metrics_tf_train.txt'", ",", "\n", "VALIDATION", ":", "dirName", "+", "'/reconstr_metrics_tf_validation.txt'", ",", "\n", "TEST", ":", "dirName", "+", "'/reconstr_metrics_tf_test.txt'", ",", "\n", "}", "\n", "\n", "", "check_dataset_keys_not_loop", "(", "list", "(", "sample_indices_by_dataset", ".", "keys", "(", ")", ")", ")", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create WavReconstructHook for: \\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "ds_key", "+", "\": \"", "+", "\", \"", ".", "join", "(", "map", "(", "str", ",", "idxs", "or", "[", "'all'", "]", ")", ")", "for", "ds_key", ",", "idxs", "in", "sample_indices_by_dataset", ".", "items", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavReconstructHook.WavReconstructHook.before_training": [[59, 66], ["tf_logging.info", "WavReconstructHook.WavReconstructHook._write_origanals", "WavReconstructHook.WavReconstructHook.write_headers_to_reconstruction_files", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.write_headers_to_reconstruction_files"], ["", "def", "before_training", "(", "self", ",", "session", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"WavReconstructHook, writing originals: \"", "+", "str", "(", "self", ".", "save_wav", ")", ")", "\n", "if", "self", ".", "save_wav", ":", "\n", "            ", "self", ".", "_write_origanals", "(", ")", "\n", "\n", "", "if", "self", ".", "compute_reconstruction_metrics", ":", "\n", "            ", "self", ".", "write_headers_to_reconstruction_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavReconstructHook.WavReconstructHook.do_when_triggered": [[67, 130], ["tf_logging.info", "wavenet.AnomalyDetector.AnomalyDetector", "numpy.arange", "WavReconstructHook.WavReconstructHook._model.encode", "numpy.squeeze", "WavReconstructHook.WavReconstructHook._model.decode_tf", "tf_logging.info", "wavenet.AnomalyDetector.AnomalyDetector.detect_anomalies", "len", "wavenet.utils.mu_law_numpy", "WavReconstructHook.WavReconstructHook.log_reconstr_metrics", "wavenet.AnomalyDetector.AnomalyDetector.set_data", "len", "ValueError", "WavReconstructHook.WavReconstructHook._model.decode_tf", "WavReconstructHook.WavReconstructHook.multi_plot_and_save", "WavReconstructHook.WavReconstructHook.plot_and_save", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.decode_tf", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.detect_anomalies", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.mu_law_numpy", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.log_reconstr_metrics", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.set_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.decode_tf", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.multi_plot_and_save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.plot_and_save"], ["", "", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for WavReconstructHook\"", ")", "\n", "\n", "anomaly_detector", "=", "None", "\n", "if", "self", ".", "anomaly_detection_params", "is", "not", "None", ":", "\n", "            ", "anomaly_detector", "=", "AnomalyDetector", "(", "self", ".", "anomaly_detection_params", ",", "self", ".", "dir_name_anomaly_detection", ",", "\n", "'{}{}'", ".", "format", "(", "self", ".", "_time_ref_shortstr", ",", "self", ".", "_time_ref", ")", ")", "\n", "\n", "", "for", "ds_key", "in", "self", ".", "_samples", ":", "\n", "            ", "indices", ",", "samples", "=", "self", ".", "_samples", "[", "ds_key", "]", "\n", "_", ",", "labels", "=", "self", ".", "_labels", "[", "ds_key", "]", "\n", "original_indices", "=", "indices", "\n", "\n", "samples", "=", "samples", "[", "indices", "]", "\n", "labels", "=", "labels", "[", "indices", "]", "\n", "indices", "=", "np", ".", "arange", "(", "0", ",", "samples", ".", "shape", "[", "0", "]", ")", "\n", "\n", "encode_tuple", "=", "self", ".", "_model", ".", "encode", "(", "samples", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "\n", "if", "len", "(", "encode_tuple", ")", "==", "2", ":", "\n", "                ", "zs", ",", "x_shifted", "=", "encode_tuple", "\n", "hs", "=", "None", "\n", "covariance", "=", "None", "\n", "", "elif", "len", "(", "encode_tuple", ")", "==", "6", ":", "\n", "                ", "zs", ",", "hs", ",", "covariance", ",", "prior_mean", ",", "prior_cov", ",", "x_shifted", "=", "encode_tuple", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"This tuple should not be this length: {}\"", ".", "format", "(", "len", "(", "encode_tuple", ")", ")", ")", "\n", "\n", "# compute quantized and feed below...", "\n", "", "x_target_quantized", "=", "mu_law_numpy", "(", "samples", ")", "+", "128", "\n", "x_target_quantized", "=", "np", ".", "squeeze", "(", "x_target_quantized", ",", "axis", "=", "-", "1", ")", "\n", "\n", "reconstructed_samples", ",", "reconstr_loss_per_sample", "=", "self", ".", "_model", ".", "decode_tf", "(", "zs", ",", "x_shifted", ",", "\n", "x_target_quantized", "=", "x_target_quantized", ",", "\n", "sess", "=", "run_context", ".", "session", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "\n", "if", "self", ".", "compute_reconstruction_metrics", ":", "\n", "                ", "self", ".", "log_reconstr_metrics", "(", "self", ".", "_time_ref", ",", "samples", ",", "reconstructed_samples", ",", "reconstr_loss_per_sample", ",", "\n", "labels", ",", "self", ".", "reconstr_metrics_file_names", "[", "ds_key", "]", ")", "\n", "\n", "", "if", "anomaly_detector", "is", "not", "None", ":", "\n", "                ", "anomaly_detector", ".", "set_data", "(", "ds_key", ",", "samples", ",", "reconstructed_samples", ",", "labels", ",", "reconstr_loss_per_sample", ")", "\n", "\n", "", "if", "self", ".", "_plot", ":", "\n", "                ", "if", "hs", "is", "not", "None", "and", "covariance", "is", "not", "None", "and", "self", ".", "reconstruct_from_mean", ":", "# if mean/covariance are not none -> VAE", "\n", "                    ", "reconstructed_samples_mean", ",", "reconstr_loss_mean", "=", "self", ".", "_model", ".", "decode_tf", "(", "hs", ",", "x_shifted", ",", "\n", "sess", "=", "run_context", ".", "session", ",", "\n", "x_target_quantized", "=", "x_target_quantized", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "\n", "self", ".", "multi_plot_and_save", "(", "ds_key", ",", "original_indices", ",", "reconstructed_samples_mean", "[", "indices", "]", ",", "reconstructed_samples", "[", "indices", "]", ",", "\n", "samples", "[", "indices", "]", ",", "labels", "[", "indices", "]", ",", "self", ".", "_time_ref", ",", "self", ".", "_time_ref_shortstr", ",", "\n", "zs", "[", "indices", "]", ",", "hs", "[", "indices", "]", ",", "covariance", "[", "indices", "]", ",", "prior_mean", ",", "\n", "prior_cov", ",", "prefix", "=", "'multiplot_tf_'", ",", "save_enc", "=", "False", ",", "\n", "save_wav", "=", "self", ".", "save_wav", ",", "plot_mean_separately", "=", "True", ",", "plot_rainbowgram", "=", "False", ")", "\n", "", "elif", "hs", "is", "None", "and", "covariance", "is", "None", ":", "# AE", "\n", "                    ", "self", ".", "plot_and_save", "(", "ds_key", ",", "original_indices", ",", "reconstructed_samples", "[", "original_indices", "]", ",", "samples", "[", "original_indices", "]", ",", "labels", "[", "original_indices", "]", ",", "self", ".", "_time_ref", ",", "self", ".", "_time_ref_shortstr", ",", "\n", "zs", "[", "original_indices", "]", ",", "prefix", "=", "\"reconstruction_tf_\"", ",", "suffix", "=", "\"sample\"", ",", "save_enc", "=", "False", ",", "save_wav", "=", "self", ".", "save_wav", ")", "\n", "", "", "tf_logging", ".", "info", "(", "\"finished with %s\"", "%", "ds_key", ")", "\n", "\n", "", "if", "anomaly_detector", "is", "not", "None", ":", "\n", "            ", "anomaly_detector", ".", "detect_anomalies", "(", "self", ".", "_model", ".", "dataset", ".", "sample_rate", ",", "'tf'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook.__init__": [[17, 39], ["argo.core.hooks.AbstractWavHook.AbstractWavHook.__init__", "datasets.Dataset.check_dataset_keys_not_loop", "tf_logging.info", "list", "sample_indices_by_dataset.keys", "sample_indices_by_dataset.items", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "sample_indices_by_dataset", "=", "{", "\n", "VALIDATION", ":", "[", "]", "}", ",", "\n", "hop_legth_cqt", "=", "128", ",", "\n", "dataset_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", "\n", ")", ":", "\n", "\n", "        ", "_dirName", "=", "dirName", "+", "'/mean_variance_plots'", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "dataset_keys", ",", "hop_legth_cqt", "=", "hop_legth_cqt", ",", "\n", "dirName", "=", "_dirName", ")", "\n", "\n", "self", ".", "_sample_indices_by_dataset", "=", "sample_indices_by_dataset", "\n", "\n", "check_dataset_keys_not_loop", "(", "list", "(", "sample_indices_by_dataset", ".", "keys", "(", ")", ")", ")", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create WavenetGaussianVisualizationHook for: \\n\"", "\n", "+", "\"\\n\"", ".", "join", "(", "[", "ds_key", "+", "\": \"", "+", "\", \"", ".", "join", "(", "map", "(", "str", ",", "idxs", ")", ")", "\n", "for", "ds_key", ",", "idxs", "in", "sample_indices_by_dataset", ".", "items", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook.before_training": [[40, 42], ["tf_logging.info"], "methods", ["None"], ["", "def", "before_training", "(", "self", ",", "session", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"WavenetGaussianVisualizationHook\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook.do_when_triggered": [[43, 53], ["tf_logging.info", "WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook._model.get_mean_covariance", "WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook.plot_mean_sigma", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.get_mean_covariance", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook.plot_mean_sigma"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for WavenetGaussianVisualizationHook\"", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_samples", ":", "\n", "            ", "indices", ",", "samples", "=", "self", ".", "_samples", "[", "ds_key", "]", "\n", "\n", "mean", ",", "covariance", "=", "self", ".", "_model", ".", "get_mean_covariance", "(", "samples", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "self", ".", "plot_mean_sigma", "(", "mean", ",", "covariance", ",", "ds_key", ",", "indices", ",", "self", ".", "_time_ref", ",", "self", ".", "_time_ref_shortstr", ",", "\n", "prefix", "=", "'mean_sigma_'", ",", "suffix", "=", "'sample'", ")", "\n", "tf_logging", ".", "info", "(", "\"finished with %s\"", "%", "ds_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook.plot_mean_sigma": [[54, 96], ["numpy.sqrt", "zip", "numpy.diagonal", "matplotlib.pyplot.title", "numpy.arange", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "matplotlib.pyplot.fill_between", "matplotlib.pyplot.fill_between", "matplotlib.pyplot.savefig", "matplotlib.pyplot.legend", "matplotlib.pyplot.close", "str().zfill", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "", "def", "plot_mean_sigma", "(", "self", ",", "means", ",", "covariance", ",", "ds_key", ",", "indices", ",", "time_ref", ",", "time_ref_str", ",", "prefix", "=", "''", ",", "suffix", "=", "None", ")", ":", "\n", "        ", "'''\n        plots the mean and variance (main diagonal of covariance matrix)\n         of a multivariate gaussian distribution only for the first 2 channels\n        Args:\n            means (np.array): the means of the samples, shape=(batch_sz, dimension, channels)\n            covariance (np.array): the covariance matrix of the samples associated with the mean,\n                                    shape=(batch_sz, channels, dimension, dimension)\n            ds_key (str): 'train' or 'validation'\n            indices: the indices of the processed samples\n            time_ref: the time step in which the hook has been triggered\n            time_ref_str: 'ep' for epoch or other time step reference\n            prefix (str): beginning of file name\n            suffix: eof_name\n\n        Returns:\n            None\n        '''", "\n", "sigmas", "=", "np", ".", "sqrt", "(", "np", ".", "diagonal", "(", "covariance", ",", "axis1", "=", "-", "2", ",", "axis2", "=", "-", "1", ")", ")", "\n", "for", "index", ",", "mean", ",", "sigma", "in", "zip", "(", "indices", ",", "means", ",", "sigmas", ")", ":", "\n", "            ", "fileName", "=", "prefix", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "str", "(", "index", ")", "+", "\"_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", "+", "(", "\"_\"", "+", "suffix", "if", "suffix", "is", "not", "None", "else", "\"\"", ")", "\n", "\n", "plt", ".", "title", "(", "'Mu & Sigma of latent gaussian distribution'", ")", "\n", "x", "=", "np", ".", "arange", "(", "0", ",", "mean", ".", "shape", "[", "0", "]", ")", "\n", "sigma1", ",", "sigma2", "=", "sigma", "[", "0", "]", ",", "sigma", "[", "1", "]", "\n", "mean1", ",", "mean2", "=", "mean", "[", ":", ",", "0", "]", ",", "mean", "[", ":", ",", "1", "]", "\n", "\n", "plt", ".", "plot", "(", "x", ",", "mean1", ",", "'r-'", ",", "label", "=", "'mean1'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "mean2", ",", "'b-'", ",", "label", "=", "'mean2'", ")", "\n", "\n", "plt", ".", "fill_between", "(", "x", ",", "mean1", "-", "sigma1", ",", "mean1", "+", "sigma1", ",", "alpha", "=", "0.5", ",", "edgecolor", "=", "'#ff3842'", ",", "\n", "facecolor", "=", "'#ff3842'", ")", "# red", "\n", "plt", ".", "fill_between", "(", "x", ",", "mean2", "-", "sigma2", ",", "mean2", "+", "sigma2", ",", "alpha", "=", "0.5", ",", "edgecolor", "=", "'#1a009e'", ",", "\n", "facecolor", "=", "'#7f66ff'", ")", "# blue", "\n", "plt", ".", "savefig", "(", "self", ".", "_dirName", "+", "'/'", "+", "fileName", "+", "'.png'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.ELBO_IAF.__init__": [[41, 44], ["ELBO.ELBO.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "beta", "=", "1.0", ",", "warm_up_method", "=", "None", ",", "kl_min", "=", "0.25", ",", "name", "=", "\"ELBO_IAF\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "beta", "=", "beta", ",", "warm_up_method", "=", "warm_up_method", ",", "name", "=", "name", ")", "\n", "self", ".", "_kl_min", "=", "kl_min", "\n", "# self.dec_log_stdv = tf.get_variable(\"dec_log_stdv\", initializer=tf.constant(0.0))", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.ELBO_IAF.create_id": [[46, 53], ["super().create_id", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "# cost_fuction_kwargs[0] is the cost function name", "\n", "        ", "_id", "=", "super", "(", ")", ".", "create_id", "(", "cost_fuction_kwargs", ")", "\n", "_id", "+=", "\"_km\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"kl_min\"", "]", ")", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.ELBO_IAF.compute_kl_of_layer": [[54, 77], ["posterior.log_prob", "prior.log_prob", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.maximum", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "compute_kl_of_layer", "(", "self", ",", "x_repeated", ",", "prior", ",", "posterior", ",", "z1", ",", "flow_chain_params", ",", "zN", ")", ":", "\n", "\n", "# logqs = posterior.logps(z1)", "\n", "        ", "logqs", "=", "posterior", ".", "log_prob", "(", "z1", ")", "\n", "for", "flow_params", "in", "flow_chain_params", ":", "\n", "            ", "logqs", "+=", "flow_params", "[", "'lnsd'", "]", "\n", "\n", "# logps = prior.logps(zN)", "\n", "", "logps", "=", "prior", ".", "log_prob", "(", "zN", ")", "\n", "kl_cost", "=", "logqs", "-", "logps", "\n", "\n", "if", "self", ".", "_kl_min", ">", "0", ":", "\n", "# [0, 1, 2, 3] -> [0, 1] -> [1] / (b * k)", "\n", "            ", "kl_ave", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "kl_cost", ",", "[", "1", ",", "2", "]", ")", ",", "[", "0", "]", ",", "keepdims", "=", "True", ")", "\n", "kl_ave", "=", "tf", ".", "maximum", "(", "kl_ave", ",", "self", ".", "_kl_min", ")", "\n", "kl_ave", "=", "tf", ".", "tile", "(", "kl_ave", ",", "[", "tf", ".", "shape", "(", "x_repeated", ")", "[", "0", "]", ",", "1", "]", ")", "#self._batch_size", "\n", "kl_obj", "=", "tf", ".", "reduce_sum", "(", "kl_ave", ",", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "kl_obj", "=", "tf", ".", "reduce_sum", "(", "kl_cost", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "\n", "", "kl_cost", "=", "tf", ".", "reduce_sum", "(", "kl_cost", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "\n", "return", "kl_obj", ",", "kl_cost", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.ELBO_IAF._build": [[78, 148], ["zip", "ELBO_IAF.integral_log_prob", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "ELBO_IAF.ELBO_IAF.get_warm_up_coefficient", "ELBO_IAF.ELBO_IAF.compute_kl_of_layer"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.integral_log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.get_warm_up_coefficient", "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.ELBO_IAF.compute_kl_of_layer"], ["", "def", "_build", "(", "self", ",", "model", ")", ":", "\n", "\n", "        ", "kl_cost", "=", "0.0", "\n", "kl_obj", "=", "0.0", "\n", "\n", "x", "=", "model", ".", "x", "\n", "x_repeated", "=", "model", ".", "x_repeated", "\n", "model_visible", "=", "model", ".", "_model_visible", "\n", "for", "prior", ",", "posterior", ",", "z1", ",", "flow_chain_params", ",", "zN", "in", "zip", "(", "model", ".", "priors", ",", "\n", "model", ".", "posteriors", ",", "\n", "model", ".", "z1s", ",", "\n", "model", ".", "flows_params", ",", "\n", "model", ".", "zNs", ")", ":", "\n", "\n", "            ", "layer_obj", ",", "layer_cost", "=", "self", ".", "compute_kl_of_layer", "(", "x_repeated", ",", "\n", "prior", ",", "\n", "posterior", ",", "\n", "z1", ",", "\n", "flow_chain_params", ",", "\n", "zN", ")", "\n", "kl_obj", "+=", "layer_obj", "\n", "kl_cost", "+=", "layer_cost", "\n", "\n", "\n", "# log_pxz = discretized_logistic(x_reconstruction_node, self.dec_log_stdv, sample=x_repeated)", "\n", "", "log_pxz", "=", "integral_log_prob", "(", "model_visible", ",", "x_repeated", ")", "\n", "\n", "# NB originally it was reduce_sum", "\n", "# TODO ?", "\n", "#obj = tf.reduce_mean(kl_obj - log_pxz)", "\n", "\n", "\n", "# beta = tf.placeholder_with_default(self._beta, shape=(), name='beta_regularizer')", "\n", "# warm_up = self.get_warm_up_coefficient(self._warm_up_method, vae)", "\n", "#", "\n", "# # The loss is composed of two terms:", "\n", "# #", "\n", "# # 1.) The reconstruction loss (the negative log probability", "\n", "# #     of the input under the reconstructed distribution", "\n", "# #     induced by the decoder in the data space).", "\n", "# #     This can be interpreted as the number of \"nats\" required", "\n", "# #     for reconstructing the input when the activation in latent", "\n", "# #     is given.", "\n", "#", "\n", "# reconstruction_loss = self.reconstruction_loss(x_target, n_z_samples, model_visible)", "\n", "#", "\n", "# # 2.) The latent loss, which is defined as the Kullback Leibler divergence", "\n", "# #     between the distribution in latent space induced by the encoder on", "\n", "# #     the data and some prior. This acts as a kind of regularizer.", "\n", "# #     This can be interpreted as the number of \"nats\" required", "\n", "# #     for transmitting the the latent space distribution given", "\n", "# #     the prior.", "\n", "#", "\n", "# latent_loss = beta * self.latent_loss(gaussian_model_latent, prior)", "\n", "#", "\n", "# cost = warm_up * latent_loss + reconstruction_loss", "\n", "\n", "# NB originally is was tf.add_n", "\n", "_k", "=", "model", ".", "_network", ".", "_k", "\n", "\n", "reconstruction_loss", "=", "tf", ".", "reduce_mean", "(", "log_pxz", ")", "\n", "latent_loss_obj", "=", "tf", ".", "reduce_mean", "(", "kl_obj", ")", "\n", "latent_loss_cost", "=", "tf", ".", "reduce_mean", "(", "kl_cost", ")", "\n", "\n", "warm_up", "=", "self", ".", "get_warm_up_coefficient", "(", "self", ".", "_warm_up_method", ",", "model", ")", "\n", "\n", "loss", "=", "warm_up", "*", "self", ".", "beta", "*", "latent_loss_obj", "-", "reconstruction_loss", "\n", "#tf.reduce_mean(compute_lowerbound(log_pxz, kl_cost, _k))", "\n", "\n", "return", "loss", ",", "[", "[", "reconstruction_loss", "]", ",", "[", "latent_loss_obj", ",", "latent_loss_cost", "]", "]", ",", "[", "[", "\"RL\"", "]", ",", "[", "\"max(KL,kl_min)\"", ",", "\"KL\"", "]", "]", ",", "[", "{", "\"fileName\"", ":", "\"cost_function_RL\"", "}", ",", "{", "\"fileName\"", ":", "\"cost_function_KL\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.logsumexp": [[10, 13], ["tensorflow.reduce_max", "tensorflow.reshape", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.exp"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["def", "logsumexp", "(", "x", ")", ":", "\n", "    ", "x_max", "=", "tf", ".", "reduce_max", "(", "x", ",", "[", "1", "]", ",", "keepdims", "=", "True", ")", "\n", "return", "tf", ".", "reshape", "(", "x_max", ",", "[", "-", "1", "]", ")", "+", "tf", ".", "log", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "x", "-", "x_max", ")", ",", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.integral_log_prob": [[32, 37], ["tensorflow.log", "tensorflow.reduce_sum", "tensorflow.floor", "distribution.cdf", "distribution.cdf"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["def", "integral_log_prob", "(", "distribution", ",", "sample", ",", "binsize", "=", "1", "/", "256.0", ")", ":", "\n", "    ", "xi", "=", "tf", ".", "floor", "(", "sample", "/", "binsize", ")", "*", "binsize", "\n", "xip1", "=", "xi", "+", "binsize", "\n", "logp", "=", "tf", ".", "log", "(", "distribution", ".", "cdf", "(", "xip1", ")", "-", "distribution", ".", "cdf", "(", "xi", ")", "+", "NUMTOL", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "logp", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.FFNetwork.FFNetwork.create_id": [[24, 35], ["super().create_id", "argo.core.utils.argo_utils.get_method_id", "filter"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "layers_ids", "=", "[", "utils", ".", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "]", "\n", "\n", "_id", "=", "'-n'", "+", "\"_\"", ".", "join", "(", "filter", "(", "None", ",", "layers_ids", ")", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.FFNetwork.FFNetwork.__init__": [[36, 39], ["argo.core.network.ArgoStochasticNetworkWithDefaults.ArgoStochasticNetworkWithDefaults.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", ",", "seed", "=", "None", ")", ":", "# , remove_node_from_logits = False", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "seed", ")", "\n", "self", ".", "_network_architecture", "=", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.FFNetwork.FFNetwork._build": [[42, 78], ["argo.core.network.GeneralSonnetNetwork.GeneralSonnetNetwork", "FFNetwork.FFNetwork.module"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "x", ",", "is_training", "=", "False", ",", "network_str", "=", "\"\"", ")", ":", "#drop_one_logit = False):", "\n", "\n", "        ", "'''\n        # check if I need a n-1 logit layer, where the n_th is consider fixed to 1\n        if self.remove_node_from_logits:\n            # I need all this tricky steps, since the dictionary is shared between datastructures\n            network_architecture = self._network_architecture.copy()\n            last_module = self._network_architecture[-1]\n            new_last_module = []\n            new_last_module.append(last_module[0])\n            new_last_module.append(last_module[1].copy())\n            new_last_module[1][\"output_size\"] -= 1\n            new_last_module.append(last_module[2])\n            \n            network_architecture[-1] = new_last_module\n            \n        else:\n            network_architecture = self._network_architecture\n        '''", "\n", "\n", "network_architecture", "=", "self", ".", "_network_architecture", "\n", "#if drop_one_logit:", "\n", "#     network_architecture[-1][1][\"output_size\"] -= 1 ", "\n", "\n", "\n", "self", ".", "module", "=", "GeneralSonnetNetwork", "(", "self", ".", "_network_defaults", "[", "\"activation\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", ",", "\n", "network_architecture", ",", "\n", "is_training", "=", "is_training", ",", "\n", "network_str", "=", "network_str", ",", "\n", "name", "=", "\"network\"", ")", "\n", "\n", "return", "self", ".", "module", "(", "x", ")", "\n", "# return self._create_deterministic_layers(x, self._network_architecture)", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MSE.MSE.__init__": [[7, 9], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"MSE\"", ")", ":", "# drop_one_logit=0, ", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MSE.MSE.create_id": [[12, 18], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "_id", "=", "\"MSE\"", "#+ str(cost_fuction_kwargs.get(\"drop_one_logit\",0))", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MSE.MSE._build": [[19, 41], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "argo.core.utils.argo_utils.create_panels_lists", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_panels_lists"], ["", "def", "_build", "(", "self", ",", "prediction_model", ",", "drop_one_logit", "=", "False", ")", ":", "\n", "\n", "        ", "y", "=", "prediction_model", ".", "y", "\n", "logits", "=", "prediction_model", ".", "logits", "\n", "\n", "loss_per_sample", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "y", "-", "logits", ")", ",", "axis", "=", "1", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ")", "\n", "\n", "# First panel will be at screen during traininig", "\n", "list_of_vpanels_of_plots", "=", "[", "\n", "[", "\n", "{", "\n", "'nodes'", ":", "[", "loss", "]", ",", "\n", "'names'", ":", "[", "\"mse\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"mse\"", "}", "\n", "}", ",", "\n", "]", "\n", "]", "\n", "\n", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "=", "create_panels_lists", "(", "list_of_vpanels_of_plots", ")", "\n", "\n", "return", "loss", ",", "loss_per_sample", ",", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AlphaLikelihood.AlphaLikelihood.__init__": [[11, 15], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "alpha_parameter", "=", "None", ",", "n_samples", "=", "1", ",", "name", "=", "\"LL\"", ")", ":", "# drop_one_logit=0,", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_alpha_parameter", "=", "alpha_parameter", "\n", "self", ".", "_use_alpha", "=", "(", "alpha_parameter", "is", "not", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AlphaLikelihood.AlphaLikelihood.create_id": [[16, 26], ["cost_fuction_kwargs.get", "cost_fuction_kwargs.get", "cost_fuction_kwargs.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "        ", "alpha_parameter", "=", "cost_fuction_kwargs", ".", "get", "(", "'alpha_parameter'", ")", "\n", "use_alpha", "=", "cost_fuction_kwargs", ".", "get", "(", "'use_alpha'", ")", "\n", "n_samples", "=", "cost_fuction_kwargs", ".", "get", "(", "'n_samples'", ")", "\n", "_id", "=", "\"LL-\"", "\n", "if", "use_alpha", ":", "\n", "            ", "_id", "+=", "\"alpha:{0:.2g}\"", ".", "format", "(", "alpha_parameter", ")", "\n", "_id", "+=", "\"-asam:{0:.1g}\"", ".", "format", "(", "n_samples", ")", "#+ str(cost_fuction_kwargs.get(\"drop_one_logit\",0))", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AlphaLikelihood.AlphaLikelihood._build": [[27, 138], ["tensorflow.shape", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "argo.core.utils.argo_utils.create_panels_lists", "tensorflow.reduce_sum", "tensorflow.square", "tensorflow.tile", "tensorflow.scalar_mul", "tensorflow.reshape", "tensorflow.reduce_logsumexp", "tensorflow.scalar_mul", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reduce_mean", "distr.log_prob", "distr.log_prob", "distr.log_prob", "distr.log_prob", "distr.log_prob"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_panels_lists", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "_build", "(", "self", ",", "model", ")", ":", "#, drop_one_logit=False):", "\n", "\n", "        ", "n_samples", "=", "model", ".", "n_samples_ph", "\n", "y", "=", "model", ".", "y", "\n", "shaper", "=", "tf", ".", "shape", "(", "y", ")", "\n", "distr", "=", "model", ".", "prediction_distr", "\n", "\n", "if", "self", ".", "_use_alpha", ":", "\n", "\n", "            ", "if", "self", ".", "_alpha_parameter", "!=", "0", ":", "\n", "                ", "y_tile", "=", "tf", ".", "tile", "(", "y", ",", "[", "n_samples", ",", "1", "]", ")", "\n", "loss_core", "=", "-", "distr", ".", "log_prob", "(", "y_tile", ")", "\n", "#loss_per_minibatch = tf.exp(tf.scalar_mul(self._alpha_parameter,distr.log_prob(y_tile)))", "\n", "#loss_per_minibatch_reshaped=tf.reshape(loss_per_minibatch, (alpha_samples,shaper[0]))", "\n", "#loss_per_minibatch_avg=tf.reduce_mean(loss_per_minibatch_reshaped,axis=0)", "\n", "#loss_per_sample=tf.scalar_mul(-1./self._alpha_parameter,tf.log(loss_per_minibatch_avg))", "\n", "loss_per_minibatch", "=", "tf", ".", "scalar_mul", "(", "self", ".", "_alpha_parameter", ",", "distr", ".", "log_prob", "(", "y_tile", ")", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "loss_per_minibatch_reshaped", "=", "tf", ".", "reshape", "(", "loss_per_minibatch", ",", "(", "n_samples", ",", "shaper", "[", "0", "]", ")", ")", "\n", "loss_per_minibatch_avg", "=", "tf", ".", "reduce_logsumexp", "(", "loss_per_minibatch_reshaped", ",", "axis", "=", "0", ")", "\n", "loss_per_sample", "=", "tf", ".", "scalar_mul", "(", "-", "1.", "/", "self", ".", "_alpha_parameter", ",", "loss_per_minibatch_avg", ")", "\n", "", "else", ":", "\n", "                ", "y_tile", "=", "tf", ".", "tile", "(", "y", ",", "[", "n_samples", ",", "1", "]", ")", "\n", "loss_core", "=", "-", "distr", ".", "log_prob", "(", "y_tile", ")", "\n", "loss_per_minibatch", "=", "-", "distr", ".", "log_prob", "(", "y_tile", ")", "\n", "loss_per_minibatch_reshaped", "=", "tf", ".", "reshape", "(", "loss_per_minibatch", ",", "(", "n_samples", ",", "shaper", "[", "0", "]", ")", ")", "\n", "loss_per_sample", "=", "tf", ".", "reduce_mean", "(", "loss_per_minibatch_reshaped", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "loss_per_sample", "=", "-", "distr", ".", "log_prob", "(", "y", ")", "\n", "loss_core", "=", "loss_per_sample", "\n", "\n", "", "nll", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ",", "name", "=", "\"nll\"", ")", "\n", "kl_losses", "=", "model", ".", "kl_losses", "\n", "total_KL", "=", "tf", ".", "reduce_sum", "(", "kl_losses", ")", "/", "model", ".", "dataset", ".", "n_samples_train", "\n", "loss", "=", "nll", "+", "total_KL", "\n", "nll_core", "=", "tf", ".", "reduce_mean", "(", "loss_core", ",", "name", "=", "\"nll_core\"", ")", "\n", "\n", "# in case of Bayesian network I need to add kl_losses for the weights if I want to see them", "\n", "# (otherwise kl_losses will be an empty list for non bayesian predictions)", "\n", "# if kl_losses:", "\n", "#", "\n", "#     KL_i_names = [\"KL_\" + str(int(i+1)) for i, l in enumerate(kl_losses)]", "\n", "#", "\n", "#     nodes_to_log = [[loss],", "\n", "#                     [nll],", "\n", "#                     # [total_KL],", "\n", "#                     # kl_losses", "\n", "#                     ]", "\n", "#", "\n", "#     names_of_nodes_to_log = [[\"loss\"],", "\n", "#                              [\"NLL\"],", "\n", "#                              # [\"total_KL\"],", "\n", "#                              # KL_i_names", "\n", "#                              ]", "\n", "#", "\n", "#     filenames_to_log_to = [{\"fileName\" : \"loss\"},", "\n", "#                             {\"fileName\" : \"negloglikelihood\"},", "\n", "#                             # {\"fileName\" : \"total_KL\"},", "\n", "#                             # {\"fileName\" : \"all_KLs\", \"legend\": 0}", "\n", "#                            ]", "\n", "#", "\n", "# else:", "\n", "\n", "\n", "means", "=", "model", ".", "prediction_mean", "\n", "# if self._use_alpha:", "\n", "means", "=", "tf", ".", "reshape", "(", "means", ",", "(", "n_samples", ",", "shaper", "[", "0", "]", ",", "shaper", "[", "1", "]", ")", ")", "\n", "means", "=", "tf", ".", "reduce_mean", "(", "means", ",", "axis", "=", "0", ")", "\n", "# else:", "\n", "#     pass", "\n", "\n", "mse_per_sample", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "y", "-", "means", ")", ",", "axis", "=", "1", ")", "\n", "mse", "=", "tf", ".", "reduce_mean", "(", "mse_per_sample", ")", "\n", "\n", "# First panel will be at screen during training", "\n", "list_of_vpanels_of_plots", "=", "[", "\n", "[", "\n", "{", "\n", "'nodes'", ":", "[", "loss", "]", ",", "\n", "'names'", ":", "[", "\"loss\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"loss\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "nll", "]", ",", "\n", "'names'", ":", "[", "\"NLL\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"negloglikelihood\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "mse", "]", ",", "\n", "'names'", ":", "[", "\"mse\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"mse\"", "}", "\n", "}", "\n", "]", "\n", "]", "\n", "\n", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "=", "create_panels_lists", "(", "list_of_vpanels_of_plots", ")", "\n", "\n", "# nodes_to_log = [[loss], [nll], [mse], [loss_core]]", "\n", "#", "\n", "# names_of_nodes_to_log = [[\"loss\"], [\"NLL\"], [\"MSE\"], [\"loss_core\"]]", "\n", "#", "\n", "# filenames_to_log_to = [{\"fileName\": \"loss\"},", "\n", "#                        {\"fileName\": \"negloglikelihood\"},", "\n", "#                        {\"fileName\": \"mse\"},", "\n", "#                        {\"fileName\": \"loss_core\"}", "\n", "#                        ]", "\n", "\n", "return", "loss", ",", "loss_per_sample", ",", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.IELBO.IELBO.__init__": [[10, 15], ["ELBO.ELBO.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "beta", "=", "1.0", ",", "warm_up_method", "=", "None", ",", "h", "=", "0.01", ",", "normalize", "=", "1", ",", "name", "=", "\"IELBO\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "beta", "=", "beta", ",", "warm_up_method", "=", "warm_up_method", ",", "name", "=", "name", ")", "\n", "\n", "self", ".", "_h", "=", "h", "\n", "self", ".", "_normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.IELBO.IELBO.create_id": [[16, 22], ["IELBO.IELBO.create_warm_up_id", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.create_warm_up_id"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "        ", "_id", "=", "\"IELBO_b\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"beta\"", "]", ")", "+", "\"_h\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"h\"", "]", ")", "+", "\"_n\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"normalize\"", "]", ")", "\n", "\n", "_id", "+=", "self", ".", "create_warm_up_id", "(", "cost_fuction_kwargs", ")", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.IELBO.IELBO._build": [[23, 31], ["tensorflow.placeholder_with_default", "tensorflow.placeholder_with_default", "super()._build", "isinstance"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood._build"], ["", "def", "_build", "(", "self", ",", "vae", ")", ":", "\n", "\n", "        ", "self", ".", "h", "=", "tf", ".", "placeholder_with_default", "(", "self", ".", "_h", ",", "shape", "=", "(", ")", ",", "name", "=", "'half_intergral_interval'", ")", "\n", "self", ".", "normalize", "=", "tf", ".", "placeholder_with_default", "(", "self", ".", "_normalize", ",", "shape", "=", "(", ")", ",", "name", "=", "'normalize_integral'", ")", "\n", "\n", "assert", "(", "not", "isinstance", "(", "vae", ".", "_model_visible", ",", "tfd", ".", "Bernoulli", ")", ")", ",", "\"Cannot use the IELBO with discrete distributions for the visible variables\"", "\n", "\n", "return", "super", "(", ")", ".", "_build", "(", "vae", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.IELBO.IELBO.reconstruction_loss": [[32, 75], ["tensorflow.variable_scope", "tensorflow.tile", "model_visible.cdf", "model_visible.cdf", "tensorflow.cond", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "x_target.shape.as_list", "len", "tensorflow.equal", "tensorflow.log", "list", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "reconstruction_loss", "(", "self", ",", "x_target", ",", "n_z_samples", ",", "model_visible", ")", ":", "\n", "\n", "# with tf.variable_scope('ELBO/reconstruction_loss'):", "\n", "# no need for ELBO, sonnet module is already adding that, the line above would produce:", "\n", "# ELBO/ELBO/reconstruction_loss/node_created", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'reconstruction_loss'", ")", ":", "\n", "\n", "# 1) the log_pdf is computed with respect to distribution of the visible", "\n", "#    variables obtained from the target of input of the graph (self.x_target)", "\n", "\n", "# can I avoid replicate? maybe not..", "\n", "            ", "input_shape", "=", "x_target", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "ones", "=", "[", "1", "]", "*", "len", "(", "input_shape", ")", "\n", "x_replicate", "=", "tf", ".", "tile", "(", "x_target", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "\n", "# no need to check for the values in the interval, since the cdf is defined over R", "\n", "upper", "=", "model_visible", ".", "cdf", "(", "x_replicate", "+", "self", ".", "h", ")", "\n", "lower", "=", "model_visible", ".", "cdf", "(", "x_replicate", "-", "self", ".", "h", ")", "\n", "\n", "delta", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "self", ".", "normalize", ",", "1", ")", ",", "\n", "lambda", ":", "2.0", "*", "self", ".", "h", "+", "NUMTOL", ",", "\n", "lambda", ":", "1.0", ")", "\n", "\n", "reconstr_loss", "=", "-", "tf", ".", "log", "(", "(", "upper", "-", "lower", ")", "/", "delta", "+", "NUMTOL", ")", "\n", "\n", "# #before", "\n", "# reconstr_loss = tf.reshape(reconstr_loss, [n_z_samples, -1]+input_shape)", "\n", "# all_axis_but_first_2 = list(range(len(reconstr_loss.shape)))[2:]", "\n", "# #independent p for each input pixel", "\n", "# log_p = tf.reduce_sum(reconstr_loss, axis=all_axis_but_first_2)", "\n", "# #average over the samples", "\n", "# mean_reconstr_loss = tf.reduce_mean(log_p, axis=0)", "\n", "\n", "#now (ready for arbitrary intermediate samplings)", "\n", "all_axis_but_first", "=", "list", "(", "range", "(", "len", "(", "reconstr_loss", ".", "shape", ")", ")", ")", "[", "1", ":", "]", "\n", "#independent p for each input pixel", "\n", "log_p", "=", "tf", ".", "reduce_sum", "(", "reconstr_loss", ",", "axis", "=", "all_axis_but_first", ")", "\n", "#average over all the samples and the batch (they are both stacked on the axis 0)", "\n", "mean_reconstr_loss", "=", "tf", ".", "reduce_mean", "(", "log_p", ",", "axis", "=", "0", ",", "name", "=", "\"reconstruction_loss\"", ")", "\n", "\n", "# self.log_p_x_z = mean_reconstr_loss", "\n", "\n", "", "return", "mean_reconstr_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.__init__": [[42, 56], ["WavenetAENetwork.WavenetAENetwork.WavenetAENetwork", "argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "argo.core.network.AbstractAutoEncoder.AbstractAutoEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "# NB need to create the network before the super().__init__ because id generation depends on the network", "\n", "        ", "self", ".", "_network", "=", "WavenetAENetwork", "(", "opts", ")", "\n", "self", ".", "_cost_function", "=", "CostFunctions", ".", "instantiate_cost_function", "(", "opts", "[", "\"cost_function\"", "]", ")", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n", "self", ".", "x_reconstruction_distr_tf", "=", "None", "\n", "self", ".", "x_reconstruction_node_tf", "=", "None", "\n", "self", ".", "x_reconstruction_distr", "=", "None", "\n", "self", ".", "x_reconstruction_node", "=", "None", "\n", "self", ".", "z", "=", "None", "\n", "self", ".", "x_shifted_qs", "=", "None", "\n", "self", ".", "loss_t", "=", "None", "\n", "self", ".", "loss_tf", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.create_id": [[57, 68], ["super().create_id", "WavenetAE.WavenetAE._network.create_id", "WavenetAE.WavenetAE._cost_function.create_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["", "def", "create_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "self", ".", "launchable_name", "\n", "\n", "_id", "+=", "'-c'", "+", "self", ".", "_cost_function", ".", "create_id", "(", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "network_id", "=", "self", ".", "_network", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "+", "network_id", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.create_hooks": [[69, 192], ["super().create_hooks", "tensorflow.cast", "tensorflow.image.psnr", "wavenet.mel_utils_tensorflow.mfcc", "wavenet.mel_utils_tensorflow.mfcc", "wavenet.mel_utils_tensorflow.mcd", "super().create_hooks.append", "config.get", "config.get", "config.get", "config.get", "tensorflow.reduce_prod", "tensorflow.log", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "tensorflow.reduce_max", "WavReconstructHook.WavReconstructHook.WavReconstructHook", "WavGenerateHook.WavGenerateHook.WavGenerateHook", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook", "PCALatentVariablesHook.PCALatentVariablesHook.PCALatentVariablesHook", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mcd", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "        ", "hooks", "=", "super", "(", ")", ".", "create_hooks", "(", "config", ")", "\n", "\n", "# LOGGING HOOKS", "\n", "\n", "# the shape of the input could be different from train to eval", "\n", "dim_with_channels", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "self", ".", "x", ")", "[", "1", ":", "]", ")", ",", "\n", "tf", ".", "float32", ")", "\n", "\n", "# check https://www.reddit.com/r/MachineLearning/comments/56m5o2/discussion_calculation_of_bitsdims/", "\n", "bits_dim", "=", "(", "self", ".", "loss", "/", "dim_with_channels", ")", "/", "tf", ".", "log", "(", "2.0", ")", "# - tf.log(256.0)", "\n", "\n", "psnr_reconstruction_quality", "=", "tf", ".", "image", ".", "psnr", "(", "self", ".", "x", ",", "self", ".", "x_reconstruction_node_tf", ",", "\n", "max_val", "=", "tf", ".", "reduce_max", "(", "self", ".", "x", ")", ")", "\n", "\n", "sample_rate", "=", "self", ".", "dataset", ".", "sample_rate", "\n", "mfcc_original", "=", "mfcc", "(", "self", ".", "x", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "mfcc_reconstructed", "=", "mfcc", "(", "self", ".", "x_reconstruction_node_tf", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "mcd_reconstruction_quality", "=", "mcd", "(", "mfcc_original", ",", "mfcc_reconstructed", ")", "\n", "\n", "tensors_to_average", "=", "[", "\n", "[", "[", "psnr_reconstruction_quality", "]", "\n", "]", ",", "\n", "[", "[", "mcd_reconstruction_quality", "]", "\n", "]", ",", "\n", "[", "[", "self", ".", "loss", "]", ",", "\n", "]", ",", "\n", "[", "*", "[", "[", "name", "]", "for", "name", "in", "self", ".", "nodes_to_track", "]", "\n", "]", ",", "\n", "[", "[", "bits_dim", "]", ",", "\n", "]", "\n", "]", "\n", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "'PSNR_reconstruction_quality'", "]", "\n", "]", ",", "\n", "[", "[", "'MCD_reconstruction_distortion'", "]", "\n", "]", ",", "\n", "[", "[", "\"nll_loss\"", "]", "\n", "]", ",", "\n", "[", "*", "[", "[", "name", "]", "for", "name", "in", "self", ".", "names_nodes_to_track", "]", "\n", "]", ",", "\n", "[", "[", "\"b/d\"", "]", "\n", "]", "\n", "]", "\n", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\n", "\"fileName\"", ":", "'psnr_reconstr_quality'", "}", "\n", "]", ",", "\n", "[", "{", "\n", "\"fileName\"", ":", "'mcd_reconstr_distortion'", "}", "\n", "]", ",", "\n", "[", "{", "\"fileName\"", ":", "\"loss\"", "}", "\n", "]", ",", "\n", "[", "{", "\"fileName\"", ":", "\"nodes_loss\"", "}", "\n", "]", ",", "\n", "[", "{", "\"fileName\"", ":", "\"bits_dim\"", "}", "\n", "]", ",", "\n", "]", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", ")", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"WavReconstructHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "WavReconstructHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"WavGenerateHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "WavGenerateHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"TwoDimPCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "TwoDimPCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "z", "]", ",", "\n", "tensors_names", "=", "[", "'z'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"PCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "PCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "z", "]", ",", "\n", "tensors_names", "=", "[", "'z'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.create_network": [[193, 220], ["WavenetAE.WavenetAE._network", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "create_network", "(", "self", ")", ":", "\n", "# create autoencoder network", "\n", "# self.x_shifted, self.z, self.x_reconstruction_distr, self.x_reconstruction_node, self.x_gen = self._network(self.x)", "\n", "        ", "net", "=", "self", ".", "_network", "(", "self", ".", "x", ")", "\n", "\n", "self", ".", "x_shifted_qs", "=", "net", "[", "\"x_shifted_qs\"", "]", "\n", "self", ".", "z", "=", "net", "[", "\"z\"", "]", "\n", "self", ".", "_upsample_encoding", "=", "net", "[", "'upsample_encoding'", "]", "\n", "self", ".", "z_upsampled", "=", "net", "[", "'z_upsampled'", "]", "\n", "\n", "self", ".", "x_reconstruction_distr_tf", "=", "net", "[", "\"x_rec_distr_tf\"", "]", "\n", "self", ".", "x_reconstruction_logits_tf", "=", "self", ".", "x_reconstruction_distr_tf", ".", "logits", "\n", "self", ".", "x_reconstruction_node_tf", "=", "net", "[", "\"x_rec_tf\"", "]", "\n", "\n", "self", ".", "x_t", "=", "net", "[", "\"x_t\"", "]", "\n", "self", ".", "x_t_qs", "=", "net", "[", "\"x_t_qs\"", "]", "\n", "self", ".", "z_t", "=", "net", "[", "\"z_t\"", "]", "\n", "self", ".", "x_target_t", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'x_target_t'", ")", "\n", "self", ".", "x_target_quantized", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "'x_target_quantized'", ")", "\n", "self", ".", "x_tp1_distr", "=", "net", "[", "\"x_tp1_distr\"", "]", "\n", "self", ".", "x_tp1", "=", "net", "[", "\"x_tp1\"", "]", "\n", "self", ".", "queues_init_ops", "=", "net", "[", "\"queues_init_ops\"", "]", "\n", "self", ".", "queues_push_ops", "=", "net", "[", "\"queues_push_ops\"", "]", "\n", "self", ".", "queues_dicts", "=", "net", "[", "\"queues_dicts\"", "]", "\n", "\n", "self", ".", "queues_dequeue", "=", "[", "qd", "[", "\"dequeue\"", "]", "for", "qd", "in", "self", ".", "queues_dicts", "]", "\n", "self", ".", "queues_size", "=", "[", "qd", "[", "\"size\"", "]", "for", "qd", "in", "self", ".", "queues_dicts", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.create_loss": [[221, 228], ["WavenetAE.WavenetAE._cost_function", "WavenetAE.WavenetAE._cost_function.loss_per_sample", "WavenetAE.WavenetAE._cost_function.loss_per_sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAECostFunction.WavenetAECostFunction.loss_per_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAECostFunction.WavenetAECostFunction.loss_per_sample"], ["", "def", "create_loss", "(", "self", ")", ":", "\n", "# A TFDeepLearningModel model should be free to specify a model dependent loss..", "\n", "# compute the cost function, passing the model as a parameter", "\n", "        ", "self", ".", "loss", ",", "self", ".", "nodes_to_track", ",", "self", ".", "names_nodes_to_track", "=", "self", ".", "_cost_function", "(", "self", ")", "\n", "\n", "self", ".", "loss_t", "=", "self", ".", "_cost_function", ".", "loss_per_sample", "(", "self", ".", "x_tp1_distr", ".", "logits", ",", "self", ".", "x_target_t", ")", "\n", "self", ".", "loss_tf", "=", "self", ".", "_cost_function", ".", "loss_per_sample", "(", "self", ".", "x_reconstruction_logits_tf", ",", "self", ".", "x_target_quantized", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.encode": [[229, 257], ["WavenetAE.WavenetAE.get_raw_session", "sess.run", "WavenetAE.WavenetAE.encode", "zs.append", "x_shifted_list.append", "min", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode"], ["", "def", "encode", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Encode data by mapping it into the latent space.\"\"\"", "\n", "\n", "# sess = sess or self.get_raw_session()", "\n", "#", "\n", "# return sess.run([self.z, self.x_shifted_qs], feed_dict={", "\n", "#     self.x: X})", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "bs", ",", "length", ",", "ch", "=", "X", ".", "shape", "\n", "bs_train", "=", "self", ".", "batch_size", "[", "'train'", "]", "\n", "\n", "if", "self", ".", "_network", ".", "_e_hidden_channels", ">", "128", "and", "bs", ">", "bs_train", ":", "\n", "            ", "zs", ",", "x_shifted_list", "=", "[", "]", ",", "[", "]", "\n", "start_batch", ",", "end_batch", "=", "0", ",", "bs_train", "\n", "\n", "while", "start_batch", "!=", "end_batch", ":", "\n", "                ", "z", ",", "x_shifted", "=", "self", ".", "encode", "(", "X", "[", "start_batch", ":", "end_batch", "]", ")", "\n", "zs", ".", "append", "(", "z", ")", "\n", "x_shifted_list", ".", "append", "(", "x_shifted", ")", "\n", "\n", "start_batch", "=", "end_batch", "\n", "end_batch", "=", "min", "(", "bs", ",", "end_batch", "+", "bs_train", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "zs", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "x_shifted_list", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "sess", ".", "run", "(", "[", "self", ".", "z", ",", "self", ".", "x_shifted_qs", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.decode_tf": [[258, 288], ["min", "numpy.zeros", "numpy.zeros", "WavenetAE.WavenetAE.get_raw_session", "sess.run", "numpy.mean", "min"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "", "def", "decode_tf", "(", "self", ",", "Z", ",", "X_shifted", ",", "x_target_quantized", ",", "sess", "=", "None", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data for an autoregressive model,\n        with teacher forcing.\n            Args:\n                x_target_quantized (np.array): the target signal with values in range [0, 256]\n                                                and shape (bs, signal_length)\n            Returns:\n                reconstruction from Z and the associated reconstruction loss\n        \"\"\"", "\n", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "total_batch", ",", "signal_length", "=", "x_target_quantized", ".", "shape", "\n", "mini_batch_size", "=", "min", "(", "batch_size", "or", "total_batch", ",", "total_batch", ")", "\n", "start_batch", ",", "end_batch", "=", "0", ",", "mini_batch_size", "\n", "\n", "reconstruction", "=", "np", ".", "zeros", "(", "(", "total_batch", ",", "signal_length", ",", "1", ")", ")", "\n", "reconstr_losses", "=", "np", ".", "zeros", "(", "(", "total_batch", ")", ")", "\n", "\n", "while", "start_batch", "!=", "end_batch", ":", "\n", "            ", "reconstruction", "[", "start_batch", ":", "end_batch", "]", ",", "reconstr_loss", "=", "sess", ".", "run", "(", "[", "self", ".", "x_reconstruction_node_tf", ",", "self", ".", "loss_tf", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "z", ":", "Z", "[", "start_batch", ":", "end_batch", "]", ",", "\n", "self", ".", "x_shifted_qs", ":", "X_shifted", "[", "start_batch", ":", "end_batch", "]", ",", "\n", "self", ".", "x_target_quantized", ":", "x_target_quantized", "[", "start_batch", ":", "end_batch", "]", "\n", "}", ")", "\n", "reconstr_losses", "[", "start_batch", ":", "end_batch", "]", "=", "np", ".", "mean", "(", "reconstr_loss", ",", "axis", "=", "1", ")", "\n", "start_batch", "=", "end_batch", "\n", "end_batch", "=", "min", "(", "end_batch", "+", "mini_batch_size", ",", "total_batch", ")", "\n", "\n", "", "return", "reconstruction", ",", "reconstr_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.reconstruct_tf": [[289, 298], ["sess.run", "WavenetAE.WavenetAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "reconstruct_tf", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use AE to reconstruct given data.\n        With teacher forcing.\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node_tf", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.decode": [[299, 375], ["sess.run", "numpy.zeros", "time.time", "range", "time.time", "tf_logging.info", "time.time", "wavenet.utils.empty_all_queues", "time.time", "tf_logging.info", "all", "WavenetAE.WavenetAE.get_raw_session", "sess.run", "numpy.zeros", "losses.append", "numpy.array", "sess.run", "numpy.mean", "tf_logging.info", "str", "str().zfill", "str", "str().zfill", "int", "int", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.empty_all_queues", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "decode", "(", "self", ",", "Z", ",", "X_0", "=", "None", ",", "input_qs", "=", "False", ",", "sess", "=", "None", ",", "x_target_quantized", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data for wavenet autoregressive model\n            Args:\n                x_target_quantized (np.array): the target signal with values in range [0, 256]\n                                                and shape (bs, signal_length)\n\n            Returns:\n                the reconstruction without teacher forcing from Z and the associated reconstruction loss computed\n                at each time step individually\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "bs", ",", "z_length", ",", "z_ch", "=", "Z", ".", "shape", "\n", "hop_length", "=", "self", ".", "_network", ".", "_hop_length", "\n", "time_length", "=", "z_length", "*", "hop_length", "\n", "\n", "if", "self", ".", "_upsample_encoding", ":", "\n", "            ", "Z", "=", "sess", ".", "run", "(", "self", ".", "z_upsampled", ",", "feed_dict", "=", "{", "self", ".", "z", ":", "Z", "}", ")", "\n", "hop_length", "=", "1", "\n", "\n", "# assume x single channel", "\n", "", "if", "X_0", "is", "None", ":", "\n", "            ", "X_0", "=", "np", ".", "zeros", "(", "[", "bs", ",", "1", ",", "1", "]", ")", "\n", "\n", "#beware here we can input x_t or x_t_qs, maybe x_t_qs ia better but we should test this", "\n", "# inputs_node = self.x_t", "\n", "", "if", "input_qs", ":", "\n", "            ", "inputs_node", "=", "self", ".", "x_t_qs", "\n", "", "else", ":", "\n", "            ", "inputs_node", "=", "self", ".", "x_t", "\n", "\n", "# initialize the fast generation queues with all 0s, x_t is needed for the batch_size", "\n", "", "sess", ".", "run", "(", "self", ".", "queues_init_ops", ",", "feed_dict", "=", "{", "inputs_node", ":", "X_0", "}", ")", "\n", "\n", "audio_batch", "=", "np", ".", "zeros", "(", "(", "bs", ",", "time_length", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "x", "=", "X_0", "\n", "\n", "losses", "=", "[", "]", "\n", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "for", "t", "in", "range", "(", "time_length", ")", ":", "\n", "            ", "i_z", "=", "t", "//", "hop_length", "\n", "x", ",", "loss_t", "=", "sess", ".", "run", "(", "[", "self", ".", "x_tp1", ",", "self", ".", "loss_t", ",", "self", ".", "queues_push_ops", "]", ",", "\n", "feed_dict", "=", "{", "inputs_node", ":", "x", ",", "\n", "self", ".", "z_t", ":", "Z", "[", ":", ",", "i_z", ":", "i_z", "+", "1", ",", ":", "]", ",", "\n", "self", ".", "x_target_t", ":", "x_target_quantized", "[", ":", ",", "t", ":", "t", "+", "1", "]", "\n", "}", "\n", ")", "[", "0", ":", "2", "]", "\n", "audio_batch", "[", ":", ",", "t", ",", "0", "]", "=", "x", "[", ":", ",", "0", ",", "0", "]", "\n", "losses", ".", "append", "(", "np", ".", "mean", "(", "loss_t", ")", ")", "\n", "\n", "if", "t", "%", "1000", "==", "0", ":", "\n", "                ", "tf_logging", ".", "info", "(", "\"Sample: %d\"", "%", "t", ")", "\n", "", "", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"decoding time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "#NB(Riccardo) I dequeue all the elements from the queues, otherwise next call to queues_init_ops will hang indefinitely", "\n", "# for faster dequeuing the batch size should be fixed, to be able to use q.dequeue_many(qsize)", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "all_sizes", "=", "empty_all_queues", "(", "sess", ",", "self", ".", "queues_size", ",", "self", ".", "queues_dequeue", ")", "\n", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"dequeuing time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "# naive dequeuing (slow)", "\n", "# all_sizes = []", "\n", "# for qs, qd in zip(:", "\n", "#     qsize = sess.run(dq[\"size\"])", "\n", "#     all_sizes.append(dq[\"size\"])", "\n", "#     for i in range(qsize):", "\n", "#         sess.run(dq[\"dequeue\"])", "\n", "\n", "assert", "all", "(", "all_sizes", "==", "0", ")", ",", "\"queues not succefully emptied after decoding\"", "\n", "\n", "return", "audio_batch", ",", "np", ".", "array", "(", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.mean_reconstr_loss": [[376, 381], ["numpy.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "mean_reconstr_loss", "(", "self", ",", "individual_losses", ")", ":", "\n", "        ", "'''This method is used in WavGenerateHook in order to be able to compute the loss separately for hs, zs train\n            and validation. This is because we decode all of the above samples at once to reduce time\n        '''", "\n", "return", "np", ".", "mean", "(", "individual_losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.decode_debug_astf": [[382, 423], ["sess.run", "numpy.zeros", "time.time", "range", "time.time", "tf_logging.info", "time.time", "wavenet.utils.empty_all_queues", "time.time", "tf_logging.info", "all", "WavenetAE.WavenetAE.get_raw_session", "sess.run", "tf_logging.info", "str", "str().zfill", "str", "str().zfill", "int", "int", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.empty_all_queues", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "decode_debug_astf", "(", "self", ",", "Z", ",", "X_shifted", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data for wavenet autoregressive model,\n        test of the fast generation to see if it is equal to the tf. It should be.\"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "bs", ",", "z_length", ",", "z_ch", "=", "Z", ".", "shape", "\n", "hop_length", "=", "self", ".", "_network", ".", "_hop_length", "\n", "time_length", "=", "z_length", "*", "hop_length", "\n", "\n", "assert", "X_shifted", ".", "shape", "==", "(", "bs", ",", "time_length", ",", "1", ")", "\n", "\n", "# initialize the fast generation queues with all 0s, x_t is needed for the batch_size", "\n", "sess", ".", "run", "(", "self", ".", "queues_init_ops", ",", "feed_dict", "=", "{", "self", ".", "x_t_qs", ":", "X_shifted", "[", ":", ",", ":", "1", ",", ":", "]", "}", ")", "\n", "\n", "audio_batch", "=", "np", ".", "zeros", "(", "(", "bs", ",", "time_length", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "for", "t", "in", "range", "(", "time_length", ")", ":", "\n", "            ", "i_z", "=", "t", "//", "hop_length", "\n", "x", "=", "sess", ".", "run", "(", "[", "self", ".", "x_tp1", ",", "self", ".", "queues_push_ops", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "x_t_qs", ":", "X_shifted", "[", ":", ",", "t", ":", "t", "+", "1", ",", ":", "]", ",", "self", ".", "z_t", ":", "Z", "[", ":", ",", "i_z", ":", "i_z", "+", "1", ",", ":", "]", "}", ")", "[", "0", "]", "\n", "audio_batch", "[", ":", ",", "t", ",", "0", "]", "=", "x", "[", ":", ",", "0", ",", "0", "]", "\n", "if", "t", "%", "1000", "==", "0", ":", "\n", "                ", "tf_logging", ".", "info", "(", "\"Sample: %d\"", "%", "t", ")", "\n", "", "", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"decoding time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "#NB(Riccardo) I dequeue all the elements from the queues, otherwise next call to queues_init_ops will hang indefinitely", "\n", "# for faster dequeuing the batch size should be fixed, to be able to use q.dequeue_many(qsize)", "\n", "\n", "# smart dequeuing contemporaneously on all queues till I can", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "all_sizes", "=", "empty_all_queues", "(", "sess", ",", "self", ".", "queues_size", ",", "self", ".", "queues_dequeue", ")", "\n", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"dequeuing time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "assert", "all", "(", "all_sizes", "==", "0", ")", ",", "\"queues not succefully emptied after decoding\"", "\n", "\n", "return", "audio_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.reconstruct": [[424, 433], ["WavenetAE.WavenetAE.encode", "WavenetAE.WavenetAE.decode", "WavenetAE.WavenetAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "reconstruct", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use AE to reconstruct given data.\n        With teacher forcing.\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "Z", ",", "_", "=", "self", ".", "encode", "(", "X", ",", "sess", "=", "sess", ")", "\n", "\n", "return", "self", ".", "decode", "(", "Z", ",", "sess", "=", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAE.WavenetAE.generate": [[434, 436], ["None"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "X", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.create_id": [[38, 51], ["super().create_id", "AE.AutoEncoder._network.create_id", "AE.AutoEncoder._cost_function.create_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "self", ".", "launchable_name", "\n", "\n", "#_id += '-c' + CostFunctions.create_id(opts[\"cost_function\"])", "\n", "_id", "+=", "'-c'", "+", "self", ".", "_cost_function", ".", "create_id", "(", "self", ".", "_opts", "[", "\"cost_function\"", "]", "[", "1", "]", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "network_id", "=", "self", ".", "_network", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "+", "network_id", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.__init__": [[52, 110], ["AENetwork.AENetwork.AENetwork", "argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "argo.core.network.AbstractAutoEncoder.AbstractAutoEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "\n", "# notice that in the following opts is used, and not self._opts, until the", "\n", "# parent constructor is called", "\n", "\n", "#NB need to create the network before the super init because id generation depends on the network", "\n", "        ", "self", ".", "_network", "=", "AENetwork", "(", "opts", ",", "\"ae_network\"", ",", "seed", "=", "seed", ")", "\n", "self", ".", "_cost_function", "=", "CostFunctions", ".", "instantiate_cost_function", "(", "opts", "[", "\"cost_function\"", "]", ",", "module_path", "=", "\"vae\"", ")", "\n", "\n", "# self.covariance_parameterization = opts[\"covariance_parameterization\"]", "\n", "\n", "# be careful with initialization in the following, since values have to be float", "\n", "\n", "'''\n        if opts[\"cost_function\"][\"cost\"]==\"renyi\" or opts[\"cost_function\"][\"cost\"]==\"irenyi\":\n            if \"alpha\" not in opts[\"cost_function\"]:\n                opts[\"cost_function\"][\"alpha\"] = 1.0\n            self.alpha_default = opts[\"cost_function\"][\"alpha\"]\n\n        # beta parameter for *elbo\n        if opts[\"cost_function\"][\"cost\"]==\"elbo\" or opts[\"cost_function\"][\"cost\"]==\"ielbo\":\n            if \"beta\" not in opts[\"cost_function\"]:\n                opts[\"cost_function\"][\"beta\"] = 1.0\n            self.beta_default = opts[\"cost_function\"][\"beta\"]\n\n        # h parameter for ielbo and irenyi\n        if opts[\"cost_function\"][\"cost\"]==\"ielbo\" or opts[\"cost_function\"][\"cost\"]==\"irenyi\":\n            if \"h\" not in opts[\"cost_function\"]:\n                opts[\"cost_function\"][\"h\"] = 0.01\n            self.h_default = opts[\"cost_function\"][\"h\"]\n\n        # normalize for ielbo and irenyi\n        if opts[\"cost_function\"][\"cost\"]==\"ielbo\" or opts[\"cost_function\"][\"cost\"]==\"irenyi\":\n            if \"normalize\" not in opts[\"cost_function\"]:\n                opts[\"cost_function\"][\"normalize\"] = 0\n            self.h_normalize = opts[\"cost_function\"][\"normalize\"]\n        '''", "\n", "\n", "# TODOfunctionlogger: change this name to avoid confusion with self.cost_function", "\n", "self", ".", "_cost_function_tuple", "=", "opts", "[", "\"cost_function\"", "]", "\n", "\n", "#TODO-ARGO2 why is samples never used in the code and where should it be used?", "\n", "#self.samples_number = opts[\"samples\"]", "\n", "\n", "#TODO-ARGO2 this n_z_samples is a property of the network, is it really necessary to have it in the model?", "\n", "#TODO-ARGO2 how is this changing when we will use tf.distributions sampling and hopefully remove the replication?", "\n", "#TODO-ARGO2 n_z_samples should not be a placeholder but call Normal.samples(n_z_samples) produces the desired tensor, which can subsequently be reduced in the 0 axis to average over samples...", "\n", "#self.n_x_samples = self._network.n_x_samples", "\n", "\n", "# # replicate x", "\n", "# self.x_replicate = {}", "\n", "# self.x_target_replicate = {}", "\n", "\n", "# important nodes", "\n", "self", ".", "_model_visible", "=", "None", "\n", "self", ".", "x_reconstruction_node", "=", "None", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.create_hooks": [[111, 201], ["super().create_hooks", "super().create_hooks.append", "config.get", "config.get", "config.get", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "AEImagesReconstructHook.AEImagesReconstructHook.AEImagesReconstructHook", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook", "PCALatentVariablesHook.PCALatentVariablesHook.PCALatentVariablesHook"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks"], ["", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "        ", "hooks", "=", "super", "(", ")", ".", "create_hooks", "(", "config", ")", "\n", "\n", "#LOGGING HOOKS", "\n", "\n", "\n", "# check https://www.reddit.com/r/MachineLearning/comments/56m5o2/discussion_calculation_of_bitsdims/", "\n", "# to understand why I need to shid by log(256)", "\n", "\n", "\n", "# TODO the two shapes could be different, maybe use tf.shape(self.raw_x) (Riccardo)", "\n", "# dim_with_channels = np.prod(self.x_shape[\"train\"])", "\n", "# dim_with_channels = np.prod(self.x_shape[\"eval\"])", "\n", "#", "\n", "# # check https://www.reddit.com/r/MachineLearning/comments/56m5o2/discussion_calculation_of_bitsdims/", "\n", "# # to understand why I need to shid by log(256)", "\n", "# bits_dim = (self.loss/dim_with_channels - tf.log(256.0) )/tf.log(2.0)", "\n", "#", "\n", "\n", "tensors_to_average", "=", "[", "\n", "[", "[", "self", ".", "loss", "]", "\n", "]", ",", "\n", "self", ".", "loss_nodes_to_log", "\n", "]", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "\"loss\"", "]", "\n", "]", ",", "\n", "self", ".", "loss_nodes_to_log_names", "\n", "]", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\"fileName\"", ":", "\"loss\"", "}", "\n", "]", ",", "\n", "self", ".", "loss_nodes_to_log_filenames", "\n", "]", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", ")", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"ImagesReconstructHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "AEImagesReconstructHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"TwoDimPCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "TwoDimPCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "h", "]", ",", "\n", "tensors_names", "=", "[", "'h'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"PCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "PCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "h", "]", ",", "\n", "tensors_names", "=", "[", "'h'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "\n", "#TODO-ARGO2 append here specific AE loggers as hooks", "\n", "\n", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.create_network": [[216, 220], ["AE.AutoEncoder._network", "AE.AutoEncoder._model_visible.reconstruction_node"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node"], ["", "def", "create_network", "(", "self", ")", ":", "\n", "# create autoencoder network", "\n", "        ", "self", ".", "h", ",", "self", ".", "_model_visible", "=", "self", ".", "_network", "(", "self", ".", "x", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "self", ".", "x_reconstruction_node", "=", "self", ".", "_model_visible", ".", "reconstruction_node", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.create_loss": [[221, 223], ["AE.AutoEncoder._cost_function"], "methods", ["None"], ["", "def", "create_loss", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss", ",", "self", ".", "loss_nodes_to_log", ",", "self", ".", "loss_nodes_to_log_names", ",", "self", ".", "loss_nodes_to_log_filenames", "=", "self", ".", "_cost_function", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.encode": [[224, 231], ["sess.run", "AE.AutoEncoder.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "encode", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Encode data by mapping it into the latent space.\"\"\"", "\n", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "self", ".", "h", ",", "\n", "feed_dict", "=", "{", "self", ".", "raw_x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.decode": [[233, 239], ["sess.run", "AE.AutoEncoder.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "decode", "(", "self", ",", "H", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data.\"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node", ",", "\n", "feed_dict", "=", "{", "self", ".", "h", ":", "H", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.reconstruct": [[240, 247], ["sess.run", "AE.AutoEncoder.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "reconstruct", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use AE to reconstruct given data. \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "#if self.binary:", "\n", "return", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node", ",", "\n", "feed_dict", "=", "{", "self", ".", "n_z_samples", ":", "1", ",", "self", ".", "raw_x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AE.AutoEncoder.generate": [[249, 251], ["None"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "batch_size", "=", "1", ",", "sess", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel.__init__": [[63, 98], ["argo.core.network.load_network.instantiate_network", "argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "opts.get", "int", "tensorflow.placeholder_with_default", "argo.core.TFDeepLearningModel.TFDeepLearningModel.__init__", "copy.deepcopy", "opts.get", "int", "cost_kwargs.get"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.load_network.instantiate_network", "home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "\n", "# check if I need the following lines", "\n", "#", "\n", "# NB need to create the network before the super init because id generation depends on the network", "\n", "#self._network = FFNetwork(opts, \"ff_network\")", "\n", "#super().__init__(opts, dirName, check_ops, gpu, seed)", "\n", "#", "\n", "#self.stochastic = opts[\"stochastic\"]", "\n", "#self.stochastic_noise_param = opts[\"stochastic_noise_param\"]", "\n", "#self.rescale = opts[\"rescale\"] # rescale the inputs if they are continuous", "\n", "\n", "######################################################", "\n", "\n", "# in the following I pass opts, since the parent constructor has not been called yet", "\n", "        ", "self", ".", "_network", "=", "instantiate_network", "(", "copy", ".", "deepcopy", "(", "opts", ")", ",", "\"ff_network\"", ")", "\n", "self", ".", "_cost_function", "=", "CostFunctions", ".", "instantiate_cost_function", "(", "opts", "[", "\"cost_function\"", "]", ",", "module_path", "=", "\"prediction\"", ")", "\n", "\n", "self", ".", "network_output", "=", "None", "\n", "self", ".", "_preproc_tuple", "=", "opts", ".", "get", "(", "\"preprocess\"", ",", "None", ")", "\n", "\n", "n_samples_train", "=", "int", "(", "opts", ".", "get", "(", "\"n_samples_train\"", ",", "1", ")", ")", "\n", "\n", "# temporary backcompatibility", "\n", "if", "n_samples_train", "==", "1", ":", "\n", "            ", "cost_kwargs", "=", "opts", "[", "'cost_function'", "]", "[", "1", "]", "\n", "n_samples_train", "=", "int", "(", "cost_kwargs", ".", "get", "(", "\"n_samples\"", ",", "1", ")", ")", "\n", "\n", "", "self", ".", "n_samples_ph", "=", "tf", ".", "placeholder_with_default", "(", "n_samples_train", ",", "shape", "=", "(", ")", ",", "name", "=", "'n_samples'", ")", "\n", "\n", "# parent constructor called last", "\n", "# notice here I pass opts", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n", "self", ".", "_pb_output_nodes", "=", "[", "\"logits\"", ",", "\"ff_network/network/features\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel.create_id": [[99, 119], ["Prediction.PredictionModel._opts.get", "super().create_id", "Prediction.PredictionModel._network.create_id", "Prediction.PredictionModel._cost_function.create_id", "len", "argo.core.utils.argo_utils.get_method_id", "Prediction.PredictionModel._opts[].keys", "Prediction.PredictionModel.create_custom_regularizers_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers_id"], ["", "def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "self", ".", "launchable_name", "\n", "\n", "# add to the ID the information of the cost function", "\n", "_id", "+=", "'-c'", "+", "self", ".", "_cost_function", ".", "create_id", "(", "self", ".", "_opts", "[", "\"cost_function\"", "]", "[", "1", "]", ")", "\n", "\n", "#str_type = get_short_dtype(opts[\"dtype\"])", "\n", "preproc_tuple", "=", "self", ".", "_opts", ".", "get", "(", "\"preprocess\"", ",", "None", ")", "\n", "if", "preproc_tuple", "is", "not", "None", ":", "\n", "            ", "_id", "+=", "'-p'", "+", "get_method_id", "(", "preproc_tuple", ")", "\n", "\n", "", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "network_id", "=", "self", ".", "_network", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "+", "network_id", "\n", "if", "len", "(", "self", ".", "_opts", "[", "\"regularizers\"", "]", ".", "keys", "(", ")", ")", ">", "0", ":", "\n", "            ", "_id", "+=", "'-cr'", "+", "self", ".", "create_custom_regularizers_id", "(", ")", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel.create_network": [[120, 169], ["Prediction.PredictionModel._network", "isinstance", "isinstance", "Prediction.PredictionModel._network.get_keras_losses", "isinstance", "tensorflow.squeeze", "Prediction.PredictionModel.check_output_shape", "tensorflow.identity", "Prediction.PredictionModel.check_output_shape", "tensorflow.reduce_mean", "Prediction.PredictionModel.prediction_distr.mean", "Prediction.PredictionModel.prediction_distr.sample", "Prediction.PredictionModel.prediction_mean.get_shape", "Prediction.PredictionModel.logits.get_shape", "Prediction.PredictionModel.prediction_distr.sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork.get_keras_losses", "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.RegressionModel.check_output_shape", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.RegressionModel.check_output_shape", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "create_network", "(", "self", ")", ":", "\n", "# TODO this is not the place for such a specific thing (?)", "\n", "# TODO Please drop stuffs in specific places not in standard interfaces. Inheritance avoid `if`.", "\n", "\n", "        ", "'''\n        # Now I know this, since the optimizers has been already set\n        if isinstance(self._optimizer, DropOneLogitOptimizer):\n            self._drop_one_logit = 1\n            for i in range(3000):\n                print(\"TODO up this line here. MSE is innocent, does not want drop_one_logit... (?)\")\n        else:\n            self._drop_one_logit = 0\n        '''", "\n", "\n", "# create feed-forward network", "\n", "# TODO also here drop stuffs... let us not pollute the interfaces to the networks please. Inherit, and implement specific behaviours.", "\n", "self", ".", "network_output", "=", "self", ".", "_network", "(", "self", ".", "x", ",", "is_training", "=", "self", ".", "is_training", ")", "#, drop_one_logit=self._drop_one_logit)", "\n", "\n", "# Keras does not use global collections we need a different way to handle it", "\n", "if", "isinstance", "(", "self", ".", "_network", ",", "KerasNetwork", ")", ":", "\n", "            ", "reg_losses", ",", "kl_losses", ",", "update_ops", "=", "self", ".", "_network", ".", "get_keras_losses", "(", "self", ".", "x", ")", "\n", "self", ".", "kl_losses", "+=", "kl_losses", "\n", "self", ".", "update_ops", "+=", "update_ops", "\n", "self", ".", "regularizers", "+=", "reg_losses", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "network_output", ",", "tfp", ".", "distributions", ".", "Distribution", ")", ":", "\n", "            ", "self", ".", "prediction_distr", "=", "self", ".", "network_output", "\n", "\n", "#these creates the nodes we need, they do not compute with sampling if possible (as in the Normal case)", "\n", "if", "isinstance", "(", "self", ".", "prediction_distr", ",", "tfp", ".", "distributions", ".", "TransformedDistribution", ")", ":", "\n", "# mean is not implemented (e.g. flow) so estimate from 10 samples", "\n", "                ", "self", ".", "prediction_mean", "=", "tf", ".", "reduce_mean", "(", "self", ".", "prediction_distr", ".", "sample", "(", "10", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "prediction_mean", "=", "self", ".", "prediction_distr", ".", "mean", "(", ")", "\n", "\n", "# self.prediction_variance = self.prediction_distr.variance()", "\n", "# self.prediction_covariance = self.prediction_distr.covariance()", "\n", "", "self", ".", "prediction_sample", "=", "tf", ".", "squeeze", "(", "self", ".", "prediction_distr", ".", "sample", "(", "1", ")", ",", "axis", "=", "0", ")", "# need this squeeze for flow", "\n", "self", ".", "check_output_shape", "(", "self", ".", "prediction_mean", ".", "get_shape", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "\n", "# set a specific name, so that I can recognize the name in the pb file of the graph", "\n", "            ", "self", ".", "logits", "=", "tf", ".", "identity", "(", "self", ".", "network_output", ",", "name", "=", "\"logits\"", ")", "\n", "#pdb.set_trace()", "\n", "self", ".", "prediction_mean", "=", "self", ".", "logits", "\n", "self", ".", "prediction_sample", "=", "self", ".", "logits", "\n", "# self.prediction_covariance = 0", "\n", "self", ".", "check_output_shape", "(", "self", ".", "logits", ".", "get_shape", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel.create_input_nodes": [[170, 200], ["Prediction.PredictionModel.create_datasets_with_handles", "tensorflow.identity", "tensorflow.placeholder_with_default", "tensorflow.cond", "tensorflow.tile", "Prediction.PredictionModel._augment_data_nodes"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_datasets_with_handles", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel._augment_data_nodes"], ["", "", "def", "create_input_nodes", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        creates input nodes for a feedforward from the dataset\n\n        Sets:\n            x, y\n        \"\"\"", "\n", "\n", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "=", "self", ".", "create_datasets_with_handles", "(", "dataset", ")", "\n", "\n", "'''\n        #perturbed dataset is not contemplated for the prediction case\n        if perturbed_dataset:\n            raise Exception(\"perturbed datasets are not contemplated for the prediction case, use a regular dataset\")\n        '''", "\n", "\n", "# self.ds_raw_x already set in TFDeepLearningModel.py", "\n", "self", ".", "raw_y", "=", "datasets_nodes", "[", "1", "]", "\n", "# set a specific name, so that I can recognize the name in the pb file of the graph", "\n", "self", ".", "raw_x", "=", "tf", ".", "identity", "(", "self", ".", "ds_aug_x", ",", "name", "=", "\"inputs\"", ")", "\n", "\n", "self", ".", "augment_bool", "=", "tf", ".", "placeholder_with_default", "(", "True", ",", "shape", "=", "(", ")", ")", "\n", "self", ".", "_x", "=", "tf", ".", "cond", "(", "self", ".", "augment_bool", ",", "\n", "lambda", ":", "self", ".", "_augment_data_nodes", "(", "self", ".", "raw_x", ")", ",", "\n", "lambda", ":", "self", ".", "raw_x", "\n", ")", "\n", "\n", "self", ".", "x", "=", "tf", ".", "tile", "(", "self", ".", "_x", ",", "[", "self", ".", "n_samples_ph", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "self", ".", "y_shape", "=", "dataset", ".", "y_shape", "\n", "self", ".", "y", "=", "self", ".", "raw_y", "\n", "#self.y = tf.tile(self.raw_y, [self.alpha_samples, 1])", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel._augment_data_nodes": [[203, 231], ["preprocessing.preprocess.get_preproc_module", "Prediction.PredictionModel.preproc_module", "argo.core.utils.argo_utils.tf_sample_discrete_from_continuous", "argo.core.utils.argo_utils.tf_add_gaussian_noise_and_clip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.preprocessing.preprocess.get_preproc_module", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_sample_discrete_from_continuous", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_add_gaussian_noise_and_clip"], ["", "def", "_augment_data_nodes", "(", "self", ",", "dataset_x", ")", ":", "\n", "\n", "# I want to do some general transformation of the input. (Riccardo)", "\n", "# it is before the noise since this transformation might filter the noise otherwise.. (VAE)", "\n", "        ", "if", "self", ".", "_preproc_tuple", ":", "\n", "            ", "self", ".", "preproc_module", "=", "get_preproc_module", "(", "self", ".", "_preproc_tuple", ")", "\n", "dataset_x", "=", "self", ".", "preproc_module", "(", "dataset_x", ")", "\n", "\n", "", "if", "self", ".", "stochastic", ":", "\n", "            ", "if", "self", ".", "binary", ":", "\n", "                ", "dataset_x", "=", "tf_sample_discrete_from_continuous", "(", "dataset_x", ")", "\n", "", "else", ":", "\n", "# TODO here I suppose the input are in -1.,1.", "\n", "                ", "dataset_x", ",", "noise_data", "=", "tf_add_gaussian_noise_and_clip", "(", "dataset_x", ",", "\n", "self", ".", "stochastic_noise_param", ",", "\n", "clip_bool", "=", "self", ".", "_clip_after_noise", ")", "\n", "\n", "# TODO NEVER RESCALE remove it", "\n", "# we need to shrink data to make sure that we don't have 0 and 1 for continuous", "\n", "# data, otherwise we may have \"division by 0\" for the likelihood of the logit-normal", "\n", "# also, this may be usefu for binary data, to avoid gradients equal to zero in the first", "\n", "# layer", "\n", "# #TODO what to do with rescale, should we rescale also on raw_x? What happens if I am an autoencoder and I want to reconstruct target?", "\n", "# if not self.rescale==0.0:", "\n", "#     # TODO add a check that the domain is in [-1,1]", "\n", "#     dataset_x = tf_rescale(dataset_x, self.rescale)", "\n", "\n", "", "", "return", "dataset_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel.create_hooks": [[232, 342], ["super().create_hooks", "super().create_hooks.append", "config.get", "config.get", "config.get", "config.get", "config.get", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.CorrelationHook.CorrelationHook", "super().create_hooks.MCDropoutHook.MCDropoutHook", "super().create_hooks.MCRegressionHook.MCRegressionHook", "super().create_hooks.MCClassificationHook.MCClassificationHook", "super().create_hooks.WeightsHistogramHook.WeightsHistogramHook"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks"], ["", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "        ", "hooks", "=", "super", "(", ")", ".", "create_hooks", "(", "config", ")", "\n", "\n", "# logging hooks", "\n", "\n", "log_tensors_to_average", "=", "self", ".", "loss_nodes_to_log", "\n", "\n", "log_tensors_to_average_names", "=", "self", ".", "loss_nodes_to_log_names", "\n", "\n", "log_tensors_to_average_plots", "=", "self", ".", "loss_nodes_to_log_filenames", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "log_tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "log_tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "log_tensors_to_average_plots", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "#trigger_plot = True,", "\n", "print_to_screen", "=", "True", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "# if you want to remove some dataset from here, make support to specify from conf on which datasets to log, if in doubt ask me please. Riccardo", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", ",", "TEST", "]", "\n", ")", "\n", ")", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"CorrelationHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "'datasets_keys'", ":", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "CorrelationHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"MCDropoutHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "'datasets_keys'", ":", "[", "VALIDATION", ",", "TEST", "]", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "MCDropoutHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"MCRegressionHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "'datasets_keys'", ":", "[", "VALIDATION", ",", "TEST", "]", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "MCRegressionHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"MCClassificationHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "'datasets_keys'", ":", "[", "VALIDATION", ",", "TEST", "]", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "MCClassificationHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "# kwargs = config.get(\"MCDropoutHook_alpha\", None)", "\n", "# if kwargs:", "\n", "#     kwargs = {**self._default_model_hooks_kwargs,", "\n", "#               'datasets_keys' : [TEST,VALIDATION],", "\n", "#               **kwargs}", "\n", "#", "\n", "#     hooks.append(MCDropoutHook_alpha(model=self,", "\n", "#                                dirName=self.dirName,", "\n", "#                                **kwargs))", "\n", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"WeightsHistogramHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "\n", "hooks", ".", "append", "(", "WeightsHistogramHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "", "'''\n        kwargs = config.get(\"HessianHook\", None)\n        if kwargs:\n            kwargs = {**self._default_model_hooks_kwargs,\n                      **kwargs}\n            hooks.append(HessianHook(model = self,\n                                     dirName = self.dirName,\n                                     #tensors = [self.z,\n                                     #           self._gaussian_model_latent_mean],\n                                     #tensors_names = ['z',\n                                     #                 'mu'],\n                                     datasets_keys = [TRAIN, VALIDATION], # don't change the order (Luigi)\n                                     **kwargs\n                                    )\n                         )\n        '''", "\n", "\n", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel.create_loss": [[343, 345], ["Prediction.PredictionModel._cost_function"], "methods", ["None"], ["", "def", "create_loss", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss", ",", "self", ".", "loss_per_sample", ",", "self", ".", "loss_nodes_to_log", ",", "self", ".", "loss_nodes_to_log_names", ",", "self", ".", "loss_nodes_to_log_filenames", "=", "self", ".", "_cost_function", "(", "self", ")", "#, drop_one_logit=self._drop_one_logit)", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.PredictionModel.predict": [[348, 351], ["sess.run", "Prediction.PredictionModel.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "predict", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "prediction_sample", "]", ",", "feed_dict", "=", "{", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.ClassificationModel.check_output_shape": [[368, 380], ["Exception", "shape.as_list"], "methods", ["None"], ["    ", "def", "check_output_shape", "(", "self", ",", "shape", ")", ":", "\n", "#TODO-ARGO2 why mnist labels are not given in one_hot? and how do I know how many classes I should have here?", "\n", "\n", "#if self._drop_one_logit:", "\n", "#    if shape.as_list()[1] != (self.dataset.n_labels-1):", "\n", "#        raise Exception(\"shape `%s` is different from labels shape `%s`,\\", "\n", "#please check network architecture will produce correct output before the softmax\")", "\n", "\n", "#else:", "\n", "        ", "if", "shape", ".", "as_list", "(", ")", "[", "1", "]", "!=", "self", ".", "dataset", ".", "n_labels", ":", "\n", "            ", "raise", "Exception", "(", "\"shape `%s` is different from labels shape `%s`,\\\nplease check network architecture will produce correct output before the softmax\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Prediction.RegressionModel.check_output_shape": [[384, 389], ["list", "Exception", "shape.as_list"], "methods", ["None"], ["    ", "def", "check_output_shape", "(", "self", ",", "shape", ")", ":", "\n", "\n", "        ", "if", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "!=", "list", "(", "self", ".", "dataset", ".", "y_shape", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"shape `%s` is different from regression target shape `%s`,\\\n                    please check network architecture will produce correct output\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.IRenyiBound.IRenyiBound.__init__": [[22, 26], ["VAEFunction.VAEFunction.VAEFunction.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "gaussian_model_observed", ",", "gaussian_model_latent", ")", ":", "\n", "        ", "VAEFunction", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_gaussian_model_observed", "=", "gaussian_model_observed", "\n", "self", ".", "_gaussian_model_latent", "=", "gaussian_model_latent", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.IRenyiBound.IRenyiBound.compute": [[27, 71], ["IRenyiBound.IRenyiBound._gaussian_model_observed.log_pdf", "tensorflow.reshape", "IRenyiBound.IRenyiBound._gaussian_model_latent.log_pdf", "tensorflow.reshape", "tensorflow_probability.distributions.MultivariateNormalDiag()._log_prob", "tensorflow.reshape", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow.reduce_logsumexp", "tensorflow.zeros", "tensorflow.ones"], "methods", ["None"], ["", "def", "compute", "(", "self", ",", "alpha", ",", "x_replicate", ",", "x_reconstruced_mean", ",", "z", ",", "h", ",", "normalize", ")", ":", "\n", "        ", "\"\"\" implement Renyi cost function as in the paper Renyi Divergence Variational Inference,\n            formula [5], with alpha in (0, 1)\n            alpha = 0 => log p(x)\n            alpha -> 1 => KL lower bound\n        \"\"\"", "\n", "'''\n        # log conditional p(x|z)\n        if self._binary==1:\n            self.log_p_x_z = -tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(\n                                                         labels=x_replicate,\n                                                         logits=x_reconstructed_mean), 2)\n        else:\n            #assert self._synthetic==1\n        '''", "\n", "\n", "self", ".", "log_p_x_z", "=", "self", ".", "_gaussian_model_observed", ".", "log_pdf", "(", "x_replicate", ")", "\n", "self", ".", "log_p_x_z", "=", "tf", ".", "reshape", "(", "self", ".", "log_p_x_z", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_n_samples", "]", ")", "\n", "\n", "'''\n        if not self._synthetic:\n            raise AssertionError(\"Renyi bound not yet implemented for continuous real dataset (e.g. MNISTcontinuos\")\n        '''", "\n", "\n", "# log posterior q(z|x)", "\n", "log_q_z_x", "=", "self", ".", "_gaussian_model_latent", ".", "log_pdf", "(", "z", ")", "\n", "log_q_z_x", "=", "tf", ".", "reshape", "(", "log_q_z_x", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_n_samples", "]", ")", "\n", "\n", "# log prior p(z)", "\n", "dim_z", "=", "self", ".", "_gaussian_model_latent", ".", "_dim", "\n", "log_p_z", "=", "tfd", ".", "MultivariateNormalDiag", "(", "tf", ".", "zeros", "(", "dim_z", ")", ",", "tf", ".", "ones", "(", "dim_z", ")", ")", ".", "_log_prob", "(", "z", ")", "\n", "log_p_z", "=", "tf", ".", "reshape", "(", "log_p_z", ",", "[", "-", "1", ",", "self", ".", "_gaussian_model_latent", ".", "_n_samples", "]", ")", "\n", "\n", "# exponent for Renyi expectation -- to avoid numerical issues we use exp of log", "\n", "# use log sum exp trick", "\n", "# TODOestimatefunction: recompute this using the tf function", "\n", "exponent", "=", "(", "1", "-", "alpha", ")", "*", "(", "self", ".", "log_p_x_z", "+", "log_p_z", "-", "log_q_z_x", ")", "\n", "\n", "#max_exponent= tf.reduce_max(exponent, 1, keep_dims=True)", "\n", "#renyi_sum = tf.log(tf.reduce_mean(tf.exp(exponent - max_exponent), 1)) + tf.reduce_mean(max_exponent, 1)", "\n", "\n", "renyi_sum", "=", "-", "tf", ".", "reduce_logsumexp", "(", "exponent", ")", "/", "(", "1", "-", "alpha", ")", "\n", "\n", "return", "renyi_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAEImagesReconstructHook.VAEImagesReconstructHook.do_when_triggered": [[20, 89], ["tf_logging.info", "VAEImagesReconstructHook.VAEImagesReconstructHook.load_images", "VAEImagesReconstructHook.VAEImagesReconstructHook.load_masks", "VAEImagesReconstructHook.VAEImagesReconstructHook.load_labels", "VAEImagesReconstructHook.VAEImagesReconstructHook._model.encode", "argo.core.utils.ImagesSaver.ImagesSaver", "argo.core.utils.ImagesSaver.ImagesSaver.save_images", "VAEImagesReconstructHook.VAEImagesReconstructHook._model.decode", "VAEImagesReconstructHook.VAEImagesReconstructHook._model.decode", "VAEImagesReconstructHook.VAEImagesReconstructHook._model.decode", "VAEImagesReconstructHook.VAEImagesReconstructHook._model.decode", "int", "range", "range", "numpy.ceil", "range", "int", "range", "range", "panel[].append", "panel[].append", "panel[].append", "numpy.ceil", "range", "range", "str().zfill", "len", "panel[].append", "panel[].append", "panel[].append", "len", "len", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_images", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_masks", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_labels", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode"], ["    ", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "#tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for ImagesReconstructHook\"", ")", "\n", "\n", "self", ".", "load_images", "(", "run_context", ".", "session", ")", "\n", "self", ".", "load_masks", "(", "run_context", ".", "session", ")", "\n", "self", ".", "load_labels", "(", "run_context", ".", "session", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_images", ":", "\n", "            ", "y", "=", "self", ".", "_labels", "[", "ds_key", "]", "[", "1", "]", "if", "self", ".", "_conditional", "else", "None", "\n", "\n", "images", "=", "self", ".", "_images", "[", "ds_key", "]", "[", "1", "]", "\n", "\n", "zs", ",", "(", "means", ",", "_", ")", "=", "self", ".", "_model", ".", "encode", "(", "images", ",", "sess", "=", "run_context", ".", "session", ",", "y", "=", "y", ")", "\n", "\n", "if", "self", ".", "_model", ".", "mask", "is", "None", ":", "\n", "                ", "reconstructed_images_no_sampling", "=", "self", ".", "_model", ".", "decode", "(", "means", ",", "sess", "=", "run_context", ".", "session", ",", "y", "=", "y", ")", "\n", "reconstructed_images", "=", "self", ".", "_model", ".", "decode", "(", "zs", ",", "sess", "=", "run_context", ".", "session", ",", "y", "=", "y", ")", "\n", "", "else", ":", "\n", "                ", "masks", "=", "self", ".", "_masks", "[", "ds_key", "]", "[", "1", "]", "\n", "reconstructed_images_no_sampling", "=", "self", ".", "_model", ".", "decode", "(", "means", ",", "sess", "=", "run_context", ".", "session", ",", "mask", "=", "masks", ",", "y", "=", "y", ")", "\n", "reconstructed_images", "=", "self", ".", "_model", ".", "decode", "(", "zs", ",", "sess", "=", "run_context", ".", "session", ",", "mask", "=", "masks", ",", "y", "=", "y", ")", "\n", "\n", "", "images_saver", "=", "ImagesSaver", "(", "self", ".", "_dirName", ")", "\n", "\n", "if", "self", ".", "_slice_wise", "==", "None", ":", "\n", "                ", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", "*", "3", ")", "]", "\n", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "3", "*", "rows", ",", "3", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                        ", "panel", "[", "i", "]", ".", "append", "(", "images", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "1", "]", ".", "append", "(", "reconstructed_images_no_sampling", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "2", "]", ".", "append", "(", "reconstructed_images", "[", "c", "]", ")", "\n", "if", "c", "==", "len", "(", "images", ")", "-", "1", ":", "\n", "                            ", "break", "\n", "", "else", ":", "\n", "                            ", "c", "=", "c", "+", "1", "\n", "", "", "", "", "else", ":", "\n", "                ", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "*", "images", ".", "shape", "[", "3", "]", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", "*", "3", ")", "]", "\n", "\n", "for", "k", "in", "range", "(", "images", ".", "shape", "[", "3", "]", ")", ":", "\n", "                    ", "selected_images", "=", "images", "[", ":", ",", ":", ",", ":", ",", "k", "]", "\n", "reshaped_images", "=", "selected_images", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "selected_reconstructed_images_no_sampling", "=", "reconstructed_images_no_sampling", "[", ":", ",", ":", ",", ":", ",", "k", "]", "\n", "reshaped_reconstructed_images_no_sampling", "=", "selected_reconstructed_images_no_sampling", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "selected_reconstructed_images", "=", "reconstructed_images", "[", ":", ",", ":", ",", ":", ",", "k", "]", "\n", "reshaped_reconstructed_images", "=", "selected_reconstructed_images", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "3", "*", "rows", ",", "3", "*", "images", ".", "shape", "[", "3", "]", ")", ":", "\n", "                        ", "i", "=", "i", "+", "k", "*", "3", "\n", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                            ", "panel", "[", "i", "]", ".", "append", "(", "reshaped_images", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "1", "]", ".", "append", "(", "reshaped_reconstructed_images_no_sampling", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "2", "]", ".", "append", "(", "reshaped_reconstructed_images", "[", "c", "]", ")", "\n", "if", "c", "==", "len", "(", "images", ")", "-", "1", ":", "\n", "                                ", "break", "\n", "", "else", ":", "\n", "                                ", "c", "=", "c", "+", "1", "\n", "\n", "# \"[1st] original image [2nd] recostructed  mean [3rd] reconstr z\"", "\n", "", "", "", "", "", "images_saver", ".", "save_images", "(", "panel", ",", "\n", "fileName", "=", "\"reconstructed\"", "+", "\"_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "+", "\"_\"", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", ",", "\n", "title", "=", "self", ".", "_plot_title", ",", "\n", "fontsize", "=", "9", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PredictionKerasNetwork.PredictionKerasNetwork.create_id": [[20, 49], ["super().create_id", "PredictionKerasNetwork.PredictionKerasNetwork._net_model._id", "PredictionKerasNetwork.PredictionKerasNetwork._distr_model._id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.ArgoKerasModel.ArgoKerasModel._id", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.ArgoKerasModel.ArgoKerasModel._id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "# keras_model_tuple, distr_tuple, flow_params = self._parse_network_architecture(opts[\"network_architecture\"])", "\n", "# #delegate id creation to keras_models utils", "\n", "# _id = \"-n\" + get_network_id(keras_model_tuple)", "\n", "# if distr_tuple is not None:", "\n", "#     _id += \"_\" + get_network_id(distr_tuple)", "\n", "#", "\n", "#     if flow_params is not None:", "\n", "#         _id += \"-f\" + flow_params['name']", "\n", "#         _id += \"_n{:d}\".format(flow_params['num_bijectors'])", "\n", "#         _id += \"_hc{:d}\".format(flow_params['hidden_channels'])", "\n", "\n", "#delegate id creation to subunits", "\n", "        ", "_id", "=", "\"-n\"", "+", "self", ".", "_net_model", ".", "_id", "(", ")", "\n", "\n", "if", "self", ".", "_distr_model", "is", "not", "None", ":", "\n", "            ", "_id", "+=", "\"_\"", "+", "self", ".", "_distr_model", ".", "_id", "(", ")", "\n", "\n", "if", "self", ".", "_flow", "is", "not", "None", ":", "\n", "#TODO make flow a class too", "\n", "                ", "_id", "+=", "\"-f\"", "+", "self", ".", "_flow_params", "[", "'name'", "]", "\n", "_id", "+=", "\"_n{:d}\"", ".", "format", "(", "self", ".", "_flow_params", "[", "'num_bijectors'", "]", ")", "\n", "_id", "+=", "\"_hc{:d}\"", ".", "format", "(", "self", ".", "_flow_params", "[", "'hidden_channels'", "]", ")", "\n", "\n", "", "", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PredictionKerasNetwork.PredictionKerasNetwork._parse_network_architecture": [[50, 60], ["len", "len", "Exception"], "methods", ["None"], ["", "def", "_parse_network_architecture", "(", "self", ",", "network_architecture", ")", ":", "\n", "# this can be 2 or 3", "\n", "        ", "if", "len", "(", "network_architecture", ")", "==", "2", ":", "\n", "            ", "keras_model_tuple", ",", "distribution_tuple", "=", "network_architecture", "\n", "flow_params", "=", "None", "\n", "", "elif", "len", "(", "network_architecture", ")", "==", "3", ":", "\n", "            ", "keras_model_tuple", ",", "distribution_tuple", ",", "flow_params", "=", "network_architecture", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"`network_architecture` can be composed by either 2 or 3 tuples.\"", ")", "\n", "", "return", "keras_model_tuple", ",", "distribution_tuple", ",", "flow_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PredictionKerasNetwork.PredictionKerasNetwork.__init__": [[61, 113], ["argo.core.network.KerasNetwork.KerasNetwork.__init__", "PredictionKerasNetwork.PredictionKerasNetwork._parse_network_architecture", "PredictionKerasNetwork.PredictionKerasNetwork._keras_model_kwargs.update", "PredictionKerasNetwork.PredictionKerasNetwork._try_set_output_shape", "PredictionKerasNetwork.PredictionKerasNetwork._keras_model_builder", "len", "ValueError", "PredictionKerasNetwork.PredictionKerasNetwork._distribution_kwargs.update", "PredictionKerasNetwork.PredictionKerasNetwork._keras_model_builder", "argo.core.flows.build_flow.build_flow"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.core.PredictionKerasNetwork.PredictionKerasNetwork._parse_network_architecture", "home.repos.pwc.inspect_result.rist-ro_argo.core.PredictionKerasNetwork.PredictionKerasNetwork._try_set_output_shape", "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork._keras_model_builder", "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork._keras_model_builder", "home.repos.pwc.inspect_result.rist-ro_argo.flows.build_flow.build_flow"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", "=", "None", ")", ":", "\n", "        ", "if", "name", "is", "None", ":", "\n", "            ", "name", "=", "self", ".", "_keras_model_name", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ")", "\n", "\n", "self", ".", "_network_architecture", "=", "opts", "[", "\"network_architecture\"", "]", "\n", "\n", "keras_model_tuple", ",", "distribution_tuple", ",", "flow_params", "=", "self", ".", "_parse_network_architecture", "(", "self", ".", "_network_architecture", ")", "\n", "\n", "self", ".", "_keras_model_name", ",", "self", ".", "_keras_model_kwargs", "=", "keras_model_tuple", "\n", "self", ".", "_keras_model_kwargs", ".", "update", "(", "{", "\n", "\"layer_kwargs\"", ":", "self", ".", "_layer_kwargs", ",", "\n", "\"layer_kwargs_bayes\"", ":", "self", ".", "_layer_kwargs_bayes", "\n", "}", ")", "\n", "\n", "# activation = get_activation(opts)", "\n", "if", "len", "(", "self", ".", "_opts", "[", "\"output_shape\"", "]", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Not implemented prediction with non scalar outputs\"", ")", "\n", "\n", "", "self", ".", "_input_shape", "=", "opts", "[", "\"input_shape\"", "]", "\n", "\n", "self", ".", "_prob_bool", "=", "(", "distribution_tuple", "is", "not", "None", ")", "\n", "\n", "if", "self", ".", "_prob_bool", ":", "\n", "            ", "self", ".", "_distribution_name", ",", "self", ".", "_distribution_kwargs", "=", "distribution_tuple", "\n", "self", ".", "_distribution_kwargs", ".", "update", "(", "{", "\n", "\"layer_kwargs\"", ":", "self", ".", "_layer_kwargs", ",", "\n", "\"layer_kwargs_bayes\"", ":", "self", ".", "_layer_kwargs_bayes", "\n", "}", ")", "\n", "\n", "\n", "", "self", ".", "_try_set_output_shape", "(", "opts", ")", "\n", "\n", "self", ".", "_flow_params", "=", "flow_params", "\n", "\n", "# with self._enter_variable_scope():", "\n", "self", ".", "_net_model", "=", "self", ".", "_keras_model_builder", "(", "self", ".", "_keras_model_name", ",", "\n", "self", ".", "_keras_model_kwargs", ",", "\n", ")", "\n", "\n", "self", ".", "_distr_model", "=", "None", "\n", "self", ".", "_flow", "=", "None", "\n", "\n", "if", "self", ".", "_prob_bool", ":", "\n", "            ", "self", ".", "_distr_model", "=", "self", ".", "_keras_model_builder", "(", "self", ".", "_distribution_name", ",", "\n", "self", ".", "_distribution_kwargs", ")", "\n", "\n", "# FLOW", "\n", "if", "self", ".", "_flow_params", "is", "not", "None", ":", "\n", "                ", "flow_size", "=", "self", ".", "_output_size", "\n", "self", ".", "_flow", "=", "build_flow", "(", "self", ".", "_flow_params", ",", "flow_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PredictionKerasNetwork.PredictionKerasNetwork._try_set_output_shape": [[116, 132], ["PredictionKerasNetwork.PredictionKerasNetwork._distribution_kwargs.get", "PredictionKerasNetwork.PredictionKerasNetwork._keras_model_kwargs.get", "PredictionKerasNetwork.PredictionKerasNetwork._distribution_kwargs.update", "PredictionKerasNetwork.PredictionKerasNetwork._keras_model_kwargs.update"], "methods", ["None"], ["", "", "", "def", "_try_set_output_shape", "(", "self", ",", "opts", ")", ":", "\n", "# in classification case we keep only a scalar int.. if we would keep y as one_hot there would not be this problem", "\n", "\n", "# CHECK IF OUTPUT_SHAPE HAS BEEN SET MANUALLY", "\n", "        ", "if", "self", ".", "_prob_bool", ":", "\n", "            ", "has_been_set", "=", "(", "self", ".", "_distribution_kwargs", ".", "get", "(", "\"output_size\"", ",", "None", ")", "is", "not", "None", ")", "\n", "", "else", ":", "\n", "            ", "has_been_set", "=", "(", "self", ".", "_keras_model_kwargs", ".", "get", "(", "\"output_size\"", ",", "None", ")", "is", "not", "None", ")", "\n", "\n", "", "if", "not", "has_been_set", ":", "\n", "# TRY SET OUTPUT SHAPE", "\n", "            ", "self", ".", "_output_size", "=", "opts", "[", "\"output_shape\"", "]", "[", "0", "]", "\n", "if", "self", ".", "_prob_bool", ":", "\n", "                ", "self", ".", "_distribution_kwargs", ".", "update", "(", "{", "\"output_size\"", ":", "self", ".", "_output_size", "}", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_keras_model_kwargs", ".", "update", "(", "{", "\"output_size\"", ":", "self", ".", "_output_size", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PredictionKerasNetwork.PredictionKerasNetwork.call": [[134, 151], ["PredictionKerasNetwork.PredictionKerasNetwork._net_model", "PredictionKerasNetwork.PredictionKerasNetwork._distr_model", "tensorflow_probability.distributions.TransformedDistribution"], "methods", ["None"], ["", "", "", "def", "call", "(", "self", ",", "inputs", ",", "is_training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "logits", "=", "self", ".", "_net_model", "(", "inputs", ",", "training", "=", "is_training", ")", "\n", "\n", "if", "self", ".", "_prob_bool", ":", "\n", "            ", "outputs", "=", "self", ".", "_distr_model", "(", "logits", ",", "training", "=", "is_training", ")", "\n", "\n", "if", "self", ".", "_flow", "is", "not", "None", ":", "\n", "                ", "outputs", "=", "tfp", ".", "distributions", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "outputs", ",", "\n", "bijector", "=", "self", ".", "_flow", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "outputs", "=", "logits", "\n", "\n", "# TODO is it possible to merge everything in a single module with the same flexibility?", "\n", "# outputs = self._model(inputs, training=is_training)", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQELBO.VQELBO.__init__": [[10, 13], ["ELBO.ELBO.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "use_kl", "=", "False", ",", "beta", "=", "1.0", ",", "warm_up_method", "=", "None", ",", "name", "=", "\"VQELBO\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "beta", "=", "beta", ",", "warm_up_method", "=", "warm_up_method", ",", "name", "=", "name", ")", "\n", "self", ".", "_use_kl", "=", "use_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQELBO.VQELBO.create_id": [[14, 21], ["VQELBO.VQELBO.create_warm_up_id", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.create_warm_up_id"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "        ", "_id", "=", "\"VQELBO\"", "\n", "if", "self", ".", "_use_kl", ":", "\n", "            ", "_id", "+=", "\"_b\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"beta\"", "]", ")", "+", "self", ".", "create_warm_up_id", "(", "cost_fuction_kwargs", ")", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQELBO.VQELBO._build": [[22, 93], ["VQELBO.VQELBO.get_warm_up_coefficient", "VQELBO.VQELBO.reconstruction_loss", "VQELBO.VQELBO.latent_loss", "tensorflow.cast", "argo.core.utils.argo_utils.create_panels_lists", "tensorflow.reduce_prod", "tensorflow.log", "tensorflow.log", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.get_warm_up_coefficient", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss", "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.latent_loss", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_panels_lists", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "_build", "(", "self", ",", "vae", ")", ":", "\n", "\n", "        ", "prior", "=", "vae", ".", "_prior", "\n", "approximate_posterior", "=", "vae", ".", "_approximate_posterior", "\n", "\n", "vq_losses", "=", "vae", ".", "net_losses", "\n", "perplexity", "=", "vq_losses", "[", "\"perplexity\"", "]", "\n", "vq_loss", "=", "vq_losses", "[", "\"vq_loss\"", "]", "\n", "\n", "model_visible", "=", "vae", ".", "_model_visible", "\n", "x_target", "=", "vae", ".", "x_target", "\n", "n_z_samples", "=", "1", "\n", "\n", "warm_up", "=", "self", ".", "get_warm_up_coefficient", "(", "self", ".", "_warm_up_method", ",", "vae", ")", "\n", "\n", "rec_nll", "=", "self", ".", "reconstruction_loss", "(", "x_target", ",", "n_z_samples", ",", "model_visible", ",", "vae", ")", "\n", "\n", "KL", "=", "self", ".", "latent_loss", "(", "approximate_posterior", ",", "prior", ")", "\n", "\n", "# use kl only if specified, original VQ-VAE paper doesn't use", "\n", "kl_loss", "=", "warm_up", "*", "self", ".", "beta", "*", "KL", "if", "self", ".", "_use_kl", "else", "0.", "\n", "\n", "cost", "=", "kl_loss", "+", "vq_loss", "+", "rec_nll", "\n", "\n", "dim_with_channels", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "x_target", ")", "[", "1", ":", "]", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "# TODO I think this formula is still not correct", "\n", "# check https://www.reddit.com/r/MachineLearning/comments/56m5o2/discussion_calculation_of_bitsdims/", "\n", "bits_dim", "=", "(", "(", "rec_nll", "/", "dim_with_channels", ")", "+", "tf", ".", "log", "(", "256.0", "/", "2.0", ")", ")", "/", "tf", ".", "log", "(", "2.0", ")", "\n", "\n", "# First panel will be at screen during training", "\n", "list_of_vpanels_of_plots", "=", "[", "\n", "[", "\n", "{", "\n", "'nodes'", ":", "[", "cost", "]", ",", "\n", "'names'", ":", "[", "\"loss\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"loss\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "bits_dim", "]", ",", "\n", "'names'", ":", "[", "\"bd\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"bits_dim\"", "}", "\n", "}", ",", "\n", "\n", "]", ",", "\n", "[", "\n", "{", "\n", "'nodes'", ":", "[", "KL", "]", ",", "\n", "'names'", ":", "[", "\"KL\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"kl\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "rec_nll", "]", ",", "\n", "'names'", ":", "[", "\"RL\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"rl\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "perplexity", "]", ",", "\n", "'names'", ":", "[", "\"perplexity\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"perplexity\"", "}", "\n", "}", ",", "\n", "\n", "]", "\n", "]", "\n", "\n", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "=", "create_panels_lists", "(", "list_of_vpanels_of_plots", ")", "\n", "\n", "return", "cost", ",", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQELBO.VQELBO.latent_loss": [[95, 103], ["tensorflow.variable_scope", "tensorflow.reduce_mean", "approximate_posterior.kl_divergence"], "methods", ["None"], ["", "def", "latent_loss", "(", "self", ",", "approximate_posterior", ",", "prior", ")", ":", "\n", "\n", "# two categorical distributions", "\n", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'latent_loss'", ")", ":", "\n", "            ", "mean_latent_loss", "=", "tf", ".", "reduce_mean", "(", "approximate_posterior", ".", "kl_divergence", "(", "prior", ")", ",", "axis", "=", "0", ",", "name", "=", "\"latent_loss\"", ")", "\n", "\n", "", "return", "mean_latent_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.__init__": [[14, 18], ["ELBO.ELBO.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "beta", "=", "1.0", ",", "warm_up_method", "=", "None", ",", "latent_regularizations", "=", "(", "(", "LATENT_REGULARIZATION_TYPE_KL", ",", "1.0", ")", ")", ",", "\n", "name", "=", "\"WavenetELBO\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "warm_up_method", "=", "warm_up_method", ",", "beta", "=", "beta", ")", "\n", "self", ".", "latent_regularizations", "=", "latent_regularizations", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.create_id": [[19, 35], ["WavenetELBO.unpack_latent_reg_params", "WavenetELBO.WavenetELBO.create_warm_up_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.unpack_latent_reg_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.create_warm_up_id"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "# cost_fuction_kwargs[0] is the cost function name", "\n", "        ", "regularization_str", "=", "''", "\n", "at_least_one_warmup", "=", "False", "\n", "for", "latent_reg_params", "in", "self", ".", "latent_regularizations", ":", "\n", "            ", "latent_reg_type", ",", "weight", ",", "warmup", "=", "unpack_latent_reg_params", "(", "latent_reg_params", ")", "\n", "at_least_one_warmup", "=", "at_least_one_warmup", "or", "warmup", "\n", "regularization_str", "+=", "'{:.1f}{}+'", ".", "format", "(", "weight", ",", "latent_reg_type", ")", "\n", "\n", "", "_id", "=", "\"WELBO\"", "\n", "if", "at_least_one_warmup", ":", "\n", "            ", "_id", "+=", "self", ".", "create_warm_up_id", "(", "cost_fuction_kwargs", ")", "\n", "", "_id", "+=", "'_'", "+", "regularization_str", "[", ":", "-", "1", "]", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO._build": [[36, 103], ["tensorflow.squeeze", "WavenetELBO.WavenetELBO.get_warm_up_coefficient", "WavenetELBO.WavenetELBO.reconstruction_loss", "tensorflow.cast", "WavenetELBO.unpack_latent_reg_params", "WavenetELBO.WavenetELBO._latent_loss", "latent_losses.append", "latent_loss_names.append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.get_warm_up_coefficient", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.unpack_latent_reg_params", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO._latent_loss"], ["", "def", "_build", "(", "self", ",", "vae", ",", "isMAF", "=", "False", ")", ":", "\n", "        ", "prior", "=", "vae", ".", "_prior", "\n", "\n", "gaussian_model_latent", "=", "vae", ".", "_gaussian_model_latent", "\n", "model_visible", "=", "vae", ".", "_model_visible", "\n", "x_quant", "=", "vae", ".", "x_target_quantized", "\n", "\n", "x_indices", "=", "tf", ".", "cast", "(", "x_quant", ",", "tf", ".", "int32", ")", "+", "128", "\n", "x_target", "=", "tf", ".", "squeeze", "(", "x_indices", ",", "axis", "=", "-", "1", ")", "\n", "\n", "n_z_samples", "=", "vae", ".", "n_z_samples", "\n", "\n", "warm_up", "=", "self", ".", "get_warm_up_coefficient", "(", "self", ".", "_warm_up_method", ",", "vae", ")", "\n", "\n", "# The loss is composed of two terms:", "\n", "#", "\n", "# 1.) The reconstruction loss (the negative log probability", "\n", "#     of the input under the reconstructed distribution", "\n", "#     induced by the decoder in the data space).", "\n", "#     This can be interpreted as the number of \"nats\" required", "\n", "#     for reconstructing the input when the activation in latent", "\n", "#     is given.", "\n", "\n", "reconstruction_loss", "=", "self", ".", "reconstruction_loss", "(", "x_target", ",", "n_z_samples", ",", "model_visible", ")", "\n", "\n", "# 2.) The latent loss, which is defined as the Kullback Leibler divergence", "\n", "#     between the distribution in latent space induced by the encoder on", "\n", "#     the data and some prior. This acts as a kind of regularizer.x", "\n", "#     This can be interpreted as the number of \"nats\" required", "\n", "#     for transmitting the the latent space distribution given", "\n", "#     the prior.", "\n", "\n", "# KL, KL_i = self.kl(gaussian_model_latent, prior)", "\n", "latent_losses", "=", "[", "]", "\n", "latent_loss_names", "=", "[", "]", "\n", "# latent_losses_i = []", "\n", "for", "latent_reg_params", "in", "self", ".", "latent_regularizations", ":", "\n", "            ", "reg_type", ",", "weight", ",", "use_warmup", "=", "unpack_latent_reg_params", "(", "latent_reg_params", ")", "\n", "latent_loss", ",", "latent_loss_i", "=", "self", ".", "_latent_loss", "(", "gaussian_model_latent", ",", "prior", ",", "vae", ".", "samples_posterior", ",", "reg_type", ")", "\n", "if", "use_warmup", ":", "\n", "                ", "latent_loss", "*=", "warm_up", "\n", "", "latent_losses", ".", "append", "(", "latent_loss", "*", "weight", ")", "\n", "latent_loss_names", ".", "append", "(", "reg_type", ")", "\n", "\n", "# KL, KL_i = self.latent_loss(gaussian_model_latent, prior)", "\n", "# latent_loss = self.beta * latent_loss", "\n", "\n", "", "cost", "=", "reconstruction_loss", "\n", "for", "latent_loss", "in", "latent_losses", ":", "\n", "            ", "cost", "+=", "latent_loss", "\n", "\n", "# logging individual KL_i", "\n", "\n", "# latent_loss_shape = latent_loss_i.shape", "\n", "# if len(latent_loss_shape) > 1:", "\n", "#     all_but_last_axis = list(range(len(latent_loss_shape) - 1))", "\n", "#     latent_loss_i = tf.reduce_mean(latent_loss_i, axis=all_but_last_axis)", "\n", "#", "\n", "# latent_loss_i.set_shape((vae._network._latent_channels,))", "\n", "# latent_loss_i = tf.unstack(latent_loss_i)", "\n", "# # KL_i_names = [\"KL_\" + str(int(i + 1)) for i, l in enumerate(KL_i)]", "\n", "# KL_i_names = ['LATENT_{}'.format(i + 1) for i in range(vae._network._latent_channels)]", "\n", "\n", "", "return", "cost", ",", "[", "[", "-", "reconstruction_loss", "]", ",", "latent_losses", ",", "]", ",", "[", "[", "\"RL\"", "]", ",", "latent_loss_names", ",", "]", ",", "[", "\n", "{", "\"fileName\"", ":", "\"cost_function_RL\"", "}", ",", "\n", "{", "\"fileName\"", ":", "\"cost_function_LATENT\"", "}", ",", "\n", "# {\"fileName\": \"cost_function_LATENT_i\", \"legend\": 0}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.reconstr_loss_per_sample": [[106, 134], ["tensorflow.variable_scope", "tensorflow.tile", "tensorflow.reduce_sum", "x_target_t.shape.as_list", "len", "categorical_distribution.log_prob", "list", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "reconstr_loss_per_sample", "(", "self", ",", "x_target_t", ",", "n_z_samples", ",", "categorical_distribution", ")", ":", "\n", "        ", "'''\n        computes the log probability of x_target_t w.r.t the given categorical distribution model_visible\n        Args:\n            x_target_t: the audio signal with values in range [0, 255]\n            n_z_samples: how many samples have been drawn from the latent distribution\n            model_visible: the cateforical distribution at the end of the wavenet model\n\n        Returns:\n\n        '''", "\n", "with", "tf", ".", "variable_scope", "(", "'reconstruction_loss_t'", ")", ":", "\n", "# 1) the log_pdf is computed with respect to distribution of the visible", "\n", "#    variables obtained from the target of input of the graph (self.x_target)", "\n", "\n", "# can I avoid replicate? maybe not..", "\n", "            ", "input_shape", "=", "x_target_t", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "ones", "=", "[", "1", "]", "*", "len", "(", "input_shape", ")", "\n", "x_replicate", "=", "tf", ".", "tile", "(", "x_target_t", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "\n", "reconstr_loss", "=", "-", "categorical_distribution", ".", "log_prob", "(", "x_replicate", ")", "\n", "\n", "# now (ready for arbitrary intermediate samplings)", "\n", "all_axis_but_first", "=", "list", "(", "range", "(", "len", "(", "reconstr_loss", ".", "shape", ")", ")", ")", "[", "1", ":", "]", "\n", "# independent p for each input pixel", "\n", "reconstr_loss", "=", "tf", ".", "reduce_sum", "(", "reconstr_loss", ",", "axis", "=", "all_axis_but_first", ")", "\n", "\n", "", "return", "reconstr_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO._latent_loss": [[135, 147], ["tensorflow.variable_scope", "type", "WavenetELBO.WavenetELBO.kl_aproximation_maf", "WavenetELBO.WavenetELBO.MMD", "WavenetELBO.WavenetELBO.mu_VAE", "WavenetELBO.WavenetELBO.sigma_reg", "WavenetELBO.WavenetELBO.kl"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.kl_aproximation_maf", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.MMD", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.mu_VAE", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.sigma_reg", "home.repos.pwc.inspect_result.rist-ro_argo.utils.distances.kl"], ["", "def", "_latent_loss", "(", "self", ",", "approximate_posterior", ",", "prior", ",", "z_posterior", ",", "regularization_type", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'latent_loss'", ")", ":", "\n", "            ", "if", "type", "(", "prior", ")", "is", "IndependentChannelsTransformedDistribution", ":", "\n", "                ", "return", "self", ".", "kl_aproximation_maf", "(", "approximate_posterior", ",", "prior", ")", "\n", "", "elif", "regularization_type", "==", "LATENT_REGULARIZATION_TYPE_MMD", ":", "\n", "                ", "return", "self", ".", "MMD", "(", "z_posterior", ",", "prior", ")", "\n", "", "elif", "regularization_type", "==", "LATENT_REGULARIZATION_TYPE_MUVAE", ":", "\n", "                ", "return", "self", ".", "mu_VAE", "(", "approximate_posterior", ",", "prior", ")", "\n", "", "elif", "regularization_type", "==", "LATENT_REGULARIZATION_TYPE_SIGMA", ":", "\n", "                ", "return", "self", ".", "sigma_reg", "(", "approximate_posterior", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "kl", "(", "approximate_posterior", ",", "prior", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.sigma_reg": [[148, 154], ["tensorflow.matrix_diag_part", "approximate_posterior.covariance", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "", "", "def", "sigma_reg", "(", "self", ",", "approximate_posterior", ")", ":", "\n", "        ", "sigma_sq", "=", "tf", ".", "matrix_diag_part", "(", "approximate_posterior", ".", "covariance", "(", ")", ")", "\n", "sigma_loss", "=", "(", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "sigma_sq", ")", ")", "+", "tf", ".", "reduce_mean", "(", "sigma_sq", ")", "-", "1", ")", "/", "2", "\n", "sigma_loss_i", "=", "(", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "sigma_sq", ")", ",", "axis", "=", "-", "1", ")", "+", "tf", ".", "reduce_mean", "(", "sigma_sq", ",", "axis", "=", "-", "1", ")", "-", "1", ")", "/", "2", "\n", "\n", "return", "sigma_loss", ",", "sigma_loss_i", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.mu_VAE": [[156, 163], ["approximate_posterior.mean", "tensorflow.matrix_diag_part", "approximate_posterior.covariance", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "mu_VAE", "(", "self", ",", "approximate_posterior", ",", "prior", ")", ":", "\n", "        ", "mean", "=", "approximate_posterior", ".", "mean", "(", ")", "# bs, ch, dim", "\n", "sigma_sq", "=", "tf", ".", "matrix_diag_part", "(", "approximate_posterior", ".", "covariance", "(", ")", ")", "# bs, ch, dim", "\n", "mmd_kl", "=", "(", "tf", ".", "abs", "(", "tf", ".", "reduce_mean", "(", "mean", ")", ")", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "sigma_sq", ")", ")", "+", "tf", ".", "reduce_mean", "(", "sigma_sq", ")", "-", "1", ")", "/", "2", "\n", "mmd_kl_i", "=", "(", "tf", ".", "abs", "(", "tf", ".", "reduce_mean", "(", "mean", ",", "axis", "=", "-", "1", ")", ")", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "log", "(", "sigma_sq", ")", ",", "axis", "=", "-", "1", ")", "\n", "+", "tf", ".", "reduce_mean", "(", "sigma_sq", ",", "axis", "=", "-", "1", ")", "-", "1", ")", "/", "2", "\n", "return", "mmd_kl", ",", "mmd_kl_i", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.MMD": [[164, 181], ["prior.sample", "WavenetELBO.gaussian_kernel", "WavenetELBO.gaussian_kernel", "WavenetELBO.gaussian_kernel", "len", "list", "tensorflow.shape", "p_kernel_i.get_shape().as_list", "range", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "p_kernel_i.get_shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.gaussian_kernel", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.gaussian_kernel", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.gaussian_kernel"], ["", "def", "MMD", "(", "self", ",", "q_z", ",", "prior", ")", ":", "\n", "        ", "batch_size", "=", "tf", ".", "shape", "(", "q_z", ")", "[", "0", "]", "\n", "p_z", "=", "prior", ".", "sample", "(", "batch_size", ")", "\n", "\n", "p_kernel", ",", "p_kernel_i", "=", "gaussian_kernel", "(", "p_z", ",", "p_z", ")", "\n", "q_kernel", ",", "q_kernel_i", "=", "gaussian_kernel", "(", "q_z", ",", "q_z", ")", "\n", "p_q_kernel", ",", "p_q_kernel_i", "=", "gaussian_kernel", "(", "q_z", ",", "p_z", ")", "\n", "\n", "len_shape", "=", "len", "(", "p_kernel_i", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "all_axis_but_last", "=", "list", "(", "range", "(", "len_shape", "-", "1", ")", ")", "\n", "\n", "mmd", "=", "tf", ".", "reduce_mean", "(", "p_kernel", ")", "+", "tf", ".", "reduce_mean", "(", "q_kernel", ")", "-", "2", "*", "tf", ".", "reduce_mean", "(", "p_q_kernel", ")", "\n", "# mmd_i = tf.reduce_mean(p_kernel, axis=all_axis_but_last) + tf.reduce_mean(q_kernel, axis=all_axis_but_last)\\", "\n", "#         - 2 * tf.reduce_mean(p_q_kernel, all_axis_but_last)", "\n", "mmd_i", "=", "p_kernel_i", "+", "q_kernel_i", "-", "2", "*", "p_q_kernel_i", "\n", "\n", "return", "mmd", ",", "mmd_i", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.kl_aproximation_maf": [[182, 190], ["approximate_posterior.sample", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "approximate_posterior.log_prob", "prior.log_prob"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "kl_aproximation_maf", "(", "self", ",", "approximate_posterior", ",", "prior", ")", ":", "\n", "# with tf.variable_scope('latent_loss'):", "\n", "        ", "posterior_samples", "=", "approximate_posterior", ".", "sample", "(", "50", ")", "\n", "kl_posterior_prior", "=", "approximate_posterior", ".", "log_prob", "(", "posterior_samples", ")", "-", "prior", ".", "log_prob", "(", "posterior_samples", ")", "\n", "mean_latent_loss_i", "=", "tf", ".", "reduce_mean", "(", "kl_posterior_prior", ",", "axis", "=", "0", ",", "name", "=", "'latent_loss_i'", ")", "\n", "mean_latent_loss", "=", "tf", ".", "reduce_sum", "(", "mean_latent_loss_i", ",", "name", "=", "\"latent_loss\"", ")", "\n", "\n", "return", "mean_latent_loss", ",", "mean_latent_loss_i", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.kl": [[191, 219], ["approximate_posterior.kl_divergence", "len", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.reshape"], "methods", ["None"], ["", "def", "kl", "(", "self", ",", "approximate_posterior", ",", "prior", ")", ":", "\n", "\n", "# with tf.variable_scope('ELBO/reconstruction_loss'):", "\n", "# no need for ELBO, sonnet module is already adding that, the line above would produce:", "\n", "# ELBO/ELBO/reconstruction_loss/node_created", "\n", "# with tf.variable_scope('latent_loss'):", "\n", "# 1) cast is required", "\n", "# 2) the KL divergence is computed with respect to distribution of the latent", "\n", "#    variables obtained from the input of the graph (self.x_tilde)", "\n", "# all_axis_but_first = list(range(len(gaussian_model_latent.batch_shape)))[1:", "\n", "# average on the batch", "\n", "        ", "kl_posterior_prior", "=", "approximate_posterior", ".", "kl_divergence", "(", "prior", ")", "\n", "# kl_posterior_prior = tf.Print(kl_posterior_prior, [tf.shape(kl_posterior_prior)], '\\n\\nShape kl\\n\\n')", "\n", "\n", "if", "len", "(", "kl_posterior_prior", ".", "shape", ")", ">", "1", ":", "\n", "# this is the case of the GaussianDiagonal", "\n", "            ", "mean_latent_loss_i", "=", "tf", ".", "reduce_mean", "(", "kl_posterior_prior", ",", "axis", "=", "0", ",", "\n", "name", "=", "\"latent_loss_i\"", ")", "\n", "mean_latent_loss", "=", "tf", ".", "reduce_sum", "(", "mean_latent_loss_i", ",", "name", "=", "\"latent_loss\"", ")", "\n", "", "else", ":", "\n", "# this is the case of the vMF", "\n", "            ", "mean_latent_loss_i", "=", "tf", ".", "reduce_mean", "(", "kl_posterior_prior", ",", "axis", "=", "0", ",", "\n", "name", "=", "\"latent_loss_i\"", ")", "\n", "mean_latent_loss", "=", "mean_latent_loss_i", "\n", "mean_latent_loss_i", "=", "tf", ".", "reshape", "(", "mean_latent_loss", ",", "[", "1", ",", "]", ")", "\n", "# mean_latent_loss_i = tf.reshape(mean_latent_loss_i, [1,-1])", "\n", "\n", "", "return", "mean_latent_loss", ",", "mean_latent_loss_i", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.gaussian_kernel": [[221, 239], ["tensorflow.tile", "tensorflow.tile", "tensorflow.exp", "tensorflow.exp", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.reshape", "tensorflow.stack", "tensorflow.reshape", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.cast", "tensorflow.cast", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.square"], "function", ["None"], ["", "", "def", "gaussian_kernel", "(", "x", ",", "y", ")", ":", "# [batch_size, ch, z_dim], [batch_size, ch, z_dim]", "\n", "    ", "x_size", "=", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "# xbs", "\n", "y_size", "=", "tf", ".", "shape", "(", "y", ")", "[", "0", "]", "# ybs", "\n", "dim", "=", "tf", ".", "shape", "(", "x", ")", "[", "2", "]", "# zdim", "\n", "ch", "=", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "\n", "# straight forward method", "\n", "# exponent = - (x-y)**2 / tf.cast((2 * dim * ch), tf.float32)", "\n", "# kernel = tf.exp(exponent)", "\n", "# return tf.reduce_mean(kernel, axis=[1, 2]), tf.reduce_mean(kernel, axis=[2])", "\n", "\n", "tiled_x", "=", "tf", ".", "tile", "(", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "stack", "(", "[", "x_size", ",", "1", ",", "ch", ",", "dim", "]", ")", ")", ",", "tf", ".", "stack", "(", "[", "1", ",", "y_size", ",", "1", ",", "1", "]", ")", ")", "# xbs, ybs, dim", "\n", "tiled_y", "=", "tf", ".", "tile", "(", "tf", ".", "reshape", "(", "y", ",", "tf", ".", "stack", "(", "[", "1", ",", "y_size", ",", "ch", ",", "dim", "]", ")", ")", ",", "tf", ".", "stack", "(", "[", "x_size", ",", "1", ",", "1", ",", "1", "]", ")", ")", "\n", "\n", "kernel", "=", "tf", ".", "exp", "(", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tiled_x", "-", "tiled_y", ")", ",", "axis", "=", "[", "2", ",", "3", "]", ")", "/", "tf", ".", "cast", "(", "dim", "*", "ch", ",", "tf", ".", "float32", ")", ")", "# bs bs", "\n", "# per channel:", "\n", "kernel_i", "=", "tf", ".", "exp", "(", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tiled_x", "-", "tiled_y", ")", ",", "axis", "=", "[", "3", "]", ")", "/", "tf", ".", "cast", "(", "dim", ",", "tf", ".", "float32", ")", ")", "# bs bs ch", "\n", "return", "kernel", ",", "kernel_i", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.unpack_latent_reg_params": [[240, 242], ["None"], "function", ["None"], ["", "def", "unpack_latent_reg_params", "(", "latent_reg_params", ")", ":", "\n", "    ", "return", "latent_reg_params", "[", "'type'", "]", ",", "latent_reg_params", "[", "'weight'", "]", ",", "latent_reg_params", "[", "'use_warmup'", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAELinearInterpolationHook.VAELinearInterpolationHook.do_when_triggered": [[15, 48], ["tf_logging.info", "VAELinearInterpolationHook.VAELinearInterpolationHook.load_images_once", "VAELinearInterpolationHook.VAELinearInterpolationHook._model._compute_linear_interpolation", "VAELinearInterpolationHook.VAELinearInterpolationHook._model._compute_fisher_rao_interpolation", "argo.core.utils.ImagesSaver.ImagesSaver", "len", "range", "argo.core.utils.ImagesSaver.ImagesSaver.save_images", "range", "range", "panel[].append", "panel[].append", "panel[].append", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractLinearInterpolationHook.AbstractLinearInterpolationHook.load_images_once", "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._compute_linear_interpolation", "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._compute_fisher_rao_interpolation", "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["    ", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for VAELinearInterpolationHook\"", ")", "\n", "\n", "self", ".", "load_images_once", "(", "run_context", ".", "session", ")", "\n", "\n", "for", "(", "ds_key", ")", "in", "self", ".", "_images", ":", "\n", "\n", "            ", "couples_of_images", "=", "self", ".", "_images", "[", "ds_key", "]", "[", "1", "]", "\n", "reconstructed_interpolations_means", ",", "reconstructed_interpolations_zs", "=", "self", ".", "_model", ".", "_compute_linear_interpolation", "(", "couples_of_images", ",", "self", ".", "_n_images", ",", "run_context", ".", "session", ")", "\n", "reconstructed_interpolations_fisher_rao", "=", "self", ".", "_model", ".", "_compute_fisher_rao_interpolation", "(", "couples_of_images", ",", "self", ".", "_n_images", ",", "run_context", ".", "session", ")", "\n", "\n", "images_saver", "=", "ImagesSaver", "(", "self", ".", "_dirName", ")", "\n", "\n", "rows", "=", "len", "(", "couples_of_images", ")", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", "*", "3", ")", "]", "\n", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "3", "*", "rows", ",", "3", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "self", ".", "_n_images", "+", "2", ")", ":", "# include first and last image", "\n", "                    ", "panel", "[", "i", "]", ".", "append", "(", "reconstructed_interpolations_means", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "1", "]", ".", "append", "(", "reconstructed_interpolations_zs", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "2", "]", ".", "append", "(", "reconstructed_interpolations_fisher_rao", "[", "c", "]", ")", "\n", "#panel[i+2].append(reconstructed_images[c])", "\n", "#if c == len(images)-1:", "\n", "#    break", "\n", "#else:", "\n", "c", "=", "c", "+", "1", "\n", "\n", "# \"[1st] interpolation in mu before sampling [2nd] iterpolation in z after sampling\"", "\n", "", "", "images_saver", ".", "save_images", "(", "panel", ",", "\n", "fileName", "=", "\"interpolation_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "+", "\"_\"", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", ",", "\n", "title", "=", "\"interpolations 1) means 2) zs 3) fisher-rao on q(z|x) \\n\"", "+", "self", ".", "_plot_title", ",", "\n", "fontsize", "=", "9", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAEFunction.VAEFunction.__init__": [[10, 12], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_cost_logger_class", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAEFunction.VAEFunction.compute": [[13, 16], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "compute", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AENetwork.AENetwork.create_id": [[41, 60], ["filter", "filter", "super().create_id", "argo.core.utils.argo_utils.get_method_id", "argo.core.utils.argo_utils.get_method_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "encoder_layers_ids", "=", "filter", "(", "None", ",", "\n", "[", "utils", ".", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"encoder\"", "]", "]", "\n", ")", "\n", "\n", "decoder_layers_ids", "=", "filter", "(", "None", ",", "\n", "[", "utils", ".", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"decoder\"", "]", "]", "\n", ")", "\n", "\n", "_id", "=", "'-ne_'", "+", "\"_\"", ".", "join", "(", "encoder_layers_ids", ")", "+", "'-nd_'", "+", "\"_\"", ".", "join", "(", "decoder_layers_ids", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AENetwork.AENetwork.__init__": [[62, 73], ["argo.core.network.ArgoStochasticNetworkWithDefaults.ArgoStochasticNetworkWithDefaults.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", "=", "\"vae_network\"", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Short summary.\n\n        Args:\n            opts (dict): parameters of the task.\n            name (str): name of the Sonnet module.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "seed", ")", "\n", "network_architecture", "=", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "\n", "# TODO-ARGO2 you might want to check here that the 2 architectures (encoder and decoder) expected are effectively passed", "\n", "self", ".", "_network_architecture", "=", "network_architecture", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AENetwork.AENetwork._build": [[74, 119], ["argo.core.network.GeneralSonnetNetwork.GeneralSonnetNetwork", "AENetwork.AENetwork.encoder_module", "argo.core.network.GeneralSonnetNetwork.GeneralSonnetNetwork", "AENetwork.AENetwork.decoder_module", "x.get_shape().as_list", "x.get_shape"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "x", ",", "is_training", "=", "False", ",", "network_str", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (tf.tensor): input node.\n            network_str (str): Optional network_str specifying the network we are going to build.\n                            It is used to set some specific collections for activity and contractive regularizers.\n\n        Returns:\n            h\n            tf distribution on the visible neurons\n        \"\"\"", "\n", "\n", "self", ".", "encoder_module", "=", "GeneralSonnetNetwork", "(", "self", ".", "_network_defaults", "[", "\"activation\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", ",", "\n", "self", ".", "_network_architecture", "[", "\"encoder\"", "]", ",", "\n", "self", ".", "_stochastic_defaults", ",", "\n", "is_training", "=", "is_training", ",", "\n", "network_str", "=", "network_str", ",", "\n", "name", "=", "\"encoder\"", ")", "\n", "\n", "self", ".", "h", "=", "self", ".", "encoder_module", "(", "x", ")", "\n", "\n", "# self._latent_vars_logger_class = self._gaussian_model_latent.get_vars_logger_class()", "\n", "\n", "# I set the shape of the visible layer, to match the input shape", "\n", "input_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "self", ".", "_network_architecture", "[", "\"decoder\"", "]", "[", "-", "1", "]", "[", "1", "]", "[", "\"output_shape\"", "]", "=", "input_shape", "\n", "\n", "self", ".", "decoder_module", "=", "GeneralSonnetNetwork", "(", "self", ".", "_network_defaults", "[", "\"activation\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", ",", "\n", "self", ".", "_network_architecture", "[", "\"decoder\"", "]", ",", "\n", "self", ".", "_stochastic_defaults", ",", "\n", "is_training", "=", "is_training", ",", "\n", "network_str", "=", "network_str", ",", "\n", "name", "=", "\"decoder\"", ")", "\n", "\n", "self", ".", "_model_visible", "=", "self", ".", "decoder_module", "(", "self", ".", "h", ")", "\n", "\n", "return", "self", ".", "h", ",", "self", ".", "_model_visible", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.create_id": [[48, 65], ["super().create_id", "VQVAE.VQVAE._network.create_id", "VQVAE.VQVAE._cost_function.create_id", "len", "VQVAE.VQVAE.create_custom_regularizers_id", "len", "VQVAE.VQVAE.create_custom_regularizers_id", "[].keys", "[].keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "self", ".", "launchable_name", "\n", "\n", "# add to the ID the information of the cost function", "\n", "_id", "+=", "'-c'", "+", "self", ".", "_cost_function", ".", "create_id", "(", "self", ".", "_opts", "[", "\"cost_function\"", "]", "[", "1", "]", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "network_id", "=", "self", ".", "_network", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "+", "network_id", "\n", "if", "\"encoder\"", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", "and", "len", "(", "self", ".", "_opts", "[", "\"regularizers\"", "]", "[", "\"encoder\"", "]", ".", "keys", "(", ")", ")", ">", "0", ":", "\n", "            ", "_id", "+=", "'-crE'", "+", "self", ".", "create_custom_regularizers_id", "(", "\"encoder\"", ")", "\n", "", "if", "\"decoder\"", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", "and", "len", "(", "self", ".", "_opts", "[", "\"regularizers\"", "]", "[", "\"decoder\"", "]", ".", "keys", "(", ")", ")", ">", "0", ":", "\n", "            ", "_id", "+=", "'-crD'", "+", "self", ".", "create_custom_regularizers_id", "(", "\"decoder\"", ")", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.__init__": [[66, 84], ["VQVAENetwork.VQVAENetwork.VQVAENetwork", "argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "argo.core.network.AbstractAutoEncoder.AbstractAutoEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "\n", "# notice that in the following opts is used, and not self._opts, until the", "\n", "# parent constructor is called", "\n", "\n", "# NB need to create the network before the super init because id generation depends on the network", "\n", "        ", "self", ".", "_network", "=", "VQVAENetwork", "(", "opts", ",", "\"vqvae_network\"", ",", "seed", "=", "seed", ")", "\n", "self", ".", "_cost_function", "=", "CostFunctions", ".", "instantiate_cost_function", "(", "opts", "[", "\"cost_function\"", "]", ",", "module_path", "=", "\"vae\"", ")", "\n", "\n", "self", ".", "n_samples_prior", "=", "self", ".", "_network", ".", "n_samples_prior", "\n", "\n", "# important nodes", "\n", "# self._approximate_posterior = None", "\n", "self", ".", "_model_visible", "=", "None", "\n", "self", ".", "x_reconstruction_node", "=", "None", "\n", "self", ".", "samples", "=", "None", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.create_network": [[86, 103], ["VQVAE.VQVAE._network", "tensorflow.identity", "VQVAE.VQVAE._model_visible.reconstruction_node"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node"], ["", "def", "create_network", "(", "self", ")", ":", "\n", "\n", "# create autoencoder network", "\n", "        ", "out_net", ",", "net_losses", "=", "self", ".", "_network", "(", "self", ".", "x", ",", "self", ".", "is_training", ")", "\n", "\n", "self", ".", "z_e", "=", "out_net", "[", "'z_e'", "]", "\n", "self", ".", "z_q", "=", "out_net", "[", "'z_q'", "]", "\n", "\n", "self", ".", "net_losses", "=", "net_losses", "\n", "\n", "self", ".", "_prior", "=", "out_net", "[", "\"prior\"", "]", "\n", "self", ".", "_approximate_posterior", "=", "out_net", "[", "\"posterior\"", "]", "\n", "\n", "self", ".", "_model_visible", "=", "out_net", "[", "\"reconstruction_model\"", "]", "\n", "self", ".", "x_reconstruction_node", "=", "tf", ".", "identity", "(", "self", ".", "_model_visible", ".", "reconstruction_node", "(", ")", ",", "name", "=", "\"reconstruction_node\"", ")", "\n", "\n", "self", ".", "samples", "=", "out_net", "[", "\"generation_node\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.create_loss": [[112, 118], ["VQVAE.VQVAE._cost_function"], "methods", ["None"], ["", "def", "create_loss", "(", "self", ")", ":", "\n", "\n", "#TODO move up in AbstractAutoEncoder.", "\n", "# A TFDeepLearningModel model should be free to specify a model dependent loss..", "\n", "# compute the cost function, passing the model as a parameter", "\n", "        ", "self", ".", "loss", ",", "self", ".", "loss_nodes_to_log", ",", "self", ".", "loss_nodes_to_log_names", ",", "self", ".", "loss_nodes_to_log_filenames", "=", "self", ".", "_cost_function", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.encode": [[120, 127], ["sess.run", "VQVAE.VQVAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "encode", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Encode data by mapping it into the latent space.\"\"\"", "\n", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "self", ".", "z_q", ",", "\n", "feed_dict", "=", "{", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.decode": [[128, 136], ["sess.run", "VQVAE.VQVAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "decode", "(", "self", ",", "Z", ",", "sess", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data.\"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "image", "=", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node", ",", "\n", "feed_dict", "=", "{", "self", ".", "z_q", ":", "Z", "}", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.generate": [[137, 144], ["sess.run", "VQVAE.VQVAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "generate", "(", "self", ",", "batch_size", "=", "1", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Generate data by sampling from latent space.\n\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "self", ".", "samples", ",", "feed_dict", "=", "{", "self", ".", "n_samples_prior", ":", "batch_size", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.reconstruct": [[145, 151], ["sess.run", "VQVAE.VQVAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "reconstruct", "(", "self", ",", "X", ",", "stp", "=", "False", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use VAE to reconstruct given data. \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node", ",", "\n", "feed_dict", "=", "{", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAE.VQVAE.create_hooks": [[153, 308], ["super().create_hooks", "super().create_hooks.append", "config.get", "config.get", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "super().create_hooks.append", "super().create_hooks.append", "AEImagesReconstructHook.AEImagesReconstructHook.AEImagesReconstructHook", "argo.core.hooks.ImagesGenerateHook.ImagesGenerateHook"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks"], ["", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "        ", "hooks", "=", "super", "(", ")", ".", "create_hooks", "(", "config", ")", "\n", "\n", "# LOGGING HOOKS", "\n", "tensors_to_average", "=", "self", ".", "loss_nodes_to_log", "\n", "tensors_to_average_names", "=", "self", ".", "loss_nodes_to_log_names", "\n", "tensors_to_average_plots", "=", "self", ".", "loss_nodes_to_log_filenames", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "# if you want to remove some dataset from here, make support to specify from conf on which datasets to log, if in doubt ask me please. Riccardo", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", ",", "TEST", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", ")", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"ImagesReconstructHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "AEImagesReconstructHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"ImagesGenerateHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "ImagesGenerateHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "# kwargs = config.get(\"ImportanceSamplingHook\", None)", "\n", "# if kwargs:", "\n", "#     if not isinstance(kwargs, list):", "\n", "#         kwargs = [kwargs]", "\n", "#     for kw in kwargs:", "\n", "#         kws = {**self._plot_model_hooks_kwargs,", "\n", "#                **kw}", "\n", "#         hooks.append(ImportanceSamplingHook(model = self,", "\n", "#                                             dirName = self.dirName,", "\n", "#                                             tensors_to_average = [self.importance_sampling_node],", "\n", "#                                             datasets_keys = [TRAIN, VALIDATION], # don't change the order (Luigi)", "\n", "#                                             **kws", "\n", "#                                            )", "\n", "#                     )", "\n", "#", "\n", "# kwargs = config.get(\"TwoDimPCALatentVariablesHook\", None)", "\n", "# if kwargs:", "\n", "#     kwargs = {**self._default_model_hooks_kwargs,", "\n", "#               **kwargs}", "\n", "#     hooks.append(TwoDimPCALatentVariablesHook(model = self,", "\n", "#                                               dirName = self.dirName,", "\n", "#                                               tensors = [self.z] + list(self._approximate_posterior_params),", "\n", "#                                               tensors_names = ['z',", "\n", "#                                                                'mu'],", "\n", "#                                               datasets_keys = [TRAIN, VALIDATION], # don't change the order (Luigi)", "\n", "#                                               **kwargs", "\n", "#                                              )", "\n", "#                  )", "\n", "#", "\n", "# kwargs = config.get(\"PCALatentVariablesHook\", None)", "\n", "# if kwargs:", "\n", "#     kwargs = {**self._plot_model_hooks_kwargs,", "\n", "#               **kwargs}", "\n", "#     hooks.append(PCALatentVariablesHook(model = self,", "\n", "#                                          dirName = self.dirName,", "\n", "#                                          tensors = [self.z,", "\n", "#                                                     self._approximate_posterior_params[0]],", "\n", "#                                          tensors_names = ['z',", "\n", "#                                                           'mu'],", "\n", "#                                          datasets_keys = [TRAIN, VALIDATION], # don't change the order (Luigi)", "\n", "#                                          **kwargs", "\n", "#                                        )", "\n", "#                  )", "\n", "#", "\n", "# kwargs = config.get(\"VAELinearInterpolationHook\", None)", "\n", "# if kwargs:", "\n", "#     kwargs = {**self._default_model_hooks_kwargs,", "\n", "#               **kwargs}", "\n", "#     hooks.append(VAELinearInterpolationHook(model = self,", "\n", "#                                             dirName = self.dirName,", "\n", "#                                             **kwargs)", "\n", "#                  )", "\n", "#", "\n", "#", "\n", "# kwargs = config.get(\"LatentVarsClassificationHook\", None)", "\n", "# if kwargs:", "\n", "#     kwargs = {**self._plot_model_hooks_kwargs,", "\n", "#                **kwargs}", "\n", "#     hooks.append(LatentVarsClassificationHook(model = self,", "\n", "#                                               dirName = self.dirName,", "\n", "#                                               tensors = [self.z,", "\n", "#                                                          self._approximate_posterior_params[0],", "\n", "#                                                          tf.concat(list(self._approximate_posterior_params), axis=1)],", "\n", "#                                               tensors_names = ['z',", "\n", "#                                                                'mu',", "\n", "#                                                                'mu_cov'],", "\n", "#                                               datasets_keys = [TRAIN,VALIDATION], # don't change the order (Luigi)", "\n", "#                                               **kwargs)", "\n", "#                   )", "\n", "#", "\n", "#", "\n", "# # frechet inception distance", "\n", "# kwargs = config.get(\"FrechetInceptionDistanceHook\", None)", "\n", "# if kwargs:", "\n", "#     for kw in kwargs:", "\n", "#         kws = {**self._default_model_hooks_kwargs,", "\n", "#                **kw}", "\n", "#         hooks.append(FrechetInceptionDistanceHook(model = self,", "\n", "#                                                   dirName = self.dirName,", "\n", "#                                                   **kws)", "\n", "#                     )", "\n", "#", "\n", "# # latent traversals hook", "\n", "# kwargs = config.get(\"LatentTraversalsHook\", None)", "\n", "# if kwargs:", "\n", "#     kwargs = {**self._default_model_hooks_kwargs,", "\n", "#               **kwargs}", "\n", "#     hooks.append(LatentTraversalsHook(model=self,", "\n", "#                                       dirName=self.dirName,", "\n", "#                                       **kwargs)", "\n", "#                                       )", "\n", "#", "\n", "# kwargs = config.get(\"LatentVarsGeometricClassificationHook\", None)", "\n", "# if kwargs:", "\n", "#     kwargs = {**self._default_model_hooks_kwargs,", "\n", "#               **kwargs}", "\n", "#     hooks.append(LatentVarsGeometricClassificationHook(model=self,", "\n", "#                                                        dirName=self.dirName,", "\n", "#                                                        tensors=[self.z,", "\n", "#                                                                 self._approximate_posterior_params[0],", "\n", "#                                                                 tf.concat(list(self._approximate_posterior_params),", "\n", "#                                                                           axis=1)],", "\n", "#                                                        tensors_names=['z',", "\n", "#                                                                       'mu',", "\n", "#                                                                       'mu_cov'],", "\n", "#", "\n", "#                                                        datasets_keys=[TRAIN, VALIDATION, TEST],", "\n", "#                                                        **kwargs)", "\n", "#                  )", "\n", "\n", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AEImagesReconstructHook.AEImagesReconstructHook.do_when_triggered": [[18, 52], ["tf_logging.info", "AEImagesReconstructHook.AEImagesReconstructHook.load_images", "AEImagesReconstructHook.AEImagesReconstructHook._model.encode", "AEImagesReconstructHook.AEImagesReconstructHook._model.decode", "argo.core.utils.ImagesSaver.ImagesSaver", "int", "range", "argo.core.utils.ImagesSaver.ImagesSaver.save_images", "numpy.ceil", "range", "range", "panel[].append", "panel[].append", "len", "str().zfill", "len", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_images", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["    ", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "#tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for ImagesReconstructHook\"", ")", "\n", "time_ref", "=", "self", ".", "_time_ref", "\n", "time_ref_str", "=", "self", ".", "_time_ref_shortstr", "\n", "\n", "self", ".", "load_images", "(", "run_context", ".", "session", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_images", ":", "\n", "            ", "images", "=", "self", ".", "_images", "[", "ds_key", "]", "[", "1", "]", "\n", "\n", "hs", "=", "self", ".", "_model", ".", "encode", "(", "images", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "reconstructed_images", "=", "self", ".", "_model", ".", "decode", "(", "hs", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "\n", "images_saver", "=", "ImagesSaver", "(", "self", ".", "_dirName", ")", "\n", "\n", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", "*", "2", ")", "]", "\n", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "2", "*", "rows", ",", "2", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                    ", "panel", "[", "i", "]", ".", "append", "(", "images", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "1", "]", ".", "append", "(", "reconstructed_images", "[", "c", "]", ")", "\n", "if", "c", "==", "len", "(", "images", ")", "-", "1", ":", "\n", "                        ", "break", "\n", "", "else", ":", "\n", "                        ", "c", "=", "c", "+", "1", "\n", "\n", "# \"[1st] original image [2nd] recostructed  mean [3rd] reconstr z\"", "\n", "", "", "", "images_saver", ".", "save_images", "(", "panel", ",", "\n", "fileName", "=", "\"reconstructed\"", "+", "\"_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", ",", "\n", "title", "=", "self", ".", "_fileName", ",", "\n", "fontsize", "=", "9", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavGenerateHook.WavGenerateHook.__init__": [[16, 65], ["argo.core.hooks.AbstractWavHook.AbstractWavHook.__init__", "bool", "bool", "datasets.Dataset.check_dataset_keys_not_loop", "tf_logging.info", "type", "list", "sample_indices_by_dataset.keys", "sample_indices_by_dataset.items", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "sample_indices_by_dataset", "=", "{", "\n", "VALIDATION", ":", "[", "]", "}", ",", "\n", "fast_gen", "=", "True", ",", "# use fast_generation wavenet for reconstruction without teacher forcing", "\n", "debug_fast_gen", "=", "True", ",", "\n", "# use fast_generation wavenet with the true input shifted and quantized to reconstruct with teacher forcing and check the FastGen network", "\n", "hop_legth_cqt", "=", "128", ",", "\n", "dataset_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "save_wav", "=", "False", ",", "\n", "compute_reconstruction_metrics", "=", "True", ",", "\n", "_plot", "=", "True", ",", "\n", "generate_from_mean", "=", "True", ",", "\n", "spider_plot_time_splits", "=", "None", ",", "\n", "anomaly_detection_params", "=", "None", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "dataset_keys", ",", "hop_legth_cqt", "=", "hop_legth_cqt", ",", "\n", "dirName", "=", "dirName", ")", "\n", "\n", "self", ".", "model_class_name", "=", "type", "(", "model", ")", ".", "__name__", "\n", "self", ".", "save_wav", "=", "save_wav", "\n", "self", ".", "compute_reconstruction_metrics", "=", "compute_reconstruction_metrics", "\n", "self", ".", "_plot", "=", "_plot", "\n", "self", ".", "generate_from_mean", "=", "generate_from_mean", "\n", "self", ".", "spider_plot_time_splits", "=", "spider_plot_time_splits", "\n", "\n", "self", ".", "anomaly_detection_params", "=", "anomaly_detection_params", "\n", "\n", "if", "compute_reconstruction_metrics", ":", "\n", "            ", "self", ".", "reconstr_metrics_file_names", "=", "{", "\n", "TRAIN", ":", "dirName", "+", "'/reconstr_metrics_x_train.txt'", ",", "\n", "VALIDATION", ":", "dirName", "+", "'/reconstr_metrics_x_validation.txt'", ",", "\n", "TEST", ":", "dirName", "+", "'/reconstr_metrics_x_test.txt'", ",", "\n", "}", "\n", "\n", "", "self", ".", "_sample_indices_by_dataset", "=", "sample_indices_by_dataset", "\n", "\n", "self", ".", "_fast_gen", "=", "bool", "(", "fast_gen", ")", "\n", "self", ".", "_debug_fast_gen", "=", "bool", "(", "debug_fast_gen", ")", "\n", "\n", "check_dataset_keys_not_loop", "(", "list", "(", "sample_indices_by_dataset", ".", "keys", "(", ")", ")", ")", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create WavGenerateHook for: \\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "ds_key", "+", "\": \"", "+", "\", \"", ".", "join", "(", "map", "(", "str", ",", "idxs", "or", "[", "'all'", "]", ")", ")", "for", "ds_key", ",", "idxs", "in", "sample_indices_by_dataset", ".", "items", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavGenerateHook.WavGenerateHook.before_training": [[66, 73], ["tf_logging.info", "WavGenerateHook.WavGenerateHook._write_originals", "WavGenerateHook.WavGenerateHook.write_headers_to_reconstruction_files", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._write_originals", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.write_headers_to_reconstruction_files"], ["", "def", "before_training", "(", "self", ",", "session", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"WavGenerateHook, writing originals: \"", "+", "str", "(", "self", ".", "save_wav", ")", ")", "\n", "if", "self", ".", "save_wav", ":", "\n", "            ", "self", ".", "_write_originals", "(", ")", "\n", "\n", "", "if", "self", ".", "compute_reconstruction_metrics", ":", "\n", "            ", "self", ".", "write_headers_to_reconstruction_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavGenerateHook.WavGenerateHook.do_when_triggered": [[74, 154], ["tf_logging.info", "WavGenerateHook.WavGenerateHook.get_stacked_encodings", "WavGenerateHook.WavGenerateHook._model.decode", "zip", "wavenet.AnomalyDetector.AnomalyDetector", "tf_logging.info", "wavenet.AnomalyDetector.AnomalyDetector.detect_anomalies", "numpy.split", "numpy.split", "numpy.split", "WavGenerateHook.WavGenerateHook._model.mean_reconstr_loss", "WavGenerateHook.WavGenerateHook.log_reconstr_metrics", "wavenet.AnomalyDetector.AnomalyDetector.set_data", "WavGenerateHook.WavGenerateHook.spider_plot_encoding", "WavGenerateHook.WavGenerateHook.multi_plot_and_save", "WavGenerateHook.WavGenerateHook._model.decode_debug_astf", "WavGenerateHook.WavGenerateHook.plot_and_save", "WavGenerateHook.WavGenerateHook.plot_and_save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.WavGenerateHook.WavGenerateHook.get_stacked_encodings", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.detect_anomalies", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.mean_reconstr_loss", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.log_reconstr_metrics", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.set_data", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.spider_plot_encoding", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.multi_plot_and_save", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.decode_debug_astf", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.plot_and_save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.plot_and_save"], ["", "", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "'''\n\n        This works as follows:\n        1. stack all samples (not just the ones given by the indices) from all ds_keys and generate their encoding\n         which contains the ecnoding from all ds_keys and hs and zs stacked on the 0-axis\n        2. from the stacked encoding reconstruct the samples\n        3. de-stack the encodings and samples and compute reconstruction metrics and plot the specified samples by indices\n\n        '''", "\n", "tf_logging", ".", "info", "(", "\"trigger for WavGenerateHook\"", ")", "\n", "\n", "combined_encodings", ",", "ds_keys", ",", "ds_key_batch_sizes", ",", "covariances", ",", "prior_means", ",", "prior_covs", ",", "x_shifted_list", ",", "x_target_combined", "=", "self", ".", "get_stacked_encodings", "(", "\n", "run_context", ")", "\n", "reconstructions_combined", ",", "reconstr_losses", "=", "self", ".", "_model", ".", "decode", "(", "combined_encodings", ",", "input_qs", "=", "False", ",", "\n", "sess", "=", "run_context", ".", "session", ",", "\n", "x_target_quantized", "=", "x_target_combined", ")", "\n", "\n", "anomaly_detector", "=", "None", "\n", "if", "self", ".", "anomaly_detection_params", "is", "not", "None", ":", "\n", "            ", "anomaly_detector", "=", "AnomalyDetector", "(", "self", ".", "anomaly_detection_params", ",", "self", ".", "dir_name_anomaly_detection", ",", "\n", "'{}{}'", ".", "format", "(", "self", ".", "_time_ref_shortstr", ",", "self", ".", "_time_ref", ")", ")", "\n", "\n", "", "start_batch", "=", "0", "\n", "for", "ds_key", ",", "ds_key_batch_size", ",", "covariance", ",", "prior_mean", ",", "prior_cov", ",", "x_shifted", "in", "zip", "(", "ds_keys", ",", "ds_key_batch_sizes", ",", "covariances", ",", "prior_means", ",", "prior_covs", ",", "x_shifted_list", ")", ":", "\n", "            ", "indices", ",", "samples", "=", "self", ".", "_samples", "[", "ds_key", "]", "\n", "_", ",", "labels", "=", "self", ".", "_labels", "[", "ds_key", "]", "\n", "\n", "end_batch", "=", "start_batch", "+", "ds_key_batch_size", "\n", "zs", "=", "combined_encodings", "[", "start_batch", ":", "end_batch", "]", "\n", "reconstructed_samples", "=", "reconstructions_combined", "[", "start_batch", ":", "end_batch", "]", "\n", "reconstr_loss", "=", "reconstr_losses", "[", "start_batch", ":", "end_batch", "]", "\n", "\n", "if", "covariance", "is", "not", "None", "and", "self", ".", "generate_from_mean", ":", "\n", "# it means that we have stacked zs and hs for the current ds_key -> need to unstack", "\n", "                ", "zs", ",", "hs", "=", "np", ".", "split", "(", "zs", ",", "2", ",", "axis", "=", "0", ")", "\n", "reconstructed_samples", ",", "reconstructed_samples_mean", "=", "np", ".", "split", "(", "reconstructed_samples", ",", "2", ",", "axis", "=", "0", ")", "\n", "reconstr_loss", ",", "reconstr_loss_mean", "=", "np", ".", "split", "(", "reconstr_loss", ",", "2", ",", "axis", "=", "0", ")", "\n", "reconstr_loss_mean", "=", "self", ".", "_model", ".", "mean_reconstr_loss", "(", "reconstr_loss_mean", ")", "\n", "\n", "", "if", "self", ".", "compute_reconstruction_metrics", ":", "\n", "                ", "self", ".", "log_reconstr_metrics", "(", "self", ".", "_time_ref", ",", "samples", ",", "reconstructed_samples", ",", "reconstr_loss", ",", "labels", ",", "\n", "self", ".", "reconstr_metrics_file_names", "[", "ds_key", "]", ")", "\n", "\n", "", "if", "anomaly_detector", "is", "not", "None", ":", "\n", "                ", "anomaly_detector", ".", "set_data", "(", "ds_key", ",", "samples", ",", "reconstructed_samples", ",", "labels", ",", "reconstr_losses", ")", "\n", "\n", "", "if", "self", ".", "spider_plot_time_splits", "is", "not", "None", ":", "\n", "                ", "self", ".", "spider_plot_encoding", "(", "ds_key", ",", "indices", ",", "samples", "[", "indices", "]", ",", "labels", "[", "indices", "]", ",", "\n", "self", ".", "_time_ref", ",", "self", ".", "_time_ref_shortstr", ",", "zs", "[", "indices", "]", ",", "\n", "prefix", "=", "'spider_plot_'", ",", "num_time_splits", "=", "self", ".", "spider_plot_time_splits", ")", "\n", "\n", "", "if", "self", ".", "_plot", "and", "covariance", "is", "not", "None", "and", "self", ".", "generate_from_mean", ":", "\n", "                ", "self", ".", "multi_plot_and_save", "(", "ds_key", ",", "indices", ",", "reconstructed_samples_mean", "[", "indices", "]", ",", "\n", "reconstructed_samples", "[", "indices", "]", ",", "samples", "[", "indices", "]", ",", "labels", "[", "indices", "]", ",", "\n", "self", ".", "_time_ref", ",", "self", ".", "_time_ref_shortstr", ",", "zs", "[", "indices", "]", ",", "hs", "[", "indices", "]", ",", "\n", "covariance", "[", "indices", "]", ",", "prior_mean", ",", "prior_cov", ",", "\n", "prefix", "=", "'multiplot_x_'", ",", "save_enc", "=", "False", ",", "save_wav", "=", "self", ".", "save_wav", ",", "\n", "plot_mean_separately", "=", "False", ",", "plot_rainbowgram", "=", "False", ")", "\n", "# AE", "\n", "", "elif", "self", ".", "_plot", ":", "\n", "                ", "self", ".", "plot_and_save", "(", "ds_key", ",", "indices", ",", "reconstructed_samples", "[", "indices", "]", ",", "samples", "[", "indices", "]", ",", "\n", "labels", "[", "indices", "]", ",", "self", ".", "_time_ref", ",", "self", ".", "_time_ref_shortstr", ",", "zs", "[", "indices", "]", ",", "\n", "prefix", "=", "\"reconstruction_x_\"", ",", "suffix", "=", "'sample'", ",", "save_enc", "=", "False", ",", "save_wav", "=", "self", ".", "save_wav", ")", "\n", "\n", "", "start_batch", "=", "end_batch", "\n", "\n", "if", "self", ".", "_debug_fast_gen", ":", "\n", "# TEST FOR DEBUGGING: FAST GENERATION AS TEACHER FORCING FOR COMPARISON", "\n", "                ", "reconstructed_samples", "=", "self", ".", "_model", ".", "decode_debug_astf", "(", "(", "hs", "if", "hs", "is", "not", "None", "else", "zs", ")", ",", "x_shifted", ",", "\n", "sess", "=", "run_context", ".", "session", ")", "\n", "self", ".", "plot_and_save", "(", "ds_key", ",", "indices", ",", "reconstructed_samples", "[", "indices", "]", ",", "samples", "[", "indices", "]", ",", "self", ".", "_time_ref", ",", "\n", "self", ".", "_time_ref_shortstr", ",", "\n", "zs", "[", "indices", "]", ",", "prefix", "=", "\"reconstruction_debug_astf_\"", ",", "suffix", "=", "None", ",", "save_enc", "=", "False", ",", "\n", "save_wav", "=", "self", ".", "save_wav", ")", "\n", "", "tf_logging", ".", "info", "(", "\"finished with %s\"", "%", "ds_key", ")", "\n", "\n", "", "if", "anomaly_detector", "is", "not", "None", ":", "\n", "            ", "anomaly_detector", ".", "detect_anomalies", "(", "self", ".", "_model", ".", "dataset", ".", "sample_rate", ",", "reconstruction_method", "=", "'x'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavGenerateHook.WavGenerateHook.get_stacked_encodings": [[155, 231], ["ds_keys.append", "WavGenerateHook.WavGenerateHook._model.encode", "covariances.append", "prior_means.append", "prior_covs.append", "x_shifted_list.append", "numpy.squeeze", "ds_key_batch_sizes.append", "len", "wavenet.utils.mu_law_numpy", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "len", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.mu_law_numpy"], ["", "", "def", "get_stacked_encodings", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "'''\n        stacks all the samples from all ds keys and returns the stacked resulting encoding on axis 0\n        may have a structure like this if we also have VAE and encoding from the mean:\n\n        0 axis stacking structure e.g. not specifically this order of train/validation:\n        if self.generate_from_mean == True\n\n        || zs_validation | hs_validation || zs_train | hs_train || ...\n\n        else\n\n        || zs_ds_validation  || zs_ds_train  || ...\n\n        Returns:\n            tensor (batches, time_length, channels) : the stacked encodings\n            ds_keys (List): the order in whcih the ds_key samples are stacked in the stacked encoding tensor\n            ds_key_batch_sizes (List): a list of integers indicating how much space each ds_key takes up\n            covariances: the covariances corresponging to the means of the distribution. None if self.generate_from_mean == False\n            x_shifted_list\n            x_target_combined: the stacked target x for computing the reconstruction loss\n\n        '''", "\n", "\n", "ds_keys", "=", "[", "]", "\n", "ds_key_batch_sizes", "=", "[", "]", "# will store information about how much of the batch axis 0 is held by each ds_key samples", "\n", "stacked_encodings", "=", "None", "\n", "covariances", "=", "[", "]", "\n", "prior_means", "=", "[", "]", "\n", "prior_covs", "=", "[", "]", "\n", "x_shifted_list", "=", "[", "]", "\n", "x_target_combined", "=", "None", "\n", "\n", "for", "ds_key", "in", "self", ".", "_samples", ":", "\n", "            ", "indices", ",", "samples", "=", "self", ".", "_samples", "[", "ds_key", "]", "\n", "_", ",", "labels", "=", "self", ".", "_labels", "[", "ds_key", "]", "\n", "\n", "ds_keys", ".", "append", "(", "ds_key", ")", "\n", "\n", "encode_tuple", "=", "self", ".", "_model", ".", "encode", "(", "samples", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "if", "len", "(", "encode_tuple", ")", "==", "2", ":", "\n", "                ", "zs", ",", "x_shifted", "=", "encode_tuple", "\n", "hs", ",", "covariance", ",", "prior_mean", ",", "prior_cov", "=", "[", "None", "]", "*", "4", "\n", "", "elif", "len", "(", "encode_tuple", ")", "==", "6", ":", "\n", "                ", "zs", ",", "hs", ",", "covariance", ",", "prior_mean", ",", "prior_cov", ",", "x_shifted", "=", "encode_tuple", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"This tuple should not be this length: {}\"", ".", "format", "(", "len", "(", "encode_tuple", ")", ")", ")", "\n", "", "covariances", ".", "append", "(", "covariance", ")", "\n", "prior_means", ".", "append", "(", "prior_mean", ")", "\n", "prior_covs", ".", "append", "(", "prior_cov", ")", "\n", "x_shifted_list", ".", "append", "(", "x_shifted", ")", "\n", "\n", "x_target_quantized", "=", "mu_law_numpy", "(", "samples", ")", "+", "128", "\n", "x_target_quantized", "=", "np", ".", "squeeze", "(", "x_target_quantized", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# store information about how much zs+hs of the current ds_key will be held in the combined encodings array", "\n", "ds_key_batch_size", "=", "zs", ".", "shape", "[", "0", "]", "\n", "encoding", "=", "zs", "\n", "if", "hs", "is", "not", "None", "and", "self", ".", "generate_from_mean", ":", "\n", "                ", "ds_key_batch_size", "*=", "2", "\n", "encoding", "=", "np", ".", "concatenate", "(", "[", "zs", ",", "hs", "]", ",", "axis", "=", "0", ")", "\n", "x_target_quantized", "=", "np", ".", "concatenate", "(", "[", "x_target_quantized", ",", "x_target_quantized", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "ds_key_batch_sizes", ".", "append", "(", "ds_key_batch_size", ")", "\n", "\n", "if", "stacked_encodings", "is", "None", ":", "\n", "                ", "stacked_encodings", "=", "encoding", "\n", "", "else", ":", "\n", "                ", "stacked_encodings", "=", "np", ".", "concatenate", "(", "[", "stacked_encodings", ",", "encoding", "]", ")", "\n", "\n", "", "if", "x_target_combined", "is", "None", ":", "\n", "                ", "x_target_combined", "=", "x_target_quantized", "\n", "", "else", ":", "\n", "                ", "x_target_combined", "=", "np", ".", "concatenate", "(", "[", "x_target_combined", ",", "x_target_quantized", "]", ")", "\n", "\n", "", "", "return", "stacked_encodings", ",", "ds_keys", ",", "ds_key_batch_sizes", ",", "covariances", ",", "prior_means", ",", "prior_covs", ",", "x_shifted_list", ",", "x_target_combined", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.__init__": [[46, 60], ["WavenetVAENetwork.WavenetVAENetwork.WavenetVAENetwork", "argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "argo.core.network.AbstractAutoEncoder.AbstractAutoEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "# NB need to create the network before the super().__init__ because id generation depends on the network", "\n", "        ", "self", ".", "_network", "=", "WavenetVAENetwork", "(", "opts", ")", "\n", "self", ".", "_cost_function", "=", "CostFunctions", ".", "instantiate_cost_function", "(", "opts", "[", "\"cost_function\"", "]", ")", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n", "self", ".", "x_reconstruction_distr_tf", "=", "None", "\n", "self", ".", "x_reconstruction_node_tf", "=", "None", "\n", "self", ".", "x_reconstruction_distr", "=", "None", "\n", "self", ".", "x_reconstruction_node", "=", "None", "\n", "self", ".", "z", "=", "None", "\n", "self", ".", "x_shifted_qs", "=", "None", "\n", "self", ".", "n_z_samples", "=", "None", "\n", "self", ".", "reconstr_loss_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.create_id": [[61, 72], ["super().create_id", "WavenetVAE.WavenetVAE._network.create_id", "WavenetVAE.WavenetVAE._cost_function.create_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["", "def", "create_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "self", ".", "launchable_name", "\n", "\n", "_id", "+=", "'-c'", "+", "self", ".", "_cost_function", ".", "create_id", "(", "self", ".", "_opts", "[", "\"cost_function\"", "]", "[", "1", "]", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "network_id", "=", "self", ".", "_network", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "+", "network_id", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.create_hooks": [[73, 226], ["super().create_hooks", "tensorflow.cast", "tensorflow.image.psnr", "wavenet.mel_utils_tensorflow.mfcc", "wavenet.mel_utils_tensorflow.mfcc", "wavenet.mel_utils_tensorflow.mcd", "super().create_hooks.append", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "tensorflow.reduce_prod", "tensorflow.log", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "tensorflow.reduce_max", "WavReconstructHook.WavReconstructHook.WavReconstructHook", "WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook.WavenetGaussianVisualizationHook", "WavGenerateHook.WavGenerateHook.WavGenerateHook", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook", "PCALatentVariablesHook.PCALatentVariablesHook.PCALatentVariablesHook", "WavLatentPCAHook.WavLatentPCAHook.WavLatentPCAHook", "WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook", "tensorflow.shape", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mcd", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "        ", "hooks", "=", "super", "(", ")", ".", "create_hooks", "(", "config", ")", "\n", "\n", "# LOGGING HOOKS", "\n", "\n", "# the shape of the input could be different from train to eval", "\n", "dim_with_channels", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "self", ".", "x", ")", "[", "1", ":", "]", ")", ",", "\n", "tf", ".", "float32", ")", "\n", "\n", "# check https://www.reddit.com/r/MachineLearning/comments/56m5o2/discussion_calculation_of_bitsdims/", "\n", "bits_dim", "=", "(", "self", ".", "loss", "/", "dim_with_channels", ")", "/", "tf", ".", "log", "(", "2.0", ")", "# - tf.log(256.0)", "\n", "\n", "psnr_reconstruction_quality", "=", "tf", ".", "image", ".", "psnr", "(", "self", ".", "x", ",", "self", ".", "x_reconstruction_node_tf", ",", "max_val", "=", "tf", ".", "reduce_max", "(", "self", ".", "x", ")", ")", "\n", "\n", "sample_rate", "=", "self", ".", "dataset", ".", "sample_rate", "\n", "mfcc_original", "=", "mfcc", "(", "self", ".", "x", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "mfcc_reconstructed", "=", "mfcc", "(", "self", ".", "x_reconstruction_node_tf", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "mcd_reconstruction_quality", "=", "mcd", "(", "mfcc_original", ",", "mfcc_reconstructed", ")", "\n", "\n", "tensors_to_average", "=", "[", "\n", "[", "[", "psnr_reconstruction_quality", "]", "\n", "]", ",", "\n", "[", "[", "mcd_reconstruction_quality", "]", "\n", "]", ",", "\n", "[", "[", "-", "self", ".", "loss", "]", ",", "\n", "]", ",", "\n", "[", "[", "bits_dim", "]", ",", "\n", "]", ",", "\n", "self", ".", "nodes_to_track", "\n", "]", "\n", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "'PSNR_reconstruction_quality'", "]", "\n", "]", ",", "\n", "[", "[", "'MCD_reconstruction_distortion'", "]", "\n", "]", ",", "\n", "[", "[", "\"LB_log(p)\"", "]", "\n", "]", ",", "\n", "[", "[", "\"b/d\"", "]", "\n", "]", ",", "\n", "self", ".", "names_nodes_to_track", "\n", "]", "\n", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\n", "\"fileName\"", ":", "'psnr_reconstr_quality'", "}", "\n", "]", ",", "\n", "[", "{", "\n", "\"fileName\"", ":", "'mcd_reconstr_distortion'", "}", "\n", "]", ",", "\n", "[", "{", "\n", "\"fileName\"", ":", "\"loss\"", "}", "\n", "]", ",", "\n", "[", "{", "\n", "\"fileName\"", ":", "\"bits_dim\"", "}", "\n", "]", ",", "\n", "self", ".", "loss_nodes_to_log_filenames", "\n", "]", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", ")", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"WavReconstructHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "WavReconstructHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"WavenetGaussianVisualizationHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "WavenetGaussianVisualizationHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"WavGenerateHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "WavGenerateHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"TwoDimPCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "TwoDimPCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "z", "]", ",", "\n", "tensors_names", "=", "[", "'z'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"PCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "PCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "tf", ".", "reshape", "(", "self", ".", "z", ",", "[", "-", "1", ",", "self", ".", "z", ".", "shape", "[", "-", "1", "]", "]", ")", "]", ",", "\n", "tensors_names", "=", "[", "'z'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"WavLatentPCAHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "WavLatentPCAHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "dataset_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "'WavClusterAnomalyDetectionHook'", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "WavClusterAnomalyDetectionHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "dataset_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.create_network": [[227, 266], ["WavenetVAE.WavenetVAE._network", "tensorflow.placeholder", "WavenetVAE.WavenetVAE._gaussian_model_latent.mean", "tensorflow.transpose", "WavenetVAE.WavenetVAE._gaussian_model_latent.covariance", "WavenetVAE.WavenetVAE._prior.mean", "WavenetVAE.WavenetVAE._prior.covariance", "wavenet.utils.mu_law", "tensorflow.placeholder"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.mu_law"], ["", "def", "create_network", "(", "self", ")", ":", "\n", "# create autoencoder network", "\n", "# self.x_shifted, self.z, self.x_reconstruction_distr, self.x_reconstruction_node, self.x_gen = self._network(self.x)", "\n", "        ", "net", "=", "self", ".", "_network", "(", "self", ".", "x", ",", "x_shape", "=", "self", ".", "dataset", ".", "x_shape_train", ")", "\n", "self", ".", "x_shifted_qs", "=", "net", "[", "\"x_shifted_qs\"", "]", "\n", "self", ".", "z", "=", "net", "[", "\"z\"", "]", "\n", "self", ".", "_upsample_encoding", "=", "net", "[", "'upsample_encoding'", "]", "\n", "self", ".", "z_upsampled", "=", "net", "[", "'z_upsampled'", "]", "\n", "self", ".", "samples_posterior", "=", "net", "[", "'samples_posterior'", "]", "\n", "\n", "self", ".", "x_reconstruction_distr_tf", "=", "net", "[", "\"x_rec_distr_tf\"", "]", "\n", "self", ".", "x_reconstruction_logits_tf", "=", "self", ".", "x_reconstruction_distr_tf", ".", "logits", "\n", "self", ".", "x_reconstruction_node_tf", "=", "net", "[", "\"x_rec_tf\"", "]", "\n", "\n", "self", ".", "x_t", "=", "net", "[", "\"x_t\"", "]", "\n", "self", ".", "x_t_qs", "=", "net", "[", "\"x_t_qs\"", "]", "\n", "self", ".", "z_t", "=", "net", "[", "\"z_t\"", "]", "\n", "self", ".", "x_tp1_distr", "=", "net", "[", "\"x_tp1_distr\"", "]", "\n", "self", ".", "x_tp1", "=", "net", "[", "\"x_tp1\"", "]", "\n", "self", ".", "x_target_t", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "1", "]", ",", "name", "=", "'x_target_t'", ")", "\n", "self", ".", "queues_init_ops", "=", "net", "[", "\"queues_init_ops\"", "]", "\n", "self", ".", "queues_push_ops", "=", "net", "[", "\"queues_push_ops\"", "]", "\n", "self", ".", "queues_dicts", "=", "net", "[", "\"queues_dicts\"", "]", "\n", "\n", "self", ".", "n_z_samples", "=", "net", "[", "\"n_z_samples\"", "]", "\n", "\n", "self", ".", "queues_dequeue", "=", "[", "qd", "[", "\"dequeue\"", "]", "for", "qd", "in", "self", ".", "queues_dicts", "]", "\n", "self", ".", "queues_size", "=", "[", "qd", "[", "\"size\"", "]", "for", "qd", "in", "self", ".", "queues_dicts", "]", "\n", "self", ".", "_gaussian_model_latent", "=", "net", "[", "\"latent\"", "]", "\n", "self", ".", "_gaussian_model_latent_mean", "=", "self", ".", "_gaussian_model_latent", ".", "mean", "(", ")", "\n", "self", ".", "_gaussian_model_latent_mean_transp", "=", "tf", ".", "transpose", "(", "self", ".", "_gaussian_model_latent_mean", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "self", ".", "_gaussian_model_latent_covariance", "=", "self", ".", "_gaussian_model_latent", ".", "covariance", "(", ")", "\n", "self", ".", "_prior", "=", "net", "[", "\"prior\"", "]", "\n", "self", ".", "_prior_mean", "=", "self", ".", "_prior", ".", "mean", "(", ")", "\n", "self", ".", "_prior_covariance", "=", "self", ".", "_prior", ".", "covariance", "(", ")", "\n", "\n", "self", ".", "_model_visible", "=", "self", ".", "x_reconstruction_distr_tf", "\n", "self", ".", "x_target_quantized", "=", "mu_law", "(", "self", ".", "x_target", ")", "\n", "self", ".", "x_target_quantized_squeezed", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.create_loss": [[267, 276], ["WavenetVAE.WavenetVAE._cost_function", "WavenetVAE.WavenetVAE._cost_function.reconstr_loss_per_sample", "WavenetVAE.WavenetVAE._cost_function.reconstr_loss_per_sample", "WavenetVAE.WavenetVAE._cost_function.reconstruction_loss"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.reconstr_loss_per_sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetELBO.WavenetELBO.reconstr_loss_per_sample", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss"], ["", "def", "create_loss", "(", "self", ")", ":", "\n", "# A TFDeepLearningModel model should be free to specify a model dependent loss..", "\n", "# compute the cost function, passing the model as a parameter", "\n", "        ", "self", ".", "loss", ",", "self", ".", "nodes_to_track", ",", "self", ".", "names_nodes_to_track", ",", "self", ".", "loss_nodes_to_log_filenames", "=", "self", ".", "_cost_function", "(", "\n", "self", ")", "\n", "\n", "self", ".", "reconstr_loss_t", "=", "self", ".", "_cost_function", ".", "reconstr_loss_per_sample", "(", "self", ".", "x_target_t", ",", "self", ".", "n_z_samples", ",", "self", ".", "x_tp1_distr", ")", "\n", "self", ".", "reconstr_loss_tf_per_sample", "=", "self", ".", "_cost_function", ".", "reconstr_loss_per_sample", "(", "self", ".", "x_target_quantized_squeezed", ",", "self", ".", "n_z_samples", ",", "self", ".", "_model_visible", ")", "\n", "self", ".", "reconstr_loss_tf_val", "=", "self", ".", "_cost_function", ".", "reconstruction_loss", "(", "self", ".", "x_target_quantized_squeezed", ",", "self", ".", "n_z_samples", ",", "self", ".", "_model_visible", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.encode": [[277, 307], ["WavenetVAE.WavenetVAE.get_raw_session", "sess.run", "WavenetVAE.WavenetVAE.encode", "zs.append", "means.append", "covs.append", "prior_means.append", "prior_covs.append", "x_shifted_list.append", "min", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode"], ["", "def", "encode", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Encode data by mapping it into the latent space.\"\"\"", "\n", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "bs", ",", "length", ",", "ch", "=", "X", ".", "shape", "\n", "bs_train", "=", "self", ".", "batch_size", "[", "'train'", "]", "\n", "\n", "if", "self", ".", "_network", ".", "_e_hidden_channels", ">", "128", "and", "bs", ">", "bs_train", ":", "\n", "            ", "zs", ",", "means", ",", "covs", ",", "prior_means", ",", "prior_covs", ",", "x_shifted_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "start_batch", ",", "end_batch", "=", "0", ",", "bs_train", "\n", "\n", "while", "start_batch", "!=", "end_batch", ":", "\n", "                ", "z", ",", "mean", ",", "cov", ",", "prior_mean", ",", "prior_cov", ",", "x_shifted", "=", "self", ".", "encode", "(", "X", "[", "start_batch", ":", "end_batch", "]", ")", "\n", "zs", ".", "append", "(", "z", ")", "\n", "means", ".", "append", "(", "mean", ")", "\n", "covs", ".", "append", "(", "cov", ")", "\n", "prior_means", ".", "append", "(", "prior_mean", ")", "\n", "prior_covs", ".", "append", "(", "prior_cov", ")", "\n", "x_shifted_list", ".", "append", "(", "x_shifted", ")", "\n", "\n", "start_batch", "=", "end_batch", "\n", "end_batch", "=", "min", "(", "bs", ",", "end_batch", "+", "bs_train", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "zs", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "means", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "covs", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "prior_means", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "prior_covs", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "x_shifted_list", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "sess", ".", "run", "(", "[", "self", ".", "z", ",", "self", ".", "_gaussian_model_latent_mean_transp", ",", "self", ".", "_gaussian_model_latent_covariance", ",", "\n", "self", ".", "_prior_mean", ",", "self", ".", "_prior_covariance", ",", "self", ".", "x_shifted_qs", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.get_mean_covariance": [[308, 316], ["sess.run", "WavenetVAE.WavenetVAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "", "def", "get_mean_covariance", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "'''\n        returns the mean and the covariance of the latent gaussian distribution\n        '''", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "_gaussian_model_latent_mean_transp", ",", "self", ".", "_gaussian_model_latent_covariance", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x", ":", "X", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.decode_tf": [[327, 362], ["min", "numpy.zeros", "numpy.zeros", "WavenetVAE.WavenetVAE.get_raw_session", "sess.run", "min"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "decode_tf", "(", "self", ",", "Z", ",", "X_shifted", ",", "x_target_quantized", ",", "sess", "=", "None", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data for an autoregressive model,\n        with teacher forcing.\n            Args:\n                x_target_quantized (np.array): the target signal with values in range [0, 256]\n                                                and shape (bs, signal_length)\n            Returns:\n                reconstruction from Z and the associated reconstruction loss\n        \"\"\"", "\n", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "# decode in mini_batches because if we decode more than 50 samples at a time with 6000x8 length then", "\n", "# we will run out of memory", "\n", "total_batch", ",", "signal_length", "=", "x_target_quantized", ".", "shape", "\n", "mini_batch_size", "=", "min", "(", "batch_size", "or", "total_batch", ",", "total_batch", ")", "\n", "start_batch", ",", "end_batch", "=", "0", ",", "mini_batch_size", "\n", "\n", "reconstruction", "=", "np", ".", "zeros", "(", "(", "total_batch", ",", "signal_length", ",", "1", ")", ",", "dtype", "=", "'float32'", ")", "\n", "reconstr_losses", "=", "np", ".", "zeros", "(", "(", "total_batch", ")", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "# have to do this in batches because for total_batch > 50 it will run out of memory", "\n", "while", "start_batch", "!=", "end_batch", ":", "\n", "            ", "reconstruction", "[", "start_batch", ":", "end_batch", "]", ",", "reconstr_losses", "[", "start_batch", ":", "end_batch", "]", "=", "sess", ".", "run", "(", "[", "self", ".", "x_reconstruction_node_tf", ",", "self", ".", "reconstr_loss_tf_per_sample", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "z", ":", "Z", "[", "start_batch", ":", "end_batch", "]", ",", "\n", "self", ".", "x_shifted_qs", ":", "X_shifted", "[", "start_batch", ":", "end_batch", "]", ",", "\n", "self", ".", "x_target_quantized_squeezed", ":", "x_target_quantized", "[", "start_batch", ":", "end_batch", "]", "\n", "}", ")", "\n", "\n", "start_batch", "=", "end_batch", "\n", "end_batch", "=", "min", "(", "end_batch", "+", "mini_batch_size", ",", "total_batch", ")", "\n", "\n", "", "return", "reconstruction", ",", "reconstr_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.reconstruct_tf": [[363, 372], ["sess.run", "WavenetVAE.WavenetVAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "reconstruct_tf", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use AE to reconstruct given data.\n        With teacher forcing.\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "return", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node_tf", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.decode": [[373, 452], ["sess.run", "numpy.zeros", "numpy.zeros", "time.time", "range", "time.time", "tf_logging.info", "time.time", "wavenet.utils.empty_all_queues", "time.time", "tf_logging.info", "all", "WavenetVAE.WavenetVAE.get_raw_session", "sess.run", "numpy.zeros", "numpy.sum", "sess.run", "tf_logging.info", "str", "str().zfill", "str", "str().zfill", "int", "int", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.empty_all_queues", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "decode", "(", "self", ",", "Z", ",", "X_0", "=", "None", ",", "input_qs", "=", "False", ",", "sess", "=", "None", ",", "x_target_quantized", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data for wavenet autoregressive model\n            Args:\n                x_target_quantized (np.array): the target signal with values in range [0, 256]\n                                                and shape (bs, signal_length)\n\n            Returns:\n                the reconstruction without teacher forcing from Z and the associated reconstruction loss computed\n                at each time step individually\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "bs", ",", "z_length", ",", "z_ch", "=", "Z", ".", "shape", "\n", "hop_length", "=", "self", ".", "_network", ".", "_hop_length", "\n", "time_length", "=", "z_length", "*", "hop_length", "\n", "\n", "if", "self", ".", "_upsample_encoding", ":", "\n", "            ", "Z", "=", "sess", ".", "run", "(", "self", ".", "z_upsampled", ",", "feed_dict", "=", "{", "self", ".", "z", ":", "Z", "}", ")", "\n", "hop_length", "=", "1", "\n", "\n", "# assume x single channel", "\n", "", "if", "X_0", "is", "None", ":", "\n", "            ", "X_0", "=", "np", ".", "zeros", "(", "[", "bs", ",", "1", ",", "1", "]", ")", "\n", "\n", "# beware here we can input x_t or x_t_qs, maybe x_t_qs ia better but we should test this", "\n", "# inputs_node = self.x_t", "\n", "", "if", "input_qs", ":", "\n", "            ", "inputs_node", "=", "self", ".", "x_t_qs", "\n", "", "else", ":", "\n", "            ", "inputs_node", "=", "self", ".", "x_t", "\n", "\n", "# initialize the fast generation queues with all 0s, x_t is needed for the batch_size", "\n", "", "sess", ".", "run", "(", "self", ".", "queues_init_ops", ",", "feed_dict", "=", "{", "\n", "inputs_node", ":", "X_0", "}", ")", "\n", "\n", "audio_batch", "=", "np", ".", "zeros", "(", "(", "bs", ",", "time_length", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "x", "=", "X_0", "\n", "\n", "reconstr_loss_per_sample", "=", "np", ".", "zeros", "(", "(", "bs", ",", "time_length", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "for", "t", "in", "range", "(", "time_length", ")", ":", "\n", "            ", "i_z", "=", "t", "//", "hop_length", "\n", "\n", "x", ",", "reconstr_loss_t", "=", "sess", ".", "run", "(", "[", "self", ".", "x_tp1", ",", "self", ".", "reconstr_loss_t", ",", "self", ".", "queues_push_ops", "]", ",", "\n", "feed_dict", "=", "{", "\n", "inputs_node", ":", "x", ",", "\n", "self", ".", "z_t", ":", "Z", "[", ":", ",", "i_z", ":", "i_z", "+", "1", ",", ":", "]", ",", "\n", "self", ".", "x_target_t", ":", "x_target_quantized", "[", ":", ",", "t", ":", "t", "+", "1", "]", "\n", "}", "\n", ")", "[", "0", ":", "2", "]", "\n", "audio_batch", "[", ":", ",", "t", ",", "0", "]", "=", "x", "[", ":", ",", "0", ",", "0", "]", "\n", "reconstr_loss_per_sample", "[", ":", ",", "t", "]", "=", "reconstr_loss_t", "\n", "\n", "if", "t", "%", "1000", "==", "0", ":", "\n", "                ", "tf_logging", ".", "info", "(", "\"Sample: %d\"", "%", "t", ")", "\n", "", "", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"decoding time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "# NB(Riccardo) I dequeue all the elements from the queues, otherwise next call to queues_init_ops will hang indefinitely", "\n", "# for faster dequeuing the batch size should be fixed, to be able to use q.dequeue_many(qsize)", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "all_sizes", "=", "empty_all_queues", "(", "sess", ",", "self", ".", "queues_size", ",", "self", ".", "queues_dequeue", ")", "\n", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"dequeuing time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "# naive dequeuing (slow)", "\n", "# all_sizes = []", "\n", "# for qs, qd in zip(:", "\n", "#     qsize = sess.run(dq[\"size\"])", "\n", "#     all_sizes.append(dq[\"size\"])", "\n", "#     for i in range(qsize):", "\n", "#         sess.run(dq[\"dequeue\"])", "\n", "\n", "assert", "all", "(", "all_sizes", "==", "0", ")", ",", "\"queues not succefully emptied after decoding\"", "\n", "\n", "return", "audio_batch", ",", "np", ".", "sum", "(", "reconstr_loss_per_sample", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.mean_reconstr_loss": [[453, 466], ["numpy.apply_over_axes", "numpy.squeeze", "numpy.mean", "list", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "mean_reconstr_loss", "(", "self", ",", "log_probs", ")", ":", "\n", "        ", "'''This method is used in WavGenerateHook in order to be able to compute the loss separately for hs, zs train\n            and validation. This is because we decode all of the above samples at once to reduce time\n        '''", "\n", "# now (ready for arbitrary intermediate samplings)", "\n", "all_axis_but_first", "=", "list", "(", "range", "(", "len", "(", "log_probs", ".", "shape", ")", ")", ")", "[", "1", ":", "]", "# [1]", "\n", "# independent p for each input pixel", "\n", "log_p", "=", "np", ".", "apply_over_axes", "(", "np", ".", "sum", ",", "log_probs", ",", "axes", "=", "all_axis_but_first", ")", "# 4", "\n", "log_p", "=", "np", ".", "squeeze", "(", "log_p", ")", "\n", "# average over all the samples and the batch (they are both stacked on the axis 0)", "\n", "mean_reconstr_loss", "=", "np", ".", "mean", "(", "log_p", ",", "axis", "=", "0", ")", "\n", "\n", "return", "mean_reconstr_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.decode_debug_astf": [[467, 517], ["sess.run", "numpy.zeros", "numpy.zeros", "time.time", "range", "time.time", "tf_logging.info", "time.time", "wavenet.utils.empty_all_queues", "time.time", "tf_logging.info", "all", "WavenetVAE.WavenetVAE.get_raw_session", "WavenetVAE.WavenetVAE.mean_reconstr_loss", "sess.run", "tf_logging.info", "str", "str().zfill", "str", "str().zfill", "int", "int", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.empty_all_queues", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.mean_reconstr_loss", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "decode_debug_astf", "(", "self", ",", "Z", ",", "X_shifted", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data for wavenet autoregressive model,\n        test of the fast generation to see if it is equal to the tf. It should be.\"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "bs", ",", "z_length", ",", "z_ch", "=", "Z", ".", "shape", "\n", "hop_length", "=", "self", ".", "_network", ".", "_hop_length", "\n", "time_length", "=", "z_length", "*", "hop_length", "\n", "\n", "assert", "X_shifted", ".", "shape", "==", "(", "bs", ",", "time_length", ",", "1", ")", "\n", "\n", "# initialize the fast generation queues with all 0s, x_t is needed for the batch_size", "\n", "sess", ".", "run", "(", "self", ".", "queues_init_ops", ",", "feed_dict", "=", "{", "\n", "self", ".", "x_t_qs", ":", "X_shifted", "[", ":", ",", ":", "1", ",", ":", "]", "}", ")", "\n", "\n", "audio_batch", "=", "np", ".", "zeros", "(", "(", "bs", ",", "time_length", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "log_probs", "=", "np", ".", "zeros", "(", "(", "bs", ",", "time_length", ")", ")", "\n", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "for", "t", "in", "range", "(", "time_length", ")", ":", "\n", "            ", "i_z", "=", "t", "//", "hop_length", "\n", "x", ",", "log_prob_t", "=", "sess", ".", "run", "(", "[", "self", ".", "x_tp1", ",", "self", ".", "reconstr_loss_t", ",", "self", ".", "queues_push_ops", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "x_t_qs", ":", "X_shifted", "[", ":", ",", "t", ":", "t", "+", "1", ",", ":", "]", ",", "\n", "self", ".", "z_t", ":", "Z", "[", ":", ",", "i_z", ":", "i_z", "+", "1", ",", ":", "]", "\n", "# self.x_target_t: x_target_", "\n", "}", "\n", ")", "[", "0", ":", "2", "]", "\n", "audio_batch", "[", ":", ",", "t", ",", "0", "]", "=", "x", "[", ":", ",", "0", ",", "0", "]", "\n", "log_probs", "[", ":", ",", "t", ":", "t", "+", "1", "]", "=", "log_prob_t", "\n", "if", "t", "%", "1000", "==", "0", ":", "\n", "                ", "tf_logging", ".", "info", "(", "\"Sample: %d\"", "%", "t", ")", "\n", "", "", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"decoding time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "# NB(Riccardo) I dequeue all the elements from the queues, otherwise next call to queues_init_ops will hang indefinitely", "\n", "# for faster dequeuing the batch size should be fixed, to be able to use q.dequeue_many(qsize)", "\n", "\n", "# smart dequeuing contemporaneously on all queues till I can", "\n", "before", "=", "time", ".", "time", "(", ")", "\n", "all_sizes", "=", "empty_all_queues", "(", "sess", ",", "self", ".", "queues_size", ",", "self", ".", "queues_dequeue", ")", "\n", "after", "=", "time", ".", "time", "(", ")", "\n", "diff", "=", "after", "-", "before", "\n", "tf_logging", ".", "info", "(", "\"dequeuing time is %s:%s\"", "%", "(", "str", "(", "int", "(", "diff", "//", "60", ")", ")", ",", "str", "(", "diff", "%", "60", ")", ".", "zfill", "(", "2", ")", ")", ")", "\n", "\n", "assert", "all", "(", "all_sizes", "==", "0", ")", ",", "\"queues not succefully emptied after decoding\"", "\n", "\n", "return", "audio_batch", ",", "self", ".", "mean_reconstr_loss", "(", "log_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.reconstruct": [[518, 527], ["WavenetVAE.WavenetVAE.encode", "WavenetVAE.WavenetVAE.decode", "WavenetVAE.WavenetVAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "reconstruct", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use AE to reconstruct given data.\n        With teacher forcing.\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "Z", ",", "_", "=", "self", ".", "encode", "(", "X", ",", "sess", "=", "sess", ")", "\n", "\n", "return", "self", ".", "decode", "(", "Z", ",", "sess", "=", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetVAE.WavenetVAE.generate": [[528, 530], ["None"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "batch_size", "=", "1", ",", "sess", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAENetwork.WavenetAENetwork.create_id": [[41, 59], ["super().create_id", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "        ", "opts", "=", "self", ".", "_opts", "\n", "_id", "=", "'-st'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"num_layers_per_stage\"", "]", ")", "\n", "_id", "+=", "'-l'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"num_layers\"", "]", ")", "\n", "_id", "+=", "'-fl'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"filter_length\"", "]", ")", "\n", "_id", "+=", "'-hc'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"d_hidden_channels\"", "]", ")", "\n", "_id", "+=", "'-hl'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"hop_length\"", "]", ")", "\n", "_id", "+=", "'-oc'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"e_hidden_channels\"", "]", ")", "\n", "_id", "+=", "'-sc'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"skip_channels\"", "]", ")", "\n", "_id", "+=", "'-lc'", "+", "str", "(", "opts", "[", "\"network_architecture\"", "]", "[", "\"latent_channels\"", "]", ")", "\n", "_id", "+=", "'-dr_'", "+", "opts", "[", "'network_architecture'", "]", "[", "'dim_reduction'", "]", "\n", "_id", "+=", "'-dp'", "+", "str", "(", "opts", "[", "'network_architecture'", "]", "[", "'p_dropout_decoder_tf'", "]", ")", "\n", "_id", "+=", "'-up'", "+", "str", "(", "int", "(", "opts", "[", "'network_architecture'", "]", "[", "'upsample_encoding'", "]", ")", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAENetwork.WavenetAENetwork.__init__": [[60, 81], ["argo.core.network.ArgoAbstractNetwork.ArgoAbstractNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", "=", "\"wavenet_ae_network\"", ")", ":", "\n", "        ", "\"\"\"Short summary.\n\n        Args:\n            opts (dict): parameters of the task.\n            name (str): name of the Sonnet module.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "opts", "[", "\"seed\"", "]", ")", "\n", "network_architecture", "=", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "\n", "\n", "self", ".", "_num_layers_per_stage", "=", "network_architecture", "[", "\"num_layers_per_stage\"", "]", "\n", "self", ".", "_num_layers", "=", "network_architecture", "[", "\"num_layers\"", "]", "\n", "self", ".", "_filter_length", "=", "network_architecture", "[", "\"filter_length\"", "]", "# n_channels of h", "\n", "self", ".", "_d_hidden_channels", "=", "network_architecture", "[", "\"d_hidden_channels\"", "]", "# n_channels of z", "\n", "self", ".", "_hop_length", "=", "network_architecture", "[", "\"hop_length\"", "]", "# n_channels of z", "\n", "self", ".", "_e_hidden_channels", "=", "network_architecture", "[", "\"e_hidden_channels\"", "]", "# n_samples", "\n", "self", ".", "_skip_channels", "=", "network_architecture", "[", "\"skip_channels\"", "]", "# n_samples", "\n", "self", ".", "_latent_channels", "=", "network_architecture", "[", "\"latent_channels\"", "]", "# n_samples", "\n", "self", ".", "_dim_reduction", "=", "network_architecture", "[", "'dim_reduction'", "]", "# type of dimensionality reduction to use", "\n", "self", ".", "_prob_dropout_decoder_tf", "=", "network_architecture", "[", "'p_dropout_decoder_tf'", "]", "# prob to dropout inputs from decoder with tf", "\n", "self", ".", "_upsample_encoding", "=", "network_architecture", "[", "'upsample_encoding'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAENetwork.WavenetAENetwork._build": [[83, 180], ["wavenet.AlmostWavenetEncoder.AlmostWavenetEncoder", "wavenet.WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing", "wavenet.FastWavenetDecoder.FastWavenetDecoder", "WavenetAENetwork.WavenetAENetwork._encoder", "WavenetAENetwork.WavenetAENetwork.reduce_dimension_layer", "tensorflow.layers.Dense", "tensorflow.transpose", "tensorflow.expand_dims", "WavenetAENetwork.WavenetAENetwork.linear_upsample_layer", "tensorflow.reshape", "wavenet.utils.shift_right", "WavenetAENetwork.WavenetAENetwork._decoder_teacherforcing", "tensorflow.placeholder", "tensorflow.placeholder", "WavenetAENetwork.WavenetAENetwork._decoder", "tensorflow.variable_scope", "wavenet.utils.mu_law", "tensorflow.variable_scope", "wavenet.utils.mu_law", "tensorflow.cast", "tensorflow.cast", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAENetwork.WavenetAENetwork.reduce_dimension_layer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.shift_right", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.mu_law", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.mu_law"], ["", "def", "_build", "(", "self", ",", "x", ",", "network_str", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (tf.tensor): input node.\n            network_str (str): Optional network_str specifying the network we are going to build.\n                            It is used to set some specific collections for activity and contractive regularizers.\n\n        Returns:\n            tf distribution on the visible neurons\n            tf distribution of the latent space\n\n        \"\"\"", "\n", "\n", "self", ".", "_encoder", "=", "AlmostWavenetEncoder", "(", "self", ".", "_num_layers_per_stage", ",", "\n", "self", ".", "_num_layers", ",", "\n", "self", ".", "_filter_length", ",", "\n", "self", ".", "_hop_length", ",", "\n", "self", ".", "_e_hidden_channels", ",", "\n", "self", ".", "_latent_channels", ",", "\n", "name", "=", "'enc'", ")", "\n", "\n", "self", ".", "_decoder_teacherforcing", "=", "WavenetDecoderTeacherForcing", "(", "self", ".", "_num_layers_per_stage", ",", "\n", "self", ".", "_num_layers", ",", "\n", "self", ".", "_filter_length", ",", "\n", "self", ".", "_d_hidden_channels", ",", "\n", "self", ".", "_skip_channels", ",", "\n", "self", ".", "_prob_dropout_decoder_tf", ",", "\n", "name", "=", "'dec_tf'", ")", "\n", "\n", "self", ".", "_decoder", "=", "FastWavenetDecoder", "(", "self", ".", "_num_layers_per_stage", ",", "\n", "self", ".", "_num_layers", ",", "\n", "self", ".", "_filter_length", ",", "\n", "self", ".", "_d_hidden_channels", ",", "\n", "self", ".", "_skip_channels", ",", "\n", "self", ".", "_latent_channels", ",", "\n", "variable_scope", "=", "self", ".", "_decoder_teacherforcing", ".", "scope_name", ",", "\n", "name", "=", "'dec'", ")", "\n", "\n", "# Encode the source with 8-bit Mu-Law.", "\n", "# mu_law takes input [-1, 1] and encodes in mu(=256) discrete values", "\n", "# preprocessing output x_quant_scaled, is quantized between -1 and 1", "\n", "with", "tf", ".", "variable_scope", "(", "\"quantize\"", ")", ":", "\n", "            ", "self", ".", "x_quantized", "=", "mu_law", "(", "x", ")", "\n", "# x_quant_scaled is quantized in [-1, 1]", "\n", "self", ".", "x_quant_scaled", "=", "tf", ".", "cast", "(", "self", ".", "x_quantized", ",", "tf", ".", "float32", ")", "/", "128.0", "\n", "\n", "", "self", ".", "en", "=", "self", ".", "_encoder", "(", "self", ".", "x_quant_scaled", ")", "\n", "\n", "# self.z = pool1d(self.en, self._hop_length, name='ae_pool', mode='avg')", "\n", "self", ".", "z", "=", "self", ".", "reduce_dimension_layer", "(", "self", ".", "en", ")", "\n", "\n", "self", ".", "linear_upsample_layer", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "self", ".", "_hop_length", ")", "\n", "z_transpose", "=", "tf", ".", "transpose", "(", "self", ".", "z", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "# (bs, ch, time/hoplen)", "\n", "z_transpose", "=", "tf", ".", "expand_dims", "(", "z_transpose", ",", "axis", "=", "-", "1", ")", "\n", "z_upsampled", "=", "self", ".", "linear_upsample_layer", "(", "z_transpose", ")", "# (bs, ch, time/hoplen, hoplen)", "\n", "self", ".", "z_upsampled", "=", "tf", ".", "reshape", "(", "z_upsampled", ",", "[", "tf", ".", "shape", "(", "z_upsampled", ")", "[", "0", "]", ",", "-", "1", ",", "self", ".", "_latent_channels", "]", ")", "\n", "\n", "self", ".", "x_shifted_qs", "=", "shift_right", "(", "self", ".", "x_quant_scaled", ")", "# loose the last x, and pad at the beginning with a 0", "\n", "\n", "z", "=", "self", ".", "z_upsampled", "if", "self", ".", "_upsample_encoding", "else", "self", ".", "z", "\n", "self", ".", "x_reconstruction_distr_tf", ",", "self", ".", "x_reconstruction_node_tf", "=", "self", ".", "_decoder_teacherforcing", "(", "self", ".", "x_shifted_qs", ",", "z", ")", "\n", "\n", "# assume 1 channel audio", "\n", "self", ".", "x_t", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", ",", "1", "]", ",", "name", "=", "\"x_t\"", ")", "\n", "\n", "# Encode the source with 8-bit Mu-Law.", "\n", "# mu_law takes input [-1, 1] and encodes in mu(=256) discrete values", "\n", "# preprocessing output x_t_quant_scaled, is quantized between -1 and 1", "\n", "with", "tf", ".", "variable_scope", "(", "\"quantize_t\"", ")", ":", "\n", "            ", "self", ".", "x_t_quantized", "=", "mu_law", "(", "self", ".", "x_t", ")", "\n", "# x_t_quant_scaled is quantized in [-1, 1]", "\n", "self", ".", "x_t_quant_scaled", "=", "tf", ".", "cast", "(", "self", ".", "x_t_quantized", ",", "tf", ".", "float32", ")", "/", "128.0", "\n", "\n", "", "self", ".", "z_t", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", ",", "self", ".", "_latent_channels", "]", ",", "name", "=", "\"z_t\"", ")", "\n", "\n", "self", ".", "x_tp1_distr", ",", "self", ".", "x_tp1", ",", "queues_dicts", "=", "self", ".", "_decoder", "(", "self", ".", "x_t_quant_scaled", ",", "self", ".", "z_t", ")", "\n", "\n", "self", ".", "queues_init_ops", "=", "[", "qd", "[", "\"init\"", "]", "for", "qd", "in", "queues_dicts", "]", "\n", "self", ".", "queues_push_ops", "=", "[", "qd", "[", "\"push\"", "]", "for", "qd", "in", "queues_dicts", "]", "\n", "\n", "self", ".", "queues_dicts", "=", "queues_dicts", "\n", "\n", "return", "{", "\n", "\"x_shifted_qs\"", ":", "self", ".", "x_shifted_qs", ",", "\n", "\"z\"", ":", "self", ".", "z", ",", "\n", "\"z_upsampled\"", ":", "self", ".", "z_upsampled", ",", "\n", "\"upsample_encoding\"", ":", "self", ".", "_upsample_encoding", ",", "\n", "\"x_rec_distr_tf\"", ":", "self", ".", "x_reconstruction_distr_tf", ",", "\n", "\"x_rec_tf\"", ":", "self", ".", "x_reconstruction_node_tf", ",", "\n", "\"x_t\"", ":", "self", ".", "x_t", ",", "\n", "\"x_t_qs\"", ":", "self", ".", "x_t_quant_scaled", ",", "\n", "\"z_t\"", ":", "self", ".", "z_t", ",", "\n", "\"x_tp1_distr\"", ":", "self", ".", "x_tp1_distr", ",", "\n", "\"x_tp1\"", ":", "self", ".", "x_tp1", ",", "\n", "\"queues_init_ops\"", ":", "self", ".", "queues_init_ops", ",", "\n", "\"queues_push_ops\"", ":", "self", ".", "queues_push_ops", ",", "\n", "\"queues_dicts\"", ":", "self", ".", "queues_dicts", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavenetAENetwork.WavenetAENetwork.reduce_dimension_layer": [[182, 222], ["wavenet.utils.pool1d", "wavenet.utils.pool1d", "tensorflow.layers.Conv1D", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.squeeze", "tensorflow.transpose", "ValueError", "tensorflow.layers.Dense", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.pool1d", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.pool1d"], ["", "def", "reduce_dimension_layer", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "'''\n        reduces the inputs based on the self._dim_reduction constant\n        Args:\n            inputs (tf.Tensor): inputs of shape (batch_size, signal_length, latent_channels)\n\n        Returns:\n            tf.Tensor: reduced inputs based on self._hop_length\n                       with shape (batch_size, signal_length // self._hop_length, latent_channels)\n        '''", "\n", "if", "self", ".", "_dim_reduction", "==", "DIM_REDUCTION_MAX_POOL", ":", "\n", "            ", "reduced", "=", "pool1d", "(", "inputs", ",", "self", ".", "_hop_length", ",", "name", "=", "'ae_pool'", ",", "mode", "=", "'max'", ")", "\n", "\n", "", "elif", "self", ".", "_dim_reduction", "==", "DIM_REDUCTION_AVG_POOL", ":", "\n", "            ", "reduced", "=", "pool1d", "(", "inputs", ",", "self", ".", "_hop_length", ",", "name", "=", "'ae_pool'", ",", "mode", "=", "'avg'", ")", "\n", "\n", "", "elif", "self", ".", "_dim_reduction", "==", "DIM_REDUCTION_CONV", ":", "\n", "            ", "reduced", "=", "tf", ".", "layers", ".", "Conv1D", "(", "filters", "=", "self", ".", "_latent_channels", ",", "\n", "kernel_size", "=", "self", ".", "_hop_length", ",", "\n", "strides", "=", "self", ".", "_hop_length", ",", "\n", "padding", "=", "'same'", ")", "(", "inputs", ")", "\n", "\n", "", "elif", "self", ".", "_dim_reduction", "==", "DIM_REDUCTION_LINEAR", ":", "\n", "# because Dense can only be applied on last dimension we have to change the order of dimensions", "\n", "            ", "reduced", "=", "tf", ".", "transpose", "(", "inputs", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "# only transposing dimensions won;t help because None shape dimensions so we have to reshape", "\n", "# (bs, channels, signal//hop_len, hop_length) and apply linear layer of 1 unit to get", "\n", "# -> (bs, channels, signal//hop_len, 1) kudos @Csongor", "\n", "reduced_reshaped", "=", "tf", ".", "reshape", "(", "reduced", ",", "[", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", ",", "inputs", ".", "shape", "[", "-", "1", "]", ",", "-", "1", ",", "self", ".", "_hop_length", "]", ")", "\n", "reduced", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "1", ")", "(", "reduced_reshaped", ")", "\n", "reduced", "=", "tf", ".", "squeeze", "(", "reduced", ",", "axis", "=", "-", "1", ")", "\n", "reduced", "=", "tf", ".", "transpose", "(", "reduced", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Can\\'t recognize type of dimensionality reduction method: \\'{}\\' '", "\n", "'(change network architecture -> dim_reduction: <max_pool | avg_pool | conv | linear>'", "\n", ".", "format", "(", "self", ".", "_dim_reduction", ")", "\n", ")", "\n", "\n", "", "return", "reduced", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PCALatentVariablesHook.PCALatentVariablesHook.__init__": [[33, 83], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "tensors", ",", "\n", "tensors_names", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "create_heatmap", "=", "0", ",", "\n", "plot_offset", "=", "0", ")", ":", "\n", "\n", "        ", "dirName", "=", "dirName", "+", "'/pca_latent'", "\n", "# fileName should be set before calling super()", "\n", "#self._fileName = \"PCA latent -\" + self.network_name + \"-num_images-\" + str(n_images)", "\n", "#self._fileHeader = '# frechet_inception_distance, network = ' + self.network_name + ', num images = ' + str(n_images) + '\\n'", "\n", "#self._fileHeader += '# period \\t fid_train \\t fid_validation \\t time_sec'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "datasets_keys", ",", "\n", "dirName", "=", "dirName", ",", "\n", "plot_offset", "=", "plot_offset", ")", "\n", "\n", "self", ".", "_handle", "=", "model", ".", "ds_handle", "\n", "self", ".", "_ds_initializers", "=", "model", ".", "datasets_initializers", "\n", "self", ".", "_ds_handles_nodes", "=", "model", ".", "datasets_handles_nodes", "\n", "\n", "#sself._period = period", "\n", "\n", "self", ".", "_tensors", "=", "tensors", "\n", "self", ".", "_tensors_names", "=", "tensors_names", "\n", "self", ".", "_create_heatmap", "=", "create_heatmap", "==", "1", "\n", "\n", "#images = {ds_key : (index_list, model.dataset.get_elements(index_list, ds_key)) \\", "\n", "#                    for (ds_key, index_list) in images_indexes.items()}", "\n", "\n", "#check_dataset_keys_not_loop(list(images.keys()))", "\n", "\n", "#self._images = images", "\n", "#self._datasets_keys = datasets_keys", "\n", "#check_dataset_keys_not_loop(datasets_keys)", "\n", "\n", "self", ".", "_hook_name", "=", "\"pca_latent_variables_hook\"", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create PCALatentVariablesHook for: \"", "+", "\", \"", ".", "join", "(", "datasets_keys", ")", ")", "\n", "\n", "# with an abuse of notation, we use this as a dictionary instead of the list of lists of lists", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "self", ".", "_tensors_values", "[", "\"sigma\"", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PCALatentVariablesHook.PCALatentVariablesHook._begin_once": [[87, 122], ["zip", "argo.core.utils.argo_utils.create_concat_opts", "argo.core.utils.argo_utils.tf_cov_times_n_points", "tensorflow.svd", "tensor.shape.as_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_concat_opts", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_cov_times_n_points"], ["", "def", "_begin_once", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "concat_ops", "=", "{", "}", "\n", "self", ".", "concat_update_ops", "=", "{", "}", "\n", "self", ".", "concat_reset_ops", "=", "{", "}", "\n", "self", ".", "sigma", "=", "{", "}", "\n", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "\n", "            ", "self", ".", "concat_ops", "[", "ds_key", "]", "=", "{", "}", "\n", "self", ".", "concat_update_ops", "[", "ds_key", "]", "=", "{", "}", "\n", "self", ".", "concat_reset_ops", "[", "ds_key", "]", "=", "{", "}", "\n", "self", ".", "sigma", "[", "ds_key", "]", "=", "{", "}", "\n", "\n", "# every hook needs to have its own accumulator to not have problem of erasing memory that other hooks still needs", "\n", "# maybe memory occupation could be improved if really needed, but great troubles for concurrency in parallel execution", "\n", "scope", "=", "self", ".", "_hook_name", "+", "\"/\"", "+", "ds_key", "+", "\"_concat_metric/\"", "\n", "\n", "#with tf.variable_scope(scope) as scope:", "\n", "\n", "for", "(", "tensor", ",", "tensor_name", ")", "in", "zip", "(", "self", ".", "_tensors", ",", "self", ".", "_tensors_names", ")", ":", "\n", "\n", "                ", "dim", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "self", ".", "concat_ops", "[", "ds_key", "]", "[", "tensor_name", "]", ",", "self", ".", "concat_update_ops", "[", "ds_key", "]", "[", "tensor_name", "]", ",", "self", ".", "concat_reset_ops", "[", "ds_key", "]", "[", "tensor_name", "]", "=", "create_concat_opts", "(", "scope", "+", "tensor_name", ",", "tensor", ")", "\n", "\n", "# see https://tomaxent.com/2018/01/17/PCA-With-Tensorflow/", "\n", "# I need to reshape, since the shape is [0,dim]", "\n", "covariance", "=", "tf_cov_times_n_points", "(", "tf", ".", "reshape", "(", "self", ".", "concat_ops", "[", "ds_key", "]", "[", "tensor_name", "]", ",", "[", "-", "1", ",", "dim", "]", ")", ")", "\n", "\n", "# see https://stats.stackexchange.com/questions/314046/why-does-andrew-ng-prefer-to-use-svd-and-not-eig-of-covariance-matrix-to-do-pca", "\n", "singular_values", ",", "u", ",", "_", "=", "tf", ".", "svd", "(", "covariance", ")", "\n", "self", ".", "sigma", "[", "ds_key", "]", "[", "tensor_name", "]", "=", "singular_values", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PCALatentVariablesHook.PCALatentVariablesHook.after_create_session": [[133, 135], ["super().after_create_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session"], ["", "", "", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PCALatentVariablesHook.PCALatentVariablesHook.do_when_triggered": [[136, 181], ["tf_logging.info", "enumerate", "session.run", "session.run", "dict", "session.run", "dict", "zip", "zip", "len", "numpy.hstack", "numpy.savetxt", "session.run", "PCALatentVariablesHook.PCALatentVariablesHook.sigma[].keys", "PCALatentVariablesHook.PCALatentVariablesHook.concat_ops[].keys", "str().zfill", "PCALatentVariablesHook.PCALatentVariablesHook.sigma[].values", "PCALatentVariablesHook.PCALatentVariablesHook.concat_ops[].values", "PCALatentVariablesHook.PCALatentVariablesHook.concat_reset_ops[].values", "str", "PCALatentVariablesHook.PCALatentVariablesHook.concat_update_ops[].values", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "#tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for PCALatentVariablesHook\"", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "concat_ops", "=", "{", "}", "\n", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "#images = self._images[ds_key][1]", "\n", "\n", "            ", "session", "=", "run_context", ".", "session", "\n", "dataset_initializer", "=", "self", ".", "_ds_initializers", "[", "ds_key", "]", "\n", "\n", "#for tensor_name in self._tensors_names:", "\n", "session", ".", "run", "(", "[", "dataset_initializer", "]", "+", "[", "*", "self", ".", "concat_reset_ops", "[", "ds_key", "]", ".", "values", "(", ")", "]", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "session", ".", "run", "(", "[", "*", "self", ".", "concat_update_ops", "[", "ds_key", "]", ".", "values", "(", ")", "]", ",", "feed_dict", "=", "{", "self", ".", "_handle", ":", "self", ".", "_ds_handles", "[", "ds_key", "]", "}", ")", "# **feed_dict,", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "\n", "", "", "returns", "=", "session", ".", "run", "(", "[", "*", "self", ".", "sigma", "[", "ds_key", "]", ".", "values", "(", ")", "]", ")", "\n", "self", ".", "_tensors_values", "[", "\"sigma\"", "]", "[", "ds_key", "]", "=", "dict", "(", "zip", "(", "self", ".", "sigma", "[", "ds_key", "]", ".", "keys", "(", ")", ",", "returns", ")", ")", "\n", "\n", "returns", "=", "session", ".", "run", "(", "[", "*", "self", ".", "concat_ops", "[", "ds_key", "]", ".", "values", "(", ")", "]", ")", "\n", "concat_ops", "[", "ds_key", "]", "=", "dict", "(", "zip", "(", "self", ".", "concat_ops", "[", "ds_key", "]", ".", "keys", "(", ")", ",", "returns", ")", ")", "\n", "\n", "# unfortunately I cannot compute the real covariance matrix in TF,", "\n", "# since I cannot easily know at runtime the number of points.", "\n", "# see the comment in utils.tf_cov_time_n_points (Luigi)", "\n", "# to solve this issue, I get the number of points from the len of the concat_op node", "\n", "for", "tensor_name", "in", "self", ".", "_tensors_names", ":", "\n", "                ", "self", ".", "_tensors_values", "[", "\"sigma\"", "]", "[", "ds_key", "]", "[", "tensor_name", "]", "/=", "len", "(", "concat_ops", "[", "ds_key", "]", "[", "tensor_name", "]", ")", "\n", "\n", "# save to txt file", "\n", "", "", "for", "j", ",", "tensor_name", "in", "enumerate", "(", "self", ".", "_tensors_names", ")", ":", "\n", "            ", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "                ", "sigma", "=", "self", ".", "_tensors_values", "[", "\"sigma\"", "]", "[", "ds_key", "]", "[", "tensor_name", "]", "\n", "\n", "fileName", "=", "\"pca_\"", "+", "tensor_name", "+", "\"_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "+", "\"_\"", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "\n", "# save txt file", "\n", "data", "=", "np", ".", "hstack", "(", "[", "sigma", "]", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "_dirName", "+", "'/'", "+", "fileName", "+", "'.txt'", ",", "data", ",", "fmt", "=", "'%.3f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PCALatentVariablesHook.PCALatentVariablesHook.plot": [[182, 206], ["matplotlib.figure", "matplotlib.figure", "argo.core.utils.argo_utils.create_list_colors", "enumerate", "matplotlib.title", "matplotlib.title", "matplotlib.xlim", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.ylim", "matplotlib.legend", "matplotlib.legend", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.close", "matplotlib.close", "len", "str().zfill", "PCALatentVariablesHook.PCALatentVariablesHook._plot_heatmap", "numpy.linspace", "matplotlib.plot", "matplotlib.plot", "len", "len", "len", "str", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_list_colors", "home.repos.pwc.inspect_result.rist-ro_argo.core.PCALatentVariablesHook.PCALatentVariablesHook._plot_heatmap", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "", "", "def", "plot", "(", "self", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "6", ")", ")", "\n", "\n", "list_colors", "=", "create_list_colors", "(", "len", "(", "self", ".", "_tensors_names", ")", ")", "\n", "for", "j", ",", "tensor_name", "in", "enumerate", "(", "self", ".", "_tensors_names", ")", ":", "\n", "            ", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "                ", "sigma", "=", "self", ".", "_tensors_values", "[", "\"sigma\"", "]", "[", "ds_key", "]", "[", "tensor_name", "]", "\n", "eigenvals_idx", "=", "np", ".", "linspace", "(", "0", ",", "len", "(", "sigma", ")", ",", "len", "(", "sigma", ")", ")", "\n", "\n", "plt", ".", "plot", "(", "eigenvals_idx", ",", "sigma", ",", "linestyle_dataset", "[", "ds_key", "]", ",", "c", "=", "list_colors", "[", "j", "%", "len", "(", "list_colors", ")", "]", ",", "label", "=", "tensor_name", "+", "\" \"", "+", "ds_key", ")", "\n", "\n", "", "", "plt", ".", "title", "(", "self", ".", "_plot_title", ",", "fontsize", "=", "9", ",", "loc", "=", "'center'", ")", "\n", "plt", ".", "xlim", "(", "1", ",", "len", "(", "sigma", ")", "-", "1", ")", "\n", "plt", ".", "ylim", "(", "bottom", "=", "0", ")", "\n", "#plt.xticks(np.arange(1,len(sigma)+1))", "\n", "plt", ".", "legend", "(", ")", "\n", "\n", "fileName", "=", "\"pca_\"", "+", "self", ".", "_time_reference_str", "+", "\"_\"", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "\n", "plt", ".", "savefig", "(", "self", ".", "_dirName", "+", "'/'", "+", "fileName", "+", "'.png'", ")", "# , bbox_inches='tight'", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "if", "self", ".", "_create_heatmap", ":", "\n", "            ", "self", ".", "_plot_heatmap", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PCALatentVariablesHook.PCALatentVariablesHook._plot_heatmap": [[207, 231], ["sorted", "numpy.max", "seaborn.heatmap", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.close", "matplotlib.close", "glob.glob", "numpy.loadtxt", "eigenvals_all_epochs.append", "numpy.reshape", "numpy.arange", "len", "t.split", "len", "str", "str"], "methods", ["None"], ["", "", "def", "_plot_heatmap", "(", "self", ")", ":", "\n", "        ", "for", "tensor_name", "in", "self", ".", "_tensors_names", ":", "\n", "            ", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "                ", "filenames", "=", "sorted", "(", "glob", ".", "glob", "(", "\n", "self", ".", "_dirName", "+", "\"/pca_\"", "+", "tensor_name", "+", "\"_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "+", "\"_*.txt\"", ")", ")", "\n", "recorded_steps", "=", "[", "t", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "for", "t", "in", "filenames", "]", "\n", "\n", "eigenvals_all_epochs", "=", "[", "]", "\n", "for", "filename", "in", "filenames", ":", "\n", "                    ", "eigenvals", "=", "np", ".", "loadtxt", "(", "filename", ")", "\n", "eigenvals_all_epochs", ".", "append", "(", "eigenvals", ")", "\n", "\n", "", "eigenvals_all_epochs", "=", "np", ".", "reshape", "(", "eigenvals_all_epochs", ",", "[", "len", "(", "eigenvals_all_epochs", ")", ",", "-", "1", "]", ")", ".", "T", "\n", "# normalize the eigenvalues", "\n", "eigenvals_all_epochs", "/=", "np", ".", "max", "(", "eigenvals_all_epochs", ",", "axis", "=", "0", ")", "\n", "\n", "ax", "=", "sns", ".", "heatmap", "(", "eigenvals_all_epochs", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ",", "cmap", "=", "'Blues'", ")", "\n", "plt", ".", "xlabel", "(", "'Time period'", ")", "\n", "plt", ".", "ylabel", "(", "'Eigenvalues'", ")", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "len", "(", "recorded_steps", ")", ")", ",", "recorded_steps", ")", "\n", "\n", "heatmap_name", "=", "\"heatmap_\"", "+", "tensor_name", "+", "\"_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "+", "\"_\"", "+", "recorded_steps", "[", "-", "1", "]", "\n", "plt", ".", "savefig", "(", "self", ".", "_dirName", "+", "'/'", "+", "heatmap_name", "+", "'.png'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropy.CrossEntropy.__init__": [[9, 12], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "multiclass_metrics", "=", "False", ",", "name", "=", "\"CrossEntropy\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_multiclass_metrics", "=", "multiclass_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropy.CrossEntropy.create_id": [[13, 17], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "        ", "_id", "=", "\"CE\"", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.CrossEntropy.CrossEntropy._build": [[18, 127], ["tensorflow.tile", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "argo.core.utils.argo_utils.create_panels_lists", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.one_hot", "tensorflow.one_hot", "argo.core.utils.argo_utils.tf_f1_score", "tensorflow.metrics.auc", "Exception", "tensorflow.cast", "tensorflow.equal", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.cast", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_panels_lists", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_f1_score"], ["", "def", "_build", "(", "self", ",", "model", ",", "drop_one_logit", "=", "False", ")", ":", "\n", "\n", "        ", "y", "=", "model", ".", "y", "\n", "\n", "# if len(y.shape)==1:", "\n", "#     y = tf.expand_dims(y, axis=-1)", "\n", "\n", "kl_losses", "=", "model", ".", "kl_losses", "\n", "total_KL", "=", "tf", ".", "reduce_sum", "(", "kl_losses", ")", "/", "model", ".", "dataset", ".", "n_samples_train", "\n", "\n", "n_samples", "=", "model", ".", "n_samples_ph", "\n", "y_tile", "=", "tf", ".", "tile", "(", "y", ",", "[", "n_samples", "]", ")", "\n", "\n", "logits", "=", "model", ".", "prediction_distr", ".", "logits", "\n", "probs", "=", "model", ".", "prediction_distr", ".", "probs", "\n", "\n", "n_labels", "=", "logits", ".", "shape", "[", "1", "]", "\n", "\n", "loss_per_sample", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "tf", ".", "cast", "(", "y_tile", ",", "tf", ".", "int32", ")", ",", "\n", "logits", "=", "logits", ")", "\n", "\n", "\n", "ce", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ")", "\n", "loss", "=", "ce", "+", "total_KL", "\n", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "y_tile", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "\n", "# First panel will be at screen during training", "\n", "list_of_vpanels_of_plots", "=", "[", "\n", "[", "\n", "# {", "\n", "#     'nodes' : [loss],", "\n", "#     'names': [\"loss\"],", "\n", "#     'output': {'fileName' : \"loss\"}", "\n", "# },", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "ce", "]", ",", "\n", "'names'", ":", "[", "\"ce\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"ce\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "total_KL", "]", ",", "\n", "'names'", ":", "[", "\"kl\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"kl\"", "}", "\n", "}", ",", "\n", "\n", "{", "\n", "'nodes'", ":", "[", "accuracy", "]", ",", "\n", "'names'", ":", "[", "\"accuracy\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"accuracy\"", "}", "\n", "}", ",", "\n", "\n", "]", ",", "\n", "[", "\n", "{", "\n", "'nodes'", ":", "[", "1", "-", "accuracy", "]", ",", "\n", "'names'", ":", "[", "\"error\"", "]", ",", "\n", "'output'", ":", "{", "'fileName'", ":", "\"error\"", ",", "\"logscale-y\"", ":", "1", "}", "\n", "}", ",", "\n", "\n", "]", "\n", "]", "\n", "\n", "\n", "# nodes_to_log = [[ce],", "\n", "#                 [total_KL],", "\n", "#                 [1 - accuracy],", "\n", "#                 [accuracy]]", "\n", "#", "\n", "# nodes_to_log_names = [[\"ce\"], [\"kl\"], [\"error\"], [\"accuracy\"]]", "\n", "# nodes_to_log_filenames = [{\"fileName\": \"ce\"},", "\n", "#                           {\"fileName\": \"kl\"},", "\n", "#                           {\"fileName\": \"error\", \"logscale-y\": 1},", "\n", "#                           {\"fileName\": \"accuracy\"}]", "\n", "\n", "if", "self", ".", "_multiclass_metrics", ":", "\n", "            ", "y_pred", "=", "tf", ".", "one_hot", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "n_labels", ")", "\n", "y_true", "=", "tf", ".", "one_hot", "(", "y_tile", ",", "n_labels", ")", "\n", "f1_micro", ",", "f1_macro", ",", "f1_weighted", "=", "tf_f1_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "auc", ",", "auc_update", "=", "tf", ".", "metrics", ".", "auc", "(", "\n", "labels", "=", "tf", ".", "cast", "(", "y_true", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "# predictions=tf.nn.softmax(logits)", "\n", "predictions", "=", "probs", "\n", ")", "\n", "\n", "raise", "Exception", "(", "\"set panels correctly here first!\"", ")", "\n", "# nodes_to_log += [[auc_update],", "\n", "#                 [f1_micro, f1_macro, f1_weighted]]", "\n", "#", "\n", "# nodes_to_log_names += [[\"auc\"], [\"f1_micro\", \"f1_macro\", \"f1_weighted\"]]", "\n", "# nodes_to_log_filenames += [", "\n", "#                             {\"fileName\": \"auc\"},", "\n", "#                             {\"fileName\": \"f1_score\"}", "\n", "#                             # {\"fileName\": \"f1_micro\"},", "\n", "#                             # {\"fileName\": \"f1_macro\"},", "\n", "#                             # {\"fileName\": \"f1_weighted\"}", "\n", "#                           ]", "\n", "\n", "\n", "\n", "", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "=", "create_panels_lists", "(", "list_of_vpanels_of_plots", ")", "\n", "\n", "return", "loss", ",", "loss_per_sample", ",", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Regularizers.create_id": [[1, 26], ["str", "Exception", "Exception"], "function", ["None"], ["import", "tensorflow", "as", "tf", "\n", "\n", "from", ".", "utils", ".", "argo_utils", "import", "eval_method_from_tuple", "\n", "\n", "import", "importlib", "\n", "\n", "import", "pdb", "\n", "\n", "class", "Regularizers", "(", ")", ":", "\n", "\n", "    ", "@", "staticmethod", "\n", "def", "instantiate_regularizer", "(", "regularizer_tuple", ",", "module_path", "=", "\"\"", ")", ":", "\n", "\n", "        ", "regularizer_name", "=", "regularizer_tuple", "[", "0", "]", "\n", "regularizer_kwargs", "=", "regularizer_tuple", "[", "1", "]", "\n", "\n", "try", ":", "\n", "# first try to load from core", "\n", "#try:", "\n", "            ", "regularizer_module", "=", "importlib", ".", "import_module", "(", "\".regularizers.\"", "+", "regularizer_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "3", "]", ")", ")", "\n", "# it if fails, try to laod from module_path.core", "\n", "#except ImportError:", "\n", "#    regularizer_module = importlib.import_module(module_path + \".core.\" + regularizer_name, '.'.join(__name__.split('.')[:-1]))", "\n", "\n", "custom_regularizer", ",", "_", ",", "_", "=", "eval_method_from_tuple", "(", "regularizer_module", ",", "regularizer_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.__init__": [[15, 31], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dataset_keys", ",", "\n", "crops_per_sample", ",", "\n", "sample_indices_by_dataset", ",", "\n", "num_clusters", "=", "None", ",", "\n", "dirName", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "dataset_keys", ",", "dirName", "=", "dirName", ",", "**", "kwargs", ")", "\n", "self", ".", "_ds_handles_nodes", "=", "model", ".", "datasets_handles_nodes", "\n", "self", ".", "crops_per_sample", "=", "crops_per_sample", "\n", "self", ".", "num_clusters", "=", "num_clusters", "\n", "self", ".", "sample_indices_by_dataset", "=", "sample_indices_by_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.after_create_session": [[32, 64], ["super().after_create_session", "session.run", "range", "numpy.concatenate", "numpy.concatenate", "WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook._model.dataset.get_elements", "x_test_crops.append", "y_test_labels.append", "WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook._model.dataset.get_elements"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements"], ["", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "self", ".", "_ds_handles", "=", "session", ".", "run", "(", "self", ".", "_ds_handles_nodes", ")", "\n", "self", ".", "_samples", "=", "{", "}", "\n", "self", ".", "_labels", "=", "{", "}", "\n", "\n", "for", "ds_key", "in", "self", ".", "sample_indices_by_dataset", ":", "\n", "            ", "x_test_crops", "=", "[", "]", "\n", "y_test_labels", "=", "[", "]", "\n", "for", "crop", "in", "range", "(", "self", ".", "crops_per_sample", ")", ":", "#placeholder", "\n", "                ", "x_test", "=", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "x", ",", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "# value la placeholld", "\n", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "\n", "session", ",", "\n", "None", ")", "# passing None instead of index_list to return all samples", "\n", "# indexing will be made in the hook because I need to", "\n", "# calculate the reconstruction loss for generation", "\n", "x_test_crops", ".", "append", "(", "x_test", ")", "\n", "y_test", "=", "None", "\n", "if", "self", ".", "_model", ".", "y", "is", "not", "None", ":", "\n", "                    ", "y_test", "=", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "y", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "\n", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "\n", "session", ",", "\n", "None", ")", "\n", "\n", "# y_test = np.array([self._model.dataset.int_to_str_label(label) for label in y_test])", "\n", "", "y_test_labels", ".", "append", "(", "y_test", ")", "\n", "\n", "", "self", ".", "_samples", "[", "ds_key", "]", "=", "np", ".", "concatenate", "(", "x_test_crops", ",", "axis", "=", "0", ")", "\n", "self", ".", "_labels", "[", "ds_key", "]", "=", "np", ".", "concatenate", "(", "y_test_labels", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.do_when_triggered": [[66, 107], ["WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook._model.encode", "WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.cluster", "zs.reshape", "sklearn.decomposition.PCA", "sklearn.decomposition.PCA.fit_transform", "matplotlib.figure", "numpy.unique", "matplotlib.legend", "matplotlib.savefig", "sklearn.manifold.TSNE", "sklearn.manifold.TSNE.fit_transform", "matplotlib.figure", "numpy.unique", "matplotlib.legend", "matplotlib.savefig", "len", "numpy.argwhere().flatten", "matplotlib.scatter", "os.path.join", "numpy.argwhere().flatten", "matplotlib.scatter", "os.path.join", "len", "ValueError", "numpy.argwhere", "str", "numpy.argwhere", "str", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.core.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.cluster"], ["", "", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "for", "ds_key", "in", "self", ".", "_samples", ":", "\n", "            ", "labels", "=", "self", ".", "_labels", "[", "ds_key", "]", "\n", "encode_tuple", "=", "self", ".", "_model", ".", "encode", "(", "self", ".", "_samples", "[", "ds_key", "]", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "\n", "if", "len", "(", "encode_tuple", ")", "==", "2", ":", "\n", "                ", "zs", ",", "x_shifted", "=", "encode_tuple", "\n", "hs", "=", "None", "\n", "covariance", "=", "None", "\n", "", "elif", "len", "(", "encode_tuple", ")", "==", "6", ":", "\n", "                ", "zs", ",", "hs", ",", "covariance", ",", "prior_mean", ",", "prior_cov", ",", "x_shifted", "=", "encode_tuple", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"This tuple should not be this length: {}\"", ".", "format", "(", "len", "(", "encode_tuple", ")", ")", ")", "\n", "\n", "", "config", "=", "'{}_{}'", ".", "format", "(", "self", ".", "_samples", "[", "ds_key", "]", ".", "shape", "[", "1", "]", ",", "self", ".", "crops_per_sample", ")", "\n", "\n", "# plain", "\n", "self", ".", "cluster", "(", "zs", ",", "labels", ")", "\n", "\n", "# pca 3d", "\n", "zs_1d", "=", "zs", ".", "reshape", "(", "[", "zs", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "pca", "=", "PCA", "(", "n_components", "=", "2", ")", "\n", "pca_transformed", "=", "pca", ".", "fit_transform", "(", "zs_1d", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "for", "label", "in", "np", ".", "unique", "(", "labels", ")", ":", "\n", "                ", "idx_of_label", "=", "np", ".", "argwhere", "(", "labels", "==", "label", ")", ".", "flatten", "(", ")", "\n", "plt", ".", "scatter", "(", "x", "=", "pca_transformed", "[", "idx_of_label", ",", "0", "]", ",", "y", "=", "pca_transformed", "[", "idx_of_label", ",", "1", "]", ",", "label", "=", "str", "(", "label", ")", ")", "\n", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_dirName", ",", "'anomaly_detection'", ",", "config", "+", "'_pca.png'", ")", ")", "\n", "\n", "# t-SNE 3d", "\n", "tsne", "=", "TSNE", "(", "n_components", "=", "2", ",", "verbose", "=", "1", ",", "n_iter", "=", "5000", ")", "\n", "tsne_transformed", "=", "tsne", ".", "fit_transform", "(", "zs_1d", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "for", "label", "in", "np", ".", "unique", "(", "labels", ")", ":", "\n", "                ", "idx_of_label", "=", "np", ".", "argwhere", "(", "labels", "==", "label", ")", ".", "flatten", "(", ")", "\n", "plt", ".", "scatter", "(", "x", "=", "tsne_transformed", "[", "idx_of_label", ",", "0", "]", ",", "y", "=", "tsne_transformed", "[", "idx_of_label", ",", "1", "]", ",", "label", "=", "str", "(", "label", ")", ")", "\n", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_dirName", ",", "'anomaly_detection'", ",", "config", "+", "'_tsne.png'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.cluster": [[108, 128], ["sklearn.preprocessing.StandardScaler().fit_transform.reshape", "sklearn.preprocessing.StandardScaler().fit_transform", "sklearn.cluster.KMeans", "sklearn.cluster.KMeans.fit_predict", "print", "print", "print", "print", "len", "numpy.unique", "sklearn.metrics.classification_report", "sum", "sklearn.preprocessing.StandardScaler", "numpy.unique", "sklearn.metrics.precision_score"], "methods", ["None"], ["", "", "def", "cluster", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "x", ".", "reshape", "(", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "x", "=", "StandardScaler", "(", ")", ".", "fit_transform", "(", "x", ")", "\n", "\n", "self", ".", "num_clusters", "=", "self", ".", "num_clusters", "or", "len", "(", "np", ".", "unique", "(", "y", ")", ")", "\n", "\n", "kmeans", "=", "KMeans", "(", "n_clusters", "=", "self", ".", "num_clusters", ",", "max_iter", "=", "1000", ")", "\n", "predicted_labels", "=", "kmeans", ".", "fit_predict", "(", "x", ")", "\n", "\n", "\n", "def", "change", "(", "arr", ",", "l1", ",", "l2", ")", ":", "\n", "            ", "arr", "[", "arr", "==", "l1", "]", "=", "3", "\n", "arr", "[", "arr", "==", "l2", "]", "=", "l1", "\n", "arr", "[", "arr", "==", "3", "]", "=", "l2", "\n", "\n", "", "print", "(", "np", ".", "unique", "(", "predicted_labels", ",", "return_counts", "=", "True", ")", ")", "\n", "print", "(", "classification_report", "(", "y", ",", "predicted_labels", ")", ")", "\n", "print", "(", "'Total:'", ",", "sum", "(", "precision_score", "(", "y", ",", "predicted_labels", ",", "average", "=", "None", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.actual_labels": [[130, 144], ["range", "len", "numpy.where", "numpy.bincount().argmax", "numpy.array", "numpy.unique", "map", "numpy.bincount"], "methods", ["None"], ["", "def", "actual_labels", "(", "self", ",", "cluster_labels", ",", "y_actual", ")", ":", "\n", "        ", "'''\n        Associates most probable label with each cluster in KMeans model returns: dictionary of clusters\n        assigned to each label\n        '''", "\n", "# Initializing", "\n", "reference_labels", "=", "{", "}", "\n", "# For loop to run through each label of cluster label", "\n", "for", "i", "in", "range", "(", "len", "(", "np", ".", "unique", "(", "cluster_labels", ")", ")", ")", ":", "\n", "            ", "index", "=", "np", ".", "where", "(", "cluster_labels", "==", "i", ",", "1", ",", "0", ")", "\n", "actual_label", "=", "np", ".", "bincount", "(", "y_actual", "[", "index", "==", "1", "]", ")", ".", "argmax", "(", ")", "\n", "reference_labels", "[", "i", "]", "=", "actual_label", "\n", "\n", "", "return", "reference_labels", ",", "np", ".", "array", "(", "map", "(", "lambda", "x", ":", "reference_labels", "[", "x", "]", ",", "cluster_labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavClusterAnomalyDetectionHook.WavClusterAnomalyDetectionHook.log_result": [[145, 147], ["None"], "methods", ["None"], ["", "def", "log_result", "(", "self", ",", "report", ")", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.L2.L2.__init__": [[8, 10], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"L2\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.L2.L2.create_id": [[11, 14], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "        ", "return", "\"L2\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.L2.L2._build": [[15, 31], ["tensorflow.cast", "tensorflow.norm", "tensorflow.reduce_prod", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.shape"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "ae", ")", ":", "\n", "\n", "        ", "model_visible", "=", "ae", ".", "_model_visible", "\n", "x_target", "=", "ae", ".", "x_target", "\n", "reconstruction", "=", "ae", ".", "x_reconstruction_node", "\n", "\n", "dims", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "ae", ".", "raw_x", ")", "[", "1", ":", "]", ")", ",", "\n", "tf", ".", "float32", ")", "\n", "# x_shape is also a dict alternatively...", "\n", "# dims = np.prod(ae.x_shape[\"train\"])", "\n", "\n", "# computes avg 1/2 * l2**2", "\n", "norms", "=", "tf", ".", "norm", "(", "tf", ".", "reshape", "(", "x_target", "-", "reconstruction", ",", "[", "-", "1", ",", "dims", "]", ")", ",", "axis", "=", "1", ")", "\n", "loss", "=", "1", "/", "2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "norms", ")", ")", "\n", "\n", "return", "loss", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD.__init__": [[8, 25], ["argo.core.network.AbstractModule.AbstractModule.__init__", "tensorflow.placeholder_with_default", "MMD.MMD._check_kernel", "float"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD._check_kernel"], ["    ", "def", "__init__", "(", "self", ",", "mmd_kernel", ",", "beta", "=", "1.0", ",", "warm_up_method", "=", "None", ",", "name", "=", "\"MMD\"", ")", ":", "\n", "        ", "\"\"\"\n        Maximum mean discrepancy-based penalty used in Wasserstein AEs\n        official implementation: https://github.com/tolstikhin/wae\n\n        :param mmd_kernel: string, one of [\"RBF\", \"IMQ\"]; kernel to be used for computing MMD penalty ()\n        :param beta: float; MMD coefficient\n        :param warm_up_method: string, one of None, warm_up, inverse_warm_up\n        :param name: string; a name for the loss\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_warm_up_method", "=", "warm_up_method", "\n", "self", ".", "beta", "=", "tf", ".", "placeholder_with_default", "(", "float", "(", "beta", ")", ",", "shape", "=", "(", ")", ",", "name", "=", "'beta_regularizer'", ")", "\n", "self", ".", "mmd_kernel", "=", "mmd_kernel", "\n", "\n", "self", ".", "_check_kernel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD.create_id": [[26, 31], ["MMD.MMD.create_warm_up_id", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.create_warm_up_id"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "        ", "_id", "=", "\"MMD_b\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"beta\"", "]", ")", "+", "\"_\"", "+", "self", ".", "mmd_kernel", "\n", "_id", "+=", "self", ".", "create_warm_up_id", "(", "cost_fuction_kwargs", ")", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD._check_kernel": [[32, 35], ["ValueError"], "methods", ["None"], ["", "def", "_check_kernel", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mmd_kernel", "not", "in", "[", "'RBF'", ",", "'IMQ'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"mmd_kernel not recognized\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD.create_warm_up_id": [[37, 51], ["str", "ValueError", "str"], "methods", ["None"], ["", "", "def", "create_warm_up_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "if", "\"warm_up_method\"", "not", "in", "cost_fuction_kwargs", "or", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "is", "None", "or", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "0", "]", "is", "None", ":", "\n", "            ", "warm_up", "=", "\"0\"", "\n", "", "elif", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "0", "]", "==", "\"warm_up\"", ":", "\n", "            ", "warm_up", "=", "\"W\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "1", "]", "[", "\"epoch\"", "]", ")", "\n", "", "elif", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "0", "]", "==", "\"inverse_warm_up\"", ":", "\n", "            ", "warm_up", "=", "\"IW\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "1", "]", "[", "\"epoch\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"warm_up_method not recognized\"", ")", "\n", "", "_id", "=", "'_wu'", "+", "warm_up", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD.get_warm_up_coefficient": [[52, 89], ["tensorflow.constant", "tensorflow.cond", "Exception", "ValueError", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "float"], "methods", ["None"], ["", "def", "get_warm_up_coefficient", "(", "self", ",", "warm_up_method", ",", "vae_model", ")", ":", "\n", "# Warm up: gradually introduce the latent loss in the cost function,", "\n", "# as suggested in Ladder VAE paper, and also others", "\n", "#", "\n", "# warm_up_method  None             = no warm up", "\n", "#                \"inverse_warm_up\" = inverse warm up (scale of KL decreases until it becomes 1)", "\n", "#                \"warm_up\"         = warm up (scale of KL increases until it becomes 1)", "\n", "\n", "# initialize the warm_up coefficient to be placed in front of the KL term for ELBO and IELBO", "\n", "        ", "if", "warm_up_method", "is", "None", "or", "warm_up_method", "[", "0", "]", "is", "None", ":", "\n", "            ", "warm_up", "=", "tf", ".", "constant", "(", "1.", ")", "\n", "\n", "", "elif", "warm_up_method", "[", "0", "]", "==", "\"warm_up\"", ":", "\n", "            ", "global_step", "=", "vae_model", ".", "global_step", "\n", "warm_up_final_step", "=", "warm_up_method", "[", "1", "]", "[", "\"epoch\"", "]", "*", "vae_model", ".", "n_batches_per_epoch", "\n", "# increase the KL scale from 0 to 1, over self.warm_up_method[1][\"epoch\"] epochs", "\n", "warm_up", "=", "tf", ".", "cond", "(", "global_step", ">", "warm_up_final_step", ",", "\n", "lambda", ":", "tf", ".", "constant", "(", "1.", ")", ",", "\n", "lambda", ":", "tf", ".", "cast", "(", "global_step", "-", "1", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "\n", "tf", ".", "constant", "(", "warm_up_final_step", "-", "1", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", ")", "\n", "\n", "", "elif", "warm_up_method", "[", "0", "]", "==", "\"inverse_warm_up\"", ":", "\n", "\n", "# TODO-LUIGI what is below needs to be reimplemented", "\n", "            ", "raise", "Exception", "(", "\"what is below needs to be reimplemented\"", ")", "\n", "warm_up_final_step", "=", "warm_up_method", "[", "1", "]", "[", "\"epoch\"", "]", "*", "vae_model", ".", "n_batches_per_epoch", "\n", "\n", "# decrease the KL scale from 10 (epoch 0) to 1 (epoch warm_up_method[1][\"epoch\"])", "\n", "# in general the formula is n - ((n-1)*epoch) / warm_up_method[1][\"epoch\"]", "\n", "warm_up", "=", "tf", ".", "constant", "(", "10", ",", "dtype", "=", "tf", ".", "float32", ")", "-", "tf", ".", "cast", "(", "9", "*", "global_epoch", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "tf", ".", "constant", "(", "\n", "float", "(", "warm_up_method", "[", "1", "]", "[", "\"epoch\"", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"warm_up_method not recognized\"", ")", "\n", "\n", "", "return", "warm_up", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD._build": [[90, 119], ["MMD.MMD.get_warm_up_coefficient", "MMD.MMD.reconstruction_loss", "MMD.MMD.latent_mmd_loss", "tensorflow.shape", "gaussian_model_latent.sample", "prior.sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.get_warm_up_coefficient", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss", "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD.latent_mmd_loss", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "_build", "(", "self", ",", "vae", ")", ":", "\n", "        ", "prior", "=", "vae", ".", "_prior", "\n", "gaussian_model_latent", "=", "vae", ".", "_gaussian_model_latent", "\n", "x_target", "=", "vae", ".", "x_target", "\n", "reconstructions", "=", "vae", ".", "x_reconstruction_node", "\n", "batch_size", "=", "tf", ".", "shape", "(", "reconstructions", ")", "[", "0", "]", "\n", "\n", "warm_up", "=", "self", ".", "get_warm_up_coefficient", "(", "self", ".", "_warm_up_method", ",", "vae", ")", "\n", "\n", "# The loss is composed of two terms:", "\n", "#", "\n", "# 1.) The reconstruction loss (can be any dissimilarity in the data space).", "\n", "\n", "reconstruction_loss", "=", "self", ".", "reconstruction_loss", "(", "x_target", ",", "reconstructions", ")", "\n", "\n", "# 2.) The latent loss, which is defined as the MMD", "\n", "#     between the distribution in latent space induced by the encoder on", "\n", "#     the data and some prior. This acts as a kind of regularizer.", "\n", "\n", "# should choose between the mean or z, if we use deterministic or stochastic encoders", "\n", "# for now, the encoder is stochastic", "\n", "mmd", "=", "self", ".", "latent_mmd_loss", "(", "gaussian_model_latent", ".", "sample", "(", ")", ",", "prior", ".", "sample", "(", "batch_size", ")", ")", "\n", "# mmd = self.latent_mmd_loss(gaussian_model_latent.mean(), prior.sample(batch_size))", "\n", "\n", "latent_loss", "=", "self", ".", "beta", "*", "mmd", "\n", "\n", "cost", "=", "warm_up", "*", "latent_loss", "+", "reconstruction_loss", "\n", "\n", "return", "cost", ",", "[", "[", "reconstruction_loss", "]", ",", "[", "latent_loss", "]", "]", ",", "[", "[", "\"RL\"", "]", ",", "[", "\"MMD\"", "]", "]", ",", "[", "{", "\"fileName\"", ":", "\"cost_function_RL\"", "}", ",", "{", "\"fileName\"", ":", "\"cost_function_MMD\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD.reconstruction_loss": [[120, 132], ["tensorflow.variable_scope", "tensorflow.reduce_sum", "len", "tensorflow.square", "tensorflow.reduce_mean", "len", "RuntimeError", "reconstruction.get_shape().as_list", "list", "range", "reconstruction.get_shape"], "methods", ["None"], ["", "def", "reconstruction_loss", "(", "self", ",", "x_target", ",", "reconstruction", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'reconstruction_loss'", ")", ":", "\n", "            ", "num_dims", "=", "len", "(", "reconstruction", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "-", "1", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "x_target", "-", "reconstruction", ")", ",", "axis", "=", "list", "(", "range", "(", "1", ",", "num_dims", "+", "1", ")", ")", ")", "\n", "mean_reconstr_loss", "=", "0.05", "*", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n", "if", "len", "(", "mean_reconstr_loss", ".", "shape", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"loss should be a scalar at this point, found shape: {}\"", ".", "format", "(", "mean_reconstr_loss", ".", "shape", ")", ")", "\n", "\n", "", "", "return", "mean_reconstr_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.MMD.MMD.latent_mmd_loss": [[133, 187], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.shape", "tensorflow.shape", "tensorflow.square", "tensorflow.square", "tensorflow.exp", "tensorflow.exp", "tensorflow.multiply", "tensorflow.exp", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reduce_sum", "tensorflow.nn.top_k", "tensorflow.nn.top_k", "tensorflow.eye", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.eye", "tensorflow.reduce_sum"], "methods", ["None"], ["", "def", "latent_mmd_loss", "(", "self", ",", "samples_qz", ",", "samples_pz", ")", ":", "\n", "        ", "sigma2_p", "=", "1", "\n", "kernel", "=", "self", ".", "mmd_kernel", "\n", "n", "=", "tf", ".", "shape", "(", "samples_qz", ")", "[", "0", "]", "\n", "n", "=", "tf", ".", "cast", "(", "n", ",", "tf", ".", "int32", ")", "\n", "nf", "=", "tf", ".", "cast", "(", "n", ",", "tf", ".", "float32", ")", "\n", "half_size", "=", "(", "n", "*", "n", "-", "n", ")", "//", "2", "\n", "z_dim", "=", "tf", ".", "shape", "(", "samples_qz", ")", "[", "1", "]", "\n", "\n", "norms_pz", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "samples_pz", ")", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "dotprods_pz", "=", "tf", ".", "matmul", "(", "samples_pz", ",", "samples_pz", ",", "transpose_b", "=", "True", ")", "\n", "distances_pz", "=", "norms_pz", "+", "tf", ".", "transpose", "(", "norms_pz", ")", "-", "2.", "*", "dotprods_pz", "\n", "\n", "norms_qz", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "samples_qz", ")", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "dotprods_qz", "=", "tf", ".", "matmul", "(", "samples_qz", ",", "samples_qz", ",", "transpose_b", "=", "True", ")", "\n", "distances_qz", "=", "norms_qz", "+", "tf", ".", "transpose", "(", "norms_qz", ")", "-", "2.", "*", "dotprods_qz", "\n", "\n", "dotprods", "=", "tf", ".", "matmul", "(", "samples_qz", ",", "samples_pz", ",", "transpose_b", "=", "True", ")", "\n", "distances", "=", "norms_qz", "+", "tf", ".", "transpose", "(", "norms_pz", ")", "-", "2.", "*", "dotprods", "\n", "\n", "if", "kernel", "==", "'RBF'", ":", "\n", "# Median heuristic for the sigma^2 of Gaussian kernel", "\n", "            ", "sigma2_k", "=", "tf", ".", "nn", ".", "top_k", "(", "\n", "tf", ".", "reshape", "(", "distances", ",", "[", "-", "1", "]", ")", ",", "half_size", ")", ".", "values", "[", "half_size", "-", "1", "]", "\n", "sigma2_k", "+=", "tf", ".", "nn", ".", "top_k", "(", "\n", "tf", ".", "reshape", "(", "distances_qz", ",", "[", "-", "1", "]", ")", ",", "half_size", ")", ".", "values", "[", "half_size", "-", "1", "]", "\n", "# Maximal heuristic for the sigma^2 of Gaussian kernel", "\n", "# sigma2_k = tf.nn.top_k(tf.reshape(distances_qz, [-1]), 1).values[0]", "\n", "# sigma2_k += tf.nn.top_k(tf.reshape(distances, [-1]), 1).values[0]", "\n", "# sigma2_k = opts['latent_space_dim'] * sigma2_p", "\n", "res1", "=", "tf", ".", "exp", "(", "-", "distances_qz", "/", "2.", "/", "sigma2_k", ")", "\n", "res1", "+=", "tf", ".", "exp", "(", "-", "distances_pz", "/", "2.", "/", "sigma2_k", ")", "\n", "res1", "=", "tf", ".", "multiply", "(", "res1", ",", "1.", "-", "tf", ".", "eye", "(", "n", ")", ")", "\n", "res1", "=", "tf", ".", "reduce_sum", "(", "res1", ")", "/", "(", "nf", "*", "nf", "-", "nf", ")", "\n", "res2", "=", "tf", ".", "exp", "(", "-", "distances", "/", "2.", "/", "sigma2_k", ")", "\n", "res2", "=", "tf", ".", "reduce_sum", "(", "res2", ")", "*", "2.", "/", "(", "nf", "*", "nf", ")", "\n", "stat", "=", "res1", "-", "res2", "\n", "", "elif", "kernel", "==", "'IMQ'", ":", "\n", "# k(x, y) = C / (C + ||x - y||^2)", "\n", "# C = tf.nn.top_k(tf.reshape(distances, [-1]), half_size).values[half_size - 1]", "\n", "# C += tf.nn.top_k(tf.reshape(distances_qz, [-1]), half_size).values[half_size - 1]", "\n", "\n", "            ", "c_base", "=", "2.", "*", "tf", ".", "cast", "(", "z_dim", ",", "tf", ".", "float32", ")", "*", "sigma2_p", "\n", "stat", "=", "0.", "\n", "for", "scale", "in", "[", ".1", ",", ".2", ",", ".5", ",", "1.", ",", "2.", ",", "5.", ",", "10.", "]", ":", "\n", "                ", "C", "=", "c_base", "*", "scale", "\n", "res1", "=", "C", "/", "(", "C", "+", "distances_qz", ")", "\n", "res1", "+=", "C", "/", "(", "C", "+", "distances_pz", ")", "\n", "res1", "=", "tf", ".", "multiply", "(", "res1", ",", "1.", "-", "tf", ".", "eye", "(", "n", ")", ")", "\n", "res1", "=", "tf", ".", "reduce_sum", "(", "res1", ")", "/", "(", "nf", "*", "nf", "-", "nf", ")", "\n", "res2", "=", "C", "/", "(", "C", "+", "distances", ")", "\n", "res2", "=", "tf", ".", "reduce_sum", "(", "res2", ")", "*", "2.", "/", "(", "nf", "*", "nf", ")", "\n", "stat", "+=", "res1", "-", "res2", "\n", "", "", "return", "stat", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.__init__": [[10, 18], ["argo.core.network.AbstractModule.AbstractModule.__init__", "tensorflow.placeholder_with_default", "float"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "beta", "=", "1.0", ",", "warm_up_method", "=", "None", ",", "name", "=", "\"ELBO\"", ",", "mask", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_warm_up_method", "=", "warm_up_method", "\n", "self", ".", "beta", "=", "tf", ".", "placeholder_with_default", "(", "float", "(", "beta", ")", ",", "shape", "=", "(", ")", ",", "name", "=", "'beta_regularizer'", ")", "\n", "\n", "assert", "(", "mask", "==", "None", "or", "mask", "==", "0", "or", "mask", "==", "1", ")", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.create_id": [[20, 30], ["ELBO.ELBO.create_warm_up_id", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.create_warm_up_id"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "# cost_fuction_kwargs[0] is the cost function name", "\n", "\n", "        ", "_id", "=", "\"ELBO_b\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"beta\"", "]", ")", "\n", "_id", "+=", "self", ".", "create_warm_up_id", "(", "cost_fuction_kwargs", ")", "\n", "if", "\"mask\"", "in", "cost_fuction_kwargs", "and", "cost_fuction_kwargs", "[", "\"beta\"", "]", "==", "1", ":", "\n", "            ", "_id", "+=", "\"_m\"", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.create_warm_up_id": [[31, 44], ["str", "Exception", "str"], "methods", ["None"], ["", "def", "create_warm_up_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "if", "\"warm_up_method\"", "not", "in", "cost_fuction_kwargs", "or", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "is", "None", "or", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "0", "]", "is", "None", ":", "\n", "            ", "warm_up", "=", "\"0\"", "\n", "", "elif", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "0", "]", "==", "\"warm_up\"", ":", "\n", "            ", "warm_up", "=", "\"W\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "1", "]", "[", "\"epoch\"", "]", ")", "\n", "", "elif", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "0", "]", "==", "\"inverse_warm_up\"", ":", "\n", "            ", "warm_up", "=", "\"IW\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"warm_up_method\"", "]", "[", "1", "]", "[", "\"epoch\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"warm_up_method not recognized\"", ")", "\n", "", "_id", "=", "'_wu'", "+", "warm_up", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.get_warm_up_coefficient": [[45, 81], ["tensorflow.constant", "tensorflow.cond", "Exception", "Exception", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "float"], "methods", ["None"], ["", "def", "get_warm_up_coefficient", "(", "self", ",", "warm_up_method", ",", "vae_model", ")", ":", "\n", "# Warm up: gradually introduce the KL divergence in the cost function,", "\n", "# as suggested in Ladder VAE paper, and also others", "\n", "#", "\n", "# warm_up_method  None             = no warm up", "\n", "#                \"inverse_warm_up\" = inverse warm up (scale of KL decreases until it becomes 1)", "\n", "#                \"warm_up\"         = warm up (scale of KL increases until it becomes 1)", "\n", "\n", "# initialize the warm_up coefficient to be placed in front of the KL term for ELBO and IELBO", "\n", "        ", "if", "warm_up_method", "is", "None", "or", "warm_up_method", "[", "0", "]", "is", "None", ":", "\n", "            ", "warm_up", "=", "tf", ".", "constant", "(", "1.", ")", "\n", "\n", "", "elif", "warm_up_method", "[", "0", "]", "==", "\"warm_up\"", ":", "\n", "            ", "global_step", "=", "vae_model", ".", "global_step", "\n", "warm_up_final_step", "=", "warm_up_method", "[", "1", "]", "[", "\"epoch\"", "]", "*", "vae_model", ".", "n_batches_per_epoch", "\n", "# increase the KL scale from 0 to 1, over self.warm_up_method[1][\"epoch\"] epochs", "\n", "warm_up", "=", "tf", ".", "cond", "(", "global_step", ">", "warm_up_final_step", ",", "\n", "lambda", ":", "tf", ".", "constant", "(", "1.", ")", ",", "\n", "lambda", ":", "tf", ".", "cast", "(", "global_step", "-", "1", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "\n", "tf", ".", "constant", "(", "warm_up_final_step", "-", "1", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", ")", "\n", "\n", "", "elif", "warm_up_method", "[", "0", "]", "==", "\"inverse_warm_up\"", ":", "\n", "\n", "# TODO-LUIGI what is below needs to be reimplemented", "\n", "            ", "raise", "Exception", "(", "\"what is below needs to be reimplemented\"", ")", "\n", "warm_up_final_step", "=", "warm_up_method", "[", "1", "]", "[", "\"epoch\"", "]", "*", "vae_model", ".", "n_batches_per_epoch", "\n", "\n", "# decrease the KL scale from 10 (epoch 0) to 1 (epoch warm_up_method[1][\"epoch\"])", "\n", "# in general the formula is n - ((n-1)*epoch) / warm_up_method[1][\"epoch\"]", "\n", "warm_up", "=", "tf", ".", "constant", "(", "10", ",", "dtype", "=", "tf", ".", "float32", ")", "-", "tf", ".", "cast", "(", "9", "*", "global_epoch", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "tf", ".", "constant", "(", "float", "(", "warm_up_method", "[", "1", "]", "[", "\"epoch\"", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"warm_up_method not recognized\"", ")", "\n", "\n", "", "return", "warm_up", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO._build": [[82, 122], ["ELBO.ELBO.get_warm_up_coefficient", "ELBO.ELBO.reconstruction_loss", "ELBO.ELBO.latent_loss", "tensorflow.unstack", "str", "enumerate", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.get_warm_up_coefficient", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss", "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.latent_loss"], ["", "def", "_build", "(", "self", ",", "vae", ")", ":", "\n", "        ", "prior", "=", "vae", ".", "_prior", "\n", "approximate_posterior", "=", "vae", ".", "_approximate_posterior", "\n", "model_visible", "=", "vae", ".", "_model_visible", "\n", "x_target", "=", "vae", ".", "x_target", "\n", "n_z_samples", "=", "vae", ".", "n_z_samples", "\n", "\n", "warm_up", "=", "self", ".", "get_warm_up_coefficient", "(", "self", ".", "_warm_up_method", ",", "vae", ")", "\n", "\n", "# The loss is composed of two terms:", "\n", "#", "\n", "# 1.) The reconstruction loss (the negative log probability", "\n", "#     of the input under the reconstructed distribution", "\n", "#     induced by the decoder in the data space).", "\n", "#     This can be interpreted as the number of \"nats\" required", "\n", "#     for reconstructing the input when the activation in latent", "\n", "#     is given.", "\n", "\n", "reconstruction_loss", "=", "self", ".", "reconstruction_loss", "(", "x_target", ",", "n_z_samples", ",", "model_visible", ",", "vae", ")", "\n", "\n", "# 2.) The latent loss, which is defined as the Kullback Leibler divergence", "\n", "#     between the distribution in latent space induced by the encoder on", "\n", "#     the data and some prior. This acts as a kind of regularizer.", "\n", "#     This can be interpreted as the number of \"nats\" required", "\n", "#     for transmitting the the latent space distribution given", "\n", "#     the prior.", "\n", "\n", "\n", "KL", ",", "KL_i", "=", "self", ".", "latent_loss", "(", "approximate_posterior", ",", "prior", ")", "\n", "latent_loss", "=", "self", ".", "beta", "*", "KL", "\n", "\n", "cost", "=", "warm_up", "*", "latent_loss", "+", "reconstruction_loss", "\n", "\n", "# logging individual KL_i", "\n", "KL_i", "=", "tf", ".", "unstack", "(", "KL_i", ")", "\n", "KL_i_names", "=", "[", "\"KL_\"", "+", "str", "(", "int", "(", "i", "+", "1", ")", ")", "for", "i", ",", "l", "in", "enumerate", "(", "KL_i", ")", "]", "\n", "\n", "ELBO", "=", "-", "KL", "-", "reconstruction_loss", "\n", "\n", "return", "cost", ",", "[", "[", "ELBO", "]", ",", "[", "-", "reconstruction_loss", "]", ",", "[", "latent_loss", "]", ",", "KL_i", "]", ",", "[", "[", "\"ELBO\"", "]", ",", "[", "\"RL\"", "]", ",", "[", "\"KL\"", "]", ",", "KL_i_names", "]", ",", "[", "{", "\"fileName\"", ":", "\"cost_function_ELBO\"", "}", ",", "{", "\"fileName\"", ":", "\"cost_function_RL\"", "}", ",", "{", "\"fileName\"", ":", "\"cost_function_KL\"", "}", ",", "{", "\"fileName\"", ":", "\"cost_function_KL_i\"", ",", "\"legend\"", ":", "0", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.reconstruction_loss": [[124, 170], ["tensorflow.variable_scope", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "x_target.shape.as_list", "len", "model_visible.log_prob", "tensorflow.tile", "tensorflow.multiply", "list", "len", "RuntimeError", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "reconstruction_loss", "(", "self", ",", "x_target", ",", "n_z_samples", ",", "model_visible", ",", "model", "=", "None", ")", ":", "\n", "\n", "# with tf.variable_scope('ELBO/reconstruction_loss'):", "\n", "# no need for ELBO, sonnet module is already adding that, the line above would produce:", "\n", "# ELBO/ELBO/reconstruction_loss/node_created", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'reconstruction_loss'", ")", ":", "\n", "\n", "# 1) the log_pdf is computed with respect to distribution of the visible", "\n", "#    variables obtained from the target of input of the graph (self.x_target)", "\n", "\n", "# can I avoid replicate? maybe not..", "\n", "            ", "input_shape", "=", "x_target", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "ones", "=", "[", "1", "]", "*", "len", "(", "input_shape", ")", "\n", "x_replicate", "=", "tf", ".", "tile", "(", "x_target", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "\n", "reconstr_loss", "=", "-", "model_visible", ".", "log_prob", "(", "x_replicate", ")", "\n", "#pdb.set_trace()", "\n", "\n", "#f.Print(self.mask, [self.mask])", "\n", "\n", "if", "self", ".", "mask", "==", "1", ":", "\n", "# apply mask", "\n", "                ", "mask_replicate", "=", "tf", ".", "tile", "(", "model", ".", "mask", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "reconstr_loss", "=", "tf", ".", "multiply", "(", "reconstr_loss", ",", "mask_replicate", ")", "\n", "\n", "# #before", "\n", "# reconstr_loss = tf.reshape(reconstr_loss, [n_z_samples, -1]+input_shape)", "\n", "# all_axis_but_first_2 = list(range(len(reconstr_loss.shape)))[2:]", "\n", "# #independent p for each input pixel", "\n", "# log_p = tf.reduce_sum(reconstr_loss, axis=all_axis_but_first_2)", "\n", "# #average over the samples", "\n", "# mean_reconstr_loss = tf.reduce_mean(log_p, axis=0)", "\n", "\n", "#now (ready for arbitrary intermediate samplings)", "\n", "", "all_axis_but_first", "=", "list", "(", "range", "(", "len", "(", "reconstr_loss", ".", "shape", ")", ")", ")", "[", "1", ":", "]", "\n", "#independent p for each input pixel", "\n", "log_p", "=", "tf", ".", "reduce_sum", "(", "reconstr_loss", ",", "axis", "=", "all_axis_but_first", ")", "\n", "#average over all the samples and the batch (they are both stacked on the axis 0)", "\n", "mean_reconstr_loss", "=", "tf", ".", "reduce_mean", "(", "log_p", ",", "axis", "=", "0", ",", "name", "=", "\"reconstruction_loss\"", ")", "\n", "\n", "if", "len", "(", "mean_reconstr_loss", ".", "shape", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"loss should be a scalar at this point, found shape: {}\"", ".", "format", "(", "mean_reconstr_loss", ".", "shape", ")", ")", "\n", "\n", "# self.log_p_x_z = mean_reconstr_loss", "\n", "\n", "", "", "return", "mean_reconstr_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO.ELBO.latent_loss": [[171, 197], ["tensorflow.variable_scope", "len", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.reshape", "approximate_posterior.kl_divergence", "approximate_posterior.kl_divergence", "approximate_posterior.kl_divergence"], "methods", ["None"], ["", "def", "latent_loss", "(", "self", ",", "approximate_posterior", ",", "prior", ")", ":", "\n", "\n", "# with tf.variable_scope('ELBO/reconstruction_loss'):", "\n", "# no need for ELBO, sonnet module is already adding that, the line above would produce:", "\n", "# ELBO/ELBO/reconstruction_loss/node_created", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'latent_loss'", ")", ":", "\n", "# 1) cast is required", "\n", "# 2) the KL divergence is computed with respect to distribution of the latent", "\n", "#    variables obtained from the input of the graph (self.x_tilde)", "\n", "#all_axis_but_first = list(range(len(gaussian_model_latent.batch_shape)))[1:]", "\n", "\n", "# average on the batch", "\n", "            ", "if", "len", "(", "approximate_posterior", ".", "kl_divergence", "(", "prior", ")", ".", "shape", ")", ">", "1", ":", "\n", "# this is the case of the GaussianDiagonal", "\n", "                ", "mean_latent_loss_i", "=", "tf", ".", "reduce_mean", "(", "approximate_posterior", ".", "kl_divergence", "(", "prior", ")", ",", "axis", "=", "0", ",", "name", "=", "\"latent_loss_i\"", ")", "\n", "mean_latent_loss", "=", "tf", ".", "reduce_sum", "(", "mean_latent_loss_i", ",", "name", "=", "\"latent_loss\"", ")", "\n", "", "else", ":", "\n", "# this is the case of the vMF        ", "\n", "                ", "mean_latent_loss_i", "=", "tf", ".", "reduce_mean", "(", "approximate_posterior", ".", "kl_divergence", "(", "prior", ")", ",", "axis", "=", "0", ",", "name", "=", "\"latent_loss_i\"", ")", "\n", "mean_latent_loss", "=", "mean_latent_loss_i", "\n", "mean_latent_loss_i", "=", "tf", ".", "reshape", "(", "mean_latent_loss", ",", "[", "1", ",", "]", ")", "\n", "#mean_latent_loss_i = tf.reshape(mean_latent_loss_i, [1,-1])", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "", "", "return", "mean_latent_loss", ",", "mean_latent_loss_i", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Likelihood.Likelihood.__init__": [[8, 10], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"LL\"", ")", ":", "# drop_one_logit=0,", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Likelihood.Likelihood.create_id": [[13, 19], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "_id", "=", "\"LL\"", "#+ str(cost_fuction_kwargs.get(\"drop_one_logit\",0))", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Likelihood.Likelihood._build": [[20, 47], ["getattr", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "x_target.shape.as_list", "len", "distr.log_prob", "list", "len", "RuntimeError", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "_build", "(", "self", ",", "model", ")", ":", "#, drop_one_logit=False):", "\n", "\n", "        ", "x_target", "=", "model", ".", "x_target", "\n", "distr", "=", "model", ".", "_model_visible", "\n", "\n", "# if it is AE it does not have n_z_samples so it defaults to one and does not replicate", "\n", "n_z_samples", "=", "getattr", "(", "model", ",", "\"n_z_samples\"", ",", "1", ")", "\n", "input_shape", "=", "x_target", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "ones", "=", "[", "1", "]", "*", "len", "(", "input_shape", ")", "\n", "x_replicate", "=", "tf", ".", "tile", "(", "x_target", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "\n", "reconstr_loss", "=", "-", "distr", ".", "log_prob", "(", "x_replicate", ")", "\n", "\n", "all_axis_but_first", "=", "list", "(", "range", "(", "len", "(", "reconstr_loss", ".", "shape", ")", ")", ")", "[", "1", ":", "]", "\n", "# independent p for each input pixel", "\n", "loss_per_sample", "=", "tf", ".", "reduce_sum", "(", "reconstr_loss", ",", "axis", "=", "all_axis_but_first", ")", "\n", "# average over all the samples and the batch (they are both stacked on the axis 0)", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss_per_sample", ",", "axis", "=", "0", ",", "name", "=", "\"nll\"", ")", "\n", "\n", "if", "len", "(", "loss", ".", "shape", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"loss should be a scalar at this point, found shape: {}\"", ".", "format", "(", "loss", ".", "shape", ")", ")", "\n", "\n", "", "nodes_to_log", "=", "[", "[", "-", "loss", "]", "]", "\n", "names_of_nodes_to_log", "=", "[", "[", "'LL'", "]", "]", "\n", "filenames_to_log_to", "=", "[", "{", "\"fileName\"", ":", "\"likelihood\"", "}", "]", "\n", "\n", "return", "loss", ",", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Renyi.Renyi.__init__": [[48, 54], ["argo.core.Network.AbstractModule.__init__", "tensorflow.placeholder_with_default", "float"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "beta", "=", "1.0", ",", "warm_up_method", "=", "None", ",", "name", "=", "\"ELBO\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "#self._warm_up_method = warm_up_method", "\n", "#self.beta = tf.placeholder_with_default(float(beta), shape=(), name='beta_regularizer')", "\n", "self", ".", "alpha", "=", "tf", ".", "placeholder_with_default", "(", "float", "(", "alpha", ")", ",", "shape", "=", "(", ")", ",", "name", "=", "'alpha_renyi'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Renyi.Renyi.create_id": [[55, 63], ["str"], "methods", ["None"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "# cost_fuction_kwargs[0] is the cost function name", "\n", "\n", "        ", "_id", "=", "\"Renyi_a\"", "+", "str", "(", "cost_fuction_kwargs", "[", "\"alpha\"", "]", ")", "\n", "#_id += self.create_warm_up_id(cost_fuction_kwargs)", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Renyi.Renyi._build": [[117, 135], ["reconstruction_loss"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss"], ["def", "_build", "(", "self", ",", "vae", ")", ":", "\n", "        ", "prior", "=", "vae", ".", "_prior", "\n", "gaussian_model_latent", "=", "vae", ".", "_gaussian_model_latent", "\n", "model_visible", "=", "vae", ".", "_model_visible", "\n", "x_target", "=", "vae", ".", "x_target", "\n", "n_z_samples", "=", "vae", ".", "n_z_samples", "\n", "\n", "#warm_up = self.get_warm_up_coefficient(self._warm_up_method, vae)", "\n", "\n", "#reconstruction_loss = self.reconstruction_loss(x_target, n_z_samples, model_visible)", "\n", "#latent_loss = self.beta * self.latent_loss(gaussian_model_latent, prior)", "\n", "renyi_loss", "=", "reconstruction_loss", "(", "x_target", ",", "n_z_samples", ",", "model_visible", ",", "gaussian_model_latent", ",", "prior", ")", "# SEPTIMIA", "\n", "\n", "# Check signs SEPTIMIA", "\n", "cost", "=", "-", "renyi_loss", "\n", "\n", "# Check signs SEPTIMIA", "\n", "return", "cost", ",", "[", "renyi_loss", "]", ",", "[", "\"RenyiRL\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.Renyi.Renyi.renyi_loss": [[137, 139], ["None"], "methods", ["None"], ["", "def", "renyi_loss", "(", "self", ",", "x_target", ",", "n_z_samples", ",", "model_visible", ",", "gaussian_model_latent", ",", "prior", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VQVAENetwork.create_id": [[43, 68], ["filter", "filter", "super().create_id", "argo.core.utils.argo_utils.get_method_id", "argo.core.utils.argo_utils.get_method_id", "[].upper"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "encoder_layers_ids", "=", "filter", "(", "None", ",", "\n", "[", "utils", ".", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"encoder\"", "]", "]", "\n", ")", "\n", "\n", "decoder_layers_ids", "=", "filter", "(", "None", ",", "\n", "[", "utils", ".", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"decoder\"", "]", "]", "\n", ")", "\n", "\n", "_id", "=", "'-ne_'", "+", "\"_\"", ".", "join", "(", "encoder_layers_ids", ")", "+", "'-vq_'", "+", "\"e{:}\"", ".", "format", "(", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"vq\"", "]", "[", "\"embedding_dim\"", "]", ")", "+", "\"_p\"", "+", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"vq\"", "]", "[", "\"pre\"", "]", "[", "0", "]", "+", "\"_lc{:}\"", ".", "format", "(", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"vq\"", "]", "[", "\"latent_channels\"", "]", ")", "+", "\"_c{:}\"", ".", "format", "(", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"vq\"", "]", "[", "\"commitment_cost\"", "]", ")", "+", "\"_pr\"", "+", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"vq\"", "]", "[", "\"prior\"", "]", "[", "0", "]", ".", "upper", "(", ")", "+", "'-nd_'", "+", "\"_\"", ".", "join", "(", "decoder_layers_ids", ")", "\n", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VQVAENetwork.__init__": [[70, 95], ["argo.core.network.ArgoStochasticNetworkWithDefaults.ArgoStochasticNetworkWithDefaults.__init__", "tensorflow.placeholder_with_default"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", "=", "\"vae_network\"", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Short summary.\n\n        Args:\n            opts (dict): parameters of the task.\n            name (str): name of the Sonnet module.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "seed", ")", "\n", "\n", "network_architecture", "=", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "\n", "# TODO-ARGO2 y_name, self._pre_kwargsou might want to check here that the 2 architectures (encoder and decoder) expected are effectively passed", "\n", "self", ".", "_network_architecture", "=", "network_architecture", "\n", "self", ".", "_vq_kwargs", "=", "network_architecture", "[", "\"vq\"", "]", "\n", "self", ".", "_embedding_dim", "=", "self", ".", "_vq_kwargs", "[", "\"embedding_dim\"", "]", "\n", "self", ".", "_num_embeddings", "=", "self", ".", "_vq_kwargs", "[", "\"num_embeddings\"", "]", "\n", "self", ".", "_commitment_cost", "=", "self", ".", "_vq_kwargs", "[", "\"commitment_cost\"", "]", "\n", "self", ".", "_latent_channels", "=", "self", ".", "_vq_kwargs", "[", "\"latent_channels\"", "]", "\n", "\n", "self", ".", "_pre_name", "=", "self", ".", "_vq_kwargs", "[", "\"pre\"", "]", "\n", "\n", "self", ".", "_prior_tag", "=", "self", ".", "_vq_kwargs", "[", "\"prior\"", "]", "\n", "assert", "self", ".", "_prior_tag", "in", "[", "\"fixed\"", ",", "\"train\"", "]", ",", "\"prior `{:}` not recognized\"", ".", "format", "(", "self", ".", "_prior_tag", ")", "\n", "\n", "self", ".", "n_samples_prior", "=", "tf", ".", "placeholder_with_default", "(", "1", ",", "shape", "=", "(", ")", ",", "name", "=", "'n_samples_prior'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VQVAENetwork._build": [[97, 209], ["argo.core.network.GeneralSonnetNetwork.GeneralSonnetNetwork", "sonnet.Linear.", "tensorflow.reshape", "VQVAENetwork.VectorQuantizer", "VQVAENetwork.VQVAENetwork.vq_layer", "argo.core.network.GeneralSonnetNetwork.GeneralSonnetNetwork", "VQVAENetwork.VQVAENetwork.decoder_module", "sonnet.Conv2D", "VQVAENetwork.VQVAENetwork.encoder_module", "snt.Linear.shape[].as_list", "x.get_shape().as_list", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow_probability.distributions.Categorical", "VQVAENetwork.VQVAENetwork._cat_prior.sample", "VQVAENetwork.VQVAENetwork.vq_layer.quantize", "tensorflow.reshape", "VQVAENetwork.VQVAENetwork.decoder_module", "VQVAENetwork.VQVAENetwork.reconstruction_node", "sonnet.Linear", "Exception", "VQVAENetwork.VQVAENetwork.z_q.shape[].as_list", "x.get_shape", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer.quantize", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node"], ["", "def", "_build", "(", "self", ",", "x", ",", "is_training", ",", "network_str", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (tf.tensor): input node.\n            network_str (str): Optional network_str specifying the network we are going to build.\n                            It is used to set some specific collections for activity and contractive regularizers.\n\n        Returns:\n            tf distribution of the latent space\n            tf distribution on the visible neurons\n        \"\"\"", "\n", "\n", "# ENCODER", "\n", "self", ".", "encoder_module", "=", "GeneralSonnetNetwork", "(", "self", ".", "_network_defaults", "[", "\"activation\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", ",", "\n", "self", ".", "_network_architecture", "[", "\"encoder\"", "]", ",", "\n", "self", ".", "_stochastic_defaults", ",", "\n", "is_training", "=", "is_training", ",", "\n", "network_str", "=", "network_str", ",", "\n", "name", "=", "\"encoder\"", ")", "\n", "\n", "# LINKING", "\n", "pre_output_channels", "=", "self", ".", "_embedding_dim", "*", "self", ".", "_latent_channels", "\n", "if", "self", ".", "_pre_name", "==", "\"Conv2D\"", ":", "\n", "            ", "pre_vq_layer", "=", "snt", ".", "Conv2D", "(", "output_channels", "=", "pre_output_channels", ",", "\n", "kernel_shape", "=", "(", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "name", "=", "\"to_vq\"", ")", "\n", "", "elif", "self", ".", "_pre_name", "==", "\"Linear\"", ":", "\n", "            ", "pre_vq_layer", "=", "snt", ".", "Linear", "(", "output_size", "=", "pre_output_channels", ",", "\n", "name", "=", "\"to_vq\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"pre vq layer not recognized: `{:}`\"", ".", "format", "(", "self", ".", "_pre_name", ")", ")", "\n", "\n", "", "out_pre", "=", "pre_vq_layer", "(", "self", ".", "encoder_module", "(", "x", ")", ")", "\n", "\n", "z_preshape", "=", "[", "-", "1", "]", "+", "out_pre", ".", "shape", "[", "1", ":", "]", ".", "as_list", "(", ")", "\n", "z_shape", "=", "z_preshape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "_latent_channels", ",", "self", ".", "_embedding_dim", "]", "\n", "self", ".", "z_e", "=", "tf", ".", "reshape", "(", "out_pre", ",", "z_shape", ")", "\n", "\n", "# VQ", "\n", "self", ".", "vq_layer", "=", "VectorQuantizer", "(", "\n", "embedding_dim", "=", "self", ".", "_embedding_dim", ",", "\n", "num_embeddings", "=", "self", ".", "_num_embeddings", ",", "\n", "commitment_cost", "=", "self", ".", "_commitment_cost", ")", "\n", "\n", "vq_out", "=", "self", ".", "vq_layer", "(", "self", ".", "z_e", ",", "is_training", "=", "is_training", ")", "\n", "\n", "self", ".", "_cat_posterior", "=", "vq_out", "[", "\"encoding_distr\"", "]", "\n", "self", ".", "z_q", "=", "vq_out", "[", "\"quantize\"", "]", "\n", "\n", "# I set the shape of the visible layer, to match the input shape", "\n", "input_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "self", ".", "_network_architecture", "[", "\"decoder\"", "]", "[", "-", "1", "]", "[", "1", "]", "[", "\"output_shape\"", "]", "=", "input_shape", "\n", "# 4) and 5)", "\n", "self", ".", "decoder_module", "=", "GeneralSonnetNetwork", "(", "self", ".", "_network_defaults", "[", "\"activation\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", ",", "\n", "self", ".", "_network_architecture", "[", "\"decoder\"", "]", ",", "\n", "self", ".", "_stochastic_defaults", ",", "\n", "is_training", "=", "is_training", ",", "\n", "network_str", "=", "network_str", ",", "\n", "name", "=", "\"decoder\"", ")", "\n", "\n", "self", ".", "_model_visible", "=", "self", ".", "decoder_module", "(", "tf", ".", "reshape", "(", "self", ".", "z_q", ",", "z_preshape", ")", ")", "\n", "\n", "self", ".", "_embeddings", "=", "self", ".", "vq_layer", ".", "embeddings", "\n", "# create prior", "\n", "with", "tf", ".", "variable_scope", "(", "'generation'", ")", ":", "\n", "\n", "# uniform prior, not the best option in general, this can be learned afterwards", "\n", "            ", "self", ".", "_prior_vars", "=", "tf", ".", "get_variable", "(", "\"prior_vars\"", ",", "\n", "shape", "=", "(", "self", ".", "_num_embeddings", ",", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.", ")", ",", "\n", "trainable", "=", "True", "if", "self", ".", "_prior_tag", "==", "\"train\"", "else", "False", "\n", ")", "\n", "self", ".", "_cat_prior", "=", "tfp", ".", "distributions", ".", "Categorical", "(", "logits", "=", "self", ".", "_prior_vars", ",", "name", "=", "'prior_cat'", ")", "\n", "\n", "# independent samples, this can be improved", "\n", "batch_shape", "=", "[", "self", ".", "n_samples_prior", "]", "+", "self", ".", "z_q", ".", "shape", "[", "1", ":", "-", "1", "]", ".", "as_list", "(", ")", "\n", "cat_samples", "=", "self", ".", "_cat_prior", ".", "sample", "(", "batch_shape", ")", "\n", "\n", "quantized_samples", "=", "self", ".", "vq_layer", ".", "quantize", "(", "cat_samples", ")", "\n", "self", ".", "_prior_samples", "=", "tf", ".", "reshape", "(", "quantized_samples", ",", "z_preshape", ")", "\n", "\n", "# attach the decoder to the samples", "\n", "samples", "=", "self", ".", "decoder_module", "(", "self", ".", "_prior_samples", ")", "\n", "\n", "\n", "", "out_nodes", "=", "{", "\n", "'z_e'", ":", "self", ".", "z_e", ",", "\n", "'z_q'", ":", "self", ".", "z_q", ",", "\n", "'posterior'", ":", "self", ".", "_cat_posterior", ",", "\n", "'encodings'", ":", "vq_out", "[", "'encodings'", "]", ",", "\n", "'encoding_indices'", ":", "vq_out", "[", "'encoding_indices'", "]", ",", "\n", "'embeddings'", ":", "self", ".", "_embeddings", ",", "\n", "'reconstruction_model'", ":", "self", ".", "_model_visible", ",", "\n", "'prior'", ":", "self", ".", "_cat_prior", ",", "\n", "'generation_node'", ":", "samples", ".", "reconstruction_node", "(", ")", "\n", "}", "\n", "\n", "net_losses", "=", "{", "\n", "'vq_loss'", ":", "vq_out", "[", "'loss'", "]", ",", "\n", "'perplexity'", ":", "vq_out", "[", "'perplexity'", "]", "\n", "}", "\n", "\n", "return", "out_nodes", ",", "net_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer.__init__": [[239, 250], ["sonnet.AbstractModule.__init__", "VQVAENetwork.VectorQuantizer._enter_variable_scope", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.get_variable"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "num_embeddings", ",", "commitment_cost", ",", "\n", "name", "=", "'vq_layer'", ")", ":", "\n", "    ", "super", "(", "VectorQuantizer", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_embedding_dim", "=", "embedding_dim", "\n", "self", ".", "_num_embeddings", "=", "num_embeddings", "\n", "self", ".", "_commitment_cost", "=", "commitment_cost", "\n", "\n", "with", "self", ".", "_enter_variable_scope", "(", ")", ":", "\n", "      ", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", ")", "\n", "self", ".", "_w", "=", "tf", ".", "get_variable", "(", "'embedding'", ",", "[", "embedding_dim", ",", "num_embeddings", "]", ",", "\n", "initializer", "=", "initializer", ",", "trainable", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer._build": [[251, 303], ["tensorflow.shape", "tensorflow.concat", "tensorflow_probability.distributions.Categorical", "tensorflow.argmax", "tensorflow.one_hot", "tensorflow.reshape", "VQVAENetwork.VectorQuantizer.quantize", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.exp", "tensorflow.control_dependencies", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.stop_gradient", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.Assert", "tensorflow.matmul", "tensorflow.shape", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "tensorflow.equal", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer.quantize", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", ")", ":", "\n", "    ", "\"\"\"Connects the module to some inputs.\n\n    Args:\n      inputs: Tensor, final dimension must be equal to embedding_dim. All other\n        leading dimensions will be flattened and treated as a large batch.\n      is_training: boolean, whether this connection is to training data.\n\n    Returns:\n      dict containing the following keys and values:\n        quantize: Tensor containing the quantized version of the input.\n        loss: Tensor containing the loss to optimize.\n        perplexity: Tensor containing the perplexity of the encodings.\n        encodings: Tensor containing the discrete encodings, ie which element\n          of the quantized space each input element was mapped to.\n        encoding_indices: Tensor containing the discrete encoding indices, ie\n          which element of the quantized space each input element was mapped to.\n    \"\"\"", "\n", "# Assert last dimension is same as self._embedding_dim", "\n", "input_shape", "=", "tf", ".", "shape", "(", "inputs", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "\n", "tf", ".", "Assert", "(", "tf", ".", "equal", "(", "input_shape", "[", "-", "1", "]", ",", "self", ".", "_embedding_dim", ")", ",", "\n", "[", "input_shape", "]", ")", "]", ")", ":", "\n", "      ", "flat_inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "_embedding_dim", "]", ")", "\n", "\n", "", "distances", "=", "(", "tf", ".", "reduce_sum", "(", "flat_inputs", "**", "2", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "-", "2", "*", "tf", ".", "matmul", "(", "flat_inputs", ",", "self", ".", "_w", ")", "\n", "+", "tf", ".", "reduce_sum", "(", "self", ".", "_w", "**", "2", ",", "0", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "logits_shape", "=", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "inputs", ")", "[", ":", "-", "1", "]", ",", "[", "self", ".", "_num_embeddings", "]", "]", ",", "axis", "=", "0", ")", "\n", "encoding_cat_distr", "=", "tfp", ".", "distributions", ".", "Categorical", "(", "logits", "=", "tf", ".", "reshape", "(", "-", "distances", ",", "logits_shape", ")", ",", "name", "=", "'posterior_cat'", ")", "\n", "\n", "encoding_indices", "=", "tf", ".", "argmax", "(", "-", "distances", ",", "1", ")", "\n", "encodings", "=", "tf", ".", "one_hot", "(", "encoding_indices", ",", "self", ".", "_num_embeddings", ")", "\n", "encoding_indices", "=", "tf", ".", "reshape", "(", "encoding_indices", ",", "tf", ".", "shape", "(", "inputs", ")", "[", ":", "-", "1", "]", ")", "\n", "quantized", "=", "self", ".", "quantize", "(", "encoding_indices", ")", "\n", "\n", "e_latent_loss", "=", "tf", ".", "reduce_mean", "(", "(", "tf", ".", "stop_gradient", "(", "quantized", ")", "-", "inputs", ")", "**", "2", ")", "\n", "q_latent_loss", "=", "tf", ".", "reduce_mean", "(", "(", "quantized", "-", "tf", ".", "stop_gradient", "(", "inputs", ")", ")", "**", "2", ")", "\n", "loss", "=", "q_latent_loss", "+", "self", ".", "_commitment_cost", "*", "e_latent_loss", "\n", "\n", "quantized", "=", "inputs", "+", "tf", ".", "stop_gradient", "(", "quantized", "-", "inputs", ")", "\n", "avg_probs", "=", "tf", ".", "reduce_mean", "(", "encodings", ",", "0", ")", "\n", "perplexity", "=", "tf", ".", "exp", "(", "-", "tf", ".", "reduce_sum", "(", "avg_probs", "*", "tf", ".", "log", "(", "avg_probs", "+", "1e-10", ")", ")", ")", "\n", "\n", "return", "{", "'quantize'", ":", "quantized", ",", "\n", "'loss'", ":", "loss", ",", "\n", "'perplexity'", ":", "perplexity", ",", "\n", "'encodings'", ":", "encodings", ",", "\n", "'encoding_indices'", ":", "encoding_indices", ",", "\n", "'encoding_distr'", ":", "encoding_cat_distr", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer.embeddings": [[304, 307], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "embeddings", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_w", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer.quantize": [[308, 312], ["tensorflow.nn.embedding_lookup", "tensorflow.control_dependencies", "tensorflow.transpose", "VQVAENetwork.VectorQuantizer.embeddings.read_value"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value"], ["", "def", "quantize", "(", "self", ",", "encoding_indices", ")", ":", "\n", "    ", "with", "tf", ".", "control_dependencies", "(", "[", "encoding_indices", "]", ")", ":", "\n", "      ", "w", "=", "tf", ".", "transpose", "(", "self", ".", "embeddings", ".", "read_value", "(", ")", ",", "[", "1", ",", "0", "]", ")", "\n", "", "return", "tf", ".", "nn", ".", "embedding_lookup", "(", "w", ",", "encoding_indices", ",", "validate_indices", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.KLMonteCarloCostFunction.KLCostFunction.__init__": [[9, 16], ["VAECostFunction.VAECostFunction.VAECostFunction.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "binarized", ",", "gaussian_model_observed", ",", "gaussian_model_latent", ")", ":", "\n", "        ", "VAECostFunction", ".", "__init__", "(", "self", ",", "binarized", ")", "\n", "\n", "self", ".", "_gaussian_model_observed", "=", "gaussian_model_observed", "\n", "self", ".", "_gaussian_model_latent", "=", "gaussian_model_latent", "\n", "\n", "self", ".", "_cost_logger_class", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.KLMonteCarloCostFunction.KLCostFunction.compute": [[17, 58], ["KLMonteCarloCostFunction.KLCostFunction._gaussian_model_latent.kl_divergence_from_unit_covariance", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.log", "tensorflow.log", "KLMonteCarloCostFunction.KLCostFunction._gaussian_model_observed.log_pdf", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "compute", "(", "self", ",", "x", ",", "x_replicate", ",", "x_reconstr_mean_samples", ")", ":", "\n", "# The loss is composed of two terms:", "\n", "#", "\n", "# 1.) The reconstruction loss (the negative log probability", "\n", "#     of the input under the reconstructed Bernoulli distribution ", "\n", "#     induced by the decoder in the data space).", "\n", "#     This can be interpreted as the number of \"nats\" required", "\n", "#     for reconstructing the input when the activation in latent", "\n", "#     is given.", "\n", "\n", "        ", "if", "self", ".", "_binarized", "==", "1", ":", "\n", "            ", "reconstr_loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "\n", "labels", "=", "x_replicate", ",", "\n", "logits", "=", "x_reconstr_mean_samples", ")", ",", "1", ")", ",", "1", ")", "\n", "\n", "", "else", ":", "\n", "# see formula from https://en.wikipedia.org/wiki/Logit-normal_distribution", "\n", "            ", "x_logit", "=", "tf", ".", "log", "(", "x_replicate", ")", "-", "tf", ".", "log", "(", "1", "-", "x_replicate", ")", "\n", "self", ".", "Bsum", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "log", "(", "x_replicate", ")", "+", "tf", ".", "log", "(", "1", "-", "x_replicate", ")", ",", "axis", "=", "1", ")", "\n", "# here I have -log p(x), since I will maximize this quantity", "\n", "reconstr_loss", "=", "self", ".", "Bsum", "-", "self", ".", "_gaussian_model_observed", ".", "log_pdf", "(", "x_logit", ")", "\n", "\n", "# 2.) The latent loss, which is defined as the Kullback Leibler divergence ", "\n", "##    between the distribution in latent space induced by the encoder on ", "\n", "#     the data and some prior. This acts as a kind of regularizer.", "\n", "#     This can be interpreted as the number of \"nats\" required", "\n", "#     for transmitting the the latent space distribution given", "\n", "#     the prior.", "\n", "\n", "", "latent_loss", "=", "self", ".", "_gaussian_model_latent", ".", "kl_divergence_from_unit_covariance", "(", ")", "\n", "\n", "'''\n        if self.k==-1:\n            latent_loss = -0.5 * tf.add(tf.reduce_sum(1 + 2 * self.z_chol_diag\n                                                     - tf.square(self.z_mean)\n                                                     - tf.exp(2 * self.z_chol_diag), 1),\n                                        -tf.reduce_sum(tf.square(self.z_chol_nondiag), 1))\n\n        '''", "\n", "\n", "return", "reconstr_loss", "+", "latent_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.__init__": [[31, 63], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "tensors", ",", "\n", "tensors_names", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "+", "'/pca_latent'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "datasets_keys", ",", "dirName", "=", "self", ".", "_dirName", ")", "\n", "\n", "#self._ds_handle = model.ds_handle", "\n", "#self._ds_initializers = model.datasets_initializers", "\n", "#self._ds_handles_nodes = model.datasets_handles_nodes", "\n", "\n", "self", ".", "_tensors", "=", "tensors", "\n", "self", ".", "_tensors_names", "=", "tensors_names", "\n", "\n", "#images = {ds_key : (index_list, model.dataset.get_elements(index_list, ds_key)) \\", "\n", "#                    for (ds_key, index_list) in images_indexes.items()}", "\n", "\n", "#check_dataset_keys_not_loop(list(images.keys()))", "\n", "\n", "#self._images = images", "\n", "self", ".", "_hook_name", "=", "\"two_dim_pca_latent_variables_hook\"", "\n", "tf_logging", ".", "info", "(", "\"Create TwoDimPCALatentVariablesHook for: \"", "+", "\", \"", ".", "join", "(", "self", ".", "_datasets_keys", ")", ")", "\n", "\n", "# in this specific logger this is not used", "\n", "self", ".", "_files", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook._begin_once": [[64, 100], ["zip", "argo.core.utils.argo_utils.create_concat_opts", "tensorflow.svd", "tensorflow.diag", "tensorflow.slice", "tensorflow.matmul", "tensor.shape.as_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_concat_opts"], ["", "def", "_begin_once", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "concat_ops", "=", "{", "}", "\n", "self", ".", "concat_update_ops", "=", "{", "}", "\n", "self", ".", "concat_reset_ops", "=", "{", "}", "\n", "self", ".", "pca", "=", "{", "}", "\n", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "\n", "            ", "self", ".", "concat_ops", "[", "ds_key", "]", "=", "{", "}", "\n", "self", ".", "concat_update_ops", "[", "ds_key", "]", "=", "{", "}", "\n", "self", ".", "concat_reset_ops", "[", "ds_key", "]", "=", "{", "}", "\n", "self", ".", "pca", "[", "ds_key", "]", "=", "{", "}", "\n", "\n", "# every hook needs to have its own accumulator to not have problem of erasing memory that other hooks still needs", "\n", "# maybe memory occupation could be improved if really needed, but great troubles for concurrency in parallel execution", "\n", "scope", "=", "self", ".", "_hook_name", "+", "\"/\"", "+", "ds_key", "+", "\"_concat_metric/\"", "\n", "\n", "#with tf.variable_scope(scope) as scope:", "\n", "\n", "for", "(", "tensor", ",", "tensor_name", ")", "in", "zip", "(", "self", ".", "_tensors", ",", "self", ".", "_tensors_names", ")", ":", "\n", "\n", "                ", "dim", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "self", ".", "concat_ops", "[", "ds_key", "]", "[", "tensor_name", "]", ",", "self", ".", "concat_update_ops", "[", "ds_key", "]", "[", "tensor_name", "]", ",", "self", ".", "concat_reset_ops", "[", "ds_key", "]", "[", "tensor_name", "]", "=", "create_concat_opts", "(", "scope", "+", "tensor_name", ",", "tensor", ")", "\n", "\n", "# see https://tomaxent.com/2018/01/17/PCA-With-Tensorflow/", "\n", "singular_values", ",", "u", ",", "_", "=", "tf", ".", "svd", "(", "self", ".", "concat_ops", "[", "ds_key", "]", "[", "tensor_name", "]", ")", "\n", "sigma", "=", "tf", ".", "diag", "(", "singular_values", ")", "\n", "# first two compoments", "\n", "sigma_reduced", "=", "tf", ".", "slice", "(", "sigma", ",", "[", "0", ",", "0", "]", ",", "[", "dim", ",", "2", "]", ")", "\n", "#couldn't simply take tf.diag(singular_values[:2])?", "\n", "\n", "#TODO are you sure? PCA should use right vectors, usually called V, not U. If convention is X = U S V^T", "\n", "# the reshape is needed (why, which is original output shape of u?)", "\n", "self", ".", "pca", "[", "ds_key", "]", "[", "tensor_name", "]", "=", "tf", ".", "matmul", "(", "tf", ".", "reshape", "(", "u", ",", "[", "-", "1", ",", "dim", "]", ")", ",", "sigma_reduced", ")", "\n", "#queste sono le proiezioni di tutti i punti sui primi 2 principal axis.", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.after_create_session": [[102, 104], ["super().after_create_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session"], ["", "", "", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.do_when_triggered": [[106, 167], ["tf_logging.info", "session.run", "session.run", "dict", "zip", "matplotlib.figure", "matplotlib.figure", "matplotlib.figure", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook._model.dataset.get_elements", "int", "range", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.title", "matplotlib.title", "matplotlib.title", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.close", "matplotlib.close", "matplotlib.close", "numpy.hstack", "numpy.savetxt", "session.run", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.pca[].keys", "len", "numpy.tile", "str().zfill", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.pca[].values", "len", "len", "len", "numpy.array().reshape", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.concat_reset_ops[].values", "str", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.concat_update_ops[].values", "numpy.array", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "#tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for TwoDimPCALatentVariablesHook\"", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "#images = self._images[ds_key][1]", "\n", "\n", "            ", "session", "=", "run_context", ".", "session", "\n", "\n", "dataset_initializer", "=", "self", ".", "_ds_initializers", "[", "ds_key", "]", "\n", "\n", "#for tensor_name in self._tensors_names:", "\n", "session", ".", "run", "(", "[", "dataset_initializer", "]", "+", "[", "*", "self", ".", "concat_reset_ops", "[", "ds_key", "]", ".", "values", "(", ")", "]", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "session", ".", "run", "(", "[", "*", "self", ".", "concat_update_ops", "[", "ds_key", "]", ".", "values", "(", ")", "]", ",", "feed_dict", "=", "{", "self", ".", "_ds_handle", ":", "self", ".", "_ds_handles", "[", "ds_key", "]", "}", ")", "# **feed_dict,", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "\n", "", "", "returns", "=", "session", ".", "run", "(", "[", "*", "self", ".", "pca", "[", "ds_key", "]", ".", "values", "(", ")", "]", ")", "\n", "tensors_pca", "=", "dict", "(", "zip", "(", "self", ".", "pca", "[", "ds_key", "]", ".", "keys", "(", ")", ",", "returns", ")", ")", "\n", "\n", "for", "tensor_name", "in", "self", ".", "_tensors_names", ":", "\n", "\n", "                ", "pca", "=", "tensors_pca", "[", "tensor_name", "]", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "10", ")", ")", "\n", "\n", "# I need to take into account the number of samples z,", "\n", "# and replicate z in a little bit tricky way", "\n", "\n", "#labels = self._model.dataset.get_labels(ds_key)", "\n", "\n", "labels", "=", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "y", ",", "self", ".", "_ds_handle", ",", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "dataset_initializer", ",", "session", ")", "\n", "\n", "batch_size", "=", "self", ".", "_model", ".", "batch_size", "[", "\"eval\"", "]", "\n", "\n", "#TODO comment: what is samples? use t.shape for tensors (not len(t)) is much more understandable.", "\n", "# import pdb;pdb.set_trace()", "\n", "samples", "=", "int", "(", "len", "(", "pca", ")", "/", "len", "(", "labels", ")", ")", "#self._model.samples", "\n", "\n", "repeated_labels", "=", "[", "0", "]", "*", "(", "len", "(", "labels", ")", "*", "samples", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "batch_size", ")", ":", "\n", "                    ", "repeated_labels", "[", "i", "*", "samples", ":", "i", "*", "samples", "+", "batch_size", "*", "samples", "]", "=", "np", ".", "tile", "(", "labels", "[", "i", ":", "i", "+", "batch_size", "]", ",", "samples", ")", "\n", "\n", "", "plt", ".", "scatter", "(", "pca", "[", ":", ",", "0", "]", ",", "pca", "[", ":", ",", "1", "]", ",", "c", "=", "repeated_labels", ",", "cmap", "=", "'gist_rainbow'", ",", "s", "=", "7", ")", "\n", "\n", "plt", ".", "title", "(", "self", ".", "_plot_title", ",", "fontsize", "=", "9", ",", "loc", "=", "'center'", ")", "\n", "\n", "fileName", "=", "\"pca2d_\"", "+", "tensor_name", "+", "\"_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "+", "\"_\"", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "\n", "plt", ".", "savefig", "(", "self", ".", "_dirName", "+", "'/'", "+", "fileName", "+", "'.png'", ")", "# , bbox_inches='tight'", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "\n", "# TODO this needs to be replaced", "\n", "\n", "# save txt file", "\n", "data", "=", "np", ".", "hstack", "(", "[", "pca", ",", "np", ".", "array", "(", "repeated_labels", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ")", "\n", "np", ".", "savetxt", "(", "self", ".", "_dirName", "+", "'/'", "+", "fileName", "+", "'.txt'", ",", "data", ",", "fmt", "=", "'%.3f %.3f %i'", ",", "newline", "=", "'\\r\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.plot": [[168, 170], ["None"], "methods", ["None"], ["", "", "", "def", "plot", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_id": [[60, 79], ["super().create_id", "VAE.VAE._network.create_id", "VAE.VAE._cost_function.create_id", "str", "len", "VAE.VAE.create_custom_regularizers_id", "len", "VAE.VAE.create_custom_regularizers_id", "[].keys", "[].keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.create_custom_regularizers_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "self", ".", "launchable_name", "\n", "\n", "# add to the ID the information of the cost function", "\n", "_id", "+=", "'-c'", "+", "self", ".", "_cost_function", ".", "create_id", "(", "self", ".", "_opts", "[", "\"cost_function\"", "]", "[", "1", "]", ")", "\n", "\n", "_id", "+=", "'-s'", "+", "str", "(", "self", ".", "_opts", "[", "\"samples\"", "]", ")", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "network_id", "=", "self", ".", "_network", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "+", "network_id", "\n", "if", "\"encoder\"", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", "and", "len", "(", "self", ".", "_opts", "[", "\"regularizers\"", "]", "[", "\"encoder\"", "]", ".", "keys", "(", ")", ")", ">", "0", ":", "\n", "            ", "_id", "+=", "'-crE'", "+", "self", ".", "create_custom_regularizers_id", "(", "\"encoder\"", ")", "\n", "", "if", "\"decoder\"", "in", "self", ".", "_opts", "[", "\"regularizers\"", "]", "and", "len", "(", "self", ".", "_opts", "[", "\"regularizers\"", "]", "[", "\"decoder\"", "]", ".", "keys", "(", ")", ")", ">", "0", ":", "\n", "            ", "_id", "+=", "'-crD'", "+", "self", ".", "create_custom_regularizers_id", "(", "\"decoder\"", ")", "\n", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.__init__": [[80, 104], ["VAENetwork.VAENetwork.VAENetwork", "argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "argo.core.network.AbstractAutoEncoder.AbstractAutoEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.CostFunctions.CostFunctions.instantiate_cost_function", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "\n", "# notice that in the following opts is used, and not self._opts, until the", "\n", "# parent constructor is called", "\n", "\n", "# NB need to create the network before the super init because id generation depends on the network", "\n", "        ", "self", ".", "_network", "=", "VAENetwork", "(", "opts", ",", "\"vae_network\"", ",", "seed", "=", "seed", ")", "\n", "self", ".", "_cost_function", "=", "CostFunctions", ".", "instantiate_cost_function", "(", "opts", "[", "\"cost_function\"", "]", ",", "module_path", "=", "\"vae\"", ")", "\n", "\n", "self", ".", "n_z_samples", "=", "self", ".", "_network", ".", "n_z_samples", "\n", "\n", "# # replicate x", "\n", "# self.x_replicate = {}", "\n", "# self.x_target_replicate = {}", "\n", "\n", "# important nodes", "\n", "self", ".", "_approximate_posterior", "=", "None", "\n", "self", ".", "_model_visible", "=", "None", "\n", "self", ".", "x_reconstruction_node", "=", "None", "\n", "self", ".", "samples", "=", "None", "\n", "\n", "self", ".", "mask", "=", "None", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks": [[105, 294], ["super().create_hooks", "tensorflow.cast", "super().create_hooks.append", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "config.get", "tensorflow.reduce_prod", "tensorflow.log", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook", "super().create_hooks.append", "super().create_hooks.append", "VAE.VAE._create_importance_sampling_node", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "super().create_hooks.append", "tensorflow.log", "VAEImagesReconstructHook.VAEImagesReconstructHook.VAEImagesReconstructHook", "argo.core.hooks.ImagesGenerateHook.ImagesGenerateHook", "isinstance", "super().create_hooks.append", "TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook.TwoDimPCALatentVariablesHook", "PCALatentVariablesHook.PCALatentVariablesHook.PCALatentVariablesHook", "VAELinearInterpolationHook.VAELinearInterpolationHook.VAELinearInterpolationHook", "argo.core.hooks.LatentVarsClassificationHook.LatentVarsClassificationHook", "super().create_hooks.append", "LatentTraversalsHook.LatentTraversalsHook.LatentTraversalsHook", "argo.core.hooks.LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook", "tensorflow.shape", "argo.core.hooks.ImportanceSamplingHook.ImportanceSamplingHook", "argo.core.hooks.FrechetInceptionDistanceHook.FrechetInceptionDistanceHook", "list", "tensorflow.concat", "tensorflow.concat", "list", "list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_hooks", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._create_importance_sampling_node", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "create_hooks", "(", "self", ",", "config", ")", ":", "\n", "        ", "hooks", "=", "super", "(", ")", ".", "create_hooks", "(", "config", ")", "\n", "\n", "#LOGGING HOOKS", "\n", "\n", "# TODO here I am ignoring the number of channels, is it correct? (Luigi).", "\n", "# TODO The channels seem to be included with np.prod...", "\n", "# dim_with_channels = np.prod(self.x_shape[\"train\"])", "\n", "\n", "dim_with_channels", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "self", ".", "raw_x", ")", "[", "1", ":", "]", ")", ",", "tf", ".", "float32", ")", "\n", "# TODO the two shapes could be different, maybe use tf.shape(self.raw_x) (Riccardo)", "\n", "# dim_with_channels = np.prod(self.x_shape[\"train\"])", "\n", "# dim_with_channels = np.prod(self.x_shape[\"eval\"])", "\n", "\n", "# TODO I think this formula is still not correct, it is using loss (which inside has beta and warm_up), it is more correct than the one before maybe", "\n", "# check https://www.reddit.com/r/MachineLearning/comments/56m5o2/discussion_calculation_of_bitsdims/", "\n", "bits_dim", "=", "(", "(", "self", ".", "loss", "/", "dim_with_channels", ")", "+", "tf", ".", "log", "(", "256.0", "/", "2.0", ")", ")", "/", "tf", ".", "log", "(", "2.0", ")", "\n", "\n", "tensors_to_average", "=", "[", "\n", "[", "[", "-", "self", ".", "loss", "]", ",", "\n", "[", "bits_dim", "]", "\n", "]", ",", "\n", "self", ".", "loss_nodes_to_log", "\n", "]", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "\"LB_log(p)\"", "]", ",", "\n", "[", "\"b/d\"", "]", "\n", "]", ",", "\n", "self", ".", "loss_nodes_to_log_names", "\n", "]", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\"fileName\"", ":", "\"loss\"", "}", ",", "\n", "{", "\"fileName\"", ":", "\"bits_dim\"", "}", "\n", "]", ",", "\n", "self", ".", "loss_nodes_to_log_filenames", "\n", "]", "\n", "#[*[name for name in self.loss_nodes_to_track]],", "\n", "\n", "hooks", ".", "append", "(", "LoggingMeanTensorsHook", "(", "model", "=", "self", ",", "\n", "fileName", "=", "\"log\"", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "tensors_to_average", ",", "\n", "tensors_to_average_names", "=", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", "=", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "self", ".", "_n_steps_stats", ",", "\n", "tensorboard_dir", "=", "self", ".", "_tensorboard_dir", ",", "\n", "trigger_summaries", "=", "config", "[", "\"save_summaries\"", "]", ",", "\n", "plot_offset", "=", "self", ".", "_plot_offset", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "# if you want to remove some dataset from here, make support to specify from conf on which datasets to log, if in doubt ask me please. Riccardo", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", ",", "TEST", "]", ",", "\n", "time_reference", "=", "self", ".", "_time_reference_str", "\n", ")", "\n", ")", "\n", "\n", "\n", "kwargs", "=", "config", ".", "get", "(", "\"ImagesReconstructHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "VAEImagesReconstructHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"ImagesGenerateHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "ImagesGenerateHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"ImportanceSamplingHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "# create the IS node only when needed, this function fails when z is fully convolutional... (Riccardo)", "\n", "            ", "self", ".", "importance_sampling_node", "=", "self", ".", "_create_importance_sampling_node", "(", ")", "\n", "\n", "if", "not", "isinstance", "(", "kwargs", ",", "list", ")", ":", "\n", "                ", "kwargs", "=", "[", "kwargs", "]", "\n", "", "for", "kw", "in", "kwargs", ":", "\n", "                ", "kws", "=", "{", "**", "self", ".", "_plot_model_hooks_kwargs", ",", "\n", "**", "kw", "}", "\n", "hooks", ".", "append", "(", "ImportanceSamplingHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors_to_average", "=", "[", "self", ".", "importance_sampling_node", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kws", "\n", ")", "\n", ")", "\n", "\n", "", "", "kwargs", "=", "config", ".", "get", "(", "\"TwoDimPCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "TwoDimPCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "z", "]", "+", "list", "(", "self", ".", "_approximate_posterior_params", ")", ",", "\n", "tensors_names", "=", "[", "'z'", ",", "\n", "'mu'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"PCALatentVariablesHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_plot_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "PCALatentVariablesHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "z", ",", "\n", "self", ".", "_approximate_posterior_params", "[", "0", "]", "]", ",", "\n", "tensors_names", "=", "[", "'z'", ",", "\n", "'mu'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", "\n", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"VAELinearInterpolationHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "VAELinearInterpolationHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"LatentVarsClassificationHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_plot_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "LatentVarsClassificationHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "z", ",", "\n", "self", ".", "_approximate_posterior_params", "[", "0", "]", ",", "\n", "tf", ".", "concat", "(", "list", "(", "self", ".", "_approximate_posterior_params", ")", ",", "axis", "=", "1", ")", "]", ",", "\n", "tensors_names", "=", "[", "'z'", ",", "\n", "'mu'", ",", "\n", "'mu_cov'", "]", ",", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "# don't change the order (Luigi)", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "\n", "# frechet inception distance", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"FrechetInceptionDistanceHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "for", "kw", "in", "kwargs", ":", "\n", "                ", "kws", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kw", "}", "\n", "hooks", ".", "append", "(", "FrechetInceptionDistanceHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kws", ")", "\n", ")", "\n", "\n", "# latent traversals hook", "\n", "", "", "kwargs", "=", "config", ".", "get", "(", "\"LatentTraversalsHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "LatentTraversalsHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "", "kwargs", "=", "config", ".", "get", "(", "\"LatentVarsGeometricClassificationHook\"", ",", "None", ")", "\n", "if", "kwargs", ":", "\n", "            ", "kwargs", "=", "{", "**", "self", ".", "_default_model_hooks_kwargs", ",", "\n", "**", "kwargs", "}", "\n", "hooks", ".", "append", "(", "LatentVarsGeometricClassificationHook", "(", "model", "=", "self", ",", "\n", "dirName", "=", "self", ".", "dirName", ",", "\n", "tensors", "=", "[", "self", ".", "z", ",", "\n", "self", ".", "_approximate_posterior_params", "[", "0", "]", ",", "\n", "tf", ".", "concat", "(", "list", "(", "self", ".", "_approximate_posterior_params", ")", ",", "\n", "axis", "=", "1", ")", "]", ",", "\n", "tensors_names", "=", "[", "'z'", ",", "\n", "'mu'", ",", "\n", "'mu_cov'", "]", ",", "\n", "\n", "datasets_keys", "=", "[", "TRAIN", ",", "VALIDATION", ",", "TEST", "]", ",", "\n", "**", "kwargs", ")", "\n", ")", "\n", "\n", "", "return", "hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_input_nodes": [[295, 313], ["super().create_input_nodes", "isinstance", "hasattr", "tensorflow.slice", "tensorflow.slice", "tensorflow.slice", "tensorflow.slice", "VAE.VAE.x.shape[].as_list", "VAE.VAE.x.shape[].as_list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.create_input_nodes"], ["", "def", "create_input_nodes", "(", "self", ",", "dataset", ")", ":", "\n", "\n", "        ", "super", "(", "VAE", ",", "self", ")", ".", "create_input_nodes", "(", "dataset", ")", "\n", "\n", "# check if the dataset specifies a mask (Alexandra); so far, implemented only in ELBO", "\n", "if", "isinstance", "(", "self", ".", "_cost_function", ",", "ELBO", ")", "and", "hasattr", "(", "dataset", ",", "'use_mask'", ")", ":", "\n", "\n", "            ", "init_dims", "=", "[", "0", "]", "+", "[", "0", "for", "s", "in", "self", ".", "x", ".", "shape", "[", "1", ":", "-", "1", "]", ".", "as_list", "(", ")", "]", "\n", "end_dims", "=", "[", "-", "1", "]", "+", "[", "-", "1", "for", "s", "in", "self", ".", "x", ".", "shape", "[", "1", ":", "-", "1", "]", ".", "as_list", "(", ")", "]", "\n", "\n", "# take it from datasets_nodes[0][0] so that no perturbation is applied", "\n", "# and raw_x can be modified by removing the mask", "\n", "# see create_datasets_with_handles in TFDeepLearningModel.py (Luigi)", "\n", "self", ".", "mask", "=", "tf", ".", "slice", "(", "self", ".", "datasets_nodes", "[", "0", "]", "[", "0", "]", ",", "init_dims", "+", "[", "0", "]", ",", "end_dims", "+", "[", "1", "]", ")", "\n", "self", ".", "x", "=", "tf", ".", "slice", "(", "self", ".", "x", ",", "init_dims", "+", "[", "1", "]", ",", "end_dims", "+", "[", "-", "1", "]", ")", "\n", "\n", "self", ".", "raw_x", "=", "tf", ".", "slice", "(", "self", ".", "raw_x", ",", "init_dims", "+", "[", "1", "]", ",", "end_dims", "+", "[", "-", "1", "]", ")", "\n", "self", ".", "x_target", "=", "tf", ".", "slice", "(", "self", ".", "x_target", ",", "init_dims", "+", "[", "1", "]", ",", "end_dims", "+", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_network": [[315, 332], ["VAE.VAE._network", "tensorflow.identity", "VAE.VAE._approximate_posterior.params", "VAE.VAE._model_visible.reconstruction_node"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node"], ["", "", "def", "create_network", "(", "self", ")", ":", "\n", "\n", "# create autoencoder network", "\n", "        ", "self", ".", "_approximate_posterior", ",", "self", ".", "z", ",", "self", ".", "_model_visible", ",", "self", ".", "_prior", ",", "self", ".", "samples", "=", "self", ".", "_network", "(", "self", ".", "x", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n", "self", ".", "x_reconstruction_node", "=", "tf", ".", "identity", "(", "self", ".", "_model_visible", ".", "reconstruction_node", "(", ")", ",", "name", "=", "\"reconstruction_node\"", ")", "\n", "# NB: I need to create the node now, otherwise the call to mean() will generate an error", "\n", "#pdb.set_trace()", "\n", "\n", "# since the graph will be finalized", "\n", "\n", "# old implemenation, depending on the GaussianDiagonal in the latent", "\n", "#self._gaussian_model_latent_mean = self._gaussian_model_latent.mean()", "\n", "#self._gaussian_model_latent_cov = tf.square(self._gaussian_model_latent.stddev())", "\n", "\n", "# new method", "\n", "self", ".", "_approximate_posterior_params", "=", "self", ".", "_approximate_posterior", ".", "params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._create_importance_sampling_node": [[340, 405], ["numpy.prod", "VAE.VAE._prior.log_prob", "tensorflow.reshape", "tensorflow.tile", "VAE.VAE._model_visible.log_prob", "tensorflow.reshape", "tensorflow.reduce_logsumexp", "len", "tensorflow.reshape", "VAE.VAE._approximate_posterior.log_prob", "tensorflow.reshape", "VAE.VAE._approximate_posterior.log_prob", "tensorflow.reshape", "VAE.VAE.x.shape.as_list", "len", "tensorflow.reduce_sum", "VAE.VAE._model_visible.batch_shape.as_list", "VAE.VAE._approximate_posterior.event_shape.as_list", "VAE.VAE._approximate_posterior.batch_shape.as_list", "VAE.VAE._approximate_posterior.event_shape.as_list", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "_create_importance_sampling_node", "(", "self", ")", ":", "\n", "\n", "# create the node for the importance sampling estimator of lop p", "\n", "# ISSUE", "\n", "#pdb.set_trace()", "\n", "#dim_z = self._approximate_posterior.batch_shape.as_list()[1]", "\n", "\n", "        ", "dim_x", "=", "np", ".", "prod", "(", "self", ".", "_model_visible", ".", "batch_shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "\n", "if", "len", "(", "self", ".", "_approximate_posterior", ".", "event_shape", ".", "as_list", "(", ")", ")", "==", "0", ":", "\n", "# Gaussian Diagonal           ", "\n", "            ", "dim_z", "=", "self", ".", "_approximate_posterior", ".", "batch_shape", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "z_reshaped", "=", "tf", ".", "reshape", "(", "self", ".", "z", ",", "[", "self", ".", "n_z_samples", ",", "-", "1", ",", "dim_z", "]", ")", "\n", "log_pdf_latent_reshaped", "=", "self", ".", "_approximate_posterior", ".", "log_prob", "(", "z_reshaped", ")", "\n", "\n", "\n", "", "else", ":", "\n", "# von Mises", "\n", "\n", "# differently from th Gaussian, we have only one pdf", "\n", "# (no factorization over the latent variable) thus we can force in the reshape", "\n", "# dim_z = 1", "\n", "            ", "dim_z", "=", "1", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "#log_pdf_latent_reshaped = tf.reshape(self._approximate_posterior.log_prob(self.z), [self.n_z_samples, -1, dim_z])", "\n", "\n", "# fixed da Norbert, previosly it was ", "\n", "# z_reshaped = tf.reshape(self.z, [self.n_z_samples, -1])", "\n", "dim_z_of_prior", "=", "self", ".", "_approximate_posterior", ".", "event_shape", ".", "as_list", "(", ")", "[", "0", "]", "\n", "z_reshaped", "=", "tf", ".", "reshape", "(", "self", ".", "z", ",", "[", "self", ".", "n_z_samples", ",", "-", "1", ",", "dim_z_of_prior", "]", ")", "\n", "\n", "\n", "log_pdf_latent_reshaped", "=", "self", ".", "_approximate_posterior", ".", "log_prob", "(", "z_reshaped", ")", "\n", "log_pdf_latent_reshaped", "=", "tf", ".", "reshape", "(", "log_pdf_latent_reshaped", ",", "[", "self", ".", "n_z_samples", ",", "-", "1", ",", "dim_z", "]", ")", "\n", "\n", "# here the size is [n_z_samples x batch_size , dim_z]", "\n", "", "log_pdf_prior", "=", "self", ".", "_prior", ".", "log_prob", "(", "self", ".", "z", ")", "\n", "log_pdf_prior_reshaped", "=", "tf", ".", "reshape", "(", "log_pdf_prior", ",", "[", "self", ".", "n_z_samples", ",", "-", "1", ",", "dim_z", "]", ")", "\n", "\n", "\n", "# can I avoid replicate? maybe not..", "\n", "input_shape", "=", "self", ".", "x", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "ones", "=", "[", "1", "]", "*", "len", "(", "input_shape", ")", "\n", "x_replicate", "=", "tf", ".", "tile", "(", "self", ".", "x", ",", "[", "self", ".", "n_z_samples", "]", "+", "ones", ")", "\n", "\n", "log_pdf_conditional", "=", "self", ".", "_model_visible", ".", "log_prob", "(", "x_replicate", ")", "\n", "log_pdf_conditional_reshaped", "=", "tf", ".", "reshape", "(", "log_pdf_conditional", ",", "[", "self", ".", "n_z_samples", ",", "-", "1", ",", "dim_x", "]", ")", "\n", "\n", "#log_pdf_latent = tf.reshape(log_pdf_latent_reshaped, [-1, dim_z])", "\n", "\n", "# ADD HERE", "\n", "#log_pdf_latent_reshaped = tf.reshape(log_pdf_latent_reshaped, tf.shape(log_pdf_prior_reshaped))", "\n", "\n", "# summing log p over all variables (visible and hidden)", "\n", "sum_logs_probs", "=", "tf", ".", "reduce_sum", "(", "log_pdf_conditional_reshaped", ",", "axis", "=", "2", ")", "+", "tf", ".", "reduce_sum", "(", "log_pdf_prior_reshaped", ",", "axis", "=", "2", ")", "-", "tf", ".", "reduce_sum", "(", "log_pdf_latent_reshaped", ",", "axis", "=", "2", ")", "\n", "\n", "#batch_reshape = [self._model.n_z_samples, -1] + self._model._model_visible.batch_shape.as_list()[1:]", "\n", "#sum_logs_probs = tf.reshape(sum_logs_probs, batch_reshape)", "\n", "#logs_probs = tf.reduce_sum(sum_logs_probs, axis=2)", "\n", "logp_is", "=", "tf", ".", "reduce_logsumexp", "(", "sum_logs_probs", ",", "axis", "=", "0", ")", "\n", "\n", "return", "logp_is", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.create_loss": [[406, 412], ["VAE.VAE._cost_function"], "methods", ["None"], ["", "def", "create_loss", "(", "self", ")", ":", "\n", "\n", "#TODO move up in AbstractAutoEncoder.", "\n", "# A TFDeepLearningModel model should be free to specify a model dependent loss..", "\n", "# compute the cost function, passing the model as a parameter", "\n", "        ", "self", ".", "loss", ",", "self", ".", "loss_nodes_to_log", ",", "self", ".", "loss_nodes_to_log_names", ",", "self", ".", "loss_nodes_to_log_filenames", "=", "self", ".", "_cost_function", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.encode": [[413, 428], ["sess.run", "VAE.VAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "encode", "(", "self", ",", "X", ",", "stp", "=", "False", ",", "sess", "=", "None", ",", "y", "=", "None", ")", ":", "\n", "        ", "\"\"\"Encode data by mapping it into the latent space.\"\"\"", "\n", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "if", "stp", ":", "\n", "            ", "input", "=", "self", ".", "raw_x", "\n", "", "else", ":", "\n", "            ", "input", "=", "self", ".", "x", "\n", "\n", "", "feed_dict", "=", "{", "self", ".", "n_z_samples", ":", "1", ",", "input", ":", "X", "}", "if", "y", "is", "None", "else", "{", "self", ".", "n_z_samples", ":", "1", ",", "input", ":", "X", ",", "self", ".", "y", ":", "y", "}", "\n", "\n", "return", "sess", ".", "run", "(", "[", "self", ".", "z", ",", "\n", "self", ".", "_approximate_posterior_params", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.decode": [[430, 443], ["sess.run", "VAE.VAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "decode", "(", "self", ",", "Z", ",", "sess", "=", "None", ",", "mask", "=", "None", ",", "y", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode latent vectors in input data.\"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "feed_dict", "=", "{", "self", ".", "z", ":", "Z", "}", "if", "y", "is", "None", "else", "{", "self", ".", "z", ":", "Z", ",", "self", ".", "y", ":", "y", "}", "\n", "\n", "image", "=", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "if", "self", ".", "mask", "is", "None", ":", "\n", "            ", "return", "image", "\n", "", "else", ":", "\n", "            ", "return", "(", "mask", "*", "(", "image", "+", "1", ")", "/", "2", ")", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.generate": [[444, 457], ["sess.run", "VAE.VAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "", "def", "generate", "(", "self", ",", "batch_size", "=", "1", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Generate data by sampling from latent space.\n\n        \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "# old implementation", "\n", "#prior_samples_np = sess.run(self._prior_samples, feed_dict = {self.n_z_samples : batch_size})", "\n", "\n", "#return sess.run(self.x_reconstruction_node, feed_dict = {self.z : prior_samples_np})", "\n", "\n", "# new faster implementation", "\n", "return", "sess", ".", "run", "(", "self", ".", "samples", ",", "feed_dict", "=", "{", "self", ".", "n_z_samples", ":", "batch_size", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE.reconstruct": [[458, 470], ["sess.run", "VAE.VAE.get_raw_session"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "reconstruct", "(", "self", ",", "X", ",", "stp", "=", "False", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\" Use VAE to reconstruct given data. \"\"\"", "\n", "sess", "=", "sess", "or", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "if", "stp", ":", "\n", "            ", "input", "=", "self", ".", "raw_x", "\n", "", "else", ":", "\n", "            ", "input", "=", "self", ".", "x", "\n", "\n", "#if self.binary:", "\n", "", "return", "sess", ".", "run", "(", "self", ".", "x_reconstruction_node", ",", "\n", "feed_dict", "=", "{", "self", ".", "n_z_samples", ":", "1", ",", "input", ":", "X", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._compute_linear_interpolation": [[472, 491], ["VAE.VAE.encode", "VAE.VAE.encode", "VAE.VAE.decode", "VAE.VAE.decode", "VAE.VAE.get_raw_session", "numpy.repeat", "zip", "numpy.linspace", "zip", "numpy.linspace", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "_compute_linear_interpolation", "(", "self", ",", "couples_of_images", ",", "n_images", ",", "session", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "\n", "        ", "if", "session", "is", "None", ":", "\n", "            ", "session", "=", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "", "zs1", ",", "(", "means1", ",", "_", ")", "=", "self", ".", "encode", "(", "[", "i", "[", "0", "]", "for", "i", "in", "couples_of_images", "]", ",", "sess", "=", "session", ")", "\n", "zs2", ",", "(", "means2", ",", "_", ")", "=", "self", ".", "encode", "(", "[", "i", "[", "1", "]", "for", "i", "in", "couples_of_images", "]", ",", "sess", "=", "session", ")", "\n", "\n", "interpolations_means", "=", "[", "alpha", "*", "a", "+", "(", "1", "-", "alpha", ")", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "means1", ",", "means2", ")", "for", "alpha", "in", "np", ".", "linspace", "(", "0", ",", "1", ",", "n_images", "+", "2", ")", "]", "\n", "\n", "interpolations_zs", "=", "[", "alpha", "*", "np", ".", "array", "(", "z1", ")", "+", "(", "1", "-", "alpha", ")", "*", "np", ".", "array", "(", "z2", ")", "for", "z1", ",", "z2", "in", "zip", "(", "zs1", ",", "zs2", ")", "for", "alpha", "in", "np", ".", "linspace", "(", "0", ",", "1", ",", "n_images", "+", "2", ")", "]", "\n", "\n", "# create array of masks for all interpolations, if needed", "\n", "masks", "=", "np", ".", "repeat", "(", "mask", ",", "n_images", "+", "2", ",", "axis", "=", "0", ")", "if", "mask", "is", "not", "None", "else", "None", "\n", "\n", "reconstructed_interpolations_means", "=", "self", ".", "decode", "(", "interpolations_means", ",", "session", ",", "mask", "=", "masks", ")", "\n", "reconstructed_interpolations_zs", "=", "self", ".", "decode", "(", "interpolations_zs", ",", "session", ",", "mask", "=", "masks", ")", "\n", "\n", "return", "reconstructed_interpolations_means", ",", "reconstructed_interpolations_zs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._compute_fisher_rao_interpolation": [[493, 515], ["VAE.VAE.encode", "VAE.VAE.encode", "VAE.VAE._gaussian_interpolations", "interpolations_fisher_rao_means.reshape.reshape.reshape", "VAE.VAE.decode", "VAE.VAE.get_raw_session", "numpy.repeat", "zip", "numpy.linspace"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._gaussian_interpolations", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel.get_raw_session"], ["", "def", "_compute_fisher_rao_interpolation", "(", "self", ",", "couples_of_images", ",", "n_images", ",", "session", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "\n", "        ", "if", "session", "is", "None", ":", "\n", "            ", "session", "=", "self", ".", "get_raw_session", "(", ")", "\n", "\n", "", "_", ",", "(", "means1", ",", "covs1", ")", "=", "self", ".", "encode", "(", "[", "i", "[", "0", "]", "for", "i", "in", "couples_of_images", "]", ",", "sess", "=", "session", ")", "\n", "_", ",", "(", "means2", ",", "covs2", ")", "=", "self", ".", "encode", "(", "[", "i", "[", "1", "]", "for", "i", "in", "couples_of_images", "]", ",", "sess", "=", "session", ")", "\n", "\n", "\n", "interpolations_means", "=", "[", "alpha", "*", "a", "+", "(", "1", "-", "alpha", ")", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "means1", ",", "means2", ")", "for", "alpha", "in", "np", ".", "linspace", "(", "0", ",", "1", ",", "n_images", "+", "2", ")", "]", "\n", "\n", "\n", "interpolations_fisher_rao_means", ",", "interpolations_fisher_rao_covs", "=", "self", ".", "_gaussian_interpolations", "(", "means1", ",", "covs1", ",", "means2", ",", "covs2", ",", "n_images", ")", "\n", "\n", "interpolations_fisher_rao_means", "=", "interpolations_fisher_rao_means", ".", "reshape", "(", "-", "1", ",", "interpolations_fisher_rao_means", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# same as for linear interpolations", "\n", "masks", "=", "np", ".", "repeat", "(", "mask", ",", "n_images", "+", "2", ",", "axis", "=", "0", ")", "if", "mask", "is", "not", "None", "else", "None", "\n", "\n", "reconstructed_interpolations_fisher_rao", "=", "self", ".", "decode", "(", "interpolations_fisher_rao_means", ",", "session", ",", "mask", "=", "masks", ")", "\n", "\n", "return", "reconstructed_interpolations_fisher_rao", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAE.VAE._gaussian_interpolations": [[516, 622], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "numpy.allclose", "pdb.set_trace", "numpy.allclose", "pdb.set_trace", "numpy.allclose", "pdb.set_trace", "numpy.allclose", "pdb.set_trace", "range", "numpy.sqrt", "numpy.sqrt", "numpy.isclose", "numpy.arctan", "numpy.arctan", "range", "range", "range", "numpy.sqrt", "numpy.sqrt", "numpy.flip", "numpy.flip", "numpy.flip", "numpy.flip", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "def", "_gaussian_interpolations", "(", "self", ",", "mean_a", ",", "cov_a", ",", "mean_b", ",", "cov_b", ",", "steps", ")", ":", "\n", "\n", "        ", "n_points", "=", "mean_a", ".", "shape", "[", "0", "]", "\n", "dim", "=", "mean_a", ".", "shape", "[", "1", "]", "\n", "s", "=", "steps", "+", "2", "\n", "\n", "# figure to debug", "\n", "#plt.figure()", "\n", "\n", "mean_t", "=", "np", ".", "zeros", "(", "(", "n_points", ",", "s", ",", "dim", ")", ")", "\n", "cov_t", "=", "np", ".", "zeros", "(", "(", "n_points", ",", "s", ",", "dim", ")", ")", "\n", "cov_t_e", "=", "np", ".", "zeros", "(", "(", "n_points", ",", "s", ",", "dim", ")", ")", "\n", "cov_t_m", "=", "np", ".", "zeros", "(", "(", "n_points", ",", "s", ",", "dim", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_points", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "dim", ")", ":", "\n", "\n", "                ", "if", "mean_a", "[", "j", ",", "i", "]", "<", "mean_b", "[", "j", ",", "i", "]", ":", "\n", "                    ", "mean1", "=", "mean_b", "[", "j", ",", "i", "]", "\n", "mean2", "=", "mean_a", "[", "j", ",", "i", "]", "\n", "cov1", "=", "cov_b", "[", "j", ",", "i", "]", "\n", "cov2", "=", "cov_a", "[", "j", ",", "i", "]", "\n", "flip", "=", "1", "\n", "", "else", ":", "\n", "                    ", "mean1", "=", "mean_a", "[", "j", ",", "i", "]", "\n", "mean2", "=", "mean_b", "[", "j", ",", "i", "]", "\n", "cov1", "=", "cov_a", "[", "j", ",", "i", "]", "\n", "cov2", "=", "cov_b", "[", "j", ",", "i", "]", "\n", "flip", "=", "0", "\n", "\n", "# lines through two points", "\n", "# https://bobobobo.wordpress.com/2008/01/07/solving-linear-equations-ax-by-c-0/", "\n", "", "a", "=", "np", ".", "sqrt", "(", "cov1", ")", "-", "np", ".", "sqrt", "(", "cov2", ")", "\n", "b", "=", "mean2", "-", "mean1", "\n", "c", "=", "mean1", "*", "np", ".", "sqrt", "(", "cov2", ")", "-", "mean2", "*", "np", ".", "sqrt", "(", "cov1", ")", "\n", "mean", "=", "(", "mean1", "+", "mean2", ")", "/", "2", "\n", "sqrt_cov", "=", "(", "np", ".", "sqrt", "(", "cov1", ")", "+", "np", ".", "sqrt", "(", "cov2", ")", ")", "/", "2", "\n", "\n", "# line orthogonal to a line through a point", "\n", "# https://math.stackexchange.com/questions/646420/find-the-vector-equation-of-a-line-perpendicular-to-the-plane", "\n", "t", "=", "-", "sqrt_cov", "/", "b", "\n", "mean_0", "=", "t", "*", "a", "+", "mean", "\n", "sqrt_cov_0", "=", "0", "\n", "\n", "r", "=", "np", ".", "sqrt", "(", "cov1", "+", "(", "mean_0", "-", "mean1", ")", "**", "2", ")", "\n", "r_bis", "=", "np", ".", "sqrt", "(", "cov2", "+", "(", "mean_0", "-", "mean2", ")", "**", "2", ")", "\n", "\n", "assert", "np", ".", "isclose", "(", "r", ",", "r_bis", ",", "atol", "=", "1e-05", ")", ",", "\"assert failed\"", "\n", "\n", "# http://www.nabla.hr/PC-RectPolarCooSys4.htm", "\n", "theta1", "=", "np", ".", "arctan", "(", "np", ".", "sqrt", "(", "cov1", ")", "/", "(", "mean1", "-", "mean_0", ")", ")", "\n", "if", "(", "mean1", "-", "mean_0", ")", "<", "0", ":", "\n", "                    ", "theta1", "+=", "np", ".", "pi", "\n", "", "theta2", "=", "np", ".", "arctan", "(", "np", ".", "sqrt", "(", "cov2", ")", "/", "(", "mean2", "-", "mean_0", ")", ")", "\n", "if", "(", "mean2", "-", "mean_0", ")", "<", "0", ":", "\n", "                    ", "theta2", "+=", "np", ".", "pi", "\n", "\n", "", "for", "k", "in", "range", "(", "s", ")", ":", "\n", "                    ", "t", "=", "theta2", "+", "k", "*", "(", "theta1", "-", "theta2", ")", "/", "(", "s", "-", "1", ")", "\n", "mean_t", "[", "j", ",", "k", ",", "i", "]", "=", "r", "*", "np", ".", "cos", "(", "t", ")", "+", "mean_0", "\n", "cov_t", "[", "j", ",", "k", ",", "i", "]", "=", "(", "r", "*", "np", ".", "sin", "(", "t", ")", ")", "**", "2", "\n", "\n", "", "if", "flip", ":", "\n", "                    ", "mean_t", "[", "j", ",", ":", ",", "i", "]", "=", "np", ".", "flip", "(", "mean_t", "[", "j", ",", ":", ",", "i", "]", ",", "axis", "=", "0", ")", "\n", "cov_t", "[", "j", ",", ":", ",", "i", "]", "=", "np", ".", "flip", "(", "cov_t", "[", "j", ",", ":", ",", "i", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "inv_cov1", "=", "1", "/", "cov1", "\n", "inv_cov2", "=", "1", "/", "cov2", "\n", "\n", "for", "k", "in", "range", "(", "s", ")", ":", "\n", "                    ", "inv_cov", "=", "inv_cov2", "+", "k", "*", "(", "inv_cov1", "-", "inv_cov2", ")", "/", "(", "s", "-", "1", ")", "\n", "cov_t_e", "[", "j", ",", "k", ",", "i", "]", "=", "1", "/", "inv_cov", "\n", "\n", "", "for", "k", "in", "range", "(", "s", ")", ":", "\n", "                    ", "cov", "=", "cov2", "+", "k", "*", "(", "cov1", "-", "cov2", ")", "/", "(", "s", "-", "1", ")", "\n", "cov_t_m", "[", "j", ",", "k", ",", "i", "]", "=", "cov", "\n", "\n", "", "if", "flip", ":", "\n", "                    ", "cov_t_e", "[", "j", ",", ":", ",", "i", "]", "=", "np", ".", "flip", "(", "cov_t_e", "[", "j", ",", ":", ",", "i", "]", ",", "axis", "=", "0", ")", "\n", "cov_t_m", "[", "j", ",", ":", ",", "i", "]", "=", "np", ".", "flip", "(", "cov_t_m", "[", "j", ",", ":", ",", "i", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "'''\n            # plot debug\n            plt.plot(mean_t[:,i],np.sqrt(cov_t[:,i]))\n            plt.plot(mean_t[:,i],np.sqrt(cov_t_e[:,i]),'--')\n            plt.plot(mean_t[:,i],np.sqrt(cov_t_m[:,i]),':')\n            plt.plot(mean1,np.sqrt(cov1),'xr')\n            plt.plot(mean2,np.sqrt(cov2),'xr')\n            '''", "\n", "\n", "\n", "", "'''\n        # plot debug\n        plt.ylim(ymin=0)\n        plt.axis('equal')\n        plt.savefig(\"geodesic.png\")\n\n        pdb.set_trace()\n        '''", "\n", "\n", "assert", "(", "np", ".", "allclose", "(", "mean_a", ",", "mean_t", "[", ":", ",", "-", "1", "]", ",", "atol", "=", "0.00001", ")", ")", ",", "pdb", ".", "set_trace", "(", ")", "\n", "assert", "(", "np", ".", "allclose", "(", "mean_b", ",", "mean_t", "[", ":", ",", "0", "]", ",", "atol", "=", "0.00001", ")", ")", ",", "pdb", ".", "set_trace", "(", ")", "\n", "assert", "(", "np", ".", "allclose", "(", "cov_a", ",", "cov_t", "[", ":", ",", "-", "1", "]", ",", "atol", "=", "0.00001", ")", ")", ",", "pdb", ".", "set_trace", "(", ")", "\n", "assert", "(", "np", ".", "allclose", "(", "cov_b", ",", "cov_t", "[", ":", ",", "0", "]", ",", "atol", "=", "0.00001", ")", ")", ",", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "return", "mean_t", ",", "cov_t", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavLatentPCAHook.WavLatentPCAHook.__init__": [[14, 38], ["argo.core.hooks.AbstractWavHook.AbstractWavHook.__init__", "datasets.Dataset.check_dataset_keys_not_loop", "tf_logging.info", "type", "list", "sample_indices_by_dataset.keys", "sample_indices_by_dataset.items", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "sample_indices_by_dataset", "=", "{", "\n", "VALIDATION", ":", "[", "]", "}", ",", "\n", "hop_legth_cqt", "=", "128", ",", "\n", "dataset_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "target_dim", "=", "1", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_dir_name", "=", "dirName", "+", "'/pca_latent'", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "dataset_keys", ",", "hop_legth_cqt", "=", "hop_legth_cqt", ",", "dirName", "=", "self", ".", "_dir_name", ")", "\n", "\n", "self", ".", "model_class_name", "=", "type", "(", "model", ")", ".", "__name__", "\n", "\n", "self", ".", "_sample_indices_by_dataset", "=", "sample_indices_by_dataset", "\n", "\n", "check_dataset_keys_not_loop", "(", "list", "(", "sample_indices_by_dataset", ".", "keys", "(", ")", ")", ")", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create WavLatentPCAHook for: \\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "ds_key", "+", "\": \"", "+", "\", \"", ".", "join", "(", "map", "(", "str", ",", "idxs", ")", ")", "for", "ds_key", ",", "idxs", "in", "sample_indices_by_dataset", ".", "items", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavLatentPCAHook.WavLatentPCAHook.before_training": [[39, 41], ["tf_logging.info"], "methods", ["None"], ["", "def", "before_training", "(", "self", ",", "session", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"WavLatentPCAHook before training\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavLatentPCAHook.WavLatentPCAHook.do_when_triggered": [[42, 78], ["tf_logging.info", "WavLatentPCAHook.WavLatentPCAHook.is_model_vae", "encode_function", "matplotlib.savefig", "tf_logging.info", "len", "sklearn.decomposition.PCA().fit_transform", "sklearn.decomposition.PCA().fit_transform.append", "matplotlib.plot", "len", "numpy.stack", "sklearn.decomposition.PCA().fit_transform", "matplotlib.clf", "matplotlib.plot", "matplotlib.savefig", "len", "ValueError", "numpy.squeeze", "sklearn.decomposition.PCA", "sklearn.decomposition.PCA", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.is_model_vae", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for WavLatentPCAHook\"", ")", "\n", "encode_function", "=", "self", ".", "_model", ".", "encode_return_covariance", "if", "self", ".", "is_model_vae", "(", ")", "else", "self", ".", "_model", ".", "encode", "\n", "\n", "for", "ds_key", "in", "self", ".", "_samples", ":", "\n", "            ", "indices", ",", "samples", "=", "self", ".", "_samples", "[", "ds_key", "]", "\n", "\n", "encode_tuple", "=", "encode_function", "(", "samples", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "\n", "if", "len", "(", "encode_tuple", ")", "==", "2", ":", "\n", "                ", "zs", ",", "x_shifted", "=", "encode_tuple", "\n", "hs", "=", "None", "\n", "covariance", "=", "None", "\n", "", "elif", "len", "(", "encode_tuple", ")", "==", "4", ":", "\n", "                ", "zs", ",", "hs", ",", "x_shifted", ",", "covariance", "=", "encode_tuple", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"This tuple should not be this length: {}\"", ".", "format", "(", "len", "(", "encode_tuple", ")", ")", ")", "\n", "\n", "# zs shape = (bs, time_len, channels)", "\n", "# write_file = '{}/pca_1_dim_{}_{}.txt'.format(self._dir_name, self._time_ref)", "\n", "", "pca_zs", "=", "[", "]", "\n", "for", "zs_i", "in", "zs", ":", "\n", "                ", "pca_zs_i", "=", "PCA", "(", "n_components", "=", "1", ")", ".", "fit_transform", "(", "zs_i", ")", "\n", "pca_zs", ".", "append", "(", "np", ".", "squeeze", "(", "pca_zs_i", ")", ")", "\n", "plt", ".", "plot", "(", "pca_zs_i", ",", "'-'", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "'{}/pca_1_dim_{}_{}_wave.jpg'", ".", "format", "(", "self", ".", "_dir_name", ",", "self", ".", "_time_ref", ",", "ds_key", ")", ")", "\n", "\n", "if", "len", "(", "pca_zs", ")", ">", "1", ":", "\n", "                ", "pca_zs", "=", "np", ".", "stack", "(", "pca_zs", ")", "\n", "pca_zs", "=", "PCA", "(", "n_components", "=", "2", ")", ".", "fit_transform", "(", "pca_zs", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "plot", "(", "pca_zs", "[", ":", ",", "0", "]", ",", "pca_zs", "[", ":", ",", "1", "]", ",", "'.'", ")", "\n", "plt", ".", "savefig", "(", "'{}/pca_1_dim_{}_{}_points.jpg'", ".", "format", "(", "self", ".", "_dir_name", ",", "self", ".", "_time_ref", ",", "ds_key", ")", ")", "\n", "\n", "", "tf_logging", ".", "info", "(", "\"finished with %s\"", "%", "ds_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.WavLatentPCAHook.WavLatentPCAHook.is_model_vae": [[79, 87], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "is_model_vae", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "model_class_name", "==", "'WavenetVAE'", ":", "\n", "            ", "return", "True", "\n", "", "elif", "self", ".", "model_class_name", "==", "'WavenetAE'", ":", "\n", "            ", "return", "False", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Please check function {} -- only support WavenetVAE and WavenetAE currently'", "\n", ".", "format", "(", "self", ".", "is_model_vae", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAENetwork.VAENetwork.create_id": [[32, 52], ["filter", "filter", "super().create_id", "argo.core.utils.argo_utils.get_method_id", "argo.core.utils.argo_utils.get_method_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "encoder_layers_ids", "=", "filter", "(", "None", ",", "\n", "[", "utils", ".", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"encoder\"", "]", "]", "\n", ")", "\n", "\n", "decoder_layers_ids", "=", "filter", "(", "None", ",", "\n", "[", "utils", ".", "get_method_id", "(", "layer_tuple", ")", "\n", "for", "layer_tuple", "in", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "[", "\"decoder\"", "]", "]", "\n", ")", "\n", "\n", "_id", "=", "'-ne_'", "+", "\"_\"", ".", "join", "(", "encoder_layers_ids", ")", "+", "'-nd_'", "+", "\"_\"", ".", "join", "(", "decoder_layers_ids", ")", "\n", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAENetwork.VAENetwork.__init__": [[54, 69], ["argo.core.network.ArgoStochasticNetworkWithDefaults.ArgoStochasticNetworkWithDefaults.__init__", "tensorflow.placeholder_with_default"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", "=", "\"vae_network\"", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"Short summary.\n\n        Args:\n            opts (dict): parameters of the task.\n            name (str): name of the Sonnet module.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "seed", ")", "\n", "\n", "network_architecture", "=", "self", ".", "_opts", "[", "\"network_architecture\"", "]", "\n", "# TODO-ARGO2 you might want to check here that the 2 architectures (encoder and decoder) expected are effectively passed", "\n", "self", ".", "_network_architecture", "=", "network_architecture", "\n", "\n", "self", ".", "n_z_samples", "=", "tf", ".", "placeholder_with_default", "(", "self", ".", "_opts", "[", "\"samples\"", "]", ",", "shape", "=", "(", ")", ",", "name", "=", "'n_z_samples'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.VAENetwork.VAENetwork._build": [[70, 145], ["argo.core.network.GeneralSonnetNetwork.GeneralSonnetNetwork", "VAENetwork.VAENetwork.encoder_module", "argo.core.network.GeneralSonnetNetwork.GeneralSonnetNetwork", "VAENetwork.VAENetwork.decoder_module", "VAENetwork.VAENetwork._approximate_posterior.default_prior", "VAENetwork.VAENetwork.sample", "VAENetwork.VAENetwork.decoder_module", "tensorflow.variable_scope", "tensorflow.reshape", "VAENetwork.VAENetwork._approximate_posterior.log_prob", "x.get_shape().as_list", "[].shape.as_list", "VAENetwork.VAENetwork.reconstruction_node", "len", "VAENetwork.VAENetwork._approximate_posterior.sample", "VAENetwork.VAENetwork._approximate_posterior.event_shape.as_list", "VAENetwork.VAENetwork._approximate_posterior.event_shape.as_list", "x.get_shape", "VAENetwork.VAENetwork._approximate_posterior.batch_shape.as_list", "VAENetwork.VAENetwork._approximate_posterior.params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "_build", "(", "self", ",", "x", ",", "is_training", "=", "False", ",", "network_str", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (tf.tensor): input node.\n            network_str (str): Optional network_str specifying the network we are going to build.\n                            It is used to set some specific collections for activity and contractive regularizers.\n\n        Returns:\n            tf distribution of the latent space\n            tf distribution on the visible neurons\n        \"\"\"", "\n", "\n", "# The create_graph function creates the graph which consists of 5 parts:", "\n", "# 1) the recognition network", "\n", "# 2) the model for the latent variables", "\n", "# 3) the sampling from the output of the recognition", "\n", "# 4) the generative network which takes the sampled points as input", "\n", "# 5) the likelihood model for the visible variables", "\n", "\n", "# 1) and 2)", "\n", "# import pdb;pdb.set_trace()", "\n", "self", ".", "encoder_module", "=", "GeneralSonnetNetwork", "(", "self", ".", "_network_defaults", "[", "\"activation\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", ",", "\n", "self", ".", "_network_architecture", "[", "\"encoder\"", "]", ",", "\n", "self", ".", "_stochastic_defaults", ",", "\n", "is_training", "=", "is_training", ",", "\n", "network_str", "=", "network_str", ",", "\n", "name", "=", "\"encoder\"", ")", "\n", "self", ".", "_approximate_posterior", "=", "self", ".", "encoder_module", "(", "x", ")", "\n", "# self._latent_vars_logger_class = self._gaussian_model_latent.get_vars_logger_class()", "\n", "\n", "# 3)", "\n", "with", "tf", ".", "variable_scope", "(", "'latent_sampling'", ")", ":", "\n", "# ISSUE", "\n", "#batch_reshape = [-1] + self._approximate_posterior.batch_shape.as_list()[1:]", "\n", "            ", "if", "len", "(", "self", ".", "_approximate_posterior", ".", "event_shape", ".", "as_list", "(", ")", ")", "==", "0", ":", "\n", "# Gaussian", "\n", "                ", "batch_reshape", "=", "[", "-", "1", "]", "+", "self", ".", "_approximate_posterior", ".", "batch_shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "# von Miser-Fisher", "\n", "                ", "batch_reshape", "=", "[", "-", "1", "]", "+", "self", ".", "_approximate_posterior", ".", "event_shape", ".", "as_list", "(", ")", "\n", "", "self", ".", "z", "=", "tf", ".", "reshape", "(", "self", ".", "_approximate_posterior", ".", "sample", "(", "self", ".", "n_z_samples", ")", ",", "batch_reshape", ")", "\n", "#pdb.set_trace()", "\n", "self", ".", "log_pdf_z", "=", "self", ".", "_approximate_posterior", ".", "log_prob", "(", "self", ".", "z", ")", "\n", "\n", "# I set the shape of the visible layer, to match the input shape", "\n", "", "input_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "self", ".", "_network_architecture", "[", "\"decoder\"", "]", "[", "-", "1", "]", "[", "1", "]", "[", "\"output_shape\"", "]", "=", "input_shape", "\n", "\n", "# 4) and 5)", "\n", "self", ".", "decoder_module", "=", "GeneralSonnetNetwork", "(", "self", ".", "_network_defaults", "[", "\"activation\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_init\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"weights_reg\"", "]", ",", "\n", "self", ".", "_network_defaults", "[", "\"bias_reg\"", "]", ",", "\n", "self", ".", "_network_architecture", "[", "\"decoder\"", "]", ",", "\n", "self", ".", "_stochastic_defaults", ",", "\n", "is_training", "=", "is_training", ",", "\n", "network_str", "=", "network_str", ",", "\n", "name", "=", "\"decoder\"", ")", "\n", "\n", "self", ".", "_model_visible", "=", "self", ".", "decoder_module", "(", "self", ".", "z", ")", "\n", "\n", "# create prior", "\n", "prior_shape", "=", "self", ".", "_approximate_posterior", ".", "params", "(", ")", "[", "0", "]", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "prior", "=", "self", ".", "_approximate_posterior", ".", "default_prior", "(", "prior_shape", ")", "\n", "prior_samples", "=", "prior", ".", "sample", "(", "self", ".", "n_z_samples", ")", "\n", "\n", "# attach the decoder to the samples", "\n", "samples", "=", "self", ".", "decoder_module", "(", "prior_samples", ")", "\n", "\n", "return", "self", ".", "_approximate_posterior", ",", "self", ".", "z", ",", "self", ".", "_model_visible", ",", "prior", ",", "samples", ".", "reconstruction_node", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_id": [[79, 106], ["os.path.basename", "transform.transform.get_transform_id", "attack.attack.get_attack_id", "super().create_id", "os.path.dirname", "str", "str", "str", "str", "AdversarialModel.AdversarialModel._opts.get"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_id", "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.get_attack_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "prediction_conf", ",", "prediction_global_step", "=", "self", ".", "_opts", "[", "\"prediction\"", "]", "\n", "# name of last directory of the conf", "\n", "_id_pred", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "dirname", "(", "prediction_conf", ")", ")", "\n", "if", "prediction_global_step", "is", "not", "None", ":", "\n", "            ", "_id_pred", "+=", "\"-gs\"", "+", "str", "(", "prediction_global_step", ")", "\n", "\n", "", "_id_transf", "=", "get_transform_id", "(", "*", "self", ".", "_opts", "[", "\"transform\"", "]", ")", "\n", "\n", "_id", "=", "_id_pred", "+", "\"/\"", "+", "\"r\"", "+", "_id_transf", "+", "\"/\"", "\n", "\n", "_id", "+=", "self", ".", "launchable_name", "\n", "\n", "#_id += \"-\" + get_attack_id(*opts[\"attack\"])", "\n", "_id", "+=", "get_attack_id", "(", "*", "self", ".", "_opts", "[", "\"attack\"", "]", ")", "\n", "#n_images is not something which affects performances but simply visualization of figures..it is not mandatory to put in id..", "\n", "# _id += \"-ni\" + str(self._opts[\"n_images\"])", "\n", "_id", "+=", "\"-as\"", "+", "str", "(", "self", ".", "_opts", ".", "get", "(", "\"n_samples_accuracy\"", ",", "1", ")", ")", "\n", "\n", "_id", "+=", "'-bs'", "+", "str", "(", "self", ".", "_opts", "[", "'batch_size'", "]", ")", "\n", "\n", "_id", "+=", "\"-ns\"", "+", "str", "(", "self", ".", "_opts", "[", "\"n_seeds\"", "]", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.__init__": [[107, 170], ["argo.core.Launchable.Launchable.__init__", "tensorflow.set_random_seed", "transform.transform.get_transform_id", "opts.get", "argo.core.utils.argo_utils.unpack_dict_of_lists", "list", "os.makedirs", "opts.get", "range", "AdversarialModel.AdversarialModel.create_id().split", "AdversarialModel.AdversarialModel.create_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.unpack_dict_of_lists", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ",", "**", "unused", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "seed", ")", "\n", "\n", "self", ".", "_gpu", "=", "gpu", "\n", "\n", "self", ".", "sess", "=", "None", "\n", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "self", ".", "batch_size", "=", "opts", "[", "\"batch_size\"", "]", "\n", "\n", "self", ".", "_attack_tuple", "=", "opts", "[", "\"attack\"", "]", "\n", "self", ".", "_transform_tuple", "=", "opts", "[", "\"transform\"", "]", "\n", "self", ".", "_transform_model_id", "=", "get_transform_id", "(", "*", "self", ".", "_transform_tuple", ")", "# transform create_id ??", "\n", "\n", "self", ".", "_n_samples_acc", "=", "opts", ".", "get", "(", "\"n_samples_accuracy\"", ",", "1", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "self", ".", "_transform_kwargs_accuracy", "=", "unpack_dict_of_lists", "(", "opts", "[", "\"transform_kwargs_accuracy\"", "]", ")", "\n", "if", "\"transform_accuracy\"", "in", "opts", ":", "\n", "            ", "self", ".", "_transform_accuracy_list", "=", "opts", "[", "\"transform_accuracy\"", "]", "[", "\"transf_list\"", "]", "\n", "# self._transform_accuracy_model_id = get_transform_id(*self._transform_accuracy_tuple)", "\n", "", "else", ":", "\n", "            ", "self", ".", "_transform_accuracy_list", "=", "None", "\n", "#self._model_type = opts[\"transform\"][0]  #'ae' or 'vae'      THIS IS THE SAME AS self.transform_name", "\n", "\n", "", "self", ".", "_attack_tuple", "=", "opts", "[", "\"attack\"", "]", "\n", "self", ".", "_prediction_conf", ",", "self", ".", "_prediction_global_step", "=", "opts", "[", "\"prediction\"", "]", "\n", "\n", "self", ".", "_n_images", "=", "opts", "[", "\"n_images\"", "]", "\n", "self", ".", "_n_seeds", "=", "opts", "[", "\"n_seeds\"", "]", "\n", "self", ".", "_seeds", "=", "list", "(", "range", "(", "self", ".", "_n_seeds", ")", ")", "\n", "self", ".", "_current_batch_size", "=", "self", ".", "batch_size", "\n", "\n", "# either epsilon is a list of interesting epsilons or it is the default list", "\n", "self", ".", "_epsilons", "=", "opts", "[", "'epsilons'", "]", "[", "'values'", "]", "\n", "#opts.get('epsilons', [0.05, 0.1, 0.15, 0.2, 0.25, 0.3])", "\n", "self", ".", "_epsilons_plus", "=", "[", "0.0", "]", "+", "self", ".", "_epsilons", "\n", "\n", "# what is this??? Petru: the factor that doubles the epsilon if you go from image range [0,1] to [-1, 1], for example", "\n", "self", ".", "_rescale_factor", "=", "1.", "\n", "self", ".", "_adversarial_dir", "=", "self", ".", "dirName", "+", "\"/adversarial/\"", "\n", "os", ".", "makedirs", "(", "self", ".", "_adversarial_dir", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "_accuracy_dir", "=", "self", ".", "dirName", "+", "\"/accuracy/\"", "+", "\"d\"", "# previously \"def\"", "\n", "self", ".", "_stats_dir", "=", "self", ".", "dirName", "+", "'/statistics/'", "\n", "\n", "# put default values", "\n", "self", ".", "_plot_reconstructions", "=", "opts", "[", "\"plot_adversarial_reconstructions\"", "]", "\n", "self", ".", "_only_plot_statistics", "=", "opts", "[", "\"only_plot_statistics\"", "]", "\n", "self", ".", "_do_plot_statistics", "=", "opts", ".", "get", "(", "\"plot_statistics\"", ",", "True", ")", "\n", "self", ".", "_resize", "=", "opts", "[", "\"resize\"", "]", "\n", "\n", "# TODO make this dependent on the transformation, not all transformation refers to external config!! Imagine random noise or jpeg compression", "\n", "# why scale is special? I could have a set of fields that I would like to see maybe?", "\n", "self", ".", "_scale", "=", "\"unimplemented\"", "\n", "\n", "# # TODO get this in a cleaner way", "\n", "# if len(re.split('n[0-9]_s', self._transform_model_id)) > 1:", "\n", "#     self._scale = re.split('n[0-9]_s', self._transform_model_id)[1].split('-')[0]", "\n", "# elif len(re.split('n[0-9]_sm', self._transform_model_id)) > 1:", "\n", "#     self._scale = re.split('n[0-9]_sm', self._transform_model_id)[1].split('_')[0]", "\n", "# else:", "\n", "#     self._scale = 0.0", "\n", "\n", "self", ".", "attack_string", "=", "self", ".", "create_id", "(", ")", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.init": [[172, 186], ["AdversarialModel.AdversarialModel.create_feedable_placeholders", "tensorflow.train.get_or_create_global_step", "AdversarialModel.AdversarialModel.create_input_nodes", "AdversarialModel.AdversarialModel.create_session", "AdversarialModel.AdversarialModel.create_network", "AdversarialModel.AdversarialModel.prepare_attack"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_feedable_placeholders", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.create_input_nodes", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_session", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_network", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.prepare_attack"], ["", "def", "init", "(", "self", ",", "dataset", ")", ":", "\n", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "self", ".", "create_feedable_placeholders", "(", ")", "\n", "\n", "self", ".", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "self", ".", "create_input_nodes", "(", "dataset", ")", "\n", "\n", "self", ".", "create_session", "(", ")", "\n", "\n", "self", ".", "create_network", "(", ")", "\n", "self", ".", "prepare_attack", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_input_nodes": [[188, 224], ["AdversarialModel.AdversarialModel.create_datasets_with_handles", "tensorflow.tile", "tensorflow.placeholder", "numpy.zeros", "tensorflow.tile", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_datasets_with_handles"], ["", "def", "create_input_nodes", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        creates input nodes for a feedforward from the dataset\n\n        Sets:\n            x, y\n        \"\"\"", "\n", "\n", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "=", "self", ".", "create_datasets_with_handles", "(", "dataset", ")", "\n", "\n", "# perturbed dataset is not contemplated for the prediction case", "\n", "#if perturbed_dataset:", "\n", "#   raise Exception(\"perturbed datasets are not contemplated for the prediction case, use a regular dataset\")", "\n", "\n", "#self.raw_x, self.raw_y = datasets_nodes", "\n", "\n", "self", ".", "ds_raw_x", "=", "datasets_nodes", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "ds_aug_x", "=", "datasets_nodes", "[", "0", "]", "[", "1", "]", "\n", "self", ".", "ds_perturb_x", "=", "datasets_nodes", "[", "0", "]", "[", "2", "]", "\n", "self", ".", "raw_x", "=", "self", ".", "ds_raw_x", "\n", "self", ".", "raw_y", "=", "datasets_nodes", "[", "1", "]", "\n", "self", ".", "x_shape_dict", "=", "{", "}", "\n", "self", ".", "x_shape_dict", "[", "\"train\"", "]", "=", "dataset", ".", "x_shape_train", "\n", "self", ".", "x_shape_dict", "[", "\"eval\"", "]", "=", "dataset", ".", "x_shape_eval", "\n", "\n", "self", ".", "x_shape", "=", "self", ".", "x_shape_dict", "[", "\"eval\"", "]", "\n", "#import pdb;pdb.set_trace()", "\n", "self", ".", "x", "=", "self", ".", "raw_x", "\n", "self", ".", "x_tiled", "=", "tf", ".", "tile", "(", "self", ".", "x", ",", "[", "self", ".", "_n_samples_acc", "]", "+", "[", "1", "]", "*", "len", "(", "self", ".", "x_shape", ")", ")", "\n", "\n", "self", ".", "x_adv", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "x", ".", "shape", ")", "\n", "self", ".", "x_adv_np", "=", "np", ".", "zeros", "(", "(", "self", ".", "_n_images", ",", ")", "+", "self", ".", "x_shape", ")", "\n", "\n", "self", ".", "y_shape", "=", "dataset", ".", "y_shape", "\n", "self", ".", "y", "=", "self", ".", "raw_y", "\n", "self", ".", "y_tiled", "=", "tf", ".", "tile", "(", "self", ".", "y", ",", "[", "self", ".", "_n_samples_acc", ",", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_datasets_with_handles": [[226, 234], ["dataset.get_dataset_with_handle"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_dataset_with_handle"], ["", "def", "create_datasets_with_handles", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "=", "dataset", ".", "get_dataset_with_handle", "(", "\n", "self", ".", "batch_size", ",", "self", ".", "batch_size", ")", "\n", "self", ".", "datasets_initializers", "=", "ds_initializers", "\n", "self", ".", "datasets_handles_nodes", "=", "ds_handles", "\n", "self", ".", "ds_handle", "=", "handle", "\n", "self", ".", "raw_x", "=", "datasets_nodes", "[", "0", "]", "\n", "return", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_feedable_placeholders": [[236, 246], ["None"], "methods", ["None"], ["", "def", "create_feedable_placeholders", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        DO NOT USE FOR MODEL SPECIFIC PLACEHOLDERS (e.g. losses or samples..)\n        Create feedables. This function is setting global general purpose placeholders\n\n        Sets:\n            feedable placeholders with general purpose\n\n        \"\"\"", "\n", "self", ".", "is_training", "=", "False", "\n", "# self.is_training = tf.placeholder_with_default(False, shape=(), name=\"is_training\")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_global_steps": [[248, 250], ["tensorflow.train.get_or_create_global_step"], "methods", ["None"], ["", "def", "create_global_steps", "(", "self", ",", "n_points_train_set", ")", ":", "\n", "        ", "self", ".", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_network": [[252, 314], ["argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "datasets.Dataset.Dataset.load_dataset", "transform.transform.check_dataset_shapes", "argo.core.utils.argo_utils.load_class", "argo.core.TFDeepLearningModel.load_network", "tensorflow.placeholder", "ff_network", "ff_network.restore", "isinstance", "AdversarialModel.AdversarialModel.transform_kwargs.update", "transform.transform.get_transform_module", "AdversarialModel.AdversarialModel._build_net", "AdversarialModel.AdversarialModel._transform_module", "AdversarialModel.AdversarialModel._ff_module", "tensorflow.reduce_mean", "tensorflow.cast", "ff_network", "tensorflow.equal", "tensorflow.argmax", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.check_dataset_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.load_network", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore", "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_module"], ["", "def", "create_network", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        It gets the input nodes from the dataset and creates the network\n        starting from the input nodes created by `create_input_nodes`\n\n        Sets:\n            network nodes depending on the specific child class\n        \"\"\"", "\n", "\n", "ffconffile", "=", "self", ".", "_prediction_conf", "\n", "global_step_ff", "=", "self", ".", "_prediction_global_step", "\n", "\n", "ff_dataset_conf", ",", "ff_model_parameters", ",", "ff_config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "ffconffile", ")", "\n", "ff_dataset", "=", "Dataset", ".", "load_dataset", "(", "ff_dataset_conf", ")", "\n", "check_dataset_shapes", "(", "ff_dataset", ".", "x_shape_eval", ",", "self", ".", "x_shape", ")", "\n", "\n", "full_class_path", "=", "\"prediction.core.\"", "+", "ff_model_parameters", "[", "\"model\"", "]", "\n", "prediction_model_class", "=", "load_class", "(", "full_class_path", ")", "\n", "\n", "ff_network", ",", "ff_checkpoint_name", "=", "load_network", "(", "prediction_model_class", ",", "ffconffile", ",", "ff_dataset", ",", "global_step", "=", "global_step_ff", ")", "\n", "x_shape", "=", "(", "None", ",", ")", "+", "self", ".", "x_shape", "\n", "\n", "dummy_x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "x_shape", ",", "name", "=", "'dummy_input'", ")", "\n", "\n", "# LOAD FF NETWORK", "\n", "dummy_output", "=", "ff_network", "(", "dummy_x", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "ff_network", ".", "restore", "(", "self", ".", "sess", ",", "ff_checkpoint_name", ")", "\n", "\n", "# CALLABLE", "\n", "if", "isinstance", "(", "dummy_output", ",", "tfp", ".", "distributions", ".", "Distribution", ")", ":", "\n", "            ", "def", "ff_module", "(", "inputs", ",", "is_training", ")", ":", "\n", "                ", "return", "ff_network", "(", "inputs", ",", "is_training", "=", "is_training", ")", ".", "logits", "\n", "", "", "else", ":", "\n", "            ", "ff_module", "=", "ff_network", "#.module", "\n", "\n", "\n", "", "self", ".", "_ff_module", "=", "ff_module", "\n", "\n", "# CREATE TRANSFORM MODULES, one for attack with default params and one for accuracy calculation", "\n", "self", ".", "transform_name", ",", "self", ".", "transform_kwargs", "=", "self", ".", "_transform_tuple", "\n", "self", ".", "transform_kwargs", ".", "update", "(", "\n", "{", "\n", "\"dummy_x\"", ":", "dummy_x", ",", "\n", "\"sess\"", ":", "self", ".", "sess", ",", "\n", "\"is_training\"", ":", "self", ".", "is_training", "\n", "}", "\n", ")", "\n", "self", ".", "_transform_module", ",", "self", ".", "_transform_feedable", "=", "get_transform_module", "(", "self", ".", "transform_name", ",", "self", ".", "transform_kwargs", ")", "\n", "\n", "def", "_build_net", "(", "inputs", ")", ":", "\n", "            ", "_x", "=", "self", ".", "_transform_module", "(", "inputs", ")", "\n", "return", "self", ".", "_ff_module", "(", "_x", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n", "", "self", ".", "_build_net", "=", "_build_net", "\n", "\n", "#tile for better accuracy estimation", "\n", "self", ".", "_logits", "=", "self", ".", "_build_net", "(", "self", ".", "x_tiled", ")", "\n", "\n", "self", ".", "_accuracy", "=", "100.", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "\n", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "self", ".", "_logits", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "self", ".", "y_tiled", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy_for_transf": [[315, 337], ["tensorflow.placeholder", "transform_kwargs_accuracy.update", "transform.transform.get_transform_module", "AdversarialModel.AdversarialModel._build_net", "AdversarialModel.AdversarialModel.sess.run", "transform_module_accuracy", "tensorflow.reduce_mean", "tensorflow.cast", "tensorflow.equal", "tensorflow.argmax", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_module", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "compute_accuracy_for_transf", "(", "self", ",", "inputs", ",", "labels", ",", "transf_tuple", ",", "**", "feed_kwargs", ")", ":", "\n", "        ", "x_shape", "=", "(", "None", ",", ")", "+", "self", ".", "x_shape", "\n", "dummy_x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "x_shape", ",", "name", "=", "'dummy_input'", ")", "\n", "transform_name_accuracy", ",", "transform_kwargs_accuracy", "=", "transf_tuple", "\n", "transform_kwargs_accuracy", ".", "update", "(", "\n", "{", "\n", "\"dummy_x\"", ":", "dummy_x", ",", "\n", "\"sess\"", ":", "self", ".", "sess", ",", "\n", "\"is_training\"", ":", "self", ".", "is_training", "\n", "}", "\n", ")", "\n", "transform_module_accuracy", ",", "transform_feedable_accuracy", "=", "get_transform_module", "(", "transform_name_accuracy", ",", "transform_kwargs_accuracy", ")", "\n", "logits", "=", "self", ".", "_build_net", "(", "transform_module_accuracy", "(", "self", ".", "x_tiled", ")", ")", "\n", "\n", "accuracy", "=", "100.", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "\n", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "cast", "(", "self", ".", "y_tiled", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "return", "self", ".", "sess", ".", "run", "(", "accuracy", ",", "feed_dict", "=", "{", "self", ".", "x", ":", "inputs", ",", "\n", "self", ".", "y", ":", "labels", ",", "\n", "**", "feed_kwargs", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.prepare_attack": [[341, 377], ["attack_kwargs.update", "attack.attack.get_attack_class", "attack_kwargs.get"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.get_attack_class"], ["", "def", "prepare_attack", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        It gets the input nodes from the dataset and creates the network\n        starting from the input nodes created by `create_input_nodes`\n\n        Sets:\n            network nodes depending on the specific child class\n        \"\"\"", "\n", "\n", "\n", "input_shape", "=", "self", ".", "x_shape", "\n", "n_classes", "=", "self", ".", "dataset", ".", "n_labels", "\n", "attack_name", ",", "attack_kwargs", "=", "self", ".", "_attack_tuple", "\n", "\n", "data_interval", "=", "[", "-", "1.", ",", "1.", "]", "\n", "\n", "# what is this rescale??", "\n", "# We save the rescaling factor in order to use it in the attack", "\n", "self", ".", "_rescale_factor", "=", "data_interval", "[", "1", "]", "-", "data_interval", "[", "0", "]", "\n", "\n", "attack_kwargs", ".", "update", "(", "\n", "{", "\n", "\"data_interval\"", ":", "data_interval", ",", "\n", "\"input_shape\"", ":", "input_shape", ",", "\n", "\"n_classes\"", ":", "n_classes", "\n", "}", "\n", ")", "\n", "\n", "if", "attack_kwargs", "[", "\"proj_ord\"", "]", "==", "\"inf\"", ":", "\n", "            ", "attack_kwargs", "[", "\"proj_ord\"", "]", "=", "np", ".", "inf", "\n", "\n", "", "if", "attack_kwargs", ".", "get", "(", "\"ldist_ord\"", ",", "None", ")", "==", "\"inf\"", ":", "\n", "            ", "attack_kwargs", "[", "\"ldist_ord\"", "]", "=", "np", ".", "inf", "\n", "\n", "", "self", ".", "_attack_class", "=", "get_attack_class", "(", "attack_name", ")", "\n", "self", ".", "_attack_kwargs", "=", "attack_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.release": [[380, 384], ["super().release", "tensorflow.reset_default_graph", "AdversarialModel.AdversarialModel.sess.close"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.release"], ["", "def", "release", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "release", "(", ")", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "self", ".", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_session": [[385, 399], ["tensorflow.Session", "AdversarialModel.AdversarialModel.sess.run", "AdversarialModel.AdversarialModel.sess.run", "tensorflow.ConfigProto", "tensorflow.ConfigProto", "tensorflow.variables_initializer"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "create_session", "(", "self", ")", ":", "\n", "# set some important options", "\n", "        ", "if", "self", ".", "_gpu", "==", "-", "1", ":", "\n", "            ", "sess_config", "=", "tf", ".", "ConfigProto", "(", "device_count", "=", "{", "'GPU'", ":", "0", "}", ",", "allow_soft_placement", "=", "True", ")", "\n", "", "else", ":", "\n", "# config = tf.ConfigProto(log_device_placement=True)", "\n", "            ", "sess_config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "\n", "", "sess_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "sess_config", ")", "\n", "# TODO find a better way to do this", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "[", "self", ".", "global_step", "]", ")", ")", "\n", "self", ".", "datasets_handles", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "datasets_handles_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.attack": [[401, 434], ["AdversarialModel.AdversarialModel.dataset.get_raw_elements", "AdversarialModel.AdversarialModel.dataset.get_raw_labels", "AdversarialModel.AdversarialModel._load_np", "numpy.testing.assert_array_equal", "numpy.zeros", "AdversarialModel.AdversarialModel._attack_class", "tqdm.tqdm.tqdm", "numpy.zeros.astype", "AdversarialModel.AdversarialModel._save_np", "range", "AdversarialModel.AdversarialModel.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_raw_elements", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_raw_labels", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._load_np", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_np", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "attack", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "x_orig_np", "=", "self", ".", "dataset", ".", "get_raw_elements", "(", "dataset_str", ")", "[", ":", "self", ".", "_n_images", "]", "\n", "y_orig_np", "=", "self", ".", "dataset", ".", "get_raw_labels", "(", "dataset_str", ")", "[", ":", "self", ".", "_n_images", "]", "\n", "\n", "x_adv_shape", "=", "(", "self", ".", "_n_images", ",", ")", "+", "self", ".", "x_shape", "\n", "\n", "for", "eps", "in", "self", ".", "_epsilons", ":", "\n", "            ", "try", ":", "\n", "                ", "x_adv", "=", "self", ".", "_load_np", "(", "dataset_str", ",", "eps", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "x_adv", ".", "shape", ",", "x_adv_shape", ")", "\n", "\n", "", "except", "(", "IOError", ",", "AssertionError", ")", ":", "\n", "                ", "self", ".", "_current_batch_size", "=", "self", ".", "batch_size", "\n", "\n", "x_adv", "=", "np", ".", "zeros", "(", "x_adv_shape", ")", "\n", "\n", "attack_name", ",", "attack_kwargs", "=", "self", ".", "_attack_tuple", "\n", "\n", "attack", "=", "self", ".", "_attack_class", "(", "\n", "self", ".", "sess", ",", "\n", "self", ".", "_build_net", ",", "\n", "epsilon", "=", "self", ".", "_rescale_factor", "*", "eps", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "**", "self", ".", "_attack_kwargs", "\n", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "self", ".", "_n_images", ",", "self", ".", "batch_size", ")", ")", ":", "\n", "                    ", "if", "i", "+", "self", ".", "batch_size", ">", "self", ".", "_n_images", ":", "\n", "                        ", "self", ".", "_current_batch_size", "=", "self", ".", "_n_images", "-", "i", "\n", "", "x_adv", "[", "i", ":", "i", "+", "self", ".", "_current_batch_size", "]", "=", "attack", ".", "run", "(", "x_orig_np", "[", "i", ":", "i", "+", "self", ".", "_current_batch_size", "]", ",", "y_orig_np", "[", "i", ":", "i", "+", "self", ".", "_current_batch_size", "]", ")", "\n", "\n", "", "self", ".", "x_adv_np", "=", "x_adv", ".", "astype", "(", "'float32'", ")", "\n", "self", ".", "_save_np", "(", "dataset_str", ",", "eps", ",", "self", ".", "x_adv_np", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy": [[435, 445], ["AdversarialModel.AdversarialModel.compute_accuracy_for_feeds", "AdversarialModel.AdversarialModel.compute_accuracy_for_feeds"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy_for_feeds", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy_for_feeds"], ["", "", "", "def", "compute_accuracy", "(", "self", ",", "dataset_str", ",", "resize", ")", ":", "\n", "# count also: eps = 0 corresponding to clean", "\n", "        ", "epsilons_plus", "=", "[", "0", "]", "+", "self", ".", "_epsilons", "\n", "if", "self", ".", "_transform_accuracy_list", "is", "None", ":", "\n", "            ", "for", "value_kwargs", "in", "self", ".", "_transform_kwargs_accuracy", ":", "\n", "                ", "self", ".", "compute_accuracy_for_feeds", "(", "epsilons_plus", ",", "dataset_str", ",", "value_kwargs", ",", "resize", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "transf", "in", "self", ".", "_transform_accuracy_list", ":", "\n", "                ", "for", "value_kwargs", "in", "self", ".", "_transform_kwargs_accuracy", ":", "\n", "                    ", "self", ".", "compute_accuracy_for_feeds", "(", "epsilons_plus", ",", "dataset_str", ",", "value_kwargs", ",", "resize", ",", "transf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.build_feed_dict": [[447, 453], ["None"], "methods", ["None"], ["", "", "", "", "def", "build_feed_dict", "(", "self", ",", "value_kwargs", ")", ":", "\n", "        ", "nodes_kwargs", "=", "self", ".", "_transform_feedable", "\n", "\n", "feed_dict", "=", "{", "nodes_kwargs", "[", "k", "]", ":", "value_kwargs", "[", "k", "]", "for", "k", "in", "nodes_kwargs", "}", "\n", "\n", "return", "feed_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_statistics": [[455, 459], ["os.makedirs", "AdversarialModel.AdversarialModel.collect_stats_over_transf", "AdversarialModel.AdversarialModel._csv_stats_dir"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.collect_stats_over_transf", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_stats_dir"], ["", "def", "compute_statistics", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "transform_tuple", "=", "(", "self", ".", "transform_name", ",", "self", ".", "transform_kwargs", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "_csv_stats_dir", "(", "transform_tuple", ")", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "collect_stats_over_transf", "(", "dataset_str", ",", "transform_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.collect_stats_over_transf": [[460, 516], ["transform.transform.get_transform_id", "list", "pandas.DataFrame", "AdversarialModel.AdversarialModel._save_stats_df", "[].split", "AdversarialModel.AdversarialModel._prediction_conf.split", "len", "re.search", "re.search", "map", "AdversarialModel.AdversarialModel.collect_stats_over_transf.get_param_vals"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_id", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_stats_df"], ["", "def", "collect_stats_over_transf", "(", "self", ",", "dataset_str", ",", "transform_tuple", ",", "param_specs", "=", "[", "(", "'d'", ",", ")", ",", "(", "'stp'", ",", ")", "]", ")", ":", "\n", "        ", "ds_string", "=", "self", ".", "dirName", ".", "split", "(", "'FF'", ")", "[", "0", "]", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "net_string", "=", "self", ".", "_prediction_conf", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "transf_string", "=", "get_transform_id", "(", "*", "self", ".", "_transform_tuple", ")", "\n", "attack_string", "=", "self", ".", "attack_string", "\n", "\n", "def", "spec_name", "(", "param_spec", ")", ":", "\n", "            ", "return", "\"_\"", ".", "join", "(", "param_spec", ")", "\n", "\n", "", "def", "get_field", "(", "string", ",", "field_spec", ")", ":", "\n", "            ", "l", "=", "len", "(", "field_spec", ")", "\n", "if", "l", "==", "0", "or", "l", ">", "2", ":", "\n", "                ", "raise", "ValueError", "(", "\"Not implemented tuple length `{:}`, found field spec `{:}`\"", ".", "format", "(", "l", ",", "field_spec", ")", ")", "\n", "", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "field_spec", "[", "0", "]", "+", "'([\\._A-Za-z0-9\\,]+)'", "+", "'(-|$)'", ",", "string", ")", "\n", "if", "m", "is", "None", ":", "\n", "                ", "ss1", "=", "'0'", "\n", "", "else", ":", "\n", "                ", "ss1", "=", "m", ".", "group", "(", "2", ")", "\n", "", "if", "l", "==", "1", ":", "\n", "                ", "return", "ss1", "\n", "", "m", "=", "re", ".", "search", "(", "'(_|^)'", "+", "field_spec", "[", "1", "]", "+", "'([\\.A-Za-z0-9\\,]+)'", "+", "'(_|$)'", ",", "ss1", ")", "\n", "if", "m", "is", "None", ":", "\n", "                ", "ss2", "=", "'0'", "\n", "", "else", ":", "\n", "                ", "ss2", "=", "m", ".", "group", "(", "2", ")", "\n", "", "return", "ss2", "\n", "\n", "\n", "", "def", "get_param_vals", "(", "string", ",", "param_specs", ")", ":", "\n", "            ", "param_vals", "=", "[", "]", "\n", "for", "ps", "in", "param_specs", ":", "\n", "                ", "pv", "=", "get_field", "(", "string", ",", "ps", ")", "\n", "param_vals", ".", "append", "(", "pv", ")", "\n", "", "return", "param_vals", "\n", "\n", "", "param_names", "=", "list", "(", "map", "(", "spec_name", ",", "param_specs", ")", ")", "\n", "all_fields", "=", "[", "'eps'", ",", "'scale'", "]", "+", "param_names", "+", "[", "\"adiff_avg\"", ",", "\"adiff_std\"", ",", "\n", "\"norm_avg\"", ",", "\"norm_std\"", ",", "\n", "\"norm_adv_avg\"", ",", "\"norm_adv_std\"", ",", "\n", "\"ndiff_avg\"", ",", "\"ndiff_std\"", ",", "\n", "\"nratio_avg\"", ",", "\"nratio_std\"", ",", "\n", "\"costh_avg\"", ",", "\"costh_std\"", ",", "\n", "\"costh_mu_avg\"", ",", "\"costh_mu_std\"", ",", "\n", "\"costh_mu_adv_avg\"", ",", "\"costh_mu_adv_std\"", ",", "\n", "\"cdist_avg\"", ",", "\"cdist_std\"", ",", "\n", "\"cdist_adv_avg\"", ",", "\"cdist_adv_std\"", ",", "\n", "\"diameter_mu\"", ",", "\n", "\"diameter_mu_adv\"", ",", "]", "\n", "param_vals", "=", "[", "self", ".", "_scale", "]", "+", "get_param_vals", "(", "transf_string", ",", "param_specs", ")", "\n", "base_dir", "=", "self", ".", "dirName", ".", "split", "(", "'FF'", ")", "[", "0", "]", ".", "split", "(", "ds_string", ")", "[", "0", "]", "\n", "data", "=", "[", "]", "\n", "for", "eps", "in", "self", ".", "_epsilons", ":", "\n", "            ", "info_values_list", "=", "self", ".", "extract_one_point_info", "(", "base_dir", ",", "ds_string", ",", "net_string", ",", "get_transform_id", "(", "*", "transform_tuple", ")", ",", "attack_string", ",", "dataset_str", ",", "eps", ")", "\n", "data", ".", "append", "(", "[", "eps", "]", "+", "param_vals", "+", "info_values_list", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "np", ".", "asarray", "(", "data", ")", ",", "columns", "=", "all_fields", ")", "\n", "self", ".", "_save_stats_df", "(", "dataset_str", ",", "transform_tuple", ",", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy_for_feeds": [[518, 583], ["AdversarialModel.AdversarialModel.build_feed_dict", "len", "numpy.zeros", "numpy.mean", "numpy.std", "pandas.DataFrame", "os.makedirs", "os.makedirs", "AdversarialModel.AdversarialModel.dataset.get_raw_elements", "AdversarialModel.AdversarialModel.dataset.get_raw_labels", "tensorflow.set_random_seed", "range", "AdversarialModel.AdversarialModel._save_df", "AdversarialModel.AdversarialModel._save_df_resize", "AdversarialModel.AdversarialModel._csv_dir", "AdversarialModel.AdversarialModel._csv_dir_resize", "AdversarialModel.AdversarialModel._load_np", "argo.core.utils.argo_utils.apply_resize", "AdversarialModel.AdversarialModel.sess.run", "AdversarialModel.AdversarialModel.sess.run", "AdversarialModel.AdversarialModel.compute_accuracy_for_transf", "argo.core.utils.argo_utils.apply_resize", "AdversarialModel.AdversarialModel.sess.run", "AdversarialModel.AdversarialModel.sess.run", "AdversarialModel.AdversarialModel.compute_accuracy_for_transf", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.build_feed_dict", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_raw_elements", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_raw_labels", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_df", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_df_resize", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_dir", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_dir_resize", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._load_np", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.apply_resize", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy_for_transf", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.apply_resize", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy_for_transf"], ["", "def", "compute_accuracy_for_feeds", "(", "self", ",", "epsilons_plus", ",", "dataset_str", ",", "value_kwargs", ",", "resize", ",", "transf_acc_tuple", "=", "None", ")", ":", "\n", "        ", "full_transform_kwargs", "=", "{", "**", "self", ".", "transform_kwargs", ",", "\n", "**", "value_kwargs", "}", "\n", "\n", "if", "transf_acc_tuple", "is", "None", ":", "\n", "            ", "transform_tuple", "=", "(", "self", ".", "transform_name", ",", "full_transform_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "transform_tuple", "=", "transf_acc_tuple", "\n", "", "if", "not", "resize", ":", "\n", "# import ipdb; ipdb.set_trace()", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "_csv_dir", "(", "transform_tuple", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "_csv_dir_resize", "(", "transform_tuple", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "feed_kwargs", "=", "self", ".", "build_feed_dict", "(", "value_kwargs", ")", "\n", "\n", "x_orig_np", "=", "self", ".", "dataset", ".", "get_raw_elements", "(", "dataset_str", ")", "[", ":", "self", ".", "_n_images", "]", "\n", "y_orig_np", "=", "self", ".", "dataset", ".", "get_raw_labels", "(", "dataset_str", ")", "[", ":", "self", ".", "_n_images", "]", "\n", "\n", "n_epsilons_plus", "=", "len", "(", "epsilons_plus", ")", "\n", "\n", "accuracy_all", "=", "np", ".", "zeros", "(", "(", "self", ".", "_n_seeds", ",", "n_epsilons_plus", ")", ")", "\n", "# avg_L2_norms_all = np.zeros((self._n_seeds, n_epsilons_plus))", "\n", "\n", "for", "s", "in", "self", ".", "_seeds", ":", "\n", "            ", "tf", ".", "set_random_seed", "(", "s", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_epsilons_plus", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "# clean", "\n", "                    ", "if", "(", "resize", ")", ":", "\n", "                        ", "x_orig_tf", "=", "apply_resize", "(", "tf", ".", "constant", "(", "x_orig_np", ")", ",", "self", ".", "_resize", "[", "\"intermediate_size\"", "]", ")", "\n", "x_orig_np", "=", "self", ".", "sess", ".", "run", "(", "x_orig_tf", ")", "\n", "", "if", "transform_tuple", "is", "None", ":", "\n", "                        ", "accuracy_np", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "_accuracy", ",", "feed_dict", "=", "{", "self", ".", "x", ":", "x_orig_np", ",", "\n", "self", ".", "y", ":", "y_orig_np", ",", "\n", "**", "feed_kwargs", "}", ")", "\n", "", "else", ":", "\n", "                        ", "accuracy_np", "=", "self", ".", "compute_accuracy_for_transf", "(", "x_orig_np", ",", "y_orig_np", ",", "transf_acc_tuple", ",", "**", "feed_kwargs", ")", "\n", "", "accuracy_all", "[", "s", ",", "i", "]", "=", "accuracy_np", "\n", "\n", "", "else", ":", "\n", "                    ", "eps", "=", "epsilons_plus", "[", "i", "]", "\n", "x_np", "=", "self", ".", "_load_np", "(", "dataset_str", ",", "eps", ")", "\n", "\n", "if", "(", "resize", ")", ":", "\n", "                        ", "x_tf", "=", "apply_resize", "(", "tf", ".", "constant", "(", "x_np", ")", ",", "self", ".", "_resize", "[", "\"intermediate_size\"", "]", ")", "\n", "x_np", "=", "self", ".", "sess", ".", "run", "(", "x_tf", ")", "\n", "", "if", "transform_tuple", "is", "None", ":", "\n", "                        ", "accuracy_np", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "_accuracy", ",", "feed_dict", "=", "{", "self", ".", "x", ":", "x_orig_np", ",", "\n", "self", ".", "y", ":", "y_orig_np", ",", "\n", "**", "feed_kwargs", "}", ")", "\n", "", "else", ":", "\n", "                        ", "accuracy_np", "=", "self", ".", "compute_accuracy_for_transf", "(", "x_orig_np", ",", "y_orig_np", ",", "transf_acc_tuple", ",", "**", "feed_kwargs", ")", "\n", "", "accuracy_all", "[", "s", ",", "i", "]", "=", "accuracy_np", "\n", "\n", "", "", "", "acc_mean", "=", "np", ".", "mean", "(", "accuracy_all", ",", "axis", "=", "0", ")", "\n", "acc_std", "=", "np", ".", "std", "(", "accuracy_all", ",", "axis", "=", "0", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "{", "\"eps\"", ":", "epsilons_plus", ",", "\"acc_mean\"", ":", "acc_mean", ",", "\"acc_std\"", ":", "acc_std", "}", ",", "\n", "columns", "=", "[", "\"eps\"", ",", "\"acc_mean\"", ",", "\"acc_std\"", "]", ")", "\n", "if", "not", "resize", ":", "\n", "            ", "self", ".", "_save_df", "(", "dataset_str", ",", "transform_tuple", ",", "df", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_save_df_resize", "(", "dataset_str", ",", "transform_tuple", ",", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_np": [[585, 587], ["numpy.save", "AdversarialModel.AdversarialModel._npy_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._npy_name"], ["", "", "def", "_save_np", "(", "self", ",", "dataset_str", ",", "eps", ",", "x_adv", ")", ":", "\n", "        ", "np", ".", "save", "(", "self", ".", "_npy_name", "(", "dataset_str", ",", "eps", ")", ",", "x_adv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._load_np": [[588, 590], ["numpy.load", "AdversarialModel.AdversarialModel._npy_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._npy_name"], ["", "def", "_load_np", "(", "self", ",", "dataset_str", ",", "eps", ")", ":", "\n", "        ", "return", "np", ".", "load", "(", "self", ".", "_npy_name", "(", "dataset_str", ",", "eps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._npy_name": [[591, 593], ["str"], "methods", ["None"], ["", "def", "_npy_name", "(", "self", ",", "dataset_str", ",", "eps", ")", ":", "\n", "        ", "return", "self", ".", "_adversarial_dir", "+", "dataset_str", "+", "'-eps'", "+", "str", "(", "eps", ")", "+", "'.npy'", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_df": [[594, 596], ["df.to_csv", "AdversarialModel.AdversarialModel._csv_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_name"], ["", "def", "_save_df", "(", "self", ",", "dataset_str", ",", "transform_tuple", ",", "df", ")", ":", "\n", "        ", "df", ".", "to_csv", "(", "self", ".", "_csv_name", "(", "dataset_str", ",", "transform_tuple", ")", ",", "sep", "=", "\" \"", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_stats_df": [[597, 599], ["df.to_csv", "AdversarialModel.AdversarialModel._csv_stats_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_stats_name"], ["", "def", "_save_stats_df", "(", "self", ",", "dataset_str", ",", "transform_tuple", ",", "df", ")", ":", "\n", "        ", "df", ".", "to_csv", "(", "self", ".", "_csv_stats_name", "(", "dataset_str", ",", "transform_tuple", ")", ",", "sep", "=", "\" \"", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._load_df": [[600, 602], ["pandas.read_csv", "AdversarialModel.AdversarialModel._csv_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_name"], ["", "def", "_load_df", "(", "self", ",", "dataset_str", ",", "transform_tuple", ")", ":", "\n", "        ", "return", "pd", ".", "read_csv", "(", "self", ".", "_csv_name", "(", "dataset_str", ",", "transform_tuple", ")", ",", "sep", "=", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_name": [[603, 605], ["AdversarialModel.AdversarialModel._csv_dir"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_dir"], ["", "def", "_csv_name", "(", "self", ",", "dataset_str", ",", "transform_tuple", ")", ":", "\n", "         ", "return", "self", ".", "_csv_dir", "(", "transform_tuple", ")", "+", "\"accuracy-\"", "+", "dataset_str", "+", "'.csv'", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_stats_name": [[606, 608], ["AdversarialModel.AdversarialModel._csv_stats_dir"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_stats_dir"], ["", "def", "_csv_stats_name", "(", "self", ",", "dataset_str", ",", "transform_tuple", ")", ":", "\n", "         ", "return", "self", ".", "_csv_stats_dir", "(", "transform_tuple", ")", "+", "\"stats-\"", "+", "dataset_str", "+", "'.csv'", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_dir": [[609, 612], ["transform.transform.get_transform_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_id"], ["", "def", "_csv_dir", "(", "self", ",", "transform_tuple", ")", ":", "\n", "        ", "transform_id", "=", "get_transform_id", "(", "*", "transform_tuple", ")", "\n", "return", "self", ".", "_accuracy_dir", "+", "transform_id", "+", "\"/\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_stats_dir": [[614, 616], ["None"], "methods", ["None"], ["", "def", "_csv_stats_dir", "(", "self", ",", "transform_tuple", ")", ":", "\n", "        ", "return", "self", ".", "_stats_dir", "+", "\"/\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._save_df_resize": [[617, 619], ["df.to_csv", "AdversarialModel.AdversarialModel._csv_name_resize"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_name_resize"], ["", "def", "_save_df_resize", "(", "self", ",", "dataset_str", ",", "transform_tuple", ",", "df", ")", ":", "\n", "        ", "df", ".", "to_csv", "(", "self", ".", "_csv_name_resize", "(", "dataset_str", ",", "transform_tuple", ")", ",", "sep", "=", "\" \"", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_name_resize": [[620, 622], ["AdversarialModel.AdversarialModel._csv_dir_resize"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_dir_resize"], ["", "def", "_csv_name_resize", "(", "self", ",", "dataset_str", ",", "transform_tuple", ")", ":", "\n", "         ", "return", "self", ".", "_csv_dir_resize", "(", "transform_tuple", ")", "+", "\"accuracy-\"", "+", "dataset_str", "+", "'.csv'", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._csv_dir_resize": [[623, 626], ["str", "transform.transform.get_transform_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_id"], ["", "def", "_csv_dir_resize", "(", "self", ",", "transform_tuple", ")", ":", "\n", "        ", "transform_id", "=", "get_transform_id", "(", "*", "transform_tuple", ")", "+", "\"-resize\"", "+", "str", "(", "self", ".", "_resize", "[", "\"intermediate_size\"", "]", ")", "\n", "return", "self", ".", "_accuracy_dir", "+", "transform_id", "+", "\"/\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_accuracies": [[627, 638], ["matplotlib.pyplot.figure", "AdversarialModel.AdversarialModel.plot_all", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "glob.glob.glob", "glob.glob.glob"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.plot_all"], ["", "def", "plot_accuracies", "(", "self", ")", ":", "\n", "#TODO what is meaning of this", "\n", "        ", "if", "self", ".", "transform_name", "in", "[", "'identity'", ",", "'ae'", "]", ":", "\n", "            ", "df_list", "=", "glob", "(", "self", ".", "dirName", "+", "\"/accuracy/*/*.csv\"", ")", "\n", "", "elif", "self", ".", "transform_name", "==", "'vae'", ":", "\n", "            ", "df_list", "=", "glob", "(", "self", ".", "dirName", "+", "\"/accuracy/*1.0/*.csv\"", ")", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "(", "20", ",", "10", ")", ")", "\n", "self", ".", "plot_all", "(", "df_list", ")", "\n", "lgd", "=", "plt", ".", "legend", "(", "loc", "=", "'center left'", ",", "bbox_to_anchor", "=", "(", "1", ",", "0.5", ")", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "dirName", "+", "\"/accuracies.png\"", ",", "bbox_extra_artists", "=", "[", "lgd", "]", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_all": [[639, 645], ["pandas.read_csv", "matplotlib.pyplot.errorbar", "AdversarialModel.AdversarialModel._label_from_filename"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._label_from_filename"], ["", "def", "plot_all", "(", "self", ",", "file_list", ")", ":", "\n", "        ", "for", "filename", "in", "file_list", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "filename", ",", "sep", "=", "\" \"", ")", "\n", "plt", ".", "errorbar", "(", "df", "[", "\"eps\"", "]", ",", "df", "[", "\"acc_mean\"", "]", ",", "yerr", "=", "df", "[", "\"acc_std\"", "]", ",", "\n", "linewidth", "=", "2", ",", "elinewidth", "=", "1", ",", "alpha", "=", "0.9", ",", "\n", "label", "=", "self", ".", "_label_from_filename", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._label_from_filename": [[646, 650], ["filename.split", "os.path.splitext"], "methods", ["None"], ["", "", "def", "_label_from_filename", "(", "self", ",", "filename", ")", ":", "\n", "        ", "tname", ",", "basename", "=", "filename", ".", "split", "(", "\"/\"", ")", "[", "-", "2", ":", "]", "\n", "dsname", "=", "os", ".", "path", ".", "splitext", "(", "basename", ")", "[", "0", "]", "\n", "return", "tname", "+", "\"-\"", "+", "dsname", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.generate_reconstructions": [[651, 668], ["AdversarialModel.AdversarialModel._transform_module", "AdversarialModel.AdversarialModel.sess.run", "initial_images.append", "rec_images.append", "numpy.load", "tensorflow.constant", "AdversarialModel.AdversarialModel.dataset.get_raw_elements", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_raw_elements"], ["", "def", "generate_reconstructions", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "initial_images", "=", "[", "]", ";", "rec_images", "=", "[", "]", "\n", "\n", "for", "eps", "in", "[", "0.0", "]", "+", "self", ".", "_epsilons", ":", "\n", "            ", "if", "(", "eps", "<", "1e-4", ")", ":", "# i.e. eps == 0", "\n", "                ", "images_to_reconstruct", "=", "self", ".", "dataset", ".", "get_raw_elements", "(", "dataset_str", ")", "[", "self", ".", "_plot_reconstructions", "[", "\"images_indexes\"", "]", "]", "\n", "", "else", ":", "\n", "                ", "adv_ex_set", "=", "np", ".", "load", "(", "self", ".", "_adversarial_dir", "+", "\"test-eps\"", "+", "str", "(", "eps", ")", "+", "\".npy\"", ")", "\n", "images_to_reconstruct", "=", "adv_ex_set", "[", "self", ".", "_plot_reconstructions", "[", "\"images_indexes\"", "]", "]", "\n", "\n", "", "reconstructions", "=", "self", ".", "_transform_module", "(", "tf", ".", "constant", "(", "images_to_reconstruct", ")", ")", "\n", "reconstructions_np", "=", "self", ".", "sess", ".", "run", "(", "reconstructions", ")", "\n", "\n", "initial_images", ".", "append", "(", "images_to_reconstruct", ")", "\n", "rec_images", ".", "append", "(", "reconstructions_np", ")", "\n", "#np.save(self._adversarial_dir + \"rec_adv_eps\" + str(eps) + \".npy\", reconstructions_np)", "\n", "", "return", "initial_images", ",", "rec_images", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_reconstructions": [[671, 693], ["os.makedirs", "argo.core.utils.ImagesSaver.ImagesSaver", "len", "range", "argo.core.utils.ImagesSaver.ImagesSaver.save_images", "range", "range", "len", "panel[].append", "panel[].append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["", "def", "plot_reconstructions", "(", "self", ",", "initial_images", ",", "rec_images", ")", ":", "\n", "        ", "adversarial_reconstruction_folder", "=", "self", ".", "dirName", "+", "\"/adversarial_reconstruction\"", "\n", "os", ".", "makedirs", "(", "adversarial_reconstruction_folder", ",", "exist_ok", "=", "True", ")", "\n", "images_saver", "=", "ImagesSaver", "(", "adversarial_reconstruction_folder", ")", "\n", "\n", "rows", "=", "len", "(", "initial_images", ")", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", "*", "2", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "self", ".", "_plot_reconstructions", "[", "\"images_indexes\"", "]", ")", ")", ":", "# include first and last image", "\n", "                ", "panel", "[", "2", "*", "i", "]", ".", "append", "(", "initial_images", "[", "i", "]", "[", "j", "]", ")", "\n", "panel", "[", "2", "*", "i", "+", "1", "]", ".", "append", "(", "rec_images", "[", "i", "]", "[", "j", "]", ")", "\n", "\n", "#panel[i+2].append(reconstructed_images[c])", "\n", "#if c == len(images)-1:", "\n", "#    break", "\n", "#else:", "\n", "# \"[1st] interpolation in mu before sampling [2nd] iterpolation in z after sampling\"", "\n", "", "", "images_saver", ".", "save_images", "(", "panel", ",", "\n", "fileName", "=", "\"reconstructions\"", ",", "#+ str(ds_key) + \"_\" + self._time_reference_str + \"_\" + str(self._time_ref).zfill(4),", "\n", "title", "=", "\"reconstructions 1) initial images 2) reconstructions \\n\"", ",", "#+ self._plot_title,", "\n", "fontsize", "=", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.extract_latent_representation": [[695, 701], ["AdversarialModel.AdversarialModel._transform_module.encoder_module", "AdversarialModel.AdversarialModel._transform_module.encoder_module().mean", "AdversarialModel.AdversarialModel._transform_module.encoder_module"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "extract_latent_representation", "(", "self", ",", "transform_name", ")", ":", "\n", "        ", "if", "(", "transform_name", "==", "'ae'", ")", ":", "\n", "            ", "mu", "=", "self", ".", "_transform_module", ".", "encoder_module", "(", "self", ".", "x", ")", "\n", "", "elif", "(", "transform_name", "==", "'vae'", ")", ":", "\n", "            ", "mu", "=", "self", ".", "_transform_module", ".", "encoder_module", "(", "self", ".", "x", ")", ".", "mean", "(", ")", "\n", "", "return", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_latent_representation": [[702, 721], ["AdversarialModel.AdversarialModel.extract_latent_representation", "AdversarialModel.AdversarialModel.sess.run", "numpy.zeros", "range", "len", "AdversarialModel.AdversarialModel._load_np", "AdversarialModel.AdversarialModel.sess.run", "len", "AdversarialModel.AdversarialModel.dataset.get_raw_elements"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.extract_latent_representation", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel._load_np", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.BRATScnnLazyLoading_perSlice.BRATScnnLazyLoading_perSlice.get_raw_elements"], ["", "def", "compute_latent_representation", "(", "self", ",", "dataset_str", ")", ":", "\n", "# define node of interest", "\n", "        ", "mu", "=", "self", ".", "extract_latent_representation", "(", "self", ".", "transform_name", ")", "\n", "\n", "# get mu of clean; we need to know the latent size", "\n", "mu_clean_np", "=", "self", ".", "sess", ".", "run", "(", "mu", ",", "feed_dict", "=", "{", "self", ".", "x", ":", "self", ".", "dataset", ".", "get_raw_elements", "(", "dataset_str", ")", "[", ":", "self", ".", "_n_images", "]", ",", "\n", "}", ")", "\n", "\n", "# define mu_np, where to store the mu of clean and adv. ex. and make mu clean its 0th elem.", "\n", "mu_np", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "_epsilons_plus", ")", ",", "self", ".", "_n_images", ",", "mu_clean_np", ".", "shape", "[", "1", "]", ")", ")", "\n", "mu_np", "[", "0", "]", "=", "mu_clean_np", "\n", "\n", "# get mu adv for all eps", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "_epsilons_plus", ")", ")", ":", "\n", "            ", "eps", "=", "self", ".", "_epsilons_plus", "[", "i", "]", "\n", "x_np", "=", "self", ".", "_load_np", "(", "dataset_str", ",", "eps", ")", "\n", "mu_np", "[", "i", "]", "=", "self", ".", "sess", ".", "run", "(", "mu", ",", "feed_dict", "=", "{", "self", ".", "x", ":", "x_np", ",", "\n", "}", ")", "\n", "", "return", "mu_np", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_latent_representation_for_eps": [[722, 730], ["tensorflow.placeholder", "AdversarialModel.AdversarialModel.sess.run", "AdversarialModel.AdversarialModel._transform_module.encoder_module", "AdversarialModel.AdversarialModel._transform_module.encoder_module().mean", "AdversarialModel.AdversarialModel._transform_module.encoder_module"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "compute_latent_representation_for_eps", "(", "self", ",", "x", ",", "eps", ")", ":", "\n", "        ", "x_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "x", ".", "shape", ")", "\n", "if", "(", "self", ".", "transform_name", "==", "'ae'", ")", ":", "\n", "            ", "mu_star", "=", "self", ".", "_transform_module", ".", "encoder_module", "(", "x_ph", ")", "\n", "", "elif", "(", "self", ".", "transform_name", "==", "'vae'", ")", ":", "\n", "            ", "mu_star", "=", "self", ".", "_transform_module", ".", "encoder_module", "(", "x_ph", ")", ".", "mean", "(", ")", "\n", "", "mu_star_np", "=", "self", ".", "sess", ".", "run", "(", "mu_star", ",", "feed_dict", "=", "{", "x_ph", ":", "x", "[", ":", "self", ".", "_n_images", "]", "}", ")", "\n", "return", "mu_star_np", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.extract_one_point_info": [[732, 825], ["numpy.load", "tensorflow.placeholder", "AdversarialModel.AdversarialModel.compute_latent_representation_for_eps", "AdversarialModel.AdversarialModel.compute_latent_representation_for_eps", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.ones", "numpy.linalg.norm", "functools.partial", "functools.partial.", "functools.partial.", "numpy.max", "numpy.max", "numpy.mean", "numpy.mean", "functools.partial.", "functools.partial.", "numpy.linalg.norm", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.fill_diagonal", "numpy.min", "numpy.max", "numpy.matmul", "numpy.sum", "numpy.matmul", "numpy.sum", "AdversarialModel.AdversarialModel.extract_one_point_info.rough_sqdist_numerics_diagzero"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_latent_representation_for_eps", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_latent_representation_for_eps", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.rough_sqdist_numerics_diagzero"], ["", "def", "extract_one_point_info", "(", "self", ",", "base_dir", ",", "ds_string", ",", "net_string", ",", "transf_string", ",", "attack_string", ",", "dataset_str", ",", "eps", ")", ":", "\n", "\n", "        ", "def", "rough_sqdist_numerics_diagzero", "(", "sqdistances", ")", ":", "\n", "            ", "np", ".", "fill_diagonal", "(", "sqdistances", ",", "0.", ")", "\n", "min_dist", "=", "np", ".", "min", "(", "sqdistances", ")", "\n", "max_dist", "=", "np", ".", "max", "(", "sqdistances", ")", "\n", "if", "min_dist", "<", "0.", ":", "\n", "                ", "sqdistances", "+=", "-", "np", ".", "min", "(", "sqdistances", ")", "\n", "np", ".", "fill_diagonal", "(", "sqdistances", ",", "0.", ")", "\n", "", "return", "sqdistances", "\n", "\n", "", "def", "riemannian_dist", "(", "xp", ",", "xq", ",", "g_matrix", ")", ":", "\n", "            ", "Ixp", "=", "np", ".", "matmul", "(", "g_matrix", ",", "xp", ".", "T", ")", "\n", "sqnormp", "=", "np", ".", "sum", "(", "xp", "*", "Ixp", ".", "T", ",", "axis", "=", "1", ")", "\n", "Ixq", "=", "np", ".", "matmul", "(", "g_matrix", ",", "xq", ".", "T", ")", "\n", "sqnormq", "=", "np", ".", "sum", "(", "xq", "*", "Ixq", ".", "T", ",", "axis", "=", "1", ")", "\n", "sqdistances", "=", "sqnormp", ".", "reshape", "(", "-", "1", ",", "1", ")", "+", "sqnormq", ".", "reshape", "(", "1", ",", "-", "1", ")", "-", "2", "*", "np", ".", "matmul", "(", "xp", ",", "Ixq", ")", "\n", "# # temporarily remove this check put a rough compliance function", "\n", "# sqdistances = check_sqdist_numerics_diagzero(sqdistances)", "\n", "sqdistances", "=", "rough_sqdist_numerics_diagzero", "(", "sqdistances", ")", "\n", "distances", "=", "np", ".", "sqrt", "(", "sqdistances", ")", "\n", "return", "distances", "\n", "\n", "", "x_adv", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "*", "[", "self", ".", "dirName", ",", "\"adversarial\"", ",", "dataset_str", "+", "\"-eps{:}.npy\"", ".", "format", "(", "eps", ")", "]", ")", ")", "\n", "x_clean", "=", "self", ".", "dataset", ".", "get_raw_elements", "(", "dataset_str", ")", "[", ":", "self", ".", "_n_images", "]", "\n", "\n", "x_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "\n", "mu_np", "=", "self", ".", "compute_latent_representation_for_eps", "(", "x_clean", ",", "eps", ")", "\n", "mu_star_np", "=", "self", ".", "compute_latent_representation_for_eps", "(", "x_adv", ",", "eps", ")", "\n", "norm_np", "=", "np", ".", "linalg", ".", "norm", "(", "mu_np", ",", "axis", "=", "1", ")", "\n", "norm_star_np", "=", "np", ".", "linalg", ".", "norm", "(", "mu_star_np", ",", "axis", "=", "1", ")", "\n", "adiff", "=", "norm_star_np", "-", "norm_np", "\n", "costh", "=", "np", ".", "sum", "(", "mu_np", "*", "mu_star_np", ",", "axis", "=", "1", ")", "/", "(", "norm_np", "*", "norm_star_np", ")", "\n", "\n", "onevec", "=", "np", ".", "ones", "(", "(", "1", ",", "mu_np", ".", "shape", "[", "1", "]", ")", ")", "\n", "norm_onevec", "=", "np", ".", "linalg", ".", "norm", "(", "onevec", ")", "\n", "costh_mu", "=", "np", ".", "sum", "(", "mu_np", "*", "onevec", ",", "axis", "=", "1", ")", "/", "(", "norm_np", "*", "norm_onevec", ")", "\n", "costh_mu_adv", "=", "np", ".", "sum", "(", "mu_star_np", "*", "onevec", ",", "axis", "=", "1", ")", "/", "(", "norm_star_np", "*", "norm_onevec", ")", "\n", "nratio", "=", "norm_star_np", "/", "norm_np", "\n", "\n", "ldim", "=", "mu_np", ".", "shape", "[", "1", "]", "\n", "euclidean_dist", "=", "partial", "(", "riemannian_dist", ",", "g_matrix", "=", "np", ".", "eye", "(", "ldim", ")", ")", "\n", "\n", "distances_mu_np", "=", "euclidean_dist", "(", "mu_np", ",", "mu_np", ")", "\n", "distances_mu_star_np", "=", "euclidean_dist", "(", "mu_star_np", ",", "mu_star_np", ")", "\n", "diameter_mu_set", "=", "np", ".", "max", "(", "distances_mu_np", ")", "\n", "diameter_mu_star_set", "=", "np", ".", "max", "(", "distances_mu_star_np", ")", "\n", "\n", "centroid_mu_set", "=", "np", ".", "mean", "(", "mu_np", ",", "axis", "=", "0", ")", "\n", "centroid_mu_star_set", "=", "np", ".", "mean", "(", "mu_star_np", ",", "axis", "=", "0", ")", "\n", "\n", "cdists_set", "=", "euclidean_dist", "(", "mu_np", ",", "centroid_mu_set", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "\n", "cdists_adv_set", "=", "euclidean_dist", "(", "mu_star_np", ",", "centroid_mu_star_set", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "\n", "\n", "ndiffs_np", "=", "np", ".", "linalg", ".", "norm", "(", "mu_star_np", "-", "mu_np", ",", "axis", "=", "1", ")", "\n", "ndiff_avg", "=", "np", ".", "mean", "(", "ndiffs_np", ")", "\n", "ndiff_std", "=", "np", ".", "std", "(", "ndiffs_np", ")", "\n", "\n", "adiff_avg", "=", "np", ".", "mean", "(", "adiff", ")", "\n", "adiff_std", "=", "np", ".", "std", "(", "adiff", ")", "\n", "nratio_avg", "=", "np", ".", "mean", "(", "nratio", ")", "\n", "nratio_std", "=", "np", ".", "std", "(", "nratio", ")", "\n", "costh_avg", "=", "np", ".", "mean", "(", "costh", ")", "\n", "costh_std", "=", "np", ".", "std", "(", "costh", ")", "\n", "costh_mu_avg", "=", "np", ".", "mean", "(", "costh_mu", ")", "\n", "costh_mu_std", "=", "np", ".", "std", "(", "costh_mu", ")", "\n", "costh_mu_adv_avg", "=", "np", ".", "mean", "(", "costh_mu_adv", ")", "\n", "costh_mu_adv_std", "=", "np", ".", "std", "(", "costh_mu_adv", ")", "\n", "\n", "norms_avg", "=", "np", ".", "mean", "(", "norm_np", ")", "\n", "norms_std", "=", "np", ".", "std", "(", "norm_np", ")", "\n", "\n", "norms_adv_avg", "=", "np", ".", "mean", "(", "norm_star_np", ")", "\n", "norms_adv_std", "=", "np", ".", "std", "(", "norm_star_np", ")", "\n", "\n", "cdists_set_mean", "=", "np", ".", "mean", "(", "cdists_set", ")", "\n", "cdists_set_std", "=", "np", ".", "std", "(", "cdists_set", ")", "\n", "cdists_adv_set_mean", "=", "np", ".", "mean", "(", "cdists_adv_set", ")", "\n", "cdists_adv_set_std", "=", "np", ".", "std", "(", "cdists_adv_set", ")", "\n", "\n", "return", "[", "adiff_avg", ",", "adiff_std", ",", "\n", "norms_avg", ",", "norms_std", ",", "\n", "norms_adv_avg", ",", "norms_adv_std", ",", "\n", "ndiff_avg", ",", "ndiff_std", ",", "\n", "nratio_avg", ",", "nratio_std", ",", "\n", "costh_avg", ",", "costh_std", ",", "\n", "costh_mu_avg", ",", "costh_mu_std", ",", "\n", "costh_mu_adv_avg", ",", "costh_mu_adv_std", ",", "\n", "cdists_set_mean", ",", "cdists_set_std", ",", "\n", "cdists_adv_set_mean", ",", "cdists_adv_set_std", ",", "\n", "diameter_mu_set", ",", "\n", "diameter_mu_star_set", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_mu_statistics": [[827, 839], ["AdversarialModel.AdversarialModel.compute_latent_representation", "os.makedirs", "AdversarialModel.AdversarialModel.plot_errorbars_average_norm", "AdversarialModel.AdversarialModel.plot_histogram_norm_of_difference", "AdversarialModel.AdversarialModel.plot_histogram_difference_of_norms", "AdversarialModel.AdversarialModel.plot_histogram_cos_adv_clean", "AdversarialModel.AdversarialModel.plot_histograms_norm_per_images", "AdversarialModel.AdversarialModel.plot_histogram_norms"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_latent_representation", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_errorbars_average_norm", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_norm_of_difference", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_difference_of_norms", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_cos_adv_clean", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histograms_norm_per_images", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_norms"], ["", "def", "plot_mu_statistics", "(", "self", ",", "dataset_str", ")", ":", "\n", "        ", "mu_np", "=", "self", ".", "compute_latent_representation", "(", "dataset_str", ")", "\n", "\n", "mu_statistics_folder", "=", "self", ".", "dirName", "+", "\"/mu_statistics\"", "\n", "os", ".", "makedirs", "(", "mu_statistics_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "plot_errorbars_average_norm", "(", "dataset_str", ",", "mu_np", ",", "mu_statistics_folder", ")", "\n", "self", ".", "plot_histogram_norm_of_difference", "(", "dataset_str", ",", "mu_np", ",", "mu_statistics_folder", ")", "\n", "self", ".", "plot_histogram_difference_of_norms", "(", "dataset_str", ",", "mu_np", ",", "mu_statistics_folder", ")", "\n", "self", ".", "plot_histogram_cos_adv_clean", "(", "dataset_str", ",", "mu_np", ",", "mu_statistics_folder", ")", "\n", "self", ".", "plot_histograms_norm_per_images", "(", "dataset_str", ",", "mu_np", ",", "mu_statistics_folder", ",", "no_images", "=", "10", ")", "\n", "self", ".", "plot_histogram_norms", "(", "dataset_str", ",", "mu_np", ",", "mu_statistics_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_errorbars_average_norm": [[841, 854], ["numpy.linalg.norm", "numpy.average", "numpy.std", "matplotlib.pyplot.errorbar", "matplotlib.pyplot.title", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "pandas.DataFrame", "pandas.DataFrame.to_csv"], "methods", ["None"], ["", "def", "plot_errorbars_average_norm", "(", "self", ",", "dataset_str", ",", "mu", ",", "folder_name", ")", ":", "\n", "        ", "all_norms", "=", "np", ".", "linalg", ".", "norm", "(", "mu", ",", "axis", "=", "2", ")", "\n", "average_norms", "=", "np", ".", "average", "(", "all_norms", ",", "axis", "=", "1", ")", "\n", "std_norms", "=", "np", ".", "std", "(", "all_norms", ",", "axis", "=", "1", ")", "\n", "\n", "plt", ".", "errorbar", "(", "self", ".", "_epsilons_plus", ",", "average_norms", ",", "std_norms", ",", "capsize", "=", "5", ")", "\n", "plt", ".", "title", "(", "\"Average norm of latent representation\"", ")", "\n", "plt", ".", "savefig", "(", "folder_name", "+", "\"/mu_average_norms_errorbars.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "{", "\"eps\"", ":", "self", ".", "_epsilons_plus", ",", "\"avg_norms\"", ":", "average_norms", ",", "\"avg_norms_std\"", ":", "std_norms", "}", ",", "\n", "columns", "=", "[", "\"eps\"", ",", "\"avg_norms\"", ",", "\"avg_norms_std\"", "]", ")", "\n", "df", ".", "to_csv", "(", "folder_name", "+", "'/average_norms_text.csv'", ",", "sep", "=", "\" \"", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_norm_of_difference": [[856, 869], ["numpy.linalg.norm", "numpy.linspace", "range", "matplotlib.pyplot.hist", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.text", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "range", "len", "len", "str", "str"], "methods", ["None"], ["", "def", "plot_histogram_norm_of_difference", "(", "self", ",", "dataset_str", ",", "mu", ",", "folder_name", ")", ":", "\n", "        ", "mu_diff_adv_clean", "=", "[", "mu", "[", "i", "]", "-", "mu", "[", "0", "]", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "_epsilons_plus", ")", ")", "]", "\n", "mu_diff_norms", "=", "np", ".", "linalg", ".", "norm", "(", "mu_diff_adv_clean", ",", "axis", "=", "2", ")", "\n", "\n", "bins", "=", "np", ".", "linspace", "(", "0", ",", "15", ",", "num", "=", "51", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_epsilons_plus", ")", "-", "1", ")", ":", "\n", "            ", "plt", ".", "hist", "(", "mu_diff_norms", "[", "i", "]", ",", "bins", ",", "color", "=", "'b'", ")", "\n", "plt", ".", "title", "(", "\"||mu_adv - mu_clean||, eps = \"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "+", "1", "]", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Norm'", ")", "\n", "plt", ".", "ylabel", "(", "'No. images'", ")", "\n", "plt", ".", "text", "(", "0.1", ",", "0.3", ",", "self", ".", "_transform_model_id", ")", "\n", "plt", ".", "savefig", "(", "folder_name", "+", "\"/hist_norms_of_diff_\"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "+", "1", "]", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_difference_of_norms": [[871, 884], ["numpy.linalg.norm", "numpy.linspace", "range", "matplotlib.pyplot.hist", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.text", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "range", "len", "len", "str", "str"], "methods", ["None"], ["", "", "def", "plot_histogram_difference_of_norms", "(", "self", ",", "dataset_str", ",", "mu", ",", "folder_name", ")", ":", "\n", "        ", "mu_norms", "=", "np", ".", "linalg", ".", "norm", "(", "mu", ",", "axis", "=", "2", ")", "\n", "mu_norms_diff_adv_clean", "=", "[", "mu_norms", "[", "i", "]", "-", "mu_norms", "[", "0", "]", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "_epsilons_plus", ")", ")", "]", "\n", "\n", "bins", "=", "np", ".", "linspace", "(", "-", "7", ",", "7", ",", "num", "=", "51", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_epsilons_plus", ")", "-", "1", ")", ":", "\n", "            ", "plt", ".", "hist", "(", "mu_norms_diff_adv_clean", "[", "i", "]", ",", "bins", ",", "color", "=", "'m'", ")", "\n", "plt", ".", "title", "(", "\"||mu_adv|| - ||mu_clean||, eps = \"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "+", "1", "]", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Difference'", ")", "\n", "plt", ".", "ylabel", "(", "'No. images'", ")", "\n", "plt", ".", "text", "(", "0.1", ",", "0.3", ",", "self", ".", "_transform_model_id", ")", "\n", "plt", ".", "savefig", "(", "folder_name", "+", "\"/hist_diff_of_norms_\"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "+", "1", "]", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_cos_adv_clean": [[886, 900], ["numpy.linspace", "range", "numpy.diag", "numpy.multiply", "numpy.divide", "matplotlib.pyplot.hist", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.text", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "numpy.matmul", "range", "numpy.linalg.norm", "numpy.linalg.norm", "range", "range", "len", "numpy.transpose", "len", "len", "str", "len", "str"], "methods", ["None"], ["", "", "def", "plot_histogram_cos_adv_clean", "(", "self", ",", "dataset_str", ",", "mu", ",", "folder_name", ")", ":", "\n", "        ", "inner_prod_adv_clean", "=", "[", "np", ".", "diag", "(", "np", ".", "matmul", "(", "mu", "[", "0", "]", ",", "np", ".", "transpose", "(", "mu", "[", "i", "]", ")", ")", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "_epsilons_plus", ")", ")", "]", "\n", "prod_norm_adv_clean", "=", "[", "np", ".", "multiply", "(", "np", ".", "linalg", ".", "norm", "(", "mu", "[", "0", "]", ",", "axis", "=", "1", ")", ",", "np", ".", "linalg", ".", "norm", "(", "mu", "[", "i", "]", ",", "axis", "=", "1", ")", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "_epsilons_plus", ")", ")", "]", "\n", "cos_adv_clean", "=", "[", "np", ".", "divide", "(", "inner_prod_adv_clean", "[", "i", "]", ",", "prod_norm_adv_clean", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_epsilons_plus", ")", "-", "1", ")", "]", "\n", "\n", "bins", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "num", "=", "51", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_epsilons_plus", ")", "-", "1", ")", ":", "\n", "            ", "plt", ".", "hist", "(", "cos_adv_clean", "[", "i", "]", ",", "bins", ",", "color", "=", "'g'", ")", "\n", "plt", ".", "title", "(", "\"cos(adv, clean), eps = \"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "+", "1", "]", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Cos angle'", ")", "\n", "plt", ".", "ylabel", "(", "'No. images'", ")", "\n", "plt", ".", "text", "(", "0.1", ",", "0.3", ",", "self", ".", "_transform_model_id", ")", "\n", "plt", ".", "savefig", "(", "folder_name", "+", "\"/hist_cos_adv_clean_\"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "+", "1", "]", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histograms_norm_per_images": [[902, 914], ["numpy.linalg.norm", "range", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.text", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.plot"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "", "def", "plot_histograms_norm_per_images", "(", "self", ",", "dataset_str", ",", "mu", ",", "folder_name", ",", "no_images", ")", ":", "\n", "        ", "mu_norms", "=", "np", ".", "linalg", ".", "norm", "(", "mu", "[", ":", ",", ":", "10", ",", ":", "]", ",", "axis", "=", "2", ")", "\n", "\n", "colors", "=", "[", "'m'", ",", "'b'", ",", "'g'", ",", "'r'", ",", "'y'", ",", "'c'", ",", "'k'", ",", "'0.5'", ",", "'#C40000'", ",", "'#006400'", "]", "\n", "for", "i", "in", "range", "(", "no_images", ")", ":", "\n", "            ", "plt", ".", "plot", "(", "self", ".", "_epsilons_plus", ",", "mu_norms", "[", ":", ",", "i", "]", ",", "color", "=", "colors", "[", "i", "]", ")", "\n", "", "plt", ".", "title", "(", "\"Norm of mu, individual images\"", ")", "\n", "plt", ".", "xlabel", "(", "'Epsilon'", ")", "\n", "plt", ".", "ylabel", "(", "'Norm'", ")", "\n", "plt", ".", "text", "(", "0.1", ",", "0.3", ",", "self", ".", "_transform_model_id", ")", "\n", "plt", ".", "savefig", "(", "folder_name", "+", "\"/graph_norm_individual_images.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_histogram_norms": [[922, 935], ["numpy.linalg.norm", "numpy.linspace", "range", "len", "matplotlib.pyplot.hist", "matplotlib.pyplot.title", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.text", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "str", "str"], "methods", ["None"], ["", "def", "plot_histogram_norms", "(", "self", ",", "dataset_str", ",", "mu", ",", "folder_name", ")", ":", "\n", "#import pdb;pdb.set_trace()", "\n", "        ", "mu_norms", "=", "np", ".", "linalg", ".", "norm", "(", "mu", ",", "axis", "=", "2", ")", "\n", "\n", "bins", "=", "np", ".", "linspace", "(", "0", ",", "20", ",", "num", "=", "51", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_epsilons_plus", ")", ")", ":", "\n", "            ", "plt", ".", "hist", "(", "mu_norms", "[", "i", "]", ",", "bins", ",", "color", "=", "'m'", ")", "\n", "plt", ".", "title", "(", "\"Norms of latent representations, eps = \"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "]", ")", ")", "\n", "plt", ".", "xlabel", "(", "'L2 Norm'", ")", "\n", "plt", ".", "ylabel", "(", "'No. images'", ")", "\n", "plt", ".", "text", "(", "0.1", ",", "0.3", ",", "self", ".", "_transform_model_id", ")", "\n", "plt", ".", "savefig", "(", "folder_name", "+", "\"/hist_norms_\"", "+", "str", "(", "self", ".", "_epsilons_plus", "[", "i", "]", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.load_model": [[34, 65], ["argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "argo.core.utils.argo_utils.load_class", "argo.core.TFDeepLearningModel.update_model_params", "argo.core.utils.argo_utils.load_class.", "datasets.Dataset.Dataset.load_dataset", "os.path.split", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.update_model_params", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset"], ["def", "load_model", "(", "conf_file", ",", "dataset", "=", "None", ",", "gpu", "=", "0", ",", "seed", "=", "0", ",", "model_class_base_path", "=", "''", ")", ":", "\n", "    ", "\"\"\"Load a TFDeepLearningModel and optionally save its network\n\n    Args:\n        conf_file (str): the conf file of the model where to find the experiment.\n        dataset (datasets.Dataset): (optional) the argo Dataset of the model for the training. If not passed it will be reloaded.\n        global_step (int): the global step to load the checkpoint (if None the last checkpoint present will be loaded).\n        gpu (int) : the gpu on which the model will create the session\n        seed (int) : the seed that the model will set\n        model_class_base_path (str): the base path where to look for the model class\n\n    Returns:\n        TFDeepLearningModel: The loaded Argo TFDeepLearningModel.\n        datasets.Dataset: the argo Dataset of the model for the training.\n\n    \"\"\"", "\n", "\n", "dataset_conf", ",", "model_parameters", ",", "config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "conf_file", ")", "\n", "\n", "if", "not", "dataset", ":", "\n", "        ", "dataset", "=", "Dataset", ".", "load_dataset", "(", "dataset_conf", ")", "\n", "\n", "", "ArgoTFDeepLearningModelClass", "=", "load_class", "(", "model_parameters", "[", "\"model\"", "]", ",", "base_path", "=", "model_class_base_path", ")", "\n", "\n", "update_model_params", "(", "model_parameters", ",", "dataset", ")", "\n", "\n", "# baseDir = config[\"dirName\"]+\"/\"+dataset.id", "\n", "model_dir", "=", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "dirname", "(", "conf_file", ")", ")", "[", "0", "]", "\n", "model", "=", "ArgoTFDeepLearningModelClass", "(", "model_parameters", ",", "model_dir", ",", "gpu", "=", "gpu", ",", "seed", "=", "seed", ")", "\n", "\n", "return", "model", ",", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialLauncher.AdversarialLauncher.__init__": [[7, 9], ["argo.core.ArgoLauncher.ArgoLauncher.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialLauncher.AdversarialLauncher.execute": [[10, 29], ["model.init", "model.attack", "model.compute_accuracy", "model.plot_accuracies", "model.compute_statistics", "model.plot_mu_statistics", "model.compute_accuracy", "model.generate_reconstructions", "model.plot_reconstructions"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.init", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.attack", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_accuracies", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_statistics", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_mu_statistics", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.compute_accuracy", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.generate_reconstructions", "home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.plot_reconstructions"], ["", "def", "execute", "(", "self", ",", "model", ",", "dataset", ",", "opts", ",", "config", ")", ":", "\n", "        ", "model", ".", "init", "(", "dataset", ")", "\n", "\n", "if", "not", "model", ".", "_only_plot_statistics", ":", "\n", "            ", "model", ".", "attack", "(", "TEST", ")", "\n", "model", ".", "compute_accuracy", "(", "TEST", ",", "resize", "=", "0", ")", "\n", "model", ".", "plot_accuracies", "(", ")", "\n", "\n", "if", "(", "model", ".", "_plot_reconstructions", "[", "'enable'", "]", ")", ":", "\n", "#for value_kwargs in self._transform_kwargs_accuracy:", "\n", "                ", "initial_images", ",", "rec_images", "=", "model", ".", "generate_reconstructions", "(", "TEST", ")", "\n", "model", ".", "plot_reconstructions", "(", "initial_images", ",", "rec_images", ")", "\n", "\n", "", "", "if", "model", ".", "_do_plot_statistics", ":", "\n", "            ", "model", ".", "compute_statistics", "(", "TEST", ")", "\n", "model", ".", "plot_mu_statistics", "(", "TEST", ")", "\n", "\n", "", "if", "model", ".", "_resize", "[", "'enable'", "]", ":", "\n", "            ", "model", ".", "compute_accuracy", "(", "TEST", ",", "resize", "=", "1", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection": [[4, 9], ["open", "pickle.dump"], "function", ["None"], ["def", "save_collection", "(", "collection_path", ",", "collection", ")", ":", "\n", "# save analogies accuracies", "\n", "    ", "with", "open", "(", "collection_path", ",", "'wb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "        ", "pickle", ".", "dump", "(", "collection", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.load_collection_and_backup": [[11, 25], ["open", "pickle.load", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "", "def", "load_collection_and_backup", "(", "collection_path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "collection_path", ",", "'rb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "            ", "analogies", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "collection_path", "+", "\".bkp\"", ",", "'wb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "            ", "pickle", ".", "dump", "(", "analogies", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "", "except", ":", "\n", "        ", "analogies", "=", "{", "}", "\n", "\n", "", "return", "analogies", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.check_done_in_collection": [[27, 76], ["len", "len", "print", "print", "m.startswith", "Exception", "Exception", "Exception", "lengths.append", "m.startswith", "len", "len", "len", "numpy.testing.assert_equal", "set"], "function", ["None"], ["", "def", "check_done_in_collection", "(", "collection", ",", "alphas", ",", "name_start", ",", "enpd", ")", ":", "\n", "# enpd = expected number of methods per dataset", "\n", "\n", "    ", "expected_number", "=", "len", "(", "collection", ")", "*", "enpd", "\n", "done_alphas", "=", "0", "\n", "lengths", "=", "[", "]", "\n", "limit_count", "=", "0", "\n", "\n", "# e.g. name_start = \"u-plog\"", "\n", "limit_start", "=", "\"limit-\"", "+", "name_start", "\n", "\n", "for", "d", "in", "collection", ":", "\n", "        ", "for", "m", "in", "collection", "[", "d", "]", ":", "\n", "            ", "if", "m", ".", "startswith", "(", "name_start", ")", ":", "\n", "                ", "curve", "=", "collection", "[", "d", "]", "[", "m", "]", "\n", "# check how long are the curves of the non-limit ones", "\n", "lengths", ".", "append", "(", "len", "(", "curve", ")", ")", "\n", "", "elif", "m", ".", "startswith", "(", "limit_start", ")", ":", "\n", "                ", "length", "=", "len", "(", "collection", "[", "d", "]", "[", "m", "]", ")", "\n", "np", ".", "testing", ".", "assert_equal", "(", "length", ",", "1", ",", "\"limit curve must have lenght one, found {:}...\"", ".", "format", "(", "length", ")", ")", "\n", "# count how many limits have been done", "\n", "limit_count", "+=", "1", "\n", "\n", "", "", "", "nonlimit_count", "=", "len", "(", "lengths", ")", "\n", "\n", "done_limit", "=", "False", "\n", "# if I found some limits, they must be all", "\n", "if", "limit_count", ">", "0", ":", "\n", "\n", "# number of limits should be same of expected_number", "\n", "        ", "if", "limit_count", "!=", "expected_number", ":", "\n", "            ", "raise", "Exception", "(", "\"expected 0 or {:} limits, found {:} instead..\"", ".", "format", "(", "expected_number", ",", "limit_count", ")", ")", "\n", "\n", "", "print", "(", "\"found already limits done\"", ")", "\n", "done_limit", "=", "True", "\n", "\n", "# if I found curves, they must be all same length", "\n", "", "if", "nonlimit_count", ">", "0", ":", "\n", "        ", "if", "not", "len", "(", "set", "(", "lengths", ")", ")", "==", "1", ":", "\n", "            ", "raise", "Exception", "(", "\"error reading collection, found different lenghts for alpha\"", ")", "\n", "\n", "# number of nonlimits should be same of expected_number", "\n", "", "if", "nonlimit_count", "!=", "expected_number", ":", "\n", "            ", "raise", "Exception", "(", "\"expected 0 or {:} methods for {:}, found {:} instead..\"", ".", "format", "(", "expected_number", ",", "name_start", ",", "nonlimit_count", ")", ")", "\n", "\n", "", "done_alphas", "=", "lengths", "[", "0", "]", "\n", "print", "(", "\"found already {:} alphas done: {:}\"", ".", "format", "(", "done_alphas", ",", "alphas", "[", ":", "done_alphas", "]", ")", ")", "\n", "\n", "", "return", "done_alphas", ",", "done_limit", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_glove_cc_fnames": [[49, 78], ["ValueError"], "function", ["None"], ["def", "get_glove_cc_fnames", "(", "corpus", ")", ":", "\n", "    ", "dsdir", "=", "'/ssd_data/text/cooccurrences/'", "\n", "# simplewiki_sw6_fnamecc = dsdir + 'simplewiki201711/simplewiki201711-sw6-cooccurrence.bin'", "\n", "simplewiki_sw10_fnamecc", "=", "dsdir", "+", "'simplewiki201711/simplewiki201711-sw10-cooccurrence.bin'", "\n", "simplewiki_fnamevc", "=", "dsdir", "+", "'simplewiki201711/simplewiki201711-vocab.txt'", "\n", "\n", "enwiki_sw10_fnamecc", "=", "dsdir", "+", "'enwiki201710/enwiki201710-sw10-cooccurrence.bin'", "\n", "enwiki_fnamevc", "=", "dsdir", "+", "'enwiki201710/enwiki201710-vocab.txt'", "\n", "\n", "geb_sw10_fnamecc", "=", "dsdir", "+", "'geb/geb-sw10-cooccurrence.bin'", "\n", "geb_fnamevc", "=", "dsdir", "+", "'geb/geb-vocab.txt'", "\n", "\n", "# select which vocabulary and cooccurrence file to use", "\n", "if", "corpus", "==", "\"geb\"", ":", "\n", "        ", "fnamevc", "=", "geb_fnamevc", "\n", "fnamecc", "=", "geb_sw10_fnamecc", "\n", "\n", "", "elif", "corpus", "==", "\"enwiki\"", ":", "\n", "        ", "fnamevc", "=", "enwiki_fnamevc", "\n", "fnamecc", "=", "enwiki_sw10_fnamecc", "\n", "\n", "", "elif", "corpus", "==", "\"swiki\"", ":", "\n", "        ", "fnamevc", "=", "simplewiki_fnamevc", "\n", "fnamecc", "=", "simplewiki_sw10_fnamecc", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"corpus not recognized `%s`\"", "%", "corpus", ")", "\n", "\n", "", "return", "fnamevc", ",", "fnamecc", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.normalize_cols_numexpr": [[80, 86], ["numpy.sqrt().reshape", "numexpr.evaluate", "numpy.sqrt", "numexpr.evaluate"], "function", ["None"], ["", "def", "normalize_cols_numexpr", "(", "mat", ")", ":", "\n", "    ", "norms", "=", "np", ".", "sqrt", "(", "ne", ".", "evaluate", "(", "\"sum(mat**2, axis=0)\"", ")", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "# norms = np.linalg.norm(embs, axis=0)", "\n", "# embs = embs / norms", "\n", "mat", "=", "ne", ".", "evaluate", "(", "\"mat / norms\"", ")", "\n", "return", "mat", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_embpath": [[88, 103], ["os.path.join", "load_embeddings.get_alpha_ldv_name", "load_embeddings.get_limit_ldv_name", "ValueError"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_limit_ldv_name"], ["", "def", "get_embpath", "(", "alpha_tuple", ",", "theta", ",", "point", ",", "emb_dir", ")", ":", "\n", "    ", "alpha_id", ",", "alpha_kwargs", "=", "alpha_tuple", "\n", "ldvname", "=", "None", "\n", "if", "alpha_id", "==", "'float'", ":", "\n", "        ", "alpha", "=", "alpha_kwargs", "[", "'value'", "]", "\n", "ldvname", "=", "get_alpha_ldv_name", "(", "alpha", ",", "theta", "+", "\"_embeddings\"", ",", "point", ")", "\n", "", "elif", "alpha_id", "==", "'limit'", ":", "\n", "        ", "ntop", "=", "alpha_kwargs", "[", "'ntop'", "]", "\n", "weighted", "=", "alpha_kwargs", "[", "'weighted'", "]", "\n", "fraction", "=", "alpha_kwargs", "[", "'fraction'", "]", "\n", "ldvname", "=", "get_limit_ldv_name", "(", "theta", "+", "\"_embeddings\"", ",", "point", ",", "ntop", ",", "weighted", ",", "fraction", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Option `{:}`not recognized for alpha_id. Only `float` or `limit` are allowed.\"", ".", "format", "(", "alpha_id", ")", ")", "\n", "\n", "", "return", "os", ".", "path", ".", "join", "(", "emb_dir", ",", "ldvname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name": [[109, 114], ["load_embeddings.get_limit_ldv_name"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_limit_ldv_name"], ["", "def", "get_alpha_ldv_name", "(", "alpha", ",", "emb_name", ",", "point_name", ",", "ntop", "=", "''", ",", "weighted", "=", "False", ",", "frac", "=", "False", ")", ":", "\n", "    ", "if", "alpha", "==", "\"limit\"", ":", "\n", "        ", "return", "get_limit_ldv_name", "(", "emb_name", ",", "point_name", ",", "ntop", "=", "ntop", ",", "weighted", "=", "weighted", ",", "frac", "=", "frac", ")", "\n", "", "ldv_filename", "=", "\"alpha{:.2f}-ldv-{:}-{:}.hdf\"", ".", "format", "(", "alpha", ",", "emb_name", ",", "point_name", ")", "\n", "return", "ldv_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_limit_ldv_name": [[115, 126], ["None"], "function", ["None"], ["", "def", "get_limit_ldv_name", "(", "emb_name", ",", "point_name", ",", "ntop", ",", "weighted", ",", "frac", ")", ":", "\n", "    ", "ws", "=", "''", "\n", "if", "weighted", ":", "\n", "        ", "ws", "=", "'w'", "\n", "\n", "", "fs", "=", "''", "\n", "if", "frac", ":", "\n", "        ", "fs", "=", "'f'", "\n", "\n", "", "ldv_filename", "=", "\"limit{:}{:}{:}-ldv-{:}-{:}.hdf\"", ".", "format", "(", "ntop", ",", "ws", ",", "fs", ",", "emb_name", ",", "point_name", ")", "\n", "return", "ldv_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_pretrained_glove": [[128, 141], ["readers.get_reader", "readers.get_reader.read_embeddings"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.get_reader", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_embeddings"], ["", "def", "load_pretrained_glove", "(", "gname", ",", "dir_name", ")", ":", "\n", "    ", "g_reader", "=", "readers", ".", "get_reader", "(", "\"glove\"", ")", "\n", "\n", "#LOAD GLOVE FROM FILES", "\n", "fname", ",", "vecsize", "=", "dir_name", "\n", "consideronlyfirstvec", "=", "True", "\n", "\n", "# u_biases and v_biases are not returned at the moment since we do not know what is the use of them we might have in evaluating word analogies", "\n", "\n", "g_dictionary_size", ",", "g_dictionary", ",", "g_reversed_dictionary", ",", "u_embeddings", ",", "v_embeddings", "=", "g_reader", ".", "read_embeddings", "(", "fname", ",", "vecsize", ",", "consideronlyfirstvec", ")", "\n", "glove_vecs", "=", "{", "\"u\"", ":", "u_embeddings", ",", "\"v\"", ":", "v_embeddings", "}", "\n", "\n", "return", "g_dictionary", ",", "glove_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_pretrained_w2v": [[142, 153], ["gensim.models.keyedvectors.KeyedVectors.load_word2vec_format", "list", "numpy.array", "enumerate", "KeyedVectors.load_word2vec_format.get_vector"], "function", ["None"], ["", "def", "load_pretrained_w2v", "(", "wname", ")", ":", "\n", "# g_reader = readers.get_reader(\"word2vec\")", "\n", "    ", "fname", ",", "vecsize", "=", "info_w2v", "[", "wname", "]", "\n", "model", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "fname", ",", "binary", "=", "True", ")", "\n", "vocab", "=", "list", "(", "model", ".", "wv", ".", "vocab", ")", "\n", "dictionary", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "\n", "embeddings", "=", "np", ".", "array", "(", "[", "model", ".", "get_vector", "(", "w", ")", "for", "w", "in", "vocab", "]", ")", "\n", "\n", "vecs", "=", "{", "\"u\"", ":", "embeddings", ",", "\"v\"", ":", "None", "}", "\n", "\n", "return", "dictionary", ",", "vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.word_index": [[155, 162], ["print", "print", "sys.exit"], "function", ["None"], ["", "def", "word_index", "(", "word", ",", "dictionary", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "dictionary", "[", "word", "]", "\n", "", "except", "KeyError", "as", "kerr", ":", "\n", "        ", "print", "(", "\"\\nKey Error: {0}\"", ".", "format", "(", "kerr", ")", ")", "\n", "print", "(", "\"The word requested is not present in the dictionary.\\n\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_glove_fname": [[163, 168], ["None"], "function", ["None"], ["", "", "def", "get_glove_fname", "(", "base_dir", ",", "corpus", ",", "vecsize", ",", "nepoch", ")", ":", "\n", "    ", "nm", "=", "corpus_name", "[", "corpus", "]", "\n", "gstr", "=", "\"glove1.2-%s-m0%s-v%d-sw10-lr0.001\"", "%", "(", "nm", ",", "m0", "[", "corpus", "]", ",", "vecsize", ")", "\n", "fullname", "=", "base_dir", "+", "\"/\"", "+", "nm", "+", "\"/\"", "+", "gstr", "+", "\"/\"", "+", "gstr", "+", "\"-vectors-n%d.txt\"", "%", "nepoch", "\n", "return", "fullname", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_w2v_fname": [[169, 174], ["None"], "function", ["None"], ["", "def", "get_w2v_fname", "(", "base_dir", ",", "corpus", ",", "vecsize", ",", "nepoch", ",", "sw", "=", "10", ",", "ns", "=", "10", ")", ":", "\n", "    ", "nm", "=", "corpus_name", "[", "corpus", "]", "\n", "gstr", "=", "\"word2vec-cbow-%s-m0%s-v%d-sw%d-ns%d-lr0.05\"", "%", "(", "nm", ",", "m0", "[", "corpus", "]", ",", "vecsize", ",", "sw", ",", "ns", ")", "\n", "fullname", "=", "base_dir", "+", "\"/\"", "+", "nm", "+", "\"/\"", "+", "gstr", "+", "\"/\"", "+", "gstr", "+", "\"-vectors-n%d.txt\"", "%", "nepoch", "\n", "return", "fullname", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_word_embeddings": [[175, 179], ["numpy.asarray", "numpy.array", "load_embeddings.word_index"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index"], ["", "def", "get_word_embeddings", "(", "words", ",", "embeddings", ",", "dictionary", ")", ":", "\n", "    ", "\"\"\"Return a list of embeddings for the specified words\"\"\"", "\n", "embeddings", "=", "np", ".", "asarray", "(", "embeddings", ")", "\n", "return", "np", ".", "array", "(", "[", "embeddings", "[", "word_index", "(", "w", ",", "dictionary", ")", "]", "for", "w", "in", "words", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix": [[180, 183], ["None"], "function", ["None"], ["", "def", "get_suffix", "(", "vecsize", ",", "nepoch", ")", ":", "\n", "    ", "suffix", "=", "\"-v%d-n%d\"", "%", "(", "vecsize", ",", "nepoch", ")", "\n", "return", "suffix", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove": [[184, 204], ["readers.get_reader", "load_embeddings.get_glove_fname", "readers.get_reader.read_embeddings", "load_embeddings.calculate_glove_prob"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.get_reader", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_glove_fname", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.calculate_glove_prob"], ["", "def", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ",", "glove_dir", "=", "default_glove_dir", ")", ":", "\n", "    ", "g_reader", "=", "readers", ".", "get_reader", "(", "\"glove\"", ")", "\n", "\n", "#LOAD GLOVE FROM FILES", "\n", "fname", "=", "get_glove_fname", "(", "glove_dir", ",", "corpus", ",", "vecsize", ",", "nepoch", ")", "\n", "consideronlyfirstvec", "=", "False", "\n", "\n", "# u_biases and v_biases are not returned at the moment since we do not know what is the use of them we might have in evaluating word analogies", "\n", "g_dictionary_size", ",", "g_dictionary", ",", "g_reversed_dictionary", ",", "u_embeddings", ",", "v_embeddings", "=", "g_reader", ".", "read_embeddings", "(", "fname", ",", "vecsize", ",", "consideronlyfirstvec", ")", "\n", "glove_vecs", "=", "{", "\"u\"", ":", "u_embeddings", ",", "\"v\"", ":", "v_embeddings", "}", "\n", "\n", "p_tuple", "=", "None", "\n", "if", "calc_prob", ":", "\n", "# last word of glove is UNK token", "\n", "# U[:-1,:-1], V[:-1,:-1]", "\n", "        ", "p_tuple", "=", "calculate_glove_prob", "(", "glove_vecs", "[", "\"u\"", "]", "[", ":", "-", "1", ",", ":", "]", ",", "\n", "glove_vecs", "[", "\"v\"", "]", "[", ":", "-", "1", ",", ":", "]", ")", "\n", "\n", "\n", "", "return", "g_dictionary", ",", "glove_vecs", ",", "p_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_w2v": [[206, 216], ["readers.get_reader", "load_embeddings.get_w2v_fname", "readers.get_reader.read_embeddings"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.get_reader", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_w2v_fname", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_embeddings"], ["", "def", "load_w2v", "(", "base_dir", ",", "corpus", ",", "vecsize", ",", "nepoch", ",", "sw", "=", "10", ",", "ns", "=", "10", ")", ":", "\n", "    ", "reader", "=", "readers", ".", "get_reader", "(", "\"word2vec\"", ")", "\n", "\n", "fname", "=", "get_w2v_fname", "(", "base_dir", ",", "corpus", ",", "vecsize", ",", "nepoch", ",", "sw", "=", "sw", ",", "ns", "=", "ns", ")", "\n", "consideronlyfirstvec", "=", "False", "\n", "# u_biases and v_biases are not returned at the moment since we do not know what is the use of them we might have in evaluating word analogies", "\n", "dictionary_size", ",", "dictionary", ",", "reversed_dictionary", ",", "u_embeddings", ",", "v_embeddings", "=", "reader", ".", "read_embeddings", "(", "fname", ",", "vecsize", ",", "consideronlyfirstvec", ")", "\n", "vecs", "=", "{", "\"u\"", ":", "u_embeddings", ",", "\"v\"", ":", "v_embeddings", "}", "\n", "\n", "return", "dictionary", ",", "vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.calculate_glove_prob": [[217, 238], ["spaces.C_numexpr", "load_embeddings.normalize_cols_numexpr", "normalize_cols_numexpr.sum", "normalize_cols_numexpr.sum", "normalize_cols_numexpr.sum().reshape", "numexpr.evaluate", "numexpr.evaluate", "normalize_cols_numexpr.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.C_numexpr", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.normalize_cols_numexpr"], ["", "def", "calculate_glove_prob", "(", "U", ",", "V", ",", "norm_counts_cols", "=", "False", ",", "pos_measures", "=", "False", ")", ":", "\n", "\n", "    ", "C", "=", "C_numexpr", "(", "U", ",", "V", ")", "\n", "\n", "# C = C_numexpr(U, V)", "\n", "\n", "if", "norm_counts_cols", ":", "\n", "# C = C / C.sum(axis=0).reshape(1,-1)", "\n", "        ", "C", "=", "normalize_cols_numexpr", "(", "C", ")", "\n", "\n", "", "if", "pos_measures", ":", "\n", "        ", "p_cIw", "=", "C", "\n", "p_w", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "N", "=", "C", ".", "sum", "(", ")", "\n", "sums1", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "p_w", "=", "ne", ".", "evaluate", "(", "\"sums1 / N\"", ")", "\n", "p_cIw", "=", "ne", ".", "evaluate", "(", "\"C / sums1\"", ")", "\n", "# p_w, p_cIw = compute_p_cIw_from_counts(C)", "\n", "\n", "", "return", "p_w", ",", "p_cIw", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.calculate_glove_unigram_prob": [[240, 248], ["spaces.C_numexpr", "spaces.C_numexpr.sum", "spaces.C_numexpr.sum().reshape", "numexpr.evaluate", "spaces.C_numexpr.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.C_numexpr"], ["", "def", "calculate_glove_unigram_prob", "(", "U", ",", "V", ")", ":", "\n", "\n", "    ", "C", "=", "C_numexpr", "(", "U", ",", "V", ")", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "sums1", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "p_w", "=", "ne", ".", "evaluate", "(", "\"sums1 / N\"", ")", "\n", "\n", "return", "p_w", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_all_emb_base": [[250, 268], ["numpy.load", "numpy.load", "numpy.linalg.inv", "numpy.load", "numpy.linalg.inv", "numpy.load", "numpy.linalg.inv", "numpy.load", "numpy.linalg.inv"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_all_emb_base", "(", "embdir", ")", ":", "\n", "    ", "alphas", "=", "np", ".", "load", "(", "embdir", "+", "\"/alphas.npy\"", ")", "\n", "\n", "# I = np.load(embdir + \"/fisher-\" + point_name + \".npy\")", "\n", "\n", "I0", "=", "np", ".", "load", "(", "embdir", "+", "\"/fisher-0.npy\"", ")", "\n", "I0_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I0", ")", "\n", "\n", "Iu", "=", "np", ".", "load", "(", "embdir", "+", "\"/fisher-u.npy\"", ")", "\n", "Iu_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iu", ")", "\n", "\n", "Iud", "=", "np", ".", "load", "(", "embdir", "+", "\"/fisher-ud.npy\"", ")", "\n", "Iud_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iud", ")", "\n", "\n", "Ius", "=", "np", ".", "load", "(", "embdir", "+", "\"/fisher-us.npy\"", ")", "\n", "Ius_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Ius", ")", "\n", "\n", "return", "alphas", ",", "I0", ",", "Iu", ",", "Iud", ",", "Ius", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_emb_base": [[269, 273], ["numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_emb_base", "(", "embdir", ",", "point", ")", ":", "\n", "    ", "alphas", "=", "np", ".", "load", "(", "embdir", "+", "\"/alphas.npy\"", ")", "\n", "I", "=", "np", ".", "load", "(", "embdir", "+", "\"/fisher-\"", "+", "point", "+", "\".npy\"", ")", "\n", "return", "alphas", ",", "I", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_embeddings_ldv_hdf": [[275, 285], ["tables.open_file"], "function", ["None"], ["", "def", "load_embeddings_ldv_hdf", "(", "filename", ",", "original_norm", "=", "False", ")", ":", "\n", "    ", "with", "tables", ".", "open_file", "(", "filename", ")", "as", "f", ":", "\n", "# print(f.root.embeddings)", "\n", "        ", "embeddings_ldv", "=", "f", ".", "root", ".", "embeddings_ldv", "[", ":", ",", ":", "]", "\n", "\n", "if", "original_norm", ":", "\n", "            ", "embeddings_lscale", "=", "f", ".", "root", ".", "embeddings_lscale", "[", ":", ",", ":", "]", "\n", "embeddings_ldv", "=", "embeddings_ldv", "*", "embeddings_lscale", "\n", "\n", "", "", "return", "embeddings_ldv", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.extract_embedding_from_params": [[287, 301], ["ValueError"], "function", ["None"], ["", "def", "extract_embedding_from_params", "(", "params", ",", "vec_size", ",", "mode", ")", ":", "\n", "    ", "if", "mode", "==", "0", ":", "\n", "# standard, single embeddings are present", "\n", "        ", "emb", "=", "params", "\n", "", "elif", "mode", "==", "1", ":", "\n", "# u bu v bu, all parameters are present, I want to use u+v/2", "\n", "        ", "emb", "=", "(", "params", "[", ":", "vec_size", "]", "+", "params", "[", "vec_size", "+", "1", ":", "-", "1", "]", ")", "/", "2.", "\n", "", "elif", "mode", "==", "2", ":", "\n", "# u bu v bu, all parameters are present, I want to use u", "\n", "        ", "emb", "=", "params", "[", ":", "vec_size", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"mode can be only: 0, 1, or 2. But {:} was found.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.save_dict": [[302, 307], ["open", "pickle.dump"], "function", ["None"], ["", "def", "save_dict", "(", "dictionary", ",", "outdirname", ")", ":", "\n", "    ", "path", "=", "outdirname", "+", "\"/dictionary.pkl\"", "# -{:}\".format(gname)", "\n", "with", "open", "(", "path", ",", "'wb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "        ", "pickle", ".", "dump", "(", "dictionary", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_dict": [[308, 318], ["os.path.join", "len", "dict", "open", "pickle.load", "zip", "pickle.load.values", "pickle.load.keys"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "", "def", "load_dict", "(", "vector_dir", ")", ":", "\n", "    ", "dict_fname", "=", "os", ".", "path", ".", "join", "(", "vector_dir", ",", "\"dictionary.pkl\"", ")", "\n", "with", "open", "(", "dict_fname", ",", "'rb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "        ", "vocab", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "ivocab", "=", "dict", "(", "zip", "(", "vocab", ".", "values", "(", ")", ",", "vocab", ".", "keys", "(", ")", ")", ")", "\n", "\n", "return", "vocab", ",", "ivocab", ",", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.read_cooccurrences_from_c": [[319, 332], ["numpy.dtype", "numpy.array", "print", "scipy.sparse.coo_matrix", "scipy.sparse.csr_matrix", "numpy.fromfile", "max", "max", "max"], "function", ["None"], ["", "def", "read_cooccurrences_from_c", "(", "filename", ")", ":", "\n", "    ", "dt", "=", "np", ".", "dtype", "(", "\"i4, i4, f8\"", ")", "\n", "cooccurrences", "=", "np", ".", "array", "(", "np", ".", "fromfile", "(", "filename", ",", "dtype", "=", "dt", ")", ")", "\n", "\n", "row_ind", "=", "cooccurrences", "[", ":", "]", "[", "'f0'", "]", "-", "1", "\n", "col_ind", "=", "cooccurrences", "[", ":", "]", "[", "'f1'", "]", "-", "1", "\n", "values", "=", "cooccurrences", "[", ":", "]", "[", "'f2'", "]", "\n", "\n", "D", "=", "max", "(", "max", "(", "row_ind", "[", "-", "5", ":", "]", ")", ",", "max", "(", "col_ind", "[", "-", "5", ":", "]", ")", ")", "+", "1", "\n", "print", "(", "D", ")", "\n", "C", "=", "scipy", ".", "sparse", ".", "coo_matrix", "(", "(", "values", ",", "(", "row_ind", ",", "col_ind", ")", ")", ",", "shape", "=", "(", "D", ",", "D", ")", ")", "\n", "C", "=", "scipy", ".", "sparse", ".", "csr_matrix", "(", "C", ")", "\n", "return", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.compute_p_cIw_from_counts": [[333, 360], ["print", "C.sum", "C.sum().reshape", "numpy.squeeze", "numpy.array", "C.sum"], "function", ["None"], ["", "def", "compute_p_cIw_from_counts", "(", "C", ")", ":", "\n", "    ", "print", "(", "\"I am creating pcIw from C...\"", ")", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "sums1", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "p_w", "=", "sums1", "/", "N", "\n", "# p_c = C.sum(axis=0) / N", "\n", "p_cIw", "=", "C", "/", "sums1", "\n", "# p_wc = np.multiply(p_cIw, p_w)", "\n", "\n", "# print(\"I am creating the ratio matrix...\")", "\n", "# prodprobs = np.matmul(p_w, p_c)", "\n", "# # r1 = p_wc / prodprobs", "\n", "# # r2 = p_cIw / p_c", "\n", "# r = (C/np.matmul(C.sum(axis=1), C.sum(axis=0))) * N", "\n", "\n", "# print(\"I am creating PMI, NPMI and PPMI matrices...\")", "\n", "# PMI = np.log(r+NUMTOL)", "\n", "# NPMI = PMI/(-np.log(p_wc+NUMTOL))", "\n", "# PPMI = np.maximum(NUMTOL, PMI) - NUMTOL", "\n", "#", "\n", "# x_data = np.sqrt(p_cIw)", "\n", "# h_data = np.log(1+p_cIw)", "\n", "\n", "p_w", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "p_w", ")", ")", "\n", "# p_c = np.squeeze(np.array(p_c))", "\n", "# np.allclose(p_w, p_c)", "\n", "return", "p_w", ",", "p_cIw", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.compute_p_wc_from_counts": [[361, 389], ["print", "C.sum", "C.sum().reshape", "numexpr.evaluate", "numpy.squeeze", "numpy.array", "C.sum"], "function", ["None"], ["", "def", "compute_p_wc_from_counts", "(", "C", ")", ":", "\n", "    ", "print", "(", "\"I am creating p_wc from C...\"", ")", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "sums1", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "p_w", "=", "sums1", "/", "N", "\n", "# p_c = C.sum(axis=0) / N", "\n", "p_cIw", "=", "C", "/", "sums1", "\n", "# p_cIw = ne.evaluate(\"C / sums1\")", "\n", "# p_wc = np.multiply(p_cIw, p_w)", "\n", "p_wc", "=", "ne", ".", "evaluate", "(", "\"p_cIw * p_w\"", ")", "\n", "# print(\"I am creating the ratio matrix...\")", "\n", "# prodprobs = np.matmul(p_w, p_c)", "\n", "# # r1 = p_wc / prodprobs", "\n", "# # r2 = p_cIw / p_c", "\n", "# r = (C/np.matmul(C.sum(axis=1), C.sum(axis=0))) * N", "\n", "\n", "# print(\"I am creating PMI, NPMI and PPMI matrices...\")", "\n", "# PMI = np.log(r+NUMTOL)", "\n", "# NPMI = PMI/(-np.log(p_wc+NUMTOL))", "\n", "# PPMI = np.maximum(NUMTOL, PMI) - NUMTOL", "\n", "#", "\n", "# x_data = np.sqrt(p_cIw)", "\n", "# h_data = np.log(1+p_cIw)", "\n", "\n", "p_w", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "p_w", ")", ")", "\n", "# p_c = np.squeeze(np.array(p_c))", "\n", "# np.allclose(p_w, p_c)", "\n", "return", "p_w", ",", "p_wc", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.evaluate_similarities": [[11, 150], ["list", "range", "scores_dict.items", "logger.info", "logger.info", "logger.info", "scipy.stats.spearmanr", "logger.info", "logger.info", "glob.glob", "list.append", "itertools.chain.from_iterable", "len", "numpy.array", "measures.riemannian_cosprod", "scipy.stats.spearmanr", "logger.info", "logger.info", "list", "list", "aggr_humscores[].append", "aggr_simscores[].append", "numpy.concatenate", "numpy.concatenate", "scipy.stats.spearmanr", "plotting.create_plot_data_dict", "plotting.initialize_plot", "plotting.plot_data", "os.path.join", "sorted", "open", "csv.reader", "list", "len", "zip", "len", "plotting.create_plot_data_dict", "plotting.initialize_plot", "plotting.plot_data", "measures.normalize", "task.split", "plotting.save_object", "plotting.finalize_plot", "matplotlib.pyplot.show", "os.path.join", "[].split", "plotting.save_object", "plotting.finalize_plot", "matplotlib.pyplot.show", "min", "max", "float", "os.path.splitext"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_cosprod", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.create_plot_data_dict", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.initialize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.plot_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.create_plot_data_dict", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.initialize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.plot_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.save_object", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.finalize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.save_object", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.finalize_plot"], ["def", "evaluate_similarities", "(", "dictionary", ",", "W", ",", "g", ",", "logger", ",", "filter_dictionary", "=", "None", ",", "datasets", "=", "[", "]", ",", "outbasename", "=", "None", ",", "plot", "=", "False", ")", ":", "\n", "    ", "\"\"\"Evaluate the trained word vectors on a variety of similarity files\n    \"\"\"", "\n", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "", "folder", "=", "'/data2/text/similarities_datasets/splitted'", "\n", "\n", "if", "not", "datasets", ":", "\n", "# in each of these folders I expect to find the splits", "\n", "        ", "datasets", "=", "[", "\n", "\"wordsim353\"", ",", "\"mc\"", ",", "\"rg\"", ",", "\"scws\"", ",", "\n", "\"wordsim353sim\"", ",", "\"wordsim353rel\"", ",", "\n", "\"men\"", ",", "\"mturk287\"", ",", "\"rw\"", ",", "\"simlex999\"", "\n", "]", "\n", "\n", "", "filenames", "=", "[", "]", "\n", "\n", "for", "dirname", "in", "datasets", ":", "\n", "        ", "fsplits", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"*.csv\"", ")", ")", ")", "\n", "filenames", ".", "append", "(", "sorted", "(", "fsplits", ")", ")", "\n", "\n", "", "filenames", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "filenames", ")", ")", "\n", "\n", "scores_dict", "=", "{", "}", "\n", "corr_dict", "=", "{", "}", "\n", "\n", "all_humscores", "=", "[", "]", "\n", "all_simscores", "=", "[", "]", "\n", "plot_method", "=", "\"scatter\"", "\n", "title", "=", "\"\"", "\n", "xlabel", "=", "\"human scores\"", "\n", "ylabel", "=", "\"similarity\"", "\n", "\n", "full_count", "=", "0", "\n", "count_tot", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "filenames", ")", ")", ":", "\n", "\n", "        ", "label", "=", "\"-\"", ".", "join", "(", "os", ".", "path", ".", "splitext", "(", "filenames", "[", "i", "]", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "2", ":", "]", ")", "\n", "\n", "with", "open", "(", "filenames", "[", "i", "]", ",", "'r'", ")", "as", "instream", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "instream", ",", "delimiter", "=", "' '", ",", "skipinitialspace", "=", "True", ")", "\n", "lines", "=", "list", "(", "reader", ")", "\n", "full_count", "+=", "len", "(", "lines", ")", "\n", "ind1", ",", "ind2", ",", "humscores", "=", "zip", "(", "\n", "*", "(", "(", "dictionary", "[", "w1", "]", ",", "dictionary", "[", "w2", "]", ",", "sc", ")", "for", "(", "w1", ",", "w2", ",", "sc", ")", "in", "lines", "if", "(", "w1", "in", "filter_dictionary", ")", "and", "(", "w2", "in", "filter_dictionary", ")", ")", ")", "\n", "count_tot", "+=", "len", "(", "ind1", ")", "\n", "\n", "#     full_data = [line.rstrip().split(' ') for line in f]", "\n", "#     full_count += len(full_data)", "\n", "#     data = [x for x in full_data if all(word in dictionary for word in x)]", "\n", "#", "\n", "# indices = np.array([[dictionary[word] for word in row] for row in data])", "\n", "# ind1, ind2, ind3, ind4 = indices.T", "\n", "# read csv in a table and then calculate the distances and pair them with the scores from the csv", "\n", "", "humscores", "=", "np", ".", "array", "(", "humscores", ",", "dtype", "=", "np", ".", "float", ")", "\n", "simscores", "=", "riemannian_cosprod", "(", "W", ",", "g", ",", "ind1", ",", "ind2", ")", "\n", "\n", "if", "plot", ":", "\n", "            ", "plot_dict", "=", "create_plot_data_dict", "(", "[", "humscores", "]", ",", "[", "simscores", "]", ",", "[", "label", "]", ",", "\n", "xlabel", ",", "ylabel", ",", "plot_method_name", "=", "plot_method", ")", "\n", "\n", "axes", "=", "initialize_plot", "(", "title", ",", "xlabel", ",", "ylabel", ")", "\n", "plot_data", "(", "plot_dict", "[", "\"data\"", "]", ",", "axes", ",", "plot_method", ",", "plot_args", "=", "[", "]", ",", "plot_kwargs", "=", "{", "}", ")", "\n", "\n", "if", "outbasename", ":", "\n", "                ", "outputfile", "=", "outbasename", "+", "\"-\"", "+", "label", "+", "\".dat\"", "\n", "save_object", "(", "plot_dict", ",", "outputfile", ")", "\n", "outputpng", "=", "outbasename", "+", "\"-\"", "+", "label", "+", "\".png\"", "\n", "finalize_plot", "(", "axes", ",", "outputpng", ",", "xlim", "=", "None", ",", "ylim", "=", "None", ",", "legendloc", "=", "None", ")", "\n", "", "else", ":", "\n", "                ", "plt", ".", "show", "(", ")", "\n", "\n", "\n", "", "", "scores_dict", "[", "label", "]", "=", "(", "humscores", ",", "simscores", ")", "\n", "\n", "corr", ",", "p_value", "=", "spearmanr", "(", "humscores", ",", "simscores", ")", "\n", "corr", "=", "corr", "*", "100", "\n", "corr_dict", "[", "label", "]", "=", "corr", "\n", "\n", "logger", ".", "info", "(", "\"%s:\"", "%", "filenames", "[", "i", "]", ")", "\n", "logger", ".", "info", "(", "'SPEARMAN CORR: %.2f '", "%", "corr", ")", "\n", "\n", "all_humscores", "+=", "list", "(", "normalize", "(", "humscores", ",", "min", "(", "humscores", ")", ",", "max", "(", "humscores", ")", ")", ")", "\n", "all_simscores", "+=", "list", "(", "simscores", ")", "\n", "\n", "# aggregate scores for the full datasets", "\n", "", "aggr_humscores", "=", "{", "}", "\n", "aggr_simscores", "=", "{", "}", "\n", "for", "d", "in", "datasets", ":", "\n", "        ", "aggr_humscores", "[", "d", "]", "=", "[", "]", "\n", "aggr_simscores", "[", "d", "]", "=", "[", "]", "\n", "\n", "", "for", "task", ",", "(", "hums", ",", "sims", ")", "in", "scores_dict", ".", "items", "(", ")", ":", "\n", "        ", "d", "=", "task", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "aggr_humscores", "[", "d", "]", ".", "append", "(", "hums", ")", "\n", "aggr_simscores", "[", "d", "]", ".", "append", "(", "sims", ")", "\n", "\n", "#store aggregated scores and corrs", "\n", "", "for", "d", "in", "datasets", ":", "\n", "        ", "hums", "=", "np", ".", "concatenate", "(", "aggr_humscores", "[", "d", "]", ")", "\n", "sims", "=", "np", ".", "concatenate", "(", "aggr_simscores", "[", "d", "]", ")", "\n", "scores_dict", "[", "d", "]", "=", "(", "hums", ",", "sims", ")", "\n", "corr", ",", "p_value", "=", "spearmanr", "(", "hums", ",", "sims", ")", "\n", "corr", "=", "corr", "*", "100", "\n", "corr_dict", "[", "d", "]", "=", "corr", "\n", "\n", "", "logger", ".", "info", "(", "'Questions seen/total: %.2f%% (%d/%d)'", "%", "\n", "(", "100", "*", "count_tot", "/", "float", "(", "full_count", ")", ",", "count_tot", ",", "full_count", ")", ")", "\n", "\n", "logger", ".", "info", "(", "'\\nON ALL'", ")", "\n", "logger", ".", "info", "(", "'-------------------------'", ")", "\n", "corr", ",", "p_value", "=", "spearmanr", "(", "all_humscores", ",", "all_simscores", ")", "\n", "corr", "=", "corr", "*", "100", "\n", "\n", "label", "=", "\"all\"", "\n", "corr_dict", "[", "label", "]", "=", "corr", "\n", "\n", "logger", ".", "info", "(", "'SPEARMAN CORR: %.2f '", "%", "corr", ")", "\n", "logger", ".", "info", "(", "'\\n'", ")", "\n", "\n", "if", "plot", ":", "\n", "        ", "plot_dict", "=", "create_plot_data_dict", "(", "[", "all_humscores", "]", ",", "[", "all_simscores", "]", ",", "[", "\"all\"", "]", ",", "\n", "xlabel", ",", "ylabel", ",", "plot_method_name", "=", "plot_method", ")", "\n", "\n", "axes", "=", "initialize_plot", "(", "title", ",", "xlabel", ",", "ylabel", ")", "\n", "plot_data", "(", "plot_dict", "[", "\"data\"", "]", ",", "axes", ",", "plot_method", ",", "plot_args", "=", "[", "]", ",", "plot_kwargs", "=", "{", "}", ")", "\n", "\n", "if", "outbasename", ":", "\n", "            ", "outputfile", "=", "outbasename", "+", "\"-all.dat\"", "\n", "save_object", "(", "plot_dict", ",", "outputfile", ")", "\n", "outputpng", "=", "outbasename", "+", "\"-all.png\"", "\n", "finalize_plot", "(", "axes", ",", "outputpng", ",", "xlim", "=", "None", ",", "ylim", "=", "None", ",", "legendloc", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "\n", "", "", "return", "scores_dict", ",", "corr_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.normalize": [[152, 155], ["None"], "function", ["None"], ["", "def", "normalize", "(", "tensor", ",", "min_orig", ",", "max_orig", ",", "min_out", "=", "0", ",", "max_out", "=", "1.", ")", ":", "\n", "    ", "delta", "=", "max_out", "-", "min_out", "\n", "return", "delta", "*", "(", "tensor", "-", "min_orig", ")", "/", "(", "max_orig", "-", "min_orig", ")", "+", "min_out", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.evaluate_similarity_on_reverse_split": [[156, 188], ["glob.glob", "zip", "numpy.array", "simeval", "scipy.stats.spearmanr", "os.path.join", "os.path.join", "open", "csv.reader", "list"], "function", ["None"], ["", "def", "evaluate_similarity_on_reverse_split", "(", "filter_dictionary", ",", "simeval", ",", "dataset", ",", "i_split", ")", ":", "\n", "\n", "    ", "folder", "=", "'/data2/text/similarities_datasets/splitted'", "\n", "\n", "split_part", "=", "\"split_{:d}\"", ".", "format", "(", "i_split", ")", "\n", "label", "=", "dataset", "+", "\"-\"", "+", "split_part", "\n", "dirname", "=", "dataset", "\n", "fsplits", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"*.csv\"", ")", ")", ")", "\n", "\n", "# all the splits except the one corresponding to index i", "\n", "fsplits", "=", "[", "f", "for", "f", "in", "fsplits", "if", "not", "(", "split_part", "in", "f", ")", "]", "\n", "\n", "#now merge all the fsplits", "\n", "lines", "=", "[", "]", "\n", "for", "fname", "in", "fsplits", ":", "\n", "        ", "with", "open", "(", "fname", ",", "'r'", ")", "as", "instream", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "instream", ",", "delimiter", "=", "' '", ",", "skipinitialspace", "=", "True", ")", "\n", "lines", "+=", "list", "(", "reader", ")", "\n", "\n", "\n", "# full_count = len(lines)", "\n", "", "", "ind1", ",", "ind2", ",", "humscores", "=", "zip", "(", "\n", "*", "(", "(", "filter_dictionary", "[", "w1", "]", ",", "filter_dictionary", "[", "w2", "]", ",", "sc", ")", "for", "(", "w1", ",", "w2", ",", "sc", ")", "in", "lines", "if", "(", "w1", "in", "filter_dictionary", ")", "and", "(", "w2", "in", "filter_dictionary", ")", ")", ")", "\n", "\n", "# count_tot = len(words1)", "\n", "\n", "humscores", "=", "np", ".", "array", "(", "humscores", ",", "dtype", "=", "np", ".", "float", ")", "\n", "simscores", "=", "simeval", "(", "ind1", ",", "ind2", ")", "\n", "\n", "corr", ",", "p_value", "=", "spearmanr", "(", "humscores", ",", "simscores", ")", "\n", "corr", "=", "corr", "*", "100", "\n", "return", "corr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.euclidean_cosprod": [[190, 198], ["numpy.sum", "numpy.asarray", "numpy.asarray", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "euclidean_cosprod", "(", "embeddings", ",", "ind1", ",", "ind2", ",", "normalize", "=", "True", ")", ":", "\n", "    ", "emb1", "=", "embeddings", "[", "np", ".", "asarray", "(", "ind1", ")", "]", "\n", "emb2", "=", "embeddings", "[", "np", ".", "asarray", "(", "ind2", ")", "]", "\n", "\n", "scalprods", "=", "np", ".", "sum", "(", "emb1", "*", "emb2", ",", "axis", "=", "1", ")", "\n", "if", "normalize", ":", "\n", "        ", "scalprods", "=", "scalprods", "/", "(", "np", ".", "linalg", ".", "norm", "(", "emb1", ",", "axis", "=", "1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "emb2", ",", "axis", "=", "1", ")", ")", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.riemannian_cosprod": [[219, 241], ["numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.sum", "numpy.matmul", "numpy.sqrt", "numpy.sqrt", "numpy.asarray", "numpy.asarray", "len", "len", "numpy.matmul", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "riemannian_cosprod", "(", "embeddings", ",", "I", ",", "ind1", ",", "ind2", ",", "normalize", "=", "True", ")", ":", "\n", "    ", "Ca", "=", "embeddings", "[", "np", ".", "asarray", "(", "ind1", ")", "]", "\n", "Cb", "=", "embeddings", "[", "np", ".", "asarray", "(", "ind2", ")", "]", "\n", "\n", "#a is a list of vectors", "\n", "#b is a list of vectors", "\n", "#I is the metric", "\n", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "[", "len", "(", "Ca", ".", "shape", ")", ",", "len", "(", "Cb", ".", "shape", ")", "]", ",", "[", "2", ",", "2", "]", ")", "\n", "needed_I_shape", "=", "[", "Ca", ".", "shape", "[", "1", "]", ",", "Cb", ".", "shape", "[", "1", "]", "]", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "needed_I_shape", ",", "I", ".", "shape", ")", "\n", "\n", "ICb", "=", "np", ".", "matmul", "(", "I", ",", "Cb", ".", "T", ")", ".", "T", "\n", "scalprods", "=", "np", ".", "sum", "(", "Ca", "*", "ICb", ",", "axis", "=", "1", ")", "\n", "\n", "if", "normalize", ":", "\n", "        ", "ICa", "=", "np", ".", "matmul", "(", "I", ",", "Ca", ".", "T", ")", ".", "T", "\n", "norms1", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "Ca", "*", "ICa", ",", "axis", "=", "1", ")", ")", "\n", "norms2", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "Cb", "*", "ICb", ",", "axis", "=", "1", ")", ")", "\n", "scalprods", "=", "scalprods", "/", "(", "norms1", "*", "norms2", ")", "\n", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.evaluate_analogies": [[323, 456], ["list", "numpy.sum", "range", "val_dict.items", "numpy.concatenate", "measures.get_acc_from_val", "numpy.concatenate", "measures.get_acc_from_val", "numpy.concatenate", "measures.get_acc_from_val", "glob.glob", "list.append", "itertools.chain.from_iterable", "numpy.matmul", "len", "numpy.array", "measures.analogies_riemannian", "logger.info", "logger.info", "task.split", "tot_vals[].append", "numpy.concatenate", "measures.get_acc_from_val", "all_sem_vals.append", "numpy.concatenate", "measures.get_acc_from_val", "all_syn_vals.append", "numpy.concatenate", "measures.get_acc_from_val", "all_tot_vals.append", "os.path.join", "sorted", "open", "len", "int", "sem_vals[].append", "os.path.join", "[].split", "line.rstrip().split", "zip", "syn_vals[].append", "Exception", "all", "numpy.sum", "len", "line.rstrip", "numpy.mean", "os.path.splitext"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.measures.get_acc_from_val", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.get_acc_from_val", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.get_acc_from_val", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.analogies_riemannian", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.get_acc_from_val", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.get_acc_from_val", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.get_acc_from_val", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["def", "evaluate_analogies", "(", "dictionary", ",", "W", ",", "g", ",", "logger", ",", "filter_dictionary", ",", "datasets", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"", "\n", "\n", "folder", "=", "'/data2/text/analogies_datasets/splitted'", "\n", "\n", "if", "not", "datasets", ":", "\n", "# in each of these folders I expect to find the splits", "\n", "        ", "datasets", "=", "[", "\n", "'capital-common-countries'", ",", "'capital-world'", ",", "'currency'", ",", "\n", "'city-in-state'", ",", "'family'", ",", "'gram1-adjective-to-adverb'", ",", "\n", "'gram2-opposite'", ",", "'gram3-comparative'", ",", "'gram4-superlative'", ",", "\n", "'gram5-present-participle'", ",", "'gram6-nationality-adjective'", ",", "\n", "'gram7-past-tense'", ",", "'gram8-plural'", ",", "'gram9-plural-verbs'", ",", "\n", "]", "\n", "\n", "", "filenames", "=", "[", "]", "\n", "\n", "for", "dirname", "in", "datasets", ":", "\n", "        ", "fsplits", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"*.csv\"", ")", ")", ")", "\n", "filenames", ".", "append", "(", "sorted", "(", "fsplits", ")", ")", "\n", "\n", "", "filenames", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "filenames", ")", ")", "\n", "\n", "\n", "# # to avoid memory overflow, could be increased/decreased", "\n", "# # depending on system and vocab size", "\n", "# split_size = 100", "\n", "\n", "full_count", "=", "0", "# count all questions, including those with unknown words", "\n", "\n", "Cq", "=", "W", "\n", "ICq", "=", "np", ".", "matmul", "(", "g", ",", "Cq", ".", "T", ")", ".", "T", "\n", "sqnormq", "=", "np", ".", "sum", "(", "Cq", "*", "ICq", ",", "axis", "=", "1", ")", "\n", "\n", "val_dict", "=", "{", "}", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "filenames", ")", ")", ":", "\n", "        ", "label", "=", "\"-\"", ".", "join", "(", "os", ".", "path", ".", "splitext", "(", "filenames", "[", "i", "]", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "2", ":", "]", ")", "\n", "\n", "with", "open", "(", "filenames", "[", "i", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "full_data", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "for", "line", "in", "f", "]", "\n", "full_count", "+=", "len", "(", "full_data", ")", "\n", "data", "=", "[", "x", "for", "x", "in", "full_data", "if", "all", "(", "word", "in", "filter_dictionary", "for", "word", "in", "x", ")", "]", "\n", "\n", "", "indices", "=", "np", ".", "array", "(", "[", "[", "dictionary", "[", "word", "]", "for", "word", "in", "row", "]", "for", "row", "in", "data", "]", ")", "\n", "ind1", ",", "ind2", ",", "ind3", ",", "ind4", "=", "indices", ".", "T", "\n", "\n", "howmany", "=", "1", "\n", "predictions", "=", "analogies_riemannian", "(", "W", ",", "g", ",", "ind1", ",", "ind2", ",", "ind3", ",", "ICq", ",", "sqnormq", ",", "howmany", ")", "\n", "\n", "# val = (ind4 == predictions)  # correct predictions", "\n", "val", "=", "[", "int", "(", "i4", "in", "preds", ")", "for", "(", "i4", ",", "preds", ")", "in", "zip", "(", "ind4", ",", "predictions", ")", "]", "# correct predictions", "\n", "\n", "val_dict", "[", "label", "]", "=", "val", "\n", "\n", "logger", ".", "info", "(", "\"%s:\"", "%", "filenames", "[", "i", "]", ")", "\n", "logger", ".", "info", "(", "'ACCURACY TOP1: %.2f%% (%d/%d)'", "%", "\n", "(", "np", ".", "mean", "(", "val", ")", "*", "100", ",", "np", ".", "sum", "(", "val", ")", ",", "len", "(", "val", ")", ")", ")", "\n", "\n", "# categories = [\"sem\", \"syn\", \"tot\"]", "\n", "\n", "", "splitkeys", "=", "[", "\"0\"", ",", "\"1\"", ",", "\"2\"", "]", "\n", "# aggregate scores for the full datasets", "\n", "sem_vals", "=", "{", "}", "\n", "syn_vals", "=", "{", "}", "\n", "tot_vals", "=", "{", "}", "\n", "\n", "for", "split", "in", "splitkeys", ":", "\n", "        ", "sem_vals", "[", "split", "]", "=", "[", "]", "\n", "syn_vals", "[", "split", "]", "=", "[", "]", "\n", "tot_vals", "[", "split", "]", "=", "[", "]", "\n", "\n", "", "for", "task", ",", "val", "in", "val_dict", ".", "items", "(", ")", ":", "\n", "        ", "d", ",", "s", "=", "task", ".", "split", "(", "\"-split_\"", ")", "\n", "\n", "if", "d", "in", "sem_ds", ":", "\n", "            ", "sem_vals", "[", "s", "]", ".", "append", "(", "val", ")", "\n", "", "elif", "d", "in", "syn_ds", ":", "\n", "            ", "syn_vals", "[", "s", "]", ".", "append", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"{:} is not either semantis or syntactic..\"", ".", "format", "(", "d", ")", ")", "\n", "\n", "", "tot_vals", "[", "s", "]", ".", "append", "(", "val", ")", "\n", "\n", "\n", "", "all_sem_vals", "=", "[", "]", "\n", "all_syn_vals", "=", "[", "]", "\n", "all_tot_vals", "=", "[", "]", "\n", "\n", "acc_dict", "=", "{", "}", "\n", "# store aggregated results", "\n", "for", "s", "in", "splitkeys", ":", "\n", "        ", "label", "=", "\"sem-split_\"", "+", "s", "\n", "val", "=", "np", ".", "concatenate", "(", "sem_vals", "[", "s", "]", ")", "\n", "acc_dict", "[", "label", "]", "=", "get_acc_from_val", "(", "val", ")", "\n", "all_sem_vals", ".", "append", "(", "val", ")", "\n", "\n", "label", "=", "\"syn-split_\"", "+", "s", "\n", "val", "=", "np", ".", "concatenate", "(", "syn_vals", "[", "s", "]", ")", "\n", "acc_dict", "[", "label", "]", "=", "get_acc_from_val", "(", "val", ")", "\n", "all_syn_vals", ".", "append", "(", "val", ")", "\n", "\n", "label", "=", "\"tot-split_\"", "+", "s", "\n", "val", "=", "np", ".", "concatenate", "(", "tot_vals", "[", "s", "]", ")", "\n", "acc_dict", "[", "label", "]", "=", "get_acc_from_val", "(", "val", ")", "\n", "all_tot_vals", ".", "append", "(", "val", ")", "\n", "\n", "", "val", "=", "np", ".", "concatenate", "(", "all_sem_vals", ")", "\n", "# count_sem = len(val)", "\n", "acc_dict", "[", "\"sem\"", "]", "=", "get_acc_from_val", "(", "val", ")", "\n", "\n", "val", "=", "np", ".", "concatenate", "(", "all_syn_vals", ")", "\n", "# count_syn = len(val)", "\n", "acc_dict", "[", "\"syn\"", "]", "=", "get_acc_from_val", "(", "val", ")", "\n", "\n", "val", "=", "np", ".", "concatenate", "(", "all_tot_vals", ")", "\n", "# count_tot = len(val)", "\n", "acc_dict", "[", "\"tot\"", "]", "=", "get_acc_from_val", "(", "val", ")", "\n", "\n", "# seen_frac = 100 * count_tot / float(full_count)", "\n", "# tot_acc = 100 * correct_tot / float(count_tot)", "\n", "# sem_acc = 100 * correct_sem / float(count_sem)", "\n", "# syn_acc = 100 * correct_syn / float(count_syn)", "\n", "#", "\n", "# logger.info('Questions seen/total: %.2f%% (%d/%d)' %", "\n", "#       (seen_frac, count_tot, full_count))", "\n", "# logger.info('Semantic accuracy: %.2f%%  (%i/%i)' %", "\n", "#       (sem_acc, correct_sem, count_sem))", "\n", "# logger.info('Syntactic accuracy: %.2f%%  (%i/%i)' %", "\n", "#       (syn_acc, correct_syn, count_syn))", "\n", "# logger.info('Total accuracy: %.2f%%  (%i/%i)' % (tot_acc, correct_tot, count_tot))", "\n", "\n", "return", "acc_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.get_acc_from_val": [[458, 460], ["len", "sum"], "function", ["None"], ["", "def", "get_acc_from_val", "(", "val", ")", ":", "\n", "    ", "return", "100", "*", "sum", "(", "val", ")", "/", "len", "(", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.analogies_riemannian": [[462, 490], ["numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "range", "numpy.argmin().reshape", "sqnormq.reshape", "len", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len", "len", "numpy.matmul", "numpy.argmin"], "function", ["None"], ["", "def", "analogies_riemannian", "(", "embeddings", ",", "I", ",", "ind1", ",", "ind2", ",", "ind3", ",", "ICq", ",", "sqnormq", ",", "howmany", ")", ":", "\n", "    ", "Ca", "=", "embeddings", "[", "np", ".", "asarray", "(", "ind1", ")", "]", "\n", "Cb", "=", "embeddings", "[", "np", ".", "asarray", "(", "ind2", ")", "]", "\n", "Cc", "=", "embeddings", "[", "np", ".", "asarray", "(", "ind3", ")", "]", "\n", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "[", "len", "(", "Ca", ".", "shape", ")", ",", "len", "(", "Cb", ".", "shape", ")", "]", ",", "[", "2", ",", "2", "]", ")", "\n", "needed_I_shape", "=", "[", "Ca", ".", "shape", "[", "1", "]", ",", "Cb", ".", "shape", "[", "1", "]", "]", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "needed_I_shape", ",", "I", ".", "shape", ")", "\n", "\n", "Ct", "=", "Cb", "-", "Ca", "+", "Cc", "\n", "\n", "dists", "=", "-", "2", "*", "np", ".", "matmul", "(", "Ct", ",", "ICq", ".", "T", ")", "+", "sqnormq", ".", "reshape", "(", "1", ",", "-", "1", ")", "#+ sqnormt.reshape(-1,1)", "\n", "\n", "for", "k", "in", "range", "(", "len", "(", "ind1", ")", ")", ":", "\n", "        ", "dists", "[", "k", ",", "ind1", "[", "k", "]", "]", "=", "np", ".", "Inf", "\n", "dists", "[", "k", ",", "ind2", "[", "k", "]", "]", "=", "np", ".", "Inf", "\n", "dists", "[", "k", ",", "ind3", "[", "k", "]", "]", "=", "np", ".", "Inf", "\n", "\n", "", "all_indexes", "=", "np", ".", "argmin", "(", "dists", ",", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "# import pdb; pdb.set_trace()", "\n", "\n", "# indexes_t = select_indexes(np.argsort(distances),", "\n", "#                            to_exclude=[i1, i2, i3],", "\n", "#                            howmany=howmany)", "\n", "# all_indexes.append(indexes_t)", "\n", "\n", "return", "all_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.select_indexes": [[491, 493], ["None"], "function", ["None"], ["", "def", "select_indexes", "(", "indexes", ",", "to_exclude", ",", "howmany", ")", ":", "\n", "    ", "return", "[", "i", "for", "i", "in", "indexes", "if", "i", "not", "in", "to_exclude", "]", "[", ":", "howmany", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_eucl": [[516, 548], ["Exception", "numpy.sqrt().reshape", "numexpr.evaluate", "measures.mean_numexpr", "measures.mean_numexpr", "numpy.sqrt", "numexpr.evaluate"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.mean_numexpr", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.mean_numexpr"], ["", "def", "center_and_normalize_eucl", "(", "embs", ",", "center_before", "=", "False", ",", "center_after", "=", "True", ",", "center_index", "=", "1", ",", "normalize", "=", "True", ")", ":", "\n", "\n", "    ", "if", "center_index", "not", "in", "[", "0", ",", "1", "]", ":", "\n", "        ", "raise", "Exception", "(", "\"center_index can be either 0 for center columns or 1 for center rows\"", ")", "\n", "\n", "# is_mat = True", "\n", "# # I need a np.matrix for this function", "\n", "# if type(embs) is not np.matrixlib.defmatrix.matrix or type(embs) is not scipy.sparse.coo.coo_matrix:", "\n", "#     is_mat = False", "\n", "#     embs = np.matrix(embs)", "\n", "\n", "", "if", "center_before", ":", "\n", "# embs = embs - np.mean(embs, axis=center_index)", "\n", "        ", "embs", "=", "embs", "-", "mean_numexpr", "(", "embs", ",", "center_index", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "# import pdb;pdb.set_trace()", "\n", "        ", "norms", "=", "np", ".", "sqrt", "(", "ne", ".", "evaluate", "(", "\"sum(embs**2, axis=0)\"", ")", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "# norms = np.linalg.norm(embs, axis=0)", "\n", "# embs = embs / norms", "\n", "embs", "=", "ne", ".", "evaluate", "(", "\"embs / norms\"", ")", "\n", "# embs = embs / np.sqrt(np.sum(embs**2, axis=0))", "\n", "# embs = embs / np.linalg.norm(embs, axis=0)", "\n", "\n", "", "if", "center_after", ":", "\n", "# embs = embs - np.mean(embs, axis=center_index)", "\n", "        ", "embs", "=", "embs", "-", "mean_numexpr", "(", "embs", ",", "center_index", ")", "\n", "\n", "# if not is_mat:", "\n", "#     embs = np.array(embs)", "\n", "\n", "", "return", "embs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian": [[550, 561], ["numpy.sqrt().reshape", "numexpr.evaluate", "measures.mean_numexpr", "numpy.matmul", "numpy.sqrt", "numexpr.evaluate().sum", "numexpr.evaluate"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.mean_numexpr"], ["", "def", "center_and_normalize_riemannian", "(", "embs", ",", "g", ",", "center", "=", "True", ",", "normalize", "=", "True", ")", ":", "\n", "\n", "    ", "if", "center", ":", "\n", "        ", "embs", "=", "embs", "-", "mean_numexpr", "(", "embs", ",", "0", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "        ", "gembs", "=", "np", ".", "matmul", "(", "g", ",", "embs", ".", "T", ")", ".", "T", "\n", "norms", "=", "np", ".", "sqrt", "(", "ne", ".", "evaluate", "(", "\"embs * gembs\"", ")", ".", "sum", "(", "axis", "=", "1", ")", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "embs", "=", "ne", ".", "evaluate", "(", "\"embs / norms\"", ")", "\n", "\n", "", "return", "embs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.mean_numexpr": [[573, 582], ["mean.reshape", "numexpr.evaluate", "mean.reshape", "Exception", "numexpr.evaluate"], "function", ["None"], ["def", "mean_numexpr", "(", "embs", ",", "index", ")", ":", "\n", "    ", "if", "index", "==", "0", ":", "\n", "        ", "mean", "=", "ne", ".", "evaluate", "(", "\"sum(embs, axis=0)\"", ")", "/", "embs", ".", "shape", "[", "0", "]", "\n", "return", "mean", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "", "elif", "index", "==", "1", ":", "\n", "        ", "mean", "=", "ne", ".", "evaluate", "(", "\"sum(embs, axis=1)\"", ")", "/", "embs", ".", "shape", "[", "1", "]", "\n", "return", "mean", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"index can be either 0 or 1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.merge_dicts": [[584, 595], ["isinstance", "isinstance", "measures.merge_dicts"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.measures.merge_dicts"], ["", "", "def", "merge_dicts", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"merges b into a\"", "\n", "for", "key", "in", "b", ":", "\n", "        ", "if", "isinstance", "(", "b", "[", "key", "]", ",", "dict", ")", ":", "\n", "            ", "if", "(", "key", "in", "a", ")", "and", "isinstance", "(", "a", "[", "key", "]", ",", "dict", ")", ":", "\n", "                ", "merge_dicts", "(", "a", "[", "key", "]", ",", "b", "[", "key", "]", ")", "\n", "", "else", ":", "\n", "                ", "a", "[", "key", "]", "=", "b", "[", "key", "]", "\n", "", "", "else", ":", "\n", "            ", "a", "[", "key", "]", "=", "b", "[", "key", "]", "\n", "", "", "return", "a", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.preprocess": [[32, 36], ["None"], "methods", ["None"], ["    ", "@", "abstractmethod", "\n", "def", "preprocess", "(", "self", ",", "fin", ")", ":", "\n", "        ", "\"\"\" what to do to the newly opened text file as preprocessing \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.tuple_from_params": [[37, 40], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "tuple_from_params", "(", "self", ",", "parameters", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_dictionary": [[41, 47], ["readers.EmbeddingsFileReader.dicts_from_wordslist", "open", "readers.EmbeddingsFileReader.preprocess", "line.rstrip().split", "fin.readlines", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.dicts_from_wordslist", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.preprocess"], ["", "def", "read_dictionary", "(", "self", ",", "inputname", ")", ":", "\n", "        ", "\"\"\" read the dictionary from inputfile \"\"\"", "\n", "with", "open", "(", "inputname", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "self", ".", "preprocess", "(", "fin", ")", "\n", "words", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "line", "in", "fin", ".", "readlines", "(", ")", "]", "\n", "", "return", "self", ".", "dicts_from_wordslist", "(", "words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_word_counts": [[48, 54], ["open", "readers.EmbeddingsFileReader.preprocess", "int", "fin.readlines", "line.rstrip().split", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.preprocess"], ["", "def", "read_word_counts", "(", "self", ",", "inputname", ")", ":", "\n", "        ", "\"\"\" read the word counts from inputfile \"\"\"", "\n", "with", "open", "(", "inputname", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "self", ".", "preprocess", "(", "fin", ")", "\n", "counts", "=", "[", "int", "(", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "[", "1", "]", ")", "for", "line", "in", "fin", ".", "readlines", "(", ")", "]", "\n", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.dicts_from_wordslist": [[55, 60], ["len", "dict", "zip", "enumerate", "dictionary.values", "dictionary.keys"], "methods", ["None"], ["", "def", "dicts_from_wordslist", "(", "self", ",", "words", ")", ":", "\n", "        ", "dictionary_size", "=", "len", "(", "words", ")", "\n", "dictionary", "=", "{", "w", ":", "idx", "for", "idx", ",", "w", "in", "enumerate", "(", "words", ")", "}", "\n", "reversed_dictionary", "=", "dict", "(", "zip", "(", "dictionary", ".", "values", "(", ")", ",", "dictionary", ".", "keys", "(", ")", ")", ")", "\n", "return", "(", "dictionary_size", ",", "dictionary", ",", "reversed_dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.unpack_split_line": [[61, 67], ["line.rstrip().split", "numpy.array", "list", "itertools.chain", "line.rstrip", "readers.EmbeddingsFileReader.tuple_from_params"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.tuple_from_params"], ["", "def", "unpack_split_line", "(", "self", ",", "line", ",", "vecsize", ",", "onlyu", ")", ":", "\n", "        ", "arr", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "\n", "word", "=", "arr", "[", "0", "]", "\n", "parameters", "=", "np", ".", "array", "(", "arr", "[", "1", ":", "]", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "return", "list", "(", "itertools", ".", "chain", "(", "[", "word", "]", ",", "self", ".", "tuple_from_params", "(", "parameters", ",", "vecsize", ",", "onlyu", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_embeddings": [[68, 78], ["readers.EmbeddingsFileReader.dicts_from_wordslist", "open", "readers.EmbeddingsFileReader.preprocess", "readers.EmbeddingsFileReader.get_embeddings_fromfile"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.dicts_from_wordslist", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.preprocess", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.get_embeddings_fromfile"], ["", "def", "read_embeddings", "(", "self", ",", "inputname", ",", "vecsize", ",", "consideronlyfirstvec", ",", "words_set", "=", "None", ")", ":", "\n", "        ", "\"\"\" read the embeddings from inputfile \"\"\"", "\n", "with", "open", "(", "inputname", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "self", ".", "preprocess", "(", "fin", ")", "\n", "words", ",", "u_embeddings", ",", "v_embeddings", "=", "self", ".", "get_embeddings_fromfile", "(", "fin", ",", "vecsize", ",", "consideronlyfirstvec", ",", "words_set", ")", "\n", "\n", "", "dictionary_size", ",", "dictionary", ",", "reversed_dictionary", "=", "self", ".", "dicts_from_wordslist", "(", "words", ")", "\n", "\n", "# u_biases and v_biases are not returned at the moment since we do not know what to do with them", "\n", "return", "(", "dictionary_size", ",", "dictionary", ",", "reversed_dictionary", ",", "u_embeddings", ",", "v_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.GloVeEmbeddingsFileReader.preprocess": [[82, 84], ["None"], "methods", ["None"], ["    ", "def", "preprocess", "(", "self", ",", "fin", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.GloVeEmbeddingsFileReader.tuple_from_params": [[85, 102], ["len", "ValueError"], "methods", ["None"], ["", "def", "tuple_from_params", "(", "self", ",", "parameters", ",", "vecsize", ",", "onlyu", ")", ":", "\n", "\n", "        ", "l", "=", "len", "(", "parameters", ")", "\n", "if", "l", "!=", "vecsize", "and", "l", "!=", "2", "*", "vecsize", "+", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\"the vecsize passed is not compatible with the observation of line lenghts in the inputfile: line length = %s\"", "%", "l", ")", "\n", "\n", "", "u_w", "=", "parameters", "[", ":", "vecsize", "]", "\n", "if", "onlyu", ":", "\n", "            ", "bias_u", "=", "None", "\n", "v_w", "=", "None", "\n", "bias_v", "=", "None", "\n", "", "else", ":", "\n", "            ", "bias_u", "=", "parameters", "[", "vecsize", "]", "\n", "v_w", "=", "parameters", "[", "vecsize", "+", "1", ":", "-", "1", "]", "\n", "bias_v", "=", "parameters", "[", "-", "1", "]", "\n", "\n", "", "return", "(", "u_w", ",", "bias_u", ",", "v_w", ",", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.GloVeEmbeddingsFileReader.get_embeddings_fromfile": [[103, 114], ["zip", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "zip", "readers.GloVeEmbeddingsFileReader.unpack_split_line", "filestream.readlines", "zip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.unpack_split_line"], ["", "def", "get_embeddings_fromfile", "(", "self", ",", "filestream", ",", "vecsize", ",", "consideronlyfirstvec", ",", "words_set", "=", "None", ")", ":", "\n", "        ", "words", ",", "u_embeddings", ",", "u_biases", ",", "v_embeddings", ",", "v_biases", "=", "zip", "(", "*", "[", "self", ".", "unpack_split_line", "(", "line", ",", "vecsize", ",", "consideronlyfirstvec", ")", "for", "line", "in", "filestream", ".", "readlines", "(", ")", "]", ")", "\n", "if", "words_set", ":", "\n", "            ", "words", ",", "u_embeddings", ",", "u_biases", ",", "v_embeddings", ",", "v_biases", "=", "zip", "(", "*", "[", "(", "w", ",", "uw", ",", "bu", ",", "vw", ",", "bv", ")", "for", "w", ",", "uw", ",", "bu", ",", "vw", ",", "bv", "in", "zip", "(", "words", ",", "u_embeddings", ",", "u_biases", ",", "v_embeddings", ",", "v_biases", ")", "if", "w", "in", "words_set", "]", ")", "\n", "", "u_embeddings", "=", "np", ".", "array", "(", "u_embeddings", ")", "\n", "u_biases", "=", "np", ".", "array", "(", "u_biases", ")", "\n", "v_embeddings", "=", "np", ".", "array", "(", "v_embeddings", ")", "\n", "v_biases", "=", "np", ".", "array", "(", "v_biases", ")", "\n", "return", "(", "words", ",", "u_embeddings", ",", "v_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.preprocess": [[118, 125], ["fin.readline", "fin.readline().split", "fin.seek", "fin.readline", "fin.readline"], "methods", ["None"], ["    ", "def", "preprocess", "(", "self", ",", "fin", ")", ":", "\n", "        ", "\"\"\" here I need to skip the header and the first word if it is <\\s> - (what is this tag that word2vec introduces?) \"\"\"", "\n", "fin", ".", "readline", "(", ")", "\n", "word", "=", "fin", ".", "readline", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "if", "not", "word", "==", "'</s>'", ":", "\n", "            ", "fin", ".", "seek", "(", "0", ")", "\n", "fin", ".", "readline", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.tuple_from_params": [[126, 138], ["len", "ValueError"], "methods", ["None"], ["", "", "def", "tuple_from_params", "(", "self", ",", "parameters", ",", "vecsize", ",", "onlyu", ")", ":", "\n", "        ", "l", "=", "len", "(", "parameters", ")", "\n", "if", "l", "!=", "vecsize", "and", "l", "!=", "2", "*", "vecsize", ":", "\n", "            ", "raise", "ValueError", "(", "\"the vecsize passed is not compatible with the observation of line lenghts in the inputfile: line length = %s\"", "%", "l", ")", "\n", "\n", "", "u_w", "=", "parameters", "[", ":", "vecsize", "]", "\n", "if", "onlyu", ":", "\n", "            ", "v_w", "=", "None", "\n", "", "else", ":", "\n", "            ", "v_w", "=", "parameters", "[", "vecsize", ":", "]", "\n", "\n", "", "return", "(", "u_w", ",", "v_w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.Word2vecEmbeddingsFileReader.get_embeddings_fromfile": [[139, 146], ["zip", "numpy.array", "numpy.array", "zip", "readers.Word2vecEmbeddingsFileReader.unpack_split_line", "filestream.readlines", "zip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.unpack_split_line"], ["", "def", "get_embeddings_fromfile", "(", "self", ",", "filestream", ",", "vecsize", ",", "consideronlyfirstvec", ",", "words_set", "=", "None", ")", ":", "\n", "        ", "words", ",", "u_embeddings", ",", "v_embeddings", "=", "zip", "(", "*", "[", "self", ".", "unpack_split_line", "(", "line", ",", "vecsize", ",", "consideronlyfirstvec", ")", "for", "line", "in", "filestream", ".", "readlines", "(", ")", "]", ")", "\n", "if", "words_set", ":", "\n", "            ", "words", ",", "u_embeddings", ",", "v_embeddings", "=", "zip", "(", "*", "[", "(", "w", ",", "uw", ",", "vw", ")", "for", "w", ",", "uw", ",", "vw", "in", "zip", "(", "words", ",", "u_embeddings", ",", "v_embeddings", ")", "if", "w", "in", "words_set", "]", ")", "\n", "", "u_embeddings", "=", "np", ".", "array", "(", "u_embeddings", ")", "\n", "v_embeddings", "=", "np", ".", "array", "(", "v_embeddings", ")", "\n", "return", "(", "words", ",", "u_embeddings", ",", "v_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.rmtxt": [[7, 11], ["s.endswith", "os.path.splitext"], "function", ["None"], ["def", "rmtxt", "(", "s", ")", ":", "\n", "    ", "if", "s", ".", "endswith", "(", "\".txt\"", ")", ":", "\n", "        ", "s", "=", "os", ".", "path", ".", "splitext", "(", "s", ")", "[", "0", "]", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.get_reader": [[12, 23], ["os.path.basename", "os.path.basename.startswith", "readers.GloVeEmbeddingsFileReader", "os.path.basename.startswith", "readers.Word2vecEmbeddingsFileReader", "RuntimeError"], "function", ["None"], ["", "def", "get_reader", "(", "inputfilename", ")", ":", "\n", "    ", "basename", "=", "os", ".", "path", ".", "basename", "(", "inputfilename", ")", "\n", "reader", "=", "None", "\n", "if", "basename", ".", "startswith", "(", "'glove'", ")", ":", "\n", "        ", "reader", "=", "GloVeEmbeddingsFileReader", "(", ")", "\n", "", "elif", "basename", ".", "startswith", "(", "'word2vec'", ")", ":", "\n", "        ", "reader", "=", "Word2vecEmbeddingsFileReader", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "'the inputfilename \\'%s\\'does not start with either glove or word2vec so I do not know how to read the word embeddings'", "%", "basename", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.read_selected_words": [[24, 28], ["open", "line.rstrip().split", "fin.readlines", "line.rstrip"], "function", ["None"], ["", "def", "read_selected_words", "(", "inputname", ")", ":", "\n", "    ", "with", "open", "(", "inputname", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "words", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "for", "line", "in", "fin", ".", "readlines", "(", ")", "]", "\n", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.extract_vocabulary_from": [[148, 152], ["open", "set", "line.rstrip().split", "fin.readlines", "line.rstrip"], "function", ["None"], ["", "", "def", "extract_vocabulary_from", "(", "vocabfile", ")", ":", "\n", "    ", "with", "open", "(", "vocabfile", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "vocab_words", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "line", "in", "fin", ".", "readlines", "(", ")", "]", "\n", "vocab_words", "=", "set", "(", "vocab_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.print_array": [[217, 221], ["max", "print", "len", "w.ljust", "str"], "function", ["None"], ["", "", "def", "print_array", "(", "arr", ")", ":", "\n", "    ", "mw", "=", "max", "(", "len", "(", "w", ")", "for", "w", ",", "d", "in", "arr", ")", "\n", "for", "(", "w", ",", "d", ")", "in", "arr", ":", "\n", "        ", "print", "(", "\" \"", "+", "\"\\t\"", ".", "join", "(", "(", "w", ".", "ljust", "(", "mw", ")", ",", "str", "(", "d", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.write_hdf": [[223, 233], ["tables.open_file", "tables.Atom.from_dtype", "f.create_earray", "range", "f.root.embeddings.append"], "function", ["None"], ["", "", "def", "write_hdf", "(", "x", ",", "table_name", "=", "'embeddings'", ",", "outputname", "=", "\"table_test.hdf\"", ")", ":", "\n", "    ", "with", "tables", ".", "open_file", "(", "outputname", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "atom", "=", "tables", ".", "Atom", ".", "from_dtype", "(", "x", ".", "dtype", ")", "\n", "\n", "vec_size", "=", "300", "\n", "array_c", "=", "f", ".", "create_earray", "(", "f", ".", "root", ",", "table_name", ",", "atom", ",", "(", "0", ",", "vec_size", ")", ")", "\n", "\n", "chunk_size", "=", "500", "\n", "for", "i", "in", "range", "(", "0", ",", "70000", ",", "chunk_size", ")", ":", "\n", "            ", "f", ".", "root", ".", "embeddings", ".", "append", "(", "x", "[", "i", ":", "i", "+", "chunk_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.read_hdf": [[235, 241], ["tables.open_file"], "function", ["None"], ["", "", "", "def", "read_hdf", "(", "filename", ",", "table_name", "=", "'embeddings'", ")", ":", "\n", "    ", "with", "tables", ".", "open_file", "(", "filename", ")", "as", "f", ":", "\n", "# print(f.root.embeddings)", "\n", "        ", "x", "=", "f", ".", "root", "[", "table_name", "]", "[", ":", ",", ":", "]", "\n", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.initialize_plot": [[5, 12], ["matplotlib.figure", "plt.figure.add_subplot", "figure.add_subplot.set_title", "figure.add_subplot.set_xlabel", "figure.add_subplot.set_ylabel"], "function", ["None"], ["def", "initialize_plot", "(", "title", ",", "xlabel", "=", "None", ",", "ylabel", "=", "None", ",", "figsize", "=", "None", ")", ":", "\n", "    ", "figure", "=", "plt", ".", "figure", "(", "figsize", "=", "figsize", ")", "\n", "axes", "=", "figure", ".", "add_subplot", "(", "1", ",", "1", ",", "1", ")", "\n", "axes", ".", "set_title", "(", "title", ")", "\n", "axes", ".", "set_xlabel", "(", "xlabel", ")", "\n", "axes", ".", "set_ylabel", "(", "ylabel", ")", "\n", "return", "axes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.finalize_plot": [[13, 27], ["matplotlib.savefig", "axes.set_xlim", "axes.set_ylim", "axes.legend", "axes.legend"], "function", ["None"], ["", "def", "finalize_plot", "(", "axes", ",", "outname", ",", "xlim", "=", "None", ",", "ylim", "=", "None", ",", "legendloc", "=", "None", ")", ":", "\n", "    ", "if", "xlim", ":", "\n", "        ", "axes", ".", "set_xlim", "(", "xlim", "[", "0", "]", ",", "xlim", "[", "1", "]", ")", "\n", "", "if", "ylim", ":", "\n", "        ", "axes", ".", "set_ylim", "(", "ylim", "[", "0", "]", ",", "ylim", "[", "1", "]", ")", "\n", "\n", "", "bbox_extra_artists", "=", "None", "\n", "if", "legendloc", "==", "\"outside\"", ":", "\n", "        ", "lgd", "=", "axes", ".", "legend", "(", "loc", "=", "'center left'", ",", "bbox_to_anchor", "=", "(", "1", ",", "0.5", ")", ")", "\n", "bbox_extra_artists", "=", "[", "lgd", "]", "\n", "", "else", ":", "\n", "        ", "axes", ".", "legend", "(", "loc", "=", "legendloc", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "outname", ",", "bbox_extra_artists", "=", "bbox_extra_artists", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.save_object": [[28, 31], ["open", "pickle.dump"], "function", ["None"], ["", "def", "save_object", "(", "obj", ",", "outname", ")", ":", "\n", "    ", "with", "open", "(", "outname", ",", "'wb'", ")", "as", "outstream", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "outstream", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.load_data_dict": [[32, 36], ["open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "", "def", "load_data_dict", "(", "dataname", ")", ":", "\n", "    ", "with", "open", "(", "dataname", ",", "'br'", ")", "as", "datastream", ":", "\n", "        ", "data_dict", "=", "pickle", ".", "load", "(", "datastream", ")", "\n", "", "return", "data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.merge_data_dicts": [[38, 61], ["numpy.array", "numpy.array", "numpy.array", "range", "numpy.all", "ValueError", "numpy.all", "ValueError", "numpy.all", "ValueError", "len", "data_dict_merged[].append"], "function", ["None"], ["", "def", "merge_data_dicts", "(", "data_dict_list", ")", ":", "\n", "    ", "methods", "=", "np", ".", "array", "(", "[", "ddc", "[", "'plot_method'", "]", "for", "ddc", "in", "data_dict_list", "]", ")", "\n", "plot_method_name", "=", "methods", "[", "0", "]", "\n", "if", "not", "np", ".", "all", "(", "methods", "==", "plot_method_name", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"the plot specifications in the different input files must have all the same plot_method.\"", ")", "\n", "\n", "", "xlabels", "=", "np", ".", "array", "(", "[", "ddc", "[", "'x-label'", "]", "for", "ddc", "in", "data_dict_list", "]", ")", "\n", "xlabel", "=", "xlabels", "[", "0", "]", "\n", "if", "not", "np", ".", "all", "(", "xlabels", "==", "xlabel", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"the plot specifications in the different input files must have the same data types (x-labels did not match).\"", ")", "\n", "\n", "", "ylabels", "=", "np", ".", "array", "(", "[", "ddc", "[", "'y-label'", "]", "for", "ddc", "in", "data_dict_list", "]", ")", "\n", "ylabel", "=", "ylabels", "[", "0", "]", "\n", "if", "not", "np", ".", "all", "(", "ylabels", "==", "ylabel", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"the plot specifications in the different input files must have the same data types (y-labels did not match).\"", ")", "\n", "\n", "", "data_dict_merged", "=", "data_dict_list", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "data_dict_list", ")", ")", ":", "\n", "        ", "data_dict_merged", "[", "'data'", "]", ".", "append", "(", "data_dict_list", "[", "i", "]", "[", "'data'", "]", ")", "\n", "\n", "", "return", "data_dict_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.plot_data": [[63, 67], ["getattr", "getattr."], "function", ["None"], ["", "def", "plot_data", "(", "data", ",", "axes", ",", "plot_method", ",", "plot_args", "=", "[", "]", ",", "plot_kwargs", "=", "{", "}", ")", ":", "\n", "    ", "plot_method", "=", "getattr", "(", "plt", ",", "plot_method", ")", "\n", "for", "dc", "in", "data", ":", "\n", "        ", "plot_method", "(", "dc", "[", "'x'", "]", ",", "dc", "[", "'y'", "]", ",", "*", "plot_args", ",", "label", "=", "dc", "[", "'label'", "]", ",", "**", "plot_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.create_plot_data_dict": [[69, 75], ["zip"], "function", ["None"], ["", "", "def", "create_plot_data_dict", "(", "xs_list", ",", "ys_list", ",", "label_list", ",", "x_label", ",", "y_label", ",", "plot_method_name", "=", "\"plot\"", ")", ":", "\n", "    ", "data", "=", "[", "{", "'x'", ":", "xs", ",", "'y'", ":", "ys", ",", "'label'", ":", "label", "}", "for", "(", "xs", ",", "ys", ",", "label", ")", "in", "zip", "(", "xs_list", ",", "ys_list", ",", "label_list", ")", "]", "\n", "\n", "dict_tosave", "=", "{", "'plot_method'", ":", "plot_method_name", ",", "'x-label'", ":", "x_label", ",", "'y-label'", ":", "y_label", ",", "'data'", ":", "data", "}", "\n", "return", "dict_tosave", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.get_ok_methods": [[77, 87], ["list", "zip", "set", "ok_method", "list.append"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method"], ["", "def", "get_ok_methods", "(", "collection", ",", "ok_method", ")", ":", "\n", "    ", "couples_methods", "=", "[", "]", "\n", "for", "d", "in", "collection", ":", "\n", "        ", "for", "m", "in", "collection", "[", "d", "]", ":", "\n", "            ", "if", "ok_method", "(", "m", ")", ":", "\n", "                ", "lm", "=", "\"limit-\"", "+", "m", "\n", "couples_methods", ".", "append", "(", "(", "m", ",", "lm", ")", ")", "\n", "", "", "", "couples_methods", "=", "list", "(", "set", "(", "couples_methods", ")", ")", "\n", "methods", ",", "limit_methods", "=", "zip", "(", "*", "couples_methods", ")", "\n", "return", "methods", ",", "limit_methods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.get_ok_datasets": [[89, 95], ["ok_dataset", "datasets.append"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_dataset"], ["", "def", "get_ok_datasets", "(", "collection", ",", "ok_dataset", ")", ":", "\n", "    ", "datasets", "=", "[", "]", "\n", "for", "d", "in", "collection", ":", "\n", "        ", "if", "ok_dataset", "(", "d", ")", ":", "\n", "            ", "datasets", ".", "append", "(", "d", ")", "\n", "", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.is_method": [[97, 100], ["method_str.startswith"], "function", ["None"], ["", "def", "is_method", "(", "method_str", ",", "theta", ")", ":", "\n", "#     'u-plog-ud-cnI-I'", "\n", "    ", "return", "method_str", ".", "startswith", "(", "\"{:}-plog\"", ".", "format", "(", "theta", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.is_limit_method": [[102, 105], ["method_str.startswith"], "function", ["None"], ["", "def", "is_limit_method", "(", "method_str", ",", "theta", ")", ":", "\n", "#     'limit-u-plog-ud-cnI-I'", "\n", "    ", "return", "method_str", ".", "startswith", "(", "\"limit-{:}-plog\"", ".", "format", "(", "theta", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.is_in_point": [[107, 111], ["[].split", "method_str.split"], "function", ["None"], ["", "def", "is_in_point", "(", "method_str", ",", "point_name", ")", ":", "\n", "#     'u-plog-ud-cnI-I'", "\n", "    ", "found_pname", "=", "method_str", ".", "split", "(", "\"-plog-\"", ")", "[", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "return", "found_pname", "==", "point_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.is_a_split": [[113, 122], ["dataset_str.split", "len", "Exception"], "function", ["None"], ["", "def", "is_a_split", "(", "dataset_str", ")", ":", "\n", "    ", "arr", "=", "dataset_str", ".", "split", "(", "\"-split_\"", ")", "\n", "l", "=", "len", "(", "arr", ")", "\n", "if", "l", "==", "1", ":", "\n", "        ", "return", "False", "\n", "", "elif", "l", "==", "2", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"what is this? Unexpected dataset: {:}\"", ".", "format", "(", "dataset_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.__init__": [[157, 160], ["spaces.Space._get_zero"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere._get_zero"], ["    ", "def", "__init__", "(", "self", ",", "dim", ")", ":", "\n", "        ", "self", ".", "_dim", "=", "dim", "\n", "self", ".", "_x0", "=", "self", ".", "_get_zero", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.median": [[161, 175], ["spaces.Space._fixed_point"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._fixed_point"], ["", "def", "median", "(", "self", ",", "points", ",", "**", "fpkwargs", ")", ":", "\n", "        ", "\"\"\" Calculate the median in the Space (with the fixed point method).\n        The median is meant the point minimizing the sum of the distances.\n        \n        Args:\n            points (ndarray) : 2D array, representing a set of points.\n                Each row is a point in the Space.\n\n        Returns:\n            ndarray : The median point in the Space.\n\n        \"\"\"", "\n", "\n", "return", "self", ".", "_fixed_point", "(", "points", ",", "self", ".", "_psif1", ",", "**", "fpkwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.mean": [[177, 190], ["spaces.Space._fixed_point"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._fixed_point"], ["", "def", "mean", "(", "self", ",", "points", ",", "**", "fpkwargs", ")", ":", "\n", "        ", "\"\"\" Calculate the mean in the Space (with the fixed point method).\n        The mean is meant the point minimizing the sum of the squared distances.\n        \n        Args:\n            points (ndarray) : 2D array, representing a set of points.\n                Each row is a point in the Space.\n\n        Returns:\n            ndarray : The mean point in the Space.\n\n        \"\"\"", "\n", "return", "self", ".", "_fixed_point", "(", "points", ",", "self", ".", "_psif2", ",", "**", "fpkwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.dist_hist": [[192, 222], ["spaces.Space.dist", "numpy.mean", "numpy.sqrt", "numpy.sqrt", "numpy.min", "numpy.max", "histkwargs.get", "histkwargs.update", "numpy.histogram", "numpy.dot", "len", "numpy.sum", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.dist", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "dist_hist", "(", "self", ",", "points", ",", "xbar", ",", "**", "histkwargs", ")", ":", "\n", "        ", "\"\"\"Calculate the distances in the space and then make a histogram.\n\n        Args:\n            points (type): 2D array, representing a set of points.\n                Each row is a point in the Space.\n            xbar (type): 1D (or 2D) array. `reference` argument of `space.dist`.\n            **histkwargs (type): Optional arguments of `np.histogram` in dictionary form.\n\n        Returns:\n            sqrt_mean_sq_dist -> the sqrt of the mean of the squared distances\n            dmin, dmax, dmean, dstd -> min, max, mean and std of the distances\n            histogram of the distances, as returned by `np.histogram`\n\n        \"\"\"", "\n", "dists", "=", "self", ".", "dist", "(", "points", ",", "reference", "=", "xbar", ")", "\n", "dmean", "=", "np", ".", "mean", "(", "dists", ")", "\n", "diff", "=", "dists", "-", "dmean", "\n", "dvar", "=", "np", ".", "dot", "(", "diff", ",", "diff", ")", "/", "len", "(", "diff", ")", "\n", "sqrt_mean_sq_dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "dists", "**", "2", ")", "/", "len", "(", "dists", ")", ")", "\n", "\n", "dstd", "=", "np", ".", "sqrt", "(", "dvar", ")", "\n", "dmin", "=", "np", ".", "min", "(", "dists", ")", "\n", "dmax", "=", "np", ".", "max", "(", "dists", ")", "\n", "\n", "bins", "=", "histkwargs", ".", "get", "(", "'bins'", ",", "'auto'", ")", "\n", "histkwargs", ".", "update", "(", "{", "'bins'", ":", "bins", "}", ")", "\n", "hi", "=", "np", ".", "histogram", "(", "dists", ",", "**", "histkwargs", ")", "\n", "\n", "return", "sqrt_mean_sq_dist", ",", "dmin", ",", "dmax", ",", "dmean", ",", "dstd", ",", "hi", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.analogy_measure": [[223, 249], ["spaces.Space.parallel_transport", "spaces.Space.parallel_transport", "numpy.linalg.norm", "spaces.Space.logmap", "spaces.Space.logmap", "spaces.Space.logmap", "spaces.Space.logmap"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.parallel_transport", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.parallel_transport", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.logmap", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.logmap", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.logmap", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.logmap"], ["", "def", "analogy_measure", "(", "self", ",", "x_a", ",", "x_b", ",", "x_c", ",", "x_d", ",", "x_0", "=", "None", ")", ":", "\n", "        ", "\"\"\"Evaluate analogy measure of a:b=c:d\n        the analogy measure is calculated in x_0, since all the vectors\n        must be in the same tangent space to be compared.\n\n        Args:\n            x_a : embedding of the word a involved in the word analogy.\n            x_b : embedding of the word b involved in the word analogy.\n            x_c : embedding of the word c involved in the word analogy.\n            x_d : embedding of the word d involved in the word analogy.\n            x_0 : point of the space where to evaluate the analogy measure.\n\n        Returns:\n            float: word analogy measure.\n\n        \"\"\"", "\n", "\n", "# if x_0 is not given explicitly, x_0 is set to the zero of the space,", "\n", "# often corresponding to uniform probability distribution", "\n", "# e.g. in the simplex: mu0=[1/D,1/D, ... , 1/D] -> x0=sqrt(mu0)", "\n", "if", "x_0", "is", "None", ":", "\n", "            ", "x_0", "=", "self", ".", "_x0", "\n", "\n", "", "ptra0_logab", "=", "self", ".", "parallel_transport", "(", "self", ".", "logmap", "(", "x_a", ",", "x_b", ")", ",", "x_a", ",", "self", ".", "logmap", "(", "x_a", ",", "x_0", ")", ")", "\n", "ptrc0_logcd", "=", "self", ".", "parallel_transport", "(", "self", ".", "logmap", "(", "x_c", ",", "x_d", ")", ",", "x_c", ",", "self", ".", "logmap", "(", "x_c", ",", "x_0", ")", ")", "\n", "return", "np", ".", "linalg", ".", "norm", "(", "ptrc0_logcd", "-", "ptra0_logab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._fixed_point": [[250, 257], ["spaces.Space._check_points", "spaces.Space._x0_fp", "fpkwargs.get", "fpkwargs.update", "scipy.optimize.fixed_point"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._check_points", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere._x0_fp"], ["", "def", "_fixed_point", "(", "self", ",", "points", ",", "psif", ",", "**", "fpkwargs", ")", ":", "\n", "        ", "self", ".", "_check_points", "(", "points", ")", "\n", "x0", "=", "self", ".", "_x0_fp", "(", "points", ")", "\n", "method", "=", "fpkwargs", ".", "get", "(", "'method'", ",", "'iteration'", ")", "\n", "fpkwargs", ".", "update", "(", "{", "'method'", ":", "method", "}", ")", "\n", "xhat", "=", "scipy", ".", "optimize", ".", "fixed_point", "(", "psif", ",", "x0", ",", "args", "=", "[", "points", "]", ",", "**", "fpkwargs", ")", "\n", "return", "xhat", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._check_points": [[258, 260], ["len"], "methods", ["None"], ["", "def", "_check_points", "(", "self", ",", "points", ")", ":", "\n", "        ", "assert", "len", "(", "points", ".", "shape", ")", "==", "2", ",", "\"`points` must be a 2D ndarray\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._check_reference": [[261, 263], ["len", "numpy.array"], "methods", ["None"], ["", "def", "_check_reference", "(", "self", ",", "reference", ")", ":", "\n", "        ", "assert", "(", "len", "(", "reference", ".", "shape", ")", "==", "np", ".", "array", "(", "[", "1", ",", "2", "]", ")", ")", ".", "any", "(", ")", ",", "\"`reference` must be either a 1D or a 2D ndarray\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.dist": [[264, 284], ["spaces.Space._check_points", "spaces.Space._check_reference"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._check_points", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._check_reference"], ["", "@", "abstractmethod", "\n", "def", "dist", "(", "self", ",", "points", ",", "reference", "=", "None", ")", ":", "\n", "        ", "\"\"\"Calculate distances in the Space.\n\n        Args:\n            points (ndarray) : 2D array, representing a set of points.\n                Each row is a point in the Space.\n\n            reference (ndarray): 1D (or 2D) array. The reference point(s) to\n                calculate the distances from.\n\n        Returns:\n            ndarray: array of distances.\n\n        \"\"\"", "\n", "\n", "self", ".", "_check_points", "(", "points", ")", "\n", "\n", "if", "reference", "is", "not", "None", ":", "\n", "            ", "self", ".", "_check_reference", "(", "reference", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.logmap": [[285, 298], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "logmap", "(", "self", ",", "x_a", ",", "x_b", ")", ":", "\n", "        ", "\"\"\"Logarithmic map.\n\n        Args:\n            x_a (type): Origin in the space.\n            x_b (type): Destination in the space.\n\n        Returns:\n            ndarray: Vector to go from origin to destination.\n\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.parallel_transport": [[299, 303], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "parallel_transport", "(", "self", ",", "B0", ",", "x0", ",", "v0", ")", ":", "\n", "        ", "\"\"\" in x(0) I have the vector B(0), I move with a geodesics in the space, in the direction v(0) \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.geodesic": [[304, 308], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "geodesic", "(", "self", ",", "x0", ",", "v0", ")", ":", "\n", "        ", "\"\"\" I am in x(0) I move with a geodesic on the sphere, in the direction v(0) \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._x0_fp": [[309, 312], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_x0_fp", "(", "self", ",", "points", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._get_zero": [[313, 317], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_get_zero", "(", "self", ")", ":", "\n", "        ", "\"\"\"the 0 of this space (often corresponding to the uniform distribution)\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._psif2": [[318, 321], ["RuntimeError"], "methods", ["None"], ["", "def", "_psif2", "(", "self", ",", "x", ",", "points", ")", ":", "\n", "        ", "\"\"\" fixed point function for the point xhat, minimizing the sum of the squared distances \"\"\"", "\n", "raise", "RuntimeError", "(", "\"the function `_psif2` has been called before being defined, either redefine mean or redefine this function.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._psif1": [[322, 325], ["RuntimeError"], "methods", ["None"], ["", "def", "_psif1", "(", "self", ",", "x", ",", "points", ")", ":", "\n", "        ", "\"\"\" fixed point function for the point xhat, minimizing the sum of the distances \"\"\"", "\n", "raise", "RuntimeError", "(", "\"the function `_psif1` has been called before being defined, either redefine median or redefine this function.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace.dist": [[331, 338], ["spaces.Space.dist", "numpy.linalg.norm", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.dist"], ["def", "dist", "(", "self", ",", "points", ",", "reference", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "dist", "(", "points", ",", "reference", "=", "reference", ")", "\n", "\n", "if", "reference", "is", "None", ":", "\n", "            ", "reference", "=", "np", ".", "zeros", "(", "points", ".", "shape", "[", "1", "]", ")", "\n", "\n", "", "return", "np", ".", "linalg", ".", "norm", "(", "points", "-", "reference", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace.mean": [[339, 342], ["spaces.EuclideanSpace._check_points", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space._check_points", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "mean", "(", "self", ",", "points", ")", ":", "\n", "        ", "self", ".", "_check_points", "(", "points", ")", "\n", "return", "np", ".", "mean", "(", "points", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace._psif1": [[343, 346], ["spaces.EuclideanSpace.dist", "numpy.sum", "numpy.sum", "spaces.EuclideanSpace.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.dist"], ["", "def", "_psif1", "(", "self", ",", "x", ",", "points", ")", ":", "\n", "        ", "dists", "=", "self", ".", "dist", "(", "points", ",", "reference", "=", "x", ")", "\n", "return", "np", ".", "sum", "(", "points", "/", "dists", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", ",", "axis", "=", "0", ")", "/", "np", ".", "sum", "(", "1", "/", "dists", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace._x0_fp": [[347, 349], ["spaces.EuclideanSpace.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_x0_fp", "(", "self", ",", "points", ")", ":", "\n", "        ", "return", "self", ".", "mean", "(", "points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace._get_zero": [[350, 352], ["numpy.zeros"], "methods", ["None"], ["", "def", "_get_zero", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "self", ".", "_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace.logmap": [[353, 355], ["None"], "methods", ["None"], ["", "def", "logmap", "(", "self", ",", "x_a", ",", "x_b", ")", ":", "\n", "        ", "return", "x_b", "-", "x_a", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace.parallel_transport": [[356, 358], ["None"], "methods", ["None"], ["", "def", "parallel_transport", "(", "self", ",", "B0", ",", "x0", ",", "v0", ")", ":", "\n", "        ", "return", "B0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EuclideanSpace.geodesic": [[359, 361], ["None"], "methods", ["None"], ["", "def", "geodesic", "(", "self", ",", "x0", ",", "v0", ")", ":", "\n", "        ", "return", "x0", "+", "v0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.dist": [[371, 395], ["spaces.Space.dist", "numpy.sum", "numpy.any", "numpy.clip", "numpy.any", "numpy.any", "ValueError", "ValueError", "numpy.errstate", "numpy.arccos", "numpy.ones", "abs", "abs", "abs", "numpy.linalg.norm", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.dist", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["def", "dist", "(", "self", ",", "points", ",", "reference", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "dist", "(", "points", ",", "reference", "=", "reference", ")", "\n", "\n", "if", "reference", "is", "None", ":", "\n", "            ", "nplusone", "=", "points", ".", "shape", "[", "1", "]", "\n", "reference", "=", "np", ".", "ones", "(", "nplusone", ")", "/", "nplusone", "\n", "\n", "", "if", "np", ".", "any", "(", "abs", "(", "np", ".", "linalg", ".", "norm", "(", "points", ",", "axis", "=", "1", ")", "-", "1.", ")", ">", "difftolerance", ")", "or", "np", ".", "any", "(", "abs", "(", "np", ".", "linalg", ".", "norm", "(", "reference", ",", "axis", "=", "1", ")", "-", "1.", ")", ">", "difftolerance", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"norm of some of the vectors passed is not 1.\"", ")", "\n", "\n", "", "scalprods", "=", "np", ".", "sum", "(", "points", "*", "reference", ",", "axis", "=", "1", ")", "\n", "if", "np", ".", "any", "(", "abs", "(", "scalprods", ")", "-", "1.", ">", "difftolerance", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Some scalar products are more than 1 or less than -1.\"", ")", "\n", "\n", "#for numerical errors some of these products might accidentally be slightly more than 1 and slightly less than -1", "\n", "", "scalprods", "=", "np", ".", "clip", "(", "scalprods", ",", "-", "1", ",", "1", ")", "\n", "\n", "with", "np", ".", "errstate", "(", "all", "=", "'raise'", ")", ":", "\n", "            ", "dist", "=", "np", ".", "arccos", "(", "scalprods", ")", "\n", "# except:", "\n", "#     import pdb;pdb.set_trace()", "\n", "#", "\n", "", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere._psif2": [[396, 401], ["numpy.matmul", "numpy.sum", "numpy.arccos", "numpy.sqrt", "numpy.linalg.norm", "xi.reshape"], "methods", ["None"], ["", "def", "_psif2", "(", "self", ",", "x", ",", "points", ")", ":", "\n", "        ", "zita", "=", "np", ".", "matmul", "(", "points", ",", "x", ")", "\n", "xi", "=", "np", ".", "arccos", "(", "zita", ")", "/", "np", ".", "sqrt", "(", "1", "-", "zita", "**", "2", ")", "\n", "psi", "=", "np", ".", "sum", "(", "points", "*", "xi", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", ",", "axis", "=", "0", ")", "\n", "return", "psi", "/", "np", ".", "linalg", ".", "norm", "(", "psi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere._psif1": [[402, 407], ["numpy.matmul", "numpy.sum", "numpy.sqrt", "numpy.linalg.norm", "xi.reshape"], "methods", ["None"], ["", "def", "_psif1", "(", "self", ",", "x", ",", "points", ")", ":", "\n", "        ", "zita", "=", "np", ".", "matmul", "(", "points", ",", "x", ")", "\n", "xi", "=", "1", "/", "np", ".", "sqrt", "(", "1", "-", "zita", "**", "2", ")", "\n", "psi", "=", "np", ".", "sum", "(", "points", "*", "xi", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", ",", "axis", "=", "0", ")", "\n", "return", "psi", "/", "np", ".", "linalg", ".", "norm", "(", "psi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere._x0_fp": [[408, 412], ["numpy.mean", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_x0_fp", "(", "self", ",", "points", ")", ":", "\n", "        ", "x0", "=", "np", ".", "mean", "(", "points", ",", "axis", "=", "0", ")", "\n", "x0", "=", "x0", "/", "np", ".", "linalg", ".", "norm", "(", "x0", ")", "\n", "return", "x0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere._get_zero": [[413, 415], ["numpy.sqrt", "numpy.ones"], "methods", ["None"], ["", "def", "_get_zero", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sqrt", "(", "np", ".", "ones", "(", "self", ".", "_dim", "+", "1", ")", "/", "(", "self", ".", "_dim", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.logmap": [[416, 418], ["spaces.logmap_on_the_sphere"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.logmap_on_the_sphere"], ["", "def", "logmap", "(", "self", ",", "x_a", ",", "x_b", ")", ":", "\n", "        ", "return", "logmap_on_the_sphere", "(", "x_a", ",", "x_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.parallel_transport": [[419, 421], ["spaces.parallel_transport_on_the_sphere"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.parallel_transport_on_the_sphere"], ["", "def", "parallel_transport", "(", "self", ",", "B0", ",", "x0", ",", "v0", ")", ":", "\n", "        ", "return", "parallel_transport_on_the_sphere", "(", "B0", ",", "x0", ",", "v0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.geodesic": [[422, 424], ["spaces.geodesics_on_the_sphere"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.geodesics_on_the_sphere"], ["", "def", "geodesic", "(", "self", ",", "x0", ",", "v0", ")", ":", "\n", "        ", "return", "geodesics_on_the_sphere", "(", "x0", ",", "v0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.__init__": [[428, 449], ["len", "len", "ValueError", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dictionary", ",", "reversed_dictionary", ",", "embeddings", ",", "space", ",", "extra_info", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dictionary (dict): the dictionary of the words {word:index}.\n            reversed_dictionary (dict): the reversed_dictionary {index:word}.\n            embeddings (ndarray): The embeddings, first dimension must match with dictionary size.\n            space (spaces.Space): the space in which the embeddings live.\n            extra_info (list): a general purpose variable thought as a list of extra info.\n                        For example I might wanna remember u_embeddings and v_embeddings\n                        separately in case I use embeddings in the sphere\n\n        \"\"\"", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "reversed_dictionary", "=", "reversed_dictionary", "\n", "self", ".", "dictionary_size", "=", "len", "(", "dictionary", ")", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "extra_info", "=", "extra_info", "\n", "\n", "if", "len", "(", "self", ".", "embeddings", ")", "!=", "self", ".", "dictionary_size", ":", "\n", "            ", "raise", "ValueError", "(", "\"the number of embeddings passed %d is different from the dictionary length %d\"", "%", "(", "len", "(", "self", ".", "embeddings", ")", ",", "self", ".", "dictionary_size", ")", ")", "\n", "", "self", ".", "space", "=", "space", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.word_index": [[450, 457], ["print", "print", "sys.exit"], "methods", ["None"], ["", "def", "word_index", "(", "self", ",", "word", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "dictionary", "[", "word", "]", "\n", "", "except", "KeyError", "as", "kerr", ":", "\n", "            ", "print", "(", "\"\\nKey Error: {0}\"", ".", "format", "(", "kerr", ")", ")", "\n", "print", "(", "\"The word requested is not present in the dictionary.\\n\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.index_and_measures": [[458, 484], ["sorted", "operator.itemgetter", "spaces.EmbeddingsManager.space.analogy_measure", "enumerate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.analogy_measure"], ["", "", "def", "index_and_measures", "(", "self", ",", "index_a", ",", "index_b", ",", "index_d", ",", "howmany", "=", "10", ",", "amonghowmany", "=", "None", ",", "tolerance", "=", "False", ")", ":", "\n", "        ", "\"\"\"given three indexes a,b,d I want to find c such that a:b=c:d.\n\n        Args:\n            index_a, index_b, index_d (int): indexes of the words in the analogy.\n            howmany (int): how may words to give as an answer (scored according to distance from target).\n            amonghowmany (int): how many words in the dictionary to consider for the answer (the embeddings in the dictionary are ordered by frequency).\n            tolerance (boolean): if tolerance, remove words in the query from the possible answers.\n\n        Returns:\n            list of (index, embedding): list of answers for the word c in the analogy, sorted by relevance.\n\n        \"\"\"", "\n", "embeddings_to_search", "=", "self", ".", "embeddings", "[", ":", "amonghowmany", "]", "\n", "x_a", "=", "self", ".", "embeddings", "[", "index_a", "]", "\n", "x_b", "=", "self", ".", "embeddings", "[", "index_b", "]", "\n", "x_d", "=", "self", ".", "embeddings", "[", "index_d", "]", "\n", "#if tolerance, remove words in the query from the possible answers", "\n", "#TODO check, is this correct, does embedding numbering start from 0", "\n", "xc_star", "=", "sorted", "(", "\n", "[", "(", "i", ",", "self", ".", "space", ".", "analogy_measure", "(", "x_a", ",", "x_b", ",", "x_c", ",", "x_d", ")", ")", "for", "(", "i", ",", "x_c", ")", "in", "enumerate", "(", "embeddings_to_search", ")", "if", "(", "tolerance", "==", "False", ")", "or", "(", "i", "not", "in", "(", "index_a", ",", "index_b", ",", "index_d", ")", ")", "]", ",", "\n", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", "\n", ")", "[", ":", "howmany", "]", "\n", "return", "xc_star", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.analogy_query_c": [[485, 492], ["spaces.EmbeddingsManager.word_index", "spaces.EmbeddingsManager.word_index", "spaces.EmbeddingsManager.word_index", "spaces.EmbeddingsManager.index_and_measures"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.index_and_measures"], ["", "def", "analogy_query_c", "(", "self", ",", "word_a", ",", "word_b", ",", "word_d", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"given three words a,b,d I want to find c such that a:b=c:d.\"\"\"", "\n", "index_a", "=", "self", ".", "word_index", "(", "word_a", ")", "\n", "index_b", "=", "self", ".", "word_index", "(", "word_b", ")", "\n", "index_d", "=", "self", ".", "word_index", "(", "word_d", ")", "\n", "iam", "=", "self", ".", "index_and_measures", "(", "index_a", ",", "index_b", ",", "index_d", ",", "**", "kwargs", ")", "\n", "return", "iam", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.analogy_query_d": [[493, 497], ["spaces.EmbeddingsManager.analogy_query_c"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.analogy_query_c"], ["", "def", "analogy_query_d", "(", "self", ",", "word_a", ",", "word_b", ",", "word_c", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"given three words a,b,c I want to find d such that a:b=c:d.\"\"\"", "\n", "# Uses the fact that a:b=c:? => b:a=?:c.", "\n", "return", "self", ".", "analogy_query_c", "(", "word_b", ",", "word_a", ",", "word_c", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.analogy_query_d_from_indexes": [[498, 503], ["spaces.EmbeddingsManager.index_and_measures"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.index_and_measures"], ["", "def", "analogy_query_d_from_indexes", "(", "self", ",", "ia", ",", "ib", ",", "ic", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"given three word indexes ia,ib,ic I want to find d such that a:b=c:d.\"\"\"", "\n", "# Uses the fact that a:b=c:? => b:a=?:c.", "\n", "iam", "=", "self", ".", "index_and_measures", "(", "ib", ",", "ia", ",", "ic", ",", "**", "kwargs", ")", "\n", "return", "iam", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.word_embeddings": [[504, 507], ["numpy.array", "spaces.EmbeddingsManager.word_index"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index"], ["", "def", "word_embeddings", "(", "self", ",", "words", ")", ":", "\n", "        ", "\"\"\"Return a list of embeddings for the specified words\"\"\"", "\n", "return", "np", ".", "array", "(", "[", "self", ".", "embeddings", "[", "self", ".", "word_index", "(", "w", ")", "]", "for", "w", "in", "words", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManager.distances": [[508, 522], ["numpy.array", "numpy.array", "spaces.EmbeddingsManager.space.dist", "spaces.EmbeddingsManager.word_index", "spaces.EmbeddingsManager.word_index"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.dist", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index"], ["", "def", "distances", "(", "self", ",", "words1", ",", "words2", ")", ":", "\n", "        ", "\"\"\"Distances between two lists of words, according to the embeddings of the EmbeddingsManager.\n\n        Args:\n            words1 (list of strings):\n            words2 (list of strings):\n\n        Returns:\n            ndarray : distances between the words\n\n        \"\"\"", "\n", "emb1", "=", "np", ".", "array", "(", "[", "self", ".", "embeddings", "[", "self", ".", "word_index", "(", "w", ")", "]", "for", "w", "in", "words1", "]", ")", "\n", "emb2", "=", "np", ".", "array", "(", "[", "self", ".", "embeddings", "[", "self", ".", "word_index", "(", "w", ")", "]", "for", "w", "in", "words2", "]", ")", "\n", "return", "self", ".", "space", ".", "dist", "(", "emb1", ",", "emb2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.EmbeddingsManagerUV.__init__": [[526, 547], ["len", "spaces.HyperSphere", "ValueError", "len", "len", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dictionary", ",", "reversed_dictionary", ",", "u_embeddings", ",", "v_embeddings", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dictionary (dict): the dictionary of the words {word:index}.\n            reversed_dictionary (dict): the reversed_dictionary {index:word}.\n            u_embeddings (ndarray): The U embeddings, first dimension must match with dictionary size.\n            v_embeddings (ndarray): The V embeddings, first dimension must match with dictionary size.\n\n        \"\"\"", "\n", "self", ".", "dictionary", "=", "dictionary", "\n", "self", ".", "reversed_dictionary", "=", "reversed_dictionary", "\n", "self", ".", "dictionary_size", "=", "len", "(", "dictionary", ")", "\n", "self", ".", "space", "=", "HyperSphere", "(", "self", ".", "dictionary_size", "-", "1", ")", "\n", "self", ".", "u_embeddings", "=", "u_embeddings", "\n", "self", ".", "v_embeddings", "=", "v_embeddings", "\n", "\n", "if", "len", "(", "self", ".", "u_embeddings", ")", "!=", "self", ".", "dictionary_size", "or", "len", "(", "self", ".", "v_embeddings", ")", "!=", "self", ".", "dictionary_size", ":", "\n", "            ", "raise", "ValueError", "(", "\"the number of embeddings passed U:%d and V:%d are different from the dictionary length %d\"", "\n", "%", "(", "len", "(", "self", ".", "u_embeddings", ")", ",", "len", "(", "self", ".", "v_embeddings", ")", ",", "self", ".", "dictionary_size", ")", ")", "\n", "\n", "", "self", ".", "embeddings", "=", "self", ".", "u_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax2D_numexpr": [[12, 25], ["numexpr.evaluate", "gc.collect", "numexpr.evaluate", "numexpr.evaluate", "numexpr.evaluate", "numexpr.evaluate().reshape", "numexpr.evaluate"], "function", ["None"], ["def", "softmax2D_numexpr", "(", "xi", ",", "norm_counts_cols", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute 2D softmax values, for a list of sets of scores xi. Uses numexpr, supposedly faster than numpy on large arrays.\"\"\"", "\n", "xi_maxes", "=", "ne", ".", "evaluate", "(", "'max(xi, axis=1)'", ")", "[", ":", ",", "None", "]", "\n", "e_xi", "=", "ne", ".", "evaluate", "(", "'exp(xi-xi_maxes)'", ")", "\n", "del", "xi_maxes", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "if", "norm_counts_cols", ":", "\n", "        ", "e_xi", "=", "e_xi", "/", "ne", ".", "evaluate", "(", "'sum(e_xi, axis=0)'", ")", ".", "reshape", "(", "1", ",", "e_xi", ".", "shape", "[", "1", "]", ")", "\n", "\n", "", "sums", "=", "ne", ".", "evaluate", "(", "'sum(e_xi, axis=1)'", ")", "[", ":", ",", "None", "]", "\n", "# smax = ne.evaluate('e_xi / sums')", "\n", "return", "ne", ".", "evaluate", "(", "'e_xi / sums'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.C_numexpr": [[26, 37], ["numpy.matmul", "numexpr.evaluate", "numpy.transpose"], "function", ["None"], ["", "def", "C_numexpr", "(", "u_embeddings", ",", "v_embeddings", ")", ":", "\n", "    ", "\"\"\"Compute counts C from U and V\"\"\"", "\n", "# import pdb; pdb.set_trace()", "\n", "# return np.exp(np.matmul(u_embeddings, np.transpose(v_embeddings)))", "\n", "xi", "=", "np", ".", "matmul", "(", "u_embeddings", ",", "np", ".", "transpose", "(", "v_embeddings", ")", ")", "\n", "#", "\n", "# # xi_maxes = ne.evaluate('max(xi, axis=1)')", "\n", "# # e_xi = ne.evaluate('exp(xi-xi_maxes)')", "\n", "# # del xi_maxes", "\n", "# # gc.collect()", "\n", "return", "ne", ".", "evaluate", "(", "'exp(xi)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax2D": [[39, 43], ["numpy.exp", "numpy.sum", "numpy.max"], "function", ["None"], ["", "def", "softmax2D", "(", "xi", ")", ":", "\n", "    ", "\"\"\"Compute 2D softmax values, for a list of sets of scores xi.\"\"\"", "\n", "e_xi", "=", "np", ".", "exp", "(", "xi", "-", "np", ".", "max", "(", "xi", ",", "axis", "=", "1", ")", "[", ":", ",", "None", "]", ")", "\n", "return", "e_xi", "/", "np", ".", "sum", "(", "e_xi", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax": [[44, 48], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["", "def", "softmax", "(", "xi", ")", ":", "\n", "    ", "\"\"\"Compute softmax values for a set of scores in xi.\"\"\"", "\n", "e_xi", "=", "np", ".", "exp", "(", "xi", "-", "np", ".", "max", "(", "xi", ")", ")", "\n", "return", "e_xi", "/", "e_xi", ".", "sum", "(", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.calculate_mu_embeddings": [[49, 54], ["spaces.softmax2D_numexpr", "numpy.matmul", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax2D_numexpr"], ["", "def", "calculate_mu_embeddings", "(", "u_embeddings", ",", "v_embeddings", ",", "norm_counts_cols", "=", "False", ")", ":", "\n", "    ", "\"\"\" each row of u_embeddings and of v_embeddings represents an observation \"\"\"", "\n", "mu", "=", "softmax2D_numexpr", "(", "np", ".", "matmul", "(", "u_embeddings", ",", "np", ".", "transpose", "(", "v_embeddings", ")", ")", ",", "norm_counts_cols", "=", "norm_counts_cols", ")", "\n", "# mu = softmax2D(np.matmul(u_embeddings, np.transpose(v_embeddings)))", "\n", "return", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.calculate_x_embeddings": [[55, 61], ["spaces.calculate_mu_embeddings", "numexpr.evaluate", "numpy.linalg.norm", "np.linalg.norm.reshape"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.calculate_mu_embeddings"], ["", "def", "calculate_x_embeddings", "(", "u_embeddings", ",", "v_embeddings", ")", ":", "\n", "    ", "mu", "=", "calculate_mu_embeddings", "(", "u_embeddings", ",", "v_embeddings", ")", "\n", "x_embeddings", "=", "ne", ".", "evaluate", "(", "'sqrt(mu)'", ")", "\n", "# to ensure that they are normalized (due to small numerical errors on the way they are not perfectly normalized)", "\n", "norms", "=", "np", ".", "linalg", ".", "norm", "(", "x_embeddings", ",", "axis", "=", "1", ")", "\n", "return", "x_embeddings", "/", "norms", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.send_u_to_x_on_the_sphere": [[62, 67], ["numpy.matmul", "spaces.softmax", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax"], ["", "def", "send_u_to_x_on_the_sphere", "(", "u", ",", "v_embeddings", ")", ":", "\n", "    ", "xi", "=", "np", ".", "matmul", "(", "v_embeddings", ",", "u", ")", "\n", "mu", "=", "softmax", "(", "xi", ")", "\n", "x", "=", "np", ".", "sqrt", "(", "mu", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.dist_sphere": [[71, 76], ["numpy.arccos", "ValueError", "numpy.dot", "abs", "abs", "str", "numpy.linalg.norm", "numpy.linalg.norm", "str"], "function", ["None"], ["def", "dist_sphere", "(", "x_a", ",", "x_b", ")", ":", "\n", "    ", "if", "abs", "(", "linalg", ".", "norm", "(", "x_a", ")", "-", "1.", ")", ">", "difftolerance", "or", "abs", "(", "linalg", ".", "norm", "(", "x_b", ")", "-", "1.", ")", ">", "difftolerance", ":", "\n", "        ", "raise", "ValueError", "(", "\"norm of the vectors passed is not 1. Received vectors: \\n\"", "+", "str", "(", "x_a", ")", "+", "\"\\n\"", "+", "str", "(", "x_b", ")", ")", "\n", "\n", "", "return", "np", ".", "arccos", "(", "np", ".", "dot", "(", "x_a", ",", "x_b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.dist_sphere_riem_amb": [[77, 93], ["numpy.testing.assert_equal", "numpy.arccos", "numpy.matmul", "numpy.sum", "numpy.sum", "numpy.matmul", "numpy.matmul", "any", "any", "pdb.set_trace", "ValueError", "abs", "abs", "numpy.sqrt", "numpy.sqrt"], "function", ["None"], ["", "def", "dist_sphere_riem_amb", "(", "xa", ",", "xb", ",", "g_amb", ",", "check_norms", "=", "True", ")", ":", "\n", "# x_a and x_b are a batch of examples", "\n", "    ", "np", ".", "testing", ".", "assert_equal", "(", "g_amb", ".", "shape", "[", "0", "]", ",", "g_amb", ".", "shape", "[", "1", "]", ",", "\"metric of the ambient space must be a square matrix, found shape {:}\"", ".", "format", "(", "g_amb", ".", "shape", ")", ")", "\n", "\n", "Ixb", "=", "np", ".", "matmul", "(", "g_amb", ",", "xb", ".", "T", ")", ".", "T", "\n", "\n", "if", "check_norms", ":", "\n", "        ", "sqnormb", "=", "np", ".", "sum", "(", "xb", "*", "Ixb", ",", "axis", "=", "1", ")", "\n", "\n", "Ixa", "=", "np", ".", "matmul", "(", "g_amb", ",", "xa", ".", "T", ")", ".", "T", "\n", "sqnorma", "=", "np", ".", "sum", "(", "xa", "*", "Ixa", ",", "axis", "=", "1", ")", "\n", "if", "any", "(", "abs", "(", "np", ".", "sqrt", "(", "sqnorma", ")", "-", "1.", ")", ">", "difftolerance", ")", "or", "any", "(", "abs", "(", "np", ".", "sqrt", "(", "sqnormb", ")", "-", "1.", ")", ">", "difftolerance", ")", ":", "\n", "            ", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "raise", "ValueError", "(", "\"norm of the vectors passed is not 1 respect to the metric of the ambient space. Received norms: {:} \\n {:}\\n\"", ".", "format", "(", "sqnorma", ",", "sqnormb", ")", ")", "\n", "\n", "", "", "return", "np", ".", "arccos", "(", "np", ".", "matmul", "(", "xa", ",", "Ixb", ".", "T", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.distance_on_the_sphere": [[94, 100], ["spaces.send_u_to_x_on_the_sphere", "spaces.send_u_to_x_on_the_sphere", "numpy.arccos", "numpy.dot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.send_u_to_x_on_the_sphere", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.send_u_to_x_on_the_sphere"], ["", "def", "distance_on_the_sphere", "(", "u_a", ",", "u_b", ",", "v_embeddings", ")", ":", "\n", "# proj_xa_of_xb_min_xa = projection_on_the_sphere(x_a, x_b-x_a)", "\n", "# logmap = (np.arccos(np.dot(x_a,x_b)) / np.linalg.norm(proj_xa_of_xb_min_xa)) * proj_xa_of_xb_min_xa", "\n", "    ", "x_a", "=", "send_u_to_x_on_the_sphere", "(", "u_a", ",", "v_embeddings", ")", "\n", "x_b", "=", "send_u_to_x_on_the_sphere", "(", "u_b", ",", "v_embeddings", ")", "\n", "return", "np", ".", "arccos", "(", "np", ".", "dot", "(", "x_a", ",", "x_b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.mean_on_sphere": [[101, 105], ["spaces.HyperSphere", "spaces.Space.mean"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "mean_on_sphere", "(", "xp", ")", ":", "\n", "    ", "dim", "=", "xp", ".", "shape", "[", "1", "]", "\n", "space", "=", "HyperSphere", "(", "dim", ")", "\n", "return", "space", ".", "mean", "(", "xp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.logmap_on_the_sphere": [[108, 119], ["numpy.errstate", "spaces.projection_on_the_sphere", "numpy.linalg.norm", "numpy.arccos", "numpy.linalg.norm", "numpy.dot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.projection_on_the_sphere"], ["def", "logmap_on_the_sphere", "(", "x_a", ",", "x_b", ")", ":", "\n", "#take two points on the sphere and calculate Log_{x_a} x_b", "\n", "\n", "    ", "with", "np", ".", "errstate", "(", "all", "=", "'raise'", ")", ":", "\n", "        ", "proj_xa_of_xb_min_xa", "=", "projection_on_the_sphere", "(", "x_a", ",", "x_b", "-", "x_a", ")", "\n", "if", "np", ".", "linalg", ".", "norm", "(", "proj_xa_of_xb_min_xa", ")", ">", "NUMTOL", ":", "\n", "            ", "logmap", "=", "(", "np", ".", "arccos", "(", "np", ".", "dot", "(", "x_a", ",", "x_b", ")", ")", "/", "np", ".", "linalg", ".", "norm", "(", "proj_xa_of_xb_min_xa", ")", ")", "*", "proj_xa_of_xb_min_xa", "\n", "", "else", ":", "\n", "            ", "logmap", "=", "proj_xa_of_xb_min_xa", "\n", "\n", "", "", "return", "logmap", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.projection_on_the_sphere": [[120, 122], ["numpy.dot"], "function", ["None"], ["", "def", "projection_on_the_sphere", "(", "x", ",", "Avec", ")", ":", "\n", "    ", "return", "Avec", "-", "(", "np", ".", "dot", "(", "x", ",", "Avec", ")", ")", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.distance_in_euclidean_space": [[123, 125], ["numpy.linalg.norm"], "function", ["None"], ["", "def", "distance_in_euclidean_space", "(", "u1", ",", "u2", ")", ":", "\n", "    ", "return", "np", ".", "linalg", ".", "norm", "(", "u2", "-", "u1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.check_in_tangent_space_sphere": [[126, 130], ["numpy.dot", "ValueError", "numpy.dot"], "function", ["None"], ["", "def", "check_in_tangent_space_sphere", "(", "x0", ",", "v0", ")", ":", "\n", "    ", "if", "np", ".", "dot", "(", "x0", ",", "v0", ")", ">", "difftolerance", ":", "\n", "        ", "raise", "ValueError", "(", "\"The vector v0: \"", ",", "v0", ",", "\" does not belong to the tangent space of x0: \"", ",", "x0", ",", "\n", "\"their scalar product is: \"", ",", "np", ".", "dot", "(", "x0", ",", "v0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.parallel_transport_on_the_sphere": [[131, 145], ["spaces.check_in_tangent_space_sphere", "spaces.check_in_tangent_space_sphere", "numpy.errstate", "numpy.linalg.norm", "numpy.dot", "numpy.dot", "numpy.cos", "numpy.sin"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.check_in_tangent_space_sphere", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.check_in_tangent_space_sphere"], ["", "", "def", "parallel_transport_on_the_sphere", "(", "B0", ",", "x0", ",", "v0", ")", ":", "\n", "    ", "\"\"\" in x(0) I have the vector B(0), I move with a geodesics on the sphere, in the direction v(0) \"\"\"", "\n", "check_in_tangent_space_sphere", "(", "x0", ",", "v0", ")", "\n", "check_in_tangent_space_sphere", "(", "x0", ",", "B0", ")", "\n", "\n", "with", "np", ".", "errstate", "(", "all", "=", "'raise'", ")", ":", "\n", "        ", "omega", "=", "np", ".", "linalg", ".", "norm", "(", "v0", ")", "\n", "if", "omega", ">", "NUMTOL", ":", "\n", "            ", "u0", "=", "v0", "/", "omega", "\n", "Bt", "=", "np", ".", "dot", "(", "B0", ",", "u0", ")", "*", "(", "u0", "*", "np", ".", "cos", "(", "omega", ")", "-", "x0", "*", "np", ".", "sin", "(", "omega", ")", ")", "+", "(", "B0", "-", "np", ".", "dot", "(", "u0", ",", "B0", ")", "*", "u0", ")", "\n", "", "else", ":", "\n", "            ", "Bt", "=", "B0", "\n", "\n", "", "", "return", "Bt", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.geodesics_on_the_sphere": [[146, 153], ["spaces.check_in_tangent_space_sphere", "numpy.linalg.norm", "numpy.cos", "numpy.sin"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.check_in_tangent_space_sphere"], ["", "def", "geodesics_on_the_sphere", "(", "x0", ",", "v0", ")", ":", "\n", "#I am in x(0) I move with a geodesics on the sphere, in the direction v(0)", "\n", "    ", "check_in_tangent_space_sphere", "(", "x0", ",", "v0", ")", "\n", "omega", "=", "np", ".", "linalg", ".", "norm", "(", "v0", ")", "\n", "u0", "=", "v0", "/", "omega", "\n", "xt", "=", "x0", "*", "np", ".", "cos", "(", "omega", ")", "+", "u0", "*", "np", ".", "sin", "(", "omega", ")", "\n", "return", "xt", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.__init__": [[8, 32], ["os.path.join", "os.path.join", "PandasLogger.PandasLogger.try_read_csv", "try_to_convert.items", "PandasLogger.PandasLogger._maybe_sort_df", "os.makedirs", "pandas.DataFrame", "try_conv"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.try_read_csv", "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger._maybe_sort_df"], ["    ", "def", "__init__", "(", "self", ",", "logdir", ",", "loggername", ",", "columns_names", ",", "try_to_convert", "=", "{", "}", ",", "\n", "field_to_sort_by", "=", "None", ",", "replace_strings_for_sort", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "_filename", "=", "os", ".", "path", ".", "join", "(", "logdir", ",", "loggername", "+", "\".txt\"", ")", "\n", "self", ".", "_plotfilename", "=", "os", ".", "path", ".", "join", "(", "logdir", ",", "loggername", ")", "\n", "\n", "self", ".", "_pd_csv_kwargs", "=", "{", "\n", "\"sep\"", ":", "\" \"", "\n", "}", "\n", "\n", "read_success", ",", "_df", "=", "self", ".", "try_read_csv", "(", ")", "\n", "if", "read_success", ":", "\n", "            ", "self", ".", "_df", "=", "_df", "\n", "", "else", ":", "\n", "            ", "self", ".", "_df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "columns_names", ")", "\n", "\n", "", "for", "field", ",", "try_conv", "in", "try_to_convert", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "_df", "[", "field", "]", "=", "[", "try_conv", "(", "x", ")", "for", "x", "in", "self", ".", "_df", "[", "field", "]", ".", "array", "]", "\n", "\n", "", "self", ".", "_field_to_sort_by", "=", "field_to_sort_by", "\n", "self", ".", "_replace_strings_for_sort", "=", "replace_strings_for_sort", "\n", "\n", "self", ".", "_maybe_sort_df", "(", ")", "\n", "\n", "os", ".", "makedirs", "(", "logdir", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger._maybe_sort_df": [[33, 43], ["PandasLogger.PandasLogger._replace_strings_for_sort.items", "PandasLogger.PandasLogger._df.sort_values", "PandasLogger.PandasLogger._replace_strings_for_sort.items", "PandasLogger.PandasLogger._df[].replace", "PandasLogger.PandasLogger._df[].replace"], "methods", ["None"], ["", "def", "_maybe_sort_df", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_field_to_sort_by", "is", "not", "None", ":", "\n", "\n", "            ", "for", "string", ",", "value", "in", "self", ".", "_replace_strings_for_sort", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "_df", "[", "self", ".", "_field_to_sort_by", "]", ".", "replace", "(", "to_replace", "=", "string", ",", "value", "=", "value", ",", "inplace", "=", "True", ")", "\n", "\n", "", "self", ".", "_df", ".", "sort_values", "(", "by", "=", "self", ".", "_field_to_sort_by", ",", "inplace", "=", "True", ")", "\n", "\n", "for", "string", ",", "value", "in", "self", ".", "_replace_strings_for_sort", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "_df", "[", "self", ".", "_field_to_sort_by", "]", ".", "replace", "(", "to_replace", "=", "value", ",", "value", "=", "string", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.has_values": [[47, 52], ["zip", "booleans.any", "numpy.array", "PandasLogger.PandasLogger._isclose"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table._isclose"], ["", "", "", "def", "has_values", "(", "self", ",", "fields", ",", "values", ")", ":", "\n", "        ", "booleans", "=", "True", "\n", "for", "field", ",", "value", "in", "zip", "(", "fields", ",", "values", ")", ":", "\n", "            ", "booleans", "=", "booleans", "&", "np", ".", "array", "(", "[", "self", ".", "_isclose", "(", "x", ",", "value", ")", "for", "x", "in", "self", ".", "_df", "[", "field", "]", "]", ",", "dtype", "=", "bool", ")", "\n", "", "return", "booleans", ".", "any", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger._isclose": [[53, 58], ["isinstance", "isinstance", "numpy.isclose"], "methods", ["None"], ["", "def", "_isclose", "(", "self", ",", "x", ",", "val", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "float", ")", "and", "isinstance", "(", "val", ",", "float", ")", ":", "\n", "            ", "return", "np", ".", "isclose", "(", "x", ",", "val", ",", "atol", "=", "1e-8", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "==", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.try_read_csv": [[59, 70], ["os.path.exists", "pandas.read_csv", "os.path.getsize"], "methods", ["None"], ["", "", "def", "try_read_csv", "(", "self", ")", ":", "\n", "        ", "read_success", "=", "False", "\n", "_df", "=", "None", "\n", "try", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "_filename", ")", "and", "os", ".", "path", ".", "getsize", "(", "self", ".", "_filename", ")", ">", "0", ":", "\n", "                ", "_df", "=", "pd", ".", "read_csv", "(", "self", ".", "_filename", ",", "**", "self", ".", "_pd_csv_kwargs", ")", "\n", "read_success", "=", "True", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "return", "read_success", ",", "_df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.log": [[71, 81], ["pandas.Series", "PandasLogger.PandasLogger._df.append", "PandasLogger.PandasLogger._maybe_sort_df", "PandasLogger.PandasLogger._df.to_csv"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger._maybe_sort_df"], ["", "def", "log", "(", "self", ",", "log_values_np", ")", ":", "\n", "        ", "new_series", "=", "pd", ".", "Series", "(", "log_values_np", ",", "index", "=", "self", ".", "_df", ".", "columns", ")", "\n", "\n", "#NB as of today there is no `inplace` parameter for pandas dataframes", "\n", "self", ".", "_df", "=", "self", ".", "_df", ".", "append", "(", "new_series", ",", "ignore_index", "=", "True", ")", "\n", "# self._df.loc[index] = monitor_tensors_values_np", "\n", "# self._df.sort_index(inplace=True)", "\n", "self", ".", "_maybe_sort_df", "(", ")", "\n", "\n", "self", ".", "_df", ".", "to_csv", "(", "self", ".", "_filename", ",", "index", "=", "False", ",", "float_format", "=", "'%.6g'", ",", "**", "self", ".", "_pd_csv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.plot": [[82, 91], ["PandasLogger.PandasLogger._df.plot", "PandasLogger.PandasLogger._finalize_plot", "zip", "ax.set_ylim"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot"], ["", "def", "plot", "(", "self", ",", "ylims", "=", "None", ",", "suffix", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# subplots = False, sharex = True", "\n", "        ", "axes", "=", "self", ".", "_df", ".", "plot", "(", "**", "kwargs", ")", "\n", "\n", "if", "ylims", "is", "not", "None", ":", "\n", "            ", "for", "ax", ",", "ylim", "in", "zip", "(", "axes", ",", "ylims", ")", ":", "\n", "                ", "ax", ".", "set_ylim", "(", "ylim", ")", "\n", "\n", "", "", "self", ".", "_finalize_plot", "(", "suffix", "=", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.plot_groupby": [[92, 97], ["matplotlib.pyplot.gca", "PandasLogger.PandasLogger._df.groupby", "PandasLogger.PandasLogger._finalize_plot", "df.plot"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "plot_groupby", "(", "self", ",", "groupfield", ",", "suffix", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "for", "label", ",", "df", "in", "self", ".", "_df", ".", "groupby", "(", "groupfield", ")", ":", "\n", "            ", "df", ".", "plot", "(", "**", "kwargs", ",", "ax", "=", "ax", ",", "label", "=", "groupfield", "+", "\"_{:}\"", ".", "format", "(", "label", ")", ")", "\n", "", "self", ".", "_finalize_plot", "(", "suffix", "=", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.plot_errorbar": [[98, 119], ["PandasLogger.PandasLogger._df.groupby", "zip", "matplotlib.pyplot.errorbar", "matplotlib.pyplot.legend", "PandasLogger.PandasLogger._finalize_plot", "xdata.append", "ydata.append", "yerr.append", "matplotlib.pyplot.ylim", "sorted", "df.mean", "df.std", "zip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "plot_errorbar", "(", "self", ",", "x", ",", "y", ",", "suffix", "=", "None", ",", "ylim", "=", "None", ",", "string_replace", "=", "{", "}", ",", "**", "kwargs", ")", ":", "\n", "        ", "xdata", "=", "[", "]", "\n", "ydata", "=", "[", "]", "\n", "yerr", "=", "[", "]", "\n", "\n", "for", "label", ",", "df", "in", "self", ".", "_df", ".", "groupby", "(", "x", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "x_value", "=", "string_replace", "[", "label", "]", "\n", "", "except", ":", "\n", "                ", "x_value", "=", "label", "\n", "\n", "", "xdata", ".", "append", "(", "x_value", ")", "\n", "ydata", ".", "append", "(", "df", ".", "mean", "(", ")", "[", "y", "]", ")", "\n", "yerr", ".", "append", "(", "df", ".", "std", "(", ")", "[", "y", "]", ")", "\n", "\n", "", "xdata", ",", "ydata", ",", "yerr", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "xdata", ",", "ydata", ",", "yerr", ")", ")", ")", "\n", "plt", ".", "errorbar", "(", "xdata", ",", "ydata", ",", "yerr", "=", "yerr", ",", "label", "=", "y", ",", "**", "kwargs", ")", "\n", "if", "ylim", "is", "not", "None", ":", "\n", "            ", "plt", ".", "ylim", "(", "ylim", ")", "\n", "", "plt", ".", "legend", "(", ")", "\n", "self", ".", "_finalize_plot", "(", "suffix", "=", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger._finalize_plot": [[120, 127], ["matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close"], "methods", ["None"], ["", "def", "_finalize_plot", "(", "self", ",", "suffix", "=", "None", ")", ":", "\n", "        ", "plt", ".", "tight_layout", "(", ")", "\n", "plotfilename", "=", "self", ".", "_plotfilename", "\n", "if", "suffix", "is", "not", "None", ":", "\n", "            ", "plotfilename", "+=", "suffix", "\n", "", "plt", ".", "savefig", "(", "plotfilename", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.KL": [[6, 10], ["numpy.sum", "numpy.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["def", "KL", "(", "p", ",", "q", ")", ":", "\n", "    ", "p", "+=", "NUMTOL", "\n", "q", "+=", "NUMTOL", "\n", "return", "np", ".", "sum", "(", "p", "*", "np", ".", "log", "(", "p", "/", "q", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.BC": [[11, 15], ["numpy.log", "numpy.sum", "numpy.sqrt", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "BC", "(", "p", ",", "q", ")", ":", "\n", "    ", "p", "+=", "NUMTOL", "\n", "q", "+=", "NUMTOL", "\n", "return", "-", "np", ".", "log", "(", "np", ".", "sum", "(", "np", ".", "sqrt", "(", "p", ")", "*", "np", ".", "sqrt", "(", "q", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h": [[16, 21], ["numpy.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "h", "(", "p", ",", "alpha", ")", ":", "\n", "    ", "if", "alpha", "==", "1", ":", "\n", "        ", "return", "np", ".", "log", "(", "p", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "2", "/", "(", "1", "-", "alpha", ")", ")", "*", "p", "**", "(", "(", "1", "-", "alpha", ")", "/", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h_prime": [[22, 24], ["None"], "function", ["None"], ["", "", "def", "h_prime", "(", "p", ",", "alpha", ")", ":", "\n", "    ", "return", "p", "**", "(", "-", "(", "1", "+", "alpha", ")", "/", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot": [[25, 34], ["p.reshape.reshape", "numpy.sum().reshape", "numpy.matmul", "numpy.sum", "numpy.eye"], "function", ["None"], ["", "def", "fisher_matrix_and_whatnot", "(", "V", ",", "p", ",", "damping", "=", "0.", ")", ":", "\n", "# I is the fisher matrix, beta is the (pushforward of a vector in u -> to a vector in R^n_(alpha))", "\n", "# i.e. matrix containing as rows the coordinates of the basis for the fisher matrix (beta) in R^n_(alpha)", "\n", "    ", "p", "=", "p", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "E_V", "=", "np", ".", "sum", "(", "p", "*", "V", ",", "axis", "=", "0", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "DV", "=", "V", "-", "E_V", "\n", "I", "=", "np", ".", "matmul", "(", "DV", ".", "T", ",", "p", "*", "DV", ")", "+", "damping", "*", "np", ".", "eye", "(", "DV", ".", "shape", "[", "1", "]", ")", "\n", "\n", "return", "I", ",", "DV", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.beta_fisher_basis": [[35, 38], ["h_prime().reshape", "compute_embeddings.h_prime"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h_prime"], ["", "def", "beta_fisher_basis", "(", "DV", ",", "p", ",", "alpha", ")", ":", "\n", "    ", "beta", "=", "h_prime", "(", "p", ",", "alpha", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "*", "p", "*", "DV", "\n", "return", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_vector_on_basis": [[39, 43], ["numpy.matmul", "numpy.matmul", "p.reshape"], "function", ["None"], ["", "def", "project_vector_on_basis", "(", "c_tilde", ",", "beta", ",", "I_inv", ",", "p", ",", "alpha", ")", ":", "\n", "    ", "beta_a", "=", "p", ".", "reshape", "(", "-", "1", ",", "1", ")", "**", "alpha", "*", "beta", "\n", "c_proj", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "matmul", "(", "beta_a", ".", "T", ",", "c_tilde", ")", ")", "\n", "return", "c_proj", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_vectors_on_basis": [[44, 48], ["numpy.matmul", "numpy.matmul", "p.reshape", "numpy.transpose"], "function", ["None"], ["", "def", "project_vectors_on_basis", "(", "c_tilde_batch", ",", "beta", ",", "I_inv", ",", "p", ",", "alpha", ")", ":", "\n", "    ", "beta_a", "=", "p", ".", "reshape", "(", "-", "1", ",", "1", ")", "**", "alpha", "*", "beta", "\n", "c_proj_batch", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "matmul", "(", "beta_a", ".", "T", ",", "np", ".", "transpose", "(", "c_tilde_batch", ")", ")", ")", "\n", "return", "c_proj_batch", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_away_1vec_component": [[49, 54], ["numpy.sum().reshape", "numpy.sum"], "function", ["None"], ["", "def", "project_away_1vec_component", "(", "V", ")", ":", "\n", "    ", "D", "=", "V", ".", "shape", "[", "0", "]", "\n", "v_shift", "=", "np", ".", "sum", "(", "V", ",", "axis", "=", "0", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "/", "D", "\n", "# now V_tilde = V-v_shift is such that V_tilde \\cdot 1vec = 0vec", "\n", "return", "V", "-", "v_shift", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_vectors_away_from_normal": [[55, 67], ["n_vec.reshape.reshape", "numpy.testing.assert_array_equal", "numpy.sum", "numpy.testing.assert_approx_equal", "n_vec.reshape.reshape", "numpy.sum", "p.reshape", "c_n_coeffs.reshape", "ga_nvec.reshape"], "function", ["None"], ["", "def", "project_vectors_away_from_normal", "(", "c_tilde_batch", ",", "p", ",", "alpha", ")", ":", "\n", "    ", "n_vec", "=", "p", "**", "(", "(", "1", "-", "alpha", ")", "/", "2", ")", "\n", "n_vec", "=", "n_vec", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "n_vec", ".", "shape", "[", "1", "]", ",", "c_tilde_batch", ".", "shape", "[", "1", "]", ")", "\n", "\n", "ga_nvec", "=", "p", ".", "reshape", "(", "1", ",", "-", "1", ")", "**", "alpha", "*", "n_vec", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "n_vec_norm", "=", "np", ".", "sum", "(", "n_vec", "*", "ga_nvec", ")", "\n", "np", ".", "testing", ".", "assert_approx_equal", "(", "n_vec_norm", ",", "1", ")", "\n", "c_n_coeffs", "=", "np", ".", "sum", "(", "c_tilde_batch", "*", "ga_nvec", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "axis", "=", "1", ")", "/", "n_vec_norm", "\n", "\n", "c_proj_batch", "=", "c_tilde_batch", "-", "c_n_coeffs", ".", "reshape", "(", "-", "1", ",", "1", ")", "*", "n_vec", "\n", "return", "c_proj_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_on_basis_from_ps": [[68, 77], ["numpy.matmul", "numpy.matmul", "numpy.transpose", "numpy.log", "numpy.log", "numpy.sqrt", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "project_on_basis_from_ps", "(", "p1", ",", "DV", ",", "I_inv", ",", "p0", ",", "alpha", ")", ":", "\n", "    ", "if", "alpha", "==", "1.", ":", "\n", "        ", "p_fact", "=", "p0", "*", "(", "np", ".", "log", "(", "p1", ")", "-", "np", ".", "log", "(", "p0", ")", ")", "\n", "", "else", ":", "\n", "# p_fact = (2./(1-alpha)) * (p0**((1.+alpha)/2.) * p1**((1.-alpha)/2.) - p0 )", "\n", "        ", "p_fact", "=", "(", "2.", "/", "(", "1", "-", "alpha", ")", ")", "*", "(", "np", ".", "sqrt", "(", "p0", ")", "*", "np", ".", "sqrt", "(", "p1", ")", "*", "(", "p0", "/", "p1", ")", "**", "(", "alpha", "/", "2", ")", "-", "p0", ")", "\n", "\n", "", "c_proj_batch", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "matmul", "(", "DV", ".", "T", ",", "np", ".", "transpose", "(", "p_fact", ")", ")", ")", "\n", "return", "c_proj_batch", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.scalar_prod_logp0pw_beta_basis": [[78, 107], ["p0.reshape.reshape", "numpy.matmul", "numpy.log", "numpy.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "scalar_prod_logp0pw_beta_basis", "(", "pw", ",", "p0", ",", "DV", ",", "alpha", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        pw: a batch of probabilities (row:word, column:chi)\n        DV: centered statistics (for p0, to be consistent)\n        p0: the central probability on which tangent space to project (row vector)\n        alpha: the value of alpha\n\n    Returns:\n        scalar product between Logmaps of each point in the batch and the basis of the tangent space\n        .. math:: \\left< \\Log^{(\\alpha)_{p_0} p_w}, \\beta_i^{(\\alpha)} \\right>_{\\mathbb{R}^n_{(\\alpha)}}\n\n    \"\"\"", "\n", "\n", "p0", "=", "p0", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "if", "alpha", "==", "1.", ":", "\n", "        ", "p_fact", "=", "p0", "*", "(", "np", ".", "log", "(", "pw", "+", "NUMTOL", ")", "-", "np", ".", "log", "(", "p0", "+", "NUMTOL", ")", ")", "\n", "", "else", ":", "\n", "# p_fact = (2./(1-alpha)) * (p0**((1.+alpha)/2.) * p1**((1.-alpha)/2.) - p0 )", "\n", "        ", "p_fact", "=", "(", "2.", "/", "(", "1", "-", "alpha", ")", ")", "*", "p0", "*", "(", "(", "(", "pw", ")", "/", "(", "p0", "+", "NUMTOL", ")", ")", "**", "(", "(", "1", "-", "alpha", ")", "/", "2", ")", "-", "1", ")", "\n", "\n", "\n", "#p_fact.shape == (BATCH, DICT)", "\n", "", "ldv_alpha", "=", "np", ".", "matmul", "(", "p_fact", ",", "DV", ")", "\n", "\n", "#ldv_alpha.shape == (BATCH, d), d small linear space (usually d=300)", "\n", "return", "ldv_alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.scalar_prod_logp0pw_beta_basis_npf": [[109, 129], ["compute_embeddings.get_norm_p_fact", "numpy.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.get_norm_p_fact"], ["", "def", "scalar_prod_logp0pw_beta_basis_npf", "(", "pw", ",", "p0", ",", "DV", ",", "alpha", ")", ":", "\n", "    ", "\"\"\"\n    From normalized p_fact\n\n    Args:\n        pw: a batch of probabilities (row:word, column:chi)\n        DV: centered statistics (for p0, to be consistent)\n        p0: the central probability on which tangent space to project (row vector)\n        alpha: the value of alpha\n\n    Returns:\n        scalar product between Logmaps of each point in the batch and the basis of the tangent space\n        .. math:: \\left< \\Log^{(\\alpha)_{p_0} p_w}, \\beta_i^{(\\alpha)} \\right>_{\\mathbb{R}^n_{(\\alpha)}}\n\n    \"\"\"", "\n", "\n", "p_fact_normalized", ",", "l_scale", "=", "get_norm_p_fact", "(", "p0", ",", "pw", ",", "alpha", ")", "\n", "ldv_alpha", "=", "np", ".", "matmul", "(", "p_fact_normalized", ",", "DV", ")", "\n", "\n", "return", "ldv_alpha", ",", "l_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.get_norm_p_fact": [[130, 149], ["p0.reshape.reshape", "numpy.sqrt().reshape", "numexpr.evaluate", "numpy.max().reshape", "numexpr.evaluate", "numexpr.evaluate", "numexpr.evaluate", "numpy.sqrt", "numpy.log", "numpy.log", "numpy.max", "numexpr.evaluate().sum", "numexpr.evaluate"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "get_norm_p_fact", "(", "p0", ",", "pw", ",", "alpha", ")", ":", "\n", "    ", "p0", "=", "p0", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "if", "alpha", "==", "1.", ":", "\n", "        ", "p_fact", "=", "p0", "*", "(", "np", ".", "log", "(", "pw", "+", "NUMTOL", ")", "-", "np", ".", "log", "(", "p0", "+", "NUMTOL", ")", ")", "\n", "inf_norm", "=", "1", "\n", "", "else", ":", "\n", "        ", "ratio", "=", "ne", ".", "evaluate", "(", "\"pw / (p0 + NUMTOL)\"", ")", "# (pw / (p0 + NUMTOL))", "\n", "max_ratio", "=", "np", ".", "max", "(", "ratio", ",", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "alpha_ratio", "=", "ne", ".", "evaluate", "(", "\"(ratio / max_ratio) ** ((1 - alpha) / 2)\"", ")", "\n", "alpha_const", "=", "ne", ".", "evaluate", "(", "\"1. / max_ratio ** ((1 - alpha) / 2)\"", ")", "\n", "inf_norm", "=", "2", "/", "(", "1", "-", "alpha", ")", "*", "max_ratio", "**", "(", "(", "1", "-", "alpha", ")", "/", "2", ")", "\n", "p_fact", "=", "ne", ".", "evaluate", "(", "\"p0 * (alpha_ratio - alpha_const)\"", ")", "\n", "\n", "", "p_fact_norm", "=", "np", ".", "sqrt", "(", "ne", ".", "evaluate", "(", "\"p_fact*p_fact\"", ")", ".", "sum", "(", "axis", "=", "1", ")", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "l_norms", "=", "inf_norm", "*", "p_fact_norm", "\n", "\n", "return", "p_fact", "/", "p_fact_norm", ",", "l_norms", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.core.load_20newsgroup.read_20newsgroup": [[4, 29], ["numpy.equal", "sklearn.datasets.fetch_20newsgroups", "zip", "numpy.array", "numpy.array", "int", "int", "numpy.sum", "zip"], "function", ["None"], ["def", "read_20newsgroup", "(", "task", "=", "None", ",", "ratio_datasets", "=", "[", "0.6", ",", "0.2", ",", "0.2", "]", ",", "random_state", "=", "42", ",", "data_home", "=", "\"/ssd_data/text/\"", ")", ":", "\n", "\n", "    ", "assert", "np", ".", "equal", "(", "np", ".", "sum", "(", "ratio_datasets", ")", ",", "1", ")", "\n", "newsgroups", "=", "fetch_20newsgroups", "(", "data_home", "=", "data_home", ",", "subset", "=", "'all'", ",", "remove", "=", "(", "'headers'", ",", "'footers'", ",", "'quotes'", ")", ",", "categories", "=", "task", ",", "random_state", "=", "random_state", ")", "\n", "\n", "#newsgroups_validation_to_be_split = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=task, random_state = seeds[index])", "\n", "\n", "# filter empty data, it can happen when you remove headers footers and quotes", "\n", "all_data", ",", "all_targets", "=", "zip", "(", "*", "[", "(", "d", ",", "t", ")", "for", "d", ",", "t", "in", "zip", "(", "newsgroups", ".", "data", ",", "newsgroups", ".", "target", ")", "if", "not", "d", "==", "''", "]", ")", "\n", "all_data", "=", "np", ".", "array", "(", "all_data", ")", "\n", "all_targets", "=", "np", ".", "array", "(", "all_targets", ")", "\n", "\n", "n_points", "=", "all_targets", ".", "shape", "[", "0", "]", "\n", "n_point_train", "=", "int", "(", "n_points", "*", "ratio_datasets", "[", "0", "]", ")", "\n", "n_point_validation", "=", "int", "(", "n_points", "*", "(", "ratio_datasets", "[", "0", "]", "+", "ratio_datasets", "[", "1", "]", ")", ")", "\n", "\n", "train_data", "=", "all_data", "[", ":", "n_point_train", "]", "\n", "validation_data", "=", "all_data", "[", "n_point_train", ":", "n_point_validation", "]", "\n", "test_data", "=", "all_data", "[", "n_point_validation", ":", "]", "\n", "\n", "train_target", "=", "all_targets", "[", ":", "n_point_train", "]", "\n", "validation_target", "=", "all_targets", "[", "n_point_train", ":", "n_point_validation", "]", "\n", "test_target", "=", "all_targets", "[", "n_point_validation", ":", "]", "\n", "\n", "return", "train_data", ",", "train_target", ",", "validation_data", ",", "validation_target", ",", "test_data", ",", "test_target", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.load_regularizer.load_regularizer": [[7, 27], ["utils.argo_utils.eval_method_from_tuple", "importlib.import_module", "Exception", "__name__.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["def", "load_regularizer", "(", "regularizer_tuple", ")", ":", "#, module_path = \"\"):", "\n", "\n", "    ", "regularizer_name", "=", "regularizer_tuple", "[", "0", "]", "\n", "regularizer_kwargs", "=", "regularizer_tuple", "[", "1", "]", "\n", "\n", "try", ":", "\n", "# first try to load from here", "\n", "        ", "try", ":", "\n", "            ", "regularizer_module", "=", "importlib", ".", "import_module", "(", "\".\"", "+", "regularizer_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "# it if fails, try to load from tf", "\n", "", "except", "ImportError", ":", "\n", "# regularizer_module = importlib.import_module(module_path + \".core.\" + regularizer_name, '.'.join(__name__.split('.')[:-1]))", "\n", "            ", "regularizer_module", "=", "tf", "\n", "\n", "", "regularizer", "=", "eval_method_from_tuple", "(", "regularizer_module", ",", "regularizer_tuple", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "Exception", "(", "\"problem with module: %s, kwargs: %s, exception %s\"", "%", "(", "regularizer_name", ",", "regularizer_kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.sum_regularizer.sum_regularizer": [[6, 38], ["isinstance", "isinstance", "ValueError", "tensorflow.python.platform.tf_logging.info", "tensorflow.python.framework.ops.name_scope", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.ops.standard_ops.multiply", "tensorflow.python.ops.standard_ops.reduce_sum"], "function", ["None"], ["def", "sum_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a function that can be used to apply sum regularization to weights.\n    N.B. Sum regularization is very unortodox, it encourages highly negative weights.\n\n    Args:\n      scale: A scalar multiplier `Tensor`. 0.0 disables the regularizer.\n      scope: An optional scope name.\n    Returns:\n      A function with signature `sum_reg(weights)` that apply sum regularization.\n    Raises:\n      ValueError: If scale is not a float.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "        ", "if", "scale", "==", "0.", ":", "\n", "            ", "logging", ".", "info", "(", "'Scale of 0 disables regularizer.'", ")", "\n", "return", "lambda", "_", ":", "None", "\n", "\n", "", "", "def", "sum_reg", "(", "weights", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Applies sum regularization to weights.\"\"\"", "\n", "with", "ops", ".", "name_scope", "(", "scope", ",", "'sum_regularizer'", ",", "[", "weights", "]", ")", "as", "name", ":", "\n", "            ", "my_scale", "=", "ops", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "weights", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale'", ")", "\n", "return", "standard_ops", ".", "multiply", "(", "\n", "my_scale", ",", "\n", "standard_ops", ".", "reduce_sum", "(", "weights", ")", ",", "\n", "name", "=", "name", ")", "\n", "\n", "", "", "return", "sum_reg", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.perceptual_loss.delete_ops_from_graph": [[12, 48], ["tensorflow.GraphDef", "tf.GraphDef.node.extend", "node.input.extend", "print", "nodes.append", "inp_names.append"], "function", ["None"], ["def", "delete_ops_from_graph", "(", "graph_def", ",", "op_to_be_deleted", ")", ":", "\n", "#with open(input_model_filepath, 'rb') as f:", "\n", "#    graph_def = tf.GraphDef()", "\n", "#    graph_def.ParseFromString(f.read())", "\n", "\n", "# Delete nodes", "\n", "    ", "nodes", "=", "[", "]", "\n", "for", "node", "in", "graph_def", ".", "node", ":", "\n", "        ", "if", "op_to_be_deleted", "in", "node", ".", "name", ":", "\n", "            ", "print", "(", "'Drop'", ",", "node", ".", "name", ")", "\n", "", "else", ":", "\n", "            ", "nodes", ".", "append", "(", "node", ")", "\n", "\n", "", "", "mod_graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "mod_graph_def", ".", "node", ".", "extend", "(", "nodes", ")", "\n", "\n", "# Delete references to deleted nodes", "\n", "for", "node", "in", "mod_graph_def", ".", "node", ":", "\n", "        ", "inp_names", "=", "[", "]", "\n", "for", "inp", "in", "node", ".", "input", ":", "\n", "            ", "if", "op_to_be_deleted", "in", "inp", ":", "\n", "#pdb.set_trace()", "\n", "#inp_names.append('Placeholder')", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "inp_names", ".", "append", "(", "inp", ")", "\n", "\n", "# delete the expected input type also", "\n", "# del node.attr[:]", "\n", "", "", "del", "node", ".", "input", "[", ":", "]", "\n", "node", ".", "input", ".", "extend", "(", "inp_names", ")", "\n", "\n", "#with open(output_model_filepath, 'wb') as f:", "\n", "#    f.write(mod_graph_def.SerializeToString())", "\n", "\n", "", "return", "mod_graph_def", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.perceptual_loss.replicate": [[49, 54], ["len", "tensorflow.tile", "param.shape.as_list"], "function", ["None"], ["", "def", "replicate", "(", "param", ",", "n_z_samples", ")", ":", "\n", "    ", "num_shapes", "=", "len", "(", "param", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "ones", "=", "[", "1", "]", "*", "num_shapes", "\n", "param_replicate", "=", "tf", ".", "tile", "(", "param", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "return", "param_replicate", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.perceptual_loss.perceptual_loss": [[58, 152], ["print", "tensorflow.tile", "features_extractor_network", "features_extractor_network", "tensorflow.add_n", "tensorflow.multiply", "tensorflow.add_to_collection", "tensorflow.gfile.GFile", "tensorflow.GraphDef", "tf.GraphDef.ParseFromString", "isinstance", "tensorflow.python.framework.importer.import_graph_def", "perceptual_loss.perceptual_loss.run_feature_extractor"], "function", ["None"], ["", "def", "perceptual_loss", "(", "model", ",", "pb", ",", "input", ",", "scale", ",", "nodes", "=", "[", "]", ",", "matching", "=", "[", "]", ")", ":", "\n", "\n", "#pb = 'core/argo/networks/inception_v4.pb'", "\n", "#pb = '/home/luigi/prediction/natural/MNIST-c-st0/FF-cCE-st0-stp0-bs32-trGD_lr0.01-cNo-nD200_D200_D10-cpS-aR-wix-bic0.1-r0/saved_models/frozen_graph.pb'", "\n", "#x = tf.image.resize(model.x, [28,28])", "\n", "\n", "    ", "x", "=", "model", ".", "x", "\n", "rec", "=", "model", ".", "x_reconstruction_node", "\n", "\n", "# load graph", "\n", "# TF 1.14 graph_def = tf.contrib.gan.eval.get_graph_def_from_disk(pb)", "\n", "# since TF 1.15 moved to tensorflow-gan, thus I manually load", "\n", "# with gfile.FastGFile(pb, 'rb') as f:", "\n", "#      graph_def = graph_pb2.GraphDef.FromString(f.read())", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "pb", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "graph_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "matched_nodes", "=", "[", "]", "\n", "for", "match", "in", "matching", ":", "\n", "        ", "matched_nodes", "+=", "[", "n", ".", "name", "+", "\":0\"", "for", "n", "in", "graph_def", ".", "node", "if", "match", "in", "n", ".", "name", "]", "\n", "\n", "", "print", "(", "\"found matching nodes: `{:}`\"", ".", "format", "(", "matched_nodes", ")", ")", "\n", "\n", "# # fix batch norm nodes old bug not needed tf1.15", "\n", "# for node in graph_def.node:", "\n", "#     if node.op == 'RefSwitch':", "\n", "#         node.op = 'Switch'", "\n", "#         for index in xrange(len(node.input)):", "\n", "#             if 'moving_' in node.input[index]:", "\n", "#                 node.input[index] = node.input[index] + '/read'", "\n", "#     elif node.op == 'AssignSub':", "\n", "#         node.op = 'Sub'", "\n", "#         if 'use_locking' in node.attr: del node.attr['use_locking']", "\n", "#", "\n", "\n", "output_tensor", "=", "nodes", "+", "matched_nodes", "#\"ff_network/network/Relu_2:0\"", "\n", "#output_tensor = \"InceptionV4/Logits/AvgPool_1a/AvgPool:0\"", "\n", "#output_tensor = \"ff_network/network/features:0\"", "\n", "\n", "def", "print_nodes", "(", "graph_def", ",", "nodes", ")", ":", "\n", "        ", "for", "node", "in", "graph_def", ".", "node", ":", "\n", "            ", "print", "(", "node", ".", "name", ")", "\n", "if", "node", ".", "name", "in", "nodes", ":", "\n", "                ", "print", "(", "node", ")", "\n", "\n", "#graph_def = delete_ops_from_graph(graph_def, \"IteratorGetNext\")", "\n", "\n", "# see run_image_classifier in https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py", "\n", "", "", "", "def", "run_feature_extractor", "(", "tensor", ",", "graph_def", ",", "input_tensor", ",", "output_tensor", ",", "scope", "=", "\"feature_extractor\"", ")", ":", "\n", "\n", "        ", "input_map", "=", "{", "input_tensor", ":", "tensor", "}", "\n", "\n", "is_singleton", "=", "isinstance", "(", "output_tensor", ",", "str", ")", "\n", "if", "is_singleton", ":", "\n", "            ", "output_tensor", "=", "[", "output_tensor", "]", "\n", "\n", "# tf.import_graph_def(graph_def, input_map=input_map, name=scope)", "\n", "#", "\n", "# graph = tf.get_default_graph()", "\n", "#", "\n", "# feature = graph.get_tensor_by_name(scope + \"/feature_name:0\")", "\n", "\n", "", "features", "=", "importer", ".", "import_graph_def", "(", "graph_def", ",", "input_map", ",", "output_tensor", ",", "name", "=", "scope", ")", "\n", "\n", "if", "is_singleton", ":", "\n", "            ", "features", "=", "features", "[", "0", "]", "\n", "\n", "", "return", "features", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "#with tf.variable_scope('perceptual_loss'):", "\n", "#input = 'Placeholder:0'", "\n", "\n", "", "features_extractor_network", "=", "lambda", "x", ":", "run_feature_extractor", "(", "x", ",", "graph_def", ",", "input", ",", "output_tensor", ")", "\n", "\n", "input_shape", "=", "x", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "ones", "=", "[", "1", "]", "*", "len", "(", "input_shape", ")", "\n", "x_replicate", "=", "tf", ".", "tile", "(", "x", ",", "[", "model", ".", "n_z_samples", "]", "+", "ones", ")", "\n", "\n", "features_x", "=", "features_extractor_network", "(", "x_replicate", ")", "\n", "features_rec", "=", "features_extractor_network", "(", "rec", ")", "\n", "\n", "# check the norm is correct", "\n", "l1_norms", "=", "[", "tf", ".", "norm", "(", "features_x", "[", "i", "]", "-", "features_rec", "[", "i", "]", ",", "ord", "=", "1", ")", "for", "i", "in", "range", "(", "len", "(", "output_tensor", ")", ")", "]", "\n", "\n", "regularizer", "=", "tf", ".", "add_n", "(", "l1_norms", ")", "\n", "scaled_regularizer", "=", "tf", ".", "multiply", "(", "scale", ",", "regularizer", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "CUSTOM_REGULARIZATION", ",", "scaled_regularizer", ")", "\n", "\n", "return", "scaled_regularizer", ",", "[", "regularizer", "]", ",", "\"perceptual_loss\"", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.autoencoding_regularizer.replicate": [[7, 12], ["len", "tensorflow.tile", "param.shape.as_list"], "function", ["None"], ["def", "replicate", "(", "param", ",", "n_z_samples", ")", ":", "\n", "    ", "num_shapes", "=", "len", "(", "param", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "ones", "=", "[", "1", "]", "*", "num_shapes", "\n", "param_replicate", "=", "tf", ".", "tile", "(", "param", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "return", "param_replicate", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.autoencoding_regularizer.autoencoding_regularizer": [[13, 51], ["model._network.encoder_module().params", "argo.core.utils.argo_utils.eval_method_from_tuple.", "tensorflow.reduce_mean", "tensorflow.multiply", "tensorflow.add_to_collection", "importlib.import_module", "argo.core.utils.argo_utils.eval_method_from_tuple", "autoencoding_regularizer.replicate", "autoencoding_regularizer.replicate", "ImportError", "model._network.encoder_module"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.autoencoding_regularizer.replicate", "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.autoencoding_regularizer.replicate"], ["", "def", "autoencoding_regularizer", "(", "model", ",", "distance_function", ",", "scale", ")", ":", "\n", "    ", "\"\"\"\n        Custom regularizer which minimizes dissimilarity(enc(x), enc(rec(x)) given by distance_function\n        where distance_function \\in {euclidean, wasserstein, kl, fisher}\n    \"\"\"", "\n", "\n", "try", ":", "\n", "        ", "module_path", "=", "'argo.core.utils.distances'", "\n", "reg_module", "=", "importlib", ".", "import_module", "(", "module_path", ")", "\n", "dissimilarity", "=", "eval_method_from_tuple", "(", "reg_module", ",", "(", "distance_function", ",", ")", ",", "instantiate", "=", "False", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "raise", "ImportError", "(", "\"regularizer %s not found\"", "%", "distance_function", ")", "from", "e", "\n", "\n", "", "if", "model", ".", "mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "replicate", "(", "model", ".", "mask", ",", "model", ".", "n_z_samples", ")", "\n", "reconstruction_node", "=", "(", "mask", "*", "(", "model", ".", "x_reconstruction_node", "+", "1", ")", "/", "2", ")", "*", "2", "-", "1", "\n", "", "else", ":", "\n", "        ", "reconstruction_node", "=", "model", ".", "x_reconstruction_node", "\n", "\n", "", "encoding_of_reconstruction_params", "=", "model", ".", "_network", ".", "encoder_module", "(", "reconstruction_node", ")", ".", "params", "(", ")", "\n", "# replicate in case of multiple z samples", "\n", "approximate_posterior_params", "=", "[", "replicate", "(", "p", ",", "model", ".", "n_z_samples", ")", "\n", "for", "p", "in", "model", ".", "_approximate_posterior_params", "]", "\n", "\n", "# in case of the Euclidean distance, we compute the distance between mean vectors", "\n", "if", "distance_function", "==", "'euclidean'", ":", "\n", "        ", "approximate_posterior_params", "=", "approximate_posterior_params", "[", "0", "]", "\n", "encoding_of_reconstruction_params", "=", "encoding_of_reconstruction_params", "[", "0", "]", "\n", "\n", "", "reg_node", "=", "dissimilarity", "(", "approximate_posterior_params", ",", "\n", "encoding_of_reconstruction_params", ")", "\n", "\n", "regularizer", "=", "tf", ".", "reduce_mean", "(", "reg_node", ")", "\n", "scaled_regularizer", "=", "tf", ".", "multiply", "(", "scale", ",", "regularizer", ",", "name", "=", "distance_function", "+", "\"_custom_reg\"", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "CUSTOM_REGULARIZATION", ",", "scaled_regularizer", ")", "\n", "\n", "return", "scaled_regularizer", ",", "[", "regularizer", "]", ",", "\"autoencoding_regularizer\"", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.all_same": [[12, 14], ["all"], "function", ["None"], ["def", "all_same", "(", "items", ")", ":", "\n", "    ", "return", "all", "(", "x", "==", "items", "[", "0", "]", "for", "x", "in", "items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.check_matches": [[15, 21], ["zip", "[].strip", "collect_across.all_same", "Exception", "sorted", "list", "set", "set", "match.split", "m.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.all_same"], ["", "def", "check_matches", "(", "matches", ",", "base_dir", ")", ":", "\n", "    ", "trimmed_matches", "=", "[", "match", ".", "split", "(", "base_dir", ")", "[", "1", "]", ".", "strip", "(", "'/'", ")", "for", "match", "in", "matches", "]", "\n", "ds_strings", ",", "net_strings", "=", "zip", "(", "*", "[", "m", ".", "split", "(", "\"/\"", ")", "[", ":", "2", "]", "for", "m", "in", "trimmed_matches", "]", ")", "\n", "if", "not", "all_same", "(", "net_strings", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"net_strings are not all the same, check your regular expression, found: {:}\"", ".", "format", "(", "set", "(", "net_strings", ")", ")", ")", "\n", "", "return", "sorted", "(", "ds_strings", ")", ",", "list", "(", "set", "(", "net_strings", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.get_ds_field_value": [[22, 25], ["[].partition", "match.partition"], "function", ["None"], ["", "def", "get_ds_field_value", "(", "match", ",", "pre_ds_dir", ",", "post_ds_dir", ")", ":", "\n", "    ", "value", "=", "match", ".", "partition", "(", "pre_ds_dir", ")", "[", "2", "]", ".", "partition", "(", "post_ds_dir", ")", "[", "0", "]", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value": [[26, 30], ["collect_across.read_argo_csv"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_argo_csv"], ["", "def", "read_value", "(", "path", ",", "col", ",", "val", ",", "field", ")", ":", "\n", "    ", "df", "=", "read_argo_csv", "(", "path", ",", "**", "pd_csv_kwargs", ")", "\n", "row", "=", "df", "[", "df", "[", "col", "]", "==", "val", "]", "\n", "return", "row", "[", "field", "]", ".", "values", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_max_value": [[31, 35], ["collect_across.read_argo_csv", "df[].idxmax"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_argo_csv"], ["", "def", "read_max_value", "(", "path", ",", "field", ",", "col_ref", ")", ":", "\n", "    ", "df", "=", "read_argo_csv", "(", "path", ",", "**", "pd_csv_kwargs", ")", "\n", "imax", "=", "df", "[", "field", "]", ".", "idxmax", "(", ")", "\n", "return", "df", "[", "col_ref", "]", "[", "imax", "]", ",", "df", "[", "field", "]", "[", "imax", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_argo_csv": [[36, 42], ["pandas.read_csv", "df.rename.rename", "df.rename.rename", "col.strip"], "function", ["None"], ["", "def", "read_argo_csv", "(", "path", ",", "**", "pd_csv_kwargs", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "path", ",", "**", "pd_csv_kwargs", ")", "\n", "df", "=", "df", ".", "rename", "(", "columns", "=", "{", "\"# epochs\"", ":", "\"epoch\"", "}", ")", "\n", "rename_dict", "=", "{", "col", ":", "col", ".", "strip", "(", ")", "for", "col", "in", "df", ".", "columns", "}", "\n", "df", "=", "df", ".", "rename", "(", "columns", "=", "rename_dict", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.convert_alpha": [[43, 48], ["float"], "function", ["None"], ["", "def", "convert_alpha", "(", "alpha_str", ",", "limitfloat", ")", ":", "\n", "    ", "if", "alpha_str", "==", "'limit'", ":", "\n", "        ", "return", "limitfloat", "\n", "", "else", ":", "\n", "        ", "return", "float", "(", "alpha_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.tryfloat": [[49, 56], ["float"], "function", ["None"], ["", "", "def", "tryfloat", "(", "alpha_str", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "value", "=", "float", "(", "alpha_str", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "value", "=", "alpha_str", "\n", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.get_limit_float": [[57, 66], ["collect_across.tryfloat", "isinstance", "min"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.tryfloat"], ["", "def", "get_limit_float", "(", "data", ")", ":", "\n", "    ", "found_limit", "=", "False", "\n", "xs", "=", "[", "tryfloat", "(", "d", "[", "0", "]", ")", "for", "d", "in", "data", "]", "\n", "if", "\"limit\"", "in", "xs", ":", "\n", "        ", "found_limit", "=", "True", "\n", "\n", "", "xs", "=", "[", "x", "for", "x", "in", "xs", "if", "isinstance", "(", "x", ",", "float", ")", "]", "\n", "\n", "return", "min", "(", "xs", ")", "-", "1", ",", "found_limit", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.key_sort": [[67, 72], ["None"], "function", ["None"], ["", "def", "key_sort", "(", "a", ")", ":", "\n", "    ", "if", "a", "[", "0", "]", "==", "'limit'", ":", "\n", "        ", "return", "-", "np", ".", "inf", "\n", "\n", "", "return", "a", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.collect_data_across_ds_single_before": [[74, 109], ["glob.glob", "collect_across.check_matches", "pprint.pprint", "ds_dir.partition", "sorted", "pandas.DataFrame", "os.path.join", "os.makedirs", "os.path.join", "pd.DataFrame.to_csv", "os.path.join", "len", "ValueError", "os.path.splitext", "collect_across.get_ds_field_value", "collect_across.read_max_value", "collect_across.read_value", "collect_across.read_value", "data.append", "os.path.join", "collect_across.tryfloat"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.check_matches", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.get_ds_field_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_max_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.tryfloat"], ["", "def", "collect_data_across_ds_single_before", "(", "base_dir", ",", "ds_dir", ",", "net_dir", ",", "log_file", ",", "outdirname", "=", "\".\"", ")", ":", "\n", "\n", "    ", "dir_list", "=", "[", "base_dir", ",", "ds_dir", ",", "net_dir", ",", "log_file", "]", "\n", "matches", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", "\n", "if", "len", "(", "matches", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"No file found matching the provided regexpr: `{:}`\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", ")", "\n", "\n", "", "ds_strings", ",", "net_string", "=", "check_matches", "(", "matches", ",", "base_dir", ")", "\n", "pprint", "(", "ds_strings", ")", "\n", "\n", "pre_ds_dir", ",", "_", ",", "post_ds_dir", "=", "ds_dir", ".", "partition", "(", "\"*\"", ")", "\n", "ds_param_name", "=", "\"alpha\"", "\n", "log_name", "=", "os", ".", "path", ".", "splitext", "(", "log_file", ")", "[", "0", "]", "\n", "field_train", "=", "log_name", "+", "'_train'", "\n", "field_val", "=", "log_name", "+", "'_validation'", "\n", "field_test", "=", "log_name", "+", "'_test'", "\n", "\n", "all_fields", "=", "[", "ds_param_name", ",", "'epoch'", ",", "field_train", ",", "field_val", ",", "field_test", "]", "\n", "\n", "data", "=", "[", "]", "\n", "for", "match", "in", "matches", ":", "\n", "        ", "x", "=", "get_ds_field_value", "(", "match", ",", "pre_ds_dir", ",", "post_ds_dir", ")", "\n", "epmax", ",", "y_val", "=", "read_max_value", "(", "match", ",", "field_val", ",", "'epoch'", ")", "\n", "y_train", "=", "read_value", "(", "match", ",", "'epoch'", ",", "epmax", ",", "field_train", ")", "\n", "y_test", "=", "read_value", "(", "match", ",", "'epoch'", ",", "epmax", ",", "field_test", ")", "\n", "data", ".", "append", "(", "(", "tryfloat", "(", "x", ")", ",", "epmax", ",", "y_train", ",", "y_val", ",", "y_test", ")", ")", "\n", "\n", "", "sorted_data", "=", "sorted", "(", "data", ",", "key", "=", "key_sort", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "sorted_data", ",", "columns", "=", "all_fields", ")", "\n", "\n", "outpath", "=", "os", ".", "path", ".", "join", "(", "outdirname", ",", "pre_ds_dir", "+", "'W'", "+", "post_ds_dir", ",", "net_string", ")", "\n", "os", ".", "makedirs", "(", "outpath", ",", "exist_ok", "=", "True", ")", "\n", "outpath", "=", "os", ".", "path", ".", "join", "(", "outpath", ",", "\"collected_\"", "+", "log_file", ")", "\n", "df", ".", "to_csv", "(", "outpath", ",", "index", "=", "False", ",", "float_format", "=", "'%.6g'", ",", "**", "pd_csv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.collect_data_across_ds_before": [[111, 114], ["itertools.product", "collect_across.collect_data_across_ds_single_before"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.collect_data_across_ds_single_before"], ["", "def", "collect_data_across_ds_before", "(", "base_dir", ",", "ds_dirs", ",", "net_dirs", ",", "log_file", ",", "outdirname", "=", "\".\"", ")", ":", "\n", "    ", "for", "ds_dir", ",", "net_dir", "in", "product", "(", "ds_dirs", ",", "net_dirs", ")", ":", "\n", "        ", "collect_data_across_ds_single_before", "(", "base_dir", ",", "ds_dir", ",", "net_dir", ",", "log_file", ",", "outdirname", "=", "outdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.collect_data_across_ds_single": [[134, 163], ["glob.glob", "collect_across.check_matches", "pprint.pprint", "collect_across.name_with_wildcard", "os.path.join", "os.makedirs", "collect_across.make_plot", "collect_across.make_table", "os.path.join", "len", "ValueError", "os.path.join"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.check_matches", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.name_with_wildcard", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.make_plot", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.make_table"], ["", "", "def", "collect_data_across_ds_single", "(", "base_dir", ",", "ds_dir", ",", "net_dir", ",", "log_file", ",", "collect_dict", ",", "outdirname", "=", "\".\"", ")", ":", "\n", "    ", "log_filename", "=", "log_file", "[", "'filename'", "]", "\n", "target_col", "=", "log_file", "[", "'target_col'", "]", "\n", "\n", "dir_list", "=", "[", "base_dir", ",", "ds_dir", ",", "net_dir", ",", "log_filename", "]", "\n", "\n", "matches", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", "\n", "if", "len", "(", "matches", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"No file found matching the provided regexpr: `{:}`\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", ")", "\n", "\n", "", "ds_strings", ",", "net_string", "=", "check_matches", "(", "matches", ",", "base_dir", ")", "\n", "pprint", "(", "ds_strings", ")", "\n", "\n", "mainfield_spec", "=", "collect_dict", "[", "'main_field_spec'", "]", "\n", "baseoutputname", "=", "name_with_wildcard", "(", "ds_dir", ",", "mainfield_spec", ")", "\n", "\n", "level", "=", "-", "3", "# usually -3 for dataset in a split, basedir/dsdir/netdir/logfile", "\n", "# csv for plot", "\n", "\n", "conf_plot", "=", "collect_dict", "[", "'plot'", "]", "\n", "conf_table", "=", "collect_dict", "[", "'table'", "]", "\n", "\n", "# log_name = os.path.splitext(os.path.basename(log_filename))[0]", "\n", "\n", "outdirname", "=", "os", ".", "path", ".", "join", "(", "outdirname", ",", "baseoutputname", ",", "net_string", ")", "\n", "os", ".", "makedirs", "(", "outdirname", ",", "exist_ok", "=", "True", ")", "\n", "\n", "make_plot", "(", "matches", ",", "conf_plot", ",", "mainfield_spec", ",", "target_col", ",", "outdirname", ",", "level", "=", "level", ")", "\n", "make_table", "(", "matches", ",", "conf_table", ",", "mainfield_spec", ",", "target_col", ",", "outdirname", ",", "level", "=", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.make_plot": [[166, 186], ["sorted", "pandas.DataFrame", "os.path.join", "pd.DataFrame.to_csv", "collect_across.get_field", "collect_across.read_max_value", "collect_across.read_value", "collect_across.read_value", "data.append", "collect_across.check_where", "match.split", "collect_across.tryfloat", "m.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_max_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_where", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.tryfloat"], ["", "def", "make_plot", "(", "matches", ",", "conf_plot", ",", "mainfield_spec", ",", "target_col", ",", "outdirname", ",", "level", "=", "-", "3", ")", ":", "\n", "    ", "pv", "=", "conf_plot", "[", "'main_field_value'", "]", "\n", "matches_plot", "=", "[", "m", "for", "m", "in", "matches", "if", "check_where", "(", "m", ".", "split", "(", "'/'", ")", "[", "level", "]", ",", "mainfield_spec", ",", "pv", ")", "]", "\n", "ds_param_name", ",", "plot_field_spec", "=", "conf_plot", "[", "'plot_field_spec'", "]", "\n", "field_train", "=", "target_col", "+", "'_train'", "\n", "field_val", "=", "target_col", "+", "'_validation'", "\n", "field_test", "=", "target_col", "+", "'_test'", "\n", "all_fields", "=", "[", "ds_param_name", ",", "'epoch'", ",", "field_train", ",", "field_val", ",", "field_test", "]", "\n", "data", "=", "[", "]", "\n", "for", "match", "in", "matches_plot", ":", "\n", "        ", "x", "=", "get_field", "(", "match", ".", "split", "(", "'/'", ")", "[", "level", "]", ",", "plot_field_spec", ")", "\n", "epmax", ",", "y_val", "=", "read_max_value", "(", "match", ",", "field_val", ",", "'epoch'", ")", "\n", "y_train", "=", "read_value", "(", "match", ",", "'epoch'", ",", "epmax", ",", "field_train", ")", "\n", "y_test", "=", "read_value", "(", "match", ",", "'epoch'", ",", "epmax", ",", "field_test", ")", "\n", "data", ".", "append", "(", "(", "tryfloat", "(", "x", ")", ",", "epmax", ",", "y_train", ",", "y_val", ",", "y_test", ")", ")", "\n", "\n", "", "sorted_data", "=", "sorted", "(", "data", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "sorted_data", ",", "columns", "=", "all_fields", ")", "\n", "outpath_plot", "=", "os", ".", "path", ".", "join", "(", "outdirname", ",", "mainfield_spec", "[", "0", "]", "+", "pv", "+", "\"_\"", "+", "target_col", "+", "\".txt\"", ")", "\n", "df", ".", "to_csv", "(", "outpath_plot", ",", "index", "=", "False", ",", "float_format", "=", "'%.6g'", ",", "**", "pd_csv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.make_table": [[188, 215], ["sorted", "pandas.DataFrame", "os.path.join", "pd.DataFrame.to_csv", "collect_across.read_max_value", "collect_across.read_value", "collect_across.read_value", "data.append", "collect_across.check_where", "collect_across.get_field", "tuple", "m.split", "match.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_max_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.read_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_where", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field"], ["", "def", "make_table", "(", "matches", ",", "conf_table", ",", "mainfield_spec", ",", "target_col", ",", "outdirname", ",", "level", "=", "-", "3", ")", ":", "\n", "    ", "tv", "=", "conf_table", "[", "'main_field_value'", "]", "\n", "matches_table", "=", "[", "m", "for", "m", "in", "matches", "if", "check_where", "(", "m", ".", "split", "(", "'/'", ")", "[", "level", "]", ",", "mainfield_spec", ",", "tv", ")", "]", "\n", "\n", "all_fields", "=", "[", "fn", "for", "fn", ",", "fs", "in", "conf_table", "[", "'table_field_spec'", "]", "]", "\n", "\n", "log_field_train", "=", "target_col", "+", "'_train'", "\n", "log_field_val", "=", "target_col", "+", "'_validation'", "\n", "log_field_test", "=", "target_col", "+", "'_test'", "\n", "all_fields", "+=", "[", "'epoch'", ",", "log_field_train", ",", "log_field_val", ",", "log_field_test", "]", "\n", "\n", "data", "=", "[", "]", "\n", "for", "match", "in", "matches_table", ":", "\n", "# get values identifying this match as from specifications", "\n", "        ", "tables_field_values", "=", "[", "get_field", "(", "match", ".", "split", "(", "'/'", ")", "[", "level", "]", ",", "tfspec", ",", "with_subfields", "=", "False", ")", "for", "tfn", ",", "tfspec", "in", "conf_table", "[", "'table_field_spec'", "]", "]", "\n", "\n", "epmax", ",", "y_val", "=", "read_max_value", "(", "match", ",", "log_field_val", ",", "'epoch'", ")", "\n", "y_train", "=", "read_value", "(", "match", ",", "'epoch'", ",", "epmax", ",", "log_field_train", ")", "\n", "y_test", "=", "read_value", "(", "match", ",", "'epoch'", ",", "epmax", ",", "log_field_test", ")", "\n", "\n", "data", ".", "append", "(", "tuple", "(", "tables_field_values", ")", "+", "(", "epmax", ",", "y_train", ",", "y_val", ",", "y_test", ")", ")", "\n", "\n", "", "sorted_data", "=", "sorted", "(", "data", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "sorted_data", ",", "columns", "=", "all_fields", ")", "\n", "outpath_table", "=", "os", ".", "path", ".", "join", "(", "outdirname", ",", "mainfield_spec", "[", "0", "]", "+", "tv", "+", "\"_\"", "+", "target_col", "+", "\".txt\"", ")", "\n", "df", ".", "to_csv", "(", "outpath_table", ",", "index", "=", "False", ",", "float_format", "=", "'%.6g'", ",", "**", "pd_csv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.name_with_wildcard": [[217, 223], ["ds_dir.partition", "collect_across.get_field"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field"], ["", "def", "name_with_wildcard", "(", "ds_dir", ",", "field_spec", ")", ":", "\n", "    ", "mainfield", "=", "field_spec", "[", "0", "]", "\n", "tag", "=", "'-'", "+", "mainfield", "+", "get_field", "(", "ds_dir", ",", "(", "mainfield", ",", ")", ")", "\n", "pre_ds_dir", ",", "_", ",", "post_ds_dir", "=", "ds_dir", ".", "partition", "(", "tag", ")", "\n", "name_with_wildcard", "=", "pre_ds_dir", "+", "'-'", "+", "mainfield", "+", "'W'", "+", "post_ds_dir", "\n", "return", "name_with_wildcard", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.collect_data_across_ds": [[225, 228], ["itertools.product", "collect_across.collect_data_across_ds_single"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.collect_data_across_ds_single"], ["", "def", "collect_data_across_ds", "(", "base_dir", ",", "ds_dirs", ",", "net_dirs", ",", "log_file", ",", "collect_dict", ",", "outdirname", "=", "\".\"", ")", ":", "\n", "    ", "for", "ds_dir", ",", "net_dir", "in", "product", "(", "ds_dirs", ",", "net_dirs", ")", ":", "\n", "        ", "collect_data_across_ds_single", "(", "base_dir", ",", "ds_dir", ",", "net_dir", ",", "log_file", ",", "collect_dict", ",", "outdirname", "=", "outdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.get_field": [[230, 258], ["len", "re.split", "re.search", "ValueError", "re.search.group", "re.split", "re.split"], "function", ["None"], ["", "", "def", "get_field", "(", "string", ",", "field_spec", ",", "with_subfields", "=", "True", ")", ":", "\n", "    ", "l", "=", "len", "(", "field_spec", ")", "\n", "\n", "if", "l", "==", "0", "or", "l", ">", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not implemented tuple length `{:}`, found field spec `{:}`\"", ".", "format", "(", "l", ",", "field_spec", ")", ")", "\n", "\n", "", "m", "=", "re", ".", "split", "(", "'(-|^)'", "+", "field_spec", "[", "0", "]", ",", "string", ")", "\n", "try", ":", "\n", "        ", "after", "=", "m", "[", "2", "]", "\n", "ss1", "=", "re", ".", "split", "(", "'(-[a-zA-Z]|$)'", ",", "after", ")", "[", "0", "]", "\n", "", "except", ":", "\n", "        ", "ss1", "=", "''", "\n", "\n", "", "if", "l", "==", "1", ":", "\n", "        ", "if", "with_subfields", ":", "\n", "            ", "return", "ss1", "\n", "", "else", ":", "\n", "            ", "ss1val", "=", "re", ".", "split", "(", "'(_|$)'", ",", "ss1", ")", "[", "0", "]", "\n", "return", "ss1val", "\n", "\n", "", "", "m", "=", "re", ".", "search", "(", "'(_|^)'", "+", "field_spec", "[", "1", "]", "+", "'([\\.\\-\\,A-Za-z0-9]+)'", "+", "'(_|$)'", ",", "ss1", ")", "\n", "\n", "if", "m", "is", "None", ":", "\n", "        ", "ss2", "=", "''", "\n", "", "else", ":", "\n", "        ", "ss2", "=", "m", ".", "group", "(", "2", ")", "\n", "\n", "", "return", "ss2", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_across.check_where": [[260, 262], ["collect_across.get_field"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field"], ["", "def", "check_where", "(", "string", ",", "field_spec", ",", "value", ")", ":", "\n", "    ", "return", "get_field", "(", "string", ",", "field_spec", ",", "with_subfields", "=", "False", ")", "==", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.__init__": [[49, 51], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.plot": [[52, 226], ["matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rc", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "isinstance", "collections.OrderedDict", "collections.OrderedDict", "print", "print", "os.walk", "len", "ValueError", "AbstractPlot.join_dirs_path", "collections.OrderedDict", "print", "print", "AbstractPlot.AbstractPlot.rows_columns", "AbstractPlot.AbstractPlot.create_fig", "AbstractPlot.AbstractPlot.suptitle", "matplotlib.tight_layout", "matplotlib.tight_layout", "matplotlib.tight_layout", "print", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.savefig", "zip", "itertools.product", "print", "AbstractPlot.AbstractPlot.plot_vertical_panel", "len", "len", "dirs.append", "AbstractPlot.check_where", "AbstractPlot.check_block", "isinstance", "AbstractPlot.get_feature", "isinstance", "isinstance", "AbstractPlot.get_feature", "join_dirs_path.split", "AbstractPlot.get_feature", "i.items", "collections.OrderedDict.keys", "AbstractPlot.check_where", "isinstance", "str", "isinstance", "join_dirs_path().split", "AbstractPlot.join_dirs_path", "AbstractPlot.join_dirs_path", "join_dirs_path.split", "re.search", "re.search", "isinstance", "map", "AbstractPlot.join_dirs_path", "AbstractPlot.AbstractPlot.plot.my_items"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.join_dirs_path", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.PlotCurves.rows_columns", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.create_fig", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.suptitle", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.PlotCurves.plot_vertical_panel", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_where", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_block", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_feature", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_feature", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_feature", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_where", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.join_dirs_path", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.join_dirs_path", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.join_dirs_path"], ["", "def", "plot", "(", "self", ",", "\n", "panels", ",", "\n", "where", ",", "\n", "block", ",", "\n", "fixed_over", ",", "\n", "logs_directory", ",", "\n", "depth", ",", "\n", "dataset", ",", "\n", "tag", ",", "\n", "filename", "=", "\"log\"", ",", "\n", "dirname", "=", "\".\"", ",", "\n", "figsize", "=", "(", "26", ",", "10", ")", ",", "\n", "legend", "=", "[", "]", ",", "\n", "group_by", "=", "[", "]", ",", "\n", "rcParams", "=", "{", "}", ",", "\n", "string_to_val", "=", "{", "}", ",", "\n", "small_size", "=", "8", ",", "\n", "medium_size", "=", "10", ",", "\n", "bigger_size", "=", "12", ",", "\n", "suptitle", "=", "None", ",", "\n", "degree", "=", "10", ")", ":", "\n", "\n", "        ", "plt", ".", "rc", "(", "'font'", ",", "size", "=", "small_size", ")", "# controls default text sizes", "\n", "plt", ".", "rc", "(", "'axes'", ",", "titlesize", "=", "small_size", ")", "# fontsize of the axes title", "\n", "plt", ".", "rc", "(", "'axes'", ",", "labelsize", "=", "medium_size", ")", "# fontsize of the x and y labels", "\n", "plt", ".", "rc", "(", "'xtick'", ",", "labelsize", "=", "small_size", ")", "# fontsize of the tick labels", "\n", "plt", ".", "rc", "(", "'ytick'", ",", "labelsize", "=", "small_size", ")", "# fontsize of the tick labels", "\n", "plt", ".", "rc", "(", "'legend'", ",", "fontsize", "=", "small_size", ")", "# legend fontsize", "\n", "plt", ".", "rc", "(", "'figure'", ",", "titlesize", "=", "bigger_size", ")", "# fontsize of the figure title", "\n", "# added by Riccardo", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "rcParams", ")", "\n", "\n", "if", "isinstance", "(", "logs_directory", ",", "list", ")", ":", "\n", "            ", "sources", "=", "[", "l", "+", "\"/\"", "+", "dataset", "for", "l", "in", "logs_directory", "]", "\n", "#walk_source = itertools.chain(*[os.walk(s) for s in source])", "\n", "", "else", ":", "\n", "            ", "sources", "=", "[", "logs_directory", "+", "\"/\"", "+", "dataset", "]", "\n", "#walk_source = os.walk(source)", "\n", "\n", "", "if", "suptitle", "is", "None", ":", "\n", "            ", "suptitle", "=", "dataset", "\n", "\n", "# self.string_to_val = string_to_val", "\n", "\n", "", "dirs", "=", "[", "]", "\n", "for", "source", "in", "sources", ":", "\n", "            ", "for", "(", "parent", ",", "subdirs", ",", "files", ")", "in", "os", ".", "walk", "(", "source", ")", ":", "\n", "                ", "if", "len", "(", "join_dirs_path", "(", "source", ",", "parent", ")", ".", "split", "(", "'/'", ")", ")", "==", "depth", ":", "\n", "                    ", "dirs", ".", "append", "(", "(", "source", ",", "parent", ")", ")", "\n", "\n", "", "", "", "folders_where", "=", "[", "(", "source", ",", "d", ")", "for", "(", "source", ",", "d", ")", "in", "dirs", "if", "\n", "check_where", "(", "join_dirs_path", "(", "source", ",", "d", ")", ",", "where", ")", "and", "check_block", "(", "join_dirs_path", "(", "source", ",", "d", ")", ",", "\n", "block", ")", "]", "\n", "\n", "fixed_over_values", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "f", "in", "fixed_over", ":", "\n", "            ", "fixed_over_values", "[", "f", "]", "=", "[", "]", "\n", "\n", "", "if", "len", "(", "group_by", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"The group_by only works for 0 or 1 feature, you have more: {}\"", ".", "format", "(", "group_by", ")", ")", "\n", "\n", "", "group_by_values", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "f", "in", "group_by", ":", "\n", "            ", "group_by_values", "[", "f", "]", "=", "[", "]", "\n", "\n", "", "for", "(", "source", ",", "d", ")", "in", "folders_where", ":", "\n", "\n", "            ", "directory", "=", "join_dirs_path", "(", "source", ",", "d", ")", "\n", "for", "f_tuple", "in", "fixed_over", ":", "\n", "                ", "if", "not", "isinstance", "(", "f_tuple", ",", "tuple", ")", ":", "\n", "                    ", "f", "=", "f_tuple", "\n", "m", "=", "get_feature", "(", "f", ",", "directory", ")", "\n", "if", "m", ":", "\n", "                        ", "if", "m", ".", "group", "(", "2", ")", "not", "in", "fixed_over_values", "[", "f", "]", ":", "\n", "# here I may something like -cELBO_A1_A2-", "\n", "# and I want to keep only ELBO", "\n", "                            ", "token", "=", "m", ".", "group", "(", "2", ")", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "if", "token", "not", "in", "fixed_over_values", "[", "f", "]", ":", "\n", "                                ", "fixed_over_values", "[", "f", "]", ".", "append", "(", "token", ")", "\n", "", "", "", "", "else", ":", "\n", "                    ", "(", "f", ",", "i", ")", "=", "f_tuple", "\n", "if", "isinstance", "(", "i", ",", "int", ")", ":", "\n", "# i is a number and thus it specify the level in which I have to look for", "\n", "                        ", "splits", "=", "directory", ".", "split", "(", "'/'", ")", "\n", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "f", "+", "'([\\,\\._A-Za-z0-9\\+]+)'", "+", "'(-|$)'", ",", "splits", "[", "i", "]", ")", "\n", "if", "m", ":", "\n", "                            ", "if", "m", ".", "group", "(", "2", ")", "not", "in", "fixed_over_values", "[", "(", "f", ",", "i", ")", "]", ":", "\n", "                                ", "fixed_over_values", "[", "(", "f", ",", "i", ")", "]", ".", "append", "(", "m", ".", "group", "(", "2", ")", ")", "\n", "", "", "", "else", ":", "\n", "# i is a tag, I hadve to look for the value of the sub_tag i", "\n", "# inside the tag f", "\n", "# pdb.set_trace()", "\n", "                        ", "m", "=", "re", ".", "search", "(", "\n", "'(-|^)'", "+", "f", "+", "'([\\,\\._A-Za-z0-9\\+]*)'", "+", "i", "+", "'([\\,\\.A-Za-z0-9\\+]*)'", "+", "'([\\,\\._A-Za-z0-9\\+]*)'", "+", "'(-|$)'", ",", "\n", "directory", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "3", ")", "not", "in", "fixed_over_values", "[", "(", "f", ",", "i", ")", "]", ":", "\n", "                            ", "token", "=", "m", ".", "group", "(", "3", ")", "\n", "fixed_over_values", "[", "(", "f", ",", "i", ")", "]", ".", "append", "(", "token", ")", "\n", "\n", "", "", "", "", "for", "f_tuple", "in", "group_by", ":", "\n", "                ", "if", "not", "isinstance", "(", "f_tuple", ",", "tuple", ")", ":", "\n", "                    ", "f", "=", "f_tuple", "\n", "m", "=", "get_feature", "(", "f", ",", "directory", ")", "\n", "if", "m", ":", "\n", "                        ", "if", "m", ".", "group", "(", "2", ")", "not", "in", "group_by_values", "[", "f", "]", ":", "\n", "                            ", "group_by_values", "[", "f", "]", ".", "append", "(", "m", ".", "group", "(", "2", ")", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "(", "f", ",", "i", ")", "=", "f_tuple", "\n", "splits", "=", "directory", ".", "split", "(", "'/'", ")", "\n", "m", "=", "get_feature", "(", "f", ",", "splits", "[", "i", "]", ")", "\n", "if", "m", ":", "\n", "                        ", "if", "m", ".", "group", "(", "2", ")", "not", "in", "group_by_values", "[", "(", "f", ",", "i", ")", "]", ":", "\n", "                            ", "group_by_values", "[", "(", "f", ",", "i", ")", "]", ".", "append", "(", "m", ".", "group", "(", "2", ")", ")", "\n", "\n", "", "", "", "", "", "print", "(", "fixed_over_values", ")", "\n", "print", "(", "group_by_values", ")", "\n", "\n", "def", "my_items", "(", "i", ")", ":", "\n", "# return [(a[0][0], a[1], a[0][1]) if len(a) == 2 else a for a in i.items()]", "\n", "            ", "return", "[", "(", "a", "[", "0", "]", "[", "0", "]", ",", "a", "[", "1", "]", ",", "a", "[", "0", "]", "[", "1", "]", ")", "if", "(", "len", "(", "a", ")", "==", "2", "and", "isinstance", "(", "a", ",", "list", ")", ")", "else", "a", "for", "a", "in", "i", ".", "items", "(", ")", "]", "\n", "\n", "", "cartesian_fixed", "=", "[", "collections", ".", "OrderedDict", "(", "zip", "(", "fixed_over_values", ".", "keys", "(", ")", ",", "p", ")", ")", "for", "p", "in", "\n", "product", "(", "*", "map", "(", "make_list", ",", "fixed_over_values", ".", "values", "(", ")", ")", ")", "]", "\n", "cartesian_fixed_list", "=", "[", "d", "for", "d", "in", "cartesian_fixed", "]", "\n", "\n", "for", "c_fixed", "in", "cartesian_fixed_list", ":", "\n", "\n", "            ", "folders_cartesian_fixed", "=", "[", "(", "source", ",", "d", ")", "for", "(", "source", ",", "d", ")", "in", "folders_where", "if", "\n", "check_where", "(", "join_dirs_path", "(", "source", ",", "d", ")", ",", "my_items", "(", "c_fixed", ")", ")", "]", "\n", "\n", "print", "(", "\"============================================\"", ")", "\n", "print", "(", "c_fixed", ")", "\n", "for", "k", "in", "folders_cartesian_fixed", ":", "\n", "                ", "print", "(", "k", ")", "\n", "\n", "", "n_rows", ",", "n_columns", "=", "self", ".", "rows_columns", "(", "panels", ",", "folders_cartesian_fixed", ")", "\n", "\n", "# create figure", "\n", "fig", "=", "self", ".", "create_fig", "(", "figsize", ",", "folders_cartesian_fixed", ")", "\n", "self", ".", "suptitle", "(", "fig", ",", "suptitle", ")", "\n", "\n", "c", "=", "0", "\n", "\n", "for", "vertical_panels", "in", "panels", ":", "\n", "                ", "self", ".", "plot_vertical_panel", "(", "vertical_panels", ",", "\n", "c", ",", "\n", "n_rows", ",", "\n", "n_columns", ",", "\n", "legend", ",", "\n", "fig", ",", "\n", "folders_cartesian_fixed", ",", "\n", "group_by_values", ",", "\n", "source", ",", "\n", "degree", ",", "\n", "string_to_val", ")", "\n", "c", "+=", "1", "\n", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "def", "format_attr", "(", "k", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "k", ",", "list", ")", ":", "\n", "                    ", "return", "str", "(", "k", ")", "\n", "", "else", ":", "\n", "                    ", "if", "isinstance", "(", "k", "[", "1", "]", ",", "int", ")", ":", "\n", "                        ", "return", "str", "(", "k", "[", "0", "]", ")", "+", "'['", "+", "str", "(", "k", "[", "1", "]", ")", "+", "']'", "\n", "", "else", ":", "\n", "                        ", "return", "str", "(", "k", "[", "0", "]", ")", "+", "'_'", "+", "str", "(", "k", "[", "1", "]", ")", "\n", "\n", "", "", "", "attr", "=", "\"-\"", ".", "join", "(", "[", "format_attr", "(", "k", ")", "+", "str", "(", "v", ")", "for", "k", ",", "v", "in", "c_fixed", ".", "items", "(", ")", "]", ")", "\n", "if", "len", "(", "attr", ")", ">", "0", ":", "\n", "                ", "attr", "=", "'_'", "+", "attr", "\n", "", "print", "(", "\"saving: \"", "+", "dirname", "+", "\"/\"", "+", "dataset", "+", "\"_\"", "+", "filename", "+", "\"_\"", "+", "tag", "+", "attr", "+", "\".png\"", ")", "\n", "plt", ".", "savefig", "(", "dirname", "+", "\"/\"", "+", "dataset", "+", "\"_\"", "+", "filename", "+", "\"_\"", "+", "tag", "+", "attr", "+", "\".png\"", ",", "\n", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.create_label": [[229, 248], ["len", "AbstractPlot.get_value", "AbstractPlot.replace_scientific", "curve.get", "os.path.isfile", "open", "open.read", "join_dirs_path().replace", "AbstractPlot.join_dirs_path", "AbstractPlot.join_dirs_path"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.get_value", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.replace_scientific", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.join_dirs_path", "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.join_dirs_path"], ["", "", "def", "create_label", "(", "self", ",", "curve", ",", "directory", ",", "legend", ",", "source", ")", ":", "\n", "        ", "if", "len", "(", "legend", ")", ">", "0", ":", "\n", "            ", "\"Legend has to be in the format: [(param, name)], where param is an id in the name\"", "\n", "label", "=", "\"\"", "\n", "for", "l", "in", "legend", ":", "\n", "                ", "piece", "=", "get_value", "(", "replace_scientific", "(", "join_dirs_path", "(", "source", ",", "directory", ")", ")", ",", "l", ")", "\n", "label", "+=", "piece", "+", "\"\"", "\n", "", "", "elif", "\"y_label\"", "in", "curve", ":", "\n", "            ", "file_path", "=", "directory", "+", "'/'", "+", "curve", ".", "get", "(", "\"legend\"", ",", "\"\"", ")", "\n", "if", "\"legend\"", "in", "curve", "and", "os", ".", "path", ".", "isfile", "(", "file_path", ")", ":", "\n", "                ", "f", "=", "open", "(", "file_path", ",", "\"r\"", ")", "\n", "label", "=", "f", ".", "read", "(", ")", "\n", "if", "label", "[", "-", "1", "]", "==", "'\\n'", ":", "\n", "                    ", "label", "=", "label", "[", ":", "-", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "label", "=", "join_dirs_path", "(", "source", ",", "directory", ")", ".", "replace", "(", "'/'", ",", "'\\n'", ")", "\n", "", "", "else", ":", "\n", "            ", "label", "=", "None", "\n", "", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.rows_columns": [[249, 251], ["None"], "methods", ["None"], ["", "def", "rows_columns", "(", "self", ",", "panels", ",", "folders_cartesian_fixed", ")", ":", "\n", "        ", "return", "0", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.create_fig": [[252, 255], ["matplotlib.figure", "matplotlib.figure", "matplotlib.figure"], "methods", ["None"], ["", "def", "create_fig", "(", "self", ",", "figsize", ",", "folders_cartesian_fixed", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "figsize", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.suptitle": [[256, 258], ["fig.suptitle"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.suptitle"], ["", "def", "suptitle", "(", "self", ",", "fig", ",", "title", ")", ":", "\n", "        ", "fig", ".", "suptitle", "(", "title", ",", "y", "=", "0.995", ")", "# , fontsize=10)", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.get_colors_pairs": [[259, 271], ["len", "enumerate", "enumerate", "list", "group_by_values.values", "AbstractPlot.check_where", "enumerate", "list", "group_by_values.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_where"], ["", "def", "get_colors_pairs", "(", "self", ",", "folders_cartesian_fixed", ",", "group_by_values", ")", ":", "\n", "        ", "if", "len", "(", "group_by_values", ")", "==", "0", ":", "\n", "            ", "return", "[", "(", "i", ",", "i", ",", "d", ")", "for", "i", ",", "d", "in", "enumerate", "(", "folders_cartesian_fixed", ")", "]", "\n", "", "else", ":", "\n", "            ", "c_list", "=", "[", "]", "\n", "for", "i", ",", "c_group", "in", "enumerate", "(", "list", "(", "group_by_values", ".", "values", "(", ")", ")", "[", "0", "]", ")", ":", "\n", "                ", "group", "=", "[", "(", "i", ",", "d", ")", "for", "d", "in", "folders_cartesian_fixed", "if", "\n", "check_where", "(", "d", ",", "[", "(", "list", "(", "group_by_values", ".", "keys", "(", ")", ")", "[", "0", "]", ",", "c_group", ")", "]", ")", "]", "\n", "\n", "c_list", "+=", "[", "(", "i", ",", "*", "d", ")", "for", "i", ",", "d", "in", "enumerate", "(", "group", ")", "]", "\n", "\n", "", "return", "c_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.plot_vertical_panel": [[272, 286], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "plot_vertical_panel", "(", "self", ",", "\n", "vertical_panels", ",", "\n", "c", ",", "\n", "n_rows", ",", "\n", "n_columns", ",", "\n", "legend", ",", "\n", "fig", ",", "\n", "folders_cartesian_fixed", ",", "\n", "group_by_values", ",", "\n", "source", ",", "\n", "degree", ",", "\n", "string_to_val", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.make_list": [[27, 29], ["isinstance"], "function", ["None"], ["def", "make_list", "(", "l", ")", ":", "\n", "    ", "return", "l", "if", "isinstance", "(", "l", ",", "list", ")", "else", "[", "l", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.create_list_colors": [[35, 45], ["list", "matplotlib.to_hex", "matplotlib.TABLEAU_COLORS.values", "list", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap.", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap", "range"], "function", ["None"], ["", "def", "create_list_colors", "(", "n", ")", ":", "\n", "    ", "if", "n", "<=", "10", ":", "\n", "        ", "colors", "=", "list", "(", "mcolors", ".", "TABLEAU_COLORS", ".", "values", "(", ")", ")", "\n", "", "elif", "n", ">", "10", "and", "n", "<=", "20", ":", "\n", "        ", "colors", "=", "list", "(", "matplotlib", ".", "cm", ".", "get_cmap", "(", "\"tab20\"", ")", ".", "colors", ")", "\n", "", "else", ":", "\n", "        ", "cmap", "=", "matplotlib", ".", "cm", ".", "get_cmap", "(", "\"gist_rainbow\"", ",", "n", ")", "\n", "colors", "=", "[", "cmap", "(", "i", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "\n", "", "return", "[", "mcolors", ".", "to_hex", "(", "rgba", ")", "for", "rgba", "in", "colors", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_where": [[288, 322], ["len", "s.split", "isinstance", "isinstance", "isinstance", "AbstractPlot.get_specific_feature", "re.search", "re.search", "str", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_specific_feature"], ["", "", "def", "check_where", "(", "s", ",", "where", ")", ":", "\n", "    ", "r", "=", "True", "\n", "for", "tuple_where", "in", "where", ":", "\n", "        ", "if", "len", "(", "tuple_where", ")", "==", "2", ":", "\n", "            ", "(", "k", ",", "list_values", ")", "=", "tuple_where", "\n", "if", "not", "isinstance", "(", "list_values", ",", "list", ")", ":", "\n", "                ", "list_values", "=", "[", "list_values", "]", "\n", "", "c", "=", "False", "\n", "for", "v", "in", "list_values", ":", "\n", "                ", "if", "isinstance", "(", "k", ",", "tuple", ")", ":", "\n", "# match = re.search('(-|^)' + k + str(v) + '(_|-|$)', s)", "\n", "# here I may have something like c A and 1", "\n", "# and I need to find it in -cELBO_A1_A2-", "\n", "                    ", "match", "=", "re", ".", "search", "(", "'(-|^)'", "+", "k", "[", "0", "]", "+", "'([\\,\\._A-Za-z0-9,\\+]+)'", "+", "k", "[", "1", "]", "+", "str", "(", "v", ")", "+", "'(_|-|$)'", ",", "s", ")", "\n", "c", "=", "c", "or", "match", "\n", "", "else", ":", "\n", "# match = re.search('(-|^)' + k + str(v) + '(-|$)', s)", "\n", "# here I may have something like c and ELBO", "\n", "# and I need to find it in -cELBO_A1_A2-", "\n", "                    ", "match", "=", "re", ".", "search", "(", "'(-|^)'", "+", "k", "+", "str", "(", "v", ")", "+", "'(_|-|$)'", ",", "s", ")", "\n", "c", "=", "c", "or", "match", "\n", "", "", "r", "=", "r", "and", "c", "\n", "", "else", ":", "\n", "            ", "(", "k", ",", "list_values", ",", "i", ")", "=", "tuple_where", "\n", "split", "=", "s", ".", "split", "(", "'/'", ")", "\n", "if", "not", "isinstance", "(", "list_values", ",", "list", ")", ":", "\n", "                ", "list_values", "=", "[", "list_values", "]", "\n", "", "c", "=", "False", "\n", "for", "v", "in", "list_values", ":", "\n", "                ", "match", "=", "get_specific_feature", "(", "k", ",", "v", ",", "split", "[", "i", "]", ")", "\n", "c", "=", "c", "or", "match", "\n", "", "r", "=", "r", "and", "c", "\n", "\n", "", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_specific_feature": [[324, 326], ["re.search", "str"], "function", ["None"], ["", "def", "get_specific_feature", "(", "key", ",", "val", ",", "sstr", ")", ":", "\n", "    ", "return", "re", ".", "search", "(", "'(-|_|^)'", "+", "key", "+", "str", "(", "val", ")", "+", "'(-|_|$)'", ",", "sstr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.check_block": [[328, 342], ["len", "re.search", "s.split", "re.search", "str", "str"], "function", ["None"], ["", "def", "check_block", "(", "s", ",", "block", ")", ":", "\n", "    ", "for", "tuple_block", "in", "block", ":", "\n", "        ", "if", "len", "(", "tuple_block", ")", "==", "2", ":", "\n", "            ", "(", "k", ",", "v", ")", "=", "tuple_block", "\n", "match", "=", "re", ".", "search", "(", "k", "+", "str", "(", "v", ")", "+", "'(-|_|$)'", ",", "s", ")", "\n", "if", "match", ":", "# k + str(v) + '-' in s or k + str(v) + '_' in s:", "\n", "                ", "return", "False", "\n", "", "", "else", ":", "\n", "            ", "(", "k", ",", "v", ",", "i", ")", "=", "tuple_block", "\n", "split", "=", "s", ".", "split", "(", "'/'", ")", "\n", "match", "=", "re", ".", "search", "(", "k", "+", "str", "(", "v", ")", "+", "'(-|_|$)'", ",", "split", "[", "i", "]", ")", "\n", "if", "match", ":", "# k + str(v) + '-' in split[i] or k + str(v) + '_' in split[i]:", "\n", "                ", "return", "False", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.join_dirs_path": [[344, 346], ["d.replace().replace", "d.replace"], "function", ["None"], ["", "def", "join_dirs_path", "(", "source", ",", "d", ")", ":", "\n", "    ", "return", "d", ".", "replace", "(", "source", "+", "'/'", ",", "''", ")", ".", "replace", "(", "'//'", ",", "'/'", ")", "# .replace('/','-')", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.replace_scientific": [[348, 366], ["re.findall", "len", "copy.deepcopy", "AbstractPlot.replace_scientific.process_sn"], "function", ["None"], ["", "def", "replace_scientific", "(", "string", ")", ":", "\n", "# scientific notation numbers", "\n", "    ", "snlist", "=", "re", ".", "findall", "(", "'(\\d+[eE]([+-])(\\d+))'", ",", "string", ")", "\n", "if", "len", "(", "snlist", ")", ">", "0", ":", "\n", "        ", "def", "process_sn", "(", "number", ",", "sign", ",", "exp", ")", ":", "\n", "            ", "if", "sign", "==", "\"-\"", ":", "\n", "                ", "stringy", "=", "(", "'{:.'", "+", "str", "(", "int", "(", "exp", ")", ")", "+", "'f}'", ")", ".", "format", "(", "float", "(", "number", ")", ")", "\n", "", "else", ":", "\n", "                ", "stringy", "=", "(", "'{:'", "+", "str", "(", "int", "(", "exp", ")", ")", "+", "'d}'", ")", ".", "format", "(", "int", "(", "float", "(", "number", ")", ")", ")", "\n", "", "return", "(", "number", ",", "stringy", ")", "\n", "", "sncouples", "=", "[", "process_sn", "(", "*", "sn", ")", "for", "sn", "in", "snlist", "]", "\n", "\n", "newstring", "=", "copy", ".", "deepcopy", "(", "string", ")", "\n", "for", "oldstr", ",", "newstr", "in", "sncouples", ":", "\n", "            ", "newstring", "=", "newstring", ".", "replace", "(", "oldstr", ",", "newstr", ")", "\n", "\n", "", "return", "newstring", "\n", "", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_field": [[368, 391], ["len", "re.search", "re.search", "ValueError", "re.search.group", "re.search.group"], "function", ["None"], ["", "def", "get_field", "(", "string", ",", "field_spec", ")", ":", "\n", "    ", "l", "=", "len", "(", "field_spec", ")", "\n", "\n", "if", "l", "==", "0", "or", "l", ">", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not implemented tuple length `{:}`, found field spec `{:}`\"", ".", "format", "(", "l", ",", "field_spec", ")", ")", "\n", "\n", "", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "field_spec", "[", "0", "]", "+", "'([\\._A-Za-z0-9\\,]+)'", "+", "'(-|$)'", ",", "string", ")", "\n", "if", "m", "is", "None", ":", "\n", "        ", "ss1", "=", "'0'", "\n", "", "else", ":", "\n", "        ", "ss1", "=", "m", ".", "group", "(", "2", ")", "\n", "\n", "", "if", "l", "==", "1", ":", "\n", "        ", "return", "ss1", "\n", "\n", "", "m", "=", "re", ".", "search", "(", "'(_|^)'", "+", "field_spec", "[", "1", "]", "+", "'([\\.A-Za-z0-9\\,]+)'", "+", "'(_|$)'", ",", "ss1", ")", "\n", "\n", "if", "m", "is", "None", ":", "\n", "        ", "ss2", "=", "'0'", "\n", "", "else", ":", "\n", "        ", "ss2", "=", "m", ".", "group", "(", "2", ")", "\n", "\n", "", "return", "ss2", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_value": [[393, 427], ["len", "re.search", "re.search.group", "len", "directory.split", "re.search", "re.search.group", "re.search.group", "len", "directory.split", "re.search", "Exception", "re.search.group", "re.search.group", "re.search.group", "re.search", "re.search.group", "re.search", "re.search.group", "re.search.group", "re.search.group", "re.search.group"], "function", ["None"], ["", "def", "get_value", "(", "directory", ",", "l", ")", ":", "\n", "    ", "if", "len", "(", "l", ")", "==", "2", ":", "\n", "        ", "(", "param", ",", "name", ")", "=", "l", "\n", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "param", "+", "'([\\,\\._A-Za-z0-9\\+]+)'", "+", "'(-|$)'", ",", "directory", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "            ", "return", "name", "+", "m", ".", "group", "(", "2", ")", "\n", "", "return", "\"\"", "# \"param not found\"", "\n", "", "elif", "len", "(", "l", ")", "==", "3", ":", "\n", "        ", "(", "param", ",", "i", ",", "name", ")", "=", "l", "\n", "splits", "=", "directory", ".", "split", "(", "'/'", ")", "\n", "# pdb.set_trace()", "\n", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "param", "+", "'([\\,\\._A-Za-z0-9\\+]+)'", "+", "'(-|$)'", ",", "splits", "[", "i", "]", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "            ", "return", "name", "+", "m", ".", "group", "(", "2", ")", "\n", "", "return", "\"\"", "# \"param not found\"", "\n", "", "elif", "len", "(", "l", ")", "==", "4", ":", "\n", "        ", "(", "param", ",", "subparam", ",", "i", ",", "name", ")", "=", "l", "\n", "splits", "=", "directory", ".", "split", "(", "'/'", ")", "\n", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "param", "+", "'([\\,\\._A-Za-z0-9\\+]+)'", "+", "'(-|$)'", ",", "splits", "[", "i", "]", ")", "\n", "if", "subparam", "==", "\"\"", ":", "# in case you want just the param without the rest", "\n", "            ", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "                ", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "param", "+", "'([\\,\\.A-Za-z0-9\\+]+)'", "+", "'(_|$)'", ",", "splits", "[", "i", "]", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "                    ", "return", "name", "+", "m", ".", "group", "(", "2", ")", "\n", "", "", "", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "            ", "found", "=", "m", ".", "group", "(", "2", ")", "\n", "m", "=", "re", ".", "search", "(", "'(_)'", "+", "subparam", "+", "'([\\,\\.A-Za-z0-9\\+]+)'", "+", "'(_|$)'", ",", "found", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "                ", "return", "name", "+", "m", ".", "group", "(", "2", ")", "\n", "", "", "return", "\"\"", "# \"param not found\"", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"The length of the token should be 2 or 3\"", ")", "\n", "\n", "", "return", "\"param not found\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.get_feature": [[429, 431], ["re.search"], "function", ["None"], ["", "def", "get_feature", "(", "feature", ",", "directory", ")", ":", "\n", "    ", "return", "re", ".", "search", "(", "'(-|_|^)'", "+", "feature", "+", "'([\\,\\.A-Za-z0-9\\+]+)'", "+", "'(-|_|$)'", ",", "directory", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.WavSaver.WavSaver.__init__": [[12, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dirName", ",", "sample_rate", ")", ":", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "\n", "self", ".", "_sample_rate", "=", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.WavSaver.WavSaver.save_wav": [[16, 18], ["scipy.io.wavfile.write"], "methods", ["None"], ["", "def", "save_wav", "(", "self", ",", "wav_data", ",", "fileName", ")", ":", "\n", "        ", "wavfile", ".", "write", "(", "self", ".", "_dirName", "+", "'/'", "+", "fileName", "+", "'.wav'", ",", "self", ".", "_sample_rate", ",", "wav_data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Vgg_Bernoulli.__init__": [[21, 74], ["sonnet.AbstractModule.__init__", "len", "getter", "tensorflow.layers.dropout", "keras_models.keras_utils.get_renorm_clipping"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "\n", "filters", "=", "[", "16", ",", "16", ",", "32", ",", "32", ",", "32", "]", ",", "# [32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "name", "=", "\"vggB\"", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "drop_connect", "=", "False", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "bn_renormalization", "=", "True", ",", "\n", "aleatoric_layer", "=", "(", "\"MultivariateNormalDiag\"", ",", "{", "}", ")", ",", "\n", "**", "extra_params", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            num_outputs (type): number of outputs of the module.\n            name (type): module name.\n            activation (type): activation used for the internal layers.\n            **extra_params (type): alls the additional keyword arguments will be passed to the snt.Conv2D layers. (initializers, regularizers)\n\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "_hidden_channels", "=", "filters", "\n", "self", ".", "_strides", "=", "strides", "\n", "self", ".", "_kernel_shapes", "=", "kernels", "# All kernels are 3x3.", "\n", "self", ".", "_num_layers", "=", "len", "(", "self", ".", "_hidden_channels", ")", "\n", "self", ".", "_paddings", "=", "[", "snt", ".", "SAME", "]", "*", "self", ".", "_num_layers", "\n", "\n", "self", ".", "_prob_drop", "=", "prob_drop", "\n", "self", ".", "_drop_connect", "=", "drop_connect", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "self", ".", "_aleatoric_layer_tuple", "=", "aleatoric_layer", "\n", "self", ".", "_bn_renormalization", "=", "bn_renormalization", "\n", "# instantiate all the convolutional layers", "\n", "\n", "def", "custom_getter_dropconnect", "(", "getter", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "shape", "=", "kwargs", "[", "\"shape\"", "]", "\n", "theta", "=", "getter", "(", "name", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "theta_masked", "=", "tf", ".", "layers", ".", "dropout", "(", "theta", ",", "self", ".", "_prob_drop", ",", "training", "=", "True", ")", "\n", "\n", "return", "theta_masked", "\n", "\n", "# custom_getter = custom_getter_dropconnect if self._drop_connect else None", "\n", "", "self", ".", "_custom_getter", "=", "{", "\"w\"", ":", "custom_getter_dropconnect", "}", "if", "self", ".", "_drop_connect", "else", "None", "\n", "\n", "self", ".", "_bn_momentum", "=", "bn_momentum", "\n", "\n", "self", ".", "_renorm_clipping", "=", "None", "\n", "if", "self", ".", "_bn_renormalization", ":", "\n", "            ", "self", ".", "_renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Vgg_Bernoulli.maybe_dropout": [[75, 79], ["tensorflow.layers.dropout"], "methods", ["None"], ["", "", "def", "maybe_dropout", "(", "self", ",", "net", ")", ":", "\n", "        ", "if", "self", ".", "_drop_connect", "==", "False", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "self", ".", "_prob_drop", ",", "training", "=", "True", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Vgg_Bernoulli._build": [[80, 177], ["enumerate", "utils_modules.network_layer_builder", "utils_modules.Vgg_Bernoulli._distr_model", "sonnet.Conv2D", "sonnet.Conv2D", "zip", "layer_one", "utils_modules.Vgg_Bernoulli.maybe_dropout", "tensorflow.layers.batch_normalization", "utils_modules.Vgg_Bernoulli._activation", "layer_two", "utils_modules.Vgg_Bernoulli.maybe_dropout", "tensorflow.layers.batch_normalization", "utils_modules.Vgg_Bernoulli._activation", "tensorflow.layers.max_pooling2d", "sonnet.BatchFlatten", "range", "range"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.network_layer_builder", "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL.maybe_dropout", "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL.maybe_dropout"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (type): node of input.\n            is_training (type): tells to batchnorm if to generate the update ops.\n            test_local_stats (type): used to test local stats in batch norm.\n\n        Returns:\n            logits\n\n        \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "\n", "# self._custom_getter_layer = [self._custom_getter]*(self._num_layers)", "\n", "\n", "self", ".", "layers_one", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_1_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "i", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "#stride=self._strides[i],", "\n", "padding", "=", "self", ".", "_paddings", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "custom_getter", "=", "self", ".", "_custom_getter", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "\n", "self", ".", "layers_two", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_2_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "i", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "# stride=self._strides[i],", "\n", "padding", "=", "self", ".", "_paddings", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "custom_getter", "=", "self", ".", "_custom_getter", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "\n", "# connect them to the graph, adding batch norm and non-linearity", "\n", "for", "i", ",", "(", "layer_one", ",", "layer_two", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "layers_one", ",", "self", ".", "layers_two", ")", ")", ":", "\n", "\n", "# LAYER1", "\n", "            ", "net", "=", "layer_one", "(", "net", ")", "\n", "# bn = snt.BatchNorm(name=\"batch_norm_1_{}\".format(i))", "\n", "# net = bn(net, is_training=is_training, test_local_stats=test_local_stats)", "\n", "net", "=", "self", ".", "maybe_dropout", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_1_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "# LAYER1", "\n", "\n", "# LAYER2", "\n", "net", "=", "layer_two", "(", "net", ")", "\n", "# bn = snt.BatchNorm(name=\"batch_norm_2_{}\".format(i))", "\n", "# net = bn(net, is_training=is_training, test_local_stats=test_local_stats)", "\n", "net", "=", "self", ".", "maybe_dropout", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_2_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "net", ",", "pool_size", "=", "2", ",", "strides", "=", "self", ".", "_strides", "[", "i", "]", ",", "padding", "=", "\"VALID\"", ")", "\n", "# LAYER2", "\n", "\n", "", "net", "=", "snt", ".", "BatchFlatten", "(", "name", "=", "\"flatten\"", ")", "(", "net", ")", "\n", "\n", "# net = self.maybe_dropout(net)", "\n", "\n", "# if  self._drop_connect == False:", "\n", "#     net= tf.layers.dropout(net,self._prob_drop, training=True)", "\n", "\n", "name", ",", "kwargs", "=", "self", ".", "_aleatoric_layer_tuple", "\n", "aleatoric_kwargs", "=", "{", "\n", "**", "self", ".", "_extra_params", ",", "\n", "\"output_size\"", ":", "self", ".", "_output_size", ",", "\n", "\n", "\"custom_getter\"", ":", "None", "# self._custom_getter", "\n", "\n", "# no custom getter on the last layer", "\n", "# \"custom_getter\": self._custom_getter", "\n", "\n", "}", "\n", "\n", "self", ".", "_distr_model", "=", "network_layer_builder", "(", "name", ",", "aleatoric_kwargs", ")", "\n", "\n", "distr", "=", "self", ".", "_distr_model", "(", "net", ")", "\n", "\n", "return", "distr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Alex_Bernoulli.__init__": [[180, 230], ["sonnet.AbstractModule.__init__", "len", "getter", "tensorflow.layers.dropout"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "\n", "filters", "=", "[", "32", ",", "32", ",", "32", ",", "32", ",", "32", "]", ",", "#[64, 192,192,256,256],  # [32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "7", ",", "5", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "4", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "#strides=[2, 2, 2, 2, 2],", "\n", "name", "=", "\"AlexB\"", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "drop_connect", "=", "False", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_renormalization", "=", "False", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "aleatoric_layer", "=", "(", "\"MultivariateNormalDiag\"", ",", "{", "}", ")", ",", "\n", "**", "extra_params", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            num_outputs (type): number of outputs of the module.\n            name (type): module name.\n            activation (type): activation used for the internal layers.\n            **extra_params (type): alls the additional keyword arguments will be passed to the snt.Conv2D layers. (initializers, regularizers)\n\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "_hidden_channels", "=", "filters", "\n", "self", ".", "_strides", "=", "strides", "\n", "self", ".", "_kernel_shapes", "=", "kernels", "# All kernels are 3x3.", "\n", "self", ".", "_num_layers", "=", "len", "(", "self", ".", "_hidden_channels", ")", "\n", "self", ".", "_paddings", "=", "[", "snt", ".", "SAME", "]", "*", "self", ".", "_num_layers", "\n", "\n", "self", ".", "_prob_drop", "=", "prob_drop", "\n", "self", ".", "_drop_connect", "=", "drop_connect", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "self", ".", "_aleatoric_layer_tuple", "=", "aleatoric_layer", "\n", "# instantiate all the convolutional layers", "\n", "\n", "def", "custom_getter_dropconnect", "(", "getter", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "shape", "=", "kwargs", "[", "\"shape\"", "]", "\n", "theta", "=", "getter", "(", "name", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "theta_masked", "=", "tf", ".", "layers", ".", "dropout", "(", "theta", ",", "self", ".", "_prob_drop", ",", "training", "=", "True", ")", "*", "(", "1", "-", "self", ".", "_prob_drop", ")", "\n", "\n", "return", "theta_masked", "\n", "\n", "# custom_getter = custom_getter_dropconnect if self._drop_connect else None   ##\"b\" : custom_getter_dropconnect", "\n", "", "self", ".", "_custom_getter", "=", "{", "\"w\"", ":", "custom_getter_dropconnect", "}", "if", "self", ".", "_drop_connect", "else", "None", "\n", "\n", "self", ".", "_bn_renormalization", "=", "True", "\n", "self", ".", "_bn_momentum", "=", "bn_momentum", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Alex_Bernoulli.maybe_dropout": [[231, 235], ["tensorflow.layers.dropout"], "methods", ["None"], ["", "def", "maybe_dropout", "(", "self", ",", "net", ")", ":", "\n", "        ", "if", "self", ".", "_drop_connect", "==", "False", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "self", ".", "_prob_drop", ",", "training", "=", "True", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Alex_Bernoulli._build": [[236, 316], ["enumerate", "utils_modules.network_layer_builder", "network_layer_builder.", "sonnet.Conv2D", "layer_one", "utils_modules.Alex_Bernoulli.maybe_dropout", "utils_modules.Alex_Bernoulli._activation", "sonnet.Conv2D", "sonnet.BatchFlatten", "range", "tensorflow.layers.max_pooling2d"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.network_layer_builder", "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL.maybe_dropout"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (type): node of input.\n            is_training (type): tells to batchnorm if to generate the update ops.\n            test_local_stats (type): used to test local stats in batch norm.\n\n        Returns:\n            logits\n\n        \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "\n", "# self._custom_getter_layer = [self._custom_getter]*(self._num_layers)", "\n", "\n", "self", ".", "layers_one", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_1_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "i", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "#stride=self._strides[i],", "\n", "padding", "=", "self", ".", "_paddings", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "custom_getter", "=", "self", ".", "_custom_getter", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "\n", "\n", "# connect them to the graph, adding batch norm and non-linearity", "\n", "for", "i", ",", "layer_one", "in", "enumerate", "(", "self", ".", "layers_one", ")", ":", "\n", "\n", "# LAYER1", "\n", "            ", "net", "=", "layer_one", "(", "net", ")", "\n", "net", "=", "self", ".", "maybe_dropout", "(", "net", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "if", "i", "==", "0", "or", "i", "==", "1", "or", "i", "==", "4", ":", "\n", "                ", "net", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "net", ",", "pool_size", "=", "2", ",", "strides", "=", "self", ".", "_strides", "[", "i", "]", ",", "padding", "=", "\"SAME\"", ")", "\n", "\n", "\n", "# net=snt.Conv2D(name=\"conv_2d/l_1\",", "\n", "#                  output_channels=256,", "\n", "#                  kernel_shape=[2,2],", "\n", "#                  stride=1,", "\n", "#                  padding='VALID',", "\n", "#                  use_bias=True,", "\n", "#                  custom_getter= self._custom_getter,", "\n", "#                  **self._extra_params)(net)", "\n", "#", "\n", "# net = self.maybe_dropout(net)", "\n", "# net = self._activation(net)", "\n", "# net= snt.Conv2D(name=\"conv_2d/l_2\",", "\n", "#                      output_channels=256,", "\n", "#                      kernel_shape=[1,1],", "\n", "#                      stride=1,", "\n", "#                      padding='SAME',", "\n", "#                     use_bias=True,", "\n", "#                     custom_getter= self._custom_getter,", "\n", "#                     **self._extra_params)(net)", "\n", "#", "\n", "# net = self.maybe_dropout(net)", "\n", "# net = self._activation(net)", "\n", "", "", "net", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d/plain_layer_34\"", ",", "\n", "output_channels", "=", "32", ",", "\n", "kernel_shape", "=", "[", "1", ",", "1", "]", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", ")", "(", "net", ")", "\n", "net", "=", "snt", ".", "BatchFlatten", "(", "name", "=", "\"flatten\"", ")", "(", "net", ")", "\n", "name", ",", "kwargs", "=", "self", ".", "_aleatoric_layer_tuple", "\n", "aleatoric_kwargs", "=", "{", "\n", "**", "self", ".", "_extra_params", ",", "\n", "\"output_size\"", ":", "self", ".", "_output_size", ",", "\n", "\"custom_getter\"", ":", "None", "#self._custom_getter", "\n", "}", "\n", "\n", "aleatoric_module", "=", "network_layer_builder", "(", "name", ",", "aleatoric_kwargs", ")", "\n", "\n", "distr", "=", "aleatoric_module", "(", "net", ")", "\n", "\n", "return", "distr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL.__init__": [[375, 429], ["sonnet.AbstractModule.__init__", "len", "getter", "tensorflow.layers.dropout", "keras_models.keras_utils.get_renorm_clipping"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "\n", "filters", "=", "[", "16", ",", "16", ",", "32", ",", "32", ",", "32", "]", ",", "# [32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "name", "=", "\"vggB\"", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "drop_connect", "=", "False", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "bn_renormalization", "=", "True", ",", "\n", "aleatoric_layer", "=", "(", "\"MultivariateNormalDiag\"", ",", "{", "}", ")", ",", "\n", "**", "extra_params", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            num_outputs (type): number of outputs of the module.\n            name (type): module name.\n            activation (type): activation used for the internal layers.\n            **extra_params (type): alls the additional keyword arguments will be passed to the snt.Conv2D layers. (initializers, regularizers)\n\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "_hidden_channels", "=", "filters", "\n", "self", ".", "_strides", "=", "strides", "\n", "self", ".", "_kernel_shapes", "=", "kernels", "# All kernels are 3x3.", "\n", "self", ".", "_num_layers", "=", "len", "(", "self", ".", "_hidden_channels", ")", "\n", "self", ".", "_paddings", "=", "[", "snt", ".", "SAME", "]", "*", "self", ".", "_num_layers", "\n", "\n", "self", ".", "_prob_drop", "=", "prob_drop", "\n", "self", ".", "_drop_connect", "=", "drop_connect", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "self", ".", "_aleatoric_layer_tuple", "=", "aleatoric_layer", "\n", "self", ".", "_bn_renormalization", "=", "bn_renormalization", "\n", "# instantiate all the convolutional layers", "\n", "\n", "def", "custom_getter_dropconnect", "(", "getter", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "shape", "=", "kwargs", "[", "\"shape\"", "]", "\n", "theta", "=", "getter", "(", "name", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "theta_masked", "=", "tf", ".", "layers", ".", "dropout", "(", "theta", ",", "self", ".", "_prob_drop", ",", "training", "=", "True", ")", "\n", "\n", "return", "theta_masked", "\n", "\n", "# custom_getter = custom_getter_dropconnect if self._drop_connect else None", "\n", "", "self", ".", "_custom_getter", "=", "{", "\"w\"", ":", "custom_getter_dropconnect", "}", "if", "self", ".", "_drop_connect", "else", "None", "\n", "\n", "\n", "self", ".", "_bn_momentum", "=", "bn_momentum", "\n", "\n", "self", ".", "_renorm_clipping", "=", "None", "\n", "if", "self", ".", "_bn_renormalization", ":", "\n", "            ", "self", ".", "_renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL.maybe_dropout": [[430, 434], ["tensorflow.layers.dropout"], "methods", ["None"], ["", "", "def", "maybe_dropout", "(", "self", ",", "net", ")", ":", "\n", "        ", "if", "self", ".", "_drop_connect", "==", "False", ":", "\n", "            ", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "self", ".", "_prob_drop", ",", "training", "=", "True", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL._build": [[435, 585], ["tensorflow.layers.batch_normalization", "utils_modules.Network_WL._activation", "tensorflow.layers.batch_normalization", "utils_modules.Network_WL._activation", "tensorflow.layers.max_pooling2d", "tensorflow.layers.batch_normalization", "utils_modules.Network_WL._activation", "enumerate", "utils_modules.network_layer_builder", "utils_modules.Network_WL._distr_model", "sonnet.Conv2D", "sonnet.Conv2D", "sonnet.Conv2D", "sonnet.Conv2D", "sonnet.Conv2D", "zip", "layer_one", "utils_modules.Network_WL.maybe_dropout", "tensorflow.layers.batch_normalization", "utils_modules.Network_WL._activation", "layer_two", "utils_modules.Network_WL.maybe_dropout", "tensorflow.layers.batch_normalization", "utils_modules.Network_WL._activation", "tensorflow.layers.max_pooling2d", "sonnet.BatchFlatten", "range", "range"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.network_layer_builder", "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL.maybe_dropout", "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Network_WL.maybe_dropout"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (type): node of input.\n            is_training (type): tells to batchnorm if to generate the update ops.\n            test_local_stats (type): used to test local stats in batch norm.\n\n        Returns:\n            logits\n\n        \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "net", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d1\"", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "0", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "0", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", ")", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_1\"", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "net", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d2\"", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "0", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "0", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", ")", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_2\"", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "net", ",", "pool_size", "=", "2", ",", "strides", "=", "self", ".", "_strides", "[", "0", "]", ",", "padding", "=", "\"VALID\"", ")", "\n", "net", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_3\"", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "0", "]", "*", "2", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "0", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", ")", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_2\"", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "# self._custom_getter_layer = [self._custom_getter]*(self._num_layers)", "\n", "\n", "self", ".", "layers_one", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_1_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "i", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "#stride=self._strides[i],", "\n", "padding", "=", "self", ".", "_paddings", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "custom_getter", "=", "self", ".", "_custom_getter", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "\n", "self", ".", "layers_two", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_2_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "i", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "# stride=self._strides[i],", "\n", "padding", "=", "self", ".", "_paddings", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "custom_getter", "=", "self", ".", "_custom_getter", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "\n", "# connect them to the graph, adding batch norm and non-linearity", "\n", "for", "i", ",", "(", "layer_one", ",", "layer_two", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "layers_one", ",", "self", ".", "layers_two", ")", ")", ":", "\n", "\n", "# LAYER1", "\n", "            ", "net", "=", "layer_one", "(", "net", ")", "\n", "# bn = snt.BatchNorm(name=\"batch_norm_1_{}\".format(i))", "\n", "# net = bn(net, is_training=is_training, test_local_stats=test_local_stats)", "\n", "net", "=", "self", ".", "maybe_dropout", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_1_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "# LAYER1", "\n", "\n", "# LAYER2", "\n", "net", "=", "layer_two", "(", "net", ")", "\n", "# bn = snt.BatchNorm(name=\"batch_norm_2_{}\".format(i))", "\n", "# net = bn(net, is_training=is_training, test_local_stats=test_local_stats)", "\n", "net", "=", "self", ".", "maybe_dropout", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_2_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "net", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "net", ",", "pool_size", "=", "2", ",", "strides", "=", "self", ".", "_strides", "[", "i", "]", ",", "padding", "=", "\"VALID\"", ")", "\n", "# LAYER2", "\n", "\n", "", "net", "=", "snt", ".", "BatchFlatten", "(", "name", "=", "\"flatten\"", ")", "(", "net", ")", "\n", "\n", "# net = self.maybe_dropout(net)", "\n", "\n", "# if  self._drop_connect == False:", "\n", "#     net= tf.layers.dropout(net,self._prob_drop, training=True)", "\n", "\n", "name", ",", "kwargs", "=", "self", ".", "_aleatoric_layer_tuple", "\n", "aleatoric_kwargs", "=", "{", "\n", "**", "self", ".", "_extra_params", ",", "\n", "\"output_size\"", ":", "self", ".", "_output_size", ",", "\n", "\n", "\"custom_getter\"", ":", "None", "# self._custom_getter", "\n", "\n", "# no custom getter on the last layer", "\n", "# \"custom_getter\": self._custom_getter", "\n", "\n", "}", "\n", "\n", "self", ".", "_distr_model", "=", "network_layer_builder", "(", "name", ",", "aleatoric_kwargs", ")", "\n", "\n", "distr", "=", "self", ".", "_distr_model", "(", "net", ")", "\n", "\n", "return", "distr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Vgg16.__init__": [[590, 612], ["sonnet.AbstractModule.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["  ", "def", "__init__", "(", "self", ",", "output_size", ",", "name", "=", "\"vgg16\"", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "**", "extra_params", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        num_outputs (type): number of outputs of the module.\n        name (type): module name.\n        activation (type): activation used for the internal layers.\n        **extra_params (type): alls the additional keyword arguments will be passed to the snt.Conv2D layers.\n\n    \"\"\"", "\n", "super", "(", "Vgg16", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "_hidden_channels", "=", "[", "\n", "64", ",", "64", ",", "128", ",", "128", ",", "128", ",", "256", ",", "256", ",", "256", ",", "512", ",", "512", ",", "512", "\n", "]", "\n", "self", ".", "_num_layers", "=", "len", "(", "self", ".", "_hidden_channels", ")", "\n", "\n", "self", ".", "_kernel_shapes", "=", "[", "[", "3", ",", "3", "]", "]", "*", "self", ".", "_num_layers", "# All kernels are 3x3.", "\n", "self", ".", "_strides", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "1", ",", "2", ",", "1", ",", "1", ",", "2", ",", "1", ",", "1", "]", "\n", "self", ".", "_paddings", "=", "[", "snt", ".", "SAME", "]", "*", "self", ".", "_num_layers", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Vgg16._build": [[613, 647], ["enumerate", "sonnet.Conv2D", "layer", "sonnet.BatchNorm", "sonnet.BatchNorm.", "utils_modules.Vgg16._activation", "sonnet.BatchFlatten", "sonnet.Linear", "range"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        inputs (type): node of input.\n        is_training (type): tells to batchnorm if to generate the update ops.\n        test_local_stats (type): used to test local stats in batch norm.\n\n    Returns:\n        logits\n\n    \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "# instantiate all the convolutional layers", "\n", "self", ".", "layers", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "i", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "stride", "=", "self", ".", "_strides", "[", "i", "]", ",", "\n", "padding", "=", "self", ".", "_paddings", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "# connect them to the graph, adding batch norm and non-linearity", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "      ", "net", "=", "layer", "(", "net", ")", "\n", "bn", "=", "snt", ".", "BatchNorm", "(", "name", "=", "\"batch_norm_{}\"", ".", "format", "(", "i", ")", ")", "\n", "net", "=", "bn", "(", "net", ",", "is_training", "=", "is_training", ",", "test_local_stats", "=", "test_local_stats", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "", "net", "=", "snt", ".", "BatchFlatten", "(", "name", "=", "\"flatten\"", ")", "(", "net", ")", "\n", "\n", "logits", "=", "snt", ".", "Linear", "(", "self", ".", "_output_size", ")", "(", "net", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Vgg19.__init__": [[651, 671], ["utils_modules.Vgg16.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["  ", "def", "__init__", "(", "self", ",", "num_outputs", ",", "name", "=", "\"vgg19\"", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "**", "extra_params", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        num_outputs (type): number of outputs of the module.\n        name (type): module name.\n        activation (type): activation used for the internal layers.\n        **extra_params (type): alls the additional keyword arguments will be passed to the snt.Conv2D layers.\n    \"\"\"", "\n", "super", "(", "Vgg19", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_output_size", "=", "num_outputs", "\n", "self", ".", "_kernel_shapes", "=", "[", "[", "3", ",", "3", "]", "]", "*", "self", ".", "_num_layers", "# All kernels are 3x3.", "\n", "self", ".", "_hidden_channels", "=", "[", "\n", "64", ",", "64", ",", "128", ",", "128", ",", "128", ",", "128", ",", "256", ",", "256", ",", "256", ",", "256", ",", "512", ",", "512", ",", "512", ",", "512", "\n", "]", "\n", "self", ".", "_num_layers", "=", "len", "(", "self", ".", "_hidden_channels", ")", "\n", "self", ".", "_strides", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "1", ",", "1", ",", "2", ",", "1", ",", "1", ",", "1", ",", "2", ",", "1", ",", "1", ",", "1", "]", "\n", "self", ".", "_paddings", "=", "[", "snt", ".", "SAME", "]", "*", "self", ".", "_num_layers", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.ResUnit.__init__": [[675, 696], ["sonnet.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["  ", "def", "__init__", "(", "self", ",", "depth", ",", "name", "=", "\"resUnit\"", ",", "kernel_shape", "=", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "**", "extra_params", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        depth (int): the depth of the resUnit.\n        name (str): module name.\n        kernel_shape (int or [int,int]): the kernel size\n        stride (int): the stride\n        activation (tf function): activation used for the internal layers.\n        **extra_params: all the additional keyword arguments will be passed to snt.Conv2D layers.\n    \"\"\"", "\n", "super", "(", "ResUnit", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_depth", "=", "depth", "\n", "self", ".", "_num_layers", "=", "2", "\n", "self", ".", "_kernel_shapes", "=", "[", "kernel_shape", "]", "*", "2", "\n", "self", ".", "_strides", "=", "[", "stride", ",", "1", "]", "\n", "self", ".", "_padding", "=", "snt", ".", "SAME", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "self", ".", "_downsample_input", "=", "False", "\n", "if", "stride", "!=", "1", ":", "\n", "        ", "self", ".", "_downsample_input", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.ResUnit._build": [[697, 744], ["enumerate", "ValueError", "sonnet.Conv2D", "sonnet.BatchNorm", "sonnet.BatchNorm.", "utils_modules.ResUnit._activation", "layer", "range", "sonnet.Conv2D"], "methods", ["None"], ["", "", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        inputs (type): node of input.\n        is_training (type): tells to batchnorm if to generate the update ops.\n        test_local_stats (type): used to test local stats in batch norm.\n\n    Returns:\n        logits\n    \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "if", "inputs", ".", "shape", "[", "1", "]", "!=", "inputs", ".", "shape", "[", "2", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"ResUnit expects a square image\"", ")", "\n", "\n", "", "img_dim", "=", "inputs", ".", "shape", "[", "2", "]", "\n", "img_channels", "=", "inputs", ".", "shape", "[", "3", "]", "\n", "\n", "# instantiate all the convolutional layers", "\n", "self", ".", "layers", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_depth", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "stride", "=", "self", ".", "_strides", "[", "i", "]", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "# connect them to the graph, adding batch norm and non-linearity", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "      ", "bn", "=", "snt", ".", "BatchNorm", "(", "name", "=", "\"batch_norm_{}\"", ".", "format", "(", "i", ")", ")", "\n", "net", "=", "bn", "(", "net", ",", "is_training", "=", "is_training", ",", "test_local_stats", "=", "test_local_stats", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "net", "=", "layer", "(", "net", ")", "\n", "\n", "", "inputstoadd", "=", "inputs", "\n", "if", "self", ".", "_downsample_input", ":", "\n", "        ", "inputstoadd", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_fix\"", ",", "\n", "output_channels", "=", "self", ".", "_depth", ",", "\n", "kernel_shape", "=", "[", "1", ",", "1", "]", ",", "\n", "stride", "=", "self", ".", "_strides", "[", "0", "]", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "(", "inputs", ")", "\n", "\n", "", "logits", "=", "net", "+", "inputstoadd", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Res18.__init__": [[748, 778], ["sonnet.AbstractModule.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["  ", "def", "__init__", "(", "self", ",", "num_outputs", ",", "name", "=", "\"res18\"", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "**", "extra_params", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        num_outputs (int): the number of outputs of the module.\n        name (str): module name.\n        activation (tf function): activation used for the internal layers.\n        **extra_params: all the additional keyword arguments will be passed to all the snt.Conv2D and to the ResUnit layers.\n\n    \"\"\"", "\n", "super", "(", "Res18", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_output_size", "=", "num_outputs", "\n", "\n", "self", ".", "_conv_channels", "=", "64", "\n", "self", ".", "_conv_kernel_shape", "=", "[", "7", ",", "7", "]", "\n", "self", ".", "_conv_stride", "=", "2", "\n", "\n", "self", ".", "_pooling_kernel_shape", "=", "[", "2", ",", "2", "]", "\n", "self", ".", "_pooling_stride", "=", "2", "\n", "\n", "self", ".", "_resunit_channels", "=", "[", "\n", "64", ",", "64", ",", "128", ",", "128", ",", "256", ",", "256", ",", "512", ",", "512", "\n", "]", "\n", "self", ".", "_num_resunits", "=", "len", "(", "self", ".", "_resunit_channels", ")", "\n", "# first kernel 7x7 all the rest 3x3.", "\n", "self", ".", "_resunit_kernel_shapes", "=", "[", "[", "3", ",", "3", "]", "]", "*", "self", ".", "_num_resunits", "\n", "self", ".", "_resunit_strides", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "2", ",", "1", ",", "2", ",", "1", "]", "\n", "\n", "self", ".", "_padding", "=", "snt", ".", "SAME", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.Res18._build": [[780, 835], ["range", "tensorflow.layers.max_pooling2d", "enumerate", "tensorflow.layers.average_pooling2d", "sonnet.Conv2D", "utils_modules.Res18.layers.append", "resunit", "sonnet.BatchFlatten", "sonnet.Linear", "utils_modules.ResUnit"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        inputs (type): node of input.\n        is_training (type): tells to batchnorm if to generate the update ops.\n        test_local_stats (type): used to test local stats in batch norm.\n\n    Returns:\n        logits\n\n    \"\"\"", "\n", "# instantiate all the convolutional layers", "\n", "self", ".", "layers", "=", "[", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d\"", ",", "\n", "output_channels", "=", "self", ".", "_conv_channels", ",", "\n", "kernel_shape", "=", "self", ".", "_conv_kernel_shape", ",", "\n", "stride", "=", "self", ".", "_conv_stride", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", ")", "]", "\n", "#(self, depth, name=\"resUnit\", kernel_shape=[3,3], stride=1, activation=tf.nn.relu, **extra_params)", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_resunits", ")", ":", "\n", "        ", "self", ".", "layers", ".", "append", "(", "ResUnit", "(", "\n", "depth", "=", "self", ".", "_resunit_channels", "[", "i", "]", ",", "\n", "name", "=", "\"resunit{}\"", ".", "format", "(", "i", ")", ",", "\n", "kernel_shape", "=", "self", ".", "_resunit_kernel_shapes", "[", "i", "]", ",", "\n", "stride", "=", "self", ".", "_resunit_strides", "[", "i", "]", ",", "\n", "activation", "=", "self", ".", "_activation", ",", "\n", "**", "self", ".", "_extra_params", ")", ")", "\n", "\n", "", "net", "=", "self", ".", "layers", "[", "0", "]", "(", "inputs", ")", "\n", "net", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "\n", "net", ",", "\n", "self", ".", "_pooling_kernel_shape", ",", "\n", "self", ".", "_pooling_stride", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "data_format", "=", "'channels_last'", ",", "\n", "name", "=", "\"max_pooling2d\"", "\n", ")", "\n", "\n", "for", "i", ",", "resunit", "in", "enumerate", "(", "self", ".", "layers", "[", "1", ":", "]", ")", ":", "\n", "        ", "net", "=", "resunit", "(", "net", ")", "\n", "\n", "", "net", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "\n", "net", ",", "\n", "self", ".", "_pooling_kernel_shape", ",", "\n", "self", ".", "_pooling_stride", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "data_format", "=", "'channels_last'", ",", "\n", "name", "=", "\"avg_pooling2d\"", "\n", ")", "\n", "\n", "net", "=", "snt", ".", "BatchFlatten", "(", "name", "=", "\"flatten\"", ")", "(", "net", ")", "\n", "logits", "=", "snt", ".", "Linear", "(", "self", ".", "_output_size", ")", "(", "net", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.network_layer_builder": [[7, 17], ["importlib.import_module", "getattr", "getattr.", "__name__.split"], "function", ["None"], ["def", "network_layer_builder", "(", "module_name", ",", "module_kwargs", ")", ":", "\n", "# load the module specified", "\n", "    ", "pymodule", "=", "importlib", ".", "import_module", "(", "\"..network.\"", "+", "module_name", ",", "\n", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "module_class", "=", "getattr", "(", "pymodule", ",", "module_name", ")", "\n", "\n", "module", "=", "module_class", "(", "**", "module_kwargs", ")", "\n", "\n", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.get_network_module_id": [[846, 884], ["str", "str", "str", "str", "utils_modules.get_network_module_id", "int", "int", "str", "str", "utils_modules.get_network_module_id", "print", "print", "ValueError", "bool", "bool", "int", "str", "bool"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.get_network_module_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.utils_modules.get_network_module_id"], ["def", "get_network_module_id", "(", "method_tuple", ")", ":", "\n", "    ", "\"\"\"Creates the id for a network module.\n\n    Args:\n        method_tuple (tuple): A tuple composed of : (name of the keras model builder function, kwargs to pass to the function).\n\n    Returns:\n        string: the idname of the keras network that we want to concatenate in the output filenames.\n\n    \"\"\"", "\n", "\n", "# listWithPoints = lambda x: \".\".join(re.sub('[( )\\[\\]]', '', str(x)).replace(' ', '').split(\",\"))", "\n", "\n", "method_name", "=", "method_tuple", "[", "0", "]", "\n", "method_kwargs", "=", "method_tuple", "[", "1", "]", "\n", "\n", "methodid", "=", "name_short", "[", "method_name", "]", "\n", "\n", "if", "method_name", "==", "'Vgg_Bernoulli'", ":", "\n", "        ", "methodid", "+=", "\"_dc\"", "+", "str", "(", "int", "(", "bool", "(", "method_kwargs", "[", "\"drop_connect\"", "]", ")", ")", ")", "\n", "methodid", "+=", "\"_dr\"", "+", "str", "(", "method_kwargs", "[", "\"prob_drop\"", "]", ")", "\n", "methodid", "+=", "\"_bnm\"", "+", "str", "(", "method_kwargs", "[", "\"bn_momentum\"", "]", ")", "\n", "methodid", "+=", "\"_bnr\"", "+", "str", "(", "int", "(", "bool", "(", "method_kwargs", "[", "\"bn_renormalization\"", "]", ")", ")", ")", "\n", "methodid", "+=", "\"_\"", "+", "get_network_module_id", "(", "method_kwargs", "[", "\"aleatoric_layer\"", "]", ")", "\n", "", "elif", "method_name", "==", "'Alex_Bernoulli'", ":", "\n", "        ", "methodid", "+=", "\"_dc\"", "+", "str", "(", "int", "(", "bool", "(", "method_kwargs", "[", "\"drop_connect\"", "]", ")", ")", ")", "\n", "methodid", "+=", "\"_dr\"", "+", "str", "(", "method_kwargs", "[", "\"prob_drop\"", "]", ")", "\n", "methodid", "+=", "\"_\"", "+", "get_network_module_id", "(", "method_kwargs", "[", "\"aleatoric_layer\"", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'MultivariateNormalDiag'", "or", "method_name", "==", "'MultivariateNormalTriL'", ":", "\n", "        ", "methodid", "+=", "\"_mc\"", "+", "str", "(", "method_kwargs", "[", "\"minimal_covariance\"", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'----------------------'", ")", "\n", "print", "(", "'ERROR '", ",", "method_name", ")", "\n", "raise", "ValueError", "(", "\"id rule for keras network `%s` has to be implemented.\"", "%", "method_name", ")", "\n", "\n", "", "return", "methodid", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.distances.euclidean": [[4, 6], ["tensorflow.norm"], "function", ["None"], ["def", "euclidean", "(", "h1", ",", "h2", ")", ":", "\n", "    ", "return", "tf", ".", "norm", "(", "h1", "-", "h2", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.distances.wasserstein": [[8, 13], ["tensorflow.sqrt", "tensorflow.square", "tensorflow.square", "tensorflow.norm", "tensorflow.norm"], "function", ["None"], ["", "def", "wasserstein", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "mu1", ",", "sigma1", "=", "params1", "\n", "mu2", ",", "sigma2", "=", "params2", "\n", "wd", "=", "tf", ".", "sqrt", "(", "tf", ".", "square", "(", "tf", ".", "norm", "(", "mu1", "-", "mu2", ",", "axis", "=", "1", ")", ")", "+", "tf", ".", "square", "(", "tf", ".", "norm", "(", "sigma1", "-", "sigma2", ",", "axis", "=", "1", ")", ")", ")", "\n", "return", "wd", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.distances.fisher": [[16, 24], ["tensorflow.reduce_sum", "tensorflow.sqrt", "tensorflow.sqrt"], "function", ["None"], ["", "def", "fisher", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "mu1", ",", "sigma1", "=", "params1", "\n", "mu2", ",", "sigma2", "=", "params2", "\n", "fisher_dist", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "sqrt", "(", "2.", ")", "*", "(", "tf", ".", "sqrt", "(", "\n", "(", "(", "mu1", "-", "mu2", ")", "**", "2", "+", "2", "*", "(", "sigma1", "-", "sigma2", ")", "**", "2", ")", "*", "(", "(", "mu1", "-", "mu2", ")", "**", "2", "+", "2", "*", "(", "sigma1", "+", "sigma2", ")", "**", "2", ")", ")", "+", "(", "\n", "mu1", "-", "mu2", ")", "**", "2", "+", "2", "*", "(", "sigma1", "**", "2", "-", "sigma2", "**", "2", ")", ")", "/", "(", "\n", "4", "*", "sigma1", "*", "sigma2", ")", ",", "axis", "=", "1", ")", "\n", "return", "fisher_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.distances.kl": [[28, 34], ["tensorflow.reduce_sum", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "kl", "(", "params1", ",", "params2", ")", ":", "\n", "    ", "mu1", ",", "sigma1", "=", "params1", "\n", "mu2", ",", "sigma2", "=", "params2", "\n", "kl_div", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "log", "(", "sigma1", "/", "sigma2", ")", "+", "(", "sigma2", "**", "2", "+", "(", "mu2", "-", "mu1", ")", "**", "2", ")", "/", "(", "2", "*", "sigma1", "**", "2", ")", "-", "1", "/", "2", ",", "\n", "axis", "=", "1", ")", "\n", "return", "kl_div", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.__init__": [[17, 19], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.suptitle": [[20, 22], ["None"], "methods", ["None"], ["", "def", "suptitle", "(", "self", ",", "fig", ",", "title", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.create_fig": [[23, 28], ["matplotlib.figure", "matplotlib.figure", "matplotlib.figure", "len"], "methods", ["None"], ["", "def", "create_fig", "(", "self", ",", "figsize", ",", "folders_cartesian_fixed", ")", ":", "\n", "        ", "w", ",", "h", "=", "figsize", "\n", "size", "=", "(", "w", ",", "h", "*", "len", "(", "folders_cartesian_fixed", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "size", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.rows_columns": [[29, 33], ["len", "len"], "methods", ["None"], ["", "def", "rows_columns", "(", "self", ",", "panels", ",", "folders_cartesian_fixed", ")", ":", "\n", "        ", "n_columns", "=", "len", "(", "panels", ")", "\n", "n_rows", "=", "len", "(", "folders_cartesian_fixed", ")", "\n", "return", "n_rows", ",", "n_columns", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.plot_vertical_panel": [[34, 122], ["PlotImages.PlotImages.get_colors_pairs", "len", "len", "sorted", "argo.core.utils.argo_utils.create_list_colors", "matplotlib.imread", "matplotlib.imread", "matplotlib.imread", "range", "numpy.concatenate", "fig.add_subplot", "fig.add_subplot.imshow", "fig.add_subplot.set_title", "fig.add_subplot.get_xaxis().set_visible", "fig.add_subplot.get_yaxis().set_visible", "len", "len", "len", "range", "print", "portion_imgs.append", "directory.split", "fig.add_subplot.get_xaxis", "fig.add_subplot.get_yaxis", "list", "str", "group_by_values.values"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.get_colors_pairs", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_list_colors"], ["", "def", "plot_vertical_panel", "(", "self", ",", "\n", "vertical_panels", ",", "\n", "c", ",", "\n", "n_rows", ",", "\n", "n_columns", ",", "\n", "legend", ",", "\n", "fig", ",", "\n", "folders_cartesian_fixed", ",", "\n", "group_by_values", ",", "\n", "source", ",", "\n", "degree", ")", ":", "\n", "\n", "# only one vertical panel allowed", "\n", "        ", "assert", "(", "len", "(", "vertical_panels", ")", "==", "1", ")", "\n", "panel", "=", "vertical_panels", "[", "0", "]", "\n", "assert", "(", "len", "(", "panel", ")", "==", "1", ")", "\n", "panel", "=", "panel", "[", "0", "]", "\n", "\n", "r", "=", "0", "\n", "\n", "#for panel in vertical_panels:", "\n", "#for curve in panel:", "\n", "for", "marker", ",", "color", ",", "directory", "in", "self", ".", "get_colors_pairs", "(", "sorted", "(", "folders_cartesian_fixed", ")", ",", "\n", "group_by_values", ")", ":", "\n", "\n", "            ", "try", ":", "\n", "\n", "                ", "if", "len", "(", "group_by_values", ")", "==", "0", ":", "\n", "                    ", "max_colors", "=", "len", "(", "folders_cartesian_fixed", ")", "\n", "", "else", ":", "\n", "                    ", "max_colors", "=", "len", "(", "list", "(", "group_by_values", ".", "values", "(", ")", ")", "[", "0", "]", ")", "\n", "\n", "", "if", "max_colors", "==", "0", ":", "\n", "                    ", "max_colors", "=", "1", "\n", "", "list_colors", "=", "create_list_colors", "(", "max_colors", ")", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "# file_path = source  + \"/\" + directory + \"/\" + curve[\"filename\"]", "\n", "file_path", "=", "directory", "+", "\"/\"", "+", "panel", "[", "\"filename\"", "]", "\n", "\n", "#label = self.create_label(curve, directory, legend, source)", "\n", "#self.create_plot(marker, color, curve, ax, degree, label, list_colors, x, y)", "\n", "img", "=", "mpimg", ".", "imread", "(", "file_path", ")", "\n", "\n", "width", "=", "77", "\n", "height", "=", "77", "\n", "margin_x", "=", "125", "\n", "margin_y", "=", "72", "\n", "\n", "num_cols_images", "=", "6", "# height", "\n", "num_rows_images", "=", "4", "# width", "\n", "portion_imgs", "=", "[", "]", "#[None] * num_cols * num_rows", "\n", "for", "s", "in", "range", "(", "num_rows_images", ")", ":", "\n", "                    ", "for", "t", "in", "range", "(", "num_cols_images", ")", ":", "\n", "                        ", "im", "=", "img", "[", "(", "margin_y", "+", "t", "*", "height", ")", ":", "(", "margin_y", "+", "(", "t", "+", "1", ")", "*", "height", ")", ",", "(", "margin_x", "+", "s", "*", "width", ")", ":", "(", "margin_x", "+", "(", "s", "+", "1", ")", "*", "width", ")", "]", "\n", "portion_imgs", ".", "append", "(", "im", ")", "\n", "\n", "", "", "new_img", "=", "np", ".", "concatenate", "(", "portion_imgs", ",", "axis", "=", "1", ")", "\n", "\n", "#n_plots = len(panels)", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "n_rows", ",", "n_columns", ",", "r", "*", "n_columns", "+", "c", "+", "1", ")", "\n", "ax", ".", "imshow", "(", "new_img", ")", "\n", "\n", "#if r==0:", "\n", "#    ax.set_title(directory.split(\"/\")[-1], loc='left', pad=20)", "\n", "#else:", "\n", "ax", ".", "set_title", "(", "directory", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ",", "loc", "=", "'left'", ",", "pad", "=", "0", ")", "\n", "ax", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "\n", "r", "+=", "1", "\n", "\n", "", "except", "FileNotFoundError", "as", "e", ":", "\n", "                ", "print", "(", "\"FileNotFoundError cannot read file \"", "+", "file_path", "+", "\" \"", "+", "str", "(", "e", ")", ")", "\n", "\n", "\n", "", "'''\n            # Options for legend_loc\n            # 'best', 'upper right', 'upper left', 'lower left', 'lower right',\n            # 'right', 'center left', 'center right', 'lower center', 'upper center', 'center'\n            loc = panel.get(\"legend_loc\", \"upper right\")\n            bbox_to_anchor = curve.get(\"bbox_to_anchor\", None)\n            if bbox_to_anchor is None:\n                lgd = ax.legend(loc=loc)\n            else:\n                lgd = ax.legend(loc=loc, bbox_to_anchor=bbox_to_anchor)\n            '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.__init__": [[15, 32], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dirName", ",", "pm", "=", "True", ")", ":", "\n", "#super(ImagesGenerator, self).__init__(dirName, fileName, period_log, verbose)", "\n", "\n", "#self._n_images_columns = n_images_columns", "\n", "#self._n_images_rows = n_images_rows", "\n", "#self._color = 0", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "\n", "\n", "self", ".", "_image_width", "=", "-", "1", "\n", "self", ".", "_image_height", "=", "-", "1", "\n", "self", ".", "_channels", "=", "-", "1", "\n", "self", ".", "_pm", "=", "pm", "\n", "if", "self", ".", "_pm", ":", "\n", "            ", "self", ".", "_vmin", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "_vmin", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.image_shape": [[42, 47], ["None"], "methods", ["None"], ["", "@", "image_shape", ".", "setter", "\n", "def", "image_shape", "(", "self", ",", "shape", ")", ":", "\n", "        ", "self", ".", "_image_width", "=", "shape", "[", "0", "]", "\n", "self", ".", "_image_height", "=", "shape", "[", "1", "]", "\n", "self", ".", "_channel", "=", "shape", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images": [[48, 124], ["len", "len", "matplotlib.figure", "matplotlib.figure", "matplotlib.figure", "matplotlib.axis", "matplotlib.axis", "matplotlib.axis", "matplotlib.title", "matplotlib.title", "matplotlib.title", "range", "matplotlib.subplots_adjust", "matplotlib.subplots_adjust", "matplotlib.subplots_adjust", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.close", "matplotlib.close", "matplotlib.close", "len", "range", "len", "matplotlib.figure.add_subplot", "plt.figure.add_subplot.get_xaxis().set_visible", "plt.figure.add_subplot.get_yaxis().set_visible", "numpy.squeeze", "plt.figure.add_subplot.imshow", "len", "len", "numpy.clip", "plt.figure.add_subplot.imshow", "Exception", "plt.figure.add_subplot.get_xaxis", "plt.figure.add_subplot.get_yaxis"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], ["", "def", "save_images", "(", "self", ",", "panel", ",", "fileName", ",", "title", "=", "\"\"", ",", "fontsize", "=", "9", ")", ":", "\n", "        ", "'''\n        if width is None or height is None:\n            width = self._n_images_columns\n            height = self._n_images_rows\n        else:\n            assert(width>1)\n            assert(height>1)\n            width = int(width)\n            height = int(height)\n\n        if self._image_width<0 or self._image_height<0:\n            raise Exception(\"Image shape not set\")\n        '''", "\n", "\n", "height", "=", "len", "(", "panel", ")", "\n", "width", "=", "len", "(", "panel", "[", "0", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "width", ",", "height", ")", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "#gs1 = gridspec.GridSpec(width, height)", "\n", "#gs1.update(wspace=0.05, hspace=0.05)", "\n", "\n", "plt", ".", "title", "(", "title", ",", "fontsize", "=", "fontsize", ",", "loc", "=", "'center'", ")", "\n", "\n", "k", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "panel", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "panel", "[", "i", "]", ")", ")", ":", "\n", "                ", "ax0", "=", "fig", ".", "add_subplot", "(", "height", ",", "width", ",", "k", "+", "1", ")", "\n", "\n", "# maybe this can be merged to avoid the if, in case shapes are correct", "\n", "# to be checked", "\n", "if", "panel", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "\n", "#squeeze does not do anything if dimension 2 is not 1, compatible with RGB", "\n", "                    ", "img", "=", "np", ".", "squeeze", "(", "panel", "[", "i", "]", "[", "j", "]", ",", "axis", "=", "2", ")", "\n", "\n", "#from the doc: cmap=\"gray\" is ignored for RGB data", "\n", "ax0", ".", "imshow", "(", "img", ",", "cmap", "=", "\"gray\"", ",", "vmin", "=", "self", ".", "_vmin", ",", "vmax", "=", "1", ")", "\n", "\n", "", "elif", "panel", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "==", "3", ":", "\n", "#im_r = panel[i][j][:,:,0]", "\n", "#im_g = panel[i][j][:,:,1]", "\n", "#im_b = panel[i][j][:,:,2]", "\n", "#img = np.dstack((im_r, im_g, im_b))", "\n", "\n", "# vmin and vmax, seems to be ignored in the RGB case, for safety,", "\n", "# we rescale between 0 and 1 which is imshow default and let it deal with it", "\n", "                    ", "img", "=", "(", "panel", "[", "i", "]", "[", "j", "]", "+", "1", ")", "/", "2", "\n", "\n", "# I clip inside 0 and 1 in case the algorithm is not clipping the noise", "\n", "img", "=", "np", ".", "clip", "(", "img", ",", "0", ",", "1", ")", "\n", "\n", "ax0", ".", "imshow", "(", "img", ")", "\n", "# img = panel[i][j]", "\n", "# ax0.imshow(img, vmin=-1, vmax=1)", "\n", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "\"Expected number of channels is 1 or 3\"", ")", "\n", "\n", "#ax0.set_axis_off()", "\n", "#ax0.set_adjustable('box-forced')", "\n", "#ax0.set_xticks([])", "\n", "#ax0.set_xticks([])", "\n", "", "ax0", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "ax0", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "k", "=", "k", "+", "1", "\n", "", "k", "=", "k", "+", "(", "len", "(", "panel", "[", "0", "]", ")", "-", "len", "(", "panel", "[", "i", "]", ")", ")", "\n", "\n", "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplots_adjust.html", "\n", "# eft=0, bottom=0, right=1, top=1,", "\n", "", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0", ",", "hspace", "=", "0", ")", "\n", "#plt.tight_layout() #pad=-12, w_pad=0, h_pad=0.5)  # h_pad=Y", "\n", "\n", "plt", ".", "savefig", "(", "self", ".", "_dirName", "+", "'/'", "+", "fileName", "+", "'.png'", ")", "# , bbox_inches='tight'", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_panels_lists": [[31, 54], ["nodes_to_log.append", "names_of_nodes_to_log.append", "filenames_to_log_to.append", "isinstance", "isinstance", "isinstance", "nodes_vpanel.append", "names_vpanel.append", "files_vpanel.append"], "function", ["None"], ["def", "create_panels_lists", "(", "list_of_vpanels_of_plots", ")", ":", "\n", "    ", "nodes_to_log", "=", "[", "]", "\n", "names_of_nodes_to_log", "=", "[", "]", "\n", "filenames_to_log_to", "=", "[", "]", "\n", "\n", "for", "vpanel", "in", "list_of_vpanels_of_plots", ":", "\n", "        ", "nodes_vpanel", "=", "[", "]", "\n", "names_vpanel", "=", "[", "]", "\n", "files_vpanel", "=", "[", "]", "\n", "for", "plot", "in", "vpanel", ":", "\n", "            ", "assert", "isinstance", "(", "plot", "[", "\"nodes\"", "]", ",", "list", ")", ",", "\"`nodes` in a plot dictionary must be a list\"", "\n", "assert", "isinstance", "(", "plot", "[", "\"names\"", "]", ",", "list", ")", ",", "\"`names` in a plot dictionary must be a list\"", "\n", "assert", "isinstance", "(", "plot", "[", "\"output\"", "]", ",", "dict", ")", ",", "\"`output` in a plot dictionary must be a dict\"", "\n", "\n", "nodes_vpanel", ".", "append", "(", "plot", "[", "\"nodes\"", "]", ")", "\n", "names_vpanel", ".", "append", "(", "plot", "[", "\"names\"", "]", ")", "\n", "files_vpanel", ".", "append", "(", "plot", "[", "\"output\"", "]", ")", "\n", "\n", "", "nodes_to_log", ".", "append", "(", "nodes_vpanel", ")", "\n", "names_of_nodes_to_log", ".", "append", "(", "names_vpanel", ")", "\n", "filenames_to_log_to", ".", "append", "(", "files_vpanel", ")", "\n", "\n", "", "return", "nodes_to_log", ",", "names_of_nodes_to_log", ",", "filenames_to_log_to", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.update_conf_with_defaults": [[56, 72], ["copy.deepcopy", "copy.deepcopy.update", "copy.deepcopy.update"], "function", ["None"], ["", "def", "update_conf_with_defaults", "(", "opts", ",", "default_params", ")", ":", "\n", "\n", "# update the defaul values in opts", "\n", "# use .update to modify the dict in place", "\n", "\n", "# originally", "\n", "#passed_opts = opts.copy()", "\n", "#opts.update(self.default_params)", "\n", "#opts.update(passed_opts)", "\n", "\n", "# new", "\n", "    ", "copy_opts", "=", "copy", ".", "deepcopy", "(", "opts", ")", "\n", "copy_opts", ".", "update", "(", "default_params", ")", "\n", "copy_opts", ".", "update", "(", "opts", ")", "\n", "\n", "return", "copy_opts", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.my_loss_full_logits": [[74, 80], ["tensorflow.nn.softmax", "tensorflow.reduce_sum", "logits.get_shape().as_list", "tensorflow.log", "logits.get_shape", "tensorflow.one_hot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "my_loss_full_logits", "(", "y", ",", "logits", ")", ":", "\n", "    ", "n", "=", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "-", "tf", ".", "one_hot", "(", "y", ",", "depth", "=", "n", ")", "*", "tf", ".", "log", "(", "probabilities", "+", "NUMTOL", ")", ",", "axis", "=", "1", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.make_list": [[82, 84], ["isinstance"], "function", ["None"], ["", "def", "make_list", "(", "l", ")", ":", "\n", "    ", "return", "l", "if", "isinstance", "(", "l", ",", "list", ")", "else", "[", "l", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_list_colors": [[86, 89], ["matplotlib.cm.tab10", "numpy.arange"], "function", ["None"], ["", "def", "create_list_colors", "(", "max_colors", ")", ":", "\n", "    ", "r", "=", "max_colors", "/", "10.0", "\n", "return", "plt", ".", "cm", ".", "tab10", "(", "(", "1", "/", "r", "*", "np", ".", "arange", "(", "10", "*", "r", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module": [[91, 115], ["tf_logging.info", "importlib.import_module", "argo_utils.eval_method_from_tuple", "str", "hasattr", "argo_utils.eval_method_from_tuple", "Exception", "__name__.split", "hasattr", "Exception"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["", "def", "load_sonnet_module", "(", "module_name", ",", "kwargs", ",", "instantiate", "=", "True", ")", ":", "\n", "    ", "tf_logging", ".", "info", "(", "\"Loading sonnet module \"", "+", "str", "(", "module_name", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "my_path", "=", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "2", "]", ")", "\n", "# try first to get the module from argo", "\n", "layer_module", "=", "importlib", ".", "import_module", "(", "my_path", "+", "\".network.\"", "+", "module_name", ")", "\n", "sntmodule", "=", "eval_method_from_tuple", "(", "layer_module", ",", "(", "module_name", ",", "kwargs", ")", ",", "instantiate", ")", "\n", "\n", "", "except", "ImportError", ":", "\n", "# otherwise get module from sonnet or sonnet.nets or raise exception", "\n", "        ", "module", "=", "None", "\n", "if", "hasattr", "(", "snt", ",", "module_name", ")", ":", "\n", "            ", "module", "=", "snt", "\n", "", "elif", "hasattr", "(", "snt", ".", "nets", ",", "module_name", ")", ":", "\n", "            ", "module", "=", "snt", ".", "nets", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"sonnet module \"", "+", "module_name", "+", "\" not recognized\"", ")", "\n", "", "sntmodule", "=", "eval_method_from_tuple", "(", "module", ",", "(", "module_name", ",", "kwargs", ")", ",", "instantiate", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "Exception", "(", "\"problem loading module: %s, kwargs: %s, exception: %s\"", "%", "(", "module_name", ",", "kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "sntmodule", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_ac_collection_name": [[117, 122], ["None"], "function", ["None"], ["", "def", "get_ac_collection_name", "(", "additional_str", ")", ":", "\n", "    ", "ac_collection_name", "=", "AC_REGULARIZATION", "\n", "if", "additional_str", ":", "\n", "        ", "ac_collection_name", "+=", "\"_\"", "+", "additional_str", "\n", "", "return", "ac_collection_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.compose_name": [[124, 128], ["None"], "function", ["None"], ["", "def", "compose_name", "(", "basename", ",", "dataset_str", ",", "separator", "=", "\"_\"", ")", ":", "\n", "    ", "if", "basename", "[", "0", "]", "==", "\"-\"", ":", "\n", "        ", "basename", "=", "basename", "[", "1", ":", "]", "\n", "", "return", "basename", "+", "separator", "+", "dataset_str", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.hash_this": [[130, 137], ["hashlib.sha1", "hashlib.sha1.hexdigest", "longstring.encode"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode"], ["", "def", "hash_this", "(", "longstring", ",", "trunc", "=", "None", ")", ":", "\n", "    ", "hasher", "=", "hashlib", ".", "sha1", "(", "longstring", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "hexstr", "=", "hasher", ".", "hexdigest", "(", ")", "\n", "if", "trunc", ":", "\n", "        ", "hexstr", "=", "hexstr", "[", ":", "trunc", "]", "\n", "\n", "", "return", "hexstr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_cov_times_n_points": [[145, 154], ["tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.transpose"], "function", ["None"], ["", "def", "tf_cov_times_n_points", "(", "x", ")", ":", "\n", "    ", "mean_x", "=", "tf", ".", "reduce_mean", "(", "x", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "sum_x", "=", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "mx", "=", "tf", ".", "matmul", "(", "tf", ".", "transpose", "(", "mean_x", ")", ",", "sum_x", ")", "\n", "# n_points = x.shape.as_list()[0]", "\n", "vx", "=", "tf", ".", "matmul", "(", "tf", ".", "transpose", "(", "x", ")", ",", "x", ")", "# /n_points", "\n", "cov_xx", "=", "vx", "-", "mx", "\n", "\n", "return", "cov_xx", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_reset_metric": [[155, 194], ["scope.replace.replace", "tensorflow.variable_scope", "tensorflow.contrib.framework.get_variables", "metric", "tensorflow.contrib.framework.get_variables", "tensorflow.variables_initializer", "Exception"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables"], ["", "def", "create_reset_metric", "(", "metric", ",", "scope", ",", "**", "metric_args", ")", ":", "\n", "    ", "\"\"\"create a metric inside a scope to control over variables reset operations.\n    suggestion by: shoeffner -> https://github.com/tensorflow/tensorflow/issues/4814\n    reimplemented and added check if scope is not empty, to avoid accidentally resetting some other variables.\n\n    Args:\n        metric (type): a tf.metric function, this typically returns a tuple: (metric_op, update_op).\n        scope (type): scope_name to use in the creation of the metric nodes.\n                        (scope should be different from any other scope already containing variables)\n        **metric_args (type): arguments to pass to the metric function -> metric(**metric_args).\n\n    Returns:\n        (metric_op, update_op, reset_op)\n\n    Example usage:\n    ```python\n        metric_op, update_op, reset_op = create_reset_metric(tf.metrics.mean,\n                                                            scope=\"mean_reset_metric/\"+tensor.name,\n                                                            values=tensor)\n    ```\n    \"\"\"", "\n", "\n", "scope", "=", "scope", ".", "replace", "(", "\":\"", ",", "\"_\"", ")", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", "as", "scope", ":", "\n", "        ", "local_vars", "=", "tf", ".", "contrib", ".", "framework", ".", "get_variables", "(", "scope", ",", "\n", "collection", "=", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", "\n", "# this performs a check that the scope is currently empty,", "\n", "# this is very important to ensure the reset_op will reset", "\n", "# only the metric variables created in the present function", "\n", "if", "local_vars", ":", "\n", "            ", "raise", "Exception", "(", "\"local variables already present in scope: `%s`. \"", "\"I cannot safely initialize reset operation for the metric.\"", "%", "scope", ".", "name", ")", "\n", "\n", "", "metric_op", ",", "update_op", "=", "metric", "(", "**", "metric_args", ")", "\n", "local_vars", "=", "tf", ".", "contrib", ".", "framework", ".", "get_variables", "(", "scope", ",", "\n", "collection", "=", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", "\n", "reset_op", "=", "tf", ".", "variables_initializer", "(", "local_vars", ")", "\n", "\n", "", "return", "metric_op", ",", "update_op", ",", "reset_op", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_concat_opts": [[196, 248], ["scope.replace.replace", "tensorflow.variable_scope", "node.shape.as_list", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.cond", "tensorflow.variables_initializer", "len", "RuntimeError", "tensorflow.equal", "tensorflow.zeros", "tensorflow.constant", "tensorflow.assign", "tensorflow.assign_add", "tensorflow.assign", "tensorflow.assign_add", "tensorflow.concat"], "function", ["None"], ["", "def", "create_concat_opts", "(", "scope", ",", "node", ")", ":", "\n", "# self.concat_ops[ds_key] = tf.contrib.framework.get_variables(scope,", "\n", "#                                                             collection=tf.GraphKeys.LOCAL_VARIABLES)", "\n", "# if self.concat_ops[ds_key]:", "\n", "#    raise Exception(\"variable already present in scope: `%s`. \"\\", "\n", "#                    \"I cannot safely initialize reset operation for the metric.\" % scope.name)", "\n", "\n", "    ", "scope", "=", "scope", ".", "replace", "(", "\":\"", ",", "\"_\"", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", "as", "scope", ":", "\n", "# local_vars = tf.contrib.framework.get_variables(scope,", "\n", "#                                       collection=tf.GraphKeys.LOCAL_VARIABLES)", "\n", "# if local_vars:", "\n", "#    raise Exception(\"local variables already present in scope: `%s`. \"\\", "\n", "#                    \"I cannot safely initialize reset operation for the metric.\" % scope.name)", "\n", "\n", "# see https://github.com/tensorflow/tensorflow/issues/4432", "\n", "\n", "# TODO it must be 1-D? Maybe yes,(for PCA yes for sure).", "\n", "        ", "node_shape", "=", "node", ".", "shape", ".", "as_list", "(", ")", "\n", "if", "len", "(", "node_shape", ")", "!=", "2", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"the node passed for concatenation is not a 2D tensor, as expected...\"", ")", "\n", "\n", "", "dim", "=", "node_shape", "[", "1", "]", "\n", "\n", "accumulator", "=", "tf", ".", "get_variable", "(", "\"accumulator\"", ",", "\n", "initializer", "=", "tf", ".", "zeros", "(", "[", "0", ",", "dim", "]", ")", ",", "\n", "trainable", "=", "False", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", "]", "\n", ")", "\n", "\n", "i", "=", "tf", ".", "get_variable", "(", "\"index\"", ",", "\n", "initializer", "=", "tf", ".", "constant", "(", "0", ")", ",", "\n", "dtype", "=", "tf", ".", "int32", ",", "\n", "trainable", "=", "False", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", "]", "\n", ")", "\n", "\n", "def", "assign", "(", ")", ":", "\n", "# with tf.control_dependencies(tf.assign_add(i, 1)):", "\n", "            ", "return", "tf", ".", "assign", "(", "accumulator", ",", "node", ",", "validate_shape", "=", "False", ")", ",", "tf", ".", "assign_add", "(", "i", ",", "1", ")", "\n", "\n", "", "def", "concat", "(", ")", ":", "\n", "            ", "return", "tf", ".", "assign", "(", "accumulator", ",", "tf", ".", "concat", "(", "[", "accumulator", ",", "node", "]", ",", "axis", "=", "0", ")", ",", "validate_shape", "=", "False", ")", ",", "tf", ".", "assign_add", "(", "i", ",", "1", ")", "\n", "\n", "", "concat_update_ops", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "i", ",", "0", ")", ",", "\n", "assign", ",", "\n", "concat", ")", "\n", "\n", "concat_reset_ops", "=", "tf", ".", "variables_initializer", "(", "[", "i", "]", ")", "\n", "\n", "return", "accumulator", ",", "concat_update_ops", ",", "concat_reset_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_sample_discrete_from_continuous": [[255, 258], ["Exception", "tensorflow.distributions.Bernoulli().sample", "tensorflow.distributions.Bernoulli"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["def", "tf_sample_discrete_from_continuous", "(", "X", ")", ":", "\n", "    ", "raise", "Exception", "(", "\"Are you sure you want to use this with the new 0/1 encoding?\"", ")", "\n", "return", "tf", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "X", ",", "dtype", "=", "X", ".", "dtype", ")", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_add_noise_to_discrete": [[259, 265], ["tensorflow.distributions.Bernoulli().sample", "tensorflow.ones", "tensorflow.shape", "tensorflow.distributions.Bernoulli"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "tf_add_noise_to_discrete", "(", "X", ",", "flip_probability", ")", ":", "\n", "    ", "probs", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "X", ")", ")", "*", "(", "1", "-", "flip_probability", ")", "\n", "flip", "=", "tf", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "probs", ",", "dtype", "=", "X", ".", "dtype", ")", ".", "sample", "(", ")", "\n", "#flipped = bitwise_xor(tf.cast(X, dtype=tf.int32), tf.cast(flip, dtype=tf.int32))", "\n", "flipped", "=", "X", "*", "(", "2", "*", "flip", "-", "1", ")", "\n", "return", "flipped", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_add_gaussian_noise_and_clip": [[275, 283], ["tensorflow.distributions.Normal().sample", "tensorflow.clip_by_value", "tensorflow.distributions.Normal", "tensorflow.zeros_like", "tensorflow.ones_like"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["def", "tf_add_gaussian_noise_and_clip", "(", "data", ",", "std", "=", "0.1", ",", "low", "=", "-", "1.", ",", "high", "=", "1.", ",", "clip_bool", "=", "True", ")", ":", "\n", "# fixed problem, here it was variance, but everybody thought it was std... std is better to control since we understand the 'range' of the noise", "\n", "    ", "noise", "=", "tf", ".", "distributions", ".", "Normal", "(", "tf", ".", "zeros_like", "(", "data", ")", ",", "tf", ".", "ones_like", "(", "data", ")", "*", "std", ")", ".", "sample", "(", ")", "\n", "noisy_data", "=", "data", "+", "noise", "\n", "# clip in [low,high]", "\n", "if", "clip_bool", ":", "\n", "        ", "noisy_data", "=", "tf", ".", "clip_by_value", "(", "noisy_data", ",", "low", ",", "high", ")", "\n", "", "return", "noisy_data", ",", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_rescale": [[290, 293], ["None"], "function", ["None"], ["def", "tf_rescale", "(", "data", ",", "eps", ",", "min_value", "=", "-", "1.0", ",", "max_value", "=", "1.0", ")", ":", "\n", "    ", "delta", "=", "max_value", "-", "min_value", "\n", "return", "(", "delta", "-", "2", "*", "eps", ")", "*", "data", "+", "eps", "+", "min_value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_clip": [[299, 302], ["tensorflow.clip_by_value"], "function", ["None"], ["def", "tf_clip", "(", "data", ",", "low", "=", "-", "1.0", ",", "high", "=", "1.0", ")", ":", "\n", "#data = tf.cast(data, dtype=tf.float32)", "\n", "    ", "return", "tf", ".", "clip_by_value", "(", "data", ",", "low", ",", "high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.np_softplus": [[304, 309], ["numpy.log", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "np_softplus", "(", "x", ",", "limit", "=", "30", ")", ":", "\n", "    ", "if", "x", ">", "limit", ":", "\n", "        ", "return", "x", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "log", "(", "1.0", "+", "np", ".", "exp", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_short_dtype": [[320, 333], ["ValueError"], "function", ["None"], ["def", "get_short_dtype", "(", "dtypestr", ")", ":", "\n", "    ", "\"\"\"\n    return the dtype name (string) in short form, typically used for id construction\n\n    Args:\n        dtypestr (str) : dtype name in string format\n\n    Returns:\n        str : the short name\n    \"\"\"", "\n", "if", "not", "dtypestr", "in", "dtype_short", ":", "\n", "        ", "raise", "ValueError", "(", "'the type specified %s is not supported.'", "%", "dtypestr", ")", "\n", "", "return", "dtype_short", "[", "dtypestr", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_short_regularization_name": [[370, 383], ["ValueError"], "function", ["None"], ["def", "get_short_regularization_name", "(", "reg_name", ")", ":", "\n", "    ", "\"\"\"\n    return the regularization name (string) in short form, typically used for id construction\n\n    Args:\n        reg_name (str) : regularization name in string format\n\n    Returns:\n        str : the short name\n    \"\"\"", "\n", "if", "not", "reg_name", "in", "regularizers_short_names", ":", "\n", "        ", "raise", "ValueError", "(", "'the regularizer specified %s is not supported.'", "%", "reg_name", ")", "\n", "", "return", "regularizers_short_names", "[", "reg_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.regularization_info": [[385, 411], ["layer_dict.get", "argo_utils.get_short_regularization_name", "argo_utils.regularization_info", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_short_regularization_name", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.regularization_info"], ["", "def", "regularization_info", "(", "layer_dict", ")", ":", "\n", "# \"contractive_regularizer\" : (\"standard_contractive_regularizer\",", "\n", "# {\"norm\": 2, \"scale_mean\" : 0.1, \"scale_covariance\" : 0.1})", "\n", "    ", "reg_info", "=", "\"\"", "\n", "contr_reg", "=", "layer_dict", ".", "get", "(", "\"contractive_regularizer\"", ",", "None", ")", "\n", "if", "contr_reg", "is", "not", "None", ":", "\n", "        ", "reg_info", "=", "\"r\"", "\n", "crname", ",", "crdict", "=", "contr_reg", "\n", "if", "crname", "==", "'contractive_reg_list'", ":", "\n", "            ", "list_regs", "=", "crdict", "[", "'list_regs'", "]", "\n", "for", "reg_tuple", "in", "list_regs", ":", "\n", "                ", "reg_info", "+=", "regularization_info", "(", "{", "\"contractive_regularizer\"", ":", "reg_tuple", "}", ")", "\n", "", "", "else", ":", "\n", "            ", "reg_info", "+=", "get_short_regularization_name", "(", "crname", ")", "\n", "if", "\"norm\"", "in", "crdict", ":", "\n", "                ", "reg_info", "+=", "\"_n\"", "+", "str", "(", "crdict", "[", "\"norm\"", "]", ")", "\n", "", "if", "\"scale_mean\"", "in", "crdict", ":", "\n", "                ", "reg_info", "+=", "\"_sm\"", "+", "str", "(", "crdict", "[", "\"scale_mean\"", "]", ")", "\n", "", "if", "\"scale\"", "in", "crdict", ":", "\n", "                ", "reg_info", "+=", "\"_s\"", "+", "str", "(", "crdict", "[", "\"scale\"", "]", ")", "\n", "", "if", "\"scale_covariance\"", "in", "crdict", ":", "\n", "                ", "reg_info", "+=", "\"_sc\"", "+", "str", "(", "crdict", "[", "\"scale_covariance\"", "]", ")", "\n", "\n", "# TODO add your own regularizer type and extract relevant parameters!", "\n", "\n", "", "", "", "return", "reg_info", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints": [[513, 517], ["isinstance", "re.sub().replace().split", "re.sub().replace", "re.sub", "str", "list"], "function", ["None"], ["def", "listWithPoints", "(", "x", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "int", ")", ":", "\n", "        ", "x", "=", "[", "x", "]", "\n", "", "return", "\",\"", ".", "join", "(", "re", ".", "sub", "(", "'[( )\\[\\]]'", ",", "''", ",", "str", "(", "list", "(", "x", ")", ")", ")", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "\",\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id": [[518, 783], ["method_tuple[].split", "str", "argo_utils.regularization_info", "ValueError", "re.sub", "re.sub", "str", "str", "str", "re.sub", "str", "re.sub", "str", "str", "str", "str", "str", "int", "str", "argo_utils.listWithPoints", "str", "argo_utils.listWithPoints", "str", "argo_utils.listWithPoints", "int", "str", "argo_utils.listWithPoints", "str", "method_kwargs.get", "argo_utils.listWithPoints", "str", "argo_utils.listWithPoints", "argo_utils.listWithPoints", "str", "argo_utils.listWithPoints", "int", "argo_utils.listWithPoints", "str", "str", "argo_utils.listWithPoints", "str", "argo_utils.listWithPoints", "method_kwargs.get", "argo_utils.listWithPoints", "argo_utils.listWithPoints", "argo_utils.listWithPoints", "argo_utils.listWithPoints", "str", "str", "str", "str", "argo_utils.listWithPoints", "argo_utils.listWithPoints", "argo_utils.listWithPoints", "argo_utils.listWithPoints", "re.sub", "str", "str", "str", "str", "str", "str", "argo_utils.listWithPoints", "Exception", "re.sub", "str", "argo_utils.get_method_id", "str", "isinstance", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "argo_utils.hash_this", "print", "print", "ValueError", "str", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.regularization_info", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.hash_this"], ["", "def", "get_method_id", "(", "method_tuple", ")", ":", "\n", "    ", "\"\"\"Creates the id for a method of tensorflow.\n\n    Args:\n        method_tuple (tuple): A tuple composed of : (name of the method of tensorflow, kwargs to pass to the method, bool_activation).\n\n    Returns:\n        string: the idname of the method that we want to concatenate in the output filenames.\n\n    \"\"\"", "\n", "# ipdb.set_trace()", "\n", "# the name could be articulated, since I might want to get the initializers or regularizers", "\n", "# from different submodules in tf.", "\n", "# e.g. tf.contrib.layers.xavier_initializer", "\n", "# the method name I am interested in is the one after the last dot.", "\n", "\n", "if", "method_tuple", "is", "None", ":", "\n", "        ", "return", "\"0\"", "\n", "\n", "", "method_name", "=", "method_tuple", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "\n", "method_kwargs", "=", "method_tuple", "[", "1", "]", "\n", "\n", "methodid", "=", "method_name_short", "[", "method_name", "]", "\n", "\n", "if", "method_name", "==", "'dense'", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "'units'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'conv2d'", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "'filters'", "]", ")", "+", "'x'", "+", "re", ".", "sub", "(", "'[( )]'", ",", "''", ",", "str", "(", "method_kwargs", "[", "'kernel_size'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'max_pooling2d'", ":", "\n", "        ", "methodid", "+=", "re", ".", "sub", "(", "'[( )]'", ",", "''", ",", "str", "(", "method_kwargs", "[", "'pool_size'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'AveragePooling2D'", ":", "\n", "        ", "methodid", "+=", "re", ".", "sub", "(", "'[( )]'", ",", "''", ",", "str", "(", "method_kwargs", "[", "'pool_size'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'AveragePooling2D'", ":", "\n", "        ", "methodid", "+=", "re", ".", "sub", "(", "'[( )]'", ",", "''", ",", "str", "(", "method_kwargs", "[", "'pool_size'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'flatten'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'Linear'", ":", "\n", "#case when it is output layer", "\n", "        ", "if", "\"output_size\"", "in", "method_kwargs", ":", "\n", "            ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"output_size\"", "]", ")", "\n", "\n", "", "", "elif", "method_name", "==", "'Concatenate'", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "'node_name'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'LinearWN'", ":", "\n", "# case when it is output layer", "\n", "        ", "if", "\"output_size\"", "in", "method_kwargs", ":", "\n", "            ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"output_size\"", "]", ")", "\n", "\n", "", "methodid", "+=", "'wn'", "+", "str", "(", "int", "(", "method_kwargs", "[", "'use_weight_norm'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'Conv2D'", ":", "\n", "# case when it is output layer", "\n", "        ", "if", "\"output_channels\"", "in", "method_kwargs", ":", "\n", "            ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"output_channels\"", "]", ")", "\n", "\n", "", "methodid", "+=", "'k'", "+", "listWithPoints", "(", "method_kwargs", "[", "'kernel_shape'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'Conv2DTranspose'", ":", "\n", "# case when it is output layer", "\n", "        ", "if", "\"output_channels\"", "in", "method_kwargs", ":", "\n", "            ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"output_channels\"", "]", ")", "\n", "\n", "", "methodid", "+=", "'o'", "+", "listWithPoints", "(", "method_kwargs", "[", "'output_shape'", "]", ")", "+", "'k'", "+", "listWithPoints", "(", "method_kwargs", "[", "'kernel_shape'", "]", ")", "+", "'s'", "+", "listWithPoints", "(", "method_kwargs", "[", "'stride'", "]", ")", "# if you need to changes to 'strides', talk to me (Luigi)", "\n", "\n", "", "elif", "method_name", "==", "'Conv2DWN'", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "'output_channels'", "]", ")", "+", "'o'", "+", "listWithPoints", "(", "method_kwargs", "[", "'kernel_shape'", "]", ")", "+", "'wn'", "+", "str", "(", "int", "(", "method_kwargs", "[", "'use_weight_norm'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'ResUnit'", ":", "\n", "        ", "methodid", "+=", "'c'", "+", "str", "(", "method_kwargs", "[", "'depth'", "]", ")", "+", "'k'", "+", "listWithPoints", "(", "method_kwargs", "[", "'kernel_shape'", "]", ")", "+", "'s'", "+", "str", "(", "method_kwargs", "[", "'stride'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'VGGBlock'", ":", "\n", "        ", "methodid", "+=", "'c'", "+", "str", "(", "method_kwargs", "[", "'channels'", "]", ")", "+", "'k'", "+", "listWithPoints", "(", "method_kwargs", "[", "'kernel_shape'", "]", ")", "+", "'d'", "+", "str", "(", "method_kwargs", "[", "'prob_drop'", "]", ")", "\n", "if", "method_kwargs", ".", "get", "(", "'logits_size'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "methodid", "+=", "\"l\"", "+", "listWithPoints", "(", "method_kwargs", "[", "'logits_size'", "]", ")", "\n", "\n", "", "", "elif", "method_name", "==", "'ResNet18'", ":", "\n", "        ", "methodid", "+=", "'o'", "+", "str", "(", "method_kwargs", "[", "'output_size'", "]", ")", "+", "'wn'", "+", "str", "(", "int", "(", "method_kwargs", "[", "'use_weight_norm'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'ConvNet2D'", ":", "\n", "        ", "methodid", "+=", "'o'", "+", "listWithPoints", "(", "method_kwargs", "[", "'output_channels'", "]", ")", "+", "'k'", "+", "listWithPoints", "(", "\n", "method_kwargs", "[", "'kernel_shapes'", "]", ")", "+", "'s'", "+", "listWithPoints", "(", "method_kwargs", "[", "'strides'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'ConvNet2DTranspose'", ":", "\n", "        ", "methodid", "+=", "'o'", "+", "listWithPoints", "(", "method_kwargs", "[", "'output_channels'", "]", ")", "+", "'k'", "+", "listWithPoints", "(", "\n", "method_kwargs", "[", "'kernel_shapes'", "]", ")", "+", "'s'", "+", "listWithPoints", "(", "method_kwargs", "[", "'strides'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'ConvDec'", ":", "\n", "        ", "if", "method_kwargs", ".", "get", "(", "'linear_first'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "methodid", "+=", "'l'", "+", "listWithPoints", "(", "method_kwargs", "[", "\"linear_first\"", "]", "[", "\"sizes\"", "]", ")", "\n", "methodid", "+=", "'r'", "+", "listWithPoints", "(", "method_kwargs", "[", "\"linear_first\"", "]", "[", "\"reshape\"", "]", ")", "\n", "", "methodid", "+=", "'c'", "+", "listWithPoints", "(", "method_kwargs", "[", "'channels'", "]", ")", "+", "'k'", "+", "listWithPoints", "(", "method_kwargs", "[", "'kernel_shape'", "]", ")", "# + 's' + listWithPoints(method_kwargs['stride'])", "\n", "\n", "", "elif", "method_name", "in", "[", "'ResEnc'", ",", "'ResDec'", "]", ":", "\n", "        ", "methodid", "+=", "'h'", "+", "str", "(", "method_kwargs", "[", "'num_hiddens'", "]", ")", "\n", "methodid", "+=", "'rl'", "+", "str", "(", "method_kwargs", "[", "'num_residual_layers'", "]", ")", "\n", "methodid", "+=", "'rh'", "+", "str", "(", "method_kwargs", "[", "'num_residual_hiddens'", "]", ")", "\n", "methodid", "+=", "'d'", "+", "str", "(", "method_kwargs", "[", "'prob_drop'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'BatchFlatten'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'Identity'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'MaxPooling2D'", ":", "\n", "        ", "methodid", "+=", "re", ".", "sub", "(", "'[( )]'", ",", "''", ",", "str", "(", "method_kwargs", "[", "'pool_size'", "]", ")", ")", "+", "'s'", "+", "listWithPoints", "(", "\n", "method_kwargs", "[", "'strides'", "]", ")", "\n", "\n", "\n", "", "elif", "method_name", "==", "'Dropout'", ":", "\n", "        ", "methodid", "+=", "'r'", "+", "str", "(", "method_kwargs", "[", "'rate'", "]", ")", "# tf.layers.dropout", "\n", "\n", "", "elif", "method_name", "==", "'Sigmoid'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'Tanh'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'RandomUniform'", ":", "\n", "        ", "methodid", "+=", "'s'", "+", "str", "(", "method_kwargs", "[", "'shape'", "]", ")", "\n", "methodid", "+=", "'min'", "+", "str", "(", "method_kwargs", "[", "'minval'", "]", ")", "\n", "methodid", "+=", "'max'", "+", "str", "(", "method_kwargs", "[", "'maxval'", "]", ")", "\n", "\n", "# for the moment we don't have mean and covariance as parameters", "\n", "", "elif", "method_name", "==", "'RandomGaussian'", ":", "\n", "        ", "methodid", "+=", "'s'", "+", "str", "(", "method_kwargs", "[", "'shape'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'Tanh'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'AveragePooling2D'", ":", "\n", "        ", "methodid", "+=", "re", ".", "sub", "(", "'[( )]'", ",", "''", ",", "str", "(", "method_kwargs", "[", "'pool_size'", "]", ")", ")", "+", "'s'", "+", "listWithPoints", "(", "method_kwargs", "[", "'strides'", "]", ")", "\n", "\n", "#elif method_name=='Dropout':", "\n", "#    methodid += 'k'+str(method_kwargs['keep'])", "\n", "\n", "", "elif", "method_name", "==", "'Sigmoid'", ":", "\n", "        ", "raise", "Exception", "(", "\"why nothing in the name? talk to Luigi\"", ")", "\n", "\n", "", "elif", "method_name", "==", "'Identity'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'BatchReshape'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'BatchNorm'", ":", "\n", "        ", "methodid", "+=", "''", "#+ str(method_kwargs['offset']) + 's' + str(method_kwargs['scale']) + 'd' + str(method_kwargs['decay_rate'])", "\n", "\n", "", "elif", "method_name", "==", "'LayerNorm'", ":", "\n", "        ", "methodid", "+=", "''", "\n", "\n", "", "elif", "method_name", "==", "'GaussianDiagonal'", "or", "method_name", "==", "'GaussianDiagonalZeroOne'", "or", "method_name", "==", "'GaussianDiagonalPlusMinusOne'", "or", "method_name", "==", "'vonMisesFisher'", "or", "method_name", "==", "'LogitNormalDiagonal'", "or", "method_name", "==", "'LogitNormalDiagonalPlusMinusOne'", "or", "method_name", "==", "'LogisticDiagonalZeroOne'", "or", "method_name", "==", "'LogisticDiagonalPlusMinusOne'", ":", "\n", "# wrapped_module_name, wrapped_module_kwargs = method_kwargs[\"module_tuple\"]", "\n", "# LUIGI the lower case is done to increase readibility", "\n", "# methodid += \"\" + method_name_short[wrapped_module_name].lower()", "\n", "# if \"output_size\" in method_kwargs:", "\n", "#     methodid += str(method_kwargs[\"output_size\"])", "\n", "        ", "methodid", "+=", "\"m\"", "+", "get_method_id", "(", "method_kwargs", "[", "\"module_tuple\"", "]", ")", "\n", "\n", "if", "\"minimal_concentration\"", "in", "method_kwargs", "or", "\"minimal_covariance\"", "in", "method_kwargs", ":", "# and method_kwargs[\"minimal_concentration\"] != 1:", "\n", "            ", "if", "method_name", "==", "'vonMisesFisher'", ":", "\n", "                ", "methodid", "+=", "\"mc\"", "+", "str", "(", "method_kwargs", "[", "\"minimal_concentration\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "methodid", "+=", "\"mc\"", "+", "str", "(", "method_kwargs", "[", "\"minimal_covariance\"", "]", ")", "\n", "", "", "if", "\"zero_one_method\"", "in", "method_kwargs", "and", "method_kwargs", "[", "\"zero_one_method\"", "]", "!=", "\"sigmoid\"", ":", "\n", "            ", "methodid", "+=", "\"zo\"", "+", "str", "(", "method_name_short", "[", "method_kwargs", "[", "\"zero_one_method\"", "]", "]", ")", "\n", "", "if", "\"scalar_covariance\"", "in", "method_kwargs", ":", "\n", "            ", "scov", "=", "method_kwargs", "[", "\"scalar_covariance\"", "]", "\n", "if", "scov", "==", "True", ":", "\n", "                ", "methodid", "+=", "\"scT\"", "\n", "", "elif", "isinstance", "(", "scov", ",", "float", ")", ":", "\n", "                ", "methodid", "+=", "\"sc\"", "+", "str", "(", "scov", ")", "\n", "\n", "", "", "if", "method_name", "==", "'LogitNormalDiagonal'", "or", "method_name", "==", "'LogitNormalDiagonalPlusMinusOne'", ":", "\n", "#import pdb;pdb.set_trace()", "\n", "            ", "if", "\"clip_value\"", "in", "method_kwargs", ":", "\n", "                ", "clip", "=", "method_kwargs", "[", "\"clip_value\"", "]", "\n", "methodid", "+=", "\"cv\"", "+", "str", "(", "clip", ")", "\n", "\n", "#methodid += \"_r\" + regularization_info(method_kwargs)", "\n", "\n", "", "", "", "elif", "method_name", "==", "'Bernoulli'", "or", "method_name", "==", "'BernoulliPlusMinusOne'", ":", "\n", "        ", "if", "\"output_size\"", "in", "method_kwargs", ":", "\n", "            ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"output_size\"", "]", ")", "\n", "", "clip", "=", "method_kwargs", "[", "\"clip_value\"", "]", "\n", "methodid", "+=", "\"cv\"", "+", "str", "(", "clip", ")", "\n", "\n", "", "elif", "method_name", "==", "'OneHotCategorical'", ":", "\n", "        ", "if", "\"output_size\"", "in", "method_kwargs", ":", "\n", "            ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"output_size\"", "]", ")", "\n", "", "clip", "=", "method_kwargs", "[", "\"clip_value\"", "]", "\n", "methodid", "+=", "\"cv\"", "+", "str", "(", "clip", ")", "\n", "\n", "", "elif", "method_name", "==", "'CIFAR10TutorialNetwork'", ":", "\n", "         ", "pass", "\n", "\n", "", "elif", "\"variance_scaling_initializer\"", "in", "method_name", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "\"glorot_normal_initializer\"", "in", "method_name", "or", "\"glorot_uniform_initializer\"", "in", "method_name", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "\"truncated_normal_initializer\"", "in", "method_name", "or", "\"random_normal\"", "in", "method_name", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "'stddev'", "]", ")", "\n", "\n", "", "elif", "\"constant_initializer\"", "in", "method_name", "or", "\"constant\"", "in", "method_name", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "'value'", "]", ")", "\n", "\n", "", "elif", "method_name", "in", "[", "\"l1_regularizer\"", ",", "\"l2_regularizer\"", ",", "\"sum_regularizer\"", "]", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"scale\"", "]", ")", "\n", "\n", "", "elif", "method_name", "in", "[", "\"l1\"", ",", "\"l2\"", "]", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "\"l\"", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "\"softplus\"", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "\"linear_softplus\"", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "\"exp\"", ":", "\n", "        ", "pass", "\n", "\n", "# PREPROCESSING SECTION used to prefilter transform an image with some method", "\n", "", "elif", "method_name", "==", "\"FromAE\"", ":", "\n", "        ", "methodid", "+=", "hash_this", "(", "method_kwargs", "[", "\"filename\"", "]", ",", "trunc", "=", "3", ")", "\n", "methodid", "+=", "\"t\"", "+", "str", "(", "method_kwargs", "[", "\"transform_prob\"", "]", ")", "\n", "methodid", "+=", "\"n\"", "+", "str", "(", "method_kwargs", "[", "\"noisy_transform_prob\"", "]", ")", "\n", "\n", "# Here implement your favourite method", "\n", "# elif      :", "\n", "#", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'----------------------'", ")", "\n", "print", "(", "'ERROR '", ",", "method_name", ")", "\n", "raise", "ValueError", "(", "\"id rule for `%s` has to be implemented.\"", "%", "method_name", ")", "\n", "\n", "# support for contractive only in some layers for the moment, but it could be easily extended,", "\n", "# just add your layer and test it", "\n", "", "if", "\"contractive_regularizer\"", "in", "method_kwargs", ":", "\n", "        ", "if", "method_name", "==", "\"Linear\"", "or", "method_name", "==", "\"GaussianDiagonal\"", "or", "method_name", "==", "\"GaussianDiagonalPlusMinusOne\"", ":", "\n", "            ", "methodid", "+=", "regularization_info", "(", "method_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"contractive_regularizers not supported for `%s`.\"", "%", "method_name", ")", "\n", "\n", "", "", "return", "methodid", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_clipping_id": [[784, 791], ["None"], "function", ["None"], ["", "def", "get_clipping_id", "(", "clipping_tuple", ")", ":", "\n", "    ", "method", "=", "clipping_tuple", "[", "0", "]", "\n", "if", "not", "method", ":", "\n", "        ", "return", "method_name_short", "[", "\"no\"", "]", "\n", "", "else", ":", "\n", "        ", "value", "=", "clipping_tuple", "[", "1", "]", "[", "\"value\"", "]", "\n", "return", "method_name_short", "[", "method", "]", "+", "\"{:.4g}\"", ".", "format", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple": [[792, 816], ["argo_utils.load_method_fn_from_method_path", "load_method_fn_from_method_path."], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_method_fn_from_method_path"], ["", "", "def", "eval_method_from_tuple", "(", "module", ",", "method_tuple", ",", "instantiate", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        module (python module): module from which take the method.\n        method_tuple (tuple): (method_path, method_kwargs).\n\n    Returns:\n        if method_tuple is None returns None\n        otherwise returns\n        module.method_path(**method_kwargs)\n\n    \"\"\"", "\n", "\n", "if", "not", "method_tuple", ":", "\n", "        ", "return", "None", "\n", "\n", "", "method_fn", "=", "load_method_fn_from_method_path", "(", "module", ",", "method_tuple", "[", "0", "]", ")", "\n", "\n", "#     import pdb;pdb.set_trace()", "\n", "if", "instantiate", ":", "\n", "        ", "return", "method_fn", "(", "**", "method_tuple", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "method_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_method_fn_from_method_path": [[818, 846], ["method_path.split", "importlib.import_module", "getattr"], "function", ["None"], ["", "", "def", "load_method_fn_from_method_path", "(", "module", ",", "method_path", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        module (python module): module from which take the method.\n        method_path (string): path to the method.\n\n    Returns:\n        if method_path is None returns None\n        otherwise returns\n        module.method_path(**method_kwargs)\n\n    \"\"\"", "\n", "\n", "if", "not", "method_path", ":", "\n", "        ", "return", "None", "\n", "\n", "", "mpathsplit", "=", "method_path", ".", "split", "(", "\".\"", ")", "\n", "method_name", "=", "mpathsplit", "[", "-", "1", "]", "\n", "\n", "path", "=", "module", ".", "__name__", "\n", "middle_path", "=", "'.'", ".", "join", "(", "mpathsplit", "[", ":", "-", "1", "]", ")", "\n", "if", "middle_path", ":", "\n", "        ", "path", "+=", "'.'", "+", "middle_path", "\n", "\n", "", "last_module", "=", "importlib", ".", "import_module", "(", "path", ")", "\n", "method_fn", "=", "getattr", "(", "last_module", ",", "method_name", ")", "\n", "return", "method_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.try_load_class_from_modules": [[848, 861], ["Exception", "argo_utils.load_method_fn_from_method_path"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_method_fn_from_method_path"], ["", "def", "try_load_class_from_modules", "(", "class_path", ",", "modules", ")", ":", "\n", "    ", "LayerClass", "=", "None", "\n", "\n", "for", "module", "in", "modules", ":", "\n", "        ", "try", ":", "\n", "            ", "LayerClass", "=", "load_method_fn_from_method_path", "(", "module", ",", "class_path", ")", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "", "if", "LayerClass", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"problem loading class: {:}, not found in modules {:}\"", ".", "format", "(", "class_path", ",", "modules", ")", ")", "\n", "\n", "", "return", "LayerClass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class": [[863, 882], ["class_path.rsplit", "importlib.import_module", "getattr", "class_path.split"], "function", ["None"], ["", "def", "load_class", "(", "module_plus_class", ",", "relative", "=", "False", ",", "base_path", "=", "''", ")", ":", "\n", "# assemble class path", "\n", "    ", "class_path", "=", "''", "\n", "# if class_base_path prepend this to the path", "\n", "if", "base_path", ":", "\n", "        ", "class_path", "=", "base_path", "\n", "# if the prepended path does not finish with a dot add it", "\n", "if", "class_path", "[", "-", "1", "]", "!=", "'.'", ":", "\n", "            ", "class_path", "+=", "'.'", "\n", "", "", "class_path", "+=", "module_plus_class", "\n", "\n", "# split in all modules and class", "\n", "modulesname", ",", "classname", "=", "class_path", ".", "rsplit", "(", "'.'", ",", "1", ")", "\n", "if", "relative", ":", "\n", "        ", "modulesname", "=", "class_path", ".", "split", "(", "'.'", ",", "1", ")", "[", "1", "]", "\n", "\n", "", "my_module", "=", "importlib", ".", "import_module", "(", "modulesname", ")", "\n", "my_class", "=", "getattr", "(", "my_module", ",", "classname", ")", "\n", "return", "my_class", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_module": [[883, 900], ["importlib.import_module", "class_path.split"], "function", ["None"], ["", "def", "load_module", "(", "module", ",", "relative", "=", "False", ",", "base_path", "=", "''", ")", ":", "\n", "# assemble class path", "\n", "    ", "class_path", "=", "''", "\n", "#if class_base_path prepend this to the path", "\n", "if", "base_path", ":", "\n", "        ", "class_path", "=", "base_path", "\n", "#if the prepended path does not finish with a dot add it", "\n", "if", "class_path", "[", "-", "1", "]", "!=", "'.'", ":", "\n", "            ", "class_path", "+=", "'.'", "\n", "", "", "class_path", "+=", "module", "\n", "\n", "modulesname", "=", "class_path", "\n", "if", "relative", ":", "\n", "        ", "modulesname", "=", "class_path", ".", "split", "(", "'.'", ",", "1", ")", "[", "1", "]", "\n", "\n", "", "my_module", "=", "importlib", ".", "import_module", "(", "modulesname", ")", "\n", "return", "my_module", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_file": [[901, 904], ["open", "eval", "fstream.read"], "function", ["None"], ["", "def", "eval_file", "(", "file_name_path", ")", ":", "\n", "    ", "with", "open", "(", "file_name_path", ",", "'r'", ")", "as", "fstream", ":", "\n", "        ", "return", "eval", "(", "fstream", ".", "read", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.freeze_graph_create_pb": [[905, 954], ["print", "graph.as_default", "list", "graph.as_graph_def", "tensorflow.graph_util.convert_variables_to_constants", "set().difference", "tensorflow.gfile.GFile", "f.write", "len", "tf.graph_util.convert_variables_to_constants.SerializeToString", "tensorflow.global_variables", "set", "tensorflow.global_variables"], "function", ["None"], ["", "", "def", "freeze_graph_create_pb", "(", "session", ",", "\n", "output_names", "=", "None", ",", "\n", "variable_names_whitelist", "=", "None", ",", "\n", "variable_names_blacklist", "=", "None", ",", "\n", "output_filename", "=", "None", ",", "\n", "clear_devices", "=", "True", ")", ":", "\n", "\n", "        ", "\"\"\"\n        Freezes the state of a session into a pruned computation graph.\n\n        Creates a new computation graph where variable nodes are replaced by\n        constants taking their current value in the session. The new graph will be\n        pruned so subgraphs that are not necessary to compute the requested\n        outputs are removed.\n        @param session The TensorFlow session to be frozen.\n        @param variable_names_whitelist A list of variable to be frozen (default all)\n        @param variable_names_blacklist A list of variable names that should not be frozen,\n                                        or None to freeze all the variables in the graph.\n        @param output_names Names of the relevant graph outputs.\n        @param clear_devices Remove the device directives from the graph for better portability.\n        @return The frozen graph definition.\n        \"\"\"", "\n", "graph", "=", "session", ".", "graph", "\n", "with", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "if", "variable_names_whitelist", "is", "not", "None", ":", "\n", "                ", "freeze_var_names", "=", "variable_names_whitelist", "\n", "", "else", ":", "\n", "                ", "freeze_var_names", "=", "[", "v", ".", "op", ".", "name", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "]", "\n", "", "freeze_var_names", "=", "list", "(", "set", "(", "freeze_var_names", ")", ".", "difference", "(", "variable_names_blacklist", "or", "[", "]", ")", ")", "\n", "\n", "if", "output_names", "is", "None", ":", "\n", "                ", "output_names", "=", "[", "v", ".", "op", ".", "name", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "]", "\n", "\n", "", "input_graph_def", "=", "graph", ".", "as_graph_def", "(", ")", "\n", "if", "clear_devices", ":", "\n", "                ", "for", "node", "in", "input_graph_def", ".", "node", ":", "\n", "                    ", "node", ".", "device", "=", "\"\"", "\n", "\n", "", "", "frozen_graph", "=", "tf", ".", "graph_util", ".", "convert_variables_to_constants", "(", "session", ",", "\n", "input_graph_def", ",", "\n", "output_names", ",", "\n", "freeze_var_names", ")", "\n", "\n", "# finally we serialize and dump the output graph to the filesystem", "\n", "", "if", "output_filename", "is", "not", "None", ":", "\n", "            ", "with", "tf", ".", "gfile", ".", "GFile", "(", "output_filename", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "frozen_graph", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "print", "(", "\"freezing and creating pb file: %d ops in the final graph.\"", "%", "len", "(", "frozen_graph", ".", "node", ")", ")", "\n", "#return frozen_graph", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.unpack_dict_of_lists": [[957, 959], ["dict", "zip", "itertools.product", "dictionary.keys", "map", "dictionary.values"], "function", ["None"], ["", "def", "unpack_dict_of_lists", "(", "dictionary", ")", ":", "\n", "    ", "return", "[", "dict", "(", "zip", "(", "dictionary", ".", "keys", "(", ")", ",", "p", ")", ")", "for", "p", "in", "product", "(", "*", "map", "(", "make_list", ",", "dictionary", ".", "values", "(", ")", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.apply_resize": [[961, 965], ["tensorflow.image.resize", "tensorflow.image.resize", "tensorflow.constant", "tensorflow.shape"], "function", ["None"], ["", "def", "apply_resize", "(", "x", ",", "intermediate_size", ")", ":", "\n", "    ", "intermediate_x", "=", "tf", ".", "image", ".", "resize", "(", "x", ",", "tf", ".", "constant", "(", "[", "intermediate_size", ",", "intermediate_size", "]", ")", ")", "\n", "resized_x", "=", "tf", ".", "image", ".", "resize", "(", "intermediate_x", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", ":", "3", "]", ")", "\n", "return", "resized_x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_f1_score": [[967, 1009], ["tensorflow.cast", "tensorflow.cast", "enumerate", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.count_nonzero", "tensorflow.count_nonzero", "tensorflow.count_nonzero", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "tf_f1_score", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\"Computes 3 different f1 scores, micro macro\n    weighted.\n    micro: f1 score accross the classes, as 1\n    macro: mean of f1 scores per class\n    weighted: weighted average of f1 scores per class,\n            weighted from the support of each class\n\n    from https://stackoverflow.com/questions/45287169/tensorflow-precision-recall-f1-multi-label-classification\n\n    Args:\n        y_true (Tensor): labels, with shape (batch, num_classes)\n        y_pred (Tensor): model's predictions, same shape as y_true\n\n    Returns:\n        tuple(Tensor): (micro, macro, weighted)\n                    tuple of the computed f1 scores\n    \"\"\"", "\n", "\n", "f1s", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "\n", "y_true", "=", "tf", ".", "cast", "(", "y_true", ",", "tf", ".", "float64", ")", "\n", "y_pred", "=", "tf", ".", "cast", "(", "y_pred", ",", "tf", ".", "float64", ")", "\n", "\n", "for", "i", ",", "axis", "in", "enumerate", "(", "[", "None", ",", "0", "]", ")", ":", "\n", "        ", "TP", "=", "tf", ".", "count_nonzero", "(", "y_pred", "*", "y_true", ",", "axis", "=", "axis", ")", "\n", "FP", "=", "tf", ".", "count_nonzero", "(", "y_pred", "*", "(", "y_true", "-", "1", ")", ",", "axis", "=", "axis", ")", "\n", "FN", "=", "tf", ".", "count_nonzero", "(", "(", "y_pred", "-", "1.", ")", "*", "y_true", ",", "axis", "=", "axis", ")", "\n", "\n", "precision", "=", "TP", "/", "(", "TP", "+", "FP", ")", "\n", "recall", "=", "TP", "/", "(", "TP", "+", "FN", ")", "\n", "f1", "=", "2.", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "f1s", "[", "i", "]", "=", "tf", ".", "reduce_mean", "(", "f1", ")", "\n", "\n", "", "weights", "=", "tf", ".", "reduce_sum", "(", "y_true", ",", "axis", "=", "0", ")", "\n", "weights", "/=", "tf", ".", "reduce_sum", "(", "weights", ")", "\n", "\n", "f1s", "[", "2", "]", "=", "tf", ".", "reduce_sum", "(", "f1", "*", "weights", ")", "\n", "\n", "micro", ",", "macro", ",", "weighted", "=", "f1s", "\n", "return", "micro", ",", "macro", ",", "weighted", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.PlotCurves.__init__": [[21, 23], ["AbstractPlot.AbstractPlot.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PlotCurves", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.PlotCurves.rows_columns": [[24, 28], ["len", "numpy.max", "len"], "methods", ["None"], ["", "def", "rows_columns", "(", "self", ",", "panels", ",", "folders_cartesian_fixed", ")", ":", "\n", "        ", "n_columns", "=", "len", "(", "panels", ")", "\n", "n_rows", "=", "np", ".", "max", "(", "[", "len", "(", "p", ")", "for", "p", "in", "panels", "]", ")", "\n", "return", "n_rows", ",", "n_columns", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.PlotCurves.plot_vertical_panel": [[29, 79], ["fig.add_subplot", "AbstractPlot.AbstractPlot.create_list_colors", "len", "len", "len", "sorted", "PlotCurves.PlotCurves.get_colors_pairs", "firstCurve.set_panel_properties", "PlotCurves.PlotCurves.create_label", "argo.core.utils.Curve.Curve", "argo.core.utils.Curve.Curve.create_plot", "list", "group_by_values.values", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_list_colors", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.get_colors_pairs", "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.Curve.set_panel_properties", "home.repos.pwc.inspect_result.rist-ro_argo.utils.AbstractPlot.AbstractPlot.create_label", "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.Curve.create_plot"], ["", "def", "plot_vertical_panel", "(", "self", ",", "\n", "vertical_panels", ",", "\n", "c", ",", "\n", "n_rows", ",", "\n", "n_columns", ",", "\n", "legend", ",", "\n", "fig", ",", "\n", "folders_cartesian_fixed", ",", "\n", "group_by_values", ",", "\n", "source", ",", "\n", "degree", ",", "\n", "string_to_val", ")", ":", "\n", "\n", "        ", "r", "=", "0", "\n", "\n", "for", "panel", "in", "vertical_panels", ":", "\n", "\n", "            ", "ax", "=", "fig", ".", "add_subplot", "(", "n_rows", ",", "n_columns", ",", "r", "*", "n_columns", "+", "c", "+", "1", ")", "\n", "\n", "if", "len", "(", "group_by_values", ")", "==", "0", ":", "\n", "                ", "max_colors", "=", "len", "(", "folders_cartesian_fixed", ")", "\n", "", "else", ":", "\n", "                ", "max_colors", "=", "len", "(", "list", "(", "group_by_values", ".", "values", "(", ")", ")", "[", "0", "]", ")", "\n", "\n", "", "if", "max_colors", "==", "0", ":", "\n", "                ", "max_colors", "=", "1", "\n", "", "list_colors", "=", "create_list_colors", "(", "max_colors", ")", "\n", "\n", "firstCurve", "=", "None", "\n", "\n", "for", "curve", "in", "panel", ":", "\n", "\n", "                ", "folders_cartesian_fixed", "=", "sorted", "(", "folders_cartesian_fixed", ")", "\n", "\n", "for", "marker", ",", "color", ",", "(", "source", ",", "directory", ")", "in", "self", ".", "get_colors_pairs", "(", "folders_cartesian_fixed", ",", "\n", "group_by_values", ")", ":", "\n", "                    ", "label", "=", "self", ".", "create_label", "(", "curve", ",", "directory", ",", "legend", ",", "source", ")", "\n", "cur", "=", "Curve", "(", "directory", "=", "directory", ",", "string_to_val", "=", "string_to_val", ",", "label", "=", "label", ",", "**", "curve", ")", "\n", "\n", "if", "firstCurve", "is", "None", ":", "\n", "                        ", "firstCurve", "=", "cur", "\n", "\n", "", "cur", ".", "create_plot", "(", "markers", "[", "marker", "%", "len", "(", "markers", ")", "]", ",", "list_colors", "[", "color", "]", ",", "ax", ",", "degree", ")", "\n", "\n", "\n", "# sometimes it raises an error, so I added a check (Luigi)", "\n", "", "", "if", "firstCurve", "is", "not", "None", ":", "\n", "                ", "firstCurve", ".", "set_panel_properties", "(", "ax", ")", "\n", "\n", "", "r", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.join_dirs_path": [[80, 82], ["d.replace().replace", "d.replace"], "function", ["None"], ["", "", "", "def", "join_dirs_path", "(", "source", ",", "d", ")", ":", "\n", "    ", "return", "d", ".", "replace", "(", "source", "+", "'/'", ",", "''", ")", ".", "replace", "(", "'//'", ",", "'/'", ")", "# .replace('/','-')", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotCurves.get_value": [[83, 112], ["len", "re.search", "re.search.group", "len", "directory.split", "re.search", "re.search.group", "re.search.group", "len", "directory.split", "re.search", "Exception", "re.search.group", "re.search.group", "re.search.group", "re.search", "re.search.group", "re.search.group"], "function", ["None"], ["", "def", "get_value", "(", "directory", ",", "l", ")", ":", "\n", "    ", "if", "len", "(", "l", ")", "==", "2", ":", "\n", "        ", "(", "param", ",", "name", ")", "=", "l", "\n", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "param", "+", "'([\\._A-Za-z0-9,]+)'", "+", "'(-|$)'", ",", "directory", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "            ", "return", "name", "+", "m", ".", "group", "(", "2", ")", "\n", "", "return", "\"\"", "# \"param not found\"", "\n", "", "elif", "len", "(", "l", ")", "==", "3", ":", "\n", "        ", "(", "param", ",", "i", ",", "name", ")", "=", "l", "\n", "splits", "=", "directory", ".", "split", "(", "'/'", ")", "\n", "#pdb.set_trace()", "\n", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "param", "+", "'([\\._A-Za-z0-9,]+)'", "+", "'(-|$)'", ",", "splits", "[", "i", "]", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "            ", "return", "name", "+", "m", ".", "group", "(", "2", ")", "\n", "", "return", "\"\"", "# \"param not found\"", "\n", "", "elif", "len", "(", "l", ")", "==", "4", ":", "\n", "        ", "(", "param", ",", "subparam", ",", "i", ",", "name", ")", "=", "l", "\n", "splits", "=", "directory", ".", "split", "(", "'/'", ")", "\n", "m", "=", "re", ".", "search", "(", "'(-|^)'", "+", "param", "+", "'([\\._A-Za-z0-9,]+)'", "+", "'(-|$)'", ",", "splits", "[", "i", "]", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "            ", "found", "=", "m", ".", "group", "(", "2", ")", "\n", "m", "=", "re", ".", "search", "(", "'(_)'", "+", "subparam", "+", "'([\\.A-Za-z0-9]+)'", "+", "'(_|$)'", ",", "found", ")", "\n", "if", "m", "and", "m", ".", "group", "(", "2", ")", ":", "\n", "                ", "return", "name", "+", "m", ".", "group", "(", "2", ")", "\n", "", "", "return", "\"\"", "# \"param not found\"", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"The length of the token should be 2 or 3\"", ")", "\n", "\n", "", "return", "\"param not found\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.Curve.__init__": [[16, 110], ["f.read.split", "min", "open", "f.read", "Curve.str2float", "Curve.str2float", "numpy.array", "numpy.array", "numpy.add.accumulate", "numpy.add.accumulate", "len", "len", "print", "print", "print", "print", "row.lstrip().split", "row.lstrip().split", "str", "str", "str", "str", "row.lstrip", "row.lstrip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.str2float", "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.str2float"], ["    ", "def", "__init__", "(", "self", ",", "directory", ",", "\n", "string_to_val", ",", "\n", "label", ",", "\n", "filename", ",", "\n", "x", ",", "\n", "y", ",", "\n", "logscale_x", "=", "0", ",", "\n", "logscale_y", "=", "0", ",", "\n", "accumulate_x", "=", "0", ",", "\n", "accumulate_y", "=", "0", ",", "\n", "smoothing", "=", "0", ",", "\n", "x_label", "=", "\"\"", ",", "\n", "y_label", "=", "None", ",", "\n", "separator", "=", "\"\\t\"", ",", "\n", "min_y", "=", "None", ",", "\n", "min_x", "=", "None", ",", "\n", "max_y", "=", "None", ",", "\n", "max_x", "=", "None", ",", "\n", "scale_x", "=", "1.0", ",", "\n", "scale_y", "=", "1.0", ",", "\n", "mark_every", "=", "25", ",", "\n", "linewidth", "=", "2", ",", "\n", "linestyle", "=", "'-'", ",", "\n", "legend_loc", "=", "\"upper right\"", ",", "\n", "bbox_to_anchor", "=", "None", ",", "\n", "legend_ncol", "=", "1", ",", "\n", "ticks", "=", "None", ",", "\n", "legend", "=", "True", ")", ":", "\n", "        ", "self", ".", "directory", "=", "directory", "\n", "self", ".", "string_to_val", "=", "string_to_val", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "filename", "=", "filename", "\n", "self", ".", "logscale_x", "=", "logscale_x", "\n", "self", ".", "logscale_y", "=", "logscale_y", "\n", "self", ".", "accumulate_x", "=", "accumulate_x", "\n", "self", ".", "accumulate_y", "=", "accumulate_y", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "x_label", "=", "x_label", "\n", "self", ".", "y_label", "=", "y_label", "\n", "self", ".", "separator", "=", "separator", "\n", "self", ".", "min_y", "=", "min_y", "\n", "self", ".", "min_x", "=", "min_x", "\n", "self", ".", "max_y", "=", "max_y", "\n", "self", ".", "max_x", "=", "max_x", "\n", "self", ".", "scale_x", "=", "scale_x", "\n", "self", ".", "scale_y", "=", "scale_y", "\n", "self", ".", "linewidth", "=", "linewidth", "\n", "self", ".", "linestyle", "=", "linestyle", "\n", "self", ".", "legend_loc", "=", "legend_loc", "\n", "self", ".", "bbox_to_anchor", "=", "bbox_to_anchor", "\n", "self", ".", "legend_ncol", "=", "legend_ncol", "\n", "self", ".", "ticks", "=", "ticks", "\n", "self", ".", "legend", "=", "legend", "\n", "\n", "assert", "self", ".", "filename", "is", "not", "None", ",", "\"Filename Can't be empty\"", "\n", "file_path", "=", "self", ".", "directory", "+", "\"/\"", "+", "self", ".", "filename", "\n", "\n", "self", ".", "_plotable", "=", "False", "\n", "\n", "try", ":", "\n", "# read data from file", "\n", "            ", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "                ", "data", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "data", "=", "data", ".", "split", "(", "'\\n'", ")", "\n", "\n", "offset", "=", "1", "\n", "data", "=", "data", "[", "offset", ":", "-", "1", "]", "\n", "\n", "separator", "=", "self", ".", "separator", "\n", "x", "=", "[", "str2float", "(", "row", ".", "lstrip", "(", ")", ".", "split", "(", "separator", ")", "[", "x", "]", ",", "self", ".", "string_to_val", ")", "for", "row", "in", "data", "]", "\n", "y", "=", "[", "str2float", "(", "row", ".", "lstrip", "(", ")", ".", "split", "(", "separator", ")", "[", "y", "]", ",", "self", ".", "string_to_val", ")", "for", "row", "in", "data", "]", "\n", "\n", "self", ".", "x", "=", "self", ".", "scale_x", "*", "np", ".", "array", "(", "x", ")", "\n", "self", ".", "y", "=", "self", ".", "scale_y", "*", "np", ".", "array", "(", "y", ")", "\n", "if", "accumulate_x", "==", "1", ":", "\n", "                ", "self", ".", "x", "=", "np", ".", "add", ".", "accumulate", "(", "self", ".", "x", ")", "\n", "\n", "", "if", "accumulate_y", "==", "1", ":", "\n", "                ", "self", ".", "y", "=", "np", ".", "add", ".", "accumulate", "(", "self", ".", "y", ")", "\n", "\n", "", "self", ".", "mark_every", "=", "min", "(", "len", "(", "self", ".", "y", ")", ",", "mark_every", ")", "# int(len(y) / 20)", "\n", "\n", "assert", "(", "len", "(", "self", ".", "y", ")", ">", "1", ")", ",", "\"Not enough data to plot\"", "\n", "self", ".", "_plotable", "=", "True", "\n", "\n", "", "except", "FileNotFoundError", "as", "e", ":", "\n", "            ", "print", "(", "\"FileNotFoundError cannot read file \"", "+", "file_path", "+", "\" \"", "+", "str", "(", "e", ")", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "print", "(", "\"AssertionError file is empty \"", "+", "file_path", "+", "\" \"", "+", "str", "(", "e", ")", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "print", "(", "\"ValueError cannot read file \"", "+", "file_path", "+", "\" \"", "+", "str", "(", "e", ")", ")", "\n", "", "except", "IndexError", "as", "e", ":", "\n", "            ", "print", "(", "\"IndexError cannot read file \"", "+", "file_path", "+", "\" \"", "+", "str", "(", "e", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.Curve.create_plot": [[113, 137], ["ax.set_xscale", "Curve.smoothTriangle", "plot_function", "plot_function", "plot_function"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.smoothTriangle"], ["", "", "def", "create_plot", "(", "self", ",", "marker", ",", "color", ",", "ax", ",", "degree", ")", ":", "\n", "\n", "        ", "if", "self", ".", "_plotable", ":", "\n", "\n", "            ", "if", "self", ".", "logscale_x", "!=", "0", ":", "\n", "                ", "ax", ".", "set_xscale", "(", "'log'", ")", "\n", "\n", "", "if", "self", ".", "logscale_y", "!=", "0", ":", "\n", "                ", "plot_function", "=", "ax", ".", "semilogy", "\n", "", "else", ":", "\n", "                ", "plot_function", "=", "ax", ".", "plot", "\n", "\n", "", "if", "self", ".", "smoothing", "!=", "0", ":", "\n", "# see https://stackoverflow.com/questions/20618804/how-to-smooth-a-curve-in-the-right-way", "\n", "                ", "y_smooth", "=", "smoothTriangle", "(", "self", ".", "y", ",", "degree", ")", "# window size 51, polynomial order 3", "\n", "plot_function", "(", "self", ".", "x", ",", "y_smooth", ",", "self", ".", "linestyle", ",", "c", "=", "color", ",", "\n", "label", "=", "self", ".", "label", ",", "marker", "=", "marker", ",", "markevery", "=", "self", ".", "mark_every", ",", "\n", "markersize", "=", "10", ",", "linewidth", "=", "self", ".", "linewidth", ")", "\n", "plot_function", "(", "self", ".", "x", ",", "self", ".", "y", ",", "self", ".", "linestyle", ",", "c", "=", "color", ",", "alpha", "=", "0.3", ",", "\n", "linewidth", "=", "self", ".", "linewidth", ")", "\n", "", "else", ":", "\n", "                ", "plot_function", "(", "self", ".", "x", ",", "self", ".", "y", ",", "self", ".", "linestyle", ",", "c", "=", "color", ",", "label", "=", "self", ".", "label", ",", "\n", "marker", "=", "marker", ",", "markevery", "=", "self", ".", "mark_every", ",", "markersize", "=", "10", ",", "\n", "linewidth", "=", "self", ".", "linewidth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.Curve.set_panel_properties": [[138, 193], ["ax.set_xlim", "ax.set_xlim", "ax.set_ylim", "ax.set_ylim", "ax.set_xlabel", "ax.set_ylabel", "xticks_spec.get", "xticks_spec.get", "xticks_spec.get", "ax.set_xticks", "matplotlib.ticker.AutoMinorLocator", "ax.xaxis.set_minor_locator", "yticks_spec.get", "yticks_spec.get", "yticks_spec.get", "ax.set_yticks", "matplotlib.ticker.AutoMinorLocator", "ax.yaxis.set_minor_locator", "ax.set_axisbelow", "Curve.Curve.ticks.get", "Curve.Curve.ticks.get", "Curve.Curve.get", "Curve.Curve.get", "Curve.Curve.get", "ax.grid", "Curve.Curve.get", "Curve.Curve.get", "Curve.Curve.get", "ax.grid", "ax.grid", "ax.legend", "ax.legend", "numpy.arange", "numpy.arange"], "methods", ["None"], ["", "", "", "def", "set_panel_properties", "(", "self", ",", "ax", ")", ":", "\n", "# first curve of the panel", "\n", "\n", "        ", "ax", ".", "set_xlim", "(", "left", "=", "self", ".", "min_x", ")", "\n", "ax", ".", "set_xlim", "(", "right", "=", "self", ".", "max_x", ")", "\n", "\n", "ax", ".", "set_ylim", "(", "bottom", "=", "self", ".", "min_y", ")", "\n", "ax", ".", "set_ylim", "(", "top", "=", "self", ".", "max_y", ")", "\n", "\n", "ax", ".", "set_xlabel", "(", "self", ".", "x_label", ")", "\n", "ax", ".", "set_ylabel", "(", "self", ".", "y_label", ")", "\n", "\n", "# Options for legend_loc", "\n", "# 'best', 'upper right', 'upper left', 'lower left', 'lower right',", "\n", "# 'right', 'center left', 'center right', 'lower center', 'upper center', 'center'", "\n", "if", "self", ".", "legend", ":", "\n", "            ", "if", "self", ".", "bbox_to_anchor", "is", "None", ":", "\n", "                ", "lgd", "=", "ax", ".", "legend", "(", "loc", "=", "self", ".", "legend_loc", ",", "ncol", "=", "self", ".", "legend_ncol", ")", "\n", "", "else", ":", "\n", "                ", "lgd", "=", "ax", ".", "legend", "(", "loc", "=", "self", ".", "legend_loc", ",", "bbox_to_anchor", "=", "self", ".", "bbox_to_anchor", ",", "ncol", "=", "self", ".", "legend_ncol", ")", "\n", "\n", "", "", "if", "self", ".", "ticks", "is", "not", "None", ":", "\n", "            ", "xticks_spec", "=", "self", ".", "ticks", "[", "'x'", "]", "\n", "xstep", "=", "xticks_spec", ".", "get", "(", "'step'", ",", "1", ")", "\n", "xceil", "=", "xticks_spec", ".", "get", "(", "'ceil'", ",", "1", ")", "\n", "xnminor", "=", "xticks_spec", ".", "get", "(", "'nminor'", ",", "0", ")", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "self", ".", "min_x", ",", "self", ".", "max_x", "+", "xceil", ",", "xstep", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "xnminor", ")", "\n", "ax", ".", "xaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "\n", "yticks_spec", "=", "self", ".", "ticks", "[", "'y'", "]", "\n", "ystep", "=", "yticks_spec", ".", "get", "(", "'step'", ",", "1", ")", "\n", "yceil", "=", "yticks_spec", ".", "get", "(", "'ceil'", ",", "1", ")", "\n", "ynminor", "=", "yticks_spec", ".", "get", "(", "'nminor'", ",", "0", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "self", ".", "min_y", ",", "self", ".", "max_y", "+", "yceil", ",", "ystep", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "ynminor", ")", "\n", "ax", ".", "yaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "\n", "ax", ".", "set_axisbelow", "(", "True", ")", "\n", "\n", "major_lines", "=", "self", ".", "ticks", ".", "get", "(", "\"major\"", ",", "{", "}", ")", "\n", "minor_lines", "=", "self", ".", "ticks", ".", "get", "(", "\"minor\"", ",", "{", "}", ")", "\n", "\n", "lnst", "=", "major_lines", ".", "get", "(", "'linestyle'", ",", "'--'", ")", "\n", "lnw", "=", "major_lines", ".", "get", "(", "'linewidth'", ",", "1", ")", "\n", "lnc", "=", "major_lines", ".", "get", "(", "'color'", ",", "'lightgray'", ")", "\n", "ax", ".", "grid", "(", "which", "=", "'major'", ",", "linestyle", "=", "lnst", ",", "linewidth", "=", "lnw", ",", "color", "=", "lnc", ")", "\n", "\n", "lnst", "=", "minor_lines", ".", "get", "(", "'linestyle'", ",", "'--'", ")", "\n", "lnw", "=", "minor_lines", ".", "get", "(", "'linewidth'", ",", "1", ")", "\n", "lnc", "=", "minor_lines", ".", "get", "(", "'color'", ",", "'lightgray'", ")", "\n", "ax", ".", "grid", "(", "which", "=", "'minor'", ",", "linestyle", "=", "lnst", ",", "linewidth", "=", "lnw", ",", "color", "=", "lnc", ")", "\n", "\n", "", "else", ":", "\n", "            ", "ax", ".", "grid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.str2float": [[5, 12], ["float"], "function", ["None"], ["def", "str2float", "(", "s", ",", "string_to_val", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "val", "=", "string_to_val", "[", "s", "]", "\n", "", "except", ":", "\n", "        ", "val", "=", "float", "(", "s", ")", "\n", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.Curve.smoothTriangle": [[196, 213], ["range", "numpy.array", "smoothed.append", "len", "len", "smoothed.append", "len", "int", "range", "zip", "sum", "sum", "list", "list", "range", "range", "len"], "function", ["None"], ["", "", "", "def", "smoothTriangle", "(", "data", ",", "degree", ",", "dropVals", "=", "False", ")", ":", "\n", "    ", "\"\"\"performs moving triangle smoothing with a variable degree.\"\"\"", "\n", "\"\"\"note that if dropVals is False, output length will be identical\n    to input length, but with copies of data at the flanking regions\"\"\"", "\n", "triangle", "=", "np", ".", "array", "(", "list", "(", "range", "(", "degree", ")", ")", "+", "[", "degree", "]", "+", "list", "(", "range", "(", "degree", ")", ")", "[", ":", ":", "-", "1", "]", ")", "+", "1", "\n", "smoothed", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "degree", ",", "len", "(", "data", ")", "-", "degree", "*", "2", ")", ":", "\n", "        ", "point", "=", "data", "[", "i", ":", "i", "+", "len", "(", "triangle", ")", "]", "*", "triangle", "\n", "smoothed", ".", "append", "(", "sum", "(", "point", ")", "/", "sum", "(", "triangle", ")", ")", "\n", "", "if", "dropVals", ":", "return", "smoothed", "\n", "smoothed", "=", "[", "smoothed", "[", "0", "]", "]", "*", "int", "(", "degree", "+", "degree", "/", "2", ")", "+", "smoothed", "\n", "while", "len", "(", "smoothed", ")", "<", "len", "(", "data", ")", ":", "smoothed", ".", "append", "(", "smoothed", "[", "-", "1", "]", ")", "\n", "\n", "# some refinement", "\n", "alphas", "=", "[", "alpha", "/", "degree", "/", "2", "for", "alpha", "in", "range", "(", "degree", "*", "2", ")", "]", "\n", "smoothed", "[", ":", "degree", "*", "2", "]", "=", "[", "a", "*", "s", "+", "(", "1", "-", "a", ")", "*", "d", "for", "a", ",", "s", ",", "d", "in", "zip", "(", "alphas", ",", "smoothed", "[", ":", "degree", "*", "2", "]", ",", "data", "[", ":", "degree", "*", "2", "]", ")", "]", "\n", "return", "smoothed", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table.read_row_max": [[29, 33], ["pandas.read_csv", "df[].idxmax", "list", "numpy.array"], "function", ["None"], ["def", "read_row_max", "(", "path", ",", "field", ",", "columns", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "path", ",", "**", "pd_csv_kwargs", ")", "\n", "imax", "=", "df", "[", "field", "]", ".", "idxmax", "(", ")", "\n", "return", "list", "(", "np", ".", "array", "(", "df", "[", "columns", "]", ".", "loc", "[", "imax", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table._isclose": [[34, 39], ["isinstance", "isinstance", "numpy.isclose"], "function", ["None"], ["", "def", "_isclose", "(", "x", ",", "val", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "float", ")", "and", "isinstance", "(", "val", ",", "float", ")", ":", "\n", "        ", "return", "np", ".", "isclose", "(", "x", ",", "val", ",", "atol", "=", "1e-8", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", "==", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table.read_ref_row": [[40, 51], ["pandas.read_csv", "list", "ValueError", "Exception", "numpy.array", "numpy.array", "collect_table._isclose"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table._isclose"], ["", "", "def", "read_ref_row", "(", "path", ",", "field", ",", "value", ",", "columns", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "path", ",", "**", "pd_csv_kwargs", ")", "\n", "ref_df", "=", "df", ".", "loc", "[", "np", ".", "array", "(", "[", "_isclose", "(", "x", ",", "value", ")", "for", "x", "in", "df", "[", "field", "]", "]", ",", "dtype", "=", "bool", ")", "]", "\n", "\n", "if", "ref_df", ".", "empty", ":", "\n", "        ", "raise", "ValueError", "(", "\"Could not find reference value `{:}={:}` in file `{:}`\"", ".", "format", "(", "field", ",", "value", ",", "path", ")", ")", "\n", "\n", "#if not empty", "\n", "", "if", "ref_df", ".", "shape", "[", "0", "]", ">", "1", ":", "\n", "        ", "raise", "Exception", "(", "'found more than one reference {:}'", ".", "format", "(", "df", ")", ")", "\n", "", "return", "list", "(", "np", ".", "array", "(", "ref_df", "[", "columns", "]", ".", "iloc", "[", "0", "]", ".", "array", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table.collect_table_across_ds": [[67, 111], ["os.makedirs", "numpy.array", "conf.get", "itertools.product", "sorted", "pandas.DataFrame", "os.path.join", "pd.DataFrame.to_csv", "glob.glob", "os.path.join", "len", "ValueError", "collect_table.read_row_max", "data.append", "match.split", "collect_table.read_ref_row", "os.path.join", "numpy.array", "len", "data.append", "ds_name.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table.read_row_max", "home.repos.pwc.inspect_result.rist-ro_argo.utils.collect_table.read_ref_row"], ["", "def", "collect_table_across_ds", "(", "base_dir", ",", "ds_dirs", ",", "net_dirs", ",", "tables", ",", "outdirname", "=", "\".\"", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "outdirname", ",", "exist_ok", "=", "True", ")", "\n", "ds_idxs", "=", "np", ".", "array", "(", "[", "2", ",", "5", ",", "6", ",", "7", "]", ")", "\n", "\n", "for", "table_name", "in", "tables", ":", "\n", "        ", "conf", "=", "tables", "[", "table_name", "]", "\n", "log_file", "=", "conf", "[", "'log_file'", "]", "\n", "target_col", "=", "conf", "[", "'target_col'", "]", "\n", "extra_columns", "=", "conf", "[", "'extra_columns'", "]", "\n", "ref_field", ",", "ref_value", "=", "conf", ".", "get", "(", "'reference'", ",", "(", "None", ",", "None", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "col_name_train", "=", "target_col", "+", "'_train'", "\n", "col_name_val", "=", "target_col", "+", "'_validation'", "\n", "col_name_test", "=", "target_col", "+", "'_test'", "\n", "\n", "columns_to_return", "=", "[", "col_name_train", ",", "col_name_val", ",", "col_name_test", "]", "+", "extra_columns", "\n", "\n", "for", "ds_dir", ",", "net_dir", "in", "product", "(", "ds_dirs", ",", "net_dirs", ")", ":", "\n", "\n", "            ", "dir_list", "=", "[", "base_dir", ",", "ds_dir", ",", "net_dir", ",", "log_file", "]", "\n", "matches", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", "\n", "if", "len", "(", "matches", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"No file found matching the provided regexpr: `{:}`\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "*", "dir_list", ")", ")", ")", "\n", "\n", "\n", "", "for", "match", "in", "matches", ":", "\n", "                ", "ds_level", "=", "-", "3", "\n", "ds_name", "=", "match", ".", "split", "(", "'/'", ")", "[", "ds_level", "]", "\n", "ds_name", "=", "'-'", ".", "join", "(", "np", ".", "array", "(", "ds_name", ".", "split", "(", "'-'", ")", ")", "[", "ds_idxs", "]", ")", "\n", "data_row", "=", "read_row_max", "(", "match", ",", "col_name_val", ",", "columns_to_return", ")", "\n", "data", ".", "append", "(", "[", "ds_name", "]", "+", "data_row", ")", "\n", "\n", "if", "ref_field", "is", "not", "None", ":", "\n", "                    ", "ref_row", "=", "read_ref_row", "(", "match", ",", "ref_field", ",", "ref_value", ",", "columns_to_return", ")", "\n", "if", "len", "(", "ref_row", ")", ">", "0", ":", "\n", "                        ", "data", ".", "append", "(", "[", "ds_name", "]", "+", "ref_row", ")", "\n", "\n", "", "", "", "", "sorted_data", "=", "sorted", "(", "data", ")", "\n", "\n", "all_fields", "=", "[", "'ds'", "]", "+", "columns_to_return", "\n", "df", "=", "pd", ".", "DataFrame", "(", "sorted_data", ",", "columns", "=", "all_fields", ")", "\n", "outputname", "=", "os", ".", "path", ".", "join", "(", "outdirname", ",", "table_name", "+", "\"_\"", "+", "target_col", "+", "\".txt\"", ")", "\n", "df", ".", "to_csv", "(", "outputname", ",", "index", "=", "False", ",", "float_format", "=", "'%.6g'", ",", "**", "pd_csv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianResNet.BayesianResNet.__init__": [[9, 55], ["ArgoKerasModel.ArgoKerasModel.__init__", "range", "tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.Flatten", "keras_utils.get_renorm_clipping", "len", "BayesianResNet.ResnetBlock", "BayesianResNet.BayesianResNet.blocks_list.append", "Dense"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["def", "__init__", "(", "self", ",", "\n", "filters", "=", "[", "16", ",", "16", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "renorm", "=", "False", ",", "\n", "activation", "=", "(", "'relu'", ",", "{", "}", ")", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'bayesian_vgg'", ")", "\n", "self", ".", "_activation_tuple", "=", "activation", "\n", "\n", "if", "flipout", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "            ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "", "self", ".", "blocks_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "kernels", ")", ")", ":", "\n", "            ", "block", "=", "ResnetBlock", "(", "Conv2D", ",", "\n", "filters", "[", "i", "]", ",", "\n", "kernels", "[", "i", "]", ",", "\n", "strides", "[", "i", "]", ",", "\n", "renorm", ",", "\n", "renorm_clipping", ",", "\n", "activation_tuple", "=", "activation", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "block", ")", "\n", "\n", "", "self", ".", "_pooling", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "(", "2", ",", "1", ")", "\n", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "# if logits_size is specified I add an extra Dense layer", "\n", "self", ".", "_last_dense", "=", "None", "\n", "if", "logits_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "_last_dense", "=", "Dense", "(", "\n", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianResNet.BayesianResNet.call": [[57, 69], ["BayesianResNet.BayesianResNet._pooling", "BayesianResNet.BayesianResNet._flat", "block", "BayesianResNet.BayesianResNet._last_dense"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "net", "=", "inputs", "\n", "for", "block", "in", "self", ".", "blocks_list", ":", "\n", "            ", "net", "=", "block", "(", "net", ",", "training", "=", "training", ")", "\n", "\n", "", "net", "=", "self", ".", "_pooling", "(", "net", ")", "\n", "net", "=", "self", ".", "_flat", "(", "net", ")", "\n", "\n", "if", "self", ".", "_last_dense", ":", "\n", "            ", "net", "=", "self", ".", "_last_dense", "(", "net", ")", "\n", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianResNet.ResnetBlock.__init__": [[73, 112], ["super().__init__", "Conv2D", "tensorflow.keras.layers.BatchNormalization", "keras_utils.get_keras_activation", "Conv2D", "tensorflow.keras.layers.BatchNormalization", "keras_utils.get_keras_activation", "Conv2D", "keras_utils.get_keras_activation", "tensorflow.keras.layers.BatchNormalization"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_keras_activation", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_keras_activation", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_keras_activation"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "filters", ",", "kernel", ",", "stride", ",", "\n", "renorm", ",", "renorm_clipping", ",", "\n", "activation_tuple", "=", "(", "'relu'", ",", "{", "}", ")", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'resnet_block'", ")", "\n", "\n", "self", ".", "conv2a", "=", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "bn2a", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "self", ".", "_act2a", "=", "get_keras_activation", "(", "activation_tuple", ")", "\n", "\n", "self", ".", "conv2b", "=", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "stride", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "bn2b", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "self", ".", "_act2b", "=", "get_keras_activation", "(", "activation_tuple", ")", "\n", "# self.conv2c = None", "\n", "# if stride>1:", "\n", "self", ".", "conv2c", "=", "Conv2D", "(", "filters", ",", "\n", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "stride", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "_act2c", "=", "None", "\n", "if", "final_activation", ":", "\n", "            ", "self", ".", "_act2c", "=", "get_keras_activation", "(", "activation_tuple", ")", "\n", "self", ".", "bn2c", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianResNet.ResnetBlock.call": [[113, 132], ["BayesianResNet.ResnetBlock.conv2a", "BayesianResNet.ResnetBlock.bn2a", "BayesianResNet.ResnetBlock._act2a", "BayesianResNet.ResnetBlock.conv2b", "BayesianResNet.ResnetBlock.bn2b", "BayesianResNet.ResnetBlock._act2b", "BayesianResNet.ResnetBlock.conv2c", "BayesianResNet.ResnetBlock.bn2c", "BayesianResNet.ResnetBlock._act2c"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv2a", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "bn2a", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "_act2a", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2b", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2b", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "_act2b", "(", "x", ")", "\n", "\n", "# if self.conv2c:", "\n", "x_sh", "=", "self", ".", "conv2c", "(", "input_tensor", ")", "\n", "# else:", "\n", "#     x_sh = input_tensor", "\n", "\n", "output", "=", "x", "+", "x_sh", "\n", "if", "self", ".", "_act2c", ":", "\n", "            ", "output", "=", "self", ".", "bn2c", "(", "output", ",", "training", "=", "training", ")", "\n", "output", "=", "self", ".", "_act2c", "(", "output", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.name_net.name_net": [[4, 15], ["tensorflow.keras.Sequential", "last_layer_kwargs.update", "name_net.maybe_update", "keras_utils.parse_layer", "tf.keras.Sequential.add"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.keras_models.name_net.maybe_update", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.parse_layer"], ["def", "name_net", "(", "output_size", ",", "keras_layers_list", ",", "layer_kwargs", "=", "{", "}", ",", "layer_kwargs_bayes", "=", "{", "}", ",", "name", "=", "\"\"", ")", ":", "\n", "    ", "model", "=", "tf", ".", "keras", ".", "Sequential", "(", "[", "]", ")", "\n", "last_layer_kwargs", "=", "keras_layers_list", "[", "-", "1", "]", "[", "1", "]", "\n", "last_layer_kwargs", ".", "update", "(", "{", "\"units\"", ":", "output_size", "}", ")", "\n", "\n", "for", "layer_tuple", "in", "keras_layers_list", ":", "\n", "        ", "maybe_update", "(", "layer_tuple", ",", "layer_kwargs", ")", "\n", "layer", "=", "parse_layer", "(", "layer_tuple", ")", "\n", "model", ".", "add", "(", "layer", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.name_net.maybe_update": [[16, 23], ["layer_tuple[].update", "layer_tuple[].split"], "function", ["None"], ["", "def", "maybe_update", "(", "layer_tuple", ",", "layer_kwargs", ")", ":", "\n", "    ", "layer_name", "=", "layer_tuple", "[", "0", "]", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "\n", "if", "layer_name", "in", "[", "'Dropout'", ",", "'Flatten'", ",", "'BatchNormalization'", "]", "or", "\"Pool\"", "in", "layer_name", ":", "\n", "        ", "return", "\n", "\n", "", "layer_tuple", "[", "1", "]", ".", "update", "(", "layer_kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic.BayesianInception_Basic.__init__": [[9, 74], ["super().__init__", "range", "tensorflow.keras.layers.Flatten", "ValueError", "keras_utils.get_renorm_clipping", "len", "BayesianInception_Basic.Module_Inception", "BayesianInception_Basic.BayesianInception_Basic.blocks_list.append", "Dense"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["def", "__init__", "(", "self", ",", "\n", "filters_1x1", "=", "[", "16", ",", "16", ",", "16", ",", "32", "]", ",", "\n", "filters_3x3_reduce", "=", "[", "32", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "filters_3x3", "=", "[", "64", ",", "64", ",", "64", ",", "64", "]", ",", "\n", "filters_5x5_reduce", "=", "[", "16", ",", "16", ",", "16", ",", "32", "]", ",", "\n", "filters_5x5", "=", "[", "32", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "filters_pool_proj", "=", "[", "32", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "renorm", "=", "False", ",", "\n", "pooling", "=", "\"avg\"", ",", "\n", "activation", "=", "(", "'relu'", ",", "{", "}", ")", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'bayesian_inception_basic'", ")", "\n", "activation_name", ",", "activation_kwargs", "=", "activation", "\n", "\n", "if", "flipout", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "            ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "pooling", "==", "\"max\"", ":", "\n", "            ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPooling2D", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "            ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "            ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "\n", "", "self", ".", "blocks_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "filters_1x1", ")", ")", ":", "\n", "            ", "block", "=", "Module_Inception", "(", "Conv2D", ",", "\n", "filters_1x1", "[", "i", "]", ",", "\n", "filters_3x3_reduce", "[", "i", "]", ",", "\n", "filters_3x3", "[", "i", "]", ",", "\n", "filters_5x5_reduce", "[", "i", "]", ",", "\n", "filters_5x5", "[", "i", "]", ",", "\n", "filters_pool_proj", "[", "i", "]", ",", "\n", "strides", "[", "i", "]", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "block", ")", "\n", "\n", "", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "#        self._drop=tf.keras.layers.SpatialDropout2D(rate=0.5)", "\n", "self", ".", "_last_dense", "=", "None", "\n", "if", "logits_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "_last_dense", "=", "Dense", "(", "\n", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic.BayesianInception_Basic.call": [[75, 85], ["BayesianInception_Basic.BayesianInception_Basic._flat", "block", "BayesianInception_Basic.BayesianInception_Basic._last_dense"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "net", "=", "inputs", "\n", "for", "block", "in", "self", ".", "blocks_list", ":", "\n", "            ", "net", "=", "block", "(", "net", ",", "training", "=", "training", ")", "\n", "#        net = self._pooling(net)", "\n", "#        net = self._drop(net,training=training)", "\n", "", "net", "=", "self", ".", "_flat", "(", "net", ")", "\n", "if", "self", ".", "_last_dense", ":", "\n", "            ", "net", "=", "self", ".", "_last_dense", "(", "net", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic.Module_Inception.__init__": [[89, 144], ["super().__init__", "BayesianInception_Basic.Module_Inception.__init__.conv2d_"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "filters_1x1", ",", "\n", "filters_3x3_reduce", ",", "\n", "filters_3x3", ",", "\n", "filters_5x5_reduce", ",", "\n", "filters_5x5", ",", "\n", "filters_pool_proj", ",", "\n", "strides", ",", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'Module_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "pooling", ",", "stride", ",", "padding", "=", "'same'", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride", ",", "padding", "=", "padding", ")", "\n", "\n", "", "self", ".", "_conv1a", "=", "conv2d_", "(", "filters", "=", "filters_1x1", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch1a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act1a", "=", "act", "(", ")", "\n", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "filters_3x3_reduce", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "filters_3x3", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv3a", "=", "conv2d_", "(", "filters", "=", "filters_5x5_reduce", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch3a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act3a", "=", "act", "(", ")", "\n", "self", ".", "_conv3b", "=", "conv2d_", "(", "filters", "=", "filters_5x5", ",", "num_row", "=", "5", ",", "num_col", "=", "5", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch3b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act3b", "=", "act", "(", ")", "\n", "self", ".", "_pool_4a", "=", "pool_apply", "(", "2", ",", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_conv4a", "=", "conv2d_", "(", "filters", "=", "filters_pool_proj", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch4a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act4a", "=", "act", "(", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "self", ".", "_pool_5a", "=", "pool_apply", "(", "2", ",", "strides", ",", "padding", "=", "'same'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic.Module_Inception.call": [[145, 169], ["BayesianInception_Basic.Module_Inception._conv1a", "BayesianInception_Basic.Module_Inception._act1a", "BayesianInception_Basic.Module_Inception._conv2a", "BayesianInception_Basic.Module_Inception._act2a", "BayesianInception_Basic.Module_Inception._conv2b", "BayesianInception_Basic.Module_Inception._act2b", "BayesianInception_Basic.Module_Inception._conv3a", "BayesianInception_Basic.Module_Inception._act3a", "BayesianInception_Basic.Module_Inception._conv3b", "BayesianInception_Basic.Module_Inception._act3b", "BayesianInception_Basic.Module_Inception._pool_4a", "BayesianInception_Basic.Module_Inception._conv4a", "BayesianInception_Basic.Module_Inception._act4a", "BayesianInception_Basic.Module_Inception._concatenate_a", "BayesianInception_Basic.Module_Inception._pool_5a", "BayesianInception_Basic.Module_Inception._batch1a", "BayesianInception_Basic.Module_Inception._batch2a", "BayesianInception_Basic.Module_Inception._batch2b", "BayesianInception_Basic.Module_Inception._batch3a", "BayesianInception_Basic.Module_Inception._batch3b", "BayesianInception_Basic.Module_Inception._batch4a"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "\n", "        ", "branch1", "=", "self", ".", "_conv1a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act1a", "(", "self", ".", "_batch1a", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch2", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch2", "=", "self", ".", "_act2a", "(", "self", ".", "_batch2a", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2b", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2b", "(", "self", ".", "_batch2b", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "\n", "\n", "branch3", "=", "self", ".", "_conv3a", "(", "input_tensor", ")", "\n", "branch3", "=", "self", ".", "_act3a", "(", "self", ".", "_batch3a", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "branch3", "=", "self", ".", "_conv3b", "(", "branch3", ")", "\n", "branch3", "=", "self", ".", "_act3b", "(", "self", ".", "_batch3b", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch4", "=", "self", ".", "_pool_4a", "(", "input_tensor", ")", "\n", "branch4", "=", "self", ".", "_conv4a", "(", "branch4", ")", "\n", "branch4", "=", "self", ".", "_act4a", "(", "self", ".", "_batch4a", "(", "branch4", ",", "training", "=", "training", ")", ")", "\n", "\n", "\n", "branch_T", "=", "self", ".", "_concatenate_a", "(", "[", "branch1", ",", "branch2", ",", "branch3", ",", "branch4", "]", ")", "\n", "branch_T", "=", "self", ".", "_pool_5a", "(", "branch_T", ")", "\n", "return", "branch_T", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic_residual.BayesianInception_Basic_residual.__init__": [[9, 74], ["super().__init__", "range", "tensorflow.keras.layers.Flatten", "ValueError", "keras_utils.get_renorm_clipping", "len", "BayesianInception_Basic_residual.Module_Inception", "BayesianInception_Basic_residual.BayesianInception_Basic_residual.blocks_list.append", "Dense"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["def", "__init__", "(", "self", ",", "\n", "filters_1x1", "=", "[", "16", ",", "16", ",", "16", ",", "32", "]", ",", "\n", "filters_3x3_reduce", "=", "[", "32", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "filters_3x3", "=", "[", "64", ",", "64", ",", "64", ",", "64", "]", ",", "\n", "filters_5x5_reduce", "=", "[", "16", ",", "16", ",", "16", ",", "32", "]", ",", "\n", "filters_5x5", "=", "[", "32", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "filters_pool_proj", "=", "[", "32", ",", "32", ",", "32", ",", "32", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "renorm", "=", "False", ",", "\n", "pooling", "=", "\"avg\"", ",", "\n", "activation", "=", "(", "'relu'", ",", "{", "}", ")", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'bayesian_inception_basic_res'", ")", "\n", "activation_name", ",", "activation_kwargs", "=", "activation", "\n", "\n", "if", "flipout", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "            ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "pooling", "==", "\"max\"", ":", "\n", "            ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPooling2D", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "            ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "            ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "\n", "", "self", ".", "blocks_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "filters_1x1", ")", ")", ":", "\n", "            ", "block", "=", "Module_Inception", "(", "Conv2D", ",", "\n", "filters_1x1", "[", "i", "]", ",", "\n", "filters_3x3_reduce", "[", "i", "]", ",", "\n", "filters_3x3", "[", "i", "]", ",", "\n", "filters_5x5_reduce", "[", "i", "]", ",", "\n", "filters_5x5", "[", "i", "]", ",", "\n", "filters_pool_proj", "[", "i", "]", ",", "\n", "strides", "[", "i", "]", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "block", ")", "\n", "\n", "", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "#        self._drop=tf.keras.layers.SpatialDropout2D(rate=0.5)", "\n", "self", ".", "_last_dense", "=", "None", "\n", "if", "logits_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "_last_dense", "=", "Dense", "(", "\n", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic_residual.BayesianInception_Basic_residual.call": [[75, 85], ["BayesianInception_Basic_residual.BayesianInception_Basic_residual._flat", "block", "BayesianInception_Basic_residual.BayesianInception_Basic_residual._last_dense"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "net", "=", "inputs", "\n", "for", "block", "in", "self", ".", "blocks_list", ":", "\n", "            ", "net", "=", "block", "(", "net", ",", "training", "=", "training", ")", "\n", "#        net = self._pooling(net)", "\n", "#        net = self._drop(net,training=training)", "\n", "", "net", "=", "self", ".", "_flat", "(", "net", ")", "\n", "if", "self", ".", "_last_dense", ":", "\n", "            ", "net", "=", "self", ".", "_last_dense", "(", "net", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic_residual.Module_Inception.__init__": [[89, 144], ["super().__init__", "BayesianInception_Basic_residual.Module_Inception.__init__.conv2d_"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "filters_1x1", ",", "\n", "filters_3x3_reduce", ",", "\n", "filters_3x3", ",", "\n", "filters_5x5_reduce", ",", "\n", "filters_5x5", ",", "\n", "filters_pool_proj", ",", "\n", "strides", ",", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'Module_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "pooling", ",", "stride", ",", "padding", "=", "'same'", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride", ",", "padding", "=", "padding", ")", "\n", "\n", "", "self", ".", "_conv1a", "=", "conv2d_", "(", "filters", "=", "filters_1x1", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch1a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act1a", "=", "act", "(", ")", "\n", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "filters_3x3_reduce", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "filters_3x3", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv3a", "=", "conv2d_", "(", "filters", "=", "filters_5x5_reduce", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch3a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act3a", "=", "act", "(", ")", "\n", "self", ".", "_conv3b", "=", "conv2d_", "(", "filters", "=", "filters_5x5", ",", "num_row", "=", "5", ",", "num_col", "=", "5", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch3b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act3b", "=", "act", "(", ")", "\n", "self", ".", "_pool_4a", "=", "pool_apply", "(", "2", ",", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_conv4a", "=", "conv2d_", "(", "filters", "=", "filters_pool_proj", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "_batch4a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act4a", "=", "act", "(", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "self", ".", "_pool_5a", "=", "pool_apply", "(", "2", ",", "strides", ",", "padding", "=", "'same'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception_Basic_residual.Module_Inception.call": [[145, 170], ["BayesianInception_Basic_residual.Module_Inception._conv1a", "BayesianInception_Basic_residual.Module_Inception._act1a", "BayesianInception_Basic_residual.Module_Inception._conv2a", "BayesianInception_Basic_residual.Module_Inception._act2a", "BayesianInception_Basic_residual.Module_Inception._conv2b", "BayesianInception_Basic_residual.Module_Inception._act2b", "BayesianInception_Basic_residual.Module_Inception._conv3a", "BayesianInception_Basic_residual.Module_Inception._act3a", "BayesianInception_Basic_residual.Module_Inception._conv3b", "BayesianInception_Basic_residual.Module_Inception._act3b", "BayesianInception_Basic_residual.Module_Inception._pool_4a", "BayesianInception_Basic_residual.Module_Inception._conv4a", "BayesianInception_Basic_residual.Module_Inception._act4a", "BayesianInception_Basic_residual.Module_Inception._concatenate_a", "BayesianInception_Basic_residual.Module_Inception._batch1a", "BayesianInception_Basic_residual.Module_Inception._pool_5a"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "\n", "        ", "branch1", "=", "self", ".", "_conv1a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act1a", "(", "branch1", ")", "#self._batch1a(branch1, training=training))", "\n", "\n", "branch2", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch2", "=", "self", ".", "_act2a", "(", "branch2", ")", "#self._batch2a(branch2,training=training))", "\n", "branch2", "=", "self", ".", "_conv2b", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2b", "(", "branch2", ")", "#self._batch2b(branch2,training=training))", "\n", "\n", "\n", "branch3", "=", "self", ".", "_conv3a", "(", "input_tensor", ")", "\n", "branch3", "=", "self", ".", "_act3a", "(", "branch3", ")", "#self._batch3a(branch3,training=training))", "\n", "branch3", "=", "self", ".", "_conv3b", "(", "branch3", ")", "\n", "branch3", "=", "self", ".", "_act3b", "(", "branch3", ")", "#self._batch3b(branch3,training=training))", "\n", "\n", "branch4", "=", "self", ".", "_pool_4a", "(", "input_tensor", ")", "\n", "branch4", "=", "self", ".", "_conv4a", "(", "branch4", ")", "\n", "branch4", "=", "self", ".", "_act4a", "(", "branch4", ")", "#self._batch4a(branch4,training=training))", "\n", "\n", "\n", "branch_T", "=", "self", ".", "_concatenate_a", "(", "[", "branch1", ",", "branch2", ",", "branch3", ",", "branch4", "]", ")", "\n", "branch_T", "=", "self", ".", "_batch1a", "(", "branch_T", ",", "training", "=", "training", ")", "\n", "branch_T", "=", "self", ".", "_pool_5a", "(", "branch_T", ")", "\n", "return", "branch_T", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.MultivariateNormalDiag.MultivariateNormalDiag._id": [[10, 15], ["str", "str", "int", "int"], "methods", ["None"], ["    ", "def", "_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "'D'", "\n", "_id", "+=", "\"_b\"", "+", "str", "(", "int", "(", "self", ".", "_bl", ")", ")", "\n", "_id", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "self", ".", "_fl", ")", ")", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.MultivariateNormalDiag.MultivariateNormalDiag.__init__": [[16, 34], ["ArgoKerasModel.ArgoKerasModel.__init__", "tensorflow.keras.layers.Flatten", "functools.partial.", "functools.partial.", "functools.partial", "functools.partial", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "output_size", ",", "bayesian_layers", "=", "False", ",", "flipout", "=", "False", ",", "layer_kwargs", "=", "{", "}", ",", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'norm_diag'", ")", "\n", "\n", "self", ".", "_bl", "=", "bayesian_layers", "\n", "self", ".", "_fl", "=", "flipout", "\n", "\n", "if", "bayesian_layers", ":", "\n", "            ", "if", "flipout", ":", "\n", "                ", "Dense", "=", "partial", "(", "tfp", ".", "layers", ".", "DenseFlipout", ",", "**", "layer_kwargs_bayes", ")", "\n", "", "else", ":", "\n", "                ", "Dense", "=", "partial", "(", "tfp", ".", "layers", ".", "DenseReparameterization", ",", "**", "layer_kwargs_bayes", ")", "\n", "", "", "else", ":", "\n", "            ", "Dense", "=", "partial", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", ",", "**", "layer_kwargs", ")", "\n", "\n", "", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "dense_loc", "=", "Dense", "(", "output_size", ")", "\n", "self", ".", "dense_diag_params", "=", "Dense", "(", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.MultivariateNormalDiag.MultivariateNormalDiag.call": [[35, 48], ["MultivariateNormalDiag.MultivariateNormalDiag._flat", "MultivariateNormalDiag.MultivariateNormalDiag.dense_loc", "MultivariateNormalDiag.MultivariateNormalDiag.dense_diag_params", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow.TensorShape", "tensorflow.nn.softplus", "tuple", "tensorflow_probability.distributions.MultivariateNormalDiag.batch_shape.as_list", "tensorflow_probability.distributions.MultivariateNormalDiag.event_shape.as_list"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_flat", "(", "inputs", ")", "\n", "loc", "=", "self", ".", "dense_loc", "(", "inputs", ")", "\n", "diag_params", "=", "self", ".", "dense_diag_params", "(", "inputs", ")", "\n", "scale_diag", "=", "MINIMAL_COVARIANCE", "+", "tf", ".", "nn", ".", "softplus", "(", "diag_params", ")", "\n", "\n", "ouput_params", "=", "{", "\"loc\"", ":", "loc", ",", "\"scale_diag\"", ":", "scale_diag", "}", "\n", "distr", "=", "tfp", ".", "distributions", ".", "MultivariateNormalDiag", "(", "**", "ouput_params", ")", "\n", "\n", "# hack because keras does not want distr in output... (Riccardo)", "\n", "distr", ".", "shape", "=", "tf", ".", "TensorShape", "(", "tuple", "(", "distr", ".", "batch_shape", ".", "as_list", "(", ")", "+", "distr", ".", "event_shape", ".", "as_list", "(", ")", ")", ")", "\n", "\n", "return", "distr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.BayesianVgg._id": [[29, 48], ["utils.argo_utils.listWithPoints", "str", "str", "keras_utils.act_id", "str", "int", "int", "int", "utils.argo_utils.listWithPoints"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.act_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints"], ["def", "_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "'BVGG'", "\n", "_id", "+=", "\"_f\"", "+", "listWithPoints", "(", "self", ".", "_filters", ")", "\n", "_id", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "self", ".", "_flipout", ")", ")", "\n", "_id", "+=", "\"_rn\"", "+", "str", "(", "int", "(", "self", ".", "_renorm", ")", ")", "\n", "_id", "+=", "\"_a\"", "+", "act_id", "(", "self", ".", "_activation_tuple", ")", "\n", "_id", "+=", "\"_fa\"", "+", "str", "(", "int", "(", "self", ".", "_final_activation", ")", ")", "\n", "\n", "pooling_dict", "=", "{", "\n", "\"max\"", ":", "'M'", ",", "\n", "\"avg\"", ":", "'A'", ",", "\n", "None", ":", "'N'", "\n", "}", "\n", "_id", "+=", "\"_p\"", "+", "pooling_dict", "[", "self", ".", "_pooling", "]", "\n", "\n", "if", "self", ".", "_linear_last", "is", "not", "None", ":", "\n", "            ", "_id", "+=", "\"_l\"", "+", "listWithPoints", "(", "self", ".", "_linear_last", ")", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.BayesianVgg.__init__": [[49, 129], ["ArgoKerasModel.ArgoKerasModel.__init__", "len", "range", "len", "utils.argo_utils.make_list", "ValueError", "keras_utils.get_renorm_clipping", "BayesianVgg.VggBlock", "BayesianVgg.BayesianVgg.blocks_list.append", "BayesianVgg.BayesianVgg.blocks_list.append", "zip", "tensorflow.keras.layers.Flatten", "BayesianVgg.BayesianVgg.blocks_list.append", "tensorflow.python.util.tf_inspect.getfullargspec", "Dense", "BayesianVgg.BayesianVgg.blocks_list.append", "BayesianVgg.BayesianVgg.blocks_list.append", "tensorflow.keras.layers.BatchNormalization", "keras_utils.get_keras_activation"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.make_list", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_keras_activation"], ["", "def", "__init__", "(", "self", ",", "\n", "filters", "=", "[", "16", ",", "16", ",", "32", ",", "32", ",", "32", "]", ",", "# [32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "linear_last", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "pooling", "=", "\"max\"", ",", "\n", "renorm", "=", "False", ",", "\n", "activation", "=", "(", "'relu'", ",", "{", "'alpha'", ":", "0.3", "}", ")", ",", "\n", "final_activation", "=", "True", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'bayesian_vgg'", ")", "\n", "\n", "self", ".", "_flipout", "=", "flipout", "\n", "self", ".", "_filters", "=", "filters", "\n", "self", ".", "_renorm", "=", "renorm", "\n", "self", ".", "_pooling", "=", "pooling", "\n", "self", ".", "_final_activation", "=", "final_activation", "\n", "\n", "n_blocks", "=", "len", "(", "kernels", ")", "\n", "end_activations", "=", "[", "True", "]", "*", "n_blocks", "\n", "\n", "if", "linear_last", "is", "not", "None", ":", "\n", "            ", "n_lin_layers", "=", "len", "(", "linear_last", ")", "\n", "linear_last", "=", "make_list", "(", "linear_last", ")", "\n", "lin_end_activations", "=", "[", "True", "]", "*", "n_lin_layers", "\n", "\n", "lin_end_activations", "[", "-", "1", "]", "=", "final_activation", "\n", "\n", "", "else", ":", "\n", "            ", "end_activations", "[", "-", "1", "]", "=", "final_activation", "\n", "\n", "", "self", ".", "_linear_last", "=", "linear_last", "\n", "self", ".", "_activation_tuple", "=", "activation", "\n", "\n", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", ",", "None", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "            ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "flipout", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "            ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "", "self", ".", "blocks_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "\n", "            ", "block", "=", "VggBlock", "(", "Conv2D", ",", "\n", "filters", "[", "i", "]", ",", "\n", "kernels", "[", "i", "]", ",", "\n", "strides", "[", "i", "]", ",", "\n", "pooling", ",", "\n", "renorm", ",", "\n", "renorm_clipping", ",", "\n", "activation", ",", "\n", "final_activation", "=", "end_activations", "[", "i", "]", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "block", ")", "\n", "\n", "# if logits_size is specified I add an extra Dense layer", "\n", "", "if", "self", ".", "_linear_last", "is", "not", "None", ":", "\n", "            ", "self", ".", "blocks_list", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", ")", "\n", "# check that activations are put here", "\n", "for", "ls", ",", "act_bool", "in", "zip", "(", "self", ".", "_linear_last", ",", "lin_end_activations", ")", ":", "\n", "                ", "self", ".", "blocks_list", ".", "append", "(", "Dense", "(", "ls", ",", "**", "layer_kwargs_bayes", ")", ")", "\n", "if", "act_bool", ":", "\n", "                    ", "self", ".", "blocks_list", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "get_keras_activation", "(", "activation", ")", ")", "\n", "\n", "", "", "", "self", ".", "_layer_call_argspecs", "=", "{", "}", "\n", "for", "layer", "in", "self", ".", "blocks_list", ":", "\n", "            ", "self", ".", "_layer_call_argspecs", "[", "layer", ".", "name", "]", "=", "tf_inspect", ".", "getfullargspec", "(", "layer", ".", "call", ")", ".", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.BayesianVgg._layer_call_kwargs": [[130, 137], ["None"], "methods", ["None"], ["", "", "def", "_layer_call_kwargs", "(", "self", ",", "layer", ",", "training", ")", ":", "\n", "        ", "kwargs", "=", "{", "}", "\n", "argspec", "=", "self", ".", "_layer_call_argspecs", "[", "layer", ".", "name", "]", "\n", "if", "'training'", "in", "argspec", ":", "\n", "            ", "kwargs", "[", "'training'", "]", "=", "training", "\n", "\n", "", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.BayesianVgg.call": [[138, 145], ["BayesianVgg.BayesianVgg._layer_call_kwargs", "layer"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.BayesianVgg._layer_call_kwargs"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "net", "=", "inputs", "\n", "for", "layer", "in", "self", ".", "blocks_list", ":", "\n", "            ", "kwargs", "=", "self", ".", "_layer_call_kwargs", "(", "layer", ",", "training", ")", "\n", "net", "=", "layer", "(", "net", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.VggBlock.__init__": [[149, 184], ["super().__init__", "Conv2D", "tensorflow.keras.layers.BatchNormalization", "keras_utils.get_keras_activation", "BayesianVgg.VggBlock._get_conv_stride", "Conv2D", "tensorflow.keras.layers.BatchNormalization", "keras_utils.get_keras_activation", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.AveragePooling2D"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_keras_activation", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.VggBlock._get_conv_stride", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_keras_activation"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "filters", ",", "kernel", ",", "stride", ",", "pooling", ",", "\n", "renorm", ",", "renorm_clipping", ",", "activation_tuple", ",", "final_activation", ",", "**", "layer_kwargs_bayes", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'vgg_block'", ")", "\n", "\n", "self", ".", "conv2a", "=", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "bn2a", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "\n", "# self._act = tf.nn.leaky_relu", "\n", "self", ".", "_act2a", "=", "get_keras_activation", "(", "activation_tuple", ")", "\n", "\n", "conv2b_stride", "=", "self", ".", "_get_conv_stride", "(", "pooling", ",", "stride", ")", "\n", "\n", "self", ".", "conv2b", "=", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "strides", "=", "conv2b_stride", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "_act2b", "=", "None", "\n", "if", "final_activation", ":", "\n", "            ", "self", ".", "bn2b", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "self", ".", "_act2b", "=", "get_keras_activation", "(", "activation_tuple", ")", "\n", "\n", "", "self", ".", "_pooling", "=", "None", "\n", "if", "pooling", "==", "\"max\"", ":", "\n", "            ", "self", ".", "_pooling", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "            ", "self", ".", "_pooling", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.VggBlock._get_conv_stride": [[185, 193], ["None"], "methods", ["None"], ["", "", "def", "_get_conv_stride", "(", "self", ",", "pooling", ",", "stride", ")", ":", "\n", "\n", "        ", "if", "pooling", "is", "None", ":", "\n", "            ", "conv_stride", "=", "stride", "\n", "", "else", ":", "\n", "            ", "conv_stride", "=", "1", "\n", "\n", "", "return", "conv_stride", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianVgg.VggBlock.call": [[194, 209], ["BayesianVgg.VggBlock.conv2a", "BayesianVgg.VggBlock.bn2a", "BayesianVgg.VggBlock._act2a", "BayesianVgg.VggBlock.conv2b", "BayesianVgg.VggBlock.bn2b", "BayesianVgg.VggBlock._act2b", "BayesianVgg.VggBlock._pooling"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv2a", "(", "inputs", ")", "\n", "x", "=", "self", ".", "bn2a", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "_act2a", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2b", "(", "x", ")", "\n", "\n", "if", "self", ".", "_act2b", ":", "\n", "            ", "x", "=", "self", ".", "bn2b", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "_act2b", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "_pooling", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "_pooling", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.OneHotCategorical.OneHotCategorical._id": [[8, 11], ["None"], "methods", ["None"], ["    ", "def", "_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "'Cat'", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.OneHotCategorical.OneHotCategorical.__init__": [[12, 19], ["ArgoKerasModel.ArgoKerasModel.__init__", "functools.partial", "tensorflow.keras.layers.Flatten", "functools.partial."], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "output_size", ",", "layer_kwargs", "=", "{", "}", ",", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'onehot_categorical'", ")", "\n", "\n", "Dense", "=", "partial", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", ",", "**", "layer_kwargs", ")", "\n", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "dense_logits", "=", "Dense", "(", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.OneHotCategorical.OneHotCategorical.call": [[20, 31], ["OneHotCategorical.OneHotCategorical._flat", "OneHotCategorical.OneHotCategorical.dense_logits", "tensorflow_probability.distributions.OneHotCategorical", "tensorflow.TensorShape", "tuple", "tensorflow_probability.distributions.OneHotCategorical.batch_shape.as_list", "tensorflow_probability.distributions.OneHotCategorical.event_shape.as_list"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_flat", "(", "inputs", ")", "\n", "logits", "=", "self", ".", "dense_logits", "(", "inputs", ")", "\n", "\n", "ouput_params", "=", "{", "\"logits\"", ":", "logits", "}", "\n", "distr", "=", "tfp", ".", "distributions", ".", "OneHotCategorical", "(", "**", "ouput_params", ")", "\n", "\n", "# hack because keras does not want distr in output... (Riccardo)", "\n", "distr", ".", "shape", "=", "tf", ".", "TensorShape", "(", "tuple", "(", "distr", ".", "batch_shape", ".", "as_list", "(", ")", "+", "distr", ".", "event_shape", ".", "as_list", "(", ")", ")", ")", "\n", "\n", "return", "distr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.FromCallable.FromCallable.__init__": [[5, 9], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "callable", ",", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_cf", "=", "callable", "\n", "self", ".", "_cf_kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.FromCallable.FromCallable.call": [[10, 12], ["FromCallable.FromCallable._cf"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "_cf", "(", "inputs", ",", "**", "self", ".", "_cf_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.BayesianInception.__init__": [[9, 115], ["super().__init__", "BayesianInception.Resnet_Stem_Inception", "BayesianInception.BayesianInception.blocks_list.append", "range", "BayesianInception.ReductionA_Inception", "BayesianInception.BayesianInception.blocks_list.append", "range", "BayesianInception.ReductionB_Inception", "BayesianInception.BayesianInception.blocks_list.append", "range", "tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.SpatialDropout2D", "ValueError", "keras_utils.get_renorm_clipping", "BayesianInception.ResnetBlockA_Inception", "BayesianInception.BayesianInception.blocks_list.append", "BayesianInception.ResnetBlockB_Inception", "BayesianInception.BayesianInception.blocks_list.append", "BayesianInception.ResnetBlockC_Inception", "BayesianInception.BayesianInception.blocks_list.append", "Dense"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["def", "__init__", "(", "self", ",", "\n", "filters", "=", "[", "16", ",", "32", "]", ",", "\n", "kernels", "=", "[", "5", ",", "5", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "renorm", "=", "False", ",", "\n", "pooling", "=", "\"avg\"", ",", "\n", "activation", "=", "(", "'relu'", ",", "{", "}", ")", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'bayesian_inception'", ")", "\n", "activation_name", ",", "activation_kwargs", "=", "activation", "\n", "\n", "if", "flipout", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "            ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "            ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "pooling", "==", "\"max\"", ":", "\n", "            ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPooling2D", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "            ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "            ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "\n", "", "self", ".", "blocks_list", "=", "[", "]", "\n", "\n", "\n", "stem", "=", "Resnet_Stem_Inception", "(", "Conv2D", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "blocks_list", ".", "append", "(", "stem", ")", "\n", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "block", "=", "ResnetBlockA_Inception", "(", "Conv2D", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "block", ")", "\n", "\n", "", "redA", "=", "ReductionA_Inception", "(", "Conv2D", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "blocks_list", ".", "append", "(", "redA", ")", "\n", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "            ", "block1", "=", "ResnetBlockB_Inception", "(", "Conv2D", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "block1", ")", "\n", "\n", "", "redB", "=", "ReductionB_Inception", "(", "Conv2D", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "self", ".", "blocks_list", ".", "append", "(", "redB", ")", "\n", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "block2", "=", "ResnetBlockC_Inception", "(", "Conv2D", ",", "\n", "renorm", ",", "\n", "Pool", ",", "\n", "renorm_clipping", ",", "\n", "activation_name", "=", "activation_name", ",", "\n", "activation_kwargs", "=", "activation_kwargs", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "self", ".", "blocks_list", ".", "append", "(", "block2", ")", "\n", "\n", "", "self", ".", "_pooling", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "(", "2", ",", "1", ")", "\n", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "self", ".", "_drop", "=", "tf", ".", "keras", ".", "layers", ".", "SpatialDropout2D", "(", "rate", "=", "0.5", ")", "\n", "self", ".", "_last_dense", "=", "None", "\n", "if", "logits_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "_last_dense", "=", "Dense", "(", "\n", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.BayesianInception.call": [[116, 128], ["BayesianInception.BayesianInception._pooling", "BayesianInception.BayesianInception._drop", "BayesianInception.BayesianInception._flat", "block", "BayesianInception.BayesianInception._last_dense"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "net", "=", "inputs", "\n", "for", "block", "in", "self", ".", "blocks_list", ":", "\n", "            ", "net", "=", "block", "(", "net", ",", "training", "=", "training", ")", "\n", "", "net", "=", "self", ".", "_pooling", "(", "net", ")", "\n", "net", "=", "self", ".", "_drop", "(", "net", ",", "training", "=", "training", ")", "\n", "net", "=", "self", ".", "_flat", "(", "net", ")", "\n", "\n", "if", "self", ".", "_last_dense", ":", "\n", "            ", "net", "=", "self", ".", "_last_dense", "(", "net", ")", "\n", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ResnetBlockA_Inception.__init__": [[131, 184], ["super().__init__", "BayesianInception.ResnetBlockA_Inception.__init__.conv2d_"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'ResnetBlockA_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "1", ",", "\n", "name", "=", "None", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "pooling", ",", "stride_pool", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride_pool", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "\n", "", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv2c", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ")", "\n", "self", ".", "_batch2c", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2c", "=", "act", "(", ")", "\n", "self", ".", "_conv2d", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2d", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2d", "=", "act", "(", ")", "\n", "self", ".", "_conv2e", "=", "conv2d_", "(", "filters", "=", "28", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ")", "\n", "self", ".", "_batch2e", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e", "=", "act", "(", ")", "\n", "self", ".", "_conv2f", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ")", "\n", "self", ".", "_batch2f", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2f", "=", "act", "(", ")", "\n", "self", ".", "_conv2g", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2g", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2g", "=", "act", "(", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ResnetBlockA_Inception.call": [[185, 206], ["BayesianInception.ResnetBlockA_Inception._conv2a", "BayesianInception.ResnetBlockA_Inception._act2a", "BayesianInception.ResnetBlockA_Inception._conv2b", "BayesianInception.ResnetBlockA_Inception._act2b", "BayesianInception.ResnetBlockA_Inception._conv2c", "BayesianInception.ResnetBlockA_Inception._act2c", "BayesianInception.ResnetBlockA_Inception._conv2d", "BayesianInception.ResnetBlockA_Inception._act2d", "BayesianInception.ResnetBlockA_Inception._conv2e", "BayesianInception.ResnetBlockA_Inception._act2e", "BayesianInception.ResnetBlockA_Inception._conv2f", "BayesianInception.ResnetBlockA_Inception._act2f", "BayesianInception.ResnetBlockA_Inception._concatenate_a", "BayesianInception.ResnetBlockA_Inception._conv2g", "BayesianInception.ResnetBlockA_Inception._act2g", "BayesianInception.ResnetBlockA_Inception._batch2a", "BayesianInception.ResnetBlockA_Inception._batch2b", "BayesianInception.ResnetBlockA_Inception._batch2c", "BayesianInception.ResnetBlockA_Inception._batch2d", "BayesianInception.ResnetBlockA_Inception._batch2e", "BayesianInception.ResnetBlockA_Inception._batch2f", "BayesianInception.ResnetBlockA_Inception._batch2g"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "\n", "        ", "branch1", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act2a", "(", "self", ".", "_batch2a", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch2", "=", "self", ".", "_conv2b", "(", "input_tensor", ")", "\n", "branch2", "=", "self", ".", "_act2b", "(", "self", ".", "_batch2b", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2c", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2c", "(", "self", ".", "_batch2c", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch3", "=", "self", ".", "_conv2d", "(", "input_tensor", ")", "\n", "branch3", "=", "self", ".", "_act2d", "(", "self", ".", "_batch2d", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "branch3", "=", "self", ".", "_conv2e", "(", "branch3", ")", "\n", "branch3", "=", "self", ".", "_act2e", "(", "self", ".", "_batch2e", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "branch3", "=", "self", ".", "_conv2f", "(", "branch3", ")", "\n", "branch3", "=", "self", ".", "_act2f", "(", "self", ".", "_batch2f", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "\n", "mix", "=", "self", ".", "_concatenate_a", "(", "[", "branch1", ",", "branch2", ",", "branch3", "]", ")", "\n", "final", "=", "self", ".", "_conv2g", "(", "mix", ")", "\n", "final", "=", "self", ".", "_act2g", "(", "self", ".", "_batch2g", "(", "final", ",", "training", "=", "training", ")", ")", "\n", "return", "final", "\n", "", "", "class", "ResnetBlockB_Inception", "(", "tf", ".", "keras", ".", "Model", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ResnetBlockB_Inception.__init__": [[207, 254], ["super().__init__", "BayesianInception.ResnetBlockB_Inception.__init__.conv2d_"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'ResnetBlockB_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "1", ",", "\n", "name", "=", "None", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "pooling", ",", "stride_pool", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride_pool", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "\n", "", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv2c", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "7", ")", "\n", "self", ".", "_batch2c", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2c", "=", "act", "(", ")", "\n", "self", ".", "_conv2d", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "7", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2d", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2d", "=", "act", "(", ")", "\n", "self", ".", "_conv2e", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2e", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e", "=", "act", "(", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ResnetBlockB_Inception.call": [[254, 271], ["BayesianInception.ResnetBlockB_Inception._conv2a", "BayesianInception.ResnetBlockB_Inception._act2a", "BayesianInception.ResnetBlockB_Inception._conv2b", "BayesianInception.ResnetBlockB_Inception._act2b", "BayesianInception.ResnetBlockB_Inception._conv2c", "BayesianInception.ResnetBlockB_Inception._act2c", "BayesianInception.ResnetBlockB_Inception._conv2d", "BayesianInception.ResnetBlockB_Inception._act2d", "BayesianInception.ResnetBlockB_Inception._concatenate_a", "BayesianInception.ResnetBlockB_Inception._conv2e", "BayesianInception.ResnetBlockB_Inception._act2e", "BayesianInception.ResnetBlockB_Inception._batch2a", "BayesianInception.ResnetBlockB_Inception._batch2b", "BayesianInception.ResnetBlockB_Inception._batch2c", "BayesianInception.ResnetBlockB_Inception._batch2d", "BayesianInception.ResnetBlockB_Inception._batch2e"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "\n", "        ", "branch1", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act2a", "(", "self", ".", "_batch2a", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch2", "=", "self", ".", "_conv2b", "(", "input_tensor", ")", "\n", "branch2", "=", "self", ".", "_act2b", "(", "self", ".", "_batch2b", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2c", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2c", "(", "self", ".", "_batch2c", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2d", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2d", "(", "self", ".", "_batch2d", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "\n", "\n", "mix", "=", "self", ".", "_concatenate_a", "(", "[", "branch1", ",", "branch2", "]", ")", "\n", "final", "=", "self", ".", "_conv2e", "(", "mix", ")", "\n", "final", "=", "self", ".", "_act2e", "(", "self", ".", "_batch2e", "(", "final", ",", "training", "=", "training", ")", ")", "\n", "return", "final", "\n", "", "", "class", "ResnetBlockC_Inception", "(", "tf", ".", "keras", ".", "Model", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ResnetBlockC_Inception.__init__": [[272, 319], ["super().__init__", "BayesianInception.ResnetBlockC_Inception.__init__.conv2d_"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'ResnetBlockC_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "1", ",", "\n", "name", "=", "None", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "self", ",", "pooling", ",", "stride_pool", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride_pool", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "\n", "", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv2c", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "3", ")", "\n", "self", ".", "_batch2c", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2c", "=", "act", "(", ")", "\n", "self", ".", "_conv2d", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "3", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2d", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2d", "=", "act", "(", ")", "\n", "self", ".", "_conv2e", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2e", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e", "=", "act", "(", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ResnetBlockC_Inception.call": [[319, 336], ["BayesianInception.ResnetBlockC_Inception._conv2a", "BayesianInception.ResnetBlockC_Inception._act2a", "BayesianInception.ResnetBlockC_Inception._conv2b", "BayesianInception.ResnetBlockC_Inception._act2b", "BayesianInception.ResnetBlockC_Inception._conv2c", "BayesianInception.ResnetBlockC_Inception._act2c", "BayesianInception.ResnetBlockC_Inception._conv2d", "BayesianInception.ResnetBlockC_Inception._act2d", "BayesianInception.ResnetBlockC_Inception._concatenate_a", "BayesianInception.ResnetBlockC_Inception._conv2e", "BayesianInception.ResnetBlockC_Inception._act2e", "BayesianInception.ResnetBlockC_Inception._batch2a", "BayesianInception.ResnetBlockC_Inception._batch2b", "BayesianInception.ResnetBlockC_Inception._batch2c", "BayesianInception.ResnetBlockC_Inception._batch2d", "BayesianInception.ResnetBlockC_Inception._batch2e"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "\n", "        ", "branch1", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act2a", "(", "self", ".", "_batch2a", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch2", "=", "self", ".", "_conv2b", "(", "input_tensor", ")", "\n", "branch2", "=", "self", ".", "_act2b", "(", "self", ".", "_batch2b", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2c", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2c", "(", "self", ".", "_batch2c", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2d", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2d", "(", "self", ".", "_batch2d", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "\n", "\n", "mix", "=", "self", ".", "_concatenate_a", "(", "[", "branch1", ",", "branch2", "]", ")", "\n", "final", "=", "self", ".", "_conv2e", "(", "mix", ")", "\n", "final", "=", "self", ".", "_act2e", "(", "self", ".", "_batch2e", "(", "final", ",", "training", "=", "training", ")", ")", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.Resnet_Stem_Inception.__init__": [[338, 410], ["super().__init__", "BayesianInception.Resnet_Stem_Inception.__init__.conv2d_"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'Stem_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "1", ",", "\n", "name", "=", "None", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "pooling", ",", "stride_pool", ",", "padding", "=", "'valid'", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride_pool", ",", "padding", "=", "padding", ")", "\n", "\n", "", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv2c", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2c", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2c", "=", "act", "(", ")", "\n", "self", ".", "_pool_2c", "=", "pool_apply", "(", "3", ",", "1", ")", "\n", "self", ".", "_conv2d", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2d", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2d", "=", "act", "(", ")", "\n", "\n", "self", ".", "_conv2e", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2e", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e", "=", "act", "(", ")", "\n", "self", ".", "_conv2e1", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "7", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2e1", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e1", "=", "act", "(", ")", "\n", "self", ".", "_conv2e2", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "7", ")", "\n", "self", ".", "_batch2e2", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e2", "=", "act", "(", ")", "\n", "self", ".", "_conv2e3", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2e3", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e3", "=", "act", "(", ")", "\n", "\n", "self", ".", "_conv2f", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2f", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2f", "=", "act", "(", ")", "\n", "self", ".", "_conv2f1", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2f1", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2f1", "=", "act", "(", ")", "\n", "\n", "self", ".", "_conv2g", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2g", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2g", "=", "act", "(", ")", "\n", "self", ".", "_pool_2g", "=", "pool_apply", "(", "3", ",", "1", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "self", ".", "_concatenate_b", "=", "concatenate", "(", ")", "\n", "self", ".", "_concatenate_c", "=", "concatenate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.Resnet_Stem_Inception.call": [[411, 444], ["BayesianInception.Resnet_Stem_Inception._conv2a", "BayesianInception.Resnet_Stem_Inception._act2a", "BayesianInception.Resnet_Stem_Inception._conv2b", "BayesianInception.Resnet_Stem_Inception._act2b", "BayesianInception.Resnet_Stem_Inception._conv2c", "BayesianInception.Resnet_Stem_Inception._act2c", "BayesianInception.Resnet_Stem_Inception._pool_2c", "BayesianInception.Resnet_Stem_Inception._conv2d", "BayesianInception.Resnet_Stem_Inception._act2d", "BayesianInception.Resnet_Stem_Inception._concatenate_a", "BayesianInception.Resnet_Stem_Inception._conv2e", "BayesianInception.Resnet_Stem_Inception._act2e", "BayesianInception.Resnet_Stem_Inception._conv2e1", "BayesianInception.Resnet_Stem_Inception._act2e1", "BayesianInception.Resnet_Stem_Inception._conv2e2", "BayesianInception.Resnet_Stem_Inception._act2e2", "BayesianInception.Resnet_Stem_Inception._conv2e3", "BayesianInception.Resnet_Stem_Inception._act2e3", "BayesianInception.Resnet_Stem_Inception._conv2f", "BayesianInception.Resnet_Stem_Inception._act2f", "BayesianInception.Resnet_Stem_Inception._conv2f1", "BayesianInception.Resnet_Stem_Inception._act2f1", "BayesianInception.Resnet_Stem_Inception._concatenate_b", "BayesianInception.Resnet_Stem_Inception._conv2g", "BayesianInception.Resnet_Stem_Inception._act2g", "BayesianInception.Resnet_Stem_Inception._pool_2g", "BayesianInception.Resnet_Stem_Inception._concatenate_c", "BayesianInception.Resnet_Stem_Inception._batch2a", "BayesianInception.Resnet_Stem_Inception._batch2b", "BayesianInception.Resnet_Stem_Inception._batch2c", "BayesianInception.Resnet_Stem_Inception._batch2d", "BayesianInception.Resnet_Stem_Inception._batch2e", "BayesianInception.Resnet_Stem_Inception._batch2e1", "BayesianInception.Resnet_Stem_Inception._batch2e2", "BayesianInception.Resnet_Stem_Inception._batch2e3", "BayesianInception.Resnet_Stem_Inception._batch2f", "BayesianInception.Resnet_Stem_Inception._batch2f1", "BayesianInception.Resnet_Stem_Inception._batch2g"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "\n", "        ", "branch1", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act2a", "(", "self", ".", "_batch2a", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch1", "=", "self", ".", "_conv2b", "(", "branch1", ")", "\n", "branch1", "=", "self", ".", "_act2b", "(", "self", ".", "_batch2b", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch1", "=", "self", ".", "_conv2c", "(", "branch1", ")", "\n", "branch1", "=", "self", ".", "_act2c", "(", "self", ".", "_batch2c", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch2", "=", "self", ".", "_pool_2c", "(", "branch1", ")", "\n", "branch3", "=", "self", ".", "_conv2d", "(", "branch1", ")", "\n", "branch3", "=", "self", ".", "_act2d", "(", "self", ".", "_batch2d", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "\n", "mix", "=", "self", ".", "_concatenate_a", "(", "[", "branch3", ",", "branch2", "]", ")", "\n", "branch1", "=", "self", ".", "_conv2e", "(", "mix", ")", "\n", "branch1", "=", "self", ".", "_act2e", "(", "self", ".", "_batch2e", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch1", "=", "self", ".", "_conv2e1", "(", "branch1", ")", "\n", "branch1", "=", "self", ".", "_act2e1", "(", "self", ".", "_batch2e1", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch1", "=", "self", ".", "_conv2e2", "(", "branch1", ")", "\n", "branch1", "=", "self", ".", "_act2e2", "(", "self", ".", "_batch2e2", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch1", "=", "self", ".", "_conv2e3", "(", "branch1", ")", "\n", "branch1", "=", "self", ".", "_act2e3", "(", "self", ".", "_batch2e3", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2f", "(", "mix", ")", "\n", "branch2", "=", "self", ".", "_act2f", "(", "self", ".", "_batch2f", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2f1", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2f1", "(", "self", ".", "_batch2f1", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "mix", "=", "self", ".", "_concatenate_b", "(", "[", "branch1", ",", "branch2", "]", ")", "\n", "branch1", "=", "self", ".", "_conv2g", "(", "mix", ")", "\n", "branch1", "=", "self", ".", "_act2g", "(", "self", ".", "_batch2g", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_pool_2g", "(", "mix", ")", "\n", "branch", "=", "self", ".", "_concatenate_c", "(", "[", "branch1", ",", "branch2", "]", ")", "\n", "\n", "return", "branch", "\n", "# class Resnet_Stem_test(tf.keras.Model):", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ReductionA_Inception.__init__": [[514, 558], ["super().__init__", "BayesianInception.ReductionA_Inception.__init__.pool_apply"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'ReductionA_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "1", ",", "\n", "name", "=", "None", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "pooling", ",", "stride_pool", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride_pool", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "", "self", ".", "_pool_2a", "=", "pool_apply", "(", "3", ",", "2", ")", "\n", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv2c", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ")", "\n", "self", ".", "_batch2c", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2c", "=", "act", "(", ")", "\n", "self", ".", "_conv2d", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2d", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2d", "=", "act", "(", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ReductionA_Inception.call": [[559, 572], ["BayesianInception.ReductionA_Inception._pool_2a", "BayesianInception.ReductionA_Inception._conv2a", "BayesianInception.ReductionA_Inception._act2a", "BayesianInception.ReductionA_Inception._conv2b", "BayesianInception.ReductionA_Inception._act2b", "BayesianInception.ReductionA_Inception._conv2c", "BayesianInception.ReductionA_Inception._act2c", "BayesianInception.ReductionA_Inception._conv2d", "BayesianInception.ReductionA_Inception._act2d", "BayesianInception.ReductionA_Inception._concatenate_a", "BayesianInception.ReductionA_Inception._batch2a", "BayesianInception.ReductionA_Inception._batch2b", "BayesianInception.ReductionA_Inception._batch2c", "BayesianInception.ReductionA_Inception._batch2d"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "branch0", "=", "self", ".", "_pool_2a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act2a", "(", "self", ".", "_batch2a", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2b", "(", "input_tensor", ")", "\n", "branch2", "=", "self", ".", "_act2b", "(", "self", ".", "_batch2b", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2c", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2c", "(", "self", ".", "_batch2c", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "branch2", "=", "self", ".", "_conv2d", "(", "branch2", ")", "\n", "branch2", "=", "self", ".", "_act2d", "(", "self", ".", "_batch2d", "(", "branch2", ",", "training", "=", "training", ")", ")", "\n", "\n", "final", "=", "self", ".", "_concatenate_a", "(", "[", "branch1", ",", "branch2", ",", "branch0", "]", ")", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ReductionB_Inception.__init__": [[574, 632], ["super().__init__", "BayesianInception.ReductionB_Inception.__init__.pool_apply"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Conv2D", ",", "\n", "renorm", ",", "Pool", ",", "renorm_clipping", ",", "\n", "activation_name", "=", "'relu'", ",", "activation_kwargs", "=", "{", "}", ",", "\n", "final_activation", "=", "True", ",", "\n", "**", "layer_kwargs_bayes", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'ReductionB_Inception'", ")", "\n", "\n", "def", "conv2d_", "(", "filters", "=", "10", ",", "\n", "num_row", "=", "1", ",", "\n", "num_col", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "1", ",", "\n", "name", "=", "None", ")", ":", "\n", "            ", "return", "Conv2D", "(", "filters", ",", "\n", "kernel_size", "=", "(", "num_row", ",", "num_col", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "padding", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "", "def", "batch_bn", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "\n", "", "def", "act", "(", ")", ":", "\n", "            ", "return", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "activation_name", ",", "**", "activation_kwargs", ")", "\n", "\n", "", "def", "pool_apply", "(", "pooling", ",", "stride_pool", ")", ":", "\n", "            ", "return", "Pool", "(", "pooling", ",", "stride_pool", ")", "\n", "", "def", "concatenate", "(", ")", ":", "\n", "            ", "return", "Concatenate", "(", "axis", "=", "3", ")", "\n", "\n", "\n", "\n", "", "self", ".", "_pool_2a", "=", "pool_apply", "(", "3", ",", "2", ")", "\n", "self", ".", "_conv2a", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2a", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2a", "=", "act", "(", ")", "\n", "self", ".", "_conv2b", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2b", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2b", "=", "act", "(", ")", "\n", "self", ".", "_conv2c", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2c", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2c", "=", "act", "(", ")", "\n", "self", ".", "_conv2d", "=", "conv2d_", "(", "filters", "=", "16", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2d", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2d", "=", "act", "(", ")", "\n", "\n", "self", ".", "_conv2e", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "1", ",", "num_col", "=", "1", ")", "\n", "self", ".", "_batch2e", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2e", "=", "act", "(", ")", "\n", "\n", "self", ".", "_conv2f", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ")", "\n", "self", ".", "_batch2f", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2f", "=", "act", "(", ")", "\n", "self", ".", "_conv2g", "=", "conv2d_", "(", "filters", "=", "32", ",", "num_row", "=", "3", ",", "num_col", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'valid'", ")", "\n", "self", ".", "_batch2g", "=", "batch_bn", "(", ")", "\n", "self", ".", "_act2g", "=", "act", "(", ")", "\n", "self", ".", "_concatenate_a", "=", "concatenate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BayesianInception.ReductionB_Inception.call": [[633, 655], ["BayesianInception.ReductionB_Inception._pool_2a", "BayesianInception.ReductionB_Inception._conv2a", "BayesianInception.ReductionB_Inception._act2a", "BayesianInception.ReductionB_Inception._conv2b", "BayesianInception.ReductionB_Inception._act2b", "BayesianInception.ReductionB_Inception._conv2c", "BayesianInception.ReductionB_Inception._act2c", "BayesianInception.ReductionB_Inception._conv2d", "BayesianInception.ReductionB_Inception._act2d", "BayesianInception.ReductionB_Inception._conv2e", "BayesianInception.ReductionB_Inception._act2e", "BayesianInception.ReductionB_Inception._conv2f", "BayesianInception.ReductionB_Inception._act2f", "BayesianInception.ReductionB_Inception._conv2g", "BayesianInception.ReductionB_Inception._act2g", "BayesianInception.ReductionB_Inception._concatenate_a", "BayesianInception.ReductionB_Inception._batch2a", "BayesianInception.ReductionB_Inception._batch2b", "BayesianInception.ReductionB_Inception._batch2c", "BayesianInception.ReductionB_Inception._batch2d", "BayesianInception.ReductionB_Inception._batch2e", "BayesianInception.ReductionB_Inception._batch2f", "BayesianInception.ReductionB_Inception._batch2g"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_pool_2a", "(", "input_tensor", ")", "\n", "\n", "branch1", "=", "self", ".", "_conv2a", "(", "input_tensor", ")", "\n", "branch1", "=", "self", ".", "_act2a", "(", "self", ".", "_batch2a", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "branch1", "=", "self", ".", "_conv2b", "(", "branch1", ")", "\n", "branch1", "=", "self", ".", "_act2b", "(", "self", ".", "_batch2b", "(", "branch1", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch3", "=", "self", ".", "_conv2c", "(", "input_tensor", ")", "\n", "branch3", "=", "self", ".", "_act2c", "(", "self", ".", "_batch2c", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "branch3", "=", "self", ".", "_conv2d", "(", "branch3", ")", "\n", "branch3", "=", "self", ".", "_act2d", "(", "self", ".", "_batch2d", "(", "branch3", ",", "training", "=", "training", ")", ")", "\n", "\n", "branch4", "=", "self", ".", "_conv2e", "(", "input_tensor", ")", "\n", "branch4", "=", "self", ".", "_act2e", "(", "self", ".", "_batch2e", "(", "branch4", ",", "training", "=", "training", ")", ")", "\n", "branch4", "=", "self", ".", "_conv2f", "(", "branch4", ")", "\n", "branch4", "=", "self", ".", "_act2f", "(", "self", ".", "_batch2f", "(", "branch4", ",", "training", "=", "training", ")", ")", "\n", "branch4", "=", "self", ".", "_conv2g", "(", "branch4", ")", "\n", "branch4", "=", "self", ".", "_act2g", "(", "self", ".", "_batch2g", "(", "branch4", ",", "training", "=", "training", ")", ")", "\n", "\n", "final", "=", "self", ".", "_concatenate_a", "(", "[", "branch1", ",", "branch3", ",", "branch2", ",", "branch4", "]", ")", "\n", "return", "final", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_keras_activation": [[18, 25], ["getattr", "FromCallable.FromCallable"], "function", ["None"], ["def", "get_keras_activation", "(", "activation_tuple", ")", ":", "\n", "    ", "activation_name", ",", "activation_kwargs", "=", "activation_tuple", "\n", "\n", "activation_func", "=", "getattr", "(", "tf", ".", "keras", ".", "activations", ",", "activation_name", ")", "\n", "ActivationLayer", "=", "FromCallable", "(", "activation_func", ",", "activation_kwargs", ")", "\n", "\n", "return", "ActivationLayer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.act_id": [[26, 43], ["Exception", "activation_kwargs.get"], "function", ["None"], ["", "def", "act_id", "(", "activation_tuple", ")", ":", "\n", "    ", "activation_name", ",", "activation_kwargs", "=", "activation_tuple", "\n", "\n", "act_dict", "=", "{", "\n", "'relu'", ":", "'R'", "\n", "}", "\n", "\n", "try", ":", "\n", "        ", "_id", "=", "act_dict", "[", "activation_name", "]", "\n", "\n", "if", "activation_name", "==", "'relu'", ":", "\n", "            ", "if", "activation_kwargs", ".", "get", "(", "'alpha'", ",", "None", ")", "is", "not", "None", ":", "\n", "                ", "_id", "+=", "\"a{:.1f}\"", ".", "format", "(", "activation_kwargs", "[", "'alpha'", "]", ")", "\n", "", "", "", "except", ":", "\n", "        ", "raise", "Exception", "(", "\"Activation not supported in name id, found {:} - {:}\"", ".", "format", "(", "activation_name", ",", "activation_kwargs", ")", ")", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.parse_init_reg_kwargs_bayes": [[56, 109], ["utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "regularizers.load_regularizer.load_regularizer", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "float", "tensorflow_probability.layers.default_mean_field_normal_fn", "tensorflow_probability.layers.default_mean_field_normal_fn", "keras_utils.load_kernel_prior_fn", "tensorflow.clip_by_value"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.regularizers.load_regularizer.load_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.load_kernel_prior_fn"], ["", "def", "parse_init_reg_kwargs_bayes", "(", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "posterior_kwargs", "=", "kwargs", "[", "\"posterior\"", "]", "\n", "\n", "activity_regularizer", "=", "eval_method_from_tuple", "(", "tf", ",", "posterior_kwargs", "[", "\"activity_regularizer\"", "]", ")", "\n", "\n", "kernel_loc_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "posterior_kwargs", "[", "\"kernel_loc_initializer\"", "]", ")", "\n", "kernel_untr_scale_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "posterior_kwargs", "[", "\"kernel_untr_scale_initializer\"", "]", ")", "\n", "\n", "kernel_loc_regularizer", "=", "eval_method_from_tuple", "(", "tf", ",", "posterior_kwargs", "[", "\"kernel_loc_regularizer\"", "]", ")", "\n", "kernel_untr_scale_regularizer", "=", "load_regularizer", "(", "posterior_kwargs", "[", "\"kernel_untr_scale_regularizer\"", "]", ")", "\n", "\n", "bias_loc_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "posterior_kwargs", "[", "\"bias_loc_initializer\"", "]", ")", "\n", "bias_loc_regularizer", "=", "eval_method_from_tuple", "(", "tf", ",", "posterior_kwargs", "[", "\"bias_loc_regularizer\"", "]", ")", "\n", "\n", "kernel_untr_scale_constraint_min", "=", "-", "1000", "\n", "kernel_untr_scale_constraint_max", "=", "float", "(", "posterior_kwargs", "[", "\"kernel_untr_scale_constraint_max\"", "]", ")", "\n", "\n", "def", "kernel_untr_scale_constraint", "(", "tensor", ")", ":", "\n", "        ", "return", "tf", ".", "clip_by_value", "(", "tensor", ",", "\n", "kernel_untr_scale_constraint_min", ",", "\n", "kernel_untr_scale_constraint_max", ")", "\n", "\n", "\n", "", "kernel_posterior_fn", "=", "tfp", ".", "layers", ".", "default_mean_field_normal_fn", "(", "\n", "loc_initializer", "=", "kernel_loc_initializer", ",", "\n", "untransformed_scale_initializer", "=", "kernel_untr_scale_initializer", ",", "\n", "untransformed_scale_constraint", "=", "kernel_untr_scale_constraint", ",", "\n", "loc_regularizer", "=", "kernel_loc_regularizer", ",", "\n", "untransformed_scale_regularizer", "=", "kernel_untr_scale_regularizer", "\n", ")", "\n", "\n", "bias_posterior_fn", "=", "tfp", ".", "layers", ".", "default_mean_field_normal_fn", "(", "\n", "loc_initializer", "=", "bias_loc_initializer", ",", "\n", "loc_regularizer", "=", "bias_loc_regularizer", ",", "\n", "is_singular", "=", "True", "\n", ")", "\n", "\n", "prior_kwargs", "=", "kwargs", "[", "\"prior\"", "]", "\n", "\n", "kernel_prior_fn", "=", "load_kernel_prior_fn", "(", "prior_kwargs", ")", "\n", "\n", "\n", "kwargs_bayes", "=", "{", "\n", "\"kernel_prior_fn\"", ":", "kernel_prior_fn", ",", "\n", "\"kernel_posterior_fn\"", ":", "kernel_posterior_fn", ",", "\n", "\"bias_posterior_fn\"", ":", "bias_posterior_fn", ",", "\n", "\"activity_regularizer\"", ":", "activity_regularizer", ",", "\n", "}", "\n", "\n", "return", "kwargs_bayes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.load_kernel_prior_fn": [[110, 182], ["len", "ValueError", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "tensorflow_probability.layers.default_mean_field_normal_fn", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "add_variable_fn", "add_variable_fn", "tensorflow_probability.python.distributions.normal.Normal", "tensorflow.size", "tensorflow_probability.python.distributions.independent.Independent", "tensorflow.nn.softplus", "normal_lib.Normal.batch_shape_tensor"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["", "def", "load_kernel_prior_fn", "(", "prior_kwargs", ")", ":", "\n", "\n", "    ", "default_prior", "=", "prior_kwargs", "[", "\"default\"", "]", "\n", "\n", "if", "default_prior", ":", "\n", "        ", "if", "len", "(", "prior_kwargs", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"If prior is default, no other options should be set in the prior kwargs\"", ")", "\n", "\n", "", "kernel_prior_fn", "=", "tfp", ".", "layers", ".", "default_multivariate_normal_fn", "\n", "\n", "", "else", ":", "\n", "\n", "        ", "trainable", "=", "prior_kwargs", "[", "\"trainable\"", "]", "\n", "\n", "if", "trainable", ":", "\n", "            ", "prior_kernel_loc_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "prior_kwargs", "[", "\"kernel_loc_initializer\"", "]", ")", "\n", "prior_kernel_untr_scale_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "prior_kwargs", "[", "\"kernel_untr_scale_initializer\"", "]", ")", "\n", "kernel_prior_fn", "=", "tfp", ".", "layers", ".", "default_mean_field_normal_fn", "(", "\n", "loc_initializer", "=", "prior_kernel_loc_initializer", ",", "\n", "untransformed_scale_initializer", "=", "prior_kernel_untr_scale_initializer", "\n", ")", "\n", "\n", "# constants do not seems to work, no idea why!", "\n", "# elif prior_kwargs[\"kernel_loc_initializer\"][0]==\"initializers.constant\" and \\", "\n", "#         prior_kwargs[\"kernel_untr_scale_initializer\"][0]==\"initializers.constant\":", "\n", "#", "\n", "#     prior_kernel_loc_value = prior_kwargs[\"kernel_loc_initializer\"][1][\"value\"]", "\n", "#     prior_kernel_untr_scale_value = prior_kwargs[\"kernel_untr_scale_initializer\"][1][\"value\"]", "\n", "#", "\n", "#     def create_fixed_gaussian_prior(dtype, shape, name, trainable, add_variable_fn):", "\n", "#", "\n", "#         prior_loc = tf.constant(prior_kernel_loc_value, dtype=dtype,", "\n", "#                                 shape=shape, name='kernel_prior_loc')", "\n", "#", "\n", "#         # prior_untr_scale = tf.constant(prior_kernel_untr_scale_value, dtype=dtype,", "\n", "#         #                                name='kernel_prior_untransformed_scale')", "\n", "#", "\n", "#         dist = normal_lib.Normal(", "\n", "#             loc=prior_loc, scale=tf.nn.softplus(dtype.as_numpy_dtype(prior_kernel_untr_scale_value)))", "\n", "#", "\n", "#         batch_ndims = tf.size(input=dist.batch_shape_tensor())", "\n", "#", "\n", "#         return independent_lib.Independent(", "\n", "#             dist, reinterpreted_batch_ndims=batch_ndims)", "\n", "#", "\n", "#     kernel_prior_fn = create_fixed_gaussian_prior", "\n", "\n", "", "else", ":", "\n", "            ", "prior_kernel_loc_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "prior_kwargs", "[", "\"kernel_loc_initializer\"", "]", ")", "\n", "prior_kernel_untr_scale_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "prior_kwargs", "[", "\"kernel_untr_scale_initializer\"", "]", ")", "\n", "\n", "def", "create_fixed_gaussian_prior", "(", "dtype", ",", "shape", ",", "name", ",", "trainable", ",", "add_variable_fn", ")", ":", "\n", "\n", "                ", "prior_loc", "=", "add_variable_fn", "(", "'kernel_prior_loc'", ",", "shape", "=", "shape", ",", "dtype", "=", "dtype", ",", "trainable", "=", "False", ",", "\n", "initializer", "=", "prior_kernel_loc_initializer", ")", "\n", "prior_untr_scale", "=", "add_variable_fn", "(", "'kernel_prior_untransformed_scale'", ",", "shape", "=", "(", ")", ",", "dtype", "=", "dtype", ",", "\n", "trainable", "=", "False", ",", "\n", "initializer", "=", "prior_kernel_untr_scale_initializer", ")", "\n", "\n", "dist", "=", "normal_lib", ".", "Normal", "(", "\n", "loc", "=", "prior_loc", ",", "scale", "=", "tf", ".", "nn", ".", "softplus", "(", "prior_untr_scale", ")", ")", "\n", "\n", "batch_ndims", "=", "tf", ".", "size", "(", "input", "=", "dist", ".", "batch_shape_tensor", "(", ")", ")", "\n", "\n", "return", "independent_lib", ".", "Independent", "(", "\n", "dist", ",", "reinterpreted_batch_ndims", "=", "batch_ndims", ")", "\n", "# distr = tfp.distributions.MultivariateNormalDiag(loc=prior_loc, scale_diag=tf.nn.softplus(prior_untr_scale), name=name)", "\n", "# return distr", "\n", "\n", "", "kernel_prior_fn", "=", "create_fixed_gaussian_prior", "\n", "\n", "", "", "return", "kernel_prior_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.parse_init_reg_kwargs": [[183, 206], ["utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["", "def", "parse_init_reg_kwargs", "(", "kwargs", ")", ":", "\n", "    ", "if", "kwargs", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "#initializers", "\n", "", "kernel_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "kwargs", "[", "\"kernel_initializer\"", "]", ")", "\n", "bias_initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "kwargs", "[", "\"bias_initializer\"", "]", ")", "\n", "\n", "# regularizers", "\n", "kernel_regularizer", "=", "eval_method_from_tuple", "(", "tf", ",", "kwargs", "[", "\"kernel_regularizer\"", "]", ")", "\n", "bias_regularizer", "=", "eval_method_from_tuple", "(", "tf", ",", "kwargs", "[", "\"bias_regularizer\"", "]", ")", "\n", "activity_regularizer", "=", "eval_method_from_tuple", "(", "tf", ",", "kwargs", "[", "\"activity_regularizer\"", "]", ")", "\n", "\n", "kwargs", "=", "{", "\n", "\"kernel_initializer\"", ":", "kernel_initializer", ",", "\n", "\"bias_initializer\"", ":", "bias_initializer", ",", "\n", "\n", "\"kernel_regularizer\"", ":", "kernel_regularizer", ",", "\n", "\"bias_regularizer\"", ":", "bias_regularizer", ",", "\n", "\"activity_regularizer\"", ":", "activity_regularizer", ",", "\n", "}", "\n", "\n", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_network_id": [[228, 288], ["hasattr", "re.sub().replace().split", "str", "str", "hasattr", "int", "int", "str", "hasattr", "re.sub().replace", "str().lower", "str", "str", "str", "listWithPoints", "str", "int", "int", "str", "re.sub", "str", "str", "str", "str", "int", "int", "print", "print", "ValueError"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.listWithPoints"], ["def", "get_network_id", "(", "method_tuple", ")", ":", "\n", "    ", "\"\"\"Creates the id for a keras network.\n\n    Args:\n        method_tuple (tuple): A tuple composed of : (name of the keras model builder function, kwargs to pass to the function).\n\n    Returns:\n        string: the idname of the keras network that we want to concatenate in the output filenames.\n\n    \"\"\"", "\n", "\n", "listWithPoints", "=", "lambda", "x", ":", "\".\"", ".", "join", "(", "re", ".", "sub", "(", "'[( )\\[\\]]'", ",", "''", ",", "str", "(", "x", ")", ")", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "\",\"", ")", ")", "\n", "\n", "method_name", "=", "method_tuple", "[", "0", "]", "\n", "method_kwargs", "=", "method_tuple", "[", "1", "]", "\n", "\n", "methodid", "=", "name_short", "[", "method_name", "]", "\n", "\n", "if", "method_name", "in", "[", "'BayesianVgg'", ",", "'BayesianInception'", ",", "'BayesianInception_Basic'", ",", "'BayesianInception_Basic_residual'", "]", ":", "\n", "        ", "methodid", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "method_kwargs", "[", "'flipout'", "]", ")", ")", "\n", "methodid", "+=", "\"_rn\"", "+", "str", "(", "int", "(", "method_kwargs", "[", "'renorm'", "]", ")", ")", "\n", "if", "hasattr", "(", "method_kwargs", ",", "'logits_size'", ")", ":", "\n", "            ", "methodid", "+=", "\"_l\"", "+", "str", "(", "method_kwargs", "[", "'logits_size'", "]", ")", "\n", "\n", "#methodid += \"_f\"+listWithPoints(method_kwargs['filters'])", "\n", "", "methodid", "+=", "\"_\"", "+", "str", "(", "method_kwargs", "[", "'pooling'", "]", ")", ".", "lower", "(", ")", "[", "0", "]", "+", "\"p\"", "\n", "\n", "", "elif", "method_name", "==", "'bayesianTrick_vgg'", ":", "\n", "        ", "if", "hasattr", "(", "method_kwargs", ",", "'logits_size'", ")", ":", "\n", "            ", "methodid", "+=", "\"_l\"", "+", "str", "(", "method_kwargs", "[", "'logits_size'", "]", ")", "\n", "\n", "", "", "elif", "method_name", "in", "[", "'bayesian_resnet'", ",", "'BayesianResNet'", "]", ":", "\n", "        ", "methodid", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "method_kwargs", "[", "'flipout'", "]", ")", ")", "\n", "methodid", "+=", "\"_rn\"", "+", "str", "(", "int", "(", "method_kwargs", "[", "'renorm'", "]", ")", ")", "\n", "if", "hasattr", "(", "method_kwargs", ",", "'logits_size'", ")", ":", "\n", "            ", "methodid", "+=", "\"_l\"", "+", "str", "(", "method_kwargs", "[", "'logits_size'", "]", ")", "\n", "\n", "", "methodid", "+=", "\"_f\"", "+", "listWithPoints", "(", "method_kwargs", "[", "'filters'", "]", ")", "\n", "activation_name", "=", "method_kwargs", "[", "'activation'", "]", "[", "0", "]", "\n", "methodid", "+=", "\"_a\"", "+", "method_name_short", "[", "activation_name", "]", "\n", "\n", "", "elif", "method_name", "==", "'name_net'", ":", "\n", "        ", "methodid", "+=", "str", "(", "method_kwargs", "[", "'name'", "]", ")", "\n", "\n", "", "elif", "method_name", "==", "'MultivariateNormalDiag'", "or", "method_name", "==", "'MultivariateNormalTriL'", ":", "\n", "        ", "methodid", "+=", "\"_b\"", "+", "str", "(", "int", "(", "method_kwargs", "[", "'bayesian_layers'", "]", ")", ")", "\n", "methodid", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "method_kwargs", "[", "'flipout'", "]", ")", ")", "\n", "\n", "", "elif", "method_name", "==", "'OneHotCategorical'", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "method_name", "==", "'BiLSTM'", ":", "\n", "        ", "pass", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'----------------------'", ")", "\n", "print", "(", "'ERROR '", ",", "method_name", ")", "\n", "raise", "ValueError", "(", "\"id rule for keras network `%s` has to be implemented.\"", "%", "method_name", ")", "\n", "\n", "", "return", "methodid", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping": [[289, 324], ["tensorflow.train.get_or_create_global_step", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.constant", "tensorflow.train.polynomial_decay", "tensorflow.constant", "tensorflow.constant", "tensorflow.train.polynomial_decay", "tensorflow.cond", "tensorflow.cond"], "function", ["None"], ["", "def", "get_renorm_clipping", "(", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "# from batch renormalization paper", "\n", "    ", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"renorm_clipping\"", ")", ":", "\n", "\n", "        ", "init_decay_step", "=", "5000", "\n", "decay_global_step", "=", "global_step", "-", "init_decay_step", "\n", "\n", "rmax_initial", "=", "tf", ".", "constant", "(", "1", ",", "dtype", "=", "dtype", ")", "\n", "rmax_final", "=", "tf", ".", "constant", "(", "3", ",", "dtype", "=", "dtype", ")", "\n", "rmax_relax", "=", "tf", ".", "train", ".", "polynomial_decay", "(", "rmax_initial", ",", "\n", "decay_global_step", ",", "\n", "40000", "-", "init_decay_step", ",", "\n", "end_learning_rate", "=", "rmax_final", ",", "\n", "name", "=", "\"rmax\"", ")", "\n", "\n", "dmax_initial", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "dtype", ")", "\n", "dmax_final", "=", "tf", ".", "constant", "(", "5", ",", "dtype", "=", "dtype", ")", "\n", "dmax_relax", "=", "tf", ".", "train", ".", "polynomial_decay", "(", "dmax_initial", ",", "\n", "decay_global_step", ",", "\n", "25000", "-", "init_decay_step", ",", "\n", "end_learning_rate", "=", "dmax_final", ",", "\n", "name", "=", "\"dmax\"", ")", "\n", "\n", "rmax", "=", "tf", ".", "cond", "(", "global_step", "<", "init_decay_step", ",", "lambda", ":", "rmax_initial", ",", "lambda", ":", "rmax_relax", ")", "\n", "dmax", "=", "tf", ".", "cond", "(", "global_step", "<", "init_decay_step", ",", "lambda", ":", "dmax_initial", ",", "lambda", ":", "dmax_relax", ")", "\n", "\n", "renorm_clipping", "=", "{", "\n", "\"rmax\"", ":", "rmax", ",", "\n", "\"rmin\"", ":", "1", "/", "rmax", ",", "\n", "\"dmax\"", ":", "dmax", "\n", "}", "\n", "\n", "", "return", "renorm_clipping", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.parse_layer": [[325, 345], ["utils.argo_utils.try_load_class_from_modules", "utils.argo_utils.try_load_class_from_modules.", "utils.argo_utils.try_load_class_from_modules", "utils.argo_utils.try_load_class_from_modules."], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.try_load_class_from_modules", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.try_load_class_from_modules"], ["", "def", "parse_layer", "(", "layer_tuple", ")", ":", "\n", "# TODO how to implement decorators", "\n", "    ", "decorators", "=", "[", "]", "\n", "try", ":", "\n", "        ", "layer_name", ",", "layer_kwargs", ",", "decorators", "=", "layer_tuple", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "        ", "layer_name", ",", "layer_kwargs", "=", "layer_tuple", "\n", "\n", "", "modules", "=", "[", "tf", ",", "tfp", "]", "\n", "\n", "# load base class and instantiate", "\n", "BaseClass", "=", "try_load_class_from_modules", "(", "layer_name", ",", "modules", ")", "\n", "layer", "=", "BaseClass", "(", "**", "layer_kwargs", ")", "\n", "\n", "# for each decorator decorate it", "\n", "for", "decorator_name", ",", "decorator_kwargs", "in", "decorators", ":", "\n", "        ", "DecoratorClass", "=", "try_load_class_from_modules", "(", "decorator_name", ",", "modules", ")", "\n", "layer", "=", "DecoratorClass", "(", "layer", "=", "layer", ",", "**", "decorator_kwargs", ")", "\n", "\n", "", "return", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.BiLSTM.BiLSTM": [[13, 22], ["tensorflow.keras.Sequential", "tensorflow.keras.layers.Bidirectional", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LSTM"], "function", ["None"], ["def", "BiLSTM", "(", "output_size", ",", "layer_kwargs", "=", "{", "}", ",", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "    ", "model", "=", "tf", ".", "keras", ".", "Sequential", "(", "[", "\n", "tf", ".", "keras", ".", "layers", ".", "Bidirectional", "(", "tf", ".", "keras", ".", "layers", ".", "LSTM", "(", "64", ",", "**", "layer_kwargs", ")", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "64", ",", "activation", "=", "'relu'", ",", "**", "layer_kwargs", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "output_size", ",", "activation", "=", "None", ",", "**", "layer_kwargs", ")", "\n", "]", ")", "\n", "\n", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.MultivariateNormalTriL.MultivariateNormalTriL._id": [[9, 14], ["str", "str", "int", "int"], "methods", ["None"], ["    ", "def", "_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "'TriL'", "\n", "_id", "+=", "\"_b\"", "+", "str", "(", "int", "(", "self", ".", "_bl", ")", ")", "\n", "_id", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "self", ".", "_fl", ")", ")", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.MultivariateNormalTriL.MultivariateNormalTriL.__init__": [[15, 41], ["ArgoKerasModel.ArgoKerasModel.__init__", "tensorflow.keras.layers.Flatten", "functools.partial.", "functools.partial.", "int", "functools.partial.", "MultivariateNormalTriL.MultivariateNormalTriL.add_weight", "tensorflow.contrib.distributions.fill_triangular", "functools.partial", "functools.partial", "functools.partial", "tensorflow.initializers.constant"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "output_size", ",", "bayesian_layers", "=", "False", ",", "flipout", "=", "True", ",", "layer_kwargs", "=", "{", "}", ",", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'TriL'", ")", "\n", "\n", "self", ".", "_bl", "=", "bayesian_layers", "\n", "self", ".", "_fl", "=", "flipout", "\n", "\n", "if", "bayesian_layers", ":", "\n", "            ", "if", "flipout", ":", "\n", "                ", "Dense", "=", "partial", "(", "tfp", ".", "layers", ".", "DenseFlipout", ",", "**", "layer_kwargs_bayes", ")", "\n", "", "else", ":", "\n", "                ", "Dense", "=", "partial", "(", "tfp", ".", "layers", ".", "DenseReparameterization", ",", "**", "layer_kwargs_bayes", ")", "\n", "", "", "else", ":", "\n", "            ", "Dense", "=", "partial", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", ",", "**", "layer_kwargs", ")", "\n", "\n", "", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "self", ".", "dense_loc", "=", "Dense", "(", "output_size", ")", "\n", "self", ".", "dense_diag_params", "=", "Dense", "(", "output_size", ")", "\n", "n_out_of_diag_elems", "=", "int", "(", "output_size", "*", "(", "output_size", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "dense_out_of_diag_params", "=", "Dense", "(", "n_out_of_diag_elems", ")", "\n", "\n", "n_tril", "=", "n_out_of_diag_elems", "+", "output_size", "\n", "self", ".", "_calibration_tril_params", "=", "self", ".", "add_weight", "(", "\"calibration_tril_params\"", ",", "\n", "shape", "=", "(", "n_tril", ",", ")", ",", "\n", "trainable", "=", "False", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "value", "=", "1.", ")", ")", "\n", "self", ".", "calibration_tril", "=", "tf", ".", "contrib", ".", "distributions", ".", "fill_triangular", "(", "self", ".", "_calibration_tril_params", ",", "name", "=", "\"calibration_tril\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.MultivariateNormalTriL.MultivariateNormalTriL.call": [[42, 63], ["MultivariateNormalTriL.MultivariateNormalTriL._flat", "MultivariateNormalTriL.MultivariateNormalTriL.dense_loc", "MultivariateNormalTriL.MultivariateNormalTriL.dense_diag_params", "MultivariateNormalTriL.MultivariateNormalTriL.dense_out_of_diag_params", "tensorflow.contrib.distributions.fill_triangular", "tensorflow.pad", "tensorflow.linalg.set_diag", "tensorflow_probability.distributions.MultivariateNormalTriL", "tensorflow.TensorShape", "tensorflow.nn.softplus", "tensorflow.multiply", "tuple", "tensorflow_probability.distributions.MultivariateNormalTriL.batch_shape.as_list", "tensorflow_probability.distributions.MultivariateNormalTriL.event_shape.as_list"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_flat", "(", "inputs", ")", "\n", "loc", "=", "self", ".", "dense_loc", "(", "inputs", ")", "\n", "diag_params", "=", "self", ".", "dense_diag_params", "(", "inputs", ")", "\n", "out_of_diag_params", "=", "self", ".", "dense_out_of_diag_params", "(", "inputs", ")", "\n", "\n", "lower_triangle", "=", "tf", ".", "contrib", ".", "distributions", ".", "fill_triangular", "(", "out_of_diag_params", ")", "\n", "lower_triangle", "=", "tf", ".", "pad", "(", "lower_triangle", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "\n", "diag_positive", "=", "MINIMAL_COVARIANCE", "+", "tf", ".", "nn", ".", "softplus", "(", "diag_params", ")", "\n", "\n", "scale_tril", "=", "tf", ".", "linalg", ".", "set_diag", "(", "lower_triangle", ",", "diag_positive", ")", "\n", "\n", "ouput_params", "=", "{", "\"loc\"", ":", "loc", ",", "\"scale_tril\"", ":", "tf", ".", "multiply", "(", "self", ".", "calibration_tril", ",", "scale_tril", ")", "}", "\n", "\n", "distr", "=", "tfp", ".", "distributions", ".", "MultivariateNormalTriL", "(", "**", "ouput_params", ")", "\n", "\n", "# hack because keras does not want distr in output... (Riccardo)", "\n", "distr", ".", "shape", "=", "tf", ".", "TensorShape", "(", "tuple", "(", "distr", ".", "batch_shape", ".", "as_list", "(", ")", "+", "distr", ".", "event_shape", ".", "as_list", "(", ")", ")", ")", "\n", "\n", "return", "distr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.ArgoKerasModel.ArgoKerasModel._id": [[6, 9], ["None"], "methods", ["None"], ["    ", "@", "abstractmethod", "\n", "def", "_id", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg.bayesian_vgg": [[5, 73], ["range", "tensorflow.keras.Sequential", "ValueError", "keras_utils.get_renorm_clipping", "len", "bayesian_vgg._vggconv_block", "tensorflow.keras.layers.Flatten", "Dense"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian3D_vgg._vggconv_block"], ["def", "bayesian_vgg", "(", "filters", "=", "[", "16", ",", "16", ",", "32", ",", "32", ",", "32", "]", ",", "#[32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "pooling", "=", "\"max\"", ",", "\n", "renorm", "=", "False", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "    ", "\"\"\"Constructs a VGG16 model.\n\n    Args:\n    input_shape: A `tuple` indicating the Tensor shape.\n    num_classes: `int` representing the number of class labels.\n    kernel_posterior_scale_mean: Python `int` number for the kernel\n      posterior's scale (log variance) mean. The smaller the mean the closer\n      is the initialization to a deterministic network.\n    kernel_posterior_scale_stddev: Python `float` number for the initial kernel\n      posterior's scale stddev.\n      ```\n      q(W|x) ~ N(mu, var),\n      log_var ~ N(kernel_posterior_scale_mean, kernel_posterior_scale_stddev)\n      ````\n    kernel_posterior_scale_constraint: Python `float` number for the log value\n      to constrain the log variance throughout training.\n      i.e. log_var <= log(kernel_posterior_scale_constraint).\n\n    Returns:\n    tf.keras.Model.\n    \"\"\"", "\n", "\n", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", ",", "None", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "        ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "flipout", ":", "\n", "        ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "        ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "        ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "", "layers_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "kernels", ")", ")", ":", "\n", "        ", "layers_list", "+=", "_vggconv_block", "(", "\n", "Conv2D", ",", "\n", "filters", "[", "i", "]", ",", "\n", "kernels", "[", "i", "]", ",", "\n", "strides", "[", "i", "]", ",", "\n", "pooling", ",", "\n", "renorm", ",", "\n", "renorm_clipping", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "# if logits_size is specified I add an extra Dense layer", "\n", "", "if", "logits_size", "is", "not", "None", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", ",", "\n", "Dense", "(", "\n", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", "]", "\n", "", "model", "=", "tf", ".", "keras", ".", "Sequential", "(", "layers_list", ",", "name", "=", "'vgg'", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg._vggconv_block": [[75, 109], ["bayesian_vgg.get_conv_stride", "Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.LeakyReLU", "Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.AveragePooling2D"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian3D_vgg.get_conv_stride"], ["", "def", "_vggconv_block", "(", "Conv2D", ",", "filters", ",", "kernel", ",", "stride", ",", "pooling", ",", "renorm", ",", "renorm_clipping", ",", "**", "layer_kwargs_bayes", ")", ":", "\n", "    ", "\"\"\"Network block for VGG.\"\"\"", "\n", "\n", "layers_list", "=", "[", "\n", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "layer_kwargs_bayes", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", ")", "]", "\n", "\n", "conv_stride", "=", "get_conv_stride", "(", "pooling", ",", "stride", ")", "\n", "\n", "layers_list", "+=", "[", "\n", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "strides", "=", "conv_stride", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "layer_kwargs_bayes", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", ")", "]", "\n", "\n", "if", "pooling", "==", "\"max\"", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "]", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "]", "\n", "\n", "", "return", "layers_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg.get_conv_stride": [[111, 119], ["None"], "function", ["None"], ["", "def", "get_conv_stride", "(", "pooling", ",", "stride", ")", ":", "\n", "\n", "    ", "if", "pooling", "is", "None", ":", "\n", "        ", "conv_stride", "=", "stride", "\n", "", "else", ":", "\n", "        ", "conv_stride", "=", "1", "\n", "\n", "", "return", "conv_stride", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.bayesian_vgg_LSS": [[5, 82], ["bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.pool", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.pool", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.pool", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.pool", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.Blocks", "bayesian_vgg_LSS.pool", "tensorflow.keras.Sequential", "ValueError", "keras_utils.get_renorm_clipping", "tensorflow.keras.layers.Flatten", "Dense"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.pool", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.pool", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.pool", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.pool", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.pool", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["def", "bayesian_vgg_LSS", "(", "filters", "=", "[", "32", ",", "64", ",", "128", ",", "256", "]", ",", "#[32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "pooling", "=", "\"max\"", ",", "\n", "renorm", "=", "False", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "    ", "\"\"\"Constructs a VGG16 model.\n\n    Args:\n    input_shape: A `tuple` indicating the Tensor shape.\n    num_classes: `int` representing the number of class labels.\n    kernel_posterior_scale_mean: Python `int` number for the kernel\n      posterior's scale (log variance) mean. The smaller the mean the closer\n      is the initialization to a deterministic network.\n    kernel_posterior_scale_stddev: Python `float` number for the initial kernel\n      posterior's scale stddev.\n      ```\n      q(W|x) ~ N(mu, var),\n      log_var ~ N(kernel_posterior_scale_mean, kernel_posterior_scale_stddev)\n      ````\n    kernel_posterior_scale_constraint: Python `float` number for the log value\n      to constrain the log variance throughout training.\n      i.e. log_var <= log(kernel_posterior_scale_constraint).\n\n    Returns:\n    tf.keras.Model.\n    \"\"\"", "\n", "\n", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", ",", "None", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "        ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "flipout", ":", "\n", "        ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "        ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "        ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "", "layers_list", "=", "[", "]", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "0", "]", ",", "kernels", "[", "0", "]", ",", "renorm", ",", "renorm_clipping", ",", "2", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "pool", "(", "pooling", ",", "strides", "[", "0", "]", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "1", "]", ",", "kernels", "[", "1", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "0", "]", ",", "1", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "1", "]", ",", "kernels", "[", "1", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "pool", "(", "pooling", ",", "strides", "[", "1", "]", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "2", "]", ",", "kernels", "[", "2", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "1", "]", ",", "1", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "2", "]", ",", "kernels", "[", "2", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "pool", "(", "pooling", ",", "strides", "[", "2", "]", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "3", "]", ",", "kernels", "[", "3", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "2", "]", ",", "1", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "3", "]", ",", "kernels", "[", "3", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "pool", "(", "pooling", ",", "strides", "[", "3", "]", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "3", "]", ",", "kernels", "[", "3", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "2", "]", ",", "1", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "3", "]", ",", "kernels", "[", "3", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "2", "]", ",", "1", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "Blocks", "(", "Conv2D", ",", "filters", "[", "3", "]", ",", "kernels", "[", "3", "]", ",", "renorm", ",", "renorm_clipping", ",", "1", ",", "bn_last", "=", "False", ",", "**", "layer_kwargs_bayes", ")", "\n", "layers_list", "+=", "pool", "(", "pooling", ",", "strides", "[", "3", "]", ")", "\n", "\n", "# if logits_size is specified I add an extra Dense layer", "\n", "if", "logits_size", "is", "not", "None", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", ",", "\n", "Dense", "(", "\n", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", "]", "\n", "", "model", "=", "tf", ".", "keras", ".", "Sequential", "(", "layers_list", ",", "name", "=", "'vgg'", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.Blocks": [[125, 138], ["Conv2D", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.BatchNormalization"], "function", ["None"], ["", "def", "Blocks", "(", "Conv2D", ",", "filters", ",", "kernel", ",", "renorm", ",", "renorm_clipping", ",", "n_times", ",", "bn_last", "=", "True", ",", "**", "layer_kwargs_bayes", ")", ":", "\n", "    ", "layers_list", "=", "[", "\n", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "padding", "=", "'valid'", ",", "\n", "**", "layer_kwargs_bayes", ")", "]", "\n", "if", "bn_last", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", "]", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", ")", "]", "\n", "return", "layers_list", "*", "n_times", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_vgg_LSS.pool": [[140, 146], ["tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.AveragePooling2D"], "function", ["None"], ["", "def", "pool", "(", "pooling", ",", "stride", ")", ":", "\n", "    ", "if", "pooling", "==", "\"max\"", ":", "\n", "            ", "layers_list", "=", "[", "tf", ".", "keras", ".", "layers", ".", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "]", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "            ", "layers_list", "=", "[", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "]", "\n", "", "return", "layers_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_alex_net.bayesian_alex_net": [[5, 64], ["functools.partial", "tensorflow.keras.Sequential", "range", "tf.keras.Sequential.add", "ValueError", "len", "tf.keras.Sequential.add", "Conv2D", "tf.keras.Sequential.add", "tf.keras.Sequential.add", "Conv2D", "tf.keras.Sequential.add", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "Pool"], "function", ["None"], ["def", "bayesian_alex_net", "(", "\n", "filters", "=", "[", "32", ",", "32", ",", "32", ",", "32", ",", "32", "]", ",", "# [32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "7", ",", "5", ",", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "4", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "renorm", "=", "False", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "pooling", "=", "\"avg\"", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "    ", "if", "flipout", ":", "\n", "        ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "        ", "Conv2D", "=", "tfp", ".", "layers", ".", "Convolution2DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "        ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "pooling", "==", "\"max\"", ":", "\n", "        ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPooling2D", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "        ", "Pool", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "\n", "\n", "", "activation", "=", "partial", "(", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "\n", "_cnn", "=", "tf", ".", "keras", ".", "Sequential", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "filters", ")", ")", ":", "\n", "        ", "_cnn", ".", "add", "(", "Conv2D", "(", "filters", "[", "i", "]", ",", "\n", "kernel_size", "=", "kernels", "[", "i", "]", ",", "\n", "padding", "=", "\"SAME\"", ",", "\n", "activation", "=", "activation", ",", "\n", "**", "layer_kwargs_bayes", ")", ")", "\n", "if", "i", "==", "0", "or", "i", "==", "1", "or", "i", "==", "4", ":", "\n", "            ", "_cnn", ".", "add", "(", "Pool", "(", "pool_size", "=", "[", "2", ",", "2", "]", ",", "strides", "=", "strides", "[", "i", "]", ",", "padding", "=", "\"SAME\"", ")", ")", "\n", "\n", "\n", "", "", "_cnn", ".", "add", "(", "Conv2D", "(", "32", ",", "\n", "kernel_size", "=", "1", ",", "\n", "padding", "=", "\"SAME\"", ",", "\n", "activation", "=", "activation", ",", "\n", "**", "layer_kwargs_bayes", ")", ")", "\n", "\n", "# _cnn.add(Conv2D(32,", "\n", "#                  kernel_size=1,", "\n", "#                  padding=\"SAME\",", "\n", "#                  activation=activation,", "\n", "#                  **layer_kwargs_bayes))", "\n", "\n", "if", "logits_size", "is", "not", "None", ":", "\n", "        ", "_cnn", ".", "add", "(", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", ")", "\n", "_cnn", ".", "add", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", ")", "\n", "\n", "", "return", "_cnn", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_resnet.ResnetBlock.__init__": [[103, 116], ["super().__init__", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kernel_size", ",", "filters", ",", "conv_type", "=", "\"base\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'resnet_block'", ")", "\n", "\n", "filters1", ",", "filters2", ",", "filters3", "=", "filters", "\n", "\n", "self", ".", "conv2a", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters1", ",", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "bn2a", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "\n", "\n", "self", ".", "conv2b", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters2", ",", "kernel_size", ",", "padding", "=", "'same'", ")", "\n", "self", ".", "bn2b", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "\n", "\n", "self", ".", "conv2c", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters3", ",", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "bn2c", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_resnet.ResnetBlock.call": [[117, 131], ["bayesian_resnet.ResnetBlock.conv2a", "bayesian_resnet.ResnetBlock.bn2a", "tensorflow.nn.relu", "bayesian_resnet.ResnetBlock.conv2b", "bayesian_resnet.ResnetBlock.bn2b", "tensorflow.nn.relu", "bayesian_resnet.ResnetBlock.conv2c", "bayesian_resnet.ResnetBlock.bn2c", "tensorflow.nn.relu"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input_tensor", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv2a", "(", "input_tensor", ")", "\n", "x", "=", "self", ".", "bn2a", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2b", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2b", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2c", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2c", "(", "x", ",", "training", "=", "training", ")", "\n", "\n", "x", "+=", "input_tensor", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_resnet.bayesian_resnet": [[6, 60], ["prediction.argo.core.keras_models.keras_utils.get_kwargs_bayes", "tensorflow.keras.layers.Input", "range", "tensorflow.keras.Model", "tensorflow_probability.layers.Convolution2DFlipout", "len", "bayesian_resnet._resnet_block", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.AveragePooling2D", "tensorflow.keras.layers.Flatten", "tensorflow_probability.layers.DenseFlipout"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_resnet._resnet_block"], ["def", "bayesian_resnet", "(", "input_shape", ",", "\n", "logits_size", "=", "2", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet18 model.\n    Args:\n    input_shape: A `tuple` indicating the Tensor shape.\n    output_size: `int` representing the output size.\n    kernel_posterior_scale_mean: Python `int` number for the kernel\n      posterior's scale (log variance) mean. The smaller the mean the closer\n      is the initialization to a deterministic network.\n    kernel_posterior_scale_stddev: Python `float` number for the initial kernel\n      posterior's scale stddev.\n      ```\n      q(W|x) ~ N(mu, var),\n      log_var ~ N(kernel_posterior_scale_mean, kernel_posterior_scale_stddev)\n      ````\n    kernel_posterior_scale_constraint: Python `float` number for the log value\n      to constrain the log variance throughout training.\n      i.e. log_var <= log(kernel_posterior_scale_constraint).\n    Returns:\n    tf.keras.Model.\n    \"\"\"", "\n", "\n", "filters", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", ",", "3", "]", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", "]", "\n", "kwargs_bayes", "=", "get_kwargs_bayes", "(", ")", "\n", "\n", "image", "=", "tf", ".", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "input_shape", ",", "dtype", "=", "'float32'", ")", "\n", "x", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "(", "\n", "64", ",", "\n", "3", ",", "\n", "strides", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "kwargs_bayes", ")", "(", "image", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "kernels", ")", ")", ":", "\n", "        ", "x", "=", "_resnet_block", "(", "\n", "x", ",", "\n", "filters", "[", "i", "]", ",", "\n", "kernels", "[", "i", "]", ",", "\n", "strides", "[", "i", "]", ",", "\n", "**", "kwargs_bayes", ")", "\n", "\n", "", "x", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "AveragePooling2D", "(", "4", ",", "1", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "(", "x", ")", "\n", "\n", "x", "=", "tfp", ".", "layers", ".", "DenseFlipout", "(", "\n", "logits_size", ",", "\n", "**", "kwargs_bayes", ")", "(", "x", ")", "\n", "\n", "model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "image", ",", "outputs", "=", "x", ",", "name", "=", "'resnet18'", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_resnet._resnet_block": [[62, 89], ["tensorflow.keras.layers.add", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "bayesian_resnet._projection_shortcut", "tensorflow_probability.layers.Convolution2DFlipout", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow_probability.layers.Convolution2DFlipout"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_resnet._projection_shortcut"], ["", "def", "_resnet_block", "(", "x", ",", "filters", ",", "kernel", ",", "stride", ",", "**", "kwargs_bayes", ")", ":", "\n", "    ", "\"\"\"Network block for ResNet.\"\"\"", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "filters", "!=", "x", ".", "shape", "[", "1", "]", ":", "\n", "        ", "shortcut", "=", "_projection_shortcut", "(", "x", ",", "filters", ",", "stride", ",", "**", "kwargs_bayes", ")", "\n", "", "else", ":", "\n", "        ", "shortcut", "=", "x", "\n", "\n", "", "x", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "strides", "=", "stride", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "kwargs_bayes", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "\n", "x", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "strides", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "kwargs_bayes", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "add", "(", "[", "x", ",", "shortcut", "]", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian_resnet._projection_shortcut": [[91, 99], ["tensorflow_probability.layers.Convolution2DFlipout"], "function", ["None"], ["", "def", "_projection_shortcut", "(", "x", ",", "out_filters", ",", "stride", ",", "**", "kwargs_bayes", ")", ":", "\n", "    ", "x", "=", "tfp", ".", "layers", ".", "Convolution2DFlipout", "(", "\n", "out_filters", ",", "\n", "1", ",", "\n", "strides", "=", "stride", ",", "\n", "padding", "=", "'valid'", ",", "\n", "**", "kwargs_bayes", ")", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian3D_vgg.bayesian3D_vgg": [[5, 73], ["range", "tensorflow.keras.Sequential", "ValueError", "keras_utils.get_renorm_clipping", "len", "bayesian3D_vgg._vggconv_block", "tensorflow.keras.layers.Flatten", "Dense"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping", "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian3D_vgg._vggconv_block"], ["def", "bayesian3D_vgg", "(", "filters", "=", "[", "32", ",", "64", ",", "128", "]", ",", "#[32, 64, 64, 128, 128],", "\n", "kernels", "=", "[", "3", ",", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", ",", "2", "]", ",", "\n", "logits_size", "=", "None", ",", "\n", "flipout", "=", "True", ",", "\n", "pooling", "=", "\"max\"", ",", "\n", "renorm", "=", "False", ",", "\n", "layer_kwargs", "=", "{", "}", ",", "\n", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "\n", "    ", "\"\"\"Constructs a VGG16 model.\n\n    Args:\n    input_shape: A `tuple` indicating the Tensor shape.\n    num_classes: `int` representing the number of class labels.\n    kernel_posterior_scale_mean: Python `int` number for the kernel\n      posterior's scale (log variance) mean. The smaller the mean the closer\n      is the initialization to a deterministic network.\n    kernel_posterior_scale_stddev: Python `float` number for the initial kernel\n      posterior's scale stddev.\n      ```\n      q(W|x) ~ N(mu, var),\n      log_var ~ N(kernel_posterior_scale_mean, kernel_posterior_scale_stddev)\n      ````\n    kernel_posterior_scale_constraint: Python `float` number for the log value\n      to constrain the log variance throughout training.\n      i.e. log_var <= log(kernel_posterior_scale_constraint).\n\n    Returns:\n    tf.keras.Model.\n    \"\"\"", "\n", "\n", "pooling_choices", "=", "[", "\"max\"", ",", "\"avg\"", ",", "None", "]", "\n", "if", "pooling", "not", "in", "pooling_choices", ":", "\n", "        ", "raise", "ValueError", "(", "\"pooling must be in {:}, instead {:} found.\"", ".", "format", "(", "pooling_choices", ",", "pooling", ")", ")", "\n", "\n", "", "if", "flipout", ":", "\n", "        ", "Conv3D", "=", "tfp", ".", "layers", ".", "Convolution3DFlipout", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseFlipout", "\n", "", "else", ":", "\n", "        ", "Conv3D", "=", "tfp", ".", "layers", ".", "Convolution3DReparameterization", "\n", "Dense", "=", "tfp", ".", "layers", ".", "DenseReparameterization", "\n", "\n", "", "renorm_clipping", "=", "None", "\n", "if", "renorm", ":", "\n", "        ", "renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "", "layers_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "kernels", ")", ")", ":", "\n", "        ", "layers_list", "+=", "_vggconv_block", "(", "\n", "Conv3D", ",", "\n", "filters", "[", "i", "]", ",", "\n", "kernels", "[", "i", "]", ",", "\n", "strides", "[", "i", "]", ",", "\n", "pooling", ",", "\n", "renorm", ",", "\n", "renorm_clipping", ",", "\n", "**", "layer_kwargs_bayes", ")", "\n", "\n", "# if logits_size is specified I add an extra Dense layer", "\n", "", "if", "logits_size", "is", "not", "None", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", ",", "\n", "Dense", "(", "\n", "logits_size", ",", "\n", "**", "layer_kwargs_bayes", ")", "]", "\n", "", "model", "=", "tf", ".", "keras", ".", "Sequential", "(", "layers_list", ",", "name", "=", "'vgg'", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian3D_vgg._vggconv_block": [[75, 109], ["bayesian3D_vgg.get_conv_stride", "Conv3D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.LeakyReLU", "Conv3D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.MaxPooling3D", "tensorflow.keras.layers.AveragePooling3D"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian3D_vgg.get_conv_stride"], ["", "def", "_vggconv_block", "(", "Conv3D", ",", "filters", ",", "kernel", ",", "stride", ",", "pooling", ",", "renorm", ",", "renorm_clipping", ",", "**", "layer_kwargs_bayes", ")", ":", "\n", "    ", "\"\"\"Network block for VGG.\"\"\"", "\n", "\n", "layers_list", "=", "[", "\n", "Conv3D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "layer_kwargs_bayes", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", ")", "]", "\n", "\n", "conv_stride", "=", "get_conv_stride", "(", "pooling", ",", "stride", ")", "\n", "\n", "layers_list", "+=", "[", "\n", "Conv3D", "(", "\n", "filters", ",", "\n", "kernel", ",", "\n", "strides", "=", "conv_stride", ",", "\n", "padding", "=", "'same'", ",", "\n", "**", "layer_kwargs_bayes", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", "renorm", "=", "renorm", ",", "renorm_clipping", "=", "renorm_clipping", ")", ",", "\n", "\n", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", ")", "]", "\n", "\n", "if", "pooling", "==", "\"max\"", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "MaxPooling3D", "(", "pool_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "]", "\n", "", "elif", "pooling", "==", "\"avg\"", ":", "\n", "        ", "layers_list", "+=", "[", "tf", ".", "keras", ".", "layers", ".", "AveragePooling3D", "(", "pool_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "strides", "=", "stride", ")", "]", "\n", "\n", "", "return", "layers_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.deprecated.bayesian3D_vgg.get_conv_stride": [[111, 119], ["None"], "function", ["None"], ["", "def", "get_conv_stride", "(", "pooling", ",", "stride", ")", ":", "\n", "\n", "    ", "if", "pooling", "is", "None", ":", "\n", "        ", "conv_stride", "=", "stride", "\n", "", "else", ":", "\n", "        ", "conv_stride", "=", "1", "\n", "\n", "", "return", "conv_stride", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.__init__": [[13, 24], ["super().__init__", "utils.argo_utils.update_conf_with_defaults"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.update_conf_with_defaults"], ["def", "__init__", "(", "self", ",", "opts", ",", "name", ",", "seed", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_opts_original", "=", "opts", "\n", "self", ".", "_opts", "=", "update_conf_with_defaults", "(", "opts", ",", "self", ".", "default_params", ")", "\n", "\n", "self", ".", "_seed", "=", "seed", "\n", "\n", "self", ".", "_name", "=", "name", "\n", "# self._seed = seed", "\n", "self", ".", "_saver", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.create_id": [[26, 28], ["None"], "methods", ["None"], ["", "def", "create_id", "(", "self", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.get_variables": [[29, 41], ["None"], "methods", ["None"], ["", "def", "get_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\" overwrites the default collection to filter the variables,\n        the default for Sonnet module is collection=tf.GraphKeys.TRAINABLE_VARIABLES\n        that excludes moving mean and standard deviations for example.\n\n        Returns:\n            variables defined in the scope of the Module\n\n        see more in `AbstractModule.get_variables` documentation\n        \"\"\"", "\n", "\n", "return", "self", ".", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.get_all_variables": [[42, 54], ["None"], "methods", ["None"], ["", "def", "get_all_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\" overwrites the default collection to filter the variables,\n        the default for Sonnet module is collection=tf.GraphKeys.TRAINABLE_VARIABLES\n        that excludes moving mean and standard deviations for example.\n\n        Returns:\n            variables defined in the scope of the Module\n\n        see more in `AbstractModule.get_variables` documentation\n        \"\"\"", "\n", "\n", "return", "self", ".", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.init_saver": [[55, 68], ["tensorflow.train.Saver", "ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.get_variables"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables"], ["", "def", "init_saver", "(", "self", ",", "variables", "=", "None", ")", ":", "\n", "        ", "\"\"\"This set the saver for a network. It has to be invoked only when the Model has been connected\n\n        Args:\n            variables (list): A list of variables to save and restore, by default all the variables of the module\n            (instantiated till this precise moment) will be tracked\n\n        \"\"\"", "\n", "\n", "if", "not", "variables", ":", "\n", "            ", "variables", "=", "self", ".", "get_variables", "(", ")", "\n", "\n", "", "self", ".", "_saver", "=", "tf", ".", "train", ".", "Saver", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.save_argo": [[69, 74], ["ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork._saver.save", "ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.init_saver"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.init_saver"], ["", "def", "save_argo", "(", "self", ",", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "_saver", "is", "None", ":", "\n", "            ", "self", ".", "init_saver", "(", ")", "\n", "\n", "", "self", ".", "_saver", ".", "save", "(", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.restore": [[75, 80], ["ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork._saver.restore", "ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.init_saver"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.init_saver"], ["", "def", "restore", "(", "self", ",", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "_saver", "is", "None", ":", "\n", "            ", "self", ".", "init_saver", "(", ")", "\n", "\n", "", "self", ".", "_saver", ".", "restore", "(", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractResNetLayer.AbstractResNetLayer.__init__": [[10, 46], ["sonnet.AbstractModule.__init__", "keras_models.keras_utils.get_renorm_clipping"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["def", "__init__", "(", "self", ",", "num_hiddens", ",", "num_residual_layers", ",", "num_residual_hiddens", ",", "\n", "activation", ",", "\n", "is_training", ",", "\n", "name", "=", "'res'", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "bn_renormalization", "=", "True", ",", "\n", "**", "extra_params", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            num_outputs (type): number of outputs of the module.\n            name (type): module name.\n            activation (type): activation used for the internal layers.\n            **extra_params (type): alls the additional keyword arguments will be passed to the snt.Conv2D layers. (initializers, regularizers)\n\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_num_hiddens", "=", "num_hiddens", "\n", "self", ".", "_num_residual_layers", "=", "num_residual_layers", "\n", "self", ".", "_num_residual_hiddens", "=", "num_residual_hiddens", "\n", "\n", "self", ".", "_prob_drop", "=", "prob_drop", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "\n", "self", ".", "_bn_renormalization", "=", "bn_renormalization", "\n", "# instantiate all the convolutional layers", "\n", "\n", "self", ".", "_bn_momentum", "=", "bn_momentum", "\n", "\n", "self", ".", "_renorm_clipping", "=", "None", "\n", "if", "self", ".", "_bn_renormalization", ":", "\n", "            ", "self", ".", "_renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "", "self", ".", "_is_training", "=", "is_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractResNetLayer.AbstractResNetLayer._dropout": [[47, 50], ["tensorflow.layers.dropout"], "methods", ["None"], ["", "def", "_dropout", "(", "self", ",", "net", ",", "training", ")", ":", "\n", "        ", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "self", ".", "_prob_drop", ",", "training", "=", "training", ")", "\n", "return", "net", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianDiagonalPlusMinusOne.GaussianDiagonalPlusMinusOne.__init__": [[15, 36], ["AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'gaussian_diagonal_zero_one'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianDiagonalPlusMinusOne.GaussianDiagonalPlusMinusOne._build": [[37, 60], ["GaussianDiagonalPlusMinusOne.GaussianDiagonalPlusMinusOne.create_mean_n_cov_layers", "tensorflow.tanh", "GaussianDiagonalPlusMinusOne.GaussianDiagonalPlusMinusOne.set_contractive_regularizer", "tensorflow_probability.distributions.Normal", "types.MethodType", "types.MethodType", "GaussianDiagonalPlusMinusOne.GaussianDiagonalPlusMinusOne.mean", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "mean_plus_minus_one", "=", "tf", ".", "tanh", "(", "mean", ")", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "mean_plus_minus_one", ",", "covariance", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "output_distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "mean_plus_minus_one", ",", "scale", "=", "scale", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "def", "distribution_parameters", "(", "self", ")", ":", "\n", "            ", "return", "[", "mean_plus_minus_one", ",", "np", ".", "square", "(", "scale", ")", "]", "\n", "", "output_distribution", ".", "distribution_parameters", "=", "types", ".", "MethodType", "(", "distribution_parameters", ",", "output_distribution", ")", "\n", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.PlusMinusOneMapping.PlusMinusOneMapping.__init__": [[11, 16], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "name", "=", "'affine_scalar'", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'harmonic_bijector'", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.PlusMinusOneMapping.PlusMinusOneMapping._inverse_log_det_jacobian": [[18, 20], ["tensorflow.zeros"], "methods", ["None"], ["", "def", "_inverse_log_det_jacobian", "(", "self", ",", "y", ")", ":", "\n", "        ", "return", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "y", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.PlusMinusOneMapping.PlusMinusOneMapping._forward_log_det_jacobian": [[21, 23], ["tensorflow.zeros"], "methods", ["None"], ["", "def", "_forward_log_det_jacobian", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork.__init__": [[30, 44], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", "=", "-", "1", ",", "shape", "=", "-", "1", ",", "\n", "initializers", "=", "{", "}", ",", "regularizers", "=", "{", "}", ",", "\n", "name", "=", "'CIFAR10TutorialNetwork'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "'''\n        assert xor(size==-1,shape==-1), \"Either size or shape mut be specified, not both\"\n        \n        if size!=-1:\n            self._shape = [size]\n        else:\n            self._shape = shape\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._build": [[46, 136], ["tensorflow.nn.max_pool", "tensorflow.nn.lrn", "tensorflow.nn.lrn", "tensorflow.nn.max_pool", "tensorflow.variable_scope", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "tensorflow.nn.conv2d", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "tensorflow.nn.bias_add", "tensorflow.nn.relu", "tensorflow.variable_scope", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "tensorflow.nn.conv2d", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "tensorflow.nn.bias_add", "tensorflow.nn.relu", "tensorflow.variable_scope", "int", "tensorflow.reshape", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "tensorflow.nn.relu", "tensorflow.variable_scope", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "tensorflow.nn.relu", "tensorflow.variable_scope", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "tensorflow.add", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.matmul", "tensorflow.reshape.get_shape", "tensorflow.matmul", "tensorflow.matmul", "numpy.prod", "inputs.get_shape().as_list", "inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay", "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "\"\"\"Build the CIFAR-10 model.\n        Args:\n        images: Images returned from distorted_inputs() or inputs().\n        Returns:\n        Logits.\n        \"\"\"", "\n", "\n", "# We instantiate all variables using tf.get_variable() instead of", "\n", "# tf.Variable() in order to share variables across multiple GPU training runs.", "\n", "# If we only ran this model on a single GPU, we could simplify this function", "\n", "# by replacing all instances of tf.get_variable() with tf.Variable().", "\n", "\n", "NUM_CLASSES", "=", "10", "\n", "\n", "# conv1", "\n", "with", "tf", ".", "variable_scope", "(", "'conv1'", ")", "as", "scope", ":", "\n", "            ", "kernel", "=", "self", ".", "_variable_with_weight_decay", "(", "'weights'", ",", "\n", "shape", "=", "[", "5", ",", "5", ",", "3", ",", "64", "]", ",", "\n", "stddev", "=", "5e-2", ",", "\n", "wd", "=", "None", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs", ",", "kernel", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "biases", "=", "self", ".", "_variable_on_cpu", "(", "'biases'", ",", "[", "64", "]", ",", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "pre_activation", "=", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "biases", ")", "\n", "conv1", "=", "tf", ".", "nn", ".", "relu", "(", "pre_activation", ",", "name", "=", "scope", ".", "name", ")", "\n", "#_activation_summary(conv1)", "\n", "\n", "# pool1", "\n", "", "pool1", "=", "tf", ".", "nn", ".", "max_pool", "(", "conv1", ",", "ksize", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ",", "name", "=", "'pool1'", ")", "\n", "# norm1", "\n", "norm1", "=", "tf", ".", "nn", ".", "lrn", "(", "pool1", ",", "4", ",", "bias", "=", "1.0", ",", "alpha", "=", "0.001", "/", "9.0", ",", "beta", "=", "0.75", ",", "\n", "name", "=", "'norm1'", ")", "\n", "\n", "# conv2", "\n", "with", "tf", ".", "variable_scope", "(", "'conv2'", ")", "as", "scope", ":", "\n", "            ", "kernel", "=", "self", ".", "_variable_with_weight_decay", "(", "'weights'", ",", "\n", "shape", "=", "[", "5", ",", "5", ",", "64", ",", "64", "]", ",", "\n", "stddev", "=", "5e-2", ",", "\n", "wd", "=", "None", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "norm1", ",", "kernel", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "biases", "=", "self", ".", "_variable_on_cpu", "(", "'biases'", ",", "[", "64", "]", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "pre_activation", "=", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "biases", ")", "\n", "conv2", "=", "tf", ".", "nn", ".", "relu", "(", "pre_activation", ",", "name", "=", "scope", ".", "name", ")", "\n", "#_activation_summary(conv2)", "\n", "\n", "# norm2", "\n", "", "norm2", "=", "tf", ".", "nn", ".", "lrn", "(", "conv2", ",", "4", ",", "bias", "=", "1.0", ",", "alpha", "=", "0.001", "/", "9.0", ",", "beta", "=", "0.75", ",", "\n", "name", "=", "'norm2'", ")", "\n", "# pool2", "\n", "pool2", "=", "tf", ".", "nn", ".", "max_pool", "(", "norm2", ",", "ksize", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "padding", "=", "'SAME'", ",", "name", "=", "'pool2'", ")", "\n", "\n", "# local3", "\n", "with", "tf", ".", "variable_scope", "(", "'local3'", ")", "as", "scope", ":", "\n", "# Move everything into depth so we can perform a single matrix multiply.", "\n", "\n", "#reshape = tf.reshape(pool2, [inputs.get_shape().as_list()[0], -1])", "\n", "            ", "l", "=", "int", "(", "np", ".", "prod", "(", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "/", "3", "*", "4", ")", "\n", "#pdb.set_trace()", "\n", "reshape", "=", "tf", ".", "reshape", "(", "pool2", ",", "[", "-", "1", ",", "l", "]", ")", "\n", "dim", "=", "reshape", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "weights", "=", "self", ".", "_variable_with_weight_decay", "(", "'weights'", ",", "shape", "=", "[", "dim", ",", "300", "]", ",", "\n", "stddev", "=", "0.04", ",", "wd", "=", "0.004", ")", "\n", "biases", "=", "self", ".", "_variable_on_cpu", "(", "'biases'", ",", "[", "300", "]", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "local3", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "reshape", ",", "weights", ")", "+", "biases", ",", "name", "=", "scope", ".", "name", ")", "\n", "#_activation_summary(local3)", "\n", "\n", "# local4", "\n", "", "with", "tf", ".", "variable_scope", "(", "'local4'", ")", "as", "scope", ":", "\n", "            ", "weights", "=", "self", ".", "_variable_with_weight_decay", "(", "'weights'", ",", "shape", "=", "[", "300", ",", "150", "]", ",", "\n", "stddev", "=", "0.04", ",", "wd", "=", "0.004", ")", "\n", "biases", "=", "self", ".", "_variable_on_cpu", "(", "'biases'", ",", "[", "150", "]", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "local4", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "local3", ",", "weights", ")", "+", "biases", ",", "name", "=", "scope", ".", "name", ")", "\n", "#_activation_summary(local4)", "\n", "\n", "# linear layer(WX + b),", "\n", "# We don't apply softmax here because", "\n", "# tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits", "\n", "# and performs the softmax internally for efficiency.", "\n", "", "with", "tf", ".", "variable_scope", "(", "'softmax_linear'", ")", "as", "scope", ":", "\n", "            ", "weights", "=", "self", ".", "_variable_with_weight_decay", "(", "'weights'", ",", "[", "150", ",", "NUM_CLASSES", "]", ",", "\n", "stddev", "=", "1", "/", "150.0", ",", "wd", "=", "None", ")", "\n", "biases", "=", "self", ".", "_variable_on_cpu", "(", "'biases'", ",", "[", "NUM_CLASSES", "]", ",", "\n", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "softmax_linear", "=", "tf", ".", "add", "(", "tf", ".", "matmul", "(", "local4", ",", "weights", ")", ",", "biases", ",", "name", "=", "scope", ".", "name", ")", "\n", "#_activation_summary(softmax_linear)", "\n", "\n", "", "return", "softmax_linear", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_with_weight_decay": [[137, 159], ["CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu", "tensorflow.truncated_normal_initializer", "tensorflow.multiply", "tensorflow.add_to_collection", "tensorflow.nn.l2_loss"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu"], ["", "def", "_variable_with_weight_decay", "(", "self", ",", "name", ",", "shape", ",", "stddev", ",", "wd", ")", ":", "\n", "        ", "\"\"\"Helper to create an initialized Variable with weight decay.\n        Note that the Variable is initialized with a truncated normal distribution.\n        A weight decay is added only if one is specified.\n        Args:\n        name: name of the variable\n        shape: list of ints\n        stddev: standard deviation of a truncated Gaussian\n        wd: add L2Loss weight decay multiplied by this float. If None, weight\n        decay is not added for this Variable.\n        Returns:\n        Variable Tensor\n        \"\"\"", "\n", "\n", "dtype", "=", "tf", ".", "float16", "if", "FLAGS", ".", "use_fp16", "else", "tf", ".", "float32", "\n", "var", "=", "self", ".", "_variable_on_cpu", "(", "name", ",", "\n", "shape", ",", "\n", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "stddev", ",", "dtype", "=", "dtype", ")", ")", "\n", "if", "wd", "is", "not", "None", ":", "\n", "            ", "weight_decay", "=", "tf", ".", "multiply", "(", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", ",", "wd", ",", "name", "=", "'weight_loss'", ")", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "weight_decay", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.CIFAR10TutorialNetwork.CIFAR10TutorialNetwork._variable_on_cpu": [[160, 173], ["tensorflow.device", "tensorflow.get_variable"], "methods", ["None"], ["", "def", "_variable_on_cpu", "(", "self", ",", "name", ",", "shape", ",", "initializer", ")", ":", "\n", "        ", "\"\"\"Helper to create a Variable stored on CPU memory.\n        Args:\n        name: name of the variable\n        shape: list of ints\n        initializer: initializer for Variable\n        Returns:\n        Variable Tensor\n        \"\"\"", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "dtype", "=", "tf", ".", "float16", "if", "FLAGS", ".", "use_fp16", "else", "tf", ".", "float32", "\n", "var", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", ",", "initializer", "=", "initializer", ",", "dtype", "=", "dtype", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Tanh.Tanh.__init__": [[8, 11], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Tanh'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Tanh.Tanh._build": [[12, 15], ["tensorflow.nn.tanh"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "return", "tf", ".", "nn", ".", "tanh", "(", "inputs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.VGGBlock.VGGBlock.__init__": [[9, 62], ["sonnet.AbstractModule.__init__", "utils.argo_utils.make_list", "keras_models.keras_utils.get_renorm_clipping"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.make_list", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping"], ["    ", "def", "__init__", "(", "self", ",", "\n", "channels", ",", "\n", "is_training", ",", "\n", "kernel_shape", "=", "[", "3", ",", "3", "]", ",", "\n", "padding", "=", "\"VALID\"", ",", "\n", "linear_last", "=", "None", ",", "\n", "name", "=", "\"vggB\"", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "bn_renormalization", "=", "True", ",", "\n", "features_name", "=", "None", ",", "\n", "**", "extra_params", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Args:\n            num_outputs (type): number of outputs of the module.\n            name (type): module name.\n            activation (type): activation used for the internal layers.\n            **extra_params (type): alls the additional keyword arguments will be passed to the snt.Conv2D layers. (initializers, regularizers)\n\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_hidden_channels", "=", "channels", "\n", "\n", "if", "linear_last", "is", "not", "None", ":", "\n", "            ", "linear_last", "=", "make_list", "(", "linear_last", ")", "\n", "\n", "", "self", ".", "_linear_last", "=", "linear_last", "\n", "\n", "self", ".", "_stride", "=", "2", "\n", "self", ".", "_kernel_shape", "=", "kernel_shape", "\n", "\n", "self", ".", "_middle_padding", "=", "snt", ".", "SAME", "\n", "self", ".", "_final_padding", "=", "padding", "\n", "\n", "self", ".", "_prob_drop", "=", "prob_drop", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "\n", "self", ".", "_bn_renormalization", "=", "bn_renormalization", "\n", "\n", "self", ".", "_is_training", "=", "is_training", "\n", "\n", "self", ".", "_bn_momentum", "=", "bn_momentum", "\n", "\n", "self", ".", "_features_name", "=", "features_name", "\n", "\n", "self", ".", "_renorm_clipping", "=", "None", "\n", "if", "self", ".", "_bn_renormalization", ":", "\n", "            ", "self", ".", "_renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.VGGBlock.VGGBlock._dropout": [[63, 66], ["tensorflow.layers.dropout"], "methods", ["None"], ["", "", "def", "_dropout", "(", "self", ",", "net", ",", "training", ")", ":", "\n", "        ", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "self", ".", "_prob_drop", ",", "training", "=", "training", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.VGGBlock.VGGBlock._build": [[67, 153], ["sonnet.Conv2D", "sonnet.Conv2D", "VGGBlock.VGGBlock.layer_one", "VGGBlock.VGGBlock._dropout", "tensorflow.layers.batch_normalization", "VGGBlock.VGGBlock._activation", "VGGBlock.VGGBlock.layer_two", "VGGBlock.VGGBlock._dropout", "tensorflow.layers.batch_normalization", "VGGBlock.VGGBlock._activation", "tensorflow.layers.max_pooling2d", "len", "enumerate", "Identity.Identity.Identity", "sonnet.Linear", "sonnet.BatchFlatten", "layer", "VGGBlock.VGGBlock._dropout", "tensorflow.layers.batch_normalization", "VGGBlock.VGGBlock._activation", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout", "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout", "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (type): node of input.\n            is_training (type): tells to batchnorm if to generate the update ops.\n\n        \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "\n", "self", ".", "layer_one", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_1\"", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shape", ",", "\n", "#stride=1,", "\n", "padding", "=", "self", ".", "_middle_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", ")", "\n", "\n", "self", ".", "layer_two", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv_2d_2\"", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shape", ",", "\n", "#stride=1,", "\n", "padding", "=", "self", ".", "_middle_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", ")", "\n", "\n", "# LAYER1", "\n", "net", "=", "self", ".", "layer_one", "(", "net", ")", "\n", "net", "=", "self", ".", "_dropout", "(", "net", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_1\"", ")", "\n", "\n", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "# LAYER2", "\n", "net", "=", "self", ".", "layer_two", "(", "net", ")", "\n", "net", "=", "self", ".", "_dropout", "(", "net", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_2\"", ")", "\n", "\n", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "if", "self", ".", "_features_name", "!=", "None", ":", "\n", "            ", "net", "=", "Identity", "(", "name", "=", "self", ".", "_features_name", ")", "(", "net", ")", "\n", "\n", "", "net", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "net", ",", "pool_size", "=", "self", ".", "_stride", ",", "strides", "=", "self", ".", "_stride", ",", "padding", "=", "self", ".", "_final_padding", ")", "\n", "\n", "#LINEAR BLOCK WITH RESHAPE IF NEEDED", "\n", "if", "self", ".", "_linear_last", "is", "not", "None", ":", "\n", "            ", "self", ".", "linear_layers", "=", "[", "snt", ".", "Linear", "(", "\n", "name", "=", "\"linear_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_size", "=", "self", ".", "_linear_last", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_linear_last", ")", ")", "]", "\n", "\n", "net", "=", "snt", ".", "BatchFlatten", "(", ")", "(", "net", ")", "\n", "\n", "nl", "=", "len", "(", "self", ".", "_linear_last", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "linear_layers", ")", ":", "\n", "                ", "net", "=", "layer", "(", "net", ")", "\n", "net", "=", "self", ".", "_dropout", "(", "net", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_lin_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "# if i < nl-1:", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "\n", "", "", "return", "net", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoStochasticNetworkWithDefaults.ArgoStochasticNetworkWithDefaults.create_id": [[17, 25], ["super().create_id", "utils.argo_utils.get_method_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "'-cp'", "+", "get_method_id", "(", "(", "self", ".", "_opts", "[", "\"covariance_parameterization\"", "]", ",", "{", "}", ")", ")", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoStochasticNetworkWithDefaults.ArgoStochasticNetworkWithDefaults.__init__": [[29, 37], ["ArgoNetworkWithDefaults.ArgoNetworkWithDefaults.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", ",", "seed", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "seed", ")", "\n", "\n", "# GET DEFAULTS FOR STOCHASTIC LAYERS", "\n", "default_covariance_parametrization", "=", "self", ".", "_opts", "[", "\"covariance_parameterization\"", "]", "\n", "\n", "self", ".", "_stochastic_defaults", "=", "{", "\n", "\"covariance_parameterization\"", ":", "default_covariance_parametrization", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResUnit.ResUnit.__init__": [[6, 29], ["sonnet.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ",", "name", "=", "\"resunit\"", ",", "kernel_shape", "=", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "use_weight_norm", "=", "False", ",", "**", "extra_params", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            depth (int): the depth of the resUnit.\n            name (str): module name.\n            kernel_shape (int or [int,int]): the kernel size\n            stride (int): the stride\n            activation (tf function): activation used for the internal layers.\n            **extra_params: all the additional keyword arguments will be passed to snt.Conv2D layers.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_depth", "=", "depth", "\n", "self", ".", "_num_layers", "=", "2", "\n", "self", ".", "_kernel_shapes", "=", "[", "kernel_shape", "]", "*", "2", "\n", "self", ".", "_strides", "=", "[", "stride", ",", "1", "]", "\n", "self", ".", "_padding", "=", "snt", ".", "SAME", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "self", ".", "_downsample_input", "=", "False", "\n", "if", "stride", "!=", "1", ":", "\n", "            ", "self", ".", "_downsample_input", "=", "True", "\n", "\n", "", "self", ".", "_use_weight_norm", "=", "use_weight_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResUnit.ResUnit._build": [[30, 78], ["enumerate", "ValueError", "Conv2DWN.Conv2DWN.Conv2DWN", "sonnet.BatchNorm", "sonnet.BatchNorm.", "ResUnit.ResUnit._activation", "layer", "range", "sonnet.Conv2D"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (type): node of input.\n            is_training (type): tells to batchnorm if to generate the update ops.\n            test_local_stats (type): used to test local stats in batch norm.\n\n        Returns:\n            logits\n        \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "if", "inputs", ".", "shape", "[", "1", "]", "!=", "inputs", ".", "shape", "[", "2", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"ResUnit expects a square image\"", ")", "\n", "\n", "", "img_dim", "=", "inputs", ".", "shape", "[", "2", "]", "\n", "img_channels", "=", "inputs", ".", "shape", "[", "3", "]", "\n", "\n", "# instantiate all the convolutional layers", "\n", "self", ".", "layers", "=", "[", "Conv2DWN", "(", "name", "=", "\"conv2d_wn_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_depth", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shapes", "[", "i", "]", ",", "\n", "stride", "=", "self", ".", "_strides", "[", "i", "]", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "use_weight_norm", "=", "self", ".", "_use_weight_norm", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", "]", "\n", "# connect them to the graph, adding batch norm and non-linearity", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "bn", "=", "snt", ".", "BatchNorm", "(", "name", "=", "\"batchnorm_{}\"", ".", "format", "(", "i", ")", ")", "\n", "net", "=", "bn", "(", "net", ",", "is_training", "=", "is_training", ",", "test_local_stats", "=", "test_local_stats", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "net", "=", "layer", "(", "net", ")", "\n", "\n", "", "inputstoadd", "=", "inputs", "\n", "if", "self", ".", "_downsample_input", ":", "\n", "            ", "inputstoadd", "=", "snt", ".", "Conv2D", "(", "name", "=", "\"conv2d_downsample\"", ",", "\n", "output_channels", "=", "self", ".", "_depth", ",", "\n", "kernel_shape", "=", "[", "1", ",", "1", "]", ",", "\n", "stride", "=", "self", ".", "_strides", "[", "0", "]", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "(", "inputs", ")", "\n", "\n", "", "logits", "=", "net", "+", "inputstoadd", "\n", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.MaxPooling2D.MaxPooling2D.__init__": [[11, 19], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "pool_size", ",", "strides", ",", "padding", "=", "\"valid\"", ",", "data_format", "=", "\"channels_last\"", ",", "name", "=", "\"MaxPooling2D\"", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_pool_size", "=", "pool_size", "\n", "self", ".", "_strides", "=", "strides", "\n", "self", ".", "_padding", "=", "padding", "\n", "self", ".", "_data_format", "=", "data_format", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.MaxPooling2D.MaxPooling2D._build": [[20, 27], ["tensorflow.layers.max_pooling2d"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "input", ",", "\n", "pool_size", "=", "self", ".", "_pool_size", ",", "\n", "strides", "=", "self", ".", "_strides", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "data_format", "=", "self", ".", "_data_format", ",", "\n", "name", "=", "self", ".", "module_name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Sigmoid.Sigmoid.__init__": [[8, 11], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Sigmoid'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Sigmoid.Sigmoid._build": [[12, 15], ["tensorflow.nn.sigmoid"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "return", "tf", ".", "nn", ".", "sigmoid", "(", "inputs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianDiagonal.GaussianDiagonal.__init__": [[17, 38], ["AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0.", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'gaussian_diagonal'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianDiagonal.GaussianDiagonal._build": [[39, 71], ["GaussianDiagonal.GaussianDiagonal.create_mean_n_cov_layers", "GaussianDiagonal.GaussianDiagonal.set_contractive_regularizer", "tensorflow_probability.distributions.Normal", "types.MethodType", "types.MethodType", "types.MethodType", "GaussianDiagonal.GaussianDiagonal.mean", "tensorflow.zeros", "tensorflow.ones", "tensorflow_probability.distributions.Normal", "GaussianDiagonal.GaussianDiagonal.mean", "tensorflow.square", "GaussianDiagonal.GaussianDiagonal.stddev"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "mean", ",", "covariance", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "\n", "output_distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "mean", ",", "scale", "=", "scale", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "def", "params", "(", "self", ")", ":", "\n", "            ", "return", "(", "self", ".", "mean", "(", ")", ",", "tf", ".", "square", "(", "self", ".", "stddev", "(", ")", ")", ")", "\n", "\n", "", "output_distribution", ".", "params", "=", "types", ".", "MethodType", "(", "params", ",", "output_distribution", ")", "\n", "\n", "def", "default_prior", "(", "self", ",", "prior_shape", ")", ":", "\n", "            ", "zeros", "=", "tf", ".", "zeros", "(", "shape", "=", "prior_shape", ")", "\n", "ones", "=", "tf", ".", "ones", "(", "shape", "=", "prior_shape", ")", "\n", "prior", "=", "tfd", ".", "Normal", "(", "loc", "=", "zeros", ",", "scale", "=", "ones", ",", "name", "=", "\"prior\"", ")", "\n", "return", "prior", "\n", "\n", "", "output_distribution", ".", "default_prior", "=", "types", ".", "MethodType", "(", "default_prior", ",", "output_distribution", ")", "\n", "\n", "return", "output_distribution", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.BatchNorm.BatchNorm.__init__": [[6, 11], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "is_training", ",", "name", "=", "\"BatchNorm\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_is_training", "=", "is_training", "\n", "self", ".", "_name", "=", "name", "\n", "self", ".", "_kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.BatchNorm.BatchNorm._build": [[12, 15], ["sonnet.BatchNorm", "sonnet.BatchNorm."], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "bn", "=", "snt", ".", "BatchNorm", "(", "**", "self", ".", "_kwargs", ")", "\n", "return", "bn", "(", "inputs", ",", "is_training", "=", "self", ".", "_is_training", ",", "test_local_stats", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_all_variables": [[10, 21], ["super().get_all_variables"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_all_variables"], ["def", "get_all_variables", "(", "self", ",", "collection", "=", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", ":", "\n", "        ", "\"\"\" overwrites the default collection to filter the variables,\n        the default for Sonnet module is collection=tf.GraphKeys.TRAINABLE_VARIABLES\n        that excludes moving mean and standard deviations for example.\n\n        Returns:\n            variables used when the module is connected\n\n        see more in `AbstractModule.get_all_variables` documentation\n        \"\"\"", "\n", "return", "super", "(", ")", ".", "get_all_variables", "(", "collection", "=", "collection", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables": [[22, 33], ["super().get_variables"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables"], ["", "def", "get_variables", "(", "self", ",", "collection", "=", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", ":", "\n", "        ", "\"\"\" overwrites the default collection to filter the variables,\n        the default for Sonnet module is collection=tf.GraphKeys.TRAINABLE_VARIABLES\n        that excludes moving mean and standard deviations for example.\n\n        Returns:\n            variables defined in the scope of the Module\n\n        see more in `AbstractModule.get_variables` documentation\n        \"\"\"", "\n", "return", "super", "(", ")", ".", "get_variables", "(", "collection", "=", "collection", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.init_saver": [[34, 51], ["AbstractModule.AbstractModule._ensure_is_connected", "tensorflow.train.Saver", "AbstractModule.AbstractModule.get_variables"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables"], ["", "def", "init_saver", "(", "self", ",", "variables", "=", "None", ")", ":", "\n", "        ", "\"\"\"This set the saver for a network. It has to be invoked only when the Module has been connected,\n        otherwise it will raise an exception\n\n        Args:\n            variables (list): A list of variables to save and restore, by default all the variables of the module\n            (instantiated till this precise moment) will be tracked\n\n        Raises:\n          NotConnectedError: If the module is not connected to the Graph.\n        \"\"\"", "\n", "self", ".", "_ensure_is_connected", "(", ")", "\n", "\n", "if", "not", "variables", ":", "\n", "            ", "variables", "=", "self", ".", "get_variables", "(", ")", "\n", "\n", "", "self", ".", "_saver", "=", "tf", ".", "train", ".", "Saver", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save": [[52, 58], ["AbstractModule.AbstractModule._saver.save", "AbstractModule.AbstractModule.init_saver"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.init_saver"], ["", "def", "save", "(", "self", ",", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "_saver", "is", "None", ":", "\n", "# raise Exception(\"saver must be initialized before attempt to save\")", "\n", "            ", "self", ".", "init_saver", "(", ")", "\n", "\n", "", "self", ".", "_saver", ".", "save", "(", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore": [[59, 66], ["AbstractModule.AbstractModule._saver.restore", "AbstractModule.AbstractModule.init_saver"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.init_saver"], ["", "def", "restore", "(", "self", ",", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "_saver", "is", "None", ":", "\n", "# import pdb;pdb.set_trace()", "\n", "# raise Exception(\"saver must be initialized before attempt to restore\")", "\n", "            ", "self", ".", "init_saver", "(", ")", "\n", "\n", "", "self", ".", "_saver", ".", "restore", "(", "sess", ",", "chkptfile", ",", "**", "kwargs", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.create_id": [[16, 23], ["super().create_id", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "'-d'", "+", "str", "(", "self", ".", "_opts", "[", "\"denoising\"", "]", ")", "#+\\", "\n", "#'-re' + str(opts[\"rescale\"])", "\n", "\n", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "_id", "+=", "super_id", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.__init__": [[24, 31], ["AbstractGenerativeModel.AbstractGenerativeModel.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "self", ".", "denoising", "=", "opts", "[", "\"denoising\"", "]", "\n", "\n", "# dictionaries with train, validation and test nodes", "\n", "self", ".", "x", "=", "None", "\n", "self", ".", "x_target", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.create_input_nodes": [[33, 65], ["AbstractAutoEncoder.AbstractAutoEncoder.create_datasets_with_handles", "AbstractAutoEncoder.AbstractAutoEncoder._unpack_data_nodes", "tensorflow.placeholder_with_default", "tensorflow.cond", "len", "tensorflow.identity", "tensorflow.identity", "tensorflow.one_hot", "AbstractAutoEncoder.AbstractAutoEncoder._augment_data_nodes"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_datasets_with_handles", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel._unpack_data_nodes", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel._augment_data_nodes"], ["", "def", "create_input_nodes", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        creates input nodes for an autoencoder from the dataset\n\n        Sets:\n            x, x_target\n        \"\"\"", "\n", "\n", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "=", "self", ".", "create_datasets_with_handles", "(", "dataset", ")", "\n", "\n", "# optionally set y", "\n", "#if (not perturbed_dataset and len(datasets_nodes)==2) or (perturbed_dataset and len(datasets_nodes)==3):", "\n", "if", "len", "(", "datasets_nodes", ")", "==", "2", ":", "\n", "            ", "self", ".", "y", "=", "tf", ".", "identity", "(", "datasets_nodes", "[", "1", "]", ",", "name", "=", "\"y\"", ")", "\n", "self", ".", "y_one_hot", "=", "tf", ".", "identity", "(", "tf", ".", "one_hot", "(", "self", ".", "y", ",", "dataset", ".", "n_labels", ")", ",", "name", "=", "\"y1h\"", ")", "\n", "#self.y_one_hot = tf.identity(tf.cast(self.y, tf.float32), name=\"y1h\")", "\n", "", "else", ":", "\n", "            ", "self", ".", "y", "=", "None", "\n", "self", ".", "y_one_hot", "=", "None", "\n", "\n", "# (Luigi) see _unpack_data_nodes(self, datasets_nodes) in AbstractGenerativeModel", "\n", "# where the order raw_x=raw_x, x_data=pert_x, and x_data_target=aug_x", "\n", "", "raw_x", ",", "x_data", ",", "x_data_target", "=", "self", ".", "_unpack_data_nodes", "(", "datasets_nodes", ")", "#, perturbed_dataset)", "\n", "\n", "self", ".", "augment_bool", "=", "tf", ".", "placeholder_with_default", "(", "True", ",", "shape", "=", "(", ")", ")", "\n", "x_data", ",", "x_data_target", "=", "tf", ".", "cond", "(", "self", ".", "augment_bool", ",", "\n", "lambda", ":", "self", ".", "_augment_data_nodes", "(", "x_data", ",", "x_data_target", ",", "self", ".", "denoising", ")", ",", "\n", "lambda", ":", "(", "x_data", ",", "x_data_target", ")", "\n", ")", "\n", "self", ".", "raw_x", "=", "raw_x", "\n", "self", ".", "x", "=", "x_data", "\n", "self", ".", "x_target", "=", "x_data_target", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder._augment_data_nodes": [[67, 94], ["utils.argo_utils.tf_clip", "utils.argo_utils.tf_add_noise_to_discrete", "utils.argo_utils.tf_add_gaussian_noise_and_clip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_clip", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_add_noise_to_discrete", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_add_gaussian_noise_and_clip"], ["", "def", "_augment_data_nodes", "(", "self", ",", "source", ",", "target", ",", "denoising", "=", "False", ")", ":", "\n", "# AUGMENT SOURCE IF NEEDED", "\n", "        ", "if", "self", ".", "stochastic", ":", "\n", "            ", "if", "self", ".", "binary", ":", "\n", "                ", "source_before", "=", "source", "\n", "source", "=", "tf_add_noise_to_discrete", "(", "source", ",", "self", ".", "stochastic_noise_param", ")", "\n", "noise_data", "=", "source", "-", "source_before", "\n", "", "else", ":", "\n", "# TODO here I suppose the input are in -1.,1.", "\n", "# clip_after_noise is False if stochastic==2, see TFDeepLearningModel.py", "\n", "                ", "source", ",", "noise_data", "=", "tf_add_gaussian_noise_and_clip", "(", "source", ",", "\n", "std", "=", "self", ".", "stochastic_noise_param", ",", "\n", "clip_bool", "=", "self", ".", "_clip_after_noise", ")", "\n", "\n", "# AUGMENT TARGET IF NEEDED", "\n", "", "", "if", "not", "denoising", "and", "self", ".", "stochastic", ":", "\n", "# use the same noise for continuous datasets", "\n", "            ", "target", "=", "tf_clip", "(", "target", "+", "noise_data", ")", "\n", "\n", "#TODO never rescale", "\n", "# #RESCALE BOTH", "\n", "# if not self.rescale==0.0:", "\n", "#     # TODO add a check that the domain is in [-1,1]", "\n", "#     source = tf_rescale(source, self.rescale)", "\n", "#     target = tf_rescale(target, self.rescale)", "\n", "\n", "", "return", "source", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode": [[128, 131], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "encode", "(", "self", ",", "X", ",", "sess", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode": [[132, 135], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "decode", "(", "self", ",", "Z", ",", "sess", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.reconstruct": [[142, 145], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "reconstruct", "(", "self", ",", "X", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogisticDiagonalPlusMinusOne.LogisticDiagonalPlusMinusOne.__init__": [[11, 35], ["AbstractLogistic.AbstractLogistic.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "plus_minus_one_method", "=", "\"tanh\"", ",", "\n", "name", "=", "'logistic_diagonal_plus_minus_one'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n", "self", ".", "plus_minus_one_method", "=", "plus_minus_one_method", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogisticDiagonalPlusMinusOne.LogisticDiagonalPlusMinusOne._build": [[36, 58], ["LogisticDiagonalPlusMinusOne.LogisticDiagonalPlusMinusOne.create_mean_n_cov_layers", "LogisticDiagonalPlusMinusOne.LogisticDiagonalPlusMinusOne.force_between_plus_minus_one", "tensorflow_probability.distributions.Logistic", "types.MethodType", "LogisticDiagonalPlusMinusOne.LogisticDiagonalPlusMinusOne.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.force_between_plus_minus_one", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "mean_plus_minus_one", "=", "self", ".", "force_between_plus_minus_one", "(", "mean", ",", "self", ".", "plus_minus_one_method", ")", "\n", "\n", "# TODO if you want contractive regularizers implement them first. Then, uncomment the following lines (Riccardo)", "\n", "# self.set_contractive_regularizer(mean_zero_one, covariance,", "\n", "#                                 self._contractive_regularizer_inputs,", "\n", "#                                 self._contractive_regularizer_tuple,", "\n", "#                                 self._contractive_collection_network_str)", "\n", "#", "\n", "\n", "output_distribution", "=", "tfd", ".", "Logistic", "(", "loc", "=", "mean_plus_minus_one", ",", "scale", "=", "scale", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.RandomUniform.RandomUniform.__init__": [[12, 20], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "shape", ",", "minval", ",", "maxval", ",", "seed", "=", "None", ",", "rate", "=", "None", ",", "name", "=", "\"RandomUniform\"", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_shape", "=", "shape", "\n", "self", ".", "_minval", "=", "minval", "\n", "self", ".", "_maxval", "=", "maxval", "\n", "self", ".", "_seed", "=", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.RandomUniform.RandomUniform._build": [[21, 28], ["tensorflow.random_uniform"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "input", ")", ":", "\n", "# input is ignored", "\n", "        ", "return", "tf", ".", "random_uniform", "(", "self", ".", "_shape", ",", "\n", "minval", "=", "self", ".", "_minval", ",", "\n", "maxval", "=", "self", ".", "_maxval", ",", "\n", "seed", "=", "self", ".", "_seed", ",", "\n", "name", "=", "self", ".", "module_name", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher.__init__": [[93, 131], ["dict", "locals", "tensorflow.name_scope", "tensorflow_probability.python.internal.dtype_util.common_dtype", "tensorflow_probability.python.internal.tensor_util.convert_nonref_to_tensor", "tensorflow_probability.python.internal.tensor_util.convert_nonref_to_tensor", "tensorflow.compat.dimension_value", "tensorflow_probability.distributions.VonMisesFisher.__init__", "tensorflow_probability.python.internal.tensorshape_util.with_rank_at_least", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "mean_direction", ",", "\n", "concentration", ",", "\n", "validate_args", "=", "False", ",", "\n", "allow_nan_stats", "=", "True", ",", "\n", "name", "=", "'VonMisesFisher'", ",", "\n", "check_dim", "=", "True", ")", ":", "\n", "\n", "        ", "parameters", "=", "dict", "(", "locals", "(", ")", ")", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "name", ":", "\n", "            ", "dtype", "=", "dtype_util", ".", "common_dtype", "(", "[", "mean_direction", ",", "concentration", "]", ",", "\n", "tf", ".", "float32", ")", "\n", "self", ".", "_mean_direction", "=", "tensor_util", ".", "convert_nonref_to_tensor", "(", "\n", "mean_direction", ",", "name", "=", "'mean_direction'", ",", "dtype", "=", "dtype", ")", "\n", "self", ".", "_concentration", "=", "tensor_util", ".", "convert_nonref_to_tensor", "(", "\n", "concentration", ",", "name", "=", "'concentration'", ",", "dtype", "=", "dtype", ")", "\n", "\n", "static_event_dim", "=", "tf", ".", "compat", ".", "dimension_value", "(", "\n", "tensorshape_util", ".", "with_rank_at_least", "(", "\n", "self", ".", "_mean_direction", ".", "shape", ",", "1", ")", "[", "-", "1", "]", ")", "\n", "if", "check_dim", "==", "True", ":", "\n", "                ", "if", "static_event_dim", "is", "not", "None", "and", "static_event_dim", ">", "5", ":", "\n", "                    ", "raise", "ValueError", "(", "'von Mises-Fisher ndims > 5 is not currently '", "\n", "'supported'", ")", "\n", "\n", "# mean_direction is always reparameterized.", "\n", "# concentration is only for event_dim==3, via an inversion sampler.", "\n", "", "", "reparameterization_type", "=", "(", "\n", "reparameterization", ".", "FULLY_REPARAMETERIZED", "\n", "if", "static_event_dim", "==", "3", "else", "\n", "reparameterization", ".", "NOT_REPARAMETERIZED", ")", "\n", "super", "(", "tfd", ".", "VonMisesFisher", ",", "self", ")", ".", "__init__", "(", "\n", "dtype", "=", "self", ".", "_concentration", ".", "dtype", ",", "\n", "validate_args", "=", "validate_args", ",", "\n", "allow_nan_stats", "=", "allow_nan_stats", ",", "\n", "reparameterization_type", "=", "reparameterization_type", ",", "\n", "parameters", "=", "parameters", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher._mean": [[132, 148], ["tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.compat.dimension_value", "tensorflow.where", "tensorflow.where", "ValueError", "tensorflow.ones_like", "tensorflow.zeros_like", "vonMisesFisher._bessel_ive", "vonMisesFisher._bessel_ive"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive", "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive"], ["", "", "def", "_mean", "(", "self", ")", ":", "\n", "# Derivation: https://sachinruk.github.io/blog/von-Mises-Fisher/", "\n", "        ", "concentration", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "concentration", ")", "\n", "mean_direction", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "mean_direction", ")", "\n", "\n", "event_dim", "=", "tf", ".", "compat", ".", "dimension_value", "(", "self", ".", "event_shape", "[", "0", "]", ")", "\n", "if", "event_dim", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'event shape must be statically known for _bessel_ive'", ")", "\n", "", "safe_conc", "=", "tf", ".", "where", "(", "concentration", ">", "0", ",", "concentration", ",", "\n", "tf", ".", "ones_like", "(", "concentration", ")", ")", "\n", "safe_mean", "=", "mean_direction", "*", "(", "\n", "_bessel_ive", "(", "event_dim", "/", "2", ",", "safe_conc", ")", "/", "\n", "_bessel_ive", "(", "event_dim", "/", "2", "-", "1", ",", "safe_conc", ")", ")", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "return", "tf", ".", "where", "(", "\n", "concentration", "[", "...", ",", "tf", ".", "newaxis", "]", ">", "0.", ",", "\n", "safe_mean", ",", "tf", ".", "zeros_like", "(", "safe_mean", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher._covariance": [[149, 177], ["tensorflow.compat.dimension_value", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.linalg.set_diag", "tensorflow.where", "ValueError", "NotImplementedError", "tensorflow.where", "vonMisesFisher._bessel_ive", "vonMisesFisher._bessel_ive", "tensorflow.matmul", "tensorflow.ones_like", "tensorflow.linalg.diag_part", "tensorflow.linalg.eye", "vonMisesFisher.MyVonMisesFisher._batch_shape_tensor"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive", "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive"], ["", "def", "_covariance", "(", "self", ")", ":", "\n", "# Derivation: https://sachinruk.github.io/blog/von-Mises-Fisher/", "\n", "        ", "event_dim", "=", "tf", ".", "compat", ".", "dimension_value", "(", "self", ".", "event_shape", "[", "0", "]", ")", "\n", "if", "event_dim", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'event shape must be statically known for _bessel_ive'", ")", "\n", "# TODO(b/141142878): Enable this; numerically unstable.", "\n", "", "if", "event_dim", ">", "2", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "'vMF covariance is numerically unstable for dim>2'", ")", "\n", "", "mean_direction", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "mean_direction", ")", "\n", "concentration", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "concentration", ")", "\n", "safe_conc", "=", "tf", ".", "where", "(", "concentration", ">", "0", ",", "concentration", ",", "\n", "tf", ".", "ones_like", "(", "concentration", ")", ")", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "h", "=", "(", "_bessel_ive", "(", "event_dim", "/", "2", ",", "safe_conc", ")", "/", "\n", "_bessel_ive", "(", "event_dim", "/", "2", "-", "1", ",", "safe_conc", ")", ")", "\n", "intermediate", "=", "(", "\n", "tf", ".", "matmul", "(", "mean_direction", "[", "...", ",", ":", ",", "tf", ".", "newaxis", "]", ",", "\n", "mean_direction", "[", "...", ",", "tf", ".", "newaxis", ",", ":", "]", ")", "*", "\n", "(", "1", "-", "event_dim", "*", "h", "/", "safe_conc", "-", "h", "**", "2", ")", "[", "...", ",", "tf", ".", "newaxis", "]", ")", "\n", "cov", "=", "tf", ".", "linalg", ".", "set_diag", "(", "\n", "intermediate", ",", "\n", "tf", ".", "linalg", ".", "diag_part", "(", "intermediate", ")", "+", "(", "h", "/", "safe_conc", ")", ")", "\n", "return", "tf", ".", "where", "(", "\n", "concentration", "[", "...", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", "]", ">", "0.", ",", "cov", ",", "\n", "tf", ".", "linalg", ".", "eye", "(", "event_dim", ",", "\n", "batch_shape", "=", "self", ".", "_batch_shape_tensor", "(", "\n", "mean_direction", "=", "mean_direction", ",", "\n", "concentration", "=", "concentration", ")", ")", "/", "event_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher._log_normalization": [[178, 199], ["tensorflow.compat.dimension_value", "tensorflow.where", "tensorflow.where", "tensorflow.convert_to_tensor", "ValueError", "tensorflow.ones_like", "tensorflow.abs", "tensorflow.math.lgamma", "tensorflow.math.log", "numpy.log", "tensorflow.cast", "tensorflow.ones_like", "vonMisesFisher._bessel_ive", "numpy.log", "tensorflow.math.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "_log_normalization", "(", "self", ",", "concentration", "=", "None", ")", ":", "\n", "        ", "\"\"\"Computes the log-normalizer of the distribution.\"\"\"", "\n", "if", "concentration", "is", "None", ":", "\n", "            ", "concentration", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "concentration", ")", "\n", "\n", "#pdb.set_trace()", "\n", "", "event_dim", "=", "tf", ".", "compat", ".", "dimension_value", "(", "self", ".", "event_shape", "[", "0", "]", ")", "\n", "if", "event_dim", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'von Mises-Fisher _log_normalizer currently only '", "\n", "'supports statically known event shape'", ")", "\n", "", "safe_conc", "=", "tf", ".", "where", "(", "concentration", ">", "0", ",", "concentration", ",", "\n", "tf", ".", "ones_like", "(", "concentration", ")", ")", "\n", "safe_lognorm", "=", "(", "(", "event_dim", "/", "2", "-", "1", ")", "*", "tf", ".", "math", ".", "log", "(", "safe_conc", ")", "-", "\n", "(", "event_dim", "/", "2", ")", "*", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", "-", "\n", "tf", ".", "math", ".", "log", "(", "_bessel_ive", "(", "event_dim", "/", "2", "-", "1", ",", "safe_conc", ")", ")", "-", "\n", "tf", ".", "abs", "(", "safe_conc", ")", ")", "\n", "log_nsphere_surface_area", "=", "(", "\n", "np", ".", "log", "(", "2.", ")", "+", "(", "event_dim", "/", "2", ")", "*", "np", ".", "log", "(", "np", ".", "pi", ")", "-", "\n", "tf", ".", "math", ".", "lgamma", "(", "tf", ".", "cast", "(", "event_dim", "/", "2", ",", "self", ".", "dtype", ")", ")", ")", "\n", "return", "tf", ".", "where", "(", "concentration", ">", "0", ",", "-", "safe_lognorm", ",", "\n", "log_nsphere_surface_area", "*", "tf", ".", "ones_like", "(", "concentration", ")", ")", "# Luigi", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher._entropy": [[201, 210], ["int", "vonMisesFisher.MyVonMisesFisher._log_normalization", "vonMisesFisher._bessel_ive", "vonMisesFisher._bessel_ive"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher._log_normalization", "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive", "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive"], ["", "def", "_entropy", "(", "self", ")", ":", "\n", "        ", "mf", "=", "int", "(", "self", ".", "mean_direction", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "#return - tf.reshape(self.concentration * _bessel_ive(mf / 2, self.concentration) / _bessel_ive((mf / 2) - 1, self.concentration),", "\n", "#                           tf.convert_to_tensor(tf.shape(self.concentration)[:-1])) + self._log_normalization()", "\n", "\n", "return", "-", "self", ".", "concentration", "*", "_bessel_ive", "(", "mf", "/", "2", ",", "self", ".", "concentration", ")", "/", "_bessel_ive", "(", "(", "mf", "/", "2", ")", "-", "1", ",", "self", ".", "concentration", ")", "+", "self", ".", "_log_normalization", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher._event_shape": [[212, 215], ["tensorflow_probability.python.internal.tensorshape_util.with_rank_at_least"], "methods", ["None"], ["", "def", "_event_shape", "(", "self", ")", ":", "\n", "        ", "s", "=", "tensorshape_util", ".", "with_rank_at_least", "(", "self", ".", "mean_direction", ".", "shape", ",", "1", ")", "\n", "return", "s", "[", "-", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.MyVonMisesFisher._batch_shape": [[216, 220], ["tensorflow.broadcast_static_shape", "tensorflow_probability.python.internal.tensorshape_util.with_rank_at_least"], "methods", ["None"], ["", "def", "_batch_shape", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "broadcast_static_shape", "(", "\n", "tensorshape_util", ".", "with_rank_at_least", "(", "self", ".", "mean_direction", ".", "shape", ",", "1", ")", "[", ":", "-", "1", "]", ",", "\n", "self", ".", "concentration", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.vonMisesFisher.__init__": [[226, 247], ["AbstractStochasticLayer.AbstractStochasticLayer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_concentration", "=", "0.01", ",", "\n", "concentration_parameterization", "=", "\"softplus\"", ",", "\n", "#vectorial_covariance = True, ", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'von_mises_diagonal'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_concentration", ",", "# a little bit improper (Luigi)", "\n", "covariance_parameterization", "=", "concentration_parameterization", ",", "# a little bit improper (Luigi)", "\n", "vectorial_covariance", "=", "True", ",", "# since the vMF has only a scalar covariance", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.vonMisesFisher._build": [[248, 302], ["vonMisesFisher.vonMisesFisher.create_mean_n_cov_layers", "tensorflow.nn.l2_normalize", "vonMisesFisher.vonMisesFisher.set_contractive_regularizer", "tensorflow.reshape", "vonMisesFisher.MyVonMisesFisher", "types.MethodType", "types.MethodType", "types.MethodType", "types.MethodType", "vonMisesFisher.vonMisesFisher.mean", "tensorflow.zeros", "vonMisesFisher.MyVonMisesFisher", "int", "tensorflow.math.lgamma", "math.log", "tensorflow.cast", "vonMisesFisher.vonMisesFisher.entropy", "math.log"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "mean", ",", "concentration", ",", "_", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "# normaize the mean", "\n", "mean", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "mean", ",", "axis", "=", "-", "1", ")", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "mean", ",", "concentration", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "\n", "#output_distribution = tfd.Normal(loc=mean, scale=scale)", "\n", "concetration", "=", "tf", ".", "reshape", "(", "concentration", ",", "[", "-", "1", "]", ")", "\n", "output_distribution", "=", "MyVonMisesFisher", "(", "mean", ",", "concetration", ",", "check_dim", "=", "False", ")", "\n", "#output_distribution = tfd.VonMisesFisher(mean, covariance)", "\n", "#pdb.set_trace()", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "def", "params", "(", "self", ")", ":", "\n", "            ", "return", "(", "self", ".", "mean_direction", ",", "self", ".", "concentration", ")", "\n", "\n", "", "output_distribution", ".", "params", "=", "types", ".", "MethodType", "(", "params", ",", "output_distribution", ")", "\n", "\n", "def", "default_prior", "(", "self", ",", "dim", ")", ":", "\n", "            ", "zeros", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "dim", "]", ")", "\n", "prior", "=", "MyVonMisesFisher", "(", "zeros", ",", "0", ",", "check_dim", "=", "False", ",", "name", "=", "\"prior\"", ")", "\n", "return", "prior", "\n", "\n", "", "output_distribution", ".", "default_prior", "=", "types", ".", "MethodType", "(", "default_prior", ",", "output_distribution", ")", "\n", "\n", "def", "kl_divergence", "(", "self", ",", "p", ")", ":", "\n", "# this formula is correct only if p is the prior!", "\n", "            ", "dim", "=", "int", "(", "self", ".", "mean_direction", ".", "shape", "[", "-", "1", "]", ")", "\n", "entropy_prior", "=", "math", ".", "log", "(", "2", ")", "+", "(", "(", "dim", "+", "1", ")", "/", "2", ")", "*", "math", ".", "log", "(", "math", ".", "pi", ")", "-", "tf", ".", "math", ".", "lgamma", "(", "tf", ".", "cast", "(", "(", "dim", "+", "1", ")", "/", "2", ",", "dtype", "=", "self", ".", "dtype", ")", ")", "\n", "#return tf.ones_like(self.concentration) + entropy_prior", "\n", "return", "-", "self", ".", "entropy", "(", ")", "+", "entropy_prior", "\n", "\n", "", "output_distribution", ".", "kl_divergence", "=", "types", ".", "MethodType", "(", "kl_divergence", ",", "output_distribution", ")", "\n", "\n", "'''\n        def _entropy(self):\n            mf = int(self.mean_direction.shape[-1])\n            return - tf.reshape(self.concentration * _bessel_ive(mf / 2, self.concentration) / _bessel_ive((mf / 2) - 1, self.concentration),\n                                tf.convert_to_tensor(tf.shape(self.concentration)[:-1])) + self._log_normalization()\n        \n        output_distribution._entropy = types.MethodType(_entropy, output_distribution)\n        '''", "\n", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.vonMisesFisher._contractive_regularizer_filename": [[303, 307], ["Exception"], "methods", ["None"], ["", "@", "property", "\n", "def", "_contractive_regularizer_filename", "(", "self", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"not sure what it is now\"", ")", "\n", "return", "\".vonMisesFisherRegularizers\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive": [[36, 50], ["tensorflow.python.ops.array_ops.reshape", "tensorflow.python.ops.script_ops.py_func", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.ops.array_ops.shape", "numpy.select", "vonMisesFisher._bessel_ive", "scipy.special.ive", "scipy.special.i0e", "scipy.special.i1e", "vonMisesFisher._bessel_ive"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive", "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive"], ["@", "custom_gradient", "\n", "def", "_bessel_ive", "(", "v", ",", "z", ",", "cache", "=", "None", ")", ":", "\n", "    ", "\"\"\"Exponentially scaled modified Bessel function of the first kind.\"\"\"", "\n", "output", "=", "array_ops", ".", "reshape", "(", "script_ops", ".", "py_func", "(", "\n", "lambda", "v", ",", "z", ":", "np", ".", "select", "(", "condlist", "=", "[", "v", "==", "0", ",", "v", "==", "1", "]", ",", "\n", "choicelist", "=", "[", "scipy", ".", "special", ".", "i0e", "(", "z", ",", "dtype", "=", "z", ".", "dtype", ")", ",", "\n", "scipy", ".", "special", ".", "i1e", "(", "z", ",", "dtype", "=", "z", ".", "dtype", ")", "]", ",", "\n", "default", "=", "scipy", ".", "special", ".", "ive", "(", "v", ",", "z", ",", "dtype", "=", "z", ".", "dtype", ")", ")", ",", "[", "v", ",", "z", "]", ",", "z", ".", "dtype", ")", ",", "\n", "ops", ".", "convert_to_tensor", "(", "array_ops", ".", "shape", "(", "z", ")", ",", "dtype", "=", "dtypes", ".", "int32", ")", ")", "\n", "\n", "def", "grad", "(", "dy", ")", ":", "\n", "        ", "return", "None", ",", "dy", "*", "(", "_bessel_ive", "(", "v", "-", "1", ",", "z", ")", "-", "_bessel_ive", "(", "v", ",", "z", ")", "*", "(", "v", "+", "z", ")", "/", "z", ")", "\n", "\n", "", "return", "output", ",", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher.tf_bessel_ive": [[52, 89], ["tensorflow.convert_to_tensor", "tensorflow.where", "tensorflow.check_numerics", "tensorflow.debugging.check_numerics", "tensorflow.ones_like", "tensorflow.check_numerics", "tensorflow.math.bessel_i0e", "tensorflow.check_numerics", "vonMisesFisher._bessel_ive", "wrap", "wrap", "tensorflow.math.bessel_i1e", "wrap", "vonMisesFisher._bessel_ive", "tensorflow.where", "numpy.sqrt", "sinhe", "tensorflow.math.rsqrt", "tensorflow.ones_like", "tensorflow.where", "tensorflow.exp", "tensorflow.exp", "numpy.sqrt", "coshe", "tensorflow.math.rsqrt", "tensorflow.ones_like", "tensorflow.exp", "tensorflow.exp", "tensorflow.abs", "tensorflow.abs", "tensorflow.abs", "tensorflow.abs"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive", "home.repos.pwc.inspect_result.rist-ro_argo.network.vonMisesFisher._bessel_ive"], ["", "def", "tf_bessel_ive", "(", "v", ",", "z", ",", "cache", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes I_v(z)*exp(-abs(z)) using a recurrence relation, where z > 0.\"\"\"", "\n", "# TODO(b/67497980): Switch to a more numerically faithful implementation.", "\n", "z", "=", "tf", ".", "convert_to_tensor", "(", "z", ")", "\n", "\n", "wrap", "=", "lambda", "result", ":", "tf", ".", "debugging", ".", "check_numerics", "(", "result", ",", "'besseli{}'", ".", "format", "(", "v", "\n", ")", ")", "\n", "#if float(v) >= 2:", "\n", "#    raise ValueError(", "\n", "#        'Evaluating bessel_i by recurrence becomes imprecise for large v')", "\n", "\n", "cache", "=", "cache", "or", "{", "}", "\n", "safe_z", "=", "tf", ".", "where", "(", "z", ">", "0", ",", "z", ",", "tf", ".", "ones_like", "(", "z", ")", ")", "\n", "if", "v", "in", "cache", ":", "\n", "        ", "return", "tf", ".", "check_numerics", "(", "wrap", "(", "cache", "[", "v", "]", ")", ",", "\"wrap(cache[v] fails check numerics\"", ")", "\n", "", "if", "v", "==", "0", ":", "\n", "        ", "cache", "[", "v", "]", "=", "tf", ".", "math", ".", "bessel_i0e", "(", "z", ")", "\n", "", "elif", "v", "==", "1", ":", "\n", "        ", "cache", "[", "v", "]", "=", "tf", ".", "math", ".", "bessel_i1e", "(", "z", ")", "\n", "", "elif", "v", "==", "0.5", ":", "\n", "# sinh(x)*exp(-abs(x)), sinh(x) = (e^x - e^{-x}) / 2", "\n", "        ", "sinhe", "=", "lambda", "x", ":", "(", "tf", ".", "exp", "(", "x", "-", "tf", ".", "abs", "(", "x", ")", ")", "-", "tf", ".", "exp", "(", "-", "x", "-", "tf", ".", "abs", "(", "x", ")", ")", ")", "/", "2", "\n", "cache", "[", "v", "]", "=", "(", "\n", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "sinhe", "(", "z", ")", "*", "\n", "tf", ".", "where", "(", "z", ">", "0", ",", "tf", ".", "math", ".", "rsqrt", "(", "safe_z", ")", ",", "tf", ".", "ones_like", "(", "safe_z", ")", ")", ")", "\n", "", "elif", "v", "==", "-", "0.5", ":", "\n", "# cosh(x)*exp(-abs(x)), cosh(x) = (e^x + e^{-x}) / 2", "\n", "        ", "coshe", "=", "lambda", "x", ":", "(", "tf", ".", "exp", "(", "x", "-", "tf", ".", "abs", "(", "x", ")", ")", "+", "tf", ".", "exp", "(", "-", "x", "-", "tf", ".", "abs", "(", "x", ")", ")", ")", "/", "2", "\n", "cache", "[", "v", "]", "=", "(", "\n", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "coshe", "(", "z", ")", "*", "\n", "tf", ".", "where", "(", "z", ">", "0", ",", "tf", ".", "math", ".", "rsqrt", "(", "safe_z", ")", ",", "tf", ".", "ones_like", "(", "safe_z", ")", ")", ")", "\n", "", "if", "v", "<=", "1", ":", "\n", "        ", "return", "tf", ".", "check_numerics", "(", "wrap", "(", "cache", "[", "v", "]", ")", ",", "\"wrap(cache[v] fails check numerics\"", ")", "\n", "# Recurrence relation:", "\n", "", "cache", "[", "v", "]", "=", "(", "_bessel_ive", "(", "v", "-", "2", ",", "z", ",", "cache", ")", "-", "\n", "(", "2", "*", "(", "v", "-", "1", ")", ")", "*", "_bessel_ive", "(", "v", "-", "1", ",", "z", ",", "cache", ")", "/", "z", ")", "\n", "return", "tf", ".", "check_numerics", "(", "wrap", "(", "cache", "[", "v", "]", ")", ",", "\"wrap(cache[v] fails check numerics\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractNetwork.ArgoAbstractNetwork.__init__": [[12, 23], ["AbstractModule.AbstractModule.__init__", "utils.argo_utils.update_conf_with_defaults"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.update_conf_with_defaults"], ["def", "__init__", "(", "self", ",", "opts", ",", "name", ",", "seed", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_opts_original", "=", "opts", "\n", "self", ".", "_opts", "=", "update_conf_with_defaults", "(", "opts", ",", "self", ".", "default_params", ")", "\n", "\n", "self", ".", "_seed", "=", "seed", "\n", "\n", "self", ".", "_name", "=", "name", "\n", "# self._seed = seed", "\n", "self", ".", "_saver", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoAbstractNetwork.ArgoAbstractNetwork.create_id": [[25, 27], ["None"], "methods", ["None"], ["", "def", "create_id", "(", "self", ")", ":", "\n", "        ", "return", "\"\"", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Identity.Identity.__init__": [[9, 14], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'Identity'", ")", ":", "\n", "\n", "        ", "self", ".", "_name", "=", "name", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Identity.Identity._build": [[15, 18], ["tensorflow.identity"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "return", "tf", ".", "identity", "(", "inputs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGaussianSimple.AbstractGaussianSimple.__init__": [[6, 23], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "output_size", ",", "\n", "minimal_covariance", "=", "1e-4", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "custom_getter", "=", "{", "}", ",", "\n", "name", "=", "'abstract_gaussian_linear'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "\n", "self", ".", "_extra_kwargs", "=", "{", "\"initializers\"", ":", "initializers", ",", "\n", "\"regularizers\"", ":", "regularizers", ",", "\n", "\"custom_getter\"", ":", "custom_getter", "}", "\n", "\n", "self", ".", "_minimal_covariance", "=", "minimal_covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianDiagonalZeroOne.GaussianDiagonalZeroOne.__init__": [[15, 36], ["AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'gaussian_diagonal_zero_one'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianDiagonalZeroOne.GaussianDiagonalZeroOne._build": [[37, 60], ["GaussianDiagonalZeroOne.GaussianDiagonalZeroOne.create_mean_n_cov_layers", "tensorflow.sigmoid", "GaussianDiagonalZeroOne.GaussianDiagonalZeroOne.set_contractive_regularizer", "tensorflow_probability.distributions.Normal", "types.MethodType", "types.MethodType", "GaussianDiagonalZeroOne.GaussianDiagonalZeroOne.mean", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "mean_zero_one", "=", "tf", ".", "sigmoid", "(", "mean", ")", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "mean_zero_one", ",", "covariance", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "output_distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "mean_zero_one", ",", "scale", "=", "scale", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "def", "distribution_parameters", "(", "self", ")", ":", "\n", "            ", "return", "[", "mean_zero_one", ",", "np", ".", "square", "(", "scale", ")", "]", "\n", "", "output_distribution", ".", "distribution_parameters", "=", "types", ".", "MethodType", "(", "distribution_parameters", ",", "output_distribution", ")", "\n", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResEnc.ResEnc.__init__": [[12, 31], ["AbstractResNetLayer.AbstractResNetLayer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "num_hiddens", ",", "num_residual_layers", ",", "num_residual_hiddens", ",", "\n", "activation", ",", "\n", "is_training", ",", "\n", "name", "=", "'ResEnc'", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "bn_renormalization", "=", "True", ",", "\n", "**", "extra_params", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_hiddens", ",", "\n", "num_residual_layers", ",", "\n", "num_residual_hiddens", ",", "\n", "activation", ",", "\n", "is_training", ",", "\n", "name", "=", "name", ",", "\n", "prob_drop", "=", "prob_drop", ",", "\n", "bn_momentum", "=", "bn_momentum", ",", "\n", "bn_renormalization", "=", "bn_renormalization", ",", "\n", "**", "extra_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResEnc.ResEnc._build": [[32, 87], ["ResEnc.ResEnc._dropout", "tensorflow.layers.batch_normalization", "ResEnc.ResEnc._activation", "ResEnc.ResEnc._dropout", "tensorflow.layers.batch_normalization", "ResEnc.ResEnc._activation", "build_utils.residual_stack", "sonnet.Conv2D", "sonnet.Conv2D", "sonnet.Conv2D"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout", "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout", "home.repos.pwc.inspect_result.rist-ro_argo.network.build_utils.residual_stack"], ["", "def", "_build", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "snt", ".", "Conv2D", "(", "\n", "output_channels", "=", "self", ".", "_num_hiddens", "/", "2", ",", "\n", "kernel_shape", "=", "(", "4", ",", "4", ")", ",", "\n", "stride", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "\"enc_1\"", ")", "(", "x", ")", "\n", "\n", "h", "=", "self", ".", "_dropout", "(", "h", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "h", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "h", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_1\"", ")", "\n", "\n", "\n", "h", "=", "self", ".", "_activation", "(", "h", ")", "\n", "\n", "h", "=", "snt", ".", "Conv2D", "(", "\n", "output_channels", "=", "self", ".", "_num_hiddens", ",", "\n", "kernel_shape", "=", "(", "4", ",", "4", ")", ",", "\n", "stride", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "\"enc_2\"", ")", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "_dropout", "(", "h", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "h", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "h", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_2\"", ")", "\n", "\n", "h", "=", "self", ".", "_activation", "(", "h", ")", "\n", "\n", "h", "=", "snt", ".", "Conv2D", "(", "\n", "output_channels", "=", "self", ".", "_num_hiddens", ",", "\n", "kernel_shape", "=", "(", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "name", "=", "\"enc_3\"", ")", "(", "h", ")", "\n", "\n", "h", "=", "residual_stack", "(", "\n", "h", ",", "\n", "self", ".", "_num_hiddens", ",", "\n", "self", ".", "_num_residual_layers", ",", "\n", "self", ".", "_num_residual_hiddens", ",", "\n", "activation", "=", "self", ".", "_activation", ",", "\n", "training", "=", "self", ".", "_is_training", ",", "\n", "prob_drop", "=", "self", ".", "_prob_drop", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", "\n", ")", "\n", "\n", "return", "h", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.__init__": [[19, 24], ["TFDeepLearningModel.TFDeepLearningModel.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "opts", ",", "dirName", ",", "check_ops", "=", "False", ",", "gpu", "=", "-", "1", ",", "seed", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "dirName", ",", "check_ops", ",", "gpu", ",", "seed", ")", "\n", "\n", "# dictionaries with train, validation and test nodes", "\n", "self", ".", "x", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.create_input_nodes": [[25, 53], ["AbstractGenerativeModel.AbstractGenerativeModel.create_datasets_with_handles", "AbstractGenerativeModel.AbstractGenerativeModel._unpack_data_nodes", "tensorflow.placeholder_with_default", "tensorflow.cond", "len", "tensorflow.identity", "tensorflow.identity", "tensorflow.one_hot", "AbstractGenerativeModel.AbstractGenerativeModel._augment_data_nodes"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.AdversarialModel.AdversarialModel.create_datasets_with_handles", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel._unpack_data_nodes", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel._augment_data_nodes"], ["", "def", "create_input_nodes", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        creates input nodes for an autoencoder from the dataset\n\n        \"\"\"", "\n", "\n", "datasets_nodes", ",", "handle", ",", "ds_initializers", ",", "ds_handles", "=", "self", ".", "create_datasets_with_handles", "(", "dataset", ")", "\n", "\n", "# optionally set y", "\n", "#if (not perturbed_dataset and len(datasets_nodes)==2) or (perturbed_dataset and len(datasets_nodes)==3):", "\n", "if", "len", "(", "datasets_nodes", ")", "==", "2", ":", "\n", "            ", "self", ".", "y", "=", "tf", ".", "identity", "(", "datasets_nodes", "[", "1", "]", ",", "name", "=", "\"y\"", ")", "\n", "self", ".", "y_one_hot", "=", "tf", ".", "identity", "(", "tf", ".", "one_hot", "(", "self", ".", "y", ",", "dataset", ".", "n_labels", ")", ",", "name", "=", "\"y1h\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "y", "=", "None", "\n", "self", ".", "y_one_hot", "=", "None", "\n", "\n", "", "raw_x", ",", "x_data", ",", "x_data_target", "=", "self", ".", "_unpack_data_nodes", "(", "datasets_nodes", ")", "#, perturbed_dataset)", "\n", "\n", "self", ".", "augment_bool", "=", "tf", ".", "placeholder_with_default", "(", "True", ",", "shape", "=", "(", ")", ")", "\n", "x_data", "=", "tf", ".", "cond", "(", "self", ".", "augment_bool", ",", "\n", "lambda", ":", "self", ".", "_augment_data_nodes", "(", "x_data", ")", ",", "\n", "lambda", ":", "(", "x_data", ")", "\n", ")", "\n", "\n", "\n", "self", ".", "raw_x", "=", "raw_x", "\n", "self", ".", "x", "=", "x_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel._augment_data_nodes": [[55, 82], ["utils.argo_utils.tf_add_noise_to_discrete", "utils.argo_utils.tf_add_gaussian_noise_and_clip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_add_noise_to_discrete", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_add_gaussian_noise_and_clip"], ["", "def", "_augment_data_nodes", "(", "self", ",", "source", ")", ":", "\n", "# AUGMENT SOURCE IF NEEDED", "\n", "        ", "if", "self", ".", "stochastic", ":", "\n", "            ", "if", "self", ".", "binary", ":", "\n", "                ", "source_before", "=", "source", "\n", "source", "=", "tf_add_noise_to_discrete", "(", "source", ",", "self", ".", "stochastic_noise_param", ")", "\n", "noise_data", "=", "source", "-", "source_before", "\n", "", "else", ":", "\n", "# TODO here I suppose the input are in -1.,1.", "\n", "# clip_after_noise is False if stochastic==2, see TFDeepLearningModel.py", "\n", "                ", "source", ",", "noise_data", "=", "tf_add_gaussian_noise_and_clip", "(", "source", ",", "\n", "self", ".", "stochastic_noise_param", ",", "\n", "clip_bool", "=", "self", ".", "_clip_after_noise", ")", "\n", "\n", "# AUGMENT TARGET IF NEEDED", "\n", "#if self.stochastic:", "\n", "#    # use the same noise for continuous datasets", "\n", "#    target = tf_clip(target + noise_data)", "\n", "\n", "#TODO never rescale", "\n", "# #RESCALE BOTH", "\n", "# if not self.rescale==0.0:", "\n", "#     # TODO add a check that the domain is in [-1,1]", "\n", "#     source = tf_rescale(source, self.rescale)", "\n", "#     target = tf_rescale(target, self.rescale)", "\n", "\n", "", "", "return", "source", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel._unpack_data_nodes": [[84, 113], ["None"], "methods", ["None"], ["", "def", "_unpack_data_nodes", "(", "self", ",", "datasets_nodes", ")", ":", "#, is_perturbed_dataset):", "\n", "# what I will do next, is to move from", "\n", "#     dataset_x, perturbed_dataset_x", "\n", "# which are obtained from the dataset, to", "\n", "#     source_x, target_x", "\n", "# based on the value of perturbed_dataset", "\n", "\n", "        ", "source", "=", "None", "\n", "target", "=", "None", "\n", "\n", "'''\n        # SOURCE NODE CREATE\n        if is_perturbed_dataset:\n            dataset_x = datasets_nodes[0]\n            perturbed_dataset_x = datasets_nodes[1]\n            source = perturbed_dataset_x\n        else:\n            dataset_x = datasets_nodes[0]\n            source = dataset_x\n        '''", "\n", "\n", "raw", "=", "datasets_nodes", "[", "0", "]", "[", "0", "]", "\n", "target", "=", "datasets_nodes", "[", "0", "]", "[", "1", "]", "\n", "source", "=", "datasets_nodes", "[", "0", "]", "[", "2", "]", "\n", "#else:", "\n", "#    target = datasets_nodes[0]", "\n", "#    source = datasets_nodes[0]", "\n", "\n", "return", "raw", ",", "source", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.generate": [[114, 117], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "generate", "(", "self", ",", "batch_size", "=", "1", ",", "sess", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LinearWN.LinearWN.__init__": [[8, 43], ["kwargs[].pop", "kwargs[].pop", "sonnet.python.modules.basic.Linear.__init__", "os.path.dirname", "tensorflow.get_variable", "tensorflow.get_variable", "initializer_g", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "initializer_v", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "use_weight_norm", "=", "True", ",", "name", "=", "\"linear_wn\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            args and kwargs: all the additional keyword arguments will be passed to snt.Linear layers.\n        \"\"\"", "\n", "\n", "custom_getter", "=", "None", "\n", "\n", "if", "use_weight_norm", ":", "\n", "            ", "initializer_g", "=", "kwargs", "[", "'initializers'", "]", "[", "'g'", "]", "\n", "initializer_v", "=", "kwargs", "[", "'initializers'", "]", "[", "'v'", "]", "\n", "\n", "def", "custom_getter_w", "(", "getter", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "shape", "=", "kwargs", "[", "\"shape\"", "]", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "name", ")", "\n", "\n", "#v = getter(dirname+\"/v\", *args, **kwargs)", "\n", "# new way to create the variable, so that I can specify the initializer", "\n", "v", "=", "tf", ".", "get_variable", "(", "\"v\"", ",", "initializer", "=", "initializer_v", "(", "[", "shape", "]", ")", ")", "\n", "\n", "output_size", "=", "shape", "[", "-", "1", "]", "\n", "initial_value_g", "=", "initializer_g", "(", "[", "output_size", "]", ")", "*", "2", "\n", "ln_g", "=", "tf", ".", "get_variable", "(", "\"ln_g\"", ",", "initializer", "=", "initial_value_g", ")", "\n", "# use weight normalization (Salimans & Kingma, 2016)", "\n", "w", "=", "tf", ".", "reshape", "(", "tf", ".", "exp", "(", "ln_g", ")", ",", "[", "1", ",", "output_size", "]", ")", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "v", ",", "[", "0", "]", ")", "\n", "return", "w", "\n", "\n", "", "custom_getter", "=", "{", "\"w\"", ":", "custom_getter_w", "}", "\n", "\n", "# remove keys from the dictionary, since sonnet check for this", "\n", "", "kwargs", "[", "'initializers'", "]", ".", "pop", "(", "'g'", ",", "None", ")", "\n", "kwargs", "[", "'initializers'", "]", ".", "pop", "(", "'v'", ",", "None", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ",", "\n", "custom_getter", "=", "custom_getter", ",", "name", "=", "name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.MultivariateNormalDiag.MultivariateNormalDiag.__init__": [[10, 23], ["AbstractGaussianSimple.AbstractGaussianSimple.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "_id", "(", "self", ")", ":", "\n", "        ", "_id", "=", "'D'", "\n", "_id", "+=", "\"_b\"", "+", "str", "(", "int", "(", "self", ".", "_bl", ")", ")", "\n", "_id", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "self", ".", "_fl", ")", ")", "\n", "return", "_id", "\n", "\n", "", "def", "__init__", "(", "self", ",", "output_size", ",", "bayesian_layers", "=", "False", ",", "flipout", "=", "False", ",", "layer_kwargs", "=", "{", "}", ",", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'norm_diag'", ")", "\n", "\n", "self", ".", "_bl", "=", "bayesian_layers", "\n", "self", ".", "_fl", "=", "flipout", "\n", "\n", "if", "bayesian_layers", ":", "\n", "            ", "if", "flipout", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.MultivariateNormalDiag.MultivariateNormalDiag._build": [[25, 40], ["tensorflow.layers.flatten", "sonnet.Linear", "sonnet.Linear", "MultivariateNormalDiag.MultivariateNormalDiag.dense_loc", "MultivariateNormalDiag.MultivariateNormalDiag.dense_diag_params", "tensorflow_probability.distributions.MultivariateNormalDiag", "tensorflow.nn.softplus"], "methods", ["None"], ["", "else", ":", "\n", "                ", "Dense", "=", "partial", "(", "tfp", ".", "layers", ".", "DenseReparameterization", ",", "**", "layer_kwargs_bayes", ")", "\n", "", "", "else", ":", "\n", "            ", "Dense", "=", "partial", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", ",", "**", "layer_kwargs", ")", "\n", "\n", "", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "self", ".", "dense_loc", "=", "Dense", "(", "output_size", ")", "\n", "self", ".", "dense_diag_params", "=", "Dense", "(", "output_size", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_flat", "(", "inputs", ")", "\n", "loc", "=", "self", ".", "dense_loc", "(", "inputs", ")", "\n", "diag_params", "=", "self", ".", "dense_diag_params", "(", "inputs", ")", "\n", "scale_diag", "=", "MINIMAL_COVARIANCE", "+", "tf", ".", "nn", ".", "softplus", "(", "diag_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.OneHotCategorical.OneHotCategorical.__init__": [[23, 41], ["AbstractModule.AbstractModule.__init__", "operator.xor"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["\n", "ouput_params", "=", "{", "\"logits\"", ":", "logits", "}", "\n", "distr", "=", "tfp", ".", "distributions", ".", "OneHotCategorical", "(", "**", "ouput_params", ")", "\n", "\n", "# hack because keras does not want distr in output... (Riccardo)", "\n", "distr", ".", "shape", "=", "tf", ".", "TensorShape", "(", "tuple", "(", "distr", ".", "batch_shape", ".", "as_list", "(", ")", "+", "distr", ".", "event_shape", ".", "as_list", "(", ")", ")", ")", "\n", "\n", "return", "distr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.OneHotCategorical.OneHotCategorical._build": [[42, 70], ["tensorflow.reshape", "tensorflow.contrib.layers.softmax", "tensorflow.clip_by_value", "tensorflow.contrib.distributions.OneHotCategorical", "types.MethodType", "types.MethodType", "sonnet.Linear", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax"], []], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractLogistic.AbstractLogistic.__init__": [[9, 29], ["AbstractStochasticLayer.AbstractStochasticLayer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "-", "1", ",", "\n", "output_shape", "=", "-", "1", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'abstract_logistic'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractLogistic.AbstractLogistic._contractive_regularizer_filename": [[30, 33], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_contractive_regularizer_filename", "(", "self", ")", ":", "\n", "        ", "return", "\".LogisticRegularizers\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.build_utils.residual_stack": [[4, 43], ["range", "activation", "activation", "tensorflow.layers.dropout", "tensorflow.layers.batch_normalization", "activation", "tensorflow.layers.dropout", "tensorflow.layers.batch_normalization", "sonnet.Conv2D", "sonnet.Conv2D"], "function", ["None"], ["def", "residual_stack", "(", "h", ",", "num_hiddens", ",", "num_residual_layers", ",", "num_residual_hiddens", ",", "activation", ",", "\n", "training", ",", "prob_drop", ",", "momentum", ",", "renorm", ",", "renorm_momentum", ",", "renorm_clipping", ")", ":", "\n", "\n", "    ", "for", "i", "in", "range", "(", "num_residual_layers", ")", ":", "\n", "        ", "h_i", "=", "activation", "(", "h", ")", "\n", "\n", "h_i", "=", "snt", ".", "Conv2D", "(", "\n", "output_channels", "=", "num_residual_hiddens", ",", "\n", "kernel_shape", "=", "(", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "name", "=", "\"res3x3_%d\"", "%", "i", ")", "(", "h_i", ")", "\n", "\n", "h_i", "=", "tf", ".", "layers", ".", "dropout", "(", "h_i", ",", "prob_drop", ",", "training", "=", "training", ")", "\n", "h_i", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "h_i", ",", "training", "=", "training", ",", "\n", "momentum", "=", "momentum", ",", "\n", "renorm", "=", "renorm", ",", "\n", "renorm_momentum", "=", "renorm_momentum", ",", "\n", "renorm_clipping", "=", "renorm_clipping", ",", "\n", "name", "=", "\"bn_1_%d\"", "%", "i", ")", "\n", "\n", "h_i", "=", "activation", "(", "h_i", ")", "\n", "\n", "h_i", "=", "snt", ".", "Conv2D", "(", "\n", "output_channels", "=", "num_hiddens", ",", "\n", "kernel_shape", "=", "(", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "name", "=", "\"res1x1_%d\"", "%", "i", ")", "(", "h_i", ")", "\n", "\n", "h_i", "=", "tf", ".", "layers", ".", "dropout", "(", "h_i", ",", "prob_drop", ",", "training", "=", "training", ")", "\n", "h_i", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "h_i", ",", "training", "=", "training", ",", "\n", "momentum", "=", "momentum", ",", "\n", "renorm", "=", "renorm", ",", "\n", "renorm_momentum", "=", "renorm_momentum", ",", "\n", "renorm_clipping", "=", "renorm_clipping", ",", "\n", "name", "=", "\"bn_2_%d\"", "%", "i", ")", "\n", "\n", "h", "+=", "h_i", "\n", "\n", "", "return", "activation", "(", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogitNormalDiagonal.LogitNormalDiagonal.__init__": [[15, 39], ["AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "clip_value", "=", "0.001", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'logit_normal_diagonal'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n", "self", ".", "_clip_value", "=", "clip_value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogitNormalDiagonal.LogitNormalDiagonal._build": [[40, 72], ["LogitNormalDiagonal.LogitNormalDiagonal.create_mean_n_cov_layers", "LogitNormalDiagonal.LogitNormalDiagonal.set_contractive_regularizer", "tensorflow_probability.distributions.Normal", "tensorflow_probability.bijectors.Sigmoid", "tensorflow_probability.distributions.TransformedDistribution", "types.MethodType", "types.MethodType", "tensorflow_probability.bijectors.Sigmoid.forward", "LogitNormalDiagonal.LogitNormalDiagonal._call_log_prob", "tensorflow_probability.distributions.Normal.mean", "tf_clip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_clip"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "#TODO is this the kind of regularization we want. I think it makes sense.", "\n", "self", ".", "set_contractive_regularizer", "(", "mean", ",", "covariance", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "gaussian", "=", "tfd", ".", "Normal", "(", "loc", "=", "mean", ",", "scale", "=", "scale", ")", "\n", "\n", "sigmoid_bijector", "=", "tfb", ".", "Sigmoid", "(", ")", "\n", "logitnormal", "=", "tfd", ".", "TransformedDistribution", "(", "distribution", "=", "gaussian", ",", "bijector", "=", "sigmoid_bijector", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "# this is because there is not been for the LogitNormalDiagonal distribution", "\n", "            ", "return", "sigmoid_bijector", ".", "forward", "(", "gaussian", ".", "mean", "(", ")", ")", "\n", "\n", "", "logitnormal", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "logitnormal", ")", "\n", "\n", "clip_value", "=", "self", ".", "_clip_value", "\n", "\n", "# make sure a rescale the input for log_prob", "\n", "def", "log_prob", "(", "self", ",", "x", ",", "name", "=", "'log_prob'", ",", "**", "kwargs", ")", ":", "\n", "# kinda of dirty I know, it is used to avoid recursion (Luigi)", "\n", "            ", "return", "self", ".", "_call_log_prob", "(", "tf_clip", "(", "x", ",", "low", "=", "-", "1.0", "+", "clip_value", ",", "high", "=", "1.0", "-", "clip_value", ")", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "logitnormal", ".", "log_prob", "=", "types", ".", "MethodType", "(", "log_prob", ",", "logitnormal", ")", "\n", "\n", "\n", "return", "logitnormal", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Dropout.Dropout.__init__": [[12, 18], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rate", ",", "dropout_flag", "=", "None", ",", "name", "=", "\"Dropout\"", ")", ":", "\n", "#>>>>>>> e9f208ac74d05b1259d1b1d63445a54687bae812", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_rate", "=", "rate", "\n", "self", ".", "_dropout_flag", "=", "dropout_flag", "\n", "self", ".", "_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Dropout.Dropout._build": [[49, 53], ["tensorflow.layers.dropout"], "methods", ["None"], ["def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "dropout", "(", "inputs", ",", "self", ".", "_rate", ",", "\n", "training", "=", "self", ".", "_dropout_flag", ",", "\n", "name", "=", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoNetworkWithDefaults.ArgoNetworkWithDefaults.create_id": [[24, 41], ["super().create_id", "initializers.TFInitializers.TFInitializers.create_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "initializers.TFInitializers.TFInitializers.create_id"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "\n", "        ", "_id", "=", "'-a'", "+", "method_name_short", "[", "self", ".", "_opts", "[", "\"activation\"", "]", "]", "+", "'-wi'", "+", "TFInitializers", ".", "create_id", "(", "self", ".", "_opts", "[", "\"weights_init\"", "]", ")", "+", "'-bi'", "+", "TFInitializers", ".", "create_id", "(", "self", ".", "_opts", "[", "\"bias_init\"", "]", ")", "\n", "\n", "if", "self", ".", "_opts", "[", "\"weights_reg\"", "]", ":", "\n", "            ", "_id", "+=", "'-wr'", "+", "get_method_id", "(", "self", ".", "_opts", "[", "\"weights_reg\"", "]", ")", "\n", "\n", "", "if", "self", ".", "_opts", "[", "\"bias_reg\"", "]", ":", "\n", "            ", "_id", "+=", "'-br'", "+", "get_method_id", "(", "self", ".", "_opts", "[", "\"bias_reg\"", "]", ")", "\n", "\n", "", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ArgoNetworkWithDefaults.ArgoNetworkWithDefaults.__init__": [[46, 67], ["ArgoAbstractNetwork.ArgoAbstractNetwork.__init__", "initializers.TFInitializers.TFInitializers.instantiate_initializer", "initializers.TFInitializers.TFInitializers.instantiate_initializer", "getattr", "utils.argo_utils.eval_method_from_tuple", "utils.argo_utils.eval_method_from_tuple"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.initializers.TFInitializers.TFInitializers.instantiate_initializer", "home.repos.pwc.inspect_result.rist-ro_argo.initializers.TFInitializers.TFInitializers.instantiate_initializer", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", ",", "seed", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ",", "seed", ")", "\n", "\n", "# GET DEFAULTS FOR LAYERS CREATION", "\n", "# initializers", "\n", "self", ".", "_default_weights_init", "=", "TFInitializers", ".", "instantiate_initializer", "(", "self", ".", "_opts", "[", "\"weights_init\"", "]", ")", "\n", "self", ".", "_default_bias_init", "=", "TFInitializers", ".", "instantiate_initializer", "(", "self", ".", "_opts", "[", "\"bias_init\"", "]", ")", "\n", "\n", "# activation function", "\n", "self", ".", "_default_activation", "=", "getattr", "(", "tf", ".", "nn", ",", "self", ".", "_opts", "[", "\"activation\"", "]", ")", "\n", "\n", "# regularizers", "\n", "self", ".", "_default_weights_reg", "=", "eval_method_from_tuple", "(", "tf", ",", "self", ".", "_opts", "[", "\"weights_reg\"", "]", ")", "\n", "self", ".", "_default_bias_reg", "=", "eval_method_from_tuple", "(", "tf", ",", "self", ".", "_opts", "[", "\"bias_reg\"", "]", ")", "\n", "\n", "self", ".", "_network_defaults", "=", "{", "\n", "\"activation\"", ":", "self", ".", "_default_activation", ",", "\n", "\"weights_init\"", ":", "self", ".", "_default_weights_init", ",", "\n", "\"bias_init\"", ":", "self", ".", "_default_bias_init", ",", "\n", "\"weights_reg\"", ":", "self", ".", "_default_weights_reg", ",", "\n", "\"bias_reg\"", ":", "self", ".", "_default_bias_reg", "\n", "}", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianRegularizers.ring_loss_regularizer": [[12, 59], ["isinstance", "isinstance", "ValueError", "ValueError", "tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.cast", "tensorflow.reduce_mean", "tensorflow.multiply", "tensorflow.norm", "tensorflow.sqrt"], "function", ["None"], ["def", "ring_loss_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "# Returns a dictionary of functions that can be used to compute the regularizations", "\n", "# to the mean and covariance generated by a gaussian stochastic encoder", "\n", "\n", "# x is input to the network", "\n", "\n", "# input validation", "\n", "    ", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "        ", "if", "scale", "<", "0.", ":", "\n", "            ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "\n", "", "", "use_pfor", "=", "False", "\n", "\n", "def", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "scope", ",", "'contractive_regularizer'", ",", "[", "mean", ",", "cov", ",", "x", "]", ")", "as", "name", ":", "\n", "\n", "# scale_m = tf.convert_to_tensor(scale_mean,", "\n", "#                                dtype=mean.dtype.base_dtype,", "\n", "#                                name='scale_mean')", "\n", "#", "\n", "# scale_c = tf.convert_to_tensor(scale_covariance,", "\n", "#                                dtype=cov.dtype.base_dtype,", "\n", "#                                name='scale_covariance')", "\n", "#", "\n", "# reg_mean_node = tf.multiply(scale_m,", "\n", "#                             tf.reduce_sum(tf.abs(mean)))", "\n", "#", "\n", "# reg_cov_node = tf.multiply(scale_c,", "\n", "#                            tf.reduce_sum(tf.abs(cov)))", "\n", "\n", "            ", "scale_p", "=", "tf", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "mean", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale_penalty'", ")", "\n", "\n", "latent_size", "=", "tf", ".", "cast", "(", "mean", ".", "shape", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "D_total", "=", "tf", ".", "reduce_mean", "(", "(", "tf", ".", "norm", "(", "mean", ",", "axis", "=", "1", ")", "-", "tf", ".", "sqrt", "(", "latent_size", ")", ")", "**", "2", ")", "\n", "\n", "reg_D_node", "=", "tf", ".", "multiply", "(", "scale_p", ",", "\n", "D_total", ",", "\n", "name", "=", "name", ")", "\n", "\n", "return", "reg_D_node", "\n", "\n", "", "", "return", "contractive_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianRegularizers.ring_loss_variable_regularizer": [[62, 111], ["isinstance", "isinstance", "ValueError", "ValueError", "tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.cast", "tensorflow.get_variable", "tensorflow.reduce_mean", "tensorflow.multiply", "tensorflow.sqrt", "tensorflow.norm"], "function", ["None"], ["", "def", "ring_loss_variable_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "# Returns a dictionary of functions that can be used to compute the regularizations", "\n", "# to the mean and covariance generated by a gaussian stochastic encoder", "\n", "\n", "# x is input to the network", "\n", "\n", "# input validation", "\n", "    ", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "        ", "if", "scale", "<", "0.", ":", "\n", "            ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "\n", "", "", "use_pfor", "=", "False", "\n", "\n", "def", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "scope", ",", "'contractive_regularizer'", ",", "[", "mean", ",", "cov", ",", "x", "]", ")", "as", "name", ":", "\n", "\n", "# scale_m = tf.convert_to_tensor(scale_mean,", "\n", "#                                dtype=mean.dtype.base_dtype,", "\n", "#                                name='scale_mean')", "\n", "#", "\n", "# scale_c = tf.convert_to_tensor(scale_covariance,", "\n", "#                                dtype=cov.dtype.base_dtype,", "\n", "#                                name='scale_covariance')", "\n", "#", "\n", "# reg_mean_node = tf.multiply(scale_m,", "\n", "#                             tf.reduce_sum(tf.abs(mean)))", "\n", "#", "\n", "# reg_cov_node = tf.multiply(scale_c,", "\n", "#                            tf.reduce_sum(tf.abs(cov)))", "\n", "\n", "            ", "scale_p", "=", "tf", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "mean", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale_penalty'", ")", "\n", "\n", "latent_size", "=", "tf", ".", "cast", "(", "mean", ".", "shape", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "#             import pdb;pdb.set_trace()", "\n", "reference_norm", "=", "tf", ".", "get_variable", "(", "\"ref_norm\"", ",", "initializer", "=", "tf", ".", "sqrt", "(", "latent_size", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "trainable", "=", "True", ")", "\n", "D_total", "=", "tf", ".", "reduce_mean", "(", "(", "tf", ".", "norm", "(", "mean", ",", "axis", "=", "1", ")", "-", "reference_norm", ")", "**", "2", ")", "\n", "\n", "reg_D_node", "=", "tf", ".", "multiply", "(", "scale_p", ",", "\n", "D_total", ",", "\n", "name", "=", "name", ")", "\n", "\n", "return", "reg_D_node", "\n", "\n", "", "", "return", "contractive_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianRegularizers.wasserstein_contractive_regularizer": [[113, 185], ["isinstance", "isinstance", "ValueError", "ValueError", "tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian", "numpy.prod", "tensorflow.reshape", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "wasserstein_contractive_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "# Returns a dictionary of functions that can be used to compute the regularizations", "\n", "# to the mean and covariance generated by a gaussian stochastic encoder", "\n", "\n", "# x is input to the network", "\n", "\n", "# input validation", "\n", "    ", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "        ", "if", "scale", "<", "0.", ":", "\n", "            ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "scale", ")", "\n", "\n", "", "", "use_pfor", "=", "False", "\n", "parallel_iterations", "=", "None", "\n", "\n", "def", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "scope", ",", "'contractive_regularizer'", ",", "[", "mean", ",", "cov", ",", "x", "]", ")", "as", "name", ":", "\n", "\n", "# scale_m = tf.convert_to_tensor(scale_mean,", "\n", "#                                dtype=mean.dtype.base_dtype,", "\n", "#                                name='scale_mean')", "\n", "#", "\n", "# scale_c = tf.convert_to_tensor(scale_covariance,", "\n", "#                                dtype=cov.dtype.base_dtype,", "\n", "#                                name='scale_covariance')", "\n", "#", "\n", "# reg_mean_node = tf.multiply(scale_m,", "\n", "#                             tf.reduce_sum(tf.abs(mean)))", "\n", "#", "\n", "# reg_cov_node = tf.multiply(scale_c,", "\n", "#                            tf.reduce_sum(tf.abs(cov)))", "\n", "\n", "            ", "scale_p", "=", "tf", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "mean", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale_penalty'", ")", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "jac_mean_rk5", "=", "batch_jacobian", "(", "mean", ",", "x", ",", "parallel_iterations", "=", "parallel_iterations", ",", "use_pfor", "=", "use_pfor", ")", "# this has shape (?, latent_size, 28, 28, 1)", "\n", "\n", "jac_shape", "=", "jac_mean_rk5", ".", "shape", "\n", "\n", "lastdim", "=", "np", ".", "prod", "(", "jac_shape", "[", "2", ":", "]", ")", "\n", "jac_mean", "=", "tf", ".", "reshape", "(", "jac_mean_rk5", ",", "[", "-", "1", ",", "jac_shape", "[", "1", "]", ",", "lastdim", "]", ")", "# obtain shape (?, latent_size, 784)", "\n", "\n", "jac_cov_rk5", "=", "batch_jacobian", "(", "cov", ",", "x", ",", "use_pfor", "=", "use_pfor", ")", "\n", "jac_cov", "=", "tf", ".", "reshape", "(", "jac_cov_rk5", ",", "[", "-", "1", ",", "jac_shape", "[", "1", "]", ",", "lastdim", "]", ")", "# jac_mean_rk5 and jac_cov_rk5 have same shape: jac_shape = (?, latent_size, 28, 28, 1)", "\n", "\n", "# fisher_mean_vector = tf.ones(shape = tf.shape(cov)) # obtain constant vector 1", "\n", "# D_mean = tf.linalg.trace(tf.matmul(tf.transpose(jac_mean, perm = [0,2,1]),", "\n", "#                          tf.math.multiply(tf.expand_dims(fisher_mean_vector, axis = -1), jac_mean)))", "\n", "D_mean", "=", "tf", ".", "reduce_sum", "(", "jac_mean", "**", "2", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "\n", "fisher_cov_vector", "=", "(", "1", "/", "4", ")", "*", "(", "1", "/", "cov", ")", "#tf.math.pow(cov, tf.constant(-1.0)) # obtain 1/(4*sigma_k^2)", "\n", "\n", "# D_cov = tf.linalg.trace(tf.matmul(tf.transpose(jac_cov, perm=[0, 2, 1]),", "\n", "#                                   tf.math.multiply(tf.expand_dims(fisher_cov_vector, axis=-1), jac_cov)))", "\n", "\n", "D_cov", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "jac_cov", ",", "tf", ".", "multiply", "(", "tf", ".", "expand_dims", "(", "fisher_cov_vector", ",", "axis", "=", "-", "1", ")", ",", "jac_cov", ")", ")", ",", "\n", "axis", "=", "[", "1", ",", "2", "]", "\n", ")", "\n", "\n", "D_total", "=", "tf", ".", "reduce_mean", "(", "D_mean", "+", "D_cov", ")", "\n", "\n", "reg_D_node", "=", "tf", ".", "multiply", "(", "scale_p", ",", "\n", "D_total", ",", "\n", "name", "=", "name", ")", "\n", "\n", "return", "reg_D_node", "\n", "\n", "", "", "return", "contractive_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianRegularizers.geometric_contractive_regularizer": [[187, 265], ["isinstance", "isinstance", "ValueError", "ValueError", "tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian", "numpy.prod", "tensorflow.reshape", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "geometric_contractive_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "# Returns a dictionary of functions that can be used to compute the regularizations", "\n", "# to the mean and covariance generated by a gaussian stochastic encoder", "\n", "\n", "# x is input to the network", "\n", "\n", "# input validation", "\n", "    ", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "        ", "if", "scale", "<", "0.", ":", "\n", "            ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "scale", ")", "\n", "\n", "", "", "use_pfor", "=", "False", "\n", "\n", "def", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "scope", ",", "'contractive_regularizer'", ",", "[", "mean", ",", "cov", ",", "x", "]", ")", "as", "name", ":", "\n", "\n", "#<<<<<<< HEAD", "\n", "# scale_m = tf.convert_to_tensor(scale_mean,", "\n", "#                                dtype=mean.dtype.base_dtype,", "\n", "#                                name='scale_mean')", "\n", "#", "\n", "# scale_c = tf.convert_to_tensor(scale_covariance,", "\n", "#                                dtype=cov.dtype.base_dtype,", "\n", "#                                name='scale_covariance')", "\n", "#", "\n", "# reg_mean_node = tf.multiply(scale_m,", "\n", "#                             tf.reduce_sum(tf.abs(mean)))", "\n", "#", "\n", "# reg_cov_node = tf.multiply(scale_c,", "\n", "#                            tf.reduce_sum(tf.abs(cov)))", "\n", "#=======", "\n", "            ", "scale_p", "=", "tf", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "mean", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale_penalty'", ")", "\n", "\n", "\n", "#             import pdb;pdb.set_trace()", "\n", "jac_mean_rk5", "=", "batch_jacobian", "(", "mean", ",", "x", ",", "use_pfor", "=", "use_pfor", ")", "# this has shape (?, latent_size, 28, 28, 1)", "\n", "\n", "\n", "jac_shape", "=", "jac_mean_rk5", ".", "shape", "\n", "lastdim", "=", "np", ".", "prod", "(", "jac_shape", "[", "2", ":", "]", ")", "\n", "jac_mean", "=", "tf", ".", "reshape", "(", "jac_mean_rk5", ",", "[", "-", "1", ",", "jac_shape", "[", "1", "]", ",", "lastdim", "]", ")", "# obtain shape (?, latent_size, 784)", "\n", "\n", "\n", "jac_cov_rk5", "=", "batch_jacobian", "(", "cov", ",", "x", ",", "use_pfor", "=", "use_pfor", ")", "\n", "\n", "jac_cov", "=", "tf", ".", "reshape", "(", "jac_cov_rk5", ",", "[", "-", "1", ",", "jac_shape", "[", "1", "]", ",", "lastdim", "]", ")", "# jac_mean_rk5 and jac_cov_rk5 have same shape: jac_shape = (?, latent_size, 28, 28, 1)", "\n", "\n", "fisher_mean_vector", "=", "1", "/", "cov", "# tf.math.pow(cov, tf.constant(-1.0)) # obtain 1/sigma_k^2", "\n", "# D_mean = tf.linalg.trace(tf.matmul(tf.transpose(jac_mean, perm = [0,2,1]),", "\n", "#                          tf.math.multiply(tf.expand_dims(fisher_mean_vector, axis = -1), jac_mean)))", "\n", "D_mean", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "jac_mean", ",", "tf", ".", "multiply", "(", "tf", ".", "expand_dims", "(", "fisher_mean_vector", ",", "axis", "=", "-", "1", ")", ",", "jac_mean", ")", ")", ",", "\n", "axis", "=", "[", "1", ",", "2", "]", "\n", ")", "\n", "\n", "\n", "fisher_cov_vector", "=", "(", "1", "/", "2", ")", "*", "(", "1", "/", "(", "cov", "**", "2", ")", ")", "#* tf.math.pow(cov, tf.constant(-2.0)) # obtain 1/(2*sigma_k^4)", "\n", "# D_cov = tf.linalg.trace(tf.matmul(tf.transpose(jac_cov, perm = [0,2,1]),", "\n", "#                         tf.math.multiply(tf.expand_dims(fisher_cov_vector, axis = -1), jac_cov)))", "\n", "\n", "D_cov", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "jac_cov", ",", "tf", ".", "multiply", "(", "tf", ".", "expand_dims", "(", "fisher_cov_vector", ",", "axis", "=", "-", "1", ")", ",", "jac_cov", ")", ")", ",", "\n", "axis", "=", "[", "1", ",", "2", "]", "\n", ")", "\n", "\n", "D_total", "=", "tf", ".", "reduce_mean", "(", "D_mean", "+", "D_cov", ")", "\n", "\n", "reg_D_node", "=", "tf", ".", "multiply", "(", "scale_p", ",", "\n", "D_total", ",", "\n", "name", "=", "name", ")", "\n", "\n", "return", "reg_D_node", "\n", "\n", "", "", "return", "contractive_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianRegularizers.standard_contractive_regularizer": [[267, 350], ["isinstance", "isinstance", "ValueError", "ValueError", "tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.add", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "standard_contractive_regularizer", "(", "scale_mean", ",", "scale_covariance", ",", "batch_size", "=", "1000", ",", "while_loop", "=", "False", ",", "use_pfor", "=", "False", ",", "swap_memory", "=", "False", ",", "parallel_iterations", "=", "1", ",", "trick", "=", "False", ",", "scope", "=", "None", ")", ":", "\n", "#def standard_contractive_regularizer(scale_mean, scale_covariance, norm, trick=False, scope=None):", "\n", "\n", "# Returns a dictionary of functions that can be used to compute the regularizations", "\n", "# to the mean and covariance generated by the encoder", "\n", "\n", "# x is input to the network", "\n", "\n", "# input validation", "\n", "    ", "if", "isinstance", "(", "scale_mean", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale_mean cannot be an integer: %s'", "%", "scale_mean", ")", "\n", "\n", "# input validation", "\n", "", "if", "isinstance", "(", "scale_covariance", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale_covariance cannot be an integer: %s'", "%", "scale_covariance", ")", "\n", "\n", "#use_pfor = False # if you change this, please notify Luigi", "\n", "\n", "", "def", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "scope", ",", "'contractive_regularizer'", ",", "[", "mean", ",", "cov", ",", "x", "]", ")", "as", "name", ":", "\n", "            ", "scale_m", "=", "tf", ".", "convert_to_tensor", "(", "scale_mean", ",", "\n", "dtype", "=", "mean", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale_mean'", ")", "\n", "\n", "scale_c", "=", "tf", ".", "convert_to_tensor", "(", "scale_covariance", ",", "\n", "dtype", "=", "cov", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale_covariance'", ")", "\n", "\n", "\n", "# if while_loop:", "\n", "#     norm_jac_mean = tf.constant(0.0)", "\n", "#     norm_jac_cov = tf.constant(0.0)", "\n", "#     i = tf.constant(0)", "\n", "#     n_vars = tf.shape(mean)[1]", "\n", "#", "\n", "#     def cond(i, n_vars, norm_jac_mean, norm_jac_cov):", "\n", "#         return tf.less(i, n_vars)", "\n", "#", "\n", "#     def body(i, n_vars, norm_jac_mean, norm_jac_cov):", "\n", "#         #pdb.set_trace()", "\n", "#         norm_jac_mean += tf.pow(tf.norm(batch_jacobian(mean[:,i:i+batch_size], x, use_pfor = use_pfor), ord = norm), norm)", "\n", "#         norm_jac_cov += tf.pow(tf.norm(batch_jacobian(cov[:,i:i+batch_size], x, use_pfor = use_pfor), ord = norm), norm)", "\n", "#         return [tf.add(i, batch_size), n_vars, norm_jac_mean, norm_jac_cov]", "\n", "#", "\n", "#     _, _, norm_jac_mean, norm_jac_cov = tf.while_loop(cond,", "\n", "#                                                       body,", "\n", "#                                                       [i, n_vars, norm_jac_mean, norm_jac_cov],", "\n", "#                                                       #back_prop=True,", "\n", "#                                                       swap_memory=swap_memory,", "\n", "#                                                       parallel_iterations=parallel_iterations)", "\n", "#     norm_jac_mean = tf.pow(norm_jac_mean, 1/norm, name = \"norm_jac_mean\")", "\n", "#     norm_jac_cov = tf.pow(norm_jac_cov, 1/norm, name = \"norm_jac_cov\")", "\n", "\n", "# else:", "\n", "\n", "# norm_jac_mean = tf.math.pow(tf.norm(batch_jacobian(mean, x, use_pfor = use_pfor), ord = norm, name = \"norm_jac_mean\"), 2)", "\n", "# norm_jac_cov = tf.math.pow(tf.norm(batch_jacobian(cov, x, use_pfor = use_pfor), ord = norm, name = \"norm_jac_cov\"), 2)", "\n", "\n", "jac_mean", "=", "batch_jacobian", "(", "mean", ",", "x", ",", "use_pfor", "=", "use_pfor", ")", "# this has shape [?, latent_size, 28, 28, 1]", "\n", "jac_mean_rk2", "=", "tf", ".", "reshape", "(", "jac_mean", ",", "[", "tf", ".", "shape", "(", "jac_mean", ")", "[", "0", "]", ",", "-", "1", "]", ")", "# this has shape [?, latent_size*28*28*1]", "\n", "# norm_jac_mean = tf.reduce_mean(tf.pow(tf.norm(jac_mean_rk2, axis = 1, name = \"norm_jac_mean\"), 2))", "\n", "norm_jac_mean", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "reduce_sum", "(", "jac_mean_rk2", "**", "2", ",", "axis", "=", "1", ")", ",", "\n", "name", "=", "\"norm_jac_mean\"", ")", "\n", "\n", "jac_cov", "=", "batch_jacobian", "(", "cov", ",", "x", ",", "use_pfor", "=", "use_pfor", ")", "# this has shape [?, latent_size, 28, 28, 1]s", "\n", "jac_cov_rk2", "=", "tf", ".", "reshape", "(", "jac_cov", ",", "[", "tf", ".", "shape", "(", "jac_cov", ")", "[", "0", "]", ",", "-", "1", "]", ")", "# this has shape [?, latent_size*28*28*1]", "\n", "# norm_jac_cov = tf.reduce_mean(tf.pow(tf.norm(jac_cov_rk2, axis = 1, name = \"norm_jac_cov\"), 2))", "\n", "norm_jac_cov", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "reduce_sum", "(", "jac_cov_rk2", "**", "2", ",", "axis", "=", "1", ")", ",", "\n", "name", "=", "\"norm_jac_cov\"", ")", "\n", "\n", "reg_mean_node", "=", "tf", ".", "multiply", "(", "scale_m", ",", "\n", "norm_jac_mean", ",", "\n", "name", "=", "\"reg_mean\"", ")", "\n", "\n", "reg_cov_node", "=", "tf", ".", "multiply", "(", "scale_c", ",", "\n", "norm_jac_cov", ",", "\n", "name", "=", "\"reg_cov\"", ")", "\n", "\n", "return", "tf", ".", "add", "(", "reg_mean_node", ",", "reg_cov_node", ",", "name", "=", "name", ")", "\n", "\n", "", "", "return", "contractive_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianRegularizers.contractive_reg_list": [[403, 425], ["importlib.import_module", "getattr", "getattr.", "list_func.append", "list_nodes.append", "reg_method."], "function", ["None"], ["", "def", "contractive_reg_list", "(", "list_regs", ")", ":", "\n", "#     import pdb;pdb.set_trace()", "\n", "    ", "list_func", "=", "[", "]", "\n", "reg_module", "=", "importlib", ".", "import_module", "(", "__name__", ")", "\n", "\n", "for", "reg_tuple", "in", "list_regs", ":", "\n", "        ", "reg_name", ",", "reg_kwargs", "=", "reg_tuple", "\n", "#         import pdb;pdb.set_trace()", "\n", "reg_method", "=", "getattr", "(", "reg_module", ",", "reg_name", ")", "\n", "contr_reg", "=", "reg_method", "(", "**", "reg_kwargs", ")", "\n", "list_func", ".", "append", "(", "contr_reg", ")", "\n", "\n", "", "def", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ":", "\n", "#         import pdb;pdb.set_trace()  ", "\n", "        ", "list_nodes", "=", "[", "]", "\n", "\n", "for", "contr_reg", "in", "list_func", ":", "\n", "            ", "list_nodes", ".", "append", "(", "contr_reg", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ")", "\n", "\n", "", "return", "list_nodes", "\n", "\n", "", "return", "contractive_regularizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GaussianRegularizers.cos_contractive_regularizer": [[430, 494], ["isinstance", "isinstance", "ValueError", "ValueError", "tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.sqrt", "tensorflow.norm", "tensorflow.multiply", "tensorflow.summary.scalar", "tuple", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian", "range", "len"], "function", ["None"], ["", "def", "cos_contractive_regularizer", "(", "scale_mean", ",", "norm", ",", "scope", "=", "None", ")", ":", "\n", "# Returns a dictionary of functions that can be used to compute the regularizations", "\n", "# to the mean and covariance generated by the encoder", "\n", "\n", "# x is input to the network", "\n", "\n", "# input validation", "\n", "    ", "if", "isinstance", "(", "scale_mean", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale_mean cannot be an integer: %s'", "%", "scale_mean", ")", "\n", "", "if", "isinstance", "(", "scale_mean", ",", "numbers", ".", "Real", ")", ":", "\n", "        ", "if", "scale_mean", "<", "0.", ":", "\n", "            ", "raise", "ValueError", "(", "'Setting a scale_mean less than 0 on a regularizer: %g'", "%", "\n", "scale_mean", ")", "\n", "#if scale_mean == 0.:", "\n", "#    return lambda _: None", "\n", "\n", "# # input validation", "\n", "# if isinstance(scale_covariance, numbers.Integral):", "\n", "#     raise ValueError('scale_covariance cannot be an integer: %s' % scale_covariance)", "\n", "# if isinstance(scale_covariance, numbers.Real):", "\n", "#     if scale_covariance < 0.:", "\n", "#         raise ValueError('Setting a scale_covariance less than 0 on a regularizer: %g' %", "\n", "#                          scale_covariance)", "\n", "#if scale_covariance == 0.:", "\n", "#    return lambda _: None", "\n", "# flags = tf.app.flags", "\n", "\n", "", "", "use_pfor", "=", "False", "\n", "\n", "def", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ",", "name", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "scope", ",", "'contractive_regularizer'", ",", "[", "mean", ",", "cov", ",", "x", "]", ")", "as", "name", ":", "\n", "            ", "scale_m", "=", "tf", ".", "convert_to_tensor", "(", "scale_mean", ",", "\n", "dtype", "=", "mean", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale_mean'", ")", "\n", "\n", "# scale_c = tf.convert_to_tensor(scale_covariance,", "\n", "#                              dtype=cov.dtype.base_dtype,", "\n", "#                              name='scale_covariance')", "\n", "\n", "# these should do the \"trick\", I want to fix module and cos angle (scal prod with \"ones vector\")", "\n", "all_axis_but_batch", "=", "tuple", "(", "range", "(", "len", "(", "mean", ".", "shape", ")", ")", ")", "[", "1", ":", "]", "\n", "mean_norm", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "mean", "**", "2", ",", "axis", "=", "all_axis_but_batch", ")", ")", "\n", "mean_cos", "=", "tf", ".", "reduce_sum", "(", "mean", ",", "axis", "=", "all_axis_but_batch", ")", "/", "mean_norm", "\n", "norm_jac_mean", "=", "tf", ".", "norm", "(", "batch_jacobian", "(", "mean_cos", ",", "x", ",", "use_pfor", "=", "use_pfor", ")", ",", "ord", "=", "norm", ",", "name", "=", "\"norm_jac_mean\"", ")", "\n", "\n", "# all_axis_but_batch = tuple(range(len(cov.shape)))[1:]", "\n", "# cov_norm = tf.sqrt(tf.reduce_sum(cov**2, axis=all_axis_but_batch))", "\n", "# cov_cos = tf.reduce_sum(cov, axis=all_axis_but_batch)/cov_norm", "\n", "# norm_jac_cov = tf.norm(batch_jacobian(cov_norm + cov_cos, x, use_pfor=use_pfor), ord=norm, name=\"norm_jac_cov\")", "\n", "\n", "reg_mean_node", "=", "tf", ".", "multiply", "(", "scale_m", ",", "\n", "norm_jac_mean", ",", "\n", "name", "=", "\"reg_mean\"", ")", "\n", "\n", "# reg_cov_node = tf.multiply(scale_c,", "\n", "#                    norm_jac_cov,", "\n", "#                    name=\"reg_cov\")", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "norm_jac_mean", ".", "name", ",", "norm_jac_mean", ")", "\n", "# tf.summary.scalar(norm_jac_cov.name, norm_jac_cov)", "\n", "\n", "return", "reg_mean_node", "\n", "\n", "", "", "return", "contractive_regularizer", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.load_network.instantiate_network": [[6, 31], ["opts.get", "argo.core.utils.argo_utils.eval_method_from_tuple", "importlib.import_module", "Exception", "importlib.import_module", "__name__.split", "importlib.import_module", "__name__.split", "__name__.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["def", "instantiate_network", "(", "opts", ",", "name", ",", "module_path", "=", "\"\"", ")", ":", "\n", "    ", "network_name", "=", "opts", ".", "get", "(", "\"network\"", ",", "\"FFNetwork\"", ")", "\n", "\n", "try", ":", "\n", "# first try to load from core", "\n", "        ", "try", ":", "\n", "            ", "network_module", "=", "importlib", ".", "import_module", "(", "\"core.\"", "+", "network_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "# it if fails, try to load from up tree directory (I am core/argo/core/network/Network.py)", "\n", "", "except", "ImportError", ":", "\n", "            ", "try", ":", "\n", "                ", "network_module", "=", "importlib", ".", "import_module", "(", "\"....\"", "+", "network_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "# it if fails, try to laod from module_path.core", "\n", "", "except", "ImportError", ":", "\n", "                ", "network_module", "=", "importlib", ".", "import_module", "(", "module_path", "+", "\".core.\"", "+", "network_name", ",", "\n", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "", "", "network_tuple", "=", "(", "network_name", ",", "{", "\n", "\"opts\"", ":", "opts", ",", "\n", "\"name\"", ":", "name", "}", ")", "\n", "network", "=", "eval_method_from_tuple", "(", "network_module", ",", "network_tuple", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "Exception", "(", "\"problem in 'instantiate_network' with module: %s, kwargs: %s, exception %s\"", "%", "(", "network_name", ",", "opts", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "network", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.RandomGaussian.RandomGaussian.__init__": [[12, 18], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "shape", ",", "seed", "=", "None", ",", "rate", "=", "None", ",", "name", "=", "\"RandomUniform\"", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_shape", "=", "shape", "\n", "self", ".", "_seed", "=", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.RandomGaussian.RandomGaussian._build": [[19, 26], ["tensorflow.random_normal"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "input", ")", ":", "\n", "# input is ignored", "\n", "        ", "return", "tf", ".", "random_normal", "(", "self", ".", "_shape", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "1.0", ",", "\n", "seed", "=", "self", ".", "_seed", ",", "\n", "name", "=", "self", ".", "module_name", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Bernoulli.Bernoulli.__init__": [[20, 37], ["AbstractModule.AbstractModule.__init__", "operator.xor"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", "=", "-", "1", ",", "output_shape", "=", "-", "1", ",", "initializers", "=", "{", "}", ",", "regularizers", "=", "{", "}", ",", "clip_value", "=", "0", ",", "dtype", "=", "None", ",", "\n", "name", "=", "'Bernoulli'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "assert", "xor", "(", "output_size", "==", "-", "1", ",", "output_shape", "==", "-", "1", ")", ",", "\"Either output_size or output_shape mut be specified, not both\"", "\n", "\n", "if", "output_size", "!=", "-", "1", ":", "\n", "            ", "self", ".", "_output_shape", "=", "[", "output_size", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_output_shape", "=", "output_shape", "\n", "\n", "", "self", ".", "_initializers", "=", "initializers", "\n", "self", ".", "_regularizers", "=", "regularizers", "\n", "\n", "self", ".", "_clip_value", "=", "clip_value", "\n", "self", ".", "_dtype", "=", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Bernoulli.Bernoulli._build": [[38, 70], ["tensorflow.reshape", "types.MethodType", "types.MethodType", "types.MethodType", "tensorflow.nn.sigmoid", "tensorflow.clip_by_value", "tensorflow_probability.distributions.Bernoulli", "tensorflow_probability.distributions.Bernoulli", "Bernoulli.Bernoulli.mean", "sonnet.Linear", "Bernoulli.Bernoulli.mean", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "# create the layers for mean and covariance", "\n", "\n", "        ", "output_shape", "=", "[", "-", "1", "]", "+", "self", ".", "_output_shape", "\n", "logits", "=", "tf", ".", "reshape", "(", "snt", ".", "Linear", "(", "np", ".", "prod", "(", "self", ".", "_output_shape", ")", ",", "initializers", "=", "self", ".", "_initializers", ",", "regularizers", "=", "self", ".", "_regularizers", ")", "(", "inputs", ")", ",", "output_shape", ")", "\n", "\n", "dtype", "=", "inputs", ".", "dtype", "\n", "if", "self", ".", "_dtype", "is", "not", "None", ":", "\n", "            ", "dtype", "=", "self", ".", "_dtype", "\n", "\n", "", "if", "self", ".", "_clip_value", ">", "0", ":", "\n", "            ", "probs", "=", "tf", ".", "nn", ".", "sigmoid", "(", "logits", ")", "\n", "\n", "probs", "=", "tf", ".", "clip_by_value", "(", "probs", ",", "self", ".", "_clip_value", ",", "1", "-", "self", ".", "_clip_value", ")", "\n", "bernoulli", "=", "tfd", ".", "Bernoulli", "(", "probs", "=", "probs", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "bernoulli", "=", "tfd", ".", "Bernoulli", "(", "logits", "=", "logits", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "", "bernoulli", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "bernoulli", ")", "\n", "\n", "def", "distribution_parameters", "(", "self", ")", ":", "\n", "            ", "return", "[", "self", ".", "mean", "(", ")", "]", "\n", "", "bernoulli", ".", "distribution_parameters", "=", "types", ".", "MethodType", "(", "distribution_parameters", ",", "bernoulli", ")", "\n", "\n", "def", "get_probs", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "probs", "\n", "\n", "", "bernoulli", ".", "get_probs", "=", "types", ".", "MethodType", "(", "get_probs", ",", "bernoulli", ")", "\n", "\n", "return", "bernoulli", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResNet18.ResNet18.__init__": [[9, 40], ["sonnet.AbstractModule.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["  ", "def", "__init__", "(", "self", ",", "output_size", ",", "name", "=", "\"resnet18\"", ",", "use_weight_norm", "=", "False", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "**", "extra_params", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        num_outputs (int): the number of outputs of the module.\n        name (str): module name.\n        activation (tf function): activation used for the internal layers.\n        **extra_params: all the additional keyword arguments will be passed to all the Conv2DWN and to the ResUnit layers.\n\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "\n", "self", ".", "_conv_channels", "=", "64", "\n", "self", ".", "_conv_kernel_shape", "=", "[", "7", ",", "7", "]", "\n", "self", ".", "_conv_stride", "=", "2", "\n", "\n", "self", ".", "_pooling_kernel_shape", "=", "[", "2", ",", "2", "]", "\n", "self", ".", "_pooling_stride", "=", "2", "\n", "\n", "self", ".", "_resunit_channels", "=", "[", "\n", "64", ",", "64", ",", "128", ",", "128", ",", "256", ",", "256", ",", "512", ",", "512", "\n", "]", "\n", "self", ".", "_num_resunits", "=", "len", "(", "self", ".", "_resunit_channels", ")", "\n", "# first kernel 7x7 all the rest 3x3.", "\n", "self", ".", "_resunit_kernel_shapes", "=", "[", "[", "3", ",", "3", "]", "]", "*", "self", ".", "_num_resunits", "\n", "self", ".", "_resunit_strides", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "2", ",", "1", ",", "2", ",", "1", "]", "\n", "\n", "self", ".", "_padding", "=", "snt", ".", "SAME", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_use_weight_norm", "=", "use_weight_norm", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResNet18.ResNet18._build": [[42, 99], ["range", "tensorflow.layers.max_pooling2d", "enumerate", "tensorflow.layers.average_pooling2d", "Conv2DWN.Conv2DWN.Conv2DWN", "ResNet18.ResNet18.layers.append", "resunit", "sonnet.BatchFlatten", "sonnet.Linear", "ResUnit.ResUnit.ResUnit"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ",", "is_training", "=", "True", ",", "test_local_stats", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        inputs (type): node of input.\n        is_training (type): tells to batchnorm if to generate the update ops.\n        test_local_stats (type): used to test local stats in batch norm.\n\n    Returns:\n        logits\n\n    \"\"\"", "\n", "# instantiate all the convolutional layers", "\n", "self", ".", "layers", "=", "[", "Conv2DWN", "(", "name", "=", "\"conv2d_wn\"", ",", "\n", "output_channels", "=", "self", ".", "_conv_channels", ",", "\n", "kernel_shape", "=", "self", ".", "_conv_kernel_shape", ",", "\n", "stride", "=", "self", ".", "_conv_stride", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "use_weight_norm", "=", "self", ".", "_use_weight_norm", ",", "\n", "**", "self", ".", "_extra_params", ")", "]", "\n", "#(self, depth, name=\"resUnit\", kernel_shape=[3,3], stride=1, activation=tf.nn.relu, **extra_params)", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_resunits", ")", ":", "\n", "        ", "self", ".", "layers", ".", "append", "(", "ResUnit", "(", "\n", "depth", "=", "self", ".", "_resunit_channels", "[", "i", "]", ",", "\n", "name", "=", "\"resunit_{}\"", ".", "format", "(", "i", ")", ",", "\n", "kernel_shape", "=", "self", ".", "_resunit_kernel_shapes", "[", "i", "]", ",", "\n", "stride", "=", "self", ".", "_resunit_strides", "[", "i", "]", ",", "\n", "activation", "=", "self", ".", "_activation", ",", "\n", "use_weight_norm", "=", "self", ".", "_use_weight_norm", ",", "\n", "**", "self", ".", "_extra_params", ")", ")", "\n", "\n", "", "net", "=", "self", ".", "layers", "[", "0", "]", "(", "inputs", ")", "\n", "net", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "\n", "net", ",", "\n", "self", ".", "_pooling_kernel_shape", ",", "\n", "self", ".", "_pooling_stride", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "data_format", "=", "'channels_last'", ",", "\n", "name", "=", "\"max_pooling2d\"", "\n", ")", "\n", "\n", "for", "i", ",", "resunit", "in", "enumerate", "(", "self", ".", "layers", "[", "1", ":", "]", ")", ":", "\n", "        ", "net", "=", "resunit", "(", "net", ")", "\n", "\n", "", "net", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "\n", "net", ",", "\n", "self", ".", "_pooling_kernel_shape", ",", "\n", "self", ".", "_pooling_stride", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "data_format", "=", "'channels_last'", ",", "\n", "name", "=", "\"avg_pooling2d\"", "\n", ")", "\n", "\n", "net", "=", "snt", ".", "BatchFlatten", "(", "name", "=", "\"flatten\"", ")", "(", "net", ")", "\n", "logits", "=", "snt", ".", "Linear", "(", "self", ".", "_output_size", ")", "(", "net", ")", "\n", "\n", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.MultivariateNormalTriL.MultivariateNormalTriL.__init__": [[10, 23], ["AbstractGaussianSimple.AbstractGaussianSimple.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["        ", "_id", "=", "'TriL'", "\n", "_id", "+=", "\"_b\"", "+", "str", "(", "int", "(", "self", ".", "_bl", ")", ")", "\n", "_id", "+=", "\"_fl\"", "+", "str", "(", "int", "(", "self", ".", "_fl", ")", ")", "\n", "return", "_id", "\n", "\n", "", "def", "__init__", "(", "self", ",", "output_size", ",", "bayesian_layers", "=", "False", ",", "flipout", "=", "True", ",", "layer_kwargs", "=", "{", "}", ",", "layer_kwargs_bayes", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "'TriL'", ")", "\n", "\n", "self", ".", "_bl", "=", "bayesian_layers", "\n", "self", ".", "_fl", "=", "flipout", "\n", "\n", "if", "bayesian_layers", ":", "\n", "            ", "if", "flipout", ":", "\n", "                ", "Dense", "=", "partial", "(", "tfp", ".", "layers", ".", "DenseFlipout", ",", "**", "layer_kwargs_bayes", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.MultivariateNormalTriL.MultivariateNormalTriL._build": [[24, 61], ["tensorflow.layers.flatten", "sonnet.Linear", "sonnet.Linear", "int", "sonnet.Linear", "MultivariateNormalTriL.MultivariateNormalTriL.dense_loc", "MultivariateNormalTriL.MultivariateNormalTriL.dense_diag_params", "MultivariateNormalTriL.MultivariateNormalTriL.dense_out_of_diag_params", "tensorflow.contrib.distributions.fill_triangular", "tensorflow.pad", "tensorflow.linalg.set_diag", "tensorflow.get_variable", "tensorflow.contrib.distributions.fill_triangular", "tensorflow_probability.distributions.MultivariateNormalTriL", "tensorflow.nn.softplus", "tensorflow.multiply", "tensorflow.initializers.constant"], "methods", ["None"], ["", "else", ":", "\n", "                ", "Dense", "=", "partial", "(", "tfp", ".", "layers", ".", "DenseReparameterization", ",", "**", "layer_kwargs_bayes", ")", "\n", "", "", "else", ":", "\n", "            ", "Dense", "=", "partial", "(", "tf", ".", "keras", ".", "layers", ".", "Dense", ",", "**", "layer_kwargs", ")", "\n", "\n", "", "self", ".", "_flat", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "\n", "self", ".", "dense_loc", "=", "Dense", "(", "output_size", ")", "\n", "self", ".", "dense_diag_params", "=", "Dense", "(", "output_size", ")", "\n", "n_out_of_diag_elems", "=", "int", "(", "output_size", "*", "(", "output_size", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "dense_out_of_diag_params", "=", "Dense", "(", "n_out_of_diag_elems", ")", "\n", "\n", "n_tril", "=", "n_out_of_diag_elems", "+", "output_size", "\n", "self", ".", "_calibration_tril_params", "=", "self", ".", "add_weight", "(", "\"calibration_tril_params\"", ",", "\n", "shape", "=", "(", "n_tril", ",", ")", ",", "\n", "trainable", "=", "False", ",", "\n", "initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "value", "=", "1.", ")", ")", "\n", "self", ".", "calibration_tril", "=", "tf", ".", "contrib", ".", "distributions", ".", "fill_triangular", "(", "self", ".", "_calibration_tril_params", ",", "name", "=", "\"calibration_tril\"", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ",", "**", "extra_kwargs", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_flat", "(", "inputs", ")", "\n", "loc", "=", "self", ".", "dense_loc", "(", "inputs", ")", "\n", "diag_params", "=", "self", ".", "dense_diag_params", "(", "inputs", ")", "\n", "out_of_diag_params", "=", "self", ".", "dense_out_of_diag_params", "(", "inputs", ")", "\n", "\n", "lower_triangle", "=", "tf", ".", "contrib", ".", "distributions", ".", "fill_triangular", "(", "out_of_diag_params", ")", "\n", "lower_triangle", "=", "tf", ".", "pad", "(", "lower_triangle", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "\n", "diag_positive", "=", "MINIMAL_COVARIANCE", "+", "tf", ".", "nn", ".", "softplus", "(", "diag_params", ")", "\n", "\n", "scale_tril", "=", "tf", ".", "linalg", ".", "set_diag", "(", "lower_triangle", ",", "diag_positive", ")", "\n", "\n", "ouput_params", "=", "{", "\"loc\"", ":", "loc", ",", "\"scale_tril\"", ":", "tf", ".", "multiply", "(", "self", ".", "calibration_tril", ",", "scale_tril", ")", "}", "\n", "\n", "distr", "=", "tfp", ".", "distributions", ".", "MultivariateNormalTriL", "(", "**", "ouput_params", ")", "\n", "\n", "# hack because keras does not want distr in output... (Riccardo)", "\n", "distr", ".", "shape", "=", "tf", ".", "TensorShape", "(", "tuple", "(", "distr", ".", "batch_shape", ".", "as_list", "(", ")", "+", "distr", ".", "event_shape", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResDec.ResDec.__init__": [[13, 32], ["AbstractResNetLayer.AbstractResNetLayer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "num_hiddens", ",", "num_residual_layers", ",", "num_residual_hiddens", ",", "\n", "activation", ",", "\n", "is_training", ",", "\n", "name", "=", "'ResDec'", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "bn_renormalization", "=", "True", ",", "\n", "**", "extra_params", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_hiddens", ",", "\n", "num_residual_layers", ",", "\n", "num_residual_hiddens", ",", "\n", "activation", ",", "\n", "is_training", ",", "\n", "name", "=", "name", ",", "\n", "prob_drop", "=", "prob_drop", ",", "\n", "bn_momentum", "=", "bn_momentum", ",", "\n", "bn_renormalization", "=", "bn_renormalization", ",", "\n", "**", "extra_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ResDec.ResDec._build": [[33, 87], ["ResDec.ResDec._dropout", "tensorflow.layers.batch_normalization", "build_utils.residual_stack", "ResDec.ResDec._dropout", "tensorflow.layers.batch_normalization", "ResDec.ResDec._activation", "sonnet.Conv2D", "sonnet.Conv2DTranspose", "sonnet.Conv2DTranspose", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout", "home.repos.pwc.inspect_result.rist-ro_argo.network.build_utils.residual_stack", "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout"], ["", "def", "_build", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "snt", ".", "Conv2D", "(", "\n", "output_channels", "=", "self", ".", "_num_hiddens", ",", "\n", "kernel_shape", "=", "(", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "name", "=", "\"dec_1\"", ")", "(", "x", ")", "\n", "\n", "h", "=", "self", ".", "_dropout", "(", "h", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "h", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "h", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_1\"", ")", "\n", "\n", "h", "=", "residual_stack", "(", "\n", "h", ",", "\n", "self", ".", "_num_hiddens", ",", "\n", "self", ".", "_num_residual_layers", ",", "\n", "self", ".", "_num_residual_hiddens", ",", "\n", "activation", "=", "self", ".", "_activation", ",", "\n", "training", "=", "self", ".", "_is_training", ",", "\n", "prob_drop", "=", "self", ".", "_prob_drop", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", "\n", ")", "\n", "\n", "h", "=", "snt", ".", "Conv2DTranspose", "(", "\n", "output_channels", "=", "int", "(", "self", ".", "_num_hiddens", "/", "2", ")", ",", "\n", "output_shape", "=", "None", ",", "\n", "kernel_shape", "=", "(", "4", ",", "4", ")", ",", "\n", "stride", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "\"dec_2\"", ")", "(", "h", ")", "\n", "\n", "h", "=", "self", ".", "_dropout", "(", "h", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "h", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "h", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_2\"", ")", "\n", "\n", "h", "=", "self", ".", "_activation", "(", "h", ")", "\n", "\n", "x_recon", "=", "snt", ".", "Conv2DTranspose", "(", "\n", "output_channels", "=", "3", ",", "\n", "output_shape", "=", "None", ",", "\n", "kernel_shape", "=", "(", "4", ",", "4", ")", ",", "\n", "stride", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "\"dec_3\"", ")", "(", "h", ")", "\n", "\n", "return", "x_recon", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogitNormalDiagonalPlusMinusOne.LogitNormalDiagonalPlusMinusOne.__init__": [[20, 44], ["AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "clip_value", "=", "0.001", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'logit_normal_diagonal'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n", "self", ".", "_clip_value", "=", "clip_value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogitNormalDiagonalPlusMinusOne.LogitNormalDiagonalPlusMinusOne._build": [[45, 79], ["LogitNormalDiagonalPlusMinusOne.LogitNormalDiagonalPlusMinusOne.create_mean_n_cov_layers", "LogitNormalDiagonalPlusMinusOne.LogitNormalDiagonalPlusMinusOne.set_contractive_regularizer", "tensorflow_probability.distributions.Normal", "tensorflow_probability.bijectors.Sigmoid", "tensorflow_probability.distributions.TransformedDistribution", "PlusMinusOneMapping.PlusMinusOneMapping.PlusMinusOneMapping", "tensorflow_probability.distributions.TransformedDistribution", "types.MethodType", "types.MethodType", "PlusMinusOneMapping.PlusMinusOneMapping.PlusMinusOneMapping.forward", "LogitNormalDiagonalPlusMinusOne.LogitNormalDiagonalPlusMinusOne._call_log_prob", "tensorflow_probability.bijectors.Sigmoid.forward", "utils.argo_utils.tf_clip", "tensorflow_probability.distributions.Normal.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.tf_clip", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "#TODO is this the kind of regularization we want. I think it makes sense.", "\n", "self", ".", "set_contractive_regularizer", "(", "mean", ",", "covariance", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "gaussian", "=", "tfd", ".", "Normal", "(", "loc", "=", "mean", ",", "scale", "=", "scale", ")", "\n", "\n", "sigmoid_bijector", "=", "tfb", ".", "Sigmoid", "(", ")", "\n", "logitnormal", "=", "tfd", ".", "TransformedDistribution", "(", "distribution", "=", "gaussian", ",", "bijector", "=", "sigmoid_bijector", ")", "\n", "affine_transform", "=", "PlusMinusOneMapping", "(", "scale", "=", "2.", ",", "shift", "=", "-", "1.", ")", "\n", "logitnormal_plus_minus_one", "=", "tfd", ".", "TransformedDistribution", "(", "distribution", "=", "logitnormal", ",", "bijector", "=", "affine_transform", ")", "\n", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "# this is because there is not mean for the LogitNormalDiagonal distribution", "\n", "            ", "return", "affine_transform", ".", "forward", "(", "sigmoid_bijector", ".", "forward", "(", "gaussian", ".", "mean", "(", ")", ")", ")", "\n", "\n", "", "logitnormal_plus_minus_one", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "logitnormal_plus_minus_one", ")", "\n", "\n", "clip_value", "=", "self", ".", "_clip_value", "\n", "\n", "# make sure a rescale the input for log_prob", "\n", "def", "log_prob", "(", "self", ",", "x", ",", "name", "=", "'log_prob'", ",", "**", "kwargs", ")", ":", "\n", "# kinda of dirty I know, it is used to avoid recursion (Luigi)", "\n", "            ", "return", "self", ".", "_call_log_prob", "(", "tf_clip", "(", "x", ",", "low", "=", "-", "1.0", "+", "clip_value", ",", "high", "=", "1.0", "-", "clip_value", ")", ",", "name", "=", "name", ",", "**", "kwargs", ")", "\n", "\n", "", "logitnormal_plus_minus_one", ".", "log_prob", "=", "types", ".", "MethodType", "(", "log_prob", ",", "logitnormal_plus_minus_one", ")", "\n", "\n", "return", "logitnormal_plus_minus_one", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ContractiveRegularizer.ContractiveRegularizer.__init__": [[16, 51], ["print", "decor_arg.pop"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "**", "decor_arg", ")", ":", "\n", "\n", "        ", "print", "(", "\"ConstractiveRegularizedModule\"", ")", "\n", "\n", "#string = string", "\n", "#print(\"Object created:\" + string)", "\n", "\n", "#self._other_class = cls", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "assert", "(", "\"contractive_regularizer\"", "in", "decor_arg", ")", "\n", "\n", "contractive_regularizer", "=", "decor_arg", ".", "pop", "(", "\"contractive_regularizer\"", ")", "\n", "\n", "'''\n        # manual copy not needed\n        decor_arg_minus_contractive = {}\n        for k, d in decor_arg.items():\n            if k != \"contractive_regularizer\":\n                decor_arg_minus_contractive[k] = d\n        '''", "\n", "\n", "self", ".", "_contractive_regularizer", "=", "contractive_regularizer", "\n", "self", ".", "_decor_arg", "=", "decor_arg", "#_minus_contractive", "\n", "\n", "'''\n        @property\n        def test_set_x_fileName(self):\n            return self._test_set_x_fileName\n        \n        @test_set_x_fileName.setter\n        def test_set_x_fileName(self, test_set_x_fileName):\n            self._test_set_x_fileName = test_set_x_fileName\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ContractiveRegularizer.ContractiveRegularizer.__call__": [[52, 116], ["print", "str", "ContractiveRegularizer.ContractiveRegularizer.set_contractive_regularizer", "cls", "utils.argo_utils.eval_method_from_tuple.", "utils.argo_utils.get_ac_collection_name", "tensorflow.add_to_collection", "importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "ImportError", "__name__.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_ac_collection_name", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["", "def", "__call__", "(", "self", ",", "cls", ")", ":", "\n", "\n", "        ", "print", "(", "\"def __call__(self, cls)\"", "+", "str", "(", "cls", ")", ")", "\n", "#self.snt_module = cls", "\n", "\n", "# args of the sonnet module", "\n", "decor_arg", "=", "self", ".", "_decor_arg", "\n", "contractive_regularizer", "=", "self", ".", "_contractive_regularizer", "\n", "\n", "class", "ConstractiveRegularizedModule", "(", "cls", ")", ":", "\n", "#print(\"class ConstractiveRegularizedModule(cls)\" + str(cls))", "\n", "\n", "            ", "'''\n            def __init__(self, cls):\n                self._contractive_regularizer_tuple = None\n                self._contractive_regularizer_inputs = None\n                self._contractive_collection_network_str = \"\"\n            '''", "\n", "\n", "#pdb.set_trace()", "\n", "#snt_module = cls", "\n", "\n", "#self._decor_arg = self._decor_arg", "\n", "\n", "def", "__call__", "(", "self", ",", "*", "cls_args", ")", ":", "\n", "# cls_args is the node to which I attach _build", "\n", "\n", "# calling _build of the sonnet module", "\n", "                ", "snt_layer", "=", "cls", "(", "**", "decor_arg", ")", "(", "*", "cls_args", ")", "\n", "\n", "contractive_regularizer_name", ",", "contractive_regularizer_kwargs", ",", "contractive_regularizer_inputs", ",", "contractive_collection_network_str", "=", "contractive_regularizer", "\n", "\n", "contractive_regularizer_tuple", "=", "(", "contractive_regularizer_name", ",", "\n", "contractive_regularizer_kwargs", ")", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "snt_layer", ",", "\n", "contractive_regularizer_inputs", ",", "\n", "contractive_regularizer_tuple", ",", "\n", "contractive_collection_network_str", ")", "\n", "\n", "return", "snt_layer", "\n", "\n", "", "@", "property", "\n", "def", "_contractive_regularizer_filename", "(", "self", ")", ":", "\n", "                ", "return", "\".ContractiveRegularizer\"", "\n", "\n", "", "def", "set_contractive_regularizer", "(", "self", ",", "node", ",", "x", ",", "contractive_regularizer_tuple", "=", "None", ",", "contractive_collection_network_str", "=", "\"\"", ")", ":", "\n", "                ", "if", "contractive_regularizer_tuple", ":", "\n", "                    ", "regularizer_name", ",", "regularizer_kwargs", "=", "contractive_regularizer_tuple", "\n", "try", ":", "\n", "                        ", "reg_module", "=", "importlib", ".", "import_module", "(", "self", ".", "_contractive_regularizer_filename", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "contractive_regularizer", "=", "eval_method_from_tuple", "(", "reg_module", ",", "(", "regularizer_name", ",", "regularizer_kwargs", ")", ")", "\n", "#pdb.set_trace()", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "                        ", "raise", "ImportError", "(", "\"regularizer %s not found\"", "%", "regularizer_name", ")", "from", "e", "\n", "\n", "", "reg_node", "=", "contractive_regularizer", "(", "node", ",", "x", ")", "\n", "\n", "ac_collection_name", "=", "get_ac_collection_name", "(", "contractive_collection_network_str", ")", "\n", "tf", ".", "add_to_collection", "(", "ac_collection_name", ",", "reg_node", ")", "\n", "", "", "", "return", "ConstractiveRegularizedModule", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ContractiveRegularizer.standard_contractive_regularizer": [[117, 151], ["isinstance", "isinstance", "ValueError", "ValueError", "tensorflow.name_scope", "tensorflow.convert_to_tensor", "tensorflow.norm", "tensorflow.multiply", "tensorflow.python.ops.parallel_for.gradients.batch_jacobian"], "function", ["None"], ["", "", "def", "standard_contractive_regularizer", "(", "scale", ",", "norm", ",", "trick", "=", "False", ",", "scope", "=", "None", ")", ":", "\n", "# Returns a dictionary of functions that can be used to compute the regularizations", "\n", "# to the node", "\n", "\n", "# x is input to the network", "\n", "\n", "# input validation", "\n", "    ", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "        ", "if", "scale", "<", "0.", ":", "\n", "            ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "#if scale == 0.:", "\n", "#    return lambda _: None", "\n", "\n", "", "", "use_pfor", "=", "False", "\n", "def", "contractive_regularizer", "(", "node", ",", "x", ",", "reg_name", "=", "\"standard_contractive_regularizer\"", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "scope", ",", "reg_name", ",", "[", "node", ",", "x", "]", ")", "as", "name", ":", "\n", "            ", "scale_regularizer", "=", "tf", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "node", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale'", ")", "\n", "\n", "norm_jac", "=", "tf", ".", "norm", "(", "batch_jacobian", "(", "node", ",", "x", ",", "use_pfor", "=", "use_pfor", ")", ",", "ord", "=", "norm", ",", "name", "=", "\"norm_jac\"", ")", "\n", "\n", "reg_node", "=", "tf", ".", "multiply", "(", "scale_regularizer", ",", "\n", "norm_jac", ",", "\n", "name", "=", "reg_name", ")", "\n", "\n", "#tf.summary.scalar(norm_jac.name, norm_jac)", "\n", "\n", "return", "reg_node", "\n", "\n", "", "", "return", "contractive_regularizer", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.__init__": [[23, 108], ["AbstractModule.AbstractModule.__init__", "isinstance", "ValueError", "float"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "vectorial_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'abstract_stochastic'", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            either output_size or output_shape for the dimensions of the output layer.\n            module_tuple : (module_name, module_kwargs), you can use Linear, LinearWN, (Conv2D, Conv2DWN,) Conv2DTranspose\n                        if shape is not specified in the module_kwargs, it will be inferred using output_size and output_shape\n                        of the AbstractGaussian module.\n            minimal_covariance (float): covariance minimal threshold (in addition to NUMTOL, that is always present).\n            covariance_parameterization (str): exp or softplus.\n            scalar_covariance : one of [True, False, float]. If True or float a single scalar covariance will be used for all the distributions.\n                                If a float is passed, will instantiate a constant scalar instead of a trainable variable. NB: please be aware that\n                                covariance_parameterization is always applied on top of the initial node to get the covariance, this ensure to have\n                                a positive value always, removing checks.\n            initializers (dict): sonnet style initializers, dict of 'w' and 'b'.\n            regularizers (dict): sonnet style regularizers, dict of 'w' and 'b'.\n            contractive_regularizer (tuple): (reg_name, reg_kwargs, ref_node, network_str). network_str is for collection to which add the regularization.\n            name (str): name of this sonnet module.\n        \n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "if", "(", "output_size", "is", "not", "None", ")", "and", "(", "output_shape", "is", "not", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Either output_size or output_shape mut be specified, not both\"", ")", "\n", "\n", "", "self", ".", "_output_shape", "=", "None", "\n", "\n", "if", "output_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "_output_shape", "=", "[", "output_size", "]", "\n", "", "elif", "output_shape", "is", "not", "None", ":", "\n", "            ", "self", ".", "_output_shape", "=", "output_shape", "\n", "\n", "#         import pdb;pdb.set_trace()", "\n", "", "self", ".", "_module_tuple", "=", "module_tuple", "\n", "self", ".", "_extra_kwargs", "=", "{", "\"initializers\"", ":", "initializers", ",", "\n", "\"regularizers\"", ":", "regularizers", "}", "\n", "\n", "self", ".", "_cov_parameterization", "=", "covariance_parameterization", "\n", "\n", "self", ".", "_contractive_regularizer_tuple", "=", "None", "\n", "self", ".", "_contractive_regularizer_inputs", "=", "None", "\n", "self", ".", "_contractive_collection_network_str", "=", "\"\"", "\n", "\n", "# check on the parameters", "\n", "assert", "(", "not", "(", "scalar_covariance", "!=", "False", "and", "vectorial_covariance", "!=", "False", ")", ")", "\n", "\n", "self", ".", "_scalar_constant", "=", "None", "\n", "if", "isinstance", "(", "scalar_covariance", ",", "bool", ")", ":", "\n", "            ", "self", ".", "_scalar_bool", "=", "scalar_covariance", "\n", "", "else", ":", "\n", "            ", "self", ".", "_scalar_bool", "=", "True", "\n", "self", ".", "_scalar_constant", "=", "float", "(", "scalar_covariance", ")", "\n", "\n", "", "self", ".", "_vectorial_bool", "=", "vectorial_covariance", "\n", "#if isinstance(scalar_covariance, bool):", "\n", "#    self._vectorial_bool = vectorial_covariance", "\n", "#else:", "\n", "#    self._scalar_bool = True", "\n", "#    self._scalar_constant = float(scalar_covariance)", "\n", "\n", "\n", "if", "contractive_regularizer", ":", "\n", "            ", "contractive_regularizer_name", ",", "contractive_regularizer_kwargs", ",", "contractive_regularizer_inputs", ",", "contractive_collection_network_str", "=", "contractive_regularizer", "\n", "\n", "self", ".", "_contractive_regularizer_tuple", "=", "(", "contractive_regularizer_name", ",", "\n", "contractive_regularizer_kwargs", ")", "\n", "\n", "self", ".", "_contractive_regularizer_inputs", "=", "contractive_regularizer_inputs", "\n", "self", ".", "_contractive_collection_network_str", "=", "contractive_collection_network_str", "\n", "\n", "", "self", ".", "_minimal_covariance", "=", "minimal_covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._contractive_regularizer_filename": [[109, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abstractmethod", "\n", "def", "_contractive_regularizer_filename", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer": [[114, 133], ["utils.argo_utils.eval_method_from_tuple.", "utils.argo_utils.get_ac_collection_name", "importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "isinstance", "tensorflow.add_to_collection", "ImportError", "__name__.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_ac_collection_name", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["", "def", "set_contractive_regularizer", "(", "self", ",", "mean", ",", "cov", ",", "x", ",", "contractive_regularizer_tuple", "=", "None", ",", "contractive_collection_network_str", "=", "\"\"", ")", ":", "\n", "#         pdb.set_trace()", "\n", "        ", "if", "contractive_regularizer_tuple", ":", "\n", "            ", "regularizer_name", ",", "regularizer_kwargs", "=", "contractive_regularizer_tuple", "\n", "try", ":", "\n", "                ", "reg_module", "=", "importlib", ".", "import_module", "(", "self", ".", "_contractive_regularizer_filename", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "contractive_regularizer", "=", "eval_method_from_tuple", "(", "reg_module", ",", "(", "regularizer_name", ",", "regularizer_kwargs", ")", ")", "\n", "#                 pdb.set_trace()", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "                ", "raise", "ImportError", "(", "\"regularizer %s not found\"", "%", "regularizer_name", ")", "from", "e", "\n", "\n", "\n", "", "reg_node", "=", "contractive_regularizer", "(", "mean", ",", "cov", ",", "x", ")", "\n", "if", "not", "isinstance", "(", "reg_node", ",", "list", ")", ":", "\n", "                 ", "reg_node", "=", "[", "reg_node", "]", "\n", "\n", "", "ac_collection_name", "=", "get_ac_collection_name", "(", "contractive_collection_network_str", ")", "\n", "for", "r", "in", "reg_node", ":", "\n", "                ", "tf", ".", "add_to_collection", "(", "ac_collection_name", ",", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._get_stride": [[135, 142], ["numpy.any", "Exception", "int", "zip", "zip"], "methods", ["None"], ["", "", "", "def", "_get_stride", "(", "self", ",", "in_shape", ",", "out_shape", ")", ":", "\n", "        ", "reminders", "=", "[", "i", "%", "o", "for", "i", ",", "o", "in", "zip", "(", "in_shape", "[", "0", ":", "2", "]", ",", "out_shape", "[", "0", ":", "2", "]", ")", "]", "\n", "if", "np", ".", "any", "(", "reminders", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"the output_shape specified `%s` is not allowed since does not divide input_shape `%s`\"", "%", "(", "out_shape", "[", "0", ":", "2", "]", ",", "in_shape", "[", "0", ":", "2", "]", ")", ")", "\n", "\n", "", "stride", "=", "[", "int", "(", "i", "/", "o", ")", "for", "i", ",", "o", "in", "zip", "(", "in_shape", "[", "0", ":", "2", "]", ",", "out_shape", "[", "0", ":", "2", "]", ")", "]", "\n", "return", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in": [[144, 151], ["kwargs.keys", "Exception"], "methods", ["None"], ["", "def", "check_key_not_in", "(", "self", ",", "key_name", ",", "kwargs", ",", "accepted_value", "=", "None", ")", ":", "\n", "        ", "if", "key_name", "in", "kwargs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "accepted_value", "and", "kwargs", "[", "key_name", "]", "==", "accepted_value", ":", "\n", "                ", "return", "\n", "\n", "", "raise", "Exception", "(", "\"you specified both %s `%s` in submodule and outputshape `%s`\\\n                            in the StochasticLayer wrapper. disallowed\"", "%", "(", "key_name", ",", "kwargs", "[", "key_name", "]", ",", "self", ".", "_output_shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_in": [[152, 155], ["kwargs.keys", "Exception"], "methods", ["None"], ["", "", "def", "check_key_in", "(", "self", ",", "key_name", ",", "kwargs", ",", "kwargs_name", ",", "for_this_reason", ")", ":", "\n", "        ", "if", "key_name", "not", "in", "kwargs", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"key %s is missing in %s, it is required %s.\"", "%", "(", "key_name", ",", "kwargs_name", ",", "for_this_reason", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.force_between_zero_and_one": [[156, 176], ["Exception", "tensorflow.clip_by_value", "tensorflow.sigmoid"], "methods", ["None"], ["", "", "def", "force_between_zero_and_one", "(", "self", ",", "tnsr", ",", "method", "=", "\"sigmoid\"", ")", ":", "\n", "        ", "\"\"\"Force the tensor in between zero and one.\n\n        Args:\n            tnsr (type): the tensor.\n            method (type): sigmoid or clip.\n\n        Returns:\n            the transformed tensor with values in [0,1]\n        \"\"\"", "\n", "choices", "=", "[", "\"clip\"", ",", "\"sigmoid\"", "]", "\n", "if", "method", "not", "in", "choices", ":", "\n", "            ", "return", "Exception", "(", "\"method `%s` not recognized, must be one of `%s`\"", "%", "(", "method", ",", "choices", ")", ")", "\n", "\n", "", "if", "method", "==", "\"clip\"", ":", "\n", "            ", "tnsr", "=", "tf", ".", "clip_by_value", "(", "tnsr", ",", "0.", ",", "1.", ")", "\n", "", "elif", "method", "==", "\"sigmoid\"", ":", "\n", "            ", "tnsr", "=", "tf", ".", "sigmoid", "(", "tnsr", ")", "\n", "\n", "", "return", "tnsr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.force_between_plus_minus_one": [[177, 197], ["Exception", "tensorflow.clip_by_value", "tensorflow.tanh"], "methods", ["None"], ["", "def", "force_between_plus_minus_one", "(", "self", ",", "tnsr", ",", "method", "=", "\"tanh\"", ")", ":", "\n", "        ", "\"\"\"Force the tensor in between zero and one.\n\n        Args:\n            tnsr (type): the tensor.\n            method (type): sigmoid or clip.\n\n        Returns:\n            the transformed tensor with values in [0,1]\n        \"\"\"", "\n", "choices", "=", "[", "\"clip\"", ",", "\"tanh\"", "]", "\n", "if", "method", "not", "in", "choices", ":", "\n", "            ", "return", "Exception", "(", "\"method `%s` not recognized, must be one of `%s`\"", "%", "(", "method", ",", "choices", ")", ")", "\n", "\n", "", "if", "method", "==", "\"clip\"", ":", "\n", "            ", "tnsr", "=", "tf", ".", "clip_by_value", "(", "tnsr", ",", "-", "1.", ",", "1.", ")", "\n", "", "elif", "method", "==", "\"tanh\"", ":", "\n", "            ", "tnsr", "=", "tf", ".", "tanh", "(", "tnsr", ")", "\n", "\n", "", "return", "tnsr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.get_covariance_from_parameters_tf": [[208, 219], ["tensorflow.exp", "Exception", "tensorflow.square", "tensorflow.nn.softplus", "tensorflow.nn.softplus"], "methods", ["None"], ["", "def", "get_covariance_from_parameters_tf", "(", "self", ",", "parameters", ")", ":", "\n", "\n", "        ", "if", "self", ".", "_cov_parameterization", "==", "'exp'", ":", "\n", "            ", "covariance", "=", "tf", ".", "exp", "(", "parameters", ")", "+", "self", ".", "_minimal_covariance", "+", "NUMTOL", "\n", "", "elif", "self", ".", "_cov_parameterization", "==", "'softplus'", ":", "\n", "            ", "covariance", "=", "tf", ".", "square", "(", "tf", ".", "nn", ".", "softplus", "(", "parameters", ")", ")", "+", "self", ".", "_minimal_covariance", "+", "NUMTOL", "\n", "", "elif", "self", ".", "_cov_parameterization", "==", "'linear_softplus'", ":", "\n", "            ", "covariance", "=", "tf", ".", "nn", ".", "softplus", "(", "parameters", ")", "+", "self", ".", "_minimal_covariance", "+", "NUMTOL", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid parameterization method for the covariance diagonal elements: \"", "+", "self", ".", "_cov_parameterization", ")", "\n", "", "return", "covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.prepare_input_and_merge_module_kwargs": [[220, 265], ["tensorflow.layers.flatten", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "numpy.prod", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "AbstractStochasticLayer.AbstractStochasticLayer._get_stride", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "Exception", "tensorflow.layers.flatten.shape.as_list", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "AbstractStochasticLayer.AbstractStochasticLayer._get_stride", "tensorflow.layers.flatten.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._get_stride", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._get_stride"], ["", "def", "prepare_input_and_merge_module_kwargs", "(", "self", ",", "inputs", ",", "module_name", ",", "module_kwargs", ")", ":", "\n", "\n", "        ", "extra_kwargs", "=", "self", ".", "_extra_kwargs", "\n", "# if self._output_shape is set I should write sizes in the Submodule", "\n", "if", "module_name", "==", "\"Linear\"", "or", "module_name", "==", "\"LinearWN\"", ":", "\n", "            ", "inputs", "=", "tf", ".", "layers", ".", "flatten", "(", "inputs", ")", "\n", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_size\"", ",", "module_kwargs", ")", "\n", "extra_kwargs", "[", "\"output_size\"", "]", "=", "np", ".", "prod", "(", "self", ".", "_output_shape", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_output_shape", "=", "[", "module_kwargs", "[", "\"output_size\"", "]", "]", "\n", "\n", "", "", "elif", "module_name", "==", "\"Conv2D\"", "or", "module_name", "==", "\"Conv2DWN\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"stride\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"padding\"", ",", "module_kwargs", ",", "'SAME'", ")", "\n", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "extra_kwargs", "[", "\"stride\"", "]", "=", "self", ".", "_get_stride", "(", "inputs", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ",", "\n", "self", ".", "_output_shape", ")", "\n", "", "", "elif", "module_name", "==", "\"Conv1D\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"padding\"", ",", "module_kwargs", ",", "'SAME'", ")", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "\n", "", "", "elif", "module_name", "==", "\"Conv2DTranspose\"", "or", "module_name", "==", "\"Conv2DTransposeWN\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"stride\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"output_shape\"", ",", "module_kwargs", ")", "\n", "extra_kwargs", "[", "\"output_shape\"", "]", "=", "self", ".", "_output_shape", "[", "0", ":", "2", "]", "\n", "extra_kwargs", "[", "\"stride\"", "]", "=", "self", ".", "_get_stride", "(", "self", ".", "_output_shape", ",", "\n", "inputs", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"module name `%s` is not allowed, is not implemented yet to be wrapped by a Stochastic Layer.\"", "%", "module_name", ")", "\n", "\n", "", "kwargs", "=", "{", "**", "extra_kwargs", ",", "\n", "**", "module_kwargs", "}", "\n", "\n", "return", "inputs", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.create_mean_n_cov_layers": [[266, 308], ["AbstractStochasticLayer.AbstractStochasticLayer.prepare_input_and_merge_module_kwargs", "utils.argo_utils.load_sonnet_module", "utils.argo_utils.load_sonnet_module.", "AbstractStochasticLayer.AbstractStochasticLayer.get_covariance_from_parameters_tf", "tensorflow.sqrt", "utils.argo_utils.load_sonnet_module", "utils.argo_utils.load_sonnet_module.", "tensorflow.reshape", "tensorflow.reshape", "AbstractStochasticLayer.AbstractStochasticLayer.check_key_in", "tensorflow.get_variable", "tensorflow.constant", "kwargs.copy", "utils.argo_utils.load_sonnet_module", "utils.argo_utils.load_sonnet_module.", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.prepare_input_and_merge_module_kwargs", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.get_covariance_from_parameters_tf", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_in", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module"], ["", "def", "create_mean_n_cov_layers", "(", "self", ",", "inputs", ")", ":", "\n", "# create the layers for mean and covariance", "\n", "#         import pdb;pdb.set_trace()", "\n", "        ", "module_name", ",", "module_kwargs", "=", "self", ".", "_module_tuple", "\n", "inputs", ",", "kwargs", "=", "self", ".", "prepare_input_and_merge_module_kwargs", "(", "inputs", ",", "module_name", ",", "module_kwargs", ")", "\n", "\n", "sntmodule_mean", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "mean", "=", "sntmodule_mean", "(", "inputs", ")", "\n", "\n", "# decide how to instantiate the covariance parameters", "\n", "if", "not", "self", ".", "_scalar_bool", "and", "not", "self", ".", "_vectorial_bool", ":", "\n", "            ", "sntmodule_cov", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "covariance_params", "=", "sntmodule_cov", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "_scalar_bool", ":", "\n", "                ", "if", "self", ".", "_scalar_constant", "is", "None", ":", "\n", "                    ", "self", ".", "check_key_in", "(", "'b'", ",", "self", ".", "_extra_kwargs", "[", "'initializers'", "]", ",", "'initializers'", ",", "\n", "'to initialize the scalar covariance parameter'", ")", "\n", "init_cov", "=", "self", ".", "_extra_kwargs", "[", "'initializers'", "]", "[", "'b'", "]", "\n", "covariance_params", "=", "tf", ".", "get_variable", "(", "name", "=", "\"scalar_cov_param\"", ",", "shape", "=", "(", ")", ",", "initializer", "=", "init_cov", ")", "\n", "", "else", ":", "\n", "                    ", "covariance_params", "=", "tf", ".", "constant", "(", "self", ".", "_scalar_constant", ",", "name", "=", "\"scalar_cov_param\"", ")", "\n", "", "", "elif", "self", ".", "_vectorial_bool", ":", "\n", "                ", "new_kwargs", "=", "kwargs", ".", "copy", "(", ")", "\n", "new_kwargs", "[", "\"output_size\"", "]", "=", "1", "\n", "sntmodule_cov", "=", "load_sonnet_module", "(", "module_name", ",", "new_kwargs", ")", "\n", "covariance_params", "=", "sntmodule_cov", "(", "inputs", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"unexpected condition\"", ")", "\n", "\n", "# if I am using linear layers I need to reshape to match output_shape", "\n", "", "", "if", "module_name", "==", "\"Linear\"", "or", "module_name", "==", "\"LinearWN\"", ":", "\n", "            ", "output_shape", "=", "[", "-", "1", "]", "+", "self", ".", "_output_shape", "\n", "mean", "=", "tf", ".", "reshape", "(", "mean", ",", "output_shape", ")", "\n", "if", "not", "self", ".", "_scalar_bool", "and", "not", "self", ".", "_vectorial_bool", ":", "\n", "                ", "covariance_params", "=", "tf", ".", "reshape", "(", "covariance_params", ",", "output_shape", ")", "\n", "\n", "", "", "covariance", "=", "self", ".", "get_covariance_from_parameters_tf", "(", "covariance_params", ")", "\n", "# I need the standard deviation for the Normal tf distribution", "\n", "scale", "=", "tf", ".", "sqrt", "(", "covariance", ")", "\n", "\n", "return", "mean", ",", "covariance", ",", "scale", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec.__init__": [[8, 64], ["sonnet.AbstractModule.__init__", "len", "keras_models.keras_utils.get_renorm_clipping", "utils.argo_utils.make_list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.get_renorm_clipping", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.make_list"], ["    ", "def", "__init__", "(", "self", ",", "\n", "channels", ",", "\n", "kernel_shape", ",", "\n", "# padding=\"SAME\",", "\n", "activation", ",", "\n", "is_training", ",", "\n", "final_activation", "=", "True", ",", "\n", "linear_first", "=", "None", ",", "# {\"sizes\" : [128 * 7 * 7, ...], \"reshape\" : (7, 7, 128)]},", "\n", "name", "=", "\"conv_dec\"", ",", "\n", "prob_drop", "=", "0.1", ",", "\n", "bn_momentum", "=", "0.99", ",", "\n", "bn_renormalization", "=", "True", ",", "\n", "output_shape", "=", "None", ",", "\n", "**", "extra_params", ")", ":", "\n", "\n", "        ", "\"\"\"\n        Args:\n            output_shape (tuple): output shape to enforce (optionoal). In case it is specified, last layer will have this output shape.\n            name (type): module name.\n            activation (type): activation used for the internal layers.\n            **extra_params (type): all the additional keyword arguments will be passed to the snt.Conv2D layers. (initializers, regularizers)\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_hidden_channels", "=", "channels", "\n", "self", ".", "_num_layers", "=", "len", "(", "channels", ")", "\n", "# self._Conv_Class = snt.Conv2DTranspose if use_deconv else snt.Conv2D", "\n", "\n", "self", ".", "_stride", "=", "2", "\n", "self", ".", "_kernel_shape", "=", "kernel_shape", "\n", "\n", "self", ".", "_padding", "=", "snt", ".", "SAME", "\n", "# self._final_padding = padding", "\n", "\n", "self", ".", "_output_shape", "=", "output_shape", "\n", "\n", "self", ".", "_prob_drop", "=", "prob_drop", "\n", "self", ".", "_activation", "=", "activation", "\n", "self", ".", "_final_activation", "=", "final_activation", "\n", "self", ".", "_extra_params", "=", "extra_params", "\n", "\n", "self", ".", "_bn_renormalization", "=", "bn_renormalization", "\n", "# instantiate all the convolutional layers", "\n", "self", ".", "_bn_momentum", "=", "bn_momentum", "\n", "\n", "self", ".", "_renorm_clipping", "=", "None", "\n", "if", "self", ".", "_bn_renormalization", ":", "\n", "            ", "self", ".", "_renorm_clipping", "=", "get_renorm_clipping", "(", ")", "\n", "\n", "", "if", "linear_first", "is", "not", "None", ":", "\n", "            ", "self", ".", "_linear_first_sizes", "=", "make_list", "(", "linear_first", "[", "\"sizes\"", "]", ")", "\n", "self", ".", "_linear_first_reshape", "=", "linear_first", "[", "\"reshape\"", "]", "\n", "\n", "", "self", ".", "_linear_first", "=", "linear_first", "\n", "\n", "self", ".", "_is_training", "=", "is_training", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout": [[65, 68], ["tensorflow.layers.dropout"], "methods", ["None"], ["", "def", "_dropout", "(", "self", ",", "net", ",", "training", ")", ":", "\n", "        ", "net", "=", "tf", ".", "layers", ".", "dropout", "(", "net", ",", "self", ".", "_prob_drop", ",", "training", "=", "training", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._decide_stride": [[69, 71], ["None"], "methods", ["None"], ["", "def", "_decide_stride", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "_stride", "if", "(", "index", "%", "2", "==", "0", ")", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._build": [[72, 166], ["ConvDec.ConvDec.layers.append", "enumerate", "enumerate", "sonnet.Conv2DTranspose", "sonnet.Conv2DTranspose", "sonnet.Conv2DTranspose", "layer", "ConvDec.ConvDec._dropout", "tensorflow.layers.batch_normalization", "ConvDec.ConvDec._activation", "sonnet.Linear", "layer", "ConvDec.ConvDec._dropout", "tensorflow.layers.batch_normalization", "ConvDec.ConvDec._activation", "sonnet.BatchReshape", "range", "ConvDec.ConvDec._activation", "range", "ConvDec.ConvDec._decide_stride", "ConvDec.ConvDec._decide_stride", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout", "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._dropout", "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._decide_stride", "home.repos.pwc.inspect_result.rist-ro_argo.network.ConvDec.ConvDec._decide_stride"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (type): node of input.\n            is_training (type): tells to batchnorm if to generate the update ops.\n\n        Returns:\n            logits\n\n        \"\"\"", "\n", "\n", "net", "=", "inputs", "\n", "\n", "#LINEAR BLOCK WITH RESHAPE IF NEEDED", "\n", "# if linear_first I add extra Linear layers", "\n", "if", "self", ".", "_linear_first", "is", "not", "None", ":", "\n", "            ", "self", ".", "linear_layers", "=", "[", "snt", ".", "Linear", "(", "\n", "name", "=", "\"linear_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_size", "=", "self", ".", "_linear_first_sizes", "[", "i", "]", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_linear_first_sizes", ")", ")", "]", "\n", "\n", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "linear_layers", ")", ":", "\n", "                ", "net", "=", "layer", "(", "net", ")", "\n", "net", "=", "self", ".", "_dropout", "(", "net", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_lin_{}\"", ".", "format", "(", "i", ")", ")", "\n", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "", "net", "=", "snt", ".", "BatchReshape", "(", "shape", "=", "self", ".", "_linear_first_reshape", ")", "(", "net", ")", "\n", "\n", "#CONV BLOCKS FROM HERE", "\n", "", "self", ".", "layers", "=", "[", "snt", ".", "Conv2DTranspose", "(", "\n", "name", "=", "\"conv_2d_T_{}\"", ".", "format", "(", "i", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "i", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shape", ",", "\n", "stride", "=", "self", ".", "_decide_stride", "(", "i", ")", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_layers", "-", "1", ")", "]", "\n", "\n", "li", "=", "self", ".", "_num_layers", "-", "1", "\n", "\n", "if", "self", ".", "_output_shape", "is", "None", ":", "\n", "            ", "lastlayer", "=", "snt", ".", "Conv2DTranspose", "(", "\n", "name", "=", "\"conv_2d_T_{}\"", ".", "format", "(", "li", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "li", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shape", ",", "\n", "stride", "=", "self", ".", "_decide_stride", "(", "li", ")", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "\n", "", "else", ":", "\n", "            ", "lastlayer", "=", "snt", ".", "Conv2DTranspose", "(", "\n", "name", "=", "\"conv_2d_T_{}\"", ".", "format", "(", "li", ")", ",", "\n", "output_channels", "=", "self", ".", "_hidden_channels", "[", "li", "]", ",", "\n", "kernel_shape", "=", "self", ".", "_kernel_shape", ",", "\n", "output_shape", "=", "self", ".", "_output_shape", ",", "\n", "use_bias", "=", "True", ",", "\n", "**", "self", ".", "_extra_params", "\n", ")", "\n", "\n", "", "self", ".", "layers", ".", "append", "(", "lastlayer", ")", "\n", "\n", "# connect them to the graph, adding batch norm and non-linearity", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "net", "=", "layer", "(", "net", ")", "\n", "net", "=", "self", ".", "_dropout", "(", "net", ",", "training", "=", "self", ".", "_is_training", ")", "\n", "net", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "net", ",", "training", "=", "self", ".", "_is_training", ",", "\n", "momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm", "=", "self", ".", "_bn_renormalization", ",", "\n", "renorm_momentum", "=", "self", ".", "_bn_momentum", ",", "\n", "renorm_clipping", "=", "self", ".", "_renorm_clipping", ",", "\n", "name", "=", "\"batch_norm_{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "# no activation at the end", "\n", "if", "i", "<", "li", ":", "\n", "                ", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "", "", "if", "self", ".", "_final_activation", ":", "\n", "            ", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "", "return", "net", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Conv2DWN.Conv2DWN.__init__": [[10, 48], ["kwargs[].pop", "kwargs[].pop", "sonnet.python.modules.conv.Conv2D.__init__", "os.path.dirname", "tensorflow.get_variable", "tensorflow.get_variable", "initializer_g", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "initializer_v", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "use_weight_norm", "=", "True", ",", "name", "=", "\"conv2d_wn\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            args and kwargs: all the additional keyword arguments will be passed to snt.Conv2D layers.\n        \"\"\"", "\n", "\n", "custom_getter", "=", "None", "\n", "\n", "if", "use_weight_norm", ":", "\n", "            ", "initializer_g", "=", "kwargs", "[", "'initializers'", "]", "[", "'g'", "]", "\n", "initializer_v", "=", "kwargs", "[", "'initializers'", "]", "[", "'v'", "]", "\n", "\n", "def", "custom_getter_w", "(", "getter", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "shape", "=", "kwargs", "[", "\"shape\"", "]", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "name", ")", "\n", "\n", "#v = getter(dirname+\"/v\", *args, **kwargs)", "\n", "# new way to create the variable, so that I can specify the initializer", "\n", "v", "=", "tf", ".", "get_variable", "(", "\"v\"", ",", "initializer", "=", "initializer_v", "(", "[", "shape", "]", ")", ")", "\n", "\n", "output_channels", "=", "shape", "[", "-", "1", "]", "\n", "initial_value_g", "=", "initializer_g", "(", "[", "output_channels", "]", ")", "*", "2", "\n", "ln_g", "=", "tf", ".", "get_variable", "(", "\"ln_g\"", ",", "initializer", "=", "initial_value_g", ")", "\n", "# use weight normalization (Salimans & Kingma, 2016)", "\n", "w", "=", "tf", ".", "reshape", "(", "tf", ".", "exp", "(", "ln_g", ")", ",", "[", "1", ",", "1", ",", "1", ",", "output_channels", "]", ")", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "v", ",", "[", "0", ",", "1", ",", "2", "]", ")", "\n", "return", "w", "\n", "\n", "", "custom_getter", "=", "{", "\"w\"", ":", "custom_getter_w", "}", "\n", "\n", "# remove keys from the dictionary, since sonnet check for this", "\n", "", "kwargs", "[", "'initializers'", "]", ".", "pop", "(", "'g'", ",", "None", ")", "\n", "kwargs", "[", "'initializers'", "]", ".", "pop", "(", "'v'", ",", "None", ")", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "custom_getter", "=", "custom_getter", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGaussian.AbstractGaussian.__init__": [[5, 25], ["AbstractStochasticLayer.AbstractStochasticLayer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'abstract_gaussian'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGaussian.AbstractGaussian._contractive_regularizer_filename": [[26, 29], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_contractive_regularizer_filename", "(", "self", ")", ":", "\n", "        ", "return", "\".GaussianRegularizers\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.BernoulliPlusMinusOne.BernoulliPlusMinusOne.__init__": [[21, 38], ["AbstractModule.AbstractModule.__init__", "operator.xor"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", "=", "-", "1", ",", "output_shape", "=", "-", "1", ",", "initializers", "=", "{", "}", ",", "regularizers", "=", "{", "}", ",", "clip_value", "=", "0", ",", "dtype", "=", "None", ",", "\n", "name", "=", "'Bernoulli'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "assert", "xor", "(", "output_size", "==", "-", "1", ",", "output_shape", "==", "-", "1", ")", ",", "\"Either output_size or output_shape mut be specified, not both\"", "\n", "\n", "if", "output_size", "!=", "-", "1", ":", "\n", "            ", "self", ".", "_output_shape", "=", "[", "output_size", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_output_shape", "=", "output_shape", "\n", "\n", "", "self", ".", "_initializers", "=", "initializers", "\n", "self", ".", "_regularizers", "=", "regularizers", "\n", "\n", "self", ".", "_clip_value", "=", "clip_value", "\n", "self", ".", "_dtype", "=", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.BernoulliPlusMinusOne.BernoulliPlusMinusOne._build": [[39, 73], ["tensorflow.reshape", "PlusMinusOneMapping.PlusMinusOneMapping.PlusMinusOneMapping", "tensorflow_probability.distributions.TransformedDistribution", "types.MethodType", "types.MethodType", "types.MethodType", "tensorflow.nn.sigmoid", "tensorflow.clip_by_value", "tensorflow_probability.distributions.Bernoulli", "tensorflow_probability.distributions.Bernoulli", "BernoulliPlusMinusOne.BernoulliPlusMinusOne.mean", "sonnet.Linear", "BernoulliPlusMinusOne.BernoulliPlusMinusOne.mean", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "# create the layers for mean and covariance", "\n", "        ", "output_shape", "=", "[", "-", "1", "]", "+", "self", ".", "_output_shape", "\n", "logits", "=", "tf", ".", "reshape", "(", "snt", ".", "Linear", "(", "np", ".", "prod", "(", "self", ".", "_output_shape", ")", ",", "initializers", "=", "self", ".", "_initializers", ",", "regularizers", "=", "self", ".", "_regularizers", ")", "(", "inputs", ")", ",", "output_shape", ")", "\n", "\n", "dtype", "=", "tf", ".", "float32", "#inputs.dtype", "\n", "if", "self", ".", "_dtype", "is", "not", "None", ":", "\n", "            ", "dtype", "=", "self", ".", "_dtype", "\n", "\n", "", "if", "self", ".", "_clip_value", ">", "0", ":", "\n", "            ", "probs", "=", "tf", ".", "nn", ".", "sigmoid", "(", "logits", ")", "\n", "\n", "probs", "=", "tf", ".", "clip_by_value", "(", "probs", ",", "self", ".", "_clip_value", ",", "1", "-", "self", ".", "_clip_value", ")", "\n", "bernoulli", "=", "tfp", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "probs", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "bernoulli", "=", "tfp", ".", "distributions", ".", "Bernoulli", "(", "logits", "=", "logits", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "affine_transform", "=", "PlusMinusOneMapping", "(", "scale", "=", "2.", ",", "shift", "=", "-", "1.", ")", "\n", "bernoulli_plus_minus_one", "=", "tfp", ".", "distributions", ".", "TransformedDistribution", "(", "distribution", "=", "bernoulli", ",", "bijector", "=", "affine_transform", ",", "name", "=", "\"BernoulliPlusMinusOne\"", ")", "\n", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "", "bernoulli_plus_minus_one", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "bernoulli_plus_minus_one", ")", "\n", "\n", "def", "distribution_parameters", "(", "self", ")", ":", "\n", "            ", "return", "[", "self", ".", "mean", "(", ")", "]", "\n", "", "bernoulli_plus_minus_one", ".", "distribution_parameters", "=", "types", ".", "MethodType", "(", "distribution_parameters", ",", "bernoulli_plus_minus_one", ")", "\n", "\n", "def", "get_probs", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "distribution", ".", "probs", "\n", "\n", "", "bernoulli_plus_minus_one", ".", "get_probs", "=", "types", ".", "MethodType", "(", "get_probs", ",", "bernoulli_plus_minus_one", ")", "\n", "\n", "return", "bernoulli_plus_minus_one", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogisticDiagonalZeroOne.LogisticDiagonalZeroOne.__init__": [[11, 35], ["AbstractLogistic.AbstractLogistic.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "zero_one_method", "=", "\"sigmoid\"", ",", "\n", "name", "=", "'logistic_diagonal_zero_one'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n", "self", ".", "zero_one_method", "=", "zero_one_method", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.LogisticDiagonalZeroOne.LogisticDiagonalZeroOne._build": [[36, 58], ["LogisticDiagonalZeroOne.LogisticDiagonalZeroOne.create_mean_n_cov_layers", "LogisticDiagonalZeroOne.LogisticDiagonalZeroOne.force_between_zero_and_one", "tensorflow_probability.distributions.Logistic", "types.MethodType", "LogisticDiagonalZeroOne.LogisticDiagonalZeroOne.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.force_between_zero_and_one", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "mean_zero_one", "=", "self", ".", "force_between_zero_and_one", "(", "mean", ",", "self", ".", "zero_one_method", ")", "\n", "\n", "# TODO if you want contractive regularizers implement them first. Then, uncomment the following lines (Riccardo)", "\n", "# self.set_contractive_regularizer(mean_zero_one, covariance,", "\n", "#                                 self._contractive_regularizer_inputs,", "\n", "#                                 self._contractive_regularizer_tuple,", "\n", "#                                 self._contractive_collection_network_str)", "\n", "#", "\n", "\n", "output_distribution", "=", "tfd", ".", "Logistic", "(", "loc", "=", "mean_zero_one", ",", "scale", "=", "scale", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Conv2DTransposeWN.Conv2DTransposeWN.__init__": [[8, 45], ["kwargs[].pop", "kwargs[].pop", "sonnet.python.modules.conv.Conv2DTranspose.__init__", "os.path.dirname", "tensorflow.get_variable", "tensorflow.get_variable", "initializer_g", "tensorflow.reshape", "tensorflow.nn.l2_normalize", "initializer_v", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "use_weight_norm", "=", "True", ",", "name", "=", "\"conv2d_transpose_wn\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            args and kwargs: all the additional keyword arguments will be passed to snt.Conv2D layers.\n        \"\"\"", "\n", "\n", "custom_getter", "=", "None", "\n", "\n", "if", "use_weight_norm", ":", "\n", "\n", "            ", "initializer_g", "=", "kwargs", "[", "'initializers'", "]", "[", "'g'", "]", "\n", "initializer_v", "=", "kwargs", "[", "'initializers'", "]", "[", "'v'", "]", "\n", "\n", "def", "custom_getter_w", "(", "getter", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "shape", "=", "kwargs", "[", "\"shape\"", "]", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "name", ")", "\n", "\n", "#v = getter(dirname+\"/v\", *args, **kwargs)", "\n", "# new way to create the variable, so that I can specify the initializer", "\n", "v", "=", "tf", ".", "get_variable", "(", "\"v\"", ",", "initializer", "=", "initializer_v", "(", "[", "shape", "]", ")", ")", "\n", "\n", "output_channels", "=", "shape", "[", "-", "1", "]", "\n", "initial_value_g", "=", "initializer_g", "(", "[", "output_channels", "]", ")", "*", "2", "\n", "ln_g", "=", "tf", ".", "get_variable", "(", "\"ln_g\"", ",", "initializer", "=", "initial_value_g", ")", "\n", "# use weight normalization (Salimans & Kingma, 2016)", "\n", "w", "=", "tf", ".", "reshape", "(", "tf", ".", "exp", "(", "ln_g", ")", ",", "[", "1", ",", "1", ",", "1", ",", "output_channels", "]", ")", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "v", ",", "[", "0", ",", "1", ",", "2", "]", ")", "\n", "return", "w", "\n", "\n", "", "custom_getter", "=", "{", "\"w\"", ":", "custom_getter_w", "}", "\n", "\n", "# remove keys from the dictionary, since sonnet check for this", "\n", "", "kwargs", "[", "'initializers'", "]", ".", "pop", "(", "'g'", ",", "None", ")", "\n", "kwargs", "[", "'initializers'", "]", ".", "pop", "(", "'v'", ",", "None", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "custom_getter", "=", "custom_getter", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GeneralSonnetNetwork.GeneralSonnetNetwork.__init__": [[12, 303], ["AbstractModule.AbstractModule.__init__", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "print", "KeyError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "activation", ",", "default_weights_init", ",", "\n", "default_bias_init", ",", "default_weights_reg", ",", "default_bias_reg", ",", "\n", "network_architecture", ",", "\n", "stochastic_defaults", "=", "None", ",", "\n", "network_str", "=", "\"\"", ",", "\n", "is_training", "=", "False", ",", "\n", "# seed=None,", "\n", "name", "=", "'AbstractSonnetNetwork'", ")", ":", "\n", "\n", "        ", "\"\"\"Short summary.\n        Args:\n            activation (type): Description of parameter `activation`.\n            default_weights_init (type): Description of parameter `default_weights_init`.\n            default_bias_init (type): Description of parameter `default_bias_init`.\n            default_weights_reg (type): Description of parameter `default_weights_reg`.\n            default_bias_reg (type): Description of parameter `default_bias_reg`.\n            network_architecture (list): a list of tuples (sntModule, kwargs, bool_activate).\n                i.e. [(Linear, {\"output_size\": 100}, 1), (Linear, {\"output_size\": 10}, 1),\n                        (\"GaussianDiagonal\", {\"size\" : 20, \"minimal_covariance\" : 0}, 0)]\n            stochastic_defaults (type): Description of parameter `stochastic_defaults`.\n            network_str (str): Optional network_str specifying the network we are going to build.\n                            It is used to set some specific collections for activity and contractive regularizers.\n            name (str): name of the Module.\n\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_network_architecture", "=", "network_architecture", "\n", "self", ".", "_network_str", "=", "network_str", "\n", "\n", "# self._is_training = is_training", "\n", "# self._seed = seed", "\n", "\n", "covariance_parameterization", "=", "None", "\n", "concentration_parameterization", "=", "None", "\n", "\n", "if", "stochastic_defaults", ":", "\n", "            ", "try", ":", "\n", "# what to do for multiple sampling layers, now I sample once!", "\n", "# self.n_z_samples = stochastic_defaults[\"samples\"]", "\n", "                ", "if", "\"covariance_parameterization\"", "in", "stochastic_defaults", ":", "\n", "                    ", "covariance_parameterization", "=", "stochastic_defaults", "[", "\"covariance_parameterization\"", "]", "\n", "", "elif", "\"concentration_parameterization\"", "in", "stochastic_defaults", ":", "\n", "                    ", "concentration_parameterization", "=", "stochastic_defaults", "[", "\"concentration_parameterization\"", "]", "\n", "", "", "except", "KeyError", "as", "e", ":", "\n", "                ", "print", "(", "\"need to pass all the stochastic_defaults, missing keys\"", ")", "\n", "raise", "KeyError", "(", "\"need to pass all the stochastic_defaults, missing keys\"", ")", "from", "e", "\n", "\n", "# SET DEFAULTS FOR NETWORK CREATION", "\n", "\n", "# activation function", "\n", "", "", "self", ".", "_activation", "=", "activation", "\n", "\n", "# SET DEFAULT PARAMETERS FOR SONNET MODULES", "\n", "# these are default parameters for the snt modules, \"potentially\" they could be overwritten", "\n", "# by the properties in the specific modules of \"network_archicture\"", "\n", "self", ".", "_default_modules_kwargs", "=", "{", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", "=", "{", "\n", "\"initializers\"", ":", "{", "}", ",", "\n", "\"regularizers\"", ":", "{", "}", "\n", "}", "\n", "# \"initializers\" : {'w':default_weights_init, 'b':default_bias_init},", "\n", "# \"regularizers\" : {'w':default_weights_reg, 'b':default_bias_reg}", "\n", "\n", "if", "default_weights_init", ":", "\n", "            ", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", "[", "\"initializers\"", "]", "[", "'w'", "]", "=", "default_weights_init", "\n", "", "if", "default_bias_init", ":", "\n", "            ", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", "[", "\"initializers\"", "]", "[", "'b'", "]", "=", "default_bias_init", "\n", "\n", "", "if", "default_weights_reg", ":", "\n", "            ", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", "[", "\"regularizers\"", "]", "[", "'w'", "]", "=", "default_weights_reg", "\n", "", "if", "default_bias_reg", ":", "\n", "            ", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", "[", "\"regularizers\"", "]", "[", "'b'", "]", "=", "default_bias_reg", "\n", "\n", "", "self", ".", "_default_modules_kwargs", "[", "'BatchFlatten'", "]", "=", "{", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'BatchReshape'", "]", "=", "{", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Sigmoid'", "]", "=", "{", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Tanh'", "]", "=", "{", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Linear'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Concatenate'", "]", "=", "{", "\n", "\"node_name\"", ":", "\"y1h\"", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Identity'", "]", "=", "{", "\n", "}", "\n", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Conv2D'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'Linear'", "]", ",", "\n", "\"kernel_shape\"", ":", "(", "3", ",", "3", ")", ",", "\n", "\"stride\"", ":", "(", "1", ",", "1", ")", ",", "\n", "\"padding\"", ":", "'SAME'", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Conv2DTranspose'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'Linear'", "]", ",", "\n", "\"kernel_shape\"", ":", "(", "3", ",", "3", ")", ",", "\n", "\"stride\"", ":", "(", "1", ",", "1", ")", ",", "\n", "\"padding\"", ":", "'SAME'", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'LinearWN'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'Linear'", "]", ",", "\n", "\"use_weight_norm\"", ":", "True", "\n", "}", "\n", "# setting default values for the initializers for WN", "\n", "self", ".", "_default_modules_kwargs", "[", "'LinearWN'", "]", "[", "\"initializers\"", "]", "=", "{", "\n", "'v'", ":", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.05", ")", ",", "\n", "'b'", ":", "default_bias_init", ",", "\n", "'g'", ":", "default_bias_init", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Conv2DWN'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'Conv2D'", "]", ",", "\n", "\"use_weight_norm\"", ":", "True", "}", "\n", "# setting default values for the initializers for WN", "\n", "self", ".", "_default_modules_kwargs", "[", "'Conv2DWN'", "]", "[", "\"initializers\"", "]", "=", "{", "\n", "'v'", ":", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.05", ")", ",", "\n", "'b'", ":", "default_bias_init", ",", "\n", "'g'", ":", "default_bias_init", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'custom'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", ",", "\n", "\"activation\"", ":", "self", ".", "_activation", ",", "\n", "\"is_training\"", ":", "is_training", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'ResUnit'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'custom'", "]", "}", "\n", "self", ".", "_default_modules_kwargs", "[", "'ResNet18'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'custom'", "]", "}", "\n", "self", ".", "_default_modules_kwargs", "[", "'VGGBlock'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'custom'", "]", "}", "\n", "self", ".", "_default_modules_kwargs", "[", "'ConvDec'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'custom'", "]", "}", "\n", "self", ".", "_default_modules_kwargs", "[", "'ResEnc'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'custom'", "]", "}", "\n", "self", ".", "_default_modules_kwargs", "[", "'ResDec'", "]", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "'custom'", "]", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'ConvNet2D'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'Linear'", "]", ",", "\n", "\"kernel_shapes\"", ":", "[", "(", "3", ",", "3", ")", "]", ",", "\n", "\"strides\"", ":", "[", "2", ",", "2", "]", ",", "\n", "\"paddings\"", ":", "'SAME'", ",", "\n", "\"activation\"", ":", "self", ".", "_activation", ",", "\n", "\"activate_final\"", ":", "False", ",", "\n", "\"normalize_final\"", ":", "False", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'ConvNet2DTranspose'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'ConvNet2D'", "]", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'MaxPooling2D'", "]", "=", "{", "\n", "\"pool_size\"", ":", "(", "2", ",", "2", ")", ",", "\n", "\"strides\"", ":", "2", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'RandomUniform'", "]", "=", "{", "\n", "\"shape\"", ":", "20", ",", "\n", "\"minval\"", ":", "-", "1", ",", "\n", "\"maxval\"", ":", "1", ",", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'RandomGaussian'", "]", "=", "{", "\n", "\"shape\"", ":", "20", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'AveragePooling2D'", "]", "=", "{", "\n", "\"pool_size\"", ":", "(", "2", ",", "2", ")", ",", "\n", "\"strides\"", ":", "2", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Dropout'", "]", "=", "{", "\n", "# \"seed\" : self._seed,", "\n", "# \"rate\" : 0.5,", "\n", "\"rate\"", ":", "0.5", ",", "# tf.layers.dropout", "\n", "# \"is_training\" : self._is_training", "\n", "\"dropout_flag\"", ":", "is_training", "\n", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'BatchNorm'", "]", "=", "{", "\n", "\"is_training\"", ":", "is_training", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonal'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", ",", "\n", "# TODO check the default value", "\n", "\"minimal_covariance\"", ":", "0.", ",", "\n", "\"covariance_parameterization\"", ":", "covariance_parameterization", ",", "\n", "# This wouls be desiderable, but at the moment it does not work", "\n", "# \"module_tuple\" : (\"Linear\", {})", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonalZeroOne'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonal'", "]", ",", "\n", "\"module_tuple\"", ":", "(", "\"Linear\"", ",", "{", "}", ")", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonalPlusMinusOne'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonal'", "]", ",", "\n", "\"module_tuple\"", ":", "(", "\"Linear\"", ",", "{", "}", ")", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Gaussian'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", ",", "\n", "# TODO check the default value", "\n", "\"minimal_covariance\"", ":", "0.", ",", "\n", "\"covariance_parameterization\"", ":", "covariance_parameterization", ",", "\n", "# This wouls be desiderable, but at the moment it does not work", "\n", "# \"module_tuple\" : (\"Linear\", {})", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'vonMisesFisher'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", ",", "\n", "# TODO check the default value", "\n", "# see https://github.com/tensorflow/probability/blob/v0.9.0/tensorflow_probability/python/distributions/von_mises_fisher.py", "\n", "\"minimal_concentration\"", ":", "1", ",", "\n", "\"concentration_parameterization\"", ":", "concentration_parameterization", ",", "\n", "# This wouls be desiderable, but at the moment it does not work", "\n", "# \"module_tuple\" : (\"Linear\", {})", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'LogisticDiagonalZeroOne'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonalZeroOne'", "]", ",", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'LogisticDiagonalPlusMinusOne'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonalPlusMinusOne'", "]", ",", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'LogitNormalDiagonal'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonalZeroOne'", "]", ",", "\n", "\"clip_value\"", ":", "0.0001", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'LogitNormalDiagonalPlusMinusOne'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'GaussianDiagonalPlusMinusOne'", "]", ",", "\n", "\"clip_value\"", ":", "0.0001", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'Bernoulli'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", ",", "\n", "\"clip_value\"", ":", "0.0001", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'BernoulliPlusMinusOne'", "]", "=", "{", "\n", "**", "self", ".", "_default_modules_kwargs", "[", "'common'", "]", ",", "\n", "\"clip_value\"", ":", "0.0001", "\n", "}", "\n", "\n", "self", ".", "_default_modules_kwargs", "[", "'CIFAR10TutorialNetwork'", "]", "=", "{", "\n", "}", "\n", "\n", "# these are default parameters for the layers, \"potentially\" they could be overwritten", "\n", "# by the properties in the specific layers of \"network_archicture\"", "\n", "self", ".", "_default_layers_kwargs", "=", "{", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'common'", "]", "=", "{", "\n", "\"kernel_initializer\"", ":", "default_weights_init", ",", "\n", "\"bias_initializer\"", ":", "default_bias_init", ",", "\n", "\"kernel_regularizer\"", ":", "default_weights_reg", ",", "\n", "\"bias_regularizer\"", ":", "default_bias_reg", ",", "\n", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'flatten'", "]", "=", "{", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'dense'", "]", "=", "{", "\n", "**", "self", ".", "_default_layers_kwargs", "[", "'common'", "]", ",", "\n", "\"activity_regularizer\"", ":", "None", ",", "\n", "\"kernel_constraint\"", ":", "None", ",", "\n", "\"bias_constraint\"", ":", "None", "\n", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'conv2d'", "]", "=", "{", "\n", "**", "self", ".", "_default_layers_kwargs", "[", "'dense'", "]", ",", "\n", "# filters,", "\n", "# kernel_size,", "\n", "\"strides\"", ":", "(", "1", ",", "1", ")", ",", "\n", "\"padding\"", ":", "'valid'", "\n", "# \"data_format\" : 'channels_last',", "\n", "# \"dilation_rate\" : (1, 1)", "\n", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'max_pooling2d'", "]", "=", "{", "\n", "\"pool_size\"", ":", "(", "2", ",", "2", ")", ",", "\n", "\"strides\"", ":", "2", "\n", "}", "\n", "\n", "self", ".", "_default_layers_kwargs", "[", "'batch_normalization'", "]", "=", "{", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GeneralSonnetNetwork.GeneralSonnetNetwork._build": [[305, 402], ["print", "enumerate", "tensorflow.identity", "isinstance", "GeneralSonnetNetwork.GeneralSonnetNetwork.add_reference_for_contractive_regularizers", "utils.argo_utils.load_sonnet_module.", "GeneralSonnetNetwork.GeneralSonnetNetwork._modules.append", "GeneralSonnetNetwork.GeneralSonnetNetwork._layers.append", "GeneralSonnetNetwork.GeneralSonnetNetwork.sample", "len", "len", "decorators.copy.copy.pop", "utils.argo_utils.load_sonnet_module", "decorator_modules.append", "len", "utils.argo_utils.load_sonnet_module", "utils.argo_utils.load_sonnet_module", "isinstance", "GeneralSonnetNetwork.GeneralSonnetNetwork._activation", "len", "decorators.copy.copy.copy", "Exception", "Exception", "len", "decorator_modules.pop", "Exception", "decorator_modules.pop.", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.network.GeneralSonnetNetwork.GeneralSonnetNetwork.add_reference_for_contractive_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "\"\"\"Constructs the graph\n\n        Args:\n          inputs: `tf.Tensor` input to which to attach the network\n          network_str: string used to separate collections of the network,\n                        i.e. used for activity and contractive regularizers\n\n        Returns:\n          if stochastic_architecture==None:\n              `tf.Tensor` output with the decision of the discriminator\n          else:\n              tf.distribution\n        \"\"\"", "\n", "\n", "print", "(", "\"Parsing \"", "+", "self", ".", "module_name", "+", "\" network...\"", ")", "\n", "\n", "net", "=", "inputs", "\n", "\n", "self", ".", "_modules", "=", "[", "]", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "\n", "for", "i", ",", "module_tuple", "in", "enumerate", "(", "self", ".", "_network_architecture", ")", ":", "\n", "\n", "            ", "if", "isinstance", "(", "net", ",", "tfd", ".", "Distribution", ")", ":", "\n", "# net = net.sample(self.n_z_samples)", "\n", "                ", "net", "=", "net", ".", "sample", "(", ")", "\n", "\n", "", "if", "len", "(", "module_tuple", ")", "==", "3", ":", "\n", "                ", "module_name", ",", "module_kwargs", ",", "bool_activation", "=", "module_tuple", "\n", "# no decorators", "\n", "decorators", "=", "[", "]", "\n", "", "elif", "len", "(", "module_tuple", ")", "==", "4", ":", "\n", "                ", "module_name", ",", "module_kwargs", ",", "bool_activation", ",", "decorators", "=", "module_tuple", "\n", "# make a copy, so that I can pop safetely", "\n", "decorators", "=", "decorators", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"The length of the module_tuple should be 3 or 4: \"", "+", "str", "(", "module_tuple", ")", ")", "\n", "\n", "", "if", "module_name", "in", "self", ".", "_default_modules_kwargs", ":", "\n", "                ", "kwargs", "=", "{", "**", "self", ".", "_default_modules_kwargs", "[", "module_name", "]", ",", "\n", "**", "module_kwargs", "\n", "}", "\n", "\n", "", "elif", "module_name", "in", "self", ".", "_default_layers_kwargs", ":", "\n", "                ", "kwargs", "=", "{", "**", "self", ".", "_default_layers_kwargs", "[", "module_name", "]", ",", "\n", "**", "module_kwargs", "\n", "}", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "module_name", "+", "\" is neither a sonnet module nor a tf layer. Hint: check if you have set the self._default_modules_kwargs or self._default_layers_kwargs\"", ")", "\n", "\n", "# add reference for the contractive regularizers if needed,", "\n", "# this works for both StochaticLayers and also or regular layers + a ConstractiveRegularizer decorator", "\n", "", "self", ".", "add_reference_for_contractive_regularizers", "(", "kwargs", ",", "inputs", ")", "\n", "\n", "# load decorators", "\n", "decorator_modules", "=", "[", "]", "\n", "while", "len", "(", "decorators", ")", ">", "0", ":", "\n", "                ", "decorator_name", "=", "decorators", ".", "pop", "(", "0", ")", "\n", "decorator", "=", "load_sonnet_module", "(", "decorator_name", ",", "kwargs", ")", "# (sntmodule)", "\n", "decorator_modules", ".", "append", "(", "decorator", ")", "\n", "# linear = decorator(args)(snt.Linear)(flat)", "\n", "\n", "", "if", "len", "(", "decorator_modules", ")", ">", "0", ":", "\n", "# only load class of the moduke without instantiation", "\n", "                ", "sntmodule", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ",", "instantiate", "=", "False", ")", "\n", "while", "len", "(", "decorator_modules", ")", ">", "0", ":", "\n", "                    ", "decorator", "=", "decorator_modules", ".", "pop", "(", "-", "1", ")", "\n", "sntmodule", "=", "decorator", "(", "sntmodule", ")", "(", "kwargs", ")", "\n", "# decorator(snt.Linear)(kwargs)(net)", "\n", "", "", "else", ":", "\n", "# no decorators, load the module", "\n", "                ", "sntmodule", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "\n", "# give the name feature to the last layer (after activation)", "\n", "", "last_node_before_logits", "=", "net", "\n", "net", "=", "sntmodule", "(", "net", ")", "\n", "\n", "self", ".", "_modules", ".", "append", "(", "sntmodule", ")", "\n", "\n", "# at this point net is expected to be either a tensor (logits) or a tf.Distribution", "\n", "self", ".", "_layers", ".", "append", "(", "net", ")", "\n", "\n", "if", "bool_activation", ":", "\n", "                ", "if", "isinstance", "(", "net", ",", "tfd", ".", "Distribution", ")", ":", "\n", "                    ", "raise", "Exception", "(", "\"cannot apply activation to a tf.Distribution, check network architecture!\"", ")", "\n", "\n", "", "net", "=", "self", ".", "_activation", "(", "net", ")", "\n", "\n", "# name the last layer before logits (or distribution)", "\n", "", "", "last_node_before_logits", "=", "tf", ".", "identity", "(", "last_node_before_logits", ",", "name", "=", "\"features\"", ")", "\n", "\n", "# this will be either a tensor or a distribution", "\n", "output", "=", "net", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.GeneralSonnetNetwork.GeneralSonnetNetwork.add_reference_for_contractive_regularizers": [[403, 407], ["None"], "methods", ["None"], ["", "def", "add_reference_for_contractive_regularizers", "(", "self", ",", "kwargs", ",", "reference_node", ")", ":", "\n", "        ", "if", "\"contractive_regularizer\"", "in", "kwargs", "and", "kwargs", "[", "\"contractive_regularizer\"", "]", "is", "not", "None", ":", "\n", "            ", "reg_name", ",", "reg_kwargs", "=", "kwargs", "[", "\"contractive_regularizer\"", "]", "\n", "kwargs", "[", "\"contractive_regularizer\"", "]", "=", "(", "reg_name", ",", "reg_kwargs", ",", "reference_node", ",", "self", ".", "_network_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.__init__": [[17, 40], ["AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0.", ",", "\n", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'gaussian'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian._build": [[41, 59], ["tensorflow.layers.flatten", "sonnet.Linear", "sonnet.Linear", "sonnet.Linear.", "pdb.set_trace", "sonnet.Linear", "sonnet.Linear", "sonnet.Linear.", "tensorflow_probability.distributions.MultivariateNormalFullCovariance"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "# TODO this could be adapter to be compatible with non linear layers", "\n", "#mean, covariance, scale = self.create_mean_n_cov_layers(inputs)", "\n", "        ", "inputs", "=", "tf", ".", "layers", ".", "flatten", "(", "inputs", ")", "\n", "\n", "linear_mean", "=", "snt", ".", "Linear", "(", "output_size", "=", "output_size", ")", "\n", "mean", "=", "linear_mean", "(", "inputs", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "linear_cov", "=", "snt", ".", "Linear", "(", "output_size", "=", "[", "output_size", ",", "output_size", "]", ")", "\n", "cov", "=", "linear_mean", "(", "inputs", ")", "\n", "\n", "# TODO this neds to be adapter to the new covariance", "\n", "#self.set_contractive_regularizer(mean, covariance,", "\n", "#                                self._contractive_regularizer_inputs,", "\n", "#                                self._contractive_regularizer_tuple,", "\n", "#                                self._contractive_collection_network_str)", "\n", "\n", "output_distribution", "=", "tfd", ".", "MultivariateNormalFullCovariance", "(", "loc", "=", "mean", ",", "covariance_matrix", "=", "cov", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node": [[61, 66], ["Gaussian.Gaussian.mean", "types.MethodType"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork.create_id": [[49, 83], ["super().create_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "str", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "utils.argo_utils.get_method_id", "str", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.get_method_id"], ["def", "create_id", "(", "self", ")", ":", "\n", "        ", "opts", "=", "self", ".", "_opts", "\n", "_id", "=", "\"\"", "\n", "if", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "is", "not", "None", ":", "\n", "            ", "_id", "+=", "\"_LI\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"posterior\"", "]", "[", "\"kernel_loc_initializer\"", "]", ")", "\n", "_id", "+=", "\"_\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"posterior\"", "]", "[", "\"bias_loc_initializer\"", "]", ")", "\n", "_id", "+=", "\"_klr\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"posterior\"", "]", "[", "\"kernel_loc_regularizer\"", "]", ")", "\n", "_id", "+=", "\"_ksr\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"posterior\"", "]", "[", "\"kernel_untr_scale_regularizer\"", "]", ")", "\n", "_id", "+=", "\"_blr\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"posterior\"", "]", "[", "\"bias_loc_regularizer\"", "]", ")", "\n", "_id", "+=", "\"_SCM\"", "+", "str", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"posterior\"", "]", "[", "\"kernel_untr_scale_constraint_max\"", "]", ")", "\n", "\n", "if", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"prior\"", "]", "[", "\"default\"", "]", ":", "\n", "                ", "_id", "+=", "\"_Pdef\"", "\n", "", "else", ":", "\n", "                ", "_id", "+=", "\"_PS\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"prior\"", "]", "[", "\"kernel_untr_scale_initializer\"", "]", ")", "\n", "_id", "+=", "\"_tr\"", "+", "str", "(", "int", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", "[", "\"prior\"", "]", "[", "\"trainable\"", "]", ")", ")", "\n", "\n", "", "", "if", "opts", "[", "\"init_reg_kwargs\"", "]", "is", "not", "None", ":", "\n", "            ", "_id", "+=", "\"_ki\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs\"", "]", "[", "\"kernel_initializer\"", "]", ")", "\n", "_id", "+=", "\"_bi\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs\"", "]", "[", "\"bias_initializer\"", "]", ")", "\n", "_id", "+=", "\"_kr\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs\"", "]", "[", "\"kernel_regularizer\"", "]", ")", "\n", "_id", "+=", "\"_br\"", "+", "get_method_id", "(", "opts", "[", "\"init_reg_kwargs\"", "]", "[", "\"bias_regularizer\"", "]", ")", "\n", "\n", "# if opts[\"init_reg_kwargs\"] is not None:", "\n", "#     _id += \"-ki\" + get_method_id(opts[\"init_reg_kwargs\"][\"kernel_initializer\"])", "\n", "#     _id += \"-bi\" + get_method_id(opts[\"init_reg_kwargs\"][\"bias_initializer\"])", "\n", "#     _id += \"-kr\" + get_method_id(opts[\"init_reg_kwargs\"][\"kernel_regularizer\"])", "\n", "#     _id += \"-br\" + get_method_id(opts[\"init_reg_kwargs\"][\"bias_regularizer\"])", "\n", "\n", "", "super_id", "=", "super", "(", ")", ".", "create_id", "(", ")", "\n", "\n", "_id", "+=", "super_id", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork.__init__": [[84, 88], ["ArgoAbstractKerasNetwork.ArgoAbstractKerasNetwork.__init__", "keras_models.keras_utils.parse_init_reg_kwargs", "keras_models.keras_utils.parse_init_reg_kwargs_bayes"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.parse_init_reg_kwargs", "home.repos.pwc.inspect_result.rist-ro_argo.keras_models.keras_utils.parse_init_reg_kwargs_bayes"], ["", "def", "__init__", "(", "self", ",", "opts", ",", "name", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "opts", ",", "name", ")", "\n", "self", ".", "_layer_kwargs", "=", "parse_init_reg_kwargs", "(", "opts", "[", "\"init_reg_kwargs\"", "]", ")", "\n", "self", ".", "_layer_kwargs_bayes", "=", "parse_init_reg_kwargs_bayes", "(", "opts", "[", "\"init_reg_kwargs_bayes\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork.get_keras_losses": [[91, 125], ["KerasNetwork.KerasNetwork._get_rkua_lists", "KerasNetwork.KerasNetwork._get_rkua_lists", "pprint.pprint.pprint", "print", "print", "print", "pprint.pprint.pprint", "print", "print", "pprint.pprint.pprint", "print", "print", "pprint.pprint.pprint", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork._get_rkua_lists", "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork._get_rkua_lists"], ["", "def", "get_keras_losses", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "net_reg_losses", ",", "net_kl_losses", ",", "net_update_ops", ",", "net_all_layers", "=", "self", ".", "_get_rkua_lists", "(", "self", ".", "_net_model", ",", "inputs", ")", "\n", "distr_reg_losses", ",", "distr_kl_losses", ",", "distr_update_ops", ",", "distr_all_layers", "=", "self", ".", "_get_rkua_lists", "(", "self", ".", "_distr_model", ",", "inputs", ")", "\n", "\n", "all_layers", "=", "distr_all_layers", "+", "net_all_layers", "\n", "reg_losses", "=", "distr_reg_losses", "+", "net_reg_losses", "\n", "kl_losses", "=", "distr_kl_losses", "+", "net_kl_losses", "\n", "update_ops", "=", "distr_update_ops", "+", "net_update_ops", "\n", "\n", "# reg_losses, kl_losses, update_ops, all_layers = self._get_rkua_lists(self._model, inputs)", "\n", "\n", "# pprint(all_layers)", "\n", "pprint", "(", "[", "l", ".", "name", "for", "l", "in", "all_layers", "]", ")", "\n", "print", "(", "\"\"", ")", "\n", "# batch_norm_num = len([l for l in all_layers if \"batch_norm\" in l.name.lower()])", "\n", "# flipout_num = len([l for l in all_layers if \"flipout\" in l.name.lower()])", "\n", "# reparameterization_num = len([l for l in all_layers if \"reparameterization\" in l.name.lower()])", "\n", "# print(\"found {} BatchNorm layers\".format(batch_norm_num))", "\n", "# print(\"found {} Flipout layers\".format(flipout_num))", "\n", "# print(\"found {} Reparameterization layers\".format(reparameterization_num))", "\n", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "\"found {} keras regularizers\"", ".", "format", "(", "len", "(", "reg_losses", ")", ")", ")", "\n", "pprint", "(", "reg_losses", ")", "\n", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "\"found {} keras kl losses\"", ".", "format", "(", "len", "(", "kl_losses", ")", ")", ")", "\n", "pprint", "(", "kl_losses", ")", "\n", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "\"found {} keras update ops\"", ".", "format", "(", "len", "(", "update_ops", ")", ")", ")", "\n", "pprint", "(", "update_ops", ")", "\n", "\n", "return", "reg_losses", ",", "kl_losses", ",", "update_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork._get_rkua_lists": [[127, 143], ["print", "model.summary", "print", "print", "model.get_losses_for", "model.get_losses_for", "model.get_updates_for", "model.get_updates_for", "len", "l.name.lower", "l.name.lower"], "methods", ["None"], ["", "def", "_get_rkua_lists", "(", "self", ",", "model", ",", "inputs", ")", ":", "\n", "        ", "if", "model", "is", "None", ":", "\n", "            ", "return", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "", "losses", "=", "model", ".", "get_losses_for", "(", "None", ")", "+", "model", ".", "get_losses_for", "(", "inputs", ")", "\n", "reg_losses", "=", "[", "l", "for", "l", "in", "losses", "if", "\"regularizer\"", "in", "l", ".", "name", ".", "lower", "(", ")", "]", "\n", "kl_losses", "=", "[", "l", "for", "l", "in", "losses", "if", "\"divergence\"", "in", "l", ".", "name", ".", "lower", "(", ")", "]", "\n", "update_ops", "=", "model", ".", "get_updates_for", "(", "None", ")", "+", "model", ".", "get_updates_for", "(", "inputs", ")", "\n", "print", "(", "\"\"", ")", "\n", "model", ".", "summary", "(", ")", "\n", "print", "(", "\"\"", ")", "\n", "\n", "print", "(", "\"found {:} layers for model {:}\\n\"", ".", "format", "(", "len", "(", "model", ".", "layers", ")", ",", "model", ".", "name", ")", ")", "\n", "all_layers", "=", "model", ".", "layers", "\n", "\n", "return", "reg_losses", ",", "kl_losses", ",", "update_ops", ",", "all_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.KerasNetwork.KerasNetwork._keras_model_builder": [[161, 171], ["importlib.import_module", "getattr", "getattr.", "__name__.split"], "methods", ["None"], ["", "def", "_keras_model_builder", "(", "self", ",", "keras_model_name", ",", "keras_model_kwargs", ")", ":", "\n", "# load the keras model specified", "\n", "        ", "keras_pymodule", "=", "importlib", ".", "import_module", "(", "\"..keras_models.\"", "+", "keras_model_name", ",", "\n", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "make_model", "=", "getattr", "(", "keras_pymodule", ",", "keras_model_name", ")", "\n", "\n", "model", "=", "make_model", "(", "**", "keras_model_kwargs", ")", "\n", "\n", "return", "model", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AveragePooling2D.AveragePooling2D.__init__": [[11, 18], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "pool_size", ",", "strides", ",", "padding", "=", "\"valid\"", ",", "name", "=", "\"AveragePooling2D\"", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_pool_size", "=", "pool_size", "\n", "self", ".", "_strides", "=", "strides", "\n", "self", ".", "_padding", "=", "padding", "\n", "self", ".", "_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.AveragePooling2D.AveragePooling2D._build": [[19, 25], ["tensorflow.layers.average_pooling2d"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "average_pooling2d", "(", "input", ",", "\n", "pool_size", "=", "self", ".", "_pool_size", ",", "\n", "strides", "=", "self", ".", "_strides", ",", "\n", "padding", "=", "self", ".", "_padding", ",", "\n", "name", "=", "self", ".", "_name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Concatenate.Concatenate.__init__": [[9, 15], ["AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_name", ",", "channel_wise", "=", "False", ",", "name", "=", "'Concatenate'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "self", ".", "_node_name", "=", "node_name", "\n", "self", ".", "_channel_wise", "=", "channel_wise", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.network.Concatenate.Concatenate._build": [[16, 31], ["tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.concat", "tensorflow.reshape", "tensorflow.tile", "tensorflow.get_default_graph", "inputs.get_shape", "tensorflow.keras.layers.Dense", "len", "tensorflow.shape", "tensorflow.shape", "tensorflow.get_default_graph().get_tensor_by_name.get_shape"], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "node", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "self", ".", "_node_name", "+", "\":0\"", ")", "\n", "\n", "if", "self", ".", "_channel_wise", ":", "\n", "            ", "img_size", "=", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "node_image_like", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "img_size", "*", "img_size", ")", "(", "node", ")", "\n", "node_to_be_concatenated", "=", "tf", ".", "reshape", "(", "node_image_like", ",", "[", "-", "1", ",", "img_size", ",", "img_size", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "n_replicate", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "/", "tf", ".", "shape", "(", "node", ")", "[", "0", "]", "\n", "shape_tile", "=", "[", "1", "]", "*", "len", "(", "node", ".", "get_shape", "(", ")", ")", "\n", "shape_tile", "[", "0", "]", "=", "n_replicate", "\n", "node_to_be_concatenated", "=", "tf", ".", "tile", "(", "node", ",", "shape_tile", ")", "\n", "\n", "", "return", "tf", ".", "concat", "(", "[", "inputs", ",", "node_to_be_concatenated", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.initializers.PlusMinusOneConstantInitializer.PlusMinusOneConstantInitializer.__init__": [[13, 20], ["tensorflow.python.ops.init_ops._assert_float_dtype", "tensorflow.python.framework.dtypes.as_dtype"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "w", ",", "b", ",", "\n", "dtype", "=", "dtypes", ".", "float32", ")", ":", "\n", "\n", "        ", "self", ".", "w", "=", "w", "\n", "self", ".", "b", "=", "b", "\n", "self", ".", "dtype", "=", "_assert_float_dtype", "(", "dtypes", ".", "as_dtype", "(", "dtype", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.initializers.PlusMinusOneConstantInitializer.PlusMinusOneConstantInitializer.__call__": [[21, 30], ["tensorflow.python.ops.init_ops._compute_fans", "tensorflow.ones"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "if", "dtype", "is", "None", ":", "\n", "            ", "dtype", "=", "self", ".", "dtype", "\n", "\n", "", "scale_shape", "=", "shape", "\n", "if", "partition_info", "is", "not", "None", ":", "\n", "            ", "scale_shape", "=", "partition_info", ".", "full_shape", "\n", "", "fan_in", ",", "fan_out", "=", "_compute_fans", "(", "scale_shape", ")", "\n", "return", "-", "tf", ".", "ones", "(", "shape", ",", "dtype", "=", "dtype", ")", "*", "fan_in", "*", "self", ".", "w", "/", "2.0", "+", "self", ".", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.initializers.PlusMinusOneConstantInitializer.PlusMinusOneConstantInitializer.get_config": [[31, 36], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"w\"", ":", "self", ".", "w", ",", "\n", "\"b\"", ":", "self", ".", "b", ",", "\n", "\"dtype\"", ":", "self", ".", "dtype", ".", "name", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.initializers.TFInitializers.TFInitializers.instantiate_initializer": [[23, 56], ["initializer_kwargs.copy.copy.copy", "utils.argo_utils.eval_method_from_tuple", "importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "Exception", "__name__.split", "__name__.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["    ", "@", "staticmethod", "\n", "def", "instantiate_initializer", "(", "initializer_tuple", ")", ":", "\n", "\n", "        ", "initializer_name", "=", "initializer_tuple", "[", "0", "]", "\n", "initializer_kwargs", "=", "initializer_tuple", "[", "1", "]", "\n", "\n", "# I want to copy because I want to modify it and I don't want to accidentally modify all the references around", "\n", "# in python references to a particular entry of a dictionary can be passed around and I might overwrite different task_opts", "\n", "initializer_kwargs", "=", "initializer_kwargs", ".", "copy", "(", ")", "\n", "\n", "try", ":", "\n", "# try to get the module from tf.train", "\n", "            ", "initializer", "=", "eval_method_from_tuple", "(", "tf", ",", "(", "initializer_name", ",", "initializer_kwargs", ")", ")", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "\n", "            ", "try", ":", "\n", "# first try to load from argo.core.initializers", "\n", "                ", "initializer_module", "=", "importlib", ".", "import_module", "(", "\".\"", "+", "initializer_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "initializer", "=", "eval_method_from_tuple", "(", "initializer_module", ",", "(", "initializer_name", ",", "initializer_kwargs", ")", ")", "\n", "\n", "", "except", "ImportError", ":", "\n", "# second try to load from core.initializers", "\n", "                ", "initializer_module", "=", "importlib", ".", "import_module", "(", "\"core.network.initializers.\"", "+", "initializer_name", ",", "\n", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "initializer", "=", "eval_method_from_tuple", "(", "initializer_module", ",", "(", "initializer_name", ",", "initializer_kwargs", ")", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "Exception", "(", "\"problem loading initializer: %s, kwargs: %s, exception: %s\"", "%", "(", "\n", "initializer_name", ",", "initializer_kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "", "return", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.initializers.TFInitializers.TFInitializers.create_id": [[57, 98], ["initializer_name.split", "Exception", "str", "str", "Exception", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "initializer_tuple", ")", ":", "\n", "        ", "initializer_name", ",", "initializer_kwargs", "=", "initializer_tuple", "\n", "\n", "initializer_name", "=", "initializer_name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "\n", "_id", "=", "''", "\n", "\n", "if", "initializer_name", "==", "'PlusMinusOneConstantInitializer'", ":", "\n", "            ", "_id", "+=", "'PMOCI'", "\n", "_id", "+=", "'_w{}'", ".", "format", "(", "initializer_kwargs", "[", "\"w\"", "]", ")", "\n", "_id", "+=", "'_b{}'", ".", "format", "(", "initializer_kwargs", "[", "\"b\"", "]", ")", "\n", "\n", "\n", "", "elif", "initializer_name", "in", "method_name_short", ":", "\n", "\n", "            ", "_id", "+=", "method_name_short", "[", "initializer_name", "]", "\n", "\n", "if", "\"xavier_initializer\"", "in", "initializer_name", ":", "\n", "                ", "pass", "\n", "\n", "", "elif", "\"variance_scaling_initializer\"", "in", "initializer_name", "or", "\"VarianceScaling\"", "in", "initializer_name", ":", "\n", "                ", "_id", "+=", "\"S\"", "+", "str", "(", "initializer_kwargs", "[", "'scale'", "]", ")", "+", "\"M\"", "+", "initializer_kwargs", "[", "'mode'", "]", "[", "-", "3", ":", "]", "+", "\"D\"", "+", "initializer_kwargs", "[", "'distribution'", "]", "[", ":", "3", "]", "\n", "\n", "", "elif", "\"glorot_normal_initializer\"", "in", "initializer_name", "or", "\"glorot_uniform_initializer\"", "in", "initializer_name", ":", "\n", "                ", "pass", "\n", "\n", "", "elif", "\"truncated_normal_initializer\"", "in", "initializer_name", "or", "\"random_normal\"", "in", "initializer_name", ":", "\n", "                ", "_id", "+=", "str", "(", "initializer_kwargs", "[", "'stddev'", "]", ")", "\n", "\n", "", "elif", "\"constant_initializer\"", "in", "initializer_name", "or", "\"constant\"", "in", "initializer_name", ":", "\n", "                ", "_id", "+=", "str", "(", "initializer_kwargs", "[", "'value'", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\n", "\"No such initializer defined in tf or argo.core or your module! {}\"", ".", "format", "(", "initializer_name", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"No such initializer defined in tf or argo.core or your module! {}\"", ".", "format", "(", "initializer_name", ")", ")", "\n", "\n", "", "return", "_id", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.flows.build_flow.init_once": [[9, 12], ["tensorflow.variable_scope", "tensorflow.get_variable"], "function", ["None"], ["def", "init_once", "(", "x", ",", "name", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'build_flow'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "return", "tf", ".", "get_variable", "(", "name", ",", "initializer", "=", "x", ",", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.flows.build_flow.build_flow": [[14, 57], ["int", "flow_params.get", "range", "tfb.Chain", "bijectors.append", "list", "tfb.RealNVP", "tfb.Permute", "bijectors.append", "reversed", "tfb.MaskedAutoregressiveFlow", "int", "tfb.real_nvp_default_template", "tfb.Invert", "Exception", "build_flow.init_once", "tfb.masked_autoregressive_default_template", "tfb.MaskedAutoregressiveFlow", "numpy.random.permutation().astype", "tfb.masked_autoregressive_default_template", "numpy.random.permutation"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.flows.build_flow.init_once"], ["", "", "def", "build_flow", "(", "flow_params", ",", "flow_size", ")", ":", "#, module_path = \"\"):", "\n", "    ", "flow_size", "=", "int", "(", "flow_size", ")", "# in case it is a tf Dimension", "\n", "flow_name", "=", "flow_params", "[", "'name'", "]", "\n", "num_bijectors", "=", "flow_params", "[", "'num_bijectors'", "]", "\n", "hc", "=", "flow_params", "[", "'hidden_channels'", "]", "\n", "permute", "=", "flow_params", ".", "get", "(", "'permute'", ",", "True", ")", "\n", "# output_size = flow_params['output_size']", "\n", "\n", "bijectors", "=", "[", "]", "\n", "flow_vars", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_bijectors", ")", ":", "\n", "        ", "bij", "=", "None", "\n", "if", "flow_name", "==", "'NVP'", ":", "\n", "#         bijectors.append(NVPCoupling(D=2, d=1, layer_id=i))", "\n", "            ", "bij", "=", "tfb", ".", "RealNVP", "(", "\n", "num_masked", "=", "int", "(", "0.5", "*", "flow_size", ")", ",", "\n", "shift_and_log_scale_fn", "=", "tfb", ".", "real_nvp_default_template", "(", "hidden_layers", "=", "[", "hc", ",", "hc", "]", ")", ")", "\n", "", "elif", "flow_name", "==", "'MAF'", ":", "\n", "# shift_and_log_scale = tfb.masked_autoregressive_default_template(hidden_layers=[hc, hc])", "\n", "            ", "bij", "=", "tfb", ".", "MaskedAutoregressiveFlow", "(", "\n", "shift_and_log_scale_fn", "=", "tfb", ".", "masked_autoregressive_default_template", "(", "hidden_layers", "=", "[", "hc", ",", "hc", "]", ")", ",", "name", "=", "'maf_bijector-{}'", ".", "format", "(", "i", ")", ")", "\n", "", "elif", "flow_name", "==", "'IAF'", ":", "\n", "            ", "bij", "=", "tfb", ".", "Invert", "(", "tfb", ".", "MaskedAutoregressiveFlow", "(", "\n", "shift_and_log_scale_fn", "=", "tfb", ".", "masked_autoregressive_default_template", "(", "\n", "hidden_layers", "=", "[", "hc", ",", "hc", "]", ")", ",", "name", "=", "'iaf_bijector-{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"flow_name: `{:}` not recognized\"", ".", "format", "(", "flow_name", ")", ")", "\n", "\n", "", "bijectors", ".", "append", "(", "bij", ")", "\n", "\n", "if", "permute", ":", "\n", "            ", "perm", "=", "tfb", ".", "Permute", "(", "permutation", "=", "init_once", "(", "np", ".", "random", ".", "permutation", "(", "flow_size", ")", ".", "astype", "(", "'int32'", ")", ",", "\n", "name", "=", "'flow_permutation_{}'", ".", "format", "(", "i", ")", ")", ")", "\n", "bijectors", ".", "append", "(", "perm", ")", "\n", "\n", "# Discard the last Permute layer.", "\n", "", "", "if", "permute", ":", "\n", "        ", "bijectors", "=", "bijectors", "[", ":", "-", "1", "]", "\n", "\n", "", "flow_bijector", "=", "tfb", ".", "Chain", "(", "list", "(", "reversed", "(", "bijectors", ")", ")", ")", "\n", "\n", "return", "flow_bijector", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Nonconst.SSA1Nonconst.__init__": [[37, 51], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "k", "=", "2.0", ",", "alpha", "=", "4.0", ",", "use_locking", "=", "False", ",", "name", "=", "'SSA1Nonconst'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "SSA1Nonconst", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "self", ".", "_k", "=", "k", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_alpha_t", "=", "None", "\n", "self", ".", "_k_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Nonconst.SSA1Nonconst._prepare": [[55, 59], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_alpha_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_alpha", ",", "name", "=", "'alpha'", ")", "\n", "self", ".", "_k_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_k", ",", "name", "=", "'k'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Nonconst.SSA1Nonconst._create_slots": [[64, 70], ["SSA1Nonconst.SSA1Nonconst._zeros_slot", "SSA1Nonconst.SSA1Nonconst._zeros_slot", "SSA1Nonconst.SSA1Nonconst._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is the accumulator obtained from the discrete-type velocity. It is denoted by 'p^{k+1}'", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"old_accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"curr_it\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Nonconst.SSA1Nonconst._apply_dense": [[88, 123], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "SSA1Nonconst.SSA1Nonconst.get_slot", "SSA1Nonconst.SSA1Nonconst.get_slot", "SSA1Nonconst.SSA1Nonconst.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign_add"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "alpha_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_alpha_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "k_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_k_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifiers 'old_accum' and 'accum' from '_create_slots()'", "\n", "old_accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"old_accum\"", ")", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "# 3rd step: define the current iteration needed for the momentum inertial sequence", "\n", "# It must be converted to the same type as the trainable variables", "\n", "# We have here the inertial sequences 'alpha_n' and 'beta_n'", "\n", "curr_it", "=", "self", ".", "get_slot", "(", "var", ",", "\"curr_it\"", ")", "\n", "n", "=", "curr_it", "+", "1", "\n", "mom", "=", "n", "/", "(", "n", "+", "alpha_t", ")", "\n", "new_mom", "=", "(", "n", "+", "1.0", ")", "/", "(", "n", "+", "alpha_t", "+", "1.0", ")", "\n", "\n", "# 4th step: we have the SSA1 constant momentum formula 'accum_t <- accum_t * beta_{n+1} * beta_n^{k-1} * (1-lr*beta_n)*(2*beta_n^2-2*beta_n+1) - lr^2 * beta_{n+1} * beta_n^k * grad', i.e. 'p^{k+1}' from Defazio", "\n", "old_accum_t", "=", "state_ops", ".", "assign", "(", "old_accum", ",", "accum", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum_t", "]", ")", ":", "\n", "            ", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "new_mom", "*", "(", "mom", "**", "(", "k_t", "-", "1", ")", ")", "*", "(", "1", "-", "lr_t", "*", "mom", ")", "*", "(", "\n", "2", "*", "(", "mom", "**", "2", ")", "-", "2", "*", "mom", "+", "1", ")", "*", "accum", "-", "(", "lr_t", "**", "2", ")", "*", "new_mom", "*", "(", "mom", "**", "k_t", ")", "*", "grad", ",", "\n", "use_locking", "=", "False", ")", "\n", "\n", "\n", "# 5th step: variables updates by using 'var_update <- var + ( accum + old_accum * (beta_n * (1-lr*beta_n) - 1)  - lr^2 * grad)', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "# We use 'state_ops.add' instead of 'state_ops.sub'", "\n", "", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum", ",", "accum_t", "]", ")", ":", "\n", "            ", "var_update", "=", "state_ops", ".", "assign_add", "(", "var", ",", "accum_t", "+", "old_accum_t", "*", "(", "mom", "*", "(", "1", "-", "lr_t", "*", "mom", ")", "-", "1", ")", "-", "(", "lr_t", "**", "2", ")", "*", "grad", ")", "\n", "\n", "# 6th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "old_accum_t", ",", "accum_t", ",", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Nonconst.SSA1Nonconst._apply_sparse": [[126, 128], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.Indian.Indian.__init__": [[40, 60], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "alpha", "=", "0.5", ",", "beta", "=", "0.1", ",", "gamma_0", "=", "1.0", ",", "gamma_power", "=", "0.5", ",", "init_velocity", "=", "1.0", ",", "use_locking", "=", "False", ",", "name", "=", "'Indian'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "Indian", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "self", ".", "_beta", "=", "beta", "\n", "self", ".", "_gamma_0", "=", "gamma_0", "\n", "self", ".", "_gamma_power", "=", "gamma_power", "\n", "self", ".", "_init_velocity", "=", "init_velocity", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_alpha_t", "=", "None", "\n", "self", ".", "_beta_t", "=", "None", "\n", "self", ".", "_gamma_0_t", "=", "None", "\n", "self", ".", "_gamma_power_t", "=", "None", "\n", "self", ".", "_init_velocity_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.Indian.Indian._prepare": [[65, 72], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_alpha_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_alpha", ",", "name", "=", "'alpha'", ")", "\n", "self", ".", "_beta_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_beta", ",", "name", "=", "'beta'", ")", "\n", "self", ".", "_gamma_0_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_gamma_0", ",", "name", "=", "'gamma_0'", ")", "\n", "self", ".", "_gamma_power_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_gamma_power", ",", "name", "=", "'gamma_power'", ")", "\n", "self", ".", "_init_velocity_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_init_velocity", ",", "name", "=", "'init_velocity'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.Indian.Indian._create_slots": [[77, 81], ["Indian.Indian._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is 'psi_{k+1}' from the original work of Castera et. al. - see relation (7) from page 7", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"psi\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.Indian.Indian._apply_dense": [[100, 143], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "Indian.Indian.get_slot", "tensorflow.python.ops.math_ops.cast", "tensorflow.cond", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.train.get_or_create_global_step", "tensorflow.python.ops.math_ops.pow", "tensorflow.math.equal", "tensorflow.python.framework.ops.control_dependencies", "Indian.Indian.assign", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign_sub"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "alpha_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_alpha_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "beta_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_beta_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "gamma_0_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_gamma_0_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "gamma_power_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_gamma_power_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "init_velocity_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_init_velocity_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifier 'psi' from '_create_slots()'", "\n", "# We also memorize the old accumulator, since we will update the 'psi' variable. Here, 'psi_k' is defined in Castera et. al.", "\n", "psi_k", "=", "self", ".", "get_slot", "(", "var", ",", "\"psi\"", ")", "\n", "\n", "\n", "# 3rd step: define the current iteration needed for the momentum inertial sequence", "\n", "# It must be converted to the same type as the trainable variables", "\n", "n", "=", "math_ops", ".", "cast", "(", "curr_it", "(", ")", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# Here, we consider the adaptive learning rate, denoted by 'gamma_k' in the original article", "\n", "# The formula is given in the upper part of page 10", "\n", "adaptive_lr", "=", "lr_t", "*", "gamma_0_t", "/", "math_ops", ".", "pow", "(", "n", "+", "1", ",", "gamma_power_t", ")", "\n", "\n", "# 4th step: initialize the old value of 'psi_k', depending on the current iteration (if it is equal to 0 or not)", "\n", "# If the number of iterations > 0, then 'psi_k' = psi (the additional 'Slot' variable)", "\n", "# the formula for iteration no. 0 is given in the upper part of page 20", "\n", "# A correction: we must have '(beta^2 - beta * initial_velocity) * grad' in order to match the original implementation", "\n", "psi_cond", "=", "cond", "(", "equal", "(", "n", ",", "0", ")", ",", "lambda", ":", "(", "1.0", "-", "alpha_t", "*", "beta_t", ")", "*", "var", "-", "beta_t", "**", "2", "*", "grad", "+", "beta_t", "*", "init_velocity_t", "*", "grad", ",", "lambda", ":", "psi_k", ")", "\n", "\n", "# 5th step: we have the INDIAN formula 'psi_k <- psi_k - adaptive_lr * ((alpha - 1/beta) * theta_k + 1/beta * psi_k)'", "\n", "# We update 'accum' by assigning the value 'momentum_t * accum + grad' to it. Furthermore, the new value is return in the 'Tensor' object 'accum_t'", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "psi_cond", "]", ")", ":", "\n", "            ", "psi_k_plus_one", "=", "psi_k", ".", "assign", "(", "psi_cond", "-", "adaptive_lr", "*", "(", "(", "alpha_t", "-", "1.0", "/", "beta_t", ")", "*", "var", "+", "1.0", "/", "beta_t", "*", "psi_cond", ")", ")", "\n", "\n", "# 6th step: variables updates by using 'theta_k <- theta_k - adaptive_lr * ( (alpha-1/beta) * theta_k  + 1/beta * psi_k + beta * grad)'", "\n", "# Here we use 'state_ops.assign_sub', so the sign of the coefficients is opposite to the one appearing in the 3rd line of relation (7)", "\n", "# Here, 'grad' is in fact 'v_k' from the algorithm (7)", "\n", "", "with", "ops", ".", "control_dependencies", "(", "[", "psi_cond", "]", ")", ":", "\n", "            ", "var_update", "=", "state_ops", ".", "assign_sub", "(", "var", ",", "adaptive_lr", "*", "(", "(", "alpha_t", "-", "1.0", "/", "beta_t", ")", "*", "var", "+", "1.0", "/", "beta_t", "*", "psi_cond", "+", "beta_t", "*", "grad", ")", ")", "\n", "\n", "# 7th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "psi_k_plus_one", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.Indian.Indian._apply_sparse": [[146, 148], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Const.SSA2Const.__init__": [[32, 46], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "beta", "=", "0.7", ",", "k", "=", "2.0", ",", "use_locking", "=", "False", ",", "name", "=", "'SSA2Const'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "SSA2Const", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_beta", "=", "beta", "\n", "self", ".", "_k", "=", "k", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_beta_t", "=", "None", "\n", "self", ".", "_k_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Const.SSA2Const._prepare": [[50, 54], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_beta_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_beta", ",", "name", "=", "'beta'", ")", "\n", "self", ".", "_k_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_k", ",", "name", "=", "'k'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Const.SSA2Const._create_slots": [[58, 63], ["SSA2Const.SSA2Const._zeros_slot", "SSA2Const.SSA2Const._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is the accumulator obtained from the discrete-type velocity. It is denoted by 'p^{k+1}'", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"old_accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Const.SSA2Const._apply_dense": [[81, 106], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "SSA2Const.SSA2Const.get_slot", "SSA2Const.SSA2Const.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign_add"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "beta_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_beta_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "k_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_k_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifiers 'old_accum' and 'accum' from '_create_slots()'", "\n", "old_accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"old_accum\"", ")", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "# 3rd step: we have the SSA2 constant momentum formula 'accum_t <- beta^{k+1} * (1/beta - lr) * old_accum - lr^2 * beta^k * grad ', i.e. 'p^{k+1}' from Defazio", "\n", "old_accum_t", "=", "state_ops", ".", "assign", "(", "old_accum", ",", "accum", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum_t", "]", ")", ":", "\n", "            ", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "(", "beta_t", "**", "(", "k_t", "+", "1", ")", ")", "*", "(", "1", "/", "beta_t", "-", "lr_t", ")", "*", "accum", "-", "(", "lr_t", "**", "2", ")", "*", "(", "beta_t", "**", "(", "k_t", "+", "1", ")", ")", "*", "grad", ",", "use_locking", "=", "False", ")", "\n", "\n", "\n", "# 4th step: variables updates by using 'var_update <- var + ( accum + old_accum * (1/beta - lr - 1) )', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "# We use 'state_ops.add' instead of 'state_ops.sub'", "\n", "", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum", ",", "accum_t", "]", ")", ":", "\n", "            ", "var_update", "=", "state_ops", ".", "assign_add", "(", "var", ",", "accum_t", "+", "old_accum_t", "*", "(", "1", "/", "beta_t", "-", "lr_t", "-", "1", ")", ")", "\n", "\n", "# 5th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "old_accum_t", ",", "accum_t", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Const.SSA2Const._apply_sparse": [[109, 111], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.AggregatedMomentum.AggregatedMomentum.__init__": [[42, 58], ["tensorflow.python.training.optimizer.Optimizer.__init__", "range", "range"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-3", ",", "a", "=", "0.1", ",", "K", "=", "3", ",", "use_locking", "=", "False", ",", "name", "=", "'AggregatedMomentum'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "AggregatedMomentum", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_a", "=", "a", "\n", "self", ".", "_K", "=", "K", "\n", "self", ".", "_betas", "=", "[", "1.0", "-", "a", "**", "i", "for", "i", "in", "range", "(", "K", ")", "]", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_a_t", "=", "None", "\n", "self", ".", "_K_t", "=", "None", "\n", "self", ".", "_betas_t", "=", "[", "None", "for", "i", "in", "range", "(", "K", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.AggregatedMomentum.AggregatedMomentum._prepare": [[62, 67], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "range"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_a_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_a", ",", "name", "=", "'a'", ")", "\n", "self", ".", "_K_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_K", ",", "name", "=", "'K'", ")", "\n", "self", ".", "_betas_t", "=", "[", "ops", ".", "convert_to_tensor", "(", "self", ".", "_betas", "[", "i", "]", ",", "name", "=", "'betas_{}'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "self", ".", "_K", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.AggregatedMomentum.AggregatedMomentum._create_slots": [[72, 77], ["range", "AggregatedMomentum.AggregatedMomentum._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The K momentum variables are stored as 'Slots'", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "_K", ")", ":", "\n", "                ", "self", ".", "_zeros_slot", "(", "v", ",", "\"momentum_{}\"", ".", "format", "(", "i", ")", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.AggregatedMomentum.AggregatedMomentum._apply_dense": [[96, 124], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "range", "tensorflow.python.ops.state_ops.assign_add", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.python.ops.math_ops.cast", "AggregatedMomentum.AggregatedMomentum.get_slot", "tensorflow.python.ops.state_ops.assign", "momentum_list.append", "range"], "methods", ["None"], ["", "", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "K_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_a_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "betas_t", "=", "[", "math_ops", ".", "cast", "(", "self", ".", "_betas_t", "[", "i", "]", ",", "var", ".", "dtype", ".", "base_dtype", ")", "for", "i", "in", "range", "(", "self", ".", "_K", ")", "]", "\n", "\n", "#2nd step: we consider here the adaptive learning rate", "\n", "adaptive_lr", "=", "lr_t", "/", "K_t", "\n", "\n", "#3rd step: we define a list in which we append the new K momentum variables, along with their sum", "\n", "# We do not store them nor as 'Slots', neither as additional 'Non-Slot' variables", "\n", "# They are used at each step and then we can discard them", "\n", "momentum_list", "=", "[", "]", "\n", "summed_momentum", "=", "0.0", "\n", "for", "i", "in", "range", "(", "self", ".", "_K", ")", ":", "\n", "            ", "m", "=", "self", ".", "get_slot", "(", "var", ",", "\"momentum_{}\"", ".", "format", "(", "i", ")", ")", "\n", "m_t", "=", "state_ops", ".", "assign", "(", "m", ",", "-", "betas_t", "[", "i", "]", "*", "m", "-", "grad", ")", "\n", "summed_momentum", "+=", "m_t", "\n", "momentum_list", ".", "append", "(", "m_t", ")", "\n", "\n", "# 4th step: variables updates by using 'var_update <- var + ( adaptive_lr * summed_momentum )'", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "", "var_update", "=", "state_ops", ".", "assign_add", "(", "var", ",", "adaptive_lr", "*", "summed_momentum", ",", "use_locking", "=", "self", ".", "_use_locking", ")", "\n", "\n", "# 5th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "# Here we have put * in front of the 'momentum_list' which is of length K, since in '_create_slots()', we have constructed K elements", "\n", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "*", "momentum_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.AggregatedMomentum.AggregatedMomentum._apply_sparse": [[127, 129], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NrSamples.process_n_samples": [[3, 34], ["isinstance", "tensorflow.identity", "tensorflow.placeholder_with_default", "isinstance", "tensorflow.constant", "n_samples.items", "tensorflow.summary.scalar", "Exception", "ValueError", "tensorflow.cond", "tensorflow.less", "str", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity"], ["def", "process_n_samples", "(", "n_samples", ",", "global_epoch", ",", "name", "=", "\"n_samples\"", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        global_epoch:\n        n_samples: can be either a number, a dictionary {\"step\": n_s}, e.g. {100:0.1, 1000:0.001} or a particular keyword\n\n    Returns:\n        the processed learning rate, ready to be taken by the optimizer (if a schedule was requested returns a tf node)\n    \"\"\"", "\n", "\n", "n_s", "=", "None", "\n", "\n", "if", "isinstance", "(", "n_samples", ",", "(", "int", ")", ")", ":", "\n", "        ", "n_s", "=", "tf", ".", "placeholder_with_default", "(", "n_samples", ",", "shape", "=", "(", ")", ",", "name", "=", "'n_samples'", ")", "\n", "\n", "# instantiate n_s node if n_s is None and n_samples is a dict at this point", "\n", "", "if", "n_s", "is", "None", "and", "isinstance", "(", "n_samples", ",", "dict", ")", ":", "\n", "        ", "if", "not", "0", "in", "n_samples", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"learning rate schedule must specify, learning rate for step 0. Found schedule: %s\"", "%", "n_samples", ")", "\n", "\n", "", "n_s", "=", "tf", ".", "constant", "(", "n_samples", "[", "0", "]", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "name", ")", "\n", "for", "key", ",", "value", "in", "n_samples", ".", "items", "(", ")", ":", "\n", "            ", "n_s", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "less", "(", "global_epoch", ",", "key", ")", ",", "lambda", ":", "n_s", ",", "lambda", ":", "tf", ".", "constant", "(", "value", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "name", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"n_samples\"", ",", "n_s", ")", "\n", "\n", "", "if", "n_s", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"oops, something went wrong... could not process learning rate {}\"", ".", "format", "(", "str", "(", "n_samples", ")", ")", ")", "\n", "\n", "", "return", "tf", ".", "identity", "(", "n_s", ",", "name", "=", "\"n_samples\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NrSamples.get_n_s_id": [[36, 61], ["isinstance", "str", "isinstance", "n_samples.keys", "n_samples.values", "zip", "name.append"], "function", ["None"], ["", "def", "get_n_s_id", "(", "n_samples", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        n_samples: can be either a number, a dictionary {\"step\": n_s}, e.g. {100:0.1, 1000:0.001} or a particular keyword,\n                    or a tuple (n_s_min, n_s_name, n_s_kwargs)\n\n    Returns:\n        the id for the learning rate\n    \"\"\"", "\n", "\n", "_id", "=", "\"\"", "\n", "if", "isinstance", "(", "n_samples", ",", "(", "int", ")", ")", ":", "\n", "        ", "_id", "+=", "str", "(", "n_samples", ")", "\n", "\n", "", "elif", "isinstance", "(", "n_samples", ",", "dict", ")", ":", "\n", "        ", "keys", "=", "n_samples", ".", "keys", "(", ")", "\n", "val", "=", "n_samples", ".", "values", "(", ")", "\n", "name", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "zip", "(", "keys", ",", "val", ")", ":", "\n", "            ", "name", ".", "append", "(", "\"{}r{}\"", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "", "n", "=", "\"_\"", ".", "join", "(", "name", ")", "\n", "\n", "_id", "+=", "n", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Nonconst.SSA2Nonconst.__init__": [[35, 49], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "k", "=", "2.0", ",", "alpha", "=", "4.0", ",", "use_locking", "=", "False", ",", "name", "=", "'SSA2Nonconst'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "SSA2Nonconst", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "self", ".", "_k", "=", "k", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_alpha_t", "=", "None", "\n", "self", ".", "_k_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Nonconst.SSA2Nonconst._prepare": [[53, 57], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_alpha_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_alpha", ",", "name", "=", "'alpha'", ")", "\n", "self", ".", "_k_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_k", ",", "name", "=", "'k'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Nonconst.SSA2Nonconst._create_slots": [[61, 67], ["SSA2Nonconst.SSA2Nonconst._zeros_slot", "SSA2Nonconst.SSA2Nonconst._zeros_slot", "SSA2Nonconst.SSA2Nonconst._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is the accumulator obtained from the discrete-type velocity. It is denoted by 'p^{k+1}'", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"old_accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"curr_it\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Nonconst.SSA2Nonconst._apply_dense": [[85, 118], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "SSA2Nonconst.SSA2Nonconst.get_slot", "SSA2Nonconst.SSA2Nonconst.get_slot", "SSA2Nonconst.SSA2Nonconst.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign_add"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "alpha_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_alpha_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "k_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_k_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifiers 'old_accum' and 'accum' from '_create_slots()'", "\n", "old_accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"old_accum\"", ")", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "# 3rd step: define the current iteration needed for the momentum inertial sequence", "\n", "# It must be converted to the same type as the trainable variables", "\n", "# We have here the inertial sequences 'alpha_n' and 'beta_n'", "\n", "curr_it", "=", "self", ".", "get_slot", "(", "var", ",", "\"curr_it\"", ")", "\n", "n", "=", "curr_it", "+", "1", "\n", "mom", "=", "n", "/", "(", "n", "+", "alpha_t", ")", "\n", "new_mom", "=", "(", "n", "+", "1.0", ")", "/", "(", "n", "+", "alpha_t", "+", "1.0", ")", "\n", "\n", "# 4th step: we have the SSA2 constant momentum formula 'accum_t <- beta_{n+1} * beta_n^k * (1/beta_n - lr) * old_accum - lr^2 * beta_{n+1} beta_n^k * grad ', i.e. 'p^{k+1}' from Defazio", "\n", "old_accum_t", "=", "state_ops", ".", "assign", "(", "old_accum", ",", "accum", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum_t", "]", ")", ":", "\n", "            ", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "new_mom", "*", "(", "mom", "**", "k_t", ")", "*", "(", "1", "/", "mom", "-", "lr_t", ")", "*", "accum", "-", "(", "lr_t", "**", "2", ")", "*", "new_mom", "*", "(", "mom", "**", "k_t", ")", "*", "grad", ",", "use_locking", "=", "False", ")", "\n", "\n", "\n", "# 5th step: variables updates by using 'var_update <- var + ( accum + old_accum * (1/beta_n - lr - 1) )', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "# We use 'state_ops.add' instead of 'state_ops.sub'", "\n", "", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum", ",", "accum_t", "]", ")", ":", "\n", "            ", "var_update", "=", "state_ops", ".", "assign_add", "(", "var", ",", "accum_t", "+", "old_accum_t", "*", "(", "1", "/", "mom", "-", "lr_t", "-", "1", ")", ")", "\n", "\n", "# 6th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "old_accum_t", ",", "accum_t", ",", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA2Nonconst.SSA2Nonconst._apply_sparse": [[121, 123], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovConst.NesterovConst.__init__": [[26, 37], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "momentum", "=", "0.5", ",", "use_locking", "=", "False", ",", "name", "=", "'NesterovConst'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "NesterovConst", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_momentum", "=", "momentum", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_momentum_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovConst.NesterovConst._prepare": [[41, 44], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_momentum_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_momentum", ",", "name", "=", "'momentum'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovConst.NesterovConst._create_slots": [[49, 53], ["NesterovConst.NesterovConst._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is 'p^{k+1}' in the work of Defazio", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovConst.NesterovConst._apply_dense": [[71, 90], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "NesterovConst.NesterovConst.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.state_ops.assign_sub", "tensorflow.python.ops.control_flow_ops.group"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "momentum_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_momentum_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifier 'accum' from '_create_slots()'", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "# 3rd step: we have the Nesterov formula 'accum_t <- accum_t * momentum_t + grad', i.e. 'p^{k+1}' from Defazio", "\n", "# We update 'accum' by assigning the value 'momentum_t * accum + grad' to it. Furthermore, the new value is return in the 'Tensor' object 'accum_t'", "\n", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "momentum_t", "*", "accum", "+", "grad", ",", "use_locking", "=", "False", ")", "\n", "\n", "# 4th step: variables updates by using 'var_update <- var - ( lr_t * grad + lr_t * momentum_t * accum_t )', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "var_update", "=", "state_ops", ".", "assign_sub", "(", "var", ",", "lr_t", "*", "grad", "+", "lr_t", "*", "momentum_t", "*", "accum_t", ")", "\n", "\n", "# 5th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "accum_t", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovConst.NesterovConst._apply_sparse": [[93, 95], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovNonconst.NesterovNonconst.__init__": [[33, 45], ["tensorflow.python.training.optimizer.Optimizer.__init__", "float"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "alpha", "=", "2.0", ",", "use_locking", "=", "False", ",", "name", "=", "'NesterovNonconst'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "NesterovNonconst", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_alpha", "=", "float", "(", "alpha", ")", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_alpha_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovNonconst.NesterovNonconst._prepare": [[55, 58], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_alpha_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_alpha", ",", "name", "=", "'alpha'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovNonconst.NesterovNonconst._create_slots": [[64, 71], ["NesterovNonconst.NesterovNonconst._zeros_slot", "NesterovNonconst.NesterovNonconst._zeros_slot", "NesterovNonconst.NesterovNonconst._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "# Create 'Slot' variables", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is 'p^{k+1}' in the work of Defazio", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"momentum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"curr_it\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovNonconst.NesterovNonconst._apply_dense": [[89, 120], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "NesterovNonconst.NesterovNonconst.get_slot", "NesterovNonconst.NesterovNonconst.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.state_ops.assign_sub", "tensorflow.python.ops.control_flow_ops.group"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "alpha_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_alpha_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifier 'accum' from '_create_slots()'", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "# Optional 'get_slot' for momentum. Then we can use 'momentum = momentum_t' and then use only 'accum_t' and 'momentum' at updates", "\n", "# momentum = self.get_slot(var, \"momentum\")", "\n", "\n", "# 3rd step: define the current iteration needed for the momentum inertial sequence", "\n", "# It must be converted to the same type as the trainable variables", "\n", "curr_it", "=", "self", ".", "get_slot", "(", "var", ",", "\"curr_it\"", ")", "\n", "n", "=", "curr_it", "+", "1", "\n", "\n", "\n", "momentum_t", "=", "n", "/", "(", "n", "+", "alpha_t", "+", "1.0", ")", "\n", "momentum_t_1", "=", "(", "n", "+", "1", ")", "/", "(", "n", "+", "alpha_t", "+", "2.0", ")", "\n", "\n", "# 4th step: we have the Nesterov formula 'accum_t <- accum_t * momentum_t + grad', i.e. 'p^{k+1}' from Defazio", "\n", "# We update 'accum' by assigning the value 'momentum_t * accum + grad' to it. Furthermore, the new value is return in the 'Tensor' object 'accum_t'", "\n", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "momentum_t", "*", "accum", "+", "grad", ",", "use_locking", "=", "False", ")", "\n", "\n", "# 5th step: variables updates by using 'var_update <- var - ( lr_t * grad + lr_t * momentum_{t+1} * accum_t )', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "var_update", "=", "state_ops", ".", "assign_sub", "(", "var", ",", "lr_t", "*", "grad", "+", "lr_t", "*", "momentum_t_1", "*", "accum_t", ")", "\n", "\n", "# 6th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "accum_t", ",", "momentum_t", ",", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NesterovNonconst.NesterovNonconst._apply_sparse": [[123, 125], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalGradientOptimizer.NaturalGradientOptimizer.__init__": [[17, 30], ["kw.pop", "kw.pop", "super().__init__", "kw.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "learning_rate", ",", "*", "args", ",", "**", "kw", ")", ":", "\n", "\n", "        ", "self", ".", "_model", "=", "kw", "[", "\"model\"", "]", "\n", "self", ".", "_damping", "=", "kw", "[", "\"damping\"", "]", "\n", "\n", "# remove from args before passing to the constructor of tf.train.GradientDescentOptimizer", "\n", "kw", ".", "pop", "(", "\"model\"", ",", "None", ")", "\n", "kw", ".", "pop", "(", "\"damping\"", ",", "None", ")", "\n", "\n", "if", "\"name\"", "not", "in", "kw", ".", "keys", "(", ")", ":", "\n", "            ", "kw", "[", "\"name\"", "]", "=", "\"NaturalGradient\"", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "learning_rate", ",", "*", "args", ",", "**", "kw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalGradientOptimizer.NaturalGradientOptimizer.compute_gradients": [[31, 141], ["super().compute_gradients", "tensorflow.trainable_variables", "tensorflow.python.ops.parallel_for.gradients.jacobian", "int", "int", "tensorflow.concat", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.concat", "tensorflow.linalg.inv", "tensorflow.matmul", "range", "tensorflow.nn.log_softmax", "numpy.sum", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.ones", "tensorflow.reshape", "tensorflow.reshape", "int", "len", "tensorflow.reduce_prod", "tensorflow.slice", "tensorflow.reshape", "NaturalGradientOptimizer.NaturalGradientOptimizer.natural_gradient.append", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.diag", "numpy.prod", "tensorflow.matmul", "tensorflow.shape", "zip", "numpy.prod", "tensorflow.matmul", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "tensorflow.slice", "tensorflow.slice", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax"], ["", "def", "compute_gradients", "(", "self", ",", "loss", ",", "*", "args", ",", "**", "kw", ")", ":", "\n", "\n", "        ", "grads_and_vars", "=", "super", "(", ")", ".", "compute_gradients", "(", "loss", ",", "*", "args", ",", "**", "kw", ")", "\n", "\n", "#########################################", "\n", "# Natural gradient computed in two steps, through the Jacobian", "\n", "#########################################", "\n", "\n", "# TODO do I need to add possible regularizers to the loss", "\n", "\n", "logits", "=", "self", ".", "_model", ".", "logits", "\n", "y", "=", "self", ".", "_model", ".", "y", "\n", "#regularizer = self._model.regularizer", "\n", "# here the loss is the log-likelihood", "\n", "#loss_per_sample = self._model.loss_per_sample", "\n", "\n", "#n = logits.get_shape().as_list()[1]", "\n", "\n", "#################", "\n", "\n", "grads_and_vars_not_none", "=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "grads", "=", "[", "g", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "variables", "=", "[", "v", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars_not_none", "]", "\n", "\n", "# no reduction of the last logit", "\n", "# previous function call", "\n", "#new_loss = my_loss_full_logits(y, logits) + regularizer", "\n", "#self.likelihood_per_sample = new_loss", "\n", "\n", "trainable_vars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "\n", "\n", "# it was previously", "\n", "# jacobians = jacobian(self.likelihood_per_sample, trainable_vars)", "\n", "jacobians", "=", "jacobian", "(", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", ",", "trainable_vars", ")", "# [tf.reduce_sum(i, axis=0) for i in jacobian(self.logits, trainable_vars)]", "\n", "\n", "n_weights", "=", "int", "(", "np", ".", "sum", "(", "[", "np", ".", "prod", "(", "i", ".", "shape", "[", "2", ":", "]", ")", "for", "i", "in", "jacobians", "]", ")", ")", "#tf.shape(self.V)[0]", "\n", "n_samples", "=", "int", "(", "self", ".", "_model", ".", "batch_size", "[", "\"train\"", "]", ")", "#tf.shape(self.V)[1]", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "self", ".", "V", "=", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "i", ",", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "slice", "(", "tf", ".", "shape", "(", "i", ")", ",", "[", "0", "]", ",", "[", "2", "]", ")", ")", ",", "tf", ".", "reduce_prod", "(", "tf", ".", "slice", "(", "tf", ".", "shape", "(", "i", ")", ",", "[", "2", "]", ",", "[", "-", "1", "]", ")", ")", "]", ")", "for", "i", "in", "jacobians", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "V", "=", "tf", ".", "transpose", "(", "self", ".", "V", ")", "\n", "self", ".", "Q", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", ",", "[", "-", "1", "]", ")", "\n", "\n", "# this is an expected value, so I need to divide by the number of samples", "\n", "#self.V /= n_samples", "\n", "self", ".", "Q", "/=", "n_samples", "\n", "\n", "damp", "=", "self", ".", "_damping", "\n", "\n", "#K = tf.einsum('ki,kj->ij', self.V, self.V)", "\n", "# faster", "\n", "K", "=", "1", "/", "damp", "*", "tf", ".", "matmul", "(", "self", ".", "V", ",", "self", ".", "V", ",", "transpose_a", "=", "True", ")", "\n", "\n", "#D = tf.eye(n_weights)", "\n", "\n", "# verify invFisher", "\n", "# I = np.eye(3)", "\n", "# D = np.eye(83)", "\n", "# D/damp - 1/damp/damp * np.dot(np.dot(V,np.linalg.inv(I + 1/damp*np.dot(V.T,V))),V.T)", "\n", "\n", "G", "=", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "g", ",", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "g", ")", ")", ",", "1", "]", ")", "for", "g", "in", "grads", "]", ",", "axis", "=", "0", ")", "\n", "\n", "#I = tf.eye(n_samples)", "\n", "S", "=", "tf", ".", "linalg", ".", "inv", "(", "tf", ".", "diag", "(", "1", "/", "self", ".", "Q", ")", "+", "K", ")", "\n", "#self.VS = tf.einsum('ik,kj->ij', self.V, S)", "\n", "# faster", "\n", "self", ".", "VS", "=", "tf", ".", "matmul", "(", "self", ".", "V", ",", "S", ")", "\n", "#self.invFisher = 1/damp*D - 1/damp**2*tf.einsum('ik,jk->ij', self.VS, self.V)", "\n", "\n", "############### not efficient since I compuute the inverse matrix", "\n", "# faster due to matmul", "\n", "#self.invFisher = 1/damp*D - 1/damp**2*tf.matmul(self.VS, self.V, transpose_b = True)", "\n", "#self.NG = tf.einsum('ij,jk->ik', self.invFisher, G)", "\n", "# faster due to matmul", "\n", "#self.NG = tf.matmul(self.invFisher, G)", "\n", "###############", "\n", "\n", "size", "=", "n_samples", "*", "self", ".", "_model", ".", "dataset", ".", "n_labels", "\n", "\n", "self", ".", "_invFisher_D", "=", "1", "/", "damp", "*", "tf", ".", "ones", "(", "shape", "=", "[", "n_weights", ",", "1", "]", ")", "\n", "self", ".", "_invFisher_S", "=", "-", "tf", ".", "reshape", "(", "S", ",", "[", "size", ",", "size", "]", ")", "\n", "self", ".", "_invFisher_V", "=", "1", "/", "damp", "*", "tf", ".", "reshape", "(", "self", ".", "V", ",", "[", "n_weights", ",", "size", "]", ")", "\n", "self", ".", "_n_weights_layers", "=", "[", "int", "(", "np", ".", "prod", "(", "i", ".", "shape", "[", "2", ":", "]", ")", ")", "for", "i", "in", "jacobians", "]", "\n", "\n", "# much faster!", "\n", "self", ".", "NG", "=", "1", "/", "damp", "*", "G", "-", "(", "1", "/", "damp", ")", "**", "2", "*", "tf", ".", "matmul", "(", "self", ".", "VS", ",", "tf", ".", "matmul", "(", "self", ".", "V", ",", "\n", "G", ",", "\n", "transpose_a", "=", "True", ")", ")", "\n", "\n", "#self._model.loss = tf.reduce_mean(new_loss)", "\n", "\n", "# remove this line", "\n", "#self.grads = ng", "\n", "\n", "self", ".", "natural_gradient", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "grads", ")", ")", ":", "\n", "            ", "length", "=", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "grads", "[", "i", "]", ")", ")", "\n", "c", "=", "tf", ".", "slice", "(", "self", ".", "NG", ",", "[", "start", ",", "0", "]", ",", "[", "length", ",", "1", "]", ")", "\n", "start", "+=", "length", "\n", "d", "=", "tf", ".", "reshape", "(", "c", ",", "grads", "[", "i", "]", ".", "shape", ")", "\n", "self", ".", "natural_gradient", ".", "append", "(", "d", ")", "\n", "\n", "# restore the gradient", "\n", "", "grads_and_vars", "=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "zip", "(", "self", ".", "natural_gradient", ",", "variables", ")", "]", "\n", "\n", "return", "grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.utilsOptimizers.my_loss_full_logits": [[6, 15], ["tensorflow.nn.softmax", "tensorflow.clip_by_value", "tensorflow.reduce_sum", "logits.get_shape().as_list", "tensorflow.log", "logits.get_shape", "tensorflow.one_hot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["def", "my_loss_full_logits", "(", "y", ",", "logits", ")", ":", "\n", "\n", "    ", "n", "=", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "probabilities", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "clipped_probabilities", "=", "tf", ".", "clip_by_value", "(", "probabilities", ",", "NUMTOL", ",", "1", "-", "NUMTOL", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "-", "tf", ".", "one_hot", "(", "y", ",", "depth", "=", "n", ")", "*", "tf", ".", "log", "(", "clipped_probabilities", ")", ",", "axis", "=", "1", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovConst.ExtendedNesterovConst.__init__": [[46, 59], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "alpha", "=", "0.2", ",", "beta", "=", "0.01", ",", "use_locking", "=", "False", ",", "name", "=", "'ExtendedNesterovConst'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "ExtendedNesterovConst", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "self", ".", "_beta", "=", "beta", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_alpha_t", "=", "None", "\n", "self", ".", "_beta_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovConst.ExtendedNesterovConst._prepare": [[62, 66], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_alpha_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_alpha", ",", "name", "=", "'alpha'", ")", "\n", "self", ".", "_beta_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_beta", ",", "name", "=", "'beta'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovConst.ExtendedNesterovConst._create_slots": [[71, 76], ["ExtendedNesterovConst.ExtendedNesterovConst._zeros_slot", "ExtendedNesterovConst.ExtendedNesterovConst._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is 'p^{k+1}' in the work of Defazio", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"old_accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovConst.ExtendedNesterovConst._apply_dense": [[94, 120], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "ExtendedNesterovConst.ExtendedNesterovConst.get_slot", "ExtendedNesterovConst.ExtendedNesterovConst.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign_sub"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "alpha_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_alpha_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "beta_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_beta_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifier 'accum' from '_create_slots()'", "\n", "# We also memorize the old accumulator, since we will update the 'accum' variable. Here, 'old_accum' is 'p^{k+1}'", "\n", "old_accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"old_accum\"", ")", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "\n", "# 3rd step: we have the Extended Nesterov formula 'accum_t <- accum_t * alpha_t + grad', i.e. 'p^{k+1}' from Defazio", "\n", "# We update 'accum' by assigning the value 'momentum_t * accum + grad' to it. Furthermore, the new value is return in the 'Tensor' object 'accum_t'", "\n", "old_accum_t", "=", "state_ops", ".", "assign", "(", "old_accum", ",", "accum", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum_t", "]", ")", ":", "\n", "            ", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "alpha_t", "*", "accum", "+", "grad", ",", "use_locking", "=", "False", ")", "\n", "\n", "# 4th step: variables updates by using 'var_update <- var - ( lr_t * grad + lr_t * beta_t * accum_t + (alpha_t-beta_t) * old_accum )', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum", ",", "accum_t", "]", ")", ":", "\n", "            ", "var_update", "=", "state_ops", ".", "assign_sub", "(", "var", ",", "lr_t", "*", "grad", "+", "lr_t", "*", "beta_t", "*", "accum_t", "+", "(", "alpha_t", "-", "beta_t", ")", "*", "old_accum_t", ")", "\n", "\n", "# 5th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "old_accum_t", ",", "accum_t", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovConst.ExtendedNesterovConst._apply_sparse": [[123, 125], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.TFOptimizers.instantiate_optimizer": [[20, 92], ["LearningRates.process_learning_rate", "optimizer_kwargs.copy.copy.copy", "optimizer_kwargs.copy.copy.update", "utils.argo_utils.eval_method_from_tuple", "importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "__name__.split", "importlib.import_module", "utils.argo_utils.eval_method_from_tuple", "__name__.split", "pdb.set_trace", "kfac.LayerCollection", "kfac.LayerCollection.register_categorical_predictive_distribution", "tensorflow.logging.info", "kfac.LayerCollection.auto_register_layers", "utils.argo_utils.eval_method_from_tuple", "__name__.split", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.process_learning_rate", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.eval_method_from_tuple"], ["    ", "@", "staticmethod", "\n", "def", "instantiate_optimizer", "(", "model", ",", "optimizer_tuple", ")", ":", "\n", "\n", "        ", "optimizer_name", "=", "optimizer_tuple", "[", "0", "]", "\n", "optimizer_kwargs", "=", "optimizer_tuple", "[", "1", "]", "\n", "\n", "lr", "=", "process_learning_rate", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "model", ".", "global_step", ",", "model", ".", "n_batches_per_epoch", ")", "\n", "\n", "# I want to copy because I want to modify it and I don't want to accidentally modify all the references around", "\n", "# in python references to a particular entry of a dictionary can be passed around and I might overwrite different task_opts", "\n", "optimizer_kwargs", "=", "optimizer_kwargs", ".", "copy", "(", ")", "\n", "optimizer_kwargs", ".", "update", "(", "{", "\"learning_rate\"", ":", "lr", "}", ")", "\n", "\n", "try", ":", "\n", "# try to get the module from tf.train", "\n", "            ", "training_optimizer", "=", "eval_method_from_tuple", "(", "tf", ".", "train", ",", "(", "optimizer_name", ",", "optimizer_kwargs", ")", ")", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "\n", "            ", "optimizer_kwargs", "[", "\"model\"", "]", "=", "model", "\n", "try", ":", "\n", "# first try to load from argo.core.optimizers", "\n", "                ", "optimizer_module", "=", "importlib", ".", "import_module", "(", "\".\"", "+", "optimizer_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "training_optimizer", "=", "eval_method_from_tuple", "(", "optimizer_module", ",", "(", "optimizer_name", ",", "optimizer_kwargs", ")", ")", "\n", "\n", "", "except", "ImportError", ":", "\n", "                ", "try", ":", "\n", "# second try to load from core.optimizers", "\n", "                    ", "optimizer_module", "=", "importlib", ".", "import_module", "(", "\"core.optimizers.\"", "+", "optimizer_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "training_optimizer", "=", "eval_method_from_tuple", "(", "optimizer_module", ",", "(", "optimizer_name", ",", "optimizer_kwargs", ")", ")", "\n", "\n", "", "except", "ImportError", ":", "\n", "                    ", "try", ":", "\n", "# third try to load from core", "\n", "                        ", "optimizer_module", "=", "importlib", ".", "import_module", "(", "\"core.\"", "+", "optimizer_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "training_optimizer", "=", "eval_method_from_tuple", "(", "optimizer_module", ",", "(", "optimizer_name", ",", "optimizer_kwargs", ")", ")", "\n", "\n", "\n", "", "except", "ImportError", ":", "\n", "                        ", "try", ":", "\n", "                            ", "pdb", ".", "set_trace", "(", ")", "\n", "# next try to load kfac", "\n", "import", "kfac", "\n", "\n", "layer_collection", "=", "kfac", ".", "LayerCollection", "(", ")", "\n", "layer_collection", ".", "register_categorical_predictive_distribution", "(", "model", ".", "logits", ",", "name", "=", "\"logits\"", ")", "\n", "# Register parameters. K-FAC needs to know about the inputs, outputs, and", "\n", "# parameters of each conv/fully connected layer and the logits powering the", "\n", "# posterior probability over classes.", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"Building LayerCollection.\"", ")", "\n", "layer_collection", ".", "auto_register_layers", "(", ")", "\n", "\n", "# training_module = importlib.import_module(\".\" + training_algorithm_name, '.'.join(__name__.split('.')[:-1]))", "\n", "training_module", "=", "kfac", "\n", "\n", "kfac_kwargs", "=", "{", "\n", "**", "optimizer_kwargs", ",", "\n", "\"layer_collection\"", ":", "layer_collection", ",", "\n", "\"placement_strategy\"", ":", "\"round_robin\"", ",", "\n", "\"cov_devices\"", ":", "[", "\"/gpu:0\"", "]", ",", "\n", "\"inv_devices\"", ":", "[", "\"/gpu:0\"", "]", ",", "\n", "}", "\n", "training_optimizer", "=", "eval_method_from_tuple", "(", "training_module", ",", "(", "optimizer_name", ",", "kfac_kwargs", ")", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                            ", "raise", "Exception", "(", "\"problem loading training algorithm: %s, kwargs: %s, exception: %s\"", "%", "(", "\n", "training_module", ",", "optimizer_kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "", "", "", "", "return", "training_optimizer", ",", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.TFOptimizers._get_kfac_parameters": [[93, 101], ["LearningRates.get_lr_id", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id"], ["", "@", "staticmethod", "\n", "def", "_get_kfac_parameters", "(", "optimizer_kwargs", ")", ":", "\n", "        ", "_id", "=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_ced'", "+", "str", "(", "optimizer_kwargs", "[", "\"cov_ema_decay\"", "]", ")", "\n", "_id", "+=", "'_d'", "+", "str", "(", "optimizer_kwargs", "[", "\"damping\"", "]", ")", "\n", "_id", "+=", "'_m'", "+", "str", "(", "optimizer_kwargs", "[", "\"momentum\"", "]", ")", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.TFOptimizers.create_id": [[102, 366], ["LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "LearningRates.get_lr_id", "str", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "LearningRates.get_lr_id", "str", "LearningRates.get_lr_id", "str", "LearningRates.get_lr_id", "str", "LearningRates.get_lr_id", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "LearningRates.get_lr_id", "str", "str", "str", "TFOptimizers._get_kfac_parameters", "str", "TFOptimizers._get_kfac_parameters", "str", "str", "str", "TFOptimizers._get_kfac_parameters", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "str", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "str", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "str", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "str", "str", "Exception", "LearningRates.get_lr_id", "LearningRates.get_lr_id", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.TFOptimizers._get_kfac_parameters", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.TFOptimizers._get_kfac_parameters", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.TFOptimizers._get_kfac_parameters", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id"], ["", "@", "staticmethod", "\n", "def", "create_id", "(", "optimizer_tuple", ")", ":", "\n", "# TODO huge 'if cascade'... each optimizer should have its own id.. or maybe in utils?", "\n", "# REPLY: I agree with this, the problem is that we have here also TF optimizer", "\n", "# for which we don't have a file where it is implemented. I don't like to have everything", "\n", "# in utils, since things should be defined where they are used. Utils is difficult to read", "\n", "# (Luigi 2019-05-26)", "\n", "        ", "optimizer_name", ",", "optimizer_kwargs", "=", "optimizer_tuple", "\n", "\n", "_id", "=", "''", "\n", "\n", "\n", "if", "optimizer_name", "==", "'GradientDescentOptimizer'", ":", "\n", "            ", "_id", "+=", "'GD'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'AdagradOptimizer'", ":", "\n", "            ", "_id", "+=", "'AG'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'RMSPropOptimizer'", ":", "\n", "            ", "_id", "+=", "'RMS'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_m'", "+", "str", "(", "optimizer_kwargs", "[", "\"momentum\"", "]", ")", "\n", "_id", "+=", "'_d'", "+", "str", "(", "optimizer_kwargs", "[", "\"decay\"", "]", ")", "\n", "_id", "+=", "'_e'", "+", "str", "(", "optimizer_kwargs", "[", "\"epsilon\"", "]", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'MomentumOptimizer'", ":", "\n", "            ", "_id", "+=", "'A'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_m'", "+", "str", "(", "optimizer_kwargs", "[", "\"momentum\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "_id", "+=", "'_n'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_nesterov\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'ProximalGradientDescentOptimizer'", ":", "\n", "            ", "_id", "+=", "'PGD'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_l1'", "+", "str", "(", "optimizer_kwargs", "[", "\"l1_regularization_strength\"", "]", ")", "\n", "_id", "+=", "'_l2'", "+", "str", "(", "optimizer_kwargs", "[", "\"l2_regularization_strength\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'AdamOptimizer'", ":", "\n", "            ", "_id", "+=", "'A'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_bo'", "+", "str", "(", "optimizer_kwargs", "[", "\"beta1\"", "]", ")", "\n", "_id", "+=", "'_bt'", "+", "str", "(", "optimizer_kwargs", "[", "\"beta2\"", "]", ")", "\n", "\n", "\n", "#elif optimizer_name == 'MomentumOptimizer':", "\n", "#    _id += 'M'", "\n", "#    _id += '_lr' + get_lr_id(optimizer_kwargs[\"learning_rate\"]) ", "\n", "#    _id += '_m' + get_lr_id(optimizer_kwargs[\"momentum\"])", "\n", "#    _id += '_l' + (\"1\" if optimizer_kwargs[\"use_locking\"] else \"0\")", "\n", "#    _id += '_n' + (\"1\" if optimizer_kwargs[\"use_nesterov\"] else \"0\")", "\n", "\n", "#elif optimizer_name == 'NesterovConstOptimizer':", "\n", "#    _id += 'NC'", "\n", "#    _id += '_lr' + get_lr_id(optimizer_kwargs[\"learning_rate\"]) ", "\n", "#    _id += '_m' + get_lr_id(optimizer_kwargs[\"momentum\"])", "\n", "#    _id += '_l' + (\"1\" if optimizer_kwargs[\"use_locking\"] else \"0\")", "\n", "\n", "", "elif", "optimizer_name", "==", "'AdadeltaOptimizer'", ":", "\n", "            ", "_id", "+=", "'Ad'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_r'", "+", "str", "(", "optimizer_kwargs", "[", "\"rho\"", "]", ")", "\n", "_id", "+=", "'_e'", "+", "str", "(", "optimizer_kwargs", "[", "\"epsilon\"", "]", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'NewtonMethodOptimizer'", ":", "\n", "            ", "_id", "+=", "'N'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_d'", "+", "str", "(", "optimizer_kwargs", "[", "\"damping\"", "]", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'SaddleFreeNewtonOptimizer'", ":", "\n", "            ", "_id", "+=", "'SFN'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_d'", "+", "str", "(", "optimizer_kwargs", "[", "\"damping_values\"", "]", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'NesterovConst'", ":", "\n", "            ", "_id", "+=", "'NC'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_m'", "+", "str", "(", "optimizer_kwargs", "[", "\"momentum\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'NesterovNonconst'", ":", "\n", "            ", "_id", "+=", "'NNC'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_a'", "+", "str", "(", "optimizer_kwargs", "[", "\"alpha\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'Indian'", ":", "\n", "            ", "_id", "+=", "'IND'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_a'", "+", "str", "(", "optimizer_kwargs", "[", "\"alpha\"", "]", ")", "\n", "_id", "+=", "'_b'", "+", "str", "(", "optimizer_kwargs", "[", "\"beta\"", "]", ")", "\n", "_id", "+=", "'_g0'", "+", "str", "(", "optimizer_kwargs", "[", "\"gamma_0\"", "]", ")", "\n", "_id", "+=", "'_gp'", "+", "str", "(", "optimizer_kwargs", "[", "\"gamma_power\"", "]", ")", "\n", "_id", "+=", "'_iv'", "+", "str", "(", "optimizer_kwargs", "[", "\"init_velocity\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'ExtendedNesterovConst'", ":", "\n", "            ", "_id", "+=", "'ENC'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_a'", "+", "str", "(", "optimizer_kwargs", "[", "\"alpha\"", "]", ")", "\n", "_id", "+=", "'_b'", "+", "str", "(", "optimizer_kwargs", "[", "\"beta\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'AggregatedMomentum'", ":", "\n", "            ", "_id", "+=", "'AgM'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_a'", "+", "str", "(", "optimizer_kwargs", "[", "\"a\"", "]", ")", "\n", "_id", "+=", "'_K'", "+", "str", "(", "optimizer_kwargs", "[", "\"K\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'SSA1Const'", ":", "\n", "            ", "_id", "+=", "'SSA1'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_b'", "+", "str", "(", "optimizer_kwargs", "[", "\"beta\"", "]", ")", "\n", "_id", "+=", "'_k'", "+", "str", "(", "optimizer_kwargs", "[", "\"k\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'SSA2Const'", ":", "\n", "            ", "_id", "+=", "'SSA2'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_b'", "+", "str", "(", "optimizer_kwargs", "[", "\"beta\"", "]", ")", "\n", "_id", "+=", "'_k'", "+", "str", "(", "optimizer_kwargs", "[", "\"k\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'SSA2Nonconst'", ":", "\n", "            ", "_id", "+=", "'SSA2NC'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_k'", "+", "str", "(", "optimizer_kwargs", "[", "\"k\"", "]", ")", "\n", "_id", "+=", "'_a'", "+", "str", "(", "optimizer_kwargs", "[", "\"alpha\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'SSA1Nonconst'", ":", "\n", "            ", "_id", "+=", "'SSA1NC'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_k'", "+", "str", "(", "optimizer_kwargs", "[", "\"k\"", "]", ")", "\n", "_id", "+=", "'_a'", "+", "str", "(", "optimizer_kwargs", "[", "\"alpha\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "", "elif", "optimizer_name", "==", "'ExtendedNesterovNonconst'", ":", "\n", "            ", "_id", "+=", "'ENNC'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_a'", "+", "str", "(", "optimizer_kwargs", "[", "\"alpha\"", "]", ")", "\n", "_id", "+=", "'_b'", "+", "str", "(", "optimizer_kwargs", "[", "\"beta\"", "]", ")", "\n", "_id", "+=", "'_g'", "+", "str", "(", "optimizer_kwargs", "[", "\"gamma\"", "]", ")", "\n", "_id", "+=", "'_lk'", "+", "(", "'1'", "if", "str", "(", "optimizer_kwargs", "[", "\"use_locking\"", "]", ")", "==", "'True'", "else", "'0'", ")", "\n", "\n", "\n", "# see kfac/kfac/python/ops/optimizer.py", "\n", "# seems to be buggy, we should write to the authors..", "\n", "# however PeriodicInvCovUpdateKfacOpt with invert_every=1 and cov_update_every=1", "\n", "# could be an alternative", "\n", "", "elif", "optimizer_name", "==", "'KfacOptimizer'", ":", "\n", "            ", "_id", "+=", "'KFAC'", "\n", "_id", "+=", "TFOptimizers", ".", "_get_kfac_parameters", "(", "optimizer_kwargs", ")", "\n", "\n", "# see kfac/kfac/python/ops/kfac_utils/periodic_inv_cov_update_kfac_opt.py", "\n", "", "elif", "optimizer_name", "==", "'PeriodicInvCovUpdateKfacOpt'", ":", "\n", "            ", "_id", "+=", "'PKFAC'", "\n", "_id", "+=", "TFOptimizers", ".", "_get_kfac_parameters", "(", "optimizer_kwargs", ")", "\n", "_id", "+=", "'_ie'", "+", "str", "(", "optimizer_kwargs", "[", "\"invert_every\"", "]", ")", "\n", "_id", "+=", "'_cue'", "+", "str", "(", "optimizer_kwargs", "[", "\"cov_update_every\"", "]", ")", "\n", "\n", "# see kfac/kfac/python/ops/kfac_utils/async_inv_cov_update_kfac_opt.py", "\n", "# (not of particular interests for the moment)", "\n", "", "elif", "optimizer_name", "==", "'AsyncInvCovUpdateKfacOpt'", ":", "\n", "            ", "_id", "+=", "'AKFAC'", "\n", "_id", "+=", "TFOptimizers", ".", "_get_kfac_parameters", "(", "optimizer_kwargs", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'NaturalBackPropagationOptimizer'", ":", "\n", "            ", "_id", "+=", "'NBP'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_d'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"damping\"", "]", ")", "\n", "_id", "+=", "'_me'", "+", "str", "(", "optimizer_kwargs", "[", "\"memory_efficient\"", "]", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'NaturalGradientOptimizer'", ":", "\n", "            ", "_id", "+=", "'NG'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_d'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"damping\"", "]", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'DropOneLogitGradientDescentOptimizer'", ":", "\n", "            ", "_id", "+=", "'OLGD'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'WakeSleepOptimizer'", ":", "\n", "            ", "_id", "+=", "'WSO'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "(", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'WakeSleepGradientDescentOptimizer'", ":", "\n", "            ", "_id", "+=", "'WSGDO'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "(", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'ReweightedWakeSleepOptimizer'", ":", "\n", "            ", "_id", "+=", "'RWSO'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "(", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "_id", "+=", "'_qb'", "+", "str", "(", "optimizer_kwargs", "[", "\"q_baseline\"", "]", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'BidirectionalReweightedWakeSleepOptimizer'", ":", "\n", "            ", "_id", "+=", "'BiO'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "(", "\n", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'NaturalWakeSleepOptimizer'", ":", "\n", "            ", "_id", "+=", "'NWSO'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_dp'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", ")", "\n", "_id", "+=", "(", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'NaturalWakeSleepOptimizerAlternate'", ":", "\n", "            ", "_id", "+=", "'NWSOAL'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_dp'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", ")", "\n", "_id", "+=", "(", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "_id", "+=", "'_ks'", "+", "str", "(", "optimizer_kwargs", "[", "\"k_step_update\"", "]", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'NaturalReweightedWakeSleepOptimizerAlternate'", ":", "\n", "            ", "_id", "+=", "'NRWSOAL'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_dp'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", ")", "\n", "_id", "+=", "(", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "_id", "+=", "'_ks'", "+", "str", "(", "optimizer_kwargs", "[", "\"k_step_update\"", "]", ")", "\n", "_id", "+=", "'_qb'", "+", "str", "(", "optimizer_kwargs", "[", "\"q_baseline\"", "]", ")", "\n", "\n", "", "elif", "optimizer_name", "==", "'NaturalBidirectionalOptimizer'", ":", "\n", "            ", "_id", "+=", "'NBiDO'", "\n", "_id", "+=", "'_lr'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "_id", "+=", "'_dp'", "+", "get_lr_id", "(", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", ")", "\n", "_id", "+=", "(", "'_po'", "+", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "and", "optimizer_kwargs", "[", "\n", "\"post_optimizer\"", "]", "is", "not", "None", "else", "'_poGD'", ")", "\n", "_id", "+=", "'_ks'", "+", "str", "(", "optimizer_kwargs", "[", "\"k_step_update\"", "]", ")", "\n", "_id", "+=", "'_qb'", "+", "str", "(", "optimizer_kwargs", "[", "\"q_baseline\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"training algorithm not recognized: %s \"", ",", "optimizer_name", ")", "\n", "\n", "", "return", "_id", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.TFOptimizers.get_ilr_id": [[11, 16], ["isinstance", "str", "map"], "function", ["None"], ["def", "get_ilr_id", "(", "ilr", ")", ":", "\n", "    ", "if", "isinstance", "(", "ilr", ",", "list", ")", ":", "\n", "        ", "return", "\"_\"", ".", "join", "(", "map", "(", "str", ",", "ilr", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "str", "(", "ilr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Const.SSA1Const.__init__": [[32, 46], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "beta", "=", "0.7", ",", "k", "=", "2.0", ",", "use_locking", "=", "False", ",", "name", "=", "'SSA1Const'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "SSA1Const", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_beta", "=", "beta", "\n", "self", ".", "_k", "=", "k", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_beta_t", "=", "None", "\n", "self", ".", "_k_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Const.SSA1Const._prepare": [[50, 54], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_beta_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_beta", ",", "name", "=", "'beta'", ")", "\n", "self", ".", "_k_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_k", ",", "name", "=", "'k'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Const.SSA1Const._create_slots": [[58, 63], ["SSA1Const.SSA1Const._zeros_slot", "SSA1Const.SSA1Const._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is the accumulator obtained from the discrete-type velocity. It is denoted by 'p^{k+1}'", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"old_accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Const.SSA1Const._apply_dense": [[81, 108], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "SSA1Const.SSA1Const.get_slot", "SSA1Const.SSA1Const.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign_add"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "beta_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_beta_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "k_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_k_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifiers 'old_accum' and 'accum' from '_create_slots()'", "\n", "old_accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"old_accum\"", ")", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "# 3rd step: we have the SSA1 constant momentum formula 'accum_t <- accum_t * beta^k * (1-lr*beta)*(2*beta^2-2*beta+1) - lr^2 * beta^{k+1} * grad', i.e. 'p^{k+1}' from Defazio", "\n", "old_accum_t", "=", "state_ops", ".", "assign", "(", "old_accum", ",", "accum", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum_t", "]", ")", ":", "\n", "            ", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "(", "beta_t", "**", "k_t", ")", "*", "(", "1", "-", "lr_t", "*", "beta_t", ")", "*", "(", "\n", "2", "*", "(", "beta_t", "**", "2", ")", "-", "2", "*", "beta_t", "+", "1", ")", "*", "accum", "-", "(", "lr_t", "**", "2", ")", "*", "(", "beta_t", "**", "(", "k_t", "+", "1", ")", ")", "*", "grad", ",", "\n", "use_locking", "=", "False", ")", "\n", "\n", "\n", "# 4th step: variables updates by using 'var_update <- var + ( accum + old_accum * (beta * (1-lr*beta) - 1)  - lr^2 * grad)', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "# We use 'state_ops.add' instead of 'state_ops.sub'", "\n", "", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum", ",", "accum_t", "]", ")", ":", "\n", "            ", "var_update", "=", "state_ops", ".", "assign_add", "(", "var", ",", "accum_t", "+", "old_accum_t", "*", "(", "beta_t", "*", "(", "1", "-", "lr_t", "*", "beta_t", ")", "-", "1", ")", "-", "(", "lr_t", "**", "2", ")", "*", "grad", ")", "\n", "\n", "# 5th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "old_accum_t", ",", "accum_t", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.SSA1Const.SSA1Const._apply_sparse": [[111, 113], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.check_decay_kwargs": [[31, 39], ["Exception"], "function", ["None"], ["def", "check_decay_kwargs", "(", "kwargs", ")", ":", "\n", "    ", "has_decay_epochs", "=", "\"decay_epochs\"", "in", "kwargs", "\n", "has_decay_steps", "=", "\"decay_steps\"", "in", "kwargs", "\n", "\n", "if", "has_decay_epochs", "and", "has_decay_steps", ":", "\n", "        ", "raise", "Exception", "(", "\"can only have decay_steps or decay_epochs in the arguments for the learning rate, not both.\"", ")", "\n", "\n", "", "return", "has_decay_epochs", ",", "has_decay_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.convert_decay_epochs_in_steps": [[40, 48], ["LearningRates.check_decay_kwargs", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.check_decay_kwargs"], ["", "def", "convert_decay_epochs_in_steps", "(", "kwargs", ",", "n_batchs_per_epoch", ")", ":", "\n", "    ", "has_decay_epochs", ",", "has_decay_steps", "=", "check_decay_kwargs", "(", "kwargs", ")", "\n", "\n", "if", "has_decay_epochs", ":", "\n", "        ", "decay_epochs", "=", "kwargs", ".", "pop", "(", "\"decay_epochs\"", ")", "\n", "kwargs", "[", "'decay_steps'", "]", "=", "decay_epochs", "*", "n_batchs_per_epoch", "\n", "\n", "", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.decay_id": [[49, 56], ["LearningRates.check_decay_kwargs"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.check_decay_kwargs"], ["", "def", "decay_id", "(", "kwargs", ")", ":", "\n", "    ", "has_decay_epochs", ",", "has_decay_steps", "=", "check_decay_kwargs", "(", "kwargs", ")", "\n", "\n", "if", "has_decay_steps", ":", "\n", "        ", "return", "\".s\"", "+", "\"{:.0e}\"", ".", "format", "(", "kwargs", "[", "\"decay_steps\"", "]", ")", "\n", "", "elif", "has_decay_epochs", ":", "\n", "        ", "return", "\".e\"", "+", "\"{:.4g}\"", ".", "format", "(", "kwargs", "[", "\"decay_epochs\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.process_learning_rate": [[57, 104], ["isinstance", "tensorflow.identity", "isinstance", "isinstance", "tensorflow.constant", "learning_rate.items", "tensorflow.summary.scalar", "Exception", "ValueError", "isinstance", "ValueError", "tensorflow.cond", "copy.deepcopy", "LearningRates.convert_decay_epochs_in_steps", "getattr", "convert_decay_epochs_in_steps.update", "tensorflow.less", "str", "getattr.", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.convert_decay_epochs_in_steps"], ["", "", "def", "process_learning_rate", "(", "learning_rate", ",", "global_step", ",", "n_batchs_per_epoch", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        global_step:\n        learning_rate: can be either a number, a dictionary {\"step\": lr}, e.g. {100:0.1, 1000:0.001} or a particular keyword\n\n    Returns:\n        the processed learning rate, ready to be taken by the optimizer (if a schedule was requested returns a tf node)\n    \"\"\"", "\n", "\n", "lr", "=", "None", "\n", "\n", "if", "isinstance", "(", "learning_rate", ",", "str", ")", ":", "\n", "        ", "if", "learning_rate", "in", "known_schedules", ":", "\n", "            ", "learning_rate", "=", "known_schedules", "[", "learning_rate", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"requested schedule: %s not found in known_schedules: %s\"", "%", "(", "learning_rate", ",", "known_schedules", ")", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "learning_rate", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "        ", "lr", "=", "learning_rate", "\n", "\n", "", "elif", "isinstance", "(", "learning_rate", ",", "tuple", ")", ":", "\n", "        ", "lr_min", ",", "lr_name", ",", "lr_kwargs", "=", "learning_rate", "\n", "lr_kwargs", "=", "copy", ".", "deepcopy", "(", "lr_kwargs", ")", "\n", "lr_kwargs", "=", "convert_decay_epochs_in_steps", "(", "lr_kwargs", ",", "n_batchs_per_epoch", ")", "\n", "lr_method", "=", "getattr", "(", "tf", ".", "train", ",", "lr_name", ")", "\n", "lr_kwargs", ".", "update", "(", "{", "\"global_step\"", ":", "global_step", "}", ")", "\n", "lr", "=", "lr_min", "+", "lr_method", "(", "**", "lr_kwargs", ")", "\n", "\n", "# instantiate lr node if lr is None and learning_rate is a dict at this point", "\n", "", "if", "lr", "is", "None", "and", "isinstance", "(", "learning_rate", ",", "dict", ")", ":", "\n", "        ", "if", "not", "0", "in", "learning_rate", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"learning rate schedule must specify, learning rate for step 0. Found schedule: %s\"", "%", "learning_rate", ")", "\n", "\n", "", "lr", "=", "tf", ".", "constant", "(", "learning_rate", "[", "0", "]", ")", "\n", "# THIS IS PASSED FROM OUTSIDE global_step = tf.train.get_or_create_global_step()", "\n", "for", "key", ",", "value", "in", "learning_rate", ".", "items", "(", ")", ":", "\n", "            ", "lr", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "less", "(", "global_step", ",", "key", ")", ",", "lambda", ":", "lr", ",", "lambda", ":", "tf", ".", "constant", "(", "value", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"learning_rate\"", ",", "lr", ")", "\n", "\n", "", "if", "lr", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"oops, something went wrong... could not process learning rate {}\"", ".", "format", "(", "str", "(", "learning_rate", ")", ")", ")", "\n", "\n", "", "return", "tf", ".", "identity", "(", "lr", ",", "name", "=", "\"learning_rate\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.get_lr_id": [[106, 146], ["isinstance", "isinstance", "ValueError", "str", "isinstance", "isinstance", "LearningRates.lr_method_id", "learning_rate.keys", "learning_rate.values", "zip", "str", "name.append"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.lr_method_id"], ["", "def", "get_lr_id", "(", "learning_rate", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        learning_rate: can be either a number, a dictionary {\"step\": lr}, e.g. {100:0.1, 1000:0.001} or a particular keyword,\n                    or a tuple (lr_min, lr_name, lr_kwargs)\n\n    Returns:\n        the id for the learning rate\n    \"\"\"", "\n", "\n", "_id", "=", "\"\"", "\n", "if", "isinstance", "(", "learning_rate", ",", "str", ")", ":", "\n", "        ", "if", "learning_rate", "in", "known_schedules_short", ":", "\n", "            ", "_id", "+=", "\"S\"", "\n", "_id", "+=", "known_schedules_short", "[", "learning_rate", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"requested schedule: %s not found in known_schedules: %s\"", "%", "(", "learning_rate", ",", "known_schedules_short", ")", ")", "\n", "\n", "\n", "", "", "elif", "isinstance", "(", "learning_rate", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "        ", "_id", "+=", "str", "(", "learning_rate", ")", "\n", "\n", "", "elif", "isinstance", "(", "learning_rate", ",", "tuple", ")", ":", "\n", "        ", "lr_min", ",", "lr_name", ",", "lr_kwargs", "=", "learning_rate", "\n", "if", "lr_min", ">", "0.", ":", "\n", "            ", "_id", "+=", "lr_method_id", "(", "lr_name", ",", "lr_kwargs", ")", "\n", "_id", "+=", "\"m\"", "+", "str", "(", "lr_min", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "learning_rate", ",", "dict", ")", ":", "\n", "        ", "keys", "=", "learning_rate", ".", "keys", "(", ")", "\n", "val", "=", "learning_rate", ".", "values", "(", ")", "\n", "name", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "zip", "(", "keys", ",", "val", ")", ":", "\n", "            ", "name", ".", "append", "(", "\"{}r{}\"", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "", "n", "=", "\"_\"", ".", "join", "(", "name", ")", "\n", "\n", "_id", "+=", "n", "\n", "\n", "", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.lr_method_id": [[158, 183], ["LearningRates.decay_id", "LearningRates.decay_id", "print", "print", "ValueError"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.decay_id", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.LearningRates.decay_id"], ["def", "lr_method_id", "(", "lr_name", ",", "lr_kwargs", ")", ":", "\n", "    ", "\"\"\"Creates the id for the learning rate method.\n    \"\"\"", "\n", "\n", "# listWithPoints = lambda x: \".\".join(re.sub('[( )\\[\\]]', '', str(x)).replace(' ', '').split(\",\"))", "\n", "\n", "methodid", "=", "lr_method_name_short", "[", "lr_name", "]", "\n", "\n", "if", "lr_name", "==", "EXPONENTIAL_DECAY", ":", "\n", "        ", "methodid", "+=", "\".i\"", "+", "\"{:.0e}\"", ".", "format", "(", "lr_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "methodid", "+=", "decay_id", "(", "lr_kwargs", ")", "\n", "methodid", "+=", "\".r\"", "+", "\"{}\"", ".", "format", "(", "lr_kwargs", "[", "\"decay_rate\"", "]", ")", "\n", "\n", "", "elif", "lr_name", "==", "POLYNOMIAL_DECAY", ":", "\n", "        ", "methodid", "+=", "\".i\"", "+", "\"{:.0e}\"", ".", "format", "(", "lr_kwargs", "[", "\"learning_rate\"", "]", ")", "\n", "methodid", "+=", "decay_id", "(", "lr_kwargs", ")", "\n", "methodid", "+=", "\".r\"", "+", "\"{}\"", ".", "format", "(", "lr_kwargs", "[", "\"end_learning_rate\"", "]", ")", "\n", "methodid", "+=", "\".p\"", "+", "\"{}\"", ".", "format", "(", "lr_kwargs", "[", "\"power\"", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'----------------------'", ")", "\n", "print", "(", "'ERROR '", ",", "lr_name", ")", "\n", "raise", "ValueError", "(", "\"id rule for learning rate `%s` has to be implemented.\"", "%", "lr_name", ")", "\n", "\n", "", "return", "methodid", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovNonconst.ExtendedNesterovNonconst.__init__": [[35, 50], ["tensorflow.python.training.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "learning_rate", "=", "1e-2", ",", "alpha", "=", "4", ",", "beta", "=", "0.1", ",", "gamma", "=", "0.5", ",", "use_locking", "=", "False", ",", "name", "=", "'ExtendedNesterovNonconst'", ")", ":", "\n", "# Call the constructor of the 'Optimizer' superclass using the parameters 'use_locking' and 'name'", "\n", "        ", "super", "(", "ExtendedNesterovNonconst", ",", "self", ")", ".", "__init__", "(", "use_locking", ",", "name", ")", "\n", "# Initialize the private Python variables of the current subclass", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "self", ".", "_beta", "=", "beta", "\n", "self", ".", "_gamma", "=", "gamma", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "# Initialize the private 'Tensor' objects of the current subclass", "\n", "self", ".", "_lr_t", "=", "None", "\n", "self", ".", "_alpha_t", "=", "None", "\n", "self", ".", "_beta_t", "=", "None", "\n", "self", ".", "_gamma_t", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovNonconst.ExtendedNesterovNonconst._prepare": [[55, 60], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor"], "methods", ["None"], ["", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "self", ".", "_lr_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_lr", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "_alpha_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_alpha", ",", "name", "=", "'alpha'", ")", "\n", "self", ".", "_beta_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_beta", ",", "name", "=", "'beta'", ")", "\n", "self", ".", "_gamma_t", "=", "ops", ".", "convert_to_tensor", "(", "self", ".", "_gamma", ",", "name", "=", "'gamma'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovNonconst.ExtendedNesterovNonconst._create_slots": [[65, 71], ["ExtendedNesterovNonconst.ExtendedNesterovNonconst._zeros_slot", "ExtendedNesterovNonconst.ExtendedNesterovNonconst._zeros_slot", "ExtendedNesterovNonconst.ExtendedNesterovNonconst._zeros_slot"], "methods", ["None"], ["", "def", "_create_slots", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "for", "v", "in", "var_list", ":", "\n", "# The accumulator variable is 'p^{k+1}' in the work of Defazio", "\n", "            ", "self", ".", "_zeros_slot", "(", "v", ",", "\"old_accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"accum\"", ",", "self", ".", "_name", ")", "\n", "self", ".", "_zeros_slot", "(", "v", ",", "\"curr_it\"", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovNonconst.ExtendedNesterovNonconst._apply_dense": [[89, 128], ["tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "ExtendedNesterovNonconst.ExtendedNesterovNonconst.get_slot", "ExtendedNesterovNonconst.ExtendedNesterovNonconst.get_slot", "ExtendedNesterovNonconst.ExtendedNesterovNonconst.get_slot", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.ops.control_flow_ops.group", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.state_ops.assign_sub"], "methods", ["None"], ["", "", "def", "_apply_dense", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "# 1st step: we convert our 'Tensor' objects to have the type of the training variables", "\n", "        ", "lr_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_lr_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "alpha_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_alpha_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "beta_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_beta_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "gamma_t", "=", "math_ops", ".", "cast", "(", "self", ".", "_gamma_t", ",", "var", ".", "dtype", ".", "base_dtype", ")", "\n", "\n", "\n", "# 2nd step: we define the gradient accumulations, using the identifier 'accum' from '_create_slots()'", "\n", "# We also memorize the old accumulator, since we will update the 'accum' variable. Here, 'old_accum' is 'p^{k+1}'", "\n", "old_accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"old_accum\"", ")", "\n", "accum", "=", "self", ".", "get_slot", "(", "var", ",", "\"accum\"", ")", "\n", "\n", "\n", "# 3rd step: define the current iteration needed for the momentum inertial sequence", "\n", "# It must be converted to the same type as the trainable variables", "\n", "# We have here the inertial sequences 'alpha_n' and 'beta_n'", "\n", "curr_it", "=", "self", ".", "get_slot", "(", "var", ",", "\"curr_it\"", ")", "\n", "n", "=", "curr_it", "+", "1", "\n", "\n", "alpha_iteration", "=", "n", "/", "(", "n", "+", "alpha_t", ")", "\n", "beta_iteration", "=", "(", "n", "*", "gamma_t", "+", "beta_t", ")", "/", "(", "n", "+", "alpha_t", ")", "\n", "beta_iteration_plus_1", "=", "(", "(", "n", "+", "1", ")", "*", "gamma_t", "+", "beta_t", ")", "/", "(", "n", "+", "alpha_t", "+", "1", ")", "\n", "\n", "\n", "# 4th step: we have the Extended Nesterov formula 'accum_t <- accum_t * alpha_t + grad', i.e. 'p^{k+1}' from Defazio", "\n", "# We update 'accum' by assigning the value 'momentum_t * accum + grad' to it. Furthermore, the new value is return in the 'Tensor' object 'accum_t'", "\n", "old_accum_t", "=", "state_ops", ".", "assign", "(", "old_accum", ",", "accum", ")", "\n", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum_t", "]", ")", ":", "\n", "            ", "accum_t", "=", "state_ops", ".", "assign", "(", "accum", ",", "alpha_iteration", "*", "accum", "+", "grad", ",", "use_locking", "=", "False", ")", "\n", "\n", "# 5th step: variables updates by using 'var_update <- var - ( lr_t * grad + lr_t * beta_t * accum_t + (alpha_t-beta_t) * old_accum )', i.e. 'x^{k+1}' from Defazio", "\n", "# Here, 'accum_t' is 'p^{k+1}' because was already updated before", "\n", "", "with", "ops", ".", "control_dependencies", "(", "[", "old_accum", ",", "accum_t", "]", ")", ":", "\n", "            ", "var_update", "=", "state_ops", ".", "assign_sub", "(", "var", ",", "lr_t", "*", "grad", "+", "lr_t", "*", "beta_iteration_plus_1", "*", "accum_t", "+", "(", "alpha_iteration", "-", "beta_iteration", ")", "*", "old_accum_t", ")", "\n", "\n", "# 6th step: return the updates, i.e. we return the Graph 'Operation' that will group multiple 'Tensor' ops.", "\n", "# For more complex algorithms, the 'control_flow_ops.group' is used in the '_finish()' function, after '_apply_dense()'", "\n", "", "return", "control_flow_ops", ".", "group", "(", "*", "[", "var_update", ",", "old_accum_t", ",", "accum_t", ",", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ExtendedNesterovNonconst.ExtendedNesterovNonconst._apply_sparse": [[131, 133], ["NotImplementedError"], "methods", ["None"], ["", "def", "_apply_sparse", "(", "self", ",", "grad", ",", "var", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Sparse gradient updates are not supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalBidirectionalOptimizer.NaturalBidirectionalOptimizer.__init__": [[8, 21], ["core.optimizers.NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate.__init__", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "optimizer_kwargs", ")", "\n", "\n", "self", ".", "_b_size", "=", "self", ".", "_model", ".", "b_size", "\n", "self", ".", "_n_samples", "=", "self", ".", "_model", ".", "n_z_samples", "\n", "\n", "self", ".", "_sleep_balance", "=", "0.0", "\n", "self", ".", "_wake_q", "=", "1.0", "-", "self", ".", "_sleep_balance", "\n", "self", ".", "_sleep_q", "=", "self", ".", "_sleep_balance", "\n", "\n", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "0.", ")", "\n", "if", "optimizer_kwargs", "[", "\"q_baseline\"", "]", ":", "\n", "            ", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "1.", ")", "/", "tf", ".", "cast", "(", "self", ".", "_n_samples", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalBidirectionalOptimizer.NaturalBidirectionalOptimizer.get_unnormalized_weigth_log": [[22, 24], ["tensorflow.constant"], "methods", ["None"], ["", "", "def", "get_unnormalized_weigth_log", "(", "self", ",", "log_probs_p", ",", "log_probs_q", ")", ":", "\n", "        ", "return", "tf", ".", "constant", "(", "0.5", ")", "*", "(", "log_probs_p", "-", "log_probs_q", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.BidirectionalReweightedWakeSleepOptimizer.BidirectionalReweightedWakeSleepOptimizer.__init__": [[8, 21], ["core.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.__init__", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "optimizer_kwargs", ")", "\n", "\n", "self", ".", "_b_size", "=", "self", ".", "_model", ".", "b_size", "\n", "self", ".", "_n_samples", "=", "self", ".", "_model", ".", "n_z_samples", "\n", "\n", "self", ".", "_sleep_balance", "=", "0.0", "\n", "self", ".", "_wake_q", "=", "1.0", "-", "self", ".", "_sleep_balance", "\n", "self", ".", "_sleep_q", "=", "self", ".", "_sleep_balance", "\n", "\n", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "0.", ")", "\n", "if", "optimizer_kwargs", "[", "\"q_baseline\"", "]", ":", "\n", "            ", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "1.", ")", "/", "tf", ".", "cast", "(", "self", ".", "_n_samples", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.BidirectionalReweightedWakeSleepOptimizer.BidirectionalReweightedWakeSleepOptimizer.get_unnormalized_weigth_log": [[22, 24], ["tensorflow.constant"], "methods", ["None"], ["", "", "def", "get_unnormalized_weigth_log", "(", "self", ",", "log_probs_p", ",", "log_probs_q", ")", ":", "\n", "        ", "return", "tf", ".", "constant", "(", "0.5", ")", "*", "(", "log_probs_p", "-", "log_probs_q", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.__init__": [[14, 72], ["super().__init__", "tensorflow.python.training.momentum.MomentumOptimizer", "tensorflow.python.training.rmsprop.RMSPropOptimizer", "tensorflow.python.training.adam.AdamOptimizer", "tensorflow.contrib.opt.NadamOptimizer", "tensorflow.python.training.momentum.MomentumOptimizer", "argo.core.optimizers.NesterovConst.NesterovConst", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "self", ".", "_model", "=", "optimizer_kwargs", "[", "\"model\"", "]", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "optimizer_kwargs", "[", "\"individual_learning_rate\"", "]", "\n", "\n", "self", ".", "_learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", "\n", "self", ".", "_rescale_learning_rate", "=", "optimizer_kwargs", "[", "\"rescale_learning_rate\"", "]", "\n", "self", ".", "_d_p", "=", "None", "\n", "self", ".", "_n_reg", "=", "None", "\n", "\n", "post_optimizer", "=", "optimizer_kwargs", "[", "\"post_optimizer\"", "]", "if", "\"post_optimizer\"", "in", "optimizer_kwargs", "else", "None", "\n", "if", "post_optimizer", "is", "None", ":", "\n", "            ", "self", ".", "_post_optimizer", "=", "super", "(", ")", "\n", "\n", "", "elif", "post_optimizer", "==", "\"Momentum\"", ":", "\n", "            ", "self", ".", "_post_optimizer", "=", "MomentumOptimizer", "(", "learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "\n", "momentum", "=", "0.95", ",", "\n", "use_locking", "=", "False", ",", "\n", "name", "=", "\"MomentumOptimizer\"", ")", "\n", "\n", "", "elif", "post_optimizer", "==", "\"RMSProp\"", ":", "\n", "            ", "self", ".", "_post_optimizer", "=", "RMSPropOptimizer", "(", "learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "\n", "decay", "=", "0.9", ",", "\n", "epsilon", "=", "1e-5", ",", "\n", "use_locking", "=", "False", ",", "\n", "name", "=", "\"RMSPropOptimizer\"", ")", "\n", "\n", "", "elif", "post_optimizer", "==", "\"Adam\"", ":", "\n", "            ", "self", ".", "_post_optimizer", "=", "AdamOptimizer", "(", "learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "\n", "beta1", "=", "0.9", ",", "\n", "beta2", "=", "0.999", ",", "\n", "epsilon", "=", "1e-8", ",", "\n", "use_locking", "=", "False", ",", "\n", "name", "=", "\"AdamOptimizer\"", ")", "\n", "", "elif", "post_optimizer", "==", "\"Nadam\"", ":", "\n", "            ", "self", ".", "_post_optimizer", "=", "NadamOptimizer", "(", "learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "\n", "beta1", "=", "0.9", ",", "\n", "beta2", "=", "0.999", ",", "\n", "epsilon", "=", "1e-8", ",", "\n", "use_locking", "=", "False", ",", "\n", "name", "=", "\"NadamOptimizer\"", ")", "\n", "\n", "", "elif", "post_optimizer", "==", "\"Nesterov\"", ":", "\n", "            ", "self", ".", "_post_optimizer", "=", "MomentumOptimizer", "(", "learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "\n", "momentum", "=", "0.95", ",", "\n", "use_locking", "=", "False", ",", "\n", "use_nesterov", "=", "True", ",", "\n", "name", "=", "\"NesterovMomentumOptimizer\"", ")", "\n", "", "elif", "post_optimizer", "==", "\"NesterovConst\"", ":", "\n", "            ", "self", ".", "_post_optimizer", "=", "NesterovConst", "(", "model", "=", "self", ".", "_model", ",", "\n", "learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", ",", "\n", "use_locking", "=", "False", ",", "\n", "name", "=", "\"NesterovConstOptimizer\"", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"There is no such post optimizer defined. Must be: None, Adam, Momentum, RMSProp\"", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "self", ".", "_learning_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr": [[73, 83], ["isinstance", "list", "isinstance", "len", "len", "len", "map", "Exception", "len", "float"], "methods", ["None"], ["", "def", "check_ilr", "(", "self", ",", "individual_learning_rate", ",", "hr", ")", ":", "\n", "        ", "if", "isinstance", "(", "individual_learning_rate", ",", "list", ")", ":", "\n", "            ", "assert", "len", "(", "individual_learning_rate", ")", "==", "len", "(", "\n", "hr", ")", ",", "\"Individual learning rates have to equal in length the number of layers, {} and {}\"", ".", "format", "(", "\n", "individual_learning_rate", ",", "len", "(", "hr", ")", ")", "\n", "return", "list", "(", "map", "(", "float", ",", "individual_learning_rate", ")", ")", "\n", "", "elif", "isinstance", "(", "individual_learning_rate", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "return", "[", "float", "(", "individual_learning_rate", ")", "]", "*", "len", "(", "hr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"You gave an unexpected data type as Individual learning rates\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.apply_gradients": [[84, 86], ["WakeSleepOptimizer.WakeSleepOptimizer._post_optimizer.apply_gradients"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.apply_gradients"], ["", "", "def", "apply_gradients", "(", "self", ",", "grads_and_vars", ",", "global_step", "=", "None", ",", "name", "=", "\"WSOM\"", ")", ":", "\n", "        ", "return", "self", ".", "_post_optimizer", ".", "apply_gradients", "(", "grads_and_vars", "=", "grads_and_vars", ",", "global_step", "=", "global_step", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.compute_gradients": [[87, 145], ["WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "numpy.all", "WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "[].mean", "tensorflow.multiply", "range", "tensorflow.einsum", "WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "range", "ValueError", "zip", "tensorflow.reduce_mean", "[].mean", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.einsum", "tensorflow.multiply", "len", "WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "[].mean", "tensorflow.multiply", "tensorflow.multiply", "WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "g.name.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars"], ["", "def", "compute_gradients", "(", "self", ",", "phase", ",", "*", "args", ",", "**", "kw", ")", ":", "\n", "\n", "        ", "weights", "=", "[", "]", "\n", "grads", "=", "[", "]", "\n", "if", "phase", "==", "PHASE_WAKE", ":", "\n", "            ", "hrw", "=", "self", ".", "_model", ".", "_hrw", "\n", "hgw", "=", "self", ".", "_model", ".", "_hgw", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrw", ")", "\n", "\n", "weights", "=", "[", "self", ".", "_get_bias", "(", ")", "]", "# Size of the last hidden layer", "\n", "difference_b", "=", "hrw", "[", "-", "1", "]", "[", "1", "]", "-", "hgw", "[", "-", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "grads", "=", "[", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "difference_b", ",", "\n", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "len", "(", "hrw", ")", "-", "1", ")", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrw", ")", "-", "1", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "weights", "+=", "[", "*", "self", ".", "_get_layer_vars", "(", "\"gen_net\"", ",", "\"l_g_{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "difference_b", "=", "hrw", "[", "i", "]", "[", "1", "]", "-", "hgw", "[", "i", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hrw", "[", "i", "+", "1", "]", "[", "1", "]", ")", "\n", "\n", "grads", "+=", "[", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Ww{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "", "elif", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "hrs", "=", "self", ".", "_model", ".", "_hrs", "\n", "hgs", "=", "self", ".", "_model", ".", "_hgs", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrs", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrs", ")", "-", "1", ")", ":", "\n", "                ", "weights", "+=", "[", "*", "self", ".", "_get_layer_vars", "(", "\"rec_net\"", ",", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "difference_b", "=", "hgs", "[", "i", "+", "1", "]", "[", "1", "]", "-", "hrs", "[", "i", "+", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hgs", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "grads", "+=", "[", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Sw{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Sb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"invalid value for phase '{}'\"", ".", "format", "(", "phase", ")", ")", "\n", "\n", "", "lr", "=", "1.", "\n", "if", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "lr", "*=", "self", ".", "_rescale_learning_rate", "\n", "\n", "", "regs", "=", "self", ".", "get_regularizers", "(", "weights", ")", "\n", "\n", "grads_and_vars_not_none", "=", "[", "(", "tf", ".", "multiply", "(", "-", "lr", ",", "g", ",", "name", "=", "\"g_\"", "+", "g", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ")", "+", "r", ",", "v", ")", "for", "(", "g", ",", "r", ",", "v", ")", "in", "\n", "zip", "(", "grads", ",", "regs", ",", "weights", ")", "if", "g", "is", "not", "None", "]", "\n", "\n", "assert", "np", ".", "all", "(", "[", "g", ".", "shape", "==", "v", ".", "shape", "for", "(", "g", ",", "v", ")", "in", "\n", "grads_and_vars_not_none", "]", ")", ",", "\"The shapes of weights and gradients are not the same\"", "\n", "\n", "return", "grads_and_vars_not_none", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers": [[146, 152], ["len", "tensorflow.gradients", "tensorflow.add_n"], "methods", ["None"], ["", "def", "get_regularizers", "(", "self", ",", "weights", ")", ":", "\n", "        ", "regs", "=", "[", "0.0", "]", "*", "len", "(", "weights", ")", "\n", "if", "self", ".", "_model", ".", "regularizers", ":", "\n", "            ", "loss", "=", "0.0", "+", "tf", ".", "add_n", "(", "self", ".", "_model", ".", "regularizers", ",", "name", "=", "\"regularization\"", ")", "\n", "regs", "=", "tf", ".", "gradients", "(", "loss", ",", "weights", ")", "\n", "", "return", "regs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars": [[153, 173], ["tensorflow.get_collection", "tensorflow.get_collection", "Exception", "Exception", "len", "Exception", "len", "Exception", "str", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_layer_vars", "(", "phase", ",", "layer_name", ")", ":", "\n", "        ", "layer_scope_name", "=", "\".*\"", "+", "phase", "+", "\"/\"", "+", "layer_name", "+", "\"/.*\"", "\n", "ws", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "layer_scope_name", "+", "\"/w:0\"", ")", "\n", "if", "not", "ws", ":", "\n", "            ", "raise", "Exception", "(", "\"found no weights in scope: %s\"", "%", "layer_scope_name", ")", "\n", "", "elif", "len", "(", "ws", ")", ">", "1", ":", "\n", "            ", "raise", "Exception", "(", "\"found more than one weight in scope: %s\"", "\n", "\"\\n%s\"", "%", "(", "layer_scope_name", ",", "str", "(", "ws", ")", ")", ")", "\n", "", "w", "=", "ws", "[", "0", "]", "\n", "\n", "bs", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "layer_scope_name", "+", "\"/b:0\"", ")", "\n", "if", "not", "bs", ":", "\n", "            ", "raise", "Exception", "(", "\"found no biases in scope: %s\"", "%", "layer_scope_name", ")", "\n", "", "elif", "len", "(", "bs", ")", ">", "1", ":", "\n", "            ", "raise", "Exception", "(", "\"found more than one bias in scope: %s\"", "\n", "\"\\n%s\"", "%", "(", "layer_scope_name", ",", "str", "(", "bs", ")", ")", ")", "\n", "", "b", "=", "bs", "[", "0", "]", "\n", "\n", "return", "w", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias": [[174, 180], ["tensorflow.get_collection", "Exception"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_bias", "(", ")", ":", "\n", "        ", "bs", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "\".*/top_bias/linear/b:0\"", ")", "\n", "if", "not", "bs", ":", "\n", "            ", "raise", "Exception", "(", "\"found no prior bias\"", ")", "\n", "", "return", "bs", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepGradientDescentOptimizer.WakeSleepGradientDescentOptimizer.__init__": [[11, 24], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "self", ".", "_model", "=", "optimizer_kwargs", "[", "\"model\"", "]", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "optimizer_kwargs", "[", "\"individual_learning_rate\"", "]", "\n", "\n", "self", ".", "_learning_rate", "=", "optimizer_kwargs", "[", "\"learning_rate\"", "]", "\n", "self", ".", "_rescale_learning_rate", "=", "optimizer_kwargs", "[", "\"rescale_learning_rate\"", "]", "\n", "\n", "self", ".", "_d_p", "=", "None", "\n", "\n", "self", ".", "_grads_w", "=", "[", "]", "\n", "self", ".", "_grads_s", "=", "[", "]", "\n", "super", "(", ")", ".", "__init__", "(", "self", ".", "_learning_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepGradientDescentOptimizer.WakeSleepGradientDescentOptimizer.compute_gradients": [[25, 87], ["numpy.all", "range", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "WakeSleepGradientDescentOptimizer.WakeSleepGradientDescentOptimizer.get_loss", "tensorflow.gradients", "range", "ValueError", "len", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "WakeSleepGradientDescentOptimizer.WakeSleepGradientDescentOptimizer.get_loss", "tensorflow.gradients", "len", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "zip", "len", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "zip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepGradientDescentOptimizer.WakeSleepGradientDescentOptimizer.get_loss", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepGradientDescentOptimizer.WakeSleepGradientDescentOptimizer.get_loss", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars"], ["", "def", "compute_gradients", "(", "self", ",", "phase", ",", "loss", ",", "*", "args", ",", "**", "kw", ")", ":", "\n", "\n", "        ", "hgw", "=", "self", ".", "_model", ".", "_hgw", "\n", "hrw", "=", "self", ".", "_model", ".", "_hrw", "\n", "hrs", "=", "self", ".", "_model", ".", "_hrs", "\n", "hgs", "=", "self", ".", "_model", ".", "_hgs", "\n", "\n", "weights", "=", "[", "]", "\n", "grads_and_vars", "=", "[", "]", "\n", "if", "phase", "==", "PHASE_WAKE", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "hgw", ")", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "distr_p", "=", "hgw", "[", "i", "]", "[", "0", "]", "\n", "sample_q", "=", "tf", ".", "stop_gradient", "(", "hrw", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "distr_q", "=", "hrs", "[", "i", "]", "[", "0", "]", "\n", "sample_p", "=", "tf", ".", "stop_gradient", "(", "hgs", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "if", "i", "==", "len", "(", "hgw", ")", "-", "1", ":", "\n", "                    ", "current_weights", "=", "[", "WakeSleepOptimizer", ".", "_get_bias", "(", ")", "]", "# Size of the last hidden layer", "\n", "", "else", ":", "\n", "                    ", "current_weights", "=", "[", "*", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"gen_net\"", ",", "\"l_g_{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "likelihood", "=", "self", ".", "get_loss", "(", "distr_p", ",", "sample_q", ",", "distr_q", ",", "sample_p", ",", "phase", ")", "\n", "\n", "grad", "=", "tf", ".", "gradients", "(", "likelihood", ",", "current_weights", ")", "\n", "grads_and_vars", "+=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "zip", "(", "grad", ",", "current_weights", ")", "]", "\n", "\n", "weights", "+=", "current_weights", "\n", "", "self", ".", "_grads_w", "=", "grads_and_vars", "\n", "", "elif", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "hrs", ")", "-", "1", ")", ":", "\n", "                ", "distr_q", "=", "hrs", "[", "i", "+", "1", "]", "[", "0", "]", "\n", "sample_p", "=", "tf", ".", "stop_gradient", "(", "hgs", "[", "i", "+", "1", "]", "[", "1", "]", ")", "\n", "\n", "distr_p", "=", "hgw", "[", "i", "+", "1", "]", "[", "0", "]", "\n", "sample_q", "=", "tf", ".", "stop_gradient", "(", "hrw", "[", "i", "+", "1", "]", "[", "1", "]", ")", "\n", "\n", "sample_p", "=", "tf", ".", "stop_gradient", "(", "sample_p", ")", "\n", "likelihood", "=", "self", ".", "get_loss", "(", "distr_p", ",", "sample_q", ",", "distr_q", ",", "sample_p", ",", "phase", ")", "\n", "\n", "current_weights", "=", "[", "*", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"rec_net\"", ",", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "grad", "=", "tf", ".", "gradients", "(", "likelihood", ",", "current_weights", ")", "\n", "\n", "grads_and_vars", "+=", "[", "(", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "zip", "(", "grad", ",", "current_weights", ")", "]", "\n", "\n", "weights", "+=", "current_weights", "\n", "\n", "", "self", ".", "_grads_s", "=", "grads_and_vars", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"invalid value for phase '{}'\"", ".", "format", "(", "phase", ")", ")", "\n", "\n", "", "lr", "=", "1.", "\n", "if", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "lr", "*=", "self", ".", "_rescale_learning_rate", "\n", "\n", "", "grads_and_vars_not_none", "=", "[", "(", "lr", "*", "g", ",", "v", ")", "for", "(", "g", ",", "v", ")", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "\n", "assert", "np", ".", "all", "(", "[", "g", ".", "shape", "==", "v", ".", "shape", "for", "(", "g", ",", "v", ")", "in", "\n", "grads_and_vars_not_none", "]", ")", ",", "\"The shapes of weights and gradients are not the same\"", "\n", "\n", "return", "grads_and_vars_not_none", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepGradientDescentOptimizer.WakeSleepGradientDescentOptimizer.get_loss": [[88, 98], ["tensorflow.reduce_sum", "tensorflow.reduce_mean", "distr_q.log_prob", "distr_p.log_prob"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "get_loss", "(", "self", ",", "distr_p", ",", "sample_q", ",", "distr_q", ",", "sample_p", ",", "phase", ")", ":", "\n", "        ", "if", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "likelihood_per_node", "=", "-", "distr_q", ".", "log_prob", "(", "sample_p", ")", "\n", "", "else", ":", "\n", "            ", "likelihood_per_node", "=", "-", "distr_p", ".", "log_prob", "(", "sample_q", ")", "\n", "# sum over the layer", "\n", "", "likelihood_per_layer", "=", "tf", ".", "reduce_sum", "(", "likelihood_per_node", ",", "axis", "=", "-", "1", ")", "\n", "# average over the batch", "\n", "likelihood", "=", "tf", ".", "reduce_mean", "(", "likelihood_per_layer", ",", "axis", "=", "0", ")", "\n", "return", "likelihood", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate.__init__": [[13, 23], ["core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate.__init__", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "NaturalWakeSleepOptimizerAlternate", ".", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", "\n", "\n", "self", ".", "_sleep_balance", "=", "0.5", "\n", "self", ".", "_wake_q", "=", "1.0", "-", "self", ".", "_sleep_balance", "\n", "self", ".", "_sleep_q", "=", "self", ".", "_sleep_balance", "\n", "\n", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "0.", ")", "\n", "if", "optimizer_kwargs", "[", "\"q_baseline\"", "]", ":", "\n", "            ", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "1.", ")", "/", "tf", ".", "cast", "(", "self", ".", "_n_samples", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate.compute_gradients": [[24, 197], ["core.optimizers.NaturalWakeSleepOptimizer.get_diagonal_pad", "tensorflow.less_equal", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate.get_regularizers", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate._get_natural_regularizers", "numpy.all", "tensorflow.constant", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate.check_ilr", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "core.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.compute_normalized_weights", "tensorflow.einsum", "tensorflow.reduce_sum", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate._apply_fisher_multipliers", "range", "[].mean", "tensorflow.reshape", "tensorflow.multiply", "range", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.reduce_sum", "tensorflow.einsum", "tensorflow.reshape", "tensorflow.reduce_sum", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate._apply_fisher_multipliers", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.reduce_sum", "tensorflow.einsum", "tensorflow.reshape", "tensorflow.reduce_sum", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate._apply_fisher_multipliers", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate.check_ilr", "range", "ValueError", "zip", "[].get_probs", "tensorflow.reduce_mean", "[].mean", "tensorflow.reshape", "tensorflow.multiply", "tensorflow.multiply", "len", "[].mean", "tensorflow.reshape", "tensorflow.multiply", "tensorflow.multiply", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.einsum", "NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate._apply_fisher_multipliers", "len", "[].get_probs", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "[].get_probs", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "[].mean", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.reduce_sum.shape.as_list", "str", "str", "[].get_probs", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "tensorflow.reduce_sum.shape.as_list", "tensorflow.einsum.shape.as_list", "tensorflow.reduce_sum.shape.as_list", "tensorflow.einsum.shape.as_list", "str", "g.name.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.get_diagonal_pad", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.compute_normalized_weights", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "", "def", "compute_gradients", "(", "self", ",", "phase", ",", "*", "args", ",", "global_step", "=", "None", ",", "**", "kw", ")", ":", "\n", "        ", "weights", "=", "[", "]", "\n", "grads", "=", "[", "]", "\n", "\n", "self", ".", "_diagonal_pad", "=", "get_diagonal_pad", "(", "self", ".", "_d_p", ",", "global_step", "=", "global_step", ")", "\n", "self", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "self", ".", "_diagonal_pad", ",", "10", ")", "\n", "\n", "self", ".", "_nat_reg", "=", "[", "tf", ".", "constant", "(", "0.0", ")", "]", "\n", "\n", "if", "phase", "==", "PHASE_WAKE", ":", "\n", "            ", "hrw", "=", "self", ".", "_model", ".", "_hrw", "\n", "hgw", "=", "self", ".", "_model", ".", "_hgw", "\n", "# NATURAL GRADIENT PART", "\n", "hgs", "=", "self", ".", "_model", ".", "_hgs", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrw", ")", "\n", "\n", "weight_b", "=", "WakeSleepOptimizer", ".", "_get_bias", "(", ")", "# Size of the last hidden layer", "\n", "weights", "=", "[", "weight_b", "]", "# Size of the last hidden layer", "\n", "\n", "difference_b", "=", "hrw", "[", "-", "1", "]", "[", "1", "]", "-", "hgw", "[", "-", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "\n", "# CALC WEIGHT PART", "\n", "imp_weights_p", "=", "ReweightedWakeSleepOptimizer", ".", "compute_normalized_weights", "(", "self", ",", "hr", "=", "hrw", ",", "hg", "=", "hgw", ")", "\n", "imp_weights_q", "=", "imp_weights_p", "-", "self", ".", "_qbaseline", "\n", "# END OF CALC WEIGHT PART", "\n", "\n", "difference_b", "=", "tf", ".", "einsum", "(", "\"b,bv->bv\"", ",", "imp_weights_p", ",", "difference_b", ")", "\n", "difference_b", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reshape", "(", "difference_b", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "difference_b", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "]", ")", ",", "\n", "axis", "=", "0", ")", "\n", "\n", "# NATURAL GRADIENT PART", "\n", "grad_b", ",", "_", "=", "self", ".", "_apply_fisher_multipliers", "(", "\n", "next_layer_distr_probs", "=", "hgs", "[", "-", "1", "]", "[", "0", "]", ".", "get_probs", "(", ")", ",", "\n", "previous_layer_sample", "=", "None", ",", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "difference_w", "=", "None", ",", "\n", "global_step", "=", "global_step", ",", "\n", "layer", "=", "PHASE_WAKE", "+", "\"B\"", ",", "\n", "weight_w", "=", "None", ",", "\n", "weight_b", "=", "weight_b", ")", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "grads", "=", "[", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "-", "1", "]", ",", "grad_b", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "len", "(", "hrw", ")", "-", "1", ")", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrw", ")", "-", "1", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "weight_w", ",", "weight_b", "=", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"gen_net\"", ",", "\"l_g_{}\"", ".", "format", "(", "i", ")", ")", "\n", "weights", "+=", "[", "weight_w", ",", "weight_b", "]", "\n", "\n", "difference_b", "=", "hrw", "[", "i", "]", "[", "1", "]", "-", "hgw", "[", "i", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hrw", "[", "i", "+", "1", "]", "[", "1", "]", ")", "\n", "\n", "# CALC WEIGHT PART", "\n", "difference_b", "=", "tf", ".", "einsum", "(", "\"b,bv->bv\"", ",", "imp_weights_p", ",", "difference_b", ")", "\n", "difference_b", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reshape", "(", "difference_b", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "difference_b", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"b,buv->buv\"", ",", "imp_weights_p", ",", "difference_w", ")", "\n", "difference_w", "=", "tf", ".", "reshape", "(", "difference_w", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "*", "difference_w", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "3", "]", "]", ")", "\n", "difference_w", "=", "tf", ".", "reduce_sum", "(", "difference_w", ",", "axis", "=", "0", ")", "\n", "# END OF CALC WEIGHT PART", "\n", "\n", "# NATURAL GRADIENT PART", "\n", "grad_b", ",", "grad_w", "=", "self", ".", "_apply_fisher_multipliers", "(", "\n", "next_layer_distr_probs", "=", "hgs", "[", "i", "]", "[", "0", "]", ".", "get_probs", "(", ")", ",", "\n", "previous_layer_sample", "=", "hgs", "[", "i", "+", "1", "]", "[", "1", "]", ",", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "difference_w", "=", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "global_step", "=", "global_step", ",", "\n", "layer", "=", "PHASE_WAKE", "+", "str", "(", "i", ")", ",", "\n", "weight_w", "=", "weight_w", ",", "\n", "weight_b", "=", "weight_b", ")", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "grads", "+=", "[", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_w", ",", "\n", "name", "=", "\"Ww{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_b", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "# WAKE PHASE SLEEP", "\n", "", "for", "i", "in", "range", "(", "len", "(", "hrw", ")", "-", "1", ")", ":", "\n", "                ", "weight_w", ",", "weight_b", "=", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"rec_net\"", ",", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "\n", "weights", "+=", "[", "weight_w", ",", "weight_b", "]", "\n", "\n", "difference_b", "=", "hrw", "[", "i", "+", "1", "]", "[", "1", "]", "-", "hrw", "[", "i", "+", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hrw", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "# CALC WEIGHT PART", "\n", "difference_b", "=", "tf", ".", "einsum", "(", "\"b,bv->bv\"", ",", "imp_weights_q", ",", "difference_b", ")", "\n", "difference_b", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reshape", "(", "difference_b", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "difference_b", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"b,buv->buv\"", ",", "imp_weights_q", ",", "difference_w", ")", "\n", "difference_w", "=", "tf", ".", "reshape", "(", "difference_w", ",", "\n", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "*", "difference_w", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "3", "]", "]", ")", "\n", "difference_w", "=", "tf", ".", "reduce_sum", "(", "difference_w", ",", "axis", "=", "0", ")", "\n", "# END OF CALC WEIGHT PART", "\n", "\n", "# NATURAL GRADIENT PART", "\n", "grad_b", ",", "grad_w", "=", "self", ".", "_apply_fisher_multipliers", "(", "\n", "next_layer_distr_probs", "=", "hrw", "[", "i", "+", "1", "]", "[", "0", "]", ".", "get_probs", "(", ")", ",", "\n", "previous_layer_sample", "=", "hrw", "[", "i", "]", "[", "1", "]", ",", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "difference_w", "=", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "global_step", "=", "global_step", ",", "\n", "layer", "=", "PHASE_SLEEP", "+", "str", "(", "i", ")", ",", "\n", "weight_w", "=", "weight_w", ",", "\n", "weight_b", "=", "weight_b", ")", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "grads", "+=", "[", "\n", "tf", ".", "multiply", "(", "self", ".", "_wake_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_w", ",", "\n", "name", "=", "\"WSw{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_wake_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_b", ",", "\n", "name", "=", "\"WSb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "", "elif", "phase", "==", "PHASE_SLEEP", ":", "\n", "# CLASSIC SLEEP", "\n", "            ", "hrs", "=", "self", ".", "_model", ".", "_hrs", "\n", "hgs", "=", "self", ".", "_model", ".", "_hgs", "\n", "# NATURAL GRADIENT PART", "\n", "hrw", "=", "self", ".", "_model", ".", "_hrw", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrs", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrs", ")", "-", "1", ")", ":", "\n", "                ", "weight_w", ",", "weight_b", "=", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"rec_net\"", ",", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "\n", "weights", "+=", "[", "weight_w", ",", "weight_b", "]", "\n", "\n", "difference_b", "=", "hgs", "[", "i", "+", "1", "]", "[", "1", "]", "-", "hrs", "[", "i", "+", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hgs", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "# NATURAL GRADIENT PART", "\n", "grad_b", ",", "grad_w", "=", "self", ".", "_apply_fisher_multipliers", "(", "\n", "next_layer_distr_probs", "=", "hrw", "[", "i", "+", "1", "]", "[", "0", "]", ".", "get_probs", "(", ")", ",", "\n", "previous_layer_sample", "=", "hrw", "[", "i", "]", "[", "1", "]", ",", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "difference_w", "=", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "global_step", "=", "global_step", ",", "\n", "layer", "=", "PHASE_SLEEP", "+", "str", "(", "i", ")", "+", "\"_\"", ",", "\n", "weight_w", "=", "weight_w", ",", "\n", "weight_b", "=", "weight_b", ")", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "grads", "+=", "[", "\n", "tf", ".", "multiply", "(", "self", ".", "_sleep_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_w", ",", "\n", "name", "=", "\"Sw{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_sleep_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_b", ",", "\n", "name", "=", "\"Sb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"invalid value for phase '{}'\"", ".", "format", "(", "phase", ")", ")", "\n", "\n", "", "lr", "=", "1.", "\n", "if", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "lr", "*=", "self", ".", "_rescale_learning_rate", "\n", "\n", "", "regs", "=", "self", ".", "get_regularizers", "(", "weights", ")", "\n", "nat_regs", "=", "self", ".", "_get_natural_regularizers", "(", "weights", ")", "\n", "\n", "grads_and_vars_not_none", "=", "[", "(", "tf", ".", "multiply", "(", "-", "lr", ",", "g", ",", "name", "=", "\"g_\"", "+", "g", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ")", "+", "r", "+", "nr", ",", "v", ")", "for", "(", "g", ",", "r", ",", "nr", ",", "v", ")", "in", "\n", "zip", "(", "grads", ",", "regs", ",", "nat_regs", ",", "weights", ")", "if", "g", "is", "not", "None", "]", "\n", "\n", "\n", "assert", "np", ".", "all", "(", "[", "g", ".", "shape", "==", "v", ".", "shape", "for", "(", "g", ",", "v", ")", "in", "\n", "grads_and_vars_not_none", "]", ")", ",", "\"The shapes of weights and gradients are not the same\"", "\n", "\n", "return", "grads_and_vars_not_none", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalReweightedWakeSleepOptimizerAlternate.NaturalReweightedWakeSleepOptimizerAlternate.get_unnormalized_weigth_log": [[198, 200], ["None"], "methods", ["None"], ["", "def", "get_unnormalized_weigth_log", "(", "self", ",", "log_probs_p", ",", "log_probs_q", ")", ":", "\n", "        ", "return", "log_probs_p", "-", "log_probs_q", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate.__init__": [[10, 15], ["core.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "NaturalWakeSleepOptimizer", ".", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", "\n", "\n", "self", ".", "_k_step_update", "=", "optimizer_kwargs", "[", "\"k_step_update\"", "]", "\n", "self", ".", "_saves", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._apply_fisher_multipliers": [[16, 87], ["tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.pad", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.transpose", "tensorflow.split", "tensorflow.reshape", "numpy.bitwise_xor", "tensorflow.cast", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "tensorflow.cast", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._nat_reg.append", "tensorflow.cast", "len", "tensorflow.expand_dims", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._damping_multiplier", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.cast", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._apply_fisher_multipliers.get_fisher_weights"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._damping_multiplier"], ["", "def", "_apply_fisher_multipliers", "(", "self", ",", "next_layer_distr_probs", ",", "previous_layer_sample", ",", "difference_b", ",", "difference_w", ",", "\n", "global_step", ",", "layer", ",", "weight_w", "=", "None", ",", "weight_b", "=", "None", ")", ":", "\n", "# The formula is F=E[-q*(1-q)[h|1]^T[h|1]]", "\n", "        ", "assert", "not", "np", ".", "bitwise_xor", "(", "previous_layer_sample", "is", "not", "None", ",", "\n", "difference_w", "is", "not", "None", ")", ",", "\"In the case of the bias there's no grad_w and previous layer\"", "\n", "\n", "orig_dtype", "=", "next_layer_distr_probs", ".", "dtype", "\n", "next_layer_distr_probs", "=", "tf", ".", "cast", "(", "next_layer_distr_probs", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "difference_b", "=", "tf", ".", "cast", "(", "difference_b", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "def", "get_fisher_weights", "(", ")", ":", "\n", "            ", "weights", "=", "(", "next_layer_distr_probs", "*", "(", "1", "-", "next_layer_distr_probs", ")", ")", "/", "tf", ".", "cast", "(", "self", ".", "_n_z_length", ",", "\n", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "if", "len", "(", "weights", ".", "shape", ")", "==", "1", ":", "\n", "                ", "weights", "=", "tf", ".", "expand_dims", "(", "weights", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "weights", "\n", "\n", "", "if", "previous_layer_sample", "is", "None", ":", "# just the bias", "\n", "            ", "weight_b", "=", "tf", ".", "cast", "(", "weight_b", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "fisher_weights_reduced", "=", "self", ".", "_alternate_node", "(", "\n", "value_fn", "=", "lambda", ":", "tf", ".", "reduce_sum", "(", "get_fisher_weights", "(", ")", ",", "axis", "=", "0", ")", ",", "\n", "shape", "=", "[", "next_layer_distr_probs", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "]", ",", "\n", "name", "=", "layer", "+", "\"B\"", ",", "\n", "global_step", "=", "global_step", ",", "\n", "dtype", "=", "next_layer_distr_probs", ".", "dtype", ")", "\n", "\n", "alpha", "=", "self", ".", "_diagonal_pad", "\n", "if", "self", ".", "_d_p", "is", "None", "or", "self", ".", "_d_p", "==", "0.0", ":", "\n", "                ", "grads_b", "=", "difference_b", "/", "fisher_weights_reduced", "\n", "", "else", ":", "\n", "                ", "grads_b", "=", "self", ".", "_damping_multiplier", "(", "\n", "lambda", ":", "difference_b", "*", "(", "1.0", "+", "alpha", ")", "/", "(", "alpha", "+", "fisher_weights_reduced", ")", ",", "\n", "lambda", ":", "difference_b", ")", "\n", "", "grads_b", "=", "tf", ".", "cast", "(", "grads_b", ",", "dtype", "=", "orig_dtype", ")", "\n", "self", ".", "_nat_reg", ".", "append", "(", "tf", ".", "cast", "(", "self", ".", "_n_reg", "*", "weight_b", "*", "alpha", "*", "weight_b", ",", "dtype", "=", "orig_dtype", ")", "[", "0", "]", ")", "\n", "\n", "return", "grads_b", ",", "None", "\n", "\n", "", "difference_w", "=", "tf", ".", "cast", "(", "difference_w", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "bias_pad", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "\n", "previous_layer_sample_concat", "=", "tf", ".", "pad", "(", "previous_layer_sample", ",", "bias_pad", ",", "\"CONSTANT\"", ",", "constant_values", "=", "1", ")", "\n", "\n", "previous_layer_sample_transposed", "=", "tf", ".", "transpose", "(", "previous_layer_sample_concat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "diff_concat", "=", "tf", ".", "concat", "(", "[", "difference_w", ",", "tf", ".", "reshape", "(", "difference_b", ",", "[", "1", ",", "-", "1", "]", ")", "]", ",", "axis", "=", "0", ")", "\n", "# if self._n_reg:", "\n", "weight_concat", "=", "tf", ".", "concat", "(", "[", "weight_w", ",", "tf", ".", "reshape", "(", "weight_b", ",", "[", "1", ",", "-", "1", "]", ")", "]", ",", "axis", "=", "0", ")", "\n", "# else:", "\n", "#     weight_concat = None", "\n", "\n", "grads_w_b_concat", "=", "self", ".", "_multiply_grads_by_fisher_inv", "(", "weight_concat", "=", "weight_concat", ",", "\n", "difference", "=", "tf", ".", "transpose", "(", "diff_concat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", ",", "\n", "weights", "=", "tf", ".", "transpose", "(", "get_fisher_weights", "(", ")", ",", "perm", "=", "[", "1", ",", "0", "]", ")", ",", "\n", "previous_layer", "=", "previous_layer_sample_transposed", ",", "\n", "global_step", "=", "global_step", ",", "orig_dtype", "=", "orig_dtype", ",", "\n", "layer", "=", "layer", ")", "\n", "\n", "grads_w_b_concat", "=", "tf", ".", "transpose", "(", "grads_w_b_concat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "assert", "grads_w_b_concat", ".", "shape", "==", "diff_concat", ".", "shape", ",", "\"Shapes of gradients pre and post multiplication are not equal\"", "\n", "\n", "grads_w", ",", "grads_b", "=", "tf", ".", "split", "(", "grads_w_b_concat", ",", "[", "difference_w", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", ",", "1", "]", ",", "0", ")", "\n", "\n", "grads_b", "=", "tf", ".", "reshape", "(", "grads_b", ",", "[", "-", "1", "]", ")", "\n", "\n", "assert", "grads_b", ".", "shape", "==", "difference_b", ".", "shape", ",", "\"Shapes of gradients pre and post multiplication are not equal for b\"", "\n", "assert", "grads_w", ".", "shape", "==", "difference_w", ".", "shape", ",", "\"Shapes of gradients pre and post multiplication are not equal for W\"", "\n", "\n", "return", "grads_b", ",", "grads_w", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv": [[88, 160], ["tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.transpose", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._get_natural_regs", "tensorflow.cast", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "tensorflow.einsum", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._damping_multiplier", "tensorflow.linalg.diag", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "tensorflow.transpose", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "tensorflow.einsum", "tensorflow.einsum.set_shape", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "tensorflow.einsum", "core.optimizers.linalg.straight_inverse._true_fisher_inverse", "tensorflow.einsum", "grads.shape.as_list", "difference.shape.as_list", "difference.shape.as_list", "difference.shape.as_list", "tensorflow.einsum", "tensorflow.linalg.inv", "core.optimizers.linalg.straight_inverse._damped_fisher_inverse", "tensorflow.cast.shape.as_list", "grads.shape.as_list", "difference.shape.as_list", "difference.shape.as_list", "difference.shape.as_list", "tensorflow.einsum"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regs", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._damping_multiplier", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node", "home.repos.pwc.inspect_result.rist-ro_argo.linalg.straight_inverse._true_fisher_inverse", "home.repos.pwc.inspect_result.rist-ro_argo.linalg.straight_inverse._damped_fisher_inverse"], ["", "def", "_multiply_grads_by_fisher_inv", "(", "self", ",", "weight_concat", ",", "difference", ",", "weights", ",", "previous_layer", ",", "global_step", ",", "orig_dtype", ",", "\n", "layer", ")", ":", "# , choice=False):", "\n", "        ", "weights", "=", "tf", ".", "cast", "(", "weights", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "weight_concat", "=", "tf", ".", "cast", "(", "weight_concat", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "previous_layer", "=", "tf", ".", "cast", "(", "previous_layer", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "alpha", "=", "self", ".", "_diagonal_pad", "\n", "alpha", "=", "tf", ".", "cast", "(", "alpha", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "previous_layer_transpose", "=", "tf", ".", "transpose", "(", "previous_layer", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "if", "self", ".", "_d_p", "is", "None", "or", "self", ".", "_d_p", "==", "0.0", ":", "\n", "            ", "inv_fisher", "=", "self", ".", "_alternate_node", "(", "\n", "value_fn", "=", "lambda", ":", "_true_fisher_inverse", "(", "U", "=", "previous_layer", ",", "Q", "=", "weights", ",", "U_T", "=", "previous_layer_transpose", ")", ",", "\n", "shape", "=", "[", "difference", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", ",", "difference", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "difference", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "]", ",", "\n", "name", "=", "layer", "+", "\"MIT\"", ",", "\n", "global_step", "=", "global_step", ",", "\n", "dtype", "=", "previous_layer", ".", "dtype", ")", "\n", "\n", "inverse_x_dif", "=", "tf", ".", "einsum", "(", "'lkn,ln->lk'", ",", "inv_fisher", ",", "difference", ")", "\n", "", "else", ":", "\n", "            ", "def", "_calc_sh", "(", ")", ":", "\n", "                ", "if", "(", "self", ".", "_model", ".", "batch_size", "[", "'train'", "]", "*", "self", ".", "_model", ".", "samples", "<", "difference", ".", "shape", "[", "-", "1", "]", ")", ":", "# ^ choice:", "\n", "\n", "                    ", "C", "=", "weights", "\n", "C_inv", "=", "tf", ".", "linalg", ".", "diag", "(", "1", "/", "C", ")", "\n", "\n", "grads", "=", "difference", "\n", "\n", "k_len", "=", "self", ".", "_model", ".", "batch_size", "[", "'train'", "]", "*", "self", ".", "_model", ".", "samples", "\n", "\n", "u", "=", "self", ".", "_alternate_node", "(", "\n", "value_fn", "=", "lambda", ":", "previous_layer", ",", "\n", "shape", "=", "[", "previous_layer", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", ",", "k_len", "]", ",", "\n", "name", "=", "layer", "+", "\"U\"", ",", "\n", "global_step", "=", "global_step", ",", "\n", "dtype", "=", "previous_layer", ".", "dtype", ")", "\n", "\n", "v_T", "=", "tf", ".", "transpose", "(", "u", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "m_inner_inv", "=", "self", ".", "_alternate_node", "(", "\n", "value_fn", "=", "lambda", ":", "tf", ".", "linalg", ".", "inv", "(", "alpha", "*", "C_inv", "+", "tf", ".", "einsum", "(", "'ij,jk->ik'", ",", "v_T", ",", "u", ")", ")", ",", "\n", "shape", "=", "[", "grads", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", ",", "k_len", ",", "k_len", "]", ",", "\n", "name", "=", "layer", "+", "\"MII\"", ",", "\n", "global_step", "=", "global_step", ",", "\n", "dtype", "=", "previous_layer", ".", "dtype", ")", "\n", "\n", "M2", "=", "tf", ".", "einsum", "(", "'ij,lj->li'", ",", "u", ",", "\n", "tf", ".", "einsum", "(", "'lij,lj->li'", ",", "m_inner_inv", ",", "tf", ".", "einsum", "(", "'ik,lk->li'", ",", "v_T", ",", "grads", ")", ")", ")", "\n", "\n", "M", "=", "grads", "-", "M2", "\n", "\n", "inverse_x_dif", "=", "(", "(", "1.0", "+", "alpha", ")", "/", "alpha", ")", "*", "M", "\n", "\n", "inverse_x_dif", ".", "set_shape", "(", "grads", ".", "shape", ".", "as_list", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "inv_fisher", "=", "self", ".", "_alternate_node", "(", "\n", "value_fn", "=", "lambda", ":", "_damped_fisher_inverse", "(", "U", "=", "previous_layer", ",", "Q", "=", "weights", ",", "\n", "U_T", "=", "previous_layer_transpose", ",", "\n", "alpha", "=", "self", ".", "_diagonal_pad", ")", ",", "\n", "shape", "=", "[", "difference", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", ",", "difference", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "\n", "difference", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "]", ",", "\n", "name", "=", "layer", "+", "\"MI\"", ",", "\n", "global_step", "=", "global_step", ",", "\n", "dtype", "=", "previous_layer", ".", "dtype", ")", "\n", "inverse_x_dif", "=", "tf", ".", "einsum", "(", "'lkn,ln->lk'", ",", "inv_fisher", ",", "difference", ")", "\n", "", "return", "inverse_x_dif", "\n", "\n", "", "inverse_x_dif", "=", "self", ".", "_damping_multiplier", "(", "_calc_sh", ",", "lambda", ":", "difference", ")", "\n", "\n", "", "self", ".", "_get_natural_regs", "(", "U", "=", "previous_layer", ",", "Q", "=", "weights", ",", "W", "=", "weight_concat", ",", "orig_dtype", "=", "orig_dtype", ")", "\n", "inverse_x_dif", "=", "tf", ".", "cast", "(", "inverse_x_dif", ",", "dtype", "=", "orig_dtype", ")", "\n", "return", "inverse_x_dif", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._alternate_node": [[161, 175], ["NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._register_node", "tensorflow.cond", "tensorflow.identity", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._update_node", "tensorflow.identity", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._global_step_cond", "value_fn", "NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._get_node_by_varname"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._register_node", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._update_node", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._global_step_cond", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._get_node_by_varname"], ["", "def", "_alternate_node", "(", "self", ",", "value_fn", ",", "shape", ",", "name", ",", "dtype", ",", "global_step", ")", ":", "\n", "\n", "        ", "self", ".", "_register_node", "(", "shape", ",", "name", ",", "dtype", ")", "\n", "\n", "def", "tru", "(", ")", ":", "\n", "            ", "node", "=", "tf", ".", "identity", "(", "value_fn", "(", ")", ")", "\n", "return", "self", ".", "_update_node", "(", "node", ",", "name", ")", "\n", "\n", "", "def", "fal", "(", ")", ":", "\n", "            ", "node", "=", "tf", ".", "identity", "(", "self", ".", "_get_node_by_varname", "(", "name", ")", ")", "\n", "return", "node", "\n", "\n", "", "node", "=", "tf", ".", "cond", "(", "self", ".", "_global_step_cond", "(", "global_step", "=", "global_step", ")", ",", "tru", ",", "fal", ")", "\n", "return", "node", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._global_step_cond": [[176, 180], ["tensorflow.logical_or", "tensorflow.constant", "tensorflow.equal", "tensorflow.equal"], "methods", ["None"], ["", "def", "_global_step_cond", "(", "self", ",", "global_step", ")", ":", "\n", "        ", "if", "self", ".", "_k_step_update", "<=", "0", ":", "\n", "            ", "return", "tf", ".", "constant", "(", "True", ")", "\n", "", "return", "tf", ".", "logical_or", "(", "tf", ".", "equal", "(", "global_step", ",", "0", ")", ",", "tf", ".", "equal", "(", "global_step", "%", "self", ".", "_k_step_update", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._update_node": [[181, 187], ["NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._check_node", "tensorflow.assign", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._check_node"], ["", "def", "_update_node", "(", "self", ",", "var", ",", "var_name", ",", "validate_shape", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "_check_node", "(", "var_name", ")", ":", "\n", "            ", "new_value", "=", "tf", ".", "assign", "(", "self", ".", "_saves", "[", "var_name", "]", ",", "var", ",", "validate_shape", "=", "validate_shape", ")", "\n", "return", "new_value", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Var name is accessed before creation: '{}'\"", ".", "format", "(", "var_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._register_node": [[188, 196], ["NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._check_node", "ValueError", "tensorflow.Variable", "tensorflow.Variable", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._check_node"], ["", "", "def", "_register_node", "(", "self", ",", "exp_shape", ",", "var_name", ",", "dtype", ",", "validate_shape", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "_check_node", "(", "var_name", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Var name is already created: '{}'\"", ".", "format", "(", "var_name", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "validate_shape", "==", "True", ":", "\n", "                ", "self", ".", "_saves", "[", "var_name", "]", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "exp_shape", ")", ",", "expected_shape", "=", "exp_shape", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_saves", "[", "var_name", "]", "=", "tf", ".", "Variable", "(", "[", "]", ",", "shape", "=", "None", ",", "validate_shape", "=", "False", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._check_node": [[197, 199], ["NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._saves.keys"], "methods", ["None"], ["", "", "", "def", "_check_node", "(", "self", ",", "var_name", ")", ":", "\n", "        ", "return", "var_name", "in", "self", ".", "_saves", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._get_node_by_varname": [[200, 205], ["NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._check_node", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._check_node"], ["", "def", "_get_node_by_varname", "(", "self", ",", "var_name", ")", ":", "\n", "        ", "if", "self", ".", "_check_node", "(", "var_name", ")", ":", "\n", "            ", "return", "self", ".", "_saves", "[", "var_name", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Var name is accessed before assignment: '{}'\"", ".", "format", "(", "var_name", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.__init__": [[10, 23], ["core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.__init__", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "optimizer_kwargs", ")", "\n", "\n", "self", ".", "_b_size", "=", "self", ".", "_model", ".", "b_size", "\n", "self", ".", "_n_samples", "=", "self", ".", "_model", ".", "n_z_samples", "\n", "\n", "self", ".", "_sleep_balance", "=", "0.5", "\n", "self", ".", "_wake_q", "=", "1.0", "-", "self", ".", "_sleep_balance", "\n", "self", ".", "_sleep_q", "=", "self", ".", "_sleep_balance", "\n", "\n", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "0.", ")", "\n", "if", "optimizer_kwargs", "[", "\"q_baseline\"", "]", ":", "\n", "            ", "self", ".", "_qbaseline", "=", "tf", ".", "constant", "(", "1.", ")", "/", "tf", ".", "cast", "(", "self", ".", "_n_samples", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.compute_gradients": [[24, 137], ["ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.get_regularizers", "numpy.all", "ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.check_ilr", "ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.compute_normalized_weights", "tensorflow.einsum", "tensorflow.reduce_sum", "range", "ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer._get_bias", "[].mean", "tensorflow.reshape", "tensorflow.multiply", "range", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.reduce_sum", "tensorflow.einsum", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.reduce_sum", "tensorflow.einsum", "tensorflow.reshape", "tensorflow.reduce_sum", "ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.check_ilr", "range", "ValueError", "zip", "tensorflow.reduce_mean", "[].mean", "tensorflow.reshape", "tensorflow.multiply", "tensorflow.multiply", "len", "[].mean", "tensorflow.reshape", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.einsum", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.multiply", "len", "ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer._get_layer_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "[].mean", "tensorflow.reshape", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.reduce_mean.shape.as_list", "ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer._get_layer_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "tensorflow.reduce_mean.shape.as_list", "tensorflow.reduce_mean.shape.as_list", "tensorflow.reduce_mean.shape.as_list", "tensorflow.reduce_mean.shape.as_list", "tensorflow.reduce_mean.shape.as_list", "tensorflow.reduce_mean.shape.as_list", "g.name.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.compute_normalized_weights", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars"], ["", "", "def", "compute_gradients", "(", "self", ",", "phase", ",", "k", "=", "1", ",", "*", "args", ",", "**", "kw", ")", ":", "\n", "        ", "weights", "=", "[", "]", "\n", "grads", "=", "[", "]", "\n", "\n", "if", "phase", "==", "PHASE_WAKE", ":", "\n", "            ", "hrw", "=", "self", ".", "_model", ".", "_hrw", "\n", "hgw", "=", "self", ".", "_model", ".", "_hgw", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrw", ")", "\n", "\n", "weights", "=", "[", "self", ".", "_get_bias", "(", ")", "]", "# Size of the last hidden layer", "\n", "\n", "difference_b", "=", "hrw", "[", "-", "1", "]", "[", "1", "]", "-", "hgw", "[", "-", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "\n", "# CALC WEIGHT PART", "\n", "imp_weights_p", "=", "self", ".", "compute_normalized_weights", "(", "hr", "=", "hrw", ",", "hg", "=", "hgw", ")", "\n", "imp_weights_q", "=", "imp_weights_p", "-", "self", ".", "_qbaseline", "\n", "# END OF CALC WEIGHT PART", "\n", "\n", "difference_b", "=", "tf", ".", "einsum", "(", "\"b,bv->bv\"", ",", "imp_weights_p", ",", "difference_b", ")", "\n", "difference_b", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reshape", "(", "difference_b", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "difference_b", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "]", ")", ",", "\n", "axis", "=", "0", ")", "\n", "grads", "=", "[", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "difference_b", ",", "\n", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "len", "(", "hrw", ")", "-", "1", ")", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrw", ")", "-", "1", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "weights", "+=", "[", "*", "self", ".", "_get_layer_vars", "(", "\"gen_net\"", ",", "\"l_g_{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "difference_b", "=", "hrw", "[", "i", "]", "[", "1", "]", "-", "hgw", "[", "i", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hrw", "[", "i", "+", "1", "]", "[", "1", "]", ")", "\n", "\n", "# CALC WEIGHT PART", "\n", "difference_b", "=", "tf", ".", "einsum", "(", "\"b,bv->bv\"", ",", "imp_weights_p", ",", "difference_b", ")", "\n", "difference_b", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reshape", "(", "difference_b", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "difference_b", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"b,buv->buv\"", ",", "imp_weights_p", ",", "difference_w", ")", "\n", "difference_w", "=", "tf", ".", "reshape", "(", "difference_w", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "*", "difference_w", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "3", "]", "]", ")", "\n", "difference_w", "=", "tf", ".", "reduce_sum", "(", "difference_w", ",", "axis", "=", "0", ")", "\n", "# END OF CALC WEIGHT PART", "\n", "\n", "grads", "+=", "[", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Ww{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "# WAKE PHASE SLEEP", "\n", "", "for", "i", "in", "range", "(", "len", "(", "hrw", ")", "-", "1", ")", ":", "\n", "                ", "weights", "+=", "[", "*", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"rec_net\"", ",", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "difference_b", "=", "hrw", "[", "i", "+", "1", "]", "[", "1", "]", "-", "hrw", "[", "i", "+", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hrw", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "# CALC WEIGHT PART", "\n", "difference_b", "=", "tf", ".", "einsum", "(", "\"b,bv->bv\"", ",", "imp_weights_q", ",", "difference_b", ")", "\n", "difference_b", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "reshape", "(", "difference_b", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "difference_b", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"b,buv->buv\"", ",", "imp_weights_q", ",", "difference_w", ")", "\n", "difference_w", "=", "tf", ".", "reshape", "(", "difference_w", ",", "\n", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "*", "difference_w", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "3", "]", "]", ")", "\n", "difference_w", "=", "tf", ".", "reduce_sum", "(", "difference_w", ",", "axis", "=", "0", ")", "\n", "# END OF CALC WEIGHT PART", "\n", "\n", "grads", "+=", "[", "\n", "tf", ".", "multiply", "(", "self", ".", "_wake_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"WSw{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_wake_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"WSb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "", "elif", "phase", "==", "PHASE_SLEEP", ":", "\n", "# CLASSIC SLEEP", "\n", "            ", "hrs", "=", "self", ".", "_model", ".", "_hrs", "\n", "hgs", "=", "self", ".", "_model", ".", "_hgs", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrs", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrs", ")", "-", "1", ")", ":", "\n", "                ", "weights", "+=", "[", "*", "self", ".", "_get_layer_vars", "(", "\"rec_net\"", ",", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "difference_b", "=", "hgs", "[", "i", "+", "1", "]", "[", "1", "]", "-", "hrs", "[", "i", "+", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hgs", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "# CALC WEIGHT PART - NO WEIGHTS =1", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "reshape", "(", "difference_b", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "difference_b", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "difference_w", "=", "tf", ".", "reshape", "(", "difference_w", ",", "\n", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", ",", "*", "difference_w", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "3", "]", "]", ")", "\n", "difference_w", "=", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", "\n", "# END OF CALC WEIGHT PART", "\n", "\n", "grads", "+=", "[", "\n", "tf", ".", "multiply", "(", "self", ".", "_sleep_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Sw{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_sleep_q", "*", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "name", "=", "\"Sb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"invalid value for phase '{}'\"", ".", "format", "(", "phase", ")", ")", "\n", "\n", "", "lr", "=", "1.", "\n", "if", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "lr", "*=", "self", ".", "_rescale_learning_rate", "\n", "\n", "", "regs", "=", "self", ".", "get_regularizers", "(", "weights", ")", "\n", "\n", "grads_and_vars_not_none", "=", "[", "(", "tf", ".", "multiply", "(", "-", "lr", ",", "g", ",", "name", "=", "\"g_\"", "+", "g", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ")", "+", "r", ",", "v", ")", "for", "(", "g", ",", "r", ",", "v", ")", "in", "\n", "zip", "(", "grads", ",", "regs", ",", "weights", ")", "if", "g", "is", "not", "None", "]", "\n", "\n", "assert", "np", ".", "all", "(", "[", "g", ".", "shape", "==", "v", ".", "shape", "for", "(", "g", ",", "v", ")", "in", "\n", "grads_and_vars_not_none", "]", ")", ",", "\"The shapes of weights and gradients are not the same\"", "\n", "\n", "return", "grads_and_vars_not_none", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.compute_normalized_weights": [[138, 168], ["tensorflow.name_scope", "range", "ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.get_unnormalized_weigth_log", "tensorflow.reduce_logsumexp", "tensorflow.exp", "len", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.tile", "distr_p.log_prob", "tensorflow.reduce_sum", "tensorflow.zeros", "distr_q.log_prob", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.get_unnormalized_weigth_log", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "compute_normalized_weights", "(", "self", ",", "hr", ",", "hg", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"reweights\"", ")", ":", "\n", "            ", "log_probs_p", "=", "0.0", "\n", "log_probs_q", "=", "0.0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hg", ")", ")", ":", "\n", "                ", "samples_q", "=", "hr", "[", "i", "]", "[", "1", "]", "\n", "\n", "distr_p", "=", "hg", "[", "i", "]", "[", "0", "]", "\n", "log_probs_p_all", "=", "tf", ".", "reduce_sum", "(", "distr_p", ".", "log_prob", "(", "samples_q", ")", ",", "axis", "=", "-", "1", ")", "\n", "log_probs_p", "+=", "log_probs_p_all", "\n", "\n", "distr_q", "=", "hr", "[", "i", "]", "[", "0", "]", "\n", "if", "i", ">", "0", ":", "\n", "                    ", "log_probs_q_all", "=", "tf", ".", "reduce_sum", "(", "distr_q", ".", "log_prob", "(", "samples_q", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "log_probs_q_all", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "samples_q", ")", "[", "0", "]", ")", "\n", "\n", "", "log_probs_q", "+=", "log_probs_q_all", "\n", "\n", "", "unnormalized_weight_log", "=", "self", ".", "get_unnormalized_weigth_log", "(", "log_probs_p", ",", "log_probs_q", ")", "\n", "\n", "unnormalized_weight_log_reduced", "=", "tf", ".", "reduce_logsumexp", "(", "\n", "tf", ".", "reshape", "(", "unnormalized_weight_log", ",", "[", "self", ".", "_n_samples", ",", "self", ".", "_b_size", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "normalized_weights_log", "=", "unnormalized_weight_log", "-", "tf", ".", "tile", "(", "unnormalized_weight_log_reduced", ",", "\n", "[", "self", ".", "_n_samples", "]", ")", "\n", "normalized_weights", "=", "tf", ".", "exp", "(", "normalized_weights_log", ")", "\n", "", "return", "normalized_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.ReweightedWakeSleepOptimizer.ReweightedWakeSleepOptimizer.get_unnormalized_weigth_log": [[169, 171], ["None"], "methods", ["None"], ["", "def", "get_unnormalized_weigth_log", "(", "self", ",", "log_probs_p", ",", "log_probs_q", ")", ":", "\n", "        ", "return", "log_probs_p", "-", "log_probs_q", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.__init__": [[48, 57], ["core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.__init__", "float"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", ":", "\n", "        ", "WakeSleepOptimizer", ".", "__init__", "(", "self", ",", "**", "optimizer_kwargs", ")", "\n", "\n", "self", ".", "_d_p", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "self", ".", "_n_reg", "=", "(", "optimizer_kwargs", "[", "\"natural_reg\"", "]", "if", "\"natural_reg\"", "in", "optimizer_kwargs", "and", "float", "(", "\n", "optimizer_kwargs", "[", "\"natural_reg\"", "]", ")", ">", "0", "else", "0", ")", "\n", "self", ".", "_b_size", "=", "self", ".", "_model", ".", "b_size", "\n", "self", ".", "_n_samples", "=", "self", ".", "_model", ".", "n_z_samples", "\n", "self", ".", "_n_z_length", "=", "self", ".", "_n_samples", "*", "self", ".", "_b_size", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients": [[58, 170], ["NaturalWakeSleepOptimizer.get_diagonal_pad", "tensorflow.less_equal", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.get_regularizers", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regularizers", "numpy.all", "tensorflow.constant", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.check_ilr", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "[].mean", "tensorflow.multiply", "range", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.einsum", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.check_ilr", "range", "ValueError", "zip", "[].get_probs", "tensorflow.reduce_mean", "[].mean", "tensorflow.multiply", "tensorflow.multiply", "core.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "tensorflow.einsum", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "len", "[].get_probs", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "[].mean", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "str", "[].get_probs", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "len", "str", "len", "str", "g.name.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.get_diagonal_pad", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.get_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regularizers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_bias", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.check_ilr", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer._get_layer_vars", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "compute_gradients", "(", "self", ",", "phase", ",", "*", "args", ",", "global_step", "=", "None", ",", "**", "kw", ")", ":", "\n", "\n", "        ", "weights", "=", "[", "]", "\n", "grads", "=", "[", "]", "\n", "\n", "self", ".", "_diagonal_pad", "=", "get_diagonal_pad", "(", "self", ".", "_d_p", ",", "global_step", "=", "global_step", ")", "\n", "self", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "self", ".", "_diagonal_pad", ",", "100.0", ")", "\n", "self", ".", "_nat_reg", "=", "[", "tf", ".", "constant", "(", "0.0", ")", "]", "\n", "\n", "if", "phase", "==", "PHASE_WAKE", ":", "\n", "            ", "hrw", "=", "self", ".", "_model", ".", "_hrw", "\n", "hgw", "=", "self", ".", "_model", ".", "_hgw", "\n", "# NATURAL GRADIENT PART", "\n", "hgs", "=", "self", ".", "_model", ".", "_hgs", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrw", ")", "\n", "\n", "weight_b", "=", "WakeSleepOptimizer", ".", "_get_bias", "(", ")", "# Size of the last hidden layer", "\n", "weights", "=", "[", "weight_b", "]", "# Size of the last hidden layer", "\n", "\n", "difference_b", "=", "hrw", "[", "-", "1", "]", "[", "1", "]", "-", "hgw", "[", "-", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "\n", "# NATURAL GRADIENT PART", "\n", "grad_b", ",", "_", "=", "self", ".", "_apply_fisher_multipliers", "(", "\n", "next_layer_distr_probs", "=", "hgs", "[", "-", "1", "]", "[", "0", "]", ".", "get_probs", "(", ")", ",", "\n", "previous_layer_sample", "=", "None", ",", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "difference_w", "=", "None", ",", "\n", "global_step", "=", "global_step", ",", "\n", "layer", "=", "PHASE_WAKE", "+", "str", "(", "len", "(", "hrw", ")", "-", "1", ")", "+", "\"_\"", ",", "\n", "weight_w", "=", "None", ",", "\n", "weight_b", "=", "weight_b", ")", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "grads", "=", "[", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "-", "1", "]", ",", "grad_b", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "len", "(", "hrw", ")", "-", "1", ")", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrw", ")", "-", "1", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "weight_w", ",", "weight_b", "=", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"gen_net\"", ",", "\"l_g_{}\"", ".", "format", "(", "i", ")", ")", "\n", "weights", "+=", "[", "weight_w", ",", "weight_b", "]", "\n", "\n", "difference_b", "=", "hrw", "[", "i", "]", "[", "1", "]", "-", "hgw", "[", "i", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hrw", "[", "i", "+", "1", "]", "[", "1", "]", ")", "\n", "\n", "# NATURAL GRADIENT PART", "\n", "grad_b", ",", "grad_w", "=", "self", ".", "_apply_fisher_multipliers", "(", "\n", "next_layer_distr_probs", "=", "hgs", "[", "i", "]", "[", "0", "]", ".", "get_probs", "(", ")", ",", "\n", "previous_layer_sample", "=", "hgs", "[", "i", "+", "1", "]", "[", "1", "]", ",", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "difference_w", "=", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "global_step", "=", "global_step", ",", "\n", "layer", "=", "PHASE_WAKE", "+", "str", "(", "i", ")", "+", "\"_\"", ",", "\n", "weight_w", "=", "weight_w", ",", "\n", "weight_b", "=", "weight_b", ")", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "grads", "+=", "[", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_w", ",", "\n", "name", "=", "\"Ww{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_b", ",", "\n", "name", "=", "\"Wb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "", "elif", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "hrs", "=", "self", ".", "_model", ".", "_hrs", "\n", "hgs", "=", "self", ".", "_model", ".", "_hgs", "\n", "# NATURAL GRADIENT PART", "\n", "hrw", "=", "self", ".", "_model", ".", "_hrw", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "self", ".", "_individual_learning_rate", "=", "self", ".", "check_ilr", "(", "self", ".", "_individual_learning_rate", ",", "hrs", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "hrs", ")", "-", "1", ")", ":", "\n", "                ", "weight_w", ",", "weight_b", "=", "WakeSleepOptimizer", ".", "_get_layer_vars", "(", "\"rec_net\"", ",", "\"l_r_{}\"", ".", "format", "(", "i", ")", ")", "\n", "weights", "+=", "[", "weight_w", ",", "weight_b", "]", "\n", "\n", "difference_b", "=", "hgs", "[", "i", "+", "1", "]", "[", "1", "]", "-", "hrs", "[", "i", "+", "1", "]", "[", "0", "]", ".", "mean", "(", ")", "\n", "difference_w", "=", "tf", ".", "einsum", "(", "\"bu,bv->bvu\"", ",", "difference_b", ",", "hgs", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "# NATURAL GRADIENT PART", "\n", "grad_b", ",", "grad_w", "=", "self", ".", "_apply_fisher_multipliers", "(", "\n", "next_layer_distr_probs", "=", "hrw", "[", "i", "+", "1", "]", "[", "0", "]", ".", "get_probs", "(", ")", ",", "\n", "previous_layer_sample", "=", "hrw", "[", "i", "]", "[", "1", "]", ",", "\n", "difference_b", "=", "tf", ".", "reduce_mean", "(", "difference_b", ",", "axis", "=", "0", ")", ",", "\n", "difference_w", "=", "tf", ".", "reduce_mean", "(", "difference_w", ",", "axis", "=", "0", ")", ",", "\n", "global_step", "=", "global_step", ",", "\n", "layer", "=", "PHASE_SLEEP", "+", "str", "(", "i", ")", "+", "\"_\"", ",", "\n", "weight_w", "=", "weight_w", ",", "\n", "weight_b", "=", "weight_b", ")", "\n", "# END OF NATURAL GRADIENT PART", "\n", "\n", "grads", "+=", "[", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_w", ",", "\n", "name", "=", "\"Sw{}\"", ".", "format", "(", "i", ")", ")", ",", "\n", "tf", ".", "multiply", "(", "self", ".", "_individual_learning_rate", "[", "i", "]", ",", "grad_b", ",", "\n", "name", "=", "\"Sb{}\"", ".", "format", "(", "i", ")", ")", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"invalid value for phase '{}'\"", ".", "format", "(", "phase", ")", ")", "\n", "\n", "", "lr", "=", "1.", "\n", "if", "phase", "==", "PHASE_SLEEP", ":", "\n", "            ", "lr", "*=", "self", ".", "_rescale_learning_rate", "\n", "\n", "", "regs", "=", "self", ".", "get_regularizers", "(", "weights", ")", "\n", "nat_regs", "=", "self", ".", "_get_natural_regularizers", "(", "weights", ")", "\n", "grads_and_vars_not_none", "=", "[", "(", "tf", ".", "multiply", "(", "-", "lr", ",", "g", ",", "name", "=", "\"g_\"", "+", "g", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", ")", "+", "r", "+", "nr", ",", "v", ")", "for", "(", "g", ",", "r", ",", "nr", ",", "v", ")", "in", "\n", "zip", "(", "grads", ",", "regs", ",", "nat_regs", ",", "weights", ")", "if", "g", "is", "not", "None", "]", "\n", "\n", "assert", "np", ".", "all", "(", "[", "g", ".", "shape", "==", "v", ".", "shape", "for", "(", "g", ",", "v", ")", "in", "\n", "grads_and_vars_not_none", "]", ")", ",", "\"The shapes of weights and gradients are not the same\"", "\n", "\n", "return", "grads_and_vars_not_none", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers": [[171, 233], ["tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.pad", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "tensorflow.transpose", "tensorflow.split", "tensorflow.reshape", "numpy.bitwise_xor", "tensorflow.cast", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._nat_reg.append", "tensorflow.cast", "len", "tensorflow.expand_dims", "tensorflow.reduce_sum", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._damping_multiplier", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._apply_fisher_multipliers.get_fisher_weights"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._damping_multiplier"], ["", "def", "_apply_fisher_multipliers", "(", "self", ",", "next_layer_distr_probs", ",", "previous_layer_sample", ",", "difference_b", ",", "difference_w", ",", "\n", "global_step", ",", "layer", ",", "weight_w", "=", "None", ",", "weight_b", "=", "None", ")", ":", "\n", "# The formula is F=E[-q*(1-q)[h|1]^T[h|1]]", "\n", "\n", "        ", "assert", "not", "np", ".", "bitwise_xor", "(", "previous_layer_sample", "is", "not", "None", ",", "\n", "difference_w", "is", "not", "None", ")", ",", "\"In the case of the bias there's no grad_w and previous layer\"", "\n", "\n", "orig_dtype", "=", "next_layer_distr_probs", ".", "dtype", "\n", "next_layer_distr_probs", "=", "tf", ".", "cast", "(", "next_layer_distr_probs", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "difference_b", "=", "tf", ".", "cast", "(", "difference_b", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "def", "get_fisher_weights", "(", ")", ":", "\n", "            ", "weights", "=", "(", "next_layer_distr_probs", "*", "(", "1", "-", "next_layer_distr_probs", ")", ")", "/", "tf", ".", "cast", "(", "self", ".", "_n_z_length", ",", "\n", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "if", "len", "(", "weights", ".", "shape", ")", "==", "1", ":", "\n", "                ", "weights", "=", "tf", ".", "expand_dims", "(", "weights", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "weights", "\n", "\n", "", "if", "previous_layer_sample", "is", "None", ":", "\n", "            ", "alpha", "=", "self", ".", "_diagonal_pad", "\n", "if", "self", ".", "_d_p", "is", "None", "or", "self", ".", "_d_p", "==", "0.0", ":", "\n", "                ", "fisher_weights_reduced", "=", "tf", ".", "reduce_sum", "(", "get_fisher_weights", "(", ")", ",", "axis", "=", "0", ")", "\n", "grads_b", "=", "difference_b", "/", "fisher_weights_reduced", "\n", "", "else", ":", "\n", "                ", "grads_b", "=", "self", ".", "_damping_multiplier", "(", "\n", "lambda", ":", "difference_b", "*", "(", "1.0", "+", "alpha", ")", "/", "(", "alpha", "+", "tf", ".", "reduce_sum", "(", "get_fisher_weights", "(", ")", ",", "axis", "=", "0", ")", ")", ",", "\n", "lambda", ":", "difference_b", ")", "\n", "", "grads_b", "=", "tf", ".", "cast", "(", "grads_b", ",", "dtype", "=", "orig_dtype", ")", "\n", "self", ".", "_nat_reg", ".", "append", "(", "tf", ".", "cast", "(", "self", ".", "_n_reg", "*", "weight_b", "*", "alpha", "*", "weight_b", ",", "dtype", "=", "orig_dtype", ")", "[", "0", "]", ")", "\n", "return", "grads_b", ",", "None", "\n", "\n", "", "difference_w", "=", "tf", ".", "cast", "(", "difference_w", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "bias_pad", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ")", "\n", "\n", "previous_layer_sample_concat", "=", "tf", ".", "pad", "(", "previous_layer_sample", ",", "bias_pad", ",", "\"CONSTANT\"", ",", "constant_values", "=", "1", ")", "\n", "\n", "previous_layer_sample_transposed", "=", "tf", ".", "transpose", "(", "previous_layer_sample_concat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "diff_concat", "=", "tf", ".", "concat", "(", "[", "difference_w", ",", "tf", ".", "reshape", "(", "difference_b", ",", "[", "1", ",", "-", "1", "]", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "weight_concat", "=", "tf", ".", "concat", "(", "[", "weight_w", ",", "tf", ".", "reshape", "(", "weight_b", ",", "[", "1", ",", "-", "1", "]", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "grads_w_b_concat", "=", "self", ".", "_multiply_grads_by_fisher_inv", "(", "weight_concat", "=", "weight_concat", ",", "\n", "difference", "=", "tf", ".", "transpose", "(", "diff_concat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", ",", "\n", "weights", "=", "tf", ".", "transpose", "(", "get_fisher_weights", "(", ")", ",", "perm", "=", "[", "1", ",", "0", "]", ")", ",", "\n", "previous_layer", "=", "previous_layer_sample_transposed", ",", "\n", "global_step", "=", "global_step", ",", "orig_dtype", "=", "orig_dtype", ",", "\n", "layer", "=", "layer", ")", "\n", "\n", "grads_w_b_concat", "=", "tf", ".", "transpose", "(", "grads_w_b_concat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "assert", "grads_w_b_concat", ".", "shape", "==", "diff_concat", ".", "shape", ",", "\"Shapes of gradients pre and post multiplication are not equal\"", "\n", "\n", "grads_w", ",", "grads_b", "=", "tf", ".", "split", "(", "grads_w_b_concat", ",", "[", "difference_w", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", ",", "1", "]", ",", "0", ")", "\n", "\n", "grads_b", "=", "tf", ".", "reshape", "(", "grads_b", ",", "[", "-", "1", "]", ")", "\n", "\n", "assert", "grads_b", ".", "shape", "==", "difference_b", ".", "shape", ",", "\"Shapes of gradients pre and post multiplication are not equal for b\"", "\n", "assert", "grads_w", ".", "shape", "==", "difference_w", ".", "shape", ",", "\"Shapes of gradients pre and post multiplication are not equal for W\"", "\n", "\n", "return", "grads_b", ",", "grads_w", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv": [[234, 268], ["tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.transpose", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regs", "tensorflow.cast", "core.optimizers.linalg.straight_inverse._true_fisher_inverse", "tensorflow.einsum", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._damping_multiplier", "core.optimizers.linalg.woodberry._optimized_woodberry", "core.optimizers.linalg.straight_inverse._damped_fisher_inverse", "tensorflow.einsum"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regs", "home.repos.pwc.inspect_result.rist-ro_argo.linalg.straight_inverse._true_fisher_inverse", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._damping_multiplier", "home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._optimized_woodberry", "home.repos.pwc.inspect_result.rist-ro_argo.linalg.straight_inverse._damped_fisher_inverse"], ["", "def", "_multiply_grads_by_fisher_inv", "(", "self", ",", "weight_concat", ",", "difference", ",", "weights", ",", "previous_layer", ",", "global_step", ",", "orig_dtype", ",", "\n", "layer", ")", ":", "\n", "        ", "difference", "=", "tf", ".", "cast", "(", "difference", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "weight_concat", "=", "tf", ".", "cast", "(", "weight_concat", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "weights", "=", "tf", ".", "cast", "(", "weights", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "previous_layer", "=", "tf", ".", "cast", "(", "previous_layer", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "alpha", "=", "self", ".", "_diagonal_pad", "\n", "alpha", "=", "tf", ".", "cast", "(", "alpha", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "previous_layer_transpose", "=", "tf", ".", "transpose", "(", "previous_layer", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "if", "self", ".", "_d_p", "is", "None", "or", "self", ".", "_d_p", "==", "0.0", ":", "\n", "            ", "inv_fisher", "=", "_true_fisher_inverse", "(", "U", "=", "previous_layer", ",", "Q", "=", "weights", ",", "U_T", "=", "previous_layer_transpose", ")", "\n", "inverse_x_dif", "=", "tf", ".", "einsum", "(", "'lkn,ln->lk'", ",", "inv_fisher", ",", "difference", ")", "\n", "", "else", ":", "\n", "            ", "def", "inv_fn", "(", ")", ":", "\n", "                ", "if", "(", "self", ".", "_model", ".", "batch_size", "[", "'train'", "]", "*", "self", ".", "_model", ".", "samples", "<", "difference", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "                    ", "inverse_x_dif", "=", "_optimized_woodberry", "(", "U", "=", "previous_layer", ",", "C", "=", "weights", ",", "\n", "V_T", "=", "previous_layer_transpose", ",", "\n", "alpha", "=", "alpha", ",", "\n", "grads", "=", "difference", ",", "layer", "=", "layer", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "inv_fisher", "=", "_damped_fisher_inverse", "(", "U", "=", "previous_layer", ",", "Q", "=", "weights", ",", "U_T", "=", "previous_layer_transpose", ",", "\n", "alpha", "=", "alpha", ")", "\n", "\n", "inverse_x_dif", "=", "tf", ".", "einsum", "(", "'lkn,ln->lk'", ",", "inv_fisher", ",", "difference", ")", "\n", "", "return", "inverse_x_dif", "\n", "\n", "", "inverse_x_dif", "=", "self", ".", "_damping_multiplier", "(", "inv_fn", ",", "alternate_fn", "=", "lambda", ":", "difference", ")", "\n", "\n", "", "self", ".", "_get_natural_regs", "(", "U", "=", "previous_layer", ",", "Q", "=", "weights", ",", "W", "=", "weight_concat", ",", "orig_dtype", "=", "orig_dtype", ")", "\n", "inverse_x_dif", "=", "tf", ".", "cast", "(", "inverse_x_dif", ",", "dtype", "=", "orig_dtype", ")", "\n", "return", "inverse_x_dif", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._damping_multiplier": [[269, 280], ["tensorflow.cond", "tensorflow.identity", "tensorflow.identity", "node_fn", "alternate_fn"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity", "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity"], ["", "def", "_damping_multiplier", "(", "self", ",", "node_fn", ",", "alternate_fn", ")", ":", "\n", "        ", "def", "tru", "(", ")", ":", "\n", "            ", "nody", "=", "tf", ".", "identity", "(", "node_fn", "(", ")", ")", "\n", "return", "nody", "\n", "\n", "", "def", "fal", "(", ")", ":", "\n", "            ", "nody", "=", "tf", ".", "identity", "(", "alternate_fn", "(", ")", ")", "\n", "return", "nody", "\n", "\n", "", "nody", "=", "tf", ".", "cond", "(", "self", ".", "_diagonal_cond", ",", "tru", ",", "fal", ")", "\n", "return", "nody", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regs": [[281, 292], ["tensorflow.transpose", "tensorflow.transpose", "NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._nat_reg.append", "tensorflow.einsum", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.linalg.diag", "tensorflow.einsum"], "methods", ["None"], ["", "def", "_get_natural_regs", "(", "self", ",", "U", ",", "Q", ",", "W", ",", "orig_dtype", ")", ":", "\n", "        ", "if", "self", ".", "_n_reg", ">", "0", ":", "\n", "            ", "U_T", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "W_T", "=", "tf", ".", "transpose", "(", "W", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "regs", "=", "self", ".", "_n_reg", "*", "tf", ".", "einsum", "(", "'nk,kn->nk'", ",", "W_T", ",", "\n", "tf", ".", "einsum", "(", "'kl,ln->kn'", ",", "U", ",", "\n", "tf", ".", "einsum", "(", "'njl,ln->jn'", ",", "tf", ".", "linalg", ".", "diag", "(", "Q", ")", ",", "\n", "tf", ".", "einsum", "(", "'lk,kn->ln'", ",", "\n", "U_T", ",", "W", ")", ")", ")", ")", "\n", "loss", "=", "0.0", "+", "tf", ".", "reduce_sum", "(", "regs", ",", "name", "=", "\"nat_reg\"", ")", "\n", "self", ".", "_nat_reg", ".", "append", "(", "tf", ".", "cast", "(", "loss", ",", "dtype", "=", "orig_dtype", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._get_natural_regularizers": [[294, 300], ["len", "tensorflow.gradients", "tensorflow.add_n"], "methods", ["None"], ["", "", "def", "_get_natural_regularizers", "(", "self", ",", "weights", ")", ":", "\n", "        ", "regs", "=", "[", "0.0", "]", "*", "len", "(", "weights", ")", "\n", "if", "self", ".", "_n_reg", ">", "0", ":", "\n", "            ", "loss", "=", "0.0", "+", "tf", ".", "add_n", "(", "self", ".", "_nat_reg", ",", "name", "=", "\"natural_regularization\"", ")", "\n", "regs", "=", "tf", ".", "gradients", "(", "loss", ",", "weights", ")", "\n", "", "return", "regs", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.get_diagonal_pad": [[10, 44], ["tensorflow.identity", "isinstance", "isinstance", "tensorflow.constant", "tensorflow.train.get_or_create_global_step", "diagonal_pad.items", "tensorflow.summary.scalar", "Exception", "tensorflow.constant", "isinstance", "ValueError", "tensorflow.cond", "float", "dp_kwargs.copy.copy", "getattr", "dp_kwargs.copy.update", "tensorflow.less", "str", "getattr.", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity"], ["def", "get_diagonal_pad", "(", "diagonal_pad", ",", "global_step", ")", ":", "\n", "    ", "dp", "=", "None", "\n", "\n", "if", "diagonal_pad", "is", "None", ":", "\n", "        ", "pass", "\n", "\n", "", "elif", "isinstance", "(", "diagonal_pad", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "        ", "dp", "=", "tf", ".", "constant", "(", "float", "(", "diagonal_pad", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "", "elif", "isinstance", "(", "diagonal_pad", ",", "tuple", ")", ":", "\n", "        ", "dp_min", ",", "dp_name", ",", "dp_kwargs", "=", "diagonal_pad", "\n", "dp_kwargs", "=", "dp_kwargs", ".", "copy", "(", ")", "\n", "dp_method", "=", "getattr", "(", "tf", ".", "train", ",", "dp_name", ")", "\n", "dp_kwargs", ".", "update", "(", "{", "\n", "\"global_step\"", ":", "global_step", "}", ")", "\n", "dp", "=", "dp_min", "+", "dp_method", "(", "**", "dp_kwargs", ")", "\n", "\n", "# instantiate lr node if lr is None and diagonal_pad is a dict at this point", "\n", "", "if", "dp", "is", "None", "and", "isinstance", "(", "diagonal_pad", ",", "dict", ")", ":", "\n", "        ", "if", "not", "0", "in", "diagonal_pad", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"diagonal_pad schedule must specify, learning rate for step 0. Found schedule: %s\"", "%", "diagonal_pad", ")", "\n", "\n", "", "dp", "=", "tf", ".", "constant", "(", "diagonal_pad", "[", "0", "]", ")", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "for", "key", ",", "value", "in", "diagonal_pad", ".", "items", "(", ")", ":", "\n", "            ", "dp", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "less", "(", "global_step", ",", "key", ")", ",", "lambda", ":", "dp", ",", "lambda", ":", "tf", ".", "constant", "(", "value", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"diagonal_pad\"", ",", "dp", ")", "\n", "\n", "", "if", "dp", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"oops, something went wrong... could not process diagonal_pad {}\"", ".", "format", "(", "str", "(", "diagonal_pad", ")", ")", ")", "\n", "\n", "", "return", "tf", ".", "identity", "(", "dp", ",", "name", "=", "\"diagonal_pad\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.__init__": [[28, 72], ["tensorflow.train.SecondOrStepTimer", "datasets.Dataset.check_dataset_keys_not_loop", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "datasets_keys", ",", "\n", "plot_offset", ",", "\n", "tensorboard_dir", "=", "None", ",", "\n", "trigger_summaries", "=", "False", ",", "\n", "extra_feed_dict", "=", "{", "}", ")", ":", "\n", "\n", "        ", "time_choices", "=", "[", "EPOCHS", ",", "STEPS", "]", "\n", "if", "not", "time_reference", "in", "time_choices", ":", "\n", "            ", "raise", "ValueError", "(", "\"time reference attribute can be only in %s\"", "%", "time_choices", ")", "\n", "\n", "", "self", ".", "_timer", "=", "tf", ".", "train", ".", "SecondOrStepTimer", "(", "every_secs", "=", "None", ",", "\n", "every_steps", "=", "period", ")", "\n", "\n", "self", ".", "_time_reference_str", "=", "time_reference", "\n", "self", ".", "_time_ref_shortstr", "=", "self", ".", "_time_reference_str", "[", ":", "2", "]", "\n", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "self", ".", "_plot_offset", "=", "plot_offset", "\n", "self", ".", "_extra_feed_dict", "=", "extra_feed_dict", "\n", "# called in before_run", "\n", "self", ".", "_nodes_to_be_computed_by_run", "=", "{", "}", "\n", "\n", "check_dataset_keys_not_loop", "(", "datasets_keys", ")", "\n", "self", ".", "_datasets_keys", "=", "datasets_keys", "\n", "self", ".", "_ds_initializers", "=", "model", ".", "datasets_initializers", "\n", "self", ".", "_ds_handles_nodes", "=", "model", ".", "datasets_handles_nodes", "\n", "self", ".", "_ds_handle", "=", "model", ".", "ds_handle", "\n", "\n", "# these needs to be defined in the child class", "\n", "self", ".", "_tensors_names", "=", "None", "\n", "self", ".", "_tensors_plots", "=", "None", "\n", "self", ".", "_tensors_values", "=", "None", "\n", "\n", "self", ".", "_trigger_summaries", "=", "trigger_summaries", "\n", "self", ".", "_tensorboard_dir", "=", "tensorboard_dir", "\n", "assert", "not", "self", ".", "_trigger_summaries", "or", "self", ".", "_tensorboard_dir", "is", "not", "None", ",", "\"If you specified that you want to Trigger Summeries, you should also specify where to save them.\"", "\n", "self", ".", "SUMMARIES_KEY", "=", "\"log_mean_summaries\"", "\n", "\n", "self", ".", "_default_plot_bool", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._set_summaries_filewriters": [[73, 81], ["tensorflow.summary.FileWriter"], "methods", ["None"], ["", "def", "_set_summaries_filewriters", "(", "self", ")", ":", "\n", "        ", "\"\"\"This function sets summaryFileWriters for the local summaries\n        it needs to be invoked before training to keep track of the summaries.\n        (better invoke it as late as possible, since the FileWriter will corrupt data in the logfolder at each initialization)\n        \"\"\"", "\n", "# NB do NOT use FileWriterCache, because it will also write the graph in the summary and it will thus do it every time the model is reloaded", "\n", "if", "self", ".", "_trigger_summaries", ":", "\n", "            ", "self", ".", "summary_writers", "=", "tf", ".", "summary", ".", "FileWriter", "(", "self", ".", "_tensorboard_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._register_summary_for_tensor": [[82, 86], ["tensorflow.get_collection", "tensorflow.summary.scalar"], "methods", ["None"], ["", "", "def", "_register_summary_for_tensor", "(", "self", ",", "name", ",", "mn", ")", ":", "\n", "        ", "if", "self", ".", "_trigger_summaries", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "name", ",", "mn", ",", "collections", "=", "[", "self", ".", "SUMMARIES_KEY", "]", ")", "\n", "", "self", ".", "summary_nodes", "=", "tf", ".", "get_collection", "(", "self", ".", "SUMMARIES_KEY", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._write_summaries": [[87, 92], ["run_context.session.run", "ArgoHook.ArgoHook.summary_writers.add_summary"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "_write_summaries", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "if", "self", ".", "_trigger_summaries", ":", "\n", "            ", "summaries", "=", "run_context", ".", "session", ".", "run", "(", "self", ".", "summary_nodes", ")", "\n", "for", "summ", "in", "summaries", ":", "\n", "                ", "self", ".", "summary_writers", ".", "add_summary", "(", "summ", ",", "self", ".", "_global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.log_to_file_and_screen": [[94, 128], ["enumerate", "zip", "len", "enumerate", "zip", "str", "ArgoHook.ArgoHook._log_to_file", "tf_logging.info", "str", "zip", "utils.argo_utils.compose_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._log_to_file", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.compose_name"], ["", "", "", "def", "log_to_file_and_screen", "(", "self", ",", "log_to_screen", "=", "False", ")", ":", "\n", "\n", "        ", "firstLog", "=", "True", "\n", "for", "i", ",", "(", "tensors_vertical_panel", ",", "files_panel", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_files", ")", ")", ":", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "\n", "                ", "if", "firstLog", ":", "\n", "                    ", "time_ref_shortstr", "=", "self", ".", "_time_reference_str", "[", "0", "]", "\n", "logstring", "=", "\"[\"", "+", "time_ref_shortstr", "+", "\" \"", "+", "str", "(", "self", ".", "_time_ref", ")", "+", "\"]\"", "\n", "", "else", ":", "\n", "                    ", "logstring", "=", "\"\"", "\n", "# here it start the vertical panel", "\n", "", "for", "j", ",", "(", "tensors_names_panel", ",", "file_plot", ")", "in", "enumerate", "(", "zip", "(", "tensors_vertical_panel", ",", "files_panel", ")", ")", ":", "\n", "# log to file", "\n", "                    ", "line", "=", "str", "(", "self", ".", "_time_ref", ")", "\n", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "                        ", "logstring", "+=", "\" \"", ".", "join", "(", "\n", "[", "\" \"", "+", "compose_name", "(", "name", ",", "short_name_dataset", "[", "dataset_str", "]", ")", "+", "\" \"", "+", "\"%.4g\"", "%", "mean", "\n", "for", "(", "name", ",", "mean", ")", "in", "zip", "(", "tensors_names_panel", ",", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", ")", "]", ")", "\n", "line", "+=", "\"\\t\"", "+", "\"\\t\"", ".", "join", "(", "[", "\"%.5g\"", "%", "mean", "for", "mean", "in", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "\n", "", "line", "+=", "\"\\t\"", "+", "\"%.2f\"", "%", "self", ".", "_elapsed_secs", "\n", "\n", "line", "+=", "\"\\n\"", "\n", "self", ".", "_log_to_file", "(", "line", ",", "file_plot", ")", "\n", "\n", "", "logstring", "+=", "\"  (%.2fs)\"", "%", "self", ".", "_elapsed_secs", "\n", "\n", "# log to screen", "\n", "if", "firstLog", "and", "log_to_screen", ":", "\n", "                    ", "tf_logging", ".", "info", "(", "logstring", ")", "\n", "firstLog", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.before_run": [[129, 135], ["ArgoHook.ArgoHook._before_run_operations", "ArgoHook.ArgoHook._before_run_args", "tensorflow.train.SessionRunArgs"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._before_run_operations", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook._before_run_args"], ["", "", "", "", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "self", ".", "_before_run_operations", "(", ")", "\n", "\n", "args", "=", "self", ".", "_before_run_args", "(", ")", "\n", "\n", "return", "tf", ".", "train", ".", "SessionRunArgs", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._before_run_args": [[136, 142], ["None"], "methods", ["None"], ["", "def", "_before_run_args", "(", "self", ")", ":", "# , run_context):", "\n", "        ", "args", "=", "{", "\n", "\"globals\"", ":", "(", "self", ".", "_global_step_tensor", ",", "self", ".", "_time_reference_node", ")", ",", "\n", "**", "self", ".", "_nodes_to_be_computed_by_run", "}", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._before_run_operations": [[143, 146], ["ArgoHook.ArgoHook._timer.should_trigger_for_step"], "methods", ["None"], ["", "def", "_before_run_operations", "(", "self", ")", ":", "\n", "        ", "self", ".", "_trigged_for_step", "=", "(", "\n", "self", ".", "_next_step", "is", "not", "None", "and", "self", ".", "_timer", ".", "should_trigger_for_step", "(", "self", ".", "_next_step", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.after_run": [[147, 157], ["ArgoHook.ArgoHook.cast_time_ref", "ArgoHook.ArgoHook._write_summaries"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.cast_time_ref", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._write_summaries"], ["", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "\n", "        ", "self", ".", "_global_step", ",", "time_ref", "=", "run_values", ".", "results", "[", "\"globals\"", "]", "\n", "self", ".", "_time_ref", "=", "self", ".", "cast_time_ref", "(", "time_ref", ")", "\n", "\n", "self", ".", "_next_step", "=", "self", ".", "_global_step", "+", "1", "\n", "\n", "if", "self", ".", "_trigged_for_step", ":", "\n", "# write summaries", "\n", "            ", "self", ".", "_write_summaries", "(", "run_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.after_create_session": [[158, 171], ["session.run", "ArgoHook.ArgoHook._timer.update_last_triggered_step", "session.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "self", ".", "_next_step", "=", "None", "\n", "global_step", "=", "session", ".", "run", "(", "self", ".", "_global_step_tensor", ")", "\n", "\n", "n_past_triggers", "=", "global_step", "//", "self", ".", "_timer", ".", "_every_steps", "\n", "if", "global_step", "%", "self", ".", "_timer", ".", "_every_steps", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "            ", "n_past_triggers", "-=", "1", "\n", "\n", "", "last_trig_step", "=", "n_past_triggers", "*", "self", ".", "_timer", ".", "_every_steps", "\n", "self", ".", "_timer", ".", "update_last_triggered_step", "(", "last_trig_step", ")", "\n", "\n", "# this is needed when evaluting session run and passing the handle", "\n", "self", ".", "_ds_handles", "=", "session", ".", "run", "(", "self", ".", "_ds_handles_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.update_time": [[173, 175], ["ArgoHook.ArgoHook._timer.update_last_triggered_step"], "methods", ["None"], ["", "def", "update_time", "(", "self", ")", ":", "\n", "        ", "self", ".", "_elapsed_secs", ",", "self", ".", "_elapsed_steps", "=", "self", ".", "_timer", ".", "update_last_triggered_step", "(", "self", ".", "_global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.before_training": [[176, 178], ["ArgoHook.ArgoHook._reset_file"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2._reset_file"], ["", "def", "before_training", "(", "self", ",", "session", ")", ":", "\n", "        ", "self", ".", "_reset_file", "(", "session", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._log_to_file": [[179, 183], ["file_panel.write", "file_panel.flush"], "methods", ["None"], ["", "def", "_log_to_file", "(", "self", ",", "line", ",", "file_panel", ")", ":", "\n", "        ", "if", "file_panel", ":", "\n", "            ", "file_panel", ".", "write", "(", "line", ")", "\n", "file_panel", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._create_or_open_files": [[184, 205], ["zip", "zip", "ArgoHook.ArgoHook._filesExist.append", "ArgoHook.ArgoHook._files.append", "filesExist_panel.append", "os.path.isfile", "files_panel.append", "ArgoHook.ArgoHook._write_log_header", "files_panel.append", "open", "open"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._write_log_header"], ["", "", "def", "_create_or_open_files", "(", "self", ")", ":", "\n", "        ", "self", ".", "_filesExist", "=", "[", "]", "\n", "self", ".", "_files", "=", "[", "]", "\n", "for", "(", "tensors_vertical_panels", ",", "tensors_name_vertical_panels", ")", "in", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ":", "\n", "            ", "filesExist_panel", "=", "[", "]", "\n", "files_panel", "=", "[", "]", "\n", "for", "tensors_names_panel", ",", "tensors_plots_panel", "in", "zip", "(", "tensors_vertical_panels", ",", "tensors_name_vertical_panels", ")", ":", "\n", "\n", "# create file handler and open file", "\n", "                ", "filePath", "=", "self", ".", "_dirName", "+", "'/'", "+", "tensors_plots_panel", "[", "\"fileName\"", "]", "+", "'.txt'", "\n", "filesExist_panel", ".", "append", "(", "os", ".", "path", ".", "isfile", "(", "filePath", ")", ")", "\n", "\n", "if", "not", "filesExist_panel", "[", "-", "1", "]", ":", "\n", "                    ", "files_panel", ".", "append", "(", "open", "(", "filePath", ",", "'w'", ")", ")", "\n", "self", ".", "_write_log_header", "(", "files_panel", "[", "-", "1", "]", ",", "tensors_names_panel", ")", "\n", "", "else", ":", "\n", "                    ", "files_panel", ".", "append", "(", "open", "(", "filePath", ",", "'r+'", ")", ")", "\n", "\n", "", "", "self", ".", "_filesExist", ".", "append", "(", "filesExist_panel", ")", "\n", "self", ".", "_files", ".", "append", "(", "files_panel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._write_log_header": [[206, 212], ["ArgoHook.ArgoHook._log_to_file", "utils.argo_utils.compose_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._log_to_file", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.compose_name"], ["", "", "def", "_write_log_header", "(", "self", ",", "file_panel", ",", "tensors_names_panel", ")", ":", "\n", "        ", "header", "=", "self", ".", "_time_reference_str", "+", "\"\\t\"", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "            ", "header", "+=", "\" \"", ".", "join", "(", "[", "\" \"", "+", "compose_name", "(", "name", ",", "dataset_str", ")", "+", "\"\\t \"", "for", "name", "in", "tensors_names_panel", "]", ")", "\n", "", "header", "+=", "\"time_sec\"", "\n", "self", ".", "_log_to_file", "(", "\"# \"", "+", "header", "+", "\"\\n\"", ",", "file_panel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.cast_time_ref": [[213, 219], ["isinstance", "int", "numpy.mod"], "methods", ["None"], ["", "def", "cast_time_ref", "(", "self", ",", "time_ref", ")", ":", "\n", "# for printing purposes if epoch period turns out to be an integer then I don't want to print the zeros, e.g. 1.0", "\n", "        ", "if", "isinstance", "(", "time_ref", ",", "(", "np", ".", "floating", ",", "float", ")", ")", "and", "np", ".", "mod", "(", "time_ref", ",", "1", ")", "==", "0", ":", "\n", "            ", "time_ref", "=", "int", "(", "time_ref", ")", "\n", "\n", "", "return", "time_ref", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._reset_file": [[220, 247], ["range", "len", "range", "len", "session.run", "ArgoHook.ArgoHook.cast_time_ref", "[].readlines", "enumerate", "[].close", "open", "[].writelines", "[].flush", "line.replace().split", "line.replace", "line.startswith", "ArgoHook.ArgoHook._cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.cast_time_ref"], ["", "def", "_reset_file", "(", "self", ",", "session", ")", ":", "\n", "# reset log file", "\n", "# I need to change the handle in the iterator, so I cannot do a for ... in ...", "\n", "# this is not pythonic, sorry for that (Luigi 19/03/19)", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_files", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "self", ".", "_files", "[", "i", "]", ")", ")", ":", "\n", "\n", "                ", "if", "self", ".", "_files", "[", "i", "]", "[", "j", "]", "and", "self", ".", "_filesExist", "[", "i", "]", "[", "j", "]", ":", "\n", "\n", "# remove extra lines from the log file", "\n", "                    ", "time_ref", "=", "session", ".", "run", "(", "self", ".", "_time_reference_node", ")", "\n", "self", ".", "_time_ref", "=", "self", ".", "cast_time_ref", "(", "time_ref", ")", "\n", "\n", "lines", "=", "self", ".", "_files", "[", "i", "]", "[", "j", "]", ".", "readlines", "(", ")", "\n", "c", "=", "0", "\n", "for", "l", ",", "line", "in", "enumerate", "(", "lines", "[", ":", "]", ")", ":", "\n", "                        ", "splited", "=", "line", ".", "replace", "(", "'\\x00'", ",", "''", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "not", "line", ".", "startswith", "(", "\"#\"", ")", "and", "self", ".", "_cast", "(", "splited", "[", "0", "]", ")", ">=", "self", ".", "_time_ref", ":", "\n", "                            ", "break", "\n", "", "c", "=", "c", "+", "1", "\n", "\n", "", "fileName", "=", "self", ".", "_files", "[", "i", "]", "[", "j", "]", ".", "name", "\n", "\n", "self", ".", "_files", "[", "i", "]", "[", "j", "]", ".", "close", "(", ")", "\n", "self", ".", "_files", "[", "i", "]", "[", "j", "]", "=", "open", "(", "fileName", ",", "'w'", ")", "\n", "self", ".", "_files", "[", "i", "]", "[", "j", "]", ".", "writelines", "(", "lines", "[", ":", "c", "]", ")", "\n", "self", ".", "_files", "[", "i", "]", "[", "j", "]", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.begin": [[248, 264], ["ArgoHook.ArgoHook._set_summaries_filewriters", "tensorflow.train.get_global_step", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._set_summaries_filewriters"], ["", "", "", "", "def", "begin", "(", "self", ")", ":", "\n", "# from doc: \"Second call of begin() on the same graph, should not change the graph.\"", "\n", "# https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook", "\n", "\n", "        ", "if", "not", "self", ".", "_did_begin_already", ":", "\n", "            ", "self", ".", "_global_step_tensor", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", "\n", "self", ".", "_global_epoch", "=", "tf", ".", "get_collection", "(", "\"global_epoch\"", ")", "[", "0", "]", "\n", "\n", "if", "self", ".", "_time_reference_str", "==", "EPOCHS", ":", "\n", "                ", "self", ".", "_time_reference_node", "=", "self", ".", "_global_epoch", "\n", "self", ".", "_cast", "=", "float", "\n", "", "elif", "self", ".", "_time_reference_str", "==", "STEPS", ":", "\n", "                ", "self", ".", "_time_reference_node", "=", "self", ".", "_global_step_tensor", "\n", "self", ".", "_cast", "=", "int", "\n", "\n", "", "", "self", ".", "_set_summaries_filewriters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.end": [[265, 271], ["file_panel.close"], "methods", ["None"], ["", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "# close files", "\n", "        ", "for", "vertical_panels", "in", "self", ".", "_files", ":", "\n", "            ", "for", "file_panel", "in", "vertical_panels", ":", "\n", "                ", "if", "file_panel", ":", "\n", "                    ", "file_panel", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.plot": [[272, 404], ["len", "numpy.max", "matplotlib.figure", "matplotlib.figure", "matplotlib.figure.suptitle", "zip", "matplotlib.tight_layout", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.close", "matplotlib.close", "zip", "len", "f.read.split", "len", "matplotlib.figure.add_subplot", "len", "utils.argo_utils.create_list_colors", "enumerate", "plt.figure.add_subplot.set_xlabel", "plt.figure.add_subplot.set_ylabel", "plt.figure.add_subplot.set_xlim", "tensors_plot_panel.get", "plt.figure.add_subplot.get_xticks", "numpy.append", "numpy.append.astype().tolist", "plt.figure.add_subplot.set_xticks", "plt.figure.add_subplot.set_xticklabels", "plt.figure.add_subplot.grid", "open", "f.read", "ArgoHook.ArgoHook._cast", "enumerate", "plt.figure.add_subplot.legend", "tensors_plot_panel.get", "tensors_plot_panel.get", "numpy.append.astype", "row.replace().split", "utils.argo_utils.compose_name", "float", "tensors_plot_panel.get", "pdb.set_trace", "plt.figure.add_subplot.errorbar", "plt.figure.add_subplot.set_yscale", "plt.figure.add_subplot.semilogy", "tensors_plot_panel.get", "plt.figure.add_subplot.errorbar", "plt.figure.add_subplot.plot", "row.replace", "row.split", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.PlotImages.PlotImages.suptitle", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_list_colors", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.compose_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "", "", "", "def", "plot", "(", "self", ")", ":", "\n", "\n", "        ", "if", "not", "self", ".", "_default_plot_bool", ":", "\n", "            ", "return", "\n", "\n", "", "n_columns", "=", "len", "(", "self", ".", "_tensors_plots", ")", "\n", "n_rows", "=", "np", ".", "max", "(", "[", "len", "(", "p", ")", "for", "p", "in", "self", ".", "_tensors_plots", "]", ")", "\n", "\n", "# create figure", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "20", ",", "9", ")", ")", "\n", "fig", ".", "suptitle", "(", "self", ".", "_model", ".", "id", ",", "y", "=", "0.995", ",", "fontsize", "=", "10", ")", "\n", "\n", "c", "=", "0", "\n", "\n", "for", "(", "files_vertical_panels", ",", "tensors_names_vertical_panels", ",", "tensors_plots_vertical_panels", ")", "in", "zip", "(", "self", ".", "_files", ",", "\n", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ":", "\n", "\n", "            ", "r", "=", "0", "\n", "\n", "for", "(", "file_panel", ",", "tensors_names_panel", ",", "tensors_plot_panel", ")", "in", "zip", "(", "files_vertical_panels", ",", "\n", "tensors_names_vertical_panels", ",", "\n", "tensors_plots_vertical_panels", ")", ":", "\n", "\n", "\n", "# read data from file", "\n", "                ", "with", "open", "(", "file_panel", ".", "name", ")", "as", "f", ":", "\n", "                    ", "data", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "split_data", "=", "data", ".", "split", "(", "'\\n'", ")", "\n", "\n", "# remove lines starting with #", "\n", "first_line", "=", "split_data", "[", "0", "]", "\n", "while", "first_line", "[", "0", "]", "==", "\"#\"", ":", "\n", "                    ", "split_data", "=", "split_data", "[", "1", ":", "]", "\n", "first_line", "=", "split_data", "[", "0", "]", "\n", "\n", "\n", "# this is not ok, we should check for the value, not how many I skip", "\n", "", "data", "=", "split_data", "[", "self", ".", "_plot_offset", ":", "-", "1", "]", "\n", "\n", "\n", "x", "=", "[", "self", ".", "_cast", "(", "row", ".", "replace", "(", "'\\x00'", ",", "''", ")", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", ")", "for", "row", "in", "data", "]", "\n", "\n", "n_plots", "=", "len", "(", "tensors_names_panel", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "n_rows", ",", "n_columns", ",", "r", "*", "n_columns", "+", "c", "+", "1", ")", "\n", "\n", "max_colors", "=", "len", "(", "tensors_names_panel", ")", "# see line below to check only 10 colors are generated", "\n", "list_colors", "=", "create_list_colors", "(", "max_colors", ")", "\n", "\n", "for", "color", ",", "name", "in", "enumerate", "(", "tensors_names_panel", ")", ":", "\n", "\n", "                    ", "for", "j", ",", "dataset_str", "in", "enumerate", "(", "self", ".", "_datasets_keys", ")", ":", "\n", "\n", "                        ", "if", "tensors_plot_panel", ".", "get", "(", "\"compose-label\"", ",", "1", ")", ":", "\n", "                            ", "label", "=", "compose_name", "(", "name", ",", "dataset_str", ",", "separator", "=", "\" \"", ")", "\n", "", "else", ":", "\n", "                            ", "label", "=", "name", "\n", "\n", "", "y", "=", "[", "float", "(", "row", ".", "split", "(", "\"\\t\"", ")", "[", "color", "+", "1", "+", "j", "*", "n_plots", "]", ")", "for", "row", "in", "data", "]", "\n", "\n", "if", "tensors_plot_panel", ".", "get", "(", "\"logscale-y\"", ",", "0", ")", ":", "\n", "# check for error bars", "\n", "                            ", "if", "tensors_plot_panel", ".", "get", "(", "\"error-bars\"", ",", "0", ")", "and", "color", "%", "2", "==", "1", ":", "\n", "                                ", "pdb", ".", "set_trace", "(", ")", "\n", "ax", ".", "errorbar", "(", "x", ",", "\n", "y_curve", ",", "\n", "y", ",", "\n", "fmt", "=", "'None'", ",", "\n", "c", "=", "list_colors", "[", "color", "%", "len", "(", "list_colors", ")", "]", ",", "\n", "#ms=20,", "\n", "#mew=4", "\n", ")", "\n", "y_curve", "=", "y", "\n", "ax", ".", "set_yscale", "(", "'log'", ")", "\n", "", "else", ":", "\n", "                                ", "ax", ".", "semilogy", "(", "x", ",", "\n", "y", ",", "\n", "linestyle_dataset", "[", "dataset_str", "]", ",", "\n", "c", "=", "list_colors", "[", "color", "-", "1", "%", "len", "(", "list_colors", ")", "]", ",", "\n", "label", "=", "label", ")", "\n", "y_curve", "=", "y", "\n", "", "", "else", ":", "\n", "# check for error bars", "\n", "                            ", "if", "tensors_plot_panel", ".", "get", "(", "\"error-bars\"", ",", "0", ")", "and", "color", "%", "2", "==", "1", ":", "\n", "                                ", "ax", ".", "errorbar", "(", "x", ",", "\n", "y_curve", ",", "\n", "y", ",", "\n", "fmt", "=", "''", ",", "\n", "linestyle", "=", "'None'", ",", "\n", "c", "=", "list_colors", "[", "color", "-", "1", "%", "len", "(", "list_colors", ")", "]", ",", "\n", "#ms=20,", "\n", "#mew=4", "\n", ")", "\n", "", "else", ":", "\n", "                                ", "ax", ".", "plot", "(", "x", ",", "\n", "y", ",", "\n", "linestyle_dataset", "[", "dataset_str", "]", ",", "\n", "c", "=", "list_colors", "[", "color", "%", "len", "(", "list_colors", ")", "]", ",", "\n", "label", "=", "label", ")", "\n", "y_curve", "=", "y", "\n", "\n", "\n", "\n", "", "", "", "", "ax", ".", "set_xlabel", "(", "self", ".", "_time_reference_str", ")", "\n", "ax", ".", "set_ylabel", "(", "tensors_plot_panel", "[", "\"fileName\"", "]", ")", "\n", "ax", ".", "set_xlim", "(", "left", "=", "self", ".", "_plot_offset", ")", "\n", "\n", "if", "tensors_plot_panel", ".", "get", "(", "\"legend\"", ",", "1", ")", ":", "\n", "                    ", "ax", ".", "legend", "(", ")", "\n", "\n", "# ax.xaxis.set_major_locator(ticker.MultipleLocator(20))", "\n", "# ax.xaxis.set_minor_locator(ticker.MultipleLocator(2))", "\n", "\n", "", "xt", "=", "ax", ".", "get_xticks", "(", ")", "\n", "xt", "=", "np", ".", "append", "(", "xt", ",", "self", ".", "_plot_offset", ")", "\n", "xtl", "=", "xt", ".", "astype", "(", "int", ")", ".", "tolist", "(", ")", "\n", "xtl", "[", "-", "1", "]", "=", "self", ".", "_plot_offset", "\n", "ax", ".", "set_xticks", "(", "xt", ")", "\n", "ax", ".", "set_xticklabels", "(", "xtl", ")", "\n", "\n", "ax", ".", "grid", "(", ")", "\n", "\n", "r", "+=", "1", "\n", "\n", "", "c", "+=", "1", "\n", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "plt", ".", "savefig", "(", "self", ".", "_dirName", "+", "\"/\"", "+", "self", ".", "_fileName", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.__init__": [[16, 45], ["EveryNEpochsTFModelImagesHook.EveryNEpochsTFModelImagesHook.__init__", "tf_logging.info", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._images_indexes.items", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "images_indexes", ",", "\n", "n_images_columns", ",", "\n", "dirName", ",", "\n", "slice_wise", "=", "None", ",", "\n", "pm_one", "=", "True", ",", "\n", "conditional", "=", "False", "\n", ")", ":", "\n", "\n", "# fileName should be set before calling super()", "\n", "        ", "self", ".", "_fileName", "=", "\"reconstructed\"", "\n", "dirName", "=", "dirName", "+", "'/reconstructed_images'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dirName", ",", "pm_one", ")", "\n", "\n", "self", ".", "_images_indexes", "=", "images_indexes", "\n", "self", ".", "_n_images_columns", "=", "n_images_columns", "\n", "self", ".", "_images", "=", "None", "\n", "self", ".", "_masks", "=", "None", "\n", "self", ".", "_labels", "=", "None", "\n", "self", ".", "_slice_wise", "=", "slice_wise", "\n", "self", ".", "_conditional", "=", "conditional", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create ImagesReconstructHook for: \\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "ds_key", "+", "\": \"", "+", "\", \"", ".", "join", "(", "map", "(", "str", ",", "idxs", ")", ")", "for", "ds_key", ",", "idxs", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_images": [[47, 60], ["datasets.Dataset.check_dataset_keys_not_loop", "list", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._images_indexes.keys", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._model.dataset.get_elements", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._images_indexes.items"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements"], ["", "def", "load_images", "(", "self", ",", "session", ")", ":", "\n", "\n", "        ", "if", "self", ".", "_images", "==", "None", ":", "\n", "            ", "check_dataset_keys_not_loop", "(", "list", "(", "self", ".", "_images_indexes", ".", "keys", "(", ")", ")", ")", "\n", "\n", "images", "=", "{", "ds_key", ":", "(", "index_list", ",", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "x", ",", "self", ".", "_ds_handle", ",", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "session", ",", "index_list", ")", ")", "for", "(", "ds_key", ",", "index_list", ")", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "}", "\n", "# I set something like the following structure, e.g.", "\n", "# images = {TRAIN : ([0,100,200,300,400,500], train_images),", "\n", "#           VALIDATION : ([0,100,200,300], validation_images),", "\n", "#          },", "\n", "\n", "self", ".", "_images", "=", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_masks": [[62, 75], ["datasets.Dataset.check_dataset_keys_not_loop", "list", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._images_indexes.keys", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._model.dataset.get_elements", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._images_indexes.items"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements"], ["", "", "def", "load_masks", "(", "self", ",", "session", ")", ":", "\n", "\n", "        ", "if", "self", ".", "_masks", "==", "None", "and", "self", ".", "_model", ".", "mask", "is", "not", "None", ":", "\n", "            ", "check_dataset_keys_not_loop", "(", "list", "(", "self", ".", "_images_indexes", ".", "keys", "(", ")", ")", ")", "\n", "\n", "masks", "=", "{", "ds_key", ":", "(", "index_list", ",", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "mask", ",", "self", ".", "_ds_handle", ",", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "session", ",", "index_list", ")", ")", "for", "(", "ds_key", ",", "index_list", ")", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "}", "\n", "# I set something like the following structure, e.g.", "\n", "# images = {TRAIN : ([0,100,200,300,400,500], train_images),", "\n", "#           VALIDATION : ([0,100,200,300], validation_images),", "\n", "#          },", "\n", "\n", "self", ".", "_masks", "=", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_labels": [[76, 88], ["datasets.Dataset.check_dataset_keys_not_loop", "list", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._images_indexes.keys", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._model.dataset.get_elements", "AbstractImagesReconstructHook.AbstractImagesReconstructHook._images_indexes.items"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements"], ["", "", "def", "load_labels", "(", "self", ",", "session", ")", ":", "\n", "\n", "        ", "if", "self", ".", "_conditional", "and", "self", ".", "_labels", "is", "None", ":", "\n", "            ", "check_dataset_keys_not_loop", "(", "list", "(", "self", ".", "_images_indexes", ".", "keys", "(", ")", ")", ")", "\n", "\n", "labels", "=", "{", "ds_key", ":", "(", "index_list", ",", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "y", ",", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "\n", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "session", ",", "\n", "index_list", ")", ")", "for", "(", "ds_key", ",", "index_list", ")", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "_labels", "=", "labels", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelper.LoggerHelper.__init__": [[10, 25], ["os.path.join", "os.path.join", "LoggerHelper.LoggerHelper._get_mean_ops", "os.makedirs", "os.path.exists", "pandas.read_csv", "pandas.DataFrame", "os.path.getsize"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._get_mean_ops"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "loggername", ",", "tensors_names", ",", "tensor_nodes", ")", ":", "\n", "        ", "self", ".", "_filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "loggername", "+", "\".txt\"", ")", "\n", "self", ".", "_plotfilename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "loggername", "+", "\".png\"", ")", "\n", "self", ".", "_monitor_tensors_values", ",", "self", ".", "_monitor_tensors_updates", ",", "self", ".", "_monitor_tensors_reset", "=", "self", ".", "_get_mean_ops", "(", "tensor_nodes", ")", "\n", "\n", "self", ".", "_pd_csv_kwargs", "=", "{", "\n", "\"sep\"", ":", "\"\\t\"", "\n", "}", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "_filename", ")", "and", "os", ".", "path", ".", "getsize", "(", "self", ".", "_filename", ")", ">", "0", ":", "\n", "            ", "self", ".", "_df", "=", "pd", ".", "read_csv", "(", "self", ".", "_filename", ",", "**", "self", ".", "_pd_csv_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "tensors_names", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelper.LoggerHelper.log": [[27, 31], ["sess.run", "LoggerHelper.LoggerHelper._df.to_csv"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "log", "(", "self", ",", "sess", ",", "epoch", ")", ":", "\n", "        ", "monitor_tensors_values_np", "=", "sess", ".", "run", "(", "self", ".", "_monitor_tensors_values", ")", "\n", "self", ".", "_df", ".", "loc", "[", "epoch", "]", "=", "monitor_tensors_values_np", "\n", "self", ".", "_df", ".", "to_csv", "(", "self", ".", "_filename", ",", "**", "self", ".", "_pd_csv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelper.LoggerHelper.reset": [[32, 34], ["sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "reset", "(", "self", ",", "sess", ")", ":", "\n", "        ", "_", "=", "sess", ".", "run", "(", "self", ".", "_monitor_tensors_reset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelper.LoggerHelper.get_sess_run_args": [[35, 37], ["None"], "methods", ["None"], ["", "def", "get_sess_run_args", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_monitor_tensors_updates", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelper.LoggerHelper.plot": [[38, 43], ["LoggerHelper.LoggerHelper._df.plot", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "plot", "(", "self", ")", ":", "\n", "        ", "self", ".", "_df", ".", "plot", "(", "subplots", "=", "True", ",", "sharex", "=", "True", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "_plotfilename", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelper.LoggerHelper._get_mean_ops": [[44, 54], ["zip", "utils.argo_utils.create_reset_metric"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_reset_metric"], ["", "def", "_get_mean_ops", "(", "self", ",", "tensors", ",", "dataset_str", "=", "\"\"", ")", ":", "\n", "        ", "if", "dataset_str", ":", "\n", "            ", "dataset_str", "+=", "\"_\"", "\n", "\n", "", "mean_v", ",", "mean_u_ops", ",", "mean_r_ops", "=", "zip", "(", "*", "[", "create_reset_metric", "(", "tf", ".", "metrics", ".", "mean", ",", "\n", "scope", "=", "dataset_str", "+", "\"mean_reset_metric/\"", "+", "tnsr", ".", "name", ",", "\n", "values", "=", "tnsr", ")", "\n", "for", "tnsr", "in", "tensors", "]", ")", "\n", "return", "mean_v", ",", "mean_u_ops", ",", "mean_r_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImportanceSamplingHook.ImportanceSamplingHook.__init__": [[20, 66], ["EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info", "str", "str", "range", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "datasets_keys", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "tensors_to_average", ",", "\n", "n_samples", ",", "\n", "batch_size", ",", "\n", "repetitions", ",", "\n", "dirName", ",", "\n", "dataset_keys", "=", "[", "TRAIN", ",", "VALIDATION", "]", ",", "\n", "plot_offset", "=", "0", ",", "\n", "extra_feed_dict", "=", "{", "}", "\n", ")", ":", "\n", "\n", "        ", "dirName", "=", "dirName", "+", "'/importance_sampling'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dataset_keys", ",", "\n", "dirName", "=", "dirName", ",", "\n", "plot_offset", "=", "plot_offset", ",", "\n", "extra_feed_dict", "=", "extra_feed_dict", ")", "\n", "\n", "self", ".", "_n_samples", "=", "n_samples", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_repetitions", "=", "repetitions", "\n", "self", ".", "_label_n_samples", "=", "\"_\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "self", ".", "_n_samples", "]", ")", "\n", "\n", "self", ".", "_tensors_to_average", "=", "tensors_to_average", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create ImportanceSampling for %s samples %d repetitions \"", "%", "(", "\n", "\" \"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "self", ".", "_n_samples", "]", ")", ",", "self", ".", "_repetitions", ")", ")", "\n", "\n", "# nodes to be computed and saved", "\n", "names", "=", "[", "\"is-n\"", "+", "str", "(", "n_samples", ")", "+", "\"-r\"", "+", "str", "(", "rep", ")", "for", "n_samples", "in", "self", ".", "_n_samples", "for", "rep", "in", "\n", "range", "(", "self", ".", "_repetitions", ")", "]", "\n", "\n", "fileName", "=", "\"importance_sampling-n\"", "+", "\"_\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "n_samples", "]", ")", "\n", "self", ".", "_tensors_names", "=", "[", "[", "names", "]", "]", "\n", "self", ".", "_tensors_plots", "=", "[", "[", "{", "\n", "'fileName'", ":", "fileName", ",", "\n", "'logscale-y'", ":", "0", "}", "]", "]", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "self", ".", "_fileName", "=", "\"importance_sampling\"", "+", "\"_\"", "+", "self", ".", "_label_n_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImportanceSamplingHook.ImportanceSamplingHook._begin_once": [[71, 81], ["zip", "utils.argo_utils.create_reset_metric"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_reset_metric"], ["def", "_begin_once", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "_mean_values", "=", "{", "}", "\n", "self", ".", "_mean_update_ops", "=", "{", "}", "\n", "self", ".", "_mean_reset_ops", "=", "{", "}", "\n", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "            ", "self", ".", "_mean_values", "[", "dataset_str", "]", ",", "self", ".", "_mean_update_ops", "[", "dataset_str", "]", ",", "self", ".", "_mean_reset_ops", "[", "dataset_str", "]", "=", "zip", "(", "\n", "*", "[", "create_reset_metric", "(", "tf", ".", "metrics", ".", "mean", ",", "scope", "=", "dataset_str", "+", "\"_mean_reset_metric/\"", "+", "tnsr", ".", "name", "+", "\"/\"", "+", "self", ".", "_label_n_samples", ",", "\n", "values", "=", "tnsr", ")", "for", "tnsr", "in", "self", ".", "_tensors_to_average", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImportanceSamplingHook.ImportanceSamplingHook.do_when_triggered": [[82, 134], ["tf_logging.info", "ImportanceSamplingHook.ImportanceSamplingHook.log_to_file_and_screen", "range", "range", "scipy.special.logsumexp", "numpy.log", "numpy.mean", "np_values.append", "int", "min", "run_context.session.run", "numpy.ceil", "numpy.concatenate", "run_context.session.run", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.log_to_file_and_screen", "home.repos.pwc.inspect_result.rist-ro_argo.core.ELBO_IAF.logsumexp", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for ImportanceSampling\"", ")", "\n", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "            ", "np_values", "=", "[", "]", "\n", "for", "n", "in", "self", ".", "_n_samples", ":", "\n", "\n", "                ", "for", "i", "in", "range", "(", "self", ".", "_repetitions", ")", ":", "\n", "                    ", "mean_value", "=", "0", "\n", "\n", "imp_sampling", "=", "None", "\n", "to_be_done", "=", "n", "\n", "for", "j", "in", "range", "(", "int", "(", "np", ".", "ceil", "(", "n", "/", "self", ".", "_batch_size", ")", ")", ")", ":", "\n", "\n", "                        ", "k", "=", "min", "(", "to_be_done", ",", "self", ".", "_batch_size", ")", "\n", "to_be_done", "=", "to_be_done", "-", "k", "\n", "\n", "init_ops", "=", "(", "self", ".", "_ds_initializers", "[", "dataset_str", "]", ")", "\n", "run_context", ".", "session", ".", "run", "(", "init_ops", ")", "\n", "imp_sampling_ds", "=", "None", "\n", "while", "True", ":", "\n", "                            ", "try", ":", "\n", "                                ", "imp_sampling_batch", "=", "run_context", ".", "session", ".", "run", "(", "self", ".", "_tensors_to_average", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "_model", ".", "n_z_samples", ":", "k", ",", "\n", "self", ".", "_ds_handle", ":", "\n", "self", ".", "_ds_handles", "[", "\n", "dataset_str", "]", ",", "\n", "\n", "**", "self", ".", "_extra_feed_dict", "}", "\n", ")", "\n", "if", "imp_sampling_ds", "is", "None", ":", "\n", "                                    ", "imp_sampling_ds", "=", "imp_sampling_batch", "\n", "", "else", ":", "\n", "                                    ", "imp_sampling_ds", "=", "np", ".", "concatenate", "(", "[", "imp_sampling_ds", ",", "imp_sampling_batch", "]", ",", "axis", "=", "1", ")", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                                ", "break", "\n", "# now I have a complete pass over the dataset, for the jth chunk", "\n", "", "", "if", "imp_sampling", "is", "None", ":", "\n", "                            ", "imp_sampling", "=", "imp_sampling_ds", "\n", "", "else", ":", "\n", "                            ", "imp_sampling", "=", "np", ".", "concatenate", "(", "[", "imp_sampling", ",", "imp_sampling_ds", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "imp_sampling_group_chunks", "=", "spl", ".", "logsumexp", "(", "imp_sampling", ",", "axis", "=", "0", ")", "\n", "imp_sampling_group_chunks", "-=", "np", ".", "log", "(", "n", ")", "\n", "mean_value", "=", "np", ".", "mean", "(", "imp_sampling_group_chunks", ")", "\n", "\n", "np_values", ".", "append", "(", "mean_value", ")", "\n", "\n", "", "", "self", ".", "_tensors_values", "[", "dataset_str", "]", "=", "[", "[", "np_values", "]", "]", "\n", "\n", "", "self", ".", "log_to_file_and_screen", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook.__init__": [[34, 100], ["model._get_steps", "LoggingMeanTensorsHook.LoggingMeanTensorsHook.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "#fileName,", "\n", "dirName", ",", "\n", "#tensors_to_average,", "\n", "#tensors_to_average_names,", "\n", "#tensors_to_average_plots,", "\n", "period", ",", "\n", "#tensorboard_dir,", "\n", "#trigger_summaries,", "\n", "#print_to_screen=False,", "\n", "plot_offset", "=", "0", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "# datasets_keys=[VALIDATION],", "\n", "time_reference", "=", "\"epochs\"", "\n", ")", ":", "\n", "\n", "\n", "        ", "fileName", "=", "\"fisher_matrix\"", "\n", "dirName", "=", "dirName", "+", "'/fisher'", "\n", "average_steps", "=", "model", ".", "_get_steps", "(", "period", ",", "time_reference", ")", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "tensors_to_average", "=", "[", "\n", "[", "[", "model", ".", "_optimizer", ".", "_invFisher_D", "]", ",", "\n", "[", "model", ".", "_optimizer", ".", "_invFisher_S", "]", ",", "\n", "[", "model", ".", "_optimizer", ".", "_invFisher_V", "]", "\n", "]", ",", "\n", "]", "\n", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "\"invFisher_D\"", "]", ",", "\n", "[", "\"invFisher_S\"", "]", ",", "\n", "[", "\"invFisher_V\"", "]", "\n", "]", ",", "\n", "]", "\n", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\"fileName\"", ":", "\"invFisher_D\"", "}", ",", "\n", "{", "\"fileName\"", ":", "\"invFisher_S\"", "}", ",", "\n", "{", "\"fileName\"", ":", "\"invFisher_V\"", "}", "\n", "]", "\n", "]", "\n", "\n", "\n", "super", "(", "FisherMatrixHook", ",", "self", ")", ".", "__init__", "(", "model", ",", "\n", "fileName", ",", "\n", "dirName", ",", "\n", "tensors_to_average", ",", "\n", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "average_steps", ",", "\n", "tensorboard_dir", "=", "None", ",", "\n", "trigger_summaries", "=", "False", ",", "\n", "# trigger_plot = True,", "\n", "print_to_screen", "=", "False", ",", "\n", "plot_offset", "=", "0", ",", "\n", "train_loop_key", "=", "train_loop_key", ",", "\n", "datasets_keys", "=", "[", "]", ",", "#dataset_keys,", "\n", "time_reference", "=", "time_reference", "\n", ")", "\n", "\n", "# reset the default metric", "\n", "self", ".", "_default_metric", "=", "tf", ".", "metrics", ".", "mean_tensor", "\n", "\n", "print", "(", "\"FisherMatrixHook has been enabled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook.after_run": [[101, 106], ["super().after_run", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.after_run"], ["", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "if", "self", ".", "_trigged_for_step", ":", "\n", "            ", "tf_logging", ".", "info", "(", "\"trigger for FisherMatrixHook\"", ")", "\n", "\n", "", "super", "(", ")", ".", "after_run", "(", "run_context", ",", "run_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook.plot": [[107, 258], ["enumerate", "zip", "len", "enumerate", "numpy.load", "numpy.load", "numpy.load", "len", "numpy.dot", "numpy.zeros", "enumerate", "zip", "str().zfill", "str().zfill", "str().zfill", "enumerate", "numpy.load", "matplotlib.figure", "matplotlib.figure", "numpy.mean", "matplotlib.hist", "matplotlib.hist", "matplotlib.savefig", "matplotlib.savefig", "numpy.sum", "numpy.sum", "str().zfill", "str", "str", "str", "numpy.dot", "matplotlib.imsave", "matplotlib.imsave", "range", "str().zfill", "numpy.absolute", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "plot", "(", "self", ")", ":", "\n", "        ", "for", "i", ",", "(", "tensors_vertical_panel", ",", "files_panel", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ")", ":", "\n", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "\n", "# here it start the vertical panel", "\n", "                ", "for", "j", ",", "(", "tensors_names_panel", ",", "file_save", ")", "in", "enumerate", "(", "zip", "(", "tensors_vertical_panel", ",", "files_panel", ")", ")", ":", "\n", "                    ", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "\n", "                        ", "filePath", "=", "self", ".", "_dirName", "+", "'/'", "+", "file_save", "[", "\"fileName\"", "]", "+", "'_'", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "#d = self._tensors_values[dataset_str][i][j][0]", "\n", "m", "=", "np", ".", "load", "(", "filePath", "+", "'.npy'", ")", "\n", "\n", "plt", ".", "figure", "(", ")", "\n", "mean", "=", "np", ".", "mean", "(", "m", ",", "axis", "=", "1", ")", "\n", "plt", ".", "hist", "(", "mean", ",", "bins", "=", "100", ")", "\n", "plt", ".", "savefig", "(", "filePath", "+", "'.png'", ")", "\n", "\n", "\n", "# invFisher_D", "\n", "", "", "filePath", "=", "self", ".", "_dirName", "+", "'/invFisher_D_'", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "D", "=", "np", ".", "load", "(", "filePath", "+", "'.npy'", ")", "\n", "\n", "# invFisher_V", "\n", "filePath", "=", "self", ".", "_dirName", "+", "'/invFisher_V_'", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "V", "=", "np", ".", "load", "(", "filePath", "+", "'.npy'", ")", "\n", "\n", "# invFisher_S", "\n", "filePath", "=", "self", ".", "_dirName", "+", "'/invFisher_S_'", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "S", "=", "np", ".", "load", "(", "filePath", "+", "'.npy'", ")", "\n", "\n", "\n", "# computing aggregated statistics", "\n", "ws", "=", "self", ".", "_model", ".", "_optimizer", ".", "_n_weights_layers", "\n", "l", "=", "len", "(", "ws", ")", "\n", "VS", "=", "np", ".", "dot", "(", "V", ",", "S", ")", "\n", "\n", "#'''", "\n", "# full Fisher", "\n", "C", "=", "np", ".", "zeros", "(", "(", "np", ".", "sum", "(", "ws", ")", ",", "np", ".", "sum", "(", "ws", ")", ")", ")", "\n", "\n", "sum_i", "=", "0", "\n", "for", "ind_i", ",", "i", "in", "enumerate", "(", "ws", ")", ":", "\n", "                    ", "sum_j", "=", "0", "\n", "for", "ind_j", ",", "j", "in", "enumerate", "(", "ws", ")", ":", "\n", "                        ", "if", "ind_j", ">=", "ind_i", ":", "\n", "#print(i,j)", "\n", "                            ", "M", "=", "np", ".", "dot", "(", "VS", "[", "sum_i", ":", "sum_i", "+", "i", ",", ":", "]", ",", "V", "[", "sum_j", ":", "sum_j", "+", "j", ",", ":", "]", ".", "T", ")", "\n", "\n", "if", "ind_i", "==", "ind_j", ":", "\n", "# add to the diagonal without creating the diagonal matrix and summing", "\n", "                                ", "for", "k", "in", "range", "(", "i", ")", ":", "\n", "# this is needed so that the diagonal does not count in the mean above", "\n", "                                    ", "M", "[", "k", ",", "k", "]", "=", "D", "[", "sum_i", "+", "k", "]", "\n", "\n", "", "", "filePath", "=", "self", ".", "_dirName", "+", "'/invFisher_'", "+", "str", "(", "ind_i", ")", "+", "'_'", "+", "str", "(", "ind_j", ")", "+", "'_'", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "M", "=", "-", "np", ".", "absolute", "(", "M", ")", "\n", "#pdb.set_trace()", "\n", "plt", ".", "imsave", "(", "filePath", ",", "M", ",", "cmap", "=", "\"gray\"", ")", "\n", "\n", "#print(M)", "\n", "#M[0,:] = 0", "\n", "#M[-1,:] = 0", "\n", "#M[:,0] = 0", "\n", "#M[:,-1] = 0", "\n", "\n", "#C[sum_i:sum_i+i,sum_j:sum_j+j] = M", "\n", "#C[sum_j:sum_j+j,sum_i:sum_i+i] = M.T", "\n", "#pdb.set_trace()", "\n", "", "sum_j", "+=", "j", "\n", "", "sum_i", "+=", "i", "\n", "\n", "", "'''\n                plt.figure(figsize=(20, 20))\n                plt.matshow(C, fignum=1, cmap=plt.cm.gray)\n                #plt.xticks(range(l), df.columns, fontsize=14, rotation=45)\n                #plt.yticks(range(l), df.columns, fontsize=14)\n                #cb = plt.colorbar()\n                #cb.ax.tick_params(labelsize=14)\n                #plt.title('correlation matrix') #, fontsize=16);\n                '''", "\n", "\n", "'''\n                pdb.set_trace() \n                fig, axes = plt.subplots(1,1)\n                fig.set_size_inches(20, 20)\n                img = axes.imshow(C[-1000:,-1000:], cmap=plt.cm.gray)\n                #img = axes.imshow(M, cmap=plt.cm.gray)\n                print(C.shape)\n                plt.colorbar(img)\n                plt.tight_layout()\n                \n                filePath = self._dirName + '/invFisher_' + self._time_reference_str[0] + str(self._time_ref) \n                plt.savefig(filePath + '.png')\n                '''", "\n", "\n", "\n", "''' aggregated\n\n                Cmean = np.zeros((l,l))\n                Cstd = np.zeros((l,l))\n\n                sum_i = 0\n                for ind_i, i in enumerate(ws):\n                    sum_j = 0\n                    for ind_j, j in enumerate(ws):\n                        if ind_j>=ind_i:\n                            #print(i,j)\n                            M = np.dot(VS[sum_i:sum_i+i,:],V[sum_j:sum_j+j,:].T)\n                            if ind_i==ind_j:\n                                # add to the diagonal without creating the diagonal matrix and summing\n                                for k in range(i):\n                                    # this is needed so that the diagonal does not count in the mean above\n                                    M[k,k] = 0 #D[sum_i+k]\n                            mean = np.mean(M)\n                            #std = np.sqrt(np.mean(np.power(M,2) - mean**2))\n                            # free memory\n                            M = M[::2,::2]\n                            std = np.std(M)\n                            Cmean[ind_i,ind_j] = mean\n                            Cmean[ind_j,ind_i] = mean\n                            Cstd[ind_i,ind_j] = std\n                            Cstd[ind_j,ind_i] = std\n                            #pdb.set_trace()\n                        sum_j += j\n                    sum_i += i\n                \n                plt.figure() #figsize=(19, 15))\n                plt.matshow(Cmean) # fignum=f.number)\n                #plt.xticks(range(l), df.columns, fontsize=14, rotation=45)\n                #plt.yticks(range(l), df.columns, fontsize=14)\n                cb = plt.colorbar()\n                #cb.ax.tick_params(labelsize=14)\n                #plt.title('correlation matrix') #, fontsize=16);\n\n                filePath = self._dirName + '/invFisher_layer_mean_' + self._time_reference_str[0] + str(self._time_ref) \n                plt.savefig(filePath + '.png')\n\n\n                plt.figure() #figsize=(19, 15))\n                plt.matshow(Cstd) # fignum=f.number)\n                #plt.xticks(range(l), df.columns, fontsize=14, rotation=45)\n                #plt.yticks(range(l), df.columns, fontsize=14)\n                cb = plt.colorbar()\n                #cb.ax.tick_params(labelsize=14)\n                #plt.title('correlation matrix') #, fontsize=16);\n\n                filePath = self._dirName + '/invFisher_layer_std_' + self._time_reference_str[0] + str(self._time_ref) \n                plt.savefig(filePath + '.png')\n                '''", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook.log_to_file_and_screen": [[259, 299], ["enumerate", "zip", "len", "enumerate", "zip", "numpy.save", "numpy.save", "str().zfill", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "", "", "def", "log_to_file_and_screen", "(", "self", ",", "log_to_screen", "=", "False", ")", ":", "\n", "\n", "#firstLog = True", "\n", "\n", "        ", "for", "i", ",", "(", "tensors_vertical_panel", ",", "files_panel", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ")", ":", "\n", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "\n", "                ", "'''\n                if firstLog:\n                    time_ref_shortstr = self._time_reference_str[0]\n                    logstring = \"[\" + time_ref_shortstr + \" \" + str(self._time_ref) + \"]\"\n                else:\n                    logstring = \"\"\n                '''", "\n", "# here it start the vertical panel", "\n", "for", "j", ",", "(", "tensors_names_panel", ",", "file_save", ")", "in", "enumerate", "(", "zip", "(", "tensors_vertical_panel", ",", "files_panel", ")", ")", ":", "\n", "# log to file", "\n", "#line = str(self._time_ref)", "\n", "\n", "                    ", "'''\n                    for dataset_str in self._datasets_keys:\n                        logstring += \" \".join(\n                            [\" \" + compose_name(name, short_name_dataset[dataset_str]) + \" \" + \"%.4g\" \n                             #for (name, mean) in zip(tensors_names_panel, self._tensors_values[dataset_str][i][j][0])])\n                             for name in tensors_names_panel])\n                    '''", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "####################", "\n", "# notice the mean[0]", "\n", "#line += \"\\t\" + \"\\t\".join([\"%.5g\" % str(mean[0]) for mean in self._tensors_values[dataset_str][i][oj]])", "\n", "\n", "                        ", "filePath", "=", "self", ".", "_dirName", "+", "'/'", "+", "file_save", "[", "\"fileName\"", "]", "+", "'_'", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "d", "=", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "[", "0", "]", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "\n", "filePath", "=", "self", ".", "_dirName", "+", "'/'", "+", "file_save", "[", "\"fileName\"", "]", "+", "'_'", "+", "'step'", "+", "'_'", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "d", "=", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "[", "0", "]", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook._after_run": [[316, 333], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "_after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "\n", "#pdb.set_trace()", "\n", "\n", "        ", "'''\n        self._tensors_values[self.model._optimizer._invFisher_D] = run_context.session.run(\n            self._mean_values[self._train_loop_key])\n\n        # mean over the other dataset_keys\n        for dataset_str in self._no_train_loop_datasets_keys:\n            self._tensors_values[dataset_str] = evaluate_over_dataset(run_context.session,\n                                                                      self._ds_handle,\n                                                                      self._ds_initializers[dataset_str],\n                                                                      self._ds_handles[dataset_str],\n                                                                      self._mean_values[dataset_str])\n\n        '''", "\n", "", "def", "_create_or_open_files", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook._create_or_open_files": [[333, 335], ["None"], "methods", ["None"], ["", "def", "_create_or_open_files", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook._reset_file": [[336, 338], ["None"], "methods", ["None"], ["", "def", "_reset_file", "(", "self", ",", "session", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FisherMatrixHook.FisherMatrixHook.end": [[339, 341], ["None"], "methods", ["None"], ["", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianHook.__init__": [[24, 50], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info", "int"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "datasets_keys", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "record_eigenvalues", ",", "\n", "block_size_megabytes", ",", "\n", "dirName", ")", ":", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "+", "'/hessian'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dirName", "=", "self", ".", "_dirName", ")", "\n", "\n", "self", ".", "_handle", "=", "model", ".", "ds_handle", "\n", "self", ".", "_ds_initializers", "=", "model", ".", "datasets_initializers", "\n", "self", ".", "_ds_handles_nodes", "=", "model", ".", "datasets_handles_nodes", "\n", "\n", "self", ".", "_record_eigenvalues", "=", "record_eigenvalues", "\n", "\n", "# Block size is expressed in number of elements (float64 - hence the division by 8 bytes)", "\n", "self", ".", "_block_size", "=", "int", "(", "block_size_megabytes", "*", "1024", "*", "1024", ")", "//", "8", "\n", "\n", "self", ".", "_period", "=", "period", "\n", "self", ".", "_datasets_keys", "=", "datasets_keys", "\n", "self", ".", "_hook_name", "=", "\"hessian_hook\"", "\n", "tf_logging", ".", "info", "(", "\"Create HessianHook for: \"", "+", "\", \"", ".", "join", "(", "datasets_keys", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianHook._begin_once": [[51, 94], ["tensorflow.variable_scope", "tensorflow.trainable_variables", "tensorflow.group", "tensorflow.group", "tensorflow.group", "tensorflow.group", "tensorflow.trainable_variables", "HessianHook.my_loss_full_logits", "HessianHook.HessianGatherer", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.my_loss_full_logits"], ["", "def", "_begin_once", "(", "self", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'HessianHook'", ")", ":", "\n", "# Define two temp groups: one for storing past values for variables and one for storing current ones.", "\n", "            ", "temp_group_past", "=", "{", "}", "\n", "temp_group_current", "=", "{", "}", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "                ", "temp_group_past", "[", "var", ".", "name", "]", "=", "tf", ".", "Variable", "(", "initial_value", "=", "var", ",", "trainable", "=", "False", ")", "\n", "temp_group_current", "[", "var", ".", "name", "]", "=", "tf", ".", "Variable", "(", "initial_value", "=", "var", ",", "trainable", "=", "False", ")", "\n", "\n", "# Define 4 operations: two for storing variable values into temp, and two for loading from temps.", "\n", "# OP1. Store to 'past' register.", "\n", "", "self", ".", "_store_to_past_op", "=", "tf", ".", "group", "(", "[", "tf", ".", "assign", "(", "temp_group_past", "[", "var", ".", "name", "]", ",", "var", ")", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "# OP2. Load from 'past' register.", "\n", "self", ".", "_load_from_past_op", "=", "tf", ".", "group", "(", "[", "tf", ".", "assign", "(", "var", ",", "temp_group_past", "[", "var", ".", "name", "]", ")", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "# OP3. Store to 'current' register.", "\n", "self", ".", "_store_to_current_op", "=", "tf", ".", "group", "(", "[", "tf", ".", "assign", "(", "temp_group_current", "[", "var", ".", "name", "]", ",", "var", ")", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "# OP4. Load from 'current' register.", "\n", "self", ".", "_load_from_current_op", "=", "tf", ".", "group", "(", "[", "tf", ".", "assign", "(", "var", ",", "temp_group_current", "[", "var", ".", "name", "]", ")", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "# For debug purposes, define an op that evaluates all variables.", "\n", "self", ".", "_eval_vars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "self", ".", "_eval_temp_current", "=", "[", "temp_group_current", "[", "var", ".", "name", "]", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "]", "\n", "self", ".", "_eval_temp_past", "=", "[", "temp_group_past", "[", "var", ".", "name", "]", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "]", "\n", "\n", "# TODO: currently, the loss does not depend on the ACTUAL loss of the model. This needs to be fixed.", "\n", "loss", "=", "my_loss_full_logits", "(", "self", ".", "_model", ".", "raw_y", ",", "self", ".", "_model", ".", "logits", ")", "\n", "\n", "self", ".", "hessian_gatherer", "=", "HessianGatherer", "(", "y", "=", "loss", ",", "\n", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", ",", "\n", "block_size", "=", "self", ".", "_block_size", ")", "\n", "\n", "", "self", ".", "_nodes_to_be_computed_by_run", "[", "\"x\"", "]", "=", "self", ".", "_model", ".", "raw_x", "\n", "self", ".", "_nodes_to_be_computed_by_run", "[", "\"y\"", "]", "=", "self", ".", "_model", ".", "raw_y", "\n", "# This will not return anything, but it will store the weights of the model in the temp register.", "\n", "self", ".", "_nodes_to_be_computed_by_run", "[", "\"store_to_past\"", "]", "=", "self", ".", "_store_to_past_op", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianHook.after_create_session": [[102, 105], ["super().after_create_session", "session.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "self", ".", "_ds_handles", "=", "session", ".", "run", "(", "self", ".", "_ds_handles_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianHook.do_when_triggered": [[106, 150], ["tf_logging.info", "session.run", "session.run", "HessianHook.HessianHook.hessian_gatherer.get_hessian", "session.run", "numpy.save", "str().zfill", "os.path.join", "scipy.linalg.eigvalsh", "numpy.save", "str().zfill", "os.path.join", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.VariablePairHessianGatherer.get_hessian", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "def", "do_when_triggered", "(", "self", ",", "global_step", ",", "time_ref", ",", "run_context", ",", "run_values", ",", "time_ref_str", "=", "\"ep\"", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for HessianHook\"", ")", "\n", "\n", "# Get values relevant for hessian computation.", "\n", "session", "=", "run_context", ".", "session", "\n", "x", "=", "run_values", ".", "results", "[", "\"x\"", "]", "\n", "y", "=", "run_values", ".", "results", "[", "\"y\"", "]", "\n", "\n", "# TODO: Maybe move this comment to either the class doc or to the file doc.", "\n", "\"\"\"\n        We need to have a pair of (input, weights) that represent the same time point, i.e., both of them are used \n        together to compute a gradient update at some point in time (either 'this' step or the next one). \n        In order to compute the Hessian, we can pick either the (input, weights) pair representing the \n        previous -- most recently computed -- step, or the next one (the one that will be computed in the future).\n        We currently have access to the previous inputs by registering them in the run op, and next step weights since\n        they are the result of the previous step update op. It is hard to access the future inputs because of dataset\n        iterators, so we chose to access the previous step weights: we do this by registering them in a temporary\n        register at sess.run() time and recover them from that temp variable at hessian computation time. For \n        book keeping, we also need to store the current weight values to another temp variable, since we need to restore\n        them when we are done computing the Hessian.\n        \"\"\"", "\n", "\n", "# Store the current weight values in a temp register:", "\n", "session", ".", "run", "(", "self", ".", "_store_to_current_op", ")", "\n", "\n", "# Load the weight values as they were before the grad update.", "\n", "session", ".", "run", "(", "self", ".", "_load_from_past_op", ")", "\n", "\n", "# Compute hessian on previous value of variables using previous inputs.", "\n", "hess", "=", "self", ".", "hessian_gatherer", ".", "get_hessian", "(", "sess", "=", "session", ",", "feed_dict", "=", "{", "self", ".", "_model", ".", "raw_x", ":", "x", ",", "self", ".", "_model", ".", "raw_y", ":", "y", "}", ")", "\n", "\n", "# Restore the weight values as they were after the most recent grad update.", "\n", "session", ".", "run", "(", "self", ".", "_load_from_current_op", ")", "\n", "\n", "# Save the hessian to a .npy file.", "\n", "hess_file_name", "=", "'hessian_'", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_dirName", ",", "hess_file_name", ")", ",", "hess", ")", "\n", "\n", "# Save the eigenvalues if requested.", "\n", "if", "self", ".", "_record_eigenvalues", ":", "\n", "            ", "lambdas", "=", "eigvalsh", "(", "hess", ")", "\n", "\n", "lambdas_file_name", "=", "'eigenvalues_'", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_dirName", ",", "lambdas_file_name", ")", ",", "lambdas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianGatherer.__init__": [[165, 184], ["HessianHook.HessianGatherer._build_slice_map", "HessianHook.HessianGatherer._build_hessian_op_grid"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianGatherer._build_slice_map", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.VariablePairHessianGatherer._build_hessian_op_grid"], ["def", "__init__", "(", "self", ",", "y", ",", "var_list", ",", "block_size", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the hessian gatherer object.\n\n        :param y:                   The value to differentiate. If a rank 1 tensor is specified, a rank 3 tensor will be\n                                    computed instead of a rank 2 one. The GPU computation will proceed by evaluating the\n                                        hessian for all of those values at once - adjust the block size accordingly!\n        :param var_list:            List of tf.Variable objects for which to compute the Hessian.\n        :param block_size:          The hessian is evaluated on the GPU in blocks - this specifies the (maximum) number\n                                        of elements in these blocks.\n        \"\"\"", "\n", "\n", "self", ".", "_var_list", "=", "var_list", "\n", "self", ".", "_build_slice_map", "(", ")", "\n", "\n", "self", ".", "_block_size", "=", "block_size", "\n", "\n", "# Build the computational graph.", "\n", "self", ".", "_op_grid", "=", "self", ".", "_build_hessian_op_grid", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianGatherer.get_hessian": [[185, 219], ["numpy.zeros", "range", "len", "range", "len", "pairwise_hess_gatherer.get_hessian"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.VariablePairHessianGatherer.get_hessian"], ["", "def", "get_hessian", "(", "self", ",", "sess", ",", "feed_dict", ")", ":", "\n", "        ", "\"\"\"\n        Computes the hessian block-wise using pairs of vars and returns it as a numpy array.\n\n        :param sess:        Tensorflow session.\n        :param feed_dict:   Feed dict to pass on to sess.run()\n        :return:            ndarray of hessian.\n        \"\"\"", "\n", "\n", "# Redefining for readability", "\n", "full_width", "=", "self", ".", "_full_width", "\n", "\n", "# The output hessian in its full width and glory.", "\n", "full_hessian", "=", "np", ".", "zeros", "(", "shape", "=", "(", "full_width", ",", "full_width", ")", ")", "\n", "\n", "# Iterate over pairs of variables and compute the chunk of the Hessian that represents the second derivative", "\n", "#   with respect to all of the elements of the two variables.", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_var_list", ")", ")", ":", "\n", "            ", "i_var", "=", "self", ".", "_var_list", "[", "i", "]", "\n", "i_start_ix", ",", "i_end_ix", "=", "self", ".", "_slice_map", "[", "i_var", ".", "name", "]", "\n", "\n", "for", "j", "in", "range", "(", "i", ",", "len", "(", "self", ".", "_var_list", ")", ")", ":", "\n", "                ", "j_var", "=", "self", ".", "_var_list", "[", "j", "]", "\n", "j_start_ix", ",", "j_end_ix", "=", "self", ".", "_slice_map", "[", "j_var", ".", "name", "]", "\n", "\n", "# Gather the hessian block representing the derivatives wrt the variable pair.", "\n", "pairwise_hess_gatherer", "=", "self", ".", "_op_grid", "[", "i", "]", "[", "j", "]", "\n", "hess_block", "=", "pairwise_hess_gatherer", ".", "get_hessian", "(", "sess", ",", "feed_dict", ")", "\n", "\n", "# Assign the hessian block to its corresponding place in the hessian (takes into account symmetry).", "\n", "full_hessian", "[", "i_start_ix", ":", "i_end_ix", ",", "j_start_ix", ":", "j_end_ix", "]", "=", "hess_block", "\n", "full_hessian", "[", "j_start_ix", ":", "j_end_ix", ",", "i_start_ix", ":", "i_end_ix", "]", "=", "hess_block", ".", "T", "\n", "\n", "", "", "return", "full_hessian", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianGatherer._build_hessian_op_grid": [[220, 234], ["len", "range", "range", "HessianHook.VariablePairHessianGatherer"], "methods", ["None"], ["", "def", "_build_hessian_op_grid", "(", "self", ",", "y", ")", ":", "\n", "        ", "n_vars", "=", "len", "(", "self", ".", "_var_list", ")", "\n", "\n", "# Build a grid(i,j) of VariablePairHessianGatherer objects that represent the Hessian chunk wrt", "\n", "#   elements of Tensorflow variables i and j.", "\n", "pairwise_hess_grid", "=", "[", "x", "[", ":", "]", "for", "x", "in", "[", "[", "None", "]", "*", "n_vars", "]", "*", "n_vars", "]", "\n", "for", "i", "in", "range", "(", "n_vars", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", ",", "n_vars", ")", ":", "\n", "                ", "pairwise_hess_grid", "[", "i", "]", "[", "j", "]", "=", "VariablePairHessianGatherer", "(", "y", "=", "y", ",", "\n", "wrt_x1", "=", "self", ".", "_var_list", "[", "i", "]", ",", "\n", "wrt_x2", "=", "self", ".", "_var_list", "[", "j", "]", ",", "\n", "block_size", "=", "self", ".", "_block_size", ")", "\n", "\n", "", "", "return", "pairwise_hess_grid", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianGatherer._build_slice_map": [[235, 250], ["int", "numpy.prod"], "methods", ["None"], ["", "def", "_build_slice_map", "(", "self", ")", ":", "\n", "# We are building a dict that maps a variable name to its slice indices (start, end) in a virtual flat array", "\n", "#   that contains all var elements.", "\n", "        ", "current_ix", "=", "0", "\n", "\n", "slice_map", "=", "{", "}", "\n", "for", "var", "in", "self", ".", "_var_list", ":", "\n", "            ", "var_size", "=", "int", "(", "np", ".", "prod", "(", "var", ".", "shape", ")", ")", "\n", "slice_map", "[", "var", ".", "name", "]", "=", "(", "current_ix", ",", "current_ix", "+", "var_size", ")", "\n", "\n", "# Update the current index.", "\n", "current_ix", "+=", "var_size", "\n", "\n", "", "self", ".", "_slice_map", "=", "slice_map", "\n", "self", ".", "_full_width", "=", "current_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.HessianGatherer.get_var_slice_ixs": [[251, 253], ["None"], "methods", ["None"], ["", "def", "get_var_slice_ixs", "(", "self", ",", "var_name", ")", ":", "\n", "        ", "return", "self", ".", "_slice_map", "[", "var_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.VariablePairHessianGatherer.__init__": [[261, 289], ["int", "int", "int", "math.ceil", "HessianHook.VariablePairHessianGatherer._build_hessian_op_grid", "numpy.prod", "numpy.prod", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.VariablePairHessianGatherer._build_hessian_op_grid"], ["def", "__init__", "(", "self", ",", "y", ",", "wrt_x1", ",", "wrt_x2", ",", "block_size", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the pairwise Hessian Gatherer.\n\n        :param y:               The value to differentiate. If a rank 1 tensor is specified, a rank 3 tensor will be\n                                    computed instead of a rank 2 one. The GPU computation will proceed by evaluating the\n                                    hessian for all of those values at once - adjust the block width accordingly!\n        :param wrt_x1:          The first tensor with respect to which to compute the hessian.\n        :param wrt_x2:          The second tensor with respect to which to compute the hessian.\n        :param block_size:      The hessian is evaluated on the GPU in blocks - this specifies the (maximum) number of\n                                    elements of these blocks.\n        \"\"\"", "\n", "\n", "# Register some useful numbers.", "\n", "self", ".", "_full_height", "=", "int", "(", "np", ".", "prod", "(", "wrt_x1", ".", "shape", ")", ")", "\n", "self", ".", "_full_width", "=", "int", "(", "np", ".", "prod", "(", "wrt_x2", ".", "shape", ")", ")", "\n", "self", ".", "_block_height", "=", "int", "(", "block_size", "/", "self", ".", "_full_width", ")", "\n", "\n", "if", "self", ".", "_block_height", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'The block size set for the Hessian Hook is too small at {} elements ({:.2f} MB). '", "\n", "'Needs at least {} elements ({:.2f} MB).'", ".", "format", "(", "block_size", ",", "(", "block_size", "*", "8", ")", "/", "1048576", ",", "\n", "self", ".", "_full_width", ",", "(", "self", ".", "_full_width", "*", "8", ")", "/", "1048576", ")", ")", "\n", "\n", "", "self", ".", "_grid_height", "=", "math", ".", "ceil", "(", "self", ".", "_full_height", "/", "self", ".", "_block_height", ")", "\n", "\n", "# Build the computational graph.", "\n", "self", ".", "_op_grid", "=", "self", ".", "_build_hessian_op_grid", "(", "y", ",", "wrt_x1", ",", "wrt_x2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.VariablePairHessianGatherer._build_hessian_op_grid": [[290, 322], ["tensorflow.reshape", "range", "tensorflow.gradients", "min", "tensorflow.python.ops.parallel_for.gradients.jacobian", "tensorflow.reshape"], "methods", ["None"], ["", "def", "_build_hessian_op_grid", "(", "self", ",", "y", ",", "wrt_x1", ",", "wrt_x2", ")", ":", "\n", "# DEBUG: self.monolith_hessian = jacobian(tf.gradients(y, wrt_x1)[0], wrt_x2, use_pfor=False)", "\n", "# DEBUG: self.monolith_hessian = tf.reshape(self.monolith_hessian, shape=(self._full_height, self._full_width))", "\n", "\n", "# Compute the full gradient wrt x1. We will slice this later when computing the hessian in a blocky manner.", "\n", "        ", "full_gradient", "=", "tf", ".", "gradients", "(", "y", ",", "wrt_x1", ")", "[", "0", "]", "\n", "full_gradient", "=", "tf", ".", "reshape", "(", "full_gradient", ",", "shape", "=", "(", "self", ".", "_full_height", ",", ")", ")", "\n", "\n", "# Redefining for readability", "\n", "grid_height", "=", "self", ".", "_grid_height", "\n", "block_height", "=", "self", ".", "_block_height", "\n", "full_height", "=", "self", ".", "_full_height", "\n", "\n", "# Build a grid of Tensorflow operations - each operation computes a chunk of the Hessian.", "\n", "#   The grid is actually just a list of chunks of shape [block_height, n_elements(x2)].", "\n", "#   When assembled, the hessian chunk will have shape [n_elements(x1), n_elements(x2)].", "\n", "op_grid", "=", "[", "None", "]", "*", "grid_height", "\n", "for", "i_block", "in", "range", "(", "grid_height", ")", ":", "\n", "# Parameters for the j-axis of the hessian.", "\n", "            ", "i_start_ix", "=", "i_block", "*", "block_height", "\n", "i_end_ix", "=", "min", "(", "full_height", ",", "(", "i_block", "+", "1", ")", "*", "block_height", ")", "\n", "\n", "# Add to output op grid.", "\n", "grad_chunk", "=", "full_gradient", "[", "i_start_ix", ":", "i_end_ix", "]", "\n", "# TODO: it is not clear whether to use pfor or not (since it is still experimental - maybe we can test).", "\n", "#  See https://github.com/tensorflow/tensorflow/issues/675#issuecomment-404665051", "\n", "hess_chunk", "=", "jacobian", "(", "grad_chunk", ",", "wrt_x2", ",", "use_pfor", "=", "False", ")", "\n", "hess_chunk", "=", "tf", ".", "reshape", "(", "hess_chunk", ",", "shape", "=", "(", "grad_chunk", ".", "shape", "[", "0", "]", ",", "self", ".", "_full_width", ")", ")", "\n", "\n", "op_grid", "[", "i_block", "]", "=", "hess_chunk", "\n", "\n", "", "return", "op_grid", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.VariablePairHessianGatherer.get_hessian": [[323, 348], ["numpy.zeros", "enumerate", "min", "sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "get_hessian", "(", "self", ",", "sess", ",", "feed_dict", ")", ":", "\n", "        ", "\"\"\"\n        Computes the hessian block-wise and returns it as a numpy array.\n\n        :param sess:        Tensorflow session.\n        :param feed_dict:   Feed dict to pass on to sess.run()\n        :return:            ndarray of hessian.\n        \"\"\"", "\n", "\n", "# Redefining for readability", "\n", "block_height", "=", "self", ".", "_block_height", "\n", "full_width", "=", "self", ".", "_full_width", "\n", "full_height", "=", "self", ".", "_full_height", "\n", "\n", "# The output hessian in its full width and glory.", "\n", "full_hessian", "=", "np", ".", "zeros", "(", "shape", "=", "(", "full_height", ",", "full_width", ")", ")", "\n", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "self", ".", "_op_grid", ")", ":", "\n", "            ", "i_start_ix", "=", "i", "*", "block_height", "\n", "i_end_ix", "=", "min", "(", "full_height", ",", "(", "i", "+", "1", ")", "*", "block_height", ")", "\n", "\n", "hess_block", "=", "sess", ".", "run", "(", "op", ",", "feed_dict", ")", "\n", "full_hessian", "[", "i_start_ix", ":", "i_end_ix", ",", ":", "]", "=", "hess_block", "\n", "\n", "", "return", "full_hessian", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HessianHook.my_loss_full_logits": [[15, 21], ["tensorflow.one_hot", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["def", "my_loss_full_logits", "(", "y", ",", "logits", ")", ":", "\n", "    ", "one_hot_y", "=", "tf", ".", "one_hot", "(", "y", ",", "10", ")", "\n", "softmax", "=", "tf", ".", "exp", "(", "logits", ")", "/", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "logits", ")", ")", "\n", "cross_entropy", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "one_hot_y", "*", "tf", ".", "log", "(", "softmax", ")", ",", "axis", "=", "1", ")", ")", "\n", "\n", "return", "cross_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.EveryNEpochsTFModelImagesHook.EveryNEpochsTFModelImagesHook.__init__": [[7, 32], ["EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "utils.ImagesSaver.ImagesSaver", "len", "Exception", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", "=", "None", ",", "\n", "pm_one", "=", "True", ",", "\n", "extra_feed_dict", "=", "{", "}", ")", ":", "\n", "\n", "        ", "dataset_keys", "=", "[", "]", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dataset_keys", ",", "\n", "dirName", "=", "dirName", ",", "\n", "extra_feed_dict", "=", "extra_feed_dict", ")", "\n", "\n", "# TODO make this check at runtime on the node passed tf.shape(node)", "\n", "# TODO this will allow to remove x_shape from dataset (confusing and not needed,", "\n", "# TODO indeed for certain datasets the shape can vary and also can vary from train to test, due to different cropping)", "\n", "self", ".", "_image_shape", "=", "model", ".", "dataset", ".", "x_shape", "# x_shape is general for all datasets", "\n", "\n", "self", ".", "_pm_one", "=", "pm_one", "\n", "self", ".", "images_saver", "=", "ImagesSaver", "(", "self", ".", "_dirName", ",", "pm", "=", "self", ".", "_pm_one", ")", "\n", "if", "len", "(", "self", ".", "_image_shape", ")", "!=", "3", ":", "\n", "            ", "raise", "Exception", "(", "\"image format not correct: dataset x_shape = `%s`\"", "%", "str", "(", "self", ".", "_image_shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.EveryNEpochsTFModelImagesHook.EveryNEpochsTFModelImagesHook.plot": [[46, 48], ["None"], "methods", ["None"], ["", "", "def", "plot", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractLinearInterpolationHook.AbstractLinearInterpolationHook.__init__": [[12, 33], ["EveryNEpochsTFModelImagesHook.EveryNEpochsTFModelImagesHook.__init__", "tf_logging.info", "AbstractLinearInterpolationHook.AbstractLinearInterpolationHook._images_indexes.items", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "images_indexes", ",", "\n", "n_images", ",", "\n", "dirName", ",", "\n", "pm_one", "=", "True", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "+", "'/linear_interpolations'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dirName", "=", "self", ".", "_dirName", ",", "pm_one", "=", "pm_one", ")", "\n", "\n", "self", ".", "_images_indexes", "=", "images_indexes", "\n", "self", ".", "_images", "=", "None", "\n", "self", ".", "_n_images", "=", "n_images", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create LinearInterpolationHook for: \\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "ds_key", "+", "\": \"", "+", "\", \"", ".", "join", "(", "map", "(", "str", ",", "idxs", ")", ")", "for", "ds_key", ",", "idxs", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractLinearInterpolationHook.AbstractLinearInterpolationHook.do_when_triggered": [[34, 36], ["None"], "methods", ["None"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractLinearInterpolationHook.AbstractLinearInterpolationHook.load_images_once": [[37, 52], ["datasets.Dataset.check_dataset_keys_not_loop", "list", "AbstractLinearInterpolationHook.AbstractLinearInterpolationHook._images_indexes.keys", "AbstractLinearInterpolationHook.AbstractLinearInterpolationHook._images_indexes.items", "zip", "AbstractLinearInterpolationHook.AbstractLinearInterpolationHook._model.dataset.get_elements", "AbstractLinearInterpolationHook.AbstractLinearInterpolationHook._model.dataset.get_elements"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.check_dataset_keys_not_loop", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements"], ["", "def", "load_images_once", "(", "self", ",", "session", ")", ":", "\n", "        ", "if", "self", ".", "_images", "==", "None", ":", "\n", "            ", "check_dataset_keys_not_loop", "(", "list", "(", "self", ".", "_images_indexes", ".", "keys", "(", ")", ")", ")", "\n", "\n", "images", "=", "{", "ds_key", ":", "(", "couple_indices_list", ",", "[", "(", "img1", ",", "img2", ")", "for", "img1", ",", "img2", "in", "zip", "(", "\n", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "x", ",", "self", ".", "_ds_handle", ",", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "session", ",", "[", "i", "[", "0", "]", "for", "i", "in", "couple_indices_list", "]", ")", ",", "\n", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "x", ",", "self", ".", "_ds_handle", ",", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "session", ",", "[", "i", "[", "1", "]", "for", "i", "in", "couple_indices_list", "]", ")", ")", "]", ")", "for", "(", "ds_key", ",", "couple_indices_list", ")", "in", "self", ".", "_images_indexes", ".", "items", "(", ")", "}", "\n", "\n", "# I set something like the following structure, e.g.", "\n", "# images = {TRAIN : ([(0,50),(100,230),(200,790),(300,600),(400,1000),(500,10)], list_of_couples_train_images,", "\n", "#           VALIDATION : ([(0,50),(100,230),(200,790),(300,600),(400,1000),(500,10)], list_of_couples_validation_images,", "\n", "#          },        ", "\n", "\n", "self", ".", "_images", "=", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractLinearInterpolationHook.AbstractLinearInterpolationHook.plot": [[55, 57], ["None"], "methods", ["None"], ["", "", "def", "plot", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook.__init__": [[16, 57], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tensorflow.cast", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "dirName", ",", "\n", "tensors", ",", "\n", "tensors_names", ",", "\n", "datasets_keys", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "plot_offset", "=", "0", ",", "\n", "extra_feed_dict", "=", "{", "}", ",", "\n", "algorithm", "=", "'svm'", ",", "\n", "kernel", "=", "'rbf'", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_hook_name", "=", "\"latent_vars_classifier_\"", "+", "algorithm", "+", "\"_\"", "+", "kernel", "\n", "dirName", "=", "dirName", "+", "'/'", "+", "self", ".", "_hook_name", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "datasets_keys", ",", "\n", "dirName", "=", "dirName", ",", "\n", "plot_offset", "=", "plot_offset", ",", "\n", "extra_feed_dict", "=", "extra_feed_dict", ")", "\n", "self", ".", "_tensors", "=", "[", "[", "tensors", "]", "]", "\n", "self", ".", "_tensors_names", "=", "[", "[", "tensors_names", "]", "]", "\n", "\n", "self", ".", "_tensors_plots", "=", "[", "[", "{", "\n", "'fileName'", ":", "\"latent_vars_classifier\"", ",", "\n", "'logscale-y'", ":", "0", "}", "]", ",", "\n", "]", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "\n", "self", ".", "_fileName", "=", "\"latent_vars_classifier\"", "\n", "\n", "self", ".", "_tensor_y_name", "=", "\"y\"", "\n", "self", ".", "_tensor_y", "=", "tf", ".", "cast", "(", "self", ".", "_model", ".", "y", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "self", ".", "_algorithm", "=", "algorithm", "\n", "self", ".", "_kernel", "=", "kernel", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create LatentVarsGeometricClassificationHook\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook._begin_once": [[58, 60], ["None"], "methods", ["None"], ["", "def", "_begin_once", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook._get_encodings_and_labels": [[61, 77], ["session.run", "numpy.concatenate", "numpy.concatenate", "session.run", "encodings.append", "labels.append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "_get_encodings_and_labels", "(", "self", ",", "ds_key", ",", "tensor", ",", "session", ")", ":", "\n", "        ", "dataset_initializer", "=", "self", ".", "_ds_initializers", "[", "ds_key", "]", "\n", "\n", "session", ".", "run", "(", "[", "dataset_initializer", "]", ")", "\n", "encodings", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_encodings", ",", "batch_labels", "=", "session", ".", "run", "(", "[", "tensor", ",", "self", ".", "_tensor_y", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_ds_handle", ":", "self", ".", "_ds_handles", "[", "ds_key", "]", "}", ")", "\n", "encodings", ".", "append", "(", "batch_encodings", ")", "\n", "labels", ".", "append", "(", "batch_labels", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "np", ".", "concatenate", "(", "encodings", ")", ",", "np", ".", "concatenate", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook.do_when_triggered": [[78, 112], ["tf_logging.info", "zip", "LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook.log_to_file_and_screen", "sklearn.svm.SVC.fit", "LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook._get_encodings_and_labels", "sklearn.svm.SVC", "ValueError", "sklearn.svm.SVC.predict", "accuracies[].append", "sum", "len", "accuracies.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.log_to_file_and_screen", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook._get_encodings_and_labels", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.predict"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for LatentVarsGeometricClassificationHook - \"", "+", "self", ".", "_algorithm", ")", "\n", "\n", "session", "=", "run_context", ".", "session", "\n", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "\n", "latent_vars", "=", "{", "}", "\n", "labels", "=", "{", "}", "\n", "for", "(", "tensor", ",", "tensor_name", ")", "in", "zip", "(", "self", ".", "_tensors", "[", "0", "]", "[", "0", "]", ",", "self", ".", "_tensors_names", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "            ", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "                ", "latent_vars", "[", "ds_key", "]", ",", "labels", "[", "ds_key", "]", "=", "self", ".", "_get_encodings_and_labels", "(", "ds_key", ",", "tensor", ",", "session", ")", "\n", "\n", "# train model", "\n", "", "if", "self", ".", "_algorithm", "==", "'svm'", ":", "\n", "                ", "model", "=", "svm", ".", "SVC", "(", "kernel", "=", "self", ".", "_kernel", ",", "gamma", "=", "'auto'", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Not implemented yet\"", ")", "\n", "# model = linear_model.LogisticRegression(C=1e5, solver='lbfgs', multi_class='auto')", "\n", "", "model", ".", "fit", "(", "latent_vars", "[", "TRAIN", "]", ",", "labels", "[", "TRAIN", "]", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "                ", "pred_latent_vars", "=", "model", ".", "predict", "(", "latent_vars", "[", "ds_key", "]", ")", "\n", "accuracy", "=", "sum", "(", "pred_latent_vars", "==", "labels", "[", "ds_key", "]", ")", "/", "len", "(", "labels", "[", "ds_key", "]", ")", "\n", "\n", "if", "not", "ds_key", "in", "accuracies", ".", "keys", "(", ")", ":", "\n", "                    ", "accuracies", "[", "ds_key", "]", "=", "[", "]", "\n", "", "accuracies", "[", "ds_key", "]", ".", "append", "(", "accuracy", ")", "\n", "\n", "", "", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "            ", "self", ".", "_tensors_values", "[", "ds_key", "]", "=", "[", "[", "accuracies", "[", "ds_key", "]", "]", "]", "\n", "\n", "", "self", ".", "log_to_file_and_screen", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsGeometricClassificationHook.LatentVarsGeometricClassificationHook.plot": [[113, 115], ["super().plot"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "plot", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "plot", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__": [[14, 50], ["model._get_steps", "ArgoHook.ArgoHook.__init__", "os.makedirs", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dataset_keys", ",", "\n", "dirName", "=", "None", ",", "\n", "log_str", "=", "None", ",", "\n", "tensorboard_dir", "=", "None", ",", "\n", "trigger_summaries", "=", "False", ",", "\n", "extra_feed_dict", "=", "{", "}", ",", "\n", "plot_offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model: the argo model for which to log stuffs\n            period: a tuple `(n, time_ref)` to specify when to trigger, time_ref can be \"epoch\" or \"step\" used for plotting and txt files\n            dirName: directory where to write stuffs\n\n        \"\"\"", "\n", "\n", "n_steps", "=", "model", ".", "_get_steps", "(", "period", ",", "time_reference", ")", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "n_steps", ",", "time_reference", ",", "dataset_keys", ",", "\n", "plot_offset", "=", "plot_offset", ",", "tensorboard_dir", "=", "tensorboard_dir", ",", "trigger_summaries", "=", "trigger_summaries", ",", "\n", "extra_feed_dict", "=", "extra_feed_dict", ")", "\n", "\n", "self", ".", "_plot_title", "=", "model", ".", "dataset", ".", "id", "+", "\" \"", "+", "model", ".", "id", "\n", "\n", "\n", "self", ".", "_dirName", "=", "dirName", "\n", "\n", "self", ".", "_did_begin_already", "=", "False", "\n", "\n", "if", "dirName", ":", "\n", "            ", "os", ".", "makedirs", "(", "dirName", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "if", "log_str", ":", "\n", "            ", "tf_logging", ".", "info", "(", "log_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.begin": [[51, 69], ["super().begin", "EveryNEpochsTFModelHook.EveryNEpochsTFModelHook._begin_once", "EveryNEpochsTFModelHook.EveryNEpochsTFModelHook._create_or_open_files", "print", "RuntimeError", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.begin", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._begin_once", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2._create_or_open_files"], ["", "", "def", "begin", "(", "self", ")", ":", "\n", "        ", "super", "(", "EveryNEpochsTFModelHook", ",", "self", ")", ".", "begin", "(", ")", "\n", "\n", "if", "not", "self", ".", "_did_begin_already", ":", "\n", "            ", "self", ".", "_did_begin_already", "=", "True", "\n", "\n", "if", "self", ".", "_global_step_tensor", "is", "None", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Global step should be created to use LoggingMeanTensorsHook.\"", ")", "\n", "\n", "", "self", ".", "_begin_once", "(", ")", "\n", "\n", "", "if", "self", ".", "_tensors_names", "is", "not", "None", "and", "self", ".", "_tensors_plots", "is", "not", "None", "and", "self", ".", "_tensors_values", "is", "not", "None", ":", "\n", "            ", "self", ".", "_create_or_open_files", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "str", "(", "self", ")", "+", "\" is not using custom txt files\"", ")", "\n", "self", ".", "_files", "=", "[", "]", "\n", "self", ".", "_filesExist", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook._begin_once": [[70, 73], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "_begin_once", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.after_run": [[74, 86], ["super().after_run", "EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.update_time", "EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.do_when_triggered", "EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.plot"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.after_run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.update_time", "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook.do_when_triggered", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "super", "(", "EveryNEpochsTFModelHook", ",", "self", ")", ".", "after_run", "(", "run_context", ",", "run_values", ")", "\n", "\n", "if", "self", ".", "_trigged_for_step", ":", "\n", "\n", "# update time and reset triggered for step", "\n", "            ", "self", ".", "update_time", "(", ")", "\n", "\n", "self", ".", "do_when_triggered", "(", "run_context", ",", "run_values", ")", "\n", "\n", "if", "(", "self", ".", "_time_ref", "<", "50", "or", "self", ".", "_time_ref", "%", "10", "==", "0", ")", ":", "\n", "                ", "self", ".", "plot", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.do_when_triggered": [[87, 90], ["None"], "methods", ["None"], ["", "", "", "@", "abstractmethod", "\n", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.__init__": [[11, 36], ["os.path.join", "os.path.join", "LoggerHelperMultiDS.LoggerHelperMultiDS._get_mean_ops", "os.makedirs", "os.path.exists", "pandas.read_csv", "pandas.DataFrame", "os.path.getsize"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._get_mean_ops"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "loggername", ",", "tensors_names", ",", "tensor_nodes", ",", "\n", "ds_handle", ",", "datasets_initializers", ",", "datasets_handles", ",", "datasets_eval_names", ",", "\n", "erase_old", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "_filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "loggername", "+", "\".txt\"", ")", "\n", "self", ".", "_plotfilename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "loggername", ")", "\n", "\n", "reference_names", "=", "[", "\"epoch\"", ",", "\"dataset\"", "]", "\n", "\n", "self", ".", "_monitor_tensors_values", ",", "self", ".", "_monitor_tensors_updates", ",", "self", ".", "_monitor_tensors_reset", "=", "self", ".", "_get_mean_ops", "(", "tensor_nodes", ")", "\n", "\n", "self", ".", "_pd_csv_kwargs", "=", "{", "\n", "\"sep\"", ":", "\"\\t\"", "\n", "}", "\n", "\n", "if", "(", "not", "erase_old", ")", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "_filename", ")", "and", "os", ".", "path", ".", "getsize", "(", "self", ".", "_filename", ")", ">", "0", ":", "\n", "            ", "self", ".", "_df", "=", "pd", ".", "read_csv", "(", "self", ".", "_filename", ",", "**", "self", ".", "_pd_csv_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "reference_names", "+", "tensors_names", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "_ds_handle", "=", "ds_handle", "\n", "self", ".", "_datasets_initializers", "=", "datasets_initializers", "\n", "self", ".", "_datasets_handles", "=", "datasets_handles", "\n", "self", ".", "_datasets_eval_names", "=", "datasets_eval_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log": [[38, 55], ["LoggerHelperMultiDS.LoggerHelperMultiDS._df.to_csv", "LoggingMeanTensorsHook.evaluate_means_over_dataset", "list", "pandas.Series", "LoggerHelperMultiDS.LoggerHelperMultiDS._df.append", "itertools.chain"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.evaluate_means_over_dataset"], ["", "def", "log", "(", "self", ",", "sess", ",", "epoch", ")", ":", "\n", "\n", "        ", "for", "ds_str", "in", "self", ".", "_datasets_eval_names", ":", "\n", "            ", "monitor_tensors_values_np", "=", "evaluate_means_over_dataset", "(", "sess", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_datasets_initializers", "[", "ds_str", "]", ",", "\n", "self", ".", "_datasets_handles", "[", "ds_str", "]", ",", "\n", "self", ".", "_monitor_tensors_values", ",", "\n", "self", ".", "_monitor_tensors_updates", ",", "\n", "self", ".", "_monitor_tensors_reset", ")", "\n", "\n", "out", "=", "list", "(", "itertools", ".", "chain", "(", "monitor_tensors_values_np", ")", ")", "\n", "new_series", "=", "pd", ".", "Series", "(", "[", "epoch", ",", "ds_str", "]", "+", "out", ",", "index", "=", "self", ".", "_df", ".", "columns", ")", "\n", "#NB as of today there is no `inplace` parameter for pandas dataframes", "\n", "self", ".", "_df", "=", "self", ".", "_df", ".", "append", "(", "new_series", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "self", ".", "_df", ".", "to_csv", "(", "self", ".", "_filename", ",", "index", "=", "False", ",", "float_format", "=", "'%.6g'", ",", "**", "self", ".", "_pd_csv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.reset": [[56, 58], ["sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "reset", "(", "self", ",", "sess", ")", ":", "\n", "        ", "_", "=", "sess", ".", "run", "(", "self", ".", "_monitor_tensors_reset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.plot": [[62, 71], ["LoggerHelperMultiDS.LoggerHelperMultiDS._df.plot", "LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot", "zip", "ax.set_ylim"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot"], ["", "def", "plot", "(", "self", ",", "ylims", "=", "None", ",", "suffix", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# subplots = False, sharex = True", "\n", "        ", "axes", "=", "self", ".", "_df", ".", "plot", "(", "**", "kwargs", ")", "\n", "\n", "if", "ylims", "is", "not", "None", ":", "\n", "            ", "for", "ax", ",", "ylim", "in", "zip", "(", "axes", ",", "ylims", ")", ":", "\n", "                ", "ax", ".", "set_ylim", "(", "ylim", ")", "\n", "\n", "", "", "self", ".", "_finalize_plot", "(", "suffix", "=", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.plot_groupby": [[72, 77], ["matplotlib.pyplot.gca", "LoggerHelperMultiDS.LoggerHelperMultiDS._df.groupby", "LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot", "df.plot"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "plot_groupby", "(", "self", ",", "groupfield", ",", "suffix", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "for", "label", ",", "df", "in", "self", ".", "_df", ".", "groupby", "(", "groupfield", ")", ":", "\n", "            ", "df", ".", "plot", "(", "**", "kwargs", ",", "ax", "=", "ax", ",", "label", "=", "groupfield", "+", "\"_{:}\"", ".", "format", "(", "label", ")", ")", "\n", "", "self", ".", "_finalize_plot", "(", "suffix", "=", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._finalize_plot": [[78, 85], ["matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close"], "methods", ["None"], ["", "def", "_finalize_plot", "(", "self", ",", "suffix", "=", "None", ")", ":", "\n", "        ", "plt", ".", "tight_layout", "(", ")", "\n", "plotfilename", "=", "self", ".", "_plotfilename", "\n", "if", "suffix", "is", "not", "None", ":", "\n", "            ", "plotfilename", "+=", "'_'", "+", "suffix", "\n", "", "plt", ".", "savefig", "(", "plotfilename", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS._get_mean_ops": [[86, 96], ["zip", "utils.argo_utils.create_reset_metric"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_reset_metric"], ["", "def", "_get_mean_ops", "(", "self", ",", "tensors", ",", "dataset_str", "=", "\"\"", ")", ":", "\n", "        ", "if", "dataset_str", ":", "\n", "            ", "dataset_str", "+=", "\"_\"", "\n", "\n", "", "mean_v", ",", "mean_u_ops", ",", "mean_r_ops", "=", "zip", "(", "*", "[", "create_reset_metric", "(", "tf", ".", "metrics", ".", "mean", ",", "\n", "scope", "=", "dataset_str", "+", "\"mean_reset_metric/\"", "+", "tnsr", ".", "name", ",", "\n", "values", "=", "tnsr", ")", "\n", "for", "tnsr", "in", "tensors", "]", ")", "\n", "return", "mean_v", ",", "mean_u_ops", ",", "mean_r_ops", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.__init__": [[19, 49], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "argo.core.utils.WavSaver.WavSaver", "Exception", "type", "os.path.isdir", "os.mkdir"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dataset_keys", ",", "\n", "hop_legth_cqt", "=", "128", ",", "\n", "dirName", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "dataset_keys", ",", "dirName", "=", "dirName", ",", "**", "kwargs", ")", "\n", "self", ".", "_sample_rate", "=", "model", ".", "dataset", ".", "sample_rate", "\n", "\n", "if", "self", ".", "_sample_rate", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"The sample rate is not set for the dataset\"", ")", "\n", "\n", "", "self", ".", "dir_name_anomaly_detection", "=", "dirName", "+", "'/anomaly_detection/'", "\n", "self", ".", "dir_name_reconstructions", "=", "dirName", "+", "'/reconstructed_wav/'", "\n", "\n", "self", ".", "_wav_saver", "=", "WavSaver", "(", "self", ".", "dir_name_reconstructions", ",", "self", ".", "_sample_rate", ")", "\n", "self", ".", "model_class_name", "=", "type", "(", "model", ")", ".", "__name__", "\n", "self", ".", "_hop_legth_cqt", "=", "hop_legth_cqt", "\n", "\n", "self", ".", "_ds_initializers", "=", "model", ".", "datasets_initializers", "\n", "self", ".", "_ds_handles_nodes", "=", "model", ".", "datasets_handles_nodes", "\n", "\n", "self", ".", "reconstr_metrics_file_names", "=", "{", "}", "\n", "\n", "for", "dir_", "in", "[", "self", ".", "dir_name_reconstructions", ",", "self", ".", "dir_name_anomaly_detection", "]", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "isdir", "(", "dir_", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "dir_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.after_create_session": [[50, 88], ["super().after_create_session", "session.run", "AbstractWavHook.AbstractWavHook._sample_indices_by_dataset.items", "AbstractWavHook.AbstractWavHook._model.dataset.get_elements", "numpy.array", "AbstractWavHook.AbstractWavHook._model.dataset.get_elements", "list", "AbstractWavHook.AbstractWavHook._model.dataset.int_to_str_label", "range"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Dataset.Dataset.get_elements", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.AudioDataset.AudioDataset.int_to_str_label"], ["", "", "", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "'''\n\n            initilizes self._samples and self._labels from datasets.\n            previously it initilized them only with the\n        '''", "\n", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "self", ".", "_ds_handles", "=", "session", ".", "run", "(", "self", ".", "_ds_handles_nodes", ")", "\n", "\n", "self", ".", "_samples", "=", "{", "}", "\n", "self", ".", "_labels", "=", "{", "}", "\n", "\n", "for", "(", "ds_key", ",", "index_list", ")", "in", "self", ".", "_sample_indices_by_dataset", ".", "items", "(", ")", ":", "\n", "            ", "samples", "=", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "x", ",", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "\n", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "\n", "session", ",", "\n", "None", ")", "# passing None instead of index_list to return all samples", "\n", "# indexing will be made in the hook because I need to", "\n", "# calculate the reconstruction loss for generation", "\n", "\n", "labels", "=", "None", "\n", "if", "self", ".", "_model", ".", "y", "is", "not", "None", ":", "\n", "                ", "labels", "=", "self", ".", "_model", ".", "dataset", ".", "get_elements", "(", "self", ".", "_model", ".", "y", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_handles", "[", "ds_key", "]", ",", "\n", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "\n", "session", ",", "\n", "None", ")", "\n", "\n", "", "labels", "=", "np", ".", "array", "(", "[", "self", ".", "_model", ".", "dataset", ".", "int_to_str_label", "(", "label", ")", "for", "label", "in", "labels", "]", ")", "\n", "\n", "if", "index_list", "is", "None", ":", "\n", "                ", "index_list", "=", "list", "(", "range", "(", "0", ",", "samples", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "# return all samples and labels for a given ds_key and the corresponding indices", "\n", "", "self", ".", "_samples", "[", "ds_key", "]", "=", "(", "index_list", ",", "samples", ")", "\n", "self", ".", "_labels", "[", "ds_key", "]", "=", "(", "index_list", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.write_headers_to_reconstruction_files": [[94, 107], ["set", "AbstractWavHook.AbstractWavHook.reconstr_metrics_file_names.items", "sorted", "os.path.isfile", "AbstractWavHook.AbstractWavHook.write_to_file"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.write_to_file"], ["", "", "def", "write_headers_to_reconstruction_files", "(", "self", ")", ":", "\n", "# reconstr_metrics per label", "\n", "        ", "header", "=", "'#time_ref'", "\n", "unique_labels", "=", "set", "(", "self", ".", "_labels", "[", "'validation'", "]", "[", "1", "]", ")", "\n", "for", "metric", "in", "[", "'MCD'", ",", "'PSNR'", ",", "'loss'", "]", ":", "\n", "            ", "for", "label", "in", "sorted", "(", "unique_labels", ")", ":", "\n", "                ", "header", "+=", "'\\t{}_{} (std)'", ".", "format", "(", "metric", ",", "label", ")", "\n", "", "header", "+=", "'\\t{}_avg'", ".", "format", "(", "metric", ")", "\n", "", "header", "+=", "'\\n'", "\n", "\n", "for", "ds_key", ",", "file", "in", "self", ".", "reconstr_metrics_file_names", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "                ", "self", ".", "write_to_file", "(", "file", ",", "header", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._write_originals": [[108, 113], ["zip", "AbstractWavHook.AbstractWavHook._wav_saver.save_wav", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.WavSaver.WavSaver.save_wav"], ["", "", "", "def", "_write_originals", "(", "self", ")", ":", "\n", "        ", "for", "ds_key", "in", "self", ".", "_samples", ":", "\n", "            ", "for", "index", ",", "sample", "in", "zip", "(", "*", "self", ".", "_samples", "[", "ds_key", "]", ")", ":", "\n", "                ", "self", ".", "_wav_saver", ".", "save_wav", "(", "wav_data", "=", "sample", ",", "\n", "fileName", "=", "\"original_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "str", "(", "index", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.plot_and_save": [[114, 130], ["zip", "AbstractWavHook.AbstractWavHook._plot_wav", "AbstractWavHook.AbstractWavHook._save_encoding", "AbstractWavHook.AbstractWavHook._wav_saver.save_wav", "AbstractWavHook.AbstractWavHook._plot_wav_rainbowgram", "str().zfill", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._save_encoding", "home.repos.pwc.inspect_result.rist-ro_argo.utils.WavSaver.WavSaver.save_wav", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav_rainbowgram"], ["", "", "", "def", "plot_and_save", "(", "self", ",", "ds_key", ",", "indices", ",", "reconstructed_samples", ",", "samples", ",", "labels", ",", "time_ref", ",", "time_ref_str", ",", "\n", "zs", ",", "prefix", "=", "\"\"", ",", "suffix", "=", "None", ",", "save_enc", "=", "False", ",", "plot_rainbowgram", "=", "False", ",", "save_wav", "=", "False", ")", ":", "\n", "        ", "for", "index", ",", "sample", ",", "label", ",", "enc", ",", "rec_sample", "in", "zip", "(", "indices", ",", "samples", ",", "labels", ",", "zs", ",", "reconstructed_samples", ")", ":", "\n", "            ", "fileName", "=", "prefix", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "str", "(", "index", ")", "+", "\"_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "\n", "time_ref", ")", ".", "zfill", "(", "4", ")", "+", "(", "\n", "\"_\"", "+", "suffix", "if", "suffix", "is", "not", "None", "else", "\"\"", ")", "\n", "if", "save_enc", ":", "\n", "                ", "self", ".", "_save_encoding", "(", "enc", ",", "fileName", ")", "\n", "\n", "", "if", "save_wav", ":", "\n", "                ", "self", ".", "_wav_saver", ".", "save_wav", "(", "wav_data", "=", "rec_sample", ",", "\n", "fileName", "=", "fileName", ")", "\n", "", "self", ".", "_plot_wav", "(", "sample", ",", "label", ",", "enc", ",", "rec_sample", ",", "fileName", ")", "\n", "\n", "if", "plot_rainbowgram", ":", "\n", "                ", "self", ".", "_plot_wav_rainbowgram", "(", "sample", ",", "rec_sample", ",", "fileName", "+", "'_rainbowgram'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._save_encoding": [[131, 133], ["numpy.save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "", "", "def", "_save_encoding", "(", "self", ",", "enc", ",", "filename", ")", ":", "\n", "        ", "np", ".", "save", "(", "self", ".", "dir_name_reconstructions", "+", "'/'", "+", "filename", ",", "enc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav": [[134, 146], ["matplotlib.pyplot.subplots", "axs[].plot", "axs[].set_title", "axs[].plot", "axs[].set_title", "axs[].plot", "axs[].plot", "axs[].set_title", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "_plot_wav", "(", "self", ",", "audio_orig", ",", "label", ",", "encoding", ",", "audio_rec", ",", "fileName", ")", ":", "\n", "        ", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "3", ",", "1", ",", "figsize", "=", "(", "15", ",", "5", ")", ")", "\n", "axs", "[", "0", "]", ".", "plot", "(", "audio_orig", ")", "\n", "axs", "[", "0", "]", ".", "set_title", "(", "'Original Audio Signal - '", "+", "str", "(", "label", ")", ")", "\n", "axs", "[", "1", "]", ".", "plot", "(", "encoding", ")", "\n", "axs", "[", "1", "]", ".", "set_title", "(", "'Encoding'", ")", "\n", "axs", "[", "2", "]", ".", "plot", "(", "audio_rec", ")", "\n", "axs", "[", "2", "]", ".", "plot", "(", "audio_orig", ",", "alpha", "=", "0.5", ")", "\n", "axs", "[", "2", "]", ".", "set_title", "(", "'Reconstructed Audio Signal'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "dir_name_reconstructions", "+", "fileName", "+", "'.jpg'", ",", "quality", "=", "90", ",", "format", "=", "'jpg'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav_rainbowgram": [[147, 167], ["matplotlib.pyplot.subplots", "matplotlib.colors.LinearSegmentedColormap", "matplotlib.pyplot.register_cmap", "axs[].set_title", "AbstractWavHook.AbstractWavHook._plot_magnitude_phase", "axs[].set_title", "AbstractWavHook.AbstractWavHook._plot_magnitude_phase", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_magnitude_phase", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_magnitude_phase"], ["", "def", "_plot_wav_rainbowgram", "(", "self", ",", "audio_orig", ",", "audio_rec", ",", "fileName", ")", ":", "\n", "        ", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "2", ",", "1", ",", "figsize", "=", "(", "10", ",", "10", ")", ")", "\n", "cdict", "=", "{", "\n", "'red'", ":", "(", "(", "0.0", ",", "0.0", ",", "0.0", ")", ",", "\n", "(", "1.0", ",", "0.0", ",", "0.0", ")", ")", ",", "\n", "'green'", ":", "(", "(", "0.0", ",", "0.0", ",", "0.0", ")", ",", "\n", "(", "1.0", ",", "0.0", ",", "0.0", ")", ")", ",", "\n", "'blue'", ":", "(", "(", "0.0", ",", "0.0", ",", "0.0", ")", ",", "\n", "(", "1.0", ",", "0.0", ",", "0.0", ")", ")", ",", "\n", "'alpha'", ":", "(", "(", "0.0", ",", "1.0", ",", "1.0", ")", ",", "\n", "(", "1.0", ",", "0.0", ",", "0.0", ")", ")", "\n", "}", "\n", "my_mask", "=", "LinearSegmentedColormap", "(", "'MyMask'", ",", "cdict", ")", "\n", "plt", ".", "register_cmap", "(", "cmap", "=", "my_mask", ")", "\n", "axs", "[", "0", "]", ".", "set_title", "(", "'Original Audio Signal'", ")", "\n", "self", ".", "_plot_magnitude_phase", "(", "audio_orig", ",", "axs", "[", "0", "]", ",", "my_mask", ")", "\n", "axs", "[", "1", "]", ".", "set_title", "(", "'Reconstructed Audio Signal'", ")", "\n", "self", ".", "_plot_magnitude_phase", "(", "audio_rec", ",", "axs", "[", "1", "]", ",", "my_mask", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "dir_name_reconstructions", "+", "'/'", "+", "fileName", "+", "'.jpg'", ",", "quality", "=", "90", ",", "format", "=", "'jpg'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_magnitude_phase": [[168, 193], ["numpy.squeeze", "samples.astype.astype.astype", "librosa.cqt", "librosa.core.magphase", "numpy.angle", "numpy.unwrap", "ax.matshow", "ax.matshow", "ax.axis", "numpy.concatenate", "librosa.note_to_hz", "librosa.amplitude_to_db"], "methods", ["None"], ["", "def", "_plot_magnitude_phase", "(", "self", ",", "samples", ",", "ax", ",", "mask", ",", "n_octaves", "=", "6", ",", "n_bins_per_octave", "=", "40", ",", "res_factor", "=", "0.8", ",", "peak", "=", "70.0", ")", ":", "\n", "        ", "samples", "=", "np", ".", "squeeze", "(", "samples", ")", "\n", "samples", "=", "samples", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# compute constant q transform", "\n", "C", "=", "librosa", ".", "cqt", "(", "samples", ",", "\n", "sr", "=", "self", ".", "_sample_rate", ",", "\n", "hop_length", "=", "self", ".", "_hop_legth_cqt", ",", "\n", "bins_per_octave", "=", "n_bins_per_octave", ",", "\n", "n_bins", "=", "n_octaves", "*", "n_bins_per_octave", ",", "\n", "filter_scale", "=", "res_factor", ",", "\n", "fmin", "=", "librosa", ".", "note_to_hz", "(", "'C2'", ")", ",", "\n", ")", "\n", "\n", "# compute log magnitude and derivative of phase, see https://gist.github.com/jesseengel/e223622e255bd5b8c9130407397a0494", "\n", "mag", ",", "phase", "=", "librosa", ".", "core", ".", "magphase", "(", "C", ")", "\n", "phase_angle", "=", "np", ".", "angle", "(", "phase", ")", "\n", "phase_unwrapped", "=", "np", ".", "unwrap", "(", "phase_angle", ")", "\n", "dphase", "=", "phase_unwrapped", "[", ":", ",", "1", ":", "]", "-", "phase_unwrapped", "[", ":", ",", ":", "-", "1", "]", "\n", "dphase", "=", "np", ".", "concatenate", "(", "[", "phase_unwrapped", "[", ":", ",", "0", ":", "1", "]", ",", "dphase", "]", ",", "axis", "=", "1", ")", "/", "np", ".", "pi", "\n", "mag", "=", "(", "librosa", ".", "amplitude_to_db", "(", "mag", ",", "amin", "=", "1e-13", ",", "top_db", "=", "peak", ",", "ref", "=", "np", ".", "max", ")", "/", "peak", ")", "+", "1", "\n", "# set colours", "\n", "ax", ".", "matshow", "(", "dphase", "[", ":", ":", "-", "1", ",", ":", "]", ",", "cmap", "=", "plt", ".", "cm", ".", "rainbow", ")", "\n", "# set intensities", "\n", "ax", ".", "matshow", "(", "mag", "[", ":", ":", "-", "1", ",", ":", "]", ",", "cmap", "=", "mask", ")", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.plot": [[195, 197], ["None"], "methods", ["None"], ["", "def", "plot", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.multi_plot_and_save": [[198, 231], ["zip", "fileName.replace", "AbstractWavHook.AbstractWavHook._plot_wav_multi", "prefix.split", "AbstractWavHook.AbstractWavHook._save_encoding", "AbstractWavHook.AbstractWavHook._save_encoding", "AbstractWavHook.AbstractWavHook._wav_saver.save_wav", "AbstractWavHook.AbstractWavHook._wav_saver.save_wav", "AbstractWavHook.AbstractWavHook._plot_wav_rainbowgram", "AbstractWavHook.AbstractWavHook._plot_wav_rainbowgram", "fileName.replace", "AbstractWavHook.AbstractWavHook._plot_mean_sigma", "str().zfill", "fileName.replace", "fileName.replace", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav_multi", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._save_encoding", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._save_encoding", "home.repos.pwc.inspect_result.rist-ro_argo.utils.WavSaver.WavSaver.save_wav", "home.repos.pwc.inspect_result.rist-ro_argo.utils.WavSaver.WavSaver.save_wav", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav_rainbowgram", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav_rainbowgram", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_mean_sigma"], ["", "def", "multi_plot_and_save", "(", "self", ",", "ds_key", ",", "indices", ",", "reconstructed_samples_mean", ",", "\n", "reconstructed_samples_sampling", ",", "samples", ",", "labels", ",", "time_ref", ",", "time_ref_str", ",", "\n", "zs", ",", "means", ",", "covariances", ",", "prior_mean", ",", "prior_cov", ",", "prefix", "=", "\"\"", ",", "suffix", "=", "None", ",", "save_enc", "=", "False", ",", "\n", "save_wav", "=", "False", ",", "plot_mean_separately", "=", "False", ",", "plot_rainbowgram", "=", "False", ")", ":", "\n", "\n", "        ", "for", "index", ",", "sample", ",", "label", ",", "enc_sample", ",", "enc_mean", ",", "rec_sample_mean", ",", "rec_sample_sampling", ",", "covariance", "in", "zip", "(", "indices", ",", "samples", ",", "labels", ",", "zs", ",", "means", ",", "reconstructed_samples_mean", ",", "reconstructed_samples_sampling", ",", "covariances", ")", ":", "\n", "\n", "            ", "fileName", "=", "prefix", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "str", "(", "index", ")", "+", "\"_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "\n", "time_ref", ")", ".", "zfill", "(", "4", ")", "+", "(", "\"_\"", "+", "suffix", "if", "suffix", "is", "not", "None", "else", "\"\"", ")", "\n", "first_prefix_elem", "=", "prefix", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "mean_suffix", ",", "sample_suffix", "=", "'_mean'", ",", "'_sample'", "\n", "rec_file_name", "=", "fileName", ".", "replace", "(", "first_prefix_elem", ",", "'reconstruction'", ")", "\n", "\n", "if", "save_enc", ":", "\n", "                ", "file_name_encoding_sample", "=", "fileName", ".", "replace", "(", "first_prefix_elem", ",", "'z_encoding'", ")", "+", "sample_suffix", "\n", "file_name_encoding_mean", "=", "fileName", ".", "replace", "(", "first_prefix_elem", ",", "'z_encoding'", ")", "+", "mean_suffix", "\n", "self", ".", "_save_encoding", "(", "enc_sample", ",", "file_name_encoding_sample", ")", "\n", "self", ".", "_save_encoding", "(", "enc_mean", ",", "file_name_encoding_mean", ")", "\n", "\n", "", "if", "save_wav", ":", "\n", "                ", "self", ".", "_wav_saver", ".", "save_wav", "(", "wav_data", "=", "rec_sample_mean", ",", "fileName", "=", "rec_file_name", "+", "mean_suffix", ")", "\n", "self", ".", "_wav_saver", ".", "save_wav", "(", "wav_data", "=", "rec_sample_sampling", ",", "fileName", "=", "rec_file_name", "+", "sample_suffix", ")", "\n", "\n", "", "if", "plot_rainbowgram", ":", "\n", "                ", "self", ".", "_plot_wav_rainbowgram", "(", "sample", ",", "rec_sample_mean", ",", "rec_file_name", "+", "mean_suffix", "+", "'_rainbowgram'", ")", "\n", "self", ".", "_plot_wav_rainbowgram", "(", "sample", ",", "rec_sample_sampling", ",", "rec_file_name", "+", "sample_suffix", "+", "'_rainbowgram'", ")", "\n", "\n", "", "self", ".", "_plot_wav_multi", "(", "sample", ",", "label", ",", "enc_sample", ",", "rec_sample_mean", ",", "rec_sample_sampling", ",", "enc_mean", ".", "T", ",", "fileName", ")", "\n", "\n", "if", "enc_mean", ".", "shape", "[", "0", "]", ">", "2", "and", "plot_mean_separately", ":", "\n", "                ", "mean_variance_file_name", "=", "fileName", ".", "replace", "(", "first_prefix_elem", ",", "'mean_sigma'", ")", "\n", "self", ".", "_plot_mean_sigma", "(", "enc_mean", ",", "covariance", ",", "prior_mean", ",", "prior_cov", ",", "mean_variance_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.spider_plot_encoding": [[232, 238], ["zip", "AbstractWavHook.AbstractWavHook._spider_plot", "str().zfill", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._spider_plot"], ["", "", "", "def", "spider_plot_encoding", "(", "self", ",", "ds_key", ",", "indices", ",", "samples", ",", "labels", ",", "time_ref", ",", "time_ref_shortstr", ",", "\n", "zs", ",", "prefix", ",", "num_time_splits", ")", ":", "\n", "        ", "for", "index", ",", "sample", ",", "label", ",", "z", "in", "zip", "(", "indices", ",", "samples", ",", "labels", ",", "zs", ")", ":", "\n", "            ", "file_name", "=", "self", ".", "dir_name_reconstructions", "+", "'/'", "+", "prefix", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "str", "(", "index", ")", "+", "\"_\"", "+", "time_ref_shortstr", "+", "\"_\"", "+", "str", "(", "\n", "time_ref", ")", ".", "zfill", "(", "4", ")", "+", "'.jpg'", "\n", "self", ".", "_spider_plot", "(", "sample", ",", "z", ",", "num_time_splits", ",", "file_name", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_wav_multi": [[239, 271], ["matplotlib.pyplot.subplots", "axs[].plot", "axs[].set_title", "axs[].plot", "axs[].set_title", "axs[].plot", "axs[].set_title", "axs[].plot", "axs[].plot", "axs[].set_ylim", "axs[].set_title", "axs[].plot", "axs[].plot", "axs[].set_ylim", "axs[].set_title", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "str", "audio_orig.min", "audio_orig.max", "audio_orig.min", "audio_orig.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "", "def", "_plot_wav_multi", "(", "self", ",", "audio_orig", ",", "label", ",", "encoding_sample", ",", "audio_rec_mean", ",", "audio_rec_sampling", ",", "mean", ",", "fileName", ")", ":", "\n", "        ", "'''\n\n        Args:\n            means (np.array): the means of the samples, shape = (dim, channels)\n            covariance (np.array): the covariance matrix of the samples associated with the mean,\n                                    shape = (channels, dimension, dimension)\n\n        '''", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "5", ",", "1", ",", "figsize", "=", "(", "15", ",", "12", ")", ")", "\n", "axs", "[", "0", "]", ".", "plot", "(", "audio_orig", ")", "\n", "axs", "[", "0", "]", ".", "set_title", "(", "'Original Audio Signal - '", "+", "str", "(", "label", ")", ")", "\n", "\n", "axs", "[", "1", "]", ".", "plot", "(", "encoding_sample", ")", "\n", "axs", "[", "1", "]", ".", "set_title", "(", "'Encoding Sample'", ")", "\n", "\n", "axs", "[", "2", "]", ".", "plot", "(", "mean", ".", "T", ")", "\n", "axs", "[", "2", "]", ".", "set_title", "(", "'Encoding Mean'", ")", "\n", "\n", "axs", "[", "3", "]", ".", "plot", "(", "audio_rec_mean", ")", "\n", "axs", "[", "3", "]", ".", "plot", "(", "audio_orig", ",", "alpha", "=", "0.5", ")", "\n", "axs", "[", "3", "]", ".", "set_ylim", "(", "[", "audio_orig", ".", "min", "(", ")", ",", "audio_orig", ".", "max", "(", ")", "]", ")", "\n", "axs", "[", "3", "]", ".", "set_title", "(", "'Reconstructed Audio Signal from Mean'", ")", "\n", "\n", "axs", "[", "4", "]", ".", "plot", "(", "audio_rec_sampling", ")", "\n", "axs", "[", "4", "]", ".", "plot", "(", "audio_orig", ",", "alpha", "=", "0.5", ")", "\n", "axs", "[", "4", "]", ".", "set_ylim", "(", "[", "audio_orig", ".", "min", "(", ")", ",", "audio_orig", ".", "max", "(", ")", "]", ")", "\n", "axs", "[", "4", "]", ".", "set_title", "(", "'Reconstructed Audio Signal from Sample'", ")", "\n", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "dir_name_reconstructions", "+", "'/'", "+", "fileName", "+", "'.jpg'", ",", "quality", "=", "90", ",", "format", "=", "'jpg'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._plot_mean_sigma": [[272, 299], ["numpy.sqrt", "numpy.sqrt", "matplotlib.pyplot.subplots", "zip", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "numpy.diagonal", "numpy.diagonal", "AbstractWavHook.AbstractWavHook._filled_width_line_plot", "AbstractWavHook.AbstractWavHook._filled_width_line_plot", "ax.set_ylim", "ax.legend"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._filled_width_line_plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._filled_width_line_plot"], ["", "def", "_plot_mean_sigma", "(", "self", ",", "means", ",", "covariance", ",", "prior_means", ",", "prior_covs", ",", "file_name", ")", ":", "\n", "        ", "'''\n        plots the mean and variance (main diagonal of covariance matrix)\n         of a multivariate gaussian distribution only for the first 2 channels\n        Args:\n            means (np.array): the means of the samples, shape=(latent_dim, channels)\n            covariance (np.array): the covariance matrix of the samples associated with the mean,\n                                    shape=(channels, latent_dim, latent_dim)\n            prior_means (np.array): shape=(channels, latent_dim)\n            prior_covs (np.array): shape=(channels, latent_dim, latent_dim)\n\n        Returns:\n            None\n        '''", "\n", "sigmas", "=", "np", ".", "sqrt", "(", "np", ".", "diagonal", "(", "covariance", ",", "axis1", "=", "-", "1", ",", "axis2", "=", "-", "2", ")", ")", "\n", "prior_sigmas", "=", "np", ".", "sqrt", "(", "np", ".", "diagonal", "(", "prior_covs", ",", "axis1", "=", "-", "1", ",", "axis2", "=", "-", "2", ")", ")", "\n", "num_channels", "=", "means", ".", "shape", "[", "1", "]", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "num_channels", ",", "1", ",", "figsize", "=", "(", "15", ",", "12", ")", ")", "\n", "for", "ax", ",", "mean", ",", "sigma", ",", "prior_mean", ",", "prior_sigma", "in", "zip", "(", "axs", ",", "means", ".", "T", ",", "sigmas", ",", "prior_means", ",", "prior_sigmas", ")", ":", "\n", "            ", "self", ".", "_filled_width_line_plot", "(", "ax", ",", "prior_mean", ",", "prior_sigma", ",", "'r-'", ",", "'red'", ",", "label", "=", "'prior'", ")", "\n", "self", ".", "_filled_width_line_plot", "(", "ax", ",", "mean", ",", "sigma", ",", "'b-'", ",", "'#7f66ff'", ",", "label", "=", "'posterior'", ")", "\n", "ax", ".", "set_ylim", "(", "[", "(", "mean", "-", "sigma", ")", ".", "min", "(", ")", ",", "(", "mean", "+", "sigma", ")", ".", "max", "(", ")", "]", ")", "\n", "ax", ".", "legend", "(", "loc", "=", "2", ",", "bbox_to_anchor", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "dir_name_reconstructions", "+", "'/'", "+", "file_name", "+", "'.jpg'", ",", "quality", "=", "90", ",", "format", "=", "'jpg'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._filled_width_line_plot": [[300, 308], ["numpy.arange", "plot.plot", "plot.fill_between", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_filled_width_line_plot", "(", "self", ",", "plot", ",", "x", ",", "tube_width", ",", "line_style", ",", "fill_color", ",", "label", ")", ":", "\n", "        ", "'''\n        plots the given x as a line and fills the space between [x - tube_width, x + tube_width] with the given fill color\n        '''", "\n", "label", "=", "'{}: mu({:.3f}), sg({:.3f})'", ".", "format", "(", "label", ",", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "mean", "(", "tube_width", ")", ")", "\n", "x_ticks", "=", "np", ".", "arange", "(", "0", ",", "x", ".", "shape", "[", "0", "]", ")", "\n", "plot", ".", "plot", "(", "x_ticks", ",", "x", ",", "line_style", ",", "label", "=", "label", ")", "\n", "plot", ".", "fill_between", "(", "x_ticks", ",", "x", "-", "tube_width", ",", "x", "+", "tube_width", ",", "alpha", "=", "0.5", ",", "edgecolor", "=", "fill_color", ",", "facecolor", "=", "fill_color", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._spider_plot": [[309, 342], ["matplotlib.pyplot.figure", "matplotlib.pyplot.figure.add_gridspec", "matplotlib.pyplot.figure.add_subplot", "plt.figure.add_subplot.set_title", "plt.figure.add_subplot.plot", "matplotlib.pyplot.figure.add_subplot", "plt.figure.add_subplot.set_title", "plt.figure.add_subplot.plot", "numpy.arange", "numpy.split", "matplotlib.pyplot.ylim", "enumerate", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.clf", "plt.figure.add_subplot.axvline", "plt.figure.add_subplot.axvline", "z.min", "z.max", "matplotlib.pyplot.figure.add_subplot", "plt.figure.add_subplot.set_title", "AbstractWavHook.AbstractWavHook._spider", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._spider"], ["", "def", "_spider_plot", "(", "self", ",", "x", ",", "z", ",", "num_time_splits", ",", "file_name", ",", "label", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "constrained_layout", "=", "True", ",", "figsize", "=", "(", "20", ",", "20", ")", ")", "\n", "grid_spec", "=", "fig", ".", "add_gridspec", "(", "4", ",", "num_time_splits", "//", "2", ")", "\n", "\n", "split_signal_length", "=", "z", ".", "shape", "[", "0", "]", "//", "num_time_splits", "\n", "hoplen", "=", "x", ".", "shape", "[", "0", "]", "//", "z", ".", "shape", "[", "0", "]", "\n", "\n", "ax1_", "=", "fig", ".", "add_subplot", "(", "grid_spec", "[", "0", ",", ":", "]", ")", "\n", "ax1_", ".", "set_title", "(", "'Original Signal - '", "+", "str", "(", "label", ")", ")", "\n", "ax1_", ".", "plot", "(", "x", ")", "\n", "\n", "ax2_", "=", "fig", ".", "add_subplot", "(", "grid_spec", "[", "1", ",", ":", "]", ")", "\n", "ax2_", ".", "set_title", "(", "'Encoding Sample'", ")", "\n", "ax2_", ".", "plot", "(", "z", ")", "\n", "\n", "x_coords_split_lines", "=", "np", ".", "arange", "(", "0", ",", "z", ".", "shape", "[", "0", "]", "+", "1", ",", "split_signal_length", ")", "\n", "for", "x_coord", "in", "x_coords_split_lines", ":", "\n", "            ", "ax2_", ".", "axvline", "(", "x", "=", "x_coord", ",", "c", "=", "'k'", ")", "\n", "ax1_", ".", "axvline", "(", "x", "=", "x_coord", "*", "hoplen", ",", "c", "=", "'k'", ")", "\n", "\n", "", "sub_zs", "=", "np", ".", "split", "(", "z", ",", "num_time_splits", ")", "\n", "\n", "plt", ".", "ylim", "(", "z", ".", "min", "(", ")", ",", "z", ".", "max", "(", ")", ")", "\n", "for", "i", ",", "sub_z", "in", "enumerate", "(", "sub_zs", ")", ":", "\n", "            ", "line", "=", "2", "if", "i", "<", "num_time_splits", "//", "2", "else", "3", "\n", "ax3_i", "=", "fig", ".", "add_subplot", "(", "grid_spec", "[", "line", ",", "i", "%", "(", "num_time_splits", "//", "2", ")", "]", ",", "polar", "=", "True", ")", "\n", "ax3_i", ".", "set_title", "(", "'Time Slice '", "+", "str", "(", "i", "+", "1", ")", ")", "\n", "\n", "self", ".", "_spider", "(", "ax3_i", ",", "sub_z", ")", "\n", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "file_name", ",", "format", "=", "'jpg'", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook._spider": [[343, 354], ["matplotlib.pyplot.xticks", "numpy.concatenate", "range", "ax.plot", "range", "str", "range", "float"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "_spider", "(", "self", ",", "ax", ",", "z", ")", ":", "\n", "        ", "length", ",", "channels", "=", "z", ".", "shape", "\n", "angles", "=", "[", "n", "/", "float", "(", "channels", ")", "*", "2", "*", "np", ".", "pi", "for", "n", "in", "range", "(", "channels", ")", "]", "\n", "angles", "+=", "angles", "[", ":", "1", "]", "\n", "\n", "# x_labels", "\n", "plt", ".", "xticks", "(", "angles", "[", ":", "-", "1", "]", ",", "[", "'ch_'", "+", "str", "(", "ch", "+", "1", ")", "for", "ch", "in", "range", "(", "channels", ")", "]", ")", "\n", "\n", "circular_z", "=", "np", ".", "concatenate", "(", "[", "z", ",", "z", "[", ":", ",", ":", "1", "]", "]", ",", "axis", "=", "1", ")", "\n", "for", "t", "in", "range", "(", "length", ")", ":", "\n", "            ", "ax", ".", "plot", "(", "angles", ",", "circular_z", "[", "t", ",", ":", "]", ",", "linestyle", "=", "'solid'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.write_to_file": [[356, 361], ["string_.endswith", "open", "reconstr_metrics_file.write"], "methods", ["None"], ["", "", "def", "write_to_file", "(", "self", ",", "file_name", ",", "string_", ")", ":", "\n", "        ", "if", "not", "string_", ".", "endswith", "(", "'\\n'", ")", ":", "\n", "            ", "string_", "+=", "'\\n'", "\n", "", "with", "open", "(", "file_name", ",", "'a+'", ")", "as", "reconstr_metrics_file", ":", "\n", "            ", "reconstr_metrics_file", ".", "write", "(", "string_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.log_reconstr_loss": [[362, 380], ["open", "line.strip().split", "global_steps.append", "reconstr_losses.append", "AbstractWavHook.AbstractWavHook.write_to_file", "matplotlib.pyplot.title", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.clf", "reconstr_loss_file.readlines", "int", "float", "file_name.replace", "line.strip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.write_to_file", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "", "def", "log_reconstr_loss", "(", "self", ",", "reconstr_loss", ",", "file_name", ")", ":", "\n", "        ", "with", "open", "(", "file_name", ",", "'r+'", ")", "as", "reconstr_loss_file", ":", "\n", "            ", "lines", "=", "reconstr_loss_file", ".", "readlines", "(", ")", "[", "1", ":", "]", "\n", "\n", "", "reconstr_losses", "=", "[", "]", "\n", "global_steps", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "global_steps", ".", "append", "(", "int", "(", "line_split", "[", "0", "]", ")", ")", "\n", "reconstr_losses", ".", "append", "(", "float", "(", "line_split", "[", "1", "]", ")", ")", "\n", "\n", "", "if", "self", ".", "_time_ref", "not", "in", "global_steps", ":", "\n", "            ", "self", ".", "write_to_file", "(", "file_name", ",", "\n", "string_", "=", "'{}\\t{:.2f}'", ".", "format", "(", "self", ".", "_time_ref", ",", "reconstr_loss", ")", ")", "\n", "plt", ".", "title", "(", "'RL loss validation'", ")", "\n", "plt", ".", "plot", "(", "global_steps", ",", "reconstr_losses", ")", "\n", "plt", ".", "savefig", "(", "file_name", ".", "replace", "(", "'txt'", ",", "'jpg'", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.is_model_vae": [[382, 390], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "is_model_vae", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "model_class_name", "==", "'WavenetVAE'", ":", "\n", "            ", "return", "True", "\n", "", "elif", "self", ".", "model_class_name", "==", "'WavenetAE'", ":", "\n", "            ", "return", "False", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Please check function {} -- only support WavenetVAE and WavenetAE currently'", "\n", ".", "format", "(", "self", ".", "is_model_vae", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.do_compute_reconstruction_metrics": [[391, 401], ["core.wavenet.mel_utils_numpy.mfcc", "core.wavenet.mel_utils_numpy.mfcc", "numpy.mean", "numpy.square", "core.wavenet.mel_utils_numpy.mcd_per_sample", "psnr_per_sample.flatten", "numpy.log10", "numpy.log10", "x_original.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mcd_per_sample"], ["", "", "def", "do_compute_reconstruction_metrics", "(", "self", ",", "x_original", ",", "x_reconstruction", ")", ":", "\n", "# compute MCD", "\n", "        ", "sample_rate", "=", "self", ".", "_model", ".", "dataset", ".", "sample_rate", "\n", "mfcc_original", "=", "mfcc", "(", "x_original", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "mfcc_reconstructed", "=", "mfcc", "(", "x_reconstruction", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "\n", "mse_per_sample", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "x_original", "-", "x_reconstruction", ")", ",", "axis", "=", "1", ")", "\n", "psnr_per_sample", "=", "20", "*", "np", ".", "log10", "(", "x_original", ".", "max", "(", ")", ")", "-", "10", "*", "np", ".", "log10", "(", "mse_per_sample", ")", "\n", "\n", "return", "mcd_per_sample", "(", "mfcc_original", ",", "mfcc_reconstructed", ")", ",", "psnr_per_sample", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.log_reconstr_metrics": [[402, 434], ["sorted", "str", "enumerate", "AbstractWavHook.AbstractWavHook.write_to_file", "set", "numpy.argwhere().flatten", "AbstractWavHook.AbstractWavHook.do_compute_reconstruction_metrics", "metrics[].append", "metrics[].append", "metrics[].append", "zip", "zip", "numpy.mean", "numpy.argwhere", "numpy.mean", "numpy.std", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.write_to_file", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractWavHook.AbstractWavHook.do_compute_reconstruction_metrics", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "log_reconstr_metrics", "(", "self", ",", "time_ref", ",", "samples", ",", "reconstr_samples", ",", "reconstr_loss", ",", "labels", ",", "file_name", ")", ":", "\n", "# leave this sorted it is important to have the same format as the header", "\n", "        ", "unique_labels", "=", "sorted", "(", "set", "(", "labels", ")", ")", "\n", "labels_arrays_dict", "=", "{", "}", "\n", "\n", "# we want to write in the format metric1_label1, metric1_label2, metric1_avg metric2_label1, metric_2_label2, .... etc.", "\n", "metrics", "=", "[", "[", "]", ",", "[", "]", ",", "[", "]", "]", "\n", "for", "label", "in", "unique_labels", ":", "\n", "            ", "label_indices", "=", "np", ".", "argwhere", "(", "labels", "==", "label", ")", ".", "flatten", "(", ")", "\n", "mcd_", ",", "psnr", "=", "self", ".", "do_compute_reconstruction_metrics", "(", "samples", "[", "label_indices", "]", ",", "reconstr_samples", "[", "label_indices", "]", ")", "\n", "loss", "=", "reconstr_loss", "[", "label_indices", "]", "\n", "metrics", "[", "0", "]", ".", "append", "(", "mcd_", ")", "\n", "metrics", "[", "1", "]", ".", "append", "(", "psnr", ")", "\n", "metrics", "[", "2", "]", ".", "append", "(", "loss", ")", "\n", "\n", "", "metric_names", "=", "[", "'mcd'", ",", "'psnr'", ",", "'loss'", "]", "\n", "entry", "=", "str", "(", "time_ref", ")", "\n", "# fig, ax = plt.subplots(1, len(metric_names), figsize=(30, 25))", "\n", "\n", "for", "i", ",", "(", "metric_list", ",", "metric_name", ")", "in", "enumerate", "(", "zip", "(", "metrics", ",", "metric_names", ")", ")", ":", "\n", "# ax[i].set_title(metric_name)", "\n", "            ", "for", "metric_per_label", ",", "label", "in", "zip", "(", "metric_list", ",", "unique_labels", ")", ":", "\n", "# sns.kdeplot(metric_per_label, label=label, shade=True, ax=ax[i])", "\n", "                ", "entry", "+=", "'\\t{:.2f}({:.2f})'", ".", "format", "(", "np", ".", "mean", "(", "metric_per_label", ")", ",", "np", ".", "std", "(", "metric_per_label", ")", ")", "\n", "", "entry", "+=", "'\\t{:.2f}'", ".", "format", "(", "np", ".", "mean", "(", "np", ".", "concatenate", "(", "metric_list", ")", ")", ")", "\n", "", "entry", "+=", "'\\n'", "\n", "\n", "# relative_file_name = file_name.split(os.path.sep)[-1]", "\n", "# relative_file_name_anomaly = self.anomaly_detection_dir + '/label_hist_' + relative_file_name.replace('.txt', '.png')", "\n", "# plt.savefig(relative_file_name_anomaly)", "\n", "# plt.clf()", "\n", "self", ".", "write_to_file", "(", "file_name", ",", "entry", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImagesGenerateHook.ImagesGenerateHook.__init__": [[13, 32], ["argo.core.hooks.EveryNEpochsTFModelImagesHook.EveryNEpochsTFModelImagesHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["\n", "from", ".", "ImagesSaver", "import", "ImagesSaver", "\n", "\n", "\n", "class", "ImagesGenerateHook", "(", "EveryNEpochsTFModelImagesHook", ")", ":", "\n", "    ", "\"\"\"\n    Hook Generating images by sampling from the latent space\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "n_gen_samples", ",", "\n", "#n_images_rows,", "\n", "n_images_columns", ",", "\n", "dirName", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "+", "'/generated_images'", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImagesGenerateHook.ImagesGenerateHook.do_when_triggered": [[34, 56], ["tf_logging.info", "ImagesGenerateHook.ImagesGenerateHook._model.generate", "int", "range", "ImagesGenerateHook.ImagesGenerateHook.images_saver.save_images", "numpy.ceil", "range", "range", "panel[].append", "len", "str().zfill", "len", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractGenerativeModel.AbstractGenerativeModel.generate", "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["\n", "self", ".", "_n_images_columns", "=", "n_images_columns", "\n", "self", ".", "_n_gen_samples", "=", "n_gen_samples", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create ImagesGenerateHook for %d samples\"", "%", "self", ".", "_n_gen_samples", ")", "\n", "\n", "\n", "", "def", "do_when_triggered", "(", "self", ",", "global_step", ",", "time_ref", ",", "run_context", ",", "run_values", ",", "time_ref_str", "=", "\"ep\"", ")", ":", "\n", "#tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for ImagesGenerateHook\"", ")", "\n", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "images", "=", "self", ".", "_model", ".", "generate", "(", "batch_size", "=", "self", ".", "_n_gen_samples", ",", "sess", "=", "run_context", ".", "session", ")", "\n", "\n", "images_saver", "=", "ImagesSaver", "(", "self", ".", "_dirName", ")", "\n", "\n", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "\n", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", ")", "]", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                ", "panel", "[", "i", "]", ".", "append", "(", "images", "[", "c", "]", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook.__init__": [[83, 153], ["ArgoHook.ArgoHook.__init__", "print", "os.makedirs", "len", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "fileName", ",", "\n", "dirName", ",", "\n", "tensors_to_average", ",", "\n", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", ",", "\n", "average_steps", ",", "\n", "tensorboard_dir", ",", "\n", "trigger_summaries", ",", "\n", "# trigger_plot = True,", "\n", "print_to_screen", "=", "True", ",", "\n", "plot_offset", "=", "0", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", "]", ",", "\n", "time_reference", "=", "\"epochs\"", "\n", ")", ":", "\n", "\n", "        ", "\"\"\"LoggingMeanTensorsHook.\n\n        \"\"\"", "\n", "super", "(", "LoggingMeanTensorsHook", ",", "self", ")", ".", "__init__", "(", "model", ",", "\n", "average_steps", ",", "\n", "time_reference", ",", "\n", "datasets_keys", ",", "\n", "plot_offset", "=", "plot_offset", ",", "\n", "tensorboard_dir", "=", "tensorboard_dir", ",", "\n", "trigger_summaries", "=", "trigger_summaries", ")", "\n", "print", "(", "\"LoggingMeanTensorsHook\"", ")", "\n", "\n", "assert", "(", "tensors_to_average", ")", "\n", "assert", "(", "tensors_to_average_names", ")", "\n", "assert", "(", "tensors_to_average_plots", ")", "\n", "\n", "self", ".", "_default_metric", "=", "tf", ".", "metrics", ".", "mean", "\n", "\n", "self", ".", "_fileName", "=", "fileName", "\n", "\n", "self", ".", "_dirName", "=", "dirName", "\n", "if", "dirName", ":", "\n", "            ", "os", ".", "makedirs", "(", "dirName", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# check if the second panel is empty, as it happens in case the cost function", "\n", "# is returning an empty list for \"self.loss_nodes_to_log\"", "\n", "# (not super elegant done in this way, however good enough for the moment - Luigi)", "\n", "", "if", "len", "(", "tensors_to_average", ")", ">", "1", "and", "not", "tensors_to_average", "[", "1", "]", ":", "\n", "            ", "del", "tensors_to_average", "[", "1", "]", "\n", "del", "tensors_to_average_names", "[", "1", "]", "\n", "del", "tensors_to_average_plots", "[", "1", "]", "\n", "\n", "", "self", ".", "_tensors", "=", "tensors_to_average", "\n", "\n", "# nodes computed and saved", "\n", "self", ".", "_tensors_names", "=", "tensors_to_average_names", "\n", "self", ".", "_tensors_plots", "=", "tensors_to_average_plots", "\n", "self", ".", "_tensors_values", "=", "[", "]", "\n", "\n", "self", ".", "_print_to_screen", "=", "print_to_screen", "\n", "\n", "self", ".", "_train_loop_key", "=", "train_loop_key", "\n", "\n", "# parent constructor already called, so refer to self", "\n", "self", ".", "_no_train_loop_datasets_keys", "=", "self", ".", "_datasets_keys", "\n", "self", ".", "_datasets_keys", "=", "[", "self", ".", "_train_loop_key", "]", "+", "self", ".", "_datasets_keys", "\n", "\n", "for", "vertical_panels", "in", "self", ".", "_tensors_names", ":", "\n", "            ", "for", "tensor_names_panel", "in", "vertical_panels", ":", "\n", "                ", "tf_logging", ".", "info", "(", "\"Create LoggingMeanTensorsHook for: \"", "+", "\", \"", ".", "join", "(", "tensor_names_panel", ")", ")", "\n", "\n", "", "", "self", ".", "_did_begin_already", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook.begin": [[154, 207], ["super().begin", "LoggingMeanTensorsHook.LoggingMeanTensorsHook._create_or_open_files", "zip", "RuntimeError", "mean_values_panel.append", "mean_update_ops_panel.append", "mean_reset_ops_panel.append", "zip", "zip", "mean_values.append", "mean_update_ops.append", "mean_reset_ops.append", "zip", "LoggingMeanTensorsHook.LoggingMeanTensorsHook._register_summary_for_tensor", "utils.argo_utils.compose_name", "utils.argo_utils.create_reset_metric"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.begin", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2._create_or_open_files", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._register_summary_for_tensor", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.compose_name", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_reset_metric"], ["", "def", "begin", "(", "self", ")", ":", "\n", "        ", "super", "(", "LoggingMeanTensorsHook", ",", "self", ")", ".", "begin", "(", ")", "\n", "\n", "if", "not", "self", ".", "_did_begin_already", ":", "\n", "            ", "self", ".", "_did_begin_already", "=", "True", "\n", "\n", "self", ".", "_mean_values", "=", "{", "}", "\n", "self", ".", "_mean_update_ops", "=", "{", "}", "\n", "self", ".", "_mean_reset_ops", "=", "{", "}", "\n", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "\n", "                ", "mean_values_panel", "=", "[", "]", "\n", "mean_update_ops_panel", "=", "[", "]", "\n", "mean_reset_ops_panel", "=", "[", "]", "\n", "\n", "for", "vertical_panels", "in", "self", ".", "_tensors", ":", "\n", "\n", "                    ", "mean_values", "=", "[", "]", "\n", "mean_update_ops", "=", "[", "]", "\n", "mean_reset_ops", "=", "[", "]", "\n", "\n", "for", "tensors_panel", "in", "vertical_panels", ":", "\n", "                        ", "mean_v", ",", "mean_u_ops", ",", "mean_r_ops", "=", "zip", "(", "*", "[", "create_reset_metric", "(", "self", ".", "_default_metric", ",", "\n", "scope", "=", "dataset_str", "+", "\"_mean_reset_metric/\"", "+", "tnsr", ".", "name", ",", "\n", "values", "=", "tnsr", ")", "\n", "for", "tnsr", "in", "tensors_panel", "]", ")", "\n", "\n", "mean_values", ".", "append", "(", "mean_v", ")", "\n", "mean_update_ops", ".", "append", "(", "mean_u_ops", ")", "\n", "mean_reset_ops", ".", "append", "(", "mean_r_ops", ")", "\n", "\n", "", "mean_values_panel", ".", "append", "(", "mean_values", ")", "\n", "mean_update_ops_panel", ".", "append", "(", "mean_update_ops", ")", "\n", "mean_reset_ops_panel", ".", "append", "(", "mean_reset_ops", ")", "\n", "\n", "", "self", ".", "_mean_values", "[", "dataset_str", "]", "=", "mean_values_panel", "\n", "self", ".", "_mean_update_ops", "[", "dataset_str", "]", "=", "mean_update_ops_panel", "\n", "self", ".", "_mean_reset_ops", "[", "dataset_str", "]", "=", "mean_reset_ops_panel", "\n", "\n", "# These fors could be merged, I'm just not sure it will help the readability", "\n", "for", "(", "mean_values_vertical_panels", ",", "tensors_names_vertical_panels", ")", "in", "zip", "(", "self", ".", "_mean_values", "[", "dataset_str", "]", ",", "\n", "self", ".", "_tensors_names", ")", ":", "\n", "                    ", "for", "(", "mean_values_panel", ",", "tensor_names_panel", ")", "in", "zip", "(", "mean_values_vertical_panels", ",", "\n", "tensors_names_vertical_panels", ")", ":", "\n", "                        ", "for", "mn", ",", "mn_name", "in", "zip", "(", "mean_values_panel", ",", "tensor_names_panel", ")", ":", "\n", "                            ", "self", ".", "_register_summary_for_tensor", "(", "compose_name", "(", "mn_name", ",", "dataset_str", ")", ",", "mn", ")", "\n", "\n", "", "", "", "", "if", "self", ".", "_global_step_tensor", "is", "None", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Global step should be created to use LoggingMeanTensorsHook.\"", ")", "\n", "\n", "", "self", ".", "_create_or_open_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook._before_run_args": [[208, 220], ["super()._before_run_args", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook._before_run_args"], ["", "", "def", "_before_run_args", "(", "self", ")", ":", "\n", "        ", "args", "=", "super", "(", "LoggingMeanTensorsHook", ",", "self", ")", ".", "_before_run_args", "(", ")", "\n", "\n", "for", "(", "tensors_plots_vertical_panels", ",", "mean_update_vertical_panels", ")", "in", "zip", "(", "self", ".", "_tensors_plots", ",", "\n", "self", ".", "_mean_update_ops", "[", "\n", "self", ".", "_train_loop_key", "]", ")", ":", "\n", "            ", "for", "(", "tensors_plots", ",", "mean_update_ops", ")", "in", "zip", "(", "tensors_plots_vertical_panels", ",", "mean_update_vertical_panels", ")", ":", "\n", "# the name of the op is the name of the entire subplot, which is file of the txt file", "\n", "                ", "args", "=", "{", "**", "args", ",", "\n", "\"update_ops_\"", "+", "tensors_plots", "[", "\"fileName\"", "]", ":", "mean_update_ops", "}", "\n", "\n", "", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook._after_run": [[221, 223], ["None"], "methods", ["None"], ["", "def", "_after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook.after_run": [[224, 256], ["super().after_run", "LoggingMeanTensorsHook.LoggingMeanTensorsHook.update_time", "run_context.session.run", "LoggingMeanTensorsHook.LoggingMeanTensorsHook._after_run", "LoggingMeanTensorsHook.LoggingMeanTensorsHook.log_to_file_and_screen", "LoggingMeanTensorsHook.LoggingMeanTensorsHook.reset_means", "LoggingMeanTensorsHook.evaluate_means_over_dataset", "LoggingMeanTensorsHook.LoggingMeanTensorsHook.plot"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.after_run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.update_time", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2._after_run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.log_to_file_and_screen", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook.reset_means", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.evaluate_means_over_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "super", "(", "LoggingMeanTensorsHook", ",", "self", ")", ".", "after_run", "(", "run_context", ",", "run_values", ")", "\n", "\n", "if", "self", ".", "_trigged_for_step", ":", "\n", "\n", "# update time and reset triggered for step", "\n", "            ", "self", ".", "update_time", "(", ")", "\n", "\n", "# mean over train_loop", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "# self._mean_values", "\n", "self", ".", "_tensors_values", "[", "self", ".", "_train_loop_key", "]", "=", "run_context", ".", "session", ".", "run", "(", "\n", "self", ".", "_mean_values", "[", "self", ".", "_train_loop_key", "]", ")", "\n", "\n", "# mean over the other dataset_keys", "\n", "for", "dataset_str", "in", "self", ".", "_no_train_loop_datasets_keys", ":", "\n", "                ", "self", ".", "_tensors_values", "[", "dataset_str", "]", "=", "evaluate_means_over_dataset", "(", "run_context", ".", "session", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_initializers", "[", "dataset_str", "]", ",", "\n", "self", ".", "_ds_handles", "[", "dataset_str", "]", ",", "\n", "self", ".", "_mean_values", "[", "dataset_str", "]", ",", "\n", "self", ".", "_mean_update_ops", "[", "dataset_str", "]", ",", "\n", "self", ".", "_mean_reset_ops", "[", "dataset_str", "]", ")", "\n", "\n", "", "self", ".", "_after_run", "(", "run_context", ",", "run_values", ")", "\n", "\n", "self", ".", "log_to_file_and_screen", "(", "self", ".", "_print_to_screen", ")", "\n", "\n", "self", ".", "reset_means", "(", "run_context", ".", "session", ")", "\n", "\n", "if", "self", ".", "_time_ref", "<", "50", "or", "self", ".", "_time_ref", "%", "10", "==", "0", ":", "\n", "                ", "self", ".", "plot", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook.reset_means": [[257, 266], ["zip", "len", "session.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "", "def", "reset_means", "(", "self", ",", "session", ")", ":", "\n", "        ", "for", "mean_reset_ops_panel", ",", "tensors_vertical_panel", "in", "zip", "(", "self", ".", "_mean_reset_ops", "[", "self", ".", "_train_loop_key", "]", ",", "\n", "self", ".", "_tensors_names", ")", ":", "\n", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "\n", "                ", "for", "mean_reset_ops", "in", "mean_reset_ops_panel", ":", "\n", "# reset train means", "\n", "                    ", "session", ".", "run", "(", "mean_reset_ops", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.evaluate_means_over_dataset": [[16, 37], ["session.run", "session.run", "session.run", "Exception", "type", "session.run"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["def", "evaluate_means_over_dataset", "(", "session", ",", "handle", ",", "dataset_initializer", ",", "dataset_handle", ",", "\n", "metrics_values", ",", "metrics_update_ops", ",", "metrics_reset_ops", ",", "feed_dict", "=", "{", "}", ",", "max_iterations", "=", "-", "1", ")", ":", "\n", "\n", "    ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "        ", "raise", "Exception", "(", "\"I need a raw session to evaluate metric over dataset.\"", ")", "\n", "\n", "", "session", ".", "run", "(", "dataset_initializer", ")", "\n", "session", ".", "run", "(", "metrics_reset_ops", ")", "\n", "\n", "# pdb.set_trace()", "\n", "iteration", "=", "0", "\n", "while", "max_iterations", "==", "-", "1", "or", "iteration", "<", "max_iterations", ":", "\n", "        ", "try", ":", "\n", "            ", "session", ".", "run", "(", "metrics_update_ops", ",", "feed_dict", "=", "{", "**", "feed_dict", ",", "\n", "handle", ":", "dataset_handle", "}", ")", "\n", "iteration", "+=", "1", "\n", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "session", ".", "run", "(", "metrics_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.evaluate_over_dataset": [[38, 58], ["session.run", "session.run", "Exception", "type", "session.run"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "evaluate_over_dataset", "(", "session", ",", "handle", ",", "dataset_initializer", ",", "dataset_handle", ",", "\n", "metrics_values", ",", "feed_dict", "=", "{", "}", ",", "max_iterations", "=", "-", "1", ")", ":", "\n", "\n", "    ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "        ", "raise", "Exception", "(", "\"I need a raw session to evaluate over dataset.\"", ")", "\n", "\n", "", "session", ".", "run", "(", "dataset_initializer", ")", "\n", "\n", "# pdb.set_trace()", "\n", "iteration", "=", "0", "\n", "while", "max_iterations", "==", "-", "1", "or", "iteration", "<", "max_iterations", ":", "\n", "        ", "try", ":", "\n", "            ", "session", ".", "run", "(", "metrics_update_ops", ",", "feed_dict", "=", "{", "**", "feed_dict", ",", "\n", "handle", ":", "dataset_handle", "}", ")", "\n", "iteration", "+=", "1", "\n", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "session", ".", "run", "(", "metrics_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FrechetInceptionDistanceHook.FrechetInceptionDistanceHook.__init__": [[35, 84], ["EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "n_batches", ",", "\n", "dirName", ",", "\n", "id", "=", "None", ",", "\n", "pb", "=", "None", ",", "\n", "input_tensor", "=", "None", ",", "\n", "output_tensor", "=", "None", ",", "\n", "datasets_keys", "=", "[", "TRAIN_SHUFFLED", ",", "VALIDATION_SHUFFLED", "]", ",", "\n", "plot_offset", "=", "0", "\n", ")", ":", "\n", "\n", "        ", "if", "pb", "or", "id", "or", "input_tensor", "or", "output_tensor", ":", "\n", "# make sure that if the user specifies a pb, then all field necessary are present", "\n", "            ", "assert", "(", "pb", "and", "id", "and", "input_tensor", "and", "output_tensor", ")", "\n", "self", ".", "inception_network", "=", "False", "\n", "self", ".", "input_tensor", "=", "input_tensor", "\n", "self", ".", "output_tensor", "=", "output_tensor", "\n", "self", ".", "pb", "=", "pb", "\n", "self", ".", "network_name", "=", "id", "\n", "", "else", ":", "\n", "# use the default inception network", "\n", "            ", "self", ".", "inception_network", "=", "True", "\n", "self", ".", "network_name", "=", "NETWORK_NAME", "\n", "\n", "", "self", ".", "_batch_size_eval", "=", "model", ".", "batch_size", "[", "\"eval\"", "]", "\n", "self", ".", "_n_images", "=", "n_batches", "*", "self", ".", "_batch_size_eval", "\n", "self", ".", "_n_batches", "=", "n_batches", "\n", "\n", "# fileName should be set before calling super()", "\n", "#self._fileHeader = '# frechet_inception_distance, network = ' + self.network_name + ', num images = ' + str(self._n_images) + '\\n'", "\n", "#self._fileHeader += '# period \\t fid_train \\t fid_validation \\t time_sec'", "\n", "\n", "log_str", "=", "\"Create FrechetInceptionDistanceHook for \"", "+", "str", "(", "self", ".", "_n_images", ")", "+", "\" samples, network \"", "+", "self", ".", "network_name", "\n", "\n", "self", ".", "_hook_name", "=", "\"scores\"", "\n", "dirName", "=", "dirName", "+", "'/'", "+", "self", ".", "_hook_name", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "datasets_keys", ",", "dirName", "=", "dirName", ",", "log_str", "=", "log_str", ",", "plot_offset", "=", "plot_offset", ")", "\n", "\n", "# nodes to be computed and saved", "\n", "self", ".", "_tensors_names", "=", "[", "[", "[", "'FID'", "]", "]", "]", "\n", "fileName", "=", "\"frechet_inception_distance-\"", "+", "self", ".", "network_name", "+", "\"-num_images-\"", "+", "str", "(", "self", ".", "_n_images", ")", "\n", "self", ".", "_tensors_plots", "=", "[", "[", "{", "'fileName'", ":", "fileName", ",", "\n", "'logscale-y'", ":", "0", "}", "]", "]", "\n", "self", ".", "_tensors_values", "=", "{", "}", "#[[self._fid]]", "\n", "self", ".", "_fileName", "=", "\"frechet_inception_distance-\"", "+", "self", ".", "network_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FrechetInceptionDistanceHook.FrechetInceptionDistanceHook._compute_mean_cov_real_images_samples": [[85, 139], ["tensorflow.cast", "tensorflow.reduce_mean", "utils.argo_utils.create_reset_metric", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.assign", "cov_update_ops.append", "cov_reset_ops.append", "cov_reset_ops.append", "cov_reset_ops.append", "cov_reset_ops.append", "features.shape.as_list", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.control_dependencies", "tensorflow.assign", "cov_update_ops.append", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.control_dependencies", "tensorflow.matmul", "tensorflow.assign", "cov_update_ops.append", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.control_dependencies", "tensorflow.assign", "cov_update_ops.append", "tensorflow.squeeze", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.create_reset_metric"], ["", "def", "_compute_mean_cov_real_images_samples", "(", "self", ",", "features", ",", "dataset_str", ")", ":", "\n", "\n", "#features_shape_besides_first = features.shape.as_list()[1:]", "\n", "#features = tf.reshape(features, [self._batch_size_eval] + features_shape_besides_first)", "\n", "        ", "batch_size", "=", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "features", ")", "[", "0", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "reduced_features", "=", "tf", ".", "reduce_mean", "(", "features", ",", "axis", "=", "0", ")", "\n", "dim_features", "=", "features", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "# check I have enough images to then invert the covariance matrix", "\n", "assert", "(", "self", ".", "_n_images", ">", "dim_features", ",", "\"The number of images used in the computation of the FrechetInceptionDistance (n_batches * self._batch_size_eval) must be great than the number of features of the classification network\"", ")", "\n", "\n", "mean_values", ",", "mean_update_ops", ",", "mean_reset_ops", "=", "create_reset_metric", "(", "tf", ".", "metrics", ".", "mean_tensor", ",", "\n", "scope", "=", "dataset_str", "+", "\"_mean_reset_metric/\"", "+", "features", ".", "name", ",", "\n", "values", "=", "reduced_features", ",", "\n", "weights", "=", "batch_size", ")", "\n", "\n", "\n", "cov_update_ops", "=", "[", "]", "\n", "cov_reset_ops", "=", "[", "]", "\n", "# self._cov_values=[]", "\n", "# init variables", "\n", "sum_w", "=", "tf", ".", "Variable", "(", "0.", ")", "\n", "x_n", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_features", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "y_n", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_features", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "C_n", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_features", ",", "dim_features", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "# update ops", "\n", "add_w", "=", "tf", ".", "assign", "(", "sum_w", ",", "sum_w", "+", "batch_size", ")", "\n", "cov_update_ops", ".", "append", "(", "add_w", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "add_w", "]", ")", ":", "\n", "            ", "x_delta", "=", "tf", ".", "reduce_sum", "(", "features", "-", "x_n", ",", "axis", "=", "0", ")", "/", "add_w", "\n", "add_x_n", "=", "tf", ".", "assign", "(", "x_n", ",", "x_n", "+", "x_delta", ")", "\n", "cov_update_ops", ".", "append", "(", "add_x_n", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "add_x_n", "]", ")", ":", "\n", "                ", "C_delta", "=", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "features", "-", "x_n", ",", "0", ")", ",", "\n", "tf", ".", "expand_dims", "(", "features", "-", "y_n", ",", "0", ")", ",", "\n", "transpose_a", "=", "True", ")", "\n", "add_C_n", "=", "tf", ".", "assign", "(", "C_n", ",", "C_n", "+", "tf", ".", "squeeze", "(", "C_delta", ",", "0", ")", ")", "\n", "cov_update_ops", ".", "append", "(", "add_C_n", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "add_C_n", "]", ")", ":", "\n", "                    ", "y_delta", "=", "tf", ".", "reduce_sum", "(", "features", "-", "y_n", ",", "axis", "=", "0", ")", "/", "add_w", "\n", "add_y_n", "=", "tf", ".", "assign", "(", "y_n", ",", "y_n", "+", "y_delta", ")", "\n", "cov_update_ops", ".", "append", "(", "add_y_n", ")", "\n", "\n", "# reset ops", "\n", "", "", "", "cov_reset_ops", ".", "append", "(", "tf", ".", "assign", "(", "sum_w", ",", "0", ")", ")", "\n", "cov_reset_ops", ".", "append", "(", "tf", ".", "assign", "(", "x_n", ",", "tf", ".", "zeros", "(", "[", "dim_features", "]", ")", ")", ")", "\n", "cov_reset_ops", ".", "append", "(", "tf", ".", "assign", "(", "y_n", ",", "tf", ".", "zeros", "(", "[", "dim_features", "]", ")", ")", ")", "\n", "cov_reset_ops", ".", "append", "(", "tf", ".", "assign", "(", "C_n", ",", "tf", ".", "zeros", "(", "[", "dim_features", ",", "dim_features", "]", ")", ")", ")", "\n", "\n", "cov_values", "=", "C_n", "/", "sum_w", "\n", "\n", "return", "mean_values", ",", "mean_update_ops", ",", "mean_reset_ops", ",", "cov_update_ops", ",", "cov_reset_ops", ",", "cov_values", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FrechetInceptionDistanceHook.FrechetInceptionDistanceHook._begin_once": [[140, 205], ["tensorflow.contrib.gan.eval.get_graph_def_from_disk", "tensorflow.shape", "len", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.resize_bilinear", "tensorflow.image.resize_bilinear", "network", "network", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.contrib.gan.eval.get_graph_def_from_disk", "network", "network", "FrechetInceptionDistanceHook.FrechetInceptionDistanceHook._compute_mean_cov_real_images_samples", "FrechetInceptionDistanceHook.FrechetInceptionDistanceHook._compute_mean_cov_real_images_samples", "tensorflow.contrib.gan.eval.run_image_classifier", "x.shape.as_list", "tensorflow.equal", "tensorflow.equal", "tensorflow.contrib.gan.eval.run_image_classifier", "tensorflow.tile", "tensorflow.tile"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.FrechetInceptionDistanceHook.FrechetInceptionDistanceHook._compute_mean_cov_real_images_samples", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FrechetInceptionDistanceHook.FrechetInceptionDistanceHook._compute_mean_cov_real_images_samples"], ["", "def", "_begin_once", "(", "self", ")", ":", "\n", "\n", "        ", "x", "=", "self", ".", "_model", ".", "x", "\n", "samples", "=", "self", ".", "_model", ".", "samples", "\n", "#self.samples = tf.placeholder(x.dtype, shape=x.get_shape(), name='random_samples')", "\n", "\n", "self", ".", "_mean_values_real", "=", "{", "}", "\n", "self", ".", "_mean_update_ops_real", "=", "{", "}", "\n", "self", ".", "_mean_reset_ops_real", "=", "{", "}", "\n", "\n", "self", ".", "_cov_values_real", "=", "{", "}", "\n", "self", ".", "_cov_update_ops_real", "=", "{", "}", "\n", "self", ".", "_cov_reset_ops_real", "=", "{", "}", "\n", "\n", "self", ".", "_mean_values_sample", "=", "{", "}", "\n", "self", ".", "_mean_update_ops_sample", "=", "{", "}", "\n", "self", ".", "_mean_reset_ops_sample", "=", "{", "}", "\n", "\n", "self", ".", "_cov_values_sample", "=", "{", "}", "\n", "self", ".", "_cov_update_ops_sample", "=", "{", "}", "\n", "self", ".", "_cov_reset_ops_sample", "=", "{", "}", "\n", "\n", "if", "self", ".", "inception_network", ":", "\n", "\n", "            ", "graph_def", "=", "tf", ".", "contrib", ".", "gan", ".", "eval", ".", "get_graph_def_from_disk", "(", "INCEPTION_V4_GRAPH_DEF", ")", "\n", "network", "=", "lambda", "x", ":", "tf", ".", "contrib", ".", "gan", ".", "eval", ".", "run_image_classifier", "(", "x", ",", "graph_def", ",", "INPUT_TENSOR", ",", "OUTPUT_TENSOR", ")", "\n", "\n", "# check number of channales", "\n", "shape", "=", "tf", ".", "shape", "(", "x", ")", "\n", "channels", "=", "shape", "[", "-", "1", "]", "\n", "len_shape", "=", "len", "(", "x", ".", "shape", ".", "as_list", "(", ")", ")", "\n", "\n", "# make sure we have images with 3 channels", "\n", "x_3ch", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "channels", ",", "1", ")", ",", "lambda", ":", "tf", ".", "tile", "(", "x", ",", "[", "1", "]", "*", "(", "len_shape", "-", "1", ")", "+", "[", "3", "]", ")", ",", "lambda", ":", "x", ")", "\n", "samples_3ch", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "channels", ",", "1", ")", ",", "lambda", ":", "tf", ".", "tile", "(", "samples", ",", "[", "1", "]", "*", "(", "len_shape", "-", "1", ")", "+", "[", "3", "]", ")", ",", "lambda", ":", "samples", ")", "\n", "\n", "#samples_3channels = tf.expand_dims(samples_3channels[0],axis=0)", "\n", "#x_3channels = tf.expand_dims(x_3channels[0],axis=0)", "\n", "\n", "# resize images", "\n", "x_3ch", "=", "tf", ".", "image", ".", "resize_bilinear", "(", "x_3ch", ",", "[", "IMAGE_WIDTH", ",", "IMAGE_HEIGHT", "]", ",", "align_corners", "=", "False", ")", "\n", "samples_3ch", "=", "tf", ".", "image", ".", "resize_bilinear", "(", "samples_3ch", ",", "[", "IMAGE_WIDTH", ",", "IMAGE_HEIGHT", "]", ",", "align_corners", "=", "False", ")", "\n", "\n", "features_real", "=", "network", "(", "x_3ch", ")", "\n", "features_samples", "=", "network", "(", "samples_3ch", ")", "\n", "# more two extra dims", "\n", "features_real", "=", "tf", ".", "squeeze", "(", "features_real", ",", "[", "1", ",", "2", "]", ")", "\n", "features_sample", "=", "tf", ".", "squeeze", "(", "features_samples", ",", "[", "1", ",", "2", "]", ")", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "graph_def", "=", "tf", ".", "contrib", ".", "gan", ".", "eval", ".", "get_graph_def_from_disk", "(", "self", ".", "pb", ")", "\n", "network", "=", "lambda", "x", ":", "tf", ".", "contrib", ".", "gan", ".", "eval", ".", "run_image_classifier", "(", "x", ",", "\n", "graph_def", ",", "\n", "self", ".", "input_tensor", ",", "\n", "self", ".", "output_tensor", ")", "\n", "\n", "features_real", "=", "network", "(", "x", ")", "\n", "features_sample", "=", "network", "(", "samples", ")", "\n", "\n", "", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "\n", "            ", "self", ".", "_mean_values_real", "[", "dataset_str", "]", ",", "self", ".", "_mean_update_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_mean_reset_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_cov_update_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_cov_reset_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_cov_values_real", "[", "dataset_str", "]", "=", "self", ".", "_compute_mean_cov_real_images_samples", "(", "features_real", ",", "dataset_str", ")", "\n", "\n", "self", ".", "_mean_values_sample", "[", "dataset_str", "]", ",", "self", ".", "_mean_update_ops_sample", "[", "dataset_str", "]", ",", "self", ".", "_mean_reset_ops_sample", "[", "dataset_str", "]", ",", "self", ".", "_cov_update_ops_sample", "[", "dataset_str", "]", ",", "self", ".", "_cov_reset_ops_sample", "[", "dataset_str", "]", ",", "self", ".", "_cov_values_sample", "[", "dataset_str", "]", "=", "self", ".", "_compute_mean_cov_real_images_samples", "(", "features_sample", ",", "dataset_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.FrechetInceptionDistanceHook.FrechetInceptionDistanceHook.do_when_triggered": [[207, 272], ["tf_logging.info", "FrechetInceptionDistanceHook.FrechetInceptionDistanceHook.log_to_file_and_screen", "LoggingMeanTensorsHook.evaluate_means_over_dataset", "LoggingMeanTensorsHook.evaluate_means_over_dataset", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "real_images_covs[].dot", "numpy.isfinite().all", "warnings.warn", "scipy.linalg.sqrtm", "print", "str", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.log_to_file_and_screen", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.evaluate_means_over_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggingMeanTensorsHook.evaluate_means_over_dataset"], ["", "", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger FrechetInceptionDistanceHook for \"", "+", "str", "(", "self", ".", "_n_images", ")", "+", "\" samples, network \"", "+", "self", ".", "network_name", ")", "\n", "#self.random_samples = self._model.generate(batch_size=self._n_batches)", "\n", "\n", "real_images_means", "=", "{", "}", "\n", "real_images_covs", "=", "{", "}", "\n", "sample_means", "=", "{", "}", "\n", "sample_covs", "=", "{", "}", "\n", "\n", "# mean over the other dataset_keys", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "\n", "            ", "real_images_means", "[", "dataset_str", "]", ",", "sample_means", "[", "dataset_str", "]", "=", "evaluate_means_over_dataset", "(", "run_context", ".", "session", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_initializers", "[", "dataset_str", "]", ",", "\n", "self", ".", "_ds_handles", "[", "dataset_str", "]", ",", "\n", "[", "self", ".", "_mean_values_real", "[", "dataset_str", "]", ",", "self", ".", "_mean_values_sample", "[", "dataset_str", "]", "]", ",", "\n", "[", "self", ".", "_mean_update_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_mean_update_ops_sample", "[", "dataset_str", "]", "]", ",", "\n", "[", "self", ".", "_mean_reset_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_mean_reset_ops_sample", "[", "dataset_str", "]", "]", ",", "\n", "max_iterations", "=", "self", ".", "_n_batches", ")", "\n", "\n", "\n", "real_images_covs", "[", "dataset_str", "]", ",", "sample_covs", "[", "dataset_str", "]", "=", "evaluate_means_over_dataset", "(", "run_context", ".", "session", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_initializers", "[", "dataset_str", "]", ",", "\n", "self", ".", "_ds_handles", "[", "dataset_str", "]", ",", "\n", "[", "self", ".", "_cov_values_real", "[", "dataset_str", "]", ",", "self", ".", "_cov_values_sample", "[", "dataset_str", "]", "]", ",", "\n", "[", "self", ".", "_cov_update_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_cov_update_ops_sample", "[", "dataset_str", "]", "]", ",", "\n", "[", "self", ".", "_cov_reset_ops_real", "[", "dataset_str", "]", ",", "self", ".", "_cov_reset_ops_sample", "[", "dataset_str", "]", "]", ",", "\n", "max_iterations", "=", "self", ".", "_n_batches", ")", "\n", "\n", "\n", "try", ":", "\n", "\n", "# compute fid", "\n", "                ", "diff", "=", "real_images_means", "[", "dataset_str", "]", "-", "sample_means", "[", "dataset_str", "]", "\n", "\n", "# product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "real_images_covs", "[", "dataset_str", "]", ".", "dot", "(", "sample_covs", "[", "dataset_str", "]", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "                    ", "msg", "=", "\"fid calculation produces singular product; adding %s to diagonal of cov estimates\"", "%", "eps", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "real_images_covs", "[", "dataset_str", "]", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "real_images_covs", "[", "dataset_str", "]", "+", "offset", ")", ".", "dot", "(", "sample_covs", "[", "dataset_str", "]", "+", "offset", ")", ")", "\n", "\n", "# numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "                    ", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "                        ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "\"Imaginary component {}\"", ".", "format", "(", "m", ")", ")", "\n", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "fid", "=", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "real_images_covs", "[", "dataset_str", "]", ")", "+", "np", ".", "trace", "(", "sample_covs", "[", "dataset_str", "]", ")", "-", "2", "*", "tr_covmean", "\n", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "\"Error in computing the FrechetInceptionDistance, most likely nunrical issues in computing the sqrt of a convariance matrix. Try increasing the number of samples\"", ")", "\n", "fid", "=", "-", "1.", "\n", "\n", "\n", "", "self", ".", "_tensors_values", "[", "dataset_str", "]", "=", "[", "[", "[", "fid", "]", "]", "]", "\n", "\n", "", "self", ".", "log_to_file_and_screen", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImagesInputHook.ImagesInputHook.__init__": [[16, 51], ["EveryNEpochsTFModelImagesHook.EveryNEpochsTFModelImagesHook.__init__", "model._get_steps", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "how_many", ",", "\n", "n_images_columns", ",", "\n", "dirName", ",", "\n", "until", "=", "10", ",", "# Luigi: I think 10 is better than 100", "\n", "slice_wise", "=", "None", ",", "\n", "pm_one", "=", "True", "\n", ")", ":", "\n", "\n", "# fileName should be set before calling super()", "\n", "        ", "self", ".", "_fileName", "=", "\"input\"", "\n", "dirName", "=", "dirName", "+", "'/input_images'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dirName", "=", "dirName", ",", "pm_one", "=", "pm_one", ")", "\n", "self", ".", "_how_many", "=", "how_many", "\n", "self", ".", "_n_images_columns", "=", "n_images_columns", "\n", "\n", "self", ".", "_last_step_to_log", "=", "model", ".", "_get_steps", "(", "until", ",", "time_reference", ")", "\n", "\n", "#self._has_target = False", "\n", "#if hasattr(self._model, 'x_target'):", "\n", "#    self._has_target = True", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create ImagesInputHook\"", ")", "\n", "\n", "# add nodes to be computed in before_run", "\n", "self", ".", "_nodes_to_be_computed_by_run", "[", "\"raw_inputs\"", "]", "=", "self", ".", "_model", ".", "ds_raw_x", "#raw_x", "\n", "self", ".", "_nodes_to_be_computed_by_run", "[", "\"aug_inputs\"", "]", "=", "self", ".", "_model", ".", "ds_aug_x", "#x", "\n", "#if self._has_target:", "\n", "self", ".", "_nodes_to_be_computed_by_run", "[", "\"perturbed_inputs\"", "]", "=", "self", ".", "_model", ".", "ds_perturb_x", "#x_target", "\n", "\n", "self", ".", "_slice_wise", "=", "slice_wise", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImagesInputHook.ImagesInputHook.do_when_triggered": [[52, 110], ["tf_logging.info", "ImagesInputHook.ImagesInputHook.images_saver.save_images", "int", "range", "range", "numpy.ceil", "range", "int", "range", "range", "panel[].append", "panel[].append", "panel[].append", "numpy.ceil", "range", "range", "str().zfill", "len", "panel[].append", "panel[].append", "panel[].append", "len", "len", "str", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "\n", "# I plot input images until last period arrives", "\n", "        ", "if", "self", ".", "_global_step", "<=", "self", ".", "_last_step_to_log", ":", "\n", "\n", "            ", "tf_logging", ".", "info", "(", "\"trigger for ImagesInputHook\"", ")", "\n", "images", "=", "run_values", ".", "results", "[", "\"raw_inputs\"", "]", "[", ":", "self", ".", "_how_many", "]", "\n", "images_aug", "=", "run_values", ".", "results", "[", "\"aug_inputs\"", "]", "[", ":", "self", ".", "_how_many", "]", "\n", "\n", "#l = 2", "\n", "#if self._has_target:", "\n", "images_perturbed", "=", "run_values", ".", "results", "[", "\"perturbed_inputs\"", "]", "[", ":", "self", ".", "_how_many", "]", "\n", "l", "=", "3", "\n", "\n", "if", "self", ".", "_slice_wise", "==", "None", ":", "\n", "                ", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "l", "*", "rows", ")", "]", "\n", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "l", "*", "rows", ",", "l", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                        ", "panel", "[", "i", "]", ".", "append", "(", "images", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "1", "]", ".", "append", "(", "images_aug", "[", "c", "]", ")", "\n", "#if self._has_target:", "\n", "panel", "[", "i", "+", "2", "]", ".", "append", "(", "images_perturbed", "[", "c", "]", ")", "\n", "if", "c", "==", "len", "(", "images", ")", "-", "1", ":", "\n", "                            ", "break", "\n", "", "else", ":", "\n", "                            ", "c", "=", "c", "+", "1", "\n", "", "", "", "", "else", ":", "\n", "                ", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "*", "images", ".", "shape", "[", "3", "]", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", "*", "3", ")", "]", "\n", "\n", "for", "k", "in", "range", "(", "images", ".", "shape", "[", "3", "]", ")", ":", "\n", "\n", "                    ", "selected_images", "=", "images", "[", ":", ",", ":", ",", ":", ",", "k", "]", "\n", "reshaped_images", "=", "selected_images", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "selected_images_aug", "=", "images_aug", "[", ":", ",", ":", ",", ":", ",", "k", "]", "\n", "reshaped_images_aug", "=", "selected_images_aug", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "selected_images_perturbed", "=", "images_perturbed", "[", ":", ",", ":", ",", ":", ",", "k", "]", "\n", "reshaped_images_perturbed", "=", "selected_images_perturbed", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "l", "*", "rows", ",", "l", "*", "images", ".", "shape", "[", "3", "]", ")", ":", "\n", "                        ", "i", "=", "i", "+", "k", "*", "l", "\n", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                            ", "panel", "[", "i", "]", ".", "append", "(", "reshaped_images", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "1", "]", ".", "append", "(", "reshaped_images_aug", "[", "c", "]", ")", "\n", "#if self._has_target:", "\n", "panel", "[", "i", "+", "2", "]", ".", "append", "(", "reshaped_images_perturbed", "[", "c", "]", ")", "\n", "if", "c", "==", "len", "(", "images", ")", "-", "1", ":", "\n", "                                ", "break", "\n", "", "else", ":", "\n", "                                ", "c", "=", "c", "+", "1", "\n", "\n", "", "", "", "", "", "self", ".", "images_saver", ".", "save_images", "(", "panel", ",", "\n", "fileName", "=", "self", ".", "_fileName", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "+", "\"_\"", "+", "str", "(", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", ",", "\n", "title", "=", "\"1) raw 2) augmented 3) perturbed \"", "+", "self", ".", "_fileName", ",", "\n", "fontsize", "=", "9", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook.__init__": [[18, 41], ["LoggingMeanTensorsHook.tf_logging.info", "os.path.join"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "checkpoint_dir", ",", "\n", "save_steps", ",", "\n", "saver", "=", "None", ",", "\n", "checkpoint_basename", "=", "\"model.ckpt\"", ",", "\n", "pb_output_nodes", "=", "[", "\"logits\"", "]", ",", "\n", "save_pb_at_end", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Initializes a `CheckpointSaverHook`.\n        Args:\n          checkpoint_dir: `str`, base directory for the checkpoint files.\n          save_steps: `int`, save every N steps.\n          saver: `Saver` object, used for saving.\n          checkpoint_basename: `str`, base name for the checkpoint files.\n        \"\"\"", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create CheckpointSaverHook\"", ")", "\n", "self", ".", "_save_pb_at_end", "=", "save_pb_at_end", "\n", "self", ".", "_pb_output_nodes", "=", "pb_output_nodes", "\n", "self", ".", "_saver", "=", "saver", "\n", "self", ".", "_checkpoint_dir", "=", "checkpoint_dir", "\n", "self", ".", "_save_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "checkpoint_basename", ")", "\n", "self", ".", "_save_steps", "=", "save_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook.begin": [[42, 47], ["tensorflow.train.get_global_step", "RuntimeError"], "methods", ["None"], ["", "def", "begin", "(", "self", ")", ":", "\n", "        ", "self", ".", "_global_step_tensor", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", "\n", "if", "self", ".", "_global_step_tensor", "is", "None", ":", "\n", "          ", "raise", "RuntimeError", "(", "\n", "\"Global step should be created to use CheckpointSaverHook.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook.after_create_session": [[48, 50], ["session.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "global_step", "=", "session", ".", "run", "(", "self", ".", "_global_step_tensor", ")", "\n", "# self._save(session, global_step)", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook.before_run": [[52, 54], ["tensorflow.train.SessionRunArgs"], "methods", ["None"], ["", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "return", "SessionRunArgs", "(", "self", ".", "_global_step_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook.after_run": [[55, 60], ["CheckpointSaverHook.CheckpointSaverHook._save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook._save"], ["", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "# get the current value after train op. (you mean maybe the next value?)", "\n", "        ", "global_step", "=", "run_values", ".", "results", "+", "1", "\n", "if", "global_step", "%", "self", ".", "_save_steps", "==", "0", ":", "\n", "            ", "self", ".", "_save", "(", "run_context", ".", "session", ",", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook.end": [[61, 66], ["session.run", "CheckpointSaverHook.CheckpointSaverHook._save", "CheckpointSaverHook.CheckpointSaverHook._save_pb"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook._save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook._save_pb"], ["", "", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "last_step", "=", "session", ".", "run", "(", "self", ".", "_global_step_tensor", ")", "\n", "self", ".", "_save", "(", "session", ",", "last_step", ")", "\n", "if", "self", ".", "_save_pb_at_end", ":", "\n", "            ", "self", ".", "_save_pb", "(", "session", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook._save": [[67, 71], ["LoggingMeanTensorsHook.tf_logging.info", "CheckpointSaverHook.CheckpointSaverHook._saver.save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "", "def", "_save", "(", "self", ",", "session", ",", "step", ")", ":", "\n", "        ", "\"\"\"Saves the latest checkpoint, returns should_stop.\"\"\"", "\n", "tf_logging", ".", "info", "(", "\"Saving checkpoints for %d into %s.\"", ",", "step", ",", "self", ".", "_save_path", ")", "\n", "self", ".", "_saver", ".", "save", "(", "session", ",", "self", ".", "_save_path", ",", "global_step", "=", "step", ",", "write_meta_graph", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CheckpointSaverHook.CheckpointSaverHook._save_pb": [[72, 80], ["os.path.join", "utils.argo_utils.freeze_graph_create_pb"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.freeze_graph_create_pb"], ["", "def", "_save_pb", "(", "self", ",", "session", ")", ":", "\n", "        ", "path_pb", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_checkpoint_dir", ",", "'frozen_graph.pb'", ")", "\n", "freeze_graph_create_pb", "(", "session", ",", "\n", "output_names", "=", "self", ".", "_pb_output_nodes", ",", "\n", "variable_names_whitelist", "=", "None", ",", "\n", "variable_names_blacklist", "=", "None", ",", "\n", "output_filename", "=", "path_pb", ",", "\n", "clear_devices", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsClassificationHook.LatentVarsClassificationHook.__init__": [[38, 106], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "list", "tensorflow.cast", "tf_logging.info", "itertools.chain", "str", "range", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "dirName", ",", "\n", "tensors", ",", "\n", "tensors_names", ",", "\n", "datasets_keys", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "learning_rate", ",", "\n", "steps", ",", "\n", "repetitions", ",", "\n", "plot_offset", "=", "0", ",", "\n", "extra_feed_dict", "=", "{", "}", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_hook_name", "=", "\"latent_vars_linear_classifier\"", "\n", "dirName", "=", "dirName", "+", "'/'", "+", "self", ".", "_hook_name", "\n", "# fileName should be set before calling super()", "\n", "#self._fileName = \"frechet_inception_distance-\" + self.network_name + \"-num_images-\" + str(n_images)", "\n", "#self._fileHeader = '# frechet_inception_distance, network = ' + self.network_name + ', num images = ' + str(n_images) + '\\n'", "\n", "#self._fileHeader += '# period \\t fid_train \\t fid_validation \\t time_sec'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "datasets_keys", ",", "\n", "dirName", "=", "dirName", ",", "\n", "plot_offset", "=", "plot_offset", ",", "\n", "extra_feed_dict", "=", "extra_feed_dict", ")", "\n", "\n", "#self._n_samples = n_samples", "\n", "#self._batch_size = batch_size", "\n", "#self._repetitions = repetitions", "\n", "\n", "# potentially shared with a parent class", "\n", "#self._handle = model.ds_handle", "\n", "#self._datasets_keys = datasets_keys", "\n", "#check_dataset_keys_not_loop(datasets_keys)", "\n", "\n", "#self._ds_initializers = model.datasets_initializers", "\n", "#self._ds_handles_nodes = model.datasets_handles_nodes", "\n", "\n", "#self._tensors_to_average = tensors_to_average", "\n", "#self._tensors_to_average_names = tensors_to_average_names", "\n", "\n", "self", ".", "_repetitions", "=", "repetitions", "\n", "\n", "self", ".", "_learning_rate", "=", "learning_rate", "\n", "self", ".", "_steps", "=", "steps", "\n", "\n", "labels_avg_cov", "=", "list", "(", "chain", "(", "*", "[", "(", "n", "+", "\"_runs\"", "+", "str", "(", "self", ".", "_repetitions", ")", "+", "\"_avg\"", ",", "n", "+", "\"_runs\"", "+", "str", "(", "self", ".", "_repetitions", ")", "+", "\"_cov\"", ")", "for", "n", "in", "tensors_names", "]", ")", ")", "\n", "self", ".", "_tensors", "=", "[", "[", "tensors", "]", "]", "\n", "self", ".", "_tensors_names", "=", "[", "[", "[", "n", "+", "\"_r\"", "+", "str", "(", "r", ")", "for", "r", "in", "range", "(", "self", ".", "_repetitions", ")", "for", "n", "in", "tensors_names", "]", "]", ",", "\n", "[", "labels_avg_cov", "]", "]", "\n", "self", ".", "_tensors_plots", "=", "[", "[", "{", "\n", "'fileName'", ":", "\"latent_vars_linear_classifier\"", ",", "\n", "'logscale-y'", ":", "0", "}", "]", ",", "\n", "[", "{", "\n", "'fileName'", ":", "\"latent_vars_linear_classifier_avg\"", ",", "\n", "'logscale-y'", ":", "0", ",", "\n", "'error-bars'", ":", "1", "}", "]", "]", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "self", ".", "_fileName", "=", "\"latent_vars_linear_classifier\"", "\n", "\n", "self", ".", "_tensor_y_name", "=", "\"y\"", "\n", "self", ".", "_tensor_y", "=", "tf", ".", "cast", "(", "self", ".", "_model", ".", "y", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create LatentVarsClassification\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsClassificationHook.LatentVarsClassificationHook._begin_once": [[159, 212], ["zip", "tensor.shape.as_list", "tensorflow.name_scope", "sonnet.Linear", "sonnet.Linear.", "sonnet.Linear.get_variables", "tensorflow.variables_initializer", "tensorflow.equal", "tensorflow.cond", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.metrics.accuracy", "tensorflow.variables_initializer", "tensorflow.get_collection", "tensorflow.variables_initializer", "tensorflow.train.GradientDescentOptimizer", "tensorflow.train.GradientDescentOptimizer.compute_gradients", "tensorflow.train.GradientDescentOptimizer.apply_gradients", "tensorflow.argmax", "tensorflow.get_collection", "tensorflow.shape", "tensorflow.shape", "tensorflow.tile"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_variables", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.apply_gradients"], ["def", "_begin_once", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "tf_metric_update", "=", "{", "}", "\n", "self", ".", "tf_metric", "=", "{", "}", "\n", "self", ".", "tf_metric_reset", "=", "{", "}", "\n", "self", ".", "training_op", "=", "{", "}", "\n", "self", ".", "loss_train", "=", "{", "}", "\n", "\n", "self", ".", "tf_initializers", "=", "{", "}", "\n", "\n", "n_labels", "=", "self", ".", "_model", ".", "dataset", ".", "n_labels", "\n", "\n", "# [Luigi] here I cheat (arguably), since I know that there is only one panel, I avoid 2 extra cycles", "\n", "for", "(", "tensor", ",", "tensor_name", ")", "in", "zip", "(", "self", ".", "_tensors", "[", "0", "]", "[", "0", "]", ",", "self", ".", "_tensors_names", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "\n", "            ", "dim", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "scope", "=", "self", ".", "_hook_name", "+", "\"/classifier_\"", "+", "tensor_name", "\n", "with", "tf", ".", "name_scope", "(", "scope", ")", ":", "\n", "\n", "                ", "linear_module", "=", "snt", ".", "Linear", "(", "output_size", "=", "n_labels", ")", "\n", "logits", "=", "linear_module", "(", "tensor", ")", "\n", "\n", "# save initializers to reset weights before retraining", "\n", "var_module", "=", "linear_module", ".", "get_variables", "(", ")", "\n", "self", ".", "tf_initializers", "[", "tensor_name", "]", "=", "tf", ".", "variables_initializer", "(", "var_module", ")", "\n", "\n", "# check if I need to replicate the labels, due to multiple samples of z for a given x", "\n", "replicate_condition", "=", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "self", ".", "_tensor_y", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "tensor", ")", "[", "0", "]", ")", "\n", "y_replicate", "=", "tf", ".", "cond", "(", "replicate_condition", ",", "\n", "lambda", ":", "self", ".", "_tensor_y", ",", "\n", "lambda", ":", "tf", ".", "tile", "(", "self", ".", "_tensor_y", ",", "[", "self", ".", "_model", ".", "_network", ".", "n_z_samples", "]", ")", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "labels", "=", "y_replicate", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "self", ".", "loss_train", "[", "tensor_name", "]", "=", "loss", "\n", "self", ".", "tf_metric", "[", "tensor_name", "]", ",", "self", ".", "tf_metric_update", "[", "tensor_name", "]", "=", "tf", ".", "metrics", ".", "accuracy", "(", "y_replicate", ",", "\n", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ",", "\n", "name", "=", "\"accuracy_metric\"", ")", "\n", "\n", "# reset metric", "\n", "self", ".", "tf_metric_reset", "[", "tensor_name", "]", "=", "tf", ".", "variables_initializer", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "METRIC_VARIABLES", ")", ")", "\n", "\n", "# see https://steemit.com/machine-learning/@ronny.rest/avoiding-headaches-with-tf-metrics", "\n", "# isolate the variables stored behind the scenes by the metric operation", "\n", "running_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ",", "scope", "=", "scope", ")", "\n", "# define initializer to initialize/reset running variables", "\n", "running_vars_initializer", "=", "tf", ".", "variables_initializer", "(", "var_list", "=", "running_vars", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "self", ".", "_learning_rate", ")", "\n", "# get local variables", "\n", "classifier_vars", "=", "[", "linear_module", ".", "w", ",", "linear_module", ".", "b", "]", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "loss", ",", "var_list", "=", "classifier_vars", ")", "\n", "self", ".", "training_op", "[", "tensor_name", "]", "=", "optimizer", ".", "apply_gradients", "(", "gradients", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsClassificationHook.LatentVarsClassificationHook.do_when_triggered": [[214, 276], ["tf_logging.info", "range", "len", "LatentVarsClassificationHook.LatentVarsClassificationHook.log_to_file_and_screen", "zip", "list", "numpy.take", "session.run", "range", "numpy.mean().tolist", "numpy.std().tolist", "itertools.chain", "session.run", "session.run", "session.run", "accuracies[].append", "print", "numpy.mean", "numpy.std", "session.run", "accuracies.keys", "numpy.array().reshape", "numpy.array().reshape", "str", "range", "numpy.array", "numpy.array", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.log_to_file_and_screen", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "#tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for LatentVarsClassificationHook\"", ")", "\n", "\n", "session", "=", "run_context", ".", "session", "\n", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "\n", "# train logistic regression", "\n", "# [Luigi] here I cheat (arguably), since I know that there is only one panel, I avoid 2 extra cycles", "\n", "\n", "for", "r", "in", "range", "(", "self", ".", "_repetitions", ")", ":", "\n", "            ", "for", "(", "tensor", ",", "tensor_name", ")", "in", "zip", "(", "self", ".", "_tensors", "[", "0", "]", "[", "0", "]", ",", "self", ".", "_tensors_names", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "\n", "                ", "loss", "=", "0", "\n", "n_steps_print", "=", "1000", "\n", "\n", "# reinitialze the weights of the network in case of multiple repetitions", "\n", "session", ".", "run", "(", "self", ".", "tf_initializers", "[", "tensor_name", "]", ")", "\n", "\n", "for", "step", "in", "range", "(", "1", ",", "self", ".", "_steps", "+", "1", ")", ":", "\n", "\n", "# average loss, to see if it goes down", "\n", "                    ", "batch_loss", ",", "_", "=", "session", ".", "run", "(", "[", "self", ".", "loss_train", "[", "tensor_name", "]", ",", "self", ".", "training_op", "[", "tensor_name", "]", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_ds_handle", ":", "self", ".", "_ds_handles", "[", "TRAIN_LOOP", "]", "}", ")", "\n", "loss", "+=", "batch_loss", "\n", "\n", "if", "step", ">", "0", "and", "step", "%", "n_steps_print", "==", "0", ":", "\n", "                        ", "print", "(", "\"r:\"", "+", "str", "(", "r", ")", "+", "\" step:\"", "+", "str", "(", "step", ")", "+", "\": \"", "+", "str", "(", "loss", "/", "n_steps_print", ")", ")", "\n", "loss", "=", "0", "\n", "\n", "# evaluation of the model", "\n", "", "", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "\n", "                    ", "dataset_initializer", "=", "self", ".", "_ds_initializers", "[", "ds_key", "]", "\n", "session", ".", "run", "(", "[", "dataset_initializer", "]", "+", "[", "self", ".", "tf_metric_reset", "[", "tensor_name", "]", "]", ")", "\n", "\n", "while", "True", ":", "\n", "                        ", "try", ":", "\n", "                            ", "session", ".", "run", "(", "self", ".", "tf_metric_update", "[", "tensor_name", "]", ",", "feed_dict", "=", "{", "self", ".", "_ds_handle", ":", "self", ".", "_ds_handles", "[", "ds_key", "]", "}", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                            ", "break", "\n", "\n", "", "", "accuracy", "=", "session", ".", "run", "(", "self", ".", "tf_metric", "[", "tensor_name", "]", ")", "\n", "#print(ds_key, accuracy)", "\n", "\n", "if", "not", "ds_key", "in", "accuracies", ".", "keys", "(", ")", ":", "\n", "                        ", "accuracies", "[", "ds_key", "]", "=", "[", "]", "\n", "", "accuracies", "[", "ds_key", "]", ".", "append", "(", "accuracy", ")", "\n", "\n", "", "", "", "n_tensors", "=", "len", "(", "self", ".", "_tensors", "[", "0", "]", "[", "0", "]", ")", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "# create proper list structure, and computing mean and std", "\n", "            ", "list_mean_avg", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "accuracies", "[", "ds_key", "]", ")", ".", "reshape", "(", "[", "-", "1", ",", "n_tensors", "]", ")", ",", "axis", "=", "0", ")", ".", "tolist", "(", ")", "+", "np", ".", "std", "(", "np", ".", "array", "(", "accuracies", "[", "ds_key", "]", ")", ".", "reshape", "(", "[", "-", "1", ",", "n_tensors", "]", ")", ",", "axis", "=", "0", ")", ".", "tolist", "(", ")", "\n", "# move from mean mean mean cov cov cov", "\n", "# to mean con mean cov mean cov", "\n", "indices_mean_avg", "=", "list", "(", "chain", "(", "*", "[", "(", "n", ",", "n", "+", "n_tensors", ")", "for", "n", "in", "range", "(", "n_tensors", ")", "]", ")", ")", "\n", "list_mean_avg", "=", "np", ".", "take", "(", "list_mean_avg", ",", "indices_mean_avg", ")", "\n", "self", ".", "_tensors_values", "[", "ds_key", "]", "=", "[", "[", "accuracies", "[", "ds_key", "]", "]", ",", "[", "list_mean_avg", "]", "]", "\n", "\n", "", "self", ".", "log_to_file_and_screen", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LatentVarsClassificationHook.LatentVarsClassificationHook.plot": [[277, 369], ["super().plot"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["", "def", "plot", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "plot", "(", ")", "\n", "\n", "'''\n        # plot images\n        if self._plot_misclassified_images:\n            fileName = self._fileName + \"-misclass_train_mean-ep\"\n            image_generator = ImagesGenerator(self._dirName, fileName, self._n_misclassified_images)\n            image_generator.set_color(self._color)\n            image_generator.image_size = self._shape\n            #resized_images = [image.reshape(self._shape) for image in self.misclassified_train_mean ]\n            image_generator.save_images(self.misclassified_train_mean, epoch)\n\n            fileName = self._fileName + \"-misclass_test_mean-ep\"\n            image_generator = ImagesGenerator(self._dirName, fileName, self._n_misclassified_images)\n            image_generator.set_color(self._color)\n            image_generator.image_size = self._shape\n            #resized_images = [image.reshape(self._shape) for image in self.misclassified_test_mean ]\n            image_generator.save_images(self.misclassified_test_mean, epoch)\n\n            fileName = self._fileName + \"-misclass_train_mean_cov-ep\"\n            image_generator = ImagesGenerator(self._dirName, fileName, self._n_misclassified_images)\n            image_generator.set_color(self._color)\n            image_generator.image_size = self._shape\n            #resized_images = [image.reshape(self._shape) for image in self.misclassified_train_mean_cov ]\n            image_generator.save_images(self.misclassified_train_mean_cov, epoch)\n\n            fileName = self._fileName + \"-misclass_test_mean_cov-ep\"\n            image_generator = ImagesGenerator(self._dirName, fileName, self._n_misclassified_images)\n            image_generator.set_color(self._color)\n            image_generator.image_size = self._shape\n            #resized_images = [image.reshape(self._shape) for image in self.misclassified_test_mean_cov ]\n            image_generator.save_images(self.misclassified_test_mean_cov, epoch)\n\n            fileName = self._fileName + \"-misclass_train_samples-ep\"\n            image_generator = ImagesGenerator(self._dirName, fileName, self._n_misclassified_images)\n            image_generator.set_color(self._color)\n            image_generator.image_size = self._shape\n            #resized_images = [image.reshape(self._shape) for image in self.misclassified_train_samples ]\n            image_generator.save_images(self.misclassified_train_samples, epoch)\n\n            fileName = self._fileName + \"-misclass_test_samples-ep\"\n            image_generator = ImagesGenerator(self._dirName, fileName, self._n_misclassified_images)\n            image_generator.set_color(self._color)\n            image_generator.image_size = self._shape\n            #resized_images = [image.reshape(self._shape) for image in self.misclassified_test_samples ]\n            image_generator.save_images(self.misclassified_test_samples, epoch)\n\n\n        bins = np.linspace(0, 15, 100)\n\n        fig = plt.figure(figsize=(15,10))\n\n        ax1 = fig.add_subplot(321)\n        ax1.set_title(\"Train set means\")\n        ax1.hist(self.norm_mean_train_class, bins, alpha=0.5, label='train mean class')\n        ax1.hist(self.norm_mean_train_misclass, bins, alpha=0.5, label='train mean misclass')\n        ax1.legend(loc='upper right')\n\n        ax2 = fig.add_subplot(322)\n        ax2.set_title(\"Test set means\")\n        ax2.hist(self.norm_mean_test_class, bins, alpha=0.5, label='test mean class')\n        ax2.hist(self.norm_mean_test_misclass, bins, alpha=0.5, label='test mean misclass')\n        ax2.legend(loc='upper right')\n\n        ax3 = fig.add_subplot(323)\n        ax3.set_title(\"Train set means+covs\")\n        ax3.hist(self.norm_mean_cov_train_class, bins, alpha=0.5, label='train mean+cov class')\n        ax3.hist(self.norm_mean_cov_train_misclass, bins, alpha=0.5, label='train mean+cov misclass')\n        ax3.legend(loc='upper right')\n\n        ax4 = fig.add_subplot(324)\n        ax4.set_title(\"Test set means+covs\")\n        ax4.hist(self.norm_mean_cov_test_class, bins, alpha=0.5, label='test mean+cov class')\n        ax4.hist(self.norm_mean_cov_test_misclass, bins, alpha=0.5, label='test mean+cov misclass')\n        ax4.legend(loc='upper right')\n\n        ax5 = fig.add_subplot(325)\n        ax5.set_title(\"Train set samples\")\n        ax5.hist(self.norm_samples_train_class, bins, alpha=0.5, label='train samples class')\n        ax5.hist(self.norm_samples_train_misclass, bins, alpha=0.5, label='train sampes misclass')\n        ax5.legend(loc='upper right')\n\n        ax6 = fig.add_subplot(326)\n        ax6.set_title(\"Tests set samples\")\n        ax6.hist(self.norm_samples_test_class, bins, alpha=0.5, label='test samples class')\n        ax6.hist(self.norm_samples_test_misclass, bins, alpha=0.5, label='test sampes misclass')\n        ax6.legend(loc='upper right')\n\n        plt.savefig(self._dirName + \"/\" + self._fileName + \"-norms_class-ep\" + str(self._time_ref).zfill(4) + \".png\")\n        plt.close()\n        '''", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCClassificationHook.MCClassificationHook.__init__": [[11, 29], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", ",", "TEST", "]", ",", "\n", "posterior_samples", "=", "2500", ",", "\n", "n_batches", "=", "-", "1", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "datasets_keys", ",", "dirName", "=", "dirName", "+", "'/mc_classification'", ")", "\n", "self", ".", "_default_plot_bool", "=", "False", "\n", "\n", "self", ".", "_n_batches", "=", "n_batches", "\n", "self", ".", "_posterior_samples", "=", "posterior_samples", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create MCClassificationHook for: \\n\"", "+", "\", \"", ".", "join", "(", "datasets_keys", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCClassificationHook.MCClassificationHook.after_create_session": [[30, 46], ["super().after_create_session", "ConfidenceIntervalsOnlySamplesClassification.ConfidenceIntervalsOnlySamplesClassification.ConfidenceIntervalsOnlySamplesClassification"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session"], ["", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "self", ".", "ci_obj", "=", "ConfidenceIntervalsOnlySamplesClassification", "(", "self", ".", "_dirName", ",", "\n", "self", ".", "_ds_initializers", ",", "\n", "self", ".", "_ds_handles", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_model", ".", "n_samples_ph", ",", "\n", "self", ".", "_model", ".", "prediction_sample", ",", "\n", "self", ".", "_model", ".", "raw_x", ",", "\n", "self", ".", "_model", ".", "x", ",", "\n", "self", ".", "_model", ".", "y", ",", "\n", "posterior_samples", "=", "self", ".", "_posterior_samples", ",", "\n", "n_batches", "=", "self", ".", "_n_batches", ",", "\n", "extra_nodes_to_collect", "=", "[", "\n", "self", ".", "_model", ".", "prediction_distr", ".", "probs", "]", ",", "\n", "extra_nodes_names", "=", "[", "\"probs\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCClassificationHook.MCClassificationHook.do_when_triggered": [[48, 54], ["tf_logging.info", "MCClassificationHook.MCClassificationHook.ci_obj.do_when_triggered", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook.do_when_triggered"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "time_ref", "=", "self", ".", "_time_ref", "\n", "time_ref_str", "=", "self", ".", "_time_ref_shortstr", "\n", "tf_logging", ".", "info", "(", "\"trigger for MCClassificationHook\"", ")", "\n", "self", ".", "ci_obj", ".", "do_when_triggered", "(", "run_context", ".", "session", ",", "self", ".", "_datasets_keys", ",", "time_ref", ",", "time_ref_str", ")", "\n", "tf_logging", ".", "info", "(", "\"MCClassificationHook Done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.__init__": [[15, 48], ["super().__init__", "distr.sample", "distr.mean", "distr.variance", "distr.covariance"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dirName", ",", "\n", "dataset_initializer", ",", "\n", "dataset_handle", ",", "\n", "handle", ",", "\n", "n_samples_ph", ",", "\n", "#         session,", "\n", "distr", ",", "\n", "raw_x", ",", "\n", "x", ",", "\n", "y", ",", "\n", "posterior_samples", "=", "2500", ",", "\n", "n_batches", "=", "-", "1", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "#        self._datasets_keys= datasets_keys", "\n", "self", ".", "_posterior_samples", "=", "posterior_samples", "\n", "#        self._session=session", "\n", "self", ".", "_dirName", "=", "dirName", "\n", "\n", "self", ".", "_distsample", "=", "distr", ".", "sample", "(", ")", "\n", "self", ".", "_distmean", "=", "distr", ".", "mean", "(", ")", "\n", "self", ".", "_distvar", "=", "distr", ".", "variance", "(", ")", "\n", "self", ".", "_distcov", "=", "distr", ".", "covariance", "(", ")", "\n", "\n", "self", ".", "_raw_x", "=", "raw_x", "\n", "self", ".", "_y", "=", "y", "\n", "self", ".", "_x", "=", "x", "\n", "self", ".", "_dataset_initializer", "=", "dataset_initializer", "\n", "self", ".", "_dataset_handle", "=", "dataset_handle", "\n", "self", ".", "_handle", "=", "handle", "\n", "self", ".", "_n_batches", "=", "n_batches", "\n", "self", ".", "_n_samples_ph", "=", "n_samples_ph", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.do_when_triggered": [[53, 57], ["ConfidenceIntervals.ConfidenceIntervals._calculate_mc_dropout", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._calculate_mc_dropout"], ["", "def", "do_when_triggered", "(", "self", ",", "session", ",", "datasets_keys", ")", ":", "\n", "        ", "for", "ds_key", "in", "datasets_keys", ":", "\n", "            ", "fileName", "=", "\"mc_\"", "+", "str", "(", "ds_key", ")", "\n", "self", ".", "_calculate_mc_dropout", "(", "session", ",", "ds_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals._create_name": [[58, 60], ["None"], "methods", ["None"], ["", "", "def", "_create_name", "(", "self", ",", "prefix", ",", "baseName", ")", ":", "\n", "       ", "return", "self", ".", "_dirName", "+", "\"/\"", "+", "prefix", "+", "'-'", "+", "baseName", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.CI_calibrate": [[61, 78], ["ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts_calibrate_core", "ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts_calibrate_core", "matplotlib.pyplot.figure", "matplotlib.pyplot.scatter", "matplotlib.pyplot.scatter", "numpy.arange", "matplotlib.pyplot.plot", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "ConfidenceIntervals.ConfidenceIntervals._create_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["", "def", "CI_calibrate", "(", "self", ",", "total_covariance", ",", "mean_pred", ",", "rea_valu", ",", "baseName", ",", "alpha_calibrate", "=", "1", ",", "Aleatoric", "=", "'Ale'", ")", ":", "\n", "\n", "        ", "sumeT", ",", "ppf_run", "=", "self", ".", "general_ellip_counts_calibrate_core", "(", "total_covariance", ",", "mean_pred", ",", "rea_valu", ")", "\n", "sumeT_recali", ",", "ppf_run_recali", "=", "self", ".", "general_ellip_counts_calibrate_core", "(", "total_covariance", ",", "mean_pred", ",", "rea_valu", ",", "alpha_calibrate", ")", "\n", "\n", "fig_1", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "scatter", "(", "ppf_run", ",", "sumeT", ",", "label", "=", "'uncalibrated'", ")", "\n", "plt", ".", "scatter", "(", "ppf_run_recali", ",", "sumeT_recali", ",", "label", "=", "'calibrated'", ")", "\n", "line_s1", "=", "np", ".", "arange", "(", "0.0", ",", "1", ",", "0.01", ")", "\n", "plt", ".", "plot", "(", "line_s1", ",", "line_s1", ",", "'r-'", ",", "alpha", "=", "0.1", ")", "\n", "plt", ".", "xlabel", "(", "'Confidence level'", ")", "\n", "plt", ".", "ylabel", "(", "'Estimated coverage probability'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "_create_name", "(", "\"calibration_{}\"", ".", "format", "(", "Aleatoric", ")", ",", "baseName", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", "fig_1", ")", "\n", "if", "Aleatoric", ":", "\n", "            ", "return", "sumeT", ",", "ppf_run", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts_calibrate": [[79, 87], ["numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts_calibrate_core", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core"], ["", "", "def", "general_ellip_counts_calibrate", "(", "self", ",", "covariance", ",", "mean", ",", "real_values", ",", "alpha_ini", "=", "1", ")", ":", "\n", "\n", "        ", "shapes", "=", "np", ".", "array", "(", "mean", ")", ".", "shape", "\n", "shapes_batch", "=", "shapes", "[", "0", "]", "*", "shapes", "[", "1", "]", "\n", "means", "=", "np", ".", "array", "(", "mean", ")", ".", "reshape", "(", "shapes_batch", ",", "shapes", "[", "2", "]", ")", "\n", "reals", "=", "np", ".", "array", "(", "real_values", ")", ".", "reshape", "(", "shapes_batch", ",", "shapes", "[", "2", "]", ")", "\n", "covas", "=", "np", ".", "array", "(", "covariance", ")", ".", "reshape", "(", "shapes_batch", ",", "shapes", "[", "2", "]", ",", "shapes", "[", "2", "]", ")", "\n", "return", "self", ".", "general_ellip_counts_calibrate_core", "(", "covas", ",", "means", ",", "reals", ",", "alpha_ini", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts_calibrate_core": [[88, 104], ["numpy.linalg.inv", "numpy.einsum", "list", "scipy.stats.chi2", "enumerate", "numpy.array", "numpy.arange", "len", "scipy.stats.chi2.ppf", "enumerate", "list", "list", "numpy.array"], "methods", ["None"], ["", "def", "general_ellip_counts_calibrate_core", "(", "self", ",", "covas", ",", "means", ",", "reals", ",", "alpha_ini", "=", "1", ")", ":", "\n", "        ", "shapes", "=", "np", ".", "array", "(", "means", ")", ".", "shape", "\n", "Inverse_covariance", "=", "np", ".", "linalg", ".", "inv", "(", "covas", ")", "\n", "Ellip_eq", "=", "np", ".", "einsum", "(", "'nl,nlm,mn->n'", ",", "(", "reals", "-", "means", ")", ",", "Inverse_covariance", ",", "(", "reals", "-", "means", ")", ".", "T", ")", "\n", "ppf_run", "=", "list", "(", "np", ".", "arange", "(", "0.1", ",", "1.0", ",", "0.035", ")", ")", "\n", "suma_T", "=", "[", "0", "]", "*", "len", "(", "ppf_run", ")", "\n", "rv", "=", "chi2", "(", "df", "=", "shapes", "[", "1", "]", ")", "\n", "for", "ix", ",", "ppf", "in", "enumerate", "(", "ppf_run", ")", ":", "\n", "            ", "square_norm", "=", "rv", ".", "ppf", "(", "ppf", ")", "\n", "values", "=", "Ellip_eq", "/", "(", "square_norm", "*", "alpha_ini", ")", "\n", "for", "ids", ",", "inst", "in", "enumerate", "(", "values", ")", ":", "\n", "                ", "if", "inst", "<=", "1", ":", "\n", "                    ", "suma_T", "[", "ix", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "", "", "return", "list", "(", "np", ".", "array", "(", "suma_T", ")", "/", "shapes", "[", "0", "]", ")", ",", "list", "(", "ppf_run", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals._calculate_mc_dropout": [[106, 248], ["session.run", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.stack", "numpy.stack", "numpy.stack", "ConfidenceIntervals.ConfidenceIntervals.find_calibration", "ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts_calibrate", "matplotlib.pyplot.figure", "matplotlib.pyplot.scatter", "numpy.arange", "matplotlib.pyplot.plot", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "Exception", "ConfidenceIntervals.ConfidenceIntervals._create_name", "ConfidenceIntervals.ConfidenceIntervals._create_name", "ConfidenceIntervals.ConfidenceIntervals._create_name", "ConfidenceIntervals.ConfidenceIntervals._create_name", "ConfidenceIntervals.ConfidenceIntervals._create_name", "ConfidenceIntervals.ConfidenceIntervals._create_name", "ConfidenceIntervals.ConfidenceIntervals._create_name", "ConfidenceIntervals.ConfidenceIntervals._create_name", "open", "ft1.write", "ft1.write", "type", "session.run", "session.run", "batch_means_A.append", "batch_vars_A.append", "batch_covs_A.append", "batch_samples_A.append", "batch_reals_A.append", "range", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "ConfidenceIntervals.ConfidenceIntervals.CI", "numpy.stack.append", "covs_means.append", "means_covs.append", "Batch_samples_stack_T.append", "Total_std.append", "numpy.stack.append", "numpy.stack.append", "ConfidenceIntervals.ConfidenceIntervals._create_name", "session.run", "batch_means.append", "batch_vars.append", "batch_covs.append", "batch_samples.append", "batch_reals.append", "ConfidenceIntervals.ConfidenceIntervals._create_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.find_calibration", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.CI", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["", "def", "_calculate_mc_dropout", "(", "self", ",", "session", ",", "ds_key", ",", "epoch", ")", ":", "\n", "        ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "            ", "raise", "Exception", "(", "\"I need a raw session to evaluate metric over dataset.\"", ")", "\n", "\n", "", "dataset_initializer", "=", "self", ".", "_dataset_initializer", "[", "ds_key", "]", "\n", "dataset_handle", "=", "self", ".", "_dataset_handle", "[", "ds_key", "]", "\n", "baseName", "=", "ds_key", "+", "\"-ep{:d}\"", ".", "format", "(", "epoch", ")", "\n", "\n", "init_ops", "=", "dataset_initializer", "\n", "session", ".", "run", "(", "init_ops", ")", "\n", "\n", "count_68", "=", "0", "\n", "count_95", "=", "0", "\n", "count_99", "=", "0", "\n", "count_all", "=", "0", "\n", "means_means", "=", "[", "]", "\n", "covs_means", "=", "[", "]", "\n", "means_covs", "=", "[", "]", "\n", "Batch_samples_stack_T", "=", "[", "]", "\n", "Total_std", "=", "[", "]", "\n", "Total_covariance", "=", "[", "]", "\n", "Real_valu", "=", "[", "]", "\n", "batch_means_A", "=", "[", "]", "\n", "batch_reals_A", "=", "[", "]", "\n", "batch_vars_A", "=", "[", "]", "\n", "batch_covs_A", "=", "[", "]", "\n", "batch_samples_A", "=", "[", "]", "\n", "\n", "b", "=", "0", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "batch_means", "=", "[", "]", "\n", "batch_reals", "=", "[", "]", "\n", "batch_vars", "=", "[", "]", "\n", "batch_covs", "=", "[", "]", "\n", "batch_samples", "=", "[", "]", "\n", "\n", "\n", "try", ":", "\n", "# model.raw_x is the input before any noise addition (if present), we want to make sure we get the clean batch before noise", "\n", "                ", "batch_x", ",", "batch_y", "=", "session", ".", "run", "(", "[", "self", ".", "_raw_x", ",", "self", ".", "_y", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_handle", ":", "dataset_handle", "}", ")", "\n", "shape_batch", "=", "batch_y", ".", "shape", "[", "0", "]", "\n", "\n", "samples_A", ",", "means_A", ",", "varss_A", ",", "covs_A", "=", "session", ".", "run", "(", "[", "self", ".", "_distsample", ",", "\n", "self", ".", "_distmean", ",", "\n", "self", ".", "_distvar", ",", "\n", "self", ".", "_distcov", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_x", ":", "batch_x", ",", "self", ".", "_n_samples_ph", ":", "1", "}", ")", "\n", "# samples_A, means_A, varss_A, covs_A = session.run([self._distsample, self._distmean, self._distvar, self._distcov], feed_dict={self._raw_x: batch_x, self._n_samples_ph:1})", "\n", "batch_means_A", ".", "append", "(", "means_A", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "batch_vars_A", ".", "append", "(", "varss_A", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "batch_covs_A", ".", "append", "(", "covs_A", "[", ":", "shape_batch", ",", ":", ",", ":", "]", ")", "\n", "batch_samples_A", ".", "append", "(", "samples_A", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "batch_reals_A", ".", "append", "(", "batch_y", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "\n", "# model.x is the input after noise addition (if present), we want to make sure we feed x, so that noiose will not be added.", "\n", "for", "mcm", "in", "range", "(", "self", ".", "_posterior_samples", ")", ":", "\n", "                    ", "samples", ",", "means", ",", "varss", ",", "covs", "=", "session", ".", "run", "(", "[", "self", ".", "_distsample", ",", "\n", "self", ".", "_distmean", ",", "\n", "self", ".", "_distvar", ",", "\n", "self", ".", "_distcov", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_x", ":", "batch_x", ",", "self", ".", "_n_samples_ph", ":", "1", "}", ")", "\n", "\n", "\n", "batch_means", ".", "append", "(", "means", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "batch_vars", ".", "append", "(", "varss", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "batch_covs", ".", "append", "(", "covs", "[", ":", "shape_batch", ",", ":", ",", ":", "]", ")", "\n", "batch_samples", ".", "append", "(", "samples", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "batch_reals", ".", "append", "(", "batch_y", "[", ":", "shape_batch", ",", ":", "]", ")", "\n", "\n", "", "batch_means_stack", "=", "np", ".", "stack", "(", "batch_means", ",", "axis", "=", "2", ")", "\n", "batch_vars_stack", "=", "np", ".", "stack", "(", "batch_vars", ",", "axis", "=", "2", ")", "\n", "batch_covs_stack", "=", "np", ".", "stack", "(", "batch_covs", ",", "axis", "=", "3", ")", "\n", "batch_samples_stack", "=", "np", ".", "stack", "(", "batch_samples", ",", "axis", "=", "2", ")", "\n", "\n", "coverage_value_68", ",", "coverage_value_95", ",", "coverage_value_99", ",", "coverage_all", ",", "total_std", ",", "cov_pred_p", ",", "mean_covar_p", ",", "total_covariance", ",", "rea_valu", ",", "mean_pred", "=", "self", ".", "CI", "(", "\n", "batch_means_stack", ",", "\n", "batch_y", ",", "\n", "batch_vars_stack", ",", "\n", "batch_covs_stack", ",", "\n", "baseName", "=", "baseName", ")", "\n", "\n", "# these are same for calibrated and uncalibrated", "\n", "means_means", ".", "append", "(", "mean_pred", ")", "\n", "covs_means", ".", "append", "(", "cov_pred_p", ")", "\n", "# this changes", "\n", "means_covs", ".", "append", "(", "mean_covar_p", ")", "\n", "#               cal_means_covs.append(cal_mean_covar_p)", "\n", "Batch_samples_stack_T", ".", "append", "(", "batch_samples_stack", ")", "\n", "\n", "Total_std", ".", "append", "(", "total_std", ")", "\n", "Total_covariance", ".", "append", "(", "total_covariance", ")", "\n", "Real_valu", ".", "append", "(", "rea_valu", ")", "\n", "\n", "count_68", "+=", "coverage_value_68", "\n", "count_95", "+=", "coverage_value_95", "\n", "count_99", "+=", "coverage_value_99", "\n", "count_all", "+=", "coverage_all", "\n", "\n", "\n", "b", "+=", "1", "\n", "\n", "if", "b", "==", "self", ".", "_n_batches", ":", "\n", "                    ", "break", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "\n", "", "", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_means'", ",", "baseName", ")", ",", "batch_means_stack", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_covs'", ",", "baseName", ")", ",", "batch_covs_stack", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_reals'", ",", "baseName", ")", ",", "batch_reals", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_stack'", ",", "baseName", ")", ",", "batch_samples_stack", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_mean_covs'", ",", "baseName", ")", ",", "means_covs", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_covs_means'", ",", "baseName", ")", ",", "covs_means", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_means_means'", ",", "baseName", ")", ",", "means_means", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_batch_Batch_samples_stack_T'", ",", "baseName", ")", ",", "Batch_samples_stack_T", ")", "\n", "means_means", "=", "np", ".", "stack", "(", "means_means", ",", "axis", "=", "0", ")", "\n", "Total_covariance", "=", "np", ".", "stack", "(", "Total_covariance", ",", "axis", "=", "0", ")", "\n", "\n", "Real_valu", "=", "np", ".", "stack", "(", "Real_valu", ",", "axis", "=", "0", ")", "\n", "\n", "cal_count_68", ",", "cal_count_95", ",", "cal_count_99", ",", "Total_batch", ",", "MSE", "=", "self", ".", "find_calibration", "(", "Total_covariance", ",", "means_means", ",", "Real_valu", ",", "baseName", ")", "\n", "#_, _, _,_ = self.find_calibration( batch_covs_A, batch_means_A, batch_reals_A, '_Ale_'+baseName)", "\n", "sumeT", ",", "ppf_run", "=", "self", ".", "general_ellip_counts_calibrate", "(", "batch_covs_A", ",", "batch_means_A", ",", "batch_reals_A", ",", "alpha_ini", "=", "1", ")", "\n", "fig_2", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "scatter", "(", "ppf_run", ",", "sumeT", ",", "label", "=", "'uncalibrated-Ale'", ")", "\n", "line_s1", "=", "np", ".", "arange", "(", "0.0", ",", "1", ",", "0.01", ")", "\n", "plt", ".", "plot", "(", "line_s1", ",", "line_s1", ",", "'r-'", ",", "alpha", "=", "0.1", ")", "\n", "plt", ".", "xlabel", "(", "'Confidence level'", ")", "\n", "plt", ".", "ylabel", "(", "'Estimated coverage probability'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "_create_name", "(", "\"calibration_Aleat\"", ",", "baseName", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", "fig_2", ")", "\n", "\n", "with", "open", "(", "self", ".", "_create_name", "(", "'ci_info'", ",", "baseName", ")", "+", "'.dat'", ",", "'w'", ")", "as", "ft1", ":", "\n", "            ", "ft1", ".", "write", "(", "\"count_68 count_95 count_99 count_all MSE\\n\"", ")", "\n", "#ft1.write(\"{} {} {} {} \\n\".format(count_68 , count_95, count_99, count_all))", "\n", "ft1", ".", "write", "(", "\"{} {} {} {} {}\\n\"", ".", "format", "(", "cal_count_68", ",", "cal_count_95", ",", "cal_count_99", ",", "Total_batch", ",", "MSE", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.samples_calibrated": [[250, 264], ["means_stack.reshape", "covs_stack.reshape", "range", "range", "ssa1.append", "numpy.stack", "ssa.append", "numpy.random.multivariate_normal"], "methods", ["None"], ["", "", "def", "samples_calibrated", "(", "self", ",", "means_stack", ",", "covs_stack", ",", "alpha_calibrate", "=", "1", ")", ":", "\n", "        ", "ssa1", "=", "[", "]", "\n", "shap", "=", "means_stack", ".", "shape", "\n", "shap_0", "=", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", "\n", "means_stack_reshaped", "=", "means_stack", ".", "reshape", "(", "shap_0", ",", "shap", "[", "2", "]", ",", "shap", "[", "3", "]", ")", "\n", "covariance_stack_reshaped", "=", "covs_stack", ".", "reshape", "(", "shap_0", ",", "shap", "[", "2", "]", ",", "shap", "[", "2", "]", ",", "shap", "[", "3", "]", ")", "\n", "covariance_stack_reshaped", "=", "covariance_stack_reshaped", "*", "alpha_calibrate", "\n", "for", "i", "in", "range", "(", "shap_0", ")", ":", "\n", "            ", "ssa", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "shap", "[", "3", "]", ")", ":", "\n", "                ", "ssa", ".", "append", "(", "np", ".", "random", ".", "multivariate_normal", "(", "means_stack_reshaped", "[", "i", ",", ":", ",", "j", "]", ",", "covariance_stack_reshaped", "[", "i", ",", ":", ",", ":", ",", "j", "]", ")", ")", "\n", "", "ssa1", ".", "append", "(", "ssa", ")", "\n", "", "cal_samples", "=", "np", ".", "stack", "(", "ssa1", ",", "axis", "=", "2", ")", ".", "T", "\n", "return", "cal_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.CI": [[266, 300], ["numpy.mean", "numpy.var", "numpy.array", "numpy.mean", "numpy.mean", "numpy.sqrt", "ConfidenceIntervals.ConfidenceIntervals.ellip_counts_3_sigmas", "list", "map", "numpy.cov"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.ellip_counts_3_sigmas"], ["", "def", "CI", "(", "self", ",", "predictions", ",", "rea_valu", ",", "variance_s", ",", "covariance_s", ",", "baseName", ",", "alpha_calibrate", "=", "1", ")", ":", "\n", "#  rea_valu=denormalize(rea_valu)", "\n", "        ", "batch_size", "=", "rea_valu", ".", "shape", "[", "0", "]", "\n", "\n", "mean_pred", "=", "np", ".", "mean", "(", "predictions", ",", "axis", "=", "2", ")", "\n", "var_pred", "=", "np", ".", "var", "(", "predictions", ",", "axis", "=", "2", ")", "\n", "# covariance over parameters only, for each example in the batch", "\n", "cov_pred", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "cov", "(", "x", ")", ",", "predictions", ")", ")", ")", "\n", "mean_var", "=", "np", ".", "mean", "(", "variance_s", ",", "axis", "=", "2", ")", "\n", "mean_covar", "=", "np", ".", "mean", "(", "covariance_s", ",", "axis", "=", "3", ")", "\n", "\n", "total_variance", "=", "var_pred", "+", "mean_var", "\n", "total_covariance", "=", "cov_pred", "+", "mean_covar", "\n", "total_std", "=", "np", ".", "sqrt", "(", "total_variance", ")", "\n", "sume68", ",", "sume95", ",", "sume99", "=", "self", ".", "ellip_counts_3_sigmas", "(", "total_covariance", ",", "mean_pred", ",", "rea_valu", ",", "alpha_calibrate", ")", "\n", "\n", "sumeT", "=", "batch_size", "#np.logical_and(rea_valu > confiden_inter_T_min, rea_valu < confiden_inter_T_max)", "\n", "\n", "# fig_1 = plt.figure()", "\n", "#", "\n", "# for i, param_name in enumerate(self._parameters_list):", "\n", "#     plt.errorbar(rea_valu[:, i], mean_pred[:, i], total_std[:, i], fmt='o', #color=colors[param_name], ecolor=ecolor[param_name],", "\n", "#                  elinewidth=3, capsize=0, label=param_name)", "\n", "#", "\n", "# line_s1 = np.arange(0.0, 1, 0.01)", "\n", "# plt.plot(line_s1, line_s1, 'r-', alpha=0.1)", "\n", "# plt.xlabel('True value')", "\n", "# plt.ylabel('Predicted value')", "\n", "# plt.legend()", "\n", "# plt.savefig(self._create_name(\"correlation\", baseName) + \".png\")", "\n", "# plt.close(fig_1)", "\n", "\n", "return", "sume68", ",", "sume95", ",", "sume99", ",", "sumeT", ",", "total_std", ",", "cov_pred", ",", "mean_covar", ",", "total_covariance", ",", "rea_valu", ",", "mean_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.ellip_counts_3_sigmas": [[301, 306], ["ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts", "ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts", "ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts"], ["", "def", "ellip_counts_3_sigmas", "(", "self", ",", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ")", ":", "\n", "        ", "sume68", "=", "self", ".", "general_ellip_counts", "(", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ",", "nstd", "=", "1", ")", "\n", "sume95", "=", "self", ".", "general_ellip_counts", "(", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ",", "nstd", "=", "2", ")", "\n", "sume99", "=", "self", ".", "general_ellip_counts", "(", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ",", "nstd", "=", "3", ")", "\n", "return", "sume68", ",", "sume95", ",", "sume99", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.find_calibration": [[307, 316], ["means.reshape", "real.reshape", "covariance.reshape", "sklearn.metrics.mean_squared_error", "ConfidenceIntervals.ConfidenceIntervals.ellip_counts_3_sigmas", "ConfidenceIntervals.ConfidenceIntervals.CI_calibrate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.ellip_counts_3_sigmas", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.CI_calibrate"], ["", "def", "find_calibration", "(", "self", ",", "covariance", ",", "means", ",", "real", ",", "baseName", ")", ":", "\n", "        ", "shap", "=", "means", ".", "shape", "\n", "means_reshaped", "=", "means", ".", "reshape", "(", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", ",", "shap", "[", "2", "]", ")", "\n", "real_reshaped", "=", "real", ".", "reshape", "(", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", ",", "shap", "[", "2", "]", ")", "\n", "covariance_reshaped", "=", "covariance", ".", "reshape", "(", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", ",", "shap", "[", "2", "]", ",", "shap", "[", "2", "]", ")", "\n", "MSE", "=", "mean_squared_error", "(", "real_reshaped", ",", "means_reshaped", ")", "\n", "summe68", ",", "summe95", ",", "summe99", "=", "self", ".", "ellip_counts_3_sigmas", "(", "covariance_reshaped", ",", "means_reshaped", ",", "real_reshaped", ",", "alpha_calibrate", "=", "1", ")", "\n", "self", ".", "CI_calibrate", "(", "covariance_reshaped", ",", "means_reshaped", ",", "real_reshaped", ",", "baseName", ",", "alpha_calibrate", "=", "1", ",", "Aleatoric", "=", "'Epis'", ")", "\n", "return", "summe68", ",", "summe95", ",", "summe99", ",", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", ",", "MSE", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervals.ConfidenceIntervals.general_ellip_counts": [[318, 340], ["numpy.linalg.inv", "numpy.einsum", "scipy.stats.chi2", "scipy.stats.chi2.ppf", "enumerate"], "methods", ["None"], ["", "def", "general_ellip_counts", "(", "self", ",", "covariance", ",", "mean", ",", "real_values", ",", "alpha_calibrate", "=", "1", ",", "nstd", "=", "1", ")", ":", "\n", "        ", "Inverse_covariance", "=", "np", ".", "linalg", ".", "inv", "(", "covariance", ")", "\n", "Ellip_eq", "=", "np", ".", "einsum", "(", "'nl,nlm,mn->n'", ",", "(", "real_values", "-", "mean", ")", ",", "Inverse_covariance", ",", "(", "real_values", "-", "mean", ")", ".", "T", ")", "\n", "if", "nstd", "==", "1", ":", "\n", "            ", "ppf", "=", "0.68", "\n", "", "if", "nstd", "==", "2", ":", "\n", "            ", "ppf", "=", "0.95", "\n", "", "if", "nstd", "==", "3", ":", "\n", "            ", "ppf", "=", "0.997", "\n", "\n", "", "rv", "=", "chi2", "(", "df", "=", "mean", ".", "shape", "[", "1", "]", ")", "\n", "square_norm", "=", "rv", ".", "ppf", "(", "ppf", ")", "\n", "\n", "values", "=", "Ellip_eq", "/", "(", "square_norm", "*", "alpha_calibrate", ")", "\n", "suma_T", "=", "0", "\n", "for", "ids", ",", "inst", "in", "enumerate", "(", "values", ")", ":", "\n", "            ", "if", "inst", "<=", "1", ":", "\n", "                ", "suma_T", "+=", "1", "\n", "# print(ids, inst)", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "", "", "return", "suma_T", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesClassification.ConfidenceIntervalsOnlySamplesClassification._stats_and_plot": [[8, 31], ["numpy.concatenate", "numpy.concatenate", "numpy.sum", "numpy.argmax", "len", "numpy.mean", "accuracy_over_fracs.append", "open", "f.write", "zip", "numpy.equal", "ConfidenceIntervalsOnlySamplesClassification.ConfidenceIntervalsOnlySamplesClassification._accuracy_over_threshold", "f.write", "ConfidenceIntervalsOnlySamplesClassification.ConfidenceIntervalsOnlySamplesClassification._create_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesClassification.ConfidenceIntervalsOnlySamplesClassification._accuracy_over_threshold", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["    ", "def", "_stats_and_plot", "(", "self", ",", "baseName", ",", "batch_samples_list", ",", "real_valu_list", ",", "extra_batch_dict", ")", ":", "\n", "\n", "        ", "all_samples", "=", "np", ".", "concatenate", "(", "batch_samples_list", ",", "axis", "=", "0", ")", "\n", "y", "=", "np", ".", "concatenate", "(", "real_valu_list", ",", "axis", "=", "0", ")", "\n", "\n", "nb", ",", "no", ",", "ns", "=", "all_samples", ".", "shape", "\n", "\n", "cumulative_preds", "=", "np", ".", "sum", "(", "all_samples", ",", "axis", "=", "2", ")", "\n", "\n", "predictions_forced", "=", "np", ".", "argmax", "(", "cumulative_preds", ",", "axis", "=", "1", ")", "\n", "accuracy_forced", "=", "np", ".", "mean", "(", "np", ".", "equal", "(", "predictions_forced", ",", "y", ")", ")", "*", "100", "\n", "total", "=", "len", "(", "predictions_forced", ")", "\n", "\n", "#refuse prediction if uncertainties is too high (Bayesian defense)", "\n", "fracs", "=", "[", "0.5", ",", "0.7", ",", "0.9", "]", "\n", "accuracy_over_fracs", "=", "[", "]", "\n", "for", "frac", "in", "fracs", ":", "\n", "            ", "accuracy_over_fracs", ".", "append", "(", "self", ".", "_accuracy_over_threshold", "(", "cumulative_preds", ",", "frac", ",", "ns", ",", "y", ")", ")", "\n", "\n", "", "with", "open", "(", "self", ".", "_create_name", "(", "\"stats\"", ",", "baseName", ")", "+", "'.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"forced ->  accuracy: {:}  total: {:}\\n\"", ".", "format", "(", "accuracy_forced", ",", "total", ")", ")", "\n", "for", "frac", ",", "(", "acc_over", ",", "tot_over", ")", "in", "zip", "(", "fracs", ",", "accuracy_over_fracs", ")", ":", "\n", "                ", "f", ".", "write", "(", "\"over {:} ->  accuracy: {:}  total: {:}\\n\"", ".", "format", "(", "frac", ",", "acc_over", ",", "tot_over", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesClassification.ConfidenceIntervalsOnlySamplesClassification._accuracy_over_threshold": [[33, 41], ["numpy.array", "numpy.logical_not", "numpy.argmax", "numpy.all", "numpy.mean", "len", "numpy.equal"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "", "", "def", "_accuracy_over_threshold", "(", "self", ",", "cumulative_preds", ",", "frac", ",", "ns", ",", "y", ")", ":", "\n", "        ", "threshold", "=", "ns", "*", "frac", "\n", "more_than", "=", "np", ".", "array", "(", "cumulative_preds", ">", "threshold", ",", "dtype", "=", "np", ".", "int", ")", "\n", "non_zero_indexes", "=", "np", ".", "logical_not", "(", "np", ".", "all", "(", "more_than", "==", "0", ",", "axis", "=", "1", ")", ")", "\n", "predictions_more", "=", "np", ".", "argmax", "(", "more_than", "[", "non_zero_indexes", "]", ",", "axis", "=", "1", ")", "\n", "y_more", "=", "y", "[", "non_zero_indexes", "]", "\n", "accuracy_more", "=", "np", ".", "mean", "(", "np", ".", "equal", "(", "predictions_more", ",", "y_more", ")", ")", "*", "100", "\n", "return", "accuracy_more", ",", "len", "(", "predictions_more", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCRegressionHook.MCRegressionHook.__init__": [[11, 30], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", ",", "TEST", "]", ",", "\n", "posterior_samples", "=", "2500", ",", "\n", "n_batches", "=", "-", "1", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "datasets_keys", ",", "dirName", "=", "dirName", "+", "'/mc_regression'", ")", "\n", "self", ".", "_default_plot_bool", "=", "False", "\n", "\n", "self", ".", "_parameters_list", "=", "self", ".", "_model", ".", "dataset", ".", "_parameters_list", "\n", "self", ".", "_n_batches", "=", "n_batches", "\n", "self", ".", "_posterior_samples", "=", "posterior_samples", "\n", "\n", "tf_logging", ".", "info", "(", "\"Create MCRegressionHook for: \\n\"", "+", "\", \"", ".", "join", "(", "datasets_keys", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCRegressionHook.MCRegressionHook.after_create_session": [[31, 45], ["super().after_create_session", "ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session"], ["", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "self", ".", "ci_obj", "=", "ConfidenceIntervalsOnlySamplesRegression", "(", "self", ".", "_dirName", ",", "\n", "self", ".", "_ds_initializers", ",", "\n", "self", ".", "_ds_handles", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_model", ".", "n_samples_ph", ",", "\n", "self", ".", "_model", ".", "prediction_sample", ",", "\n", "self", ".", "_model", ".", "raw_x", ",", "\n", "self", ".", "_model", ".", "x", ",", "\n", "self", ".", "_model", ".", "y", ",", "\n", "self", ".", "_model", ".", "dataset", ".", "_parameters_list", ",", "\n", "posterior_samples", "=", "self", ".", "_posterior_samples", ",", "\n", "n_batches", "=", "self", ".", "_n_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCRegressionHook.MCRegressionHook.do_when_triggered": [[46, 52], ["tf_logging.info", "MCRegressionHook.MCRegressionHook.ci_obj.do_when_triggered", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook.do_when_triggered"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "time_ref", "=", "self", ".", "_time_ref", "\n", "time_ref_str", "=", "self", ".", "_time_ref_shortstr", "\n", "tf_logging", ".", "info", "(", "\"trigger for MCRegressionHook\"", ")", "\n", "self", ".", "ci_obj", ".", "do_when_triggered", "(", "run_context", ".", "session", ",", "self", ".", "_datasets_keys", ",", "time_ref", ",", "time_ref_str", ")", "\n", "tf_logging", ".", "info", "(", "\"MCRegressionHook Done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.__init__": [[57, 111], ["model._get_steps", "list", "list", "argo.core.hooks.LoggingMeanTensorsHook.LoggingMeanTensorsHook.__init__", "print", "list", "HMFisherMatrixHook.HMFisherMatrixHook._saved_matrices.keys", "set", "HMFisherMatrixHook.HMFisherMatrixHook._saved_matrices.values", "k.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "dirName", ",", "\n", "period", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "time_reference", "=", "\"epochs\"", "\n", ")", ":", "\n", "\n", "        ", "fileName", "=", "\"fisher_matrix\"", "\n", "dirName", "=", "dirName", "+", "'/fisher'", "\n", "average_steps", "=", "model", ".", "_get_steps", "(", "period", ",", "time_reference", ")", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "self", ".", "_saved_matrices", "=", "self", ".", "_model", ".", "_optimizer", ".", "_saves", "\n", "\n", "values", "=", "list", "(", "self", ".", "_saved_matrices", ".", "values", "(", ")", ")", "+", "[", "self", ".", "_model", ".", "_optimizer", ".", "_diagonal_pad", "]", "\n", "keys", "=", "list", "(", "self", ".", "_saved_matrices", ".", "keys", "(", ")", ")", "\n", "self", ".", "layers", "=", "list", "(", "set", "(", "[", "k", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "for", "k", "in", "keys", "]", ")", ")", "\n", "keys", "+=", "[", "\"d_pad\"", "]", "\n", "\n", "tensors_to_average", "=", "[", "\n", "[", "[", "v", "]", "for", "v", "in", "values", "]", ",", "\n", "]", "\n", "\n", "tensors_to_average_names", "=", "[", "\n", "[", "[", "k", "]", "for", "k", "in", "keys", "]", ",", "\n", "]", "\n", "\n", "tensors_to_average_plots", "=", "[", "\n", "[", "{", "\n", "\"fileName\"", ":", "k", "}", "for", "k", "in", "keys", "]", "\n", "]", "\n", "\n", "super", "(", "HMFisherMatrixHook", ",", "self", ")", ".", "__init__", "(", "model", ",", "\n", "fileName", ",", "\n", "dirName", ",", "\n", "tensors_to_average", ",", "\n", "tensors_to_average_names", ",", "\n", "tensors_to_average_plots", ",", "\n", "average_steps", "=", "average_steps", ",", "\n", "tensorboard_dir", "=", "None", ",", "\n", "trigger_summaries", "=", "False", ",", "\n", "# trigger_plot = True,", "\n", "print_to_screen", "=", "False", ",", "\n", "plot_offset", "=", "0", ",", "\n", "train_loop_key", "=", "train_loop_key", ",", "\n", "datasets_keys", "=", "[", "]", ",", "# dataset_keys,", "\n", "time_reference", "=", "time_reference", "\n", ")", "\n", "\n", "# reset the default metric", "\n", "self", ".", "_default_metric", "=", "tf", ".", "metrics", ".", "mean_tensor", "\n", "\n", "print", "(", "\"HMFisherMatrixHook has been enabled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.after_run": [[112, 117], ["super().after_run", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.after_run"], ["", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "if", "self", ".", "_trigged_for_step", ":", "\n", "            ", "tf_logging", ".", "info", "(", "\"trigger for HMFisherMatrixHook\"", ")", "\n", "\n", "", "super", "(", ")", ".", "after_run", "(", "run_context", ",", "run_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.plot": [[118, 197], ["enumerate", "zip", "len", "enumerate", "HMFisherMatrixHook.HMFisherMatrixHook.get_file_path", "numpy.load", "zip", "HMFisherMatrixHook.HMFisherMatrixHook.get_matrices", "len", "numpy.absolute", "HMFisherMatrixHook.HMFisherMatrixHook.plot_matrix", "numpy.transpose", "numpy.einsum", "numpy.absolute", "numpy.absolute.ravel", "HMFisherMatrixHook.HMFisherMatrixHook.get_file_path", "matplotlib.figure", "matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.savefig", "matplotlib.savefig", "HMFisherMatrixHook.HMFisherMatrixHook.plot_matrix", "HMFisherMatrixHook.HMFisherMatrixHook.get_file_path", "numpy.load", "HMFisherMatrixHook.HMFisherMatrixHook.keys", "numpy.einsum", "len", "numpy.absolute", "HMFisherMatrixHook.HMFisherMatrixHook.plot_matrix", "numpy.absolute", "HMFisherMatrixHook.HMFisherMatrixHook.plot_matrix", "len", "matplotlib.figure", "matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.savefig", "matplotlib.savefig", "m.ravel.ravel.ravel", "matplotlib.figure", "matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.savefig", "matplotlib.savefig", "numpy.expand_dims", "HMFisherMatrixHook.HMFisherMatrixHook.keys", "len", "numpy.absolute", "HMFisherMatrixHook.HMFisherMatrixHook.plot_matrix", "ValueError", "numpy.eye", "HMFisherMatrixHook.HMFisherMatrixHook.keys", "numpy.absolute.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_matrices", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix"], ["", "def", "plot", "(", "self", ")", ":", "\n", "        ", "for", "i", ",", "(", "tensors_vertical_panel", ",", "files_panel", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ")", ":", "\n", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "\n", "# here it start the vertical panel", "\n", "                ", "for", "j", ",", "(", "tensors_names_panel", ",", "file_save", ")", "in", "enumerate", "(", "zip", "(", "tensors_vertical_panel", ",", "files_panel", ")", ")", ":", "\n", "                    ", "if", "file_save", "[", "\"fileName\"", "]", "!=", "\"d_pad\"", ":", "\n", "                        ", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "                            ", "filePath", "=", "self", ".", "get_file_path", "(", "file_save", "[", "\"fileName\"", "]", ")", "\n", "m", "=", "np", ".", "load", "(", "filePath", "+", "'.npy'", ")", "\n", "\n", "if", "len", "(", "m", ".", "shape", ")", "==", "1", ":", "\n", "                                ", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "m", ",", "bins", "=", "100", ")", "\n", "plt", ".", "savefig", "(", "filePath", "+", "'.png'", ")", "\n", "", "else", ":", "\n", "                                ", "m", "=", "m", ".", "ravel", "(", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "m", ",", "bins", "=", "100", ")", "\n", "plt", ".", "savefig", "(", "filePath", "+", "'.png'", ")", "\n", "\n", "", "", "", "", "filePath", "=", "self", ".", "get_file_path", "(", "\"d_pad\"", ")", "\n", "d_pad", "=", "np", ".", "load", "(", "filePath", "+", "'.npy'", ")", "\n", "for", "l", "in", "self", ".", "layers", ":", "\n", "                    ", "M_s", "=", "self", ".", "get_matrices", "(", "l", ")", "\n", "\n", "if", "len", "(", "M_s", ".", "keys", "(", ")", ")", "==", "3", ":", "\n", "                        ", "bias_name", "=", "l", "+", "\"_B\"", "\n", "bias", "=", "M_s", "[", "bias_name", "]", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "bias", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "self", ".", "plot_matrix", "(", "M", ",", "bias_name", ")", "\n", "\n", "U_name", "=", "l", "+", "\"_U\"", "\n", "U", "=", "M_s", "[", "U_name", "]", "\n", "\n", "V_T", "=", "np", ".", "transpose", "(", "U", ",", "axes", "=", "[", "1", ",", "0", "]", ")", "\n", "MII_name", "=", "l", "+", "\"_MII\"", "\n", "MII", "=", "M_s", "[", "MII_name", "]", "\n", "\n", "M2", "=", "np", ".", "einsum", "(", "'ij,ljk->lik'", ",", "U", ",", "np", ".", "einsum", "(", "'lij,jk->lik'", ",", "MII", ",", "V_T", ")", ")", "\n", "\n", "M", "=", "d_pad", "*", "np", ".", "expand_dims", "(", "np", ".", "eye", "(", "M2", ".", "shape", "[", "-", "1", "]", ")", ",", "axis", "=", "0", ")", "-", "M2", "\n", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "M", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "# Let's see", "\n", "m", "=", "M", ".", "ravel", "(", ")", "\n", "filePath", "=", "self", ".", "get_file_path", "(", "l", "+", "\"_MI\"", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "m", ",", "bins", "=", "100", ")", "\n", "plt", ".", "savefig", "(", "filePath", "+", "'.png'", ")", "\n", "\n", "self", ".", "plot_matrix", "(", "M", ",", "l", "+", "\"_INV\"", ")", "\n", "", "elif", "len", "(", "M_s", ".", "keys", "(", ")", ")", "==", "2", ":", "\n", "\n", "                        ", "bias_name", "=", "l", "+", "\"_B\"", "\n", "bias", "=", "M_s", "[", "bias_name", "]", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "bias", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "\n", "self", ".", "plot_matrix", "(", "M", ",", "bias_name", ")", "\n", "\n", "mi_name", "=", "l", "+", "\"_MI\"", "\n", "mi", "=", "M_s", "[", "mi_name", "]", "\n", "M", "=", "np", ".", "absolute", "(", "mi", ")", "\n", "\n", "self", ".", "plot_matrix", "(", "M", ",", "mi_name", ")", "\n", "\n", "", "elif", "len", "(", "M_s", ".", "keys", "(", ")", ")", "==", "1", ":", "\n", "                        ", "bias_name", "=", "l", "+", "\"_B\"", "\n", "bias", "=", "M_s", "[", "bias_name", "]", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "bias", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "self", ".", "plot_matrix", "(", "M", ",", "bias_name", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", "\"Invalid amount of matrices '{}'\"", ".", "format", "(", "M", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.plot_matrix": [[198, 202], ["HMFisherMatrixHook.fix", "HMFisherMatrixHook.HMFisherMatrixHook.get_file_path", "matplotlib.imsave", "matplotlib.imsave", "map", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.fix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path"], ["", "", "", "", "", "def", "plot_matrix", "(", "self", ",", "M", ",", "name", ")", ":", "\n", "        ", "M", ",", "shap", "=", "fix", "(", "M", ")", "\n", "filePath", "=", "self", ".", "get_file_path", "(", "name", ",", "\".png\"", ",", "extra", "=", "\"x\"", ".", "join", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "shap", ")", ")", ")", "\n", "plt", ".", "imsave", "(", "filePath", ",", "M", ",", "cmap", "=", "\"gray\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.log_to_file_and_screen": [[203, 219], ["enumerate", "zip", "len", "enumerate", "zip", "HMFisherMatrixHook.HMFisherMatrixHook.get_file_path", "numpy.save", "HMFisherMatrixHook.HMFisherMatrixHook.get_file_path", "numpy.save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "def", "log_to_file_and_screen", "(", "self", ",", "log_to_screen", "=", "False", ")", ":", "\n", "\n", "        ", "for", "i", ",", "(", "tensors_vertical_panel", ",", "files_panel", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ")", ":", "\n", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "# here it start the vertical panel", "\n", "                ", "for", "j", ",", "(", "tensors_names_panel", ",", "file_save", ")", "in", "enumerate", "(", "zip", "(", "tensors_vertical_panel", ",", "files_panel", ")", ")", ":", "\n", "                    ", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "                        ", "filePath", "=", "self", ".", "get_file_path", "(", "file_save", "[", "\"fileName\"", "]", ")", "\n", "d", "=", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "[", "0", "]", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "\n", "filePath", "=", "self", ".", "get_file_path", "(", "file_save", "[", "\"fileName\"", "]", ",", "extra", "=", "\"step\"", ")", "\n", "d", "=", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "[", "0", "]", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook._after_run": [[220, 222], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "_after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook._create_or_open_files": [[223, 225], ["None"], "methods", ["None"], ["", "def", "_create_or_open_files", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook._reset_file": [[226, 228], ["None"], "methods", ["None"], ["", "def", "_reset_file", "(", "self", ",", "session", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.end": [[229, 231], ["None"], "methods", ["None"], ["", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.get_file_path": [[232, 235], ["str().zfill", "str"], "methods", ["None"], ["", "def", "get_file_path", "(", "self", ",", "name", ",", "type", "=", "\"\"", ",", "extra", "=", "\"\"", ")", ":", "\n", "        ", "return", "self", ".", "_dirName", "+", "'/{}_'", ".", "format", "(", "name", ")", "+", "extra", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "\n", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "+", "'{}'", ".", "format", "(", "type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.HMFisherMatrixHook.get_matrices": [[236, 240], ["numpy.asarray().reshape", "list", "filter", "numpy.load", "numpy.asarray", "HMFisherMatrixHook.HMFisherMatrixHook.get_file_path"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path"], ["", "def", "get_matrices", "(", "self", ",", "layer", ")", ":", "\n", "        ", "flat", "=", "np", ".", "asarray", "(", "self", ".", "_tensors_names", ")", ".", "reshape", "(", "[", "-", "1", "]", ")", "\n", "matrices", "=", "list", "(", "filter", "(", "lambda", "i", ":", "layer", "in", "i", ",", "flat", ")", ")", "\n", "return", "{", "m", ":", "np", ".", "load", "(", "self", ".", "get_file_path", "(", "m", ",", "'.npy'", ")", ")", "for", "m", "in", "matrices", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.get_closest_to_square_divisor": [[17, 25], ["numpy.sqrt", "range", "int"], "function", ["None"], ["def", "get_closest_to_square_divisor", "(", "number", ")", ":", "\n", "    ", "sq", "=", "np", ".", "sqrt", "(", "number", ")", "\n", "nv", "=", "1", "\n", "for", "i", "in", "range", "(", "int", "(", "sq", ")", ",", "0", ",", "-", "1", ")", ":", "\n", "        ", "if", "number", "%", "i", "==", "0", ":", "\n", "            ", "nv", "=", "i", "\n", "break", "\n", "", "", "return", "nv", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.stich": [[27, 38], ["HMFisherMatrixHook.get_closest_to_square_divisor", "M.reshape", "numpy.empty", "range", "range"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.get_closest_to_square_divisor"], ["", "def", "stich", "(", "M", ")", ":", "\n", "    ", "nv", "=", "get_closest_to_square_divisor", "(", "M", ".", "shape", "[", "0", "]", ")", "\n", "x", "=", "M", ".", "reshape", "(", "[", "nv", ",", "-", "1", ",", "*", "M", ".", "shape", "[", "1", ":", "]", "]", ")", "\n", "new_shape", "=", "x", ".", "shape", "\n", "pic", "=", "np", ".", "empty", "(", "[", "x", ".", "shape", "[", "0", "]", "*", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "1", "]", "*", "x", ".", "shape", "[", "3", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "x", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "k", "=", "x", ".", "shape", "[", "2", "]", "\n", "l", "=", "x", ".", "shape", "[", "3", "]", "\n", "pic", "[", "i", "*", "k", ":", "i", "*", "k", "+", "k", ",", "j", "*", "l", ":", "j", "*", "l", "+", "l", "]", "=", "x", "[", "i", ",", "j", ",", ":", ",", ":", "]", "\n", "", "", "return", "pic", ",", "new_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook.fix": [[40, 50], ["len", "M.reshape", "len", "HMFisherMatrixHook.stich"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.stich"], ["", "def", "fix", "(", "M", ")", ":", "\n", "    ", "if", "len", "(", "M", ".", "shape", ")", "==", "1", ":", "\n", "        ", "M_m", "=", "M", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "shap", "=", "M_m", ".", "shape", "\n", "", "elif", "len", "(", "M", ".", "shape", ")", "==", "2", ":", "\n", "        ", "M_m", "=", "M", "\n", "shap", "=", "M_m", ".", "shape", "\n", "", "else", ":", "\n", "        ", "M_m", ",", "shap", "=", "stich", "(", "M", ")", "\n", "", "return", "M_m", ",", "shap", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples.__init__": [[8, 47], ["super().__init__", "len", "len", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dirName", ",", "\n", "dataset_initializers", ",", "\n", "dataset_handles", ",", "\n", "handle", ",", "\n", "n_samples_ph", ",", "\n", "distsample", ",", "\n", "raw_x", ",", "\n", "x", ",", "\n", "y", ",", "\n", "posterior_samples", "=", "2500", ",", "\n", "n_batches", "=", "-", "1", ",", "\n", "extra_nodes_to_collect", "=", "[", "]", ",", "\n", "extra_nodes_names", "=", "[", "]", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "#        self._datasets_keys= datasets_keys", "\n", "self", ".", "_posterior_samples", "=", "posterior_samples", "\n", "#        self._session=session", "\n", "self", ".", "_dirName", "=", "dirName", "\n", "\n", "self", ".", "_distsample", "=", "distsample", "\n", "\n", "self", ".", "_raw_x", "=", "raw_x", "\n", "self", ".", "_y", "=", "y", "\n", "self", ".", "_x", "=", "x", "\n", "self", ".", "_dataset_initializers", "=", "dataset_initializers", "\n", "self", ".", "_dataset_handles", "=", "dataset_handles", "\n", "self", ".", "_handle", "=", "handle", "\n", "self", ".", "_n_batches", "=", "n_batches", "\n", "self", ".", "_n_samples_ph", "=", "n_samples_ph", "\n", "\n", "if", "len", "(", "extra_nodes_to_collect", ")", "!=", "len", "(", "extra_nodes_names", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"extra_nodes_names should have same length than \"", "\n", "\"extra_nodes_to_collect, found: `{:d}` and `{:d}`\"", ".", "format", "(", "len", "(", "extra_nodes_to_collect", ")", ",", "len", "(", "extra_nodes_names", ")", ")", ")", "\n", "\n", "", "self", ".", "_extra_nodes_to_collect", "=", "extra_nodes_to_collect", "\n", "self", ".", "_extra_nodes_names", "=", "extra_nodes_names", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples.do_when_triggered": [[49, 52], ["ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._calculate_mc_dropout"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._calculate_mc_dropout"], ["", "def", "do_when_triggered", "(", "self", ",", "session", ",", "datasets_keys", ",", "timeref", ",", "timeref_str", "=", "\"ep\"", ")", ":", "\n", "        ", "for", "ds_key", "in", "datasets_keys", ":", "\n", "            ", "self", ".", "_calculate_mc_dropout", "(", "session", ",", "ds_key", ",", "timeref", ",", "timeref_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._create_name": [[53, 55], ["None"], "methods", ["None"], ["", "", "def", "_create_name", "(", "self", ",", "prefix", ",", "baseName", ")", ":", "\n", "       ", "return", "self", ".", "_dirName", "+", "\"/\"", "+", "prefix", "+", "\"-\"", "+", "baseName", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._calculate_mc_dropout": [[56, 129], ["session.run", "tqdm.tqdm.tqdm", "numpy.save", "numpy.save", "ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._stats_and_plot", "Exception", "ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._create_name", "ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._create_name", "numpy.save", "type", "session.run", "range", "numpy.stack", "batch_samples_list.append", "real_valu_list.append", "tqdm.tqdm.tqdm.update", "ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._create_name", "session.run", "batch_samples.append", "zip", "extra_batch_dict[].append", "batch_extras[].append", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression._stats_and_plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "_calculate_mc_dropout", "(", "self", ",", "session", ",", "ds_key", ",", "timeref", ",", "timeref_str", ")", ":", "\n", "\n", "        ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "            ", "raise", "Exception", "(", "\"I need a raw session to evaluate metric over dataset.\"", ")", "\n", "\n", "", "dataset_initializer", "=", "self", ".", "_dataset_initializers", "[", "ds_key", "]", "\n", "dataset_handle", "=", "self", ".", "_dataset_handles", "[", "ds_key", "]", "\n", "baseName", "=", "ds_key", "+", "\"-{:}{:04d}\"", ".", "format", "(", "timeref_str", ",", "timeref", ")", "\n", "\n", "init_ops", "=", "dataset_initializer", "\n", "session", ".", "run", "(", "init_ops", ")", "\n", "batch_samples_list", "=", "[", "]", "\n", "real_valu_list", "=", "[", "]", "\n", "\n", "extra_batch_dict", "=", "{", "}", "\n", "for", "name", "in", "self", ".", "_extra_nodes_names", ":", "\n", "            ", "extra_batch_dict", "[", "name", "]", "=", "[", "]", "\n", "\n", "", "pbar", "=", "tqdm", "(", "desc", "=", "'collecting samples {:}'", ".", "format", "(", "ds_key", ")", ",", "\n", "total", "=", "(", "self", ".", "_n_batches", "if", "(", "self", ".", "_n_batches", "!=", "-", "1", ")", "else", "None", ")", ",", "dynamic_ncols", "=", "True", ")", "\n", "b", "=", "0", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "batch_extras", "=", "{", "}", "\n", "for", "name", "in", "self", ".", "_extra_nodes_names", ":", "\n", "                ", "batch_extras", "[", "name", "]", "=", "[", "]", "\n", "\n", "", "batch_samples", "=", "[", "]", "\n", "\n", "try", ":", "\n", "# model.raw_x is the input before any noise addition (if present), we want to make sure we get the clean batch before noise", "\n", "                ", "batch_x", ",", "batch_y", "=", "session", ".", "run", "(", "[", "self", ".", "_raw_x", ",", "self", ".", "_y", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_handle", ":", "dataset_handle", "}", ")", "\n", "\n", "# model.x is the input after noise addition (if present), we want to make sure we feed x, so that noiose will not be added.", "\n", "for", "mcm", "in", "range", "(", "self", ".", "_posterior_samples", ")", ":", "\n", "                    ", "samples", ",", "extra_np", "=", "session", ".", "run", "(", "[", "self", ".", "_distsample", ",", "self", ".", "_extra_nodes_to_collect", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "_x", ":", "batch_x", ",", "self", ".", "_n_samples_ph", ":", "1", "}", ")", "\n", "\n", "batch_samples", ".", "append", "(", "samples", ")", "\n", "\n", "for", "name", ",", "arr", "in", "zip", "(", "self", ".", "_extra_nodes_names", ",", "extra_np", ")", ":", "\n", "                        ", "batch_extras", "[", "name", "]", ".", "append", "(", "arr", ")", "\n", "\n", "\n", "", "", "batch_samples_stack", "=", "np", ".", "stack", "(", "batch_samples", ",", "axis", "=", "2", ")", "\n", "\n", "batch_samples_list", ".", "append", "(", "batch_samples_stack", ")", "\n", "real_valu_list", ".", "append", "(", "batch_y", ")", "\n", "\n", "for", "name", "in", "self", ".", "_extra_nodes_names", ":", "\n", "                    ", "extra_batch_dict", "[", "name", "]", ".", "append", "(", "\n", "np", ".", "stack", "(", "batch_extras", "[", "name", "]", ",", "axis", "=", "2", ")", "\n", ")", "\n", "\n", "", "b", "+=", "1", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "b", "==", "self", ".", "_n_batches", ":", "\n", "                    ", "break", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "\n", "", "", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'batch_reals'", ",", "baseName", ")", ",", "real_valu_list", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'batch_samples'", ",", "baseName", ")", ",", "batch_samples_list", ")", "\n", "\n", "for", "name", "in", "self", ".", "_extra_nodes_names", ":", "\n", "            ", "np", ".", "save", "(", "self", ".", "_create_name", "(", "name", ",", "baseName", ")", ",", "extra_batch_dict", "[", "name", "]", ")", "\n", "\n", "", "self", ".", "_stats_and_plot", "(", "baseName", ",", "batch_samples_list", ",", "real_valu_list", ",", "extra_batch_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples._stats_and_plot": [[131, 134], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_stats_and_plot", "(", "self", ",", "baseName", ",", "batch_samples_list", ",", "real_valu_list", ",", "extra_batch_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.__init__": [[14, 29], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", "]", ",", "\n", "n_samples", "=", "10", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_dirName", "=", "dirName", "+", "'/correlation'", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "datasets_keys", ",", "dirName", "=", "self", ".", "_dirName", ")", "\n", "self", ".", "_n_samples", "=", "n_samples", "\n", "self", ".", "_default_plot_bool", "=", "False", "\n", "tf_logging", ".", "info", "(", "\"Create CorrelationHook for: \\n\"", "+", "\", \"", ".", "join", "(", "datasets_keys", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._begin_once": [[30, 35], ["CorrelationHook.CorrelationHook._mean_n_variance", "tensorflow.sqrt", "distr.sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._mean_n_variance", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "_begin_once", "(", "self", ")", ":", "\n", "        ", "distr", "=", "self", ".", "_model", ".", "prediction_distr", "\n", "mean", ",", "variance", "=", "self", ".", "_mean_n_variance", "(", "distr", ".", "sample", "(", "self", ".", "_n_samples", ")", ",", "axis", "=", "0", ")", "\n", "self", ".", "prediction_mean", "=", "mean", "\n", "self", ".", "prediction_std", "=", "tf", ".", "sqrt", "(", "variance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session": [[36, 39], ["super().after_create_session", "session.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.after_create_session", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "after_create_session", "(", "self", ",", "session", ",", "coord", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_create_session", "(", "session", ",", "coord", ")", "\n", "self", ".", "_ds_handles", "=", "session", ".", "run", "(", "self", ".", "_ds_handles_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.do_when_triggered": [[40, 50], ["tf_logging.info", "tf_logging.info", "CorrelationHook.CorrelationHook._plot_correlation", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._plot_correlation"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "time_ref", "=", "self", ".", "_time_ref", "\n", "time_ref_str", "=", "self", ".", "_time_ref_shortstr", "\n", "tf_logging", ".", "info", "(", "\"trigger for CorrelationHook\"", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "            ", "fileName", "=", "self", ".", "_dirName", "+", "\"/\"", "+", "\"corrs_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", "+", "\".png\"", "\n", "self", ".", "_plot_correlation", "(", "run_context", ".", "session", ",", "ds_key", ",", "fileName", ")", "\n", "\n", "", "tf_logging", ".", "info", "(", "\"done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._plot_correlation": [[52, 78], ["CorrelationHook.CorrelationHook._evaluate_correlations_over_dataset", "range", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.errorbar"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._evaluate_correlations_over_dataset"], ["", "def", "_plot_correlation", "(", "self", ",", "session", ",", "ds_key", ",", "fileName", ")", ":", "\n", "        ", "preds", ",", "stds", ",", "ys", "=", "self", ".", "_evaluate_correlations_over_dataset", "(", "session", ",", "\n", "self", ".", "_model", ",", "\n", "self", ".", "_ds_handle", ",", "\n", "self", ".", "_ds_initializers", "[", "ds_key", "]", ",", "\n", "self", ".", "_ds_handles", "[", "ds_key", "]", ")", "\n", "\n", "params_numbers", "=", "ys", ".", "shape", "[", "1", "]", "\n", "fmt", "=", "[", "'bo'", ",", "'ro'", ",", "'yo'", ",", "'go'", ",", "'po'", ",", "'co'", "]", "\n", "for", "i", "in", "range", "(", "params_numbers", ")", ":", "\n", "            ", "plt", ".", "errorbar", "(", "ys", "[", ":", ",", "i", "]", ",", "preds", "[", ":", ",", "i", "]", ",", "stds", "[", ":", ",", "i", "]", ",", "fmt", "=", "fmt", "[", "i", "]", ",", "label", "=", "ds_key", "+", "\"{}\"", ".", "format", "(", "i", ")", ")", "\n", "\n", "#plt.errorbar(ys[:, 0], preds[:, 0], varis[:, 0], fmt='bo', label=ds_key+\"1\")", "\n", "#plt.errorbar(ys[:, 1], preds[:, 1], varis[:, 1], fmt='ro', label=ds_key+\"2\")", "\n", "#plt.errorbar(ys[:, 2], preds[:, 2], varis[:, 2], fmt='yo', label=ds_key+\"3\")", "\n", "\n", "", "colors", "=", "[", "'blue'", ",", "'red'", ",", "'green'", ",", "'orange'", ",", "'darkviolet'", ",", "'purple'", "]", "\n", "ecolors", "=", "[", "'lightblue'", ",", "'lightcoral'", ",", "'lightgreen'", ",", "'yellow'", ",", "'violet'", ",", "'magenta'", "]", "\n", "\n", "# for m in range(3):", "\n", "#     plt.errorbar(ys[:,m], preds[:,m], varis[:,m],fmt='o', color=colors[m],", "\n", "#                          ecolor=ecolors[m], elinewidth=3, capsize=0, label=ds_key)", "\n", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "fileName", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._evaluate_correlations_over_dataset": [[80, 115], ["session.run", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "Exception", "type", "session.run", "numpy.concatenate.append", "numpy.concatenate.append", "numpy.concatenate.append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "_evaluate_correlations_over_dataset", "(", "self", ",", "session", ",", "model", ",", "handle", ",", "dataset_initializer", ",", "dataset_handle", ",", "n_batches", "=", "3", ",", "feed_dict", "=", "{", "}", ")", ":", "\n", "        ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "            ", "raise", "Exception", "(", "\"I need a raw session to evaluate metric over dataset.\"", ")", "\n", "\n", "", "init_ops", "=", "dataset_initializer", "\n", "session", ".", "run", "(", "init_ops", ")", "\n", "i", "=", "0", "\n", "all_preds", "=", "[", "]", "\n", "all_stds", "=", "[", "]", "\n", "# all_covs = []", "\n", "all_ys", "=", "[", "]", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "\n", "                ", "preds", ",", "stds", ",", "ys", "=", "session", ".", "run", "(", "[", "self", ".", "prediction_mean", ",", "self", ".", "prediction_std", ",", "model", ".", "y", "]", ",", "\n", "feed_dict", "=", "{", "**", "feed_dict", ",", "handle", ":", "dataset_handle", ",", "model", ".", "n_samples_ph", ":", "1", "}", ")", "\n", "\n", "# TODO HEctor if covs are not null, create the circles around the points", "\n", "# TODO (assume covs can be the covariances of the predictions and can be either diagonal matrioces or not)", "\n", "\n", "all_preds", ".", "append", "(", "preds", ")", "\n", "all_stds", ".", "append", "(", "stds", ")", "\n", "# all_covs.append(covs)", "\n", "all_ys", ".", "append", "(", "ys", ")", "\n", "i", "+=", "1", "\n", "if", "i", ">=", "n_batches", ":", "\n", "                    ", "break", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "", "", "all_preds", "=", "np", ".", "concatenate", "(", "all_preds", ",", "axis", "=", "0", ")", "\n", "all_ys", "=", "np", ".", "concatenate", "(", "all_ys", ",", "axis", "=", "0", ")", "\n", "# all_covs = np.concatenate(all_covs, axis=0)", "\n", "all_stds", "=", "np", ".", "concatenate", "(", "all_stds", ",", "axis", "=", "0", ")", "\n", "\n", "return", "all_preds", ",", "all_stds", ",", "all_ys", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook._mean_n_variance": [[116, 125], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.squeeze", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_mean_n_variance", "(", "self", ",", "input_tensor", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ",", "name", "=", "None", ")", ":", "\n", "        ", "name", "=", "name", "if", "name", "else", "\"mean_n_variance\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", ":", "\n", "            ", "means", "=", "tf", ".", "reduce_mean", "(", "input_tensor", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "\n", "squared_deviations", "=", "tf", ".", "square", "(", "input_tensor", "-", "means", ")", "\n", "if", "not", "keepdims", ":", "\n", "                ", "means", "=", "tf", ".", "squeeze", "(", "means", ",", "axis", "=", "axis", ")", "\n", "\n", "", "return", "means", ",", "tf", ".", "reduce_mean", "(", "squared_deviations", ",", "axis", "=", "axis", ",", "keepdims", "=", "keepdims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.CorrelationHook.CorrelationHook.plot": [[126, 128], ["None"], "methods", ["None"], ["", "", "def", "plot", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook.__init__": [[14, 24], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "[", "]", ",", "dirName", "=", "dirName", "+", "'/weights_histogram'", ")", "\n", "\n", "self", ".", "_default_plot_bool", "=", "False", "\n", "tf_logging", ".", "info", "(", "\"Create WeightsHistogramHook\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook.do_when_triggered": [[25, 31], ["WeightsHistogramHook.WeightsHistogramHook._calculate_histogram", "tf_logging.info", "str().zfill", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook._calculate_histogram"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "time_ref", "=", "self", ".", "_time_ref", "\n", "time_ref_str", "=", "self", ".", "_time_ref_shortstr", "\n", "fileName", "=", "\"Histogram_hook\"", "+", "\"_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "self", ".", "_calculate_histogram", "(", "run_context", ".", "session", ",", "fileName", ")", "\n", "tf_logging", ".", "info", "(", "\"trigger for WeightsHistogramHook\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook._plot_weight_posteriors": [[32, 74], ["matplotlib.pyplot.figure", "matplotlib.pyplot.figure.add_subplot", "zip", "plt.figure.add_subplot.set_title", "matplotlib.pyplot.figure.add_subplot", "zip", "plt.figure.add_subplot.set_title", "matplotlib.pyplot.figure.add_subplot", "matplotlib.pyplot.figure.add_subplot", "zip", "plt.figure.add_subplot.set_title", "plt.figure.add_subplot.set_title", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "seaborn.distplot", "seaborn.distplot", "loc.flatten", "seaborn.distplot", "numpy.asarray().flatten", "seaborn.distplot", "qm.flatten", "qs.flatten", "len", "numpy.tile", "WeightsHistogramHook.WeightsHistogramHook._create_name", "numpy.asarray", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["", "def", "_plot_weight_posteriors", "(", "self", ",", "loc_post", ",", "untr_scale_post", ",", "loc_prior", ",", "untr_scale_prior", ",", "layer_names", ",", "figure_name", ")", ":", "\n", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "3", ")", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "2", ",", "2", ",", "1", ")", "\n", "for", "n", ",", "qm", "in", "zip", "(", "layer_names", ",", "loc_post", ")", ":", "\n", "# try:", "\n", "#     sns.distplot(qm.flatten(), ax=ax)#, label=n)", "\n", "# except:", "\n", "            ", "sns", ".", "distplot", "(", "qm", ".", "flatten", "(", ")", ",", "ax", "=", "ax", ",", "kde", "=", "False", ")", "\n", "\n", "", "ax", ".", "set_title", "(", "\"posterior weights mean\"", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "2", ",", "2", ",", "2", ")", "\n", "for", "n", ",", "qs", "in", "zip", "(", "layer_names", ",", "untr_scale_post", ")", ":", "\n", "# qs_s=np.log(1.0 + np.exp(qs.flatten()))", "\n", "# try:", "\n", "#     sns.distplot(qs.flatten(), ax=ax)#, label=n)", "\n", "# except:", "\n", "            ", "sns", ".", "distplot", "(", "qs", ".", "flatten", "(", ")", ",", "ax", "=", "ax", ",", "kde", "=", "False", ")", "\n", "\n", "", "ax", ".", "set_title", "(", "\"posterior weights untr scale\"", ")", "\n", "\n", "ax21", "=", "fig", ".", "add_subplot", "(", "2", ",", "2", ",", "3", ")", "\n", "ax22", "=", "fig", ".", "add_subplot", "(", "2", ",", "2", ",", "4", ")", "\n", "\n", "for", "n", ",", "loc", ",", "untr_sc", "in", "zip", "(", "layer_names", ",", "loc_prior", ",", "untr_scale_prior", ")", ":", "\n", "            ", "loc_flat", "=", "loc", ".", "flatten", "(", ")", "\n", "sns", ".", "distplot", "(", "loc_flat", ",", "ax", "=", "ax21", ",", "kde", "=", "False", ")", "#, label=n)", "\n", "# scale_flat = np.log(1.0 + np.exp(np.asarray(untr_sc).flatten()))", "\n", "untr_scale_flat", "=", "np", ".", "asarray", "(", "untr_sc", ")", ".", "flatten", "(", ")", "\n", "if", "len", "(", "untr_scale_flat", ")", "==", "1", ":", "# in case a layer has a single scale parameter (fixed prior)", "\n", "                ", "untr_scale_flat", "=", "np", ".", "tile", "(", "untr_scale_flat", ",", "[", "len", "(", "loc_flat", ")", "]", ")", "# I need to tile just for good histogram visualization", "\n", "", "sns", ".", "distplot", "(", "untr_scale_flat", ",", "ax", "=", "ax22", ",", "kde", "=", "False", ")", "#, label=n)", "\n", "\n", "", "ax21", ".", "set_title", "(", "\"prior weights mean\"", ")", "\n", "ax22", ".", "set_title", "(", "\"prior weights untr scale\"", ")", "\n", "\n", "lgd", "=", "plt", ".", "legend", "(", "labels", "=", "layer_names", ",", "loc", "=", "'center left'", ",", "bbox_to_anchor", "=", "(", "1", ",", "0.5", ")", ")", "\n", "\n", "plt", ".", "savefig", "(", "self", ".", "_create_name", "(", "\"Layers_\"", ",", "figure_name", ")", "+", "\".png\"", ",", "bbox_extra_artists", "=", "[", "lgd", "]", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook._create_name": [[75, 77], ["None"], "methods", ["None"], ["", "def", "_create_name", "(", "self", ",", "prefix", ",", "baseName", ")", ":", "\n", "        ", "return", "self", ".", "_dirName", "+", "\"/\"", "+", "prefix", "+", "'_'", "+", "baseName", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook._calculate_histogram": [[78, 98], ["WeightsHistogramHook.WeightsHistogramHook.get_weights", "session.run", "WeightsHistogramHook.WeightsHistogramHook._plot_weight_posteriors", "Exception", "os.path.basename", "type"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook.get_weights", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook._plot_weight_posteriors"], ["", "def", "_calculate_histogram", "(", "self", ",", "session", ",", "baseName", ")", ":", "\n", "        ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "            ", "raise", "Exception", "(", "\"I need a  session to evaluate.\"", ")", "\n", "\n", "\n", "", "all_vars", "=", "self", ".", "get_weights", "(", "self", ".", "_model", ".", "_network", ")", "\n", "\n", "loc_posterior", "=", "[", "w", "for", "w", "in", "all_vars", "if", "\"kernel_posterior_loc\"", "in", "w", ".", "name", "]", "\n", "untr_scale_posterior", "=", "[", "w1", "for", "w1", "in", "all_vars", "if", "\"kernel_posterior_untransformed_scale\"", "in", "w1", ".", "name", "]", "\n", "\n", "loc_prior", "=", "[", "w2", "for", "w2", "in", "all_vars", "if", "\"kernel_prior_loc\"", "in", "w2", ".", "name", "]", "\n", "untr_scale_prior", "=", "[", "w3", "for", "w3", "in", "all_vars", "if", "\"kernel_prior_untransformed_scale\"", "in", "w3", ".", "name", "]", "\n", "\n", "_loc_post", ",", "_untr_scale_post", ",", "_loc_prior", ",", "_untr_scale_prior", "=", "session", ".", "run", "(", "[", "loc_posterior", ",", "\n", "untr_scale_posterior", ",", "\n", "loc_prior", ",", "\n", "untr_scale_prior", "]", ")", "\n", "\n", "layer_names", "=", "[", "os", ".", "path", ".", "basename", "(", "node", ".", "name", ")", "for", "node", "in", "loc_posterior", "]", "\n", "self", ".", "_plot_weight_posteriors", "(", "_loc_post", ",", "_untr_scale_post", ",", "_loc_prior", ",", "_untr_scale_prior", ",", "layer_names", ",", "baseName", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.WeightsHistogramHook.WeightsHistogramHook.get_weights": [[99, 106], ["isinstance", "model.get_all_variables", "isinstance", "Exception"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.get_all_variables"], ["", "def", "get_weights", "(", "self", ",", "model", ")", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "snt", ".", "AbstractModule", ")", ":", "\n", "            ", "return", "model", ".", "get_all_variables", "(", ")", "\n", "", "elif", "isinstance", "(", "model", ",", "tf", ".", "keras", ".", "Model", ")", ":", "\n", "            ", "return", "model", ".", "variables", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"what kind of model is this?\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression.__init__": [[15, 48], ["ConfidenceIntervalsOnlySamples.ConfidenceIntervalsOnlySamples.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dirName", ",", "\n", "dataset_initializers", ",", "\n", "dataset_handles", ",", "\n", "handle", ",", "\n", "n_samples_ph", ",", "\n", "distsample", ",", "\n", "raw_x", ",", "\n", "x", ",", "\n", "y", ",", "\n", "parameters_list", ",", "\n", "posterior_samples", "=", "2500", ",", "\n", "n_batches", "=", "-", "1", ",", "\n", "extra_nodes_to_collect", "=", "[", "]", ",", "\n", "extra_nodes_names", "=", "[", "]", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dirName", ",", "\n", "dataset_initializers", ",", "\n", "dataset_handles", ",", "\n", "handle", ",", "\n", "n_samples_ph", ",", "\n", "distsample", ",", "\n", "raw_x", ",", "\n", "x", ",", "\n", "y", ",", "\n", "posterior_samples", "=", "posterior_samples", ",", "\n", "n_batches", "=", "n_batches", ",", "\n", "extra_nodes_to_collect", "=", "extra_nodes_to_collect", ",", "\n", "extra_nodes_names", "=", "extra_nodes_names", ")", "\n", "\n", "\n", "self", ".", "_parameters_list", "=", "parameters_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression._stats_and_plot": [[50, 65], ["scipy.stats.skew", "scipy.stats.kurtosis", "open", "f.write", "f.write", "ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression._triangle_plot", "matplotlib.pyplot.close", "print", "print", "ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression._create_name", "ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression._create_name", "traceback.format_exc"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression._triangle_plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["", "def", "_stats_and_plot", "(", "self", ",", "baseName", ",", "batch_samples_list", ",", "real_valu_list", ",", "extra_batch_dict", ")", ":", "\n", "        ", "these_samples", "=", "batch_samples_list", "[", "0", "]", "[", "0", "]", ".", "T", "\n", "these_y", "=", "real_valu_list", "[", "0", "]", "[", "0", "]", "\n", "skewness", "=", "scipy", ".", "stats", ".", "skew", "(", "these_samples", ",", "axis", "=", "0", ")", "\n", "kurtosis", "=", "scipy", ".", "stats", ".", "kurtosis", "(", "these_samples", ",", "axis", "=", "0", ")", "\n", "with", "open", "(", "self", ".", "_create_name", "(", "\"stats_contours\"", ",", "baseName", ")", "+", "'.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"skewness: {:}\\n\"", ".", "format", "(", "skewness", ")", ")", "\n", "f", ".", "write", "(", "\"kurtosis: {:}\\n\"", ".", "format", "(", "kurtosis", ")", ")", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "_triangle_plot", "(", "these_samples", ",", "these_y", ",", "self", ".", "_create_name", "(", "\"contours\"", ",", "baseName", ")", "+", "'.pdf'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"ERROR: an Error occurred with plotGTC, continuing training... \\n\"", ")", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ConfidenceIntervalsOnlySamplesRegression.ConfidenceIntervalsOnlySamplesRegression._triangle_plot": [[66, 102], ["len", "getdist.plots.getSubplotPlotter", "getdist.MCSamples", "getdist.MCSamples.updateSettings", "getdist.plots.getSubplotPlotter.triangle_plot", "len", "range", "getdist.plots.getSubplotPlotter.export", "range", "ax.axvline", "ax.axhline"], "methods", ["None"], ["", "", "def", "_triangle_plot", "(", "self", ",", "these_samples", ",", "these_y", ",", "plotname", ")", ":", "\n", "        ", "names", "=", "self", ".", "_parameters_list", "\n", "labels", "=", "[", "]", "\n", "\n", "level_lines", "=", "[", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", ",", "0.95", ",", "0.98", "]", "\n", "\n", "num_level_lines", "=", "len", "(", "level_lines", ")", "\n", "g", "=", "plots", ".", "getSubplotPlotter", "(", "width_inch", "=", "9", ")", "\n", "g", ".", "settings", ".", "num_plot_contours", "=", "num_level_lines", "\n", "\n", "mcsamples", "=", "MCSamples", "(", "samples", "=", "these_samples", ",", "names", "=", "names", ",", "labels", "=", "names", ")", "\n", "mcsamples", ".", "updateSettings", "(", "{", "'contours'", ":", "level_lines", "}", ")", "\n", "\n", "g", ".", "triangle_plot", "(", "[", "mcsamples", "]", ",", "names", ",", "\n", "# filled_compare=True,", "\n", "legend_labels", "=", "labels", ",", "\n", "legend_loc", "=", "'upper right'", ",", "\n", "# filled=False,", "\n", "contour_colors", "=", "[", "'darkblue'", ",", "'green'", "]", ",", "\n", "#                     filled=True,", "\n", "#                     contour_lws=[.2, .4, .68, .95, .98]", "\n", ")", "\n", "\n", "n_params", "=", "len", "(", "names", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_params", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "n_params", ")", ":", "\n", "                ", "if", "j", ">", "i", ":", "\n", "                    ", "continue", "\n", "\n", "", "ax", "=", "g", ".", "subplots", "[", "i", ",", "j", "]", "\n", "ax", ".", "axvline", "(", "these_y", "[", "j", "]", ",", "color", "=", "'black'", ",", "ls", "=", "'--'", ",", "alpha", "=", "0.4", ")", "\n", "if", "i", "!=", "j", ":", "\n", "                    ", "ax", ".", "axhline", "(", "these_y", "[", "i", "]", ",", "color", "=", "'black'", ",", "ls", "=", "'-.'", ",", "alpha", "=", "0.4", ")", "\n", "\n", "", "", "", "g", ".", "export", "(", "plotname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ImageReconstructHook.ImagesReconstructHook.do_when_triggered": [[13, 47], ["tf_logging.info", "ImageReconstructHook.ImagesReconstructHook.load_images", "ImageReconstructHook.ImagesReconstructHook._model.encode", "ImageReconstructHook.ImagesReconstructHook._model.decode", "ImageReconstructHook.ImagesReconstructHook._model.decode", "int", "range", "ImageReconstructHook.ImagesReconstructHook.images_saver.save_images", "numpy.ceil", "range", "range", "panel[].append", "panel[].append", "panel[].append", "panel[].append", "panel[].append", "len", "str().zfill", "len", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.AbstractImagesReconstructHook.AbstractImagesReconstructHook.load_images", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.encode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractAutoEncoder.AbstractAutoEncoder.decode", "home.repos.pwc.inspect_result.rist-ro_argo.utils.ImagesSaver.ImagesSaver.save_images"], ["    ", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "# tf_logging.info(\"trigger for ImagesGeneratorHook s\" +  str(global_step) + \" s/e\" + str(global_step/global_epoch)+ \" e\" + str(global_epoch))", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for ImagesReconstructHook\"", ")", "\n", "\n", "self", ".", "load_images", "(", "run_context", ".", "session", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_images", ":", "\n", "            ", "images", "=", "self", ".", "_images", "[", "ds_key", "]", "[", "1", "]", "\n", "zs", ",", "means", "=", "self", ".", "_model", ".", "encode", "(", "images", ",", "run_context", ".", "session", ")", "\n", "reconstructed_images_m_means", ",", "reconstructed_images_m_sample", "=", "self", ".", "_model", ".", "decode", "(", "means", ",", "run_context", ".", "session", ")", "\n", "reconstructed_images_z_means", ",", "reconstructed_images_z_sample", "=", "self", ".", "_model", ".", "decode", "(", "zs", ",", "run_context", ".", "session", ")", "\n", "\n", "rows", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "_n_images_columns", ")", ")", "\n", "panel", "=", "[", "[", "]", "for", "x", "in", "range", "(", "rows", "*", "5", ")", "]", "\n", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "5", "*", "rows", ",", "5", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "self", ".", "_n_images_columns", ")", ":", "\n", "                    ", "panel", "[", "i", "]", ".", "append", "(", "images", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "1", "]", ".", "append", "(", "reconstructed_images_m_means", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "2", "]", ".", "append", "(", "reconstructed_images_m_sample", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "3", "]", ".", "append", "(", "reconstructed_images_z_means", "[", "c", "]", ")", "\n", "panel", "[", "i", "+", "4", "]", ".", "append", "(", "reconstructed_images_z_sample", "[", "c", "]", ")", "\n", "if", "c", "==", "len", "(", "images", ")", "-", "1", ":", "\n", "                        ", "break", "\n", "", "else", ":", "\n", "                        ", "c", "=", "c", "+", "1", "\n", "\n", "# \"[1st] original image [2nd] recostructed  mean [3rd] reconstr z\"", "\n", "", "", "", "self", ".", "images_saver", ".", "save_images", "(", "panel", ",", "\n", "fileName", "=", "\"reconstruction_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "self", ".", "_time_ref_shortstr", "+", "\"_\"", "+", "str", "(", "\n", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", ",", "\n", "title", "=", "self", ".", "_plot_title", ",", "\n", "fontsize", "=", "9", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.__init__": [[56, 93], ["model._get_steps", "argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "list", "list", "print", "list", "HMFisherMatrixHook2.HMFisherMatrixHook2._saved_matrices.keys", "set", "HMFisherMatrixHook2.HMFisherMatrixHook2._saved_matrices.values", "k.split"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.TFDeepLearningModel._get_steps", "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "dirName", ",", "\n", "period", ",", "\n", "train_loop_key", "=", "TRAIN_LOOP", ",", "\n", "time_reference", "=", "\"epochs\"", "\n", ")", ":", "\n", "\n", "        ", "dirName", "=", "dirName", "+", "'/fisher'", "\n", "fileName", "=", "\"fisher_matrix\"", "\n", "average_steps", "=", "model", ".", "_get_steps", "(", "period", ",", "time_reference", ")", "\n", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "period", "=", "average_steps", ",", "time_reference", "=", "time_reference", ",", "dataset_keys", "=", "[", "TRAIN", "]", ",", "\n", "dirName", "=", "dirName", ",", "trigger_summaries", "=", "False", ",", "\n", "plot_offset", "=", "0", ")", "\n", "\n", "self", ".", "_saved_matrices", "=", "self", ".", "_model", ".", "_optimizer", ".", "_saves", "\n", "\n", "values", "=", "list", "(", "self", ".", "_saved_matrices", ".", "values", "(", ")", ")", "+", "[", "self", ".", "_model", ".", "_optimizer", ".", "_diagonal_pad", "]", "\n", "keys", "=", "list", "(", "self", ".", "_saved_matrices", ".", "keys", "(", ")", ")", "\n", "self", ".", "layers", "=", "list", "(", "set", "(", "[", "k", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "for", "k", "in", "keys", "]", ")", ")", "\n", "keys", "+=", "[", "\"d_pad\"", "]", "\n", "\n", "self", ".", "_tensors_to_average", "=", "[", "\n", "[", "[", "v", "]", "for", "v", "in", "values", "]", ",", "\n", "]", "\n", "\n", "self", ".", "_tensors_names", "=", "[", "\n", "[", "[", "k", "]", "for", "k", "in", "keys", "]", ",", "\n", "]", "\n", "\n", "self", ".", "_tensors_plots", "=", "[", "\n", "[", "{", "\n", "\"fileName\"", ":", "k", "}", "for", "k", "in", "keys", "]", "\n", "]", "\n", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "print", "(", "\"HMFisherMatrixHook2 has been enabled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.calc_values": [[94, 110], ["run_context.session.run", "run_context.session.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "calc_values", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "\n", "        ", "run_context", ".", "session", ".", "run", "(", "self", ".", "_ds_initializers", ")", "\n", "\n", "# mean over the other dataset_keys", "\n", "# for i, (tensors_vertical_panel, files_panel) in enumerate(zip(self._tensors_names,", "\n", "#                                                               self._tensors_plots)):", "\n", "#", "\n", "#     if len(tensors_vertical_panel) > 0:", "\n", "#", "\n", "#         # here it start the vertical panel", "\n", "#         for j, (tensors_names_panel, file_save) in enumerate(zip(tensors_vertical_panel, files_panel)):", "\n", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "            ", "self", ".", "_tensors_values", "[", "dataset_str", "]", "=", "run_context", ".", "session", ".", "run", "(", "\n", "self", ".", "_tensors_to_average", ",", "feed_dict", "=", "{", "\n", "self", ".", "_ds_handle", ":", "self", ".", "_ds_handles", "[", "dataset_str", "]", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.after_run": [[112, 121], ["super().after_run", "tf_logging.info", "run_context.session.run", "HMFisherMatrixHook2.HMFisherMatrixHook2.cast_time_ref", "HMFisherMatrixHook2.HMFisherMatrixHook2.calc_values"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.after_run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook.cast_time_ref", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.calc_values"], ["", "", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "if", "self", ".", "_trigged_for_step", ":", "\n", "            ", "tf_logging", ".", "info", "(", "\"trigger for HMFisherMatrixHook2\"", ")", "\n", "time_ref", "=", "run_context", ".", "session", ".", "run", "(", "self", ".", "_time_reference_node", ")", "\n", "self", ".", "_time_ref", "=", "self", ".", "cast_time_ref", "(", "time_ref", ")", "\n", "\n", "self", ".", "calc_values", "(", "run_context", ",", "run_values", ")", "\n", "\n", "", "super", "(", ")", ".", "after_run", "(", "run_context", ",", "run_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot": [[122, 206], ["enumerate", "zip", "len", "enumerate", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "numpy.load", "zip", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_matrices", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "numpy.save", "len", "numpy.absolute", "HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "numpy.transpose", "numpy.einsum", "numpy.absolute", "numpy.absolute.ravel", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "matplotlib.figure", "matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.savefig", "matplotlib.savefig", "HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "numpy.save", "numpy.asarray", "HMFisherMatrixHook2.HMFisherMatrixHook2.keys", "numpy.einsum", "len", "numpy.absolute", "HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "numpy.absolute", "HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "len", "matplotlib.figure", "matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.savefig", "matplotlib.savefig", "m.ravel.ravel.ravel", "matplotlib.figure", "matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.savefig", "matplotlib.savefig", "numpy.expand_dims", "HMFisherMatrixHook2.HMFisherMatrixHook2.keys", "len", "numpy.absolute", "HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "ValueError", "numpy.eye", "HMFisherMatrixHook2.HMFisherMatrixHook2.keys", "numpy.absolute.keys"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_matrices", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix"], ["", "def", "plot", "(", "self", ")", ":", "\n", "        ", "for", "i", ",", "(", "tensors_vertical_panel", ",", "files_panel", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ")", ":", "\n", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "\n", "# here it start the vertical panel", "\n", "                ", "for", "j", ",", "(", "tensors_names_panel", ",", "file_save", ")", "in", "enumerate", "(", "zip", "(", "tensors_vertical_panel", ",", "files_panel", ")", ")", ":", "\n", "\n", "                    ", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "                        ", "filePath", "=", "self", ".", "get_file_path", "(", "file_save", "[", "\"fileName\"", "]", ")", "\n", "d", "=", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "[", "0", "]", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "if", "file_save", "[", "\"fileName\"", "]", "!=", "\"d_pad\"", ":", "\n", "                            ", "filePath", "=", "self", ".", "get_file_path", "(", "file_save", "[", "\"fileName\"", "]", ",", "extra", "=", "\"step\"", ")", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "\n", "m", "=", "np", ".", "asarray", "(", "d", ")", "\n", "\n", "if", "len", "(", "m", ".", "shape", ")", "==", "1", ":", "\n", "                                ", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "m", ",", "bins", "=", "100", ")", "\n", "plt", ".", "savefig", "(", "filePath", "+", "'.png'", ")", "\n", "", "else", ":", "\n", "                                ", "m", "=", "m", ".", "ravel", "(", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "m", ",", "bins", "=", "100", ")", "\n", "plt", ".", "savefig", "(", "filePath", "+", "'.png'", ")", "\n", "\n", "", "", "", "", "filePath", "=", "self", ".", "get_file_path", "(", "\"d_pad\"", ")", "\n", "d_pad", "=", "np", ".", "load", "(", "filePath", "+", "'.npy'", ")", "\n", "for", "l", "in", "self", ".", "layers", ":", "\n", "                    ", "M_s", "=", "self", ".", "get_matrices", "(", "l", ")", "\n", "\n", "if", "len", "(", "M_s", ".", "keys", "(", ")", ")", "==", "3", ":", "\n", "                        ", "bias_name", "=", "l", "+", "\"_B\"", "\n", "bias", "=", "M_s", "[", "bias_name", "]", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "bias", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "self", ".", "plot_matrix", "(", "M", ",", "bias_name", ")", "\n", "\n", "U_name", "=", "l", "+", "\"_U\"", "\n", "U", "=", "M_s", "[", "U_name", "]", "\n", "\n", "V_T", "=", "np", ".", "transpose", "(", "U", ",", "axes", "=", "[", "1", ",", "0", "]", ")", "\n", "MII_name", "=", "l", "+", "\"_MII\"", "\n", "MII", "=", "M_s", "[", "MII_name", "]", "\n", "\n", "M2", "=", "np", ".", "einsum", "(", "'ij,ljk->lik'", ",", "U", ",", "np", ".", "einsum", "(", "'lij,jk->lik'", ",", "MII", ",", "V_T", ")", ")", "\n", "\n", "M", "=", "d_pad", "*", "np", ".", "expand_dims", "(", "np", ".", "eye", "(", "M2", ".", "shape", "[", "-", "1", "]", ")", ",", "axis", "=", "0", ")", "-", "M2", "\n", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "M", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "# Let's see", "\n", "m", "=", "M", ".", "ravel", "(", ")", "\n", "filePath", "=", "self", ".", "get_file_path", "(", "l", "+", "\"_MI\"", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "m", ",", "bins", "=", "100", ")", "\n", "plt", ".", "savefig", "(", "filePath", "+", "'.png'", ")", "\n", "\n", "self", ".", "plot_matrix", "(", "M", ",", "l", "+", "\"_INV\"", ")", "\n", "", "elif", "len", "(", "M_s", ".", "keys", "(", ")", ")", "==", "2", ":", "\n", "\n", "                        ", "bias_name", "=", "l", "+", "\"_B\"", "\n", "bias", "=", "M_s", "[", "bias_name", "]", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "bias", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "\n", "self", ".", "plot_matrix", "(", "M", ",", "bias_name", ")", "\n", "\n", "mi_name", "=", "l", "+", "\"_MI\"", "\n", "mi", "=", "M_s", "[", "mi_name", "]", "\n", "M", "=", "np", ".", "absolute", "(", "mi", ")", "\n", "self", ".", "plot_matrix", "(", "M", ",", "mi_name", ")", "\n", "\n", "", "elif", "len", "(", "M_s", ".", "keys", "(", ")", ")", "==", "1", ":", "\n", "                        ", "bias_name", "=", "l", "+", "\"_B\"", "\n", "bias", "=", "M_s", "[", "bias_name", "]", "\n", "M", "=", "(", "(", "1.0", "+", "d_pad", ")", "/", "d_pad", ")", "*", "bias", "\n", "M", "=", "np", ".", "absolute", "(", "M", ")", "\n", "self", ".", "plot_matrix", "(", "M", ",", "bias_name", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", "\"Invalid amount of matrices '{}'\"", ".", "format", "(", "M", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot_matrix": [[207, 211], ["HMFisherMatrixHook2.fix", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "matplotlib.imsave", "matplotlib.imsave", "map", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.fix", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path"], ["", "", "", "", "", "def", "plot_matrix", "(", "self", ",", "M", ",", "name", ")", ":", "\n", "        ", "M", ",", "shap", "=", "fix", "(", "M", ")", "\n", "filePath", "=", "self", ".", "get_file_path", "(", "name", ",", "\".png\"", ",", "extra", "=", "\"x\"", ".", "join", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "shap", ")", ")", ")", "\n", "plt", ".", "imsave", "(", "filePath", ",", "M", ",", "cmap", "=", "\"gray\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.log_to_file_and_screen": [[212, 228], ["enumerate", "zip", "len", "enumerate", "zip", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "numpy.save", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "numpy.save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "def", "log_to_file_and_screen", "(", "self", ",", "log_to_screen", "=", "False", ")", ":", "\n", "\n", "        ", "for", "i", ",", "(", "tensors_vertical_panel", ",", "files_panel", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_tensors_names", ",", "\n", "self", ".", "_tensors_plots", ")", ")", ":", "\n", "\n", "            ", "if", "len", "(", "tensors_vertical_panel", ")", ">", "0", ":", "\n", "# here it start the vertical panel", "\n", "                ", "for", "j", ",", "(", "tensors_names_panel", ",", "file_save", ")", "in", "enumerate", "(", "zip", "(", "tensors_vertical_panel", ",", "files_panel", ")", ")", ":", "\n", "                    ", "for", "dataset_str", "in", "self", ".", "_datasets_keys", ":", "\n", "                        ", "filePath", "=", "self", ".", "get_file_path", "(", "file_save", "[", "\"fileName\"", "]", ")", "\n", "d", "=", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "[", "0", "]", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "\n", "filePath", "=", "self", ".", "get_file_path", "(", "file_save", "[", "\"fileName\"", "]", ",", "extra", "=", "\"step\"", ")", "\n", "d", "=", "self", ".", "_tensors_values", "[", "dataset_str", "]", "[", "i", "]", "[", "j", "]", "[", "0", "]", "\n", "np", ".", "save", "(", "filePath", ",", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2._after_run": [[229, 231], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "_after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2._create_or_open_files": [[232, 234], ["None"], "methods", ["None"], ["", "def", "_create_or_open_files", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2._reset_file": [[235, 237], ["None"], "methods", ["None"], ["", "def", "_reset_file", "(", "self", ",", "session", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.end": [[238, 240], ["None"], "methods", ["None"], ["", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path": [[241, 244], ["str().zfill", "str"], "methods", ["None"], ["", "def", "get_file_path", "(", "self", ",", "name", ",", "type", "=", "\"\"", ",", "extra", "=", "\"\"", ")", ":", "\n", "        ", "return", "self", ".", "_dirName", "+", "'/{}_'", ".", "format", "(", "name", ")", "+", "extra", "+", "\"_\"", "+", "self", ".", "_time_reference_str", "[", "0", "]", "+", "str", "(", "\n", "self", ".", "_time_ref", ")", ".", "zfill", "(", "4", ")", "+", "'{}'", ".", "format", "(", "type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_matrices": [[245, 249], ["numpy.asarray().reshape", "list", "filter", "numpy.load", "numpy.asarray", "HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.get_file_path"], ["", "def", "get_matrices", "(", "self", ",", "layer", ")", ":", "\n", "        ", "flat", "=", "np", ".", "asarray", "(", "self", ".", "_tensors_names", ")", ".", "reshape", "(", "[", "-", "1", "]", ")", "\n", "matrices", "=", "list", "(", "filter", "(", "lambda", "i", ":", "layer", "in", "i", ",", "flat", ")", ")", "\n", "return", "{", "m", ":", "np", ".", "load", "(", "self", ".", "get_file_path", "(", "m", ",", "'.npy'", ")", ")", "for", "m", "in", "matrices", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.get_closest_to_square_divisor": [[16, 24], ["numpy.sqrt", "range", "int"], "function", ["None"], ["def", "get_closest_to_square_divisor", "(", "number", ")", ":", "\n", "    ", "sq", "=", "np", ".", "sqrt", "(", "number", ")", "\n", "nv", "=", "1", "\n", "for", "i", "in", "range", "(", "int", "(", "sq", ")", ",", "0", ",", "-", "1", ")", ":", "\n", "        ", "if", "number", "%", "i", "==", "0", ":", "\n", "            ", "nv", "=", "i", "\n", "break", "\n", "", "", "return", "nv", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.stich": [[26, 37], ["HMFisherMatrixHook2.get_closest_to_square_divisor", "M.reshape", "numpy.empty", "range", "range"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.get_closest_to_square_divisor"], ["", "def", "stich", "(", "M", ")", ":", "\n", "    ", "nv", "=", "get_closest_to_square_divisor", "(", "M", ".", "shape", "[", "0", "]", ")", "\n", "x", "=", "M", ".", "reshape", "(", "[", "nv", ",", "-", "1", ",", "*", "M", ".", "shape", "[", "1", ":", "]", "]", ")", "\n", "new_shape", "=", "x", ".", "shape", "\n", "pic", "=", "np", ".", "empty", "(", "[", "x", ".", "shape", "[", "0", "]", "*", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "1", "]", "*", "x", ".", "shape", "[", "3", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "x", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "k", "=", "x", ".", "shape", "[", "2", "]", "\n", "l", "=", "x", ".", "shape", "[", "3", "]", "\n", "pic", "[", "i", "*", "k", ":", "i", "*", "k", "+", "k", ",", "j", "*", "l", ":", "j", "*", "l", "+", "l", "]", "=", "x", "[", "i", ",", "j", ",", ":", ",", ":", "]", "\n", "", "", "return", "pic", ",", "new_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.fix": [[39, 49], ["len", "M.reshape", "len", "HMFisherMatrixHook2.stich"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.stich"], ["", "def", "fix", "(", "M", ")", ":", "\n", "    ", "if", "len", "(", "M", ".", "shape", ")", "==", "1", ":", "\n", "        ", "M_m", "=", "M", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "shap", "=", "M_m", ".", "shape", "\n", "", "elif", "len", "(", "M", ".", "shape", ")", "==", "2", ":", "\n", "        ", "M_m", "=", "M", "\n", "shap", "=", "M_m", ".", "shape", "\n", "", "else", ":", "\n", "        ", "M_m", ",", "shap", "=", "stich", "(", "M", ")", "\n", "", "return", "M_m", ",", "shap", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.__init__": [[15, 41], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "tensorboard_dir", ",", "\n", "print_to_screen", "=", "True", ",", "\n", "sample_size", "=", "10000", ",", "\n", "dirName", "=", "None", ",", "fileName", "=", "\"truekl\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "[", "TRAIN", "]", ",", "dirName", "=", "dirName", ",", "\n", "tensorboard_dir", "=", "tensorboard_dir", ",", "trigger_summaries", "=", "False", ",", "plot_offset", "=", "0", ")", "\n", "self", ".", "sample_size", "=", "sample_size", "\n", "self", ".", "_dirName", "=", "dirName", "\n", "\n", "self", ".", "_print_to_screen", "=", "print_to_screen", "\n", "self", ".", "_tensorboard_dir", "=", "tensorboard_dir", "\n", "\n", "self", ".", "_tensors_to_average", "=", "None", "\n", "\n", "self", ".", "_tensors_names", "=", "[", "[", "[", "\"uniform\"", ",", "\"true-kl\"", ",", "\"accuracy\"", "]", "]", "]", "\n", "self", ".", "_tensors_plots", "=", "[", "[", "{", "\n", "'fileName'", ":", "fileName", ",", "\n", "'logscale-y'", ":", "0", "}", "]", "]", "\n", "self", ".", "_tensors_values", "=", "{", "}", "\n", "self", ".", "_fileName", "=", "fileName", "\n", "\n", "self", ".", "_x_flat", "=", "np", ".", "prod", "(", "self", ".", "_model", ".", "dataset", ".", "x_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.begin": [[42, 49], ["super().begin", "ThreeByThreeHook.ThreeByThreeHook._define_true_likelihood", "ThreeByThreeHook.ThreeByThreeHook._define_true_kl", "ThreeByThreeHook.ThreeByThreeHook._register_summeries"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.begin", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._define_true_likelihood", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._define_true_kl", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._register_summeries"], ["", "def", "begin", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "begin", "(", ")", "\n", "\n", "self", ".", "_define_true_likelihood", "(", ")", "\n", "self", ".", "_define_true_kl", "(", ")", "\n", "\n", "self", ".", "_register_summeries", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.safe_loop_session_run": [[50, 62], ["Exception", "session.run", "type", "session.run", "session.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "safe_loop_session_run", "(", "self", ",", "session", ",", "nodes", ",", "init_ops", ",", "feed_dict", ")", ":", "\n", "\n", "        ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "            ", "raise", "Exception", "(", "\"I need a raw session to evaluate metric over dataset.\"", ")", "\n", "\n", "", "result", "=", "None", "\n", "try", ":", "\n", "            ", "result", "=", "session", ".", "run", "(", "nodes", ",", "feed_dict", "=", "{", "**", "feed_dict", "}", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "            ", "session", ".", "run", "(", "init_ops", ")", "\n", "result", "=", "session", ".", "run", "(", "nodes", ",", "feed_dict", "=", "{", "**", "feed_dict", "}", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.do_when_triggered": [[63, 74], ["tf_logging.info", "ThreeByThreeHook.ThreeByThreeHook.safe_loop_session_run", "ThreeByThreeHook.ThreeByThreeHook.log_to_file_and_screen"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook.safe_loop_session_run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.log_to_file_and_screen"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "tf_logging", ".", "info", "(", "\"trigger for ThreeByThreeHook\"", ")", "\n", "\n", "true_kl", ",", "uniform_kl2", ",", "good_gen", ",", "bad_gen", "=", "self", ".", "safe_loop_session_run", "(", "\n", "run_context", ".", "session", ",", "[", "self", ".", "true_kl", ",", "self", ".", "uniform_kl2", ",", "self", ".", "good_gen", ",", "self", ".", "bad_gen", "]", ",", "\n", "self", ".", "_ds_initializers", ",", "feed_dict", "=", "{", "\n", "self", ".", "_model", ".", "n_z_samples", ":", "1", ",", "self", ".", "_model", ".", "b_size", ":", "self", ".", "sample_size", "}", ")", "\n", "\n", "self", ".", "_tensors_values", "[", "TRAIN", "]", "=", "[", "[", "[", "uniform_kl2", ",", "true_kl", ",", "good_gen", "]", "]", "]", "\n", "\n", "self", ".", "log_to_file_and_screen", "(", "log_to_screen", "=", "self", ".", "_print_to_screen", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._define_true_likelihood": [[75, 85], ["numpy.zeros", "likelihood_pairs.keys", "numpy.asarray", "tensorflow.constant", "int", "str", "int"], "methods", ["None"], ["", "def", "_define_true_likelihood", "(", "self", ")", ":", "\n", "        ", "likelihood_pairs", "=", "{", "int", "(", "\"\"", ".", "join", "(", "str", "(", "int", "(", "x", ")", ")", "for", "x", "in", "pattern", ")", ",", "2", ")", ":", "likelihood", "for", "pattern", ",", "likelihood", "\n", "in", "self", ".", "_model", ".", "dataset", ".", "likelihood", "}", "\n", "\n", "probs_true", "=", "np", ".", "zeros", "(", "2", "**", "self", ".", "_x_flat", ")", "\n", "for", "i", "in", "likelihood_pairs", ".", "keys", "(", ")", ":", "\n", "            ", "probs_true", "[", "i", "]", "=", "likelihood_pairs", "[", "i", "]", "\n", "\n", "", "self", ".", "non_zeros", "=", "np", ".", "asarray", "(", "[", "i", ">", "0.0", "for", "i", "in", "probs_true", "]", ")", "\n", "self", ".", "probs_true", "=", "tf", ".", "constant", "(", "probs_true", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._define_true_kl": [[86, 111], ["tensorflow.reshape", "tensorflow.cast", "tensorflow.bincount", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "ThreeByThreeHook.ThreeByThreeHook._pm_cast", "tensorflow.map_fn", "tensorflow.reduce_sum", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.logical_not", "tensorflow.log", "tensorflow.log", "tensorflow.cast", "tensorflow.reverse", "tensorflow.range", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "numpy.asarray", "tensorflow.cast", "tensorflow.size"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._pm_cast", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "_define_true_kl", "(", "self", ")", ":", "\n", "        ", "maximum_bin", "=", "2", "**", "self", ".", "_x_flat", "\n", "\n", "def", "binary_array_to_int", "(", "binary_array", ")", ":", "\n", "            ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "tf", ".", "reverse", "(", "tensor", "=", "binary_array", ",", "axis", "=", "[", "0", "]", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "*", "2", "**", "tf", ".", "range", "(", "tf", ".", "cast", "(", "tf", ".", "size", "(", "binary_array", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ")", ")", "\n", "\n", "", "gen_samples", "=", "tf", ".", "reshape", "(", "self", ".", "_model", ".", "x_inferred", ",", "(", "self", ".", "_model", ".", "n_z_samples", "*", "self", ".", "_model", ".", "b_size", ",", "-", "1", ")", ")", "\n", "gen_samples_zero_one", "=", "tf", ".", "cast", "(", "self", ".", "_pm_cast", "(", "gen_samples", ")", ",", "tf", ".", "int32", ")", "\n", "\n", "self", ".", "probs_gen", "=", "tf", ".", "bincount", "(", "tf", ".", "map_fn", "(", "binary_array_to_int", ",", "gen_samples_zero_one", ")", ",", "minlength", "=", "maximum_bin", ",", "\n", "maxlength", "=", "maximum_bin", ")", "\n", "\n", "self", ".", "probs_gen", "=", "self", ".", "probs_gen", "/", "tf", ".", "reduce_sum", "(", "self", ".", "probs_gen", ")", "\n", "\n", "self", ".", "good_gen", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "boolean_mask", "(", "self", ".", "probs_gen", ",", "self", ".", "non_zeros", ")", ")", "\n", "self", ".", "bad_gen", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "boolean_mask", "(", "self", ".", "probs_gen", ",", "tf", ".", "logical_not", "(", "self", ".", "non_zeros", ")", ")", ")", "\n", "\n", "probs_true", "=", "self", ".", "probs_true", "\n", "\n", "self", ".", "true_kl", "=", "tf", ".", "reduce_sum", "(", "\n", "probs_true", "*", "(", "\n", "tf", ".", "log", "(", "tf", ".", "clip_by_value", "(", "self", ".", "probs_true", ",", "1e-6", ",", "1", ")", "/", "tf", ".", "clip_by_value", "(", "self", ".", "probs_gen", ",", "1e-6", ",", "1", ")", ")", ")", ")", "\n", "self", ".", "uniform_kl2", "=", "tf", ".", "reduce_sum", "(", "probs_true", "*", "(", "\n", "tf", ".", "log", "(", "tf", ".", "clip_by_value", "(", "self", ".", "probs_true", ",", "1e-6", ",", "1", ")", "/", "np", ".", "asarray", "(", "[", "1.0", "/", "maximum_bin", "]", "*", "maximum_bin", ",", "dtype", "=", "np", ".", "float64", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._register_summeries": [[112, 115], ["zip", "ThreeByThreeHook.ThreeByThreeHook._register_summary_for_tensor"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.ArgoHook.ArgoHook._register_summary_for_tensor"], ["", "def", "_register_summeries", "(", "self", ")", ":", "\n", "        ", "for", "(", "name", ",", "node", ")", "in", "zip", "(", "self", ".", "_tensors_names", "[", "0", "]", "[", "0", "]", ",", "[", "self", ".", "uniform_kl2", ",", "self", ".", "true_kl", ",", "self", ".", "good_gen", "]", ")", ":", "\n", "            ", "self", ".", "_register_summary_for_tensor", "(", "name", ",", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.ThreeByThreeHook.ThreeByThreeHook._pm_cast": [[116, 121], ["None"], "methods", ["None"], ["", "", "def", "_pm_cast", "(", "self", ",", "number", ")", ":", "\n", "        ", "if", "self", ".", "_model", ".", "dataset", ".", "_pm_one", ":", "\n", "            ", "return", "(", "number", "+", "1", ")", "/", "2", "\n", "", "else", ":", "\n", "            ", "return", "number", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.__init__": [[25, 44], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "dirName", ",", "\n", "datasets_keys", "=", "[", "VALIDATION", ",", "TEST", "]", ",", "\n", "posterior_samples", "=", "2500", ",", "\n", "n_batches", "=", "-", "1", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ",", "dataset_keys", "=", "datasets_keys", ",", "dirName", "=", "dirName", "+", "'/mc_dropout'", ")", "\n", "self", ".", "_default_plot_bool", "=", "False", "\n", "\n", "self", ".", "_parameters_list", "=", "self", ".", "_model", ".", "dataset", ".", "_parameters_list", "\n", "self", ".", "_n_batches", "=", "n_batches", "\n", "self", ".", "_posterior_samples", "=", "posterior_samples", "\n", "self", ".", "calibrated_value_Aleatoric", "=", "{", "}", "\n", "tf_logging", ".", "info", "(", "\"Create mcDropoutHook for: \\n\"", "+", "\", \"", ".", "join", "(", "datasets_keys", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.do_when_triggered": [[46, 56], ["tf_logging.info", "MCDropoutHook.MCDropoutHook._calculate_mc_dropout_calibrate", "MCDropoutHook.MCDropoutHook._calculate_mc_dropout", "tf_logging.info", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._calculate_mc_dropout_calibrate", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._calculate_mc_dropout"], ["", "def", "do_when_triggered", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "time_ref", "=", "self", ".", "_time_ref", "\n", "time_ref_str", "=", "self", ".", "_time_ref_shortstr", "\n", "tf_logging", ".", "info", "(", "\"trigger for mcDropoutHook\"", ")", "\n", "\n", "for", "ds_key", "in", "self", ".", "_datasets_keys", ":", "\n", "            ", "fileName", "=", "\"mc_\"", "+", "str", "(", "ds_key", ")", "+", "\"_\"", "+", "time_ref_str", "+", "\"_\"", "+", "str", "(", "time_ref", ")", ".", "zfill", "(", "4", ")", "\n", "self", ".", "calibrated_value_Aleatoric", "=", "self", ".", "_calculate_mc_dropout_calibrate", "(", "run_context", ".", "session", ",", "ds_key", ",", "fileName", ")", "\n", "self", ".", "_calculate_mc_dropout", "(", "run_context", ".", "session", ",", "ds_key", ",", "fileName", ")", "\n", "tf_logging", ".", "info", "(", "\"finished with %s\"", "%", "ds_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._calculate_mc_dropout_calibrate": [[58, 143], ["session.run", "MCDropoutHook.MCDropoutHook.calibrated_number", "Exception", "type", "session.run", "session.run", "batch_means.append", "batch_vars.append", "batch_covs.append", "batch_reals.append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.calibrated_number", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "", "def", "_calculate_mc_dropout_calibrate", "(", "self", ",", "session", ",", "ds_key", ",", "baseName", ",", "is_training_value", "=", "False", ")", ":", "\n", "        ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "            ", "raise", "Exception", "(", "\"I need a raw session to evaluate metric over dataset.\"", ")", "\n", "\n", "", "dataset_initializer", "=", "self", ".", "_ds_initializers", "[", "ds_key", "]", "\n", "dataset_handle", "=", "self", ".", "_ds_handles", "[", "ds_key", "]", "\n", "handle", "=", "self", ".", "_ds_handle", "\n", "model", "=", "self", ".", "_model", "\n", "parameters_list", "=", "self", ".", "_parameters_list", "\n", "\n", "\n", "# labels_min = self._labels_min", "\n", "# labels_max = self._labels_max", "\n", "# with open(self._create_name('max-min_info', baseName)+'.dat', 'w') as ft5:", "\n", "#     ft5.write(\"min_params  max_params\\n\")", "\n", "#     ft5.write(\"{} {} \\n\".format(labels_min, labels_max))", "\n", "\n", "\n", "init_ops", "=", "dataset_initializer", "\n", "session", ".", "run", "(", "init_ops", ")", "\n", "\n", "\n", "\n", "b", "=", "0", "\n", "N_calibrated_batches", "=", "1000", "*", "self", ".", "_n_batches", "\n", "batch_means", "=", "[", "]", "\n", "batch_vars", "=", "[", "]", "\n", "batch_covs", "=", "[", "]", "\n", "batch_reals", "=", "[", "]", "\n", "\n", "while", "True", ":", "\n", "\n", "\n", "\n", "            ", "try", ":", "\n", "# model.raw_x is the input before any noise addition (if present), we want to make sure we get the clean batch before noise", "\n", "                ", "batch_x", ",", "batch_y", "=", "session", ".", "run", "(", "[", "model", ".", "raw_x", ",", "model", ".", "y", "]", ",", "\n", "feed_dict", "=", "{", "model", ".", "is_training", ":", "is_training_value", ",", "\n", "handle", ":", "dataset_handle", ",", "\n", "model", ".", "n_samples_ph", ":", "1", "}", ")", "\n", "\n", "\n", "\n", "\n", "# model.x is the input after noise addition (if present), we want to make sure we feed x, so that noiose will not be added.", "\n", "\n", "\n", "samples", ",", "means", ",", "vars", ",", "covs", "=", "session", ".", "run", "(", "[", "model", ".", "prediction_sample", ",", "\n", "model", ".", "prediction_mean", ",", "\n", "model", ".", "prediction_variance", ",", "\n", "model", ".", "prediction_covariance", "]", ",", "\n", "feed_dict", "=", "{", "model", ".", "x", ":", "batch_x", ",", "\n", "model", ".", "is_training", ":", "is_training_value", ",", "\n", "handle", ":", "dataset_handle", "}", ")", "\n", "\n", "batch_means", ".", "append", "(", "means", ")", "\n", "batch_vars", ".", "append", "(", "vars", ")", "\n", "batch_covs", ".", "append", "(", "covs", ")", "\n", "batch_reals", ".", "append", "(", "batch_y", ")", "\n", "\n", "b", "+=", "1", "\n", "\n", "if", "b", "==", "N_calibrated_batches", ":", "\n", "                    ", "break", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "# np.save(self._create_name('calibration_batch_means', baseName), batch_means)", "\n", "# np.save(self._create_name('calibration_batch_covs', baseName), batch_covs)", "\n", "# np.save(self._create_name('calibration_batch_reals', baseName), batch_reals)", "\n", "\n", "", "", "calibrated_value", "=", "self", ".", "calibrated_number", "(", "batch_covs", "[", ":", "-", "1", "]", ",", "batch_means", "[", ":", "-", "1", "]", ",", "batch_reals", "[", ":", "-", "1", "]", ")", "\n", "# sumeT, ppf_run = self.CI_calibrate(", "\n", "#                         batch_covs,", "\n", "#                         batch_means,", "\n", "#                         batch_reals,", "\n", "#                         baseName,", "\n", "#                         alpha_calibrate=calibrated_value,", "\n", "#                         Aleatoric=1)", "\n", "# sumeT=np.array(sumeT)", "\n", "# ppf_run=np.array(ppf_run)", "\n", "# results_calibred=np.stack((sumeT,ppf_run)).T", "\n", "# np.save(self._create_name('ci_info_calibration', baseName), results_calibred)", "\n", "return", "calibrated_value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name": [[404, 406], ["None"], "methods", ["None"], ["", "", "def", "_create_name", "(", "self", ",", "prefix", ",", "baseName", ")", ":", "\n", "        ", "return", "self", ".", "_dirName", "+", "\"/\"", "+", "prefix", "+", "'_'", "+", "baseName", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.CI_calibrate": [[150, 167], ["MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core", "MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core", "matplotlib.pyplot.figure", "matplotlib.pyplot.scatter", "matplotlib.pyplot.scatter", "numpy.arange", "matplotlib.pyplot.plot", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "MCDropoutHook.MCDropoutHook._create_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["", "def", "CI_calibrate", "(", "self", ",", "total_covariance", ",", "mean_pred", ",", "rea_valu", ",", "baseName", ",", "alpha_calibrate", "=", "1", ",", "Aleatoric", "=", "0", ")", ":", "\n", "\n", "        ", "sumeT", ",", "ppf_run", "=", "self", ".", "general_ellip_counts_calibrate_core", "(", "total_covariance", ",", "mean_pred", ",", "rea_valu", ")", "\n", "sumeT_recali", ",", "ppf_run_recali", "=", "self", ".", "general_ellip_counts_calibrate_core", "(", "total_covariance", ",", "mean_pred", ",", "rea_valu", ",", "alpha_calibrate", ")", "\n", "\n", "fig_1", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "scatter", "(", "ppf_run", ",", "sumeT", ")", "\n", "plt", ".", "scatter", "(", "ppf_run_recali", ",", "sumeT_recali", ",", "label", "=", "'calibrated'", ")", "\n", "line_s1", "=", "np", ".", "arange", "(", "0.0", ",", "1", ",", "0.01", ")", "\n", "plt", ".", "plot", "(", "line_s1", ",", "line_s1", ",", "'r-'", ",", "alpha", "=", "0.1", ")", "\n", "plt", ".", "xlabel", "(", "'Confidence level'", ")", "\n", "plt", ".", "ylabel", "(", "'Estimated coverage probability'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "_create_name", "(", "\"calibration_{}\"", ".", "format", "(", "Aleatoric", ")", ",", "baseName", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", "fig_1", ")", "\n", "if", "Aleatoric", ":", "\n", "            ", "return", "sumeT", ",", "ppf_run", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate": [[168, 176], ["numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core"], ["", "", "def", "general_ellip_counts_calibrate", "(", "self", ",", "covariance", ",", "mean", ",", "real_values", ",", "alpha_ini", "=", "1", ")", ":", "\n", "\n", "        ", "shapes", "=", "np", ".", "array", "(", "mean", ")", ".", "shape", "\n", "shapes_batch", "=", "shapes", "[", "0", "]", "*", "shapes", "[", "1", "]", "\n", "means", "=", "np", ".", "array", "(", "mean", ")", ".", "reshape", "(", "shapes_batch", ",", "shapes", "[", "2", "]", ")", "\n", "reals", "=", "np", ".", "array", "(", "real_values", ")", ".", "reshape", "(", "shapes_batch", ",", "shapes", "[", "2", "]", ")", "\n", "covas", "=", "np", ".", "array", "(", "covariance", ")", ".", "reshape", "(", "shapes_batch", ",", "shapes", "[", "2", "]", ",", "shapes", "[", "2", "]", ")", "\n", "return", "self", ".", "general_ellip_counts_calibrate_core", "(", "covas", ",", "means", ",", "reals", ",", "alpha_ini", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate_core": [[177, 193], ["numpy.linalg.inv", "numpy.einsum", "list", "scipy.stats.chi2", "enumerate", "numpy.array", "numpy.arange", "len", "scipy.stats.chi2.ppf", "enumerate", "list", "list", "numpy.array"], "methods", ["None"], ["", "def", "general_ellip_counts_calibrate_core", "(", "self", ",", "covas", ",", "means", ",", "reals", ",", "alpha_ini", "=", "1", ")", ":", "\n", "        ", "shapes", "=", "np", ".", "array", "(", "means", ")", ".", "shape", "\n", "Inverse_covariance", "=", "np", ".", "linalg", ".", "inv", "(", "covas", ")", "\n", "Ellip_eq", "=", "np", ".", "einsum", "(", "'nl,nlm,mn->n'", ",", "(", "reals", "-", "means", ")", ",", "Inverse_covariance", ",", "(", "reals", "-", "means", ")", ".", "T", ")", "\n", "ppf_run", "=", "list", "(", "np", ".", "arange", "(", "0.1", ",", "1.0", ",", "0.035", ")", ")", "\n", "suma_T", "=", "[", "0", "]", "*", "len", "(", "ppf_run", ")", "\n", "rv", "=", "chi2", "(", "df", "=", "shapes", "[", "1", "]", ")", "\n", "for", "ix", ",", "ppf", "in", "enumerate", "(", "ppf_run", ")", ":", "\n", "            ", "square_norm", "=", "rv", ".", "ppf", "(", "ppf", ")", "\n", "values", "=", "Ellip_eq", "/", "(", "square_norm", "*", "alpha_ini", ")", "\n", "for", "ids", ",", "inst", "in", "enumerate", "(", "values", ")", ":", "\n", "                ", "if", "inst", "<=", "1", ":", "\n", "                    ", "suma_T", "[", "ix", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "", "", "return", "list", "(", "np", ".", "array", "(", "suma_T", ")", "/", "shapes", "[", "0", "]", ")", ",", "list", "(", "ppf_run", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.func": [[194, 196], ["scipy.stats.beta.cdf"], "methods", ["None"], ["", "def", "func", "(", "self", ",", "x", ",", "a", ",", "b", ")", ":", "\n", "        ", "return", "beta", ".", "cdf", "(", "x", ",", "a", ",", "b", ")", "\n", "", "def", "invfunc", "(", "self", ",", "x", ",", "a", ",", "b", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.invfunc": [[196, 198], ["scipy.stats.beta.ppf"], "methods", ["None"], ["", "def", "invfunc", "(", "self", ",", "x", ",", "a", ",", "b", ")", ":", "\n", "        ", "return", "beta", ".", "ppf", "(", "x", ",", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.mininizer": [[200, 207], ["MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate", "numpy.array", "numpy.array", "scipy.optimize.curve_fit", "MCDropoutHook.MCDropoutHook.func", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts_calibrate", "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.func"], ["", "def", "mininizer", "(", "self", ",", "datacov", ",", "datamean", ",", "datareal", ",", "x0", ",", "s", ")", ":", "\n", "        ", "sumat_Re", ",", "ppft_Re", "=", "self", ".", "general_ellip_counts_calibrate", "(", "datacov", ",", "datamean", ",", "datareal", ",", "s", ")", "\n", "column_2_Re", "=", "np", ".", "array", "(", "sumat_Re", ")", "\n", "column_1_Re", "=", "np", ".", "array", "(", "ppft_Re", ")", "\n", "results_calibred_Re", "=", "np", ".", "stack", "(", "(", "column_1_Re", ",", "column_2_Re", ")", ")", ".", "T", "\n", "popt1_Re", ",", "pcov1_Re", "=", "curve_fit", "(", "self", ".", "func", ",", "results_calibred_Re", "[", ":", ",", "0", "]", ",", "results_calibred_Re", "[", ":", ",", "1", "]", ")", "\n", "return", "self", ".", "func", "(", "x0", ",", "*", "popt1_Re", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.calibrated_number": [[208, 215], ["numpy.linspace", "numpy.linspace", "summa.append", "sum", "numpy.argmin", "numpy.abs", "MCDropoutHook.MCDropoutHook.mininizer"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.mininizer"], ["", "def", "calibrated_number", "(", "self", ",", "datacov", ",", "datamean", ",", "datareal", ")", ":", "\n", "        ", "x_val", "=", "np", ".", "linspace", "(", "0.2", ",", "1", ",", "100", ")", "\n", "y_val", "=", "np", ".", "linspace", "(", "0.1", ",", "3", ",", "50", ")", "\n", "summa", "=", "[", "]", "\n", "for", "s0", "in", "y_val", ":", "\n", "            ", "summa", ".", "append", "(", "sum", "(", "np", ".", "abs", "(", "self", ".", "mininizer", "(", "datacov", ",", "datamean", ",", "datareal", ",", "x_val", ",", "s0", ")", "-", "x_val", ")", ")", ")", "\n", "", "return", "y_val", "[", "np", ".", "argmin", "(", "summa", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._calculate_mc_dropout": [[218, 403], ["session.run", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "MCDropoutHook.MCDropoutHook.find_calibration", "MCDropoutHook.MCDropoutHook.samples_calibrated", "numpy.save", "Exception", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "MCDropoutHook.MCDropoutHook._create_name", "open", "ft1.write", "ft1.write", "ft1.write", "pygtc.plotGTC", "matplotlib.pyplot.close", "type", "session.run", "range", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "MCDropoutHook.MCDropoutHook.CI", "numpy.stack.append", "numpy.stack.append", "numpy.stack.append", "numpy.stack.append", "numpy.stack.append", "numpy.stack.append", "Batch_samples_stack_T.append", "Batch_means_stack_T.append", "Batch_covs_stack_T.append", "tf_logging.error", "tf_logging.error", "session.run", "batch_means.append", "batch_vars.append", "batch_covs.append", "batch_samples.append", "MCDropoutHook.MCDropoutHook._create_name", "traceback.format_exc", "numpy.transpose", "MCDropoutHook.MCDropoutHook._create_name"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.find_calibration", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.samples_calibrated", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.CI", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["", "def", "_calculate_mc_dropout", "(", "self", ",", "session", ",", "ds_key", ",", "baseName", ",", "is_training_value", "=", "False", ")", ":", "\n", "        ", "if", "type", "(", "session", ")", ".", "__name__", "!=", "'Session'", ":", "\n", "            ", "raise", "Exception", "(", "\"I need a raw session to evaluate metric over dataset.\"", ")", "\n", "\n", "", "dataset_initializer", "=", "self", ".", "_ds_initializers", "[", "ds_key", "]", "\n", "dataset_handle", "=", "self", ".", "_ds_handles", "[", "ds_key", "]", "\n", "handle", "=", "self", ".", "_ds_handle", "\n", "model", "=", "self", ".", "_model", "\n", "parameters_list", "=", "self", ".", "_parameters_list", "\n", "\n", "\n", "init_ops", "=", "dataset_initializer", "\n", "session", ".", "run", "(", "init_ops", ")", "\n", "\n", "count_68", "=", "0", "\n", "count_95", "=", "0", "\n", "count_99", "=", "0", "\n", "count_all", "=", "0", "\n", "cal_count_68", "=", "0", "\n", "cal_count_95", "=", "0", "\n", "cal_count_99", "=", "0", "\n", "cal_count_all", "=", "0", "\n", "\n", "means_means", "=", "[", "]", "\n", "covs_means", "=", "[", "]", "\n", "cal_means_covs", "=", "[", "]", "\n", "means_covs", "=", "[", "]", "\n", "\n", "Total_std", "=", "[", "]", "\n", "Total_covariance", "=", "[", "]", "\n", "cal_Total_std", "=", "[", "]", "\n", "Real_valu", "=", "[", "]", "\n", "Batch_samples_stack_T", "=", "[", "]", "\n", "Batch_means_stack_T", "=", "[", "]", "\n", "Batch_covs_stack_T", "=", "[", "]", "\n", "\n", "b", "=", "0", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "batch_means", "=", "[", "]", "\n", "batch_vars", "=", "[", "]", "\n", "batch_covs", "=", "[", "]", "\n", "cal_batch_vars", "=", "[", "]", "\n", "cal_batch_covs", "=", "[", "]", "\n", "batch_samples", "=", "[", "]", "\n", "\n", "try", ":", "\n", "# model.raw_x is the input before any noise addition (if present), we want to make sure we get the clean batch before noise", "\n", "                ", "batch_x", ",", "batch_y", "=", "session", ".", "run", "(", "[", "model", ".", "raw_x", ",", "model", ".", "y", "]", ",", "\n", "feed_dict", "=", "{", "model", ".", "is_training", ":", "is_training_value", ",", "\n", "handle", ":", "dataset_handle", ",", "\n", "model", ".", "n_samples_ph", ":", "1", "}", ")", "\n", "\n", "\n", "# model.x is the input after noise addition (if present), we want to make sure we feed x, so that noiose will not be added.", "\n", "for", "_", "in", "range", "(", "self", ".", "_posterior_samples", ")", ":", "\n", "\n", "                    ", "samples", ",", "means", ",", "varss", ",", "covs", "=", "session", ".", "run", "(", "[", "model", ".", "prediction_sample", ",", "\n", "model", ".", "prediction_mean", ",", "\n", "model", ".", "prediction_variance", ",", "\n", "model", ".", "prediction_covariance", "]", ",", "\n", "feed_dict", "=", "{", "model", ".", "x", ":", "batch_x", ",", "\n", "model", ".", "is_training", ":", "is_training_value", ",", "\n", "handle", ":", "dataset_handle", "}", ")", "\n", "##calibration###", "\n", "\n", "cal_varss", "=", "varss", "#*calibrated_valued", "\n", "cal_covs", "=", "covs", "#*calibrated_valued", "\n", "#                     ssa=[]", "\n", "#                     for i in range(means.shape[0]):", "\n", "#                         ssa.append(np.random.multivariate_normal(means[i,:], cal_covs[i,:,:]))", "\n", "#                     cal_samples = np.array(ssa)", "\n", "#                     ####end", "\n", "\n", "batch_means", ".", "append", "(", "means", ")", "\n", "batch_vars", ".", "append", "(", "varss", ")", "\n", "batch_covs", ".", "append", "(", "covs", ")", "\n", "#                     cal_batch_vars.append(cal_varss)", "\n", "#                     cal_batch_covs.append(cal_covs)", "\n", "batch_samples", ".", "append", "(", "samples", ")", "##calibr", "\n", "\n", "", "batch_means_stack", "=", "np", ".", "stack", "(", "batch_means", ",", "axis", "=", "2", ")", "\n", "batch_vars_stack", "=", "np", ".", "stack", "(", "batch_vars", ",", "axis", "=", "2", ")", "\n", "batch_covs_stack", "=", "np", ".", "stack", "(", "batch_covs", ",", "axis", "=", "3", ")", "\n", "#                 cal_batch_vars_stack = np.stack(cal_batch_vars, axis=2)", "\n", "#                 cal_batch_covs_stack = np.stack(cal_batch_covs, axis=3)", "\n", "batch_samples_stack", "=", "np", ".", "stack", "(", "batch_samples", ",", "axis", "=", "2", ")", "\n", "\n", "coverage_value_68", ",", "coverage_value_95", ",", "coverage_value_99", ",", "coverage_all", ",", "total_std", ",", "cov_pred_p", ",", "mean_covar_p", ",", "total_covariance", ",", "rea_valu", ",", "mean_pred", "=", "self", ".", "CI", "(", "\n", "batch_means_stack", ",", "\n", "batch_y", ",", "\n", "batch_vars_stack", ",", "\n", "batch_covs_stack", ",", "\n", "baseName", "=", "baseName", ")", "\n", "\n", "#                 cal_coverage_value_68, cal_coverage_value_95, cal_coverage_value_99, cal_coverage_all, \\", "\n", "#                     cal_total_std, cal_cov_pred_p, cal_mean_covar_p, cal_total_covariance, cal_rea_valu, cal_mean_pred = self.CI(", "\n", "#                                                         batch_means_stack,", "\n", "#                                                         batch_y,", "\n", "#                                                         cal_batch_vars_stack,", "\n", "#                                                         cal_batch_covs_stack,", "\n", "#                                                         baseName = \"cal_\"+baseName,", "\n", "#                                                         alpha_calibrate=calibrated_valued)", "\n", "\n", "# these are same for calibrated and uncalibrated", "\n", "means_means", ".", "append", "(", "mean_pred", ")", "\n", "covs_means", ".", "append", "(", "cov_pred_p", ")", "\n", "# this changes", "\n", "means_covs", ".", "append", "(", "mean_covar_p", ")", "\n", "#               cal_means_covs.append(cal_mean_covar_p)", "\n", "\n", "Total_std", ".", "append", "(", "total_std", ")", "\n", "Total_covariance", ".", "append", "(", "total_covariance", ")", "\n", "#               cal_Total_std.append(cal_total_std)", "\n", "\n", "Real_valu", ".", "append", "(", "rea_valu", ")", "\n", "Batch_samples_stack_T", ".", "append", "(", "batch_samples_stack", ")", "\n", "Batch_means_stack_T", ".", "append", "(", "batch_means_stack", ")", "\n", "Batch_covs_stack_T", ".", "append", "(", "batch_covs_stack", ")", "\n", "\n", "count_68", "+=", "coverage_value_68", "\n", "count_95", "+=", "coverage_value_95", "\n", "count_99", "+=", "coverage_value_99", "\n", "count_all", "+=", "coverage_all", "\n", "\n", "#                 cal_count_68 += cal_coverage_value_68", "\n", "#                 cal_count_95 += cal_coverage_value_95", "\n", "#                 cal_count_99 += cal_coverage_value_99", "\n", "#                 cal_count_all += cal_coverage_all", "\n", "\n", "b", "+=", "1", "\n", "\n", "if", "b", "==", "self", ".", "_n_batches", ":", "\n", "                    ", "break", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "\n", "", "", "means_means", "=", "np", ".", "stack", "(", "means_means", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "covs_means", "=", "np", ".", "stack", "(", "covs_means", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "means_covs", "=", "np", ".", "stack", "(", "means_covs", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "Total_std", "=", "np", ".", "stack", "(", "Total_std", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "Total_covariance", "=", "np", ".", "stack", "(", "Total_covariance", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "\n", "#        cal_means_covs = np.stack(cal_means_covs, axis=0)", "\n", "#        cal_Total_std = np.stack(cal_Total_std, axis=0)", "\n", "Real_valu", "=", "np", ".", "stack", "(", "Real_valu", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "Batch_samples_stack", "=", "np", ".", "stack", "(", "Batch_samples_stack_T", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "Batch_means_stack", "=", "np", ".", "stack", "(", "Batch_means_stack_T", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "Batch_covs_stack", "=", "np", ".", "stack", "(", "Batch_covs_stack_T", "[", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "\n", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'means_means'", ",", "baseName", ")", ",", "means_means", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'covs_means_'", ",", "baseName", ")", ",", "covs_means", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'means_covs_'", ",", "baseName", ")", ",", "means_covs", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'Total_std_'", ",", "baseName", ")", ",", "Total_std", ")", "\n", "#np.save(self._create_name('cal_means_covs_', baseName), cal_means_covs)", "\n", "#np.save(self._create_name('cal_Total_std_', baseName), cal_Total_std)", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'Real_valu_'", ",", "baseName", ")", ",", "Real_valu", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'batch_samples_'", ",", "baseName", ")", ",", "Batch_samples_stack", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'Batch_means_stack_'", ",", "baseName", ")", ",", "Batch_means_stack", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'Batch_covs_stack_'", ",", "baseName", ")", ",", "Batch_covs_stack", ")", "\n", "\n", "cal_count_68", ",", "cal_count_95", ",", "cal_count_99", ",", "calibrated_valued", "=", "self", ".", "find_calibration", "(", "Total_covariance", ",", "means_means", ",", "Real_valu", ",", "baseName", ")", "\n", "\n", "cal_samples", "=", "self", ".", "samples_calibrated", "(", "Batch_means_stack", ",", "Batch_covs_stack", ")", "\n", "np", ".", "save", "(", "self", ".", "_create_name", "(", "'cal_Batch_samples_stack'", ",", "baseName", ")", ",", "cal_samples", ")", "\n", "\n", "with", "open", "(", "self", ".", "_create_name", "(", "'ci_info'", ",", "baseName", ")", "+", "'.dat'", ",", "'w'", ")", "as", "ft1", ":", "\n", "            ", "ft1", ".", "write", "(", "\"count_68 count_95 count_99 count_all calibration\\n\"", ")", "\n", "ft1", ".", "write", "(", "\"{} {} {} {} {}\\n\"", ".", "format", "(", "count_68", ",", "count_95", ",", "count_99", ",", "count_all", ",", "self", ".", "calibrated_value_Aleatoric", ")", ")", "\n", "ft1", ".", "write", "(", "\"{} {} {} {} {}\\n\"", ".", "format", "(", "cal_count_68", ",", "cal_count_95", ",", "cal_count_99", ",", "count_all", ",", "calibrated_valued", ")", ")", "\n", "\n", "\n", "\n", "# batch_samples_stack = np.array(list(map(lambda x,y: np.random.multivariate_normal(mean = x, cov = y), batch_means_stack, batch_covs_stack)))", "\n", "", "try", ":", "\n", "            ", "GTC", "=", "pygtc", ".", "plotGTC", "(", "chains", "=", "[", "np", ".", "transpose", "(", "batch_samples_stack", "[", "0", "]", ")", "]", ",", "figureSize", "=", "5", ",", "nContourLevels", "=", "2", ",", "sigmaContourLevels", "=", "True", ",", "\n", "paramNames", "=", "parameters_list", ",", "plotName", "=", "self", ".", "_create_name", "(", "\"fullGTC\"", ",", "baseName", ")", "+", "'.pdf'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "tf_logging", ".", "error", "(", "\" an Error occurred with plotGTC, continuing training... \\n\"", ")", "\n", "tf_logging", ".", "error", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.samples_calibrated": [[407, 421], ["means_stack.reshape", "covs_stack.reshape", "range", "range", "ssa1.append", "numpy.stack", "ssa.append", "numpy.random.multivariate_normal"], "methods", ["None"], ["", "def", "samples_calibrated", "(", "self", ",", "means_stack", ",", "covs_stack", ",", "alpha_calibrate", "=", "1", ")", ":", "\n", "        ", "ssa1", "=", "[", "]", "\n", "shap", "=", "means_stack", ".", "shape", "\n", "shap_0", "=", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", "\n", "means_stack_reshaped", "=", "means_stack", ".", "reshape", "(", "shap_0", ",", "shap", "[", "2", "]", ",", "shap", "[", "3", "]", ")", "\n", "covariance_stack_reshaped", "=", "covs_stack", ".", "reshape", "(", "shap_0", ",", "shap", "[", "2", "]", ",", "shap", "[", "2", "]", ",", "shap", "[", "3", "]", ")", "\n", "covariance_stack_reshaped", "=", "covariance_stack_reshaped", "*", "alpha_calibrate", "\n", "for", "i", "in", "range", "(", "shap_0", ")", ":", "\n", "            ", "ssa", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "shap", "[", "3", "]", ")", ":", "\n", "                ", "ssa", ".", "append", "(", "np", ".", "random", ".", "multivariate_normal", "(", "means_stack_reshaped", "[", "i", ",", ":", ",", "j", "]", ",", "covariance_stack_reshaped", "[", "i", ",", ":", ",", ":", ",", "j", "]", ")", ")", "\n", "", "ssa1", ".", "append", "(", "ssa", ")", "\n", "", "cal_samples", "=", "np", ".", "stack", "(", "ssa1", ",", "axis", "=", "2", ")", ".", "T", "\n", "return", "cal_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.CI": [[423, 457], ["numpy.mean", "numpy.var", "numpy.array", "numpy.mean", "numpy.mean", "numpy.sqrt", "MCDropoutHook.MCDropoutHook.ellip_counts_3_sigmas", "matplotlib.pyplot.figure", "enumerate", "numpy.arange", "matplotlib.pyplot.plot", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "list", "matplotlib.pyplot.errorbar", "map", "MCDropoutHook.MCDropoutHook._create_name", "numpy.cov"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.ellip_counts_3_sigmas", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook._create_name"], ["", "def", "CI", "(", "self", ",", "predictions", ",", "rea_valu", ",", "variance_s", ",", "covariance_s", ",", "baseName", ",", "alpha_calibrate", "=", "1", ")", ":", "\n", "#  rea_valu=denormalize(rea_valu)", "\n", "        ", "batch_size", "=", "rea_valu", ".", "shape", "[", "0", "]", "\n", "\n", "mean_pred", "=", "np", ".", "mean", "(", "predictions", ",", "axis", "=", "2", ")", "\n", "var_pred", "=", "np", ".", "var", "(", "predictions", ",", "axis", "=", "2", ")", "\n", "# covariance over parameters only, for each example in the batch", "\n", "cov_pred", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "cov", "(", "x", ")", ",", "predictions", ")", ")", ")", "\n", "mean_var", "=", "np", ".", "mean", "(", "variance_s", ",", "axis", "=", "2", ")", "\n", "mean_covar", "=", "np", ".", "mean", "(", "covariance_s", ",", "axis", "=", "3", ")", "\n", "\n", "total_variance", "=", "var_pred", "+", "mean_var", "\n", "total_covariance", "=", "cov_pred", "+", "mean_covar", "\n", "total_std", "=", "np", ".", "sqrt", "(", "total_variance", ")", "\n", "sume68", ",", "sume95", ",", "sume99", "=", "self", ".", "ellip_counts_3_sigmas", "(", "total_covariance", ",", "mean_pred", ",", "rea_valu", ",", "alpha_calibrate", ")", "\n", "\n", "sumeT", "=", "batch_size", "#np.logical_and(rea_valu > confiden_inter_T_min, rea_valu < confiden_inter_T_max)", "\n", "\n", "fig_1", "=", "plt", ".", "figure", "(", ")", "\n", "\n", "for", "i", ",", "param_name", "in", "enumerate", "(", "self", ".", "_parameters_list", ")", ":", "\n", "            ", "plt", ".", "errorbar", "(", "rea_valu", "[", ":", ",", "i", "]", ",", "mean_pred", "[", ":", ",", "i", "]", ",", "total_std", "[", ":", ",", "i", "]", ",", "fmt", "=", "'o'", ",", "#color=colors[param_name], ecolor=ecolor[param_name],", "\n", "elinewidth", "=", "3", ",", "capsize", "=", "0", ",", "label", "=", "param_name", ")", "\n", "\n", "", "line_s1", "=", "np", ".", "arange", "(", "0.0", ",", "1", ",", "0.01", ")", "\n", "plt", ".", "plot", "(", "line_s1", ",", "line_s1", ",", "'r-'", ",", "alpha", "=", "0.1", ")", "\n", "plt", ".", "xlabel", "(", "'True value'", ")", "\n", "plt", ".", "ylabel", "(", "'Predicted value'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "self", ".", "_create_name", "(", "\"correlation\"", ",", "baseName", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", "fig_1", ")", "\n", "\n", "return", "sume68", ",", "sume95", ",", "sume99", ",", "sumeT", ",", "total_std", ",", "cov_pred", ",", "mean_covar", ",", "total_covariance", ",", "rea_valu", ",", "mean_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.ellip_counts_3_sigmas": [[458, 463], ["MCDropoutHook.MCDropoutHook.general_ellip_counts", "MCDropoutHook.MCDropoutHook.general_ellip_counts", "MCDropoutHook.MCDropoutHook.general_ellip_counts"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts"], ["", "def", "ellip_counts_3_sigmas", "(", "self", ",", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ")", ":", "\n", "        ", "sume68", "=", "self", ".", "general_ellip_counts", "(", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ",", "nstd", "=", "1", ")", "\n", "sume95", "=", "self", ".", "general_ellip_counts", "(", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ",", "nstd", "=", "2", ")", "\n", "sume99", "=", "self", ".", "general_ellip_counts", "(", "covariance", ",", "mean", ",", "rea_values", ",", "alpha_calibrate", ",", "nstd", "=", "3", ")", "\n", "return", "sume68", ",", "sume95", ",", "sume99", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.find_calibration": [[464, 474], ["means.reshape", "real.reshape", "covariance.reshape", "MCDropoutHook.MCDropoutHook.calibrated_number", "MCDropoutHook.MCDropoutHook.ellip_counts_3_sigmas", "MCDropoutHook.MCDropoutHook.CI_calibrate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.calibrated_number", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.ellip_counts_3_sigmas", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.CI_calibrate"], ["", "def", "find_calibration", "(", "self", ",", "covariance", ",", "means", ",", "real", ",", "baseName", ")", ":", "\n", "        ", "shap", "=", "means", ".", "shape", "\n", "\n", "means_reshaped", "=", "means", ".", "reshape", "(", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", ",", "shap", "[", "2", "]", ")", "\n", "real_reshaped", "=", "real", ".", "reshape", "(", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", ",", "shap", "[", "2", "]", ")", "\n", "covariance_reshaped", "=", "covariance", ".", "reshape", "(", "shap", "[", "0", "]", "*", "shap", "[", "1", "]", ",", "shap", "[", "2", "]", ",", "shap", "[", "2", "]", ")", "\n", "calibrated_value", "=", "self", ".", "calibrated_number", "(", "covariance", ",", "means", ",", "real", ")", "\n", "summe68", ",", "summe95", ",", "summe99", "=", "self", ".", "ellip_counts_3_sigmas", "(", "covariance_reshaped", ",", "means_reshaped", ",", "real_reshaped", ",", "alpha_calibrate", "=", "calibrated_value", ")", "\n", "self", ".", "CI_calibrate", "(", "covariance_reshaped", ",", "means_reshaped", ",", "real_reshaped", ",", "baseName", ",", "alpha_calibrate", "=", "calibrated_value", ")", "\n", "return", "summe68", ",", "summe95", ",", "summe99", ",", "calibrated_value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.hooks.MCDropoutHook.MCDropoutHook.general_ellip_counts": [[476, 498], ["numpy.linalg.inv", "numpy.einsum", "scipy.stats.chi2", "scipy.stats.chi2.ppf", "enumerate"], "methods", ["None"], ["", "def", "general_ellip_counts", "(", "self", ",", "covariance", ",", "mean", ",", "real_values", ",", "alpha_calibrate", "=", "1", ",", "nstd", "=", "1", ")", ":", "\n", "        ", "Inverse_covariance", "=", "np", ".", "linalg", ".", "inv", "(", "covariance", ")", "\n", "Ellip_eq", "=", "np", ".", "einsum", "(", "'nl,nlm,mn->n'", ",", "(", "real_values", "-", "mean", ")", ",", "Inverse_covariance", ",", "(", "real_values", "-", "mean", ")", ".", "T", ")", "\n", "if", "nstd", "==", "1", ":", "\n", "            ", "ppf", "=", "0.68", "\n", "", "if", "nstd", "==", "2", ":", "\n", "            ", "ppf", "=", "0.95", "\n", "", "if", "nstd", "==", "3", ":", "\n", "            ", "ppf", "=", "0.997", "\n", "\n", "", "rv", "=", "chi2", "(", "df", "=", "mean", ".", "shape", "[", "1", "]", ")", "\n", "square_norm", "=", "rv", ".", "ppf", "(", "ppf", ")", "\n", "\n", "values", "=", "Ellip_eq", "/", "(", "square_norm", "*", "alpha_calibrate", ")", "\n", "suma_T", "=", "0", "\n", "for", "ids", ",", "inst", "in", "enumerate", "(", "values", ")", ":", "\n", "            ", "if", "inst", "<=", "1", ":", "\n", "                ", "suma_T", "+=", "1", "\n", "# print(ids, inst)", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "", "", "return", "suma_T", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook.__init__": [[13, 34], ["argo.core.hooks.EveryNEpochsTFModelHook.EveryNEpochsTFModelHook.__init__", "os.path.join", "argo.core.hooks.LoggingMeanTensorsHook.tf_logging.info"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "period", ",", "\n", "time_reference", ",", "\n", "checkpoint_basename", "=", "\"model.ckpt\"", ")", ":", "\n", "        ", "\"\"\"\n        Initializes a `CheckpointModelSaverHook`.\n\n        Args:\n            model: the Argo model\n            period: the period for the hook\n            time_reference: either epochs or steps\n            checkpoint_basename: basename for model saving\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "period", ",", "time_reference", ")", "\n", "\n", "self", ".", "_checkpoint_dir", "=", "model", ".", "_checkpoint_dir", "\n", "self", ".", "_saver", "=", "model", ".", "_saver", "\n", "self", ".", "_save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_checkpoint_dir", ",", "checkpoint_basename", ")", "\n", "tf_logging", ".", "info", "(", "\"Create CheckpointSaverHook\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook.do_when_triggered": [[35, 37], ["CheckpointModelSaverHook.CheckpointModelSaverHook._save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook._save"], ["", "def", "do_when_triggered", "(", "self", ",", "global_step", ",", "time_ref", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "self", ".", "_save", "(", "run_context", ".", "session", ",", "time_ref", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook.end": [[38, 41], ["session.run", "CheckpointModelSaverHook.CheckpointModelSaverHook._save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook._save"], ["", "def", "end", "(", "self", ",", "session", ")", ":", "\n", "        ", "time_ref", "=", "session", ".", "run", "(", "self", ".", "_time_reference_node", ")", "\n", "self", ".", "_save", "(", "session", ",", "time_ref", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.old_files.CheckpointModelSaverHook.CheckpointModelSaverHook._save": [[42, 46], ["argo.core.hooks.LoggingMeanTensorsHook.tf_logging.info", "CheckpointModelSaverHook.CheckpointModelSaverHook._saver.save"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save"], ["", "def", "_save", "(", "self", ",", "session", ",", "step", ")", ":", "\n", "        ", "\"\"\"Saves the latest checkpoint, returns should_stop.\"\"\"", "\n", "tf_logging", ".", "info", "(", "\"Saving checkpoints for %d into %s.\"", ",", "step", ",", "self", ".", "_save_path", ")", "\n", "self", ".", "_saver", ".", "save", "(", "session", ",", "self", ".", "_save_path", ",", "global_step", "=", "step", ",", "write_meta_graph", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.preprocessing.FromAE.FromAE.__init__": [[16, 30], ["argo.core.network.Network.AbstractModule.__init__", "tensorflow.placeholder_with_default", "tensorflow.random_uniform", "tensorflow.less", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "transform_prob", "=", "0.1", ",", "noisy_transform_prob", "=", "0.", ",", "name", "=", "'from_ae'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "if", "not", "(", "0.", "<=", "transform_prob", "<=", "1.", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"`transform_prob` must be between 0 and 1, found `%f`\"", "%", "transform_prob", ")", "\n", "\n", "", "self", ".", "_transform_prob", "=", "transform_prob", "\n", "self", ".", "_noisy_prob", "=", "tf", ".", "placeholder_with_default", "(", "noisy_transform_prob", ",", "shape", "=", "(", ")", ")", "\n", "self", ".", "random_number", "=", "tf", ".", "random_uniform", "(", "(", ")", ",", "0", ",", "1.0", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# transform only a certain fraction of times", "\n", "self", ".", "t_cond", "=", "tf", ".", "less", "(", "self", ".", "random_number", ",", "self", ".", "_transform_prob", ")", "\n", "\n", "self", ".", "_frozen_graph_filename", "=", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.preprocessing.FromAE.FromAE._transform": [[49, 74], ["tensorflow.get_default_graph", "tensorflow.import_graph_def", "tensorflow.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name.set_shape", "tensorflow.gfile.GFile", "tensorflow.GraphDef", "tensorflow.GraphDef.ParseFromString", "f.read"], "methods", ["None"], ["", "def", "_transform", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "scope", "=", "\"import\"", "\n", "# x_shape = (None,)+dataset.x_shape", "\n", "# x = tf.placeholder(tf.float32, shape=x_shape)", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "self", ".", "_frozen_graph_filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "graph_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "# The name var will prefix every op/nodes in your graph", "\n", "# Since we load everything in a new graph, this is not needed", "\n", "", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "tf", ".", "import_graph_def", "(", "graph_def", ",", "input_map", "=", "{", "\"inputs\"", ":", "inputs", ",", "\"noisy_prob\"", ":", "self", ".", "_noisy_prob", "}", ",", "name", "=", "scope", ")", "\n", "\n", "full_scope", "=", "self", ".", "scope_name", "+", "\"/\"", "+", "scope", "\n", "transformed", "=", "graph", ".", "get_tensor_by_name", "(", "full_scope", "+", "\"/transformed:0\"", ")", "\n", "# make sure shapes are the same or compatible with inputs", "\n", "transformed", ".", "set_shape", "(", "inputs", ".", "shape", ")", "\n", "\n", "# if self._post_transform_noise>0:", "\n", "#     transformed, noise = tf_add_gaussian_noise_and_clip(transformed,", "\n", "#                                                         self._post_transform_noise,", "\n", "#                                                         low=0,", "\n", "#                                                         high=1)", "\n", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.preprocessing.FromAE.FromAE._build": [[89, 103], ["FromAE.FromAE._transform", "tensorflow.cond"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.preprocessing.FromAE.FromAE._transform"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "transformed_inputs", "=", "self", ".", "_transform", "(", "inputs", ")", "\n", "\n", "# transform only a certain fraction of times", "\n", "# t_cond decides to transform the whole batch ATM (for efficiency)", "\n", "# other option for image by image preprocessing, woud be to include", "\n", "# the transformation in the dataset augmentation with `map`.", "\n", "# In case this seems needed, ask me (Riccardo)", "\n", "outputs", "=", "tf", ".", "cond", "(", "self", ".", "t_cond", ",", "\n", "lambda", ":", "transformed_inputs", ",", "\n", "lambda", ":", "inputs", "\n", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.preprocessing.preprocess.get_preproc_module": [[5, 28], ["importlib.import_module", "getattr", "Exception", "importlib.import_module", "__name__.split", "importlib.import_module", "__name__.split", "__name__.split"], "function", ["None"], ["def", "get_preproc_module", "(", "preproc_tuple", ",", "module_path", "=", "\"\"", ")", ":", "\n", "    ", "preproc_name", "=", "preproc_tuple", "[", "0", "]", "\n", "preproc_kwargs", "=", "preproc_tuple", "[", "1", "]", "\n", "\n", "try", ":", "\n", "# first try to load from here", "\n", "        ", "try", ":", "\n", "            ", "py_module", "=", "importlib", ".", "import_module", "(", "\".\"", "+", "preproc_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "# it if fails, try to load from up tree directory (I am prediction/core/preprocessing/preprocess.py)", "\n", "", "except", "ImportError", ":", "\n", "            ", "try", ":", "\n", "                ", "py_module", "=", "importlib", ".", "import_module", "(", "\"....preprocessing\"", "+", "preproc_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "# it if fails, try to laod from module_path.core", "\n", "", "except", "ImportError", ":", "\n", "                ", "py_module", "=", "importlib", ".", "import_module", "(", "module_path", "+", "\".core.preprocessing\"", "+", "preproc_name", ",", "\n", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "", "", "preproc_module", "=", "getattr", "(", "py_module", ",", "preproc_name", ")", "(", "**", "preproc_kwargs", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "Exception", "(", "\"problem with module: %s, kwargs: %s, exception %s\"", "%", "(", "preproc_name", ",", "preproc_kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "preproc_module", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonal.GaussianTriDiagonal.__init__": [[13, 34], ["argo.core.network.AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0.", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'gaussian_diagonal'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonal.GaussianTriDiagonal._build": [[35, 57], ["GaussianTriDiagonal.GaussianTriDiagonal.create_mean_n_cov_layers", "GaussianTriDiagonal.GaussianTriDiagonal.set_contractive_regularizer", "tensorflow_probability.distributions.MultivariateNormalTriL", "types.MethodType", "GaussianTriDiagonal.GaussianTriDiagonal.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "mean", ",", "covariance", ",", "scale", ",", "L", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "mean_t", "=", "mean", "\n", "covariance_t", "=", "covariance", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "mean", ",", "covariance", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "# output_distribution = MultivariateNormalTriLChannelFlipped(loc=mean_t, scale_tril=L, validate_args=True)", "\n", "output_distribution", "=", "tfd", ".", "MultivariateNormalTriL", "(", "loc", "=", "mean_t", ",", "scale_tril", "=", "L", ",", "validate_args", "=", "True", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "self", ".", "mean", "=", "mean", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonal.GaussianTriDiagonal.mean": [[60, 62], ["None"], "methods", ["None"], ["", "def", "mean", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonal.GaussianTriDiagonal.create_mean_n_cov_layers": [[63, 130], ["argo.core.utils.argo_utils.load_sonnet_module", "argo.core.utils.argo_utils.load_sonnet_module.", "argo.core.utils.argo_utils.load_sonnet_module", "argo.core.utils.argo_utils.load_sonnet_module.", "argo.core.utils.argo_utils.load_sonnet_module", "argo.core.utils.argo_utils.load_sonnet_module.", "GaussianTriDiagonal.GaussianTriDiagonal.get_covariance_from_parameters_tf", "tensorflow.transpose", "tensorflow.layers.flatten", "tensorflow.reshape", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "numpy.prod", "tensorflow.reshape", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "GaussianTriDiagonal.GaussianTriDiagonal._get_stride", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "Exception", "tensorflow.layers.flatten.shape.as_list", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "GaussianTriDiagonal.GaussianTriDiagonal.check_key_not_in", "GaussianTriDiagonal.GaussianTriDiagonal._get_stride", "tensorflow.layers.flatten.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.get_covariance_from_parameters_tf", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._get_stride", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._get_stride"], ["", "def", "create_mean_n_cov_layers", "(", "self", ",", "inputs", ")", ":", "\n", "# create the layers for mean and covariance", "\n", "\n", "        ", "module_name", ",", "module_kwargs", "=", "self", ".", "_module_tuple", "\n", "extra_kwargs", "=", "self", ".", "_extra_kwargs", "\n", "if", "module_name", "==", "\"Linear\"", "or", "module_name", "==", "\"LinearWN\"", ":", "\n", "            ", "inputs", "=", "tf", ".", "layers", ".", "flatten", "(", "inputs", ")", "\n", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_size\"", ",", "module_kwargs", ")", "\n", "extra_kwargs", "[", "\"output_size\"", "]", "=", "np", ".", "prod", "(", "self", ".", "_output_shape", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_output_shape", "=", "[", "module_kwargs", "[", "\"output_size\"", "]", "]", "\n", "\n", "", "", "elif", "module_name", "==", "\"Conv2D\"", "or", "module_name", "==", "\"Conv2DWN\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"stride\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"padding\"", ",", "module_kwargs", ",", "'SAME'", ")", "\n", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "extra_kwargs", "[", "\"stride\"", "]", "=", "self", ".", "_get_stride", "(", "inputs", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ",", "\n", "self", ".", "_output_shape", ")", "\n", "", "", "elif", "module_name", "==", "\"Conv1D\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"padding\"", ",", "module_kwargs", ",", "'SAME'", ")", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "\n", "", "", "elif", "module_name", "==", "\"Conv2DTranspose\"", "or", "module_name", "==", "\"Conv2DTransposeWN\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"stride\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"output_shape\"", ",", "module_kwargs", ")", "\n", "extra_kwargs", "[", "\"output_shape\"", "]", "=", "self", ".", "_output_shape", "[", "0", ":", "2", "]", "\n", "extra_kwargs", "[", "\"stride\"", "]", "=", "self", ".", "_get_stride", "(", "self", ".", "_output_shape", ",", "\n", "inputs", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"module name `%s` is not allowed, is not implemented yet to be wrapped by a Stochastic Layer.\"", "%", "module_name", ")", "\n", "\n", "", "kwargs", "=", "{", "**", "extra_kwargs", ",", "\n", "**", "module_kwargs", "}", "\n", "\n", "sntmodule_mean", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "mean", "=", "sntmodule_mean", "(", "inputs", ")", "\n", "\n", "sntmodule_cov", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "covariance_params", "=", "sntmodule_cov", "(", "inputs", ")", "\n", "\n", "sntmodule_cov_plus", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "covariance_params_plus", "=", "sntmodule_cov_plus", "(", "inputs", ")", "\n", "\n", "# if I am using linear layers I need to reshape to match output_shape", "\n", "if", "module_name", "==", "\"Linear\"", "or", "module_name", "==", "\"LinearWN\"", ":", "\n", "            ", "output_shape", "=", "[", "-", "1", "]", "+", "self", ".", "_output_shape", "\n", "mean", "=", "tf", ".", "reshape", "(", "mean", ",", "output_shape", ")", "\n", "if", "not", "self", ".", "_scalar_bool", ":", "\n", "                ", "covariance_params", "=", "tf", ".", "reshape", "(", "covariance_params", ",", "output_shape", ")", "\n", "\n", "", "", "covariance", ",", "L", "=", "self", ".", "get_covariance_from_parameters_tf", "(", "covariance_params", ",", "covariance_params_plus", ")", "\n", "# I don't need the standard deviation for the MultivariateFullCovariance", "\n", "scale", "=", "None", "\n", "mean", "=", "tf", ".", "transpose", "(", "mean", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "return", "mean", ",", "covariance", ",", "scale", ",", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonal.GaussianTriDiagonal.get_covariance_from_parameters_tf": [[131, 162], ["tensorflow.unstack", "tensorflow.unstack", "range", "tensorflow.stack", "tensorflow.stack", "len", "tensorflow.map_fn", "tensorflow.slice", "tensorflow.map_fn", "tensorflow.pad", "tensorflow.matmul", "tensorflow.nn.softplus", "tensorflow.transpose", "GaussianTriDiagonal.diagonalize_covariance_matrix", "GaussianTriDiagonal.diagonalize_covariance_matrix", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.diagonalize_covariance_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.diagonalize_covariance_matrix"], ["", "def", "get_covariance_from_parameters_tf", "(", "self", ",", "parameters", ",", "parameters_plus", ")", ":", "\n", "\n", "        ", "unst_param", "=", "tf", ".", "unstack", "(", "parameters", ",", "axis", "=", "2", ")", "\n", "unst_param_plus", "=", "tf", ".", "unstack", "(", "parameters_plus", ",", "axis", "=", "2", ")", "\n", "\n", "covariances", "=", "[", "]", "\n", "Ls", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "unst_param", ")", ")", ":", "\n", "            ", "param", "=", "unst_param", "[", "i", "]", "\n", "param_plus", "=", "unst_param_plus", "[", "i", "]", "\n", "\n", "# loop through batches and tridiagonalize the covariance matrices", "\n", "# tf.nn.softplus(parameters)", "\n", "L1", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "diagonalize_covariance_matrix", "(", "x", ",", "epsilon", "=", "0", ")", ",", "tf", ".", "nn", ".", "softplus", "(", "param", ")", ")", "\n", "\n", "param_plus", "=", "tf", ".", "slice", "(", "param_plus", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "param_plus", ")", "[", "1", "]", "-", "1", "]", ")", "\n", "\n", "L2", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "diagonalize_covariance_matrix", "(", "x", ",", "epsilon", "=", "0", ")", ",", "param_plus", ")", "\n", "L2", "=", "tf", ".", "pad", "(", "L2", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ",", "mode", "=", "'CONSTANT'", ")", "\n", "\n", "L", "=", "L1", "+", "L2", "\n", "cov", "=", "tf", ".", "matmul", "(", "L", ",", "tf", ".", "transpose", "(", "L", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "\n", "covariances", "+=", "[", "cov", "]", "\n", "Ls", "+=", "[", "L", "]", "\n", "\n", "", "covariance", "=", "tf", ".", "stack", "(", "covariances", ",", "axis", "=", "1", ")", "\n", "Lss", "=", "tf", ".", "stack", "(", "Ls", ",", "axis", "=", "1", ")", "\n", "\n", "return", "covariance", ",", "Lss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonal.tridiagonalize_covariance_matrix": [[164, 178], ["tensorflow.zeros", "tensorflow.linalg.set_diag", "tensorflow.zeros", "tensorflow.linalg.set_diag", "tensorflow.pad", "tensorflow.matmul", "tensorflow.shape", "tensorflow.transpose"], "function", ["None"], ["", "", "def", "tridiagonalize_covariance_matrix", "(", "params", ",", "params_plus", ")", ":", "\n", "    ", "time_dim", "=", "tf", ".", "shape", "(", "params", ")", "[", "0", "]", "\n", "\n", "L1", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "time_dim", ",", "time_dim", ")", ")", "\n", "diagonal1", "=", "params", "\n", "L1", "=", "tf", ".", "linalg", ".", "set_diag", "(", "L1", ",", "diagonal1", ")", "\n", "\n", "L2", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "time_dim", "-", "1", ",", "time_dim", "-", "1", ")", ")", "\n", "diagonal2", "=", "params_plus", "\n", "L2", "=", "tf", ".", "linalg", ".", "set_diag", "(", "L2", ",", "diagonal2", ")", "\n", "L2", "=", "tf", ".", "pad", "(", "L2", ",", "[", "[", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "1", "]", "]", ",", "mode", "=", "'CONSTANT'", ")", "\n", "\n", "L", "=", "L1", "+", "L2", "\n", "return", "tf", ".", "matmul", "(", "L", ",", "tf", ".", "transpose", "(", "L", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonal.diagonalize_covariance_matrix": [[180, 188], ["tensorflow.zeros", "tensorflow.linalg.set_diag", "tensorflow.shape"], "function", ["None"], ["", "def", "diagonalize_covariance_matrix", "(", "params", ",", "epsilon", "=", "0.01", ")", ":", "\n", "    ", "time_dim", "=", "tf", ".", "shape", "(", "params", ")", "[", "0", "]", "\n", "\n", "L1", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "time_dim", ",", "time_dim", ")", ")", "\n", "diagonal1", "=", "params", "+", "epsilon", "\n", "L1", "=", "tf", ".", "linalg", ".", "set_diag", "(", "L1", ",", "diagonal1", ")", "\n", "\n", "return", "L1", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianDiagonal.GaussianDiagonal.__init__": [[12, 33], ["argo.core.network.GaussianDiagonal.GaussianDiagonal.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["\n", "import", "types", "\n", "\n", "class", "GaussianDiagonal", "(", "AbstractGaussian", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0.", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'gaussian_diagonal'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianDiagonal.GaussianDiagonal._build": [[34, 54], ["argo.core.network.GaussianDiagonal.GaussianDiagonal.GaussianDiagonal.create_mean_n_cov_layers", "tensorflow.transpose", "tensorflow.transpose", "argo.core.network.GaussianDiagonal.GaussianDiagonal.GaussianDiagonal.set_contractive_regularizer", "tensorflow_probability.distributions.MultivariateNormalDiag", "types.MethodType", "argo.core.network.GaussianDiagonal.GaussianDiagonal.GaussianDiagonal.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n", "", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "mean", ",", "covariance", ",", "scale", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "mean", ",", "covariance", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "\n", "output_distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "mean", ",", "scale", "=", "scale", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.__init__": [[13, 25], ["tensorflow_probability.distributions.MultivariateNormalDiag", "range", "print", "argo.core.flows.build_flow.build_flow", "tensorflow_probability.distributions.TransformedDistribution", "IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution._independent_channels_distributions.append", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.flows.build_flow.build_flow"], ["    ", "def", "__init__", "(", "self", ",", "event_shape", ",", "flow_params", ",", "dim", ",", "channels", ")", ":", "\n", "        ", "self", ".", "_flow_params", "=", "flow_params", "\n", "self", ".", "_dim", "=", "dim", "\n", "self", ".", "_channels", "=", "channels", "\n", "base_dist", "=", "tfd", ".", "MultivariateNormalDiag", "(", "loc", "=", "tf", ".", "zeros", "(", "event_shape", ")", ")", "\n", "\n", "self", ".", "_independent_channels_distributions", "=", "[", "]", "\n", "for", "ch", "in", "range", "(", "self", ".", "_channels", ")", ":", "\n", "            ", "flow_maf", "=", "build_flow", "(", "flow_params", ",", "flow_size", "=", "dim", ")", "\n", "transformed_distribution", "=", "tfd", ".", "TransformedDistribution", "(", "distribution", "=", "base_dist", ",", "bijector", "=", "flow_maf", ")", "\n", "self", ".", "_independent_channels_distributions", ".", "append", "(", "transformed_distribution", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.mean": [[26, 33], ["tensorflow.concat", "tensorflow.reduce_mean", "IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution._independent_channels_distributions[].sample", "range"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "mean", "(", "self", ")", ":", "\n", "        ", "'''\n        Returns: tensor of shape (ch, dim)\n        '''", "\n", "samples_independent_channels", "=", "tf", ".", "concat", "(", "[", "self", ".", "_independent_channels_distributions", "[", "i", "]", ".", "sample", "(", "100", ")", "for", "i", "in", "\n", "range", "(", "self", ".", "_channels", ")", "]", ",", "axis", "=", "1", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "samples_independent_channels", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance": [[34, 39], ["tensorflow.zeros"], "methods", ["None"], ["", "def", "covariance", "(", "self", ")", ":", "\n", "        ", "'''\n        Returns: tensor of shape (ch, dim, dim)\n        '''", "\n", "return", "tf", ".", "zeros", "(", "[", "self", ".", "_channels", ",", "self", ".", "_dim", ",", "self", ".", "_dim", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob": [[40, 56], ["tensorflow.concat", "data.get_shape().as_list", "IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution._independent_channels_distributions[].log_prob", "data.get_shape", "range"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "data", ")", ":", "\n", "        ", "'''\n\n        Args:\n            data (tf.Tensor): of shape (ch, dim) or (batch, ch, dim)\n        Returns:\n            log_prob: of shape (ch) if no batch shape given or (batch, ch)\n        '''", "\n", "data_channels", "=", "data", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "2", "]", "\n", "assert", "data_channels", "==", "self", ".", "_channels", ",", "'Channels in the data: {} and the distribution dont match on axis -2'", ".", "format", "(", "data_channels", ",", "\n", "self", ".", "_channels", ")", "\n", "return", "tf", ".", "concat", "(", "\n", "[", "self", ".", "_independent_channels_distributions", "[", "i", "]", ".", "log_prob", "(", "data", "[", "...", ",", "i", ":", "i", "+", "1", ",", ":", "]", ")", "for", "i", "in", "\n", "range", "(", "self", ".", "_channels", ")", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.sample": [[57, 61], ["tensorflow.concat", "IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution._independent_channels_distributions[].sample", "range"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "sample", "(", "self", ",", "n_samples", ")", ":", "\n", "        ", "return", "tf", ".", "concat", "(", "\n", "[", "self", ".", "_independent_channels_distributions", "[", "i", "]", ".", "sample", "(", "n_samples", ")", "for", "i", "in", "range", "(", "self", ".", "_channels", ")", "]", ",", "\n", "axis", "=", "-", "2", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultiVariateNormalChannelFlipped.MultiVariateNormalChannelFlipped.__init__": [[5, 7], ["tensorflow_probability.distributions.MultivariateNormalDiag.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultiVariateNormalChannelFlipped.MultiVariateNormalChannelFlipped.sample": [[8, 11], ["tensorflow.transpose", "super().sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "sample", "(", "self", ",", "sample_shape", "=", "(", ")", ",", "seed", "=", "None", ",", "name", "=", "\"sample\"", ")", ":", "\n", "        ", "return", "tf", ".", "transpose", "(", "super", "(", ")", ".", "sample", "(", "sample_shape", ",", "seed", ",", "name", ")", ",", "\n", "perm", "=", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", "#extra dimension because of sample", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalFullCovarianceChannelFlipped.MultivariateNormalFullCovarianceChannelFlipped.__init__": [[5, 7], ["tensorflow_probability.distributions.MultivariateNormalFullCovariance.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalFullCovarianceChannelFlipped.MultivariateNormalFullCovarianceChannelFlipped.sample": [[8, 11], ["tensorflow.transpose", "super().sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "sample", "(", "self", ",", "sample_shape", "=", "(", ")", ",", "seed", "=", "None", ",", "name", "=", "\"sample\"", ")", ":", "\n", "        ", "return", "tf", ".", "transpose", "(", "super", "(", ")", ".", "sample", "(", "sample_shape", ",", "seed", ",", "name", ")", ",", "\n", "perm", "=", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", "#extra dimension because of sample", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.__init__": [[5, 7], ["tensorflow_probability.distributions.MultivariateNormalTriL.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample": [[8, 11], ["tensorflow.transpose", "super().sample"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "sample", "(", "self", ",", "sample_shape", "=", "(", ")", ",", "seed", "=", "None", ",", "name", "=", "\"sample\"", ")", ":", "\n", "        ", "return", "tf", ".", "transpose", "(", "super", "(", ")", ".", "sample", "(", "sample_shape", ",", "seed", ",", "name", ")", ",", "\n", "perm", "=", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", "#extra dimension because of sample", "", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AlmostWavenetEncoder.AlmostWavenetEncoder.__init__": [[11, 25], ["sonnet.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "num_layers_per_stage", ",", "\n", "num_layers", ",", "\n", "filter_length", ",", "\n", "hop_length", ",", "\n", "e_hidden_channels", ",", "\n", "latent_channels", ",", "\n", "name", "=", "'almost_wavenet_encoder'", ")", ":", "\n", "        ", "super", "(", "AlmostWavenetEncoder", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_num_layers_per_stage", "=", "num_layers_per_stage", "\n", "self", ".", "_num_layers", "=", "num_layers", "\n", "self", ".", "_filter_length", "=", "filter_length", "\n", "self", ".", "_hop_length", "=", "hop_length", "\n", "self", ".", "_e_hidden_channels", "=", "e_hidden_channels", "\n", "self", ".", "_latent_channels", "=", "latent_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AlmostWavenetEncoder.AlmostWavenetEncoder._build": [[26, 76], ["sonnet.Conv1D", "sonnet.Conv1D.", "range", "sonnet.Conv1D", "sonnet.Conv1D.", "tensorflow.nn.relu", "sonnet.Conv1D", "sonnet.Conv1D.", "tensorflow.nn.relu", "sonnet.Conv1D", "sonnet.Conv1D."], "methods", ["None"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Build the graph for this configuration.\n\n       Args:\n         inputs: input node (already preprocessed)\n\n       Returns:\n         A dict of outputs that includes the 'predictions', 'loss', the 'encoding',\n         the 'quantized_input', and whatever metrics we want to track for eval.\n       \"\"\"", "\n", "\n", "# https://deepmind.github.io/sonnet/_modules/sonnet/python/modules/conv.html#Conv1D", "\n", "\n", "###", "\n", "# The Non-Causal Temporal Encoder.", "\n", "###", "\n", "ae_startconv", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_e_hidden_channels", ",", "\n", "kernel_shape", "=", "self", ".", "_filter_length", ",", "\n", "name", "=", "'ae_startconv'", ")", "\n", "\n", "en", "=", "ae_startconv", "(", "inputs", ")", "\n", "\n", "for", "num_layer", "in", "range", "(", "self", ".", "_num_layers", ")", ":", "\n", "            ", "dilation", "=", "2", "**", "(", "num_layer", "%", "self", ".", "_num_layers_per_stage", ")", "\n", "d", "=", "tf", ".", "nn", ".", "relu", "(", "en", ")", "\n", "\n", "ae_dilatedconv", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_e_hidden_channels", ",", "\n", "kernel_shape", "=", "self", ".", "_filter_length", ",", "\n", "rate", "=", "dilation", ",", "\n", "name", "=", "'ae_dilatedconv_%d'", "%", "(", "num_layer", "+", "1", ")", ")", "\n", "\n", "d", "=", "ae_dilatedconv", "(", "d", ")", "\n", "\n", "d", "=", "tf", ".", "nn", ".", "relu", "(", "d", ")", "\n", "\n", "ae_res", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_e_hidden_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'ae_res_%d'", "%", "(", "num_layer", "+", "1", ")", ")", "\n", "\n", "en", "+=", "ae_res", "(", "d", ")", "\n", "\n", "", "ae_bottleneck", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_latent_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'ae_bottleneck'", ")", "\n", "\n", "en", "=", "ae_bottleneck", "(", "en", ")", "\n", "\n", "return", "en", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.mcd": [[7, 20], ["tensorflow.squeeze", "tensorflow.reduce_mean", "tensorflow.sqrt", "tensorflow.abs", "tensorflow.tensordot", "tensorflow.transpose"], "function", ["None"], ["def", "mcd", "(", "mfcc1", ",", "mfcc2", ")", ":", "\n", "    ", "'''\n    computes the mel cepstral distance between 2 signals given the mel frequency cepstral coefficients (mfcc) of the signals\n    Args:\n        mfcc1: mfcc for first signal\n        mfcc2: mfcc for the second signal\n\n    Returns:\n\n    '''", "\n", "diff", "=", "mfcc1", "-", "mfcc2", "\n", "diff", "=", "tf", ".", "squeeze", "(", "diff", ")", "\n", "return", "logSpecDbConst", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "sqrt", "(", "tf", ".", "abs", "(", "tf", ".", "tensordot", "(", "diff", ",", "tf", ".", "transpose", "(", "diff", ")", ",", "axes", "=", "1", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.logSpecDb_mcd": [[22, 24], ["mel_utils_tensorflow.mcd"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mcd"], ["", "def", "logSpecDb_mcd", "(", "mfcc1", ",", "mfcc2", ")", ":", "\n", "    ", "return", "logSpecDbConst", "*", "mcd", "(", "mfcc1", ",", "mfcc2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.tf_log10": [[26, 36], ["tensorflow.log", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "tf_log10", "(", "x", ")", ":", "\n", "    ", "'''\n    computes the log in base 10 of the tensor x\n    Args:\n        x (tensorflow.Tensor): the tensor on whic to compute the log in base 10\n\n    Returns:\n        tensorflow.Tensor: a tensorflow node of the log in base 10\n    '''", "\n", "return", "tf", ".", "log", "(", "x", "+", "1e-6", ")", "/", "tf", ".", "log", "(", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.calculate_nfft": [[38, 53], ["None"], "function", ["None"], ["", "def", "calculate_nfft", "(", "samplerate", ",", "winlen", ")", ":", "\n", "    ", "\"\"\"Calculates the FFT size as a power of two greater than or equal to\n    the number of samples in a single window length.\n\n    Having an FFT less than the window length loses precision by dropping\n    many of the samples; a longer FFT than the window allows zero-padding\n    of the FFT buffer which is neutral in terms of frequency domain conversion.\n    :param samplerate: The sample rate of the signal we are working with, in Hz.\n    :param winlen: The length of the analysis window in seconds.\n    \"\"\"", "\n", "window_length_samples", "=", "winlen", "*", "samplerate", "\n", "nfft", "=", "1", "\n", "while", "nfft", "<", "window_length_samples", ":", "\n", "        ", "nfft", "*=", "2", "\n", "", "return", "nfft", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.mfcc_tf": [[55, 83], ["tensorflow.squeeze", "int", "int", "tensorflow.signal.stft", "tensorflow.abs", "tensorflow.signal.linear_to_mel_weight_matrix", "tensorflow.tensordot", "tf.tensordot.set_shape", "tensorflow.math.log", "tf.abs.shape[].concatenate", "tensorflow.signal.mfccs_from_log_mel_spectrograms"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "mfcc_tf", "(", "pcm", ",", "sample_rate", ",", "win_len", "=", "0.025", ",", "winstep", "=", "0.01", ")", ":", "\n", "# A Tensor of [batch_size, num_samples] mono PCM samples in the range [-1, 1].", "\n", "# pcm = tf.compat.v1.placeholder(tf.float32, [None, None])", "\n", "    ", "pcm", "=", "tf", ".", "squeeze", "(", "pcm", ",", "axis", "=", "-", "1", ")", "\n", "# A 1024-point STFT with frames of 64 ms and 75% overlap.", "\n", "frame_length", "=", "int", "(", "win_len", "*", "sample_rate", ")", "\n", "frame_step", "=", "int", "(", "sample_rate", "*", "winstep", ")", "\n", "stfts", "=", "tf", ".", "signal", ".", "stft", "(", "pcm", ",", "frame_length", "=", "frame_length", ",", "frame_step", "=", "frame_step", ",", "fft_length", "=", "400", ")", "\n", "spectrograms", "=", "tf", ".", "abs", "(", "stfts", ")", "\n", "\n", "# Warp the linear scale spectrograms into the mel-scale.", "\n", "num_spectrogram_bins", "=", "stfts", ".", "shape", "[", "-", "1", "]", ".", "value", "\n", "lower_edge_hertz", ",", "upper_edge_hertz", ",", "num_mel_bins", "=", "0", ",", "sample_rate", "/", "2", ",", "80", "\n", "linear_to_mel_weight_matrix", "=", "tf", ".", "signal", ".", "linear_to_mel_weight_matrix", "(", "\n", "num_mel_bins", ",", "num_spectrogram_bins", ",", "sample_rate", ",", "lower_edge_hertz", ",", "\n", "upper_edge_hertz", ")", "\n", "mel_spectrograms", "=", "tf", ".", "tensordot", "(", "\n", "spectrograms", ",", "linear_to_mel_weight_matrix", ",", "1", ")", "\n", "mel_spectrograms", ".", "set_shape", "(", "spectrograms", ".", "shape", "[", ":", "-", "1", "]", ".", "concatenate", "(", "\n", "linear_to_mel_weight_matrix", ".", "shape", "[", "-", "1", ":", "]", ")", ")", "\n", "\n", "# Compute a stabilized log to get log-magnitude mel-scale spectrograms.", "\n", "log_mel_spectrograms", "=", "tf", ".", "math", ".", "log", "(", "mel_spectrograms", "+", "1e-6", ")", "\n", "\n", "# Compute MFCCs from log_mel_spectrograms and take the first 13.", "\n", "mfccs_tf", "=", "tf", ".", "signal", ".", "mfccs_from_log_mel_spectrograms", "(", "\n", "log_mel_spectrograms", ")", "[", "...", ",", ":", "13", "]", "\n", "return", "mfccs_tf", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.mfcc": [[85, 114], ["mel_utils_tensorflow.fbank", "tensorflow.log", "numpy.ones", "mel_utils_tensorflow.calculate_nfft", "tensorflow.signal.dct", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.fbank", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.calculate_nfft", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "mfcc", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "numcep", "=", "13", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "None", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "appendEnergy", "=", "True", ",", "\n", "winfunc", "=", "lambda", "x", ":", "np", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute MFCC features from an audio signal.\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the sample rate of the signal we are working with, in Hz.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param numcep: the number of cepstrum to return, default 13\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is None, which uses the calculate_nfft function to choose the smallest size that does not drop sample data.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param ceplifter: apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22.\n    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use np window functions here e.g. winfunc=np.hamming\n    :returns: A np array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\n    \"\"\"", "\n", "nfft", "=", "nfft", "or", "calculate_nfft", "(", "samplerate", ",", "winlen", ")", "\n", "feat", ",", "energy", "=", "fbank", "(", "signal", ",", "samplerate", ",", "winlen", ",", "winstep", ",", "nfilt", ",", "nfft", ",", "lowfreq", ",", "highfreq", ",", "preemph", ",", "winfunc", ")", "\n", "feat", "=", "tf", ".", "log", "(", "feat", "+", "1e-6", ")", "\n", "feat", "=", "tf", ".", "signal", ".", "dct", "(", "feat", ",", "type", "=", "2", ",", "axis", "=", "-", "1", ",", "norm", "=", "'ortho'", ")", "[", "...", ",", ":", "numcep", "]", "\n", "if", "appendEnergy", ":", "\n", "# replace first cepstral coefficient with log of frame energy", "\n", "        ", "energy", "=", "tf", ".", "expand_dims", "(", "energy", ",", "axis", "=", "-", "1", ")", "\n", "feat", "=", "tf", ".", "concat", "(", "[", "tf", ".", "log", "(", "energy", "+", "1e-6", ")", ",", "feat", "[", "...", ",", "1", ":", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.fbank": [[116, 147], ["mel_utils_tensorflow.preemphasis", "mel_utils_tensorflow.framesig", "mel_utils_tensorflow.powspec", "tensorflow.reduce_sum", "tensorflow.where", "mel_utils_tensorflow.get_filterbanks", "tensorflow.tensordot", "tensorflow.where", "numpy.ones", "tensorflow.ones_like", "tensorflow.keras.backend.epsilon", "tensorflow.transpose", "tensorflow.ones_like", "tensorflow.keras.backend.epsilon"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.preemphasis", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.framesig", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.powspec", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.get_filterbanks"], ["", "def", "fbank", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "\n", "winfunc", "=", "lambda", "x", ":", "np", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute Mel-filterbank energy features from an audio signal.\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the sample rate of the signal we are working with, in Hz.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use np window functions here e.g. winfunc=np.hamming\n    :returns: 2 values. The first is a np array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector. The\n        second return value is the energy in each frame (total energy, unwindowed)\n    \"\"\"", "\n", "highfreq", "=", "highfreq", "or", "samplerate", "/", "2", "\n", "signal", "=", "preemphasis", "(", "signal", ",", "preemph", ")", "\n", "frames", "=", "framesig", "(", "signal", ",", "winlen", "*", "samplerate", ",", "winstep", "*", "samplerate", ",", "winfunc", ")", "\n", "pspec", "=", "powspec", "(", "frames", ",", "nfft", ")", "\n", "energy", "=", "tf", ".", "reduce_sum", "(", "pspec", ",", "axis", "=", "-", "1", ")", "# this stores the total energy in each frame", "\n", "tf_epsilon", "=", "tf", ".", "ones_like", "(", "energy", ")", "*", "tf", ".", "keras", ".", "backend", ".", "epsilon", "(", ")", "\n", "energy", "=", "tf", ".", "where", "(", "energy", "==", "0", ",", "tf_epsilon", ",", "energy", ")", "# if energy is zero, we get problems with log", "\n", "\n", "fb", "=", "get_filterbanks", "(", "nfilt", ",", "nfft", ",", "samplerate", ",", "lowfreq", ",", "highfreq", ")", "\n", "feat", "=", "tf", ".", "tensordot", "(", "pspec", ",", "tf", ".", "transpose", "(", "fb", ")", ",", "axes", "=", "1", ")", "# compute the filterbank energies", "\n", "tf_epsilon", "=", "tf", ".", "ones_like", "(", "feat", ")", "*", "tf", ".", "keras", ".", "backend", ".", "epsilon", "(", ")", "\n", "feat", "=", "tf", ".", "where", "(", "feat", "==", "0", ",", "tf_epsilon", ",", "feat", ")", "# if feat is zero, we get problems with log", "\n", "\n", "return", "feat", ",", "energy", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.logfbank": [[149, 167], ["mel_utils_tensorflow.fbank", "tensorflow.log", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.fbank", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "logfbank", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "\n", "winfunc", "=", "lambda", "x", ":", "np", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute log Mel-filterbank energy features from an audio signal.\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the sample rate of the signal we are working with, in Hz.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use np window functions here e.g. winfunc=np.hamming\n    :returns: A np array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n    \"\"\"", "\n", "feat", ",", "energy", "=", "fbank", "(", "signal", ",", "samplerate", ",", "winlen", ",", "winstep", ",", "nfilt", ",", "nfft", ",", "lowfreq", ",", "highfreq", ",", "preemph", ",", "winfunc", ")", "\n", "return", "tf", ".", "log", "(", "feat", "+", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.hz2mel": [[169, 175], ["numpy.log10"], "function", ["None"], ["", "def", "hz2mel", "(", "hz", ")", ":", "\n", "    ", "\"\"\"Convert a value in Hertz to Mels\n    :param hz: a value in Hz. This can also be a np array, conversion proceeds element-wise.\n    :returns: a value in Mels. If an array was passed in, an identical sized array is returned.\n    \"\"\"", "\n", "return", "2595", "*", "np", ".", "log10", "(", "1", "+", "hz", "/", "700.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.mel2hz": [[177, 183], ["None"], "function", ["None"], ["", "def", "mel2hz", "(", "mel", ")", ":", "\n", "    ", "\"\"\"Convert a value in Mels to Hertz\n    :param mel: a value in Mels. This can also be a np array, conversion proceeds element-wise.\n    :returns: a value in Hertz. If an array was passed in, an identical sized array is returned.\n    \"\"\"", "\n", "return", "700", "*", "(", "10", "**", "(", "mel", "/", "2595.0", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.get_filterbanks": [[185, 222], ["mel_utils_tensorflow.hz2mel", "mel_utils_tensorflow.hz2mel", "numpy.linspace", "numpy.floor", "tensorflow.zeros", "range", "numpy.ones", "range", "range", "int", "int", "tensorflow.constant", "tensorflow.where", "int", "int", "tensorflow.constant", "tensorflow.where", "mel_utils_tensorflow.mel2hz"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.hz2mel", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.hz2mel", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mel2hz"], ["", "def", "get_filterbanks", "(", "nfilt", "=", "20", ",", "nfft", "=", "512", ",", "samplerate", "=", "16000", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n    :param nfilt: the number of filters in the filterbank, default 20.\n    :param nfft: the FFT size. Default is 512.\n    :param samplerate: the sample rate of the signal we are working with, in Hz. Affects mel spacing.\n    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n    :param highfreq: highest band edge of mel filters, default samplerate/2\n    :returns: A np array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n    \"\"\"", "\n", "highfreq", "=", "highfreq", "or", "samplerate", "/", "2", "\n", "assert", "highfreq", "<=", "samplerate", "/", "2", ",", "\"highfreq is greater than samplerate/2\"", "\n", "\n", "# compute points evenly spaced in mels", "\n", "lowmel", "=", "hz2mel", "(", "lowfreq", ")", "\n", "highmel", "=", "hz2mel", "(", "highfreq", ")", "\n", "melpoints", "=", "np", ".", "linspace", "(", "lowmel", ",", "highmel", ",", "nfilt", "+", "2", ")", "\n", "# our points are in Hz, but we use fft bins, so we have to convert", "\n", "#  from Hz to fft bin number", "\n", "bin", "=", "np", ".", "floor", "(", "(", "nfft", "+", "1", ")", "*", "mel2hz", "(", "melpoints", ")", "/", "samplerate", ")", "\n", "\n", "fbank", "=", "tf", ".", "zeros", "(", "[", "nfilt", ",", "nfft", "//", "2", "+", "1", "]", ",", "tf", ".", "float32", ")", "\n", "false_value", "=", "-", "1", "\n", "\n", "mask", "=", "np", ".", "ones", "(", "fbank", ".", "shape", ")", "*", "false_value", "\n", "for", "j", "in", "range", "(", "0", ",", "nfilt", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "int", "(", "bin", "[", "j", "]", ")", ",", "int", "(", "bin", "[", "j", "+", "1", "]", ")", ")", ":", "\n", "            ", "mask", "[", "j", ",", "i", "]", "=", "(", "i", "-", "bin", "[", "j", "]", ")", "/", "(", "bin", "[", "j", "+", "1", "]", "-", "bin", "[", "j", "]", ")", "\n", "mask_tf", "=", "tf", ".", "constant", "(", "mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fbank", "=", "tf", ".", "where", "(", "mask_tf", ">=", "0", ",", "mask_tf", ",", "fbank", ")", "\n", "mask", "[", "j", ",", "i", "]", "=", "false_value", "\n", "", "for", "i", "in", "range", "(", "int", "(", "bin", "[", "j", "+", "1", "]", ")", ",", "int", "(", "bin", "[", "j", "+", "2", "]", ")", ")", ":", "\n", "            ", "mask", "[", "j", ",", "i", "]", "=", "(", "bin", "[", "j", "+", "2", "]", "-", "i", ")", "/", "(", "bin", "[", "j", "+", "2", "]", "-", "bin", "[", "j", "+", "1", "]", ")", "\n", "mask_tf", "=", "tf", ".", "constant", "(", "mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fbank", "=", "tf", ".", "where", "(", "mask_tf", ">=", "0", ",", "mask_tf", ",", "fbank", ")", "\n", "mask", "[", "j", ",", "i", "]", "=", "false_value", "\n", "", "", "return", "fbank", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.lifter": [[224, 238], ["numpy.shape", "tensorflow.arange", "tensorflow.sin"], "function", ["None"], ["", "def", "lifter", "(", "cepstra", ",", "L", "=", "22", ")", ":", "\n", "    ", "\"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n    magnitude of the high frequency DCT coeffs.\n    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n    \"\"\"", "\n", "if", "L", ">", "0", ":", "\n", "        ", "nframes", ",", "ncoeff", "=", "np", ".", "shape", "(", "cepstra", ")", "\n", "n", "=", "tf", ".", "arange", "(", "ncoeff", ")", "\n", "lift", "=", "1", "+", "(", "L", "/", "2.", ")", "*", "tf", ".", "sin", "(", "tf", ".", "pi", "*", "n", "/", "L", ")", "\n", "return", "lift", "*", "cepstra", "\n", "", "else", ":", "\n", "# values of L <= 0, do nothing", "\n", "        ", "return", "cepstra", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.round_half_up": [[244, 246], ["int", "decimal.Decimal().quantize", "decimal.Decimal", "decimal.Decimal"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer.quantize"], ["", "", "def", "round_half_up", "(", "number", ")", ":", "\n", "    ", "return", "int", "(", "decimal", ".", "Decimal", "(", "number", ")", ".", "quantize", "(", "decimal", ".", "Decimal", "(", "'1'", ")", ",", "rounding", "=", "decimal", ".", "ROUND_HALF_UP", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.framesig": [[248, 279], ["tensorflow.shape", "int", "int", "tensorflow.case", "tensorflow.cast", "tensorflow.zeros", "tensorflow.concat", "tensorflow.tile", "tensorflow.gather", "tensorflow.tile", "numpy.ones", "tensorflow.ones", "mel_utils_tensorflow.round_half_up", "mel_utils_tensorflow.round_half_up", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.tile", "winfunc", "tensorflow.ceil", "tensorflow.expand_dims", "tensorflow.range"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.round_half_up", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.round_half_up"], ["", "def", "framesig", "(", "sig", ",", "frame_len", ",", "frame_step", ",", "winfunc", "=", "lambda", "x", ":", "np", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Frame a signal into overlapping frames.\n    :param sig: the audio signal to frame.\n    :param frame_len: length of each frame measured in samples.\n    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n    :param stride_trick: use stride trick to compute the rolling window and window multiplication faster\n    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n    \"\"\"", "\n", "winfunc", "=", "lambda", "x", ":", "tf", ".", "ones", "(", "(", "x", ",", ")", ")", "\n", "sig_shape", "=", "tf", ".", "shape", "(", "sig", ")", "\n", "batch", ",", "slen", "=", "sig_shape", "[", "0", "]", ",", "sig_shape", "[", "1", "]", "\n", "frame_len", "=", "int", "(", "round_half_up", "(", "frame_len", ")", ")", "\n", "frame_step", "=", "int", "(", "round_half_up", "(", "frame_step", ")", ")", "\n", "\n", "val1", "=", "lambda", ":", "1", "\n", "val2", "=", "lambda", ":", "tf", ".", "cast", "(", "1", "+", "tf", ".", "ceil", "(", "(", "1", "*", "slen", "-", "frame_len", ")", "/", "frame_step", ")", ",", "tf", ".", "int32", ")", "\n", "numframes", "=", "tf", ".", "case", "(", "[", "(", "slen", "<=", "frame_len", ",", "val1", ")", "]", ",", "default", "=", "val2", ")", "\n", "\n", "padlen", "=", "tf", ".", "cast", "(", "(", "numframes", "-", "1", ")", "*", "frame_step", "+", "frame_len", ",", "tf", ".", "int32", ")", "\n", "zeros", "=", "tf", ".", "zeros", "(", "(", "batch", ",", "padlen", "-", "slen", ",", ")", ",", "dtype", "=", "sig", ".", "dtype", ")", "\n", "padsignal", "=", "tf", ".", "concat", "(", "(", "sig", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "\n", "indices", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "0", ",", "frame_len", ")", ",", "axis", "=", "0", ")", ",", "(", "numframes", ",", "1", ")", ")", "\n", "indices", "=", "indices", "+", "tf", ".", "transpose", "(", "\n", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "0", ",", "numframes", "*", "frame_step", ",", "frame_step", ")", ",", "axis", "=", "0", ")", ",", "(", "frame_len", ",", "1", ")", ")", ")", "\n", "\n", "frames", "=", "tf", ".", "gather", "(", "padsignal", ",", "indices", ",", "axis", "=", "-", "1", ")", "\n", "win", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "winfunc", "(", "frame_len", ")", ",", "axis", "=", "0", ")", ",", "(", "numframes", ",", "1", ")", ")", "\n", "\n", "return", "frames", "*", "win", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.magspec_np": [[281, 290], ["numpy.fft.rfft", "numpy.absolute().astype", "numpy.absolute"], "function", ["None"], ["", "def", "magspec_np", "(", "frames", ",", "NFFT", ")", ":", "\n", "    ", "\"\"\"Compute the magnitude spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n\n    :param frames: the array of frames. Each row is a frame.\n    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the magnitude spectrum of the corresponding frame.\n    \"\"\"", "\n", "complex_spec", "=", "(", "np", ".", "fft", ".", "rfft", "(", "frames", ",", "NFFT", ")", ")", "\n", "return", "np", ".", "absolute", "(", "complex_spec", ")", ".", "astype", "(", "'float64'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.powspec": [[292, 302], ["tensorflow.numpy_function", "tensorflow.cast", "tensorflow.square"], "function", ["None"], ["", "def", "powspec", "(", "frames", ",", "NFFT", ")", ":", "\n", "    ", "\"\"\"Compute the power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n    :param frames: the array of frames. Each row is a frame.\n    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the power spectrum of the corresponding frame.\n    \"\"\"", "\n", "mag_spec", "=", "tf", ".", "numpy_function", "(", "magspec_np", ",", "[", "frames", ",", "NFFT", "]", ",", "tf", ".", "float64", ")", "\n", "\n", "mag_spec", "=", "tf", ".", "cast", "(", "mag_spec", ",", "tf", ".", "float32", ")", "\n", "return", "1.0", "/", "NFFT", "*", "tf", ".", "square", "(", "mag_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_tensorflow.preemphasis": [[304, 316], ["tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "tensorflow.shape"], "function", ["None"], ["", "def", "preemphasis", "(", "signal", ",", "coeff", "=", "0.95", ")", ":", "\n", "    ", "\"\"\"perform preemphasis on the input signal.\n    :param signal: The signal to filter.\n    :param coeff: The preemphasis coefficient. 0 is no filter, default is 0.95.\n    :returns: the filtered signal.\n    \"\"\"", "\n", "batch", "=", "tf", ".", "shape", "(", "signal", ")", "[", "0", "]", "\n", "# new_signal = signal, dtype=tf.float32)", "\n", "first_elem", "=", "tf", ".", "reshape", "(", "signal", "[", ":", ",", "0", "]", ",", "(", "batch", ",", "-", "1", ",", "1", ")", ")", "\n", "new_signal", "=", "tf", ".", "concat", "(", "(", "first_elem", ",", "signal", "[", ":", ",", "1", ":", "]", "-", "coeff", "*", "signal", "[", ":", ",", ":", "-", "1", "]", ")", ",", "axis", "=", "-", "2", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "new_signal", ",", "(", "batch", ",", "-", "1", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mcd": [[10, 14], ["numpy.mean", "numpy.sqrt", "numpy.abs", "numpy.dot", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["def", "mcd", "(", "mfcc1", ",", "mfcc2", ")", ":", "\n", "# np stackexchange: https://dsp.stackexchange.com/questions/56391/mel-cepstral-distortion", "\n", "    ", "diff", "=", "mfcc1", "-", "mfcc2", "\n", "return", "logSpecDbConst", "*", "numpy", ".", "mean", "(", "numpy", ".", "sqrt", "(", "numpy", ".", "abs", "(", "numpy", ".", "dot", "(", "diff", ",", "numpy", ".", "transpose", "(", "diff", ",", "axes", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mcd_per_sample": [[15, 18], ["numpy.mean", "numpy.sqrt", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "mcd_per_sample", "(", "mfcc1", ",", "mfcc2", ")", ":", "\n", "# np stackexchange: https://dsp.stackexchange.com/questions/56391/mel-cepstral-distortion", "\n", "    ", "return", "logSpecDbConst", "*", "numpy", ".", "mean", "(", "numpy", ".", "sqrt", "(", "numpy", ".", "sum", "(", "(", "mfcc1", "-", "mfcc2", ")", "**", "2", ",", "axis", "=", "-", "1", ")", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.calculate_nfft": [[19, 34], ["None"], "function", ["None"], ["", "def", "calculate_nfft", "(", "samplerate", ",", "winlen", ")", ":", "\n", "    ", "\"\"\"Calculates the FFT size as a power of two greater than or equal to\n    the number of samples in a single window length.\n\n    Having an FFT less than the window length loses precision by dropping\n    many of the samples; a longer FFT than the window allows zero-padding\n    of the FFT buffer which is neutral in terms of frequency domain conversion.\n    :param samplerate: The sample rate of the signal we are working with, in Hz.\n    :param winlen: The length of the analysis window in seconds.\n    \"\"\"", "\n", "window_length_samples", "=", "winlen", "*", "samplerate", "\n", "nfft", "=", "1", "\n", "while", "nfft", "<", "window_length_samples", ":", "\n", "        ", "nfft", "*=", "2", "\n", "", "return", "nfft", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc": [[36, 63], ["mel_utils_numpy.fbank", "numpy.log", "scipy.fftpack.dct", "numpy.ones", "mel_utils_numpy.calculate_nfft", "numpy.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.fbank", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.calculate_nfft", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "mfcc", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "numcep", "=", "13", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "None", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "appendEnergy", "=", "True", ",", "\n", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute MFCC features from an audio signal.\n\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the samplerate of the signal we are working with.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param numcep: the number of cepstrum to return, default 13\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n    :returns: A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\n    \"\"\"", "\n", "nfft", "=", "nfft", "or", "calculate_nfft", "(", "samplerate", ",", "winlen", ")", "\n", "feat", ",", "energy", "=", "fbank", "(", "signal", ",", "samplerate", ",", "winlen", ",", "winstep", ",", "nfilt", ",", "nfft", ",", "lowfreq", ",", "highfreq", ",", "preemph", ",", "winfunc", ")", "\n", "feat", "=", "numpy", ".", "log", "(", "feat", "+", "1e-6", ")", "\n", "feat", "=", "dct", "(", "feat", ",", "type", "=", "2", ",", "axis", "=", "-", "1", ",", "norm", "=", "'ortho'", ")", "\n", "feat", "=", "feat", "[", "...", ",", ":", "numcep", "]", "\n", "if", "appendEnergy", ":", "feat", "[", "...", ",", "0", "]", "=", "numpy", ".", "log", "(", "energy", "+", "1e-6", ")", "# replace first cepstral coefficient with log of frame energy", "\n", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.fbank": [[65, 94], ["mel_utils_numpy.preemphasis", "mel_utils_numpy.framesig", "mel_utils_numpy.powspec", "numpy.sum", "numpy.where", "mel_utils_numpy.get_filterbanks", "numpy.dot", "numpy.where", "numpy.ones", "numpy.finfo", "numpy.finfo"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.preemphasis", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.framesig", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.powspec", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.get_filterbanks"], ["", "def", "fbank", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "\n", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute Mel-filterbank energy features from an audio signal.\n\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the samplerate of the signal we are working with.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n    :returns: 2 values. The first is a numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector. The\n        second return value is the energy in each frame (total energy, unwindowed)\n    \"\"\"", "\n", "highfreq", "=", "highfreq", "or", "samplerate", "/", "2", "\n", "signal", "=", "preemphasis", "(", "signal", ",", "preemph", ")", "\n", "frames", "=", "framesig", "(", "signal", ",", "winlen", "*", "samplerate", ",", "winstep", "*", "samplerate", ",", "winfunc", ")", "\n", "pspec", "=", "powspec", "(", "frames", ",", "nfft", ")", "\n", "energy", "=", "numpy", ".", "sum", "(", "pspec", ",", "axis", "=", "-", "1", ")", "# this stores the total energy in each frame", "\n", "energy", "=", "numpy", ".", "where", "(", "energy", "==", "0", ",", "numpy", ".", "finfo", "(", "float", ")", ".", "eps", ",", "energy", ")", "# if energy is zero, we get problems with log", "\n", "\n", "fb", "=", "get_filterbanks", "(", "nfilt", ",", "nfft", ",", "samplerate", ",", "lowfreq", ",", "highfreq", ")", "\n", "feat", "=", "numpy", ".", "dot", "(", "pspec", ",", "fb", ".", "T", ")", "# compute the filterbank energies", "\n", "feat", "=", "numpy", ".", "where", "(", "feat", "==", "0", ",", "numpy", ".", "finfo", "(", "float", ")", ".", "eps", ",", "feat", ")", "# if feat is zero, we get problems with log", "\n", "return", "feat", ",", "energy", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.logfbank": [[96, 113], ["mel_utils_numpy.fbank", "numpy.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.fbank", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "logfbank", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ")", ":", "\n", "    ", "\"\"\"Compute log Mel-filterbank energy features from an audio signal.\n\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the samplerate of the signal we are working with.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n    \"\"\"", "\n", "feat", ",", "energy", "=", "fbank", "(", "signal", ",", "samplerate", ",", "winlen", ",", "winstep", ",", "nfilt", ",", "nfft", ",", "lowfreq", ",", "highfreq", ",", "preemph", ")", "\n", "return", "numpy", ".", "log", "(", "feat", "+", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.hz2mel": [[114, 121], ["numpy.log10"], "function", ["None"], ["", "def", "hz2mel", "(", "hz", ")", ":", "\n", "    ", "\"\"\"Convert a value in Hertz to Mels\n\n    :param hz: a value in Hz. This can also be a numpy array, conversion proceeds element-wise.\n    :returns: a value in Mels. If an array was passed in, an identical sized array is returned.\n    \"\"\"", "\n", "return", "2595", "*", "numpy", ".", "log10", "(", "1", "+", "hz", "/", "700.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mel2hz": [[123, 130], ["None"], "function", ["None"], ["", "def", "mel2hz", "(", "mel", ")", ":", "\n", "    ", "\"\"\"Convert a value in Mels to Hertz\n\n    :param mel: a value in Mels. This can also be a numpy array, conversion proceeds element-wise.\n    :returns: a value in Hertz. If an array was passed in, an identical sized array is returned.\n    \"\"\"", "\n", "return", "700", "*", "(", "10", "**", "(", "mel", "/", "2595.0", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.get_filterbanks": [[132, 161], ["mel_utils_numpy.hz2mel", "mel_utils_numpy.hz2mel", "numpy.linspace", "numpy.floor", "numpy.zeros", "range", "range", "range", "int", "int", "int", "int", "mel_utils_numpy.mel2hz"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.hz2mel", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.hz2mel", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mel2hz"], ["", "def", "get_filterbanks", "(", "nfilt", "=", "20", ",", "nfft", "=", "512", ",", "samplerate", "=", "16000", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n\n    :param nfilt: the number of filters in the filterbank, default 20.\n    :param nfft: the FFT size. Default is 512.\n    :param samplerate: the samplerate of the signal we are working with. Affects mel spacing.\n    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n    :param highfreq: highest band edge of mel filters, default samplerate/2\n    :returns: A numpy array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n    \"\"\"", "\n", "highfreq", "=", "highfreq", "or", "samplerate", "/", "2", "\n", "assert", "highfreq", "<=", "samplerate", "/", "2", ",", "\"highfreq is greater than samplerate/2\"", "\n", "\n", "# compute points evenly spaced in mels", "\n", "lowmel", "=", "hz2mel", "(", "lowfreq", ")", "\n", "highmel", "=", "hz2mel", "(", "highfreq", ")", "\n", "melpoints", "=", "numpy", ".", "linspace", "(", "lowmel", ",", "highmel", ",", "nfilt", "+", "2", ")", "\n", "# our points are in Hz, but we use fft bins, so we have to convert", "\n", "#  from Hz to fft bin number", "\n", "bin", "=", "numpy", ".", "floor", "(", "(", "nfft", "+", "1", ")", "*", "mel2hz", "(", "melpoints", ")", "/", "samplerate", ")", "\n", "\n", "fbank", "=", "numpy", ".", "zeros", "(", "[", "nfilt", ",", "nfft", "//", "2", "+", "1", "]", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nfilt", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "int", "(", "bin", "[", "j", "]", ")", ",", "int", "(", "bin", "[", "j", "+", "1", "]", ")", ")", ":", "\n", "            ", "fbank", "[", "j", ",", "i", "]", "=", "(", "i", "-", "bin", "[", "j", "]", ")", "/", "(", "bin", "[", "j", "+", "1", "]", "-", "bin", "[", "j", "]", ")", "\n", "", "for", "i", "in", "range", "(", "int", "(", "bin", "[", "j", "+", "1", "]", ")", ",", "int", "(", "bin", "[", "j", "+", "2", "]", ")", ")", ":", "\n", "            ", "fbank", "[", "j", ",", "i", "]", "=", "(", "bin", "[", "j", "+", "2", "]", "-", "i", ")", "/", "(", "bin", "[", "j", "+", "2", "]", "-", "bin", "[", "j", "+", "1", "]", ")", "\n", "", "", "return", "fbank", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.lifter": [[163, 178], ["numpy.shape", "numpy.arange", "numpy.sin"], "function", ["None"], ["", "def", "lifter", "(", "cepstra", ",", "L", "=", "22", ")", ":", "\n", "    ", "\"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n    magnitude of the high frequency DCT coeffs.\n\n    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n    \"\"\"", "\n", "if", "L", ">", "0", ":", "\n", "        ", "nframes", ",", "ncoeff", "=", "numpy", ".", "shape", "(", "cepstra", ")", "\n", "n", "=", "numpy", ".", "arange", "(", "ncoeff", ")", "\n", "lift", "=", "1", "+", "(", "L", "/", "2.", ")", "*", "numpy", ".", "sin", "(", "numpy", ".", "pi", "*", "n", "/", "L", ")", "\n", "return", "lift", "*", "cepstra", "\n", "", "else", ":", "\n", "# values of L <= 0, do nothing", "\n", "        ", "return", "cepstra", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.round_half_up": [[185, 187], ["int", "decimal.Decimal().quantize", "decimal.Decimal", "decimal.Decimal"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.VQVAENetwork.VectorQuantizer.quantize"], ["", "", "def", "round_half_up", "(", "number", ")", ":", "\n", "    ", "return", "int", "(", "decimal", ".", "Decimal", "(", "number", ")", ".", "quantize", "(", "decimal", ".", "Decimal", "(", "'1'", ")", ",", "rounding", "=", "decimal", ".", "ROUND_HALF_UP", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.framesig": [[189, 219], ["int", "int", "int", "numpy.zeros", "numpy.concatenate", "numpy.array", "numpy.tile", "numpy.ones", "mel_utils_numpy.round_half_up", "mel_utils_numpy.round_half_up", "numpy.tile", "winfunc", "int", "numpy.arange", "numpy.tile", "math.ceil", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.round_half_up", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.round_half_up"], ["", "def", "framesig", "(", "sig", ",", "frame_len", ",", "frame_step", ",", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Frame a signal into overlapping frames.\n\n    :param sig: the audio signal to frame.\n    :param frame_len: length of each frame measured in samples.\n    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n    \"\"\"", "\n", "batch", ",", "slen", "=", "sig", ".", "shape", "\n", "frame_len", "=", "int", "(", "round_half_up", "(", "frame_len", ")", ")", "\n", "frame_step", "=", "int", "(", "round_half_up", "(", "frame_step", ")", ")", "\n", "if", "slen", "<=", "frame_len", ":", "\n", "        ", "numframes", "=", "1", "\n", "", "else", ":", "\n", "        ", "numframes", "=", "1", "+", "int", "(", "math", ".", "ceil", "(", "(", "1.0", "*", "slen", "-", "frame_len", ")", "/", "frame_step", ")", ")", "\n", "\n", "", "padlen", "=", "int", "(", "(", "numframes", "-", "1", ")", "*", "frame_step", "+", "frame_len", ")", "\n", "\n", "zeros", "=", "numpy", ".", "zeros", "(", "(", "batch", ",", "padlen", "-", "slen", ",", ")", ")", "\n", "padsignal", "=", "numpy", ".", "concatenate", "(", "(", "sig", ",", "zeros", ")", ",", "axis", "=", "1", ")", "\n", "\n", "indices", "=", "numpy", ".", "tile", "(", "numpy", ".", "arange", "(", "0", ",", "frame_len", ")", ",", "(", "numframes", ",", "1", ")", ")", "+", "numpy", ".", "tile", "(", "numpy", ".", "arange", "(", "0", ",", "numframes", "*", "frame_step", ",", "frame_step", ")", ",", "(", "frame_len", ",", "1", ")", ")", ".", "T", "\n", "\n", "indices", "=", "numpy", ".", "array", "(", "indices", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "frames", "=", "padsignal", "[", ":", ",", "indices", "]", "\n", "win", "=", "numpy", ".", "tile", "(", "winfunc", "(", "frame_len", ")", ",", "(", "numframes", ",", "1", ")", ")", "\n", "\n", "return", "frames", "*", "win", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.magspec": [[221, 235], ["numpy.fft.rfft", "numpy.absolute"], "function", ["None"], ["", "def", "magspec", "(", "frames", ",", "NFFT", ")", ":", "\n", "    ", "\"\"\"Compute the magnitude spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n\n    :param frames: the array of frames. Each row is a frame.\n    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the magnitude spectrum of the corresponding frame.\n    \"\"\"", "\n", "# if numpy.shape(frames)[-1] > NFFT:", "\n", "#     a = 2", "\n", "# logging.warn(", "\n", "#     'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',", "\n", "#     numpy.shape(frames)[-2], NFFT)", "\n", "complex_spec", "=", "numpy", ".", "fft", ".", "rfft", "(", "frames", ",", "NFFT", ")", "\n", "return", "numpy", ".", "absolute", "(", "complex_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.powspec": [[237, 245], ["numpy.square", "mel_utils_numpy.magspec"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.magspec"], ["", "def", "powspec", "(", "frames", ",", "NFFT", ")", ":", "\n", "    ", "\"\"\"Compute the power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n\n    :param frames: the array of frames. Each row is a frame.\n    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the power spectrum of the corresponding frame.\n    \"\"\"", "\n", "return", "1.0", "/", "NFFT", "*", "numpy", ".", "square", "(", "magspec", "(", "frames", ",", "NFFT", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.preemphasis": [[247, 258], ["signal.copy", "signal.copy.reshape"], "function", ["None"], ["", "def", "preemphasis", "(", "signal", ",", "coeff", "=", "0.95", ")", ":", "\n", "    ", "\"\"\"perform preemphasis on the input signal.\n\n    :param signal: The signal to filter.\n    :param coeff: The preemphasis coefficient. 0 is no filter, default is 0.95.\n    :returns: the filtered signal.\n    \"\"\"", "\n", "batch", "=", "signal", ".", "shape", "[", "0", "]", "\n", "new_signal", "=", "signal", ".", "copy", "(", ")", "\n", "new_signal", "[", ":", ",", "1", ":", "]", "=", "signal", "[", ":", ",", "1", ":", "]", "-", "coeff", "*", "signal", "[", ":", ",", ":", "-", "1", "]", "\n", "return", "new_signal", ".", "reshape", "(", "batch", ",", "-", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing.__init__": [[17, 31], ["sonnet.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["def", "__init__", "(", "self", ",", "num_layers_per_stage", ",", "\n", "num_layers", ",", "\n", "filter_length", ",", "\n", "d_hidden_channels", ",", "\n", "skip_channels", ",", "\n", "prob_dropout_decoder_tf", ",", "\n", "name", "=", "'wavenet_decoder_teacher_forcing'", ")", ":", "\n", "        ", "super", "(", "WavenetDecoderTeacherForcing", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_num_layers_per_stage", "=", "num_layers_per_stage", "\n", "self", ".", "_num_layers", "=", "num_layers", "\n", "self", ".", "_filter_length", "=", "filter_length", "\n", "self", ".", "_d_hidden_channels", "=", "d_hidden_channels", "\n", "self", ".", "_skip_channels", "=", "skip_channels", "\n", "self", ".", "_prob_dropout_decoder_tf", "=", "prob_dropout_decoder_tf", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._build": [[32, 140], ["sonnet.Conv1D", "sonnet.Conv1D", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "sonnet.Conv1D.", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "range", "tensorflow.nn.relu", "sonnet.Conv1D", "sonnet.Conv1D.", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "sonnet.Conv1D", "utils.condition", "tensorflow.nn.relu", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "sonnet.Conv1D", "sonnet.Conv1D.", "tensorflow_probability.distributions.Categorical", "utils.inv_mu_law", "tensorflow.nn.dropout", "sonnet.Conv1D.", "sonnet.Conv1D.", "sonnet.Conv1D", "sonnet.Conv1D.", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "sonnet.Conv1D", "sonnet.Conv1D.", "utils.condition", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "tensorflow.sigmoid", "tensorflow.tanh", "sonnet.Conv1D", "sonnet.Conv1D.", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "sonnet.Conv1D", "sonnet.Conv1D.", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing._nodes_list.append", "sonnet.Conv1D.", "tensorflow.expand_dims", "utils.condition.get_shape().as_list", "WavenetDecoderTeacherForcing.WavenetDecoderTeacherForcing.dec_distr.mode", "utils.condition.get_shape().as_list", "utils.condition.get_shape", "utils.condition.get_shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.condition", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.inv_mu_law", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.condition"], ["", "def", "_build", "(", "self", ",", "x_shifted", ",", "en", ",", "conditioning", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "_nodes_list", "=", "[", "]", "\n", "\n", "startconv", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_d_hidden_channels", ",", "\n", "kernel_shape", "=", "self", ".", "_filter_length", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'startconv'", ")", "\n", "\n", "skip_start", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_skip_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'skip_start'", ")", "\n", "\n", "if", "self", ".", "_prob_dropout_decoder_tf", ">", "0", ":", "\n", "            ", "l", "=", "tf", ".", "nn", ".", "dropout", "(", "x_shifted", ",", "rate", "=", "self", ".", "_prob_dropout_decoder_tf", ")", "\n", "l", "=", "startconv", "(", "x_shifted", ")", "\n", "", "else", ":", "\n", "            ", "l", "=", "startconv", "(", "x_shifted", ")", "\n", "\n", "", "self", ".", "_nodes_list", ".", "append", "(", "l", ")", "\n", "\n", "# Set up skip connections.", "\n", "s", "=", "skip_start", "(", "l", ")", "\n", "self", ".", "_nodes_list", ".", "append", "(", "s", ")", "\n", "\n", "# Residual blocks with skip connections.", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_layers", ")", ":", "\n", "            ", "dilation", "=", "2", "**", "(", "i", "%", "self", ".", "_num_layers_per_stage", ")", "\n", "\n", "causal_convolution", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "2", "*", "self", ".", "_d_hidden_channels", ",", "\n", "kernel_shape", "=", "[", "self", ".", "_filter_length", "]", ",", "\n", "rate", "=", "dilation", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'dilatedconv_%d'", "%", "(", "i", "+", "1", ")", ")", "\n", "\n", "dil", "=", "causal_convolution", "(", "l", ")", "\n", "self", ".", "_nodes_list", ".", "append", "(", "dil", ")", "\n", "\n", "encoding_convolution", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "2", "*", "self", ".", "_d_hidden_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'cond_map_%d'", "%", "(", "i", "+", "1", ")", ")", "\n", "\n", "enc", "=", "encoding_convolution", "(", "en", ")", "\n", "dil", "=", "condition", "(", "dil", ",", "enc", ")", "\n", "self", ".", "_nodes_list", ".", "append", "(", "dil", ")", "\n", "\n", "assert", "dil", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "%", "2", "==", "0", "\n", "m", "=", "dil", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "//", "2", "\n", "d_sigmoid", "=", "tf", ".", "sigmoid", "(", "dil", "[", ":", ",", ":", ",", ":", "m", "]", ")", "\n", "d_tanh", "=", "tf", ".", "tanh", "(", "dil", "[", ":", ",", ":", ",", "m", ":", "]", ")", "\n", "dil", "=", "d_sigmoid", "*", "d_tanh", "\n", "\n", "res_convolution", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_d_hidden_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'res_%d'", "%", "(", "i", "+", "1", ")", ")", "\n", "\n", "l", "+=", "res_convolution", "(", "dil", ")", "\n", "self", ".", "_nodes_list", ".", "append", "(", "l", ")", "\n", "\n", "skip_conv", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_skip_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'skip_%d'", "%", "(", "i", "+", "1", ")", ")", "\n", "\n", "s", "+=", "skip_conv", "(", "dil", ")", "\n", "self", ".", "_nodes_list", ".", "append", "(", "s", ")", "\n", "\n", "\n", "", "s", "=", "tf", ".", "nn", ".", "relu", "(", "s", ")", "\n", "\n", "out", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_skip_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'out1'", ")", "\n", "\n", "s", "=", "out", "(", "s", ")", "\n", "self", ".", "_nodes_list", ".", "append", "(", "s", ")", "\n", "\n", "cond_map_out", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "self", ".", "_skip_channels", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'cond_map_out1'", ")", "\n", "\n", "\n", "s", "=", "condition", "(", "s", ",", "cond_map_out", "(", "en", ")", ")", "\n", "\n", "s", "=", "tf", ".", "nn", ".", "relu", "(", "s", ")", "\n", "self", ".", "_nodes_list", ".", "append", "(", "s", ")", "\n", "\n", "logits_conv", "=", "snt", ".", "Conv1D", "(", "output_channels", "=", "256", ",", "\n", "kernel_shape", "=", "1", ",", "\n", "padding", "=", "snt", ".", "CAUSAL", ",", "\n", "name", "=", "'logits'", ")", "\n", "\n", "self", ".", "logits", "=", "logits_conv", "(", "s", ")", "\n", "\n", "# self.logits = tf.reshape(self.logits, [-1, 256])", "\n", "# self._probs = tf.nn.softmax(self.logits, name='softmax')", "\n", "self", ".", "dec_distr", "=", "tfd", ".", "Categorical", "(", "logits", "=", "self", ".", "logits", ")", "\n", "# dimension of rec_sample should be: [bs, length, 1]", "\n", "\n", "self", ".", "reconstruction", "=", "inv_mu_law", "(", "tf", ".", "expand_dims", "(", "self", ".", "dec_distr", ".", "mode", "(", ")", ",", "axis", "=", "-", "1", ")", "-", "128", ")", "\n", "# self.reconstruction = inv_mu_law(tf.expand_dims(self.dec_distr.mean(), axis=-1) - 128)", "\n", "\n", "return", "self", ".", "dec_distr", ",", "self", ".", "reconstruction", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.mu_law": [[5, 22], ["tensorflow.clip_by_value", "tensorflow.floor", "numpy.log", "tensorflow.cast", "tensorflow.sign", "tensorflow.log", "tensorflow.abs"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["return", "delta", "*", "(", "tensor", "-", "min_orig", ")", "/", "(", "max_orig", "-", "min_orig", ")", "+", "min_out", "\n", "\n", "", "def", "min_max_data_np", "(", "arrays", ")", ":", "\n", "    ", "all_max", "=", "[", "]", "\n", "all_min", "=", "[", "]", "\n", "\n", "for", "arr", "in", "arrays", ":", "\n", "        ", "all_min", ".", "append", "(", "np", ".", "min", "(", "arr", ")", ")", "\n", "all_max", ".", "append", "(", "np", ".", "max", "(", "arr", ")", ")", "\n", "\n", "", "data_min", "=", "np", ".", "min", "(", "all_min", ")", "\n", "data_max", "=", "np", ".", "max", "(", "all_max", ")", "\n", "\n", "return", "data_min", ",", "data_max", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.mu_law_numpy": [[23, 40], ["numpy.clip", "numpy.floor", "numpy.log", "tensorflow.cast", "numpy.sign", "numpy.log", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], []], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.inv_mu_law": [[41, 60], ["tensorflow.cast", "tensorflow.where", "tensorflow.equal", "tensorflow.sign", "tensorflow.abs"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.condition": [[61, 89], ["tensorflow.shape", "tensorflow.shape", "tf.reshape.get_shape().as_list", "tensorflow.shape", "tensorflow.shape", "tf.reshape.get_shape().as_list", "tensorflow.control_dependencies", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tf.reshape.get_shape", "tf.reshape.get_shape", "tensorflow.assert_equal"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.shift_right": [[91, 106], ["tensorflow.pad", "tensorflow.slice", "x.get_shape().as_list", "tensorflow.shape", "tensorflow.stack", "x.get_shape"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.pool1d": [[108, 141], ["tensorflow.shape", "tensorflow.control_dependencies", "pool_fn", "TypeError", "tensorflow.assert_equal", "tensorflow.assert_equal", "tensorflow.mod", "tensorflow.mod"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.empty_all_queues": [[143, 153], ["numpy.array", "sess.run", "numpy.sum", "list", "sess.run", "numpy.array", "numpy.where", "sess.run", "numpy.array"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], []], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.__init__": [[19, 36], ["numpy.array", "numpy.array"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "anomaly_detection_params", ",", "anomaly_detection_dir", ",", "time_ref", ")", ":", "\n", "        ", "self", ".", "anomaly_detection_params", "=", "anomaly_detection_params", "\n", "self", ".", "anomaly_labels", "=", "np", ".", "array", "(", "anomaly_detection_params", "[", "PARAM_ANOMALY_LABELS", "]", ")", "\n", "self", ".", "normal_labels", "=", "np", ".", "array", "(", "anomaly_detection_params", "[", "PARAM_NORMAL_LABELS", "]", ")", "\n", "self", ".", "grid_search_size", "=", "anomaly_detection_params", "[", "PARAM_GRID_SEARCH_SIZE", "]", "\n", "self", ".", "anomaly_detection_dir", "=", "anomaly_detection_dir", "\n", "self", ".", "time_ref", "=", "time_ref", "\n", "\n", "self", ".", "validation_samples", "=", "None", "\n", "self", ".", "validation_reconstructions", "=", "None", "\n", "self", ".", "validation_labels", "=", "None", "\n", "self", ".", "validation_reconstr_losses", "=", "None", "\n", "\n", "self", ".", "test_samples", "=", "None", "\n", "self", ".", "test_reconstructions", "=", "None", "\n", "self", ".", "test_labels", "=", "None", "\n", "self", ".", "test_reconstr_losses", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.set_data": [[37, 52], ["numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum"], "methods", ["None"], ["", "def", "set_data", "(", "self", ",", "ds_key", ",", "samples", ",", "reconstructions", ",", "labels", ",", "reconstruction_losses", ")", ":", "\n", "        ", "if", "ds_key", "==", "VALIDATION", ":", "\n", "            ", "self", ".", "validation_samples", "=", "samples", "\n", "self", ".", "validation_reconstructions", "=", "reconstructions", "\n", "self", ".", "validation_labels", "=", "labels", "\n", "self", ".", "validation_reconstr_losses", "=", "reconstruction_losses", "\n", "\n", "", "elif", "ds_key", "==", "TEST", ":", "\n", "            ", "self", ".", "test_samples", "=", "samples", "\n", "self", ".", "test_reconstructions", "=", "reconstructions", "\n", "self", ".", "test_labels", "=", "labels", "\n", "self", ".", "test_reconstr_losses", "=", "reconstruction_losses", "\n", "\n", "self", ".", "n_anomalous_total_test", "=", "np", ".", "sum", "(", "np", ".", "sum", "(", "(", "self", ".", "test_labels", "==", "self", ".", "anomaly_labels", "[", ":", ",", "None", "]", ")", ".", "any", "(", "axis", "=", "0", ")", ")", ")", "\n", "self", ".", "n_normal_total_test", "=", "np", ".", "sum", "(", "np", ".", "sum", "(", "(", "self", ".", "test_labels", "==", "self", ".", "normal_labels", "[", ":", ",", "None", "]", ")", ".", "any", "(", "axis", "=", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.indices_of_labels": [[53, 58], ["numpy.argwhere().flatten", "numpy.arange", "len", "numpy.argwhere"], "methods", ["None"], ["", "", "def", "indices_of_labels", "(", "self", ",", "labels", ",", "target_labels", ")", ":", "\n", "        ", "if", "target_labels", "is", "None", ":", "\n", "            ", "return", "np", ".", "arange", "(", "len", "(", "labels", ")", ")", "\n", "\n", "", "return", "np", ".", "argwhere", "(", "(", "labels", "==", "target_labels", "[", ":", ",", "None", "]", ")", ".", "any", "(", "axis", "=", "0", ")", ")", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.compute_metrics": [[59, 73], ["AnomalyDetector.AnomalyDetector.indices_of_labels", "numpy.mean", "mel_utils_numpy.mfcc", "mel_utils_numpy.mfcc", "mel_utils_numpy.mcd_per_sample", "numpy.square", "psnr.flatten", "numpy.log10", "numpy.log10", "target_samples.max"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.indices_of_labels", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mfcc", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.mel_utils_numpy.mcd_per_sample"], ["", "def", "compute_metrics", "(", "self", ",", "samples", ",", "reconstructions", ",", "reconstruction_losses", ",", "sample_rate", ",", "labels", ",", "target_labels", ")", ":", "\n", "        ", "target_indices", "=", "self", ".", "indices_of_labels", "(", "labels", ",", "target_labels", ")", "\n", "target_samples", "=", "samples", "[", "target_indices", "]", "\n", "target_reconstructions", "=", "reconstructions", "[", "target_indices", "]", "\n", "\n", "# will have shape (bs, 1)", "\n", "mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "target_samples", "-", "target_reconstructions", ")", ",", "axis", "=", "1", ")", "\n", "psnr", "=", "20", "*", "np", ".", "log10", "(", "target_samples", ".", "max", "(", ")", ")", "-", "10", "*", "np", ".", "log10", "(", "mse", ")", "\n", "\n", "mfcc_original", "=", "mfcc", "(", "target_samples", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "mfcc_reconstructed", "=", "mfcc", "(", "target_reconstructions", ",", "samplerate", "=", "sample_rate", ",", "preemph", "=", "0", ")", "\n", "mcd", "=", "mcd_per_sample", "(", "mfcc_original", ",", "mfcc_reconstructed", ")", "\n", "\n", "return", "mcd", ",", "psnr", ".", "flatten", "(", ")", ",", "reconstruction_losses", "[", "target_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.detect_anomalies": [[74, 135], ["AnomalyDetector.AnomalyDetector.compute_metrics", "numpy.array", "AnomalyDetector.AnomalyDetector.pair_plots", "AnomalyDetector.AnomalyDetector.plot_3d", "AnomalyDetector.AnomalyDetector.compute_metrics", "numpy.array", "AnomalyDetector.AnomalyDetector.pair_plots", "AnomalyDetector.AnomalyDetector.plot_3d", "AnomalyDetector.AnomalyDetector.grid_search_threshold", "AnomalyDetector.AnomalyDetector.grid_search_threshold", "AnomalyDetector.AnomalyDetector.grid_search_threshold", "numpy.concatenate", "pandas.DataFrame", "data_frame.set_index.set_index.set_index", "data_frame.set_index.set_index.to_csv", "print", "list", "list", "print", "map", "map"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.compute_metrics", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.pair_plots", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.plot_3d", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.compute_metrics", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.pair_plots", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.plot_3d", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.grid_search_threshold", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.grid_search_threshold", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.grid_search_threshold"], ["", "def", "detect_anomalies", "(", "self", ",", "sample_rate", ",", "reconstruction_method", ")", ":", "\n", "        ", "if", "self", ".", "test_labels", "is", "None", ":", "\n", "            ", "print", "(", "'Skipping doing anomaly detection. Both validation and test must be available! Got only validation.'", ")", "\n", "", "elif", "self", ".", "validation_samples", "is", "None", ":", "\n", "            ", "print", "(", "'Skipping doing anomaly detection. Both validation and test must be available! Got only test.'", ")", "\n", "\n", "# set threshhold from validation data", "\n", "", "mcd_validation", ",", "psnr_validation", ",", "loss_validation", "=", "self", ".", "compute_metrics", "(", "self", ".", "validation_samples", ",", "\n", "self", ".", "validation_reconstructions", ",", "\n", "self", ".", "validation_reconstr_losses", ",", "\n", "sample_rate", ",", "\n", "self", ".", "validation_labels", ",", "\n", "None", ",", "\n", ")", "\n", "\n", "binary_labels", "=", "np", ".", "array", "(", "list", "(", "map", "(", "self", ".", "label_binary_value", ",", "self", ".", "validation_labels", ")", ")", ")", "\n", "self", ".", "pair_plots", "(", "mcd_validation", ",", "psnr_validation", ",", "loss_validation", ",", "binary_labels", ",", "\n", "self", ".", "anomaly_detection_dir", "+", "'/pair_plot_metrics_{}_validation_{}.png'", ".", "format", "(", "reconstruction_method", ",", "self", ".", "time_ref", ")", ")", "\n", "self", ".", "plot_3d", "(", "mcd_validation", ",", "psnr_validation", ",", "loss_validation", ",", "binary_labels", ",", "\n", "self", ".", "anomaly_detection_dir", "+", "'/3Dplot_metrics_{}_validation_{}.png'", ".", "format", "(", "reconstruction_method", ",", "self", ".", "time_ref", ")", ")", "\n", "\n", "# calculate test anomalies based on validation threshold", "\n", "\n", "mcd_test", ",", "psnr_test", ",", "loss_test", "=", "self", ".", "compute_metrics", "(", "self", ".", "test_samples", ",", "\n", "self", ".", "test_reconstructions", ",", "\n", "self", ".", "test_reconstr_losses", ",", "\n", "sample_rate", ",", "\n", "self", ".", "test_labels", ",", "\n", "target_labels", "=", "None", ",", "\n", ")", "\n", "\n", "binary_labels", "=", "np", ".", "array", "(", "list", "(", "map", "(", "self", ".", "label_binary_value", ",", "self", ".", "test_labels", ")", ")", ")", "\n", "self", ".", "pair_plots", "(", "mcd_test", ",", "psnr_test", ",", "loss_test", ",", "binary_labels", ",", "\n", "self", ".", "anomaly_detection_dir", "+", "'/pair_plot_metrics_{}_test_{}.png'", ".", "format", "(", "reconstruction_method", ",", "self", ".", "time_ref", ")", ")", "\n", "self", ".", "plot_3d", "(", "mcd_test", ",", "psnr_test", ",", "loss_test", ",", "binary_labels", ",", "\n", "self", ".", "anomaly_detection_dir", "+", "'/3Dplot_metrics_{}_test_{}.png'", ".", "format", "(", "reconstruction_method", ",", "self", ".", "time_ref", ")", ")", "\n", "\n", "\n", "# grid search from the validation data to find best anomaly detection, based on std deviation of the metrics", "\n", "\n", "# mcd", "\n", "greater_than", "=", "lambda", "x", ",", "y", ":", "x", ">=", "y", "\n", "less_than", "=", "lambda", "x", ",", "y", ":", "x", "<=", "y", "\n", "\n", "best_scores_mcd", "=", "self", ".", "grid_search_threshold", "(", "mcd_test", ",", "greater_than", ",", "mcd_validation", ")", "\n", "best_scores_psnr", "=", "self", ".", "grid_search_threshold", "(", "psnr_test", ",", "less_than", ",", "psnr_validation", ")", "\n", "best_scores_loss", "=", "self", ".", "grid_search_threshold", "(", "loss_test", ",", "greater_than", ",", "loss_validation", ")", "\n", "\n", "all_metrics_scores", "=", "np", ".", "concatenate", "(", "[", "best_scores_mcd", ",", "best_scores_psnr", ",", "best_scores_loss", "]", ")", "\n", "\n", "data_frame", "=", "pd", ".", "DataFrame", "(", "all_metrics_scores", ",", "\n", "columns", "=", "[", "'threshold'", ",", "'precision anomaly'", ",", "'precision normal'", ",", "'recall anomaly'", ",", "\n", "'recall normal'", ",", "'discriminant power anomaly'", ",", "'youden index anomaly'", "]", ")", "\n", "\n", "n_total_entries_per_metric", "=", "all_metrics_scores", ".", "shape", "[", "0", "]", "//", "3", "\n", "data_frame", "[", "'used_metric'", "]", "=", "[", "'MCD'", "]", "*", "n_total_entries_per_metric", "+", "[", "'PSNR'", "]", "*", "n_total_entries_per_metric", "+", "[", "'LOSS'", "]", "*", "n_total_entries_per_metric", "\n", "data_frame", "=", "data_frame", ".", "set_index", "(", "'used_metric'", ")", "\n", "\n", "output_file", "=", "self", ".", "anomaly_detection_dir", "+", "'/anomaly_detection_{}_test_{}.csv'", ".", "format", "(", "reconstruction_method", ",", "self", ".", "time_ref", ")", "\n", "data_frame", ".", "to_csv", "(", "output_file", ",", "float_format", "=", "'%.2f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.grid_search_threshold": [[136, 171], ["AnomalyDetector.AnomalyDetector.indices_of_labels", "AnomalyDetector.AnomalyDetector.indices_of_labels", "numpy.std", "numpy.mean", "numpy.linspace", "numpy.stack", "len", "compare_func", "numpy.argwhere().flatten", "numpy.argwhere().flatten", "len", "len", "AnomalyDetector.div", "AnomalyDetector.div", "AnomalyDetector.div", "AnomalyDetector.div", "scores.append", "numpy.intersect1d", "numpy.intersect1d", "numpy.intersect1d", "len", "len", "len", "len", "numpy.argwhere", "numpy.argwhere", "numpy.sqrt", "numpy.log10", "numpy.log10", "numpy.logical_not", "AnomalyDetector.div", "AnomalyDetector.div"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.indices_of_labels", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.indices_of_labels", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.div", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.div", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.div", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.div", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.div", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.div"], ["", "def", "grid_search_threshold", "(", "self", ",", "metric_per_sample_test", ",", "compare_func", ",", "metric_per_sample_validation", ")", ":", "\n", "        ", "true_anomaly_indices", "=", "self", ".", "indices_of_labels", "(", "self", ".", "test_labels", ",", "self", ".", "anomaly_labels", ")", "\n", "true_normal_indices", "=", "self", ".", "indices_of_labels", "(", "self", ".", "test_labels", ",", "self", ".", "normal_labels", ")", "\n", "\n", "assert", "len", "(", "np", ".", "intersect1d", "(", "true_anomaly_indices", ",", "\n", "true_normal_indices", ")", ")", "==", "0", ",", "'Got duplicates in normal and anomaly indices'", "\n", "# assert len(true_anomaly_indices) + len(true_normal_indices) == len(self.test_labels), 'Some labels are missing'", "\n", "\n", "scores", "=", "[", "]", "\n", "std_metric_value", "=", "np", ".", "std", "(", "metric_per_sample_validation", ")", "\n", "mean_metric_value", "=", "np", ".", "mean", "(", "metric_per_sample_validation", ")", "\n", "for", "stddev", "in", "np", ".", "linspace", "(", "-", "3", "*", "std_metric_value", ",", "std_metric_value", "*", "3", ",", "self", ".", "grid_search_size", ")", ":", "\n", "            ", "threshold", "=", "mean_metric_value", "+", "stddev", "\n", "anomaly_truth_table", "=", "compare_func", "(", "metric_per_sample_test", ",", "threshold", ")", "\n", "predicted_anomalous_indices", "=", "np", ".", "argwhere", "(", "anomaly_truth_table", ")", ".", "flatten", "(", ")", "\n", "predicted_normal_indices", "=", "np", ".", "argwhere", "(", "np", ".", "logical_not", "(", "anomaly_truth_table", ")", ")", ".", "flatten", "(", ")", "\n", "\n", "correctly_labeled_anomalous", "=", "len", "(", "np", ".", "intersect1d", "(", "predicted_anomalous_indices", ",", "true_anomaly_indices", ")", ")", "\n", "correctly_labeled_normal", "=", "len", "(", "np", ".", "intersect1d", "(", "predicted_normal_indices", ",", "true_normal_indices", ")", ")", "\n", "\n", "precision_anomaly", "=", "div", "(", "correctly_labeled_anomalous", ",", "len", "(", "predicted_anomalous_indices", ")", ")", "\n", "recall_anomaly", "=", "div", "(", "correctly_labeled_anomalous", ",", "len", "(", "true_anomaly_indices", ")", ")", "\n", "\n", "precision_normal", "=", "div", "(", "correctly_labeled_normal", ",", "len", "(", "predicted_normal_indices", ")", ")", "\n", "recall_normal", "=", "div", "(", "correctly_labeled_normal", ",", "len", "(", "true_normal_indices", ")", ")", "\n", "\n", "discriminant_power_anomaly", "=", "(", "np", ".", "sqrt", "(", "3", ")", "/", "np", ".", "pi", ")", "*", "(", "np", ".", "log10", "(", "div", "(", "recall_anomaly", ",", "(", "1", "-", "recall_anomaly", ")", ")", ")", "\n", "+", "np", ".", "log10", "(", "div", "(", "recall_normal", ",", "(", "1", "-", "recall_normal", ")", ")", ")", ")", "\n", "\n", "youden_index", "=", "recall_anomaly", "-", "(", "1", "-", "recall_normal", ")", "\n", "\n", "scores", ".", "append", "(", "[", "threshold", ",", "precision_anomaly", ",", "precision_normal", ",", "recall_anomaly", ",", "recall_normal", ",", "\n", "discriminant_power_anomaly", ",", "youden_index", "]", ")", "\n", "\n", "", "return", "np", ".", "stack", "(", "scores", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.row_with_most_maxes_on_columns": [[172, 178], ["numpy.argmax", "numpy.unique", "numpy.argmax"], "methods", ["None"], ["", "def", "row_with_most_maxes_on_columns", "(", "self", ",", "matrix", ")", ":", "\n", "        ", "maxes_on_rows", "=", "np", ".", "argmax", "(", "matrix", ",", "axis", "=", "0", ")", "\n", "vals", ",", "counts", "=", "np", ".", "unique", "(", "maxes_on_rows", ",", "return_counts", "=", "True", ")", "\n", "best_score_row", "=", "vals", "[", "np", ".", "argmax", "(", "counts", ")", "]", "\n", "\n", "return", "best_score_row", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.pair_plots": [[179, 196], ["pandas.DataFrame", "matplotlib.clf", "seaborn.PairGrid", "seaborn.PairGrid.map_upper", "seaborn.PairGrid.map_lower", "seaborn.PairGrid.map_diag", "seaborn.PairGrid.add_legend", "matplotlib.savefig", "labels.flatten"], "methods", ["None"], ["", "def", "pair_plots", "(", "self", ",", "mcd", ",", "psnr", ",", "loss", ",", "labels", ",", "file_name", ")", ":", "\n", "        ", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "'mcd'", ":", "mcd", ",", "\n", "'psnr'", ":", "psnr", ",", "\n", "'loss'", ":", "loss", ",", "\n", "'label'", ":", "labels", ".", "flatten", "(", ")", "\n", "}", "\n", ")", "\n", "\n", "plt", ".", "clf", "(", ")", "\n", "g", "=", "sns", ".", "PairGrid", "(", "df", ",", "hue", "=", "'label'", ")", "\n", "g", ".", "map_upper", "(", "plt", ".", "scatter", ",", "s", "=", "1", ")", "\n", "g", ".", "map_lower", "(", "sns", ".", "kdeplot", ",", "shade", "=", "True", ",", "shade_lowest", "=", "False", ",", "n_levels", "=", "4", ",", "alpha", "=", "0.5", ")", "\n", "g", ".", "map_diag", "(", "sns", ".", "kdeplot", ",", "lw", "=", "1", ",", "legend", "=", "False", ",", "shade", "=", "True", ")", "\n", "g", ".", "add_legend", "(", ")", "\n", "plt", ".", "savefig", "(", "file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.plot_3d": [[197, 210], ["matplotlib.figure", "matplotlib.figure.add_subplot", "numpy.logical_not", "plt.figure.add_subplot.scatter", "plt.figure.add_subplot.scatter", "plt.figure.add_subplot.set_xlabel", "plt.figure.add_subplot.set_ylabel", "plt.figure.add_subplot.set_zlabel", "plt.figure.add_subplot.legend", "matplotlib.savefig", "matplotlib.clf"], "methods", ["None"], ["", "def", "plot_3d", "(", "self", ",", "mcd", ",", "psnr", ",", "loss", ",", "labels", ",", "file_name", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "111", ",", "projection", "=", "'3d'", ")", "\n", "anomaly_indices", "=", "labels", "==", "LABEL_ANOMALY", "\n", "normal_indices", "=", "np", ".", "logical_not", "(", "anomaly_indices", ")", "\n", "ax", ".", "scatter", "(", "mcd", "[", "anomaly_indices", "]", ",", "psnr", "[", "anomaly_indices", "]", ",", "loss", "[", "anomaly_indices", "]", ",", "color", "=", "'orange'", ",", "label", "=", "LABEL_ANOMALY", ")", "\n", "ax", ".", "scatter", "(", "mcd", "[", "normal_indices", "]", ",", "psnr", "[", "normal_indices", "]", ",", "loss", "[", "normal_indices", "]", ",", "color", "=", "'green'", ",", "label", "=", "LABEL_NORMAL", ",", "marker", "=", "'+'", ")", "\n", "ax", ".", "set_xlabel", "(", "'MCD'", ")", "\n", "ax", ".", "set_ylabel", "(", "'PSNR'", ")", "\n", "ax", ".", "set_zlabel", "(", "'LOSS'", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "file_name", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.AnomalyDetector.label_binary_value": [[211, 216], ["None"], "methods", ["None"], ["", "def", "label_binary_value", "(", "self", ",", "label", ")", ":", "\n", "        ", "if", "label", "in", "self", ".", "normal_labels", ":", "\n", "            ", "return", "LABEL_NORMAL", "\n", "", "else", ":", "\n", "            ", "return", "LABEL_ANOMALY", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.AnomalyDetector.div": [[217, 221], ["None"], "function", ["None"], ["", "", "", "def", "div", "(", "x", ",", "y", ")", ":", "\n", "    ", "if", "y", "==", "0", ":", "\n", "        ", "return", "1e-9", "\n", "", "return", "x", "/", "y", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.__init__": [[13, 33], ["argo.core.network.AbstractGaussian.AbstractGaussian.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module_tuple", "=", "(", "\"Linear\"", ",", "{", "}", ")", ",", "\n", "output_size", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "minimal_covariance", "=", "0.", ",", "\n", "covariance_parameterization", "=", "\"softplus\"", ",", "\n", "scalar_covariance", "=", "False", ",", "\n", "initializers", "=", "{", "}", ",", "\n", "regularizers", "=", "{", "}", ",", "\n", "contractive_regularizer", "=", "None", ",", "\n", "name", "=", "'gaussian_tridiagonal_precision'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "module_tuple", "=", "module_tuple", ",", "\n", "output_size", "=", "output_size", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "minimal_covariance", "=", "minimal_covariance", ",", "\n", "covariance_parameterization", "=", "covariance_parameterization", ",", "\n", "scalar_covariance", "=", "scalar_covariance", ",", "\n", "initializers", "=", "initializers", ",", "\n", "regularizers", "=", "regularizers", ",", "\n", "contractive_regularizer", "=", "contractive_regularizer", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision._build": [[34, 62], ["GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.set_contractive_regularizer", "tensorflow_probability.distributions.MultivariateNormalTriL", "types.MethodType", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.set_contractive_regularizer", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "_build", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "mean", ",", "covariance", ",", "scale", ",", "L", "=", "self", ".", "create_mean_n_cov_layers", "(", "inputs", ")", "\n", "\n", "mean_t", "=", "mean", "\n", "covariance_t", "=", "covariance", "\n", "\n", "self", ".", "set_contractive_regularizer", "(", "mean", ",", "covariance_t", ",", "\n", "self", ".", "_contractive_regularizer_inputs", ",", "\n", "self", ".", "_contractive_regularizer_tuple", ",", "\n", "self", ".", "_contractive_collection_network_str", ")", "\n", "\n", "# You might wonder why we use cholesky here, if we already have the covariance matrix.", "\n", "# The reason is, that because the matrix is ill conditioned often,", "\n", "# after inverting the precision matrix the cov can become asymetric because of numerical issues,", "\n", "# and the validate arguments gives an error.", "\n", "# If we give its cholesky decomposition, it stays symmetric.", "\n", "\n", "output_distribution", "=", "tfd", ".", "MultivariateNormalTriL", "(", "loc", "=", "mean_t", ",", "scale_tril", "=", "L", ",", "\n", "validate_args", "=", "True", ")", "\n", "\n", "# add reconstruction_node method (needed to some sort of mean or median to get reconstructions without sampling)", "\n", "def", "reconstruction_node", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "mean", "(", ")", "\n", "\n", "", "output_distribution", ".", "reconstruction_node", "=", "types", ".", "MethodType", "(", "reconstruction_node", ",", "output_distribution", ")", "\n", "\n", "self", ".", "mean", "=", "mean", "\n", "return", "output_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean": [[63, 65], ["None"], "methods", ["None"], ["", "def", "mean", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.create_mean_n_cov_layers": [[66, 134], ["argo.core.utils.argo_utils.load_sonnet_module", "argo.core.utils.argo_utils.load_sonnet_module.", "argo.core.utils.argo_utils.load_sonnet_module", "argo.core.utils.argo_utils.load_sonnet_module.", "argo.core.utils.argo_utils.load_sonnet_module", "argo.core.utils.argo_utils.load_sonnet_module.", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.get_covariance_from_parameters_tf", "tensorflow.transpose", "tensorflow.layers.flatten", "tensorflow.reshape", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "numpy.prod", "tensorflow.reshape", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision._get_stride", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "Exception", "tensorflow.layers.flatten.shape.as_list", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.check_key_not_in", "GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision._get_stride", "tensorflow.layers.flatten.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_sonnet_module", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.get_covariance_from_parameters_tf", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._get_stride", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer.check_key_not_in", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractStochasticLayer.AbstractStochasticLayer._get_stride"], ["", "def", "create_mean_n_cov_layers", "(", "self", ",", "inputs", ")", ":", "\n", "# create the layers for mean and covariance", "\n", "\n", "        ", "module_name", ",", "module_kwargs", "=", "self", ".", "_module_tuple", "\n", "extra_kwargs", "=", "self", ".", "_extra_kwargs", "\n", "# if self._output_shape is set I should write sizes in the Submodule", "\n", "if", "module_name", "==", "\"Linear\"", "or", "module_name", "==", "\"LinearWN\"", ":", "\n", "            ", "inputs", "=", "tf", ".", "layers", ".", "flatten", "(", "inputs", ")", "\n", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_size\"", ",", "module_kwargs", ")", "\n", "extra_kwargs", "[", "\"output_size\"", "]", "=", "np", ".", "prod", "(", "self", ".", "_output_shape", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_output_shape", "=", "[", "module_kwargs", "[", "\"output_size\"", "]", "]", "\n", "\n", "", "", "elif", "module_name", "==", "\"Conv2D\"", "or", "module_name", "==", "\"Conv2DWN\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"stride\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"padding\"", ",", "module_kwargs", ",", "'SAME'", ")", "\n", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "extra_kwargs", "[", "\"stride\"", "]", "=", "self", ".", "_get_stride", "(", "inputs", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ",", "\n", "self", ".", "_output_shape", ")", "\n", "", "", "elif", "module_name", "==", "\"Conv1D\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"padding\"", ",", "module_kwargs", ",", "'SAME'", ")", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "\n", "", "", "elif", "module_name", "==", "\"Conv2DTranspose\"", "or", "module_name", "==", "\"Conv2DTransposeWN\"", ":", "\n", "            ", "if", "self", ".", "_output_shape", "is", "not", "None", ":", "\n", "                ", "self", ".", "check_key_not_in", "(", "\"output_channels\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"stride\"", ",", "module_kwargs", ")", "\n", "self", ".", "check_key_not_in", "(", "\"output_shape\"", ",", "module_kwargs", ")", "\n", "extra_kwargs", "[", "\"output_shape\"", "]", "=", "self", ".", "_output_shape", "[", "0", ":", "2", "]", "\n", "extra_kwargs", "[", "\"stride\"", "]", "=", "self", ".", "_get_stride", "(", "self", ".", "_output_shape", ",", "\n", "inputs", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "extra_kwargs", "[", "\"output_channels\"", "]", "=", "self", ".", "_output_shape", "[", "2", "]", "\n", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\n", "\"module name `%s` is not allowed, is not implemented yet to be wrapped by a Stochastic Layer.\"", "%", "module_name", ")", "\n", "\n", "", "kwargs", "=", "{", "**", "extra_kwargs", ",", "\n", "**", "module_kwargs", "}", "\n", "\n", "sntmodule_mean", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "mean", "=", "sntmodule_mean", "(", "inputs", ")", "\n", "\n", "sntmodule_cov", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "covariance_params", "=", "sntmodule_cov", "(", "inputs", ")", "\n", "\n", "sntmodule_cov_plus", "=", "load_sonnet_module", "(", "module_name", ",", "kwargs", ")", "\n", "covariance_params_plus", "=", "sntmodule_cov_plus", "(", "inputs", ")", "\n", "\n", "# if I am using linear layers I need to reshape to match output_shape", "\n", "if", "module_name", "==", "\"Linear\"", "or", "module_name", "==", "\"LinearWN\"", ":", "\n", "            ", "output_shape", "=", "[", "-", "1", "]", "+", "self", ".", "_output_shape", "\n", "mean", "=", "tf", ".", "reshape", "(", "mean", ",", "output_shape", ")", "\n", "if", "not", "self", ".", "_scalar_bool", ":", "\n", "                ", "covariance_params", "=", "tf", ".", "reshape", "(", "covariance_params", ",", "output_shape", ")", "\n", "\n", "", "", "covariance", ",", "L", "=", "self", ".", "get_covariance_from_parameters_tf", "(", "covariance_params", ",", "covariance_params_plus", ")", "\n", "# I don't need the standard deviation for the MultivariateFullCovariance", "\n", "scale", "=", "None", "\n", "mean", "=", "tf", ".", "transpose", "(", "mean", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "return", "mean", ",", "covariance", ",", "scale", ",", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.get_covariance_from_parameters_tf": [[135, 173], ["tensorflow.unstack", "tensorflow.unstack", "range", "tensorflow.stack", "tensorflow.stack", "len", "tensorflow.map_fn", "tensorflow.slice", "tensorflow.map_fn", "tensorflow.pad", "tensorflow.matmul", "tensorflow.linalg.inv", "tensorflow.linalg.cholesky", "tensorflow.transpose", "GaussianTriDiagonalPrecision.diagonalize_covariance_matrix", "GaussianTriDiagonalPrecision.diagonalize_covariance_matrix", "tensorflow.eye", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.diagonalize_covariance_matrix", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.diagonalize_covariance_matrix"], ["", "def", "get_covariance_from_parameters_tf", "(", "self", ",", "parameters", ",", "parameters_plus", ")", ":", "\n", "\n", "        ", "unst_param", "=", "tf", ".", "unstack", "(", "parameters", ",", "axis", "=", "2", ")", "\n", "unst_param_plus", "=", "tf", ".", "unstack", "(", "parameters_plus", ",", "axis", "=", "2", ")", "\n", "\n", "covariances", "=", "[", "]", "\n", "\n", "LS", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "unst_param", ")", ")", ":", "\n", "            ", "param", "=", "unst_param", "[", "i", "]", "\n", "param_plus", "=", "unst_param_plus", "[", "i", "]", "\n", "\n", "# loop through batches and tridiagonalize the covariance matrices", "\n", "# tf.nn.softplus(parameters)", "\n", "L1", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "diagonalize_covariance_matrix", "(", "x", ",", "epsilon", "=", "0", ")", ",", "param", ")", "\n", "\n", "param_plus", "=", "tf", ".", "slice", "(", "param_plus", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "param_plus", ")", "[", "1", "]", "-", "1", "]", ")", "\n", "\n", "L2", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "diagonalize_covariance_matrix", "(", "x", ",", "epsilon", "=", "0", ")", ",", "param_plus", ")", "\n", "L2", "=", "tf", ".", "pad", "(", "L2", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "1", "]", "]", ",", "mode", "=", "'CONSTANT'", ")", "\n", "\n", "L", "=", "L1", "+", "L2", "\n", "\n", "prec", "=", "tf", ".", "matmul", "(", "L", ",", "tf", ".", "transpose", "(", "L", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "\n", "prec", "=", "prec", "+", "(", "self", ".", "_minimal_covariance", "+", "NUMTOL", ")", "*", "tf", ".", "eye", "(", "tf", ".", "shape", "(", "prec", ")", "[", "-", "1", "]", ")", "\n", "\n", "cov", "=", "tf", ".", "linalg", ".", "inv", "(", "prec", ")", "\n", "\n", "L_cov", "=", "tf", ".", "linalg", ".", "cholesky", "(", "cov", ")", "\n", "covariances", "+=", "[", "cov", "]", "\n", "LS", "+=", "[", "L_cov", "]", "\n", "\n", "", "covariance", "=", "tf", ".", "stack", "(", "covariances", ",", "axis", "=", "1", ")", "\n", "LS", "=", "tf", ".", "stack", "(", "LS", ",", "axis", "=", "1", ")", "\n", "\n", "return", "covariance", ",", "LS", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.tridiagonalize_covariance_matrix": [[175, 189], ["tensorflow.zeros", "tensorflow.linalg.set_diag", "tensorflow.zeros", "tensorflow.linalg.set_diag", "tensorflow.pad", "tensorflow.matmul", "tensorflow.shape", "tensorflow.transpose"], "function", ["None"], ["", "", "def", "tridiagonalize_covariance_matrix", "(", "params", ",", "params_plus", ")", ":", "\n", "    ", "time_dim", "=", "tf", ".", "shape", "(", "params", ")", "[", "0", "]", "\n", "\n", "L1", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "time_dim", ",", "time_dim", ")", ")", "\n", "diagonal1", "=", "params", "\n", "L1", "=", "tf", ".", "linalg", ".", "set_diag", "(", "L1", ",", "diagonal1", ")", "\n", "\n", "L2", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "time_dim", "-", "1", ",", "time_dim", "-", "1", ")", ")", "\n", "diagonal2", "=", "params_plus", "\n", "L2", "=", "tf", ".", "linalg", ".", "set_diag", "(", "L2", ",", "diagonal2", ")", "\n", "L2", "=", "tf", ".", "pad", "(", "L2", ",", "[", "[", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "1", "]", "]", ",", "mode", "=", "'CONSTANT'", ")", "\n", "\n", "L", "=", "L1", "+", "L2", "\n", "return", "tf", ".", "matmul", "(", "L", ",", "tf", ".", "transpose", "(", "L", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.diagonalize_covariance_matrix": [[191, 199], ["tensorflow.zeros", "tensorflow.linalg.set_diag", "tensorflow.shape"], "function", ["None"], ["", "def", "diagonalize_covariance_matrix", "(", "params", ",", "epsilon", "=", "0.01", ")", ":", "\n", "    ", "time_dim", "=", "tf", ".", "shape", "(", "params", ")", "[", "0", "]", "\n", "\n", "L1", "=", "tf", ".", "zeros", "(", "shape", "=", "(", "time_dim", ",", "time_dim", ")", ")", "\n", "diagonal1", "=", "params", "+", "epsilon", "\n", "L1", "=", "tf", ".", "linalg", ".", "set_diag", "(", "L1", ",", "diagonal1", ")", "\n", "\n", "return", "L1", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_woodberry.test_woo1": [[9, 24], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.woodberry._woodberry", "sess.run", "numpy.allclose", "numpy.asarray", "numpy.asarray", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.linalg.diag"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["def", "test_woo1", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", "]", ",", "[", "2.", "]", ",", "[", "3.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "C", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "1.", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "matmul", "(", "tf", ".", "linalg", ".", "diag", "(", "C", ")", ",", "V", ")", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_woodberry", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "C", "=", "C", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_woodberry.test_woo2": [[26, 41], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.woodberry._woodberry", "sess.run", "numpy.allclose", "numpy.asarray", "numpy.asarray", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.linalg.diag"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_woo2", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", ",", "2.", "]", ",", "[", "3.", ",", "4.", "]", ",", "[", "5.", ",", "6.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "C", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "1.", ",", "1.", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "matmul", "(", "tf", ".", "linalg", ".", "diag", "(", "C", ")", ",", "V", ")", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_woodberry", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "C", "=", "C", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_woodberry.test_woo3": [[43, 58], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.woodberry._woodberry", "sess.run", "numpy.allclose", "numpy.asarray", "numpy.asarray", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.linalg.diag"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_woo3", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", ",", "2.", "]", ",", "[", "3.", ",", "4.", "]", ",", "[", "5.", ",", "6.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "C", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "2.", ",", "2.", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "matmul", "(", "tf", ".", "linalg", ".", "diag", "(", "C", ")", ",", "V", ")", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_woodberry", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "C", "=", "C", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_woodberry.test_woo4": [[60, 78], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.ones", "tensorflow.einsum", "core.optimizers.linalg.woodberry._woodberry_alpha_trick", "sess.run", "numpy.allclose", "numpy.asarray", "numpy.asarray", "tensorflow.linalg.inv", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.linalg.diag"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry_alpha_trick", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_woo4", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", ",", "2.", "]", ",", "[", "3.", ",", "4.", "]", ",", "[", "5.", ",", "6.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "C", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "2.", ",", "2.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "G", "=", "tf", ".", "ones", "(", "[", "1", ",", "3", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "(", "alpha", "*", "I", "+", "tf", ".", "einsum", "(", "\"ik, lkj-> lij\"", ",", "U", ",", "tf", ".", "einsum", "(", "\"lik, kj-> lij\"", ",", "tf", ".", "linalg", ".", "diag", "(", "C", ")", ",", "V", ")", ")", ")", "/", "(", "1.", "+", "alpha", ")", "\n", "\n", "compare", "=", "tf", ".", "einsum", "(", "\"lik, lk-> li\"", ",", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", ",", "G", ")", "\n", "\n", "inverse", "=", "_woodberry_alpha_trick", "(", "U", "=", "U", ",", "C", "=", "C", ",", "V_T", "=", "V", ",", "alpha", "=", "alpha", ",", "grads", "=", "G", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh1": [[10, 26], ["tensorflow.constant", "tensorflow.eye", "tensorflow.transpose", "tensorflow.eye", "tensorflow.matmul", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison", "sess.run", "numpy.allclose"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["def", "test_sh1", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "eye", "(", "2", ",", "batch_shape", "=", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "2", ",", "batch_shape", "=", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "matmul", "=", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "alpha_i", "=", "alpha", "*", "I", "\n", "v_", "=", "alpha_i", "+", "matmul", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh2": [[28, 42], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison", "sess.run", "numpy.allclose", "numpy.asarray", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh2", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "[", "1.", ",", "2.", "]", ",", "[", "2", ",", "1", "]", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "2", ",", "batch_shape", "=", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh3": [[44, 58], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison", "sess.run", "numpy.allclose", "numpy.asarray", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh3", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "[", "1.", ",", "2.", "]", ",", "[", "2", ",", "1", "]", ",", "[", "0", ",", "1", "]", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "batch_shape", "=", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh4": [[60, 74], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison", "sess.run", "numpy.allclose", "numpy.asarray", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh4", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "[", "1.", "]", ",", "[", "2.", "]", ",", "[", "3.", "]", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "batch_shape", "=", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh5": [[76, 90], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison", "sess.run", "numpy.allclose", "numpy.asarray", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh5", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "[", "1.", "]", ",", "[", "2.", "]", ",", "[", "3.", "]", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "batch_shape", "=", "[", "1", ",", "3", ",", "3", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh6": [[92, 106], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison", "sess.run", "numpy.allclose", "numpy.asarray", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh6", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "[", "1.", "]", ",", "[", "2.", "]", ",", "[", "3.", "]", "]", ",", "[", "[", "1.", "]", ",", "[", "2.", "]", ",", "[", "3.", "]", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "batch_shape", "=", "[", "2", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh7": [[108, 122], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison_nobatch", "sess.run", "numpy.allclose", "numpy.asarray", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_nobatch", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh7", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", "]", ",", "[", "2.", "]", ",", "[", "3.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison_nobatch", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh8": [[124, 138], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.eye", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison_nobatch", "sess.run", "numpy.allclose", "numpy.asarray", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_nobatch", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh8", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", ",", "2.", "]", ",", "[", "3.", ",", "4.", "]", ",", "[", "5.", ",", "6.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U", ",", "V", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison_nobatch", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh9": [[140, 159], ["tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "tensorflow.constant", "tensorflow.einsum", "tensorflow.eye", "tensorflow.ones", "tensorflow.einsum", "core.optimizers.linalg.shermann_morrison._shermann_morison_alpha_trick", "sess.run", "numpy.allclose", "numpy.asarray", "numpy.asarray", "tensorflow.linalg.inv", "tensorflow.einsum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_alpha_trick", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh9", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", ",", "2.", "]", ",", "[", "3.", ",", "4.", "]", ",", "[", "5.", ",", "6.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "[", "1.", ",", "0.", "]", ",", "[", "0.", ",", "2.", "]", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "V_hat", "=", "tf", ".", "einsum", "(", "\"lik, kj-> lij\"", ",", "Q", ",", "V", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "G", "=", "tf", ".", "ones", "(", "[", "1", ",", "3", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "v_", "=", "(", "alpha", "*", "I", "+", "tf", ".", "einsum", "(", "\"ik, lkj-> lij\"", ",", "U", ",", "V_hat", ")", ")", "/", "(", "1.", "+", "alpha", ")", "\n", "compare", "=", "tf", ".", "einsum", "(", "\"lik, lk-> li\"", ",", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", ",", "G", ")", "\n", "\n", "inverse", "=", "_shermann_morison_alpha_trick", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V_hat", ",", "grads", "=", "G", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.test_shermann_morisson.test_sh10": [[161, 177], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.eye", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.linalg.inv", "core.optimizers.linalg.shermann_morrison._shermann_morison_alpha_trick_single", "sess.run", "numpy.allclose", "numpy.asarray", "numpy.asarray", "tensorflow.sqrt", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_alpha_trick_single", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_sh10", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", ",", "2.", "]", ",", "[", "3.", ",", "4.", "]", ",", "[", "5.", ",", "6.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "asarray", "(", "[", "[", "1.", ",", "0.", "]", ",", "[", "0.", ",", "2.", "]", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "I", "=", "tf", ".", "eye", "(", "3", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "U_hat", "=", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "sqrt", "(", "Q", ")", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U_hat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "v_", "=", "(", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U_hat", ",", "V", ")", ")", "/", "(", "1.", "+", "alpha", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "inverse", "=", "_shermann_morison_alpha_trick_single", "(", "alpha", "=", "alpha", ",", "U", "=", "U_hat", ")", "\n", "\n", "c", ",", "i", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "i", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model": [[11, 31], ["tensorflow.Variable", "collections.namedtuple", "fake_model.keys", "fake_model.values"], "function", ["None"], ["def", "get_fake_model", "(", "n", "=", "100", ",", "b", "=", "4", ",", "s", "=", "5", ")", ":", "\n", "    ", "fake_model", "=", "{", "\n", "\"b_size\"", ":", "b", ",", "\n", "\"batch_size\"", ":", "{", "\n", "\"train\"", ":", "b", "}", ",", "\n", "\"samples\"", ":", "s", ",", "\n", "\"n_z_samples\"", ":", "s", "}", "\n", "fake_model", "=", "namedtuple", "(", "'FHM'", ",", "fake_model", ".", "keys", "(", ")", ")", "(", "*", "fake_model", ".", "values", "(", ")", ")", "\n", "\n", "k", "=", "fake_model", ".", "b_size", "*", "fake_model", ".", "samples", "\n", "optimizer_kwargs", "=", "{", "\n", "\"model\"", ":", "fake_model", ",", "\n", "\"individual_learning_rate\"", ":", "1.0", ",", "\n", "\"learning_rate\"", ":", "0.01", ",", "\n", "\"rescale_learning_rate\"", ":", "1.0", ",", "\n", "\"diagonal_pad\"", ":", "0.001", ",", "\n", "'k_step_update'", ":", "1", "}", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "1", ")", "\n", "return", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_N_vs_NA": [[33, 58], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "core.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_N_vs_NA", "(", ")", ":", "\n", "    ", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "=", "get_fake_model", "(", "n", "=", "100", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "NWSO", "=", "NaturalWakeSleepOptimizer", "(", "**", "optimizer_kwargs", ")", "\n", "NWSO", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSO", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSO", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "NWSOAL", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "inverse", "=", "NWSO", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer1\"", ")", "\n", "compare", "=", "NWSOAL", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer2\"", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_N_vs_NA_small": [[60, 85], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "core.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_N_vs_NA_small", "(", ")", ":", "\n", "    ", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "=", "get_fake_model", "(", "n", "=", "10", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "NWSO", "=", "NaturalWakeSleepOptimizer", "(", "**", "optimizer_kwargs", ")", "\n", "NWSO", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSO", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSO", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "NWSOAL", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "inverse", "=", "NWSO", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer1\"", ")", "\n", "compare", "=", "NWSOAL", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer2\"", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_N_vs_NA_big": [[87, 112], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "core.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_N_vs_NA_big", "(", ")", ":", "\n", "    ", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "=", "get_fake_model", "(", "n", "=", "500", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "NWSO", "=", "NaturalWakeSleepOptimizer", "(", "**", "optimizer_kwargs", ")", "\n", "NWSO", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSO", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSO", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "NWSOAL", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "inverse", "=", "NWSO", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer1\"", ")", "\n", "compare", "=", "NWSOAL", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer2\"", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_N_vs_NA_Wclean": [[114, 135], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.transpose", "core.optimizers.linalg.woodberry._optimized_woodberry", "core.optimizers.linalg.woodberry._woodberry_alpha_trick", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._optimized_woodberry", "home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry_alpha_trick", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_N_vs_NA_Wclean", "(", ")", ":", "\n", "    ", "k", ",", "_", ",", "_", ",", "_", ",", "n", ",", "_", ",", "_", "=", "get_fake_model", "(", "n", "=", "500", ")", "\n", "\n", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "U_T", "=", "tf", ".", "transpose", "(", "U", ")", "\n", "\n", "backward", "=", "_optimized_woodberry", "(", "U", "=", "U", ",", "C", "=", "Q", ",", "V_T", "=", "U_T", ",", "alpha", "=", "alpha", ",", "grads", "=", "G", ")", "\n", "forward", "=", "_woodberry_alpha_trick", "(", "U", "=", "U", ",", "C", "=", "Q", ",", "V_T", "=", "U_T", ",", "alpha", "=", "alpha", ",", "grads", "=", "G", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "forward", ",", "backward", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_NA_SH_vs_INV_W_big": [[136, 161], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_NA_SH_vs_INV_W_big", "(", ")", ":", "\n", "    ", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "=", "get_fake_model", "(", "n", "=", "500", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "NWSOAL1", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL1", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL1", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL1", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "NWSOAL2", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL2", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL2", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL2", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "inverse", "=", "NWSOAL1", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer1\"", ",", "choice", "=", "True", ")", "\n", "compare", "=", "NWSOAL2", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer2\"", ",", "choice", "=", "False", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_NA_SH_vs_INV_W_small": [[162, 187], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_NA_SH_vs_INV_W_small", "(", ")", ":", "\n", "    ", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "=", "get_fake_model", "(", "n", "=", "10", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "NWSOAL1", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL1", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL1", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL1", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "NWSOAL2", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL2", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL2", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL2", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "inverse", "=", "NWSOAL1", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer1\"", ",", "choice", "=", "True", ")", "\n", "compare", "=", "NWSOAL2", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer2\"", ",", "choice", "=", "False", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_NA_SH_vs_INV_W_RIcc": [[188, 213], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_NA_SH_vs_INV_W_RIcc", "(", ")", ":", "\n", "    ", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "=", "get_fake_model", "(", "n", "=", "500", ",", "b", "=", "10", ",", "s", "=", "1", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "NWSOAL1", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL1", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL1", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL1", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "NWSOAL2", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL2", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL2", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL2", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "inverse", "=", "NWSOAL1", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer1\"", ",", "choice", "=", "True", ")", "\n", "compare", "=", "NWSOAL2", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer2\"", ",", "choice", "=", "False", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.test_speed_NA_SH_vs_INV_W_Ricc2": [[214, 239], ["accuracy_test.get_fake_model", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate", "tensorflow.less_equal", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "core.optimizers.NaturalWakeSleepOptimizerAlternate.NaturalWakeSleepOptimizerAlternate._multiply_grads_by_fisher_inv", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "print", "print", "numpy.allclose", "numpy.random.normal", "numpy.random.normal().reshape", "numpy.random.normal", "tensorflow.global_variables_initializer", "numpy.random.normal"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.accuracy_test.get_fake_model", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer._multiply_grads_by_fisher_inv", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_NA_SH_vs_INV_W_Ricc2", "(", ")", ":", "\n", "    ", "k", ",", "fake_model", ",", "optimizer_kwargs", ",", "global_step", ",", "n", ",", "b", ",", "s", "=", "get_fake_model", "(", "n", "=", "500", ",", "b", "=", "10", ",", "s", "=", "1", ")", "\n", "\n", "G", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "normal", "(", "1", ",", "0.01", ",", "n", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "n", "]", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "normal", "(", "1", ",", "0.01", ",", "n", "*", "k", ")", ".", "reshape", "(", "[", "n", ",", "k", "]", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "normal", "(", "1", ",", "0.01", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ",", "shape", "=", "[", "1", ",", "k", "]", ")", "\n", "\n", "NWSOAL1", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL1", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL1", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL1", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "NWSOAL2", "=", "NaturalWakeSleepOptimizerAlternate", "(", "**", "optimizer_kwargs", ")", "\n", "NWSOAL2", ".", "_diagonal_pad", "=", "optimizer_kwargs", "[", "\"diagonal_pad\"", "]", "\n", "NWSOAL2", ".", "_diagonal_cond", "=", "tf", ".", "less_equal", "(", "NWSOAL2", ".", "_diagonal_pad", ",", "10.0", ")", "\n", "\n", "inverse", "=", "NWSOAL1", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer1\"", ",", "choice", "=", "True", ")", "\n", "compare", "=", "NWSOAL2", ".", "_multiply_grads_by_fisher_inv", "(", "G", ",", "Q", ",", "U", ",", "global_step", ",", "\"layer2\"", ",", "choice", "=", "False", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "print", "(", "c", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "print", "(", "ii", "[", ":", "10", ",", ":", "10", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ",", ")", ",", "\"Not that close\"", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.test.speed_test.test_speed_SM_S": [[15, 47], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.eye", "time.time", "tensorflow.matmul", "tensorflow.transpose", "core.optimizers.linalg.shermann_morrison._shermann_morison_alpha_trick_single", "time.time", "tensorflow.linalg.inv", "tensorflow.Session", "time.time", "range", "time.time", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.diag", "tensorflow.sqrt", "tf.Session.run", "datetime.timedelta", "datetime.timedelta", "numpy.random.rand", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_alpha_trick_single", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["def", "test_speed_SM_S", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "diag", "(", "np", ".", "random", ".", "rand", "(", "k", ")", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "I", "=", "tf", ".", "eye", "(", "n", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "start_setup", "=", "time", ".", "time", "(", ")", "\n", "\n", "U_hat", "=", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "sqrt", "(", "Q", ")", ")", "\n", "V", "=", "tf", ".", "transpose", "(", "U_hat", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "\n", "inverse", "=", "_shermann_morison_alpha_trick_single", "(", "alpha", "=", "alpha", ",", "U", "=", "U_hat", ")", "\n", "\n", "end_setup", "=", "time", ".", "time", "(", ")", "\n", "\n", "v_", "=", "(", "alpha", "*", "I", "+", "tf", ".", "matmul", "(", "U_hat", ",", "V", ")", ")", "/", "(", "1.", "+", "alpha", ")", "\n", "compare", "=", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "start_run", "=", "time", ".", "time", "(", ")", "\n", "c", ",", "ii", "=", "0", ",", "0", "\n", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "        ", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "", "end_run", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Setup time SM-s\"", ",", "timedelta", "(", "seconds", "=", "end_setup", "-", "start_setup", ")", ")", "\n", "print", "(", "\"Run time SM-s\"", ",", "timedelta", "(", "seconds", "=", "end_run", "-", "start_run", ")", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ")", ",", "\"Not close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.speed_test.test_speed_SM": [[50, 81], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.eye", "time.time", "tensorflow.transpose", "tensorflow.einsum", "tensorflow.ones", "core.optimizers.linalg.shermann_morrison._shermann_morison_alpha_trick", "time.time", "tensorflow.einsum", "tensorflow.Session", "time.time", "range", "time.time", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "tensorflow.linalg.diag", "tensorflow.linalg.inv", "tf.Session.run", "datetime.timedelta", "datetime.timedelta", "tensorflow.einsum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_alpha_trick", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_SM", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "l", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "I", "=", "tf", ".", "eye", "(", "n", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "start_setup", "=", "time", ".", "time", "(", ")", "\n", "\n", "V_T", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "V_hat", "=", "tf", ".", "einsum", "(", "\"lik, kj->lij\"", ",", "tf", ".", "linalg", ".", "diag", "(", "Q", ")", ",", "V_T", ")", "\n", "\n", "G", "=", "tf", ".", "ones", "(", "[", "l", ",", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "inverse", "=", "_shermann_morison_alpha_trick", "(", "alpha", "=", "alpha", ",", "U", "=", "U", ",", "V_T", "=", "V_hat", ",", "grads", "=", "G", ")", "\n", "\n", "end_setup", "=", "time", ".", "time", "(", ")", "\n", "\n", "v_", "=", "(", "alpha", "*", "I", "+", "tf", ".", "einsum", "(", "\"ik, lkj->lij\"", ",", "U", ",", "V_hat", ")", ")", "/", "(", "1.", "+", "alpha", ")", "\n", "compare", "=", "tf", ".", "einsum", "(", "\"lik, lk->li\"", ",", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", ",", "G", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "c", ",", "ii", "=", "0", ",", "0", "\n", "start_run", "=", "time", ".", "time", "(", ")", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "        ", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "", "end_run", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Setup time SM\"", ",", "timedelta", "(", "seconds", "=", "end_setup", "-", "start_setup", ")", ")", "\n", "print", "(", "\"Run time SM\"", ",", "timedelta", "(", "seconds", "=", "end_run", "-", "start_run", ")", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ")", ",", "\"Not close\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.speed_test.test_speed_W": [[83, 116], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.eye", "time.time", "tensorflow.transpose", "tensorflow.einsum", "tensorflow.ones", "core.optimizers.linalg.woodberry._woodberry_alpha_trick", "time.time", "tensorflow.einsum", "tensorflow.Session", "time.time", "range", "time.time", "print", "print", "numpy.allclose", "numpy.random.rand", "numpy.random.rand", "tensorflow.linalg.diag", "tensorflow.linalg.inv", "tf.Session.run", "datetime.timedelta", "datetime.timedelta", "tensorflow.einsum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry_alpha_trick", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "test_speed_W", "(", ")", ":", "\n", "    ", "alpha", "=", "tf", ".", "constant", "(", "0.1", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "U", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "n", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "Q", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "rand", "(", "l", ",", "k", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "I", "=", "tf", ".", "eye", "(", "n", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "start_setup", "=", "time", ".", "time", "(", ")", "\n", "\n", "V_T", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "V_hat", "=", "tf", ".", "einsum", "(", "\"lik, kj->lij\"", ",", "tf", ".", "linalg", ".", "diag", "(", "Q", ")", ",", "V_T", ")", "\n", "\n", "G", "=", "tf", ".", "ones", "(", "[", "l", ",", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "inverse", "=", "_woodberry_alpha_trick", "(", "U", "=", "U", ",", "C", "=", "Q", ",", "V_T", "=", "V_T", ",", "alpha", "=", "alpha", ",", "grads", "=", "G", ")", "\n", "\n", "end_setup", "=", "time", ".", "time", "(", ")", "\n", "\n", "v_", "=", "(", "alpha", "*", "I", "+", "tf", ".", "einsum", "(", "\"ik, lkj->lij\"", ",", "U", ",", "V_hat", ")", ")", "/", "(", "1.", "+", "alpha", ")", "\n", "compare", "=", "tf", ".", "einsum", "(", "\"lik, lk->li\"", ",", "tf", ".", "linalg", ".", "inv", "(", "v_", ")", ",", "G", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "start_run", "=", "time", ".", "time", "(", ")", "\n", "c", ",", "ii", "=", "0", ",", "0", "\n", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "        ", "c", ",", "ii", "=", "sess", ".", "run", "(", "[", "compare", ",", "inverse", "]", ")", "\n", "\n", "", "end_run", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Setup time Woodberry\"", ",", "timedelta", "(", "seconds", "=", "end_setup", "-", "start_setup", ")", ")", "\n", "print", "(", "\"Run time Woodberry\"", ",", "timedelta", "(", "seconds", "=", "end_run", "-", "start_run", ")", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "c", ",", "ii", ")", ",", "\"Not close\"", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index": [[41, 48], ["print", "print", "sys.exit"], "function", ["None"], ["def", "word_index", "(", "word", ",", "dictionary", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "dictionary", "[", "word", "]", "\n", "", "except", "KeyError", "as", "kerr", ":", "\n", "        ", "print", "(", "\"\\nKey Error: {0}\"", ".", "format", "(", "kerr", ")", ")", "\n", "print", "(", "\"The word requested is not present in the dictionary.\\n\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings": [[49, 53], ["numpy.asarray", "numpy.array", "evaluate_analogies_from_alpha_embeddings.word_index"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index"], ["", "", "def", "get_word_embeddings", "(", "words", ",", "embeddings", ",", "dictionary", ")", ":", "\n", "    ", "\"\"\"Return a list of embeddings for the specified words\"\"\"", "\n", "embeddings", "=", "np", ".", "asarray", "(", "embeddings", ")", "\n", "return", "np", ".", "array", "(", "[", "embeddings", "[", "word_index", "(", "w", ",", "dictionary", ")", "]", "for", "w", "in", "words", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_indexes": [[54, 57], ["numpy.array", "evaluate_analogies_from_alpha_embeddings.word_index"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.word_index"], ["", "def", "get_word_indexes", "(", "words", ",", "dictionary", ")", ":", "\n", "    ", "\"\"\"Return a list of indexes for the specified words\"\"\"", "\n", "return", "np", ".", "array", "(", "[", "word_index", "(", "w", ",", "dictionary", ")", "for", "w", "in", "words", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.analogies_euclidean": [[58, 104], ["evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "evaluate_analogies_from_alpha_embeddings.get_word_indexes", "evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "evaluate_analogies_from_alpha_embeddings.get_word_indexes", "evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "evaluate_analogies_from_alpha_embeddings.get_word_indexes", "zip", "numexpr.evaluate().sum", "evaluate_analogies_from_alpha_embeddings.select_indexes", "all_indexes.append", "embt.reshape", "numpy.argsort", "numexpr.evaluate"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_indexes", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_indexes", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_indexes", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.select_indexes"], ["", "def", "analogies_euclidean", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "words3", ",", "howmany", ",", "tolerance", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "ind1", "=", "get_word_indexes", "(", "words1", ",", "dictionary", ")", "\n", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "ind2", "=", "get_word_indexes", "(", "words2", ",", "dictionary", ")", "\n", "\n", "emb3", "=", "get_word_embeddings", "(", "words3", ",", "embeddings", ",", "dictionary", ")", "\n", "ind3", "=", "get_word_indexes", "(", "words3", ",", "dictionary", ")", "\n", "\n", "emb_targets", "=", "emb2", "-", "emb1", "+", "emb3", "\n", "\n", "all_indexes", "=", "[", "]", "\n", "\n", "for", "embt", ",", "i1", ",", "i2", ",", "i3", "in", "zip", "(", "emb_targets", ",", "ind1", ",", "ind2", ",", "ind3", ")", ":", "\n", "        ", "diffs", "=", "embt", ".", "reshape", "(", "1", ",", "-", "1", ")", "-", "embeddings", "\n", "# import pdb;pdb.set_trace()", "\n", "distances", "=", "ne", ".", "evaluate", "(", "'diffs**2'", ")", ".", "sum", "(", "axis", "=", "1", ")", "\n", "# import pdb;pdb.set_trace()", "\n", "# distances = np.sqrt(distances)", "\n", "# indexes_t = np.argsort(distances)[:howmany]", "\n", "\n", "indexes_t", "=", "select_indexes", "(", "np", ".", "argsort", "(", "distances", ")", ",", "\n", "to_exclude", "=", "[", "i1", ",", "i2", ",", "i3", "]", ",", "\n", "howmany", "=", "howmany", ")", "\n", "all_indexes", ".", "append", "(", "indexes_t", ")", "\n", "\n", "# emb_targets = np.expand_dims(emb_targets, axis=1)", "\n", "# embeddings = np.expand_dims(embeddings, axis=0)", "\n", "#", "\n", "# # distances = np.linalg.norm(emb_targets-embeddings, axis=2)", "\n", "# # diff = emb_targets-embeddings", "\n", "# # distances = ne.evaluate('sum(diff*diff, axis=2)')", "\n", "# distances = ne.evaluate('(emb_targets-embeddings)**2').sum(axis=2)", "\n", "# # import pdb;pdb.set_trace()", "\n", "# # distances = np.sum((emb_targets-embeddings)**2, axis=2)", "\n", "# # distances = np.sqrt(distances)", "\n", "# all_indexes = np.argsort(distances, axis=1)", "\n", "\n", "# if tolerance:", "\n", "#     all_indexes = [select_indexes(query_pred_indexes, [i1, i2, i3], howmany)", "\n", "#                        for query_pred_indexes, i1, i2, i3 in zip(all_indexes, ind1, ind2, ind3)]", "\n", "# else:", "\n", "#     all_indexes = all_indexes[:, :howmany]", "\n", "\n", "", "return", "all_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.select_indexes": [[105, 107], ["None"], "function", ["None"], ["", "def", "select_indexes", "(", "indexes", ",", "to_exclude", ",", "howmany", ")", ":", "\n", "    ", "return", "[", "i", "for", "i", "in", "indexes", "if", "i", "not", "in", "to_exclude", "]", "[", ":", "howmany", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.evaluate_analogies": [[108, 200], ["max", "range", "logger.info", "len", "zip", "evaluate_analogies_from_alpha_embeddings.aneval", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "open", "len", "len", "logger.info", "line.rstrip().split", "len", "len", "int", "numpy.sum", "all", "zip", "numpy.sum", "numpy.sum", "float", "line.rstrip", "numpy.sum", "len", "float", "float", "float", "numpy.mean", "evaluate_analogies_from_alpha_embeddings.aneval"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.aneval", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.aneval"], ["", "def", "evaluate_analogies", "(", "aneval", ",", "logger", ",", "tolerance", ")", ":", "\n", "    ", "\"\"\"Evaluate the trained word vectors on a variety of analogies\"\"\"", "\n", "\n", "folder", "=", "'/data/captamerica_hd2/text/analogies_datasets'", "\n", "filenames", "=", "[", "\n", "'capital-common-countries.txt'", ",", "'capital-world.txt'", ",", "'currency.txt'", ",", "\n", "'city-in-state.txt'", ",", "'family.txt'", ",", "'gram1-adjective-to-adverb.txt'", ",", "\n", "'gram2-opposite.txt'", ",", "'gram3-comparative.txt'", ",", "'gram4-superlative.txt'", ",", "\n", "'gram5-present-participle.txt'", ",", "'gram6-nationality-adjective.txt'", ",", "\n", "'gram7-past-tense.txt'", ",", "'gram8-plural.txt'", ",", "'gram9-plural-verbs.txt'", ",", "\n", "]", "\n", "\n", "topnumbers", "=", "[", "1", ",", "5", ",", "10", "]", "\n", "howmany", "=", "max", "(", "topnumbers", ")", "\n", "# # to avoid memory overflow, could be increased/decreased", "\n", "# # depending on system and vocab size", "\n", "# split_size = 100", "\n", "\n", "count_sem", "=", "0", "# count all semantic questions", "\n", "count_syn", "=", "0", "# count all syntactic questions", "\n", "count_tot", "=", "0", "# count all questions", "\n", "full_count", "=", "0", "# count all questions, including those with unknown words", "\n", "\n", "correct_tot", "=", "{", "}", "# count correct semantic questions", "\n", "correct_sem", "=", "{", "}", "# count correct syntactic questions", "\n", "correct_syn", "=", "{", "}", "# count correct questions", "\n", "\n", "for", "tnum", "in", "topnumbers", ":", "\n", "        ", "correct_tot", "[", "tnum", "]", "=", "0", "\n", "correct_sem", "[", "tnum", "]", "=", "0", "\n", "correct_syn", "[", "tnum", "]", "=", "0", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "filenames", ")", ")", ":", "\n", "        ", "with", "open", "(", "'%s/%s'", "%", "(", "folder", ",", "filenames", "[", "i", "]", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "full_data", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "for", "line", "in", "f", "]", "\n", "full_count", "+=", "len", "(", "full_data", ")", "\n", "data", "=", "[", "x", "for", "x", "in", "full_data", "if", "all", "(", "word", "in", "dictionary", "for", "word", "in", "x", ")", "]", "\n", "\n", "# import pdb;pdb.set_trace()", "\n", "", "words1", ",", "words2", ",", "words3", ",", "words4", "=", "zip", "(", "*", "data", ")", "\n", "\n", "# indices = np.array([[dictionary[word] for word in row] for row in data])", "\n", "# ind1, ind2, ind3, ind4 = indices.T", "\n", "#", "\n", "# analogy_query_d_from_indexes = partial(embeddings_manager.analogy_query_d_from_indexes,", "\n", "#                                 howmany=howmany, amonghowmany=amonghowmany, tolerance=tolerance)", "\n", "#", "\n", "# return `howmany` couples [(index, measure)] for each query", "\n", "# index_and_measures = pool.starmap(analogy_query_d_from_indexes, zip(ind1, ind2, ind3))", "\n", "\n", "# for each query extract the list of index predictions", "\n", "# predictions = [list(zip(*iam))[0] for iam in index_and_measures]", "\n", "# import pdb; pdb.set_trace()", "\n", "predictions", "=", "aneval", "(", "words1", ",", "words2", ",", "words3", ",", "howmany", "=", "howmany", ",", "tolerance", "=", "tolerance", ")", "\n", "ind4", "=", "[", "dictionary", "[", "w", "]", "for", "w", "in", "words4", "]", "\n", "\n", "logger", ".", "info", "(", "\"%s:\"", "%", "filenames", "[", "i", "]", ")", "\n", "\n", "count_tot", "=", "count_tot", "+", "len", "(", "words1", ")", "\n", "\n", "if", "i", "<", "5", ":", "\n", "            ", "count_sem", "=", "count_sem", "+", "len", "(", "words1", ")", "\n", "", "else", ":", "\n", "            ", "count_syn", "=", "count_syn", "+", "len", "(", "words1", ")", "\n", "\n", "", "val", "=", "{", "}", "\n", "# import pdb;pdb.set_trace()", "\n", "for", "tnum", "in", "topnumbers", ":", "\n", "            ", "val", "[", "tnum", "]", "=", "[", "int", "(", "i4", "in", "preds", "[", ":", "tnum", "]", ")", "for", "(", "i4", ",", "preds", ")", "in", "zip", "(", "ind4", ",", "predictions", ")", "]", "# correct predictions", "\n", "\n", "correct_tot", "[", "tnum", "]", "=", "correct_tot", "[", "tnum", "]", "+", "np", ".", "sum", "(", "val", "[", "tnum", "]", ")", "\n", "\n", "if", "i", "<", "5", ":", "\n", "                ", "correct_sem", "[", "tnum", "]", "=", "correct_sem", "[", "tnum", "]", "+", "np", ".", "sum", "(", "val", "[", "tnum", "]", ")", "\n", "", "else", ":", "\n", "                ", "correct_syn", "[", "tnum", "]", "=", "correct_syn", "[", "tnum", "]", "+", "np", ".", "sum", "(", "val", "[", "tnum", "]", ")", "\n", "\n", "", "logger", ".", "info", "(", "'ACCURACY TOP%d: %.2f%% (%d/%d)'", "%", "\n", "(", "tnum", ",", "np", ".", "mean", "(", "val", "[", "tnum", "]", ")", "*", "100", ",", "np", ".", "sum", "(", "val", "[", "tnum", "]", ")", ",", "len", "(", "val", "[", "tnum", "]", ")", ")", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "'Questions seen/total: %.2f%% (%d/%d)'", "%", "\n", "(", "100", "*", "count_tot", "/", "float", "(", "full_count", ")", ",", "count_tot", ",", "full_count", ")", ")", "\n", "\n", "for", "tnum", "in", "topnumbers", ":", "\n", "        ", "logger", ".", "info", "(", "'\\nTOP%d STATS'", "%", "tnum", ")", "\n", "logger", ".", "info", "(", "'-------------------------'", ")", "\n", "logger", ".", "info", "(", "'Semantic accuracy: %.2f%%  (%i/%i)'", "%", "\n", "(", "100", "*", "correct_sem", "[", "tnum", "]", "/", "float", "(", "count_sem", ")", ",", "correct_sem", "[", "tnum", "]", ",", "count_sem", ")", ")", "\n", "logger", ".", "info", "(", "'Syntactic accuracy: %.2f%%  (%i/%i)'", "%", "\n", "(", "100", "*", "correct_syn", "[", "tnum", "]", "/", "float", "(", "count_syn", ")", ",", "correct_syn", "[", "tnum", "]", ",", "count_syn", ")", ")", "\n", "logger", ".", "info", "(", "'Total accuracy: %.2f%%  (%i/%i)'", "%", "\n", "(", "100", "*", "correct_tot", "[", "tnum", "]", "/", "float", "(", "count_tot", ")", ",", "correct_tot", "[", "tnum", "]", ",", "count_tot", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.aneval": [[237, 239], ["evaluate_analogies_from_alpha_embeddings.analogies_euclidean"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.analogies_euclidean"], ["def", "aneval", "(", "words1", ",", "words2", ",", "words3", ",", "howmany", ",", "tolerance", ")", ":", "\n", "    ", "return", "analogies_euclidean", "(", "u_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "words3", ",", "howmany", "=", "howmany", ",", "tolerance", "=", "tolerance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.load_similarities": [[51, 59], ["open", "pickle.load", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["def", "load_similarities", "(", "simdir", ")", ":", "\n", "    ", "with", "open", "(", "simdir", "+", "\"/base-similarities.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "base_similarities", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "simdir", "+", "\"/alpha-similarities.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "alpha_similarities", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "base_similarities", ",", "alpha_similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.load_analogies": [[61, 70], ["open", "pickle.load", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_analogies", "(", "analogdir", ")", ":", "\n", "    ", "with", "open", "(", "analogdir", "+", "\"/base-analogies.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "base_analogies", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "analogdir", "+", "\"/alpha-analogies.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "alpha_analogies", "=", "pickle", ".", "load", "(", "f", ")", "\n", "#     alpha_analogies = None", "\n", "\n", "", "return", "base_analogies", ",", "alpha_analogies", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.load_sim_an": [[72, 100], ["corpus_id.split", "int", "int", "os.path.join", "os.path.join", "os.path.join", "numpy.load", "nice_plots.load_similarities", "nice_plots.load_analogies"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.load_similarities", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.load_analogies"], ["", "def", "load_sim_an", "(", "host", ",", "corpus_id", ")", ":", "\n", "    ", "corpus", ",", "vstr", ",", "nstr", "=", "corpus_id", ".", "split", "(", "'-'", ")", "\n", "vecsize", "=", "int", "(", "vstr", "[", "1", ":", "]", ")", "\n", "nepoch", "=", "int", "(", "nstr", "[", "1", ":", "]", ")", "\n", "\n", "simbasedir", "=", "\"/data/{:}_hd1/text/new-similarities\"", ".", "format", "(", "host", ")", "\n", "analogbasedir", "=", "\"/data/{:}_hd1/text/new-analogies\"", ".", "format", "(", "host", ")", "\n", "embbasedir", "=", "\"/data/{:}_hd1/text/new-alpha-embeddings/{:}-alpha-emb\"", ".", "format", "(", "host", ",", "corpus", ")", "\n", "\n", "embdir", "=", "os", ".", "path", ".", "join", "(", "embbasedir", ",", "corpus_id", ")", "\n", "simdir", "=", "os", ".", "path", ".", "join", "(", "simbasedir", ",", "corpus_id", ")", "\n", "analogdir", "=", "os", ".", "path", ".", "join", "(", "analogbasedir", ",", "corpus_id", ")", "\n", "\n", "alphas", "=", "np", ".", "load", "(", "embdir", "+", "\"/alphas.npy\"", ")", "\n", "base_similarities", ",", "alpha_similarities", "=", "load_similarities", "(", "simdir", ")", "\n", "base_analogies", ",", "alpha_analogies", "=", "load_analogies", "(", "analogdir", ")", "\n", "\n", "similarities", "=", "{", "\n", "\"base\"", ":", "base_similarities", ",", "\n", "\"alpha\"", ":", "alpha_similarities", "\n", "}", "\n", "\n", "analogies", "=", "{", "\n", "\"base\"", ":", "base_analogies", ",", "\n", "\"alpha\"", ":", "alpha_analogies", "\n", "}", "\n", "\n", "return", "corpus", ",", "vecsize", ",", "nepoch", ",", "alphas", ",", "similarities", ",", "analogies", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.nice_label": [[136, 155], ["core.plotting.is_method", "core.plotting.is_limit_method", "nl.replace.replace", "core.plotting.is_method", "m.split", "core.plotting.is_limit_method", "m.split", "Exception", "m.split", "m.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_limit_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_limit_method"], ["def", "nice_label", "(", "m", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "nl", "=", "nice_label_base", "[", "m", "]", "\n", "", "except", ":", "\n", "        ", "if", "is_method", "(", "m", ",", "'u'", ")", ":", "\n", "            ", "nl", "=", "\"E-U-\"", "+", "m", ".", "split", "(", "\"u-plog-\"", ")", "[", "1", "]", "\n", "", "elif", "is_limit_method", "(", "m", ",", "'u'", ")", ":", "\n", "            ", "nl", "=", "\"LE-U-\"", "+", "m", ".", "split", "(", "\"limit-u-plog-\"", ")", "[", "1", "]", "\n", "", "elif", "is_method", "(", "m", ",", "'u+v'", ")", ":", "\n", "            ", "nl", "=", "\"E-U+V-\"", "+", "m", ".", "split", "(", "\"u+v-plog-\"", ")", "[", "1", "]", "\n", "", "elif", "is_limit_method", "(", "m", ",", "'u+v'", ")", ":", "\n", "            ", "nl", "=", "\"LE-U+V-\"", "+", "m", ".", "split", "(", "\"limit-u+v-plog-\"", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"unexpected method name {:}\"", ".", "format", "(", "m", ")", ")", "\n", "\n", "", "for", "s1", ",", "s2", "in", "to_replace", ":", "\n", "            ", "nl", "=", "nl", ".", "replace", "(", "s1", ",", "s2", ")", "\n", "\n", "", "", "return", "nl", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.plot_base": [[173, 178], ["axis.hlines", "nice_plots.nice_label"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.nice_label"], ["def", "plot_base", "(", "base_methods", ",", "base_results", ",", "axis", ")", ":", "\n", "    ", "for", "bm", "in", "base_methods", ":", "\n", "        ", "c", ",", "s", "=", "base_methods", "[", "bm", "]", "\n", "value", "=", "base_results", "[", "bm", "]", "\n", "axis", ".", "hlines", "(", "value", ",", "amin", ",", "amax", ",", "linestyles", "=", "s", ",", "color", "=", "c", ",", "label", "=", "nice_label", "(", "bm", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.plot_all": [[180, 247], ["matplotlib.pyplot.subplots", "enumerate", "itertools.cycle", "zip", "nice_plots.plot_base", "nice_plots.plot_base", "axs[].legend", "fig.subplots_adjust", "matplotlib.pyplot.savefig", "print", "matplotlib.pyplot.close", "subprocess.run", "ax.set_title", "ax.set_ylim", "next", "axs[].plot", "axs[].hlines", "axs[].set_xlim", "axs[].set_xticks", "matplotlib.ticker.AutoMinorLocator", "axs[].xaxis.set_minor_locator", "axs[].set_yticks", "matplotlib.ticker.AutoMinorLocator", "axs[].yaxis.set_minor_locator", "axs[].set_axisbelow", "axs[].grid", "axs[].grid", "axs[].plot", "axs[].hlines", "axs[].set_xlim", "axs[].grid", "axs[].set_xticks", "matplotlib.ticker.AutoMinorLocator", "axs[].xaxis.set_minor_locator", "axs[].set_yticks", "matplotlib.ticker.AutoMinorLocator", "axs[].yaxis.set_minor_locator", "axs[].set_axisbelow", "axs[].grid", "axs[].grid", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "nice_plots.nice_label", "min", "nice_plots.nice_label", "min", "max", "max", "nice_plots.get_sims_ylim", "nice_plots.get_an_ylim"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.plot_base", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.plot_base", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.nice_label", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.nice_label", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_sims_ylim", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_an_ylim"], ["", "", "def", "plot_all", "(", "enwiki_collections", ",", "geb_collections", ",", "datasets", ",", "methods", ",", "limit_methods", ",", "base_methods", ",", "plot_folder", ",", "get_ylim", ")", ":", "\n", "    ", "titles", "=", "[", "\"enwiki\"", ",", "\"geb\"", "]", "\n", "\n", "for", "d", "in", "datasets", ":", "\n", "        ", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "2", ",", "sharex", "=", "'all'", ")", "\n", "# fig.suptitle(d)", "\n", "for", "i", ",", "ax", "in", "enumerate", "(", "axs", ")", ":", "\n", "            ", "ax", ".", "set_title", "(", "titles", "[", "i", "]", ")", "\n", "ax", ".", "set_ylim", "(", "get_ylim", "(", "d", ")", ")", "\n", "\n", "", "cc", "=", "cycle", "(", "colors", ")", "\n", "for", "m", ",", "lm", "in", "zip", "(", "methods", ",", "limit_methods", ")", ":", "\n", "            ", "enwiki_curve", "=", "enwiki_collections", "[", "'alpha'", "]", "[", "d", "]", "[", "m", "]", "\n", "enwiki_lim", "=", "enwiki_collections", "[", "'alpha'", "]", "[", "d", "]", "[", "lm", "]", "\n", "geb_curve", "=", "geb_collections", "[", "'alpha'", "]", "[", "d", "]", "[", "m", "]", "\n", "geb_lim", "=", "geb_collections", "[", "'alpha'", "]", "[", "d", "]", "[", "lm", "]", "\n", "\n", "c", "=", "next", "(", "cc", ")", "\n", "\n", "axs", "[", "0", "]", ".", "plot", "(", "alphas", ",", "enwiki_curve", ",", "color", "=", "c", ",", "label", "=", "nice_label", "(", "m", ")", ")", "\n", "axs", "[", "0", "]", ".", "hlines", "(", "enwiki_lim", ",", "amin", ",", "amax", ",", "linestyles", "=", "'--'", ",", "color", "=", "c", ")", "\n", "axs", "[", "0", "]", ".", "set_xlim", "(", "-", "10", ",", "6", ")", "\n", "#axs[0].grid()", "\n", "\n", "axs", "[", "0", "]", ".", "set_xticks", "(", "np", ".", "arange", "(", "-", "10", ",", "7", ",", "2", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "2", ")", "\n", "axs", "[", "0", "]", ".", "xaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "\n", "axs", "[", "0", "]", ".", "set_yticks", "(", "np", ".", "arange", "(", "min", "(", "get_ylim", "(", "d", ")", ")", ",", "max", "(", "get_ylim", "(", "d", ")", ")", "+", "1", ",", "2", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "2", ")", "\n", "axs", "[", "0", "]", ".", "yaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "\n", "axs", "[", "0", "]", ".", "set_axisbelow", "(", "True", ")", "\n", "#ax.grid(which='major', linestyle='-', linewidth='0.5', color='gray')", "\n", "#ax.grid(which='minor', linestyle='-', linewidth='0.5', color='gray')", "\n", "axs", "[", "0", "]", ".", "grid", "(", "which", "=", "'major'", ",", "linestyle", "=", "'-'", ",", "linewidth", "=", "'1'", ",", "color", "=", "'lightgray'", ")", "\n", "axs", "[", "0", "]", ".", "grid", "(", "which", "=", "'minor'", ",", "linestyle", "=", "'--'", ",", "linewidth", "=", "'1'", ",", "color", "=", "'lightgray'", ")", "\n", "\n", "axs", "[", "1", "]", ".", "plot", "(", "alphas", ",", "geb_curve", ",", "color", "=", "c", ",", "label", "=", "nice_label", "(", "m", ")", ")", "\n", "axs", "[", "1", "]", ".", "hlines", "(", "geb_lim", ",", "amin", ",", "amax", ",", "linestyles", "=", "'--'", ",", "color", "=", "c", ")", "\n", "axs", "[", "1", "]", ".", "set_xlim", "(", "-", "10", ",", "7", ")", "\n", "axs", "[", "1", "]", ".", "grid", "(", ")", "\n", "\n", "axs", "[", "1", "]", ".", "set_xticks", "(", "np", ".", "arange", "(", "-", "10", ",", "7", ",", "2", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "2", ")", "\n", "axs", "[", "1", "]", ".", "xaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "\n", "axs", "[", "1", "]", ".", "set_yticks", "(", "np", ".", "arange", "(", "min", "(", "get_ylim", "(", "d", ")", ")", ",", "max", "(", "get_ylim", "(", "d", ")", ")", "+", "1", ",", "2", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "2", ")", "\n", "axs", "[", "1", "]", ".", "yaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "\n", "axs", "[", "1", "]", ".", "set_axisbelow", "(", "True", ")", "\n", "#ax.grid(which='major', linestyle='-', linewidth='0.5', color='gray')", "\n", "#ax.grid(which='minor', linestyle='-', linewidth='0.5', color='gray')", "\n", "axs", "[", "1", "]", ".", "grid", "(", "which", "=", "'major'", ",", "linestyle", "=", "'-'", ",", "linewidth", "=", "'1'", ",", "color", "=", "'lightgray'", ")", "\n", "axs", "[", "1", "]", ".", "grid", "(", "which", "=", "'minor'", ",", "linestyle", "=", "'--'", ",", "linewidth", "=", "'1'", ",", "color", "=", "'lightgray'", ")", "\n", "\n", "", "plot_base", "(", "base_methods", ",", "enwiki_collections", "[", "'base'", "]", "[", "d", "]", ",", "axs", "[", "0", "]", ")", "\n", "plot_base", "(", "base_methods", ",", "geb_collections", "[", "'base'", "]", "[", "d", "]", ",", "axs", "[", "1", "]", ")", "\n", "lgd", "=", "axs", "[", "0", "]", ".", "legend", "(", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "1", ",", "0.0", ")", ",", "ncol", "=", "4", ")", "\n", "#plt.tight_layout()", "\n", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.4", ")", "# or whatever", "\n", "path", "=", "plot_folder", "+", "\"/\"", "+", "d", "+", "\".png\"", "\n", "plt", ".", "savefig", "(", "path", ")", "#, bbox_extra_artist = [lgd])", "\n", "print", "(", "\"saved \"", "+", "path", ")", "\n", "plt", ".", "close", "(", ")", "\n", "subprocess", ".", "run", "(", "[", "\"convert\"", ",", "\"-trim\"", ",", "path", ",", "path", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.ok_method": [[307, 317], ["numpy.any", "numpy.any", "core.plotting.is_method", "core.plotting.is_in_point", "method_str.split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_in_point"], ["def", "ok_method", "(", "method_str", ")", ":", "\n", "    ", "ok_theta", "=", "np", ".", "any", "(", "[", "is_method", "(", "method_str", ",", "t", ")", "for", "t", "in", "thetas", "]", ")", "\n", "ok_point", "=", "np", ".", "any", "(", "[", "is_in_point", "(", "method_str", ",", "p", ")", "for", "p", "in", "points", "]", ")", "\n", "ok_norm", "=", "(", "\"-n\"", "in", "method_str", ")", "\n", "\n", "if", "\"-n\"", "in", "method_str", ":", "\n", "        ", "norm_str", ",", "prod_str", "=", "method_str", ".", "split", "(", "'-'", ")", "[", "-", "2", ":", "]", "\n", "ok_prod", "=", "(", "norm_str", "[", "1", "]", "==", "prod_str", ")", "\n", "\n", "", "return", "ok_theta", "and", "ok_point", "and", "ok_norm", "and", "ok_prod", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.ok_dataset": [[262, 264], ["core.plotting.is_a_split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_a_split"], ["", "def", "ok_dataset", "(", "dataset_str", ")", ":", "\n", "    ", "return", "not", "is_a_split", "(", "dataset_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.get_sims_ylim": [[269, 288], ["None"], "function", ["None"], ["def", "get_sims_ylim", "(", "d", ")", ":", "\n", "    ", "if", "\"all\"", "in", "d", ":", "\n", "        ", "return", "(", "50", ",", "68", ")", "\n", "", "if", "\"mc\"", "in", "d", ":", "\n", "        ", "return", "(", "60", ",", "90", ")", "\n", "", "if", "\"wordsim\"", "in", "d", ":", "\n", "        ", "return", "(", "50", ",", "85", ")", "\n", "", "if", "\"rw\"", "in", "d", ":", "\n", "        ", "return", "(", "30", ",", "60", ")", "\n", "", "if", "\"scws\"", "in", "d", ":", "\n", "        ", "return", "(", "40", ",", "70", ")", "\n", "", "if", "\"simlex\"", "in", "d", ":", "\n", "        ", "return", "(", "20", ",", "50", ")", "\n", "", "if", "\"mturk\"", "in", "d", ":", "\n", "        ", "return", "(", "45", ",", "75", ")", "\n", "", "if", "\"rg\"", "in", "d", ":", "\n", "        ", "return", "(", "60", ",", "90", ")", "\n", "", "if", "\"men\"", "in", "d", ":", "\n", "        ", "return", "(", "50", ",", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.nice_plots.get_an_ylim": [[293, 300], ["None"], "function", ["None"], ["def", "get_an_ylim", "(", "d", ")", ":", "\n", "    ", "if", "\"tot\"", "in", "d", ":", "\n", "        ", "return", "(", "62", ",", "78", ")", "\n", "", "if", "\"sem\"", "in", "d", ":", "\n", "        ", "return", "(", "60", ",", "90", ")", "\n", "", "if", "\"syn\"", "in", "d", ":", "\n", "        ", "return", "(", "45", ",", "75", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.cross_validation_similarity.evaluate_cross_sim_and_org": [[10, 33], ["sorted", "zip", "cvcorrs.get", "cvcorrs[].get", "cross_validation_similarity.make_simeval", "core.measures.evaluate_similarity_on_reverse_split", "[].append", "print", "print"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.cross_validation_similarity.make_simeval", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.evaluate_similarity_on_reverse_split"], ["def", "evaluate_cross_sim_and_org", "(", "dictionary", ",", "dataset", ",", "i_split", ",", "dataset_split", ",", "method", ",", "couples_data", ",", "ntop", "=", "1", ",", "cvcorrs", "=", "{", "}", ")", ":", "\n", "\n", "    ", "p", ",", "I_inv", ",", "DV", ",", "I_norm", ",", "I_prod", "=", "methods_args", "[", "method", "]", "\n", "\n", "sorted_data", "=", "sorted", "(", "couples_data", ",", "reverse", "=", "True", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "top_alphas", ",", "top_sims", "=", "zip", "(", "*", "sorted_data", "[", ":", "ntop", "]", ")", "\n", "\n", "if", "cvcorrs", ".", "get", "(", "dataset_split", ",", "None", ")", "is", "None", ":", "\n", "        ", "cvcorrs", "[", "dataset_split", "]", "=", "{", "}", "\n", "", "if", "cvcorrs", "[", "dataset_split", "]", ".", "get", "(", "method", ",", "None", ")", "is", "None", ":", "\n", "        ", "cvcorrs", "[", "dataset_split", "]", "[", "method", "]", "=", "[", "]", "\n", "\n", "", "for", "alpha", "in", "top_alphas", ":", "\n", "\n", "        ", "simeval", "=", "make_simeval", "(", "p_embeddings", ",", "dictionary", ",", "alpha", ",", "I_inv", ",", "DV", ",", "\n", "p", ",", "I_norm", ",", "I_prod", ",", "method", "=", "\"cos\"", ")", "\n", "\n", "corr", "=", "evaluate_similarity_on_reverse_split", "(", "dictionary", ",", "simeval", ",", "dataset", ",", "i_split", ")", "\n", "\n", "cvcorrs", "[", "dataset_split", "]", "[", "method", "]", ".", "append", "(", "[", "alpha", ",", "corr", "]", ")", "\n", "\n", "print", "(", "\"{} alpha {}:\"", ".", "format", "(", "dataset_split", ",", "alpha", ")", ")", "\n", "print", "(", "'SPEARMAN CORR: %.2f '", "%", "corr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.cross_validation_similarity.make_simeval": [[34, 43], ["similarity_logmap_Esubmodel_trick"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick"], ["", "", "def", "make_simeval", "(", "p_embeddings", ",", "dictionary", ",", "alpha", ",", "I_inv", ",", "DV", ",", "\n", "p", ",", "I_norm", ",", "I_prod", ",", "method", "=", "\"cos\"", ")", ":", "\n", "\n", "    ", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_logmap_Esubmodel_trick", "(", "p_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "\n", "alpha", ",", "I_inv", ",", "DV", ",", "p", ",", "I_prod", ",", "I_norm", "=", "I_norm", ",", "\n", "method", "=", "method", ")", "\n", "\n", "", "return", "simeval", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.cross_validation_similarity.load_from_dir": [[45, 61], ["numpy.load", "numpy.load", "numpy.load", "open", "pickle.load", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_from_dir", "(", "simdir", ")", ":", "\n", "    ", "alphas", "=", "np", ".", "load", "(", "simdir", "+", "\"/alphas.npy\"", ")", "\n", "\n", "I0", "=", "np", ".", "load", "(", "simdir", "+", "\"/fisher-0.npy\"", ")", "\n", "# I0_inv = np.linalg.inv(I0)", "\n", "\n", "Iu", "=", "np", ".", "load", "(", "simdir", "+", "\"/fisher-u.npy\"", ")", "\n", "# Iu_inv = np.linalg.inv(Iu)", "\n", "\n", "with", "open", "(", "simdir", "+", "\"/base-similarities.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "base_similarities", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "simdir", "+", "\"/alpha-similarities.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "alpha_similarities", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "alphas", ",", "I0", ",", "Iu", ",", "base_similarities", ",", "alpha_similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.cross_validation_similarity.main": [[63, 123], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.basename", "os.path.basename.split", "int", "int", "cross_validation_similarity.load_from_dir", "os.path.join", "pandas.DataFrame", "pd.DataFrame.to_csv", "os.path.normpath", "range", "all_couples.sort", "cross_validation_similarity.evaluate_cross_sim_and_org", "list", "zip", "numpy.abs", "numpy.isnan"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.cross_validation_similarity.load_from_dir", "home.repos.pwc.inspect_result.rist-ro_argo.test.cross_validation_similarity.evaluate_cross_sim_and_org"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Make cross-validation correlations.'", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "'simdir'", ",", "type", "=", "str", ",", "help", "=", "\"directory where to find similarity results\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ntop'", ",", "'-t'", ",", "type", "=", "int", ",", "help", "=", "\"how many top\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "simdir", "=", "args", ".", "simdir", "\n", "\n", "wemb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "simdir", ")", ")", "\n", "corpus", ",", "vstr", ",", "nstr", "=", "wemb_id", ".", "split", "(", "'-'", ")", "\n", "vecsize", "=", "int", "(", "vstr", "[", "1", ":", "]", ")", "\n", "nepoch", "=", "int", "(", "nstr", "[", "1", ":", "]", ")", "\n", "\n", "ntop", "=", "args", ".", "ntop", "\n", "\n", "alphas", ",", "I0", ",", "Iu", ",", "base_similarities", ",", "alpha_similarities", "=", "load_from_dir", "(", "simdir", ")", "\n", "\n", "outputname", "=", "os", ".", "path", ".", "join", "(", "simdir", ",", "\"alpha-similarities-cross-val-top{}.json\"", ".", "format", "(", "ntop", ")", ")", "\n", "\n", "datasets", "=", "[", "\"wordsim353\"", ",", "\n", "\"mc\"", ",", "\"rg\"", ",", "\"scws\"", ",", "\n", "\"wordsim353sim\"", ",", "\"wordsim353rel\"", ",", "\n", "\"men\"", ",", "\"mturk287\"", ",", "\"rw\"", ",", "\"simlex999\"", "\n", "]", "\n", "\n", "\n", "n_splits", "=", "3", "\n", "\n", "cvcorrs", "=", "{", "}", "\n", "\n", "for", "d", "in", "datasets", ":", "\n", "\n", "        ", "for", "m", "in", "methods_args", ":", "\n", "\n", "            ", "curves", "=", "[", "]", "\n", "\n", "for", "n", "in", "range", "(", "n_splits", ")", ":", "\n", "                ", "all_couples", "=", "[", "]", "\n", "\n", "ds", "=", "d", "+", "\"-split_{:}\"", ".", "format", "(", "n", ")", "\n", "\n", "# load small, mid and large and merge", "\n", "for", "key", "in", "data", ":", "\n", "                    ", "all_couples", "+=", "list", "(", "zip", "(", "alphas", "[", "key", "]", ",", "data", "[", "key", "]", "[", "ds", "]", "[", "m", "]", ")", ")", "\n", "\n", "", "all_couples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "all_couples", "=", "[", "(", "a", ",", "v", ")", "for", "a", ",", "v", "in", "all_couples", "if", "np", ".", "abs", "(", "a", ")", "<=", "70.1", "]", "\n", "all_couples", "=", "[", "(", "a", ",", "v", ")", "for", "a", ",", "v", "in", "all_couples", "if", "not", "np", ".", "isnan", "(", "v", ")", "]", "\n", "\n", "#find best top alphas", "\n", "# calculate reverse for the selected alpha", "\n", "# store results in the form {m: [(a1, s1), (a2, s2),...]}", "\n", "evaluate_cross_sim_and_org", "(", "v_dictionary", ",", "d", ",", "n", ",", "ds", ",", "m", ",", "all_couples", ",", "ntop", ",", "cvcorrs", "=", "cvcorrs", ")", "\n", "\n", "\n", "", "", "", "df", "=", "pd", ".", "DataFrame", "(", "cvcorrs", ")", "\n", "df", ".", "to_csv", "(", "outputname", ",", "sep", "=", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.init_logger": [[7, 22], ["logging.basicConfig", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler", "logging.getLogger.addHandler"], "function", ["None"], ["def", "init_logger", "(", "logname", ")", ":", "\n", "    ", "logging", ".", "basicConfig", "(", "format", "=", "'%(message)s'", ",", "filename", "=", "logname", ",", "filemode", "=", "'w'", ",", "level", "=", "logging", ".", "DEBUG", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "logname", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "# # create file handler which logs even debug messages", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "logname", ",", "mode", "=", "'w'", ")", "\n", "# create console handler", "\n", "# ch = logging.StreamHandler(sys.stdout)", "\n", "\n", "# add the handlers to the logger", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "# logger.addHandler(ch)", "\n", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.init_stream_logger": [[23, 31], ["logging.basicConfig", "logging.getLogger"], "function", ["None"], ["", "def", "init_stream_logger", "(", ")", ":", "\n", "    ", "logging", ".", "basicConfig", "(", "format", "=", "'%(message)s'", ",", "level", "=", "logging", ".", "DEBUG", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "# logger.setLevel(logging.DEBUG)", "\n", "# # create file handler which logs even debug messages", "\n", "# fh = logging.FileHandler(logname)", "\n", "# create console handler", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.read_prob_from_wordcounts_csv": [[32, 37], ["pandas.read_csv", "pd.read_csv.set_index", "df[].sum"], "function", ["None"], ["", "def", "read_prob_from_wordcounts_csv", "(", "vocab_name", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "vocab_name", ",", "names", "=", "[", "\"words\"", ",", "\"counts\"", "]", ",", "sep", "=", "\" \"", ")", "\n", "df", "[", "\"probs\"", "]", "=", "df", "[", "\"counts\"", "]", "/", "df", "[", "\"counts\"", "]", ".", "sum", "(", ")", "\n", "df", ".", "set_index", "(", "\"words\"", ",", "inplace", "=", "True", ")", "\n", "return", "df", "[", "\"probs\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_data": [[39, 52], ["create_plot_data_dict", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.create_plot_data_dict"], ["", "def", "save_data", "(", "xs_list", ",", "ys_list", ",", "label_list", ",", "x_label", ",", "y_label", ",", "outname", ",", "plot_method_name", "=", "\"plot\"", ")", ":", "\n", "# if kwargs_list:", "\n", "#     #TODO use args and kwargs, store label in kwargs", "\n", "#     data=[{'plot_method': plot_method_name, 'xs': xs, 'ys': ys, 'label':label, 'kwargs':kwargs} \\", "\n", "#         for (xs,ys,label,kwargs) in zip(xs_list,ys_list,label_list,kwargs_list)]", "\n", "# else:", "\n", "\n", "    ", "dict_tosave", "=", "create_plot_data_dict", "(", "xs_list", ",", "ys_list", ",", "label_list", ",", "x_label", ",", "y_label", ",", "plot_method_name", ")", "\n", "\n", "with", "open", "(", "outname", ",", "'wb'", ")", "as", "outstream", ":", "\n", "        ", "pickle", ".", "dump", "(", "dict_tosave", ",", "outstream", ")", "\n", "\n", "", "return", "dict_tosave", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_pca": [[54, 59], ["mylogging.save_data", "get_pca", "numpy.arange", "itertools.cycle"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_data", "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.get_pca"], ["", "def", "save_pca", "(", "embeddings_list", ",", "labels", ",", "outname", ",", "n_components", "=", "300", ")", ":", "\n", "    ", "eigs_list", "=", "[", "get_pca", "(", "embeddings", ",", "n_components", ")", "for", "embeddings", "in", "embeddings_list", "]", "\n", "eigenvals_idx", "=", "np", ".", "arange", "(", "n_components", ")", "+", "1", "\n", "\n", "save_data", "(", "itertools", ".", "cycle", "(", "[", "eigenvals_idx", "]", ")", ",", "eigs_list", ",", "labels", ",", "outname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_distribution": [[66, 68], ["mylogging.save_data", "numpy.arange", "len"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_data"], ["", "def", "save_distribution", "(", "mu_embedding", ",", "words", ",", "label", ",", "outname", ")", ":", "\n", "    ", "save_data", "(", "[", "np", ".", "arange", "(", "len", "(", "words", ")", ")", "+", "1", "]", ",", "[", "mu_embedding", "]", ",", "[", "label", "]", ",", "outname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.strconv": [[69, 74], ["type", "str"], "function", ["None"], ["", "def", "strconv", "(", "obj", ")", ":", "\n", "    ", "if", "type", "(", "obj", ")", "in", "[", "float", ",", "np", ".", "float", ",", "np", ".", "float32", ",", "np", ".", "float64", "]", ":", "\n", "        ", "return", "'%.6f'", "%", "obj", "\n", "", "else", ":", "\n", "        ", "return", "str", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_columns_to_txt": [[75, 80], ["zip", "spacer.join", "outstream.write", "mylogging.strconv"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.strconv"], ["", "", "def", "write_columns_to_txt", "(", "list_of_list_of_stuffs", ",", "outstream", ",", "spacer", "=", "' '", ")", ":", "\n", "    ", "for", "arr", "in", "zip", "(", "*", "list_of_list_of_stuffs", ")", ":", "\n", "        ", "line", "=", "spacer", ".", "join", "(", "[", "strconv", "(", "n", ")", "for", "n", "in", "arr", "]", ")", "\n", "line", "+=", "'\\n'", "\n", "outstream", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_rows_to_txt": [[81, 86], ["spacer.join", "outstream.write", "mylogging.strconv"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.strconv"], ["", "", "def", "write_rows_to_txt", "(", "list_of_list_of_stuffs", ",", "outstream", ",", "spacer", "=", "' '", ")", ":", "\n", "    ", "for", "arr", "in", "list_of_list_of_stuffs", ":", "\n", "        ", "line", "=", "spacer", ".", "join", "(", "[", "strconv", "(", "n", ")", "for", "n", "in", "arr", "]", ")", "\n", "line", "+=", "'\\n'", "\n", "outstream", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_txt": [[87, 90], ["open", "mylogging.write_columns_to_txt"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_columns_to_txt"], ["", "", "def", "save_txt", "(", "list_of_list_of_stuffs", ",", "outname", ",", "mode", "=", "'w'", ")", ":", "\n", "    ", "with", "open", "(", "outname", ",", "mode", ")", "as", "outstream", ":", "\n", "        ", "write_columns_to_txt", "(", "list_of_list_of_stuffs", ",", "outstream", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.load_similarities": [[12, 20], ["open", "pickle.load", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["def", "load_similarities", "(", "simdir", ")", ":", "\n", "    ", "with", "open", "(", "simdir", "+", "\"/base-similarities.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "base_similarities", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "simdir", "+", "\"/alpha-similarities.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "alpha_similarities", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "base_similarities", ",", "alpha_similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.load_analogies": [[22, 31], ["open", "pickle.load", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load"], ["", "def", "load_analogies", "(", "analogdir", ")", ":", "\n", "    ", "with", "open", "(", "analogdir", "+", "\"/base-analogies.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "base_analogies", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "analogdir", "+", "\"/alpha-analogies.pkl\"", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "alpha_analogies", "=", "pickle", ".", "load", "(", "f", ")", "\n", "#     alpha_analogies = None", "\n", "\n", "", "return", "base_analogies", ",", "alpha_analogies", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_ok_methods": [[101, 111], ["list", "zip", "set", "plot_sim_and_an.ok_method", "sorted", "list.append", "plot_sim_and_an.ok_method", "plot_sim_and_an.ok_method", "plot_sim_and_an.ok_method", "plot_sim_and_an.ok_method", "plot_sim_and_an.ok_method"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method"], ["def", "get_ok_methods", "(", "collection", ",", "ok_method", ")", ":", "\n", "    ", "couples_methods", "=", "[", "]", "\n", "for", "d", "in", "collection", ":", "\n", "        ", "for", "m", "in", "collection", "[", "d", "]", ":", "\n", "            ", "if", "ok_method", "(", "m", ")", ":", "\n", "                ", "lm", "=", "\"limit-\"", "+", "m", "\n", "couples_methods", ".", "append", "(", "(", "m", ",", "lm", ")", ")", "\n", "", "", "", "couples_methods", "=", "list", "(", "set", "(", "couples_methods", ")", ")", "\n", "methods", ",", "limit_methods", "=", "zip", "(", "*", "sorted", "(", "couples_methods", ")", ")", "\n", "return", "methods", ",", "limit_methods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_ok_datasets": [[113, 119], ["sorted", "plot_sim_and_an.ok_dataset", "datasets.append", "plot_sim_and_an.ok_dataset", "plot_sim_and_an.ok_dataset", "plot_sim_and_an.ok_dataset", "plot_sim_and_an.ok_dataset"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_dataset"], ["", "def", "get_ok_datasets", "(", "collection", ",", "ok_dataset", ")", ":", "\n", "    ", "datasets", "=", "[", "]", "\n", "for", "d", "in", "collection", ":", "\n", "        ", "if", "ok_dataset", "(", "d", ")", ":", "\n", "            ", "datasets", ".", "append", "(", "d", ")", "\n", "", "", "return", "sorted", "(", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_method": [[121, 124], ["method_str.startswith"], "function", ["None"], ["", "def", "is_method", "(", "method_str", ",", "theta", ")", ":", "\n", "#     'u-plog-ud-cnI-I'", "\n", "    ", "return", "method_str", ".", "startswith", "(", "\"{:}-plog\"", ".", "format", "(", "theta", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_limit_method": [[126, 129], ["method_str.startswith"], "function", ["None"], ["", "def", "is_limit_method", "(", "method_str", ",", "theta", ")", ":", "\n", "#     'limit-u-plog-ud-cnI-I'", "\n", "    ", "return", "method_str", ".", "startswith", "(", "\"limit-{:}-plog\"", ".", "format", "(", "theta", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_in_point": [[131, 135], ["[].split", "method_str.split"], "function", ["None"], ["", "def", "is_in_point", "(", "method_str", ",", "point_name", ")", ":", "\n", "#     'u-plog-ud-cnI-I'", "\n", "    ", "found_pname", "=", "method_str", ".", "split", "(", "\"-plog-\"", ")", "[", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "return", "found_pname", "==", "point_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_a_split": [[137, 146], ["dataset_str.split", "len", "Exception"], "function", ["None"], ["", "def", "is_a_split", "(", "dataset_str", ")", ":", "\n", "    ", "arr", "=", "dataset_str", ".", "split", "(", "\"-split_\"", ")", "\n", "l", "=", "len", "(", "arr", ")", "\n", "if", "l", "==", "1", ":", "\n", "        ", "return", "False", "\n", "", "elif", "l", "==", "2", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"what is this? Unexpected dataset: {:}\"", ".", "format", "(", "dataset_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_method": [[371, 376], ["numpy.any", "numpy.any", "plot_sim_and_an.is_method", "plot_sim_and_an.is_in_point"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_method", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_in_point"], ["def", "ok_method", "(", "method_str", ")", ":", "\n", "    ", "ok_theta", "=", "np", ".", "any", "(", "[", "is_method", "(", "method_str", ",", "t", ")", "for", "t", "in", "thetas", "]", ")", "\n", "ok_point", "=", "np", ".", "any", "(", "[", "is_in_point", "(", "method_str", ",", "p", ")", "for", "p", "in", "points", "]", ")", "\n", "ok_norm", "=", "not", "(", "\"-cn\"", "in", "method_str", ")", "\n", "return", "ok_theta", "and", "ok_point", "and", "ok_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.ok_dataset": [[378, 380], ["plot_sim_and_an.is_a_split"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.is_a_split"], ["", "def", "ok_dataset", "(", "dataset_str", ")", ":", "\n", "    ", "return", "not", "is_a_split", "(", "dataset_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_sims_ylim": [[165, 184], ["None"], "function", ["None"], ["def", "get_sims_ylim", "(", "d", ")", ":", "\n", "    ", "if", "\"all\"", "in", "d", ":", "\n", "        ", "return", "(", "40", ",", "70", ")", "\n", "", "if", "\"mc\"", "in", "d", ":", "\n", "        ", "return", "(", "60", ",", "90", ")", "\n", "", "if", "\"wordsim\"", "in", "d", ":", "\n", "        ", "return", "(", "50", ",", "85", ")", "\n", "", "if", "\"rw\"", "in", "d", ":", "\n", "        ", "return", "(", "30", ",", "60", ")", "\n", "", "if", "\"scws\"", "in", "d", ":", "\n", "        ", "return", "(", "40", ",", "70", ")", "\n", "", "if", "\"simlex\"", "in", "d", ":", "\n", "        ", "return", "(", "20", ",", "50", ")", "\n", "", "if", "\"mturk\"", "in", "d", ":", "\n", "        ", "return", "(", "45", ",", "75", ")", "\n", "", "if", "\"rg\"", "in", "d", ":", "\n", "        ", "return", "(", "60", ",", "90", ")", "\n", "", "if", "\"men\"", "in", "d", ":", "\n", "        ", "return", "(", "50", ",", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.plot_base": [[186, 191], ["matplotlib.pyplot.hlines"], "function", ["None"], ["", "", "def", "plot_base", "(", "base_methods", ",", "base_results", ")", ":", "\n", "    ", "for", "bm", "in", "base_methods", ":", "\n", "        ", "c", ",", "s", "=", "base_methods", "[", "bm", "]", "\n", "value", "=", "base_results", "[", "bm", "]", "\n", "plt", ".", "hlines", "(", "value", ",", "amin", ",", "amax", ",", "linestyles", "=", "s", ",", "color", "=", "c", ",", "label", "=", "bm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.plot_all": [[193, 215], ["matplotlib.pyplot.figure", "matplotlib.pyplot.title", "itertools.cycle", "zip", "matplotlib.pyplot.ylim", "plot_sim_and_an.plot_base", "matplotlib.pyplot.legend", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "next", "matplotlib.pyplot.plot", "matplotlib.pyplot.hlines", "plot_sim_and_an.get_sims_ylim", "plot_sim_and_an.get_an_ylim"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.plot_base", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_sims_ylim", "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_an_ylim"], ["", "", "def", "plot_all", "(", "datasets", ",", "base_results", ",", "alpha_results", ",", "base_methods", ",", "methods", ",", "limit_methods", ",", "plot_folder", ",", "get_ylim", ")", ":", "\n", "\n", "    ", "for", "d", "in", "datasets", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "15", ",", "10", ")", ")", "\n", "plt", ".", "title", "(", "d", ")", "\n", "\n", "cc", "=", "cycle", "(", "colors", ")", "\n", "\n", "for", "m", ",", "lm", "in", "zip", "(", "methods", ",", "limit_methods", ")", ":", "\n", "            ", "curve", "=", "alpha_results", "[", "d", "]", "[", "m", "]", "\n", "lim", "=", "alpha_results", "[", "d", "]", "[", "lm", "]", "\n", "c", "=", "next", "(", "cc", ")", "\n", "plt", ".", "plot", "(", "alphas", ",", "curve", ",", "color", "=", "c", ",", "label", "=", "m", ")", "\n", "plt", ".", "hlines", "(", "lim", ",", "amin", ",", "amax", ",", "linestyles", "=", "'--'", ",", "color", "=", "c", ")", "\n", "\n", "", "plt", ".", "ylim", "(", "get_ylim", "(", "d", ")", ")", "\n", "plot_base", "(", "base_methods", ",", "base_results", "[", "d", "]", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "path", "=", "plot_folder", "+", "\"/\"", "+", "d", "+", "\".png\"", "\n", "plt", ".", "savefig", "(", "path", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_an_ylim": [[221, 228], ["None"], "function", ["None"], ["def", "get_an_ylim", "(", "d", ")", ":", "\n", "    ", "if", "\"sem\"", "in", "d", ":", "\n", "        ", "return", "(", "60", ",", "90", ")", "\n", "", "if", "\"syn\"", "in", "d", ":", "\n", "        ", "return", "(", "45", ",", "75", ")", "\n", "", "if", "\"tot\"", "in", "d", ":", "\n", "        ", "return", "(", "50", ",", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.plot_sim_and_an.get_other_ds": [[266, 273], ["ods.split", "other_ds.append"], "function", ["None"], ["def", "get_other_ds", "(", "d", ",", "s", ",", "datasets", ")", ":", "\n", "    ", "other_ds", "=", "[", "]", "\n", "for", "ods", "in", "datasets", ":", "\n", "        ", "od", ",", "os", "=", "ods", ".", "split", "(", "\"-split_\"", ")", "\n", "if", "od", "==", "d", "and", "s", "!=", "os", ":", "\n", "            ", "other_ds", ".", "append", "(", "ods", ")", "\n", "", "", "return", "other_ds", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_from_u_distance_not_normalized.unpack_split": [[4, 16], ["numpy.array", "len", "ValueError"], "function", ["None"], ["def", "unpack_split", "(", "arr", ")", ":", "\n", "    ", "word", "=", "arr", "[", "0", "]", "\n", "parameters", "=", "np", ".", "array", "(", "arr", "[", "1", ":", "]", ",", "dtype", "=", "np", ".", "float", ")", "\n", "l", "=", "len", "(", "parameters", ")", "\n", "if", "not", "l", "%", "2", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Words parameters lenght is %d, not even. The input file passed is expected to contain: u_vec bias_u v_vec bias_v.\"", "%", "l", ")", "\n", "", "lh", "=", "l", "/", "2", "\n", "u_w", "=", "parameters", "[", ":", "lh", "-", "1", "]", "\n", "bias_u", "=", "parameters", "[", "lh", "-", "1", "]", "\n", "v_w", "=", "parameters", "[", "lh", ":", "-", "1", "]", "\n", "bias_v", "=", "parameters", "[", "-", "1", "]", "\n", "return", "(", "word", ",", "u_w", ",", "bias_u", ",", "v_w", ",", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_from_u_distance_not_normalized.main": [[17, 36], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "evaluate_from_u_distance_not_normalized.evaluate_vectors", "open", "zip", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "enumerate", "enumerate", "evaluate_from_u_distance_not_normalized.unpack_split", "line.rstrip().split", "fin.readlines", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_plain.evaluate_vectors", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_from_u_distance_not_normalized.unpack_split"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'inputfile'", ",", "help", "=", "'The file where to find the parameters of the GloVe model. Each line: word u_vec u_bias v_vec v_bias'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "inputfile", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "words", ",", "u_embeddings", ",", "u_biases", ",", "v_embeddings", ",", "v_biases", "=", "zip", "(", "*", "[", "unpack_split", "(", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", ")", "for", "line", "in", "fin", ".", "readlines", "(", ")", "]", ")", "\n", "u_embeddings", "=", "np", ".", "array", "(", "u_embeddings", ")", "\n", "u_biases", "=", "np", ".", "array", "(", "u_biases", ")", "\n", "v_embeddings", "=", "np", ".", "array", "(", "v_embeddings", ")", "\n", "v_biases", "=", "np", ".", "array", "(", "v_biases", ")", "\n", "\n", "", "vocab_size", "=", "len", "(", "words", ")", "\n", "vocab", "=", "{", "w", ":", "idx", "for", "idx", ",", "w", "in", "enumerate", "(", "words", ")", "}", "\n", "ivocab", "=", "{", "idx", ":", "w", "for", "idx", ",", "w", "in", "enumerate", "(", "words", ")", "}", "\n", "\n", "vectors", "=", "u_embeddings", "\n", "\n", "evaluate_vectors", "(", "vectors", ",", "vocab", ",", "ivocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_from_u_distance_not_normalized.evaluate_vectors": [[37, 112], ["xrange", "print", "print", "print", "print", "len", "numpy.array", "numpy.zeros", "int", "enumerate", "numpy.argmin", "print", "print", "open", "len", "numpy.ceil", "numpy.sum", "zip", "len", "sum", "line.rstrip().split", "len", "zip", "len", "sum", "len", "sum", "all", "len", "float", "numpy.linalg.norm", "numpy.dot", "numpy.sum", "len", "float", "float", "float", "float", "line.rstrip", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "evaluate_vectors", "(", "W", ",", "vocab", ",", "ivocab", ")", ":", "\n", "    ", "\"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"", "\n", "\n", "filenames", "=", "[", "\n", "'capital-common-countries.txt'", ",", "'capital-world.txt'", ",", "'currency.txt'", ",", "\n", "'city-in-state.txt'", ",", "'family.txt'", ",", "'gram1-adjective-to-adverb.txt'", ",", "\n", "'gram2-opposite.txt'", ",", "'gram3-comparative.txt'", ",", "'gram4-superlative.txt'", ",", "\n", "'gram5-present-participle.txt'", ",", "'gram6-nationality-adjective.txt'", ",", "\n", "'gram7-past-tense.txt'", ",", "'gram8-plural.txt'", ",", "'gram9-plural-verbs.txt'", ",", "\n", "]", "\n", "prefix", "=", "'./eval/question-data/'", "\n", "\n", "# to avoid memory overflow, could be increased/decreased", "\n", "# depending on system and vocab size", "\n", "split_size", "=", "100", "\n", "\n", "correct_sem", "=", "0", ";", "# count correct semantic questions", "\n", "correct_syn", "=", "0", ";", "# count correct syntactic questions", "\n", "correct_tot", "=", "0", "# count correct questions", "\n", "count_sem", "=", "0", ";", "# count all semantic questions", "\n", "count_syn", "=", "0", ";", "# count all syntactic questions", "\n", "count_tot", "=", "0", "# count all questions", "\n", "full_count", "=", "0", "# count all questions, including those with unknown words", "\n", "\n", "for", "i", "in", "xrange", "(", "len", "(", "filenames", ")", ")", ":", "\n", "        ", "with", "open", "(", "'%s/%s'", "%", "(", "prefix", ",", "filenames", "[", "i", "]", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "full_data", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "for", "line", "in", "f", "]", "\n", "full_count", "+=", "len", "(", "full_data", ")", "\n", "data", "=", "[", "x", "for", "x", "in", "full_data", "if", "all", "(", "word", "in", "vocab", "for", "word", "in", "x", ")", "]", "\n", "\n", "", "indices", "=", "np", ".", "array", "(", "[", "[", "vocab", "[", "word", "]", "for", "word", "in", "row", "]", "for", "row", "in", "data", "]", ")", "\n", "ind1", ",", "ind2", ",", "ind3", ",", "ind4", "=", "indices", ".", "T", "\n", "\n", "predictions", "=", "np", ".", "zeros", "(", "(", "len", "(", "indices", ")", ",", ")", ")", "\n", "num_iter", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "indices", ")", "/", "float", "(", "split_size", ")", ")", ")", "\n", "\n", "# the norm is slow,", "\n", "# we can use the fact that || ua - ub -uc +ud ||^2 = ||ua - ub - uc||^2 + ||u_d||^2 - 2 (u_a-u_b-u_c) u_d", "\n", "# distnorms = [np.linalg.norm((W[a, :] - W[b, :] - W[c, :]) + W, axis=1) for (a,b,c) in zip(ind1,ind2,ind3)]", "\n", "d_norms", "=", "(", "np", ".", "sum", "(", "W", "**", "2", ",", "1", ")", "**", "(", "0.5", ")", ")", "\n", "distnorms", "=", "[", "np", ".", "linalg", ".", "norm", "(", "W", "[", "a", ",", ":", "]", "-", "W", "[", "b", ",", ":", "]", "-", "W", "[", "c", ",", ":", "]", ")", "+", "d_norms", "-", "2", "*", "np", ".", "dot", "(", "(", "W", "[", "b", ",", ":", "]", "-", "W", "[", "a", ",", ":", "]", "+", "W", "[", "c", ",", ":", "]", ")", ",", "W", ".", "T", ")", "for", "(", "a", ",", "b", ",", "c", ")", "in", "zip", "(", "ind1", ",", "ind2", ",", "ind3", ")", "]", "\n", "\n", "for", "k", ",", "(", "a", ",", "b", ",", "c", ")", "in", "enumerate", "(", "zip", "(", "ind1", ",", "ind2", ",", "ind3", ")", ")", ":", "\n", "            ", "distnorms", "[", "k", "]", "[", "a", "]", "=", "np", ".", "Inf", "\n", "distnorms", "[", "k", "]", "[", "b", "]", "=", "np", ".", "Inf", "\n", "distnorms", "[", "k", "]", "[", "c", "]", "=", "np", ".", "Inf", "\n", "\n", "", "predictionsnorm", "=", "np", ".", "argmin", "(", "distnorms", ",", "axis", "=", "1", ")", "\n", "\n", "# scalar product, is valid only if vectors are normalized", "\n", "# distprods = [-np.dot((W[b, :] - W[a, :]+  W[c, :]), W.T) for (a,b,c) in zip(ind1,ind2,ind3)]", "\n", "# predictionsprod = np.argmin(distprods, axis=1)", "\n", "# print(all(predictionsnorm==predictionsprod))", "\n", "\n", "val", "=", "(", "ind4", "==", "predictionsnorm", ")", "# correct predictions", "\n", "count_tot", "=", "count_tot", "+", "len", "(", "ind1", ")", "\n", "correct_tot", "=", "correct_tot", "+", "sum", "(", "val", ")", "\n", "if", "i", "<", "5", ":", "\n", "            ", "count_sem", "=", "count_sem", "+", "len", "(", "ind1", ")", "\n", "correct_sem", "=", "correct_sem", "+", "sum", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "count_syn", "=", "count_syn", "+", "len", "(", "ind1", ")", "\n", "correct_syn", "=", "correct_syn", "+", "sum", "(", "val", ")", "\n", "\n", "", "print", "(", "\"%s:\"", "%", "filenames", "[", "i", "]", ")", "\n", "print", "(", "'ACCURACY TOP1: %.2f%% (%d/%d)'", "%", "\n", "(", "np", ".", "mean", "(", "val", ")", "*", "100", ",", "np", ".", "sum", "(", "val", ")", ",", "len", "(", "val", ")", ")", ")", "\n", "\n", "", "print", "(", "'Questions seen/total: %.2f%% (%d/%d)'", "%", "\n", "(", "100", "*", "count_tot", "/", "float", "(", "full_count", ")", ",", "count_tot", ",", "full_count", ")", ")", "\n", "print", "(", "'Semantic accuracy: %.2f%%  (%i/%i)'", "%", "\n", "(", "100", "*", "correct_sem", "/", "float", "(", "count_sem", ")", ",", "correct_sem", ",", "count_sem", ")", ")", "\n", "print", "(", "'Syntactic accuracy: %.2f%%  (%i/%i)'", "%", "\n", "(", "100", "*", "correct_syn", "/", "float", "(", "count_syn", ")", ",", "correct_syn", ",", "count_syn", ")", ")", "\n", "print", "(", "'Total accuracy: %.2f%%  (%i/%i)'", "%", "(", "100", "*", "correct_tot", "/", "float", "(", "count_tot", ")", ",", "correct_tot", ",", "count_tot", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.evaluate_similarities": [[78, 196], ["list", "range", "logger.info", "logger.info", "logger.info", "scipy.stats.spearmanr", "logger.info", "logger.info", "glob.glob", "list.append", "itertools.chain.from_iterable", "len", "numpy.array", "logmap_similarities_plot.similarity_fisher_uv.simeval", "list", "list", "scipy.stats.spearmanr", "logger.info", "logger.info", "core.plotting.create_plot_data_dict", "core.plotting.initialize_plot", "core.plotting.plot_data", "os.path.join", "sorted", "open", "csv.reader", "list", "len", "zip", "len", "core.plotting.create_plot_data_dict", "core.plotting.initialize_plot", "core.plotting.plot_data", "core.plotting.save_object", "core.plotting.finalize_plot", "matplotlib.show", "os.path.join", "[].split", "core.plotting.save_object", "core.plotting.finalize_plot", "matplotlib.show", "float", "os.path.splitext"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.create_plot_data_dict", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.initialize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.plot_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.create_plot_data_dict", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.initialize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.plot_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.save_object", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.finalize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.save_object", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.finalize_plot"], ["def", "evaluate_similarities", "(", "filter_dictionary", ",", "simeval", ",", "logger", ",", "datasets", "=", "[", "]", ",", "outbasename", "=", "None", ",", "plot", "=", "True", ")", ":", "\n", "    ", "\"\"\"Evaluate the trained word vectors on a variety of similarity files\n\n    Args:\n        simeval (method): a method that takes two lists of words and returns a similarity measure. simeval(words1,words2),\n                        i.e. simeval([\"dog\", \"cat\"], [\"tiger\", \"airplane\"])\n        # embeddings_manager (spaces.EmbeddingsManager): embeddings manager, to analyze embeddings.\n        logger (Logger): class to use for logging\n    \"\"\"", "\n", "\n", "folder", "=", "'/data/captamerica_hd2/text/similarities_datasets/splitted'", "\n", "\n", "# # in each of these folders I expect to find the splits", "\n", "# datasets = [", "\n", "#         \"wordsim353\", \"mc\", \"rg\", \"scws\",", "\n", "#         \"wordsim353sim\", \"wordsim353rel\",", "\n", "#         \"men\", \"mturk287\", \"rw\", \"simlex999\"", "\n", "#         ]", "\n", "\n", "filenames", "=", "[", "]", "\n", "\n", "for", "dirname", "in", "datasets", ":", "\n", "        ", "fsplits", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"*.csv\"", ")", ")", ")", "\n", "filenames", ".", "append", "(", "sorted", "(", "fsplits", ")", ")", "\n", "\n", "", "filenames", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "filenames", ")", ")", "\n", "\n", "scores_dict", "=", "{", "}", "\n", "corr_dict", "=", "{", "}", "\n", "\n", "all_humscores", "=", "[", "]", "\n", "all_simscores", "=", "[", "]", "\n", "plot_method", "=", "\"scatter\"", "\n", "title", "=", "\"\"", "\n", "xlabel", "=", "\"human scores\"", "\n", "ylabel", "=", "\"similarity\"", "\n", "\n", "full_count", "=", "0", "\n", "count_tot", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "filenames", ")", ")", ":", "\n", "\n", "        ", "label", "=", "\"-\"", ".", "join", "(", "os", ".", "path", ".", "splitext", "(", "filenames", "[", "i", "]", ")", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "2", ":", "]", ")", "\n", "\n", "with", "open", "(", "filenames", "[", "i", "]", ",", "'r'", ")", "as", "instream", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "instream", ",", "delimiter", "=", "' '", ",", "skipinitialspace", "=", "True", ")", "\n", "lines", "=", "list", "(", "reader", ")", "\n", "full_count", "+=", "len", "(", "lines", ")", "\n", "words1", ",", "words2", ",", "humscores", "=", "zip", "(", "\n", "*", "(", "(", "w1", ",", "w2", ",", "sc", ")", "for", "(", "w1", ",", "w2", ",", "sc", ")", "in", "lines", "if", "(", "w1", "in", "filter_dictionary", ")", "and", "(", "w2", "in", "filter_dictionary", ")", ")", ")", "\n", "count_tot", "+=", "len", "(", "words1", ")", "\n", "\n", "#     full_data = [line.rstrip().split(' ') for line in f]", "\n", "#     full_count += len(full_data)", "\n", "#     data = [x for x in full_data if all(word in dictionary for word in x)]", "\n", "#", "\n", "# indices = np.array([[dictionary[word] for word in row] for row in data])", "\n", "# ind1, ind2, ind3, ind4 = indices.T", "\n", "# read csv in a table and then calculate the distances and pair them with the scores from the csv", "\n", "", "humscores", "=", "np", ".", "array", "(", "humscores", ",", "dtype", "=", "np", ".", "float", ")", "\n", "simscores", "=", "simeval", "(", "words1", ",", "words2", ")", "\n", "\n", "if", "plot", ":", "\n", "            ", "plot_dict", "=", "create_plot_data_dict", "(", "[", "humscores", "]", ",", "[", "simscores", "]", ",", "[", "label", "]", ",", "\n", "xlabel", ",", "ylabel", ",", "plot_method_name", "=", "plot_method", ")", "\n", "\n", "axes", "=", "initialize_plot", "(", "title", ",", "xlabel", ",", "ylabel", ")", "\n", "plot_data", "(", "plot_dict", "[", "\"data\"", "]", ",", "axes", ",", "plot_method", ",", "plot_args", "=", "[", "]", ",", "plot_kwargs", "=", "{", "}", ")", "\n", "\n", "if", "outbasename", ":", "\n", "                ", "outputfile", "=", "outbasename", "+", "\"-\"", "+", "label", "+", "\".dat\"", "\n", "save_object", "(", "plot_dict", ",", "outputfile", ")", "\n", "outputpng", "=", "outbasename", "+", "\"-\"", "+", "label", "+", "\".png\"", "\n", "finalize_plot", "(", "axes", ",", "outputpng", ",", "xlim", "=", "None", ",", "ylim", "=", "None", ",", "legendloc", "=", "None", ")", "\n", "", "else", ":", "\n", "                ", "plt", ".", "show", "(", ")", "\n", "\n", "", "", "all_humscores", "+=", "list", "(", "humscores", ")", "\n", "all_simscores", "+=", "list", "(", "simscores", ")", "\n", "scores_dict", "[", "label", "]", "=", "(", "humscores", ",", "simscores", ")", "\n", "\n", "corr", ",", "p_value", "=", "spearmanr", "(", "humscores", ",", "simscores", ")", "\n", "corr", "=", "corr", "*", "100", "\n", "corr_dict", "[", "label", "]", "=", "corr", "\n", "\n", "logger", ".", "info", "(", "\"%s:\"", "%", "filenames", "[", "i", "]", ")", "\n", "logger", ".", "info", "(", "'SPEARMAN CORR: %.2f '", "%", "corr", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Questions seen/total: %.2f%% (%d/%d)'", "%", "\n", "(", "100", "*", "count_tot", "/", "float", "(", "full_count", ")", ",", "count_tot", ",", "full_count", ")", ")", "\n", "\n", "logger", ".", "info", "(", "'\\nON ALL'", ")", "\n", "logger", ".", "info", "(", "'-------------------------'", ")", "\n", "corr", ",", "p_value", "=", "spearmanr", "(", "all_humscores", ",", "all_simscores", ")", "\n", "corr", "=", "corr", "*", "100", "\n", "\n", "label", "=", "\"all\"", "\n", "corr_dict", "[", "label", "]", "=", "corr", "\n", "\n", "logger", ".", "info", "(", "'SPEARMAN CORR: %.2f '", "%", "corr", ")", "\n", "logger", ".", "info", "(", "'\\n'", ")", "\n", "\n", "if", "plot", ":", "\n", "        ", "plot_dict", "=", "create_plot_data_dict", "(", "[", "all_humscores", "]", ",", "[", "all_simscores", "]", ",", "[", "\"all\"", "]", ",", "\n", "xlabel", ",", "ylabel", ",", "plot_method_name", "=", "plot_method", ")", "\n", "\n", "axes", "=", "initialize_plot", "(", "title", ",", "xlabel", ",", "ylabel", ")", "\n", "plot_data", "(", "plot_dict", "[", "\"data\"", "]", ",", "axes", ",", "plot_method", ",", "plot_args", "=", "[", "]", ",", "plot_kwargs", "=", "{", "}", ")", "\n", "\n", "if", "outbasename", ":", "\n", "            ", "outputfile", "=", "outbasename", "+", "\"-all.dat\"", "\n", "save_object", "(", "plot_dict", ",", "outputfile", ")", "\n", "outputpng", "=", "outbasename", "+", "\"-all.png\"", "\n", "finalize_plot", "(", "axes", ",", "outputpng", ",", "xlim", "=", "None", ",", "ylim", "=", "None", ",", "legendloc", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "\n", "", "", "return", "scores_dict", ",", "corr_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.read_cooccurrences_from_c": [[199, 212], ["numpy.dtype", "numpy.array", "print", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix", "numpy.fromfile", "max", "max", "max"], "function", ["None"], ["", "def", "read_cooccurrences_from_c", "(", "filename", ")", ":", "\n", "    ", "dt", "=", "np", ".", "dtype", "(", "\"i4, i4, f8\"", ")", "\n", "cooccurrences", "=", "np", ".", "array", "(", "np", ".", "fromfile", "(", "filename", ",", "dtype", "=", "dt", ")", ")", "\n", "\n", "row_ind", "=", "cooccurrences", "[", ":", "]", "[", "'f0'", "]", "-", "1", "\n", "col_ind", "=", "cooccurrences", "[", ":", "]", "[", "'f1'", "]", "-", "1", "\n", "values", "=", "cooccurrences", "[", ":", "]", "[", "'f2'", "]", "\n", "\n", "D", "=", "max", "(", "max", "(", "row_ind", "[", "-", "5", ":", "]", ")", ",", "max", "(", "col_ind", "[", "-", "5", ":", "]", ")", ")", "+", "1", "\n", "print", "(", "D", ")", "\n", "C", "=", "scipy", ".", "sparse", ".", "coo_matrix", "(", "(", "values", ",", "(", "row_ind", ",", "col_ind", ")", ")", ",", "shape", "=", "(", "D", ",", "D", ")", ")", "\n", "C", "=", "scipy", ".", "sparse", ".", "csr_matrix", "(", "C", ")", "\n", "return", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.read_cooccurrences_from_c_old": [[214, 236], ["zip", "print", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "scipy.sparse.coo_matrix", "open", "CREC", "max", "stream.readinto", "sizeof", "cooccurrences.append"], "function", ["None"], ["", "def", "read_cooccurrences_from_c_old", "(", "filename", ")", ":", "\n", "# import cooccurrences with couple counts", "\n", "    ", "from", "ctypes", "import", "Structure", ",", "sizeof", ",", "c_int", ",", "c_double", "\n", "\n", "class", "CREC", "(", "Structure", ")", ":", "\n", "        ", "_fields_", "=", "[", "(", "'w1'", ",", "c_int", ")", ",", "\n", "(", "'w2'", ",", "c_int", ")", ",", "\n", "(", "'value'", ",", "c_double", ")", "]", "\n", "\n", "", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "stream", ":", "\n", "        ", "cooccurrences", "=", "[", "]", "\n", "cr", "=", "CREC", "(", ")", "\n", "while", "stream", ".", "readinto", "(", "cr", ")", "==", "sizeof", "(", "cr", ")", ":", "\n", "            ", "cooccurrences", ".", "append", "(", "(", "cr", ".", "w1", "-", "1", ",", "cr", ".", "w2", "-", "1", ",", "cr", ".", "value", ")", ")", "\n", "\n", "", "", "row_ind", ",", "col_ind", ",", "values", "=", "zip", "(", "*", "cooccurrences", ")", "\n", "\n", "D", "=", "max", "(", "row_ind", "+", "col_ind", ")", "+", "1", "\n", "print", "(", "D", ")", "\n", "C", "=", "scipy", ".", "sparse", ".", "coo_matrix", "(", "(", "values", ",", "(", "row_ind", ",", "col_ind", ")", ")", ",", "shape", "=", "(", "D", ",", "D", ")", ")", "\n", "\n", "return", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.sizeof_fmt": [[238, 245], ["abs"], "function", ["None"], ["", "def", "sizeof_fmt", "(", "num", ",", "suffix", "=", "'B'", ")", ":", "\n", "    ", "''' By Fred Cirera, after https://stackoverflow.com/a/1094933/1870254'''", "\n", "for", "unit", "in", "[", "''", ",", "'Ki'", ",", "'Mi'", ",", "'Gi'", ",", "'Ti'", ",", "'Pi'", ",", "'Ei'", ",", "'Zi'", "]", ":", "\n", "        ", "if", "abs", "(", "num", ")", "<", "1024.0", ":", "\n", "            ", "return", "\"%3.1f%s%s\"", "%", "(", "num", ",", "unit", ",", "suffix", ")", "\n", "", "num", "/=", "1024.0", "\n", "", "return", "\"%.1f%s%s\"", "%", "(", "num", ",", "'Yi'", ",", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.see_all_vars": [[246, 250], ["sorted", "print", "logmap_similarities_plot.sizeof_fmt", "sys.getsizeof", "locals().items", "locals"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.sizeof_fmt"], ["", "def", "see_all_vars", "(", "howmany", "=", "None", ")", ":", "\n", "    ", "for", "name", ",", "size", "in", "sorted", "(", "(", "(", "name", ",", "sys", ".", "getsizeof", "(", "value", ")", ")", "for", "name", ",", "value", "in", "locals", "(", ")", ".", "items", "(", ")", ")", ",", "\n", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "[", ":", "howmany", "]", ":", "\n", "        ", "print", "(", "\"{:>30} : {:>8}\"", ".", "format", "(", "name", ",", "sizeof_fmt", "(", "size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_KL": [[253, 263], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "core.compute_embeddings.KL", "core.compute_embeddings.KL"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.KL", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.KL"], ["", "", "def", "similarity_KL", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "symm", "=", "True", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "\n", "sims", "=", "KL", "(", "emb1", ",", "emb2", ")", "\n", "if", "symm", ":", "\n", "        ", "sims", "+=", "KL", "(", "emb2", ",", "emb1", ")", "\n", "sims", "/=", "2.", "\n", "\n", "", "return", "-", "sims", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_BC": [[265, 272], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "core.compute_embeddings.BC"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.BC"], ["", "def", "similarity_BC", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "\n", "sims", "=", "BC", "(", "emb1", ",", "emb2", ")", "\n", "\n", "return", "-", "sims", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.divergence": [[273, 288], ["numpy.sum", "numpy.sum", "numpy.sum", "numpy.log", "numpy.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "divergence", "(", "p", ",", "q", ",", "alpha", ")", ":", "\n", "    ", "p", "+=", "NUMTOL", "\n", "q", "+=", "NUMTOL", "\n", "div", "=", "0", "\n", "if", "alpha", "==", "1", ":", "\n", "        ", "div", "=", "np", ".", "sum", "(", "p", "-", "q", "+", "q", "*", "np", ".", "log", "(", "q", "/", "p", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "elif", "alpha", "==", "-", "1", ":", "\n", "        ", "div", "=", "np", ".", "sum", "(", "q", "-", "p", "+", "p", "*", "np", ".", "log", "(", "p", "/", "q", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "c0", "=", "4", "/", "(", "1", "-", "alpha", "**", "2", ")", "\n", "cp", "=", "(", "1", "-", "alpha", ")", "/", "2", "\n", "cq", "=", "(", "1", "+", "alpha", ")", "/", "2", "\n", "div", "=", "np", ".", "sum", "(", "c0", "*", "(", "cp", "*", "p", "+", "cq", "*", "q", "-", "(", "p", "**", "cp", ")", "*", "(", "q", "**", "cq", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "return", "div", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_div": [[290, 300], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "logmap_similarities_plot.divergence", "logmap_similarities_plot.divergence"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.divergence", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.divergence"], ["", "def", "similarity_div", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "alpha", ",", "symm", "=", "True", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "\n", "sims", "=", "divergence", "(", "emb1", ",", "emb2", ",", "alpha", ")", "\n", "if", "symm", ":", "\n", "        ", "sims", "+=", "divergence", "(", "emb2", ",", "emb1", ",", "alpha", ")", "\n", "sims", "/=", "2.", "\n", "\n", "", "return", "-", "sims", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap": [[302, 351], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "p0.reshape.reshape", "core.compute_embeddings.h", "core.compute_embeddings.h", "logmap_similarities_plot.riemannian_cosprod_fordiag", "core.compute_embeddings.h", "core.compute_embeddings.h", "core.compute_embeddings.h", "core.compute_embeddings.project_vectors_away_from_normal", "core.compute_embeddings.project_vectors_away_from_normal", "numpy.ones", "ValueError"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_cosprod_fordiag", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_vectors_away_from_normal", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_vectors_away_from_normal"], ["", "def", "similarity_logmap", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "alpha", ",", "p0", "=", "None", ",", "dual_transp", "=", "False", ",", "metric", "=", "\"alpha\"", ",", "project", "=", "False", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "\n", "emb1", "+=", "NUMTOL", "\n", "emb2", "+=", "NUMTOL", "\n", "\n", "if", "p0", "is", "None", ":", "\n", "# UNIFORM", "\n", "        ", "s", "=", "embeddings", ".", "shape", "[", "1", "]", "\n", "p0", "=", "np", ".", "ones", "(", "s", ")", "/", "s", "\n", "# UNIFORM", "\n", "\n", "", "p0", "=", "p0", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "ha_p0", "=", "h", "(", "p0", ",", "alpha", ")", "\n", "ha_emb1", "=", "h", "(", "emb1", ",", "alpha", ")", "\n", "logmaps01", "=", "ha_emb1", "-", "ha_p0", "\n", "\n", "if", "dual_transp", ":", "\n", "        ", "ha_emb2", "=", "h", "(", "emb2", ",", "-", "alpha", ")", "\n", "ha_x0", "=", "h", "(", "p0", ",", "-", "alpha", ")", "\n", "logmaps02", "=", "ha_emb2", "-", "ha_x0", "\n", "", "else", ":", "\n", "        ", "ha_emb2", "=", "h", "(", "emb2", ",", "alpha", ")", "\n", "logmaps02", "=", "ha_emb2", "-", "ha_p0", "\n", "\n", "# if I am using the metric in the tangent space alpha", "\n", "", "if", "metric", "==", "\"alpha\"", ":", "\n", "        ", "g_vec", "=", "p0", "**", "alpha", "\n", "# g = np.diag(g.reshape(-1))", "\n", "", "elif", "metric", "==", "\"simplex\"", ":", "\n", "        ", "g_vec", "=", "1", "/", "p0", "\n", "# g = np.diag(g.reshape(-1))", "\n", "", "elif", "metric", "==", "\"id\"", ":", "\n", "        ", "g_vec", "=", "1", "\n", "# g = np.eye(p0.shape[1])", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"metric type not recognized `%s`\"", "%", "metric", ")", "\n", "\n", "", "if", "project", ":", "\n", "        ", "logmaps01", "=", "project_vectors_away_from_normal", "(", "logmaps01", ",", "p0", ",", "alpha", ")", "\n", "logmaps02", "=", "project_vectors_away_from_normal", "(", "logmaps02", ",", "p0", ",", "alpha", ")", "\n", "\n", "# scalprods = riemannian_cosprod(logmaps01, logmaps02, g, normalize=True)", "\n", "", "scalprods", "=", "riemannian_cosprod_fordiag", "(", "logmaps01", ",", "logmaps02", ",", "g_vec", ",", "normalize", "=", "True", ")", "\n", "# scalprods = np.sum(logmaps01 * g * logmaps02, axis=1)", "\n", "\n", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel": [[353, 406], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "p.reshape.reshape", "core.compute_embeddings.h", "core.compute_embeddings.h", "core.compute_embeddings.project_vectors_on_basis", "core.compute_embeddings.h", "core.compute_embeddings.project_vectors_on_basis", "logmap_similarities_plot.riemannian_normalize", "logmap_similarities_plot.riemannian_normalize", "core.compute_embeddings.h", "core.compute_embeddings.h", "core.compute_embeddings.h", "logmap_similarities_plot.riemannian_cosprod", "numpy.arccos", "numpy.arccos", "mod1.reshape", "mod2.reshape", "ValueError", "logmap_similarities_plot.riemannian_distance", "numpy.sum", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_vectors_on_basis", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_vectors_on_basis", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_normalize", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_cosprod", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_distance"], ["", "def", "similarity_logmap_Esubmodel", "(", "p_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "alpha", ",", "I_inv", ",", "beta", ",", "\n", "p", ",", "I_prod", ",", "I_norm", "=", "None", ",", "rescale", "=", "False", ",", "method", "=", "\"cosprod\"", ")", ":", "\n", "# proj logmap", "\n", "    ", "p1", "=", "get_word_embeddings", "(", "words1", ",", "p_embeddings", ",", "dictionary", ")", "\n", "# u1 = get_word_embeddings(words1, u_embeddings, dictionary)", "\n", "# v1 = get_word_embeddings(words1, v_embeddings, dictionary)", "\n", "\n", "p2", "=", "get_word_embeddings", "(", "words2", ",", "p_embeddings", ",", "dictionary", ")", "\n", "# u2 = get_word_embeddings(words2, u_embeddings, dictionary)", "\n", "# v2 = get_word_embeddings(words2, v_embeddings, dictionary)", "\n", "\n", "p1", "+=", "NUMTOL", "\n", "p2", "+=", "NUMTOL", "\n", "\n", "p", "=", "p", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "ha_p0", "=", "h", "(", "p", ",", "alpha", ")", "\n", "ha_emb1", "=", "h", "(", "p1", ",", "alpha", ")", "\n", "logmaps01", "=", "ha_emb1", "-", "ha_p0", "\n", "#now for each line need to project", "\n", "C_proj1", "=", "project_vectors_on_basis", "(", "logmaps01", ",", "beta", ",", "I_inv", ",", "p", ",", "alpha", ")", "\n", "\n", "ha_emb2", "=", "h", "(", "p2", ",", "alpha", ")", "\n", "logmaps02", "=", "ha_emb2", "-", "ha_p0", "\n", "#now for each line need to project", "\n", "C_proj2", "=", "project_vectors_on_basis", "(", "logmaps02", ",", "beta", ",", "I_inv", ",", "p", ",", "alpha", ")", "\n", "\n", "\n", "# normalize the vector with which metric, TODO (multiply by a scalar)", "\n", "if", "I_norm", "is", "not", "None", ":", "\n", "        ", "C_proj1", "=", "riemannian_normalize", "(", "C_proj1", ",", "I_norm", ")", "\n", "C_proj2", "=", "riemannian_normalize", "(", "C_proj2", ",", "I_norm", ")", "\n", "\n", "", "if", "rescale", ":", "\n", "        ", "x1", "=", "h", "(", "p1", ",", "0", ")", "\n", "x2", "=", "h", "(", "p2", ",", "0", ")", "\n", "x0", "=", "h", "(", "p", ",", "0", ")", "\n", "# np.allclose(np.sqrt(np.sum(x1 ** 2, axis=1)), 2)", "\n", "# np.allclose(np.sqrt(np.sum(x2 ** 2, axis=1)), 2)", "\n", "# np.allclose(np.sqrt(np.sum(x0 ** 2, axis=1)), 2)", "\n", "mod1", "=", "2", "*", "np", ".", "arccos", "(", "np", ".", "sum", "(", "x1", "*", "x0", ",", "axis", "=", "1", ")", "/", "4.", ")", "\n", "mod2", "=", "2", "*", "np", ".", "arccos", "(", "np", ".", "sum", "(", "x2", "*", "x0", ",", "axis", "=", "1", ")", "/", "4.", ")", "\n", "C_proj1", "=", "C_proj1", "*", "mod1", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "C_proj2", "=", "C_proj2", "*", "mod2", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "if", "method", "==", "\"cos\"", ":", "\n", "#scalar product with which metric", "\n", "        ", "scalprods", "=", "riemannian_cosprod", "(", "C_proj1", ",", "C_proj2", ",", "I_prod", ",", "normalize", "=", "False", ")", "\n", "", "elif", "method", "==", "\"dis\"", ":", "\n", "        ", "scalprods", "=", "-", "riemannian_distance", "(", "C_proj1", ",", "C_proj2", ",", "I_prod", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"expected only `cos` or `dis`, instead %s given.\"", "%", "method", ")", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick": [[407, 460], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "p.reshape.reshape", "core.compute_embeddings.project_on_basis_from_ps", "core.compute_embeddings.project_on_basis_from_ps", "logmap_similarities_plot.riemannian_normalize", "logmap_similarities_plot.riemannian_normalize", "core.compute_embeddings.h", "core.compute_embeddings.h", "core.compute_embeddings.h", "logmap_similarities_plot.riemannian_cosprod", "numpy.arccos", "numpy.arccos", "mod1.reshape", "mod2.reshape", "ValueError", "logmap_similarities_plot.riemannian_distance", "numpy.sum", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_on_basis_from_ps", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_on_basis_from_ps", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_normalize", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_normalize", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.h", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_cosprod", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_distance"], ["", "def", "similarity_logmap_Esubmodel_trick", "(", "p_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "alpha", ",", "I_inv", ",", "DV", ",", "\n", "p", ",", "I_prod", ",", "I_norm", "=", "None", ",", "rescale", "=", "False", ",", "method", "=", "\"cos\"", ")", ":", "\n", "# proj logmap", "\n", "    ", "p1", "=", "get_word_embeddings", "(", "words1", ",", "p_embeddings", ",", "dictionary", ")", "\n", "# u1 = get_word_embeddings(words1, u_embeddings, dictionary)", "\n", "# v1 = get_word_embeddings(words1, v_embeddings, dictionary)", "\n", "\n", "p2", "=", "get_word_embeddings", "(", "words2", ",", "p_embeddings", ",", "dictionary", ")", "\n", "# u2 = get_word_embeddings(words2, u_embeddings, dictionary)", "\n", "# v2 = get_word_embeddings(words2, v_embeddings, dictionary)", "\n", "\n", "p1", "+=", "NUMTOL", "\n", "p2", "+=", "NUMTOL", "\n", "\n", "p", "=", "p", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "# ha_p0 = h(p, alpha)", "\n", "# ha_emb1 = h(p1, alpha)", "\n", "# logmaps01 = ha_emb1 - ha_p0", "\n", "# #now for each line need to project", "\n", "C_proj1", "=", "project_on_basis_from_ps", "(", "p1", ",", "DV", ",", "I_inv", ",", "p", ",", "alpha", ")", "\n", "\n", "# ha_emb2 = h(p2, alpha)", "\n", "# logmaps02 = ha_emb2 - ha_p0", "\n", "#now for each line need to project", "\n", "C_proj2", "=", "project_on_basis_from_ps", "(", "p2", ",", "DV", ",", "I_inv", ",", "p", ",", "alpha", ")", "\n", "\n", "\n", "# normalize the vector with which metric, TODO (multiply by a scalar)", "\n", "if", "I_norm", "is", "not", "None", ":", "\n", "        ", "C_proj1", "=", "riemannian_normalize", "(", "C_proj1", ",", "I_norm", ")", "\n", "C_proj2", "=", "riemannian_normalize", "(", "C_proj2", ",", "I_norm", ")", "\n", "\n", "", "if", "rescale", ":", "\n", "        ", "x1", "=", "h", "(", "p1", ",", "0", ")", "\n", "x2", "=", "h", "(", "p2", ",", "0", ")", "\n", "x0", "=", "h", "(", "p", ",", "0", ")", "\n", "# np.allclose(np.sqrt(np.sum(x1 ** 2, axis=1)), 2)", "\n", "# np.allclose(np.sqrt(np.sum(x2 ** 2, axis=1)), 2)", "\n", "# np.allclose(np.sqrt(np.sum(x0 ** 2, axis=1)), 2)", "\n", "mod1", "=", "2", "*", "np", ".", "arccos", "(", "np", ".", "sum", "(", "x1", "*", "x0", ",", "axis", "=", "1", ")", "/", "4.", ")", "\n", "mod2", "=", "2", "*", "np", ".", "arccos", "(", "np", ".", "sum", "(", "x2", "*", "x0", ",", "axis", "=", "1", ")", "/", "4.", ")", "\n", "C_proj1", "=", "C_proj1", "*", "mod1", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "C_proj2", "=", "C_proj2", "*", "mod2", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "if", "method", "==", "\"cos\"", ":", "\n", "#scalar product with which metric", "\n", "        ", "scalprods", "=", "riemannian_cosprod", "(", "C_proj1", ",", "C_proj2", ",", "I_prod", ",", "normalize", "=", "False", ")", "\n", "", "elif", "method", "==", "\"dis\"", ":", "\n", "        ", "scalprods", "=", "-", "riemannian_distance", "(", "C_proj1", ",", "C_proj2", ",", "I_prod", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"expected only `cos` or `dis`, instead %s given.\"", "%", "method", ")", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_hyps": [[462, 507], ["core.spaces.HyperSphere", "core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "numpy.array", "numpy.array", "numpy.sum", "core.spaces.HyperSphere.logmap", "core.spaces.HyperSphere.logmap", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.logmap", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.logmap"], ["", "def", "similarity_logmap_hyps", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "x0", "=", "None", ")", ":", "\n", "    ", "hyps", "=", "HyperSphere", "(", "embeddings", ".", "shape", "[", "1", "]", "-", "1", ")", "\n", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "\n", "if", "x0", "is", "None", ":", "\n", "# UNIFORM", "\n", "        ", "x0", "=", "hyps", ".", "_x0", "\n", "# UNIFORM", "\n", "\n", "# # MEAN", "\n", "# x0 = hyps.mean(embeddings_manager.embeddings)", "\n", "# # MEAN", "\n", "\n", "# # MEDIAN", "\n", "# x0 = hyps.median(embeddings_manager.embeddings)", "\n", "# # MEDIAN", "\n", "\n", "", "logmaps01", "=", "np", ".", "array", "(", "[", "hyps", ".", "logmap", "(", "x0", ",", "xa", ")", "for", "xa", "in", "emb1", "]", ")", "\n", "logmaps02", "=", "np", ".", "array", "(", "[", "hyps", ".", "logmap", "(", "x0", ",", "xb", ")", "for", "xb", "in", "emb2", "]", ")", "\n", "\n", "# #PROJECT LOGMAPS ON THE SUBMODEL TANGENT SPACE", "\n", "# u_embeddings, v_embeddings = embeddings_manager.extra_info", "\n", "# v_embeddings_normalized = v_embeddings / np.linalg.norm(v_embeddings, axis=0)", "\n", "#", "\n", "# prods_log10_V = np.matmul(logmaps10, v_embeddings_normalized)", "\n", "# projected_logmaps10 = np.matmul(prods_log10_V, np.transpose(v_embeddings_normalized))", "\n", "#", "\n", "# prods_log20_V = np.matmul(logmaps20, v_embeddings_normalized)", "\n", "# projected_logmaps20 = np.matmul(prods_log20_V, np.transpose(v_embeddings_normalized))", "\n", "\n", "# np.sum(np.transpose(np.transpose(projected_logmaps10)*np.transpose(logmaps10)/(np.linalg.norm(projected_logmaps10, axis=1)*np.linalg.norm(logmaps10, axis=1))),axis=1)", "\n", "\n", "# #LINEARDIFF", "\n", "# logmaps10 = emb1-x0", "\n", "# logmaps20 = emb2-x0", "\n", "# #LINEARDIFF", "\n", "\n", "# logmaps10=projected_logmaps10", "\n", "# logmaps20=projected_logmaps20", "\n", "scalprods", "=", "np", ".", "sum", "(", "logmaps01", "*", "logmaps02", ",", "axis", "=", "1", ")", "/", "(", "\n", "np", ".", "linalg", ".", "norm", "(", "logmaps01", ",", "axis", "=", "1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "logmaps02", ",", "axis", "=", "1", ")", ")", "\n", "# scalprods = np.linalg.norm(logmaps20-logmaps10, axis=1)", "\n", "\n", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cosprod": [[508, 515], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "numpy.sum", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings"], ["", "def", "similarity_cosprod", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "normalize", "=", "True", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "scalprods", "=", "np", ".", "sum", "(", "emb1", "*", "emb2", ",", "axis", "=", "1", ")", "\n", "if", "normalize", ":", "\n", "        ", "scalprods", "=", "scalprods", "/", "(", "np", ".", "linalg", ".", "norm", "(", "emb1", ",", "axis", "=", "1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "emb2", ",", "axis", "=", "1", ")", ")", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cos_fisher": [[516, 521], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "logmap_similarities_plot.riemannian_cosprod"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_cosprod"], ["", "def", "similarity_cos_fisher", "(", "embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "I", ",", "normalize", "=", "False", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "embeddings", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "embeddings", ",", "dictionary", ")", "\n", "\n", "return", "riemannian_cosprod", "(", "emb1", ",", "emb2", ",", "I", ",", "normalize", "=", "normalize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_distance": [[533, 544], ["numpy.sum", "numpy.matmul"], "function", ["None"], ["", "def", "riemannian_distance", "(", "Ca", ",", "Cb", ",", "I", ")", ":", "\n", "#a is a list of vectors", "\n", "#b is a list of vectors", "\n", "#I is the metric", "\n", "\n", "    ", "vec", "=", "Cb", "-", "Ca", "\n", "\n", "Ivec", "=", "np", ".", "matmul", "(", "I", ",", "vec", ".", "T", ")", ".", "T", "\n", "distances", "=", "np", ".", "sum", "(", "vec", "*", "Ivec", ",", "axis", "=", "1", ")", "\n", "\n", "return", "distances", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_cosprod": [[545, 563], ["numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.sum", "numpy.matmul", "numpy.sqrt", "numpy.sqrt", "len", "len", "numpy.matmul", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "riemannian_cosprod", "(", "Ca", ",", "Cb", ",", "I", ",", "normalize", "=", "True", ")", ":", "\n", "#a is a list of vectors", "\n", "#b is a list of vectors", "\n", "#I is the metric", "\n", "    ", "np", ".", "testing", ".", "assert_array_equal", "(", "[", "len", "(", "Ca", ".", "shape", ")", ",", "len", "(", "Cb", ".", "shape", ")", "]", ",", "[", "2", ",", "2", "]", ")", "\n", "needed_I_shape", "=", "[", "Ca", ".", "shape", "[", "1", "]", ",", "Cb", ".", "shape", "[", "1", "]", "]", "\n", "np", ".", "testing", ".", "assert_array_equal", "(", "needed_I_shape", ",", "I", ".", "shape", ")", "\n", "\n", "ICb", "=", "np", ".", "matmul", "(", "I", ",", "Cb", ".", "T", ")", ".", "T", "\n", "scalprods", "=", "np", ".", "sum", "(", "Ca", "*", "ICb", ",", "axis", "=", "1", ")", "\n", "\n", "if", "normalize", ":", "\n", "        ", "ICa", "=", "np", ".", "matmul", "(", "I", ",", "Ca", ".", "T", ")", ".", "T", "\n", "norms1", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "Ca", "*", "ICa", ",", "axis", "=", "1", ")", ")", "\n", "norms2", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "Cb", "*", "ICb", ",", "axis", "=", "1", ")", ")", "\n", "scalprods", "=", "scalprods", "/", "(", "norms1", "*", "norms2", ")", "\n", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_cosprod_fordiag": [[564, 582], ["isinstance", "numpy.sum", "g_vec.reshape.reshape", "numpy.sqrt", "numpy.sqrt", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "riemannian_cosprod_fordiag", "(", "Ca", ",", "Cb", ",", "g_vec", ",", "normalize", "=", "True", ")", ":", "\n", "#a is a list of vectors", "\n", "#b is a list of vectors", "\n", "#I is the metric", "\n", "\n", "    ", "if", "isinstance", "(", "g_vec", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "g_vec", "=", "g_vec", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "", "ICb", "=", "g_vec", "*", "Cb", "\n", "scalprods", "=", "np", ".", "sum", "(", "Ca", "*", "ICb", ",", "axis", "=", "1", ")", "\n", "\n", "if", "normalize", ":", "\n", "        ", "ICa", "=", "g_vec", "*", "Ca", "\n", "norms1", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "Ca", "*", "ICa", ",", "axis", "=", "1", ")", ")", "\n", "norms2", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "Cb", "*", "ICb", ",", "axis", "=", "1", ")", ")", "\n", "scalprods", "=", "scalprods", "/", "(", "norms1", "*", "norms2", ")", "\n", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.riemannian_normalize": [[583, 588], ["numpy.sqrt", "numpy.matmul", "numpy.sum", "np.sqrt.reshape"], "function", ["None"], ["", "def", "riemannian_normalize", "(", "C", ",", "I", ")", ":", "\n", "    ", "IC", "=", "np", ".", "matmul", "(", "I", ",", "C", ".", "T", ")", ".", "T", "\n", "norms", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "C", "*", "IC", ",", "axis", "=", "1", ")", ")", "\n", "Cnorm", "=", "C", "/", "norms", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "return", "Cnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_fisher_uv": [[589, 619], ["p0.reshape.reshape", "core.compute_embeddings.fisher_matrix_and_whatnot", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "numpy.ones", "logmap_similarities_plot.similarity_cos_fisher", "logmap_similarities_plot.similarity_cos_fisher", "logmap_similarities_plot.similarity_cos_fisher", "numpy.eye"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cos_fisher", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cos_fisher", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cos_fisher"], ["", "def", "similarity_fisher_uv", "(", "u_embeddings", ",", "v_embeddings", ",", "embs_name", ",", "dictionary", ",", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "\n", "filter_dictionary", "=", "None", ")", ":", "\n", "# SIMILARITIES FISHER U V", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "", "p0", "=", "np", ".", "ones", "(", "v_embeddings", ".", "shape", "[", "0", "]", ")", "/", "v_embeddings", ".", "shape", "[", "0", "]", "\n", "p0", "=", "p0", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "I", ",", "_", "=", "fisher_matrix_and_whatnot", "(", "v_embeddings", ",", "p0", ")", "\n", "\n", "method_name", "=", "embs_name", "+", "\"-0-f\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_cos_fisher", "(", "u_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "I", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "method_name", "=", "embs_name", "+", "\"-0-i_n\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_cos_fisher", "(", "u_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "np", ".", "eye", "(", "v_embeddings", ".", "shape", "[", "1", "]", ")", ",", "normalize", "=", "True", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "method_name", "=", "embs_name", "+", "\"-0-f_n\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_cos_fisher", "(", "u_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "I", ",", "normalize", "=", "True", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cosUVmod": [[621, 641], ["core.load_embeddings.get_word_embeddings", "core.load_embeddings.get_word_embeddings", "p0.reshape.reshape", "numpy.matmul", "numpy.matmul", "numexpr.evaluate", "numexpr.evaluate", "numpy.ones", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings"], ["", "def", "similarity_cosUVmod", "(", "U", ",", "V", ",", "dictionary", ",", "words1", ",", "words2", ",", "p0", "=", "None", ",", "normalize", "=", "True", ")", ":", "\n", "    ", "emb1", "=", "get_word_embeddings", "(", "words1", ",", "U", ",", "dictionary", ")", "\n", "emb2", "=", "get_word_embeddings", "(", "words2", ",", "U", ",", "dictionary", ")", "\n", "\n", "V", "=", "V", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "if", "p0", "is", "None", ":", "\n", "# UNIFORM", "\n", "        ", "D", "=", "V", ".", "shape", "[", "0", "]", "\n", "p0", "=", "np", ".", "ones", "(", "D", ")", "/", "D", "\n", "# UNIFORM", "\n", "\n", "", "p0", "=", "p0", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "g", "=", "np", ".", "matmul", "(", "V", ".", "T", ",", "ne", ".", "evaluate", "(", "\"p0 * V\"", ")", ")", "\n", "\n", "emb2", "=", "np", ".", "matmul", "(", "emb2", ",", "g", ")", "\n", "scalprods", "=", "ne", ".", "evaluate", "(", "\"sum(emb1 * emb2, axis=1)\"", ")", "\n", "if", "normalize", ":", "\n", "        ", "scalprods", "=", "scalprods", "/", "(", "np", ".", "linalg", ".", "norm", "(", "emb1", ",", "axis", "=", "1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "emb2", ",", "axis", "=", "1", ")", ")", "\n", "", "return", "scalprods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_calc_and_org": [[642, 661], ["stream_logger.info", "stream_logger.info", "logmap_similarities_plot.evaluate_similarities", "stream_logger.info", "stream_logger.info", "[].append", "y_data.get", "y_data[].get"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.evaluate_similarities"], ["", "def", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "extra_param_name", "=", "\"\"", ")", ":", "\n", "    ", "full_name", "=", "method_name", "+", "extra_param_name", "\n", "\n", "stream_logger", ".", "info", "(", "full_name", ")", "\n", "stream_logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "sc", ",", "corr", "=", "evaluate_similarities", "(", "filter_dictionary", ",", "simeval", ",", "stream_logger", ",", "datasets", "=", "all_datasets_names", ",", "plot", "=", "False", ")", "\n", "stream_logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "stream_logger", ".", "info", "(", "\"\"", ")", "\n", "\n", "scores", "[", "full_name", "]", "=", "sc", "\n", "correlations", "[", "full_name", "]", "=", "corr", "\n", "\n", "for", "task_name", "in", "corr", ":", "\n", "        ", "if", "y_data", ".", "get", "(", "task_name", ",", "None", ")", "is", "None", ":", "\n", "            ", "y_data", "[", "task_name", "]", "=", "{", "}", "\n", "", "if", "y_data", "[", "task_name", "]", ".", "get", "(", "method_name", ",", "None", ")", "is", "None", ":", "\n", "            ", "y_data", "[", "task_name", "]", "[", "method_name", "]", "=", "[", "]", "\n", "\n", "", "y_data", "[", "task_name", "]", "[", "method_name", "]", ".", "append", "(", "corr", "[", "task_name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.get_number_from_string": [[666, 675], ["re.findall", "len", "len", "float", "ValueError", "str"], "function", ["None"], ["def", "get_number_from_string", "(", "string", ")", ":", "\n", "    ", "floats_str", "=", "re", ".", "findall", "(", "'\\-?\\d+\\.\\d+'", ",", "string", ")", "\n", "\n", "if", "len", "(", "floats_str", ")", "==", "0", ":", "\n", "        ", "return", "-", "np", ".", "inf", "\n", "", "elif", "len", "(", "floats_str", ")", "==", "1", ":", "\n", "        ", "return", "float", "(", "floats_str", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"found more than one float `%s` in the string `%s`\"", "%", "(", "str", "(", "floats_str", ")", ",", "string", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.print_table": [[692, 706], ["df.sort_values", "df.drop", "logger.info", "logger.info", "logger.info", "logger.info", "mylogging.init_logger", "pandas.DataFrame().transpose", "logmap_similarities_plot.get_number_from_string", "df.to_string", "pandas.DataFrame"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.init_logger", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.get_number_from_string"], ["", "", "def", "print_table", "(", "correlations", ",", "outputfile", "=", "None", ")", ":", "\n", "    ", "logger", "=", "stream_logger", "if", "outputfile", "is", "None", "else", "init_logger", "(", "outputfile", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "correlations", ")", ".", "transpose", "(", ")", "[", "ordered_columns", "]", "\n", "df", "[", "'indexNumber'", "]", "=", "[", "get_number_from_string", "(", "i", ")", "for", "i", "in", "df", ".", "index", "]", "\n", "df", "[", "'indexes'", "]", "=", "df", ".", "index", "\n", "\n", "df", ".", "sort_values", "(", "[", "'indexNumber'", ",", "'indexes'", "]", ",", "ascending", "=", "True", ",", "inplace", "=", "True", ")", "\n", "df", ".", "drop", "(", "[", "'indexNumber'", ",", "'indexes'", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n", "logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "logger", ".", "info", "(", "df", ".", "to_string", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "logger", ".", "info", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.get_style_code": [[707, 721], ["None"], "function", ["None"], ["", "def", "get_style_code", "(", "method_name", ")", ":", "\n", "    ", "if", "\"-f\"", "in", "method_name", "or", "\"-a\"", "in", "method_name", ":", "\n", "        ", "stylestr", "=", "'.'", "\n", "", "elif", "\"-i\"", "in", "method_name", ":", "\n", "        ", "stylestr", "=", "'x'", "\n", "", "else", ":", "\n", "        ", "return", "':'", "\n", "\n", "", "if", "\"-0-\"", "in", "method_name", ":", "\n", "        ", "stylestr", "+=", "'--'", "\n", "", "elif", "\"-u-\"", "in", "method_name", ":", "\n", "        ", "stylestr", "+=", "'-'", "\n", "\n", "", "return", "stylestr", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.plot_all_tasks": [[732, 760], ["min", "max", "matplotlib.close", "os.path.basename", "core.plotting.initialize_plot", "sorted", "core.plotting.finalize_plot", "open", "json.dump", "y_all_methods.keys", "len", "ValueError", "len", "matplotlib.hlines", "logmap_similarities_plot.get_style_code", "matplotlib.plot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.initialize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.finalize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.get_style_code", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["def", "plot_all_tasks", "(", "alphas", ",", "y_data", ",", "outname", ")", ":", "\n", "    ", "xmin", "=", "min", "(", "alphas", ")", "\n", "xmax", "=", "max", "(", "alphas", ")", "\n", "\n", "# y_data is a dictionary of dictionaries of list", "\n", "# task -> method -> list of accuracies corresponding to the parameters (alphas)", "\n", "for", "task_name", "in", "y_data", ":", "\n", "        ", "plot_name", "=", "os", ".", "path", ".", "basename", "(", "outname", ")", "\n", "axes", "=", "initialize_plot", "(", "plot_name", ",", "\"alpha\"", ",", "\"\"", ")", "\n", "\n", "y_all_methods", "=", "y_data", "[", "task_name", "]", "\n", "for", "method_name", "in", "sorted", "(", "y_all_methods", ".", "keys", "(", ")", ")", ":", "\n", "            ", "y", "=", "y_all_methods", "[", "method_name", "]", "\n", "\n", "if", "len", "(", "y", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"y_data of %s is empty...\"", "%", "method_name", ")", "\n", "", "elif", "len", "(", "y", ")", "==", "1", ":", "\n", "                ", "plt", ".", "hlines", "(", "y", "[", "0", "]", ",", "xmin", ",", "xmax", ",", "linestyle", "=", "'--'", ",", "linewidth", "=", "2", ",", "color", "=", "hline_color", "[", "method_name", "]", ",", "label", "=", "method_name", ")", "\n", "", "else", ":", "\n", "                ", "stylecodestr", "=", "get_style_code", "(", "method_name", ")", "\n", "plt", ".", "plot", "(", "alphas", ",", "y", ",", "stylecodestr", ",", "label", "=", "method_name", ")", "\n", "\n", "", "", "finalize_plot", "(", "axes", ",", "outname", "+", "\"-\"", "+", "task_name", "+", "\".png\"", ",", "xlim", "=", "(", "xmin", ",", "xmax", ")", ",", "ylim", "=", "(", "ymin", ",", "ymax", ")", ")", "\n", "\n", "", "with", "open", "(", "outname", "+", "\".json\"", ",", "'w'", ")", "as", "fstream", ":", "\n", "        ", "json", ".", "dump", "(", "y_data", ",", "fstream", ")", "\n", "\n", "", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_divergences": [[762, 808], ["logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_KL", "logmap_similarities_plot.similarity_KL", "logmap_similarities_plot.similarity_BC", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_div", "str", "logmap_similarities_plot.similarity_div", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_KL", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_KL", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_BC", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_div", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_div"], ["", "def", "similarities_divergences", "(", "p_cIw", ",", "prob_name", ",", "alphas", ",", "dictionary", ",", "y_data", "=", "{", "}", ",", "correlations", "=", "{", "}", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "# SIMILARITIES DIVERGENCES", "\n", "    ", "scores", "=", "{", "}", "\n", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "# KL between p(c|w)", "\n", "", "method_name", "=", "prob_name", "+", "\"-KL\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_KL", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "symm", "=", "False", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "# KL between p(c|w) symmetric", "\n", "method_name", "=", "prob_name", "+", "\"-KLsymm\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_KL", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "symm", "=", "True", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "# Bhattharchayya between p(c|w)", "\n", "method_name", "=", "prob_name", "+", "\"-BC\"", "\n", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_BC", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "for", "a", "in", "alphas", ":", "\n", "# alpha divergence between p(c|w)", "\n", "        ", "method_name", "=", "prob_name", "+", "\"-D\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_div", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "symm", "=", "False", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-Dsymm\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_div", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "symm", "=", "True", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "\n", "", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_logmaps_fullrank": [[810, 885], ["logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_logmap", "str", "logmap_similarities_plot.similarity_logmap", "str", "logmap_similarities_plot.similarity_logmap", "str", "logmap_similarities_plot.similarity_logmap", "str", "logmap_similarities_plot.similarity_logmap", "str", "logmap_similarities_plot.similarity_logmap", "str", "logmap_similarities_plot.similarity_logmap", "str", "logmap_similarities_plot.similarity_logmap", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap"], ["", "def", "similarities_logmaps_fullrank", "(", "p_cIw", ",", "prob_name", ",", "p_w", ",", "alphas", ",", "dictionary", ",", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "\n", "# SIMILARITIES LOGMAPS", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "", "for", "a", "in", "alphas", ":", "\n", "\n", "        ", "method_name", "=", "prob_name", "+", "\"-0-Log-a\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "metric", "=", "\"alpha\"", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "# in the uniform p0, all metrics: alpha, simplex and id are equivalent in terms of similarity score since they are one multiple of the other", "\n", "# method_name = prob_name + \"-0-Log-i\"", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap(p_cIw, dictionary, words1, words2, a, metric=\"id\")", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "#", "\n", "# method_name = prob_name + \"-0-Log-s\"", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap(p_cIw, dictionary, words1, words2, a, metric=\"simplex\")", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "\n", "\n", "# method_name = prob_name+\"-0-DTLog\"", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap(p_cIw, dictionary, words1, words2, a, dual_transp=True)", "\n", "#", "\n", "# similarity_calc_and_org(method_name, simeval, scores, correlations, y_data, str(a))", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-Log-a\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "p0", "=", "p_w", ",", "metric", "=", "\"alpha\"", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-Log-s\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "p0", "=", "p_w", ",", "metric", "=", "\"simplex\"", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-Log-i\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "p0", "=", "p_w", ",", "metric", "=", "\"id\"", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-0-pjLog-a\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "metric", "=", "\"alpha\"", ",", "project", "=", "True", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-a\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "p0", "=", "p_w", ",", "metric", "=", "\"alpha\"", ",", "project", "=", "True", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-s\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "p0", "=", "p_w", ",", "metric", "=", "\"simplex\"", ",", "project", "=", "True", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-i\"", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "p0", "=", "p_w", ",", "metric", "=", "\"id\"", ",", "project", "=", "True", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "# method_name = prob_name+\"-u-DTLog\"", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap(p_cIw, dictionary, words1, words2, a, x0=p_w, dual_transp=True)", "\n", "#", "\n", "# similarity_calc_and_org(method_name, simeval, scores, correlations, y_data, str(a))", "\n", "\n", "", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_logmaps_Esubmodel": [[886, 993], ["p0.reshape.reshape", "core.compute_embeddings.fisher_matrix_and_whatnot", "numpy.linalg.inv", "pu.reshape.reshape", "core.compute_embeddings.fisher_matrix_and_whatnot", "numpy.linalg.inv", "numpy.eye", "numpy.ones", "core.compute_embeddings.beta_fisher_basis", "core.compute_embeddings.beta_fisher_basis", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_logmap_Esubmodel", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.beta_fisher_basis", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.beta_fisher_basis", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel"], ["", "def", "similarities_logmaps_Esubmodel", "(", "p_cIw", ",", "U", ",", "V", ",", "prob_name", ",", "pu", ",", "alphas", ",", "dictionary", ",", "\n", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "filter_dictionary", "=", "None", ",", "method", "=", "\"cos\"", ")", ":", "\n", "\n", "# SIMILARITIES LOGMAPS", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "# I is the fisher matrix, beta is the (pushforward of a vector in u -> to a vector in R^n_(alpha))", "\n", "# i.e. matrix containing as rows the coordinates of the basis for the fisher matrix (beta) in R^n_(alpha)", "\n", "\n", "", "p0", "=", "np", ".", "ones", "(", "V", ".", "shape", "[", "0", "]", ")", "/", "V", ".", "shape", "[", "0", "]", "\n", "p0", "=", "p0", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "I0", ",", "DV0", "=", "fisher_matrix_and_whatnot", "(", "V", ",", "p0", ")", "\n", "I0_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I0", ")", "\n", "\n", "pu", "=", "pu", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "Iu", ",", "DVu", "=", "fisher_matrix_and_whatnot", "(", "V", ",", "pu", ")", "\n", "Iu_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iu", ")", "\n", "\n", "Id", "=", "np", ".", "eye", "(", "V", ".", "shape", "[", "1", "]", ")", "\n", "\n", "for", "a", "in", "alphas", ":", "\n", "        ", "beta0", "=", "beta_fisher_basis", "(", "DV0", ",", "p0", ",", "a", ")", "\n", "betau", "=", "beta_fisher_basis", "(", "DVu", ",", "pu", ",", "a", ")", "\n", "\n", "# method_name = prob_name+\"-0-pjLog-f\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, I0_inv, beta0, p0, I0, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-0-pjLog-nf-f\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "I0_inv", ",", "beta0", ",", "p0", ",", "I0", ",", "I_norm", "=", "I0", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "# method_name = prob_name+\"-0-pjLog-nf-r-f\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, I0_inv, beta0, p0, I0, I_norm=I0, rescale=True, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "#", "\n", "# method_name = prob_name+\"-0-pjLog-nf-r-i\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, I0_inv, beta0, p0, Id, I_norm=I0, rescale=True, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-0-pjLog-nf-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "I0_inv", ",", "beta0", ",", "p0", ",", "Id", ",", "I_norm", "=", "I0", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-0-pjLog-ni-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "I0_inv", ",", "beta0", ",", "p0", ",", "Id", ",", "I_norm", "=", "Id", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "# method_name = prob_name+\"-0-pjLog-i\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, I0_inv, beta0, p0, Id, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "#", "\n", "# method_name = prob_name+\"-0-pjLog-ni-f\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, I0_inv, beta0, p0, I0, I_norm=Id, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-nf-f\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "Iu_inv", ",", "betau", ",", "pu", ",", "Iu", ",", "I_norm", "=", "Iu", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "# method_name = prob_name + \"-u-pjLog-f\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, Iu_inv, betau, pu, Iu, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "#", "\n", "# method_name = prob_name + \"-u-pjLog-nf-r-f\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, Iu_inv, betau, pu, Iu, I_norm=Iu, rescale=True, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "#", "\n", "# method_name = prob_name + \"-u-pjLog-nf-r-i\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, Iu_inv, betau, pu, Id, I_norm=Iu, rescale=True, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-nf-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "Iu_inv", ",", "betau", ",", "pu", ",", "Id", ",", "I_norm", "=", "Iu", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-ni-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "Iu_inv", ",", "betau", ",", "pu", ",", "Id", ",", "I_norm", "=", "Id", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "# method_name = prob_name + \"-u-pjLog-i\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, Iu_inv, betau, pu, Id, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "#", "\n", "# method_name = prob_name + \"-u-pjLog-ni-f\"+method", "\n", "# def simeval(words1, words2):", "\n", "#     return similarity_logmap_Esubmodel(p_cIw, dictionary, words1, words2, a, Iu_inv, betau, pu, Iu, I_norm=Id, method=method)", "\n", "# similarity_calc_and_org(method_name, simeval, filter_dictionary, scores, correlations, y_data, str(a))", "\n", "\n", "", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_logmaps_Esubmodel_trick": [[994, 1049], ["p0.reshape.reshape", "core.compute_embeddings.fisher_matrix_and_whatnot", "numpy.linalg.inv", "pu.reshape.reshape", "core.compute_embeddings.fisher_matrix_and_whatnot", "numpy.linalg.inv", "numpy.eye", "numpy.ones", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "str", "logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_logmap_Esubmodel_trick"], ["", "def", "similarities_logmaps_Esubmodel_trick", "(", "p_cIw", ",", "U", ",", "V", ",", "prob_name", ",", "pu", ",", "alphas", ",", "dictionary", ",", "\n", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "filter_dictionary", "=", "None", ",", "method", "=", "\"cos\"", ")", ":", "\n", "\n", "# SIMILARITIES LOGMAPS", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "# I is the fisher matrix, beta is the (pushforward of a vector in u -> to a vector in R^n_(alpha))", "\n", "# i.e. matrix containing as rows the coordinates of the basis for the fisher matrix (beta) in R^n_(alpha)", "\n", "\n", "", "p0", "=", "np", ".", "ones", "(", "V", ".", "shape", "[", "0", "]", ")", "/", "V", ".", "shape", "[", "0", "]", "\n", "p0", "=", "p0", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "I0", ",", "DV0", "=", "fisher_matrix_and_whatnot", "(", "V", ",", "p0", ")", "\n", "I0_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I0", ")", "\n", "\n", "pu", "=", "pu", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "Iu", ",", "DVu", "=", "fisher_matrix_and_whatnot", "(", "V", ",", "pu", ")", "\n", "Iu_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iu", ")", "\n", "\n", "Id", "=", "np", ".", "eye", "(", "V", ".", "shape", "[", "1", "]", ")", "\n", "\n", "for", "a", "in", "alphas", ":", "\n", "\n", "        ", "method_name", "=", "prob_name", "+", "\"-0-pjLog-nf-f\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel_trick", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "I0_inv", ",", "DV0", ",", "p0", ",", "I0", ",", "I_norm", "=", "I0", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-0-pjLog-nf-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel_trick", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "I0_inv", ",", "DV0", ",", "p0", ",", "Id", ",", "I_norm", "=", "I0", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-0-pjLog-ni-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel_trick", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "I0_inv", ",", "DV0", ",", "p0", ",", "Id", ",", "I_norm", "=", "Id", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-nf-f\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel_trick", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "Iu_inv", ",", "DVu", ",", "pu", ",", "Iu", ",", "I_norm", "=", "Iu", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-nf-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel_trick", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "Iu_inv", ",", "DVu", ",", "pu", ",", "Id", ",", "I_norm", "=", "Iu", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "method_name", "=", "prob_name", "+", "\"-u-pjLog-ni-i\"", "+", "method", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "            ", "return", "similarity_logmap_Esubmodel_trick", "(", "p_cIw", ",", "dictionary", ",", "words1", ",", "words2", ",", "a", ",", "Iu_inv", ",", "DVu", ",", "pu", ",", "Id", ",", "I_norm", "=", "Id", ",", "method", "=", "method", ")", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ",", "str", "(", "a", ")", ")", "\n", "\n", "", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean": [[1050, 1064], ["logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_cosprod"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cosprod"], ["", "def", "similarity_euclidean", "(", "embs", ",", "embs_name", ",", "dictionary", ",", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "# SIMILARITIES EUCLIDEAN", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "", "method_name", "=", "embs_name", "+", "\"-cosprod\"", "\n", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_cosprod", "(", "embs", ",", "dictionary", ",", "words1", ",", "words2", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean_preproc": [[1065, 1076], ["logmap_similarities_plot.similarity_euclidean", "logmap_similarities_plot.similarity_euclidean", "logmap_similarities_plot.similarity_euclidean", "logmap_similarities_plot.center_and_normalize_eucl", "logmap_similarities_plot.center_and_normalize_eucl", "logmap_similarities_plot.center_and_normalize_eucl"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "def", "similarity_euclidean_preproc", "(", "embs", ",", "embs_name", ",", "dictionary", ",", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "", "similarity_euclidean", "(", "center_and_normalize_eucl", "(", "embs", ",", "True", ",", "False", ",", "0", ")", ",", "embs_name", "+", "\"-cn\"", ",", "dictionary", ",", "\n", "correlations", "=", "correlations", ",", "y_data", "=", "y_data", ",", "filter_dictionary", "=", "filter_dictionary", ")", "\n", "similarity_euclidean", "(", "center_and_normalize_eucl", "(", "embs", ",", "False", ",", "True", ",", "0", ")", ",", "embs_name", "+", "\"-nc\"", ",", "dictionary", ",", "\n", "correlations", "=", "correlations", ",", "y_data", "=", "y_data", ",", "filter_dictionary", "=", "filter_dictionary", ")", "\n", "similarity_euclidean", "(", "center_and_normalize_eucl", "(", "embs", ",", "False", ",", "False", ",", "0", ")", ",", "embs_name", "+", "\"-n\"", ",", "dictionary", ",", "\n", "correlations", "=", "correlations", ",", "y_data", "=", "y_data", ",", "filter_dictionary", "=", "filter_dictionary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_almost_fisher_uv": [[1078, 1092], ["logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_cosUVmod"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cosUVmod"], ["", "def", "similarity_almost_fisher_uv", "(", "u_embeddings", ",", "v_embeddings", ",", "embs_name", ",", "dictionary", ",", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "p0", "=", "None", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "# SIMILARITIES FISHER U V", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "", "method_name", "=", "embs_name", "+", "\"-cosmod\"", "\n", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_cosUVmod", "(", "u_embeddings", ",", "v_embeddings", ",", "dictionary", ",", "words1", ",", "words2", ",", "p0", "=", "p0", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_double_cosprod": [[1093, 1107], ["logmap_similarities_plot.similarity_calc_and_org", "logmap_similarities_plot.similarity_cosprod", "logmap_similarities_plot.similarity_cosprod"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cosprod", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_cosprod"], ["", "def", "similarity_double_cosprod", "(", "u_embs", ",", "v_embs", ",", "embs_name", ",", "dictionary", ",", "correlations", "=", "{", "}", ",", "y_data", "=", "{", "}", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "# SIMILARITIES double cosprod", "\n", "    ", "scores", "=", "{", "}", "\n", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "dictionary", "\n", "\n", "", "method_name", "=", "embs_name", "+", "\"-dbcosprod\"", "\n", "\n", "def", "simeval", "(", "words1", ",", "words2", ")", ":", "\n", "        ", "return", "similarity_cosprod", "(", "u_embs", ",", "dictionary", ",", "words1", ",", "words2", ")", "+", "similarity_cosprod", "(", "v_embs", ",", "dictionary", ",", "words1", ",", "words2", ")", "\n", "\n", "", "similarity_calc_and_org", "(", "method_name", ",", "simeval", ",", "filter_dictionary", ",", "scores", ",", "correlations", ",", "y_data", ")", "\n", "\n", "return", "correlations", ",", "y_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.mean_numexpr": [[1109, 1118], ["mean.reshape", "numexpr.evaluate", "mean.reshape", "Exception", "numexpr.evaluate"], "function", ["None"], ["", "def", "mean_numexpr", "(", "embs", ",", "index", ")", ":", "\n", "    ", "if", "index", "==", "0", ":", "\n", "        ", "mean", "=", "ne", ".", "evaluate", "(", "\"sum(embs, axis=0)\"", ")", "/", "embs", ".", "shape", "[", "0", "]", "\n", "return", "mean", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "", "elif", "index", "==", "1", ":", "\n", "        ", "mean", "=", "ne", ".", "evaluate", "(", "\"sum(embs, axis=1)\"", ")", "/", "embs", ".", "shape", "[", "1", "]", "\n", "return", "mean", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"index can be either 0 or 1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl": [[1120, 1152], ["Exception", "numpy.sqrt().reshape", "numexpr.evaluate", "logmap_similarities_plot.mean_numexpr", "logmap_similarities_plot.mean_numexpr", "numpy.sqrt", "numexpr.evaluate"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.mean_numexpr", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.mean_numexpr"], ["", "", "def", "center_and_normalize_eucl", "(", "embs", ",", "center_before", "=", "False", ",", "center_after", "=", "True", ",", "center_index", "=", "1", ",", "normalize", "=", "True", ")", ":", "\n", "\n", "    ", "if", "center_index", "not", "in", "[", "0", ",", "1", "]", ":", "\n", "        ", "raise", "Exception", "(", "\"center_index can be either 0 for center columns or 1 for center rows\"", ")", "\n", "\n", "# is_mat = True", "\n", "# # I need a np.matrix for this function", "\n", "# if type(embs) is not np.matrixlib.defmatrix.matrix or type(embs) is not scipy.sparse.coo.coo_matrix:", "\n", "#     is_mat = False", "\n", "#     embs = np.matrix(embs)", "\n", "\n", "", "if", "center_before", ":", "\n", "# embs = embs - np.mean(embs, axis=center_index)", "\n", "        ", "embs", "=", "embs", "-", "mean_numexpr", "(", "embs", ",", "center_index", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "# import pdb;pdb.set_trace()", "\n", "        ", "norms", "=", "np", ".", "sqrt", "(", "ne", ".", "evaluate", "(", "\"sum(embs**2, axis=0)\"", ")", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "# norms = np.linalg.norm(embs, axis=0)", "\n", "# embs = embs / norms", "\n", "embs", "=", "ne", ".", "evaluate", "(", "\"embs / norms\"", ")", "\n", "# embs = embs / np.sqrt(np.sum(embs**2, axis=0))", "\n", "# embs = embs / np.linalg.norm(embs, axis=0)", "\n", "\n", "", "if", "center_after", ":", "\n", "# embs = embs - np.mean(embs, axis=center_index)", "\n", "        ", "embs", "=", "embs", "-", "mean_numexpr", "(", "embs", ",", "center_index", ")", "\n", "\n", "# if not is_mat:", "\n", "#     embs = np.array(embs)", "\n", "\n", "", "return", "embs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge": [[1154, 1165], ["isinstance", "isinstance", "logmap_similarities_plot.merge"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge"], ["", "def", "merge", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"merges b into a\"", "\n", "for", "key", "in", "b", ":", "\n", "        ", "if", "isinstance", "(", "b", "[", "key", "]", ",", "dict", ")", ":", "\n", "            ", "if", "(", "key", "in", "a", ")", "and", "isinstance", "(", "a", "[", "key", "]", ",", "dict", ")", ":", "\n", "                ", "merge", "(", "a", "[", "key", "]", ",", "b", "[", "key", "]", ")", "\n", "", "else", ":", "\n", "                ", "a", "[", "key", "]", "=", "b", "[", "key", "]", "\n", "", "", "else", ":", "\n", "            ", "a", "[", "key", "]", "=", "b", "[", "key", "]", "\n", "", "", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_p_wc_from_counts": [[1167, 1195], ["print", "C.sum", "C.sum().reshape", "numexpr.evaluate", "numpy.squeeze", "numpy.array", "C.sum"], "function", ["None"], ["", "def", "compute_p_wc_from_counts", "(", "C", ")", ":", "\n", "    ", "print", "(", "\"I am creating p_wc from C...\"", ")", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "sums1", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "p_w", "=", "sums1", "/", "N", "\n", "# p_c = C.sum(axis=0) / N", "\n", "p_cIw", "=", "C", "/", "sums1", "\n", "# p_cIw = ne.evaluate(\"C / sums1\")", "\n", "# p_wc = np.multiply(p_cIw, p_w)", "\n", "p_wc", "=", "ne", ".", "evaluate", "(", "\"p_cIw * p_w\"", ")", "\n", "# print(\"I am creating the ratio matrix...\")", "\n", "# prodprobs = np.matmul(p_w, p_c)", "\n", "# # r1 = p_wc / prodprobs", "\n", "# # r2 = p_cIw / p_c", "\n", "# r = (C/np.matmul(C.sum(axis=1), C.sum(axis=0))) * N", "\n", "\n", "# print(\"I am creating PMI, NPMI and PPMI matrices...\")", "\n", "# PMI = np.log(r+NUMTOL)", "\n", "# NPMI = PMI/(-np.log(p_wc+NUMTOL))", "\n", "# PPMI = np.maximum(NUMTOL, PMI) - NUMTOL", "\n", "#", "\n", "# x_data = np.sqrt(p_cIw)", "\n", "# h_data = np.log(1+p_cIw)", "\n", "\n", "p_w", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "p_w", ")", ")", "\n", "# p_c = np.squeeze(np.array(p_c))", "\n", "# np.allclose(p_w, p_c)", "\n", "return", "p_w", ",", "p_wc", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_PMI_from_counts": [[1196, 1216], ["print", "C.sum", "print", "numpy.log", "numpy.matmul", "C.sum", "C.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "compute_PMI_from_counts", "(", "C", ")", ":", "\n", "    ", "print", "(", "\"I am creating the ratio matrix...\"", ")", "\n", "# prodprobs = np.matmul(p_w, p_c)", "\n", "# # r1 = p_wc / prodprobs", "\n", "# # r2 = p_cIw / p_c", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "r", "=", "(", "C", "/", "np", ".", "matmul", "(", "C", ".", "sum", "(", "axis", "=", "1", ")", ",", "C", ".", "sum", "(", "axis", "=", "0", ")", ")", ")", "*", "N", "\n", "\n", "print", "(", "\"I am creating PMI...\"", ")", "\n", "PMI", "=", "np", ".", "log", "(", "r", "+", "NUMTOL", ")", "\n", "# NPMI = PMI/(-np.log(p_wc+NUMTOL))", "\n", "# PPMI = np.maximum(NUMTOL, PMI) - NUMTOL", "\n", "#", "\n", "# x_data = np.sqrt(p_cIw)", "\n", "# h_data = np.log(1+p_cIw)", "\n", "\n", "# p_w = np.squeeze(np.array(p_w))", "\n", "# p_c = np.squeeze(np.array(p_c))", "\n", "# np.allclose(p_w, p_c)", "\n", "return", "PMI", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_PPMI_from_counts": [[1217, 1230], ["print", "C.sum", "print", "numpy.log", "numpy.maximum", "numpy.matmul", "C.sum", "C.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "compute_PPMI_from_counts", "(", "C", ")", ":", "\n", "    ", "print", "(", "\"I am creating the ratio matrix...\"", ")", "\n", "# prodprobs = np.matmul(p_w, p_c)", "\n", "# # r1 = p_wc / prodprobs", "\n", "# # r2 = p_cIw / p_c", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "r", "=", "(", "C", "/", "np", ".", "matmul", "(", "C", ".", "sum", "(", "axis", "=", "1", ")", ",", "C", ".", "sum", "(", "axis", "=", "0", ")", ")", ")", "*", "N", "\n", "\n", "print", "(", "\"I am creating PMI...\"", ")", "\n", "PMI", "=", "np", ".", "log", "(", "r", "+", "NUMTOL", ")", "\n", "# NPMI = PMI/(-np.log(p_wc+NUMTOL))", "\n", "PPMI", "=", "np", ".", "maximum", "(", "NUMTOL", ",", "PMI", ")", "-", "NUMTOL", "\n", "return", "PPMI", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_p_cIw_from_counts": [[1232, 1259], ["print", "C.sum", "C.sum().reshape", "numpy.squeeze", "numpy.array", "C.sum"], "function", ["None"], ["", "def", "compute_p_cIw_from_counts", "(", "C", ")", ":", "\n", "    ", "print", "(", "\"I am creating pcIw from C...\"", ")", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "sums1", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "p_w", "=", "sums1", "/", "N", "\n", "# p_c = C.sum(axis=0) / N", "\n", "p_cIw", "=", "C", "/", "sums1", "\n", "# p_wc = np.multiply(p_cIw, p_w)", "\n", "\n", "# print(\"I am creating the ratio matrix...\")", "\n", "# prodprobs = np.matmul(p_w, p_c)", "\n", "# # r1 = p_wc / prodprobs", "\n", "# # r2 = p_cIw / p_c", "\n", "# r = (C/np.matmul(C.sum(axis=1), C.sum(axis=0))) * N", "\n", "\n", "# print(\"I am creating PMI, NPMI and PPMI matrices...\")", "\n", "# PMI = np.log(r+NUMTOL)", "\n", "# NPMI = PMI/(-np.log(p_wc+NUMTOL))", "\n", "# PPMI = np.maximum(NUMTOL, PMI) - NUMTOL", "\n", "#", "\n", "# x_data = np.sqrt(p_cIw)", "\n", "# h_data = np.log(1+p_cIw)", "\n", "\n", "p_w", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "p_w", ")", ")", "\n", "# p_c = np.squeeze(np.array(p_c))", "\n", "# np.allclose(p_w, p_c)", "\n", "return", "p_w", ",", "p_cIw", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_probs_from_counts": [[1261, 1287], ["print", "C.sum", "numpy.multiply", "numpy.squeeze", "numpy.squeeze", "numpy.allclose", "C.sum", "C.sum", "C.sum", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "compute_probs_from_counts", "(", "C", ")", ":", "\n", "    ", "print", "(", "\"I am creating probabilities matrices...\"", ")", "\n", "N", "=", "C", ".", "sum", "(", ")", "\n", "p_w", "=", "C", ".", "sum", "(", "axis", "=", "1", ")", "/", "N", "\n", "p_c", "=", "C", ".", "sum", "(", "axis", "=", "0", ")", "/", "N", "\n", "p_cIw", "=", "C", "/", "C", ".", "sum", "(", "axis", "=", "1", ")", "\n", "p_wc", "=", "np", ".", "multiply", "(", "p_cIw", ",", "p_w", ")", "\n", "\n", "# print(\"I am creating the ratio matrix...\")", "\n", "# prodprobs = np.matmul(p_w, p_c)", "\n", "# # r1 = p_wc / prodprobs", "\n", "# # r2 = p_cIw / p_c", "\n", "# r = (C/np.matmul(C.sum(axis=1), C.sum(axis=0))) * N", "\n", "\n", "# print(\"I am creating PMI, NPMI and PPMI matrices...\")", "\n", "# PMI = np.log(r+NUMTOL)", "\n", "# NPMI = PMI/(-np.log(p_wc+NUMTOL))", "\n", "# PPMI = np.maximum(NUMTOL, PMI) - NUMTOL", "\n", "#", "\n", "# x_data = np.sqrt(p_cIw)", "\n", "# h_data = np.log(1+p_cIw)", "\n", "\n", "p_w", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "p_w", ")", ")", "\n", "p_c", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "p_c", ")", ")", "\n", "np", ".", "allclose", "(", "p_w", ",", "p_c", ")", "\n", "return", "p_w", ",", "p_cIw", ",", "p_wc", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.calculate_or_load_common_base": [[1288, 1331], ["logmap_similarities_plot.merge", "logmap_similarities_plot.merge", "os.path.split", "os.path.splitext", "open", "json.dump", "os.path.basename", "open", "json.load", "core.load_embeddings.read_cooccurrences_from_c", "logmap_similarities_plot.compute_probs_from_counts", "logmap_similarities_plot.similarity_euclidean", "logmap_similarities_plot.similarity_euclidean", "gc.collect", "core.load_embeddings.load_pretrained_glove", "logmap_similarities_plot.similarity_euclidean"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.read_cooccurrences_from_c", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_probs_from_counts", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_pretrained_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean"], ["", "def", "calculate_or_load_common_base", "(", "fnamecc", ",", "v_dictionary", ",", "outdirname", ",", "corrs", ",", "y_data", ")", ":", "\n", "    ", "json_dir", "=", "os", ".", "path", ".", "split", "(", "outdirname", ")", "[", "0", "]", "\n", "_id", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "fnamecc", ")", ")", "[", "0", "]", "\n", "json_name", "=", "json_dir", "+", "\"/\"", "+", "_id", "+", "\"-common_base.json\"", "\n", "\n", "try", ":", "\n", "\n", "        ", "with", "open", "(", "json_name", ",", "'r'", ")", "as", "fstream", ":", "\n", "            ", "cb_corrs", ",", "cb_y_data", "=", "json", ".", "load", "(", "fstream", ")", "\n", "\n", "", "", "except", ":", "\n", "\n", "        ", "cb_corrs", "=", "{", "}", "\n", "cb_y_data", "=", "{", "}", "\n", "C", "=", "read_cooccurrences_from_c", "(", "fnamecc", ")", "\n", "p_w", ",", "p_cIw", ",", "p_wc", "=", "compute_probs_from_counts", "(", "C", ")", "\n", "\n", "similarity_euclidean", "(", "p_wc", ",", "\"p_wc\"", ",", "v_dictionary", ",", "correlations", "=", "cb_corrs", ",", "y_data", "=", "cb_y_data", ")", "\n", "similarity_euclidean", "(", "p_cIw", ",", "\"p_cIw\"", ",", "v_dictionary", ",", "correlations", "=", "cb_corrs", ",", "y_data", "=", "cb_y_data", ")", "\n", "del", "p_wc", ",", "p_cIw", ",", "p_w", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "g_dict", ",", "g_vecs", "=", "load_pretrained_glove", "(", "\"wikigiga5\"", ")", "\n", "similarity_euclidean", "(", "g_vecs", "[", "\"u\"", "]", ",", "\"wikigiga5-u+v\"", ",", "g_dict", ",", "\n", "correlations", "=", "cb_corrs", ",", "y_data", "=", "cb_y_data", ",", "filter_dictionary", "=", "v_dictionary", ")", "\n", "\n", "# # COMMON CRAWL", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl42B\")", "\n", "# similarity_euclidean(g_vecs[\"u\"], \"commoncrawl42B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=v_dictionary)", "\n", "#", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl840B\")", "\n", "# keys_a = set(g_dict.keys())", "\n", "# keys_b = set(v_dictionary.keys())", "\n", "# intersection_keys = keys_a & keys_b", "\n", "# similarity_euclidean(g_vecs[\"u\"], \"commoncrawl840B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=intersection_keys)", "\n", "\n", "", "with", "open", "(", "json_name", ",", "'w'", ")", "as", "fstream", ":", "\n", "            ", "json", ".", "dump", "(", "[", "cb_corrs", ",", "cb_y_data", "]", ",", "fstream", ")", "\n", "\n", "", "merge", "(", "corrs", ",", "cb_corrs", ")", "\n", "merge", "(", "y_data", ",", "cb_y_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.calculate_or_load_common_base_preproc": [[1333, 1390], ["os.path.basename", "logmap_similarities_plot.merge", "logmap_similarities_plot.merge", "os.path.split", "open", "json.load", "core.load_embeddings.read_cooccurrences_from_c", "core.load_embeddings.compute_p_cIw_from_counts", "logmap_similarities_plot.similarity_euclidean_preproc", "gc.collect", "core.load_embeddings.load_pretrained_glove", "logmap_similarities_plot.similarity_euclidean_preproc", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.read_cooccurrences_from_c", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_p_cIw_from_counts", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean_preproc", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_pretrained_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean_preproc"], ["", "def", "calculate_or_load_common_base_preproc", "(", "fnamecc", ",", "v_dictionary", ",", "outdirname", ",", "corrs", ",", "y_data", ")", ":", "\n", "    ", "json_dir", "=", "os", ".", "path", ".", "split", "(", "outdirname", ")", "[", "0", "]", "\n", "_id", "=", "os", ".", "path", ".", "basename", "(", "fnamecc", ")", "\n", "json_name", "=", "json_dir", "+", "\"/\"", "+", "_id", "+", "\"-common_base_preproc.json\"", "\n", "\n", "try", ":", "\n", "        ", "with", "open", "(", "json_name", ",", "'r'", ")", "as", "fstream", ":", "\n", "            ", "cb_corrs", ",", "cb_y_data", "=", "json", ".", "load", "(", "fstream", ")", "\n", "\n", "", "", "except", ":", "\n", "\n", "        ", "cb_corrs", "=", "{", "}", "\n", "cb_y_data", "=", "{", "}", "\n", "\n", "C", "=", "read_cooccurrences_from_c", "(", "fnamecc", ")", "\n", "\n", "# p_w, p_wc = compute_p_wc_from_counts(C)", "\n", "#", "\n", "# times.append(time.time())", "\n", "#", "\n", "# corrs = {}", "\n", "# y_data = {}", "\n", "#", "\n", "# similarity_euclidean_preproc(p_wc, \"p_wc\", v_dictionary, correlations=corrs, y_data=y_data)", "\n", "#", "\n", "# times.append(time.time())", "\n", "#", "\n", "# del p_wc", "\n", "# gc.collect()", "\n", "\n", "p_w", ",", "p_cIw", "=", "compute_p_cIw_from_counts", "(", "C", ")", "\n", "\n", "similarity_euclidean_preproc", "(", "p_cIw", ",", "\"p_cIw\"", ",", "v_dictionary", ",", "correlations", "=", "cb_corrs", ",", "y_data", "=", "cb_y_data", ")", "\n", "del", "p_cIw", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "g_dict", ",", "g_vecs", "=", "load_pretrained_glove", "(", "\"wikigiga5\"", ")", "\n", "similarity_euclidean_preproc", "(", "g_vecs", "[", "\"u\"", "]", ",", "\"wikigiga5-u+v\"", ",", "g_dict", ",", "\n", "correlations", "=", "cb_corrs", ",", "y_data", "=", "cb_y_data", ",", "filter_dictionary", "=", "v_dictionary", ")", "\n", "\n", "# # COMMON CRAWL", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl42B\")", "\n", "# similarity_euclidean_preproc(g_vecs[\"u\"], \"commoncrawl42B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=v_dictionary)", "\n", "#", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl840B\")", "\n", "# keys_a = set(g_dict.keys())", "\n", "# keys_b = set(v_dictionary.keys())", "\n", "# intersection_keys = keys_a & keys_b", "\n", "# similarity_euclidean_preproc(g_vecs[\"u\"], \"commoncrawl840B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=intersection_keys)", "\n", "\n", "with", "open", "(", "json_name", ",", "'w'", ")", "as", "fstream", ":", "\n", "            ", "json", ".", "dump", "(", "[", "cb_corrs", ",", "cb_y_data", "]", ",", "fstream", ")", "\n", "\n", "", "", "merge", "(", "corrs", ",", "cb_corrs", ")", "\n", "merge", "(", "y_data", ",", "cb_y_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.base_similarities": [[1392, 1485], ["core.load_embeddings.get_suffix", "open", "json.load", "open", "json.load", "logmap_similarities_plot.calculate_or_load_common_base", "core.load_embeddings.load_glove", "logmap_similarities_plot.similarity_euclidean", "logmap_similarities_plot.similarity_euclidean", "logmap_similarities_plot.similarity_euclidean", "logmap_similarities_plot.similarity_double_cosprod", "logmap_similarities_plot.similarity_fisher_uv", "logmap_similarities_plot.print_table", "y_data.items", "print", "logmap_similarities_plot.calculate_or_load_common_base_preproc", "core.load_embeddings.load_glove", "logmap_similarities_plot.similarity_euclidean_preproc", "logmap_similarities_plot.similarity_euclidean_preproc", "logmap_similarities_plot.similarity_euclidean_preproc", "logmap_similarities_plot.similarity_double_cosprod", "logmap_similarities_plot.print_table", "y_data.items", "y_data.items", "logmap_similarities_plot.center_and_normalize_eucl", "logmap_similarities_plot.center_and_normalize_eucl", "y_data_ref_nop[].update", "open", "json.dump", "open", "json.dump", "json.load.get", "task_dict.items", "task_dict.items", "task_dict.items"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calculate_or_load_common_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_double_cosprod", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_fisher_uv", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.print_table", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.calculate_or_load_common_base_preproc", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean_preproc", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean_preproc", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_euclidean_preproc", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarity_double_cosprod", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.print_table", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "def", "base_similarities", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "fnamecc", ",", "v_dictionary", ",", "ref_keys_no_preproc", ",", "ref_keys_preproc", ",", "outdirname", ")", ":", "\n", "    ", "suffix", "=", "get_suffix", "(", "vecsize", ",", "nepoch", ")", "\n", "base_json_name", "=", "outdirname", "+", "\"/base_data_ref\"", "+", "suffix", "+", "\".json\"", "\n", "basep_json_name", "=", "outdirname", "+", "\"/base_preproc_data_ref\"", "+", "suffix", "+", "\".json\"", "\n", "\n", "try", ":", "\n", "        ", "with", "open", "(", "base_json_name", ",", "'r'", ")", "as", "fstream", ":", "\n", "            ", "y_data_ref_nop", "=", "json", ".", "load", "(", "fstream", ")", "\n", "\n", "", "with", "open", "(", "basep_json_name", ",", "'r'", ")", "as", "fstream", ":", "\n", "            ", "y_data_ref_p", "=", "json", ".", "load", "(", "fstream", ")", "\n", "\n", "", "", "except", ":", "\n", "\n", "        ", "corrs", "=", "{", "}", "\n", "y_data", "=", "{", "}", "\n", "calculate_or_load_common_base", "(", "fnamecc", ",", "v_dictionary", ",", "outdirname", ",", "corrs", ",", "y_data", ")", "\n", "\n", "g_dict", ",", "g_vecs", ",", "_", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ")", "\n", "similarity_euclidean", "(", "g_vecs", "[", "\"u\"", "]", ",", "corpus", "+", "\"-u\"", ",", "v_dictionary", ",", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "similarity_euclidean", "(", "g_vecs", "[", "\"v\"", "]", ",", "corpus", "+", "\"-v\"", ",", "v_dictionary", ",", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "similarity_euclidean", "(", "g_vecs", "[", "\"u\"", "]", "+", "g_vecs", "[", "\"v\"", "]", ",", "corpus", "+", "\"-u+v\"", ",", "v_dictionary", ",", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "similarity_double_cosprod", "(", "g_vecs", "[", "\"u\"", "]", ",", "g_vecs", "[", "\"v\"", "]", ",", "corpus", "+", "\"-uvDcos\"", ",", "v_dictionary", ",", "correlations", "=", "corrs", ",", "\n", "y_data", "=", "y_data", ")", "\n", "\n", "similarity_fisher_uv", "(", "g_vecs", "[", "\"u\"", "]", ",", "g_vecs", "[", "\"v\"", "]", ",", "corpus", ",", "v_dictionary", ",", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "# similarity_fisher_uv(g_vecs[\"u\"], project_away_1vec_component(g_vecs[\"v\"]), gmn+\"-o1\", v_dictionary, correlations=corrs, y_data=y_data)", "\n", "\n", "# similarity_almost_fisher_uv(g_vecs[\"u\"], g_vecs[\"v\"], gmn + \"-0-uv\", v_dictionary, correlations=corrs, y_data=y_data)", "\n", "# similarity_almost_fisher_uv(g_vecs[\"u\"], g_vecs[\"v\"], gmn + \"-u-uv\", v_dictionary,", "\n", "#                      correlations=corrs, y_data=y_data, p0=p_w)", "\n", "\n", "print_table", "(", "corrs", ",", "outdirname", "+", "\"/base\"", "+", "suffix", "+", "\".txt\"", ")", "\n", "\n", "# corrs_ref = {k:v for k, v in corrs.items() if k in ref_keys_no_preproc}", "\n", "y_data_ref_nop", "=", "{", "}", "\n", "for", "task_key", ",", "task_dict", "in", "y_data", ".", "items", "(", ")", ":", "\n", "            ", "task_ref_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "task_dict", ".", "items", "(", ")", "if", "k", "in", "ref_keys_no_preproc", "}", "\n", "y_data_ref_nop", "[", "task_key", "]", "=", "task_ref_dict", "\n", "\n", "\n", "", "print", "(", "\"I start with preprocessing\"", ")", "\n", "\n", "# PREPROCESSING", "\n", "\n", "# center and normalize columns of p_wc and p_cIw before cosprod", "\n", "# center and normalize columns of U and V before cosprod", "\n", "\n", "# center and normalize columns of counts before computing p_cIw, then logmap", "\n", "# center and normalize columns of U and V before computing p, then logmap", "\n", "\n", "\n", "calculate_or_load_common_base_preproc", "(", "fnamecc", ",", "v_dictionary", ",", "outdirname", ",", "corrs", ",", "y_data", ")", "\n", "\n", "\n", "g_dict", ",", "g_vecs", ",", "_", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ")", "\n", "\n", "similarity_euclidean_preproc", "(", "g_vecs", "[", "\"u\"", "]", ",", "corpus", "+", "\"-u\"", ",", "v_dictionary", ",", "\n", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "\n", "similarity_euclidean_preproc", "(", "g_vecs", "[", "\"v\"", "]", ",", "corpus", "+", "\"-v\"", ",", "v_dictionary", ",", "\n", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "\n", "similarity_euclidean_preproc", "(", "g_vecs", "[", "\"u\"", "]", "+", "g_vecs", "[", "\"v\"", "]", ",", "corpus", "+", "\"-u+v\"", ",", "\n", "v_dictionary", ",", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "\n", "similarity_double_cosprod", "(", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"u\"", "]", ",", "True", ",", "False", ",", "0", ")", ",", "\n", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"v\"", "]", ",", "True", ",", "False", ",", "0", ")", ",", "corpus", "+", "\"-uvDcos-cn\"", ",", "\n", "v_dictionary", ",", "correlations", "=", "corrs", ",", "y_data", "=", "y_data", ")", "\n", "\n", "print_table", "(", "corrs", ",", "outdirname", "+", "\"/base-preproc\"", "+", "suffix", "+", "\".txt\"", ")", "\n", "\n", "# corrs_ref = {k:v for k, v in corrs.items() if k in ref_keys_preproc}", "\n", "y_data_ref_p", "=", "{", "}", "\n", "for", "task_key", ",", "task_dict", "in", "y_data", ".", "items", "(", ")", ":", "\n", "            ", "task_ref_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "task_dict", ".", "items", "(", ")", "if", "k", "in", "ref_keys_preproc", "}", "\n", "y_data_ref_p", "[", "task_key", "]", "=", "task_ref_dict", "\n", "\n", "", "for", "task_key", ",", "task_dict", "in", "y_data", ".", "items", "(", ")", ":", "\n", "            ", "task_ref_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "task_dict", ".", "items", "(", ")", "if", "k", "in", "ref_keys_no_preproc", "}", "\n", "\n", "if", "y_data_ref_nop", ".", "get", "(", "task_key", ",", "None", ")", "is", "None", ":", "\n", "                ", "y_data_ref_nop", "[", "task_key", "]", "=", "{", "}", "\n", "", "y_data_ref_nop", "[", "task_key", "]", ".", "update", "(", "task_ref_dict", ")", "\n", "\n", "", "with", "open", "(", "base_json_name", ",", "'w'", ")", "as", "fstream", ":", "\n", "            ", "json", ".", "dump", "(", "y_data_ref_nop", ",", "fstream", ")", "\n", "\n", "", "with", "open", "(", "basep_json_name", ",", "'w'", ")", "as", "fstream", ":", "\n", "            ", "json", ".", "dump", "(", "y_data_ref_p", ",", "fstream", ")", "\n", "\n", "\n", "", "", "return", "y_data_ref_nop", ",", "y_data_ref_p", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_u_scale": [[1488, 1502], ["core.load_embeddings.calculate_glove_prob", "logmap_similarities_plot.similarities_logmaps_Esubmodel_trick", "logmap_similarities_plot.print_table", "logmap_similarities_plot.merge", "logmap_similarities_plot.plot_all_tasks", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.calculate_glove_prob", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_logmaps_Esubmodel_trick", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.print_table", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.plot_all_tasks"], ["", "def", "similarities_u_scale", "(", "U", ",", "V", ",", "scale", ",", "alphas", ",", "gname", ",", "v_dictionary", ",", "outdirname", ",", "y_data_ref", ")", ":", "\n", "    ", "corrs", "=", "{", "}", "\n", "y_data", "=", "{", "}", "\n", "U_mult", "=", "scale", "*", "U", "\n", "V_mult", "=", "V", "\n", "g_p_w", ",", "g_p_cIw", "=", "calculate_glove_prob", "(", "U_mult", ",", "V_mult", ")", "\n", "\n", "similarities_logmaps_Esubmodel_trick", "(", "g_p_cIw", ",", "U_mult", ",", "V_mult", ",", "\"p_cIw-m-E\"", ",", "g_p_w", ",", "alphas", ",", "v_dictionary", ",", "corrs", ",", "y_data", ",", "method", "=", "\"cos\"", ")", "\n", "# similarities_logmaps_Esubmodel(g_p_cIw, U, project_away_1vec_component(V), \"p_cIw-o1\", g_p_w, alphas,", "\n", "#                                v_dictionary, corrs, y_data)", "\n", "output", "=", "outdirname", "+", "\"/logmaps-p_\"", "+", "gname", "+", "\"-Esubmodel-cos-uscale%s\"", "%", "str", "(", "scale", ")", "\n", "print_table", "(", "corrs", ",", "output", "+", "\".txt\"", ")", "\n", "merge", "(", "y_data", ",", "y_data_ref", ")", "\n", "plot_all_tasks", "(", "alphas", ",", "y_data", ",", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.all_log_similarities": [[1505, 1554], ["core.load_embeddings.load_glove", "core.load_embeddings.get_suffix", "logmap_similarities_plot.similarities_u_scale"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_u_scale"], ["", "def", "all_log_similarities", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "alphas", ",", "v_dictionary", ",", "outdirname", ",", "y_data_ref", "=", "{", "}", ")", ":", "\n", "# # FULL SIMPLEX FROM DATA COMMENT", "\n", "# C = read_cooccurrences_from_c(fnamecc)", "\n", "# p_w, p_cIw, p_wc = compute_probs_from_counts(C)", "\n", "#", "\n", "# # corrs = {}", "\n", "# # y_data = {}", "\n", "# # similarities_divergences(p_cIw, \"p_cIw\", alphas, corrs, y_data)", "\n", "# # print_table(corrs, \"divergence-p_data.txt\")", "\n", "# # plot_all_tasks(alphas, y_data, \"divergence-p_data\")", "\n", "#", "\n", "# corrs = {}", "\n", "# y_data = {}", "\n", "#", "\n", "# similarities_logmaps_fullrank(p_cIw, \"p_cIw-d-P\", p_w, alphas, v_dictionary, corrs, y_data)", "\n", "# print_table(corrs, \"logmaps-p_data.txt\")", "\n", "# merge(y_data, y_data_ref)", "\n", "# plot_all_tasks(alphas, y_data, \"logmaps-p_data\")", "\n", "#", "\n", "# del C, p_wc, p_cIw, p_w", "\n", "# gc.collect()", "\n", "# # FULL SIMPLEX FROM DATA COMMENT", "\n", "\n", "    ", "gname", "=", "corpus", "+", "get_suffix", "(", "vecsize", ",", "nepoch", ")", "\n", "g_dict", ",", "g_vecs", ",", "g_tuple", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ")", "\n", "# g_p_w, g_p_cIw = g_tuple", "\n", "U", "=", "g_vecs", "[", "\"u\"", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "V", "=", "g_vecs", "[", "\"v\"", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "# #MODEL FULL RANK COMMENT", "\n", "# corrs = {}", "\n", "# y_data = {}", "\n", "# similarities_logmaps_fullrank(g_p_cIw, \"p_cIw-m-P\", g_p_w, alphas, v_dictionary, corrs, y_data)", "\n", "# print_table(corrs, \"logmaps-p_\" + gmn + \"-full.txt\")", "\n", "# merge(y_data, y_data_ref)", "\n", "# plot_all_tasks(alphas, y_data, \"logmaps-p_\" + gmn + \"-full\")", "\n", "# #MODEL FULL RANK COMMENT", "\n", "\n", "# corrs = {}", "\n", "# y_data = {}", "\n", "# similarities_logmaps_Esubmodel(g_p_cIw, U, V, \"p_cIw-m-E\", g_p_w, alphas, v_dictionary, corrs, y_data, method=\"cos\")", "\n", "# # similarities_logmaps_Esubmodel(g_p_cIw, U, project_away_1vec_component(V), \"p_cIw-o1\", g_p_w, alphas,", "\n", "# #                                v_dictionary, corrs, y_data)", "\n", "# print_table(corrs, \"logmaps-p_\" + gmn + \"-Esubmodel-cos.txt\")", "\n", "# merge(y_data, y_data_ref)", "\n", "# plot_all_tasks(alphas, y_data, \"logmaps-p_\" + gmn + \"-Esubmodel-cos\")", "\n", "\n", "for", "scale", "in", "[", "1", "]", ":", "#[0.5, 1]:", "\n", "        ", "similarities_u_scale", "(", "U", ",", "V", ",", "scale", ",", "alphas", ",", "gname", ",", "v_dictionary", ",", "outdirname", ",", "y_data_ref", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_u_preproc": [[1566, 1581], ["numpy.mean", "core.load_embeddings.calculate_glove_prob", "logmap_similarities_plot.similarities_logmaps_Esubmodel", "logmap_similarities_plot.print_table", "logmap_similarities_plot.merge", "logmap_similarities_plot.plot_all_tasks", "numpy.linalg.norm", "logmap_similarities_plot.center_and_normalize_eucl", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.calculate_glove_prob", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_logmaps_Esubmodel", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.print_table", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.plot_all_tasks", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "", "def", "similarities_u_preproc", "(", "U", ",", "V", ",", "scale", ",", "alphas", ",", "gname", ",", "v_dictionary", ",", "outdirname", ",", "y_data_ref", ")", ":", "\n", "    ", "corrs", "=", "{", "}", "\n", "y_data", "=", "{", "}", "\n", "scale0", "=", "np", ".", "mean", "(", "np", ".", "linalg", ".", "norm", "(", "U", ",", "axis", "=", "0", ")", ")", "\n", "U_preproc", "=", "scale", "*", "scale0", "*", "center_and_normalize_eucl", "(", "U", ",", "True", ",", "False", ",", "0", ",", "normalize", "=", "True", ")", "\n", "V_preproc", "=", "V", "\n", "# np.testing.assert_array_equal(U, g_vecs[\"u\"][:-1, :])", "\n", "g_p_w", ",", "g_p_cIw", "=", "calculate_glove_prob", "(", "U_preproc", ",", "V_preproc", ")", "\n", "similarities_logmaps_Esubmodel", "(", "g_p_cIw", ",", "U_preproc", ",", "V_preproc", ",", "\"p_cIw-ucn-m-E\"", ",", "g_p_w", ",", "alphas", ",", "\n", "v_dictionary", ",", "corrs", ",", "y_data", ",", "method", "=", "\"cos\"", ")", "\n", "\n", "output", "=", "outdirname", "+", "\"/logmaps-p_\"", "+", "gname", "+", "\"-Esubmodel-preproc-u-n%.2f-scale%s\"", "%", "(", "scale0", ",", "str", "(", "scale", ")", ")", "\n", "print_table", "(", "corrs", ",", "output", "+", "\".txt\"", ")", "\n", "merge", "(", "y_data", ",", "y_data_ref", ")", "\n", "plot_all_tasks", "(", "alphas", ",", "y_data", ",", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.all_log_similarities_preproc": [[1593, 1661], ["core.load_embeddings.load_glove", "core.load_embeddings.get_suffix", "logmap_similarities_plot.similarities_u_preproc"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.similarities_u_preproc"], ["", "def", "all_log_similarities_preproc", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "alphas", ",", "v_dictionary", ",", "outdirname", ",", "y_data_ref", "=", "{", "}", ")", ":", "\n", "# ##COMMENTED", "\n", "# C = read_cooccurrences_from_c(fnamecc)", "\n", "#", "\n", "# corrs = {}", "\n", "# y_data = {}", "\n", "#", "\n", "# C = C / C.sum(axis=0).reshape(1,-1)", "\n", "# p_w, p_cIw = compute_p_cIw_from_counts(C)", "\n", "# similarities_logmaps_fullrank(p_cIw, \"p_cIw-Cds-d-P\", p_w, alphas, v_dictionary, corrs, y_data)", "\n", "#", "\n", "# del C, p_w, p_cIw", "\n", "# gc.collect()", "\n", "#", "\n", "# # C = read_cooccurrences_from_c(fnamecc)", "\n", "# # C = C / np.sqrt(np.sum(C ** 2, axis=0)).reshape(1, -1)", "\n", "# # C = C / np.linalg.norm(C, axis=0).reshape(1, -1)", "\n", "# # p_w, p_cIw = compute_p_cIw_from_counts(C)", "\n", "# # similarities_logmaps_fullrank(p_cIw, \"p_cIw-Cn\", p_w, alphas, v_dictionary, corrs, y_data)", "\n", "# # del p_cIw, C, p_w", "\n", "# # gc.collect()", "\n", "#", "\n", "# # C_proc = C / np.amax(C, axis=0)", "\n", "# # N, p_w, p_cIw, p_wc = compute_probs_from_counts(C_proc)", "\n", "# # similarities_logmaps_fullrank(p_cIw, \"p_cIw-dm\", alphas, corrs, y_data)", "\n", "# # similarities_logmaps_fullrank(p_wc, \"p_wc-dm\", alphas, corrs, y_data)", "\n", "#", "\n", "# print_table(corrs, \"logmaps-p_data-preproc.txt\")", "\n", "# merge(y_data, y_data_ref)", "\n", "# plot_all_tasks(alphas, y_data, \"logmaps-p_data-preproc\")", "\n", "\n", "    ", "gname", "=", "corpus", "+", "get_suffix", "(", "vecsize", ",", "nepoch", ")", "\n", "g_dict", ",", "g_vecs", ",", "g_tuple", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ")", "\n", "\n", "U", "=", "g_vecs", "[", "\"u\"", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "V", "=", "g_vecs", "[", "\"v\"", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "# OLD PREPROC on the model", "\n", "# g_p_w, g_p_cIw = calculate_glove_prob(", "\n", "#             center_and_normalize_eucl(g_vecs[\"u\"], True, False, 0, normalize=False),", "\n", "#             center_and_normalize_eucl(g_vecs[\"v\"], True, False, 0, normalize=False))", "\n", "#", "\n", "# # p_w = g_prob.sum(axis=1)", "\n", "# similarities_logmaps_fullrank(g_p_cIw, \"p_cIw-uvc\", g_p_w, alphas, v_dictionary, corrs, y_data)", "\n", "#", "\n", "# # except:", "\n", "# #     pdb.set_trace()", "\n", "#", "\n", "# g_p_w, g_p_cIw = calculate_glove_prob(", "\n", "#                     g_vecs[\"u\"],", "\n", "#                     center_and_normalize_eucl(g_vecs[\"v\"], True, False, 0, normalize=False))", "\n", "#", "\n", "# similarities_logmaps_fullrank(g_p_cIw, \"p_cIw-vc\", g_p_w, alphas, v_dictionary, corrs, y_data)", "\n", "#", "\n", "# g_p_w, g_p_cIw = calculate_glove_prob(g_vecs[\"u\"], g_vecs[\"v\"], norm_counts_cols = True)", "\n", "# similarities_logmaps_fullrank(g_p_cIw, \"p_cIw-Cn\", g_p_w, alphas, v_dictionary, corrs, y_data)", "\n", "#", "\n", "# xi = np.matmul(g_vecs[\"u\"], np.transpose(g_vecs[\"v\"]))", "\n", "# similarity_euclidean(xi, \"xi\", v_dictionary, corrs, y_data)", "\n", "# OLD PREPROC on the model", "\n", "\n", "# you can check this projection does not change the distribution \"much\" np.allclose", "\n", "# g_p_w, g_p_cIw = calculate_glove_prob(g_vecs[\"u\"], g_vecs[\"v\"])", "\n", "# g_p_w, g_p_cIw = calculate_glove_prob(g_vecs[\"u\"], project_away_1vec_component(g_vecs[\"v\"]))", "\n", "\n", "#U PREPROC", "\n", "for", "scale", "in", "[", "10", "]", ":", "\n", "        ", "similarities_u_preproc", "(", "U", ",", "V", ",", "scale", ",", "alphas", ",", "gname", ",", "v_dictionary", ",", "outdirname", ",", "y_data_ref", ")", "\n", "#U PREPROC", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.test_sparse_matrices": [[1713, 1746], ["times.append", "scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "times.append", "times.append", "scipy.sparse.csc_matrix.mean", "times.append", "scipy.sparse.csc_matrix.mean", "times.append", "times.append", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix", "times.append", "times.append", "scipy.sparse.csr_matrix.mean", "times.append", "scipy.sparse.csr_matrix.mean", "times.append", "print", "print", "print", "print", "print", "time.time", "time.time", "scipy.sparse.csc_matrix.sum().reshape", "time.time", "time.time", "time.time", "numpy.array", "numpy.array", "time.time", "time.time", "scipy.sparse.csr_matrix.sum().reshape", "time.time", "time.time", "time.time", "numpy.array", "numpy.array", "numpy.allclose", "numpy.allclose", "numpy.allclose", "scipy.sparse.csc_matrix.sum", "scipy.sparse.csr_matrix.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "", "def", "test_sparse_matrices", "(", "C", ")", ":", "\n", "    ", "import", "time", "\n", "\n", "times", "=", "[", "]", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csc", "=", "scipy", ".", "sparse", ".", "csc_matrix", "(", "C", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C1_csc", "=", "C_csc", "/", "C_csc", ".", "sum", "(", "axis", "=", "0", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C2_csc", "=", "C_csc", ".", "mean", "(", "axis", "=", "0", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C3_csc", "=", "C_csc", ".", "mean", "(", "axis", "=", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "deltas_csc", "=", "np", ".", "array", "(", "times", "[", "1", ":", "]", ")", "-", "np", ".", "array", "(", "times", "[", ":", "-", "1", "]", ")", "\n", "\n", "times", "=", "[", "]", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csr", "=", "scipy", ".", "sparse", ".", "csr_matrix", "(", "C", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C1_csr", "=", "C_csr", "/", "C_csr", ".", "sum", "(", "axis", "=", "0", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C2_csr", "=", "C_csr", ".", "mean", "(", "axis", "=", "0", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C3_csr", "=", "C_csr", ".", "mean", "(", "axis", "=", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "deltas_csr", "=", "np", ".", "array", "(", "times", "[", "1", ":", "]", ")", "-", "np", ".", "array", "(", "times", "[", ":", "-", "1", "]", ")", "\n", "\n", "print", "(", "\"csr:\"", ",", "deltas_csr", ")", "\n", "print", "(", "\"csc:\"", ",", "deltas_csc", ")", "\n", "\n", "print", "(", "np", ".", "allclose", "(", "C1_csr", ",", "C1_csc", ")", ")", "\n", "print", "(", "np", ".", "allclose", "(", "C2_csr", ",", "C2_csc", ")", ")", "\n", "print", "(", "np", ".", "allclose", "(", "C3_csr", ",", "C3_csc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.test_huge_sparse_matrices": [[1747, 1782], ["times.append", "scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "times.append", "times.append", "scipy.sparse.csc_matrix.mean", "times.append", "scipy.sparse.csc_matrix.mean", "times.append", "gc.collect", "times.append", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix", "times.append", "times.append", "scipy.sparse.csr_matrix.mean", "times.append", "scipy.sparse.csr_matrix.mean", "times.append", "gc.collect", "print", "print", "time.time", "time.time", "scipy.sparse.csc_matrix.sum().reshape", "time.time", "time.time", "time.time", "numpy.array", "numpy.array", "time.time", "time.time", "scipy.sparse.csr_matrix.sum().reshape", "time.time", "time.time", "time.time", "numpy.array", "numpy.array", "scipy.sparse.csc_matrix.sum", "scipy.sparse.csr_matrix.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "test_huge_sparse_matrices", "(", "C", ")", ":", "\n", "    ", "import", "time", "\n", "\n", "times", "=", "[", "]", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csc", "=", "scipy", ".", "sparse", ".", "csc_matrix", "(", "C", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csc", "/", "C_csc", ".", "sum", "(", "axis", "=", "0", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csc", ".", "mean", "(", "axis", "=", "0", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csc", ".", "mean", "(", "axis", "=", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "deltas_csc", "=", "np", ".", "array", "(", "times", "[", "1", ":", "]", ")", "-", "np", ".", "array", "(", "times", "[", ":", "-", "1", "]", ")", "\n", "\n", "del", "C_csc", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "times", "=", "[", "]", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csr", "=", "scipy", ".", "sparse", ".", "csr_matrix", "(", "C", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csr", "/", "C_csr", ".", "sum", "(", "axis", "=", "0", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csr", ".", "mean", "(", "axis", "=", "0", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "C_csr", ".", "mean", "(", "axis", "=", "1", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "deltas_csr", "=", "np", ".", "array", "(", "times", "[", "1", ":", "]", ")", "-", "np", ".", "array", "(", "times", "[", ":", "-", "1", "]", ")", "\n", "\n", "del", "C_csr", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "print", "(", "\"csr:\"", ",", "deltas_csr", ")", "\n", "print", "(", "\"csc:\"", ",", "deltas_csc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.plot_isotropicity": [[1784, 1818], ["matplotlib.legend", "matplotlib.savefig", "core.load_embeddings.load_glove", "numpy.transpose", "scipy.sparse.linalg.eigsh", "scipy.sparse.linalg.eigsh", "scipy.sparse.linalg.eigsh", "numpy.transpose", "scipy.sparse.linalg.eigsh", "scipy.sparse.linalg.eigsh", "scipy.sparse.linalg.eigsh", "numpy.transpose", "scipy.sparse.linalg.eigsh", "scipy.sparse.linalg.eigsh", "scipy.sparse.linalg.eigsh", "numpy.array", "print", "print", "matplotlib.plot", "numpy.matmul", "logmap_similarities_plot.center_and_normalize_eucl", "numpy.matmul", "logmap_similarities_plot.center_and_normalize_eucl", "numpy.matmul", "sorted"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "def", "plot_isotropicity", "(", "glove_models_names", ",", "outdirname", ")", ":", "\n", "# isotropicity of v vectors", "\n", "    ", "all_eigs", "=", "{", "}", "\n", "for", "gmn", "in", "glove_models_names", ":", "\n", "        ", "_", ",", "g_vecs", ",", "_", "=", "load_glove", "(", "gmn", ",", "calc_prob", "=", "False", ")", "\n", "X", "=", "np", ".", "transpose", "(", "g_vecs", "[", "\"v\"", "]", "[", ":", "-", "1", ",", ":", "]", ")", "\n", "D", "=", "X", ".", "shape", "[", "1", "]", "\n", "Cov", "=", "np", ".", "matmul", "(", "X", ",", "X", ".", "T", ")", "/", "(", "D", "-", "1", ")", "\n", "eigs", ",", "V", "=", "scipy", ".", "sparse", ".", "linalg", ".", "eigsh", "(", "Cov", ")", "\n", "all_eigs", "[", "gmn", "]", "=", "eigs", "\n", "\n", "X", "=", "np", ".", "transpose", "(", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"v\"", "]", "[", ":", "-", "1", ",", ":", "]", ",", "True", ",", "False", ",", "0", ")", ")", "\n", "# X = X - X.mean(axis=1).reshape(-1,1)", "\n", "# X = X / np.linalg.norm(X, axis=1).reshape(-1,1)", "\n", "Cov", "=", "np", ".", "matmul", "(", "X", ",", "X", ".", "T", ")", "/", "(", "D", "-", "1", ")", "\n", "eigs", ",", "V", "=", "scipy", ".", "sparse", ".", "linalg", ".", "eigsh", "(", "Cov", ")", "\n", "all_eigs", "[", "gmn", "+", "\"-cn\"", "]", "=", "eigs", "\n", "\n", "X", "=", "np", ".", "transpose", "(", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"v\"", "]", "[", ":", "-", "1", ",", ":", "]", ",", "False", ",", "False", ",", "0", ")", ")", "\n", "# X = X - X.mean(axis=1).reshape(-1,1)", "\n", "# X = X / np.linalg.norm(X, axis=1).reshape(-1,1)", "\n", "Cov", "=", "np", ".", "matmul", "(", "X", ",", "X", ".", "T", ")", "/", "(", "D", "-", "1", ")", "\n", "eigs", ",", "V", "=", "scipy", ".", "sparse", ".", "linalg", ".", "eigsh", "(", "Cov", ")", "\n", "all_eigs", "[", "gmn", "+", "\"-c\"", "]", "=", "eigs", "\n", "\n", "", "for", "gmn", "in", "all_eigs", ":", "\n", "        ", "eigs", "=", "np", ".", "array", "(", "sorted", "(", "all_eigs", "[", "gmn", "]", ",", "reverse", "=", "True", ")", ")", "\n", "print", "(", "gmn", ")", "\n", "print", "(", "eigs", ")", "\n", "eigs", "=", "eigs", "[", "1", ":", "]", "\n", "plt", ".", "plot", "(", "eigs", "/", "eigs", "[", "0", "]", ",", "label", "=", "gmn", ")", "\n", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "outdirname", "+", "\"/isotropy_v.png\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.make_all_sims": [[1820, 1871], ["core.load_embeddings.get_suffix", "os.path.join", "os.makedirs", "g_reader.read_dictionary", "logmap_similarities_plot.base_similarities", "logmap_similarities_plot.all_log_similarities", "open", "json.dump", "ValueError", "list"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_dictionary", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.base_similarities", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.all_log_similarities"], ["", "def", "make_all_sims", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "alphas", ",", "baseoutdir", ",", "exp_name_for_dir", ")", ":", "\n", "\n", "    ", "suffix", "=", "get_suffix", "(", "vecsize", ",", "nepoch", ")", "\n", "\n", "outdirname", "=", "os", ".", "path", ".", "join", "(", "baseoutdir", ",", "corpus", "+", "exp_name_for_dir", "+", "\"/\"", "+", "corpus", "+", "suffix", ")", "\n", "\n", "os", ".", "makedirs", "(", "outdirname", ",", "exist_ok", "=", "True", ")", "\n", "\n", "dsdir", "=", "'/ssd_data/text/cooccurrences/'", "\n", "# simplewiki_sw6_fnamecc = dsdir + 'simplewiki201711/simplewiki201711-sw6-cooccurrence.bin'", "\n", "simplewiki_sw10_fnamecc", "=", "dsdir", "+", "'simplewiki201711/simplewiki201711-sw10-cooccurrence.bin'", "\n", "simplewiki_fnamevc", "=", "dsdir", "+", "'simplewiki201711/simplewiki201711-vocab.txt'", "\n", "\n", "enwiki_sw10_fnamecc", "=", "dsdir", "+", "'enwiki201710/enwiki201710-sw10-cooccurrence.bin'", "\n", "enwiki_fnamevc", "=", "dsdir", "+", "'enwiki201710/enwiki201710-vocab.txt'", "\n", "\n", "# select which vocabulary and cooccurrence file to use", "\n", "if", "corpus", "==", "\"enwiki\"", ":", "\n", "        ", "fnamevc", "=", "enwiki_fnamevc", "\n", "fnamecc", "=", "enwiki_sw10_fnamecc", "\n", "ref_keys_no_preproc", "=", "[", "\"enwiki-u+v-n-cosprod\"", ",", "\"enwiki-u-cosprod\"", ",", "\"wikigiga5-u+v-n-cosprod\"", ",", "\n", "\"p_cIw-cn-cosprod\"", "]", "\n", "ref_keys_preproc", "=", "[", "\"enwiki-u+v-n-cosprod\"", ",", "\"enwiki-u-n-cosprod\"", ",", "\"wikigiga5-u+v-n-cosprod\"", ",", "\"p_cIw-cn-cosprod\"", "]", "#, \"wikigiga5-u+v-c-cosprod\"]", "\n", "\n", "", "elif", "corpus", "==", "\"swiki\"", ":", "\n", "        ", "fnamevc", "=", "simplewiki_fnamevc", "\n", "fnamecc", "=", "simplewiki_sw10_fnamecc", "\n", "# glove_models_names = [\"swiki-500\", \"swiki-1000\"]", "\n", "# glove_models_names = [\"swiki-1000\"]", "\n", "ref_keys_no_preproc", "=", "[", "\"swiki-u+v-n-cosprod\"", ",", "\"swiki-u-cosprod\"", ",", "\"wikigiga5-u+v-n-cosprod\"", ",", "\"p_cIw-cn-cosprod\"", "]", "# , \"wikigiga5-u+v-c-cosprod\"]", "\n", "ref_keys_preproc", "=", "[", "\"swiki-u+v-n-cosprod\"", ",", "\"swiki-u-n-cosprod\"", ",", "\"wikigiga5-u+v-n-cosprod\"", ",", "\"p_cIw-cn-cosprod\"", "]", "#, \"wikigiga5-u+v-c-cosprod\"]", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"corpus not recognized `%s`\"", "%", "corpus", ")", "\n", "\n", "# w2v_reader = readers.get_reader(\"word2vec\")", "\n", "\n", "", "(", "dictionary_size", ",", "v_dictionary", ",", "v_reversed_dictionary", ")", "=", "g_reader", ".", "read_dictionary", "(", "fnamevc", ")", "\n", "\n", "# plot_isotropicity()", "\n", "\n", "# C = read_cooccurrences_from_c(fnamecc)", "\n", "# test_sparse_matrices(C)", "\n", "# sys.exit(0)", "\n", "with", "open", "(", "outdirname", "+", "\"/alphas.json\"", ",", "'w'", ")", "as", "fstream", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"alphas\"", ":", "list", "(", "alphas", ")", "}", ",", "fstream", ")", "\n", "\n", "", "y_data_ref_nop", ",", "y_data_ref_p", "=", "base_similarities", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "fnamecc", ",", "v_dictionary", ",", "\n", "ref_keys_no_preproc", ",", "ref_keys_preproc", ",", "outdirname", ")", "\n", "# y_data_ref={}", "\n", "all_log_similarities", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "alphas", ",", "v_dictionary", ",", "outdirname", ",", "y_data_ref", "=", "y_data_ref_nop", ")", "\n", "# all_log_similarities_preproc(corpus, vecsize, nepoch, alphas, v_dictionary, outdirname, y_data_ref=y_data_ref_p)", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_ref_vecsize": [[45, 51], ["None"], "function", ["None"], ["def", "get_ref_vecsize", "(", "name", ",", "kwargs", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "vecsize", "=", "kwargs", "[", "\"vecsize\"", "]", "\n", "", "except", ":", "\n", "        ", "vecsize", "=", "info_pretrained", "[", "name", "]", "[", "1", "]", "\n", "", "return", "vecsize", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_ref_name": [[52, 59], ["None"], "function", ["None"], ["", "def", "get_ref_name", "(", "name", ",", "kwargs", ")", ":", "\n", "    ", "if", "name", "in", "info_pretrained", ":", "\n", "        ", "return", "name", "\n", "\n", "", "return", "\"{:}-{:}-v{:}-n{:}-sw{:}-ns{:}\"", ".", "format", "(", "name", ",", "kwargs", "[", "\"corpus\"", "]", ",", "\n", "kwargs", "[", "\"vecsize\"", "]", ",", "kwargs", "[", "\"nepoch\"", "]", ",", "\n", "kwargs", "[", "\"sw\"", "]", ",", "kwargs", "[", "\"ns\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_ref_theta_name": [[60, 73], ["thname.split", "len"], "function", ["None"], ["", "def", "get_ref_theta_name", "(", "name", ",", "thname", ")", ":", "\n", "\n", "    ", "if", "name", "in", "info_pretrained", ":", "\n", "        ", "tns", "=", "thname", ".", "split", "(", "\"_\"", ")", "\n", "if", "len", "(", "tns", ")", "==", "1", ":", "\n", "            ", "newthname", "=", "\"\"", "\n", "", "else", ":", "\n", "            ", "newthname", "=", "tns", "[", "1", "]", "\n", "\n", "", "return", "newthname", "\n", "\n", "", "else", ":", "\n", "        ", "return", "thname", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.basic_silh_dist": [[86, 88], ["functools.partial"], "function", ["None"], ["def", "basic_silh_dist", "(", "thname", ",", "g_matrix", ")", ":", "\n", "    ", "return", "partial", "(", "riemannian_dist", ",", "g_matrix", "=", "g_matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.create_clustering_methods": [[89, 100], ["word_embedding.test.core.clustering.KMeansSim.KMeansSim", "functools.partial", "word_embedding.test.core.clustering.RepeatedBisectionSim.RepeatedBisectionSim", "functools.partial", "spherecluster.SphericalKMeans", "functools.partial", "sklearn.cluster.KMeans", "functools.partial", "sklearn.linear_model.LogisticRegression", "functools.partial"], "function", ["None"], ["", "def", "create_clustering_methods", "(", "ngroups", ",", "g_matrix", ",", "n_init", ")", ":", "\n", "    ", "clustering_methods", "=", "{", "\n", "\"kmsim\"", ":", "(", "KMeansSim", "(", "n_clusters", "=", "ngroups", ",", "g_matrix", "=", "g_matrix", ",", "n_init", "=", "n_init", ")", ",", "partial", "(", "dist_on_sphere", ",", "g_matrix", "=", "g_matrix", ")", ")", ",", "\n", "\"krbsim\"", ":", "(", "RepeatedBisectionSim", "(", "n_clusters", "=", "ngroups", ",", "g_matrix", "=", "g_matrix", ",", "n_init", "=", "n_init", ",", "bm", "=", "'agg'", ")", ",", "partial", "(", "dist_on_sphere", ",", "g_matrix", "=", "g_matrix", ")", ")", ",", "\n", "\"skm\"", ":", "(", "SphericalKMeans", "(", "n_clusters", "=", "ngroups", ",", "n_init", "=", "n_init", ")", ",", "partial", "(", "dist_on_sphere", ",", "g_matrix", "=", "g_matrix", ")", ")", ",", "\n", "# \"vmfs\" : (VonMisesFisherMixture(n_clusters=ngroups, n_init=n_init, posterior_type='soft'), partial(dist_on_sphere, g_matrix=g_matrix)),", "\n", "# \"vmfh\" : (VonMisesFisherMixture(n_clusters=ngroups, n_init=n_init, posterior_type='hard'), partial(dist_on_sphere, g_matrix=g_matrix)),", "\n", "\"km\"", ":", "(", "KMeans", "(", "n_clusters", "=", "ngroups", ",", "n_init", "=", "n_init", ")", ",", "partial", "(", "dist_on_sphere", ",", "g_matrix", "=", "g_matrix", ")", ")", ",", "\n", "\"lgr\"", ":", "(", "sklearn", ".", "linear_model", ".", "LogisticRegression", "(", "random_state", "=", "0", ",", "solver", "=", "'lbfgs'", ",", "multi_class", "=", "'multinomial'", ",", "max_iter", "=", "500", ")", ",", "partial", "(", "dist_on_sphere", ",", "g_matrix", "=", "g_matrix", ")", ")", ",", "\n", "}", "\n", "return", "clustering_methods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.cluster_references": [[109, 160], ["word_embedding.test.core.clustering.logging.CustomDefaultDict", "word_embedding.test.core.clustering.logging.CustomDefaultDict", "references.items", "os.path.splitext", "functools.partial", "functools.partial", "os.path.basename", "isinstance", "clustering.get_ref_name", "clustering.get_ref_vecsize", "numpy.eye", "refloader", "word_embedding.test.core.clustering.utils.load_csv_into_dict", "len", "clustering.create_clustering_methods", "clustering.prepare_clusters", "tqdm.tqdm", "prepare_clusters.items", "clustering.get_ref_theta_name", "baselog.try_read_csv", "create_clustering_methods.items", "word_embedding.test.core.clustering.utils.silhouette", "baselog.log", "logger.try_read_csv", "clustering.basic_silh_dist", "word_embedding.test.core.clustering.utils.do_clustering", "logger.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_ref_name", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_ref_vecsize", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.load_csv_into_dict", "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.create_clustering_methods", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.prepare_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_ref_theta_name", "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.try_read_csv", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.silhouette", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.try_read_csv", "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.basic_silh_dist", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.do_clustering", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["def", "cluster_references", "(", "groups_filename", ",", "output_folder", ",", "references", ")", ":", "\n", "    ", "groups_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "groups_filename", ")", ")", "[", "0", "]", "\n", "\n", "loggers", "=", "CustomDefaultDict", "(", "partial", "(", "instantiate_logger", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "log_prefix", "=", "\"{:}_clustering\"", ".", "format", "(", "groups_name", ")", ",", "\n", "names_to_log", "=", "[", "\"purity\"", ",", "\"homogeneity\"", ",", "\"completeness\"", ",", "\"silhouette\"", "]", "\n", ")", "\n", ")", "\n", "\n", "basic_loggers", "=", "CustomDefaultDict", "(", "partial", "(", "instantiate_logger", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "log_prefix", "=", "\"{:}_base_silhouette\"", ".", "format", "(", "groups_name", ")", ",", "\n", "names_to_log", "=", "[", "\"silhouette\"", "]", "\n", ")", "\n", ")", "\n", "\n", "for", "refname", ",", "(", "refloader", ",", "refloadkwargs_list", ",", "refthetas", ")", "in", "references", ".", "items", "(", ")", ":", "\n", "        ", "refloadkwargs_list", "=", "refloadkwargs_list", "if", "isinstance", "(", "refloadkwargs_list", ",", "list", ")", "else", "[", "refloadkwargs_list", "]", "\n", "\n", "for", "refloadkwargs", "in", "refloadkwargs_list", ":", "\n", "            ", "outbasename", "=", "get_ref_name", "(", "refname", ",", "refloadkwargs", ")", "\n", "vecsize", "=", "get_ref_vecsize", "(", "refname", ",", "refloadkwargs", ")", "\n", "g_matrix", "=", "np", ".", "eye", "(", "vecsize", ")", "\n", "\n", "dictionary", ",", "vecs", "=", "refloader", "(", "**", "refloadkwargs", ")", "\n", "\n", "groups", "=", "load_csv_into_dict", "(", "groups_filename", ",", "dictionary", ")", "\n", "ngroups", "=", "len", "(", "groups", ")", "\n", "\n", "clustering_methods", "=", "create_clustering_methods", "(", "ngroups", ",", "g_matrix", ",", "n_init", "=", "N_INIT", ")", "\n", "\n", "for", "th", "in", "refthetas", ":", "\n", "                ", "points_dict", "=", "prepare_clusters", "(", "vecs", ",", "th", ",", "groups", ",", "dictionary", ")", "\n", "\n", "for", "thname", ",", "(", "points", ",", "labels", ")", "in", "tqdm", "(", "points_dict", ".", "items", "(", ")", ",", "desc", "=", "refname", "+", "\"-\"", "+", "th", ")", ":", "\n", "#in the reference case, we don't want to write \"u\" since it is depending on the reference (usually \"u\" but loads \"u+v\", hence the confusion)", "\n", "                    ", "thname", "=", "get_ref_theta_name", "(", "refname", ",", "thname", ")", "\n", "\n", "baselog", "=", "basic_loggers", "[", "(", "outbasename", ",", "thname", ")", "]", "\n", "success", ",", "_", "=", "baselog", ".", "try_read_csv", "(", ")", "\n", "if", "not", "success", ":", "\n", "                        ", "silh", "=", "silhouette", "(", "points", ",", "labels", ",", "basic_silh_dist", "(", "thname", ",", "g_matrix", ")", ")", "\n", "baselog", ".", "log", "(", "[", "silh", "]", ")", "\n", "\n", "", "for", "cname", ",", "(", "cobj", ",", "cdist", ")", "in", "clustering_methods", ".", "items", "(", ")", ":", "\n", "                        ", "logger", "=", "loggers", "[", "(", "outbasename", ",", "thname", ",", "cname", ")", "]", "\n", "success", ",", "_", "=", "logger", ".", "try_read_csv", "(", ")", "\n", "if", "not", "success", ":", "\n", "                            ", "pur", ",", "hom", ",", "comp", ",", "silh", "=", "do_clustering", "(", "cobj", ",", "points", ",", "labels", ",", "cdist", ")", "\n", "logger", ".", "log", "(", "[", "pur", ",", "hom", ",", "comp", ",", "silh", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.cluster_glove_trained": [[162, 219], ["word_embedding.test.core.clustering.logging.CustomDefaultDict", "word_embedding.test.core.clustering.logging.CustomDefaultDict", "os.path.splitext", "functools.partial", "functools.partial", "numpy.eye", "os.path.basename", "tqdm.tqdm", "word_embedding.test.core.clustering.logging.CustomDefaultDict.items", "word_embedding.test.core.load_embeddings.load_glove", "word_embedding.test.core.clustering.utils.load_csv_into_dict", "len", "clustering.create_clustering_methods", "logger.plot", "clustering.prepare_clusters", "prepare_clusters.items", "create_clustering_methods.items", "baselog.has_value", "word_embedding.test.core.clustering.utils.silhouette", "baselog.log", "clustering.basic_silh_dist", "clustering.is_preproc", "logger.has_value", "word_embedding.test.core.clustering.utils.do_clustering", "logger.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.load_csv_into_dict", "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.create_clustering_methods", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.prepare_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.silhouette", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.basic_silh_dist", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.is_preproc", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.do_clustering", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "", "", "", "", "", "", "def", "cluster_glove_trained", "(", "groups_filename", ",", "output_folder", ",", "corpora", ",", "thetas", ",", "vecsizes", ",", "nepochs", ")", ":", "\n", "    ", "groups_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "groups_filename", ")", ")", "[", "0", "]", "\n", "\n", "loggers", "=", "CustomDefaultDict", "(", "partial", "(", "instantiate_logger", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "log_prefix", "=", "\"{:}_clustering_glove\"", ".", "format", "(", "groups_name", ")", ",", "\n", "names_to_log", "=", "[", "\"epoch\"", ",", "\"purity\"", ",", "\"homogeneity\"", ",", "\"completeness\"", ",", "\"silhouette\"", "]", "\n", ")", "\n", ")", "\n", "\n", "basic_loggers", "=", "CustomDefaultDict", "(", "partial", "(", "instantiate_logger", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "log_prefix", "=", "\"{:}_base_silhouette_glove\"", ".", "format", "(", "groups_name", ")", ",", "\n", "names_to_log", "=", "[", "\"epoch\"", ",", "\"silhouette\"", "]", "\n", ")", "\n", ")", "\n", "\n", "for", "vecsize", "in", "vecsizes", ":", "\n", "        ", "g_matrix", "=", "np", ".", "eye", "(", "vecsize", ")", "\n", "\n", "for", "corpus", "in", "corpora", ":", "\n", "            ", "wename", "=", "\"{:}_v{:}\"", ".", "format", "(", "corpus", ",", "vecsize", ")", "\n", "for", "nepoch", "in", "tqdm", "(", "nepochs", ",", "desc", "=", "wename", ")", ":", "\n", "\n", "                ", "dictionary", ",", "vecs", ",", "_", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ",", "\n", "glove_dir", "=", "base_dir", "[", "corpus", "]", ")", "\n", "\n", "groups", "=", "load_csv_into_dict", "(", "groups_filename", ",", "dictionary", ")", "\n", "ngroups", "=", "len", "(", "groups", ")", "\n", "clustering_methods", "=", "create_clustering_methods", "(", "ngroups", ",", "g_matrix", ",", "n_init", "=", "N_INIT", ")", "\n", "\n", "for", "theta", "in", "thetas", ":", "\n", "                    ", "points_dict", "=", "prepare_clusters", "(", "vecs", ",", "theta", ",", "groups", ",", "dictionary", ")", "\n", "\n", "for", "thname", ",", "(", "points", ",", "labels", ")", "in", "points_dict", ".", "items", "(", ")", ":", "\n", "                        ", "baselog", "=", "basic_loggers", "[", "(", "wename", ",", "thname", ")", "]", "\n", "if", "not", "baselog", ".", "has_value", "(", "\"epoch\"", ",", "nepoch", ")", ":", "\n", "                            ", "silh", "=", "silhouette", "(", "points", ",", "labels", ",", "basic_silh_dist", "(", "thname", ",", "g_matrix", ")", ")", "\n", "baselog", ".", "log", "(", "[", "nepoch", ",", "silh", "]", ")", "\n", "\n", "", "for", "cname", ",", "(", "cobj", ",", "cdist", ")", "in", "clustering_methods", ".", "items", "(", ")", ":", "\n", "# skip if the method is not meaningful", "\n", "                            ", "if", "(", "cname", "not", "in", "clmethods_for_not_preproc", ")", "and", "is_preproc", "(", "thname", ")", ":", "\n", "                                ", "continue", "\n", "\n", "", "logger", "=", "loggers", "[", "(", "wename", ",", "thname", ",", "cname", ")", "]", "\n", "if", "not", "logger", ".", "has_value", "(", "\"epoch\"", ",", "nepoch", ")", ":", "\n", "                                ", "pur", ",", "hom", ",", "comp", ",", "silh", "=", "do_clustering", "(", "cobj", ",", "points", ",", "labels", ",", "cdist", ")", "\n", "logger", ".", "log", "(", "[", "nepoch", ",", "pur", ",", "hom", ",", "comp", ",", "silh", "]", ")", "\n", "\n", "# for theta in thetas:", "\n", "#     for thname in [theta, theta+\"_norm\", theta+\"_std\"]:", "\n", "#         for cname in clustering_methods:", "\n", "#             key_tuple = (wename, thname, cname)", "\n", "#             loggers[key_tuple].plot(x=\"epoch\")", "\n", "", "", "", "", "", "for", "nametuple", ",", "logger", "in", "loggers", ".", "items", "(", ")", ":", "\n", "                ", "logger", ".", "plot", "(", "x", "=", "\"epoch\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.is_preproc": [[221, 223], ["None"], "function", ["None"], ["", "", "", "", "def", "is_preproc", "(", "thname", ")", ":", "\n", "    ", "return", "(", "\"norm\"", "in", "thname", "or", "\"std\"", "in", "thname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_embeddings": [[225, 232], ["ValueError"], "function", ["None"], ["", "def", "get_embeddings", "(", "vecs", ",", "theta", ")", ":", "\n", "    ", "if", "theta", "==", "\"u\"", ":", "\n", "        ", "return", "vecs", "[", "\"u\"", "]", "\n", "", "elif", "theta", "==", "\"u+v\"", ":", "\n", "        ", "return", "vecs", "[", "\"u\"", "]", "+", "vecs", "[", "\"v\"", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"theta option not recognized\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.points_and_labels_from_clusters": [[234, 244], ["zip", "numpy.concatenate", "numpy.concatenate", "numpy.random.permutation", "enumerate", "clusters.keys"], "function", ["None"], ["", "", "def", "points_and_labels_from_clusters", "(", "clusters", ")", ":", "\n", "    ", "points_list", ",", "labels_list", "=", "zip", "(", "*", "[", "(", "clusters", "[", "g", "]", ",", "[", "i", "]", "*", "clusters", "[", "g", "]", ".", "shape", "[", "0", "]", ")", "for", "i", ",", "g", "in", "enumerate", "(", "clusters", ".", "keys", "(", ")", ")", "]", ")", "\n", "\n", "clusters_points", "=", "np", ".", "concatenate", "(", "points_list", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels_list", ",", "axis", "=", "0", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "clusters_points", ".", "shape", "[", "0", "]", ")", "\n", "shuffled_clusters_points", "=", "clusters_points", "[", "perm", "]", "\n", "shuffled_labels", "=", "labels", "[", "perm", "]", "\n", "\n", "return", "clusters_points", ",", "labels", ",", "shuffled_clusters_points", ",", "shuffled_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.prepare_clusters": [[246, 261], ["clustering.get_embeddings", "sklearn.preprocessing.scale", "word_embedding.test.core.clustering.utils.make_clusters_out_of", "clustering.points_and_labels_from_clusters", "clustering.points_and_labels_from_clusters", "clustering.points_and_labels_from_clusters", "numpy.linalg.norm().reshape", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.get_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.make_clusters_out_of", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.points_and_labels_from_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.points_and_labels_from_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.points_and_labels_from_clusters"], ["", "def", "prepare_clusters", "(", "vecs", ",", "theta", ",", "groups", ",", "dictionary", ")", ":", "\n", "    ", "embeddings", "=", "get_embeddings", "(", "vecs", ",", "theta", ")", "\n", "embeddings_norm", "=", "embeddings", "/", "(", "np", ".", "linalg", ".", "norm", "(", "embeddings", ",", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "+", "NORMTOL", ")", "\n", "embeddings_std", "=", "sklearn", ".", "preprocessing", ".", "scale", "(", "embeddings", ")", "\n", "\n", "clusters", ",", "clusters_norm", ",", "clusters_std", "=", "make_clusters_out_of", "(", "\n", "[", "embeddings", ",", "embeddings_norm", ",", "embeddings_std", "]", ",", "groups", ",", "dictionary", ")", "\n", "\n", "_", ",", "_", ",", "points", ",", "labels", "=", "points_and_labels_from_clusters", "(", "clusters", ")", "\n", "_", ",", "_", ",", "points_norm", ",", "labels_norm", "=", "points_and_labels_from_clusters", "(", "clusters_norm", ")", "\n", "_", ",", "_", ",", "points_std", ",", "labels_std", "=", "points_and_labels_from_clusters", "(", "clusters_std", ")", "\n", "\n", "return", "{", "theta", ":", "(", "points", ",", "labels", ")", ",", "\n", "theta", "+", "\"_norm\"", ":", "(", "points_norm", ",", "labels_norm", ")", ",", "\n", "theta", "+", "\"_std\"", ":", "(", "points_std", ",", "labels_std", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.clustering.read_groups": [[264, 268], ["word_embedding.test.core.clustering.utils.load_csv_into_dict", "os.path.splitext", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.load_csv_into_dict"], ["", "def", "read_groups", "(", "groups_filename", ",", "dictionary", ")", ":", "\n", "    ", "groups_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "groups_filename", ")", ")", "[", "0", "]", "\n", "groups", "=", "load_csv_into_dict", "(", "groups_filename", ",", "dictionary", ")", "\n", "return", "groups", ",", "groups_name", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.get_pca": [[36, 51], ["sklearn.decomposition.PCA().fit", "sklearn.decomposition.PCA"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit"], ["def", "get_pca", "(", "matrix", ",", "ncomponents", ")", ":", "\n", "# OLD HAND-MADE PCA", "\n", "# # _, pca_eigenvalues, _ = np.linalg.svd(matrix)", "\n", "# # rowvar is False means rows contain observations", "\n", "# cov_matrix = np.cov(matrix, rowvar=False)", "\n", "# # cov_matrix = self.covariance_matrix(matrix)", "\n", "# pca_eigenvalues, _ = np.linalg.eig(cov_matrix)", "\n", "# # sort eigevals in descending order", "\n", "# pca_eigs_index = np.argsort(-pca_eigenvalues)", "\n", "# pca_eigenvalues = pca_eigenvalues[pca_eigs_index]", "\n", "# return pca_eigenvalues", "\n", "#", "\n", "# SKLEARN PCA", "\n", "    ", "pca", "=", "PCA", "(", "n_components", "=", "ncomponents", ")", ".", "fit", "(", "matrix", ")", "\n", "return", "pca", ".", "explained_variance_", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.analyze_embeddings": [[53, 101], ["space.mean", "space.dist_hist", "mylogging.save_data", "space.dist_hist", "mylogging.save_data", "space.dist", "open", "outstream.write", "outstream.write", "outstream.write", "outstream.write", "outstream.write", "outstream.write", "outstream.write", "outstream.write", "mylogging.write_rows_to_txt", "outstream.write", "outstream.write", "mylogging.write_rows_to_txt", "outstream.write", "outstream.write", "mylogging.write_rows_to_txt", "numpy.array", "str", "str", "numpy.diff", "numpy.diff"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.dist_hist", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.Space.dist_hist", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_data", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.HyperSphere.dist", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_rows_to_txt", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_rows_to_txt", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_rows_to_txt"], ["", "def", "analyze_embeddings", "(", "embeddings", ",", "x_0", ",", "space", ",", "embeddings_label", ",", "outputbasename", ")", ":", "\n", "    ", "\"\"\"Analyze the embeddings distribution in the space and save results to files.\n    \n    Args:\n        embeddings (list of numpy.array): embeddings to analyze.\n        x_0 (numpy.array): The uniform distribution, used as a reference for the space we are analyzing.\n        space (class Space): the space to consider (has methods median, dist, etc...).\n        embeddings_label (string): label to use for saving the data (used for the future plots).\n        outputbasename (string): base name for the output file.\n    \"\"\"", "\n", "\n", "x_bar", "=", "space", ".", "mean", "(", "embeddings", ")", "\n", "\n", "avg_sqrtmsd", ",", "avg_dmin", ",", "avg_dmax", ",", "avg_dmean", ",", "avg_dstd", ",", "avg_dhi", "=", "space", ".", "dist_hist", "(", "embeddings", ",", "x_bar", ",", "bins", "=", "'auto'", ")", "\n", "ys", ",", "xs", "=", "avg_dhi", "\n", "save_data", "(", "[", "xs", "[", ":", "-", "1", "]", "]", ",", "[", "ys", "]", ",", "[", "embeddings_label", "+", "\"-from-avg\"", "]", ",", "outputbasename", "+", "\"-from-avg-hist.dat\"", ",", "\n", "plot_method_name", "=", "\"bar\"", ",", "kwargs_list", "=", "[", "{", "'align'", ":", "'edge'", ",", "'width'", ":", "np", ".", "diff", "(", "xs", ")", "}", "]", "\n", ")", "\n", "\n", "un_sqrtmsd", ",", "un_dmin", ",", "un_dmax", ",", "un_dmean", ",", "un_dstd", ",", "un_dhi", "=", "space", ".", "dist_hist", "(", "embeddings", ",", "x_0", ",", "bins", "=", "'auto'", ")", "\n", "ys", ",", "xs", "=", "un_dhi", "\n", "save_data", "(", "[", "xs", "[", ":", "-", "1", "]", "]", ",", "[", "ys", "]", ",", "[", "embeddings_label", "+", "\"-from-un\"", "]", ",", "outputbasename", "+", "\"-from-un-hist.dat\"", ",", "\n", "plot_method_name", "=", "\"bar\"", ",", "kwargs_list", "=", "[", "{", "'align'", ":", "'edge'", ",", "'width'", ":", "np", ".", "diff", "(", "xs", ")", "}", "]", "\n", ")", "\n", "\n", "dist_avg_un", "=", "space", ".", "dist", "(", "np", ".", "array", "(", "[", "x_bar", "]", ")", ",", "x_0", ")", "[", "0", "]", "\n", "\n", "with", "open", "(", "outputbasename", "+", "'-summary.txt'", ",", "'w'", ")", "as", "outstream", ":", "\n", "        ", "outstream", ".", "write", "(", "\"STATS ON THE EMBEDDINGS, obtained in the space: %s\\n\"", "%", "space", ".", "__class__", ".", "__name__", ")", "\n", "outstream", ".", "write", "(", "\"-----------------------------------------------------------\\n\\n\"", ")", "\n", "outstream", ".", "write", "(", "\"uniform (x_0)\\n\"", ")", "\n", "outstream", ".", "write", "(", "str", "(", "x_0", ")", ")", "\n", "outstream", ".", "write", "(", "\"\\n\"", ")", "\n", "outstream", ".", "write", "(", "\"mean (x_bar)\\n\"", ")", "\n", "outstream", ".", "write", "(", "str", "(", "x_bar", ")", ")", "\n", "outstream", ".", "write", "(", "\"\\n\"", ")", "\n", "rows", "=", "[", "(", "\"dist(x_bar, x_0)\"", ",", "dist_avg_un", ")", "]", "\n", "write_rows_to_txt", "(", "rows", ",", "outstream", ",", "spacer", "=", "'  '", ")", "\n", "\n", "outstream", ".", "write", "(", "\"\\n-----------------------------------------------------------\\n\\n\"", ")", "\n", "outstream", ".", "write", "(", "\"distances from x_0:\\n\"", ")", "\n", "rows", "=", "[", "(", "\"sqrtmeansqdist\"", ",", "\"min\"", ",", "\"max\"", ",", "\"mean\"", ",", "\"std\"", ")", ",", "(", "un_sqrtmsd", ",", "un_dmin", ",", "un_dmax", ",", "un_dmean", ",", "un_dstd", ")", "]", "\n", "write_rows_to_txt", "(", "rows", ",", "outstream", ",", "spacer", "=", "'  '", ")", "\n", "\n", "outstream", ".", "write", "(", "\"\\n-----------------------------------------------------------\\n\\n\"", ")", "\n", "outstream", ".", "write", "(", "\"distances from x_bar:\\n\"", ")", "\n", "rows", "=", "[", "(", "\"sqrtmeansqdist\"", ",", "\"min\"", ",", "\"max\"", ",", "\"mean\"", ",", "\"std\"", ")", ",", "(", "avg_sqrtmsd", ",", "avg_dmin", ",", "avg_dmax", ",", "avg_dmean", ",", "avg_dstd", ")", "]", "\n", "write_rows_to_txt", "(", "rows", ",", "outstream", ",", "spacer", "=", "'  '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.get_distribution_stats": [[103, 172], ["progressbar.progressbar", "numpy.array", "numpy.mean", "numpy.sqrt", "numpy.array", "numpy.array", "range", "numpy.argsort", "extract_stats.index_before_elbow", "np.array.append", "numpy.mean", "open", "outstream.write", "outstream.write", "mylogging.write_rows_to_txt", "outstream.write", "outstream.write", "mylogging.write_rows_to_txt", "outstream.write", "outstream.write", "mylogging.write_rows_to_txt", "len", "numpy.array", "mylogging.save_distribution", "mylogging.save_txt", "numpy.power", "enumerate", "list", "list", "word.replace", "zip", "zip", "list", "list", "itertools.chain", "zip", "itertools.chain", "zip", "sorted"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.index_before_elbow", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_rows_to_txt", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_rows_to_txt", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.write_rows_to_txt", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_distribution", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_txt"], ["", "", "def", "get_distribution_stats", "(", "mu_embeddings", ",", "words", ",", "selected_words", ",", "outputdistribbasename", ")", ":", "\n", "#get elbow for all words", "\n", "#1 how many words before the elbow in average", "\n", "#2 10 words with max n of words before the elbow", "\n", "#3 10 words with min n of words before the elbow", "\n", "#4 distances from the center of learned words", "\n", "\n", "#save distribution for selected words", "\n", "    ", "ntuples", "=", "[", "]", "\n", "# cnt=0", "\n", "for", "i", "in", "progressbar", ".", "progressbar", "(", "range", "(", "len", "(", "words", ")", ")", ")", ":", "\n", "        ", "word", "=", "words", "[", "i", "]", "\n", "# i=dictionary[word]", "\n", "\n", "# cnt+=1", "\n", "# if cnt==30:", "\n", "#     break", "\n", "\n", "mu_embedding", "=", "mu_embeddings", "[", "i", "]", "\n", "indexes", "=", "np", ".", "argsort", "(", "-", "mu_embedding", ")", "\n", "ordered_mu_embedding", "=", "mu_embedding", "[", "indexes", "]", "\n", "ordered_words", "=", "np", ".", "array", "(", "words", ")", "[", "indexes", "]", "\n", "\n", "ntuple", "=", "index_before_elbow", "(", "word", ",", "ordered_mu_embedding", ")", "\n", "ntuples", ".", "append", "(", "ntuple", ")", "\n", "\n", "if", "word", "in", "selected_words", ":", "\n", "#save the distribution", "\n", "            ", "thiswordname", "=", "outputdistribbasename", "+", "'-'", "+", "word", ".", "replace", "(", "'/'", ",", "'_'", ")", "\n", "save_distribution", "(", "ordered_mu_embedding", ",", "ordered_words", ",", "inputlabel", "+", "'-'", "+", "word", ",", "thiswordname", "+", "'.dat'", ")", "\n", "n", "=", "ntuple", "[", "-", "1", "]", "+", "10", "\n", "save_txt", "(", "[", "ordered_words", "[", ":", "n", "]", ",", "ordered_mu_embedding", "[", ":", "n", "]", "]", ",", "thiswordname", "+", "'-before_elbow.txt'", ")", "\n", "\n", "# import pdb;pdb.set_trace()", "\n", "", "", "ntuples", "=", "np", ".", "array", "(", "ntuples", ")", "\n", "nmeans", "=", "np", ".", "mean", "(", "ntuples", ",", "axis", "=", "0", ")", "\n", "nstds", "=", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "np", ".", "power", "(", "ntuples", "-", "nmeans", ",", "2", ")", ",", "axis", "=", "0", ")", ")", "\n", "\n", "#SORT based on keys 5,2,1 and get the arg", "\n", "to_sort", "=", "[", "(", "tup", "[", "1", "]", "[", "5", "]", ",", "tup", "[", "1", "]", "[", "2", "]", ",", "tup", "[", "1", "]", "[", "1", "]", ",", "tup", "[", "0", "]", ")", "for", "tup", "in", "enumerate", "(", "ntuples", ")", "]", "\n", "ordidxs", "=", "np", ".", "array", "(", "list", "(", "zip", "(", "*", "sorted", "(", "to_sort", ")", ")", ")", "[", "-", "1", "]", ")", "\n", "words", "=", "np", ".", "array", "(", "words", ")", "\n", "\n", "# WRITE STATS TO FILE", "\n", "#1 how many words before the elbow in average", "\n", "#2 10 words with max n of words before the elbow", "\n", "#3 10 words with min n of words before the elbow", "\n", "#4 distances from the center of learned words", "\n", "\n", "with", "open", "(", "outputdistribbasename", "+", "'-distribution-summary.txt'", ",", "'w'", ")", "as", "outstream", ":", "\n", "        ", "outstream", ".", "write", "(", "\"STATS ON THE LEARNED CONDITIONAL DISTRIBUTIONS OF THE WORDS\\n\"", ")", "\n", "outstream", ".", "write", "(", "\"-----------------------------------------------------------\\n\\n\"", ")", "\n", "rows", "=", "[", "(", "\"method\"", ",", "\"mean\"", ",", "\"std\"", ")", "]", "+", "list", "(", "zip", "(", "methodname", ",", "nmeans", ",", "nstds", ")", ")", "\n", "write_rows_to_txt", "(", "rows", ",", "outstream", ",", "spacer", "=", "'  '", ")", "\n", "\n", "outstream", ".", "write", "(", "\"\\n-----------------------------------------------------------\\n\\n\"", ")", "\n", "outstream", ".", "write", "(", "\"10 words with min n of words before the elbow:\\n\"", ")", "\n", "header", "=", "[", "\"word\"", "]", "+", "methodname", "\n", "first_words", "=", "words", "[", "ordidxs", "[", ":", "10", "]", "]", "\n", "first_tuples", "=", "ntuples", "[", "ordidxs", "[", ":", "10", "]", "]", "\n", "rows", "=", "[", "header", "]", "+", "[", "list", "(", "itertools", ".", "chain", "(", "[", "w", "]", ",", "t", ")", ")", "for", "(", "w", ",", "t", ")", "in", "zip", "(", "first_words", ",", "first_tuples", ")", "]", "\n", "write_rows_to_txt", "(", "rows", ",", "outstream", ",", "spacer", "=", "'  '", ")", "\n", "\n", "outstream", ".", "write", "(", "\"\\n-----------------------------------------------------------\\n\\n\"", ")", "\n", "outstream", ".", "write", "(", "\"10 words with max n of words before the elbow:\\n\"", ")", "\n", "last_words", "=", "words", "[", "ordidxs", "[", "-", "10", ":", "]", "]", "\n", "last_tuples", "=", "ntuples", "[", "ordidxs", "[", "-", "10", ":", "]", "]", "\n", "rows", "=", "[", "header", "]", "+", "[", "list", "(", "itertools", ".", "chain", "(", "[", "w", "]", ",", "t", ")", ")", "for", "(", "w", ",", "t", ")", "in", "zip", "(", "last_words", ",", "last_tuples", ")", "]", "\n", "write_rows_to_txt", "(", "rows", ",", "outstream", ",", "spacer", "=", "'  '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.write_distribs_from_selected": [[174, 193], ["progressbar.progressbar", "range", "numpy.argsort", "extract_stats.index_before_elbow", "mylogging.save_distribution", "mylogging.save_txt", "len", "numpy.array", "selword.replace"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.index_before_elbow", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_distribution", "home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.save_txt"], ["", "", "def", "write_distribs_from_selected", "(", "mu_embeddings", ",", "words", ",", "selected_words", ",", "dictionary", ",", "outputdistribbasename", ")", ":", "\n", "#Save distribution for selected words, in case I do not compute all stats.", "\n", "#it is better to have it separated from the loop in get_stats", "\n", "#since maybe I do not want to recompute all the stats", "\n", "\n", "    ", "for", "i", "in", "progressbar", ".", "progressbar", "(", "range", "(", "len", "(", "selected_words", ")", ")", ")", ":", "\n", "        ", "selword", "=", "selected_words", "[", "i", "]", "\n", "selidx", "=", "dictionary", "[", "selword", "]", "\n", "mu_embedding", "=", "mu_embeddings", "[", "selidx", "]", "\n", "\n", "indexes", "=", "np", ".", "argsort", "(", "-", "mu_embedding", ")", "\n", "ordered_mu_embedding", "=", "mu_embedding", "[", "indexes", "]", "\n", "ordered_words", "=", "np", ".", "array", "(", "words", ")", "[", "indexes", "]", "\n", "ntuple", "=", "index_before_elbow", "(", "selword", ",", "ordered_mu_embedding", ")", "\n", "#save the distribution", "\n", "thiswordname", "=", "outputdistribbasename", "+", "'-'", "+", "selword", ".", "replace", "(", "'/'", ",", "'_'", ")", "\n", "save_distribution", "(", "ordered_mu_embedding", ",", "ordered_words", ",", "inputlabel", "+", "'-'", "+", "word", ",", "thiswordname", "+", "'.dat'", ")", "\n", "n", "=", "ntuple", "[", "-", "1", "]", "+", "10", "\n", "save_txt", "(", "[", "ordered_words", "[", ":", "n", "]", ",", "ordered_mu_embedding", "[", ":", "n", "]", "]", ",", "thiswordname", "+", "'-before_elbow.txt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.plot_with_demarcation": [[198, 208], ["plt.title", "plt.plot", "plt.xlim", "plt.ylim", "enumerate", "plt.legend", "plt.show", "plt.vlines", "plt.ylim", "plt.ylim"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["def", "plot_with_demarcation", "(", "word", ",", "indexes", ",", "ordered_prob", ",", "ntuple", ",", "xlim", "=", "None", ",", "ylim", "=", "None", ",", ")", ":", "\n", "    ", "plt", ".", "title", "(", "word", ")", "\n", "plt", ".", "plot", "(", "indexes", ",", "ordered_prob", ",", "'bx-'", ")", "\n", "plt", ".", "xlim", "(", "xlim", ")", "\n", "plt", ".", "ylim", "(", "ylim", ")", "\n", "for", "i", ",", "n", "in", "enumerate", "(", "ntuple", ")", ":", "\n", "        ", "plt", ".", "vlines", "(", "n", ",", "plt", ".", "ylim", "(", ")", "[", "0", "]", ",", "plt", ".", "ylim", "(", ")", "[", "1", "]", ",", "linestyles", "=", "'dashed'", ",", "color", "=", "color", "[", "i", "]", ",", "label", "=", "methodname", "[", "i", "]", ")", "\n", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.__normalize": [[209, 211], ["min", "max", "min"], "function", ["None"], ["", "def", "__normalize", "(", "a", ")", ":", "\n", "    ", "return", "(", "a", "-", "min", "(", "a", ")", ")", "/", "(", "max", "(", "a", ")", "-", "min", "(", "a", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.func": [[274, 276], ["None"], "function", ["None"], ["def", "func", "(", "x", ",", "a", ",", "b", ")", ":", "\n", "    ", "return", "a", "*", "x", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.invf": [[277, 279], ["numpy.power"], "function", ["None"], ["", "def", "invf", "(", "x", ",", "a0", ",", "alpha", ")", ":", "\n", "    ", "return", "a0", "*", "np", ".", "power", "(", "x", ",", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.expofit_elbow": [[280, 316], ["numpy.log", "scipy.optimize.curve_fit", "int", "numpy.ceil"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "expofit_elbow", "(", "x", ",", "y", ")", ":", "\n", "# x=np.arange(700, dtype=float)", "\n", "# y=np.exp(-x)+0.01*np.random.normal(size=x.shape)", "\n", "# y=abs(y)*1.1", "\n", "\n", "    ", "mni", "=", "1", "\n", "mxi", "=", "300", "\n", "\n", "# xn=__normalize(x)[mni:mxi]", "\n", "# yn=__normalize(y)[mni:mxi]", "\n", "xn", "=", "x", "[", "mni", ":", "mxi", "]", "\n", "yn", "=", "np", ".", "log", "(", "y", "[", "mni", ":", "mxi", "]", ")", "\n", "\n", "# initial_guess_exp=(1,-1)", "\n", "# weights=np.power(x[mni:mxi],-5)", "\n", "popt", ",", "pcov", "=", "curve_fit", "(", "func", ",", "xn", ",", "yn", ")", "#, sigma=weights, p0=initial_guess_exp)", "\n", "\n", "a", ",", "b", "=", "popt", "\n", "\n", "# from matplotlib import pyplot as plt", "\n", "# plt.plot(xn,yn,'o')", "\n", "# plt.plot(xn,weights,'--')", "\n", "# plt.plot(xn,expf(*[xn]+list(initial_guess_exp)),'-', label='initialguess')", "\n", "# plt.plot(xn,expf(xn,a0,alpha),'-',label='fitted')", "\n", "# # plt.plot(xn[1:],invf(xn[1:],a0i,alphai),'-')", "\n", "# plt.legend()", "\n", "# plt.show()", "\n", "#", "\n", "# plt.plot(x,y,'o')", "\n", "# plt.plot(xn,np.exp(expf(xn,a0,alpha)),'-',label='fitted')", "\n", "# plt.show()", "\n", "#", "\n", "tau", "=", "int", "(", "np", ".", "ceil", "(", "-", "1", "/", "a", ")", ")", "\n", "# plt.vlines(xnrot[idmax], plt.ylim()[0], plt.ylim()[1], linestyles='dashed')", "\n", "\n", "return", "tau", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.std_check": [[317, 319], ["numpy.std"], "function", ["None"], ["", "def", "std_check", "(", "arr", ",", "bound", ")", ":", "\n", "    ", "return", "np", ".", "std", "(", "arr", ")", "<", "bound", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.std_and_value_check": [[320, 322], ["numpy.std"], "function", ["None"], ["", "def", "std_and_value_check", "(", "arr", ",", "bound", ")", ":", "\n", "    ", "return", "(", "np", ".", "std", "(", "arr", ")", "<", "bound", "and", "arr", "[", "0", "]", "<", "bound", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.elbow_from_diffs": [[323, 337], ["numpy.asarray", "next", "len", "range", "condition", "len"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.utils.condition"], ["", "def", "elbow_from_diffs", "(", "x", ",", "y", ",", "low_trigger", "=", "False", ")", ":", "\n", "    ", "y", "=", "np", ".", "asarray", "(", "y", ")", "\n", "s", "=", "10", "\n", "frac", "=", "10.", "\n", "refd", "=", "y", "[", "0", "]", "/", "frac", "\n", "# import pdb;pdb.set_trace()", "\n", "# diffs=y[:-s]-y[s:]", "\n", "# index=next(i for i in range(len(diffs)-1) if diffs[i]<refd)+s", "\n", "condition", "=", "std_check", "\n", "if", "low_trigger", ":", "\n", "        ", "condition", "=", "std_and_value_check", "\n", "\n", "", "index", "=", "next", "(", "(", "i", "for", "i", "in", "range", "(", "len", "(", "y", ")", ")", "if", "condition", "(", "y", "[", "i", ":", "i", "+", "s", "]", ",", "refd", ")", ")", ",", "len", "(", "y", ")", ")", "\n", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.index_before_elbow": [[339, 448], ["len", "numpy.arange", "kneed.KneeLocator", "int", "extract_stats.__normalize", "numpy.array", "sklearn.cluster.KMeans().fit", "next", "extract_stats.elbow_from_diffs", "extract_stats.elbow_from_diffs", "numpy.ceil", "numpy.argmax", "ordered_prob.reshape", "collections.Counter", "ValueError", "sklearn.cluster.KMeans", "enumerate"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.__normalize", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.elbow_from_diffs", "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.elbow_from_diffs"], ["", "def", "index_before_elbow", "(", "word", ",", "ordered_prob", ")", ":", "\n", "    ", "\"\"\"Find the index of the knee for an ordered probability distribution, expected ordered.\n\n    Args:\n        ordered_prob (type): the ordered probability distribution.\n\n    Returns:\n        type: a tuple with the different indexes calculated by different methods (e.g. kneedle, 2nd derivative, 2-means and hierarchical clustering single linkage selecting 2 clusters, ...).\n\n    \"\"\"", "\n", "\n", "# #TIME", "\n", "# import time", "\n", "# t=[]", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "\n", "# Kneedle algorithm https://www1.icsi.berkeley.edu/~barath/papers/kneedle-simplex11.pdf", "\n", "# code: https://github.com/arvkevi/kneed", "\n", "dict_size", "=", "len", "(", "ordered_prob", ")", "\n", "indexes", "=", "np", ".", "arange", "(", "dict_size", ")", "\n", "# n_kneedle = elbow_simple(indexes, ordered_prob)", "\n", "kn", "=", "KneeLocator", "(", "indexes", ",", "ordered_prob", ",", "direction", "=", "'decreasing'", ",", "invert", "=", "True", ",", "label", "=", "word", ")", "\n", "#it is possible that the KneeLocator does not find any local maxima, in this case the probability is approx equal for all words", "\n", "n_kneedle", "=", "kn", ".", "knee", "if", "kn", ".", "knee", "else", "dict_size", "\n", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "\n", "# Simple Kneedle", "\n", "# indexes = np.arange(len(ordered_prob))", "\n", "# n_simplekneedle = elbow_find(indexes, ordered_prob)", "\n", "n_simplekneedle", "=", "int", "(", "np", ".", "ceil", "(", "n_kneedle", "*", "(", "2", "/", "3", ")", ")", ")", "\n", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "\n", "#Max second derivative", "\n", "ysn", "=", "__normalize", "(", "ordered_prob", ")", "\n", "secondDerivatives", "=", "np", ".", "array", "(", "[", "(", "ysn", "[", "i", "+", "1", "]", "+", "ysn", "[", "i", "-", "1", "]", "-", "2", "*", "ysn", "[", "i", "]", ")", "for", "i", "in", "indexes", "[", "1", ":", "-", "1", "]", "]", ")", "\n", "n_snddv", "=", "np", ".", "argmax", "(", "secondDerivatives", ")", "+", "1", "\n", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "\n", "#Clustering 2-mean", "\n", "kmeans", "=", "KMeans", "(", "n_clusters", "=", "2", ")", ".", "fit", "(", "ordered_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", "#, init=np.array([0,1]).reshape(-1,1)).fit(ordered_prob.reshape(-1,1))", "\n", "target", "=", "kmeans", ".", "labels_", "[", "0", "]", "\n", "compl", "=", "1", "if", "target", "==", "0", "else", "0", "\n", "i0k", "=", "next", "(", "i", "for", "(", "i", ",", "l", ")", "in", "enumerate", "(", "kmeans", ".", "labels_", ")", "if", "l", "==", "compl", ")", "\n", "counter1k", "=", "Counter", "(", "kmeans", ".", "labels_", ")", "[", "target", "]", "\n", "if", "not", "i0k", "==", "counter1k", ":", "\n", "        ", "raise", "ValueError", "(", "\"found anomaly in data k\"", ")", "\n", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "\n", "#DIFFERENCE FRACTION", "\n", "", "n_diff", "=", "elbow_from_diffs", "(", "indexes", ",", "ordered_prob", ")", "\n", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "\n", "#DIFFERENCE FRACTION", "\n", "n_diffnfrac", "=", "elbow_from_diffs", "(", "indexes", ",", "ordered_prob", ",", "low_trigger", "=", "True", ")", "\n", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "#", "\n", "# #Agglomerative clustering simple linkage, looking for 2 clusters", "\n", "# agglom = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='average').fit(ordered_prob.reshape(-1,1))", "\n", "# target=1", "\n", "# compl=0", "\n", "# i0a=next(i for (i,l) in enumerate(agglom.labels_) if l==compl)", "\n", "# if i0a==0:", "\n", "#     target=0", "\n", "#     compl=1", "\n", "#     i0a=next(i for (i,l) in enumerate(agglom.labels_) if l==compl)", "\n", "# counter1a=Counter(agglom.labels_)[target]", "\n", "# if not i0a==counter1a:", "\n", "#     raise ValueError(\"found anomaly in data a\")", "\n", "#", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# #ENDTIME", "\n", "\n", "# #Fraction of the maximum probability", "\n", "# plim=ordered_prob[0]/3.", "\n", "# n_fracmax=next(i for i,p in enumerate(ordered_prob) if p<plim)", "\n", "#", "\n", "\n", "# #TIME", "\n", "# t.append(time.time())", "\n", "# t=np.array(t)", "\n", "# deltas=t[1:]-t[:-1]", "\n", "# print(\"times:  \"+\"  \".join(map(str,deltas)))", "\n", "# #ENDTIME", "\n", "ntuple", "=", "(", "n_kneedle", ",", "n_simplekneedle", ",", "n_snddv", ",", "i0k", ",", "n_diff", ",", "n_diffnfrac", ")", "#, i0a", "\n", "\n", "# print(ntuple)", "\n", "# plot_with_demarcation(word, indexes, ordered_prob, ntuple, xlim=(-5,1000))", "\n", "\n", "return", "ntuple", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.extract_stats.make_folders": [[450, 459], ["os.makedirs", "os.makedirs", "os.makedirs"], "function", ["None"], ["", "def", "make_folders", "(", "inputlabel", ")", ":", "\n", "    ", "outputdatafolder", "=", "outputfolder", "+", "'/'", "+", "inputlabel", "\n", "outputpcafolder", "=", "outputdatafolder", "+", "'/pca'", "\n", "outputdistsfolder", "=", "outputdatafolder", "+", "'/dists'", "\n", "outputdistribfolder", "=", "outputdatafolder", "+", "'/words_distributions'", "\n", "os", ".", "makedirs", "(", "outputpcafolder", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "outputdistsfolder", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "outputdistribfolder", ",", "exist_ok", "=", "True", ")", "\n", "return", "(", "outputpcafolder", ",", "outputdistsfolder", ",", "outputdistribfolder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.main": [[16, 87], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.basename", "os.path.basename.split", "int", "int", "os.path.join", "os.makedirs", "mylogging.init_logger", "core.load_embeddings.load_dict", "evaluate_analogies.make_base_analogies", "core.load_embeddings.load_all_emb_base", "numpy.linalg.inv", "numpy.linalg.inv", "numpy.linalg.inv", "numpy.linalg.inv", "core.results_collection.load_collection_and_backup", "core.results_collection.check_done_in_collection", "tqdm.tqdm", "core.results_collection.check_done_in_collection", "tqdm.tqdm", "os.path.normpath", "evaluate_analogies.make_limit_analogies", "evaluate_analogies.make_limit_analogies", "evaluate_analogies.make_limit_analogies", "core.results_collection.save_collection", "evaluate_analogies.make_alpha_analogies", "evaluate_analogies.make_alpha_analogies", "evaluate_analogies.make_alpha_analogies", "core.results_collection.save_collection", "evaluate_analogies.make_limit_analogies", "evaluate_analogies.make_limit_analogies", "evaluate_analogies.make_limit_analogies", "evaluate_analogies.make_limit_analogies", "core.results_collection.save_collection", "evaluate_analogies.make_alpha_analogies", "evaluate_analogies.make_alpha_analogies", "evaluate_analogies.make_alpha_analogies", "evaluate_analogies.make_alpha_analogies", "core.results_collection.save_collection"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.init_logger", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_dict", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_base_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_all_emb_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.load_collection_and_backup", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.check_done_in_collection", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.check_done_in_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'embdir'", ",", "type", "=", "str", ",", "help", "=", "\"directory where to find structure of embeddings\"", ")", "\n", "parser", ".", "add_argument", "(", "'--outputdir'", ",", "'-o'", ",", "help", "=", "'outputdir'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "emb_dir", "=", "args", ".", "embdir", "\n", "baseoutdir", "=", "args", ".", "outputdir", "\n", "\n", "emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "corpus", ",", "vstr", ",", "nstr", "=", "emb_id", ".", "split", "(", "'-'", ")", "\n", "vecsize", "=", "int", "(", "vstr", "[", "1", ":", "]", ")", "\n", "nepoch", "=", "int", "(", "nstr", "[", "1", ":", "]", ")", "\n", "\n", "emboutdirname", "=", "os", ".", "path", ".", "join", "(", "baseoutdir", ",", "emb_id", ")", "\n", "os", ".", "makedirs", "(", "emboutdirname", ",", "exist_ok", "=", "True", ")", "\n", "\n", "global", "stream_logger", "\n", "stream_logger", "=", "init_logger", "(", "emboutdirname", "+", "\"/analogies.log\"", ")", "\n", "\n", "vocab", ",", "ivocab", ",", "vocab_size", "=", "load_dict", "(", "emb_dir", ")", "\n", "\n", "# BASE ANALOGIES", "\n", "make_base_analogies", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "vocab", ",", "baseoutdir", ")", "\n", "\n", "\n", "# ALPHA SIMILARITIES", "\n", "alphas", ",", "I0", ",", "Iu", ",", "Iud", ",", "Ius", "=", "load_all_emb_base", "(", "emb_dir", ")", "\n", "\n", "I0_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I0", ")", "\n", "Iu_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iu", ")", "\n", "Iud_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iud", ")", "\n", "Ius_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Ius", ")", "\n", "\n", "\n", "collection_path", "=", "emboutdirname", "+", "\"/alpha-analogies.pkl\"", "\n", "analogies", "=", "load_collection_and_backup", "(", "collection_path", ")", "\n", "\n", "# 3 points, 6 things, expected 18", "\n", "done_alphas", ",", "done_limit", "=", "check_done_in_collection", "(", "analogies", ",", "alphas", ",", "\"u-plog\"", ",", "18", ")", "\n", "\n", "if", "not", "done_limit", ":", "\n", "        ", "make_limit_analogies", "(", "emb_dir", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"0\"", ",", "analogies", ")", "\n", "make_limit_analogies", "(", "emb_dir", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"u\"", ",", "analogies", ")", "\n", "make_limit_analogies", "(", "emb_dir", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"ud\"", ",", "analogies", ")", "\n", "save_collection", "(", "collection_path", ",", "analogies", ")", "\n", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", "[", "done_alphas", ":", "]", ",", "desc", "=", "\"u-alpha-loop\"", ")", ":", "\n", "        ", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"0\"", ",", "analogies", ")", "\n", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"u\"", ",", "analogies", ")", "\n", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"ud\"", ",", "analogies", ")", "\n", "save_collection", "(", "collection_path", ",", "analogies", ")", "\n", "\n", "\n", "# 4 points, 6 things, expected 24", "\n", "", "done_alphas", ",", "done_limit", "=", "check_done_in_collection", "(", "analogies", ",", "alphas", ",", "\"u+v-plog\"", ",", "24", ")", "\n", "\n", "if", "not", "done_limit", ":", "\n", "        ", "make_limit_analogies", "(", "emb_dir", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"0\"", ",", "analogies", ")", "\n", "make_limit_analogies", "(", "emb_dir", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"u\"", ",", "analogies", ")", "\n", "make_limit_analogies", "(", "emb_dir", ",", "Ius", ",", "Ius_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"us\"", ",", "analogies", ")", "\n", "make_limit_analogies", "(", "emb_dir", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"ud\"", ",", "analogies", ")", "\n", "save_collection", "(", "collection_path", ",", "analogies", ")", "\n", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", "[", "done_alphas", ":", "]", ",", "desc", "=", "\"u+v-alpha-loop\"", ")", ":", "\n", "        ", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"u\"", ",", "analogies", ")", "\n", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"0\"", ",", "analogies", ")", "\n", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"ud\"", ",", "analogies", ")", "\n", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "Ius", ",", "Ius_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"us\"", ",", "analogies", ")", "\n", "save_collection", "(", "collection_path", ",", "analogies", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.calc_log_analog": [[89, 96], ["evaluate_analogies.analogies_calc_and_org", "evaluate_analogies.analogies_calc_and_org"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org"], ["", "", "def", "calc_log_analog", "(", "embs", ",", "Id", ",", "g", ",", "vocab", ",", "emb_name", ",", "analogies", "=", "{", "}", ")", ":", "\n", "\n", "    ", "method_name", "=", "emb_name", "+", "\"-I\"", "\n", "analogies_calc_and_org", "(", "method_name", ",", "embs", ",", "Id", ",", "vocab", "=", "vocab", ",", "analogies", "=", "analogies", ")", "\n", "\n", "method_name", "=", "emb_name", "+", "\"-F\"", "\n", "analogies_calc_and_org", "(", "method_name", ",", "embs", ",", "g", ",", "vocab", "=", "vocab", ",", "analogies", "=", "analogies", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org": [[101, 120], ["stream_logger.info", "stream_logger.info", "core.measures.evaluate_analogies", "stream_logger.info", "stream_logger.info", "[].append", "analogies.get", "analogies[].get"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.evaluate_analogies"], ["", "def", "analogies_calc_and_org", "(", "method_name", ",", "W", ",", "g", ",", "vocab", ",", "analogies", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "\n", "    ", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "vocab", "\n", "\n", "", "stream_logger", ".", "info", "(", "method_name", ")", "\n", "stream_logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "acc", "=", "evaluate_analogies", "(", "vocab", ",", "W", ",", "g", ",", "stream_logger", ",", "filter_dictionary", ")", "\n", "stream_logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "stream_logger", ".", "info", "(", "\"\"", ")", "\n", "\n", "for", "task", "in", "acc", ":", "\n", "        ", "if", "analogies", ".", "get", "(", "task", ",", "None", ")", "is", "None", ":", "\n", "            ", "analogies", "[", "task", "]", "=", "{", "}", "\n", "\n", "", "if", "analogies", "[", "task", "]", ".", "get", "(", "method_name", ",", "None", ")", "is", "None", ":", "\n", "            ", "analogies", "[", "task", "]", "[", "method_name", "]", "=", "[", "]", "\n", "\n", "", "analogies", "[", "task", "]", "[", "method_name", "]", ".", "append", "(", "acc", "[", "task", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_analogies_fn": [[122, 150], ["stream_logger.info", "os.path.join", "core.load_embeddings.load_embeddings_ldv_hdf", "numpy.eye", "numpy.matmul().transpose", "evaluate_analogies.calc_log_analog", "core.measures.center_and_normalize_riemannian", "evaluate_analogies.calc_log_analog", "core.measures.center_and_normalize_riemannian", "evaluate_analogies.calc_log_analog", "emb_name.split", "numpy.matmul", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_embeddings_ldv_hdf", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.calc_log_analog", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.calc_log_analog", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.calc_log_analog"], ["", "", "def", "make_analogies_fn", "(", "emb_dir", ",", "ldv_filename", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "analogies", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "stream_logger", ".", "info", "(", "ldv_filename", ")", "\n", "ldv_path", "=", "os", ".", "path", ".", "join", "(", "emb_dir", ",", "ldv_filename", ")", "\n", "ldv", "=", "load_embeddings_ldv_hdf", "(", "ldv_path", ")", "\n", "Id", "=", "np", ".", "eye", "(", "ldv", ".", "shape", "[", "1", "]", ")", "\n", "plog", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "transpose", "(", "ldv", ")", ")", ".", "transpose", "(", ")", "\n", "\n", "en", "=", "emb_name", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "full_name", "=", "prefix", "+", "en", "+", "\"-plog-\"", "+", "point_name", "\n", "\n", "calc_log_analog", "(", "plog", ",", "Id", ",", "I", ",", "vocab", ",", "emb_name", "=", "full_name", ",", "analogies", "=", "analogies", ")", "\n", "\n", "# # STANDARDIZE", "\n", "# plog_std = standardize_riemannian(plog, I)", "\n", "# calc_log_analog(plog_std, Id, I, vocab, emb_name=full_name+\"-stF\", analogies=analogies)", "\n", "#", "\n", "# plog_std = standardize_riemannian(plog, Id)", "\n", "# calc_log_analog(plog_std, Id, I, vocab, emb_name=full_name+\"-stI\", analogies=analogies)", "\n", "#", "\n", "# del plog_std", "\n", "# gc.collect()", "\n", "\n", "# NORMALIZE", "\n", "plog_cn", "=", "center_and_normalize_riemannian", "(", "plog", ",", "Id", ",", "center", "=", "False", ")", "\n", "calc_log_analog", "(", "plog_cn", ",", "Id", ",", "I", ",", "vocab", ",", "emb_name", "=", "full_name", "+", "\"-nI\"", ",", "analogies", "=", "analogies", ")", "\n", "\n", "plog_cn", "=", "center_and_normalize_riemannian", "(", "plog", ",", "I", ",", "center", "=", "False", ")", "\n", "calc_log_analog", "(", "plog_cn", ",", "Id", ",", "I", ",", "vocab", ",", "emb_name", "=", "full_name", "+", "\"-nF\"", ",", "analogies", "=", "analogies", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_alpha_analogies": [[158, 161], ["core.load_embeddings.get_alpha_ldv_name", "evaluate_analogies.make_analogies_fn"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_analogies_fn"], ["", "def", "make_alpha_analogies", "(", "emb_dir", ",", "alpha", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "analogies", "=", "{", "}", ")", ":", "\n", "    ", "ldv_filename", "=", "get_alpha_ldv_name", "(", "alpha", ",", "emb_name", ",", "point_name", ")", "\n", "make_analogies_fn", "(", "emb_dir", ",", "ldv_filename", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "analogies", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_limit_analogies": [[163, 166], ["core.load_embeddings.get_limit_ldv_name", "evaluate_analogies.make_analogies_fn"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_limit_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_analogies_fn"], ["", "def", "make_limit_analogies", "(", "emb_dir", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "analogies", "=", "{", "}", ")", ":", "\n", "    ", "ldv_filename", "=", "get_limit_ldv_name", "(", "emb_name", ",", "point_name", ")", "\n", "make_analogies_fn", "(", "emb_dir", ",", "ldv_filename", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "analogies", ",", "prefix", "=", "\"limit-\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.make_base_analogies": [[168, 215], ["core.load_embeddings.get_glove_cc_fnames", "core.load_embeddings.get_suffix", "os.path.join", "print", "open", "pickle.load", "print", "evaluate_analogies.calculate_or_load_common_base", "core.load_embeddings.load_glove", "numpy.eye", "evaluate_analogies.analogies_calc_and_org", "evaluate_analogies.analogies_calc_and_org", "evaluate_analogies.analogies_calc_and_org", "evaluate_analogies.analogies_calc_and_org", "print", "core.measures.center_and_normalize_eucl", "core.measures.center_and_normalize_eucl", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_glove_cc_fnames", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calculate_or_load_common_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "def", "make_base_analogies", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "dictionary", ",", "baseoutdir", ")", ":", "\n", "\n", "    ", "fnamevc", ",", "fnamecc", "=", "get_glove_cc_fnames", "(", "corpus", ")", "\n", "\n", "suffix", "=", "get_suffix", "(", "vecsize", ",", "nepoch", ")", "\n", "gname", "=", "corpus", "+", "suffix", "\n", "\n", "outdirname", "=", "os", ".", "path", ".", "join", "(", "baseoutdir", ",", "gname", ")", "\n", "\n", "base_pkl_name", "=", "outdirname", "+", "\"/base-analogies.pkl\"", "\n", "\n", "try", ":", "\n", "\n", "        ", "with", "open", "(", "base_pkl_name", ",", "'rb'", ")", "as", "fstream", ":", "\n", "            ", "base_analogs", "=", "pickle", ".", "load", "(", "fstream", ")", "\n", "\n", "", "print", "(", "\"successfully opened base analogies\"", ")", "\n", "\n", "", "except", ":", "\n", "\n", "        ", "print", "(", "\"failed to open base analogies, calculating it:\"", ")", "\n", "\n", "base_analogs", "=", "{", "}", "\n", "calculate_or_load_common_base", "(", "fnamecc", ",", "dictionary", ",", "baseoutdir", ",", "base_analogs", ")", "\n", "\n", "g_dict", ",", "g_vecs", ",", "_", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ")", "\n", "\n", "Id", "=", "np", ".", "eye", "(", "g_vecs", "[", "\"u\"", "]", ".", "shape", "[", "1", "]", ")", "\n", "\n", "analogies_calc_and_org", "(", "\"u\"", ",", "g_vecs", "[", "\"u\"", "]", ",", "Id", ",", "\n", "dictionary", ",", "analogies", "=", "base_analogs", ")", "\n", "\n", "# store u vecs, center them and then check u is not changed", "\n", "analogies_calc_and_org", "(", "\"u-cn\"", ",", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"u\"", "]", ",", "True", ",", "False", ",", "0", ")", ",", "Id", ",", "\n", "dictionary", ",", "analogies", "=", "base_analogs", ")", "\n", "\n", "\n", "analogies_calc_and_org", "(", "\"u+v\"", ",", "g_vecs", "[", "\"u\"", "]", "+", "g_vecs", "[", "\"v\"", "]", ",", "Id", ",", "\n", "dictionary", ",", "analogies", "=", "base_analogs", ")", "\n", "analogies_calc_and_org", "(", "\"u+v-cn\"", ",", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"u\"", "]", "+", "g_vecs", "[", "\"v\"", "]", ",", "True", ",", "False", ",", "0", ")", ",", "Id", ",", "\n", "dictionary", ",", "analogies", "=", "base_analogs", ")", "\n", "\n", "print", "(", "\"done base analogies\"", ")", "\n", "with", "open", "(", "base_pkl_name", ",", "'wb'", ")", "as", "fstream", ":", "\n", "            ", "pickle", ".", "dump", "(", "base_analogs", ",", "fstream", ")", "\n", "\n", "", "", "return", "base_analogs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.calculate_or_load_common_base": [[217, 275], ["core.measures.merge_dicts", "os.path.splitext", "print", "os.path.basename", "open", "pickle.load", "print", "print", "core.load_embeddings.load_pretrained_glove", "numpy.eye", "evaluate_analogies.analogies_calc_and_org", "evaluate_analogies.analogies_calc_and_org", "print", "core.measures.center_and_normalize_eucl", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.measures.merge_dicts", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_pretrained_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies.analogies_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "def", "calculate_or_load_common_base", "(", "fnamecc", ",", "dictionary", ",", "baseoutdir", ",", "corrs", ")", ":", "\n", "\n", "    ", "_id", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "fnamecc", ")", ")", "[", "0", "]", "\n", "\n", "# NB common base name must depend on the embedding at hand, since the dictionary changes", "\n", "common_base", "=", "baseoutdir", "+", "\"/\"", "+", "_id", "+", "\"-base_analogies.pkl\"", "\n", "\n", "try", ":", "\n", "        ", "print", "(", "\"successfully opened common base\"", ")", "\n", "with", "open", "(", "common_base", ",", "'rb'", ")", "as", "fstream", ":", "\n", "            ", "cb_analogs", "=", "pickle", ".", "load", "(", "fstream", ")", "\n", "\n", "", "", "except", ":", "\n", "\n", "        ", "print", "(", "\"failed to open common base, calculating it:\"", ")", "\n", "cb_analogs", "=", "{", "}", "\n", "\n", "# # stupid method for analogies", "\n", "# C = read_cooccurrences_from_c(fnamecc)", "\n", "# p_w, p_cIw = compute_p_cIw_from_counts(C)", "\n", "# Id = np.eye(p_cIw.shape[1])", "\n", "# # def simeval(ind1, ind2):", "\n", "# #     return riemannian_cosprod(center_and_normalize_eucl(p_cIw, True, False, 0), Id, ind1, ind2)", "\n", "# p_cIw = center_and_normalize_eucl(p_cIw, True, False, 0)", "\n", "# analogies_calc_and_org(\"p_cIw-cn\", p_cIw, Id, dictionary, analogies=cb_analogs)", "\n", "#", "\n", "# del p_cIw, C, p_w", "\n", "# gc.collect()", "\n", "# # stupid method for analogies", "\n", "\n", "print", "(", "\"calculating wikigiga5\"", ")", "\n", "g_dict", ",", "g_vecs", "=", "load_pretrained_glove", "(", "\"wikigiga5\"", ")", "\n", "# def simeval(ind1, ind2):", "\n", "#     return euclidean_cosprod(center_and_normalize_eucl(g_vecs[\"u\"], True, False, 0), ind1, ind2)", "\n", "Id", "=", "np", ".", "eye", "(", "g_vecs", "[", "\"u\"", "]", ".", "shape", "[", "1", "]", ")", "\n", "analogies_calc_and_org", "(", "\"wikigiga5-u+v\"", ",", "g_vecs", "[", "\"u\"", "]", ",", "Id", ",", "\n", "g_dict", ",", "analogies", "=", "cb_analogs", ",", "filter_dictionary", "=", "dictionary", ")", "\n", "analogies_calc_and_org", "(", "\"wikigiga5-u+v-n\"", ",", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"u\"", "]", ",", "False", ",", "False", ",", "0", ")", ",", "Id", ",", "\n", "g_dict", ",", "analogies", "=", "cb_analogs", ",", "filter_dictionary", "=", "dictionary", ")", "\n", "\n", "# # COMMON CRAWL", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl42B\")", "\n", "# similarity_euclidean_preproc(g_vecs[\"u\"], \"commoncrawl42B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=v_dictionary)", "\n", "#", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl840B\")", "\n", "# keys_a = set(g_dict.keys())", "\n", "# keys_b = set(v_dictionary.keys())", "\n", "# intersection_keys = keys_a & keys_b", "\n", "# similarity_euclidean_preproc(g_vecs[\"u\"], \"commoncrawl840B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=intersection_keys)", "\n", "\n", "print", "(", "\"done common base\"", ")", "\n", "\n", "with", "open", "(", "common_base", ",", "'wb'", ")", "as", "fstream", ":", "\n", "            ", "pickle", ".", "dump", "(", "cb_analogs", ",", "fstream", ")", "\n", "\n", "", "", "merge_dicts", "(", "corrs", ",", "cb_analogs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.main": [[20, 90], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.basename", "os.path.basename.split", "int", "int", "os.path.join", "os.makedirs", "mylogging.init_logger", "core.load_embeddings.load_dict", "evaluate_similarities.make_base_sims", "core.load_embeddings.load_all_emb_base", "numpy.linalg.inv", "numpy.linalg.inv", "numpy.linalg.inv", "numpy.linalg.inv", "core.results_collection.load_collection_and_backup", "core.results_collection.check_done_in_collection", "tqdm.tqdm", "core.results_collection.check_done_in_collection", "tqdm.tqdm", "os.path.normpath", "evaluate_similarities.make_limit_sims", "evaluate_similarities.make_limit_sims", "evaluate_similarities.make_limit_sims", "core.results_collection.save_collection", "evaluate_similarities.make_alpha_sims", "evaluate_similarities.make_alpha_sims", "evaluate_similarities.make_alpha_sims", "core.results_collection.save_collection", "evaluate_similarities.make_limit_sims", "evaluate_similarities.make_limit_sims", "evaluate_similarities.make_limit_sims", "evaluate_similarities.make_limit_sims", "core.results_collection.save_collection", "evaluate_similarities.make_alpha_sims", "evaluate_similarities.make_alpha_sims", "evaluate_similarities.make_alpha_sims", "evaluate_similarities.make_alpha_sims", "core.results_collection.save_collection"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.mylogging.init_logger", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_dict", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_base_sims", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_all_emb_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.load_collection_and_backup", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.check_done_in_collection", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.check_done_in_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims", "home.repos.pwc.inspect_result.rist-ro_argo.core.results_collection.save_collection"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'embdir'", ",", "type", "=", "str", ",", "help", "=", "\"directory where to find structure of embeddings\"", ")", "\n", "parser", ".", "add_argument", "(", "'--outputdir'", ",", "'-o'", ",", "help", "=", "'outputdir'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "emb_dir", "=", "args", ".", "embdir", "\n", "baseoutdir", "=", "args", ".", "outputdir", "\n", "\n", "emb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "corpus", ",", "vstr", ",", "nstr", "=", "emb_id", ".", "split", "(", "'-'", ")", "\n", "vecsize", "=", "int", "(", "vstr", "[", "1", ":", "]", ")", "\n", "nepoch", "=", "int", "(", "nstr", "[", "1", ":", "]", ")", "\n", "\n", "emboutdirname", "=", "os", ".", "path", ".", "join", "(", "baseoutdir", ",", "emb_id", ")", "\n", "os", ".", "makedirs", "(", "emboutdirname", ",", "exist_ok", "=", "True", ")", "\n", "\n", "global", "stream_logger", "\n", "stream_logger", "=", "init_logger", "(", "emboutdirname", "+", "\"/similarities.log\"", ")", "\n", "\n", "vocab", ",", "ivocab", ",", "vocab_size", "=", "load_dict", "(", "emb_dir", ")", "\n", "\n", "# BASE SIMILARITIES", "\n", "make_base_sims", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "vocab", ",", "baseoutdir", ")", "\n", "\n", "# ALPHA SIMILARITIES", "\n", "alphas", ",", "I0", ",", "Iu", ",", "Iud", ",", "Ius", "=", "load_all_emb_base", "(", "emb_dir", ")", "\n", "\n", "I0_inv", "=", "np", ".", "linalg", ".", "inv", "(", "I0", ")", "\n", "Iu_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iu", ")", "\n", "Iud_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Iud", ")", "\n", "Ius_inv", "=", "np", ".", "linalg", ".", "inv", "(", "Ius", ")", "\n", "\n", "\n", "collection_path", "=", "emboutdirname", "+", "\"/alpha-similarities.pkl\"", "\n", "correlations", "=", "load_collection_and_backup", "(", "collection_path", ")", "\n", "\n", "# 3 points, 6 things, expected 18", "\n", "done_alphas", ",", "done_limit", "=", "check_done_in_collection", "(", "correlations", ",", "alphas", ",", "\"u-plog\"", ",", "18", ")", "\n", "\n", "if", "not", "done_limit", ":", "\n", "        ", "make_limit_sims", "(", "emb_dir", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"0\"", ",", "correlations", ")", "\n", "make_limit_sims", "(", "emb_dir", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"u\"", ",", "correlations", ")", "\n", "make_limit_sims", "(", "emb_dir", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"ud\"", ",", "correlations", ")", "\n", "save_collection", "(", "collection_path", ",", "correlations", ")", "\n", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", "[", "done_alphas", ":", "]", ",", "desc", "=", "\"u-alpha-loop\"", ")", ":", "\n", "        ", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"0\"", ",", "correlations", ")", "\n", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"u\"", ",", "correlations", ")", "\n", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u_embeddings\"", ",", "\"ud\"", ",", "correlations", ")", "\n", "save_collection", "(", "collection_path", ",", "correlations", ")", "\n", "\n", "\n", "# 4 points, 6 things, expected 24", "\n", "", "done_alphas", ",", "done_limit", "=", "check_done_in_collection", "(", "correlations", ",", "alphas", ",", "\"u+v-plog\"", ",", "24", ")", "\n", "\n", "if", "not", "done_limit", ":", "\n", "        ", "make_limit_sims", "(", "emb_dir", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"0\"", ",", "correlations", ")", "\n", "make_limit_sims", "(", "emb_dir", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"u\"", ",", "correlations", ")", "\n", "make_limit_sims", "(", "emb_dir", ",", "Ius", ",", "Ius_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"us\"", ",", "correlations", ")", "\n", "make_limit_sims", "(", "emb_dir", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"ud\"", ",", "correlations", ")", "\n", "save_collection", "(", "collection_path", ",", "correlations", ")", "\n", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", "[", "done_alphas", ":", "]", ",", "desc", "=", "\"u+v-alpha-loop\"", ")", ":", "\n", "        ", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "Iu", ",", "Iu_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"u\"", ",", "correlations", ")", "\n", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "I0", ",", "I0_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"0\"", ",", "correlations", ")", "\n", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "Iud", ",", "Iud_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"ud\"", ",", "correlations", ")", "\n", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "Ius", ",", "Ius_inv", ",", "vocab", ",", "\"u+v_embeddings\"", ",", "\"us\"", ",", "correlations", ")", "\n", "save_collection", "(", "collection_path", ",", "correlations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org": [[93, 112], ["stream_logger.info", "stream_logger.info", "core.measures.evaluate_similarities", "stream_logger.info", "stream_logger.info", "[].append", "correlations.get", "correlations[].get"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.evaluate_similarities"], ["", "", "def", "similarity_calc_and_org", "(", "method_name", ",", "W", ",", "g", ",", "vocab", ",", "correlations", ",", "filter_dictionary", "=", "None", ")", ":", "\n", "\n", "    ", "if", "filter_dictionary", "is", "None", ":", "\n", "        ", "filter_dictionary", "=", "vocab", "\n", "\n", "", "stream_logger", ".", "info", "(", "method_name", ")", "\n", "stream_logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "sc", ",", "corr", "=", "evaluate_similarities", "(", "vocab", ",", "W", ",", "g", ",", "stream_logger", ",", "filter_dictionary", ",", "datasets", "=", "[", "]", ",", "plot", "=", "False", ")", "\n", "stream_logger", ".", "info", "(", "\"---------------------------------------------------------------------------\"", ")", "\n", "stream_logger", ".", "info", "(", "\"\"", ")", "\n", "\n", "for", "task", "in", "corr", ":", "\n", "        ", "if", "correlations", ".", "get", "(", "task", ",", "None", ")", "is", "None", ":", "\n", "            ", "correlations", "[", "task", "]", "=", "{", "}", "\n", "\n", "", "if", "correlations", "[", "task", "]", ".", "get", "(", "method_name", ",", "None", ")", "is", "None", ":", "\n", "            ", "correlations", "[", "task", "]", "[", "method_name", "]", "=", "[", "]", "\n", "\n", "", "correlations", "[", "task", "]", "[", "method_name", "]", ".", "append", "(", "corr", "[", "task", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calc_log_sims": [[131, 138], ["evaluate_similarities.similarity_calc_and_org", "evaluate_similarities.similarity_calc_and_org"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org"], ["", "", "def", "calc_log_sims", "(", "embs", ",", "Id", ",", "g", ",", "vocab", ",", "emb_name", ",", "correlations", "=", "{", "}", ")", ":", "\n", "\n", "    ", "method_name", "=", "emb_name", "+", "\"-I\"", "\n", "similarity_calc_and_org", "(", "method_name", ",", "embs", ",", "Id", ",", "vocab", "=", "vocab", ",", "correlations", "=", "correlations", ")", "\n", "\n", "method_name", "=", "emb_name", "+", "\"-F\"", "\n", "similarity_calc_and_org", "(", "method_name", ",", "embs", ",", "g", ",", "vocab", "=", "vocab", ",", "correlations", "=", "correlations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_sims_fn": [[143, 183], ["stream_logger.info", "os.path.join", "core.load_embeddings.load_embeddings_ldv_hdf", "numpy.eye", "numpy.matmul().transpose", "evaluate_similarities.calc_log_sims", "core.measures.center_and_normalize_riemannian", "evaluate_similarities.calc_log_sims", "core.measures.center_and_normalize_riemannian", "evaluate_similarities.calc_log_sims", "emb_name.split", "numpy.matmul", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_embeddings_ldv_hdf", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calc_log_sims", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calc_log_sims", "home.repos.pwc.inspect_result.rist-ro_argo.core.measures.center_and_normalize_riemannian", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calc_log_sims"], ["", "def", "make_sims_fn", "(", "ldv_filename", ",", "emb_dir", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "correlations", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "stream_logger", ".", "info", "(", "ldv_filename", ")", "\n", "\n", "ldv_path", "=", "os", ".", "path", ".", "join", "(", "emb_dir", ",", "ldv_filename", ")", "\n", "ldv", "=", "load_embeddings_ldv_hdf", "(", "ldv_path", ")", "\n", "Id", "=", "np", ".", "eye", "(", "ldv", ".", "shape", "[", "1", "]", ")", "\n", "plog", "=", "np", ".", "matmul", "(", "I_inv", ",", "np", ".", "transpose", "(", "ldv", ")", ")", ".", "transpose", "(", ")", "\n", "\n", "en", "=", "emb_name", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "full_name", "=", "prefix", "+", "en", "+", "\"-plog-\"", "+", "point_name", "\n", "\n", "# ldv commented", "\n", "# calc_log_sims(ldv, Id, I_inv, vocab, emb_name=\"ldv-\"+point_name+\"-st0\", correlations=correlations)", "\n", "# ldv commented", "\n", "\n", "calc_log_sims", "(", "plog", ",", "Id", ",", "I", ",", "vocab", ",", "emb_name", "=", "full_name", ",", "correlations", "=", "correlations", ")", "\n", "\n", "# STANDARDIZE FROM HERE", "\n", "# ldv commented", "\n", "# d0 = (np.sum(ldv ** 2, axis=0) ** (0.5))", "\n", "# ldv_std = ldv / d0.reshape(1, -1)", "\n", "# calc_log_sims(ldv_std, Id, I_inv, vocab, emb_name=\"ldv-\"+point_name+\"-st1\", correlations=correlations)", "\n", "# ldv commented", "\n", "\n", "# # STANDARDIZE", "\n", "# plog_std = standardize_riemannian(plog, I)", "\n", "# calc_log_sims(plog_std, Id, I, vocab, emb_name=full_name+\"-stF\", correlations=correlations)", "\n", "#", "\n", "# plog_std = standardize_riemannian(plog, Id)", "\n", "# calc_log_sims(plog_std, Id, I, vocab, emb_name=full_name+\"-stI\", correlations=correlations)", "\n", "#", "\n", "# del plog_std", "\n", "# gc.collect()", "\n", "\n", "# NORMALIZE", "\n", "plog_cn", "=", "center_and_normalize_riemannian", "(", "plog", ",", "Id", ")", "\n", "calc_log_sims", "(", "plog_cn", ",", "Id", ",", "I", ",", "vocab", ",", "emb_name", "=", "full_name", "+", "\"-cnI\"", ",", "correlations", "=", "correlations", ")", "\n", "\n", "plog_cn", "=", "center_and_normalize_riemannian", "(", "plog", ",", "I", ")", "\n", "calc_log_sims", "(", "plog_cn", ",", "Id", ",", "I", ",", "vocab", ",", "emb_name", "=", "full_name", "+", "\"-cnF\"", ",", "correlations", "=", "correlations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_alpha_sims": [[192, 196], ["core.load_embeddings.get_alpha_ldv_name", "evaluate_similarities.make_sims_fn"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_sims_fn"], ["", "def", "make_alpha_sims", "(", "emb_dir", ",", "alpha", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "correlations", "=", "{", "}", ")", ":", "\n", "# point_name is either \"0\" or \"u\"", "\n", "    ", "ldv_filename", "=", "get_alpha_ldv_name", "(", "alpha", ",", "emb_name", ",", "point_name", ")", "\n", "make_sims_fn", "(", "ldv_filename", ",", "emb_dir", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "correlations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_limit_sims": [[198, 202], ["core.load_embeddings.get_limit_ldv_name", "evaluate_similarities.make_sims_fn"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_limit_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_sims_fn"], ["", "def", "make_limit_sims", "(", "emb_dir", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "correlations", "=", "{", "}", ")", ":", "\n", "# point_name is either \"0\" or \"u\"", "\n", "    ", "ldv_filename", "=", "get_limit_ldv_name", "(", "emb_name", ",", "point_name", ")", "\n", "make_sims_fn", "(", "ldv_filename", ",", "emb_dir", ",", "I", ",", "I_inv", ",", "vocab", ",", "emb_name", ",", "point_name", ",", "correlations", ",", "prefix", "=", "\"limit-\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.make_base_sims": [[204, 243], ["core.load_embeddings.get_glove_cc_fnames", "core.load_embeddings.get_suffix", "os.path.join", "open", "pickle.load", "evaluate_similarities.calculate_or_load_common_base", "core.load_embeddings.load_glove", "numpy.eye", "evaluate_similarities.similarity_calc_and_org", "evaluate_similarities.similarity_calc_and_org", "core.measures.center_and_normalize_eucl", "core.measures.center_and_normalize_eucl", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_glove_cc_fnames", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calculate_or_load_common_base", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "def", "make_base_sims", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "dictionary", ",", "baseoutdir", ")", ":", "\n", "\n", "    ", "fnamevc", ",", "fnamecc", "=", "get_glove_cc_fnames", "(", "corpus", ")", "\n", "\n", "suffix", "=", "get_suffix", "(", "vecsize", ",", "nepoch", ")", "\n", "gname", "=", "corpus", "+", "suffix", "\n", "\n", "outdirname", "=", "os", ".", "path", ".", "join", "(", "baseoutdir", ",", "gname", ")", "\n", "\n", "base_pkl_name", "=", "outdirname", "+", "\"/base-similarities.pkl\"", "\n", "\n", "try", ":", "\n", "        ", "with", "open", "(", "base_pkl_name", ",", "'rb'", ")", "as", "fstream", ":", "\n", "            ", "base_sims", "=", "pickle", ".", "load", "(", "fstream", ")", "\n", "\n", "", "", "except", ":", "\n", "\n", "        ", "base_sims", "=", "{", "}", "\n", "calculate_or_load_common_base", "(", "fnamecc", ",", "dictionary", ",", "baseoutdir", ",", "base_sims", ")", "\n", "\n", "g_dict", ",", "g_vecs", ",", "_", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ")", "\n", "\n", "Id", "=", "np", ".", "eye", "(", "g_vecs", "[", "\"u\"", "]", ".", "shape", "[", "1", "]", ")", "\n", "# def simeval(ind1, ind2):", "\n", "#     return riemannian_cosprod(center_and_normalize_eucl(g_vecs[\"u\"], True, False, 0), Id, ind1, ind2)", "\n", "similarity_calc_and_org", "(", "\"u-cn\"", ",", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"u\"", "]", ",", "True", ",", "False", ",", "0", ")", ",", "Id", ",", "dictionary", ",", "\n", "correlations", "=", "base_sims", ")", "\n", "\n", "# def simeval(ind1, ind2):", "\n", "#     return euclidean_cosprod(center_and_normalize_eucl(g_vecs[\"u\"] + g_vecs[\"v\"], True, False, 0), ind1, ind2)", "\n", "\n", "similarity_calc_and_org", "(", "\"u+v-cn\"", ",", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"u\"", "]", "+", "g_vecs", "[", "\"v\"", "]", ",", "True", ",", "False", ",", "0", ")", ",", "Id", ",", "\n", "dictionary", ",", "correlations", "=", "base_sims", ")", "\n", "\n", "\n", "with", "open", "(", "base_pkl_name", ",", "'wb'", ")", "as", "fstream", ":", "\n", "            ", "pickle", ".", "dump", "(", "base_sims", ",", "fstream", ")", "\n", "\n", "", "", "return", "base_sims", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.calculate_or_load_common_base": [[245, 303], ["core.measures.merge_dicts", "os.path.splitext", "print", "os.path.basename", "open", "pickle.load", "print", "print", "core.load_embeddings.read_cooccurrences_from_c", "core.load_embeddings.compute_p_cIw_from_counts", "numpy.eye", "core.measures.center_and_normalize_eucl", "evaluate_similarities.similarity_calc_and_org", "gc.collect", "print", "core.load_embeddings.load_pretrained_glove", "numpy.eye", "evaluate_similarities.similarity_calc_and_org", "print", "core.measures.center_and_normalize_eucl", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.measures.merge_dicts", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.Boston.load", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.read_cooccurrences_from_c", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.compute_p_cIw_from_counts", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_pretrained_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_similarities.similarity_calc_and_org", "home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.center_and_normalize_eucl"], ["", "def", "calculate_or_load_common_base", "(", "fnamecc", ",", "dictionary", ",", "baseoutdir", ",", "corrs", ")", ":", "\n", "\n", "    ", "_id", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "fnamecc", ")", ")", "[", "0", "]", "\n", "\n", "# NB common base name must depend on the embedding at hand, since the dictionary changes", "\n", "common_base", "=", "baseoutdir", "+", "\"/\"", "+", "_id", "+", "\"-base_similarities.pkl\"", "\n", "\n", "try", ":", "\n", "        ", "with", "open", "(", "common_base", ",", "'rb'", ")", "as", "fstream", ":", "\n", "            ", "cb_corrs", "=", "pickle", ".", "load", "(", "fstream", ")", "\n", "\n", "", "print", "(", "\"successfully opened common base\"", ")", "\n", "\n", "", "except", ":", "\n", "\n", "        ", "cb_corrs", "=", "{", "}", "\n", "\n", "print", "(", "\"failed to open common base, calculating it:\"", ")", "\n", "\n", "print", "(", "\"calculating pcIw\"", ")", "\n", "C", "=", "read_cooccurrences_from_c", "(", "fnamecc", ")", "\n", "p_w", ",", "p_cIw", "=", "compute_p_cIw_from_counts", "(", "C", ")", "\n", "Id", "=", "np", ".", "eye", "(", "p_cIw", ".", "shape", "[", "1", "]", ")", "\n", "# def simeval(ind1, ind2):", "\n", "#     return riemannian_cosprod(center_and_normalize_eucl(p_cIw, True, False, 0), Id, ind1, ind2)", "\n", "p_cIw", "=", "center_and_normalize_eucl", "(", "p_cIw", ",", "True", ",", "False", ",", "0", ")", "\n", "similarity_calc_and_org", "(", "\"p_cIw-cn\"", ",", "p_cIw", ",", "Id", ",", "dictionary", ",", "correlations", "=", "cb_corrs", ")", "\n", "\n", "del", "p_cIw", ",", "C", ",", "p_w", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "print", "(", "\"calculating wikigiga5\"", ")", "\n", "g_dict", ",", "g_vecs", "=", "load_pretrained_glove", "(", "\"wikigiga5\"", ")", "\n", "# def simeval(ind1, ind2):", "\n", "#     return euclidean_cosprod(center_and_normalize_eucl(g_vecs[\"u\"], True, False, 0), ind1, ind2)", "\n", "Id", "=", "np", ".", "eye", "(", "g_vecs", "[", "\"u\"", "]", ".", "shape", "[", "1", "]", ")", "\n", "similarity_calc_and_org", "(", "\"wikigiga5-u+v\"", ",", "center_and_normalize_eucl", "(", "g_vecs", "[", "\"u\"", "]", ",", "False", ",", "False", ",", "0", ")", ",", "Id", ",", "\n", "g_dict", ",", "correlations", "=", "cb_corrs", ",", "filter_dictionary", "=", "dictionary", ")", "\n", "\n", "# # COMMON CRAWL", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl42B\")", "\n", "# similarity_euclidean_preproc(g_vecs[\"u\"], \"commoncrawl42B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=v_dictionary)", "\n", "#", "\n", "# g_dict, g_vecs = load_pretrained_glove(\"commoncrawl840B\")", "\n", "# keys_a = set(g_dict.keys())", "\n", "# keys_b = set(v_dictionary.keys())", "\n", "# intersection_keys = keys_a & keys_b", "\n", "# similarity_euclidean_preproc(g_vecs[\"u\"], \"commoncrawl840B-u+v\", g_dict,", "\n", "#                      correlations=cb_corrs, y_data=cb_y_data, filter_dictionary=intersection_keys)", "\n", "\n", "print", "(", "\"done common base\"", ")", "\n", "\n", "with", "open", "(", "common_base", ",", "'wb'", ")", "as", "fstream", ":", "\n", "            ", "pickle", ".", "dump", "(", "cb_corrs", ",", "fstream", ")", "\n", "\n", "\n", "", "", "merge_dicts", "(", "corrs", ",", "cb_corrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_plain.main": [[6, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "numpy.zeros", "vectors.items", "evaluate_analogies_plain.evaluate_vectors", "open", "open", "core.load_embeddings.extract_embedding_from_params", "numpy.sum", "d1.reshape", "line.rstrip().split", "numpy.array", "enumerate", "enumerate", "x.rstrip().split", "f.readlines", "line.rstrip", "x.rstrip"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_plain.evaluate_vectors", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.extract_embedding_from_params"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'vectors_file'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_file'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--vec_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "int", ",", "choices", "=", "[", "0", ",", "1", ",", "2", "]", ",", "default", "=", "0", ")", "\n", "\n", "# mode", "\n", "# 0 standard, single embeddings are present", "\n", "# 1 u bu v bu, all parameters are present, I want to use u+v/2", "\n", "# 2 u bu v bu, all parameters are present, I want to use u", "\n", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "mode", "=", "args", ".", "mode", "\n", "vec_size", "=", "args", ".", "vec_size", "\n", "\n", "vocab_file", "=", "args", ".", "vocab_file", "\n", "if", "vocab_file", "is", "None", ":", "\n", "        ", "vocab_file", "=", "args", ".", "vectors_file", "\n", "\n", "", "with", "open", "(", "vocab_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "words", "=", "[", "x", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "x", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "args", ".", "vectors_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "vectors", "=", "{", "}", "\n", "for", "line", "in", "f", ":", "\n", "            ", "vals", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "\n", "vectors", "[", "vals", "[", "0", "]", "]", "=", "np", ".", "array", "(", "vals", "[", "1", ":", "]", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "", "", "vocab_size", "=", "len", "(", "words", ")", "\n", "vocab", "=", "{", "w", ":", "idx", "for", "idx", ",", "w", "in", "enumerate", "(", "words", ")", "}", "\n", "ivocab", "=", "{", "idx", ":", "w", "for", "idx", ",", "w", "in", "enumerate", "(", "words", ")", "}", "\n", "\n", "# vector_dim = len(vectors[ivocab[0]])", "\n", "\n", "W", "=", "np", ".", "zeros", "(", "(", "vocab_size", ",", "vec_size", ")", ")", "\n", "for", "word", ",", "parameters", "in", "vectors", ".", "items", "(", ")", ":", "\n", "# if word == '<unk>':", "\n", "#     continue", "\n", "        ", "W", "[", "vocab", "[", "word", "]", ",", ":", "]", "=", "extract_embedding_from_params", "(", "parameters", ",", "vec_size", ",", "mode", ")", "\n", "\n", "# normalize each word vector to unit variance", "\n", "# W_norm = np.zeros(W.shape)", "\n", "# d0 = (np.sum(W ** 2, axis=0) ** (0.5))", "\n", "", "d1", "=", "(", "np", ".", "sum", "(", "W", "**", "2", ",", "axis", "=", "1", ")", "**", "(", "0.5", ")", ")", "\n", "# import pdb;pdb.set_trace()", "\n", "# w_mean = np.mean(W, axis=1).reshape(-1,1)", "\n", "# W_norm = (W-w_mean) / d0.reshape(1,-1)", "\n", "# W_norm = W_norm / d1.reshape(-1,1)", "\n", "\n", "W_norm", "=", "W", "\n", "# d1 = (np.sum(W_norm ** 2, axis=1) ** (0.5))", "\n", "# W_norm = W_norm / d0.reshape(1, -1)", "\n", "W_norm", "=", "W_norm", "/", "d1", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "# # ORIGINAL", "\n", "# # normalize each word vector to unit variance", "\n", "# d = (np.sum(W ** 2, 1) ** (0.5))", "\n", "# W_norm = (W.T / d).T", "\n", "# # ORIGINAL", "\n", "\n", "evaluate_vectors", "(", "W_norm", ",", "vocab", ",", "ivocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_plain.evaluate_vectors": [[71, 143], ["range", "print", "print", "print", "print", "len", "numpy.array", "numpy.zeros", "int", "range", "print", "print", "open", "len", "numpy.ceil", "numpy.arange", "numpy.dot", "range", "numpy.argmax().flatten", "len", "sum", "line.rstrip().split", "len", "min", "len", "len", "sum", "len", "sum", "all", "len", "float", "len", "numpy.argmax", "numpy.sum", "len", "float", "float", "float", "float", "line.rstrip", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "evaluate_vectors", "(", "W", ",", "vocab", ",", "ivocab", ")", ":", "\n", "    ", "\"\"\"Evaluate the trained word vectors on a variety of tasks\"\"\"", "\n", "\n", "filenames", "=", "[", "\n", "'capital-common-countries.txt'", ",", "'capital-world.txt'", ",", "'currency.txt'", ",", "\n", "'city-in-state.txt'", ",", "'family.txt'", ",", "'gram1-adjective-to-adverb.txt'", ",", "\n", "'gram2-opposite.txt'", ",", "'gram3-comparative.txt'", ",", "'gram4-superlative.txt'", ",", "\n", "'gram5-present-participle.txt'", ",", "'gram6-nationality-adjective.txt'", ",", "\n", "'gram7-past-tense.txt'", ",", "'gram8-plural.txt'", ",", "'gram9-plural-verbs.txt'", ",", "\n", "]", "\n", "prefix", "=", "'/data2/text/analogies_datasets'", "\n", "\n", "# to avoid memory overflow, could be increased/decreased", "\n", "# depending on system and vocab size", "\n", "split_size", "=", "100", "\n", "\n", "correct_sem", "=", "0", ";", "# count correct semantic questions", "\n", "correct_syn", "=", "0", ";", "# count correct syntactic questions", "\n", "correct_tot", "=", "0", "# count correct questions", "\n", "count_sem", "=", "0", ";", "# count all semantic questions", "\n", "count_syn", "=", "0", ";", "# count all syntactic questions", "\n", "count_tot", "=", "0", "# count all questions", "\n", "full_count", "=", "0", "# count all questions, including those with unknown words", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "filenames", ")", ")", ":", "\n", "        ", "with", "open", "(", "'%s/%s'", "%", "(", "prefix", ",", "filenames", "[", "i", "]", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "full_data", "=", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "for", "line", "in", "f", "]", "\n", "full_count", "+=", "len", "(", "full_data", ")", "\n", "data", "=", "[", "x", "for", "x", "in", "full_data", "if", "all", "(", "word", "in", "vocab", "for", "word", "in", "x", ")", "]", "\n", "\n", "", "indices", "=", "np", ".", "array", "(", "[", "[", "vocab", "[", "word", "]", "for", "word", "in", "row", "]", "for", "row", "in", "data", "]", ")", "\n", "ind1", ",", "ind2", ",", "ind3", ",", "ind4", "=", "indices", ".", "T", "\n", "\n", "predictions", "=", "np", ".", "zeros", "(", "(", "len", "(", "indices", ")", ",", ")", ")", "\n", "num_iter", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "indices", ")", "/", "float", "(", "split_size", ")", ")", ")", "\n", "for", "j", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "subset", "=", "np", ".", "arange", "(", "j", "*", "split_size", ",", "min", "(", "(", "j", "+", "1", ")", "*", "split_size", ",", "len", "(", "ind1", ")", ")", ")", "\n", "\n", "pred_vec", "=", "(", "W", "[", "ind2", "[", "subset", "]", ",", ":", "]", "-", "W", "[", "ind1", "[", "subset", "]", ",", ":", "]", "\n", "+", "W", "[", "ind3", "[", "subset", "]", ",", ":", "]", ")", "\n", "#cosine similarity if input W has been normalized", "\n", "dist", "=", "np", ".", "dot", "(", "W", ",", "pred_vec", ".", "T", ")", "\n", "\n", "for", "k", "in", "range", "(", "len", "(", "subset", ")", ")", ":", "\n", "                ", "dist", "[", "ind1", "[", "subset", "[", "k", "]", "]", ",", "k", "]", "=", "-", "np", ".", "Inf", "\n", "dist", "[", "ind2", "[", "subset", "[", "k", "]", "]", ",", "k", "]", "=", "-", "np", ".", "Inf", "\n", "dist", "[", "ind3", "[", "subset", "[", "k", "]", "]", ",", "k", "]", "=", "-", "np", ".", "Inf", "\n", "\n", "# predicted word index", "\n", "", "predictions", "[", "subset", "]", "=", "np", ".", "argmax", "(", "dist", ",", "0", ")", ".", "flatten", "(", ")", "\n", "\n", "", "val", "=", "(", "ind4", "==", "predictions", ")", "# correct predictions", "\n", "count_tot", "=", "count_tot", "+", "len", "(", "ind1", ")", "\n", "correct_tot", "=", "correct_tot", "+", "sum", "(", "val", ")", "\n", "if", "i", "<", "5", ":", "\n", "            ", "count_sem", "=", "count_sem", "+", "len", "(", "ind1", ")", "\n", "correct_sem", "=", "correct_sem", "+", "sum", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "count_syn", "=", "count_syn", "+", "len", "(", "ind1", ")", "\n", "correct_syn", "=", "correct_syn", "+", "sum", "(", "val", ")", "\n", "\n", "", "print", "(", "\"%s:\"", "%", "filenames", "[", "i", "]", ")", "\n", "print", "(", "'ACCURACY TOP1: %.2f%% (%d/%d)'", "%", "\n", "(", "np", ".", "mean", "(", "val", ")", "*", "100", ",", "np", ".", "sum", "(", "val", ")", ",", "len", "(", "val", ")", ")", ")", "\n", "\n", "", "print", "(", "'Questions seen/total: %.2f%% (%d/%d)'", "%", "\n", "(", "100", "*", "count_tot", "/", "float", "(", "full_count", ")", ",", "count_tot", ",", "full_count", ")", ")", "\n", "print", "(", "'Semantic accuracy: %.2f%%  (%i/%i)'", "%", "\n", "(", "100", "*", "correct_sem", "/", "float", "(", "count_sem", ")", ",", "correct_sem", ",", "count_sem", ")", ")", "\n", "print", "(", "'Syntactic accuracy: %.2f%%  (%i/%i)'", "%", "\n", "(", "100", "*", "correct_syn", "/", "float", "(", "count_syn", ")", ",", "correct_syn", ",", "count_syn", ")", ")", "\n", "print", "(", "'Total accuracy: %.2f%%  (%i/%i)'", "%", "(", "100", "*", "correct_tot", "/", "float", "(", "count_tot", ")", ",", "correct_tot", ",", "count_tot", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.calculate_all_embeddings": [[20, 121], ["core.load_embeddings.calculate_glove_prob", "os.path.basename", "calculate_alpha_vectors.well_cond_fisher_and_whatnot", "calculate_alpha_vectors.well_cond_fisher_and_whatnot", "calculate_alpha_vectors.well_cond_fisher_and_whatnot", "core.load_embeddings.save_dict", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm", "gc.collect", "core.load_embeddings.calculate_glove_prob", "calculate_alpha_vectors.well_cond_fisher_and_whatnot", "calculate_alpha_vectors.plot_fisher_eigs", "calculate_alpha_vectors.print_damping", "numpy.save", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm", "tqdm.tqdm", "numpy.ones", "list", "calculate_alpha_vectors.limit_embeddings_ldv", "calculate_alpha_vectors.limit_embeddings_ldv", "calculate_alpha_vectors.limit_embeddings_ldv", "calculate_alpha_vectors.alpha_embeddings_ldv", "calculate_alpha_vectors.alpha_embeddings_ldv", "calculate_alpha_vectors.alpha_embeddings_ldv", "list", "calculate_alpha_vectors.limit_embeddings_ldv", "calculate_alpha_vectors.limit_embeddings_ldv", "calculate_alpha_vectors.limit_embeddings_ldv", "calculate_alpha_vectors.limit_embeddings_ldv", "calculate_alpha_vectors.alpha_embeddings_ldv", "calculate_alpha_vectors.alpha_embeddings_ldv", "calculate_alpha_vectors.alpha_embeddings_ldv", "itertools.product", "itertools.product"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.calculate_glove_prob", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.well_cond_fisher_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.well_cond_fisher_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.well_cond_fisher_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.save_dict", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.calculate_glove_prob", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.well_cond_fisher_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.plot_fisher_eigs", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.print_damping", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.save", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_ldv", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_ldv"], ["def", "calculate_all_embeddings", "(", "U", ",", "V", ",", "pud", ",", "alphas", ",", "dictionary", ",", "outdirname", ")", ":", "\n", "\n", "    ", "g_p_w", ",", "g_p_cIw", "=", "calculate_glove_prob", "(", "U", ",", "V", ")", "\n", "damping_couples", "=", "[", "]", "\n", "\n", "gname", "=", "os", ".", "path", ".", "basename", "(", "outdirname", ")", "\n", "\n", "# uniform", "\n", "p0", "=", "np", ".", "ones", "(", "V", ".", "shape", "[", "0", "]", ")", "/", "V", ".", "shape", "[", "0", "]", "\n", "I0", ",", "DV0", ",", "_", "=", "well_cond_fisher_and_whatnot", "(", "V", ",", "p0", ",", "\"F-0\"", ",", "damping_couples", "=", "damping_couples", ")", "\n", "\n", "# unigram from data", "\n", "Iud", ",", "DVud", ",", "_", "=", "well_cond_fisher_and_whatnot", "(", "V", ",", "pud", ",", "\"F-ud\"", ",", "damping_couples", "=", "damping_couples", ")", "\n", "\n", "# unigram from glove model theta=u", "\n", "pu", "=", "g_p_w", "\n", "Iu", ",", "DVu", ",", "_", "=", "well_cond_fisher_and_whatnot", "(", "V", ",", "pu", ",", "\"F-u\"", ",", "damping_couples", "=", "damping_couples", ")", "\n", "\n", "# save dictionary", "\n", "save_dict", "(", "dictionary", ",", "outdirname", ")", "\n", "# save Fisher metric 0", "\n", "np", ".", "save", "(", "outdirname", "+", "\"/fisher-0\"", ",", "I0", ")", "\n", "# save Fisher metric u", "\n", "np", ".", "save", "(", "outdirname", "+", "\"/fisher-u\"", ",", "Iu", ")", "\n", "# save Fisher metric u from data", "\n", "np", ".", "save", "(", "outdirname", "+", "\"/fisher-ud\"", ",", "Iud", ")", "\n", "# save alphas", "\n", "np", ".", "save", "(", "outdirname", "+", "\"/alphas\"", ",", "alphas", ")", "\n", "\n", "# MODEL FROM THETA = U", "\n", "p_embeddings", "=", "g_p_cIw", "\n", "\n", "# limits ldv", "\n", "for", "ntop", ",", "wbool", ",", "fbool", "in", "tqdm", "(", "list", "(", "product", "(", "ntops", ",", "weigthed_limits", ",", "frac_limits", ")", ")", ",", "desc", "=", "\"{:} limit-u\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/limit{:d}-ldv-u_embeddings-0\".format(ntop)", "\n", "        ", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "p0", ",", "DV0", ",", "outdirname", ",", "\"u_embeddings\"", ",", "\"0\"", ",", "ntop", "=", "ntop", ",", "weighted", "=", "wbool", ",", "frac", "=", "fbool", ")", "\n", "# output = outdirname + \"/limit-ldv-u_embeddings-u\"", "\n", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "pu", ",", "DVu", ",", "outdirname", ",", "\"u_embeddings\"", ",", "\"u\"", ",", "ntop", "=", "ntop", ",", "weighted", "=", "wbool", ",", "frac", "=", "fbool", ")", "\n", "# output = outdirname + \"/limit{:d}-ldv-u_embeddings-ud\"", "\n", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "pud", ",", "DVud", ",", "outdirname", ",", "\"u_embeddings\"", ",", "\"ud\"", ",", "ntop", "=", "ntop", ",", "weighted", "=", "wbool", ",", "frac", "=", "fbool", ")", "\n", "\n", "# save ldv 0", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", ",", "desc", "=", "\"{:} alpha-u-0\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/alpha{:.2f}-ldv-u_embeddings-0\".format(alpha)", "\n", "        ", "alpha_embeddings_ldv", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "p0", ",", "DV0", ",", "outdirname", ",", "\"u_embeddings\"", ",", "\"0\"", ")", "\n", "\n", "# save ldv u", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", ",", "desc", "=", "\"{:} alpha-u-u\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/alpha{:.2f}-ldv-u_embeddings-u\".format(alpha)", "\n", "        ", "alpha_embeddings_ldv", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "pu", ",", "DVu", ",", "outdirname", ",", "\"u_embeddings\"", ",", "\"u\"", ")", "\n", "\n", "# save ldv ud", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", ",", "desc", "=", "\"{:} alpha-u-ud\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/alpha{:.2f}-ldv-u_embeddings-ud\".format(alpha)", "\n", "        ", "alpha_embeddings_ldv", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "pud", ",", "DVud", ",", "outdirname", ",", "\"u_embeddings\"", ",", "\"ud\"", ")", "\n", "\n", "#free some memory", "\n", "", "del", "p_embeddings", ",", "g_p_cIw", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "# MODEL FROM THETA = U+V", "\n", "g_p_w", ",", "g_p_cIw", "=", "calculate_glove_prob", "(", "U", "+", "V", ",", "V", ")", "\n", "\n", "# unigram from glove model theta=u", "\n", "pus", "=", "g_p_w", "\n", "Ius", ",", "DVus", ",", "_", "=", "well_cond_fisher_and_whatnot", "(", "V", ",", "pus", ",", "\"F-us\"", ",", "damping_couples", "=", "damping_couples", ")", "\n", "\n", "p_embeddings", "=", "g_p_cIw", "\n", "\n", "# plot eigenvalues of fisher metric in these parametrizations", "\n", "plot_fisher_eigs", "(", "[", "I0", ",", "Iu", ",", "Iud", ",", "Ius", "]", ",", "[", "\"F-0\"", ",", "\"F-u\"", ",", "\"F-ud\"", ",", "\"F-us\"", "]", ",", "outdirname", ")", "\n", "print_damping", "(", "damping_couples", ",", "outdirname", ")", "\n", "\n", "# save Fisher metric u from sum model", "\n", "np", ".", "save", "(", "outdirname", "+", "\"/fisher-us\"", ",", "Ius", ")", "\n", "\n", "# limits ldv", "\n", "for", "ntop", ",", "wbool", ",", "fbool", "in", "tqdm", "(", "list", "(", "product", "(", "ntops", ",", "weigthed_limits", ",", "frac_limits", ")", ")", ",", "desc", "=", "\"{:} limit-u+v\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/limit-ldv-u+v_embeddings-0\"", "\n", "        ", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "p0", ",", "DV0", ",", "outdirname", ",", "\"u+v_embeddings\"", ",", "\"0\"", ",", "ntop", "=", "ntop", ",", "weighted", "=", "wbool", ",", "frac", "=", "fbool", ")", "\n", "# output = outdirname + \"/limit-ldv-u+v_embeddings-u\"", "\n", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "pu", ",", "DVu", ",", "outdirname", ",", "\"u+v_embeddings\"", ",", "\"u\"", ",", "ntop", "=", "ntop", ",", "weighted", "=", "wbool", ",", "frac", "=", "fbool", ")", "\n", "# output = outdirname + \"/limit-ldv-u+v_embeddings-ud\"", "\n", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "pud", ",", "DVud", ",", "outdirname", ",", "\"u+v_embeddings\"", ",", "\"ud\"", ",", "ntop", "=", "ntop", ",", "weighted", "=", "wbool", ",", "frac", "=", "fbool", ")", "\n", "# output = outdirname + \"/limit-ldv-u+v_embeddings-us\"", "\n", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "pus", ",", "DVus", ",", "outdirname", ",", "\"u+v_embeddings\"", ",", "\"us\"", ",", "ntop", "=", "ntop", ",", "weighted", "=", "wbool", ",", "frac", "=", "fbool", ")", "\n", "\n", "# save ldv 0", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", ",", "desc", "=", "\"{:} alpha-u+v-0\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/alpha{:.2f}-ldv-u+v_embeddings-0\".format(alpha)", "\n", "        ", "alpha_embeddings_ldv", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "p0", ",", "DV0", ",", "outdirname", ",", "\"u+v_embeddings\"", ",", "\"0\"", ")", "\n", "\n", "# save ldv u", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", ",", "desc", "=", "\"{:} alpha-u+v-u\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/alpha{:.2f}-ldv-u+v_embeddings-u\".format(alpha)", "\n", "        ", "alpha_embeddings_ldv", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "pu", ",", "DVu", ",", "outdirname", ",", "\"u+v_embeddings\"", ",", "\"u\"", ")", "\n", "\n", "# save ldv ud", "\n", "", "for", "alpha", "in", "tqdm", "(", "alphas", ",", "desc", "=", "\"{:} alpha-u+v-ud\"", ".", "format", "(", "gname", ")", ")", ":", "\n", "# output = outdirname + \"/alpha{:.2f}-ldv-u+v_embeddings-ud\".format(alpha)", "\n", "        ", "alpha_embeddings_ldv", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "pud", ",", "DVud", ",", "outdirname", ",", "\"u+v_embeddings\"", ",", "\"ud\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.well_cond_fisher_and_whatnot": [[129, 161], ["p.reshape.reshape", "core.compute_embeddings.fisher_matrix_and_whatnot", "p.reshape.reshape", "numpy.linalg.cond", "print", "damping_couples.append", "core.compute_embeddings.fisher_matrix_and_whatnot", "numpy.linalg.cond", "Exception"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.fisher_matrix_and_whatnot"], ["", "", "def", "well_cond_fisher_and_whatnot", "(", "V", ",", "p", ",", "nameI", ",", "damping_couples", "=", "[", "]", ")", ":", "\n", "    ", "max_cond", "=", "1e3", "\n", "p", "=", "p", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "I", ",", "DV", "=", "fisher_matrix_and_whatnot", "(", "V", ",", "p", ")", "\n", "p", "=", "p", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "damping", "=", "0", "\n", "condition", "=", "np", ".", "linalg", ".", "cond", "(", "I", ")", "\n", "\n", "good", "=", "False", "\n", "if", "condition", "<=", "max_cond", ":", "\n", "        ", "good", "=", "True", "\n", "", "else", ":", "\n", "        ", "damping", "=", "1e-6", "\n", "\n", "", "while", "not", "good", ":", "\n", "        ", "I", ",", "DV", "=", "fisher_matrix_and_whatnot", "(", "V", ",", "p", ",", "damping", "=", "damping", ")", "\n", "condition", "=", "np", ".", "linalg", ".", "cond", "(", "I", ")", "\n", "good", "=", "(", "condition", "<=", "max_cond", ")", "and", "(", "condition", ">=", "0.9", "*", "max_cond", ")", "\n", "if", "not", "good", ":", "\n", "            ", "if", "condition", ">", "max_cond", ":", "\n", "                ", "damping", "*=", "10", "\n", "", "elif", "condition", "<", "0.9", "*", "max_cond", ":", "\n", "                ", "damping", "/=", "2", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Not sure what is happening here. \"", "\n", "\"Condition is {:} and max_cond is {:}\"", ".", "format", "(", "condition", ",", "max_cond", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"{:} : had to use damping factor of {:}, for condition number {:}\"", ".", "format", "(", "nameI", ",", "damping", ",", "condition", ")", ")", "\n", "damping_couples", ".", "append", "(", "(", "nameI", ",", "damping", ")", ")", "\n", "\n", "return", "I", ",", "DV", ",", "damping_couples", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.plot_fisher_eigs": [[163, 173], ["zip", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "numpy.linalg.eigh", "numpy.array", "matplotlib.pyplot.plot", "sorted", "numpy.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "plot_fisher_eigs", "(", "I_list", ",", "labels", ",", "outdirname", ")", ":", "\n", "# isotropicity of v vectors", "\n", "    ", "for", "I", ",", "label", "in", "zip", "(", "I_list", ",", "labels", ")", ":", "\n", "        ", "eigs", ",", "V", "=", "np", ".", "linalg", ".", "eigh", "(", "I", ")", "\n", "eigs", "=", "np", ".", "array", "(", "sorted", "(", "eigs", ",", "reverse", "=", "True", ")", ")", "\n", "plt", ".", "plot", "(", "np", ".", "log", "(", "eigs", ")", ",", "label", "=", "label", ")", "\n", "#plt.plot(eigs/eigs[0], label=label)", "\n", "\n", "", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "outdirname", "+", "\"/fisher_eigenvalues.png\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.print_damping": [[175, 179], ["open", "out_file.write", "map"], "function", ["None"], ["", "def", "print_damping", "(", "damping_couples", ",", "outdirname", ")", ":", "\n", "    ", "with", "open", "(", "outdirname", "+", "\"/damping.txt\"", ",", "'w'", ")", "as", "out_file", ":", "\n", "        ", "for", "couple", "in", "damping_couples", ":", "\n", "            ", "out_file", ".", "write", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "couple", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_txt": [[181, 199], ["list", "open", "range", "open.close", "dictionary.keys", "len", "core.load_embeddings.get_word_embeddings", "core.compute_embeddings.project_on_basis_from_ps", "calculate_alpha_vectors.write_to_file"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.project_on_basis_from_ps", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.write_to_file"], ["", "", "", "def", "alpha_embeddings_txt", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "pu", ",", "DV", ",", "I_inv", ",", "output", ",", "chunk_size", "=", "1000", ")", ":", "\n", "# print(\"calculating vectors for alpha={:.1f}\".format(alpha))", "\n", "    ", "all_words", "=", "list", "(", "dictionary", ".", "keys", "(", ")", ")", "\n", "\n", "fstream", "=", "open", "(", "output", ",", "\"w\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "all_words", ")", ",", "chunk_size", ")", ":", "\n", "        ", "words", "=", "all_words", "[", "i", ":", "i", "+", "chunk_size", "]", "\n", "\n", "# proj logmap", "\n", "p1", "=", "get_word_embeddings", "(", "words", ",", "p_embeddings", ",", "dictionary", ")", "\n", "# u1 = get_word_embeddings(words1, u_embeddings, dictionary)", "\n", "# v1 = get_word_embeddings(words1, v_embeddings, dictionary)", "\n", "\n", "C_proj1", "=", "project_on_basis_from_ps", "(", "p1", ",", "DV", ",", "I_inv", ",", "pu", ",", "alpha", ")", "\n", "\n", "write_to_file", "(", "fstream", ",", "words", ",", "C_proj1", ")", "\n", "", "fstream", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.alpha_embeddings_ldv": [[200, 232], ["os.path.join", "list", "core.load_embeddings.get_alpha_ldv_name", "os.path.exists", "dictionary.keys", "tables.open_file", "tables.Atom.from_dtype", "f.create_earray", "f.create_earray", "range", "os.path.getsize", "len", "core.load_embeddings.get_word_embeddings", "core.compute_embeddings.scalar_prod_logp0pw_beta_basis_npf", "f.root.embeddings_ldv.append", "f.root.embeddings_lscale.append"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.compute_embeddings.scalar_prod_logp0pw_beta_basis_npf"], ["", "def", "alpha_embeddings_ldv", "(", "alpha", ",", "dictionary", ",", "p_embeddings", ",", "p0", ",", "DV", ",", "outdirname", ",", "emb_name", ",", "point_name", ",", "chunk_size", "=", "5000", ")", ":", "\n", "# print(\"calculating vectors for alpha={:.1f}\".format(alpha))", "\n", "\n", "    ", "full_path", "=", "os", ".", "path", ".", "join", "(", "outdirname", ",", "get_alpha_ldv_name", "(", "alpha", ",", "emb_name", ",", "point_name", ")", ")", "\n", "\n", "#check if file already exists and is not empty (nothing to do)", "\n", "if", "os", ".", "path", ".", "exists", "(", "full_path", ")", "and", "os", ".", "path", ".", "getsize", "(", "full_path", ")", ">", "0", ":", "\n", "        ", "return", "\n", "\n", "", "all_words", "=", "list", "(", "dictionary", ".", "keys", "(", ")", ")", "\n", "\n", "with", "tables", ".", "open_file", "(", "full_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "atom", "=", "tables", ".", "Atom", ".", "from_dtype", "(", "p_embeddings", ".", "dtype", ")", "\n", "\n", "vec_size", "=", "DV", ".", "shape", "[", "1", "]", "\n", "# 0 means the array can be expanded on that axis", "\n", "array_ldv", "=", "f", ".", "create_earray", "(", "f", ".", "root", ",", "'embeddings_ldv'", ",", "atom", ",", "(", "0", ",", "vec_size", ")", ")", "\n", "array_lscale", "=", "f", ".", "create_earray", "(", "f", ".", "root", ",", "'embeddings_lscale'", ",", "atom", ",", "(", "0", ",", "1", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "all_words", ")", ",", "chunk_size", ")", ":", "\n", "            ", "words", "=", "all_words", "[", "i", ":", "i", "+", "chunk_size", "]", "\n", "\n", "# proj logmap", "\n", "p1", "=", "get_word_embeddings", "(", "words", ",", "p_embeddings", ",", "dictionary", ")", "\n", "# u1 = get_word_embeddings(words1, u_embeddings, dictionary)", "\n", "# v1 = get_word_embeddings(words1, v_embeddings, dictionary)", "\n", "\n", "# scalprods_ldv_alpha = scalar_prod_logp0pw_beta_basis(p1, p0, DV, alpha)", "\n", "scalprods_ldv_alpha", ",", "scalprods_lscale", "=", "scalar_prod_logp0pw_beta_basis_npf", "(", "p1", ",", "p0", ",", "DV", ",", "alpha", ")", "\n", "\n", "f", ".", "root", ".", "embeddings_ldv", ".", "append", "(", "scalprods_ldv_alpha", ")", "\n", "f", ".", "root", ".", "embeddings_lscale", ".", "append", "(", "scalprods_lscale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.limit_embeddings_ldv": [[233, 283], ["os.path.join", "list", "core.load_embeddings.get_alpha_ldv_name", "os.path.exists", "dictionary.keys", "tables.open_file", "tables.Atom.from_dtype", "f.create_earray", "range", "os.path.getsize", "len", "core.load_embeddings.get_word_embeddings", "numpy.sum", "f.root.embeddings_ldv.append", "numpy.argpartition", "numpy.zeros", "range", "numpy.expand_dims", "p0.reshape", "range"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.test.evaluate_analogies_from_alpha_embeddings.get_word_embeddings"], ["", "", "", "def", "limit_embeddings_ldv", "(", "dictionary", ",", "p_embeddings", ",", "p0", ",", "DV", ",", "outdirname", ",", "emb_name", ",", "point_name", ",", "chunk_size", "=", "10000", ",", "ntop", "=", "1", ",", "weighted", "=", "False", ",", "frac", "=", "False", ")", ":", "\n", "# print(\"calculating limit vectors for alpha minus infinity\")", "\n", "\n", "    ", "full_path", "=", "os", ".", "path", ".", "join", "(", "outdirname", ",", "get_alpha_ldv_name", "(", "\"limit\"", ",", "emb_name", ",", "point_name", ",", "ntop", "=", "ntop", ",", "weighted", "=", "weighted", ",", "frac", "=", "frac", ")", ")", "\n", "\n", "#check if file already exists and is not empty (nothing to do)", "\n", "if", "os", ".", "path", ".", "exists", "(", "full_path", ")", "and", "os", ".", "path", ".", "getsize", "(", "full_path", ")", ">", "0", ":", "\n", "        ", "return", "\n", "\n", "", "all_words", "=", "list", "(", "dictionary", ".", "keys", "(", ")", ")", "\n", "\n", "with", "tables", ".", "open_file", "(", "full_path", ",", "'w'", ")", "as", "f", ":", "\n", "\n", "        ", "atom", "=", "tables", ".", "Atom", ".", "from_dtype", "(", "p_embeddings", ".", "dtype", ")", "\n", "\n", "vec_size", "=", "DV", ".", "shape", "[", "1", "]", "\n", "# 0 means the array can be expanded on that axis", "\n", "array_c", "=", "f", ".", "create_earray", "(", "f", ".", "root", ",", "'embeddings_ldv'", ",", "atom", ",", "(", "0", ",", "vec_size", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "all_words", ")", ",", "chunk_size", ")", ":", "\n", "            ", "words", "=", "all_words", "[", "i", ":", "i", "+", "chunk_size", "]", "\n", "\n", "# proj logmap", "\n", "p1", "=", "get_word_embeddings", "(", "words", ",", "p_embeddings", ",", "dictionary", ")", "\n", "\n", "if", "frac", ":", "\n", "                ", "pf", "=", "p1", "/", "p0", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "pf", "=", "p1", "\n", "\n", "", "idxs_star", "=", "np", ".", "argpartition", "(", "-", "pf", ",", "kth", "=", "ntop", ",", "axis", "=", "1", ")", "[", ":", ",", ":", "ntop", "]", "\n", "\n", "# limit_ldv = DV[idxs_star].sum(axis=1)", "\n", "weights", "=", "1", "\n", "if", "weighted", ":", "\n", "                ", "weights", "=", "np", ".", "zeros", "(", "idxs_star", ".", "shape", ")", "\n", "\n", "for", "i", "in", "range", "(", "idxs_star", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "idxs_star", ".", "shape", "[", "1", "]", ")", ":", "\n", "                        ", "weights", "[", "i", ",", "j", "]", "=", "pf", "[", "i", ",", "idxs_star", "[", "i", ",", "j", "]", "]", "\n", "\n", "", "", "weights", "=", "np", ".", "expand_dims", "(", "weights", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "limit_ldv", "=", "np", ".", "sum", "(", "DV", "[", "idxs_star", "]", "*", "weights", ",", "axis", "=", "1", ")", "\n", "\n", "# old code only for the max, only for LE", "\n", "# chi_star = np.argmax(p1, axis=1)", "\n", "# limit_ldv = DV[chi_star]", "\n", "\n", "f", ".", "root", ".", "embeddings_ldv", ".", "append", "(", "limit_ldv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.write_to_file": [[285, 291], ["zip", "fstream.flush", "fstream.write", "map"], "function", ["None"], ["", "", "", "def", "write_to_file", "(", "fstream", ",", "words", ",", "embeddings", ")", ":", "\n", "    ", "for", "w", ",", "emb", "in", "zip", "(", "words", ",", "embeddings", ")", ":", "\n", "        ", "line", "=", "\" \"", ".", "join", "(", "map", "(", "str", ",", "emb", ")", ")", "\n", "line", "=", "w", "+", "\" \"", "+", "line", "+", "\"\\n\"", "\n", "fstream", ".", "write", "(", "line", ")", "\n", "", "fstream", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.make_all": [[311, 334], ["core.readers.get_reader", "os.path.join", "os.makedirs", "readers.get_reader.read_dictionary", "readers.get_reader.read_word_counts", "core.load_embeddings.load_glove", "calculate_alpha_vectors.calculate_all_embeddings", "core.load_embeddings.get_suffix", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.readers.get_reader", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_dictionary", "home.repos.pwc.inspect_result.rist-ro_argo.core.readers.EmbeddingsFileReader.read_word_counts", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.test.calculate_alpha_vectors.calculate_all_embeddings", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_suffix"], ["def", "make_all", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "alphas", ",", "baseoutdir", ",", "exp_name_for_dir", ")", ":", "\n", "    ", "g_reader", "=", "readers", ".", "get_reader", "(", "\"glove\"", ")", "\n", "\n", "gname", "=", "corpus", "+", "get_suffix", "(", "vecsize", ",", "nepoch", ")", "\n", "outdirname", "=", "os", ".", "path", ".", "join", "(", "baseoutdir", ",", "corpus", "+", "exp_name_for_dir", "+", "\"/\"", "+", "gname", ")", "\n", "\n", "os", ".", "makedirs", "(", "outdirname", ",", "exist_ok", "=", "True", ")", "\n", "\n", "\n", "# select which vocabulary and cooccurrence file to use", "\n", "fnamevc", "=", "fnamevc_dict", "[", "corpus", "]", "\n", "(", "dictionary_size", ",", "v_dictionary", ",", "v_reversed_dictionary", ")", "=", "g_reader", ".", "read_dictionary", "(", "fnamevc", ")", "\n", "word_counts", "=", "g_reader", ".", "read_word_counts", "(", "fnamevc", ")", "\n", "pud", "=", "word_counts", "/", "np", ".", "sum", "(", "word_counts", ")", "\n", "\n", "\n", "g_dict", ",", "g_vecs", ",", "g_tuple", "=", "load_glove", "(", "corpus", ",", "vecsize", ",", "nepoch", ",", "calc_prob", "=", "False", ")", "\n", "\n", "# g_p_w, g_p_cIw = g_tuple", "\n", "U", "=", "g_vecs", "[", "\"u\"", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "V", "=", "g_vecs", "[", "\"v\"", "]", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "calculate_all_embeddings", "(", "U", ",", "V", ",", "pud", ",", "alphas", ",", "v_dictionary", ",", "outdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.create_clustering_methods": [[27, 38], ["spherecluster.SphericalKMeans", "functools.partial"], "function", ["None"], ["def", "create_clustering_methods", "(", "ngroups", ",", "g_matrix", ",", "n_init", ")", ":", "\n", "    ", "clustering_methods", "=", "{", "\n", "# \"kmsim\" : (KMeansSim(n_clusters=ngroups, g_matrix=g_matrix, n_init=n_init), partial(dist_on_sphere, g_matrix=g_matrix)),", "\n", "# \"krbsim\" : (RepeatedBisectionSim(n_clusters=ngroups, g_matrix=g_matrix, n_init=n_init, bm='agg'), partial(dist_on_sphere, g_matrix=g_matrix)),", "\n", "\"skm\"", ":", "(", "SphericalKMeans", "(", "n_clusters", "=", "ngroups", ",", "max_iter", "=", "1000", ",", "n_init", "=", "n_init", ")", ",", "partial", "(", "dist_on_sphere", ",", "g_matrix", "=", "g_matrix", ")", ")", ",", "\n", "# \"vmfs\" : (VonMisesFisherMixture(n_clusters=ngroups, n_init=n_init, posterior_type='soft'), partial(dist_on_sphere, g_matrix=g_matrix)),", "\n", "# \"vmfh\" : (VonMisesFisherMixture(n_clusters=ngroups, n_init=n_init, posterior_type='hard'), partial(dist_on_sphere, g_matrix=g_matrix)),", "\n", "# \"km\" : (KMeans(n_clusters=ngroups, n_init=n_init), partial(riemannian_dist, g_matrix=g_matrix)),", "\n", "# \"lgr\" : (sklearn.linear_model.LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=500), partial(dist_on_sphere, g_matrix=g_matrix)),", "\n", "}", "\n", "return", "clustering_methods", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.create_preproc_metric_tuples": [[62, 89], ["norm_metric_tuples.append", "functools.partial", "functools.partial", "ValueError", "ValueError"], "function", ["None"], ["def", "create_preproc_metric_tuples", "(", "Id", ",", "F", ")", ":", "\n", "    ", "norm_metric_tuples", "=", "[", "]", "\n", "\n", "for", "preproc_name", ",", "metric_name", "in", "preproc_metric_name_tuples", ":", "\n", "        ", "if", "preproc_name", "==", "\"nI\"", ":", "\n", "            ", "preproc", "=", "partial", "(", "riemannian_normalize", ",", "g_matrix", "=", "Id", ")", "\n", "", "elif", "preproc_name", "==", "\"nF\"", ":", "\n", "            ", "preproc", "=", "partial", "(", "riemannian_normalize", ",", "g_matrix", "=", "F", ")", "\n", "", "elif", "preproc_name", "==", "\"std\"", ":", "\n", "            ", "preproc", "=", "sklearn", ".", "preprocessing", ".", "scale", "\n", "", "elif", "preproc_name", "==", "\"\"", ":", "\n", "            ", "preproc", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"`{:}` not recognized\"", ".", "format", "(", "preproc_name", ")", ")", "\n", "\n", "", "if", "metric_name", "==", "\"I\"", ":", "\n", "            ", "g_matrix", "=", "Id", "\n", "", "elif", "metric_name", "==", "\"F\"", ":", "\n", "            ", "g_matrix", "=", "F", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"`{:}` not recognized\"", ".", "format", "(", "metric_name", ")", ")", "\n", "\n", "", "norm_metric_tuples", ".", "append", "(", "\n", "(", "preproc_name", ",", "preproc", ",", "metric_name", ",", "g_matrix", ")", "\n", ")", "\n", "\n", "", "return", "norm_metric_tuples", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.basic_silh_dist": [[91, 96], ["preproc_name.startswith", "functools.partial", "functools.partial"], "function", ["None"], ["", "def", "basic_silh_dist", "(", "preproc_name", ",", "g_matrix", ")", ":", "\n", "    ", "if", "preproc_name", ".", "startswith", "(", "\"n\"", ")", ":", "\n", "        ", "return", "partial", "(", "dist_on_sphere", ",", "g_matrix", "=", "g_matrix", ")", "\n", "", "else", ":", "\n", "        ", "return", "partial", "(", "riemannian_dist", ",", "g_matrix", "=", "g_matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings._tryfloat": [[98, 105], ["float"], "function", ["None"], ["", "", "def", "_tryfloat", "(", "v", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "value", "=", "float", "(", "v", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "value", "=", "v", "\n", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.make_all_frames": [[106, 210], ["viz_embeddings.get_emb_dir", "os.path.basename", "word_embedding.test.core.load_embeddings.load_emb_base", "numpy.linalg.inv", "numpy.eye", "viz_embeddings.create_preproc_metric_tuples", "word_embedding.test.core.load_embeddings.load_dict", "word_embedding.test.core.clustering.utils.get_enc", "word_embedding.test.core.clustering.utils.load_csv_into_dict", "word_embedding.test.core.clustering.utils.get_color_list", "os.path.join", "os.makedirs", "word_embedding.test.core.clustering.logging.CustomDefaultDict", "word_embedding.test.core.clustering.logging.CustomDefaultDict", "list", "os.path.normpath", "os.path.splitext", "len", "list", "functools.partial", "functools.partial", "enumerate", "os.path.join", "os.makedirs", "tqdm.tqdm", "baselog.plot", "os.path.join", "word_embedding.test.core.clustering.utils.make_video", "os.path.basename", "zip", "word_embedding.test.core.load_embeddings.get_alpha_ldv_name", "os.path.join", "word_embedding.test.core.load_embeddings.load_embeddings_ldv_hdf", "numpy.matmul().transpose", "word_embedding.test.core.clustering.utils.preprocess_clusters", "numpy.random.permutation", "word_embedding.test.core.clustering.utils.make_frame", "len", "viz_embeddings.create_clustering_methods", "create_clustering_methods.items", "logger.plot_errorbar", "logger.plot_errorbar", "word_embedding.test.core.clustering.utils.frame_name", "baselog.has_values", "word_embedding.test.core.clustering.utils.silhouette", "baselog.log", "range", "numpy.matmul", "word_embedding.test.core.clustering.utils.load_csv_into_dict.items", "viz_embeddings.basic_silh_dist", "numpy.transpose", "word_embedding.test.core.clustering.utils.get_indices", "logger.has_values", "time.time", "word_embedding.test.core.clustering.utils.do_clustering", "time.time", "logger.log"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.get_emb_dir", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_emb_base", "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.create_preproc_metric_tuples", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_dict", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.get_enc", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.load_csv_into_dict", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.get_color_list", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.make_video", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.get_alpha_ldv_name", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_embeddings_ldv_hdf", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.preprocess_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.make_frame", "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.create_clustering_methods", "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.plot_errorbar", "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.plot_errorbar", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.frame_name", "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.has_values", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.silhouette", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log", "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.basic_silh_dist", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.get_indices", "home.repos.pwc.inspect_result.rist-ro_argo.core.PandasLogger.PandasLogger.has_values", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.do_clustering", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "make_all_frames", "(", "alphas", ",", "corpus", ",", "vecsize", ",", "theta", ",", "nepoch", ",", "point", ",", "enc_name", ",", "groups_filename", ",", "baseoutdir", ")", ":", "\n", "    ", "emb_dir", "=", "get_emb_dir", "(", "corpus", ",", "vecsize", ",", "nepoch", ")", "\n", "wemb_id", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "emb_dir", ")", ")", "\n", "_", ",", "F", "=", "load_emb_base", "(", "emb_dir", ",", "point", ")", "\n", "\n", "F_inv", "=", "np", ".", "linalg", ".", "inv", "(", "F", ")", "\n", "Id", "=", "np", ".", "eye", "(", "F", ".", "shape", "[", "0", "]", ")", "\n", "preproc_metric_tuples", "=", "create_preproc_metric_tuples", "(", "Id", ",", "F", ")", "\n", "\n", "dictionary", ",", "idictionary", ",", "dsize", "=", "load_dict", "(", "emb_dir", ")", "\n", "encoder", "=", "get_enc", "(", "enc_name", ")", "\n", "\n", "# load groups from file", "\n", "groups", "=", "load_csv_into_dict", "(", "groups_filename", ",", "dictionary", ")", "\n", "groups_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "groups_filename", ")", ")", "[", "0", "]", "\n", "\n", "# make sure each group has a fixed paired colour", "\n", "colors_list", "=", "get_color_list", "(", "len", "(", "groups", ")", ")", "\n", "colors", "=", "{", "g", ":", "c", "for", "g", ",", "c", "in", "zip", "(", "groups", ",", "colors_list", ")", "}", "\n", "\n", "output_folder", "=", "os", ".", "path", ".", "join", "(", "baseoutdir", ",", "\"{:}_clusters/{:}/{:}/\"", ".", "format", "(", "enc_name", ",", "wemb_id", ",", "groups_name", ")", ")", "\n", "os", ".", "makedirs", "(", "output_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "alphas", "=", "[", "\"limit\"", "]", "+", "list", "(", "alphas", ")", "\n", "\n", "loggers", "=", "CustomDefaultDict", "(", "partial", "(", "instantiate_logger", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "log_prefix", "=", "\"{:}_clustering\"", ".", "format", "(", "groups_name", ")", ",", "\n", "names_to_log", "=", "[", "\"alpha\"", ",", "\"purity\"", ",", "\"homogeneity\"", ",", "\"completeness\"", ",", "\"silhouette\"", ",", "\"run\"", ",", "\"time\"", "]", ",", "\n", "try_to_convert", "=", "{", "'alpha'", ":", "_tryfloat", "}", ",", "\n", "field_to_sort_by", "=", "'alpha'", ",", "\n", "replace_strings_for_sort", "=", "{", "'limit'", ":", "-", "np", ".", "inf", "}", "\n", ")", "\n", ")", "\n", "\n", "basic_loggers", "=", "CustomDefaultDict", "(", "partial", "(", "instantiate_logger", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "log_prefix", "=", "\"{:}_base_silhouette\"", ".", "format", "(", "groups_name", ")", ",", "\n", "names_to_log", "=", "[", "\"alpha\"", ",", "\"silhouette\"", "]", ",", "\n", "try_to_convert", "=", "{", "'alpha'", ":", "_tryfloat", "}", ",", "\n", "field_to_sort_by", "=", "'alpha'", ",", "\n", "replace_strings_for_sort", "=", "{", "'limit'", ":", "-", "np", ".", "inf", "}", "\n", ")", "\n", ")", "\n", "\n", "enum_alphas", "=", "list", "(", "enumerate", "(", "alphas", ")", ")", "\n", "\n", "for", "preproc_name", ",", "preproc", ",", "metric_name", ",", "g_matrix", "in", "preproc_metric_tuples", ":", "\n", "# for norm metric", "\n", "        ", "video_folder", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"video_{:}\"", ".", "format", "(", "preproc_name", ")", ")", "\n", "os", ".", "makedirs", "(", "video_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "for", "i", ",", "alpha", "in", "tqdm", "(", "enum_alphas", ",", "desc", "=", "\"{:} {:} {:} {:} {:} {:} {:} {:}\"", ".", "format", "(", "enc_name", ",", "corpus", ",", "vecsize", ",", "nepoch", ",", "theta", ",", "point", ",", "preproc_name", ",", "metric_name", ")", ")", ":", "\n", "\n", "            ", "ldv_name", "=", "get_alpha_ldv_name", "(", "alpha", ",", "theta", "+", "\"_embeddings\"", ",", "point", ")", "\n", "ldv_path", "=", "os", ".", "path", ".", "join", "(", "emb_dir", ",", "ldv_name", ")", "\n", "\n", "original_norm", "=", "True", "if", "alpha", "!=", "\"limit\"", "else", "False", "\n", "ldv", "=", "load_embeddings_ldv_hdf", "(", "ldv_path", ",", "original_norm", "=", "original_norm", ")", "\n", "plog", "=", "np", ".", "matmul", "(", "F_inv", ",", "np", ".", "transpose", "(", "ldv", ")", ")", ".", "transpose", "(", ")", "\n", "\n", "clusters", "=", "{", "g", ":", "plog", "[", "get_indices", "(", "dictionary", ",", "words", ")", "]", "for", "g", ",", "words", "in", "groups", ".", "items", "(", ")", "}", "\n", "\n", "# for norm, metric", "\n", "points_prep", ",", "len_list", ",", "group_keys", ",", "labels", "=", "preprocess_clusters", "(", "clusters", ",", "preproc_method", "=", "preproc", ",", "repack", "=", "False", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "points_prep", ".", "shape", "[", "0", "]", ")", "\n", "shuffled_points", "=", "points_prep", "[", "perm", "]", "\n", "shuffled_labels", "=", "labels", "[", "perm", "]", "\n", "\n", "make_frame", "(", "video_folder", ",", "encoder", ",", "clusters", ",", "theta", ",", "point", ",", "enc_name", ",", "preproc_name", ",", "alpha", ",", "i", ",", "colors", ")", "\n", "\n", "baselog", "=", "basic_loggers", "[", "(", "wemb_id", ",", "theta", ",", "point", ",", "preproc_name", ",", "metric_name", ")", "]", "\n", "if", "not", "baselog", ".", "has_values", "(", "[", "\"alpha\"", "]", ",", "[", "alpha", "]", ")", ":", "\n", "                ", "silh", "=", "silhouette", "(", "shuffled_points", ",", "shuffled_labels", ",", "basic_silh_dist", "(", "preproc_name", ",", "g_matrix", ")", ")", "\n", "baselog", ".", "log", "(", "[", "alpha", ",", "silh", "]", ")", "\n", "\n", "", "ngroups", "=", "len", "(", "group_keys", ")", "\n", "clustering_methods", "=", "create_clustering_methods", "(", "ngroups", ",", "g_matrix", ",", "n_init", "=", "N_INIT", ")", "\n", "\n", "for", "cname", ",", "(", "cobj", ",", "cdist", ")", "in", "clustering_methods", ".", "items", "(", ")", ":", "\n", "# skip redundant clusterings", "\n", "                ", "if", "cname", "in", "[", "\"kmsim\"", ",", "\"krbsim\"", "]", "and", "preproc_name", "==", "\"\"", ":", "\n", "                    ", "continue", "\n", "\n", "", "logger", "=", "loggers", "[", "(", "wemb_id", ",", "theta", ",", "point", ",", "preproc_name", ",", "metric_name", ",", "cname", ")", "]", "\n", "for", "run", "in", "range", "(", "RUNS", ")", ":", "\n", "                    ", "if", "not", "logger", ".", "has_values", "(", "[", "\"run\"", ",", "\"alpha\"", "]", ",", "[", "run", ",", "alpha", "]", ")", ":", "\n", "                        ", "ti", "=", "time", ".", "time", "(", ")", "\n", "pur", ",", "hom", ",", "comp", ",", "silh", "=", "do_clustering", "(", "cobj", ",", "shuffled_points", ",", "shuffled_labels", ",", "cdist", ")", "\n", "tf", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "log", "(", "[", "alpha", ",", "pur", ",", "hom", ",", "comp", ",", "silh", ",", "run", ",", "tf", "-", "ti", "]", ")", "\n", "\n", "\n", "", "", "", "", "", "for", "preproc_name", ",", "preproc", ",", "metric_name", ",", "g_matrix", "in", "preproc_metric_tuples", ":", "\n", "# for norm, metric", "\n", "        ", "baselog", "=", "basic_loggers", "[", "(", "wemb_id", ",", "theta", ",", "point", ",", "preproc_name", ",", "metric_name", ")", "]", "\n", "baselog", ".", "plot", "(", "x", "=", "\"alpha\"", ",", "y", "=", "\"silhouette\"", ",", "ylim", "=", "(", "-", "1", ",", "1", ")", ")", "\n", "for", "cname", "in", "clustering_methods_list", ":", "\n", "            ", "logger", "=", "loggers", "[", "(", "wemb_id", ",", "theta", ",", "point", ",", "preproc_name", ",", "metric_name", ",", "cname", ")", "]", "\n", "logger", ".", "plot_errorbar", "(", "x", "=", "\"alpha\"", ",", "y", "=", "\"purity\"", ",", "ylim", "=", "(", "0", ",", "1", ")", ",", "string_replace", "=", "replace_strings_for_plots", ",", "suffix", "=", "\"-pur\"", ")", "\n", "logger", ".", "plot_errorbar", "(", "x", "=", "\"alpha\"", ",", "y", "=", "\"silhouette\"", ",", "ylim", "=", "(", "-", "1", ",", "1", ")", ",", "string_replace", "=", "replace_strings_for_plots", ",", "suffix", "=", "\"-silh\"", ")", "\n", "\n", "", "video_folder", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"video_{:}\"", ".", "format", "(", "preproc_name", ")", ")", "\n", "make_video", "(", "video_folder", ",", "frame_name", "(", "theta", ",", "point", ",", "enc_name", ",", "preproc_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.test.viz_embeddings.get_emb_dir": [[214, 216], ["os.path.join"], "function", ["None"], ["def", "get_emb_dir", "(", "corpus", ",", "vecsize", ",", "nepoch", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "base_emb_dir", ",", "corpus", "+", "\"-alpha-emb\"", ",", "\"{:}-v{:}-n{:}\"", ".", "format", "(", "corpus", ",", "vecsize", ",", "nepoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.straight_inverse._damped_fisher_inverse": [[4, 13], ["tensorflow.einsum", "tensorflow.einsum", "tensorflow.linalg.inv", "tensorflow.eye", "tf.einsum.shape.as_list"], "function", ["None"], ["def", "_damped_fisher_inverse", "(", "U", ",", "Q", ",", "U_T", ",", "alpha", ")", ":", "\n", "\n", "    ", "V_T", "=", "tf", ".", "einsum", "(", "'lk,kn->lkn'", ",", "Q", ",", "U_T", ")", "\n", "F", "=", "tf", ".", "einsum", "(", "'ij,ljk->lik'", ",", "U", ",", "V_T", ")", "\n", "\n", "F_hat", "=", "alpha", "*", "tf", ".", "eye", "(", "F", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "dtype", "=", "F", ".", "dtype", ")", "+", "F", "\n", "\n", "F_inv", "=", "tf", ".", "linalg", ".", "inv", "(", "F_hat", ")", "\n", "return", "(", "1.0", "+", "alpha", ")", "*", "F_inv", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.straight_inverse._true_fisher_inverse": [[15, 22], ["tensorflow.einsum", "tensorflow.einsum", "tensorflow.linalg.inv"], "function", ["None"], ["", "def", "_true_fisher_inverse", "(", "U", ",", "Q", ",", "U_T", ")", ":", "\n", "\n", "    ", "V_T", "=", "tf", ".", "einsum", "(", "'lk,kn->lkn'", ",", "Q", ",", "U_T", ")", "\n", "F", "=", "tf", ".", "einsum", "(", "'ij,ljk->lik'", ",", "U", ",", "V_T", ")", "\n", "\n", "F_inv", "=", "tf", ".", "linalg", ".", "inv", "(", "F", ")", "\n", "return", "F_inv", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_alpha_trick_single": [[4, 16], ["tensorflow.transpose", "tensorflow.eye", "tensorflow.matmul", "tensorflow.shape", "U.shape.as_list", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.eye", "tensorflow.linalg.inv"], "function", ["None"], ["def", "_shermann_morison_alpha_trick_single", "(", "alpha", ",", "U", ")", ":", "\n", "    ", "V_T", "=", "tf", ".", "transpose", "(", "U", ",", "perm", "=", "[", "1", ",", "0", "]", ")", "\n", "n_z_s", "=", "tf", ".", "shape", "(", "U", ")", "[", "-", "1", "]", "\n", "k_layer_length", "=", "U", ".", "shape", ".", "as_list", "(", ")", "[", "-", "2", "]", "\n", "\n", "M", "=", "tf", ".", "eye", "(", "k_layer_length", ",", "dtype", "=", "alpha", ".", "dtype", ")", "\n", "\n", "M_inner", "=", "alpha", "*", "tf", ".", "eye", "(", "n_z_s", ",", "dtype", "=", "alpha", ".", "dtype", ")", "+", "tf", ".", "matmul", "(", "V_T", ",", "U", ")", "\n", "M2", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "linalg", ".", "inv", "(", "M_inner", ")", ")", ",", "V_T", ")", "\n", "\n", "M", "-=", "M2", "\n", "return", "(", "(", "1.0", "+", "alpha", ")", "/", "alpha", ")", "*", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_alpha_trick": [[18, 29], ["tensorflow.linalg.inv", "tensorflow.einsum", "tensorflow.shape", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.eye"], "function", ["None"], ["", "def", "_shermann_morison_alpha_trick", "(", "alpha", ",", "U", ",", "V_T", ",", "grads", ")", ":", "\n", "    ", "n_z_s", "=", "tf", ".", "shape", "(", "U", ")", "[", "-", "1", "]", "\n", "\n", "M_inner_inv", "=", "tf", ".", "linalg", ".", "inv", "(", "alpha", "*", "tf", ".", "eye", "(", "n_z_s", ",", "dtype", "=", "alpha", ".", "dtype", ")", "+", "tf", ".", "einsum", "(", "'lij,jk->lik'", ",", "V_T", ",", "U", ")", ")", "\n", "\n", "M2", "=", "tf", ".", "einsum", "(", "'ij,lj->li'", ",", "U", ",", "\n", "tf", ".", "einsum", "(", "'lij,lj->li'", ",", "M_inner_inv", ",", "tf", ".", "einsum", "(", "'lik,lk->li'", ",", "V_T", ",", "grads", ")", ")", ")", "\n", "\n", "inverse_x_dif", "=", "grads", "-", "M2", "\n", "\n", "return", "(", "(", "1.0", "+", "alpha", ")", "/", "alpha", ")", "*", "inverse_x_dif", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison": [[31, 44], ["tensorflow.matmul", "tensorflow.shape", "tensorflow.shape", "U.shape.as_list", "tensorflow.eye", "tensorflow.eye", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.linalg.inv"], "function", ["None"], ["", "def", "_shermann_morison", "(", "alpha", ",", "U", ",", "V_T", ")", ":", "\n", "    ", "b_size", "=", "tf", ".", "shape", "(", "U", ")", "[", "0", "]", "\n", "n_z_s", "=", "tf", ".", "shape", "(", "U", ")", "[", "-", "1", "]", "\n", "k_layer_length", "=", "U", ".", "shape", ".", "as_list", "(", ")", "[", "-", "2", "]", "\n", "\n", "M", "=", "1.0", "/", "alpha", "*", "tf", ".", "eye", "(", "k_layer_length", ",", "batch_shape", "=", "[", "b_size", "]", ",", "dtype", "=", "alpha", ".", "dtype", ")", "\n", "\n", "M_inner", "=", "tf", ".", "eye", "(", "n_z_s", ",", "batch_shape", "=", "[", "b_size", "]", ",", "dtype", "=", "alpha", ".", "dtype", ")", "+", "1.0", "/", "alpha", "*", "tf", ".", "matmul", "(", "V_T", ",", "U", ")", "\n", "M2", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "linalg", ".", "inv", "(", "M_inner", ")", ")", ",", "V_T", ")", "\n", "\n", "M", "-=", "(", "1.0", "/", "(", "alpha", "**", "2", ")", ")", "*", "M2", "\n", "\n", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.shermann_morrison._shermann_morison_nobatch": [[46, 58], ["tensorflow.matmul", "tensorflow.shape", "U.shape.as_list", "tensorflow.eye", "tensorflow.eye", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.linalg.inv"], "function", ["None"], ["", "def", "_shermann_morison_nobatch", "(", "alpha", ",", "U", ",", "V_T", ")", ":", "\n", "    ", "n_z_s", "=", "tf", ".", "shape", "(", "U", ")", "[", "-", "1", "]", "\n", "k_layer_length", "=", "U", ".", "shape", ".", "as_list", "(", ")", "[", "-", "2", "]", "\n", "\n", "M", "=", "1.0", "/", "alpha", "*", "tf", ".", "eye", "(", "k_layer_length", ",", "dtype", "=", "alpha", ".", "dtype", ")", "\n", "\n", "M_inner", "=", "tf", ".", "eye", "(", "n_z_s", ",", "dtype", "=", "alpha", ".", "dtype", ")", "+", "1.0", "/", "alpha", "*", "tf", ".", "matmul", "(", "V_T", ",", "U", ")", "\n", "M2", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "linalg", ".", "inv", "(", "M_inner", ")", ")", ",", "V_T", ")", "\n", "\n", "M", "-=", "(", "1.0", "/", "(", "alpha", "**", "2", ")", ")", "*", "M2", "\n", "\n", "return", "M", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry": [[4, 18], ["tensorflow.map_fn", "tensorflow.linalg.diag", "tensorflow.matmul", "U.shape.as_list", "tensorflow.eye", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.linalg.inv"], "function", ["None"], ["def", "_woodberry", "(", "alpha", ",", "U", ",", "C", ",", "V_T", ")", ":", "\n", "    ", "k_layer_length", "=", "U", ".", "shape", ".", "as_list", "(", ")", "[", "-", "2", "]", "\n", "\n", "C_inv", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "1.0", "/", "x", ",", "C", ")", "\n", "C_inv_diag", "=", "tf", ".", "linalg", ".", "diag", "(", "C_inv", ")", "\n", "\n", "M", "=", "1.0", "/", "alpha", "*", "tf", ".", "eye", "(", "k_layer_length", ",", "dtype", "=", "alpha", ".", "dtype", ")", "\n", "\n", "M_inner", "=", "C_inv_diag", "+", "1.0", "/", "alpha", "*", "tf", ".", "matmul", "(", "V_T", ",", "U", ")", "\n", "M2", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "U", ",", "tf", ".", "linalg", ".", "inv", "(", "M_inner", ")", ")", ",", "V_T", ")", "\n", "\n", "M", "-=", "(", "1.0", "/", "(", "alpha", "**", "2", ")", ")", "*", "M2", "\n", "\n", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._woodberry_alpha_trick": [[20, 37], ["tensorflow.map_fn", "tensorflow.linalg.diag", "tensorflow.eye", "tensorflow.einsum", "tensorflow.einsum", "U.shape.as_list", "tensorflow.matmul", "tensorflow.einsum", "tensorflow.linalg.inv"], "function", ["None"], ["", "def", "_woodberry_alpha_trick", "(", "U", ",", "C", ",", "V_T", ",", "alpha", ",", "grads", ",", "layer", "=", "\"\"", ")", ":", "\n", "    ", "k_layer_length", "=", "U", ".", "shape", ".", "as_list", "(", ")", "[", "-", "2", "]", "\n", "\n", "C_inv", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "1.0", "/", "x", ",", "C", ")", "\n", "C_inv_diag", "=", "tf", ".", "linalg", ".", "diag", "(", "C_inv", ")", "\n", "\n", "M", "=", "tf", ".", "eye", "(", "k_layer_length", ",", "dtype", "=", "alpha", ".", "dtype", ")", "\n", "\n", "M_inner", "=", "alpha", "*", "C_inv_diag", "+", "tf", ".", "matmul", "(", "V_T", ",", "U", ")", "\n", "M2", "=", "tf", ".", "einsum", "(", "\"lik, kj -> lij\"", ",", "tf", ".", "einsum", "(", "\"ik, lkj -> lij\"", ",", "U", ",", "tf", ".", "linalg", ".", "inv", "(", "M_inner", ")", ")", ",", "V_T", ")", "\n", "\n", "M", "-=", "M2", "\n", "inverse_F", "=", "(", "(", "1.0", "+", "alpha", ")", "/", "alpha", ")", "*", "M", "\n", "\n", "inverse_x_diff", "=", "tf", ".", "einsum", "(", "\"lik,lk->li\"", ",", "inverse_F", ",", "grads", ")", "\n", "\n", "return", "inverse_x_diff", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.linalg.woodberry._optimized_woodberry": [[39, 52], ["tensorflow.linalg.diag", "tensorflow.linalg.inv", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum"], "function", ["None"], ["", "def", "_optimized_woodberry", "(", "U", ",", "C", ",", "V_T", ",", "alpha", ",", "grads", ",", "layer", "=", "\"\"", ")", ":", "\n", "    ", "C_inv", "=", "tf", ".", "linalg", ".", "diag", "(", "1.0", "/", "C", ")", "\n", "\n", "M_inner_inv", "=", "tf", ".", "linalg", ".", "inv", "(", "alpha", "*", "C_inv", "+", "tf", ".", "einsum", "(", "'ij,jk->ik'", ",", "V_T", ",", "U", ")", ")", "\n", "\n", "M2", "=", "tf", ".", "einsum", "(", "'ij,lj->li'", ",", "U", ",", "\n", "tf", ".", "einsum", "(", "'lij,lj->li'", ",", "M_inner_inv", ",", "tf", ".", "einsum", "(", "'ik,lk->li'", ",", "V_T", ",", "grads", ")", ")", ")", "\n", "\n", "M", "=", "grads", "-", "M2", "\n", "\n", "inverse_x_dif", "=", "(", "(", "1.0", "+", "alpha", ")", "/", "alpha", ")", "*", "M", "\n", "\n", "return", "inverse_x_dif", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS.__init__": [[8, 10], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"HMLJLRWS\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS.create_id": [[11, 16], ["None"], "methods", ["None"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "_id", "=", "\"HMLJLRWS\"", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS._build": [[17, 36], ["HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS._get_reconstruction_log_joint_likelihood_p", "HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS._get_dream_rec_log_joint_conditional_q", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS._get_reconstruction_log_joint_likelihood_p", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS._get_dream_rec_log_joint_conditional_q", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["", "def", "_build", "(", "self", ",", "hm", ")", ":", "\n", "        ", "batch_size", "=", "hm", ".", "b_size", "\n", "n_samples", "=", "hm", ".", "n_z_samples", "\n", "mega_batch_size", "=", "batch_size", "*", "n_samples", "\n", "\n", "log_joint_likelihood_p", "=", "self", ".", "_get_reconstruction_log_joint_likelihood_p", "(", "hm", ",", "mega_batch_size", ")", "\n", "\n", "log_joint_likelihood_q", "=", "self", ".", "_get_dream_rec_log_joint_conditional_q", "(", "hm", ",", "mega_batch_size", ")", "\n", "\n", "log_px_unnormalized", "=", "hm", ".", "importance_sampling_node", "-", "tf", ".", "log", "(", "tf", ".", "cast", "(", "n_samples", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "total_loss", "=", "-", "tf", ".", "reduce_mean", "(", "log_px_unnormalized", ",", "axis", "=", "0", ")", "\n", "\n", "reconstruction_loss", "=", "-", "log_joint_likelihood_p", "\n", "dream_reconstruction_loss", "=", "-", "log_joint_likelihood_q", "\n", "\n", "return", "total_loss", ",", "[", "[", "reconstruction_loss", "]", ",", "[", "dream_reconstruction_loss", "]", "]", ",", "[", "[", "\"NLL_X\"", "]", ",", "[", "\"NLL_H\"", "]", "]", ",", "[", "{", "\n", "\"fileName\"", ":", "\"reconstruction_loss_NLLX\"", "}", ",", "{", "\n", "\"fileName\"", ":", "\"reconstruction_loss_NLLH\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS._get_dream_rec_log_joint_conditional_q": [[37, 52], ["tensorflow.zeros", "range", "tensorflow.reduce_mean", "len", "[].log_prob", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "_get_dream_rec_log_joint_conditional_q", "(", "self", ",", "hm", ",", "mega_batch_size", ")", ":", "\n", "        ", "gen_layers", "=", "hm", ".", "_hgs", "\n", "rec_layers", "=", "hm", ".", "_hrs", "\n", "\n", "log_joint_likelihood_q", "=", "tf", ".", "zeros", "(", "(", "mega_batch_size", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "rec_layers", ")", ")", ":", "\n", "            ", "sample_p", "=", "gen_layers", "[", "i", "]", "[", "1", "]", "\n", "log_likelihood", "=", "rec_layers", "[", "i", "]", "[", "0", "]", ".", "log_prob", "(", "sample_p", ")", "\n", "\n", "log_joint_likelihood_q", "+=", "tf", ".", "reduce_sum", "(", "log_likelihood", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "log_joint_likelihood_q", "=", "tf", ".", "reduce_mean", "(", "log_joint_likelihood_q", ",", "axis", "=", "0", ")", "\n", "\n", "return", "log_joint_likelihood_q", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihoodRWS.HMLogJointLikelihoodRWS._get_reconstruction_log_joint_likelihood_p": [[53, 68], ["tensorflow.zeros", "range", "tensorflow.reduce_mean", "len", "tensorflow.reduce_sum", "distr_p.log_prob"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "_get_reconstruction_log_joint_likelihood_p", "(", "self", ",", "hm", ",", "mega_batch_size", ")", ":", "\n", "        ", "gen_layers", "=", "hm", ".", "_hgw", "\n", "rec_layers", "=", "hm", ".", "_hrw", "\n", "\n", "log_joint_likelihood_p", "=", "tf", ".", "zeros", "(", "(", "mega_batch_size", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_layers", ")", ")", ":", "\n", "            ", "sample_q", "=", "rec_layers", "[", "i", "]", "[", "1", "]", "\n", "distr_p", "=", "gen_layers", "[", "i", "]", "[", "0", "]", "\n", "\n", "log_joint_likelihood_p", "+=", "tf", ".", "reduce_sum", "(", "distr_p", ".", "log_prob", "(", "sample_q", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "log_joint_likelihood_p", "=", "tf", ".", "reduce_mean", "(", "log_joint_likelihood_p", ",", "axis", "=", "0", ")", "\n", "\n", "return", "log_joint_likelihood_p", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.__init__": [[7, 9], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"HMLL\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.create_id": [[10, 15], ["None"], "methods", ["None"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "_id", "=", "\"HMLL\"", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood._build": [[17, 40], ["HMLogLikelihood.HMLogLikelihood.reconstruction_loss", "HMLogLikelihood.HMLogLikelihood.reconstruction_loss"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss", "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss"], ["", "def", "_build", "(", "self", ",", "hm", ")", ":", "\n", "        ", "n_z_samples", "=", "hm", ".", "n_z_samples", "\n", "\n", "\n", "x_target", "=", "hm", ".", "x_target", "\n", "x_distr", "=", "hm", ".", "_hgw", "[", "0", "]", "[", "0", "]", "\n", "\n", "h_target", "=", "hm", ".", "_prior_samples", "\n", "h_distr", "=", "hm", ".", "_hrs", "[", "-", "1", "]", "[", "0", "]", "\n", "\n", "# The loss is composed of two terms:", "\n", "#", "\n", "# 1.) The reconstruction loss (the negative log probability", "\n", "#     of the input under the reconstructed distribution", "\n", "#     induced by the decoder in the data space).", "\n", "#     This can be interpreted as the number of \"nats\" required", "\n", "#     for reconstructing the input when the activation in latent", "\n", "#     is given.", "\n", "\n", "reconstruction_loss", "=", "self", ".", "reconstruction_loss", "(", "x_target", ",", "n_z_samples", ",", "x_distr", ")", "\n", "dream_reconstruction_loss", "=", "self", ".", "reconstruction_loss", "(", "h_target", ",", "n_z_samples", ",", "h_distr", ")", "\n", "\n", "return", "None", ",", "[", "[", "reconstruction_loss", "]", ",", "[", "dream_reconstruction_loss", "]", "]", ",", "[", "[", "\"NLL_X\"", "]", ",", "[", "\"NLL_H\"", "]", "]", ",", "[", "{", "\"fileName\"", ":", "\"reconstruction_loss_NLLX\"", "}", ",", "{", "\"fileName\"", ":", "\"reconstruction_loss_NLLH\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogLikelihood.HMLogLikelihood.reconstruction_loss": [[42, 67], ["tensorflow.variable_scope", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "x_target.shape.as_list", "len", "distr.log_prob", "list", "range", "distr.logits.shape.as_list", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "reconstruction_loss", "(", "self", ",", "x_target", ",", "n_z_samples", ",", "distr", ")", ":", "\n", "\n", "# with tf.variable_scope('LL/reconstruction_loss'):", "\n", "# no need for LL, sonnet module is already adding that, the line above would produce:", "\n", "# LL/LL/reconstruction_loss/node_created", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'reconstruction_loss'", ")", ":", "\n", "\n", "# 1) the log_pdf is computed with respect to distribution of the visible", "\n", "#    variables obtained from the target of input of the graph (self.x_target)", "\n", "# can I avoid replicate? maybe not..", "\n", "            ", "input_shape", "=", "x_target", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "ones", "=", "[", "1", "]", "*", "len", "(", "input_shape", ")", "\n", "x_replicate", "=", "tf", ".", "tile", "(", "x_target", ",", "[", "n_z_samples", "]", "+", "ones", ")", "\n", "\n", "x_replicate", "=", "tf", ".", "reshape", "(", "x_replicate", ",", "[", "-", "1", "]", "+", "distr", ".", "logits", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "\n", "reconstr_loss", "=", "-", "distr", ".", "log_prob", "(", "x_replicate", ")", "\n", "#now (ready for arbitrary intermediate samplings)", "\n", "all_axis_but_first", "=", "list", "(", "range", "(", "len", "(", "reconstr_loss", ".", "shape", ")", ")", ")", "[", "1", ":", "]", "\n", "#independent p for each input pixel", "\n", "log_p", "=", "tf", ".", "reduce_sum", "(", "reconstr_loss", ",", "axis", "=", "all_axis_but_first", ")", "\n", "#average over all the samples and the batch (they are both stacked on the axis 0)", "\n", "mean_reconstr_loss", "=", "tf", ".", "reduce_mean", "(", "log_p", ",", "axis", "=", "0", ",", "name", "=", "\"reconstruction_loss\"", ")", "\n", "\n", "", "return", "mean_reconstr_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.__init__": [[8, 10], ["argo.core.network.AbstractModule.AbstractModule.__init__"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"HMLJL\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood.create_id": [[11, 16], ["None"], "methods", ["None"], ["", "def", "create_id", "(", "self", ",", "cost_fuction_kwargs", ")", ":", "\n", "\n", "        ", "_id", "=", "\"HMLJL\"", "\n", "\n", "return", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.cost.HMLogJointLikelihood.HMLogJointLikelihood._build": [[17, 52], ["tensorflow.zeros", "range", "tensorflow.reduce_mean", "tensorflow.zeros", "range", "tensorflow.reduce_mean", "len", "tensorflow.reduce_sum", "len", "[].log_prob", "tensorflow.reduce_sum", "distr_p.log_prob"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.log_prob"], ["", "def", "_build", "(", "self", ",", "hm", ")", ":", "\n", "        ", "batch_size", "=", "hm", ".", "b_size", "\n", "n_samples", "=", "hm", ".", "n_z_samples", "\n", "mega_batch_size", "=", "batch_size", "*", "n_samples", "\n", "\n", "gen_layers", "=", "hm", ".", "_hgw", "\n", "rec_layers", "=", "hm", ".", "_hrw", "\n", "\n", "log_joint_likelihood_p", "=", "tf", ".", "zeros", "(", "(", "mega_batch_size", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_layers", ")", ")", ":", "\n", "            ", "sample_q", "=", "rec_layers", "[", "i", "]", "[", "1", "]", "\n", "distr_p", "=", "gen_layers", "[", "i", "]", "[", "0", "]", "\n", "log_joint_likelihood_p", "+=", "tf", ".", "reduce_sum", "(", "distr_p", ".", "log_prob", "(", "sample_q", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "log_joint_likelihood_p", "=", "tf", ".", "reduce_mean", "(", "log_joint_likelihood_p", ",", "axis", "=", "0", ")", "\n", "\n", "\n", "gen_layers", "=", "hm", ".", "_hgs", "\n", "rec_layers", "=", "hm", ".", "_hrs", "\n", "\n", "log_joint_likelihood_q", "=", "tf", ".", "zeros", "(", "(", "mega_batch_size", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "rec_layers", ")", ")", ":", "\n", "            ", "sample_p", "=", "gen_layers", "[", "i", "]", "[", "1", "]", "\n", "log_likelihood", "=", "rec_layers", "[", "i", "]", "[", "0", "]", ".", "log_prob", "(", "sample_p", ")", "\n", "\n", "log_joint_likelihood_q", "+=", "tf", ".", "reduce_sum", "(", "log_likelihood", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "log_joint_likelihood_q", "=", "tf", ".", "reduce_mean", "(", "log_joint_likelihood_q", ",", "axis", "=", "0", ")", "\n", "\n", "reconstruction_loss", "=", "-", "log_joint_likelihood_p", "\n", "dream_reconstruction_loss", "=", "-", "log_joint_likelihood_q", "\n", "return", "None", ",", "[", "[", "reconstruction_loss", "]", ",", "[", "dream_reconstruction_loss", "]", "]", ",", "[", "[", "\"NLL_X\"", "]", ",", "[", "\"NLL_H\"", "]", "]", ",", "[", "{", "\n", "\"fileName\"", ":", "\"reconstruction_loss_NLLX\"", "}", ",", "\n", "{", "\n", "\"fileName\"", ":", "\"reconstruction_loss_NLLH\"", "}", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.adversarial.accuracy_repeated_reconstructions.ff": [[180, 183], ["ff_module"], "function", ["None"], ["def", "ff", "(", "x", ")", ":", "\n", "    ", "logits", "=", "ff_module", "(", "x", ")", "\n", "return", "logits", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.adversarial.accuracy_repeated_reconstructions.vae_ff_nos": [[184, 191], ["encoder_module", "encoder_module.mean", "decoder_module", "decoder_module.reconstruction_node", "ff_module"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node"], ["", "def", "vae_ff_nos", "(", "x", ")", ":", "\n", "    ", "model_latent", "=", "encoder_module", "(", "x", ")", "\n", "mean", "=", "model_latent", ".", "mean", "(", ")", "\n", "rec_distr", "=", "decoder_module", "(", "mean", ")", "\n", "recnode", "=", "rec_distr", ".", "reconstruction_node", "(", ")", "\n", "logits", "=", "ff_module", "(", "recnode", ")", "\n", "return", "logits", ",", "mean", ",", "_", ",", "recnode", "# \"_\" was originally \"cov\"", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.adversarial.accuracy_repeated_reconstructions.vae_ff_s": [[192, 203], ["encoder_module", "encoder_module.mean", "tensorflow.square", "tensorflow.distributions.Normal", "tf.distributions.Normal.sample", "tensorflow.reshape", "decoder_module", "decoder_module.reconstruction_node", "ff_module"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.network.Gaussian.Gaussian.reconstruction_node"], ["", "def", "vae_ff_s", "(", "x", ")", ":", "\n", "    ", "model_latent", "=", "encoder_module", "(", "x", ")", "\n", "mean", "=", "model_latent", ".", "mean", "(", ")", "\n", "std", "=", "model_latent", ".", "scale", "\n", "cov", "=", "tf", ".", "square", "(", "std", ")", "\n", "distr", "=", "tf", ".", "distributions", ".", "Normal", "(", "loc", "=", "mean", ",", "scale", "=", "std", ")", "\n", "samples", "=", "distr", ".", "sample", "(", "1", ")", ";", "samples", "=", "tf", ".", "reshape", "(", "samples", ",", "(", "10000", ",", "20", ")", ")", "\n", "rec_distr", "=", "decoder_module", "(", "samples", ")", "\n", "recnode", "=", "rec_distr", ".", "reconstruction_node", "(", ")", "\n", "logits", "=", "ff_module", "(", "recnode", ")", "\n", "return", "logits", ",", "mean", ",", "cov", ",", "recnode", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.adversarial.accuracy_repeated_reconstructions.v_ff_nos": [[204, 210], ["encoder_module", "encoder_module.mean", "encoder_module.covariance", "ff_module"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance"], ["", "def", "v_ff_nos", "(", "x", ")", ":", "\n", "    ", "model_latent", "=", "encoder_module", "(", "x", ")", "\n", "mean", "=", "model_latent", ".", "mean", "(", ")", "\n", "cov", "=", "model_latent", ".", "covariance", "(", ")", "\n", "logits", "=", "ff_module", "(", "mean", ")", "\n", "return", "logits", ",", "mean", ",", "cov", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.adversarial.accuracy_repeated_reconstructions.v_ff_s": [[211, 219], ["encoder_module", "encoder_module.mean", "encoder_module.covariance", "tensorflow.distributions.Normal", "tf.distributions.Normal.sample", "ff_module"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.IndependentChannelsTransformedDistribution.IndependentChannelsTransformedDistribution.covariance", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "v_ff_s", "(", "x", ")", ":", "\n", "    ", "model_latent", "=", "encoder_module", "(", "x", ")", "\n", "mean", "=", "model_latent", ".", "mean", "(", ")", "\n", "cov", "=", "model_latent", ".", "covariance", "(", ")", "\n", "distr", "=", "tf", ".", "distributions", ".", "Normal", "(", "loc", "=", "mean", ",", "scale", "=", "cov", ")", "\n", "samples", "=", "distr", ".", "sample", "(", "1", ")", "\n", "logits", "=", "ff_module", "(", "samples", ")", "\n", "return", "logits", ",", "mean", ",", "cov", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.BasicIterativeMethod.BasicIterativeMethod.__init__": [[7, 97], ["tensorflow.Variable", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.assign", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.assign", "tensorflow.assign", "tensorflow.expand_dims", "tensorflow.map_fn", "tensorflow.nn.softmax", "tensorflow.argmax", "tensorflow.expand_dims", "tensorflow.reduce_sum", "set", "tensorflow.compat.v1.train.GradientDescentOptimizer", "tensorflow.compat.v1.train.GradientDescentOptimizer.minimize", "tensorflow.global_variables", "numpy.zeros", "numpy.zeros", "numpy.zeros", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.one_hot", "tensorflow.math.log", "Exception", "tensorflow.global_variables", "tensorflow.nn.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.softmax", "home.repos.pwc.inspect_result.rist-ro_argo.hooks.LoggerHelperMultiDS.LoggerHelperMultiDS.log"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "model", ",", "num_steps", ",", "proj_ord", "=", "np", ".", "inf", ",", "epsilon", "=", "0.1", ",", "batch_size", "=", "50", ",", "ldist_ord", "=", "2", ",", "\n", "learning_rate", "=", "0.1", ",", "data_interval", "=", "[", "0.", ",", "1.", "]", ",", "input_shape", "=", "[", "28", ",", "28", ",", "1", "]", ",", "n_classes", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sess (tf.Session): the tf session\n            model: the function taking an input x and creating the graph nodes and returning the logits of the model\n            num_steps: the number of steps to do\n            proj_ord: the order of the projection (0: no projection, int>0: project according to the norm ord=int\n                                                                    make norm of the perturbation equal to epsilon,\n                                                np.inf: project in the box with sides epsilon)\n            epsilon: the epsilon used for the projection (unless prj_ord=0, then no projection is done)\n            const: constant to weight the adv loss against the ldistance loss\n            ldist_ord: the ord of the norm used for the ldistance in the CW variational problem\n            data_interval: the interval of the data\n            learning_rate: learning rate for the adam optimizer\n            input_shape: the input shape\n            n_classes: the number of classes for the classification\n        \"\"\"", "\n", "\n", "self", ".", "_sess", "=", "sess", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "self", ".", "num_steps", "=", "num_steps", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "_curr_bs", "=", "self", ".", "batch_size", "\n", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "\n", "self", ".", "_x", "=", "x", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", "+", "input_shape", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "name", "=", "'modifier'", ")", "\n", "self", ".", "_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "input_shape", ")", "\n", "self", ".", "_input_xvar", "=", "input_xvar", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", "+", "input_shape", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "name", "=", "'input_x'", ")", "\n", "self", ".", "_assign_input_to_var", "=", "tf", ".", "assign", "(", "self", ".", "_input_xvar", ",", "self", ".", "_input", ")", "\n", "\n", "self", ".", "_label", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ")", "\n", "self", ".", "_y", "=", "y", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ",", "trainable", "=", "False", ")", "\n", "self", ".", "_assign_label_to_y", "=", "tf", ".", "assign", "(", "self", ".", "_y", ",", "self", ".", "_label", ")", "\n", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n", "delta", "=", "tf", ".", "clip_by_value", "(", "self", ".", "_x", ",", "data_interval", "[", "0", "]", ",", "data_interval", "[", "1", "]", ")", "-", "input_xvar", "\n", "# projection of delta", "\n", "#         import pdb;pdb.set_trace()", "\n", "# quick fix", "\n", "if", "proj_ord", "==", "'inf'", ":", "\n", "            ", "proj_ord", "=", "np", ".", "inf", "\n", "\n", "", "if", "proj_ord", "==", "np", ".", "inf", ":", "\n", "            ", "delta", "=", "tf", ".", "clip_by_value", "(", "delta", ",", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "elif", "proj_ord", "==", "0", ":", "\n", "            ", "delta", "=", "delta", "\n", "", "elif", "proj_ord", "==", "2", ":", "\n", "            ", "delta", "=", "self", ".", "epsilon", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "delta", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"not yet implemented proj_ord=%d\"", "%", "proj_ord", ")", "\n", "\n", "", "self", ".", "_assign_xs_and_clip", "=", "tf", ".", "assign", "(", "self", ".", "_x", ",", "input_xvar", "+", "delta", ")", "\n", "\n", "x_expanded", "=", "tf", ".", "expand_dims", "(", "self", ".", "_x", ",", "axis", "=", "1", ")", "\n", "self", ".", "_logits", "=", "logits", "=", "tf", ".", "map_fn", "(", "model", ",", "x_expanded", ")", "\n", "self", ".", "_probs", "=", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "_logits", ")", "\n", "self", ".", "_preds", "=", "tf", ".", "argmax", "(", "self", ".", "_logits", ",", "axis", "=", "2", ")", "\n", "\n", "one_hot", "=", "tf", ".", "expand_dims", "(", "tf", ".", "one_hot", "(", "self", ".", "_y", ",", "n_classes", ")", ",", "axis", "=", "1", ")", "\n", "\n", "correct_prob", "=", "tf", ".", "reduce_sum", "(", "one_hot", "*", "probs", ",", "axis", "=", "2", ")", "\n", "# wrong_logit = tf.reduce_max((1-one_hot) * logits - 1e4*one_hot, axis=1)", "\n", "\n", "# ldist = 0.", "\n", "# if ldist_ord>0:", "\n", "#     ldist = tf.norm(x - input_xvar, ord=ldist_ord)", "\n", "\n", "# sum up the losses", "\n", "# self._loss2 = ldist", "\n", "# self._loss1 = correct_logit - wrong_logit", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "self", ".", "_loss", "=", "-", "tf", ".", "math", ".", "log", "(", "correct_prob", ")", "\n", "\n", "# All variables in the graph before I instantiate the optimizer", "\n", "start_vars", "=", "set", "(", "n", ".", "name", "for", "n", "in", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "optimizer", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", ")", "\n", "self", ".", "_train", "=", "optimizer", ".", "minimize", "(", "-", "self", ".", "_loss", ",", "var_list", "=", "[", "self", ".", "_x", "]", ")", "# maximize the loss", "\n", "\n", "# All variables in the graph after I instantiate the optimizer", "\n", "end_vars", "=", "tf", ".", "global_variables", "(", ")", "\n", "self", ".", "_optimizer_vars", "=", "[", "n", "for", "n", "in", "end_vars", "if", "n", ".", "name", "not", "in", "start_vars", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.BasicIterativeMethod.BasicIterativeMethod.run": [[98, 124], ["BasicIterativeMethod.BasicIterativeMethod._sess.run", "BasicIterativeMethod.BasicIterativeMethod._sess.run", "BasicIterativeMethod.BasicIterativeMethod._sess.run", "BasicIterativeMethod.BasicIterativeMethod._sess.run", "BasicIterativeMethod.BasicIterativeMethod._sess.run", "range", "BasicIterativeMethod.BasicIterativeMethod._sess.run", "tensorflow.variables_initializer", "pdb.set_trace", "numpy.zeros", "numpy.zeros", "BasicIterativeMethod.BasicIterativeMethod._sess.run", "BasicIterativeMethod.BasicIterativeMethod._sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "run", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "self", ".", "_sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "self", ".", "_optimizer_vars", ")", ")", "\n", "\n", "current_batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "# if we have less than self.batch_size examples left we pad x with zeroes to match self.batch_size", "\n", "if", "current_batch_size", "<", "self", ".", "batch_size", ":", "\n", "            ", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "padded_x", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", ")", "+", "self", ".", "input_shape", ")", "\n", "padded_x", "[", "0", ":", "x", ".", "shape", "[", "0", "]", "]", "=", "x", "\n", "x", "=", "padded_x", "\n", "padded_y", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "padded_y", "[", ":", "y", ".", "shape", "[", "0", "]", "]", "=", "y", "\n", "y", "=", "padded_y", "\n", "\n", "", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_input_to_var", ",", "{", "self", ".", "_input", ":", "x", "}", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_label_to_y", ",", "{", "self", ".", "_label", ":", "y", "}", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_x", ".", "initializer", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_xs_and_clip", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "_", ",", "p", ",", "loss", "=", "self", ".", "_sess", ".", "run", "(", "[", "self", ".", "_train", ",", "self", ".", "_preds", ",", "self", ".", "_loss", "]", ")", "\n", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_xs_and_clip", ")", "\n", "\n", "", "return", "self", ".", "_sess", ".", "run", "(", "self", ".", "_x", "[", ":", "current_batch_size", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.get_attack_class": [[3, 24], ["importlib.import_module", "getattr", "Exception", "__name__.split"], "function", ["None"], ["def", "get_attack_class", "(", "method_name", ",", "module_path", "=", "\"\"", ")", ":", "\n", "    ", "try", ":", "\n", "# # first try to load from here", "\n", "# try:", "\n", "        ", "py_module", "=", "importlib", ".", "import_module", "(", "\".\"", "+", "method_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# # it if fails, try to load from up tree directory", "\n", "# except ImportError:", "\n", "#     try:", "\n", "#         py_module = importlib.import_module(\"....transform\" + transform_name, '.'.join(__name__.split('.')[:-1]))", "\n", "#     # it if fails, try to laod from module_path.core", "\n", "#     except ImportError:", "\n", "#         py_module = importlib.import_module(module_path + \".core.transform\" + transform_name,", "\n", "#                                                  '.'.join(__name__.split('.')[:-1]))", "\n", "\n", "attack_class", "=", "getattr", "(", "py_module", ",", "method_name", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "Exception", "(", "\"problem with module: %s, exception %s\"", "%", "(", "method_name", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "attack_class", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.get_attack_id": [[34, 76], ["attack.maybe_capitalize", "attack.maybe_capitalize", "attack.maybe_capitalize", "print", "print", "ValueError", "attack.maybe_capitalize", "attack.maybe_capitalize", "attack.maybe_capitalize"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.maybe_capitalize", "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.maybe_capitalize", "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.maybe_capitalize", "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.maybe_capitalize", "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.maybe_capitalize", "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.maybe_capitalize"], ["def", "get_attack_id", "(", "method_name", ",", "method_kwargs", ")", ":", "\n", "    ", "\"\"\"Creates the id for an attack.\n\n    Args:\n        method_tuple (tuple): A tuple composed of : (name of the builder function, kwargs to pass to the function).\n\n    Returns:\n        string: the idname of the function that we want to concatenate in the output filenames.\n\n    \"\"\"", "\n", "\n", "# listWithPoints = lambda x: \".\".join(re.sub('[( )\\[\\]]', '', str(x)).replace(' ', '').split(\",\"))", "\n", "\n", "methodid", "=", "name_short", "[", "method_name", "]", "\n", "\n", "if", "method_name", "==", "'CarliniWagner'", ":", "\n", "        ", "methodid", "+=", "\"_n\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "'num_steps'", "]", ")", "\n", "methodid", "+=", "\"_po\"", "+", "\"{:}\"", ".", "format", "(", "maybe_capitalize", "(", "method_kwargs", "[", "'proj_ord'", "]", ")", ")", "\n", "methodid", "+=", "\"_do\"", "+", "\"{:}\"", ".", "format", "(", "maybe_capitalize", "(", "method_kwargs", "[", "'ldist_ord'", "]", ")", ")", "\n", "# methodid += \"_c\" + str(int(method_kwargs['const']))", "\n", "methodid", "+=", "\"_lr\"", "+", "\"{:.2e}\"", ".", "format", "(", "method_kwargs", "[", "'learning_rate'", "]", ")", "\n", "", "elif", "method_name", "==", "'EOT'", ":", "\n", "        ", "methodid", "+=", "\"_n\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "'num_steps'", "]", ")", "\n", "methodid", "+=", "\"_ss\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "'sample_size'", "]", ")", "\n", "methodid", "+=", "\"_lr\"", "+", "\"{:.2e}\"", ".", "format", "(", "method_kwargs", "[", "'learning_rate'", "]", ")", "\n", "methodid", "+=", "\"_po\"", "+", "\"{:}\"", ".", "format", "(", "maybe_capitalize", "(", "method_kwargs", "[", "'proj_ord'", "]", ")", ")", "\n", "", "elif", "method_name", "==", "'EOT_CarliniWagner'", ":", "\n", "        ", "methodid", "+=", "\"_n\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "'num_steps'", "]", ")", "\n", "methodid", "+=", "\"_po\"", "+", "\"{:}\"", ".", "format", "(", "maybe_capitalize", "(", "method_kwargs", "[", "'proj_ord'", "]", ")", ")", "\n", "methodid", "+=", "\"_do\"", "+", "\"{:}\"", ".", "format", "(", "maybe_capitalize", "(", "method_kwargs", "[", "'ldist_ord'", "]", ")", ")", "\n", "methodid", "+=", "\"_lr\"", "+", "\"{:.2e}\"", ".", "format", "(", "method_kwargs", "[", "'learning_rate'", "]", ")", "\n", "methodid", "+=", "\"_ss\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "'sample_size'", "]", ")", "\n", "", "elif", "method_name", "==", "'BasicIterativeMethod'", ":", "\n", "        ", "methodid", "+=", "\"_n\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "'num_steps'", "]", ")", "\n", "methodid", "+=", "\"_po\"", "+", "\"{:}\"", ".", "format", "(", "maybe_capitalize", "(", "method_kwargs", "[", "'proj_ord'", "]", ")", ")", "\n", "methodid", "+=", "\"_lr\"", "+", "\"{:.2e}\"", ".", "format", "(", "method_kwargs", "[", "'learning_rate'", "]", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'----------------------'", ")", "\n", "print", "(", "'ERROR '", ",", "method_name", ")", "\n", "raise", "ValueError", "(", "\"id rule for `%s` has to be implemented.\"", "%", "method_name", ")", "\n", "\n", "", "return", "methodid", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.attack.maybe_capitalize": [[77, 82], ["None"], "function", ["None"], ["", "def", "maybe_capitalize", "(", "ord_string", ")", ":", "\n", "    ", "if", "ord_string", "==", "\"inf\"", ":", "\n", "        ", "ord_string", "=", "\"Inf\"", "\n", "\n", "", "return", "ord_string", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.EOT.EOT.__init__": [[5, 111], ["tensorflow.Variable", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.transpose", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.map_fn", "tensorflow.argmax", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_sum", "set", "tensorflow.compat.v1.train.GradientDescentOptimizer", "tensorflow.compat.v1.train.GradientDescentOptimizer.minimize", "tensorflow.global_variables", "numpy.zeros", "numpy.zeros", "numpy.zeros", "tensorflow.tile", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.reduce_mean", "Exception", "tensorflow.global_variables", "tensorflow.nn.l2_normalize"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "model", ",", "num_steps", ",", "sample_size", "=", "30", ",", "proj_ord", "=", "np", ".", "inf", ",", "epsilon", "=", "0.1", ",", "batch_size", "=", "50", ",", "\n", "learning_rate", "=", "0.1", ",", "data_interval", "=", "[", "0.", ",", "1.", "]", ",", "input_shape", "=", "[", "28", ",", "28", ",", "1", "]", ",", "n_classes", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sess (tf.Session): the tf session\n            model: the function taking an input x and creating the graph nodes and returning the logits of the model\n            num_steps: the number of steps to do\n            proj_ord: the order of the projection (0: no projection, int>0: project according to the norm ord=int\n                                                                    make norm of the perturbation equal to epsilon,\n                                                np.inf: project in the box with sides epsilon)\n            epsilon: the epsilon used for the projection (unless prj_ord=0, then no projection is done)\n            const: constant to weight the adv loss against the ldistance loss\n            data_interval: the interval of the data\n            learning_rate: learning rate for the adam optimizer\n            input_shape: the input shape\n        \"\"\"", "\n", "\n", "self", ".", "_sess", "=", "sess", "\n", "# self._defend = defend", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "self", ".", "_num_steps", "=", "num_steps", "\n", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_curr_bs", "=", "self", ".", "_batch_size", "\n", "\n", "self", ".", "_sample_size", "=", "sample_size", "\n", "\n", "self", ".", "_input_shape", "=", "input_shape", "\n", "\n", "self", ".", "_epsilon", "=", "epsilon", "\n", "\n", "self", ".", "_data_interval", "=", "data_interval", "\n", "\n", "# clean input variable", "\n", "self", ".", "_x", "=", "x", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", "+", "self", ".", "_input_shape", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "name", "=", "'modifier'", ")", "\n", "self", ".", "_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "_input_shape", ")", "\n", "\n", "self", ".", "_y", "=", "y", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ",", "trainable", "=", "False", ")", "\n", "self", ".", "_label", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ")", "\n", "\n", "# clean input variable repeated", "\n", "self", ".", "_input_var", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", "+", "input_shape", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "name", "=", "'input_rep'", ")", "\n", "\n", "self", ".", "_label_repeated", "=", "tf", ".", "transpose", "(", "tf", ".", "tile", "(", "(", "self", ".", "_y", ",", ")", ",", "(", "self", ".", "_sample_size", ",", "1", ")", ")", ")", "\n", "\n", "# initialization", "\n", "self", ".", "assign_x_var", "=", "tf", ".", "assign", "(", "self", ".", "_x", ",", "self", ".", "_input", ")", "\n", "self", ".", "assign_input_var", "=", "tf", ".", "assign", "(", "self", ".", "_input_var", ",", "self", ".", "_input", ")", "\n", "# self.assign_xvar_repeated = tf.assign(self._xvar_repeated, self._x_repeated)", "\n", "self", ".", "assign_label", "=", "tf", ".", "assign", "(", "self", ".", "_y", ",", "self", ".", "_label", ")", "\n", "\n", "delta", "=", "tf", ".", "clip_by_value", "(", "self", ".", "_x", ",", "data_interval", "[", "0", "]", ",", "data_interval", "[", "1", "]", ")", "-", "self", ".", "_input_var", "\n", "\n", "if", "proj_ord", "==", "'inf'", ":", "\n", "            ", "proj_ord", "=", "np", ".", "inf", "\n", "", "if", "proj_ord", "==", "np", ".", "inf", ":", "\n", "            ", "delta", "=", "tf", ".", "clip_by_value", "(", "delta", ",", "-", "self", ".", "_epsilon", ",", "self", ".", "_epsilon", ")", "\n", "", "elif", "proj_ord", "==", "0", ":", "\n", "            ", "delta", "=", "delta", "\n", "", "elif", "proj_ord", "==", "2", ":", "\n", "            ", "delta", "=", "self", ".", "_epsilon", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "delta", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"not yet implemented proj_ord=%d\"", "%", "proj_ord", ")", "\n", "\n", "", "self", ".", "_assign_xs_and_clip", "=", "tf", ".", "assign", "(", "self", ".", "_x", ",", "self", ".", "_input_var", "+", "delta", ")", "\n", "\n", "# perturbed variable repeated", "\n", "# self._xvar_repeated = xvar_repeated = tf.Variable(np.zeros((self._batch_size, self._sample_size) + input_shape, dtype=np.float32),", "\n", "#                                     name='modifier_rep')", "\n", "\n", "x_expanded", "=", "tf", ".", "expand_dims", "(", "self", ".", "_x", ",", "axis", "=", "1", ")", "\n", "self", ".", "_xvar_repeated", "=", "tf", ".", "tile", "(", "x_expanded", ",", "(", "1", ",", "self", ".", "_sample_size", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "\n", "# transforming the input", "\n", "# self.ensemble_xs = ensemble_xs = tf.map_fn(defend, self._xvar_repeated)", "\n", "# self._logits = logits = tf.map_fn(model, self.ensemble_xs)", "\n", "self", ".", "_logits", "=", "logits", "=", "tf", ".", "map_fn", "(", "model", ",", "self", ".", "_xvar_repeated", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "# self._probs = probs = tf.nn.softmax(self._logits)", "\n", "self", ".", "_preds", "=", "tf", ".", "argmax", "(", "self", ".", "_logits", ",", "axis", "=", "2", ")", "\n", "\n", "\n", "# one_hot = tf.one_hot(self._label_repeated, n_classes)", "\n", "# correct_prob = tf.reduce_sum(one_hot * probs, axis = 2)", "\n", "\n", "# # import ipdb; ipdb.set_trace()", "\n", "# self._loss = tf.reduce_sum(-tf.math.log(correct_prob))", "\n", "# # self._loss = -tf.math.log(correct_prob)", "\n", "self", ".", "_softmax", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "_logits", ",", "labels", "=", "self", ".", "_label_repeated", ")", "\n", "self", ".", "_loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "reduce_mean", "(", "self", ".", "_softmax", ",", "axis", "=", "1", ")", ")", "\n", "\n", "# ensemble_grad, = tf.gradients(self._loss, self._input)", "\n", "\n", "# # All variables in the graph before I instantiate the optimizer", "\n", "start_vars", "=", "set", "(", "n", ".", "name", "for", "n", "in", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "optimizer", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "self", ".", "_train", "=", "optimizer", ".", "minimize", "(", "-", "self", ".", "_loss", ",", "var_list", "=", "[", "self", ".", "_x", "]", ")", "# maximize the loss", "\n", "\n", "# All variables in the graph after I instantiate the optimizer", "\n", "end_vars", "=", "tf", ".", "global_variables", "(", ")", "\n", "self", ".", "_optimizer_vars", "=", "[", "n", "for", "n", "in", "end_vars", "if", "n", ".", "name", "not", "in", "start_vars", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.EOT.EOT.run": [[112, 142], ["EOT.EOT._sess.run", "EOT.EOT._sess.run", "EOT.EOT._sess.run", "EOT.EOT._sess.run", "EOT.EOT._sess.run", "EOT.EOT._sess.run", "range", "EOT.EOT._sess.run", "tensorflow.variables_initializer", "numpy.zeros", "numpy.zeros", "EOT.EOT._sess.run", "EOT.EOT._sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "run", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "# import ipdb; ipdb.set_trace()", "\n", "        ", "self", ".", "_sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "self", ".", "_optimizer_vars", ")", ")", "\n", "\n", "current_batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "# if we have less than self._batch_size examples left we pad x with zeroes to match self._batch_size", "\n", "if", "current_batch_size", "<", "self", ".", "_batch_size", ":", "\n", "            ", "padded_x", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", "+", "self", ".", "_input_shape", ")", "\n", "padded_x", "[", "0", ":", "x", ".", "shape", "[", "0", "]", "]", "=", "x", "\n", "x", "=", "padded_x", "\n", "padded_y", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", ")", "\n", "padded_y", "[", ":", "y", ".", "shape", "[", "0", "]", "]", "=", "y", "\n", "y", "=", "padded_y", "\n", "\n", "\n", "", "self", ".", "_sess", ".", "run", "(", "self", ".", "assign_x_var", ",", "{", "self", ".", "_input", ":", "x", "}", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "assign_input_var", ",", "{", "self", ".", "_input", ":", "x", "}", ")", "\n", "# self._sess.run(self.assign_xvar_repeated, {self._input: x})", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "assign_label", ",", "{", "self", ".", "_label", ":", "y", "}", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_x", ".", "initializer", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_xs_and_clip", ")", "\n", "\n", "# import ipdb; ipdb.set_trace()", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_steps", ")", ":", "\n", "            ", "_", ",", "p", ",", "loss", "=", "self", ".", "_sess", ".", "run", "(", "[", "self", ".", "_train", ",", "self", ".", "_preds", ",", "self", ".", "_loss", "]", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_xs_and_clip", ")", "\n", "\n", "", "return", "self", ".", "_sess", ".", "run", "(", "self", ".", "_x", "[", ":", "current_batch_size", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.EOT_CarliniWagner.EOT_CarliniWagner.__init__": [[7, 70], ["tensorflow.placeholder", "tensorflow.Variable", "tensorflow.assign", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.Variable", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.map_fn", "tensorflow.map_fn", "tensorflow.argmax", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.assign", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.reduce_mean", "set", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.global_variables", "numpy.zeros", "numpy.zeros", "tensorflow.clip_by_value", "numpy.zeros", "tensorflow.one_hot", "tensorflow.multiply", "tensorflow.maximum", "tensorflow.norm", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.multiply", "Exception", "tensorflow.global_variables", "tensorflow.sign", "tensorflow.nn.l2_normalize"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.optimizers.WakeSleepOptimizer.WakeSleepOptimizer.apply_gradients", "home.repos.pwc.inspect_result.rist-ro_argo.optimizers.NaturalWakeSleepOptimizer.NaturalWakeSleepOptimizer.compute_gradients"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "defend", ",", "model", ",", "epsilon", ",", "proj_ord", "=", "2", ",", "ldist_ord", "=", "2", ",", "data_interval", "=", "[", "0", ",", "1", "]", ",", "batch_size", "=", "50", ",", "sample_size", "=", "30", ",", "num_steps", "=", "1000", ",", "learning_rate", "=", "0.1", ",", "const", "=", "10", ",", "k", "=", "0", ",", "debug", "=", "False", ",", "input_shape", "=", "[", "28", ",", "28", ",", "1", "]", ",", "n_classes", "=", "10", ")", ":", "\n", "        ", "self", ".", "_sess", "=", "sess", "\n", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "\n", "self", ".", "_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "input_shape", ")", "\n", "self", ".", "_x", "=", "x", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", "+", "input_shape", ")", ",", "dtype", "=", "np", ".", "float32", ",", "trainable", "=", "False", ")", "\n", "self", ".", "assign_input_to_x", "=", "tf", ".", "assign", "(", "x", ",", "self", ".", "_input", ")", "\n", "\n", "x_expanded", "=", "tf", ".", "expand_dims", "(", "x", ",", "axis", "=", "1", ")", "\n", "x_repeated", "=", "tf", ".", "tile", "(", "x_expanded", ",", "(", "1", ",", "sample_size", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "delta", "=", "delta", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", "+", "input_shape", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "if", "proj_ord", "==", "np", ".", "inf", ":", "\n", "            ", "self", ".", "delta", "=", "tf", ".", "clip_by_value", "(", "delta", ",", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "elif", "proj_ord", "==", "0", ":", "\n", "            ", "self", ".", "delta", "=", "delta", "\n", "", "elif", "proj_ord", "==", "2", ":", "\n", "            ", "self", ".", "delta", "=", "self", ".", "epsilon", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "delta", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"not yet implemented proj_ord=%d\"", "%", "proj_ord", ")", "\n", "\n", "", "delta_expanded", "=", "tf", ".", "expand_dims", "(", "self", ".", "delta", ",", "axis", "=", "1", ")", "\n", "delta_repeated", "=", "tf", ".", "tile", "(", "delta_expanded", ",", "(", "1", ",", "sample_size", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "x_adv", "=", "tf", ".", "clip_by_value", "(", "self", ".", "_x", "+", "self", ".", "delta", ",", "data_interval", "[", "0", "]", ",", "data_interval", "[", "1", "]", ")", "\n", "\n", "x_repeated_clipped", "=", "tf", ".", "clip_by_value", "(", "x_repeated", "+", "delta_repeated", ",", "data_interval", "[", "0", "]", ",", "data_interval", "[", "1", "]", ")", "\n", "ensemble_xs", "=", "tf", ".", "map_fn", "(", "defend", ",", "x_repeated_clipped", ")", "\n", "self", ".", "_logits", "=", "logits", "=", "tf", ".", "map_fn", "(", "model", ",", "ensemble_xs", ")", "\n", "self", ".", "_preds", "=", "tf", ".", "argmax", "(", "self", ".", "_logits", ",", "axis", "=", "2", ")", "\n", "\n", "self", ".", "_label", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ")", "\n", "self", ".", "_y", "=", "y", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ",", "trainable", "=", "False", ")", "\n", "self", ".", "assign_label_to_y", "=", "tf", ".", "assign", "(", "y", ",", "self", ".", "_label", ")", "\n", "\n", "one_hot", "=", "tf", ".", "expand_dims", "(", "tf", ".", "one_hot", "(", "y", ",", "n_classes", ")", ",", "axis", "=", "1", ")", "\n", "ensemble_labels", "=", "tf", ".", "tile", "(", "one_hot", ",", "(", "1", ",", "sample_size", ",", "1", ")", ")", "\n", "\n", "correct_logit", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "ensemble_labels", ",", "self", ".", "_logits", ")", ",", "axis", "=", "1", ")", "\n", "wrong_logit", "=", "tf", ".", "reduce_max", "(", "tf", ".", "multiply", "(", "1", "-", "ensemble_labels", ",", "self", ".", "_logits", ")", "-", "1e4", "*", "ensemble_labels", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "loss_adv", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "maximum", "(", "correct_logit", "-", "wrong_logit", ",", "-", "k", ")", ")", "\n", "self", ".", "loss", "=", "tf", ".", "norm", "(", "self", ".", "delta", ")", "+", "const", "*", "self", ".", "loss_adv", "\n", "\n", "#All variables in the graph before I instantiate the optimizer", "\n", "start_vars", "=", "set", "(", "n", ".", "name", "for", "n", "in", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "grad", ",", "var", "=", "optimizer", ".", "compute_gradients", "(", "self", ".", "loss", ",", "[", "self", ".", "delta", "]", ")", "[", "0", "]", "\n", "self", ".", "train", "=", "optimizer", ".", "apply_gradients", "(", "[", "(", "tf", ".", "sign", "(", "grad", ")", ",", "var", ")", "]", ")", "\n", "\n", "#All variables in the graph after I instantiate the optimizer", "\n", "end_vars", "=", "tf", ".", "global_variables", "(", ")", "\n", "self", ".", "optimizer_vars", "=", "[", "n", "for", "n", "in", "end_vars", "if", "n", ".", "name", "not", "in", "start_vars", "]", "\n", "\n", "self", ".", "_epsilon", "=", "epsilon", "\n", "self", ".", "_max_steps", "=", "num_steps", "\n", "self", ".", "_learning_rate", "=", "learning_rate", "\n", "self", ".", "_debug", "=", "debug", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.EOT_CarliniWagner.EOT_CarliniWagner.run": [[71, 94], ["EOT_CarliniWagner.EOT_CarliniWagner._sess.run", "EOT_CarliniWagner.EOT_CarliniWagner._sess.run", "EOT_CarliniWagner.EOT_CarliniWagner._sess.run", "EOT_CarliniWagner.EOT_CarliniWagner._sess.run", "range", "EOT_CarliniWagner.EOT_CarliniWagner._sess.run", "numpy.zeros", "numpy.zeros", "tensorflow.variables_initializer", "EOT_CarliniWagner.EOT_CarliniWagner._sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "run", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "\n", "        ", "current_batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "if", "current_batch_size", "<", "self", ".", "_batch_size", ":", "\n", "            ", "padded_x", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", "+", "self", ".", "input_shape", ")", "\n", "padded_x", "[", "0", ":", "x", ".", "shape", "[", "0", "]", "]", "=", "x", "\n", "x", "=", "padded_x", "\n", "padded_y", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", ")", ")", "\n", "padded_y", "[", ":", "y", ".", "shape", "[", "0", "]", "]", "=", "y", "\n", "y", "=", "padded_y", "\n", "\n", "", "self", ".", "_sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "self", ".", "optimizer_vars", ")", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "delta", ".", "initializer", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "assign_input_to_x", ",", "feed_dict", "=", "{", "self", ".", "_input", ":", "x", "}", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "assign_label_to_y", ",", "feed_dict", "=", "{", "self", ".", "_label", ":", "y", "}", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "_max_steps", ")", ":", "\n", "            ", "self", ".", "_sess", ".", "run", "(", "self", ".", "train", ")", "\n", "\n", "", "p", ",", "adv", "=", "self", ".", "_sess", ".", "run", "(", "[", "self", ".", "_preds", ",", "self", ".", "x_adv", "]", ")", "\n", "\n", "return", "adv", "[", ":", "current_batch_size", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.__init__": [[5, 92], ["tensorflow.Variable", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.assign", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.assign", "tensorflow.assign", "tensorflow.expand_dims", "tensorflow.map_fn", "tensorflow.argmax", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.reduce_sum", "set", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize", "tensorflow.global_variables", "numpy.zeros", "numpy.zeros", "numpy.zeros", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.one_hot", "tensorflow.norm", "tensorflow.norm", "Exception", "tensorflow.global_variables", "tensorflow.nn.l2_normalize"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "model", ",", "num_steps", ",", "proj_ord", "=", "np", ".", "inf", ",", "epsilon", "=", "0.1", ",", "batch_size", "=", "50", ",", "ldist_ord", "=", "2", ",", "const", "=", "1", ",", "data_interval", "=", "[", "0.", ",", "1.", "]", ",", "\n", "learning_rate", "=", "0.1", ",", "input_shape", "=", "[", "28", ",", "28", ",", "1", "]", ",", "n_classes", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sess (tf.Session): the tf session\n            model: the function taking an input x and creating the graph nodes and returning the logits of the model\n            num_steps: the number of steps to do\n            proj_ord: the order of the projection (0: no projection, int>0: project according to the norm ord=int\n                                                                    make norm of the perturbation equal to epsilon,\n                                                np.inf: project in the box with sides epsilon)\n            epsilon: the epsilon used for the projection (unless prj_ord=0, then no projection is done)\n            batch_size: how many examples are processed at a time\n            const: constant to weight the adv loss against the ldistance loss\n            ord: the ord of the norm used for the ldistance in the CW variational problem\n            data_interval: the interval of the data\n            learning_rate: learning rate for the adam optimizer\n            input_shape: the input shape\n            n_classes: the number of classes for the classification\n        \"\"\"", "\n", "\n", "self", ".", "_sess", "=", "sess", "\n", "self", ".", "_model", "=", "model", "\n", "\n", "self", ".", "num_steps", "=", "num_steps", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "_curr_bs", "=", "self", ".", "batch_size", "\n", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "\n", "self", ".", "_x", "=", "x", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", "+", "input_shape", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "name", "=", "'modifier'", ")", "\n", "self", ".", "_input", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "input_shape", ")", "\n", "self", ".", "_input_xvar", "=", "input_xvar", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", "+", "input_shape", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "name", "=", "'input_x'", ")", "\n", "self", ".", "_assign_input_to_var", "=", "tf", ".", "assign", "(", "self", ".", "_input_xvar", ",", "self", ".", "_input", ")", "\n", "\n", "self", ".", "_label", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ")", "\n", "self", ".", "_y", "=", "y", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ",", "trainable", "=", "False", ")", "\n", "self", ".", "_assign_label_to_y", "=", "tf", ".", "assign", "(", "self", ".", "_y", ",", "self", ".", "_label", ")", "\n", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n", "delta", "=", "tf", ".", "clip_by_value", "(", "self", ".", "_x", ",", "data_interval", "[", "0", "]", ",", "data_interval", "[", "1", "]", ")", "-", "input_xvar", "\n", "# projection of delta", "\n", "if", "proj_ord", "==", "np", ".", "inf", ":", "\n", "            ", "delta", "=", "tf", ".", "clip_by_value", "(", "delta", ",", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ")", "\n", "", "elif", "proj_ord", "==", "0", ":", "\n", "            ", "delta", "=", "delta", "\n", "", "elif", "proj_ord", "==", "2", ":", "\n", "            ", "delta", "=", "self", ".", "epsilon", "*", "tf", ".", "nn", ".", "l2_normalize", "(", "delta", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"not yet implemented proj_ord=%d\"", "%", "proj_ord", ")", "\n", "\n", "", "self", ".", "_assign_xs_and_clip", "=", "tf", ".", "assign", "(", "self", ".", "_x", ",", "input_xvar", "+", "delta", ")", "\n", "\n", "x_expanded", "=", "tf", ".", "expand_dims", "(", "self", ".", "_x", ",", "axis", "=", "1", ")", "\n", "self", ".", "_logits", "=", "logits", "=", "tf", ".", "map_fn", "(", "model", ",", "x_expanded", ")", "\n", "\n", "self", ".", "_preds", "=", "tf", ".", "argmax", "(", "self", ".", "_logits", ",", "axis", "=", "2", ")", "\n", "\n", "one_hot", "=", "tf", ".", "expand_dims", "(", "tf", ".", "one_hot", "(", "self", ".", "_y", ",", "n_classes", ")", ",", "axis", "=", "1", ")", "\n", "\n", "correct_logit", "=", "tf", ".", "reduce_sum", "(", "one_hot", "*", "logits", ",", "axis", "=", "2", ")", "\n", "wrong_logit", "=", "tf", ".", "reduce_max", "(", "(", "1", "-", "one_hot", ")", "*", "logits", "-", "1e4", "*", "one_hot", ",", "axis", "=", "2", ")", "\n", "\n", "ldist", "=", "0.", "\n", "if", "ldist_ord", ">", "0", ":", "\n", "            ", "if", "self", ".", "batch_size", "==", "1", ":", "\n", "                ", "ldist", "=", "tf", ".", "norm", "(", "self", ".", "_x", "-", "input_xvar", ",", "ord", "=", "ldist_ord", ")", "\n", "", "else", ":", "\n", "                ", "ldist", "=", "tf", ".", "norm", "(", "self", ".", "_x", "-", "input_xvar", ",", "ord", "=", "ldist_ord", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "", "", "self", ".", "_loss2", "=", "ldist", "\n", "self", ".", "_loss1", "=", "correct_logit", "-", "wrong_logit", "\n", "self", ".", "_loss_arr", "=", "const", "*", "self", ".", "_loss1", "+", "self", ".", "_loss2", "\n", "self", ".", "_loss", "=", "tf", ".", "reduce_sum", "(", "self", ".", "_loss_arr", ")", "\n", "\n", "# All variables in the graph before I instantiate the optimizer", "\n", "start_vars", "=", "set", "(", "n", ".", "name", "for", "n", "in", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "self", ".", "_train", "=", "optimizer", ".", "minimize", "(", "self", ".", "_loss", ",", "var_list", "=", "[", "self", ".", "_x", "]", ")", "\n", "\n", "# All variables in the graph after I instantiate the optimizer", "\n", "end_vars", "=", "tf", ".", "global_variables", "(", ")", "\n", "self", ".", "_optimizer_vars", "=", "[", "n", "for", "n", "in", "end_vars", "if", "n", ".", "name", "not", "in", "start_vars", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run": [[93, 118], ["CarliniWagner.CarliniWagner._sess.run", "CarliniWagner.CarliniWagner._sess.run", "CarliniWagner.CarliniWagner._sess.run", "CarliniWagner.CarliniWagner._sess.run", "CarliniWagner.CarliniWagner._sess.run", "range", "CarliniWagner.CarliniWagner._sess.run", "tensorflow.variables_initializer", "numpy.zeros", "numpy.zeros", "CarliniWagner.CarliniWagner._sess.run", "CarliniWagner.CarliniWagner._sess.run"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run", "home.repos.pwc.inspect_result.rist-ro_argo.attack.CarliniWagner.CarliniWagner.run"], ["", "def", "run", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "self", ".", "_sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "self", ".", "_optimizer_vars", ")", ")", "\n", "\n", "current_batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "# if we have less than self.batch_size examples left we pad x with zeroes to match self.batch_size", "\n", "if", "current_batch_size", "<", "self", ".", "batch_size", ":", "\n", "            ", "padded_x", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", ")", "+", "self", ".", "input_shape", ")", "\n", "padded_x", "[", "0", ":", "x", ".", "shape", "[", "0", "]", "]", "=", "x", "\n", "x", "=", "padded_x", "\n", "padded_y", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "padded_y", "[", ":", "y", ".", "shape", "[", "0", "]", "]", "=", "y", "\n", "y", "=", "padded_y", "\n", "\n", "", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_input_to_var", ",", "{", "self", ".", "_input", ":", "x", "}", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_label_to_y", ",", "{", "self", ".", "_label", ":", "y", "}", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_x", ".", "initializer", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_xs_and_clip", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "_", ",", "p", ",", "loss", "=", "self", ".", "_sess", ".", "run", "(", "[", "self", ".", "_train", ",", "self", ".", "_preds", ",", "self", ".", "_loss_arr", "]", ")", "\n", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_assign_xs_and_clip", ")", "\n", "\n", "", "return", "self", ".", "_sess", ".", "run", "(", "self", ".", "_x", "[", ":", "current_batch_size", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.identity.identity": [[3, 9], ["None"], "function", ["None"], ["def", "identity", "(", "dummy_x", ",", "sess", ",", "is_training", "=", "False", ")", ":", "\n", "\n", "    ", "def", "transform", "(", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n", "", "return", "transform", ",", "{", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.vae.TransformVAE.__init__": [[53, 59], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "encoder_module", ",", "decoder_module", ",", "sample_hid_node", ",", "sample_vis_node", ",", "z_std_scale_node", ")", ":", "\n", "        ", "self", ".", "_sample_hid_node", "=", "sample_hid_node", "\n", "self", ".", "_sample_vis_node", "=", "sample_vis_node", "\n", "self", ".", "_z_std_scale_node", "=", "z_std_scale_node", "\n", "self", ".", "encoder_module", "=", "encoder_module", "\n", "self", ".", "decoder_module", "=", "decoder_module", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.vae.TransformVAE.__call__": [[61, 86], ["vae.TransformVAE.encoder_module", "tensorflow.cond", "vae.TransformVAE.decoder_module", "tensorflow.cond", "vae.TransformVAE.mean", "tensorflow_probability.distributions.MultivariateNormalDiag().sample", "vae.TransformVAE.mean", "tensorflow_probability.distributions.MultivariateNormalDiag"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "#import pdb;pdb.set_trace()", "\n", "        ", "enc", "=", "self", ".", "encoder_module", "(", "x", ")", "\n", "self", ".", "enc", "=", "enc", "\n", "\n", "def", "sample_z_build", "(", ")", ":", "\n", "            ", "mean", "=", "enc", ".", "mean", "(", ")", "\n", "std", "=", "enc", ".", "scale", "\n", "return", "tfd", ".", "MultivariateNormalDiag", "(", "loc", "=", "mean", ",", "scale_diag", "=", "std", "*", "self", ".", "_z_std_scale_node", ")", ".", "sample", "(", ")", "\n", "\n", "", "def", "z_mean_build", "(", ")", ":", "\n", "            ", "return", "enc", ".", "mean", "(", ")", "\n", "\n", "", "z", "=", "tf", ".", "cond", "(", "self", ".", "_sample_hid_node", ",", "\n", "sample_z_build", ",", "\n", "z_mean_build", ")", "\n", "\n", "dec", "=", "self", ".", "decoder_module", "(", "z", ")", "\n", "\n", "rec", "=", "tf", ".", "cond", "(", "self", ".", "_sample_vis_node", ",", "\n", "dec", ".", "sample", ",", "\n", "dec", ".", "reconstruction_node", "\n", ")", "\n", "\n", "return", "rec", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.vae.vae": [[5, 50], ["transform.load_network_with_dummy_x", "tensorflow.placeholder_with_default", "tensorflow.placeholder_with_default", "tensorflow.placeholder_with_default", "vae.TransformVAE"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.load_network_with_dummy_x"], ["def", "vae", "(", "dummy_x", ",", "sess", ",", "is_training", ",", "conf_file", ",", "global_step", "=", "None", ",", "sample_hid", "=", "False", ",", "sample_vis", "=", "False", ",", "z_std_scale", "=", "1.", ")", ":", "\n", "    ", "vae_network", "=", "load_network_with_dummy_x", "(", "dummy_x", ",", "\n", "sess", ",", "\n", "is_training", "=", "is_training", ",", "\n", "conf_file", "=", "conf_file", ",", "\n", "global_step", "=", "global_step", ",", "\n", "base_path", "=", "\"vae.core\"", ")", "\n", "\n", "encoder_module", "=", "vae_network", ".", "encoder_module", "\n", "decoder_module", "=", "vae_network", ".", "decoder_module", "\n", "\n", "sample_hid_node", "=", "tf", ".", "placeholder_with_default", "(", "sample_hid", ",", "shape", "=", "(", ")", ",", "name", "=", "\"sample_hid\"", ")", "\n", "sample_vis_node", "=", "tf", ".", "placeholder_with_default", "(", "sample_vis", ",", "shape", "=", "(", ")", ",", "name", "=", "\"sample_vis\"", ")", "\n", "z_std_scale_node", "=", "tf", ".", "placeholder_with_default", "(", "z_std_scale", ",", "shape", "=", "(", ")", ",", "name", "=", "\"z_std_scale\"", ")", "\n", "\n", "\n", "# def transform(x):", "\n", "#     enc = encoder_module(x)", "\n", "#", "\n", "#     def sample_z_build():", "\n", "#         mean = enc.mean()", "\n", "#         std = enc.scale", "\n", "#         return tfd.MultivariateNormalDiag(loc=mean, scale_diag=std * z_std_scale_node).sample()", "\n", "#", "\n", "#     def z_mean_build():", "\n", "#         return enc.mean()", "\n", "#", "\n", "#     z = tf.cond(sample_hid_node,", "\n", "#                 sample_z_build,", "\n", "#                 z_mean_build)", "\n", "#", "\n", "#     dec = decoder_module(z)", "\n", "#", "\n", "#     rec = tf.cond(sample_vis_node,", "\n", "#                   dec.sample,", "\n", "#                   dec.reconstruction_node", "\n", "#                   )", "\n", "#", "\n", "#     return rec", "\n", "\n", "transform", "=", "TransformVAE", "(", "encoder_module", ",", "decoder_module", ",", "sample_hid_node", ",", "sample_vis_node", ",", "z_std_scale_node", ")", "\n", "\n", "return", "transform", ",", "{", "\"sample_hid\"", ":", "sample_hid_node", ",", "\n", "\"sample_vis\"", ":", "sample_vis_node", ",", "\n", "\"z_std_scale\"", ":", "z_std_scale_node", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.ae.TransformAE.__init__": [[37, 41], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "encoder_module", ",", "decoder_module", ",", "sample_vis_node", ")", ":", "\n", "        ", "self", ".", "_sample_vis_node", "=", "sample_vis_node", "\n", "self", ".", "encoder_module", "=", "encoder_module", "\n", "self", ".", "decoder_module", "=", "decoder_module", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.ae.TransformAE.__call__": [[43, 58], ["ae.TransformAE.encoder_module", "ae.TransformAE.decoder_module", "tensorflow.cond"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "enc", "=", "self", ".", "encoder_module", "(", "x", ")", "\n", "self", ".", "enc", "=", "enc", "\n", "\n", "def", "z_mean_build", "(", ")", ":", "\n", "            ", "return", "self", ".", "enc", "\n", "\n", "", "dec", "=", "self", ".", "decoder_module", "(", "enc", ")", "\n", "\n", "rec", "=", "tf", ".", "cond", "(", "self", ".", "_sample_vis_node", ",", "\n", "dec", ".", "sample", ",", "\n", "dec", ".", "reconstruction_node", "\n", ")", "\n", "\n", "return", "rec", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.ae.ae": [[4, 31], ["transform.load_network_with_dummy_x", "tensorflow.placeholder_with_default", "ae.TransformAE"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.load_network_with_dummy_x"], ["def", "ae", "(", "dummy_x", ",", "sess", ",", "is_training", ",", "conf_file", ",", "global_step", ",", "sample_vis", "=", "False", ")", ":", "\n", "    ", "ae_network", "=", "load_network_with_dummy_x", "(", "dummy_x", ",", "\n", "sess", ",", "\n", "is_training", "=", "is_training", ",", "\n", "conf_file", "=", "conf_file", ",", "\n", "global_step", "=", "global_step", ",", "\n", "base_path", "=", "\"vae.core\"", ")", "\n", "\n", "encoder_module", "=", "ae_network", ".", "encoder_module", "\n", "decoder_module", "=", "ae_network", ".", "decoder_module", "\n", "\n", "sample_vis_node", "=", "tf", ".", "placeholder_with_default", "(", "sample_vis", ",", "shape", "=", "(", ")", ",", "name", "=", "\"sample_vis\"", ")", "\n", "\n", "# def transform(x):", "\n", "#     enc = encoder_module(x)", "\n", "#     dec = decoder_module(enc)", "\n", "#", "\n", "#     rec = tf.cond(sample_vis_node,", "\n", "#                   dec.sample,", "\n", "#                   dec.reconstruction_node", "\n", "#                   )", "\n", "#", "\n", "#     return rec", "\n", "\n", "transform", "=", "TransformAE", "(", "encoder_module", ",", "decoder_module", ",", "sample_vis_node", ")", "\n", "\n", "return", "transform", ",", "{", "\"sample_vis\"", ":", "sample_vis_node", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.Transformation.build": [[118, 131], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        build the transform method\n\n        Args:\n            **kwargs: arguments for the transform builder\n\n        Returns:\n            The transform method\n\n        \"\"\"", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_module": [[11, 35], ["importlib.import_module", "getattr", "Exception", "__name__.split"], "function", ["None"], ["def", "get_transform_module", "(", "transform_name", ",", "transform_kwargs", ",", "module_path", "=", "\"\"", ")", ":", "\n", "\n", "    ", "try", ":", "\n", "# # first try to load from here", "\n", "# try:", "\n", "        ", "py_module", "=", "importlib", ".", "import_module", "(", "\".\"", "+", "transform_name", ",", "'.'", ".", "join", "(", "__name__", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# # it if fails, try to load from up tree directory", "\n", "# except ImportError:", "\n", "#     try:", "\n", "#         py_module = importlib.import_module(\"....transform\" + transform_name, '.'.join(__name__.split('.')[:-1]))", "\n", "#     # it if fails, try to laod from module_path.core", "\n", "#     except ImportError:", "\n", "#         py_module = importlib.import_module(module_path + \".core.transform\" + transform_name,", "\n", "#                                                  '.'.join(__name__.split('.')[:-1]))", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "\n", "transform_module", "=", "getattr", "(", "py_module", ",", "transform_name", ")", "(", "**", "transform_kwargs", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "Exception", "(", "\"problem with module: %s, kwargs: %s, exception %s\"", "%", "(", "transform_name", ",", "transform_kwargs", ",", "e", ")", ")", "from", "e", "\n", "\n", "", "return", "transform_module", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.load_network_with_dummy_x": [[37, 54], ["core.argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "datasets.Dataset.Dataset.load_dataset", "transform.check_dataset_shapes", "core.argo.core.utils.argo_utils.load_class", "core.argo.core.TFDeepLearningModel.load_network", "network", "network.restore"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.ArgoLauncher.ArgoLauncher.process_conf_file", "home.repos.pwc.inspect_result.rist-ro_argo.datasets.CMB.CMB.load_dataset", "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.check_dataset_shapes", "home.repos.pwc.inspect_result.rist-ro_argo.utils.argo_utils.load_class", "home.repos.pwc.inspect_result.rist-ro_argo.core.TFDeepLearningModel.load_network", "home.repos.pwc.inspect_result.rist-ro_argo.network.AbstractModule.AbstractModule.restore"], ["", "def", "load_network_with_dummy_x", "(", "dummy_x", ",", "sess", ",", "is_training", ",", "conf_file", ",", "global_step", ",", "base_path", ")", ":", "\n", "    ", "dataset_conf", ",", "model_parameters", ",", "config", "=", "ArgoLauncher", ".", "process_conf_file", "(", "conf_file", ")", "\n", "dataset", "=", "Dataset", ".", "load_dataset", "(", "dataset_conf", ")", "\n", "check_dataset_shapes", "(", "dataset", ".", "x_shape_eval", ",", "dummy_x", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "full_class_path", "=", "base_path", "+", "\".\"", "+", "model_parameters", "[", "\"model\"", "]", "\n", "\n", "model_class", "=", "load_class", "(", "full_class_path", ")", "\n", "network", ",", "checkpoint_name", "=", "load_network", "(", "model_class", ",", "\n", "conf_file", "=", "conf_file", ",", "\n", "dataset", "=", "dataset", ",", "\n", "global_step", "=", "global_step", ")", "\n", "# LOAD NETWORK", "\n", "\n", "stuff", "=", "network", "(", "dummy_x", ",", "is_training", "=", "is_training", ")", "\n", "network", ".", "restore", "(", "sess", ",", "checkpoint_name", ")", "\n", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.check_dataset_shapes": [[56, 62], ["numpy.testing.assert_array_equal", "str", "str"], "function", ["None"], ["", "def", "check_dataset_shapes", "(", "shape1", ",", "shape2", ")", ":", "\n", "# if datasets x_shape are different raise Exception! what is the meaning of a comparison otherwise?", "\n", "    ", "np", ".", "testing", ".", "assert_array_equal", "(", "shape1", ",", "shape2", ",", "\n", "\"the datasets that you are trying to load have \\\n                different x_shape : `%s` and `%s`\"", "%", "(", "\n", "str", "(", "shape1", ")", ",", "str", "(", "shape2", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.get_transform_id": [[66, 109], ["transform.extract_last_dir", "transform.extract_last_dir", "print", "print", "ValueError", "str"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.extract_last_dir", "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.extract_last_dir"], ["", "def", "get_transform_id", "(", "method_name", ",", "method_kwargs", ")", ":", "\n", "    ", "\"\"\"Creates the id for a transformation.\n\n    Args:\n        method_tuple (tuple): A tuple composed of : (name of the builder function, kwargs to pass to the function).\n\n    Returns:\n        string: the idname of the function that we want to concatenate in the output filenames.\n\n    \"\"\"", "\n", "\n", "# listWithPoints = lambda x: \".\".join(re.sub('[( )\\[\\]]', '', str(x)).replace(' ', '').split(\",\"))", "\n", "\n", "if", "method_name", "==", "'identity'", ":", "\n", "        ", "methodid", "=", "\"clean\"", "\n", "\n", "# elif method_name == 'resize':", "\n", "#     methodid = 'resize' + method_kwargs['intermediate_size']", "\n", "\n", "", "elif", "method_name", "==", "'ae'", ":", "\n", "        ", "methodid", "=", "extract_last_dir", "(", "method_kwargs", "[", "'conf_file'", "]", ")", "\n", "\n", "if", "method_kwargs", "[", "'global_step'", "]", "is", "not", "None", ":", "\n", "            ", "methodid", "+=", "\"-gs\"", "+", "method_kwargs", "[", "'global_step'", "]", "\n", "", "methodid", "+=", "\"-sh\"", "#+ \"{:d}\".format(method_kwargs[\"sample_hid\"])", "\n", "\n", "", "elif", "method_name", "==", "'vae'", ":", "\n", "        ", "methodid", "=", "extract_last_dir", "(", "method_kwargs", "[", "'conf_file'", "]", ")", "\n", "\n", "if", "method_kwargs", "[", "'global_step'", "]", "is", "not", "None", ":", "\n", "            ", "methodid", "+=", "\"-gs\"", "+", "method_kwargs", "[", "'global_step'", "]", "\n", "\n", "", "methodid", "+=", "\"-sh\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "\"sample_hid\"", "]", ")", "\n", "methodid", "+=", "\"-sx\"", "+", "\"{:d}\"", ".", "format", "(", "method_kwargs", "[", "\"sample_vis\"", "]", ")", "\n", "methodid", "+=", "\"-zsc\"", "+", "str", "(", "method_kwargs", "[", "\"z_std_scale\"", "]", ")", "\n", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'----------------------'", ")", "\n", "print", "(", "'ERROR '", ",", "method_name", ")", "\n", "raise", "ValueError", "(", "\"id rule for `%s` has to be implemented.\"", "%", "method_name", ")", "\n", "\n", "", "return", "methodid", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.transform.transform.extract_last_dir": [[110, 112], ["os.path.basename", "os.path.dirname"], "function", ["None"], ["", "def", "extract_last_dir", "(", "path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotSenti.load_x_y": [[16, 28], ["print", "f.read.split", "open", "f.read", "float", "float", "row.split", "row.split"], "function", ["None"], ["def", "load_x_y", "(", "file_path", ")", ":", "\n", "    ", "print", "(", "file_path", ")", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "data", "=", "data", ".", "split", "(", "'\\n'", ")", "\n", "data", "=", "data", "[", ":", "-", "1", "]", "\n", "\n", "x", "=", "[", "float", "(", "row", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", ")", "for", "row", "in", "data", "]", "\n", "y", "=", "[", "float", "(", "row", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", ")", "for", "row", "in", "data", "]", "\n", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.plot_single_errorbar": [[75, 98], ["df.groupby", "zip", "numpy.linspace", "scipy.interpolate.make_interp_spline", "scipy.interpolate.make_interp_spline.", "matplotlib.pyplot.plot", "xdata.append", "ydata.append", "yerr.append", "numpy.min", "numpy.max", "sorted", "float", "df.max", "df.std", "zip"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.hooks.HMFisherMatrixHook2.HMFisherMatrixHook2.plot"], ["def", "plot_single_errorbar", "(", "df", ",", "x", ",", "y", ",", "string_replace", "=", "{", "}", ",", "**", "kwargs", ")", ":", "\n", "    ", "xdata", "=", "[", "]", "\n", "ydata", "=", "[", "]", "\n", "yerr", "=", "[", "]", "\n", "\n", "for", "label", ",", "df", "in", "df", ".", "groupby", "(", "x", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "x_value", "=", "string_replace", "[", "label", "]", "\n", "", "except", ":", "\n", "            ", "x_value", "=", "float", "(", "label", ")", "\n", "\n", "", "xdata", ".", "append", "(", "x_value", ")", "\n", "# ydata.append(df.mean()[y])", "\n", "ydata", ".", "append", "(", "df", ".", "max", "(", ")", "[", "y", "]", ")", "\n", "yerr", ".", "append", "(", "df", ".", "std", "(", ")", "[", "y", "]", ")", "\n", "\n", "\n", "", "xdata", ",", "ydata", ",", "yerr", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "xdata", ",", "ydata", ",", "yerr", ")", ")", ")", "\n", "# plt.errorbar(xdata, ydata, yerr=yerr, **kwargs)", "\n", "xnew", "=", "np", ".", "linspace", "(", "np", ".", "min", "(", "xdata", ")", ",", "np", ".", "max", "(", "xdata", ")", ",", "31", ")", "\n", "spl", "=", "make_interp_spline", "(", "xdata", ",", "ydata", ",", "k", "=", "1", ")", "\n", "ynew", "=", "spl", "(", "xnew", ")", "\n", "plt", ".", "plot", "(", "xnew", ",", "ynew", "*", "100", ",", "marker", "=", "'o'", ",", "**", "kwargs", ")", "\n", "# plt.plot(xdata, np.array(ydata)*100, marker='o', **kwargs)", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.nice_label": [[102, 117], ["[].replace", "arr[].upper", "[].split", "arr[].split", "filename.split"], "function", ["None"], ["def", "nice_label", "(", "filename", ")", ":", "\n", "    ", "arr", "=", "filename", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "'_'", ")", "[", "2", ":", "-", "1", "]", "\n", "evsize", "=", "arr", "[", "0", "]", ".", "split", "(", "'-'", ")", "[", "1", "]", ".", "replace", "(", "'v'", ",", "'E'", ")", "\n", "theta", "=", "arr", "[", "1", "]", ".", "upper", "(", ")", "\n", "point", "=", "arr", "[", "2", "]", "\n", "norm", "=", "arr", "[", "3", "]", "\n", "prod", "=", "arr", "[", "4", "]", "\n", "\n", "skip", "=", "False", "\n", "if", "norm", "[", "1", "]", "!=", "prod", ":", "\n", "        ", "skip", "=", "True", "\n", "", "if", "not", "(", "theta", "in", "thetas", ")", ":", "\n", "        ", "skip", "=", "True", "\n", "\n", "", "return", "\"-\"", ".", "join", "(", "[", "evsize", ",", "theta", ",", "point", ",", "prod", "]", ")", ",", "skip", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.log_clustering_name": [[119, 121], ["None"], "function", ["None"], ["", "def", "log_clustering_name", "(", ")", ":", "\n", "    ", "\"{:}_clustering\"", ".", "format", "(", "task_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters._tryfloat": [[122, 129], ["float"], "function", ["None"], ["", "def", "_tryfloat", "(", "v", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "value", "=", "float", "(", "v", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "value", "=", "v", "\n", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.add_one_plot": [[131, 144], ["plotClusters.nice_label", "pandas.read_csv", "plotClusters.plot_single_errorbar"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.nice_label", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.plot_single_errorbar"], ["", "def", "add_one_plot", "(", "matches", ",", "x", ",", "y", ")", ":", "\n", "    ", "replace_strings_for_plots", "=", "{", "\n", "'limit'", ":", "-", "6.", ",", "# since for plotting I need to choose a value", "\n", "}", "\n", "\n", "for", "filename", "in", "matches", ":", "\n", "        ", "label", ",", "skip", "=", "nice_label", "(", "filename", ")", "\n", "if", "skip", ":", "\n", "            ", "continue", "\n", "\n", "", "df", "=", "pd", ".", "read_csv", "(", "filename", ",", "**", "pd_csv_kwargs", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "plot_single_errorbar", "(", "df", ",", "x", ",", "y", ",", "string_replace", "=", "replace_strings_for_plots", ",", "alpha", "=", "0.9", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.finalize_plot": [[146, 171], ["matplotlib.pyplot.title", "matplotlib.pyplot.ylim", "matplotlib.pyplot.xlim", "matplotlib.pyplot.gca", "plt.gca.set_xticks", "matplotlib.ticker.AutoMinorLocator", "plt.gca.xaxis.set_minor_locator", "plt.gca.set_yticks", "matplotlib.ticker.AutoMinorLocator", "plt.gca.yaxis.set_minor_locator", "plt.gca.set_axisbelow", "plt.gca.grid", "plt.gca.grid", "plt.gca.legend", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "numpy.arange", "numpy.arange", "min", "max"], "function", ["None"], ["", "", "def", "finalize_plot", "(", "ylim", ",", "plotoutpath", ",", "suptitle", "=", "''", ")", ":", "\n", "    ", "plt", ".", "title", "(", "suptitle", ")", "\n", "xlim", "=", "(", "-", "6.", ",", "4.", ")", "\n", "plt", ".", "ylim", "(", "ylim", ")", "\n", "plt", ".", "xlim", "(", "xlim", ")", "\n", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "xlim", "[", "0", "]", ",", "xlim", "[", "1", "]", ",", "1", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "2", ")", "\n", "ax", ".", "xaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "min", "(", "ylim", ")", ",", "max", "(", "ylim", ")", "+", "1", ",", "2", ")", ")", "\n", "minor_locator", "=", "AutoMinorLocator", "(", "2", ")", "\n", "ax", ".", "yaxis", ".", "set_minor_locator", "(", "minor_locator", ")", "\n", "\n", "ax", ".", "set_axisbelow", "(", "True", ")", "\n", "# ax.grid(which='major', linestyle='-', linewidth='0.5', color='gray')", "\n", "# ax.grid(which='minor', linestyle='-', linewidth='0.5', color='gray')", "\n", "ax", ".", "grid", "(", "which", "=", "'major'", ",", "linestyle", "=", "'--'", ",", "linewidth", "=", "'1'", ",", "color", "=", "'lightgray'", ")", "\n", "ax", ".", "grid", "(", "which", "=", "'minor'", ",", "linestyle", "=", "':'", ",", "linewidth", "=", "'1'", ",", "color", "=", "'lightgray'", ")", "\n", "\n", "lgd", "=", "ax", ".", "legend", "(", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.1", ")", ",", "ncol", "=", "2", ")", "\n", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "plotoutpath", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plot20newsgroup.load_x_y": [[18, 30], ["print", "f.read.split", "open", "f.read", "float", "float", "row.split", "row.split"], "function", ["None"], ["def", "load_x_y", "(", "file_path", ")", ":", "\n", "    ", "print", "(", "file_path", ")", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "data", "=", "data", ".", "split", "(", "'\\n'", ")", "\n", "data", "=", "data", "[", ":", "-", "1", "]", "\n", "\n", "x", "=", "[", "float", "(", "row", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", ")", "for", "row", "in", "data", "]", "\n", "y", "=", "[", "float", "(", "row", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", ")", "for", "row", "in", "data", "]", "\n", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.save_test_file": [[25, 37], ["os.makedirs", "print", "float", "float", "numpy.savetxt", "print", "open", "f.read", "f.read.split", "numpy.array", "f.read.split", "f.read.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.save_file": [[39, 53], ["numpy.hstack", "os.makedirs", "numpy.savetxt", "numpy.array", "os.makedirs", "numpy.savetxt", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.logical_xor": [[55, 57], ["bool", "bool"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.solve": [[58, 83], ["print", "sklearn.linear_model.LogisticRegression", "datetime.datetime.now", "sklearn.linear_model.LogisticRegression.fit", "datetime.datetime.now", "print", "sklearn.linear_model.LogisticRegression.predict", "sklearn.metrics.accuracy_score", "sklearn.linear_model.LogisticRegression.predict", "sklearn.metrics.accuracy_score", "str", "delta.total_seconds"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.predict", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.predict"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.logistic_regression": [[84, 167], ["numpy.concatenate", "multiprocessing.Manager", "multiprocessing.Manager.dict", "multiprocessing.Manager.dict", "multiprocessing.Manager.dict", "multiprocessing.Pool", "functools.partial", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "max", "print", "sklearn.linear_model.LogisticRegression", "models[].predict", "sklearn.metrics.accuracy_score", "utils.logical_xor", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.Normalizer.fit_transform", "sklearn.preprocessing.Normalizer.transform", "sklearn.preprocessing.Normalizer.transform", "sklearn.preprocessing.Normalizer", "sklearn.preprocessing.Normalizer.fit_transform", "sklearn.preprocessing.Normalizer.transform", "sklearn.preprocessing.Normalizer.transform", "dict", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "sorted", "sorted", "manager.dict.items", "manager.dict.items", "dict"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.predict", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.logical_xor"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.accuracy_tf_idf": [[171, 192], ["sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit_transform", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "utils.logistic_regression", "int"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.logistic_regression"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.accuracy_glove": [[194, 218], ["datetime.datetime.now", "print", "utils.vectorizer_glove", "utils.vectorizer_glove", "datetime.datetime.now", "print", "utils.logistic_regression", "int", "str", "delta.total_seconds"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.vectorizer_glove", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.vectorizer_glove", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.logistic_regression"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.vectorize": [[236, 284], ["sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer", "datetime.datetime.now", "zip", "datetime.datetime.now", "print", "vectorizer.build_analyzer.", "len", "numpy.mean", "global_X.append", "global_Y.append", "document.append", "str", "delta.total_seconds"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.vectorizer_glove": [[286, 332], ["multiprocessing.Manager", "multiprocessing.Manager.list", "multiprocessing.Manager.list", "len", "multiprocessing.Pool", "functools.partial", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "numpy.arange", "numpy.array", "numpy.array"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.old_vectorizer_glove": [[334, 376], ["sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.build_analyzer", "zip", "vectorizer.build_analyzer.", "numpy.array", "len", "numpy.mean", "Y.append", "print", "document.append", "numpy.vstack"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.utils.load_embedding": [[377, 388], ["print", "riccardo.read_glove.load_glove", "print", "riccardo.read_glove.load_pretrained_glove"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_glove", "home.repos.pwc.inspect_result.rist-ro_argo.core.load_embeddings.load_pretrained_glove"], []], "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.senti.read_senti": [[56, 72], ["pandas.read_table", "df_data_sentence[].str.split", "df_data_sentence_processed.rename.rename", "pandas.read_table", "df_data_sentiment[].str.split", "df_data_sentiment_processed.rename.rename", "df_data_sentence_processed.rename.merge"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.test.logmap_similarities_plot.merge"], ["", "def", "read_senti", "(", "path", ")", ":", "\n", "# read dictionary into df", "\n", "    ", "df_data_sentence", "=", "pd", ".", "read_table", "(", "path", "+", "'dictionary.txt'", ")", "\n", "df_data_sentence_processed", "=", "df_data_sentence", "[", "'Phrase|Index'", "]", ".", "str", ".", "split", "(", "'|'", ",", "expand", "=", "True", ")", "\n", "df_data_sentence_processed", "=", "df_data_sentence_processed", ".", "rename", "(", "columns", "=", "{", "0", ":", "'Phrase'", ",", "1", ":", "'phrase_ids'", "}", ")", "\n", "\n", "# read sentiment labels into df", "\n", "df_data_sentiment", "=", "pd", ".", "read_table", "(", "path", "+", "'sentiment_labels.txt'", ")", "\n", "df_data_sentiment_processed", "=", "df_data_sentiment", "[", "'phrase ids|sentiment values'", "]", ".", "str", ".", "split", "(", "'|'", ",", "expand", "=", "True", ")", "\n", "df_data_sentiment_processed", "=", "df_data_sentiment_processed", ".", "rename", "(", "columns", "=", "{", "0", ":", "'phrase_ids'", ",", "1", ":", "'sentiment_values'", "}", ")", "\n", "\n", "\n", "#combine data frames containing sentence and sentiment", "\n", "df_processed_all", "=", "df_data_sentence_processed", ".", "merge", "(", "df_data_sentiment_processed", ",", "how", "=", "'inner'", ",", "on", "=", "'phrase_ids'", ")", "\n", "\n", "return", "df_processed_all", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.logging.CustomDefaultDict.__missing__": [[16, 19], ["logging.CustomDefaultDict.default_factory"], "methods", ["None"], ["    ", "def", "__missing__", "(", "self", ",", "key", ")", ":", "\n", "        ", "self", "[", "key", "]", "=", "value", "=", "self", ".", "default_factory", "(", "key", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.logging.instantiate_logger": [[4, 13], ["word_embedding.test.core.PandasLogger.PandasLogger"], "function", ["None"], ["def", "instantiate_logger", "(", "keytuple", ",", "output_folder", ",", "log_prefix", ",", "names_to_log", ",", "try_to_convert", "=", "{", "}", ",", "\n", "field_to_sort_by", "=", "None", ",", "replace_strings_for_sort", "=", "{", "}", ")", ":", "\n", "    ", "keystring", "=", "\"_\"", ".", "join", "(", "keytuple", ")", "\n", "return", "PandasLogger", "(", "output_folder", ",", "\n", "\"{:}_{:}\"", ".", "format", "(", "log_prefix", ",", "keystring", ")", ",", "\n", "names_to_log", ",", "\n", "try_to_convert", "=", "try_to_convert", ",", "\n", "field_to_sort_by", "=", "field_to_sort_by", ",", "\n", "replace_strings_for_sort", "=", "replace_strings_for_sort", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.RepeatedBisectionSim.RepeatedBisectionSim.__init__": [[8, 15], ["KMeansSim.KMeansSim.__init__", "SingleKMeansSim.SingleKMeansSim.SingleKMeansSim", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_clusters", ",", "g_matrix", ",", "n_init", "=", "10", ",", "conv", "=", "1e-15", ",", "bm", "=", "'agg'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "n_clusters", ",", "g_matrix", ",", "n_init", "=", "n_init", ",", "conv", "=", "conv", ")", "\n", "self", ".", "_singlebisect", "=", "SingleKMeansSim", "(", "n_clusters", "=", "2", ",", "g_matrix", "=", "g_matrix", ")", "\n", "bisection_measures", "=", "[", "'agg'", ",", "'size'", "]", "# aggregation dissimilarity or size", "\n", "if", "bm", "not", "in", "bisection_measures", ":", "\n", "            ", "raise", "ValueError", "(", "\"bm must be in: {:}, found {:}\"", ".", "format", "(", "bisection_measures", ",", "bm", ")", ")", "\n", "", "self", ".", "_bm", "=", "bm", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.RepeatedBisectionSim.RepeatedBisectionSim._fit_loop": [[16, 24], ["range", "RepeatedBisectionSim.RepeatedBisectionSim._repeated_bisection", "RepeatedBisectionSim.RepeatedBisectionSim._singlekmeans.fit", "RepeatedBisectionSim.RepeatedBisectionSim._set_clusters"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.RepeatedBisectionSim.RepeatedBisectionSim._repeated_bisection", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._set_clusters"], ["", "def", "_fit_loop", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "_n_init", ")", ":", "\n", "            ", "rb_clusters", ",", "rb_centers", "=", "self", ".", "_repeated_bisection", "(", "self", ".", "vectors", ")", "\n", "\n", "clusters", ",", "centers", ",", "labels_", ",", "score", "=", "self", ".", "_singlekmeans", ".", "fit", "(", "self", ".", "vectors", ",", "init", "=", "rb_centers", ")", "\n", "\n", "if", "score", ">", "self", ".", "score", ":", "\n", "                ", "self", ".", "_set_clusters", "(", "score", ",", "clusters", ",", "centers", ",", "labels_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.RepeatedBisectionSim.RepeatedBisectionSim._repeated_bisection": [[25, 38], ["RepeatedBisectionSim.RepeatedBisectionSim._singlebisect.fit", "range", "RepeatedBisectionSim.RepeatedBisectionSim._choose_next_cluster", "all_clusters.pop", "all_centers.pop", "RepeatedBisectionSim.RepeatedBisectionSim._singlebisect.fit"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.RepeatedBisectionSim.RepeatedBisectionSim._choose_next_cluster", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit"], ["", "", "", "def", "_repeated_bisection", "(", "self", ",", "vectors", ")", ":", "\n", "        ", "all_clusters", ",", "all_centers", ",", "all_labels_", ",", "_", "=", "self", ".", "_singlebisect", ".", "fit", "(", "vectors", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "_n_clusters", "-", "2", ")", ":", "\n", "            ", "next_c", "=", "self", ".", "_choose_next_cluster", "(", "all_clusters", ",", "all_centers", ")", "\n", "choosen_cluster", "=", "all_clusters", ".", "pop", "(", "next_c", ")", "\n", "_", "=", "all_centers", ".", "pop", "(", "next_c", ")", "\n", "\n", "b_clusters", ",", "b_centers", ",", "b_labels_", ",", "_", "=", "self", ".", "_singlebisect", ".", "fit", "(", "choosen_cluster", ")", "\n", "all_clusters", "+=", "b_clusters", "\n", "all_centers", "+=", "b_centers", "\n", "\n", "", "return", "all_clusters", ",", "all_centers", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.RepeatedBisectionSim.RepeatedBisectionSim._choose_next_cluster": [[39, 48], ["numpy.argmax", "utils.aggregate_dissimilarity", "Exception", "len"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.aggregate_dissimilarity"], ["", "def", "_choose_next_cluster", "(", "self", ",", "clusters", ",", "centers", ")", ":", "\n", "        ", "if", "self", ".", "_bm", "==", "'agg'", ":", "\n", "            ", "measure", "=", "aggregate_dissimilarity", "(", "clusters", ",", "centers", ",", "self", ".", "_g_matrix", ")", "\n", "", "elif", "self", ".", "_bm", "==", "'size'", ":", "\n", "            ", "measure", "=", "[", "len", "(", "cl", ")", "for", "cl", "in", "clusters", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'bm not understood'", ")", "\n", "\n", "", "return", "np", ".", "argmax", "(", "measure", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.__init__": [[8, 15], ["SingleKMeansSim.SingleKMeansSim.SingleKMeansSim", "KMeansSim.KMeansSim._reset_clusters"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._reset_clusters"], ["def", "__init__", "(", "self", ",", "n_clusters", ",", "g_matrix", ",", "n_init", "=", "10", ",", "conv", "=", "1e-15", ")", ":", "\n", "        ", "self", ".", "_n_clusters", "=", "n_clusters", "\n", "self", ".", "_n_init", "=", "n_init", "\n", "self", ".", "_convergence_tol", "=", "conv", "\n", "self", ".", "_g_matrix", "=", "g_matrix", "\n", "self", ".", "_singlekmeans", "=", "SingleKMeansSim", "(", "n_clusters", "=", "n_clusters", ",", "g_matrix", "=", "g_matrix", ")", "\n", "self", ".", "_reset_clusters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._reset_clusters": [[16, 21], ["None"], "methods", ["None"], ["", "def", "_reset_clusters", "(", "self", ")", ":", "\n", "        ", "self", ".", "score", "=", "-", "np", ".", "inf", "\n", "self", ".", "clusters", "=", "[", "[", "]", "]", "*", "self", ".", "_n_clusters", "\n", "self", ".", "centers", "=", "[", "]", "\n", "self", ".", "labels_", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._set_clusters": [[22, 27], ["None"], "methods", ["None"], ["", "def", "_set_clusters", "(", "self", ",", "score", ",", "clusters", ",", "centers", ",", "labels_", ")", ":", "\n", "        ", "self", ".", "score", "=", "score", "\n", "self", ".", "clusters", "=", "clusters", "\n", "self", ".", "centers", "=", "centers", "\n", "self", ".", "labels_", "=", "labels_", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._vectors_check": [[28, 41], ["numpy.array", "len", "utils.riemannian_norm", "utils.riemannian_norm.reshape"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_norm"], ["", "def", "_vectors_check", "(", "self", ",", "vectors", ",", "norm_vecs", ")", ":", "\n", "        ", "vectors", "=", "np", ".", "array", "(", "vectors", ")", "\n", "\n", "assert", "len", "(", "vectors", ")", ">=", "self", ".", "_n_clusters", "\n", "\n", "if", "norm_vecs", ":", "\n", "            ", "norm", "=", "riemannian_norm", "(", "vectors", ",", "self", ".", "_g_matrix", ")", "\n", "vectors", "=", "vectors", "/", "norm", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "# unstack vectors", "\n", "", "*", "vectors", ",", "=", "vectors", "\n", "\n", "return", "vectors", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.fit": [[42, 49], ["KMeansSim.KMeansSim._vectors_check", "KMeansSim.KMeansSim._reset_clusters", "KMeansSim.KMeansSim._fit_loop"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._vectors_check", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._reset_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._fit_loop"], ["", "def", "fit", "(", "self", ",", "vectors", ",", "norm_vecs", "=", "True", ")", ":", "\n", "        ", "\"\"\"Perform clustering.\"\"\"", "\n", "vectors", "=", "self", ".", "_vectors_check", "(", "vectors", ",", "norm_vecs", ")", "\n", "self", ".", "vectors", "=", "vectors", "\n", "self", ".", "_reset_clusters", "(", ")", "\n", "\n", "self", ".", "_fit_loop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._fit_loop": [[50, 56], ["range", "KMeansSim.KMeansSim._singlekmeans.fit", "KMeansSim.KMeansSim._set_clusters"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim._set_clusters"], ["", "def", "_fit_loop", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "_n_init", ")", ":", "\n", "            ", "clusters", ",", "centers", ",", "labels_", ",", "score", "=", "self", ".", "_singlekmeans", ".", "fit", "(", "self", ".", "vectors", ")", "\n", "\n", "if", "score", ">", "self", ".", "score", ":", "\n", "                ", "self", ".", "_set_clusters", "(", "score", ",", "clusters", ",", "centers", ",", "labels_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.predict": [[57, 61], ["utils.cos_similarity", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.cos_similarity"], ["", "", "", "def", "predict", "(", "self", ",", "vectors", ")", ":", "\n", "        ", "sims", "=", "cos_similarity", "(", "vectors", ",", "self", ".", "centers", ",", "g_matrix", "=", "self", ".", "_g_matrix", ")", "\n", "labels_", "=", "np", ".", "argmax", "(", "sims", ",", "axis", "=", "1", ")", "\n", "return", "labels_", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.__init__": [[7, 12], ["range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_clusters", ",", "g_matrix", ")", ":", "\n", "        ", "self", ".", "_n_clusters", "=", "n_clusters", "\n", "self", ".", "clusters", "=", "[", "[", "]", "for", "i", "in", "range", "(", "n_clusters", ")", "]", "\n", "self", ".", "_convergence_tol", "=", "1e-10", "\n", "self", ".", "_g_matrix", "=", "g_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim._update_clusters": [[13, 22], ["utils.cos_similarity", "numpy.argmax", "zip", "SingleKMeansSim.SingleKMeansSim.clusters[].append"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.cos_similarity"], ["", "def", "_update_clusters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Determine which cluster center each `self.vector` is closest to.\"\"\"", "\n", "self", ".", "clusters", "=", "[", "[", "]", "for", "c", "in", "self", ".", "centers", "]", "\n", "\n", "sims", "=", "cos_similarity", "(", "self", ".", "vectors", ",", "self", ".", "centers", ",", "g_matrix", "=", "self", ".", "_g_matrix", ")", "\n", "self", ".", "labels_", "=", "np", ".", "argmax", "(", "sims", ",", "axis", "=", "1", ")", "\n", "\n", "for", "index", ",", "vector", "in", "zip", "(", "self", ".", "labels_", ",", "self", ".", "vectors", ")", ":", "\n", "            ", "self", ".", "clusters", "[", "index", "]", ".", "append", "(", "vector", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim._update_centers": [[23, 37], ["numpy.allclose", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean"], ["", "", "def", "_update_centers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move `self.centers` to the centers of `self.clusters`.\n\n        Return True if centers moved, else False.\n\n        \"\"\"", "\n", "\n", "new_centers", "=", "[", "np", ".", "mean", "(", "cl", ",", "axis", "=", "0", ")", "for", "cl", "in", "self", ".", "clusters", "]", "\n", "\n", "if", "np", ".", "allclose", "(", "new_centers", ",", "self", ".", "centers", ",", "atol", "=", "self", ".", "_convergence_tol", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "self", ".", "centers", "=", "new_centers", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit": [[38, 60], ["SingleKMeansSim.SingleKMeansSim._update_clusters", "SingleKMeansSim.SingleKMeansSim._update_centers", "utils.sim_score", "SingleKMeansSim.smart_initialize", "SingleKMeansSim.SingleKMeansSim._update_clusters", "random.sample", "isinstance", "isinstance", "numpy.array", "numpy.testing.assert_equal", "ValueError", "type"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim._update_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim._update_centers", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.sim_score", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.smart_initialize", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim._update_clusters", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample"], ["", "def", "fit", "(", "self", ",", "vectors", ",", "init", "=", "'kmeans++'", ")", ":", "\n", "        ", "\"\"\"Perform k-means clustering.\"\"\"", "\n", "\n", "self", ".", "vectors", "=", "vectors", "\n", "\n", "if", "init", "==", "'kmeans++'", ":", "\n", "            ", "self", ".", "centers", "=", "smart_initialize", "(", "vectors", ",", "self", ".", "_n_clusters", ",", "g_matrix", "=", "self", ".", "_g_matrix", ")", "\n", "", "elif", "init", "==", "'random'", ":", "\n", "            ", "self", ".", "centers", "=", "random", ".", "sample", "(", "vectors", ",", "self", ".", "_n_clusters", ")", "\n", "", "elif", "isinstance", "(", "init", ",", "np", ".", "ndarray", ")", "or", "isinstance", "(", "init", ",", "list", ")", ":", "\n", "            ", "self", ".", "centers", "=", "np", ".", "array", "(", "init", ")", "\n", "np", ".", "testing", ".", "assert_equal", "(", "self", ".", "centers", ".", "shape", "[", "0", "]", ",", "self", ".", "_n_clusters", ",", "\"initial centers must be same number of the desired clusters\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"init can be `kmeans++`, `random` or a list/numpy.ndarray, found: {:}\"", ".", "format", "(", "type", "(", "init", ")", ")", ")", "\n", "\n", "", "self", ".", "_update_clusters", "(", ")", "\n", "while", "self", ".", "_update_centers", "(", ")", ":", "\n", "            ", "self", ".", "_update_clusters", "(", ")", "\n", "\n", "", "self", ".", "score", "=", "sim_score", "(", "self", ".", "clusters", ",", "self", ".", "centers", ",", "g_matrix", "=", "self", ".", "_g_matrix", ")", "\n", "\n", "return", "self", ".", "clusters", ",", "self", ".", "centers", ",", "self", ".", "labels_", ",", "self", ".", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.smart_initialize": [[62, 73], ["random.sample", "range", "numpy.min", "numpy.arange", "numpy.random.choice", "random.sample.append", "utils.dist_on_sphere", "np.min.sum", "len"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.MultivariateNormalTriLChannelFlipped.MultivariateNormalTriLChannelFlipped.sample", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.dist_on_sphere"], ["", "", "def", "smart_initialize", "(", "vectors", ",", "K", ",", "g_matrix", ")", ":", "\n", "    ", "C", "=", "random", ".", "sample", "(", "vectors", ",", "1", ")", "\n", "\n", "for", "k", "in", "range", "(", "1", ",", "K", ")", ":", "\n", "        ", "min_dist", "=", "np", ".", "min", "(", "dist_on_sphere", "(", "vectors", ",", "C", ",", "g_matrix", "=", "g_matrix", ")", ",", "axis", "=", "1", ")", "\n", "probs", "=", "min_dist", "/", "min_dist", ".", "sum", "(", ")", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "vectors", ")", ")", "\n", "i_c", "=", "np", ".", "random", ".", "choice", "(", "indices", ",", "p", "=", "probs", ")", "\n", "C", ".", "append", "(", "vectors", "[", "i_c", "]", ")", "\n", "\n", "", "return", "C", "", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.load_csv_into_dict": [[18, 27], ["pandas.read_csv", "len", "len", "print", "[].apply().to_dict", "df[].isin", "[].apply", "float", "pd.read_csv.groupby"], "function", ["None"], ["return", "data_min", ",", "data_max", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.frame_path": [[28, 30], ["os.path.join", "utils.frame_name"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.frame_name"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.frame_name": [[31, 33], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.make_video": [[36, 42], ["subprocess.Popen", "subprocess.Popen.wait"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.make_frame": [[43, 52], ["utils.frame_path", "utils.check_exist", "utils.low_dim_clust", "utils.scatter_plot"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.frame_path", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_exist", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.low_dim_clust", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.scatter_plot"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.get_indices": [[54, 56], ["numpy.array"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.get_enc": [[59, 68], ["sklearn.decomposition.PCA", "MulticoreTSNE.MulticoreTSNE", "Exception"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.get_color_list": [[69, 79], ["list", "matplotlib.to_hex", "matplotlib.TABLEAU_COLORS.values", "list", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap.", "matplotlib.cm.get_cmap", "matplotlib.cm.get_cmap", "range"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.do_clustering": [[81, 92], ["utils.compute_scores", "cluster_obj.fit", "cluster_obj.fit", "cluster_obj.predict"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.compute_scores", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.SingleKMeansSim.SingleKMeansSim.fit", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.KMeansSim.KMeansSim.predict"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.low_dim_clusters": [[93, 101], ["utils.low_dim_clust", "clusters_2d_list.append"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.low_dim_clust"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.low_dim_clust": [[102, 113], ["utils.unpack_clusters_dict", "encoder.fit_transform", "utils.repack_clusters_dict", "sklearn.preprocessing.scale"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.unpack_clusters_dict", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.repack_clusters_dict"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.low_dim_cluster_points": [[114, 120], ["encoder.fit_transform", "numpy.max"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.unpack_clusters_dict": [[121, 131], ["list", "zip", "numpy.concatenate", "numpy.concatenate", "clusters.keys", "enumerate"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.repack_clusters_dict": [[132, 139], ["iter", "list", "list", "itertools.islice", "enumerate"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.make_clusters_out_of": [[140, 147], ["clusters_list.append", "groups.items", "utils.get_indices"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.get_indices"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.preprocess_clusters": [[148, 160], ["utils.unpack_clusters_dict", "preproc_method", "utils.repack_clusters_dict"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.unpack_clusters_dict", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.repack_clusters_dict"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.expected_keys": [[162, 168], ["len", "hasattr", "Exception"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_exist": [[170, 172], ["os.path.exists", "os.path.getsize"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.scatter_plot": [[173, 183], ["word_embedding.test.core.plotting.initialize_plot", "clusters_2d.items", "word_embedding.test.core.plotting.finalize_plot", "matplotlib.pyplot.close", "zip", "matplotlib.pyplot.scatter"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.core.plotting.initialize_plot", "home.repos.pwc.inspect_result.rist-ro_argo.word_embeddings.plotClusters.finalize_plot"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.mean_centroid_dist": [[185, 216], ["numpy.mean", "numpy.mean", "centroid.reshape.reshape", "numpy.sum().reshape", "numpy.sum().reshape", "numpy.testing.assert_array_equal", "utils.check_sqdist_numerics", "numpy.sqrt", "numpy.matmul", "numpy.matmul().reshape", "numpy.matmul", "list", "word_embedding.test.core.spaces.mean_on_sphere", "centroid.reshape.reshape", "word_embedding.test.core.spaces.dist_sphere_riem_amb", "ValueError", "centroid.reshape.reshape", "numpy.sum", "numpy.sum", "map", "numpy.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_sqdist_numerics", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.mean_on_sphere", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.dist_sphere_riem_amb"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.silhouette": [[217, 221], ["dist_method", "sklearn.metrics.silhouette_score"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils._silhouette": [[222, 249], ["zip", "numpy.concatenate", "numpy.concatenate", "sklearn.metrics.silhouette_score", "numpy.sum", "utils.check_sqdist_numerics_diagzero", "numpy.sqrt", "numpy.max", "numpy.matmul", "word_embedding.test.core.spaces.dist_sphere_riem_amb", "ValueError", "np.sum.reshape", "np.sum.reshape", "numpy.matmul", "enumerate", "clusters.keys"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_sqdist_numerics_diagzero", "home.repos.pwc.inspect_result.rist-ro_argo.core.spaces.dist_sphere_riem_amb"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_sqdist_numerics_diagzero": [[256, 273], ["numpy.diag", "numpy.allclose", "numpy.fill_diagonal", "numpy.min", "numpy.max", "numpy.min", "numpy.max", "numpy.fill_diagonal", "numpy.min"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.rough_sqdist_numerics_diagzero": [[274, 285], ["numpy.fill_diagonal", "numpy.min", "numpy.max", "numpy.fill_diagonal", "numpy.min"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_sqdist_numerics": [[286, 297], ["numpy.min", "numpy.max", "numpy.min"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.print_scores": [[298, 301], ["utils.compute_scores", "print"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.compute_scores"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.compute_scores": [[302, 310], ["dist_method", "utils.purity_score", "sklearn.metrics.homogeneity_score", "sklearn.metrics.completeness_score", "sklearn.metrics.silhouette_score"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.purity_score"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.purity_score": [[311, 316], ["sklearn.metrics.cluster.contingency_matrix", "numpy.sum", "numpy.sum", "numpy.amax"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.sim_score": [[317, 320], ["numpy.mean", "numpy.mean", "utils.dist_on_sphere", "zip"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.wavenet.GaussianTriDiagonalPrecision.GaussianTriDiagonalPrecision.mean", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.dist_on_sphere"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.aggregate_dissimilarity": [[321, 326], ["numpy.testing.assert_equal", "numpy.array().reshape", "numpy.testing.assert_equal", "len", "len", "len", "len", "numpy.array", "zip", "len", "utils.riemannian_sqnorm"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_sqnorm"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.cos_similarity": [[327, 342], ["utils.check_and_reshape", "utils.check_and_reshape", "numpy.matmul", "numpy.matmul", "numpy.matmul", "numpy.sqrt", "numpy.sqrt", "numpy.sum", "numpy.sum", "np.sqrt.reshape", "np.sqrt.reshape"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_and_reshape", "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_and_reshape"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.dist_on_sphere": [[343, 346], ["utils.cos_similarity", "numpy.arccos", "numpy.clip"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.cos_similarity", "home.repos.pwc.inspect_result.rist-ro_argo.core.utils.clip"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_and_reshape": [[347, 353], ["numpy.asarray", "len", "emb.reshape.reshape", "len", "numpy.array"], "function", ["None"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_norm": [[354, 357], ["utils.riemannian_sqnorm", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_sqnorm"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_sqnorm": [[358, 363], ["utils.check_and_reshape", "numpy.sum().reshape", "numpy.matmul", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.check_and_reshape"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_dist": [[364, 381], ["numpy.matmul", "numpy.sum", "numpy.matmul", "numpy.sum", "utils.rough_sqdist_numerics_diagzero", "numpy.sqrt", "np.sum.reshape", "np.sum.reshape", "numpy.matmul"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.rough_sqdist_numerics_diagzero"], []], "home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_normalize": [[384, 386], ["riemannian_norm().reshape", "utils.riemannian_norm"], "function", ["home.repos.pwc.inspect_result.rist-ro_argo.clustering.utils.riemannian_norm"], []], "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromWords.MyEmbeddingsFromWords.__init__": [[5, 18], ["super().__init__", "tensorflow.lookup.StaticHashTable", "numpy.expand_dims", "tensorflow.constant", "numpy.zeros", "numpy.concatenate", "tensorflow.lookup.KeyValueTensorInitializer", "tensorflow.constant", "list", "list", "dictionary.keys", "dictionary.values"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dictionary", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_table_dictionary", "=", "tf", ".", "lookup", ".", "StaticHashTable", "(", "\n", "initializer", "=", "tf", ".", "lookup", ".", "KeyValueTensorInitializer", "(", "\n", "keys", "=", "list", "(", "dictionary", ".", "keys", "(", ")", ")", ",", "\n", "values", "=", "list", "(", "dictionary", ".", "values", "(", ")", ")", ",", "\n", ")", ",", "\n", "default_value", "=", "tf", ".", "constant", "(", "-", "1", ")", ",", "\n", "name", "=", "\"vocab\"", "\n", ")", "\n", "\n", "unk_emb", "=", "np", ".", "expand_dims", "(", "np", ".", "zeros", "(", "embeddings", ".", "shape", "[", "1", "]", ")", ",", "axis", "=", "0", ")", "\n", "self", ".", "_all_embs", "=", "tf", ".", "constant", "(", "np", ".", "concatenate", "(", "(", "embeddings", ",", "unk_emb", ")", ",", "axis", "=", "0", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromWords.MyEmbeddingsFromWords.call": [[19, 23], ["MyEmbeddingsFromWords.MyEmbeddingsFromWords._table_dictionary.lookup", "tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "words_indexes", "=", "self", ".", "_table_dictionary", ".", "lookup", "(", "inputs", ")", "\n", "batch_embs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_all_embs", ",", "words_indexes", ")", "\n", "return", "batch_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__": [[5, 10], ["super().__init__", "numpy.expand_dims", "tensorflow.constant", "numpy.zeros", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embeddings", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "unk_emb", "=", "np", ".", "expand_dims", "(", "np", ".", "zeros", "(", "embeddings", ".", "shape", "[", "1", "]", ")", ",", "axis", "=", "0", ")", "\n", "self", ".", "_all_embs", "=", "tf", ".", "constant", "(", "np", ".", "concatenate", "(", "(", "embeddings", ",", "unk_emb", ")", ",", "axis", "=", "0", ")", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rist-ro_argo.layers.MyEmbeddingsFromInts.MyEmbeddingsFromInts.call": [[11, 14], ["tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "batch_embs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "_all_embs", ",", "inputs", ")", "\n", "return", "batch_embs", "\n", "\n"]]}