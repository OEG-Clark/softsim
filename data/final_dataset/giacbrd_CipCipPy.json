{"home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.annotation.entities": [[4, 36], ["dxtr.spot", "set", "mentions.keys", "spots.append", "set", "enumerate", "set.add", "enumerate", "dxtr.get_spots"], "function", ["None"], ["def", "entities", "(", "text", ",", "dxtr", ",", "link_prob", ")", ":", "\n", "    ", "\"\"\"Returns all the useful information from the entity linking system for a text\"\"\"", "\n", "dxtr_spots", "=", "dxtr", ".", "spot", "(", "text", ")", "\n", "spots", "=", "[", "]", "\n", "mentions", "=", "{", "}", "\n", "all_entities", "=", "set", "(", "entity", "[", "\"entity\"", "]", "for", "spot", "in", "dxtr_spots", "if", "spot", "[", "\"linkFrequency\"", "]", ">", "2", "\n", "for", "entity", "in", "spot", "[", "\"candidates\"", "]", "if", "entity", "[", "\"commonness\"", "]", ">=", "0.1", "and", "entity", "[", "\"freq\"", "]", ">", "2", ")", "\n", "for", "spot", "in", "dxtr_spots", ":", "\n", "        ", "if", "spot", "[", "\"linkFrequency\"", "]", "<=", "2", ":", "\n", "            ", "continue", "\n", "", "spot", "[", "\"candidates\"", "]", "=", "[", "ent", "for", "ent", "in", "spot", "[", "\"candidates\"", "]", "if", "ent", "[", "\"commonness\"", "]", ">=", "0.1", "and", "ent", "[", "\"freq\"", "]", ">", "2", "]", "\n", "for", "entity", "in", "spot", "[", "\"candidates\"", "]", ":", "\n", "            ", "ent_id", "=", "entity", "[", "\"entity\"", "]", "\n", "if", "ent_id", "not", "in", "mentions", ":", "\n", "# Do not keep entity candidates of mentions", "\n", "# mentions[ent_id] = [{key: value for key, value in m.iteritems() if key != \"candidates\"}", "\n", "#                     for m in dxtr.get_spots(ent_id) if m[\"linkProbability\"] > link_prob]", "\n", "                ", "mentions", "[", "ent_id", "]", "=", "[", "m", "for", "m", "in", "dxtr", ".", "get_spots", "(", "ent_id", ")", "if", "m", "[", "\"linkProbability\"", "]", ">=", "link_prob", "\n", "and", "m", "[", "\"linkFrequency\"", "]", ">", "2", "]", "\n", "", "", "spots", ".", "append", "(", "spot", ")", "\n", "# Clean up mentions", "\n", "", "for", "ent_id", "in", "mentions", ".", "keys", "(", ")", ":", "\n", "        ", "to_delete", "=", "set", "(", ")", "\n", "for", "i", ",", "ment", "in", "enumerate", "(", "mentions", "[", "ent_id", "]", ")", ":", "\n", "            ", "ment", "[", "\"candidates\"", "]", "=", "[", "ent", "for", "ent", "in", "ment", "[", "\"candidates\"", "]", "if", "ent", "[", "\"entity\"", "]", "in", "all_entities", "\n", "and", "ent", "[", "\"commonness\"", "]", ">=", "0.1", "and", "ent", "[", "\"freq\"", "]", ">", "2", "]", "\n", "if", "not", "ment", "[", "\"candidates\"", "]", ":", "\n", "                ", "to_delete", ".", "add", "(", "i", ")", "\n", "", "", "mentions", "[", "ent_id", "]", "=", "[", "ment", "for", "i", ",", "ment", "in", "enumerate", "(", "mentions", "[", "ent_id", "]", ")", "if", "i", "not", "in", "to_delete", "]", "\n", "if", "not", "mentions", "[", "ent_id", "]", ":", "\n", "            ", "del", "mentions", "[", "ent_id", "]", "\n", "", "", "return", "spots", ",", "mentions", "", "", ""]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.cache.CacheException.__init__": [[13, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "value", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.cache.CacheException.__str__": [[16, 18], ["repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "repr", "(", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.cache.getCache": [[20, 32], ["hashlib.md5().hexdigest", "os.path.join", "os.path.join", "os.path.isfile", "os.path.exists", "os.makedirs", "cPickle.load", "hashlib.md5", "open"], "function", ["None"], ["", "", "def", "getCache", "(", "path", ",", "idText", ")", ":", "\n", "    ", "\"\"\"Verify if there is cached data for the unique string that identifies \n    the data and return it, else return None.\"\"\"", "\n", "fName", "=", "hashlib", ".", "md5", "(", "idText", ")", ".", "hexdigest", "(", ")", "\n", "cachePath", "=", "os", ".", "path", ".", "join", "(", "CACHE_PATH", ",", "path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cachePath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cachePath", ")", "\n", "", "cacheFilePath", "=", "os", ".", "path", ".", "join", "(", "cachePath", ",", "fName", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cacheFilePath", ")", ":", "\n", "        ", "return", "cPickle", ".", "load", "(", "open", "(", "cacheFilePath", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.cache.storeCache": [[33, 44], ["hashlib.md5().hexdigest", "os.path.join", "os.path.join", "os.path.exists", "os.makedirs", "os.path.isfile", "cache.CacheException", "cPickle.dump", "hashlib.md5", "open"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec.dump"], ["", "", "def", "storeCache", "(", "path", ",", "idText", ",", "data", ",", "overwrite", "=", "False", ")", ":", "\n", "    ", "\"\"\"Store data in cache.\"\"\"", "\n", "fName", "=", "hashlib", ".", "md5", "(", "idText", ")", ".", "hexdigest", "(", ")", "\n", "cachePath", "=", "os", ".", "path", ".", "join", "(", "CACHE_PATH", ",", "path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cachePath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cachePath", ")", "\n", "", "cacheFilePath", "=", "os", ".", "path", ".", "join", "(", "cachePath", ",", "fName", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cacheFilePath", ")", "and", "not", "overwrite", ":", "\n", "        ", "raise", "CacheException", "(", "\"This data already exists in the cache!\"", ")", "\n", "", "else", ":", "\n", "        ", "cPickle", ".", "dump", "(", "data", ",", "open", "(", "cacheFilePath", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.cache.cleanCache": [[45, 61], ["hashlib.md5().hexdigest", "os.path.join", "os.path.isfile", "shutil.rmtree", "os.path.isdir", "os.remove", "cache.CacheException", "os.path.join", "shutil.rmtree", "cache.CacheException", "hashlib.md5", "os.path.join"], "function", ["None"], ["", "", "def", "cleanCache", "(", "path", "=", "None", ",", "idText", "=", "None", ")", ":", "\n", "    ", "\"\"\"Delete cached data, if no argument is specified delete all the cache.\"\"\"", "\n", "if", "idText", "==", "None", ":", "\n", "        ", "if", "path", "==", "None", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "CACHE_PATH", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "CACHE_PATH", ",", "path", ")", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "CACHE_PATH", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "CacheException", "(", "\"Cache path does not exist!\"", ")", "\n", "", "", "else", ":", "\n", "        ", "fName", "=", "hashlib", ".", "md5", "(", "idText", ")", ".", "hexdigest", "(", ")", "\n", "cacheFilePath", "=", "os", ".", "path", ".", "join", "(", "CACHE_PATH", ",", "path", ",", "fName", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cacheFilePath", ")", ":", "\n", "            ", "os", ".", "remove", "(", "cacheFilePath", ")", "\n", "", "else", ":", "\n", "            ", "raise", "CacheException", "(", "\"Cached data does not exist!\"", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.language.Lang.__init__": [[16, 24], ["os.walk", "os.path.abspath", "open", "fName.rfind"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "trainPath", ")", ":", "\n", "        ", "\"\"\"trainPath contains a train file for each language.\n        Each file contains language trigrams (one for line), ordered by frequency (most popular at the top).\n        Training files can be created with createTrigrams.\"\"\"", "\n", "self", ".", "languages", "=", "{", "}", "\n", "for", "names", "in", "os", ".", "walk", "(", "os", ".", "path", ".", "abspath", "(", "trainPath", ")", ")", ":", "\n", "            ", "for", "fName", "in", "names", "[", "2", "]", ":", "\n", "                ", "self", ".", "languages", "[", "fName", "[", "fName", ".", "rfind", "(", "'.'", ")", "]", "]", "=", "[", "line", "[", "0", ":", "3", "]", "for", "line", "in", "open", "(", "names", "[", "0", "]", "+", "'/'", "+", "fName", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.language.Lang.createTrigrams": [[25, 46], ["language.Lang.__class__.hashRepl.sub", "language.Lang.__class__.url.sub", "len", "xrange", "freq.items.items.items", "freq.items.items.sort", "language.Lang.translate", "text[].lower", "len", "operator.itemgetter", "tg[].strip", "len"], "methods", ["None"], ["", "", "", "def", "createTrigrams", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Extracts trigrams from a text, and order them by frequency\"\"\"", "\n", "#text = ' ' + self.__class__.cleaner.sub(\" \", text)", "\n", "text", "=", "self", ".", "__class__", ".", "hashRepl", ".", "sub", "(", "\" \"", ",", "text", ")", "\n", "text", "=", "self", ".", "__class__", ".", "url", ".", "sub", "(", "\" \"", ",", "text", ")", "\n", "text", "=", "' '", "+", "text", ".", "translate", "(", "self", ".", "__class__", ".", "cleanTable", ")", "\n", "length", "=", "len", "(", "text", ")", "\n", "freq", "=", "{", "}", "\n", "for", "i", "in", "xrange", "(", "length", ")", ":", "\n", "            ", "trigram", "=", "text", "[", "i", ":", "i", "+", "3", "]", ".", "lower", "(", ")", "\n", "if", "len", "(", "trigram", ")", "==", "2", ":", "\n", "                ", "trigram", "+=", "' '", "\n", "", "elif", "len", "(", "trigram", ")", "==", "1", ":", "\n", "                ", "trigram", "+=", "'  '", "\n", "", "if", "trigram", "in", "freq", ":", "\n", "                ", "freq", "[", "trigram", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "freq", "[", "trigram", "]", "=", "1", "\n", "", "", "freq", "=", "freq", ".", "items", "(", ")", "\n", "freq", ".", "sort", "(", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "\n", "return", "[", "tg", "[", "0", "]", "for", "tg", "in", "freq", "if", "tg", "[", "0", "]", ".", "strip", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.language.Lang.calcDistance": [[47, 56], ["xrange", "len", "xrange", "len", "abs"], "methods", ["None"], ["", "def", "calcDistance", "(", "self", ",", "distr", ",", "lang", "=", "'english'", ")", ":", "\n", "        ", "\"\"\"Distance between trigram vectors\"\"\"", "\n", "distance", "=", "0", "\n", "for", "i", "in", "xrange", "(", "len", "(", "distr", ")", ")", ":", "\n", "            ", "for", "j", "in", "xrange", "(", "len", "(", "self", ".", "languages", "[", "lang", "]", ")", ")", ":", "\n", "                ", "if", "self", ".", "languages", "[", "lang", "]", "[", "j", "]", "==", "distr", "[", "i", "]", ":", "\n", "                    ", "break", "\n", "", "distance", "+=", "abs", "(", "i", "-", "j", ")", "\n", "", "", "return", "distance", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.language.Lang.guess": [[57, 70], ["language.Lang.createTrigrams", "float", "language.Lang.languages.iterkeys", "language.Lang.strip", "language.Lang.calcDistance"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.language.Lang.createTrigrams", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.language.Lang.calcDistance"], ["", "def", "guess", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Returns the most probable language of a text\"\"\"", "\n", "if", "not", "text", ".", "strip", "(", ")", ":", "\n", "            ", "return", "None", "\n", "", "text", "=", "self", ".", "createTrigrams", "(", "text", ")", "\n", "currMin", "=", "float", "(", "'inf'", ")", "\n", "currLang", "=", "None", "\n", "for", "lang", "in", "self", ".", "languages", ".", "iterkeys", "(", ")", ":", "\n", "            ", "guessed", "=", "self", ".", "calcDistance", "(", "text", ",", "lang", ")", "\n", "if", "guessed", "<", "currMin", ":", "\n", "                ", "currMin", "=", "guessed", "\n", "currLang", "=", "lang", "\n", "", "", "return", "currLang", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.__init__.substPunct": [[43, 45], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.__init__.queryNumToId": [[46, 49], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.__init__.queryIdToNum": [[50, 53], ["int"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.__init__.textHash": [[54, 57], ["int", "hashlib.md5().hexdigest", "hashlib.md5", "text.encode"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.setFeatureExtractor": [[40, 46], ["FeatureExtractor", "FeatureExtractor", "FeatureExtractor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.featureExtract": [[47, 61], ["features.extend", "features.extend", "features.extend", "features.extend", "features.extend", "__init__.Filterer.statusFeatEx.get", "__init__.Filterer.genericFeatEx.get", "__init__.Filterer.genericFeatEx.get", "__init__.Filterer.entityFeatEx.get", "__init__.Filterer.entityFeatEx.get"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.featureExtractQuery": [[62, 70], ["features.extend", "features.extend", "__init__.Filterer.genericFeatEx.get", "__init__.Filterer.entityFeatEx.get"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.intersect": [[71, 74], ["len", "set", "set", "terms", "terms"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.tweetHash": [[75, 77], ["utils.textHash", "str"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.utils.__init__.textHash"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.SupervisedFilterer.__init__": [[81, 83], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.SupervisedFilterer.get": [[84, 181], ["enumerate", "utils.io.dataset_iter", "__init__.SupervisedFilterer.featureExtractQuery", "set", "rawTweets.append", "utils.io.dataset_iter", "__init__.SupervisedFilterer.__init__.TrainingSet", "int", "__init__.SupervisedFilterer.featureExtractQuery", "results[].append", "__init__.SupervisedFilterer.featureExtract", "rawTweets.append", "__init__.SupervisedFilterer.featureExtract", "rawTweets.append", "__init__.SupervisedFilterer.__init__.TrainingSet.vectorize", "__init__.SupervisedFilterer.classifier.retrain", "str", "utils.retweetRE.findall", "__init__.SupervisedFilterer.featureExtract", "__init__.SupervisedFilterer.__init__.TrainingSet.vectorizeTest", "__init__.SupervisedFilterer.classifier.classify", "cPickle.dump", "float", "results[].append", "open", "str", "len", "hasUrl", "callable", "__init__.SupervisedFilterer.classifier.getProb", "__init__.SupervisedFilterer.__init__.TrainingSet.addExample", "__init__.SupervisedFilterer.__init__.TrainingSet.vectorize", "__init__.SupervisedFilterer.classifier.retrain", "__init__.SupervisedFilterer.__init__.TrainingSet.addExample", "__init__.SupervisedFilterer.__init__.TrainingSet.vectorize", "__init__.SupervisedFilterer.classifier.retrain", "os.path.join", "getattr", "set", "str", "int"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.featureExtractQuery", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.featureExtractQuery", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.featureExtract", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.featureExtract", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.vectorize", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.retrain", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.filtering.__init__.Filterer.featureExtract", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.vectorizeTest", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.classify", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec.dump", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.hasUrl", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.ADAClassifier.getProb", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.addExample", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.vectorize", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.retrain", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.addExample", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.vectorize", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.retrain"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.retrieval.__init__.getStoredValue": [[39, 46], ["searcher.document", "unicode"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec._getCommand": [[6, 8], ["None"], "function", ["None"], ["def", "_getCommand", "(", "toolsDir", ",", "toolsJar", ")", ":", "\n", "    ", "return", "\"java -Xmx4g -cp '\"", "+", "toolsDir", "+", "\"/lib/*:\"", "+", "toolsDir", "+", "\"/dist/twitter-corpus-tools-0.0.1.jar' \"", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec.download": [[10, 18], ["trec._getCommand", "os.walk", "subprocess.check_call", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec._getCommand"], ["", "def", "download", "(", "toolsPath", ",", "toolsJar", ",", "datPath", ",", "outPath", ")", ":", "\n", "    ", "command", "=", "_getCommand", "(", "toolsPath", ")", "\n", "for", "names", "in", "os", ".", "walk", "(", "datPath", ")", ":", "\n", "        ", "for", "fName", "in", "names", "[", "2", "]", ":", "\n", "            ", "if", "fName", "[", "-", "3", ":", "]", "==", "'dat'", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "(", "\n", "command", "+", "\" com.twitter.corpus.download.AsyncHtmlStatusBlockCrawler -data \"", "+", "os", ".", "path", ".", "join", "(", "names", "[", "0", "]", ",", "\n", "fName", ")", "+", "\" -output \"", "+", "os", ".", "path", ".", "join", "(", "outPath", ",", "fName", "[", ":", "-", "4", "]", "+", "\".html.seq\"", ")", ")", ",", "shell", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec.dump": [[20, 28], ["trec._getCommand", "os.walk", "subprocess.check_call", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec._getCommand"], ["", "", "", "", "def", "dump", "(", "toolsPath", ",", "toolsJar", ",", "corpusPath", ",", "outPath", ")", ":", "\n", "    ", "command", "=", "_getCommand", "(", "toolsPath", ")", "\n", "for", "names", "in", "os", ".", "walk", "(", "corpusPath", ")", ":", "\n", "        ", "for", "fName", "in", "names", "[", "2", "]", ":", "\n", "            ", "if", "fName", "[", "-", "3", ":", "]", "==", "'seq'", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "(", "\n", "command", "+", "\" com.twitter.corpus.demo.ReadStatuses -input \"", "+", "os", ".", "path", ".", "join", "(", "names", "[", "0", "]", ",", "\n", "fName", ")", "+", "\" -dump -html > \"", "+", "os", ".", "path", ".", "join", "(", "outPath", ",", "fName", "[", ":", "-", "4", "]", "+", "\".txt\"", ")", ")", ",", "shell", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec.repair": [[30, 42], ["trec._getCommand", "os.walk", "subprocess.check_call", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.trec._getCommand"], ["", "", "", "", "def", "repair", "(", "toolsPath", ",", "toolsJar", ",", "datPath", ",", "corpusPath", ",", "outPath", ",", "logsPath", ")", ":", "\n", "    ", "command", "=", "_getCommand", "(", "toolsPath", ")", "\n", "for", "names", "in", "os", ".", "walk", "(", "datPath", ")", ":", "\n", "        ", "for", "fName", "in", "names", "[", "2", "]", ":", "\n", "            ", "if", "fName", "[", "-", "3", ":", "]", "==", "'dat'", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "(", "\n", "command", "+", "\" com.twitter.corpus.download.VerifyHtmlStatusBlockCrawl -data \"", "+", "os", ".", "path", ".", "join", "(", "names", "[", "0", "]", ",", "\n", "fName", ")", "+", "\" -statuses_input \"", "+", "os", ".", "path", ".", "join", "(", "corpusPath", ",", "\n", "fName", "[", ":", "-", "4", "]", "+", "\".html.seq\"", ")", "+", "\" -statuses_repaired \"", "+", "os", ".", "path", ".", "join", "(", "outPath", ",", "\n", "fName", "[", ":", "-", "4", "]", "+", "\".html.seq\"", ")", "+", "\" -output_success \"", "+", "os", ".", "path", ".", "join", "(", "logsPath", ",", "\n", "\"log.success\"", ")", "+", "\" -output_failure \"", "+", "os", ".", "path", ".", "join", "(", "logsPath", ",", "\"log.failure\"", ")", ")", ",", "\n", "shell", "=", "True", ")", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.__init__.build": [[36, 53], ["os.listdir", "list", "os.path.exists", "os.makedirs", "codecs.open", "open", "codecs.open.close", "filters.BaseFilter", "os.sep.join", "os.sep.join", "filter.filter.strip", "filter.filter", "codecs.open.write"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.__init__.fuse": [[54, 59], ["NotImplementedError"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.__init__._enrich": [[60, 101], ["codecs.open", "open", "open", "__init__._enrich.goNext"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.corpus.__init__.enrich": [[102, 118], ["multiprocessing.Pool", "os.listdir", "os.listdir", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "os.path.exists", "os.makedirs", "int", "multiprocessing.Pool.apply_async", "range", "len", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.__init__": [[22, 24], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "functions", ")", ":", "\n", "        ", "self", ".", "functions", "=", "functions", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get": [[25, 34], ["inspect.isfunction", "isinstance", "result.extend", "result.extend", "f", "f"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "data", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "f", "in", "self", ".", "functions", ":", "\n", "            ", "if", "isfunction", "(", "f", ")", ":", "\n", "                ", "if", "isinstance", "(", "data", ",", "basestring", ")", ":", "\n", "                    ", "result", ".", "extend", "(", "f", "(", "data", ")", ")", "\n", "", "else", ":", "\n", "                    ", "result", ".", "extend", "(", "f", "(", "*", "data", ")", ")", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.getSegmenter": [[41, 46], ["utils.hashtag.Segmenter"], "function", ["None"], ["def", "getSegmenter", "(", "dictionary", ")", ":", "\n", "    ", "global", "segmenter", "\n", "if", "not", "segmenter", ":", "\n", "        ", "segmenter", "=", "Segmenter", "(", "dictionary", ")", "\n", "", "return", "segmenter", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.getStemmer": [[48, 53], ["nltk.stem.LancasterStemmer"], "function", ["None"], ["def", "getStemmer", "(", ")", ":", "\n", "    ", "global", "stemmer", "\n", "if", "not", "stemmer", ":", "\n", "        ", "stemmer", "=", "nltk", ".", "stem", ".", "LancasterStemmer", "(", ")", "\n", "", "return", "stemmer", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.getLemmatizer": [[55, 60], ["nltk.stem.WordNetLemmatizer"], "function", ["None"], ["def", "getLemmatizer", "(", ")", ":", "\n", "    ", "global", "lemmatizer", "\n", "if", "not", "lemmatizer", ":", "\n", "        ", "lemmatizer", "=", "nltk", ".", "stem", ".", "WordNetLemmatizer", "(", ")", "\n", "", "return", "lemmatizer", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.surfaceForms": [[61, 97], ["set", "set", "set.add", "zip", "spot[].replace", "str", "set.extend", "r.replace", "set.union", "curr_mentions.append"], "function", ["None"], ["", "def", "surfaceForms", "(", "data", ",", "min_linkprob", ",", "min_score", ")", ":", "\n", "    ", "\"\"\"Returns the surface forms of all the entities of each mention in the text (Exp3 in the SAC 2015 paper)\"\"\"", "\n", "if", "min_linkprob", ">", "1.", "or", "min_score", ">", "1.", "or", "not", "data", ":", "\n", "        ", "return", "[", "]", "\n", "", "spots", "=", "data", "[", "0", "]", "\n", "mentions", "=", "data", "[", "1", "]", "\n", "result", "=", "[", "]", "\n", "# Add the spots in the text to the final result", "\n", "partial_result", "=", "set", "(", ")", "\n", "# Explore other mentions", "\n", "for", "spot", "in", "(", "s", "for", "s", "in", "spots", "if", "s", "[", "\"linkProbability\"", "]", ">=", "min_linkprob", ")", ":", "\n", "        ", "base_linkprob", "=", "spot", "[", "\"linkProbability\"", "]", "\n", "partial_result", ".", "add", "(", "spot", "[", "\"mention\"", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ")", "\n", "for", "entity", "in", "spot", "[", "\"candidates\"", "]", ":", "\n", "            ", "ent_id", "=", "entity", "[", "\"entity\"", "]", "\n", "ent_id_str", "=", "str", "(", "ent_id", ")", "\n", "if", "ent_id_str", "not", "in", "mentions", ":", "\n", "                ", "continue", "\n", "", "ent_comm", "=", "entity", "[", "\"commonness\"", "]", "\n", "curr_mentions", "=", "[", "]", "\n", "for", "mention", "in", "(", "m", "for", "m", "in", "mentions", "[", "ent_id_str", "]", "if", "m", "[", "\"linkProbability\"", "]", ">=", "min_linkprob", "\n", "and", "m", "[", "\"linkFrequency\"", "]", ">", "2", "and", "m", "[", "\"mention\"", "]", "!=", "spot", "[", "\"mention\"", "]", ")", ":", "\n", "                ", "ment_ent_comm", "=", "0", "\n", "for", "ment_ent", "in", "mention", "[", "\"candidates\"", "]", ":", "\n", "                    ", "if", "ment_ent", "[", "\"entity\"", "]", "==", "ent_id", ":", "\n", "                        ", "ment_ent_comm", "=", "ment_ent", "[", "\"commonness\"", "]", "\n", "break", "\n", "", "", "curr_mentions", ".", "append", "(", "(", "mention", "[", "\"mention\"", "]", ",", "mention", "[", "\"linkProbability\"", "]", "*", "ment_ent_comm", "\n", "*", "ent_comm", "*", "base_linkprob", ")", ")", "\n", "", "result", ".", "extend", "(", "curr_mentions", ")", "\n", "", "", "result", "=", "[", "r", "for", "r", "in", "result", "if", "r", "[", "1", "]", ">=", "min_score", "]", "\n", "if", "not", "result", ":", "\n", "        ", "return", "[", "ALIAS_FEATURE", "+", "feat", "for", "feat", "in", "partial_result", "]", "\n", "", "result", "=", "zip", "(", "*", "result", ")", "[", "0", "]", "\n", "result", "=", "set", "(", "r", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "for", "r", "in", "result", ")", "\n", "return", "[", "ALIAS_FEATURE", "+", "feat", "for", "feat", "in", "result", ".", "union", "(", "partial_result", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.firstEntity": [[98, 110], ["result.append", "max", "str"], "function", ["None"], ["", "def", "firstEntity", "(", "data", ",", "min_linkprob", ",", "min_score", ")", ":", "\n", "    ", "\"\"\"Returns only the first candidate entity for each mention\"\"\"", "\n", "if", "min_linkprob", ">", "1.", "or", "not", "data", ":", "\n", "        ", "return", "[", "]", "\n", "", "spots", "=", "data", "[", "0", "]", "\n", "result", "=", "[", "]", "\n", "for", "spot", "in", "(", "s", "for", "s", "in", "spots", "if", "s", "[", "\"linkProbability\"", "]", ">=", "min_linkprob", ")", ":", "\n", "        ", "if", "not", "spot", "[", "\"candidates\"", "]", ":", "\n", "            ", "continue", "\n", "", "candidate", "=", "max", "(", "(", "entity", "[", "\"commonness\"", "]", ",", "entity", "[", "\"entity\"", "]", ")", "for", "entity", "in", "spot", "[", "\"candidates\"", "]", ")", "[", "1", "]", "\n", "result", ".", "append", "(", "ENTITY_FEATURE", "+", "str", "(", "candidate", ")", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.mentionsInText": [[111, 121], ["result.append", "spot[].replace"], "function", ["None"], ["", "def", "mentionsInText", "(", "data", ",", "min_linkprob", ",", "min_score", ")", ":", "\n", "    ", "\"\"\"Returns the mentions spotted in the text (Exp1 in the SAC 2015 paper)\"\"\"", "\n", "if", "min_linkprob", ">", "1.", "or", "not", "data", ":", "\n", "        ", "return", "[", "]", "\n", "", "spots", "=", "data", "[", "0", "]", "\n", "result", "=", "[", "]", "\n", "# Explore mentions", "\n", "for", "spot", "in", "(", "s", "for", "s", "in", "spots", "if", "s", "[", "\"linkProbability\"", "]", ">=", "min_linkprob", ")", ":", "\n", "        ", "result", ".", "append", "(", "MENTION_FEATURE", "+", "spot", "[", "\"mention\"", "]", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.candidateEntities": [[122, 136], ["result.append", "str"], "function", ["None"], ["", "def", "candidateEntities", "(", "data", ",", "min_linkprob", ",", "min_score", ")", ":", "\n", "    ", "\"\"\"Returns all the candidate entities for each mention (Exp2 in the SAC 2015 paper)\"\"\"", "\n", "if", "min_linkprob", ">", "1.", "or", "min_score", ">", "1.", "or", "not", "data", ":", "\n", "        ", "return", "[", "]", "\n", "", "spots", "=", "data", "[", "0", "]", "\n", "mentions", "=", "data", "[", "1", "]", "\n", "result", "=", "[", "]", "\n", "# Explore mentions", "\n", "for", "spot", "in", "(", "s", "for", "s", "in", "spots", "if", "s", "[", "\"linkProbability\"", "]", ">=", "min_linkprob", ")", ":", "\n", "        ", "base_linkprob", "=", "spot", "[", "\"linkProbability\"", "]", "\n", "for", "entity", "in", "spot", "[", "\"candidates\"", "]", ":", "\n", "            ", "if", "(", "entity", "[", "\"commonness\"", "]", "*", "base_linkprob", ")", ">=", "min_score", ":", "\n", "                ", "result", ".", "append", "(", "ENTITY_FEATURE", "+", "str", "(", "entity", "[", "\"entity\"", "]", ")", ")", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.allEntityFeatures": [[137, 139], ["feature.candidateEntities", "feature.surfaceForms"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.candidateEntities", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.surfaceForms"], ["", "def", "allEntityFeatures", "(", "data", ",", "min_linkprob", ",", "min_score", ")", ":", "\n", "    ", "return", "candidateEntities", "(", "data", ",", "min_linkprob", ",", "min_score", ")", "+", "surfaceForms", "(", "data", ",", "min_linkprob", ",", "min_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms": [[140, 151], ["utils.hashReplRE.sub", "utils.urlRE.sub", "utils.wordDotsRE.sub", "nltk.sent_tokenize", "sent.split", "t.lower", "terms.extend", "nltk.word_tokenize", "t.strip", "len", "set().issubset", "set"], "function", ["None"], ["", "def", "terms", "(", "text", ")", ":", "\n", "    ", "\"\"\"Returns the unique, filtered, terms of a text\"\"\"", "\n", "terms", "=", "[", "]", "\n", "text", "=", "hashReplRE", ".", "sub", "(", "\" \"", ",", "text", ")", "\n", "text", "=", "urlRE", ".", "sub", "(", "\" \"", ",", "text", ")", "\n", "text", "=", "wordDotsRE", ".", "sub", "(", "\".\"", ",", "text", ")", "\n", "for", "sent", "in", "nltk", ".", "sent_tokenize", "(", "text", ")", ":", "\n", "        ", "for", "subSent", "in", "sent", ".", "split", "(", "';'", ")", ":", "\n", "            ", "terms", ".", "extend", "(", "nltk", ".", "word_tokenize", "(", "subSent", ")", ")", "\n", "", "", "terms", "=", "[", "t", ".", "lower", "(", ")", "for", "t", "in", "terms", "if", "t", ".", "strip", "(", ")", "and", "len", "(", "t", ")", ">", "1", "and", "t", "!=", "u'\\ufffd'", "]", "\n", "return", "[", "t", "for", "t", "in", "terms", "if", "t", "not", "in", "filterSet", "and", "not", "set", "(", "t", ")", ".", "issubset", "(", "punctuations2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.lemmas": [[152, 155], ["feature.terms", "getLemmatizer().lemmatize", "feature.getLemmatizer"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.getLemmatizer"], ["", "def", "lemmas", "(", "text", ")", ":", "\n", "    ", "text_terms", "=", "terms", "(", "text", ")", "\n", "return", "[", "getLemmatizer", "(", ")", ".", "lemmatize", "(", "t", ")", "for", "t", "in", "text_terms", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.stems": [[156, 159], ["feature.terms", "getStemmer().stem", "feature.getStemmer"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.getStemmer"], ["", "def", "stems", "(", "text", ")", ":", "\n", "    ", "text_terms", "=", "terms", "(", "text", ")", "\n", "return", "[", "STEM_PREFIX", "+", "getStemmer", "(", ")", ".", "stem", "(", "t", ")", "for", "t", "in", "text_terms", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.bigrams": [[160, 172], ["utils.hashReplRE.sub", "utils.urlRE.sub", "utils.wordDotsRE.sub", "nltk.sent_tokenize", "sent.split", "bigrams_list.extend", "nltk.bigrams", "nltk.word_tokenize", "set().issubset", "set().issubset", "set", "set"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.bigrams"], ["", "def", "bigrams", "(", "text", ")", ":", "\n", "    ", "\"\"\"Returns term pairs of a text\"\"\"", "\n", "bigrams_list", "=", "[", "]", "\n", "text", "=", "hashReplRE", ".", "sub", "(", "\";\"", ",", "text", ")", "\n", "text", "=", "urlRE", ".", "sub", "(", "\";\"", ",", "text", ")", "\n", "text", "=", "wordDotsRE", ".", "sub", "(", "\".\"", ",", "text", ")", "\n", "for", "sent", "in", "nltk", ".", "sent_tokenize", "(", "text", ")", ":", "\n", "        ", "for", "subSent", "in", "sent", ".", "split", "(", "';'", ")", ":", "\n", "            ", "bigrams_list", ".", "extend", "(", "nltk", ".", "bigrams", "(", "nltk", ".", "word_tokenize", "(", "subSent", ")", ")", ")", "\n", "# Differently from terms, we accept stopwords in bigrams", "\n", "", "", "return", "[", "'_'", ".", "join", "(", "b", ")", ".", "lower", "(", ")", "for", "b", "in", "bigrams_list", "if", "u'\\ufffd'", "not", "in", "b", "#and len(b[0]) > 1 and len(b[1]) > 1", "\n", "and", "not", "set", "(", "b", "[", "0", "]", ")", ".", "issubset", "(", "punctuations2", ")", "and", "not", "set", "(", "b", "[", "1", "]", ")", ".", "issubset", "(", "punctuations2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.hashtags": [[173, 176], ["utils.hashtagRE.findall"], "function", ["None"], ["", "def", "hashtags", "(", "text", ")", ":", "\n", "    ", "\"\"\"Returns hashtags of a text\"\"\"", "\n", "return", "[", "h", "for", "h", "in", "hashtagRE", ".", "findall", "(", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.mentions": [[177, 180], ["utils.replyRE.findall"], "function", ["None"], ["", "def", "mentions", "(", "text", ")", ":", "\n", "    ", "\"\"\"Returns mentioned users of a text\"\"\"", "\n", "return", "[", "r", "for", "r", "in", "replyRE", ".", "findall", "(", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.hasHashtags": [[181, 184], ["utils.hashtagRE.findall"], "function", ["None"], ["", "def", "hasHashtags", "(", "text", ")", ":", "\n", "    ", "\"\"\"Returns hashtags of a text\"\"\"", "\n", "return", "[", "HASHTAG_FEATURE", "]", "if", "hashtagRE", ".", "findall", "(", "text", ")", "else", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.hasMentions": [[185, 188], ["utils.replyRE.findall"], "function", ["None"], ["", "def", "hasMentions", "(", "text", ")", ":", "\n", "    ", "\"\"\"Returns mentioned users of a text\"\"\"", "\n", "return", "[", "MENTION_FEATURE", "]", "if", "replyRE", ".", "findall", "(", "text", ")", "else", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.hasUrl": [[189, 192], ["utils.urlRE.findall"], "function", ["None"], ["", "def", "hasUrl", "(", "text", ")", ":", "\n", "    ", "\"\"\"Return a feature if there is a url in the text\"\"\"", "\n", "return", "[", "URL_FEATURE", "]", "if", "urlRE", ".", "findall", "(", "text", ")", "else", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.segmHashtags": [[193, 197], ["feature.getSegmenter", "feature.terms", "feature.hashtags", "getSegmenter.get"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.getSegmenter", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.hashtags", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get"], ["", "def", "segmHashtags", "(", "text", ",", "dictionary", ")", ":", "\n", "    ", "\"\"\"Returns terms of the segmented hashtags of a text\"\"\"", "\n", "segmenter", "=", "getSegmenter", "(", "dictionary", ")", "\n", "return", "terms", "(", "' '", ".", "join", "(", "' '", ".", "join", "(", "segmenter", ".", "get", "(", "ht", ")", "[", "0", "]", ")", "for", "ht", "in", "hashtags", "(", "text", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.segmHashtagsBigrams": [[198, 205], ["feature.getSegmenter", "feature.hashtags", "hashBigr.extend", "feature.bigrams", "getSegmenter.get"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.getSegmenter", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.hashtags", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.bigrams", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get"], ["", "def", "segmHashtagsBigrams", "(", "text", ",", "dictionary", ")", ":", "\n", "    ", "\"\"\"Returns term pairs of the segmented hashtags of a text\"\"\"", "\n", "segmenter", "=", "getSegmenter", "(", "dictionary", ")", "\n", "hashBigr", "=", "[", "]", "\n", "for", "ht", "in", "hashtags", "(", "text", ")", ":", "\n", "        ", "hashBigr", ".", "extend", "(", "bigrams", "(", "' '", ".", "join", "(", "segmenter", ".", "get", "(", "ht", ")", "[", "0", "]", ")", ")", ")", "\n", "", "return", "hashBigr", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.countIntersectingTerms": [[206, 216], ["feature.terms", "feature.terms", "len", "math.floor", "range", "int", "result.append", "set", "set", "float", "float", "len"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.terms"], ["", "def", "countIntersectingTerms", "(", "text", ",", "query", ")", ":", "\n", "    ", "\"\"\"Returns a feature representing the number of terms in common between two texts\"\"\"", "\n", "result", "=", "[", "]", "\n", "termsQuery", "=", "terms", "(", "query", ")", "\n", "termsText", "=", "terms", "(", "text", ")", "\n", "intersectionNumber", "=", "len", "(", "set", "(", "termsQuery", ")", "&", "set", "(", "termsText", ")", ")", "\n", "normalizedIntersection", "=", "math", ".", "floor", "(", "(", "float", "(", "intersectionNumber", ")", "/", "float", "(", "len", "(", "termsQuery", ")", ")", ")", "*", "5.0", ")", "\n", "for", "i", "in", "range", "(", "int", "(", "normalizedIntersection", ")", ")", ":", "\n", "        ", "result", ".", "append", "(", "'_intersect_'", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.annotations": [[217, 219], ["annotationTweet.split"], "function", ["None"], ["", "def", "annotations", "(", "annotationTweet", ")", ":", "\n", "    ", "return", "[", "ANNOTATION_PREFIX", "+", "a", "for", "a", "in", "annotationTweet", ".", "split", "(", "'\\t'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.__init__": [[43, 56], ["sklearn.feature_extraction.text.TfidfVectorizer", "__init__.TrainingSet.tweetId.append", "__init__.TrainingSet.tweetTarget.append", "__init__.TrainingSet.features.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.vectorize": [[57, 60], ["__init__.TrainingSet.tfidf_vect.fit_transform"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.vectorizeTest": [[61, 64], ["__init__.TrainingSet.tfidf_vect.transform"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.addExample": [[65, 70], ["__init__.TrainingSet.tweetId.append", "__init__.TrainingSet.tweetTarget.append", "__init__.TrainingSet.features.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.TrainingSet.popOldExample": [[71, 78], ["__init__.TrainingSet.tweetId.pop", "__init__.TrainingSet.tweetTarget.pop", "__init__.TrainingSet.features.pop"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.Classifier.retrain": [[82, 84], ["__init__.Classifier.cl.fit"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.Classifier.classify": [[85, 87], ["__init__.Classifier.cl.predict"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.ProbClassifier.getProb": [[91, 93], ["__init__.ProbClassifier.cl.predict_proba"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NBClassifier.__init__": [[100, 102], ["sklearn.naive_bayes.MultinomialNB"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.SVMClassifier.__init__": [[106, 108], ["sklearn.svm.SVC"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.OneClassClassifier.__init__": [[112, 114], ["sklearn.svm.OneClassSVM"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.OneClassClassifier.retrain": [[115, 121], ["__init__.OneClassClassifier.cl.fit", "len", "enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.KNNClassifier.__init__": [[125, 127], ["sklearn.neighbors.KNeighborsClassifier"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.ADAClassifier.__init__": [[131, 134], ["sklearn.ensemble.AdaBoostClassifier", "sklearn.tree.DecisionTreeClassifier"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.ADAClassifier.retrain": [[135, 138], ["__init__.ADAClassifier.cl.fit"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.ADAClassifier.classify": [[139, 142], ["__init__.ADAClassifier.cl.predict"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.ADAClassifier.getProb": [[143, 146], ["__init__.ADAClassifier.cl.predict_proba"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.RClassifier.__init__": [[150, 152], ["sklearn.linear_model.RidgeClassifier"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.LClassifier.__init__": [[156, 158], ["sklearn.linear_model.LogisticRegression"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NCClassifier.__init__": [[162, 165], ["sklearn.neighbors.NearestCentroid"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NCClassifier.retrain": [[166, 171], ["__init__.NCClassifier.cl.fit", "__init__.Classifier.retrain", "v.toarray"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.retrain"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NCClassifier.classify": [[172, 177], ["__init__.Classifier.classify", "__init__.NCClassifier.cl.predict", "vectorizedTest.toarray"], "methods", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.classify"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.RocchioClassifier.__init__": [[181, 184], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.RocchioClassifier.retrain": [[185, 193], ["vectors.mean", "len", "enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.RocchioClassifier.classify": [[194, 201], ["scipy.sparse.issparse", "vectorizedTest.toarray.toarray.toarray", "__init__.RocchioClassifier.distance_func"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.__init__": [[205, 209], ["numpy.zeros"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.retrain": [[210, 224], ["pos_vectors.mean", "len", "v.toarray", "numpy.zeros", "numpy.array().mean", "enumerate", "enumerate", "v.getnnz", "__init__.NegativeRocchioClassifier.neg_centroid.any", "numpy.array", "__init__.NegativeRocchioClassifier.distance_func"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.NegativeRocchioClassifier.classify": [[225, 232], ["scipy.sparse.issparse", "__init__.NegativeRocchioClassifier.distance_func", "__init__.NegativeRocchioClassifier.distance_func", "vectorizedTest.toarray.toarray.toarray"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.DTClassifier.__init__": [[236, 238], ["sklearn.tree.DecisionTreeClassifier"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.__init__.RFClassifier.__init__": [[242, 244], ["sklearn.ensemble.RandomForestClassifier"], "methods", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.evaluation.trec.printEval": [[7, 64], ["FilterJig", "FilterJig.add_op", "FilterJig.add_op", "FilterJig.add_op", "FilterJig.add_op", "FilterJig.add_op", "FilterJig.add_op", "FilterJig.add_op", "dict", "bs", "bs.find_all", "collections.defaultdict", "collections.defaultdict", "results.iteritems", "collections.defaultdict.iterkeys", "FilterJig.print_scores", "FilterJig.comp_means", "FilterJig.print_means", "EvalJig.NumRetr", "EvalJig.NumRel", "EvalJig.RelRet", "Precision", "Recall", "Fb", "T11SU", "open", "t.parent.num.text.strip", "re.search().group", "t.text.strip", "open", "q.lstrip.lstrip", "FilterJig.zero", "sum", "collections.defaultdict.has_key", "line.split", "int", "r[].split", "run[].append", "warn", "FilterJig.compute", "FilterJig.compute", "re.search", "float", "qrels[].values"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.evaluation.__init__.T11SU"], ["    ", "return", "\"java -Xmx4g -cp '\"", "+", "toolsDir", "+", "\"/lib/*:\"", "+", "toolsDir", "+", "\"/dist/twitter-corpus-tools-0.0.1.jar' \"", "\n", "\n", "\n", "", "def", "download", "(", "toolsPath", ",", "toolsJar", ",", "datPath", ",", "outPath", ")", ":", "\n", "    ", "command", "=", "_getCommand", "(", "toolsPath", ")", "\n", "for", "names", "in", "os", ".", "walk", "(", "datPath", ")", ":", "\n", "        ", "for", "fName", "in", "names", "[", "2", "]", ":", "\n", "            ", "if", "fName", "[", "-", "3", ":", "]", "==", "'dat'", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "(", "\n", "command", "+", "\" com.twitter.corpus.download.AsyncHtmlStatusBlockCrawler -data \"", "+", "os", ".", "path", ".", "join", "(", "names", "[", "0", "]", ",", "\n", "fName", ")", "+", "\" -output \"", "+", "os", ".", "path", ".", "join", "(", "outPath", ",", "fName", "[", ":", "-", "4", "]", "+", "\".html.seq\"", ")", ")", ",", "shell", "=", "True", ")", "\n", "\n", "\n", "", "", "", "", "def", "dump", "(", "toolsPath", ",", "toolsJar", ",", "corpusPath", ",", "outPath", ")", ":", "\n", "    ", "command", "=", "_getCommand", "(", "toolsPath", ")", "\n", "for", "names", "in", "os", ".", "walk", "(", "corpusPath", ")", ":", "\n", "        ", "for", "fName", "in", "names", "[", "2", "]", ":", "\n", "            ", "if", "fName", "[", "-", "3", ":", "]", "==", "'seq'", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "(", "\n", "command", "+", "\" com.twitter.corpus.demo.ReadStatuses -input \"", "+", "os", ".", "path", ".", "join", "(", "names", "[", "0", "]", ",", "\n", "fName", ")", "+", "\" -dump -html > \"", "+", "os", ".", "path", ".", "join", "(", "outPath", ",", "fName", "[", ":", "-", "4", "]", "+", "\".txt\"", ")", ")", ",", "shell", "=", "True", ")", "\n", "\n", "\n", "", "", "", "", "def", "repair", "(", "toolsPath", ",", "toolsJar", ",", "datPath", ",", "corpusPath", ",", "outPath", ",", "logsPath", ")", ":", "\n", "    ", "command", "=", "_getCommand", "(", "toolsPath", ")", "\n", "for", "names", "in", "os", ".", "walk", "(", "datPath", ")", ":", "\n", "        ", "for", "fName", "in", "names", "[", "2", "]", ":", "\n", "            ", "if", "fName", "[", "-", "3", ":", "]", "==", "'dat'", ":", "\n", "                ", "subprocess", ".", "check_call", "(", "(", "\n", "command", "+", "\" com.twitter.corpus.download.VerifyHtmlStatusBlockCrawl -data \"", "+", "os", ".", "path", ".", "join", "(", "names", "[", "0", "]", ",", "\n", "fName", ")", "+", "\" -statuses_input \"", "+", "os", ".", "path", ".", "join", "(", "corpusPath", ",", "\n", "fName", "[", ":", "-", "4", "]", "+", "\".html.seq\"", ")", "+", "\" -statuses_repaired \"", "+", "os", ".", "path", ".", "join", "(", "outPath", ",", "\n", "fName", "[", ":", "-", "4", "]", "+", "\".html.seq\"", ")", "+", "\" -output_success \"", "+", "os", ".", "path", ".", "join", "(", "logsPath", ",", "\n", "\"log.success\"", ")", "+", "\" -output_failure \"", "+", "os", ".", "path", ".", "join", "(", "logsPath", ",", "\"log.failure\"", ")", ")", ",", "\n", "shell", "=", "True", ")", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.evaluation.__init__.ROC": [[31, 55], ["results.iteritems", "int", "set", "set", "curves.append", "set.add", "sorted", "len", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.evaluation.__init__.AUC": [[56, 60], ["zip", "numpy.trapz"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.evaluation.__init__.T11SU": [[61, 79], ["results.iteritems", "int", "evals.append", "len", "max"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.evaluation.__init__.F1": [[80, 96], ["results.iteritems", "int", "evals.append", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.linkTitle.index": [[14, 49], ["os.listdir", "whoosh.fields.Schema", "getIndexPath", "whoosh.index.create_in", "whoosh.index.create_in.writer", "ix.writer.commit", "os.path.exists", "os.makedirs", "shutil.rmtree", "os.makedirs", "utils.io.iterTweets", "whoosh.fields.ID", "whoosh.fields.TEXT", "os.path.join", "ix.writer.add_document", "int"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.__init__.getIndexPath"], ["def", "index", "(", "corpusPath", ",", "name", ",", "tweetTime", "=", "None", ",", "stored", "=", "False", ",", "overwrite", "=", "True", ",", "procs", "=", "PROC_NUM", ",", "limitmb", "=", "MEM_SIZE", ")", ":", "\n", "    ", "\"\"\"Indexing of titles of the linked pages.\"\"\"", "\n", "\n", "dirList", "=", "os", ".", "listdir", "(", "corpusPath", ")", "\n", "\n", "schema", "=", "Schema", "(", "id", "=", "ID", "(", "stored", "=", "True", ",", "unique", "=", "True", ")", ",", "\n", "date", "=", "DATETIME", ",", "\n", "title", "=", "TEXT", "(", "stored", "=", "stored", ")", "\n", ")", "\n", "\n", "indexPath", "=", "getIndexPath", "(", "name", ",", "tweetTime", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "indexPath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "indexPath", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "overwrite", ":", "\n", "            ", "return", "\n", "", "shutil", ".", "rmtree", "(", "indexPath", ")", "\n", "os", ".", "makedirs", "(", "indexPath", ")", "\n", "", "ix", "=", "whoosh", ".", "index", ".", "create_in", "(", "indexPath", ",", "schema", ")", "\n", "writer", "=", "ix", ".", "writer", "(", "procs", "=", "PROC_NUM", ",", "limitmb", "=", "MEM_SIZE", ")", "\n", "\n", "for", "fName", "in", "dirList", ":", "\n", "#if tweetTime and dateFromFileName(fName) > tweetTime:", "\n", "#    continue", "\n", "#print fName", "\n", "        ", "for", "tweet", "in", "iterTweets", "(", "os", ".", "path", ".", "join", "(", "corpusPath", ",", "fName", ")", ")", ":", "\n", "            ", "if", "tweetTime", "and", "int", "(", "tweet", "[", "0", "]", ")", ">", "tweetTime", ":", "\n", "                ", "continue", "\n", "", "if", "tweet", "[", "2", "]", "!=", "'302'", ":", "#and not 'RT @' in tweet[4]: # FIXME retweet filtering", "\n", "                ", "writer", ".", "add_document", "(", "id", "=", "tweet", "[", "0", "]", ",", "\n", "date", "=", "tweet", "[", "3", "]", ",", "\n", "title", "=", "tweet", "[", "4", "]", "\n", ")", "\n", "\n", "", "", "", "writer", ".", "commit", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.hashtag.index": [[15, 52], ["os.listdir", "utils.hashtag.Segmenter", "whoosh.fields.Schema", "getIndexPath", "whoosh.index.create_in", "whoosh.index.create_in.writer", "ix.writer.commit", "os.path.exists", "os.makedirs", "shutil.rmtree", "os.makedirs", "utils.io.iterTweets", "whoosh.fields.ID", "whoosh.fields.TEXT", "os.path.join", "ix.writer.add_document", "int", "utils.hashtag.Segmenter.get", "len"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.__init__.getIndexPath", "home.repos.pwc.inspect_result.giacbrd_CipCipPy.classification.feature.FeatureExtractor.get"], ["", "def", "__init__", "(", "self", ",", "dictionary", ")", ":", "\n", "        ", "\"\"\"dictionary is a map of terms and frequency values (a dict file, serialized with pickle).\n        It can be generated from a generic text, and it is used for segmentation.\"\"\"", "\n", "self", ".", "dictionary", "=", "pickle", ".", "load", "(", "open", "(", "dictionary", ")", ")", "\n", "self", ".", "maxWordLength", "=", "max", "(", "map", "(", "len", ",", "self", ".", "dictionary", ")", ")", "\n", "self", ".", "total", "=", "float", "(", "sum", "(", "self", ".", "dictionary", ".", "values", "(", ")", ")", ")", "\n", "\n", "\n", "", "def", "get", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Segment the hashtag text\"\"\"", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "probs", ",", "lasts", "=", "[", "1.0", "]", ",", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "text", ")", "+", "1", ")", ":", "\n", "            ", "prob_k", ",", "k", "=", "max", "(", "(", "probs", "[", "j", "]", "*", "self", ".", "__wordProb", "(", "text", "[", "j", ":", "i", "]", ")", ",", "j", ")", "\n", "for", "j", "in", "range", "(", "max", "(", "0", ",", "i", "-", "self", ".", "maxWordLength", ")", ",", "i", ")", ")", "\n", "probs", ".", "append", "(", "prob_k", ")", "\n", "lasts", ".", "append", "(", "k", ")", "\n", "", "words", "=", "[", "]", "\n", "i", "=", "len", "(", "text", ")", "\n", "while", "0", "<", "i", ":", "\n", "            ", "words", ".", "append", "(", "text", "[", "lasts", "[", "i", "]", ":", "i", "]", ")", "\n", "i", "=", "lasts", "[", "i", "]", "\n", "", "words", ".", "reverse", "(", ")", "\n", "return", "words", ",", "probs", "[", "-", "1", "]", "\n", "\n", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "se", "=", "Segmenter", "(", "sys", ".", "argv", "[", "1", "]", ")", "\n", "print", "se", ".", "get", "(", "'skypeisnotworkingagain'", ")", "\n", "print", "se", ".", "get", "(", "'mamamiahereicomeagain'", ")", "\n", "print", "se", ".", "get", "(", "'blacksabbathrocks'", ")", "\n", "print", "se", ".", "get", "(", "'facebookisnotworking'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.__init__.getIndexPath": [[36, 38], ["os.path.join", "str"], "function", ["None"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.__init__.getIndex": [[39, 42], ["whoosh.index.open_dir().searcher", "whoosh.index.open_dir", "__init__.getIndexPath"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.__init__.getIndexPath"], []], "home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.status.index": [[14, 65], ["os.listdir", "whoosh.fields.Schema", "getIndexPath", "whoosh.index.create_in", "whoosh.index.create_in.writer", "ix.writer.commit", "os.path.exists", "os.makedirs", "shutil.rmtree", "os.makedirs", "utils.io.iterTweets", "whoosh.fields.ID", "whoosh.fields.DATETIME", "whoosh.fields.TEXT", "whoosh.fields.KEYWORD", "os.path.join", "ix.writer.add_document", "int", "int"], "function", ["home.repos.pwc.inspect_result.giacbrd_CipCipPy.indexing.__init__.getIndexPath"], ["def", "index", "(", "corpusPath", ",", "name", ",", "tweetTime", "=", "None", ",", "stored", "=", "False", ",", "overwrite", "=", "True", ",", "procs", "=", "PROC_NUM", ",", "limitmb", "=", "MEM_SIZE", ")", ":", "#, featureExtractor):", "\n", "    ", "\"\"\"Indexing of the status of tweets.\"\"\"", "\n", "\n", "dirList", "=", "os", ".", "listdir", "(", "corpusPath", ")", "\n", "\n", "schema", "=", "Schema", "(", "id", "=", "ID", "(", "stored", "=", "True", ",", "unique", "=", "True", ")", ",", "\n", "user", "=", "ID", ",", "\n", "http", "=", "NUMERIC", ",", "# http state", "\n", "date", "=", "DATETIME", "(", "stored", "=", "stored", ")", ",", "# tweet date", "\n", "status", "=", "TEXT", "(", "stored", "=", "stored", ")", ",", "# status text of the tweet #TODO use a proper analyzer", "\n", "hashtags", "=", "KEYWORD", "(", "stored", "=", "stored", ")", "# list of hashtags in the status", "\n", "#replies = KEYWORD, # list of user replies in the status, as users", "\n", "#vector = STORED", "\n", "#score = NUMERIC(stored = True), # static score for ranking", "\n", "#retweets = NUMERIC(type = type(1.), stored = True) # number of retweets of this tweet", "\n", "## next fields to fill on a second indexer pass ##", "\n", "#retweets = KEYWORD, # list of retweets in the status, as tweet ids", "\n", "#retweeteds = KEYWORD # list of tweets which retweet this tweet, as tweet ids", "\n", ")", "\n", "\n", "indexPath", "=", "getIndexPath", "(", "name", ",", "tweetTime", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "indexPath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "indexPath", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "overwrite", ":", "\n", "            ", "return", "\n", "", "shutil", ".", "rmtree", "(", "indexPath", ")", "\n", "os", ".", "makedirs", "(", "indexPath", ")", "\n", "", "ix", "=", "whoosh", ".", "index", ".", "create_in", "(", "indexPath", ",", "schema", ")", "\n", "writer", "=", "ix", ".", "writer", "(", "procs", "=", "PROC_NUM", ",", "limitmb", "=", "MEM_SIZE", ")", "\n", "\n", "for", "fName", "in", "dirList", ":", "\n", "#if tweetTime and dateFromFileName(fName) > tweetTime:", "\n", "#    continue", "\n", "#print fName", "\n", "        ", "for", "tweet", "in", "iterTweets", "(", "os", ".", "path", ".", "join", "(", "corpusPath", ",", "fName", ")", ")", ":", "\n", "            ", "if", "tweetTime", "and", "int", "(", "tweet", "[", "0", "]", ")", ">", "tweetTime", ":", "\n", "                ", "continue", "\n", "", "if", "tweet", "[", "2", "]", "!=", "'302'", ":", "#and not 'RT @' in tweet[4]: # FIXME retweet filtering", "\n", "#v = featureExtractor(tweet[4].encode('ascii', 'replace'))", "\n", "                ", "writer", ".", "add_document", "(", "id", "=", "tweet", "[", "0", "]", ",", "\n", "user", "=", "tweet", "[", "1", "]", ",", "\n", "http", "=", "int", "(", "tweet", "[", "2", "]", ")", ",", "\n", "date", "=", "tweet", "[", "3", "]", ",", "\n", "status", "=", "tweet", "[", "4", "]", ",", "\n", "hashtags", "=", "u' '", ".", "join", "(", "tweet", "[", "5", "]", ")", "\n", "#replies = u' '.join(tweet[6]),", "\n", "#vector = repr(v)", "\n", ")", "\n", "\n", "", "", "", "writer", ".", "commit", "(", ")", "\n", "", ""]]}