{"home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.random_state_selection": [[18, 60], ["state_importance_df.sample", "state_importance_df.sample.iterrows", "bisect.bisect", "bisect.insort_left", "summary_states_with_context.extend", "len", "len", "range"], "function", ["None"], ["def", "random_state_selection", "(", "state_importance_df", ",", "budget", ",", "context_length", ",", "minimum_gap", ",", "seed", "=", "None", ")", ":", "\n", "    ", "''' generate random summary\n    :param state_importance_df: dataframe with 2 columns: state and importance score of the state\n    :param budget: allowed length of summary - note this includes only the important states, it doesn't count context\n    around them\n    :param context_length: how many states to show around the chosen important state (e.g., if context_lenght=10, we\n    will show 10 states before and 10 states after the important state\n    :param minimum_gap: how many states should we skip after showing the context for an important state. For example, if\n    we chose state 200, and the context length is 10, we will show states 189-211. If minimum_gap=10, we will not\n    consider states 212-222 and states 178-198 because they are too close\n    :param seed: optional int to set a seed\n    :return: a list with the indices of the randomly chosen states, and a list with all summary states (includes the context)\n    '''", "\n", "shuffled_states", "=", "state_importance_df", ".", "sample", "(", "frac", "=", "1.0", ",", "random_state", "=", "seed", ",", "replace", "=", "False", ")", "\n", "summary_states", "=", "[", "]", "\n", "for", "index", ",", "row", "in", "shuffled_states", ".", "iterrows", "(", ")", ":", "\n", "\n", "        ", "state_index", "=", "row", "[", "'state'", "]", "\n", "index_in_summary", "=", "bisect", "(", "summary_states", ",", "state_index", ")", "\n", "# print('state: ', state_index)", "\n", "# print('index in summary: ', index_in_summary)", "\n", "# print('summary: ', summary_states)", "\n", "state_before", "=", "None", "\n", "state_after", "=", "None", "\n", "if", "index_in_summary", ">", "0", ":", "\n", "            ", "state_before", "=", "summary_states", "[", "index_in_summary", "-", "1", "]", "\n", "", "if", "index_in_summary", "<", "len", "(", "summary_states", ")", ":", "\n", "            ", "state_after", "=", "summary_states", "[", "index_in_summary", "]", "\n", "", "if", "state_after", "is", "not", "None", ":", "\n", "            ", "if", "state_index", "+", "context_length", "+", "minimum_gap", ">", "state_after", ":", "\n", "                ", "continue", "\n", "", "", "if", "state_before", "is", "not", "None", ":", "\n", "            ", "if", "state_index", "-", "context_length", "-", "minimum_gap", "<", "state_before", ":", "\n", "                ", "continue", "\n", "", "", "insort_left", "(", "summary_states", ",", "state_index", ")", "\n", "if", "len", "(", "summary_states", ")", "==", "budget", ":", "\n", "            ", "break", "\n", "\n", "", "", "summary_states_with_context", "=", "[", "]", "\n", "for", "state", "in", "summary_states", ":", "\n", "        ", "summary_states_with_context", ".", "extend", "(", "(", "range", "(", "state", "-", "context_length", ",", "state", "+", "context_length", ")", ")", ")", "\n", "", "return", "summary_states", ",", "summary_states_with_context", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.highlights": [[61, 102], ["state_importance_df.sort_values", "state_importance_df.sort_values.iterrows", "bisect.bisect", "bisect.insort_left", "summary_states_with_context.extend", "len", "len", "range"], "function", ["None"], ["", "def", "highlights", "(", "state_importance_df", ",", "budget", ",", "context_length", ",", "minimum_gap", ")", ":", "\n", "    ", "''' generate highlights summary\n    :param state_importance_df: dataframe with 2 columns: state and importance score of the state\n    :param budget: allowed length of summary - note this includes only the important states, it doesn't count context\n    around them\n    :param context_length: how many states to show around the chosen important state (e.g., if context_lenght=10, we\n    will show 10 states before and 10 states after the important state\n    :param minimum_gap: how many states should we skip after showing the context for an important state. For example, if\n    we chose state 200, and the context length is 10, we will show states 189-211. If minimum_gap=10, we will not\n    consider states 212-222 and states 178-198 because they are too close\n    :return: a list with the indices of the important states, and a list with all summary states (includes the context)\n    '''", "\n", "sorted_df", "=", "state_importance_df", ".", "sort_values", "(", "[", "'importance'", "]", ",", "ascending", "=", "False", ")", "\n", "summary_states", "=", "[", "]", "\n", "for", "index", ",", "row", "in", "sorted_df", ".", "iterrows", "(", ")", ":", "\n", "\n", "        ", "state_index", "=", "row", "[", "'state'", "]", "\n", "index_in_summary", "=", "bisect", "(", "summary_states", ",", "state_index", ")", "\n", "# print('state: ', state_index)", "\n", "# print('index in summary: ', index_in_summary)", "\n", "# print('summary: ', summary_states)", "\n", "state_before", "=", "None", "\n", "state_after", "=", "None", "\n", "if", "index_in_summary", ">", "0", ":", "\n", "            ", "state_before", "=", "summary_states", "[", "index_in_summary", "-", "1", "]", "\n", "", "if", "index_in_summary", "<", "len", "(", "summary_states", ")", ":", "\n", "            ", "state_after", "=", "summary_states", "[", "index_in_summary", "]", "\n", "", "if", "state_after", "is", "not", "None", ":", "\n", "            ", "if", "state_index", "+", "context_length", "+", "minimum_gap", ">", "state_after", ":", "\n", "                ", "continue", "\n", "", "", "if", "state_before", "is", "not", "None", ":", "\n", "            ", "if", "state_index", "-", "context_length", "-", "minimum_gap", "<", "state_before", ":", "\n", "                ", "continue", "\n", "", "", "insort_left", "(", "summary_states", ",", "state_index", ")", "\n", "if", "len", "(", "summary_states", ")", "==", "budget", ":", "\n", "            ", "break", "\n", "\n", "", "", "summary_states_with_context", "=", "[", "]", "\n", "for", "state", "in", "summary_states", ":", "\n", "        ", "summary_states_with_context", ".", "extend", "(", "(", "range", "(", "state", "-", "context_length", ",", "state", "+", "context_length", ")", ")", ")", "\n", "", "return", "summary_states", ",", "summary_states_with_context", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.find_similar_state_in_summary": [[105, 119], ["distance_metric"], "function", ["None"], ["", "def", "find_similar_state_in_summary", "(", "state_importance_df", ",", "summary_states", ",", "new_state", ",", "distance_metric", ",", "distance_threshold", "=", "None", ")", ":", "\n", "    ", "most_similar_state", "=", "None", "\n", "minimal_distance", "=", "10000000", "\n", "for", "state", "in", "summary_states", ":", "\n", "        ", "state_features", "=", "state_importance_df", ".", "loc", "[", "state_importance_df", "[", "'state'", "]", "==", "state", "]", ".", "iloc", "[", "0", "]", ".", "features", "\n", "distance", "=", "distance_metric", "(", "state_features", ",", "new_state", ")", "\n", "if", "distance", "<", "minimal_distance", ":", "\n", "            ", "minimal_distance", "=", "distance", "\n", "most_similar_state", "=", "state", "\n", "", "", "if", "distance_threshold", "is", "None", ":", "\n", "        ", "return", "most_similar_state", ",", "minimal_distance", "\n", "", "elif", "minimal_distance", "<", "distance_threshold", ":", "\n", "        ", "return", "most_similar_state", ",", "minimal_distance", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.highlights_div": [[121, 210], ["state_importance_df[].values.min", "state_importance_df[].values.max", "numpy.random.choice", "range", "numpy.array", "numpy.percentile", "print", "state_importance_df.sort_values", "state_importance_df.sort_values.iterrows", "len", "range", "bisect.bisect", "highlights_state_selection.find_similar_state_in_summary", "len", "distance_metric", "np.array.append", "len", "bisect.insort_left", "print", "max", "summary_states_with_context.extend", "len", "bisect.insort_left", "print", "min", "range"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.find_similar_state_in_summary"], ["", "def", "highlights_div", "(", "state_importance_df", ",", "budget", ",", "context_length", ",", "minimum_gap", ",", "distance_metric", "=", "distance", ".", "euclidean", ",", "percentile_threshold", "=", "3", ",", "subset_threshold", "=", "1000", ")", ":", "\n", "    ", "''' generate highlights-div  summary\n    :param state_importance_df: dataframe with 2 columns: state and importance score of the state\n    :param budget: allowed length of summary - note this includes only the important states, it doesn't count context\n    around them\n    :param context_length: how many states to show around the chosen important state (e.g., if context_lenght=10, we\n    will show 10 states before and 10 states after the important state\n    :param minimum_gap: how many states should we skip after showing the context for an important state. For example, if\n    we chose state 200, and the context length is 10, we will show states 189-211. If minimum_gap=10, we will not\n    consider states 212-222 and states 178-198 because they are too close\n    :param distance_metric: metric to use for comparing states (function)\n    :param percentile_threshold: what minimal distance to allow between states in summary\n    :param subset_threshold: number of random states to be used as basis for the div-threshold\n    :return: a list with the indices of the important states, and a list with all summary states (includes the context)\n    '''", "\n", "\n", "min_state", "=", "state_importance_df", "[", "'state'", "]", ".", "values", ".", "min", "(", ")", "\n", "max_state", "=", "state_importance_df", "[", "'state'", "]", ".", "values", ".", "max", "(", ")", "\n", "\n", "state_features", "=", "state_importance_df", "[", "'features'", "]", ".", "values", "\n", "state_features", "=", "np", ".", "random", ".", "choice", "(", "state_features", ",", "size", "=", "subset_threshold", ",", "replace", "=", "False", ")", "\n", "distances", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "state_features", "-", "1", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "state_features", ")", ")", ":", "\n", "            ", "distance", "=", "distance_metric", "(", "state_features", "[", "i", "]", ",", "state_features", "[", "j", "]", ")", "\n", "distances", ".", "append", "(", "distance", ")", "\n", "", "", "distances", "=", "np", ".", "array", "(", "distances", ")", "\n", "threshold", "=", "np", ".", "percentile", "(", "distances", ",", "percentile_threshold", ")", "\n", "print", "(", "'threshold:'", ",", "threshold", ")", "\n", "\n", "sorted_df", "=", "state_importance_df", ".", "sort_values", "(", "[", "'importance'", "]", ",", "ascending", "=", "False", ")", "\n", "summary_states", "=", "[", "]", "\n", "summary_states_with_context", "=", "[", "]", "\n", "num_chosen_states", "=", "0", "\n", "for", "index", ",", "row", "in", "sorted_df", ".", "iterrows", "(", ")", ":", "\n", "        ", "state_index", "=", "row", "[", "'state'", "]", "\n", "index_in_summary", "=", "bisect", "(", "summary_states", ",", "state_index", ")", "\n", "# print('state: ', state_index)", "\n", "# print('index in summary: ', index_in_summary)", "\n", "# print('summary: ', summary_states)", "\n", "state_before", "=", "None", "\n", "state_after", "=", "None", "\n", "if", "index_in_summary", ">", "0", ":", "\n", "            ", "state_before", "=", "summary_states", "[", "index_in_summary", "-", "1", "]", "\n", "", "if", "index_in_summary", "<", "len", "(", "summary_states", ")", ":", "\n", "            ", "state_after", "=", "summary_states", "[", "index_in_summary", "]", "\n", "", "if", "state_after", "is", "not", "None", ":", "\n", "            ", "if", "state_index", "+", "context_length", "+", "minimum_gap", ">", "state_after", ":", "\n", "                ", "continue", "\n", "", "", "if", "state_before", "is", "not", "None", ":", "\n", "            ", "if", "state_index", "-", "context_length", "-", "minimum_gap", "<", "state_before", ":", "\n", "                ", "continue", "\n", "\n", "# if num_chosen_states < budget:", "\n", "#     insort_left(summary_states,state_index)", "\n", "#     num_chosen_states += 1", "\n", "\n", "\n", "# compare to most similar state", "\n", "", "", "most_similar_state", ",", "min_distance", "=", "find_similar_state_in_summary", "(", "state_importance_df", ",", "summary_states_with_context", ",", "row", "[", "'features'", "]", ",", "\n", "distance_metric", ")", "\n", "if", "most_similar_state", "is", "None", ":", "\n", "            ", "insort_left", "(", "summary_states", ",", "state_index", ")", "\n", "num_chosen_states", "+=", "1", "\n", "print", "(", "'summary_states:'", ",", "summary_states", ")", "\n", "\n", "", "else", ":", "\n", "# similar_state_importance = state_importance_df.loc[state_importance_df['state'] == most_similar_state].iloc[0].importance", "\n", "# if row['importance'] > similar_state_importance:", "\n", "            ", "if", "min_distance", ">", "threshold", ":", "\n", "                ", "insort_left", "(", "summary_states", ",", "state_index", ")", "\n", "num_chosen_states", "+=", "1", "\n", "print", "(", "'summary_states:'", ",", "summary_states", ")", "\n", "# print('took')", "\n", "# else:", "\n", "#     print(state_index)", "\n", "#     print('skipped')", "\n", "\n", "#recalculate the context states", "\n", "", "", "summary_states_with_context", "=", "[", "]", "\n", "for", "state", "in", "summary_states", ":", "\n", "            ", "left_index", "=", "max", "(", "state", "-", "context_length", ",", "min_state", ")", "\n", "right_index", "=", "min", "(", "state", "+", "context_length", ",", "max_state", ")", "+", "1", "\n", "summary_states_with_context", ".", "extend", "(", "(", "range", "(", "left_index", ",", "right_index", ")", ")", ")", "\n", "\n", "", "if", "len", "(", "summary_states", ")", "==", "budget", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "summary_states", ",", "summary_states_with_context", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.compute_states_importance": [[212, 218], ["states_q_values_df[].apply", "states_q_values_df[].apply", "numpy.max", "numpy.min", "numpy.max", "numpy.partition", "x.flatten"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.ArgmaxRule.apply", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.ArgmaxRule.apply"], ["", "def", "compute_states_importance", "(", "states_q_values_df", ",", "compare_to", "=", "'worst'", ")", ":", "\n", "    ", "if", "compare_to", "==", "'worst'", ":", "\n", "        ", "states_q_values_df", "[", "'importance'", "]", "=", "states_q_values_df", "[", "'q_values'", "]", ".", "apply", "(", "lambda", "x", ":", "np", ".", "max", "(", "x", ")", "-", "np", ".", "min", "(", "x", ")", ")", "\n", "", "elif", "compare_to", "==", "'second'", ":", "\n", "        ", "states_q_values_df", "[", "'importance'", "]", "=", "states_q_values_df", "[", "'q_values'", "]", ".", "apply", "(", "lambda", "x", ":", "np", ".", "max", "(", "x", ")", "-", "np", ".", "partition", "(", "x", ".", "flatten", "(", ")", ",", "-", "2", ")", "[", "-", "2", "]", ")", "\n", "", "return", "states_q_values_df", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.read_q_value_files": [[219, 238], ["os.listdir", "pandas.DataFrame", "filename.split", "int", "states.append", "open", "str.strip", "numpy.fromstring", "q_values_list.append", "q_val_file.read", "len"], "function", ["None"], ["", "def", "read_q_value_files", "(", "path", ")", ":", "\n", "    ", "''' reading q values from files. Assume each state is a seperate text file with a list of q values\n    :param path: path to the directory where the text files are stored\n    :return: a pandas dataframe with two columns: state (index) and q_values (numpy array)\n    '''", "\n", "states", "=", "[", "]", "\n", "q_values_list", "=", "[", "]", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "path", ")", ":", "\n", "        ", "file_split", "=", "filename", ".", "split", "(", "'_'", ")", "\n", "state_index", "=", "int", "(", "file_split", "[", "len", "(", "file_split", ")", "-", "1", "]", "[", ":", "-", "4", "]", ")", "\n", "states", ".", "append", "(", "state_index", ")", "\n", "# print(filename)", "\n", "with", "open", "(", "path", "+", "'/'", "+", "filename", ",", "'r'", ")", "as", "q_val_file", ":", "\n", "            ", "q_vals", "=", "str", ".", "strip", "(", "q_val_file", ".", "read", "(", ")", ",", "'[]'", ")", "\n", "q_vals", "=", "np", ".", "fromstring", "(", "q_vals", ",", "dtype", "=", "float", ",", "sep", "=", "' '", ")", "\n", "q_values_list", ".", "append", "(", "q_vals", ")", "\n", "\n", "", "", "q_values_df", "=", "pd", ".", "DataFrame", "(", "{", "'state'", ":", "states", ",", "'q_values'", ":", "q_values_list", "}", ")", "\n", "return", "q_values_df", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.read_feature_files": [[240, 263], ["os.listdir", "pandas.DataFrame", "filename.split", "int", "states.append", "filename.endswith", "open", "str.strip", "features_text.replace.replace", "numpy.fromstring", "feature_vector_list.append", "feature_file.read", "features_text.replace.split", "len"], "function", ["None"], ["", "def", "read_feature_files", "(", "path", ")", ":", "\n", "    ", "''' reading state features from files. Assume each state is a seperate text file with a feature vector\n    :param path: path to the directory where the text files are stored\n    :return: a pandas dataframe with two columns: state (index) and features (numpy array)\n    '''", "\n", "states", "=", "[", "]", "\n", "feature_vector_list", "=", "[", "]", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "path", ")", ":", "\n", "        ", "if", "not", "filename", ".", "endswith", "(", "'.txt'", ")", ":", "# skip text files, use npy files", "\n", "            ", "continue", "\n", "", "file_split", "=", "filename", ".", "split", "(", "'_'", ")", "\n", "state_index", "=", "int", "(", "file_split", "[", "len", "(", "file_split", ")", "-", "1", "]", "[", ":", "-", "4", "]", ")", "\n", "states", ".", "append", "(", "state_index", ")", "\n", "# print(filename)", "\n", "with", "open", "(", "path", "+", "'/'", "+", "filename", ",", "'r'", ")", "as", "feature_file", ":", "\n", "            ", "features_text", "=", "str", ".", "strip", "(", "feature_file", ".", "read", "(", ")", ",", "'[]'", ")", "\n", "features_text", "=", "features_text", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "features_text", "=", "' '", ".", "join", "(", "features_text", ".", "split", "(", ")", ")", "\n", "feature_vector", "=", "np", ".", "fromstring", "(", "features_text", ",", "dtype", "=", "float", ",", "sep", "=", "' '", ")", "\n", "feature_vector_list", ".", "append", "(", "feature_vector", ")", "\n", "\n", "", "", "state_features_df", "=", "pd", ".", "DataFrame", "(", "{", "'state'", ":", "states", ",", "'features'", ":", "feature_vector_list", "}", ")", "\n", "return", "state_features_df", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.highlights_state_selection.read_input_files": [[264, 284], ["os.listdir", "pandas.DataFrame", "filename.endswith", "filename.split", "int", "states.append", "numpy.load", "input.flatten.flatten", "input_list.append", "os.path.join", "len"], "function", ["None"], ["", "def", "read_input_files", "(", "path", ")", ":", "\n", "    ", "'''reading state inputs from files. Assume each state is a seperate npy file with a array\n    :param path: path to the directory where the npy files are stored\n    :return: a pandas dataframe with two columns: state (index) and features (numpy array)\n    The inputs are called features so one can use the df interchangeably with the one from read_feature_files.\n    '''", "\n", "states", "=", "[", "]", "\n", "input_list", "=", "[", "]", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "path", ")", ":", "\n", "        ", "if", "filename", ".", "endswith", "(", "'.npy'", ")", ":", "# only use npy files", "\n", "            ", "file_split", "=", "filename", ".", "split", "(", "'_'", ")", "\n", "state_index", "=", "int", "(", "file_split", "[", "len", "(", "file_split", ")", "-", "1", "]", "[", ":", "-", "4", "]", ")", "\n", "states", ".", "append", "(", "state_index", ")", "\n", "\n", "input", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ")", "\n", "input", "=", "input", ".", "flatten", "(", ")", "#flatten arrays since we only need the distance between states", "\n", "input_list", ".", "append", "(", "input", ")", "\n", "\n", "", "", "state_input_df", "=", "pd", ".", "DataFrame", "(", "{", "'state'", ":", "states", ",", "'features'", ":", "input_list", "}", ")", "#we use features as name to make the div-code less bloated", "\n", "return", "state_input_df", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.Argmax.__init__": [[12, 15], ["innvestigate.analyzer.relevance_based.relevance_analyzer._LRPFixedParams.__init__"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "innvestigate", ".", "analyzer", ".", "relevance_based", ".", "relevance_analyzer", ".", "LRP_RULES", "[", "'Argmax'", "]", "=", "ArgmaxRule", "\n", "super", "(", "Argmax", ",", "self", ")", ".", "__init__", "(", "model", ",", "*", "args", ",", "rule", "=", "\"Argmax\"", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.ArgmaxRule.__init__": [[21, 45], ["innvestigate.analyzer.relevance_based.relevance_rule.Alpha1Beta0IgnoreBiasRule.__init__", "innvestigate.analyzer.relevance_based.relevance_rule.Alpha1Beta0IgnoreBiasRule.__init__"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.__init__", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "layer", "=", "args", "[", "0", "]", "\n", "self", ".", "layer", "=", "layer", "\n", "\n", "# use classical LRP rule for non-convolutional layers and first convolutional layer after the input", "\n", "if", "layer", ".", "__class__", "==", "keras", ".", "layers", ".", "convolutional", ".", "Conv2D", ":", "\n", "            ", "if", "layer", ".", "_inbound_nodes", "[", "0", "]", ".", "inbound_layers", "[", "0", "]", ".", "__class__", "==", "keras", ".", "engine", ".", "input_layer", ".", "InputLayer", ":", "\n", "                ", "super", "(", "Alpha1Beta0IgnoreBiasRule", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "\n", "alpha", "=", "1", ",", "\n", "beta", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "weights", "=", "layer", ".", "weights", "[", "0", "]", "\n", "self", ".", "padding", "=", "layer", ".", "padding", "\n", "self", ".", "filter_size", "=", "layer", ".", "kernel_size", "[", "0", "]", "\n", "#TODO assumes quadratic stride for now", "\n", "self", ".", "stride", "=", "layer", ".", "strides", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "super", "(", "Alpha1Beta0IgnoreBiasRule", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "\n", "alpha", "=", "1", ",", "\n", "beta", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.ArgmaxRule.apply": [[47, 123], ["super().apply", "super().apply", "Xs.get_shape().as_list", "list", "list.pop", "custom_layers.ArgmaxPositions", "keras.spatial_2d_padding", "keras.spatial_2d_padding", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "Xs.get_shape", "keras.spatial_2d_padding", "keras.spatial_2d_padding", "ValueError", "max", "max", "max", "max"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.ArgmaxRule.apply", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.ArgmaxRule.apply"], ["", "", "def", "apply", "(", "self", ",", "Xs", ",", "Ys", ",", "Rs", ",", "reverse_state", ")", ":", "\n", "# use classical LRP rule for non-convolutional layers and first convolutional layer after the input", "\n", "        ", "if", "self", ".", "layer", ".", "__class__", "!=", "keras", ".", "layers", ".", "convolutional", ".", "Conv2D", ":", "\n", "            ", "return", "super", "(", "Alpha1Beta0IgnoreBiasRule", ",", "self", ")", ".", "apply", "(", "Xs", ",", "Ys", ",", "Rs", ",", "reverse_state", ")", "\n", "", "if", "self", ".", "layer", ".", "_inbound_nodes", "[", "0", "]", ".", "inbound_layers", "[", "0", "]", ".", "__class__", "==", "keras", ".", "engine", ".", "input_layer", ".", "InputLayer", ":", "\n", "            ", "return", "super", "(", "Alpha1Beta0IgnoreBiasRule", ",", "self", ")", ".", "apply", "(", "Xs", ",", "Ys", ",", "Rs", ",", "reverse_state", ")", "\n", "\n", "#remove additional array from innvestigate LRP stuff", "\n", "#TODO this could break something", "\n", "", "Xs", "=", "Xs", "[", "0", "]", "#TODO make this more generall", "\n", "Rs", "=", "Rs", "[", "0", "]", "\n", "\n", "weights", "=", "self", ".", "weights", "\n", "padding", "=", "self", ".", "padding", "\n", "filter_size", "=", "self", ".", "filter_size", "\n", "stride", "=", "self", ".", "stride", "\n", "input_shape", "=", "Xs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "\n", "# getting the output of the previous layer and add padding if it was used while training the net", "\n", "if", "(", "padding", "!=", "0", ")", ":", "\n", "            ", "if", "(", "padding", "==", "\"valid\"", ")", ":", "\n", "#TODO non quadratic filters", "\n", "                ", "filter_height", "=", "filter_size", "\n", "filter_width", "=", "filter_size", "\n", "\n", "# valid padding doesnt really pad but only considers the values outside the original input as zero, so we just pad enough zeros at the ends of the input", "\n", "pad_top", "=", "0", "\n", "pad_bottom", "=", "filter_height", "\n", "pad_left", "=", "0", "\n", "pad_right", "=", "filter_size", "\n", "\n", "# padded_input", "\n", "out", "=", "K", ".", "spatial_2d_padding", "(", "Xs", ",", "padding", "=", "(", "(", "pad_top", ",", "pad_bottom", ")", ",", "(", "pad_left", ",", "pad_right", ")", ")", ")", "\n", "\n", "", "elif", "(", "padding", "==", "\"same\"", ")", ":", "\n", "                ", "in_height", "=", "input_shape", "[", "0", "]", "\n", "in_width", "=", "input_shape", "[", "1", "]", "\n", "filter_height", "=", "filter_size", "\n", "filter_width", "=", "filter_size", "\n", "strides", "=", "(", "1", ",", "stride", ",", "stride", ",", "1", ")", "\n", "\n", "# calculate padding according to https://www.tensorflow.org/api_guides/python/nn#Convolution ( tf version 1.11 )", "\n", "if", "(", "in_height", "%", "strides", "[", "1", "]", "==", "0", ")", ":", "\n", "                    ", "pad_along_height", "=", "max", "(", "filter_height", "-", "strides", "[", "1", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                    ", "pad_along_height", "=", "max", "(", "filter_height", "-", "(", "in_height", "%", "strides", "[", "1", "]", ")", ",", "0", ")", "\n", "", "if", "(", "in_width", "%", "strides", "[", "2", "]", "==", "0", ")", ":", "\n", "                    ", "pad_along_width", "=", "max", "(", "filter_width", "-", "strides", "[", "2", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                    ", "pad_along_width", "=", "max", "(", "filter_width", "-", "(", "in_width", "%", "strides", "[", "2", "]", ")", ",", "0", ")", "\n", "\n", "", "pad_top", "=", "pad_along_height", "//", "2", "\n", "pad_bottom", "=", "pad_along_height", "-", "pad_top", "\n", "pad_left", "=", "pad_along_width", "//", "2", "\n", "pad_right", "=", "pad_along_width", "-", "pad_left", "\n", "\n", "#padded_input", "\n", "out", "=", "K", ".", "spatial_2d_padding", "(", "Xs", ",", "padding", "=", "(", "(", "pad_top", ",", "pad_bottom", ")", ",", "(", "pad_left", ",", "pad_right", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'as of now only *same*,*valid* and *0* are supported paddings'", ")", "\n", "\n", "", "self", ".", "input_vector_length", "=", "1", "\n", "shape", "=", "list", "(", "out", ".", "shape", ")", "\n", "shape", ".", "pop", "(", "0", ")", "\n", "for", "i", "in", "shape", ":", "\n", "                ", "self", ".", "input_vector_length", "*=", "i", "\n", "\n", "# the actual argmax part", "\n", "", "", "new_relevance_array", "=", "custom_layers", ".", "ArgmaxPositions", "(", "stride", ",", "filter_size", ",", "out", ",", "weights", ")", "(", "Rs", ")", "\n", "\n", "#remove padding, if it was added", "\n", "if", "(", "padding", "!=", "0", ")", ":", "\n", "            ", "new_relevance_array", "=", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", ":", ",", "pad_top", ":", "-", "pad_bottom", ",", "pad_left", ":", "-", "pad_right", ",", ":", "]", ")", "(", "new_relevance_array", ")", "\n", "\n", "", "return", "new_relevance_array", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.add_saliency_to_image": [[16, 33], ["skimage.transform.resize", "numpy.zeros", "numpy.stack", "numpy.clip"], "function", ["None"], ["def", "add_saliency_to_image", "(", "saliency", ",", "image", ",", "saliency_brightness", "=", "2", ")", ":", "\n", "    ", "'''\n    adds a saliency map(in green) over a given image\n    :param saliency: the saliency map to be applied\n    :param image: the original image\n    :param saliency_brightness: the brightness of the saliency map\n    :return: the overlayed image\n    '''", "\n", "\n", "image_shape", "=", "(", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ")", "\n", "saliency", "=", "transform", ".", "resize", "(", "saliency", ",", "image_shape", ",", "order", "=", "0", ",", "mode", "=", "'reflect'", ")", "\n", "zeros", "=", "np", ".", "zeros", "(", "image_shape", ")", "\n", "saliency", "=", "np", ".", "stack", "(", "(", "zeros", ",", "saliency", ",", "zeros", ")", ",", "axis", "=", "-", "1", ")", "\n", "saliency", "*=", "saliency_brightness", "\n", "final_image", "=", "image", "+", "saliency", "\n", "final_image", "=", "np", ".", "clip", "(", "final_image", ",", "0", ",", "1", ")", "\n", "return", "final_image", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.create_edge_image": [[34, 43], ["skimage.color.rgb2gray", "skimage.filters.sobel", "numpy.stack"], "function", ["None"], ["", "def", "create_edge_image", "(", "image", ")", ":", "\n", "    ", "''' creates a edge version of an image\n    :param image: the original image\n    :return: edge only version of the image\n    '''", "\n", "image", "=", "skimage", ".", "color", ".", "rgb2gray", "(", "image", ")", "\n", "image", "=", "filters", ".", "sobel", "(", "image", ")", "\n", "image", "=", "np", ".", "stack", "(", "(", "image", ",", "image", ",", "image", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.output_saliency_map": [[44, 62], ["numpy.squeeze", "skimage.transform.resize", "image_utils.add_saliency_to_image", "image_utils.create_edge_image"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.add_saliency_to_image", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.create_edge_image"], ["", "def", "output_saliency_map", "(", "saliency", ",", "image", ",", "scale_factor", "=", "3", ",", "saliency_factor", "=", "2", ",", "edges", "=", "True", ")", ":", "\n", "    ", "''' scales the image and adds the saliency map\n    :param saliency:\n    :param image:\n    :param scale_factor: factor to scale height and width of the image\n    :param saliency_factor:\n    :param edges: if True, creates a edge version of the image first\n    :return:\n    '''", "\n", "image", "=", "np", ".", "squeeze", "(", "image", ")", "\n", "output_shape", "=", "(", "image", ".", "shape", "[", "0", "]", "*", "scale_factor", ",", "image", ".", "shape", "[", "1", "]", "*", "scale_factor", ")", "\n", "image", "=", "transform", ".", "resize", "(", "image", ",", "output_shape", ",", "order", "=", "0", ",", "mode", "=", "'reflect'", ")", "\n", "if", "edges", ":", "\n", "        ", "image", "=", "create_edge_image", "(", "image", ",", "output_shape", ")", "\n", "\n", "", "final_image", "=", "add_saliency_to_image", "(", "saliency", ",", "image", ",", "saliency_factor", ")", "\n", "\n", "return", "final_image", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.saliency_in_channel": [[63, 81], ["numpy.squeeze", "skimage.transform.resize", "skimage.transform.resize", "numpy.clip"], "function", ["None"], ["", "def", "saliency_in_channel", "(", "saliency", ",", "image", ",", "scale_factor", "=", "3", ",", "saliency_brightness", "=", "2", ",", "channel", "=", "1", ")", ":", "\n", "    ", "'''\n    Ressizes image and adds saliency\n    :param saliency:\n    :param image:\n    :param scale_factor:\n    :param saliency_factor:\n    :return:\n    '''", "\n", "image", "=", "np", ".", "squeeze", "(", "image", ")", "\n", "output_shape", "=", "(", "image", ".", "shape", "[", "0", "]", "*", "scale_factor", ",", "image", ".", "shape", "[", "1", "]", "*", "scale_factor", ")", "\n", "image", "=", "transform", ".", "resize", "(", "image", ",", "output_shape", ",", "order", "=", "0", ",", "mode", "=", "'reflect'", ")", "\n", "saliency", "=", "transform", ".", "resize", "(", "saliency", ",", "output_shape", ",", "order", "=", "0", ",", "mode", "=", "'reflect'", ")", "\n", "saliency", "=", "saliency", "*", "saliency_brightness", "\n", "image", "[", ":", ",", ":", ",", "channel", "]", "=", "saliency", "\n", "image", "=", "np", ".", "clip", "(", "image", ",", "0", ",", "1", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.normalise_image": [[82, 95], ["numpy.asarray", "np.asarray.min", "np.asarray.max", "print", "np.asarray.max"], "function", ["None"], ["", "def", "normalise_image", "(", "image", ")", ":", "\n", "    ", "'''normalises image by forcing the min and max values to 0 and 1 respectively\n     :param image: the input image\n    :return: normalised image as numpy array\n    '''", "\n", "try", ":", "\n", "        ", "image", "=", "np", ".", "asarray", "(", "image", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "'Cannot convert image to array'", ")", "\n", "", "image", "=", "image", "-", "image", ".", "min", "(", ")", "\n", "if", "image", ".", "max", "(", ")", "!=", "0", ":", "\n", "        ", "image", "=", "image", "/", "image", ".", "max", "(", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.show_image": [[96, 100], ["matplotlib.imshow", "matplotlib.show"], "function", ["None"], ["", "def", "show_image", "(", "image", ")", ":", "\n", "    ", "'''shortcut to show an image with matplotlib'''", "\n", "plt", ".", "imshow", "(", "image", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.crop_image_button": [[101, 112], ["int"], "function", ["None"], ["", "def", "crop_image_button", "(", "image", ",", "part", "=", "0.18", ")", ":", "\n", "    ", "'''\n    cuts the lower *part* from an image\n    :param image: the image to be cropped\n    :param part: part of the image to be cut (expects floats between 0 and 1)\n    :return: the cropped image\n    '''", "\n", "image_length", "=", "image", ".", "shape", "[", "0", "]", "\n", "pixels", "=", "int", "(", "image_length", "*", "part", ")", "\n", "crop", "=", "image", "[", "0", ":", "image_length", "-", "pixels", ",", ":", ",", ":", "]", "\n", "return", "crop", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.add_black_pixels": [[113, 124], ["numpy.zeros"], "function", ["None"], ["", "def", "add_black_pixels", "(", "image", ",", "pixels", "=", "80", ")", ":", "\n", "    ", "'''\n    adds black pixels to the bottom of an image\n    :param image: the image\n    :param pixels: the number of black pixels to be added\n    :return: image with black pixels\n    '''", "\n", "image_length", "=", "image", ".", "shape", "[", "0", "]", "\n", "new_image", "=", "np", ".", "zeros", "(", "(", "image_length", "+", "pixels", ",", "image", ".", "shape", "[", "1", "]", ",", "image", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "image", ".", "dtype", ")", "\n", "new_image", "[", "0", ":", "image_length", ",", ":", ",", ":", "]", "=", "image", "\n", "return", "new_image", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.interpolate": [[126, 138], ["float_array.astype"], "function", ["None"], ["", "def", "interpolate", "(", "array1", ",", "array2", ",", "t", ")", ":", "\n", "    ", "'''\n    linear interpolation between two frames of a state\n    :param array1: starting array\n    :param array2: end array\n    :param t: time parameter, goes from -1 to 3 ( 0=0.25, 3=1 in the normal interpolation formula)\n    :return: the interpolated array\n    '''", "\n", "t", "=", "(", "t", "*", "0.25", ")", "+", "0.25", "\n", "float_array", "=", "(", "array2", "*", "t", ")", "+", "(", "array1", "*", "(", "1", "-", "t", ")", ")", "\n", "int_array", "=", "float_array", ".", "astype", "(", "'uint8'", ")", "\n", "return", "int_array", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.generate_video": [[139, 188], ["image_utils.natural_sort", "cv2.VideoWriter_fourcc", "cv2.VideoWriter", "numpy.zeros", "int", "cv2.destroyAllWindows", "cv2.VideoWriter.release", "os.path.isdir", "os.makedirs", "os.listdir", "image.split", "int", "cv2.VideoWriter.write", "cv2.imread", "cv2.resize", "print", "print", "range", "os.path.join", "image_utils.crop_image_button", "image_utils.add_black_pixels", "cv2.VideoWriter.write"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.natural_sort", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.crop_image_button", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.add_black_pixels"], ["", "def", "generate_video", "(", "image_folder", ",", "out_path", ",", "name", "=", "\"video.mp4\"", ",", "image_indices", "=", "None", ",", "crop_images", "=", "True", ",", "black_pixels", "=", "80", ")", ":", "\n", "    ", "''' creates a video from images in a folder\n    :param image_folder: folder containing the images\n    :param out_path: output folder for the video\n    :param name: name of the output video\n    :param image_indices: states to be included in the summary video\n    :return: nothing, but saves the video in the given path\n    '''", "\n", "images", "=", "[", "img", "for", "img", "in", "os", ".", "listdir", "(", "image_folder", ")", "]", "\n", "images", "=", "natural_sort", "(", "images", ")", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'H264'", ")", "#important for browser support, MP4V is not working with browsers", "\n", "fps", "=", "30", "\n", "height", ",", "width", ",", "layers", "=", "420", ",", "320", ",", "3", "\n", "if", "not", "(", "os", ".", "path", ".", "isdir", "(", "out_path", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_path", ")", "\n", "", "video", "=", "cv2", ".", "VideoWriter", "(", "out_path", "+", "name", ",", "fourcc", ",", "fps", ",", "(", "width", ",", "height", "+", "black_pixels", ")", ")", "\n", "old_state_index", "=", "None", "\n", "black_frame", "=", "np", ".", "zeros", "(", "(", "height", "+", "black_pixels", ",", "width", ",", "layers", ")", ",", "np", ".", "uint8", ")", "\n", "black_frame_number", "=", "int", "(", "fps", ")", "\n", "\n", "for", "image", "in", "images", ":", "\n", "        ", "to_write", "=", "False", "\n", "try", ":", "\n", "            ", "image_str", "=", "image", ".", "split", "(", "'_'", ")", "\n", "state_index", "=", "int", "(", "image_str", "[", "1", "]", ")", "\n", "if", "(", "state_index", "in", "image_indices", ")", "or", "(", "image_indices", "is", "None", ")", ":", "\n", "\n", "#check if the states are successive and insert black frames, if the are not", "\n", "                ", "if", "old_state_index", "!=", "None", "and", "state_index", "!=", "old_state_index", "+", "1", "and", "state_index", "!=", "old_state_index", ":", "\n", "                    ", "for", "n", "in", "range", "(", "black_frame_number", ")", ":", "\n", "                        ", "video", ".", "write", "(", "black_frame", ")", "\n", "", "", "old_state_index", "=", "state_index", "\n", "\n", "i", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "image_folder", ",", "image", ")", ")", "\n", "if", "crop_images", ":", "\n", "                    ", "i", "=", "crop_image_button", "(", "i", ")", "\n", "", "i", "=", "cv2", ".", "resize", "(", "i", ",", "(", "width", ",", "height", ")", ")", "\n", "if", "crop_images", ":", "\n", "                    ", "i", "=", "add_black_pixels", "(", "i", ",", "pixels", "=", "black_pixels", ")", "\n", "", "to_write", "=", "True", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "print", "(", "'Try next image.'", ")", "\n", "continue", "\n", "", "if", "to_write", ":", "\n", "            ", "video", ".", "write", "(", "i", ")", "\n", "\n", "", "", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "video", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.natural_sort": [[189, 196], ["l.sort", "text.isdigit", "int", "convert", "re.split"], "function", ["None"], ["", "def", "natural_sort", "(", "l", ")", ":", "\n", "    ", "\"\"\" Sort the given list in natural sort (the way that humans expect).\n    \"\"\"", "\n", "convert", "=", "lambda", "text", ":", "int", "(", "text", ")", "if", "text", ".", "isdigit", "(", ")", "else", "text", "\n", "alphanum_key", "=", "lambda", "key", ":", "[", "convert", "(", "c", ")", "for", "c", "in", "re", ".", "split", "(", "'([0-9]+)'", ",", "key", ")", "]", "\n", "l", ".", "sort", "(", "key", "=", "alphanum_key", ")", "\n", "return", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.save_image": [[197, 208], ["matplotlib.imsave", "os.path.isdir", "os.makedirs", "os.rmdir"], "function", ["None"], ["", "def", "save_image", "(", "file_name", ",", "image", ")", ":", "\n", "    ", "\"\"\"\n    saves image under file_name and creates the directory if it does not exist yet\n    :param file_name:\n    :param image:\n    :return: nothing\n    \"\"\"", "\n", "if", "not", "(", "os", ".", "path", ".", "isdir", "(", "file_name", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "file_name", ")", "\n", "os", ".", "rmdir", "(", "file_name", ")", "\n", "", "plt", ".", "imsave", "(", "file_name", ",", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_layers.ArgmaxPositions.__init__": [[28, 43], ["super().__init__", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.__init__"], ["def", "__init__", "(", "self", ",", "stride", ",", "filter_size", ",", "layer_output", ",", "layer_weights", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        :param layer_output: the output of the layer to be analyzed\n        :param layer_weights: the weights of the layer to be analyzed\n        :param stride: the stride of the layer to be analyzed (has to be quadratic TODO make it free)\n        :param filter_size: the filter size of the layer to be analyzed (has to be quadratic TODO make it free)\n        '''", "\n", "super", "(", "ArgmaxPositions", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "filter_size", "=", "filter_size", "\n", "self", ".", "layer_output", "=", "layer_output", "\n", "self", ".", "layer_weights", "=", "layer_weights", "\n", "\n", "# reference value for later", "\n", "self", ".", "zero", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_layers.ArgmaxPositions.build": [[44, 46], ["super().build"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_layers.ArgmaxPositions.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "super", "(", "ArgmaxPositions", ",", "self", ")", ".", "build", "(", "input_shape", ")", "# Be sure to call this at the end", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_layers.ArgmaxPositions.update_relevance": [[47, 94], ["tensorflow.expand_dims", "tensorflow.unravel_index", "keras.one_hot", "keras.one_hot", "keras.reshape", "keras.reshape", "keras.layers.Flatten", "keras.layers.Flatten", "keras.layers.Flatten", "keras.layers.Flatten", "keras.layers.Flatten", "keras.layers.Flatten", "keras.layers.Flatten", "keras.layers.Flatten", "tensorflow.argmax", "tensorflow.reduce_prod"], "methods", ["None"], ["", "def", "update_relevance", "(", "self", ",", "relevance_index", ")", ":", "\n", "        ", "'''\n        finds the most contributing position for a given relevance value and propagates the relevance to this position\n        :param relevance_index: index of the relevance value to be analyzed\n        :return: a mask with only one non-zero entry (with value equal to the relevance value to be analyzed)\n                at the most contributing position. The mask has the same shape as the layer_output.\n        '''", "\n", "# get x and y range of the relevant part of the picture", "\n", "x_start", "=", "self", ".", "stride", "*", "relevance_index", "[", "1", "]", "\n", "x_end", "=", "self", ".", "stride", "*", "relevance_index", "[", "1", "]", "+", "self", ".", "filter_size", "\n", "y_start", "=", "self", ".", "stride", "*", "relevance_index", "[", "2", "]", "\n", "y_end", "=", "self", ".", "stride", "*", "relevance_index", "[", "2", "]", "+", "self", ".", "filter_size", "\n", "\n", "# getting correct input in the batch", "\n", "batch_input", "=", "self", ".", "layer_output", "[", "relevance_index", "[", "0", "]", "]", "\n", "\n", "# getting the part/window of the input which corresponds to the relevance value", "\n", "input_patch", "=", "batch_input", "[", "x_start", ":", "x_end", ",", "y_start", ":", "y_end", ",", ":", "]", "\n", "\n", "# getting the filter which corresponds to the relevance value", "\n", "weight", "=", "self", ".", "layer_weights", "[", ":", ",", ":", ",", ":", ",", "relevance_index", "[", "3", "]", "]", "\n", "\n", "# callculating pointwise product, which is also used during forward propagation", "\n", "product", "=", "input_patch", "*", "weight", "\n", "\n", "# Getting local position of the most contributing neuron in this window", "\n", "old_shape", "=", "product", ".", "shape", "\n", "product", "=", "keras", ".", "layers", ".", "Flatten", "(", ")", "(", "product", ")", "\n", "product", "=", "tf", ".", "expand_dims", "(", "product", ",", "axis", "=", "0", ")", "\n", "product", "=", "keras", ".", "layers", ".", "Flatten", "(", ")", "(", "product", ")", "\n", "position", "=", "tf", ".", "argmax", "(", "product", ",", "axis", "=", "-", "1", ")", "[", "0", "]", "\n", "position", "=", "tf", ".", "unravel_index", "(", "position", ",", "old_shape", ")", "\n", "\n", "# getting global version of the local position", "\n", "global_position", "=", "[", "position", "[", "0", "]", "+", "x_start", ",", "position", "[", "1", "]", "+", "y_start", ",", "position", "[", "2", "]", "]", "\n", "\n", "# ravel gloabl position, indexes are shifted since out.shape has an empty first dimension", "\n", "global_index", "=", "global_position", "[", "0", "]", "*", "self", ".", "layer_output", ".", "shape", "[", "-", "2", "]", "*", "self", ".", "layer_output", ".", "shape", "[", "-", "1", "]", "+", "global_position", "[", "1", "]", "*", "self", ".", "layer_output", ".", "shape", "[", "-", "1", "]", "+", "global_position", "[", "2", "]", "\n", "\n", "# generate one_hot mask with the relevance value at the global argamx position", "\n", "mask", "=", "K", ".", "one_hot", "(", "global_index", ",", "tf", ".", "reduce_prod", "(", "batch_input", ".", "shape", ")", ")", "\n", "relevance_value", "=", "self", ".", "relevance_values", "[", "0", ",", "relevance_index", "[", "1", "]", ",", "relevance_index", "[", "2", "]", ",", "relevance_index", "[", "3", "]", "]", "\n", "mask", "=", "mask", "*", "relevance_value", "\n", "mask", "=", "K", ".", "reshape", "(", "mask", ",", "batch_input", ".", "shape", ")", "\n", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_layers.ArgmaxPositions.call": [[95, 118], ["tensorflow.not_equal", "tensorflow.where", "tensorflow.map_fn", "tensorflow.reduce_sum", "keras.expand_dims", "keras.expand_dims"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "'''\n            Caluclates the relvance vlalues of the analyzed layer according to the argmax-rule.\n            Assumes no padding.\n            :param inputs: the relevance values of the layer succeeding the layer to be analyzed\n            :returns: an array containing the relvance vlalues of the analyzed layer according to the argmax-rule\n        '''", "\n", "# get all non-zero relevance values", "\n", "self", ".", "relevance_values", "=", "inputs", "\n", "where", "=", "tf", ".", "not_equal", "(", "inputs", ",", "self", ".", "zero", ")", "\n", "indices", "=", "tf", ".", "where", "(", "where", ")", "\n", "\n", "# generate a mask for each relevance value, which only has this relevance value as non-zero value", "\n", "# at the most contributing position", "\n", "relevance_masks", "=", "tf", ".", "map_fn", "(", "self", ".", "update_relevance", ",", "indices", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "#sum over all masks", "\n", "new_relevance_array", "=", "tf", ".", "reduce_sum", "(", "relevance_masks", ",", "axis", "=", "0", ")", "\n", "\n", "#this is needed for shaping reasons TODO innvestigate further", "\n", "new_relevance_array", "=", "K", ".", "expand_dims", "(", "new_relevance_array", ",", "axis", "=", "0", ")", "\n", "\n", "return", "new_relevance_array", "", "", "", ""]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.Tensorflow_to_Keras.load_Model_with_trained_variables": [[17, 73], ["tensorflow.reset_default_graph", "keras.layers.Input", "keras.models.Model", "keras.models.Model", "keras.models.Model", "tensorflow.Session", "joblib.load", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "os.path.expanduser", "keras.layers.Dense", "keras.layers.Dense", "layer.set_weights", "print", "print", "type", "print", "print", "str", "str", "str"], "function", ["None"], ["def", "load_Model_with_trained_variables", "(", "load_path", ")", ":", "\n", "# Load Checkpoint", "\n", "    ", "tf", ".", "reset_default_graph", "(", ")", "\n", "dictOfWeights", "=", "{", "}", ";", "dictOfBiases", "=", "{", "}", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "col", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "expanduser", "(", "load_path", ")", ")", "\n", "i", "=", "0", "\n", "for", "var", "in", "col", ":", "\n", "            ", "i", "=", "i", "+", "1", "\n", "if", "type", "(", "var", ")", "is", "np", ".", "ndarray", ":", "\n", "                ", "print", "(", "str", "(", "i", ")", "+", "\" \"", "+", "var", "+", "str", "(", "col", "[", "var", "]", ".", "shape", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "str", "(", "i", ")", "+", "\" \"", "+", "var", "+", "\" no ndarray\"", ")", "\n", "", "if", "\"target\"", "not", "in", "var", ":", "\n", "                ", "if", "\"weights\"", "in", "var", ":", "\n", "                    ", "dictOfWeights", "[", "var", "]", "=", "col", "[", "var", "]", "\n", "", "if", "\"biases\"", "in", "var", ":", "\n", "                    ", "dictOfBiases", "[", "var", "]", "=", "col", "[", "var", "]", "\n", "", "", "pass", "\n", "\n", "# Keras Model", "\n", "", "", "hidden", "=", "256", "\n", "ThirdLastBiases", "=", "dictOfBiases", "[", "'deepq/q_func/action_value/fully_connected_1/biases:0'", "]", "\n", "num_actions", "=", "ThirdLastBiases", ".", "size", "\n", "dueling", "=", "True", "\n", "inputs", "=", "Input", "(", "shape", "=", "(", "84", ",", "84", ",", "4", ")", ")", "\n", "# ConvLayer", "\n", "x", "=", "Conv2D", "(", "32", ",", "(", "8", ",", "8", ")", ",", "strides", "=", "(", "4", ",", "4", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'SAME'", ",", "name", "=", "'deepq/q_func/convnet/Conv'", ")", "(", "inputs", ")", "\n", "x1", "=", "Conv2D", "(", "64", ",", "(", "4", ",", "4", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'SAME'", ",", "name", "=", "'deepq/q_func/convnet/Conv_1'", ")", "(", "x", ")", "\n", "x2", "=", "Conv2D", "(", "64", ",", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'SAME'", ",", "name", "=", "'deepq/q_func/convnet/Conv_2'", ")", "(", "x1", ")", "\n", "conv_out", "=", "Flatten", "(", ")", "(", "x2", ")", "\n", "# Action values", "\n", "action_out", "=", "conv_out", "\n", "action_out", "=", "Dense", "(", "hidden", ",", "activation", "=", "'relu'", ",", "name", "=", "'deepq/q_func/action_value/fully_connected'", ")", "(", "action_out", ")", "\n", "action_scores", "=", "Dense", "(", "num_actions", ",", "name", "=", "'deepq/q_func/action_value/fully_connected_1'", ",", "activation", "=", "'linear'", ")", "(", "action_out", ")", "# num_actions in {4, .., 18}", "\n", "# State values", "\n", "if", "dueling", ":", "\n", "        ", "state_out", "=", "conv_out", "\n", "state_out", "=", "Dense", "(", "hidden", ",", "activation", "=", "'relu'", ",", "name", "=", "'deepq/q_func/state_value/fully_connected'", ")", "(", "state_out", ")", "\n", "state_score", "=", "Dense", "(", "1", ",", "name", "=", "'deepq/q_func/state_value/fully_connected_1'", ")", "(", "state_out", ")", "\n", "# Finish model", "\n", "", "model", "=", "Model", "(", "inputs", ",", "[", "action_scores", ",", "state_score", "]", ")", "\n", "modelActionPart", "=", "Model", "(", "inputs", ",", "action_scores", ")", "\n", "modelStatePart", "=", "Model", "(", "inputs", ",", "state_score", ")", "\n", "\n", "# Load weights", "\n", "for", "layer", "in", "model", ".", "layers", ":", "\n", "        ", "if", "layer", ".", "name", "+", "\"/weights:0\"", "in", "dictOfWeights", ":", "\n", "            ", "newWeights", "=", "dictOfWeights", "[", "layer", ".", "name", "+", "\"/weights:0\"", "]", "\n", "newBiases", "=", "dictOfBiases", "[", "layer", ".", "name", "+", "\"/biases:0\"", "]", "\n", "# set_weights(list of ndarrays with 2 elements: 0->weights 1->biases)", "\n", "layer", ".", "set_weights", "(", "[", "newWeights", ",", "newBiases", "]", ")", "\n", "print", "(", "\"Found and applied values for layer \"", "+", "layer", ".", "name", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"No corresponding layer found for\"", "+", "layer", ".", "name", ")", "\n", "", "", "return", "model", ",", "modelStatePart", ",", "modelActionPart", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.__init__": [[11, 18], ["numpy.zeros", "numpy.stack"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "self", ".", "env", "=", "env", "\n", "self", ".", "width", "=", "84", "\n", "self", ".", "height", "=", "84", "\n", "self", ".", "zeros", "=", "np", ".", "zeros", "(", "(", "self", ".", "width", ",", "self", ".", "height", ")", ")", "\n", "self", ".", "stacked_frame", "=", "np", ".", "stack", "(", "(", "self", ".", "zeros", ",", "self", ".", "zeros", ",", "self", ".", "zeros", ",", "self", ".", "zeros", ")", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "noop_action", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.preprocess_frame": [[19, 29], ["cv2.cvtColor", "cv2.resize"], "methods", ["None"], ["", "def", "preprocess_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "''' preprocessing according to openai's atari_wrappers.WrapFrame\n            also applys scaling between 0 and 1 which is done in tensorflow in baselines\n        :param frame: the input frame\n        :return: rescaled and greyscaled frame\n        '''", "\n", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "frame", "=", "cv2", ".", "resize", "(", "frame", ",", "(", "self", ".", "width", ",", "self", ".", "height", ")", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", ")", "\n", "frame", "=", "frame", "/", "255", "\n", "return", "frame", "[", ":", ",", ":", ",", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.update_stacked_frame": [[30, 41], ["range", "custom_atari_wrapper.atari_wrapper.preprocess_frame", "numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.preprocess_frame"], ["", "def", "update_stacked_frame", "(", "self", ",", "new_frame", ")", ":", "\n", "        ", "''' adds the new_frame to the stack of 4 frames, while shifting each other frame one to the left\n        :param new_frame:\n        :return: the new stacked frame\n        '''", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "self", ".", "stacked_frame", "[", ":", ",", ":", ",", "i", "]", "=", "self", ".", "stacked_frame", "[", ":", ",", ":", ",", "i", "+", "1", "]", "\n", "", "new_frame", "=", "self", ".", "preprocess_frame", "(", "new_frame", ")", "\n", "new_frame", "=", "np", ".", "squeeze", "(", "new_frame", ")", "\n", "self", ".", "stacked_frame", "[", ":", ",", ":", ",", "3", "]", "=", "new_frame", "\n", "return", "self", ".", "stacked_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.step": [[42, 49], ["custom_atari_wrapper.atari_wrapper.repeat_frames", "custom_atari_wrapper.atari_wrapper.update_stacked_frame", "custom_atari_wrapper.atari_wrapper.reset"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.repeat_frames", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.update_stacked_frame", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.reset"], ["", "def", "step", "(", "self", ",", "action", ",", "skip_frames", "=", "4", ")", ":", "\n", "        ", "max_frame", ",", "stacked_observations", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "repeat_frames", "(", "action", ",", "skip_frames", "=", "skip_frames", ")", "\n", "stacked_frames", "=", "self", ".", "update_stacked_frame", "(", "max_frame", ")", "\n", "#reset the environment if the game ended", "\n", "if", "done", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "stacked_frames", ",", "stacked_observations", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.repeat_frames": [[50, 71], ["numpy.zeros", "range", "numpy.zeros.max", "custom_atari_wrapper.atari_wrapper.env.step", "stacked_observations.append"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.step"], ["", "def", "repeat_frames", "(", "self", ",", "action", ",", "skip_frames", "=", "4", ")", ":", "\n", "        ", "''' skip frames to be inline with baselines DQN. stops when the current game is done\n        :param action: the choosen action which will be repeated\n        :param skip_frames: the number of frames to skip\n        :return max frame: the frame used by the agent\n        :return stacked_observations: all skipped observations '''", "\n", "stacked_observations", "=", "[", "]", "\n", "#TODO dirty numbers", "\n", "obs_buffer", "=", "np", ".", "zeros", "(", "(", "2", ",", "210", ",", "160", ",", "3", ")", ",", "dtype", "=", "'uint8'", ")", "\n", "total_reward", "=", "0", "\n", "for", "i", "in", "range", "(", "skip_frames", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "total_reward", "+=", "reward", "\n", "if", "i", "==", "skip_frames", "-", "2", ":", "obs_buffer", "[", "0", "]", "=", "observation", "\n", "if", "i", "==", "skip_frames", "-", "1", ":", "obs_buffer", "[", "1", "]", "=", "observation", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "", "stacked_observations", ".", "append", "(", "observation", ")", "\n", "\n", "", "max_frame", "=", "obs_buffer", ".", "max", "(", "axis", "=", "0", ")", "\n", "return", "max_frame", ",", "stacked_observations", ",", "total_reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.reset": [[72, 88], ["custom_atari_wrapper.atari_wrapper.env.reset", "range", "numpy.random.randint", "print", "range", "custom_atari_wrapper.atari_wrapper.env.step", "custom_atari_wrapper.atari_wrapper.env.step", "custom_atari_wrapper.atari_wrapper.env.reset", "custom_atari_wrapper.atari_wrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.reset", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.step", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.step", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.reset", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.reset"], ["", "def", "reset", "(", "self", ",", "noop_max", "=", "30", ")", ":", "\n", "        ", "\"\"\" Do no-op action for a number of steps in [1, noop_max], to achieve random game starts.\n        We also do no-op for 250 steps because Pacman cant do anything at the beginning of the game (number found empirically)\n        \"\"\"", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "250", ")", ":", "\n", "            ", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "self", ".", "noop_action", ")", "\n", "if", "done", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "", "", "noops", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "noop_max", "+", "1", ")", "\n", "print", "(", "\"number noops:\"", ",", "noops", ")", "\n", "for", "_", "in", "range", "(", "noops", ")", ":", "\n", "            ", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "self", ".", "noop_action", ")", "\n", "if", "done", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.fixed_reset": [[89, 103], ["custom_atari_wrapper.atari_wrapper.env.reset", "range", "custom_atari_wrapper.atari_wrapper.env.step", "custom_atari_wrapper.atari_wrapper.env.render", "custom_atari_wrapper.atari_wrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.reset", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.step", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.custom_atari_wrapper.atari_wrapper.reset"], ["", "def", "fixed_reset", "(", "self", ",", "step_number", ",", "action", ")", ":", "\n", "        ", "'''\n        Create a fixed starting position for the environment by doing *action* for *step_number* steps\n        :param step_number: number of steps to be done at the beginning of the game\n        :param action: action to be done at the start of the game\n        :return: obs at the end of the starting sequence\n        '''", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "step_number", ")", ":", "\n", "            ", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "env", ".", "render", "(", ")", "\n", "if", "done", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "", "", "return", "obs", "", "", "", ""]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.save_frame": [[25, 30], ["matplotlib.imsave", "os.path.isdir", "os.makedirs", "os.rmdir", "str"], "function", ["None"], ["def", "save_frame", "(", "array", ",", "save_file", ",", "frame", ")", ":", "\n", "    ", "if", "not", "(", "os", ".", "path", ".", "isdir", "(", "save_file", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_file", ")", "\n", "os", ".", "rmdir", "(", "save_file", ")", "\n", "", "plt", ".", "imsave", "(", "save_file", "+", "'_'", "+", "str", "(", "frame", ")", "+", "'.png'", ",", "array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.save_array": [[31, 36], ["numpy.save", "os.path.isdir", "os.makedirs", "os.rmdir", "str"], "function", ["None"], ["", "def", "save_array", "(", "array", ",", "save_file", ",", "frame", ")", ":", "\n", "    ", "if", "not", "(", "os", ".", "path", ".", "isdir", "(", "save_file", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_file", ")", "\n", "os", ".", "rmdir", "(", "save_file", ")", "\n", "", "np", ".", "save", "(", "save_file", "+", "'_'", "+", "str", "(", "frame", ")", "+", "'.npy'", ",", "array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.save_q_values": [[37, 44], ["os.path.isdir", "os.makedirs", "os.rmdir", "open", "text_file.write", "str", "str"], "function", ["None"], ["", "def", "save_q_values", "(", "array", ",", "save_file", ",", "frame", ")", ":", "\n", "    ", "if", "not", "(", "os", ".", "path", ".", "isdir", "(", "save_file", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_file", ")", "\n", "os", ".", "rmdir", "(", "save_file", ")", "\n", "", "save_file", "=", "save_file", "+", "'_'", "+", "str", "(", "frame", ")", "+", "'.txt'", "\n", "with", "open", "(", "save_file", ",", "\"w\"", ")", "as", "text_file", ":", "\n", "        ", "text_file", ".", "write", "(", "str", "(", "array", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.save_raw_data": [[45, 57], ["stream_generator.save_array", "numpy.squeeze", "numpy.hstack", "stream_generator.save_frame"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.save_array", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.save_frame"], ["", "", "def", "save_raw_data", "(", "array", ",", "save_file", ",", "frame", ")", ":", "\n", "    ", "'''\n    saves a raw state or saliency map as array and as image\n    :param array: array to be saved\n    :param save_file: file path were the data should be saved\n    :param frame: the frame index of the file\n    :return: None\n    '''", "\n", "save_array", "(", "array", ",", "save_file", ",", "frame", ")", "\n", "image", "=", "np", ".", "squeeze", "(", "array", ")", "\n", "image", "=", "np", ".", "hstack", "(", "(", "image", "[", ":", ",", ":", ",", "0", "]", ",", "image", "[", ":", ",", ":", ",", "1", "]", ",", "image", "[", ":", ",", ":", ",", "2", "]", ",", "image", "[", ":", ",", ":", ",", "3", "]", ")", ")", "\n", "save_frame", "(", "image", ",", "save_file", ",", "frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.get_feature_vector": [[58, 70], ["keras.backend.function", "numpy.squeeze", "keras.backend.function."], "function", ["None"], ["", "def", "get_feature_vector", "(", "model", ",", "input", ")", ":", "\n", "    ", "'''\n    returns the output of the second to last layer, which act similar to a feature vector for the DQN-network\n    :param model: the model used for prediction\n    :param input: the input for the prediction\n    :return:\n    '''", "\n", "helper_func", "=", "keras", ".", "backend", ".", "function", "(", "[", "model", ".", "layers", "[", "0", "]", ".", "input", "]", ",", "\n", "[", "model", ".", "layers", "[", "-", "2", "]", ".", "output", "]", ")", "\n", "features", "=", "helper_func", "(", "[", "input", "]", ")", "[", "0", "]", "\n", "features", "=", "np", ".", "squeeze", "(", "features", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.overlay_stream.interpolate": [[12, 22], ["None"], "function", ["None"], ["def", "interpolate", "(", "array1", ",", "array2", ",", "t", ")", ":", "\n", "    ", "'''\n    linear interpolation between two frames of a state\n    :param array1: starting array\n    :param array2: end array\n    :param t: time parameter, goes from -1 to 3 ( 0=0.25, 3=1 in the normal interpolation formula)\n    :return: the interpolated array\n    '''", "\n", "t", "=", "(", "t", "*", "0.25", ")", "+", "0.25", "\n", "return", "(", "array2", "*", "t", ")", "+", "(", "array1", "*", "(", "1", "-", "t", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.overlay_stream.overlay_stream": [[24, 77], ["image_utils.natural_sort", "os.path.isdir", "os.makedirs", "os.listdir", "image.split", "int", "int", "cv2.imread", "cv2.cvtColor", "image_utils.save_image", "numpy.load", "image_utils.normalise_image", "image_utils.output_saliency_map", "stream_generator.save_frame", "image_str[].replace", "os.path.join", "numpy.maximum", "os.path.join", "interpolate.sum", "print", "numpy.zeros", "overlay_stream.interpolate", "str", "print", "print", "str", "str"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.natural_sort", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.save_image", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.normalise_image", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.output_saliency_map", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.stream_generator.save_frame", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.overlay_stream.interpolate"], ["", "def", "overlay_stream", "(", "stream_directory", ")", ":", "\n", "    ", "'''\n    overlays all screens in the stream_directory\n    :param stream_directory: see above\n    :return: nothing\n    '''", "\n", "stream_folder", "=", "stream_directory", "\n", "image_folder", "=", "stream_folder", "+", "\"/screen\"", "\n", "raw_argmax_base", "=", "stream_folder", "+", "\"/raw_argmax/raw_argmax\"", "\n", "save_folder", "=", "stream_folder", "+", "\"/argmax_smooth\"", "\n", "save_folder2", "=", "stream_folder", "+", "\"/screen_smooth\"", "\n", "if", "not", "(", "os", ".", "path", ".", "isdir", "(", "save_folder2", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_folder2", ")", "\n", "\n", "", "images", "=", "[", "img", "for", "img", "in", "os", ".", "listdir", "(", "image_folder", ")", "]", "\n", "images", "=", "image_utils", ".", "natural_sort", "(", "images", ")", "\n", "\n", "old_saliency_map", "=", "None", "\n", "old_image", "=", "None", "\n", "for", "image", "in", "images", ":", "\n", "        ", "try", ":", "\n", "            ", "image_str", "=", "image", ".", "split", "(", "'_'", ")", "\n", "state_index", "=", "int", "(", "image_str", "[", "1", "]", ")", "\n", "frame_index", "=", "int", "(", "image_str", "[", "2", "]", ".", "replace", "(", "\".png\"", ",", "\"\"", ")", ")", "\n", "\n", "i", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "image_folder", ",", "image", ")", ")", "\n", "i", "=", "cv2", ".", "cvtColor", "(", "i", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "if", "old_image", "is", "not", "None", ":", "\n", "                ", "smooth_i", "=", "np", ".", "maximum", "(", "old_image", ",", "i", ")", "\n", "old_image", "=", "i", "\n", "i", "=", "smooth_i", "\n", "", "else", ":", "\n", "                ", "old_image", "=", "i", "\n", "\n", "", "image_utils", ".", "save_image", "(", "os", ".", "path", ".", "join", "(", "save_folder2", ",", "image", ")", ",", "i", ")", "\n", "\n", "saliency_filename", "=", "raw_argmax_base", "+", "\"_\"", "+", "str", "(", "state_index", ")", "+", "\".npy\"", "\n", "saliency_map", "=", "np", ".", "load", "(", "saliency_filename", ")", "\n", "saliency_map", "=", "image_utils", ".", "normalise_image", "(", "saliency_map", ")", "\n", "if", "saliency_map", ".", "sum", "(", ")", ">", "0.9", "*", "saliency_map", ".", "shape", "[", "0", "]", "*", "saliency_map", ".", "shape", "[", "1", "]", "*", "saliency_map", ".", "shape", "[", "2", "]", ":", "\n", "                ", "print", "(", "state_index", ")", "\n", "saliency_map", "=", "np", ".", "zeros", "(", "saliency_map", ".", "shape", ")", "\n", "", "if", "old_saliency_map", "is", "not", "None", ":", "\n", "                ", "saliency_map", "=", "interpolate", "(", "old_saliency_map", ",", "saliency_map", ",", "frame_index", ")", "\n", "", "saliency", "=", "image_utils", ".", "output_saliency_map", "(", "saliency_map", "[", ":", ",", ":", ",", "3", "]", ",", "i", ",", "edges", "=", "False", ")", "\n", "index", "=", "str", "(", "state_index", ")", "+", "'_'", "+", "str", "(", "frame_index", ")", "\n", "stream_generator", ".", "save_frame", "(", "saliency", ",", "save_folder", "+", "\"/argmax\"", ",", "index", ")", "\n", "if", "frame_index", "==", "3", ":", "\n", "                ", "old_saliency_map", "=", "saliency_map", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "print", "(", "'Try next image.'", ")", "\n", "continue", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time": [[21, 27], ["data_frame.rename.columns.get_loc", "data_frame.rename.rename"], "function", ["None"], ["def", "rename_time", "(", "data_frame", ",", "successive_name", ",", "new_name", ")", ":", "\n", "    ", "index", "=", "data_frame", ".", "columns", ".", "get_loc", "(", "successive_name", ")", "\n", "index", "-=", "1", "\n", "old_column_name", "=", "data_frame", ".", "columns", "[", "index", "]", "\n", "data_frame", "=", "data_frame", ".", "rename", "(", "columns", "=", "{", "old_column_name", ":", "new_name", "}", ",", "errors", "=", "\"raise\"", ")", "\n", "return", "data_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_times": [[29, 38], ["result_fusion.rename_time", "result_fusion.rename_time", "result_fusion.rename_time", "result_fusion.rename_time", "result_fusion.rename_time", "result_fusion.rename_time", "result_fusion.rename_time"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.rename_time"], ["", "def", "rename_times", "(", "data_frame", ")", ":", "\n", "    ", "data_frame", "=", "rename_time", "(", "data_frame", ",", "'ageTime'", ",", "'demographicsTime'", ")", "\n", "data_frame", "=", "rename_time", "(", "data_frame", ",", "'retrospectionVideo1Time'", ",", "'retro1Time'", ")", "\n", "data_frame", "=", "rename_time", "(", "data_frame", ",", "'retrospectionVideo2Time'", ",", "'retro2Time'", ")", "\n", "data_frame", "=", "rename_time", "(", "data_frame", ",", "'retrospectionVideo3Time'", ",", "'retro3Time'", ")", "\n", "data_frame", "=", "rename_time", "(", "data_frame", ",", "'trustDescription1Time'", ",", "'trust1Time'", ")", "\n", "data_frame", "=", "rename_time", "(", "data_frame", ",", "'trustDescription2Time'", ",", "'trust2Time'", ")", "\n", "data_frame", "=", "rename_time", "(", "data_frame", ",", "'trustDescription3Time'", ",", "'trust3Time'", ")", "\n", "return", "data_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.delete_times": [[40, 55], ["range", "data.drop.drop", "data.drop.columns.get_loc", "len", "to_delete.append"], "function", ["None"], ["", "def", "delete_times", "(", "data", ",", "keep_time_columns", "=", "keep_time_colums", ")", ":", "\n", "    ", "\"\"\"\n    Deletes all time columns form the given dataframe that are not in *keep_time_columns*\n    :param data: the dataframe where the time columns should be deleted\n    :param keep_time_columns: the time columns to be kept\n    :return: the dataframe without unnecessary time columns\n    \"\"\"", "\n", "start_index", "=", "data", ".", "columns", ".", "get_loc", "(", "'interviewtime'", ")", "+", "1", "\n", "to_delete", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "start_index", ",", "len", "(", "data", ".", "columns", ")", ")", ":", "\n", "        ", "column_name", "=", "data", ".", "columns", "[", "i", "]", "\n", "if", "column_name", "not", "in", "keep_time_columns", ":", "\n", "            ", "to_delete", ".", "append", "(", "column_name", ")", "\n", "", "", "data", "=", "data", ".", "drop", "(", "to_delete", ",", "axis", "=", "1", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.eval_retrospection": [[57, 136], ["data_frame[].tolist", "data_frame[].tolist", "data_frame[].tolist", "data_frame[].tolist", "data_frame[].tolist", "data_frame[].tolist", "len", "range", "range", "points.append", "goals.append", "result_fusion.eval_retrospection.calculate_points"], "function", ["None"], ["", "def", "eval_retrospection", "(", "data_frame", ",", "number", ")", ":", "\n", "    ", "\"\"\"\n    Simple first evaluation of the object selection during the retrospection task.\n    Calculates and defines the score of this task and checks if the participants got the agent specific goals.\n    :param data_frame: the dataframe containing the survey results\n    :param number: the number of the agent (1 = power pill,2 = normal or 3 = fear ghost)\n    :return: the same data frame with two additional columns for the score and a binary value showing whether the\n     participants got the agent specific goal.\n    \"\"\"", "\n", "def", "get_name", "(", "index", ")", ":", "\n", "        ", "return", "'retrospection'", "+", "str", "(", "number", ")", "+", "'['", "+", "str", "(", "index", ")", "+", "']'", "\n", "", "pacman", "=", "data_frame", "[", "get_name", "(", "1", ")", "]", ".", "tolist", "(", ")", "\n", "normal_pill", "=", "data_frame", "[", "get_name", "(", "2", ")", "]", ".", "tolist", "(", ")", "\n", "power_pill", "=", "data_frame", "[", "get_name", "(", "3", ")", "]", ".", "tolist", "(", ")", "\n", "ghost", "=", "data_frame", "[", "get_name", "(", "4", ")", "]", ".", "tolist", "(", ")", "\n", "blue_ghost", "=", "data_frame", "[", "get_name", "(", "5", ")", "]", ".", "tolist", "(", ")", "\n", "cherry", "=", "data_frame", "[", "get_name", "(", "6", ")", "]", ".", "tolist", "(", ")", "\n", "\n", "length", "=", "len", "(", "pacman", ")", "\n", "\n", "# define score calculation", "\n", "def", "calculate_points", "(", "index", ")", ":", "\n", "        ", "i", "=", "index", "\n", "# check if they selected to many items", "\n", "if", "pacman", "[", "i", "]", "+", "normal_pill", "[", "i", "]", "+", "power_pill", "[", "i", "]", "+", "ghost", "[", "i", "]", "+", "blue_ghost", "[", "i", "]", "+", "cherry", "[", "i", "]", ">", "3", ":", "\n", "            ", "points", "=", "0", "\n", "# here the score's per object and task are defined and added together", "\n", "", "else", ":", "\n", "# power pill agent", "\n", "            ", "if", "number", "==", "1", ":", "\n", "                ", "points", "=", "pacman", "[", "i", "]", "+", "normal_pill", "[", "i", "]", "*", "-", "1", "+", "power_pill", "[", "i", "]", "+", "ghost", "[", "i", "]", "*", "-", "1", "+", "blue_ghost", "[", "i", "]", "*", "-", "1", "+", "cherry", "[", "i", "]", "*", "-", "1", "\n", "# normal agent", "\n", "", "elif", "number", "==", "2", ":", "\n", "                ", "points", "=", "pacman", "[", "i", "]", "+", "normal_pill", "[", "i", "]", "*", "-", "0.5", "+", "power_pill", "[", "i", "]", "*", "-", "0.5", "+", "ghost", "[", "i", "]", "*", "-", "0.5", "+", "blue_ghost", "[", "i", "]", "*", "1", "+", "cherry", "[", "i", "]", "*", "-", "0.5", "\n", "# agent afraid of ghosts", "\n", "", "elif", "number", "==", "3", ":", "\n", "                ", "points", "=", "pacman", "[", "i", "]", "+", "normal_pill", "[", "i", "]", "*", "-", "0.5", "+", "power_pill", "[", "i", "]", "*", "-", "0.5", "+", "ghost", "[", "i", "]", "*", "1", "+", "blue_ghost", "[", "i", "]", "*", "1", "+", "cherry", "[", "i", "]", "*", "-", "0.5", "\n", "", "else", ":", "\n", "                ", "print", "(", "'number'", ",", "number", ",", "'not implemented'", ")", "\n", "points", "=", "'Nan'", "\n", "", "", "return", "points", "\n", "\n", "", "points", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "length", ")", ":", "\n", "        ", "points", ".", "append", "(", "calculate_points", "(", "j", ")", ")", "\n", "\n", "", "column_name", "=", "'retrospection'", "+", "str", "(", "number", ")", "+", "'Points'", "\n", "data_frame", "[", "column_name", "]", "=", "points", "\n", "\n", "\n", "# check if the participant got the agent specific goal", "\n", "def", "got_goal", "(", "index", ",", "number", ")", ":", "\n", "        ", "i", "=", "index", "\n", "# check if the participant i selected to many items", "\n", "if", "pacman", "[", "i", "]", "+", "normal_pill", "[", "i", "]", "+", "power_pill", "[", "i", "]", "+", "ghost", "[", "i", "]", "+", "blue_ghost", "[", "i", "]", "+", "cherry", "[", "i", "]", ">", "3", ":", "\n", "            ", "points", "=", "0", "\n", "", "else", ":", "\n", "# power pill agent", "\n", "            ", "if", "number", "==", "1", ":", "\n", "                ", "points", "=", "power_pill", "[", "i", "]", "\n", "# normal agent", "\n", "", "elif", "number", "==", "2", ":", "\n", "                ", "points", "=", "blue_ghost", "[", "i", "]", "\n", "# agent afraid of ghosts", "\n", "", "elif", "number", "==", "3", ":", "\n", "                ", "points", "=", "ghost", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "'number'", ",", "number", ",", "'not implemented'", ")", "\n", "\n", "", "", "return", "points", "\n", "\n", "", "goals", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "length", ")", ":", "\n", "        ", "goals", ".", "append", "(", "got_goal", "(", "j", ",", "number", ")", ")", "\n", "\n", "", "column_name", "=", "'retrospection'", "+", "str", "(", "number", ")", "+", "'Goal'", "\n", "data_frame", "[", "column_name", "]", "=", "goals", "\n", "\n", "return", "data_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.result_fusion.eval_trust": [[138, 162], ["str", "correct_answer_arr.append", "str"], "function", ["None"], ["", "def", "eval_trust", "(", "data_frame", ",", "agent_number", ")", ":", "\n", "    ", "\"\"\"\n    simple first evaluation of the trust task that checks wheter the participants got the correct agent\n    :param data_frame: the dataframe containing the survey results\n    :param agent_number: the number of the comparison (1,2 or 3)\n    :return: the same data_frame but with an added binary column 'trust' + *agent_number* + 'correct' storing whether\n    the participants where correct.\n    \"\"\"", "\n", "# the correct answer for each comparison", "\n", "correct_answers_dict", "=", "{", "1", ":", "2", ",", "2", ":", "1", ",", "3", ":", "1", "}", "\n", "column_name", "=", "'trustBool'", "+", "str", "(", "agent_number", ")", "\n", "resulting_column_name", "=", "'trust'", "+", "str", "(", "agent_number", ")", "+", "'correct'", "\n", "correct_answer_arr", "=", "[", "]", "\n", "answer_arr", "=", "data_frame", "[", "column_name", "]", "\n", "for", "entry", "in", "answer_arr", ":", "\n", "        ", "if", "entry", "==", "correct_answers_dict", "[", "agent_number", "]", ":", "\n", "            ", "correct", "=", "1", ";", "\n", "", "else", ":", "\n", "            ", "correct", "=", "0", ";", "\n", "", "correct_answer_arr", ".", "append", "(", "correct", ")", "\n", "\n", "", "data_frame", "[", "resulting_column_name", "]", "=", "correct_answer_arr", "\n", "\n", "return", "data_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation_demographic.analyze_demographic": [[11, 18], ["Survey_results.evaluation.analyze_distribution"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.analyze_distribution"], ["def", "analyze_demographic", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n    Helper function that inserts the AI experience columns into analyze distribution.\n    \"\"\"", "\n", "ax", "=", "analyze_distribution", "(", "data", ",", "[", "'experienceAI2[1]'", ",", "'experienceAI2[2]'", ",", "'experienceAI2[3]'", ",", "'experienceAI2[4]'", ",", "\n", "'experienceAI2[5]'", "]", ")", "\n", "return", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.mann_whitney": [[16, 38], ["print", "print", "Survey_results.evaluation.mean_and_CI", "print", "Survey_results.evaluation.mean_and_CI", "print", "print", "print", "p_vals.append", "scipy.mannwhitneyu", "Survey_results.evaluation.rank_biserial_effect_size", "scipy.mannwhitneyu"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.rank_biserial_effect_size"], ["def", "mann_whitney", "(", "data", ",", "column_name", ")", ":", "\n", "    ", "''' doing the mann whitney test for the dependant variable in the given column\n        Same es the one in evaluation but we only test H vs HS\n    '''", "\n", "data_highlights", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "2", "]", "\n", "data_highlightsLRP", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "4", "]", "\n", "\n", "highlights_values", "=", "data_highlights", "[", "column_name", "]", ".", "values", "\n", "highlightsLRP_values", "=", "data_highlightsLRP", "[", "column_name", "]", ".", "values", "\n", "\n", "print", "(", "'##### testing the column:'", ",", "column_name", ",", "'#####'", ")", "\n", "\n", "print", "(", "'CI highlights:'", ")", "\n", "mean_and_CI", "(", "highlights_values", ")", "\n", "print", "(", "'CI highlights LRP:'", ")", "\n", "mean_and_CI", "(", "highlightsLRP_values", ")", "\n", "\n", "p_vals", "=", "[", "]", "\n", "print", "(", "'highlights < highlightsLRP'", ")", "\n", "print", "(", "stats", ".", "mannwhitneyu", "(", "highlights_values", ",", "highlightsLRP_values", ",", "alternative", "=", "'less'", ")", ")", "\n", "print", "(", "rank_biserial_effect_size", "(", "highlights_values", ",", "highlightsLRP_values", ")", ")", "\n", "p_vals", ".", "append", "(", "stats", ".", "mannwhitneyu", "(", "highlights_values", ",", "highlightsLRP_values", ",", "alternative", "=", "'less'", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.mean_analysis": [[40, 63], ["print", "print", "Survey_results.evaluation.mean_and_CI", "print", "Survey_results.evaluation.mean_and_CI", "print", "Survey_results.evaluation.mean_and_CI", "print", "Survey_results.evaluation.mean_and_CI"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI"], ["", "def", "mean_analysis", "(", "data", ",", "column_name", ")", ":", "\n", "    ", "''' calculating mean and CI for the dependant variable in the given column\n    '''", "\n", "data_random", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "1", "]", "\n", "data_randomLRP", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "3", "]", "\n", "data_highlights", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "2", "]", "\n", "data_highlightsLRP", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "4", "]", "\n", "\n", "random_values", "=", "data_random", "[", "column_name", "]", ".", "values", "\n", "randomLRP_values", "=", "data_randomLRP", "[", "column_name", "]", ".", "values", "\n", "highlights_values", "=", "data_highlights", "[", "column_name", "]", ".", "values", "\n", "highlightsLRP_values", "=", "data_highlightsLRP", "[", "column_name", "]", ".", "values", "\n", "\n", "print", "(", "'##### testing the column:'", ",", "column_name", ",", "'#####'", ")", "\n", "\n", "print", "(", "'CI random:'", ")", "\n", "mean_and_CI", "(", "random_values", ")", "\n", "print", "(", "'CI random_LRP:'", ")", "\n", "mean_and_CI", "(", "randomLRP_values", ")", "\n", "print", "(", "'CI highlights:'", ")", "\n", "mean_and_CI", "(", "highlights_values", ")", "\n", "print", "(", "'CI highlights LRP:'", ")", "\n", "mean_and_CI", "(", "highlightsLRP_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.read_text_data": [[65, 75], ["pandas.read_csv"], "function", ["None"], ["", "def", "read_text_data", "(", "file_name", ")", ":", "\n", "    ", "'''\n    reads the data frame that contains the categorized textuals answers\n    :param file_name: csv file, expects sepration by ';'\n    :return: the data frame and an array with the participants' seeds\n    '''", "\n", "text_data", "=", "pd", ".", "read_csv", "(", "file_name", ",", "sep", "=", "';'", ")", "\n", "concepts", "=", "text_data", "[", "'SESSION ID: SEED'", "]", ".", "values", "\n", "\n", "return", "text_data", ",", "concepts", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.get_grouped_df": [[77, 128], ["evaluate_text.read_text_data", "groups.keys", "pandas.DataFrame", "groups.keys", "new_randnumbers.append", "new_seeds.append", "numpy.where", "groups.keys", "evaluate_text.check_group", "new_groups[].append", "print", "str"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.read_text_data", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.check_group"], ["", "def", "get_grouped_df", "(", "categories_df", ",", "data", ",", "groups", ")", ":", "\n", "    ", "'''\n    generates a data frame that encodes for each group if the participants answer contained a category that belongs to\n    this group\n    :param categories_df: csv file with the categories identified by the coder, ecpects seperation by ';'\n    :param data: the survey results as exported from LimeSurvey\n    :param groups: a dictionary that defnies how the categories should be grouped\n    :return: the resulting data frame, the first column contains the participants seed, the other columns encode\n     , for each group, if it was part of the participants answer\n    '''", "\n", "text_data", ",", "concepts", "=", "read_text_data", "(", "categories_df", ")", "\n", "\n", "seeds", "=", "data", "[", "'seed'", "]", "\n", "randnumbers", "=", "data", "[", "'randnumber'", "]", "\n", "new_randnumbers", "=", "[", "]", "\n", "new_seeds", "=", "[", "]", "\n", "\n", "# create empty lists to fill the dataframe later", "\n", "new_groups", "=", "{", "}", "\n", "for", "key", "in", "groups", ".", "keys", "(", ")", ":", "\n", "        ", "new_groups", "[", "key", "]", "=", "[", "]", "\n", "\n", "", "for", "idx", "in", "data", ".", "index", ".", "values", ":", "\n", "# getting the condition number", "\n", "        ", "randnumber", "=", "randnumbers", "[", "idx", "]", "\n", "new_randnumbers", ".", "append", "(", "randnumber", ")", "\n", "\n", "# unique seed of the participant", "\n", "seed", "=", "seeds", "[", "idx", "]", "\n", "new_seeds", ".", "append", "(", "seed", ")", "\n", "\n", "# get indices of concepts included in the participants answer", "\n", "try", ":", "\n", "            ", "test", "=", "text_data", "[", "str", "(", "seed", ")", "]", ".", "values", "\n", "", "except", ":", "\n", "            ", "print", "(", "'seed'", ",", "seed", ",", "'not found'", ")", "\n", "pass", "\n", "", "categories", "=", "np", ".", "where", "(", "test", "==", "1", ")", "\n", "user_list", "=", "concepts", "[", "categories", "]", "\n", "# print(user_list)", "\n", "for", "key", "in", "groups", ".", "keys", "(", ")", ":", "\n", "            ", "temp", "=", "check_group", "(", "user_list", ",", "groups", "[", "key", "]", ")", "\n", "new_groups", "[", "key", "]", ".", "append", "(", "temp", ")", "\n", "\n", "", "", "new_data_frame", "=", "pd", ".", "DataFrame", "(", ")", "\n", "# new_data_frame['randnumber'] = new_randnumbers", "\n", "new_data_frame", "[", "'seed'", "]", "=", "new_seeds", "\n", "for", "key", "in", "groups", ".", "keys", "(", ")", ":", "\n", "        ", "new_data_frame", "[", "key", "]", "=", "new_groups", "[", "key", "]", "\n", "\n", "", "return", "new_data_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.count_non_grouped_items": [[130, 168], ["evaluate_text.read_text_data", "print", "new_randnumbers.append", "numpy.where", "groups.values", "print", "print", "str"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.read_text_data"], ["", "def", "count_non_grouped_items", "(", "data", ",", "categories_df", ",", "groups", ")", ":", "\n", "    ", "'''\n    helper function to check how many categories have not been grouped yet\n    (counts the actual appearances in the participants answers)\n    '''", "\n", "text_data", ",", "concepts", "=", "read_text_data", "(", "categories_df", ")", "\n", "\n", "seeds", "=", "data", "[", "'seed'", "]", "\n", "randnumbers", "=", "data", "[", "'randnumber'", "]", "\n", "new_randnumbers", "=", "[", "]", "\n", "new_seeds", "=", "[", "]", "\n", "\n", "non_category", "=", "0", "\n", "for", "idx", "in", "data", ".", "index", ".", "values", ":", "\n", "# getting the condition number", "\n", "        ", "randnumber", "=", "randnumbers", "[", "idx", "]", "\n", "new_randnumbers", ".", "append", "(", "randnumber", ")", "\n", "\n", "# unique seed of the participant", "\n", "seed", "=", "seeds", "[", "idx", "]", "\n", "\n", "# get indices of concepts included in the participants answer", "\n", "try", ":", "\n", "            ", "test", "=", "text_data", "[", "str", "(", "seed", ")", "]", ".", "values", "\n", "", "except", ":", "\n", "            ", "print", "(", "'seed'", ",", "seed", ",", "'not found'", ")", "\n", "pass", "\n", "", "categories", "=", "np", ".", "where", "(", "test", "==", "1", ")", "[", "0", "]", "\n", "for", "cat", "in", "categories", ":", "\n", "            ", "present", "=", "False", "\n", "for", "i", "in", "groups", ".", "values", "(", ")", ":", "\n", "                ", "if", "concepts", "[", "cat", "]", "in", "i", ":", "\n", "                    ", "present", "=", "True", "\n", "", "", "if", "present", "==", "False", ":", "\n", "                ", "print", "(", "concepts", "[", "cat", "]", ")", "\n", "non_category", "+=", "1", "\n", "\n", "", "", "", "print", "(", "non_category", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.check_group": [[170, 177], ["None"], "function", ["None"], ["", "def", "check_group", "(", "user_list", ",", "group_list", ")", ":", "\n", "    ", "''' check if atleast one item from the group list is in the user_list\n    '''", "\n", "for", "i", "in", "group_list", ":", "\n", "        ", "if", "i", "in", "user_list", ":", "\n", "            ", "return", "1", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluate_text.score": [[179, 197], ["numpy.zeros", "groups.keys"], "function", ["None"], ["", "def", "score", "(", "positive", ",", "neutral", ",", "data", ")", ":", "\n", "    ", "'''\n    a simple scoring function that gives +1 for each correct group and -1 for false group, neutral groups are ignored\n    :param positive: array of positive groups\n    :param neutral: array of neutral groups\n    :param data: data frame encoding for each participant and group, if the group is contained in the participants answers\n    :return: array of scores for each participant\n    '''", "\n", "keys", "=", "groups", ".", "keys", "(", ")", "-", "[", "'RULES'", ",", "'HEATMAP'", ",", "'INTERPRETATION'", ",", "'GAMEPLAY'", ",", "'UNJUSTIFIED'", "]", "\n", "sum", "=", "np", ".", "zeros", "(", "data", ".", "index", ".", "values", ".", "shape", ")", "\n", "for", "key", "in", "keys", ":", "\n", "        ", "if", "key", "in", "positive", ":", "\n", "            ", "sum", "+=", "data", "[", "key", "]", "\n", "", "elif", "key", "in", "neutral", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "sum", "-=", "data", "[", "key", "]", "\n", "", "", "return", "sum", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.boot_matrix": [[16, 24], ["len", "numpy.random.randint"], "function", ["None"], ["def", "boot_matrix", "(", "z", ",", "B", ")", ":", "\n", "    ", "\"\"\"Bootstrap sample\n\n    Returns all bootstrap samples in a matrix\"\"\"", "\n", "\n", "n", "=", "len", "(", "z", ")", "# sample size", "\n", "idz", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n", ",", "size", "=", "(", "B", ",", "n", ")", ")", "# indices to pick for all boostrap samples", "\n", "return", "z", "[", "idz", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.bootstrap_mean": [[26, 43], ["len", "evaluation.boot_matrix", "boot_matrix.mean", "numpy.percentile", "matplotlib.hist"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.boot_matrix"], ["", "def", "bootstrap_mean", "(", "x", ",", "B", "=", "100000", ",", "alpha", "=", "0.05", ",", "plot", "=", "False", ")", ":", "\n", "    ", "\"\"\"Bootstrap standard error and (1-alpha)*100% c.i. for the population mean\n\n    Returns bootstrapped standard error and different types of confidence intervals\"\"\"", "\n", "\n", "# Deterministic things", "\n", "n", "=", "len", "(", "x", ")", "# sample size", "\n", "\n", "# Generate boostrap distribution of sample mean", "\n", "xboot", "=", "boot_matrix", "(", "x", ",", "B", "=", "B", ")", "\n", "sampling_distribution", "=", "xboot", ".", "mean", "(", "axis", "=", "1", ")", "\n", "\n", "quantile_boot", "=", "np", ".", "percentile", "(", "sampling_distribution", ",", "q", "=", "(", "100", "*", "alpha", "/", "2", ",", "100", "*", "(", "1", "-", "alpha", "/", "2", ")", ")", ")", "\n", "\n", "if", "plot", ":", "\n", "        ", "plt", ".", "hist", "(", "sampling_distribution", ",", "bins", "=", "\"fd\"", ")", "\n", "", "return", "quantile_boot", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI": [[45, 48], ["print", "print", "values.mean", "evaluation.bootstrap_mean"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.bootstrap_mean"], ["", "def", "mean_and_CI", "(", "values", ")", ":", "\n", "    ", "print", "(", "'mean: '", ",", "values", ".", "mean", "(", ")", ")", "\n", "print", "(", "bootstrap_mean", "(", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.rank_biserial_effect_size": [[50, 55], ["scipy.mannwhitneyu", "len", "len"], "function", ["None"], ["", "def", "rank_biserial_effect_size", "(", "x", ",", "y", ")", ":", "\n", "    ", "mann_whitney_res", "=", "stats", ".", "mannwhitneyu", "(", "x", ",", "y", ")", "\n", "u", "=", "mann_whitney_res", "[", "0", "]", "\n", "effect_size", "=", "1.0", "-", "(", "(", "2.0", "*", "u", ")", "/", "(", "len", "(", "x", ")", "*", "len", "(", "y", ")", ")", ")", "\n", "return", "effect_size", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mann_whitney": [[57, 105], ["print", "print", "evaluation.mean_and_CI", "print", "evaluation.mean_and_CI", "print", "evaluation.mean_and_CI", "print", "evaluation.mean_and_CI", "print", "print", "print", "p_vals.append", "print", "print", "print", "p_vals.append", "print", "print", "print", "p_vals.append", "print", "print", "print", "p_vals.append", "scipy.mannwhitneyu", "evaluation.rank_biserial_effect_size", "scipy.mannwhitneyu", "evaluation.rank_biserial_effect_size", "scipy.mannwhitneyu", "evaluation.rank_biserial_effect_size", "scipy.mannwhitneyu", "evaluation.rank_biserial_effect_size", "scipy.mannwhitneyu", "scipy.mannwhitneyu", "scipy.mannwhitneyu", "scipy.mannwhitneyu"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.mean_and_CI", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.rank_biserial_effect_size", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.rank_biserial_effect_size", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.rank_biserial_effect_size", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.rank_biserial_effect_size"], ["", "def", "mann_whitney", "(", "data", ",", "column_name", ",", "mean_only", "=", "False", ")", ":", "\n", "    ", "''' calculating either the mean or the mann whitney tests for for the dependant variable in the given column\n    :param data: dataframe containing the data\n    :param column_name: column of the dependent variable in the dataframe\n    :param mean_only: if True, only the mean for each condition is calculated\n    '''", "\n", "#splitting data into conditions", "\n", "data_random", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "1", "]", "\n", "data_randomLRP", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "3", "]", "\n", "data_highlights", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "2", "]", "\n", "data_highlightsLRP", "=", "data", ".", "loc", "[", "data", ".", "randnumber", "==", "4", "]", "\n", "\n", "random_values", "=", "data_random", "[", "column_name", "]", ".", "values", "\n", "randomLRP_values", "=", "data_randomLRP", "[", "column_name", "]", ".", "values", "\n", "highlights_values", "=", "data_highlights", "[", "column_name", "]", ".", "values", "\n", "highlightsLRP_values", "=", "data_highlightsLRP", "[", "column_name", "]", ".", "values", "\n", "\n", "print", "(", "'##### testing the column:'", ",", "column_name", ",", "'#####'", ")", "\n", "\n", "#calculating mean and confidence intervall for each condition", "\n", "print", "(", "'CI random:'", ")", "\n", "mean_and_CI", "(", "random_values", ")", "\n", "print", "(", "'CI random_LRP:'", ")", "\n", "mean_and_CI", "(", "randomLRP_values", ")", "\n", "print", "(", "'CI highlights:'", ")", "\n", "mean_and_CI", "(", "highlights_values", ")", "\n", "print", "(", "'CI highlights LRP:'", ")", "\n", "mean_and_CI", "(", "highlightsLRP_values", ")", "\n", "\n", "#mann whitney tests", "\n", "if", "not", "mean_only", ":", "\n", "        ", "p_vals", "=", "[", "]", "\n", "print", "(", "'random < randomLRP'", ")", "\n", "print", "(", "stats", ".", "mannwhitneyu", "(", "random_values", ",", "randomLRP_values", ",", "alternative", "=", "'less'", ")", ")", "\n", "print", "(", "rank_biserial_effect_size", "(", "random_values", ",", "randomLRP_values", ")", ")", "\n", "p_vals", ".", "append", "(", "stats", ".", "mannwhitneyu", "(", "random_values", ",", "randomLRP_values", ",", "alternative", "=", "'less'", ")", "[", "1", "]", ")", "\n", "print", "(", "'highlights < highlightsLRP'", ")", "\n", "print", "(", "stats", ".", "mannwhitneyu", "(", "highlights_values", ",", "highlightsLRP_values", ",", "alternative", "=", "'less'", ")", ")", "\n", "print", "(", "rank_biserial_effect_size", "(", "highlights_values", ",", "highlightsLRP_values", ")", ")", "\n", "p_vals", ".", "append", "(", "stats", ".", "mannwhitneyu", "(", "highlights_values", ",", "highlightsLRP_values", ",", "alternative", "=", "'less'", ")", "[", "1", "]", ")", "\n", "print", "(", "'random < highlights'", ")", "\n", "print", "(", "stats", ".", "mannwhitneyu", "(", "random_values", ",", "highlights_values", ",", "alternative", "=", "'less'", ")", ")", "\n", "print", "(", "rank_biserial_effect_size", "(", "random_values", ",", "highlights_values", ")", ")", "\n", "p_vals", ".", "append", "(", "stats", ".", "mannwhitneyu", "(", "random_values", ",", "highlights_values", ",", "alternative", "=", "'less'", ")", "[", "1", "]", ")", "\n", "print", "(", "'randomLRP < highlightsLRP'", ")", "\n", "print", "(", "stats", ".", "mannwhitneyu", "(", "randomLRP_values", ",", "highlightsLRP_values", ",", "alternative", "=", "'less'", ")", ")", "\n", "print", "(", "rank_biserial_effect_size", "(", "randomLRP_values", ",", "highlightsLRP_values", ")", ")", "\n", "p_vals", ".", "append", "(", "stats", ".", "mannwhitneyu", "(", "randomLRP_values", ",", "highlightsLRP_values", ",", "alternative", "=", "'less'", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.show_and_save_plt": [[107, 151], ["seaborn.set_style", "matplotlib.xlabel", "matplotlib.xticks", "matplotlib.yticks", "os.path.join", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.show", "matplotlib.ylabel", "ax.set", "ax.yaxis.label.set_size", "ax.xaxis.label.set_size", "os.path.isdir", "os.makedirs", "os.rmdir", "matplotlib.ylabel", "matplotlib.xlabel", "print"], "function", ["None"], ["", "", "def", "show_and_save_plt", "(", "ax", ",", "file_name", ",", "y_label", "=", "None", ",", "title", "=", "None", ",", "ylim", "=", "None", ",", "label_size", "=", "18", ",", "tick_size", "=", "14", ")", ":", "\n", "    ", "\"\"\"\n    Shows and saves the given plot and defines the appearance of the final plot.\n    :param ax: the plot to be saved.\n    :param file_name: save file name where the file is saved.\n    :param y_label: the y axis label displayed\n    :param title: titel of displayed in the plot (currently not used)\n    :param ylim: limits of the y axis.\n    :param label_size: font size of the label text\n    :param tick_size: font size of the tick numbers\n    \"\"\"", "\n", "#this only works the second time the function is used, since it sets the style for future plots.", "\n", "# It was still more convenient this way. #TODO fix this", "\n", "sns", ".", "set_style", "(", "\"whitegrid\"", ")", "\n", "\n", "if", "y_label", "!=", "None", ":", "\n", "        ", "plt", ".", "ylabel", "(", "y_label", ")", "\n", "", "plt", ".", "xlabel", "(", "None", ")", "\n", "#plt.supitle=(title)", "\n", "#ax.set(title=title)", "\n", "if", "ylim", "!=", "None", ":", "\n", "        ", "ax", ".", "set", "(", "ylim", "=", "ylim", ")", "\n", "\n", "", "try", ":", "\n", "        ", "ax", ".", "yaxis", ".", "label", ".", "set_size", "(", "label_size", ")", "\n", "ax", ".", "xaxis", ".", "label", ".", "set_size", "(", "label_size", ")", "\n", "", "except", ":", "\n", "        ", "try", ":", "\n", "            ", "plt", ".", "ylabel", "(", "y_label", ",", "fontsize", "=", "label_size", ")", "\n", "plt", ".", "xlabel", "(", "fontsize", "=", "label_size", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "\n", "", "", "plt", ".", "xticks", "(", "fontsize", "=", "tick_size", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "tick_size", ")", "\n", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "'figures'", ",", "file_name", ")", "\n", "if", "not", "(", "os", ".", "path", ".", "isdir", "(", "file_name", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "file_name", ")", "\n", "os", ".", "rmdir", "(", "file_name", ")", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "file_name", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.satisfaction_analysis": [[153, 191], ["seaborn.barplot", "evaluation.show_and_save_plt", "str", "avg_satisfaction.append", "print", "str", "str"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.show_and_save_plt"], ["", "def", "satisfaction_analysis", "(", "number", ",", "data", ")", ":", "\n", "    ", "'''\n    Helper function to analyze the participants satisfaction in in each tast (Trust and Retrospection)\n    :param number: specifies the Task: 1 = Retrospection, 2= Trust\n    :param data: dataframe containing the data\n    :return:\n    '''", "\n", "\n", "# getting the correct column name for the given task number", "\n", "column_name", "=", "'explSatisfaction'", "+", "str", "(", "number", ")", "\n", "if", "number", "==", "1", ":", "\n", "        ", "result_name", "=", "'explSatisfaction'", "+", "'Retro'", "+", "'Avg'", "\n", "title", "=", "'Average satisfaction for the '", "+", "'retrospection task'", "\n", "", "elif", "number", "==", "2", ":", "\n", "        ", "result_name", "=", "'explSatisfaction'", "+", "'Trust'", "+", "'Avg'", "\n", "title", "=", "'Average satisfaction for the '", "+", "'comparison task'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'number not implemented'", ")", "\n", "# inverting the negative question 3 to be inline with the other positive questions", "\n", "", "data", "[", "column_name", "+", "'[3]'", "]", "=", "6", "-", "data", "[", "column_name", "+", "'[3]'", "]", "\n", "\n", "# calculating the average satisfaction for all questions that were actually asked", "\n", "avg_satisfaction", "=", "[", "]", "\n", "for", "i", "in", "data", ".", "index", ".", "values", ":", "\n", "        ", "temp", "=", "0", "\n", "if", "data", "[", "'randnumber'", "]", "[", "i", "]", "<", "3", ":", "\n", "            ", "for", "j", "in", "(", "1", ",", "2", ",", "3", ",", "4", ")", ":", "\n", "                ", "temp", "+=", "data", "[", "column_name", "+", "'['", "+", "str", "(", "j", ")", "+", "']'", "]", "[", "i", "]", "\n", "", "temp", "=", "temp", "/", "4", "\n", "", "else", ":", "\n", "            ", "for", "j", "in", "(", "1", ",", "2", ",", "3", ",", "5", ",", "6", ")", ":", "\n", "                ", "temp", "+=", "data", "[", "column_name", "+", "'['", "+", "str", "(", "j", ")", "+", "']'", "]", "[", "i", "]", "\n", "", "temp", "=", "temp", "/", "5", "\n", "", "avg_satisfaction", ".", "append", "(", "temp", ")", "\n", "\n", "", "data", "[", "result_name", "]", "=", "avg_satisfaction", "\n", "ax", "=", "sns", ".", "barplot", "(", "x", "=", "'condition'", ",", "y", "=", "result_name", ",", "data", "=", "data", ",", "order", "=", "[", "'L'", ",", "'H'", ",", "'L+S'", ",", "'H+S'", "]", ")", "\n", "show_and_save_plt", "(", "ax", ",", "result_name", ",", "y_label", "=", "'Average Rating'", ",", "title", "=", "title", ",", "ylim", "=", "(", "1", ",", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.Survey_results.evaluation.analyze_distribution": [[193, 216], ["pandas.melt", "pd.melt.variable.apply", "seaborn.barplot", "columns.index"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.argmax_analyzer.ArgmaxRule.apply"], ["", "def", "analyze_distribution", "(", "data", ",", "columns", ")", ":", "\n", "    ", "\"\"\"\n    Analyzes the distribution of the values in the given columns\n    :param data: The dataframe to be analyzed\n    :param columns: The name of the columns to be compared\n    :return ax: a plot showing the distribution\n    \"\"\"", "\n", "df", "=", "data", "[", "columns", "]", "\n", "def", "get_column_number", "(", "column", ")", ":", "\n", "        ", "\"\"\"\n        Converts the column names to their position in the original columns-array.\n        Should the name not be in the columns array the name will not be converted.\n        \"\"\"", "\n", "if", "column", "in", "columns", ":", "\n", "            ", "return", "columns", ".", "index", "(", "column", ")", "+", "1", "\n", "", "else", ":", "\n", "            ", "return", "column", "\n", "\n", "", "", "df", "=", "pd", ".", "melt", "(", "df", ")", "\n", "df", ".", "variable", "=", "df", ".", "variable", ".", "apply", "(", "get_column_number", ")", "\n", "ax", "=", "sns", ".", "barplot", "(", "x", "=", "\"variable\"", ",", "y", "=", "\"value\"", ",", "data", "=", "df", ")", "\n", "\n", "return", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.sanity_checks.sanity_checks.rand_layer": [[29, 36], ["numpy.random.normal", "numpy.random.normal", "layer.set_weights", "layer.get_weights", "layer.get_weights"], "function", ["None"], ["def", "rand_layer", "(", "layer", ",", "mean", "=", "0", ",", "SD", "=", "0.1", ")", ":", "\n", "    ", "'''Custom layer randomization for testing purposes.'''", "\n", "weights_shape", "=", "layer", ".", "get_weights", "(", ")", "[", "0", "]", ".", "shape", "\n", "bias_shape", "=", "layer", ".", "get_weights", "(", ")", "[", "1", "]", ".", "shape", "\n", "rand_weights", "=", "np", ".", "random", ".", "normal", "(", "mean", ",", "SD", ",", "weights_shape", ")", "\n", "rand_bias", "=", "np", ".", "random", ".", "normal", "(", "mean", ",", "SD", ",", "bias_shape", ")", "\n", "layer", ".", "set_weights", "(", "[", "rand_weights", ",", "rand_bias", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.sanity_checks.sanity_checks.init_layer": [[37, 46], ["keras.get_session", "tensorflow.variables_initializer", "K.get_session.run"], "function", ["None"], ["", "def", "init_layer", "(", "layer", ")", ":", "\n", "    ", "''' Re-initializes the given layer with the original initializer to achieve randomization of the layer that is\n    within reasonable bounds for that layer.\n    :param layer: the layer to be randomized\n    :return: nothing, the given layer is randomized\n    '''", "\n", "session", "=", "K", ".", "get_session", "(", ")", "\n", "weights_initializer", "=", "tf", ".", "variables_initializer", "(", "layer", ".", "weights", ")", "\n", "session", ".", "run", "(", "weights_initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.sanity_checks.sanity_checks.copy_model": [[47, 56], ["keras.models.clone_model", "keras.models.clone_model", "keras.models.clone_model.set_weights", "model.get_weights"], "function", ["None"], ["", "def", "copy_model", "(", "model", ")", ":", "\n", "    ", "'''\n    Copies a keras model including the weights\n    :param model: the model to be copied\n    :return: the new copy of the model\n    '''", "\n", "model_m1", "=", "keras", ".", "models", ".", "clone_model", "(", "model", ")", "\n", "model_m1", ".", "set_weights", "(", "model", ".", "get_weights", "(", ")", ")", "\n", "return", "model_m1", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.sanity_checks.sanity_checks.check_models": [[57, 64], ["range", "print", "print", "print", "model1.get_layer().get_weights", "model.get_layer().get_weights", "model1.get_layer().get_weights", "model.get_layer().get_weights", "model1.get_layer", "model.get_layer", "model1.get_layer", "model.get_layer"], "function", ["None"], ["", "def", "check_models", "(", "model1", ",", "model", ")", ":", "\n", "    ", "''' checks if two models have the same weights, to make sure that a layer was randomized.'''", "\n", "for", "i", "in", "range", "(", "1", ",", "7", ")", ":", "\n", "        ", "if", "i", "!=", "4", ":", "\n", "            ", "print", "(", "'layer '", ",", "i", ")", "\n", "print", "(", "(", "model1", ".", "get_layer", "(", "index", "=", "i", ")", ".", "get_weights", "(", ")", "[", "0", "]", "==", "model", ".", "get_layer", "(", "index", "=", "i", ")", ".", "get_weights", "(", ")", "[", "0", "]", ")", ".", "all", "(", ")", ")", "\n", "print", "(", "(", "model1", ".", "get_layer", "(", "index", "=", "i", ")", ".", "get_weights", "(", ")", "[", "1", "]", "==", "model", ".", "get_layer", "(", "index", "=", "i", ")", ".", "get_weights", "(", ")", "[", "1", "]", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.sanity_checks.sanity_checks.calc_sim": [[65, 94], ["image_utils.normalise_image", "image_utils.normalise_image", "scipy.stats.spearmanr", "scipy.stats.spearmanr", "max", "skimage.metrics.structural_similarity", "skimage.metrics.structural_similarity", "max", "skimage.feature.hog", "skimage.feature.hog", "scipy.stats.pearsonr", "skimage.feature.hog", "scipy.stats.pearsonr", "max", "pearson_list.append", "ssim_list.append", "spearman_list.append", "image_utils.normalise_image.flatten", "image_utils.normalise_image.flatten", "neg_random_relevance.flatten", "image_utils.normalise_image.flatten", "image_utils.normalise_image.flatten", "image_utils.normalise_image.flatten", "neg_random_relevance.flatten", "image_utils.normalise_image.flatten"], "function", ["home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.normalise_image", "home.repos.pwc.inspect_result.HuTobias_HIGHLIGHTS-LRP.None.image_utils.normalise_image"], ["", "", "", "def", "calc_sim", "(", "learned_relevance", ",", "random_relevance", ")", ":", "\n", "    ", "''' Helper function to calculate the similarities of two saliency maps (for learned weights and partly random wheights).\n    Only works in this code, since the similarity lists are created elsewhere. '''", "\n", "#normalizing:", "\n", "learned_relevance", "=", "normalise_image", "(", "learned_relevance", ")", "\n", "random_relevance", "=", "normalise_image", "(", "random_relevance", ")", "\n", "neg_random_relevance", "=", "1", "-", "random_relevance", "\n", "\n", "spearman", ",", "spearman2", "=", "spearmanr", "(", "random_relevance", ".", "flatten", "(", ")", ",", "learned_relevance", ".", "flatten", "(", ")", ",", "nan_policy", "=", "'omit'", ")", "\n", "test", ",", "_", "=", "spearmanr", "(", "neg_random_relevance", ".", "flatten", "(", ")", ",", "learned_relevance", ".", "flatten", "(", ")", ",", "nan_policy", "=", "'omit'", ")", "\n", "spearman", "=", "max", "(", "spearman", ",", "test", ")", "\n", "\n", "# ssim_val = ssim(random_relevance,learned_relevance, multichannel=True)", "\n", "ssim_val", "=", "ssim", "(", "random_relevance", ".", "flatten", "(", ")", ",", "learned_relevance", ".", "flatten", "(", ")", ")", "\n", "test", "=", "ssim", "(", "neg_random_relevance", ".", "flatten", "(", ")", ",", "learned_relevance", ".", "flatten", "(", ")", ")", "\n", "ssim_val", "=", "max", "(", "ssim_val", ",", "test", ")", "\n", "\n", "random_hog", "=", "hog", "(", "random_relevance", ")", "\n", "learned_hog", "=", "hog", "(", "learned_relevance", ")", "\n", "pearson", ",", "_", "=", "pearsonr", "(", "random_hog", ",", "learned_hog", ")", "\n", "\n", "neg_random_hog", "=", "hog", "(", "neg_random_relevance", ")", "\n", "test", ",", "_", "=", "pearsonr", "(", "neg_random_hog", ",", "learned_hog", ")", "\n", "pearson", "=", "max", "(", "pearson", ",", "test", ")", "\n", "\n", "\n", "pearson_list", ".", "append", "(", "pearson", ")", "\n", "ssim_list", ".", "append", "(", "ssim_val", ")", "\n", "spearman_list", ".", "append", "(", "spearman", ")", "\n", "\n"]]}