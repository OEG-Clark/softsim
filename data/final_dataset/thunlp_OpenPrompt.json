{"home.repos.pwc.inspect_result.thunlp_OpenPrompt.None.setup.get_requirements": [[5, 11], ["open", "freq.readlines", "os.path.join", "ret.append", "line.strip"], "function", ["None"], ["def", "get_requirements", "(", "path", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"requirements.txt\"", ")", ",", "encoding", "=", "\"utf-8\"", ")", "as", "freq", ":", "\n", "        ", "for", "line", "in", "freq", ".", "readlines", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_condition_generation_dataset.test_WebNLGProcessor": [[10, 24], ["os.path.join", "processor.get_train_examples", "processor.get_train_examples", "processor.get_test_examples", "len", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples"], ["def", "test_WebNLGProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"webnlg_2017\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "valid_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "\n", "assert", "len", "(", "train_dataset", ")", "==", "18025", "\n", "assert", "len", "(", "valid_dataset", ")", "==", "18025", "\n", "assert", "len", "(", "test_dataset", ")", "==", "4928", "\n", "assert", "test_dataset", "[", "0", "]", ".", "text_a", "==", "\" | Abilene_Regional_Airport : cityServed : Abilene,_Texas\"", "\n", "assert", "test_dataset", "[", "0", "]", ".", "text_b", "==", "\"\"", "\n", "assert", "test_dataset", "[", "0", "]", ".", "tgt_text", "==", "\"Abilene, Texas is served by the Abilene regional airport.\"", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_typing_dataset.test_FewNERDProcessor": [[10, 32], ["os.path.join", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["def", "test_FewNERDProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"FewNERD\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "dev_dataset", "=", "processor", ".", "get_dev_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "66", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "\n", "\"person-actor\"", ",", "\"person-director\"", ",", "\"person-artist/author\"", ",", "\"person-athlete\"", ",", "\"person-politician\"", ",", "\"person-scholar\"", ",", "\"person-soldier\"", ",", "\"person-other\"", ",", "\n", "\"organization-showorganization\"", ",", "\"organization-religion\"", ",", "\"organization-company\"", ",", "\"organization-sportsteam\"", ",", "\"organization-education\"", ",", "\"organization-government/governmentagency\"", ",", "\"organization-media/newspaper\"", ",", "\"organization-politicalparty\"", ",", "\"organization-sportsleague\"", ",", "\"organization-other\"", ",", "\n", "\"location-GPE\"", ",", "\"location-road/railway/highway/transit\"", ",", "\"location-bodiesofwater\"", ",", "\"location-park\"", ",", "\"location-mountain\"", ",", "\"location-island\"", ",", "\"location-other\"", ",", "\n", "\"product-software\"", ",", "\"product-food\"", ",", "\"product-game\"", ",", "\"product-ship\"", ",", "\"product-train\"", ",", "\"product-airplane\"", ",", "\"product-car\"", ",", "\"product-weapon\"", ",", "\"product-other\"", ",", "\n", "\"building-theater\"", ",", "\"building-sportsfacility\"", ",", "\"building-airport\"", ",", "\"building-hospital\"", ",", "\"building-library\"", ",", "\"building-hotel\"", ",", "\"building-restaurant\"", ",", "\"building-other\"", ",", "\n", "\"event-sportsevent\"", ",", "\"event-attack/battle/war/militaryconflict\"", ",", "\"event-disaster\"", ",", "\"event-election\"", ",", "\"event-protest\"", ",", "\"event-other\"", ",", "\n", "\"art-music\"", ",", "\"art-writtenart\"", ",", "\"art-film\"", ",", "\"art-painting\"", ",", "\"art-broadcastprogram\"", ",", "\"art-other\"", ",", "\n", "\"other-biologything\"", ",", "\"other-chemicalthing\"", ",", "\"other-livingthing\"", ",", "\"other-astronomything\"", ",", "\"other-god\"", ",", "\"other-law\"", ",", "\"other-award\"", ",", "\"other-disease\"", ",", "\"other-medical\"", ",", "\"other-language\"", ",", "\"other-currency\"", ",", "\"other-educationaldegree\"", ",", "\n", "]", "\n", "assert", "dev_dataset", "[", "0", "]", ".", "text_a", "==", "\"The final stage in the development of the Skyfox was the production of a model with tricycle landing gear to better cater for the pilot training market .\"", "\n", "assert", "dev_dataset", "[", "0", "]", ".", "meta", "[", "\"entity\"", "]", "==", "\"Skyfox\"", "\n", "assert", "dev_dataset", "[", "0", "]", ".", "label", "==", "30", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_nli_dataset.test_SNLIProcessor": [[10, 25], ["os.path.join", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "len", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["def", "test_SNLIProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"SNLI\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "dev_dataset", "=", "processor", ".", "get_dev_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "3", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "'entailment'", ",", "'neutral'", ",", "'contradiction'", "]", "\n", "assert", "len", "(", "train_dataset", ")", "==", "549367", "\n", "assert", "len", "(", "dev_dataset", ")", "==", "9842", "\n", "assert", "len", "(", "test_dataset", ")", "==", "9824", "\n", "assert", "train_dataset", "[", "0", "]", ".", "text_a", "==", "'A person on a horse jumps over a broken down airplane.'", "\n", "assert", "train_dataset", "[", "0", "]", ".", "text_b", "==", "'A person is training his horse for a competition.'", "\n", "assert", "train_dataset", "[", "0", "]", ".", "label", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_relation_classification_dataset.test_TACREDProcessor": [[10, 27], ["os.path.join", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "len", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["def", "test_TACREDProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"TACRED\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "dev_dataset", "=", "processor", ".", "get_dev_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "42", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "\"no_relation\"", ",", "\"org:founded\"", ",", "\"org:subsidiaries\"", ",", "\"per:date_of_birth\"", ",", "\"per:cause_of_death\"", ",", "\"per:age\"", ",", "\"per:stateorprovince_of_birth\"", ",", "\"per:countries_of_residence\"", ",", "\"per:country_of_birth\"", ",", "\"per:stateorprovinces_of_residence\"", ",", "\"org:website\"", ",", "\"per:cities_of_residence\"", ",", "\"per:parents\"", ",", "\"per:employee_of\"", ",", "\"per:city_of_birth\"", ",", "\"org:parents\"", ",", "\"org:political/religious_affiliation\"", ",", "\"per:schools_attended\"", ",", "\"per:country_of_death\"", ",", "\"per:children\"", ",", "\"org:top_members/employees\"", ",", "\"per:date_of_death\"", ",", "\"org:members\"", ",", "\"org:alternate_names\"", ",", "\"per:religion\"", ",", "\"org:member_of\"", ",", "\"org:city_of_headquarters\"", ",", "\"per:origin\"", ",", "\"org:shareholders\"", ",", "\"per:charges\"", ",", "\"per:title\"", ",", "\"org:number_of_employees/members\"", ",", "\"org:dissolved\"", ",", "\"org:country_of_headquarters\"", ",", "\"per:alternate_names\"", ",", "\"per:siblings\"", ",", "\"org:stateorprovince_of_headquarters\"", ",", "\"per:spouse\"", ",", "\"per:other_family\"", ",", "\"per:city_of_death\"", ",", "\"per:stateorprovince_of_death\"", ",", "\"org:founded_by\"", "]", "\n", "assert", "len", "(", "train_dataset", ")", "==", "68124", "\n", "assert", "len", "(", "dev_dataset", ")", "==", "22631", "\n", "assert", "len", "(", "test_dataset", ")", "==", "15509", "\n", "assert", "train_dataset", "[", "0", "]", ".", "text_a", "==", "'Tom Thabane resigned in October last year to form the All Basotho Convention -LRB- ABC -RRB- , crossing the floor with 17 members of parliament , causing constitutional monarch King Letsie III to dissolve parliament and call the snap election .'", "\n", "assert", "train_dataset", "[", "0", "]", ".", "meta", "[", "\"head\"", "]", "==", "\"All Basotho Convention\"", "\n", "assert", "train_dataset", "[", "0", "]", ".", "meta", "[", "\"tail\"", "]", "==", "\"Tom Thabane\"", "\n", "assert", "train_dataset", "[", "0", "]", ".", "label", "==", "41", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_relation_classification_dataset.test_TACREVProcessor": [[28, 40], ["os.path.join", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "len", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["", "def", "test_TACREVProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"TACREV\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "dev_dataset", "=", "processor", ".", "get_dev_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "42", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "\"no_relation\"", ",", "\"org:founded\"", ",", "\"org:subsidiaries\"", ",", "\"per:date_of_birth\"", ",", "\"per:cause_of_death\"", ",", "\"per:age\"", ",", "\"per:stateorprovince_of_birth\"", ",", "\"per:countries_of_residence\"", ",", "\"per:country_of_birth\"", ",", "\"per:stateorprovinces_of_residence\"", ",", "\"org:website\"", ",", "\"per:cities_of_residence\"", ",", "\"per:parents\"", ",", "\"per:employee_of\"", ",", "\"per:city_of_birth\"", ",", "\"org:parents\"", ",", "\"org:political/religious_affiliation\"", ",", "\"per:schools_attended\"", ",", "\"per:country_of_death\"", ",", "\"per:children\"", ",", "\"org:top_members/employees\"", ",", "\"per:date_of_death\"", ",", "\"org:members\"", ",", "\"org:alternate_names\"", ",", "\"per:religion\"", ",", "\"org:member_of\"", ",", "\"org:city_of_headquarters\"", ",", "\"per:origin\"", ",", "\"org:shareholders\"", ",", "\"per:charges\"", ",", "\"per:title\"", ",", "\"org:number_of_employees/members\"", ",", "\"org:dissolved\"", ",", "\"org:country_of_headquarters\"", ",", "\"per:alternate_names\"", ",", "\"per:siblings\"", ",", "\"org:stateorprovince_of_headquarters\"", ",", "\"per:spouse\"", ",", "\"per:other_family\"", ",", "\"per:city_of_death\"", ",", "\"per:stateorprovince_of_death\"", ",", "\"org:founded_by\"", "]", "\n", "assert", "len", "(", "train_dataset", ")", "==", "68124", "\n", "assert", "len", "(", "dev_dataset", ")", "==", "22631", "\n", "assert", "len", "(", "test_dataset", ")", "==", "15509", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_relation_classification_dataset.test_ReTACREDProcessor": [[41, 53], ["os.path.join", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "len", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["", "def", "test_ReTACREDProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"ReTACRED\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "dev_dataset", "=", "processor", ".", "get_dev_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "40", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "\"no_relation\"", ",", "\"org:members\"", ",", "\"per:siblings\"", ",", "\"per:spouse\"", ",", "\"org:country_of_branch\"", ",", "\"per:country_of_death\"", ",", "\"per:parents\"", ",", "\"per:stateorprovinces_of_residence\"", ",", "\"org:top_members/employees\"", ",", "\"org:dissolved\"", ",", "\"org:number_of_employees/members\"", ",", "\"per:stateorprovince_of_death\"", ",", "\"per:origin\"", ",", "\"per:children\"", ",", "\"org:political/religious_affiliation\"", ",", "\"per:city_of_birth\"", ",", "\"per:title\"", ",", "\"org:shareholders\"", ",", "\"per:employee_of\"", ",", "\"org:member_of\"", ",", "\"org:founded_by\"", ",", "\"per:countries_of_residence\"", ",", "\"per:other_family\"", ",", "\"per:religion\"", ",", "\"per:identity\"", ",", "\"per:date_of_birth\"", ",", "\"org:city_of_branch\"", ",", "\"org:alternate_names\"", ",", "\"org:website\"", ",", "\"per:cause_of_death\"", ",", "\"org:stateorprovince_of_branch\"", ",", "\"per:schools_attended\"", ",", "\"per:country_of_birth\"", ",", "\"per:date_of_death\"", ",", "\"per:city_of_death\"", ",", "\"org:founded\"", ",", "\"per:cities_of_residence\"", ",", "\"per:age\"", ",", "\"per:charges\"", ",", "\"per:stateorprovince_of_birth\"", "]", "\n", "assert", "len", "(", "train_dataset", ")", "==", "58465", "\n", "assert", "len", "(", "dev_dataset", ")", "==", "19584", "\n", "assert", "len", "(", "test_dataset", ")", "==", "13418", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_relation_classification_dataset.test_SemEvalProcessor": [[54, 70], ["os.path.join", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "len", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["", "def", "test_SemEvalProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"SemEval\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "dev_dataset", "=", "processor", ".", "get_dev_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "19", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "\"Other\"", ",", "\"Member-Collection(e1,e2)\"", ",", "\"Entity-Destination(e1,e2)\"", ",", "\"Content-Container(e1,e2)\"", ",", "\"Message-Topic(e1,e2)\"", ",", "\"Entity-Origin(e1,e2)\"", ",", "\"Cause-Effect(e1,e2)\"", ",", "\"Product-Producer(e1,e2)\"", ",", "\"Instrument-Agency(e1,e2)\"", ",", "\"Component-Whole(e1,e2)\"", ",", "\"Member-Collection(e2,e1)\"", ",", "\"Entity-Destination(e2,e1)\"", ",", "\"Content-Container(e2,e1)\"", ",", "\"Message-Topic(e2,e1)\"", ",", "\"Entity-Origin(e2,e1)\"", ",", "\"Cause-Effect(e2,e1)\"", ",", "\"Product-Producer(e2,e1)\"", ",", "\"Instrument-Agency(e2,e1)\"", ",", "\"Component-Whole(e2,e1)\"", "]", "\n", "assert", "len", "(", "train_dataset", ")", "==", "6507", "\n", "assert", "len", "(", "dev_dataset", ")", "==", "1493", "\n", "assert", "len", "(", "test_dataset", ")", "==", "2717", "\n", "assert", "dev_dataset", "[", "0", "]", ".", "text_a", "==", "'the system as described above has its greatest application in an arrayed configuration of antenna elements .'", "\n", "assert", "dev_dataset", "[", "0", "]", ".", "meta", "[", "\"head\"", "]", "==", "\"configuration\"", "\n", "assert", "dev_dataset", "[", "0", "]", ".", "meta", "[", "\"tail\"", "]", "==", "\"elements\"", "\n", "assert", "dev_dataset", "[", "0", "]", ".", "label", "==", "18", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_text_classification_dataset.test_AgnewsProcessor": [[10, 24], ["os.path.join", "processor.get_train_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["def", "test_AgnewsProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"agnews\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "trainvalid_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "4", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "\"World\"", ",", "\"Sports\"", ",", "\"Business\"", ",", "\"Tech\"", "]", "\n", "assert", "len", "(", "trainvalid_dataset", ")", "==", "120000", "\n", "assert", "len", "(", "test_dataset", ")", "==", "7600", "\n", "assert", "test_dataset", "[", "0", "]", ".", "text_a", "==", "\"Fears for T N pension after talks\"", "\n", "assert", "test_dataset", "[", "0", "]", ".", "text_b", "==", "\"Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"", "\n", "assert", "test_dataset", "[", "0", "]", ".", "label", "==", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_text_classification_dataset.test_DBpediaProcessor": [[25, 35], ["os.path.join", "processor.get_train_examples", "processor.get_test_examples", "processor.get_num_labels", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels"], ["", "def", "test_DBpediaProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"dbpedia\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "trainvalid_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "14", "\n", "assert", "len", "(", "trainvalid_dataset", ")", "==", "560000", "\n", "assert", "len", "(", "test_dataset", ")", "==", "70000", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_text_classification_dataset.test_ImdbProcessor": [[36, 46], ["os.path.join", "processor.get_train_examples", "processor.get_test_examples", "processor.get_num_labels", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels"], ["", "def", "test_ImdbProcessor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"imdb\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "trainvalid_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "2", "\n", "assert", "len", "(", "trainvalid_dataset", ")", "==", "25000", "\n", "assert", "len", "(", "test_dataset", ")", "==", "25000", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.test_data_processor.test_text_classification_dataset.test_SST2Processor": [[58, 73], ["os.path.join", "processor.get_train_examples", "processor.get_dev_examples", "processor.get_test_examples", "processor.get_num_labels", "processor.get_labels", "len", "len", "len", "dataset_name.lower"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels"], ["", "def", "test_SST2Processor", "(", ")", ":", "\n", "    ", "dataset_name", "=", "\"SST-2\"", "\n", "dataset_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "dataset_name", ")", "\n", "processor", "=", "PROCESSORS", "[", "dataset_name", ".", "lower", "(", ")", "]", "(", ")", "\n", "train_dataset", "=", "processor", ".", "get_train_examples", "(", "dataset_path", ")", "\n", "dev_dataset", "=", "processor", ".", "get_dev_examples", "(", "dataset_path", ")", "\n", "test_dataset", "=", "processor", ".", "get_test_examples", "(", "dataset_path", ")", "\n", "\n", "assert", "processor", ".", "get_num_labels", "(", ")", "==", "2", "\n", "assert", "processor", ".", "get_labels", "(", ")", "==", "[", "'0'", ",", "'1'", "]", "\n", "assert", "len", "(", "train_dataset", ")", "==", "6920", "\n", "assert", "len", "(", "dev_dataset", ")", "==", "872", "\n", "assert", "len", "(", "test_dataset", ")", "==", "1821", "\n", "assert", "train_dataset", "[", "0", "]", ".", "text_a", "==", "'a stirring , funny and finally transporting re-imagining of beauty and the beast and 1930s horror films'", "\n", "assert", "train_dataset", "[", "0", "]", ".", "label", "==", "1", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.experiments.cli.build_dataloader": [[26, 39], ["openprompt.PromptDataLoader", "hasattr", "re.template", "re.template", "re.template"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.template", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.template", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.template"], ["def", "build_dataloader", "(", "dataset", ",", "template", ",", "tokenizer", ",", "tokenizer_wrapper_class", ",", "config", ",", "split", ")", ":", "\n", "    ", "dataloader", "=", "PromptDataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "template", "=", "template", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "tokenizer_wrapper_class", "=", "tokenizer_wrapper_class", ",", "\n", "batch_size", "=", "config", "[", "split", "]", ".", "batch_size", ",", "\n", "shuffle", "=", "config", "[", "split", "]", ".", "shuffle_data", ",", "\n", "teacher_forcing", "=", "config", "[", "split", "]", ".", "teacher_forcing", "if", "hasattr", "(", "config", "[", "split", "]", ",", "'teacher_forcing'", ")", "else", "None", ",", "\n", "predict_eos_token", "=", "True", "if", "config", ".", "task", "==", "\"generation\"", "else", "False", ",", "\n", "**", "config", ".", "dataloader", "\n", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.experiments.cli.main": [[42, 118], ["openprompt.config.get_config", "openprompt.data_utils.load_dataset", "Exception", "openprompt.utils.logging.config_experiment_dir", "openprompt.utils.logging.init_logger", "openprompt.config.save_config_to_yaml", "cli.trainer", "os.path.join", "len", "ValueError", "cli.trainer", "openprompt.data_utils.FewShotSampler", "openprompt.data_utils.FewShotSampler.", "cli.trainer", "cli.trainer", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_config", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.logging.config_experiment_dir", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.logging.init_logger", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.save_config_to_yaml", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.experiments.cli.trainer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.experiments.cli.trainer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.experiments.cli.trainer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.experiments.cli.trainer"], ["", "def", "main", "(", ")", ":", "\n", "    ", "config", ",", "args", "=", "get_config", "(", ")", "\n", "# exit()", "\n", "# init logger, create log dir and set log level, etc.", "\n", "if", "args", ".", "resume", "and", "args", ".", "test", ":", "\n", "        ", "raise", "Exception", "(", "\"cannot use flag --resume and --test together\"", ")", "\n", "", "if", "args", ".", "resume", "or", "args", ".", "test", ":", "\n", "        ", "config", ".", "logging", ".", "path", "=", "EXP_PATH", "=", "args", ".", "resume", "or", "args", ".", "test", "\n", "", "else", ":", "\n", "        ", "EXP_PATH", "=", "config_experiment_dir", "(", "config", ")", "\n", "init_logger", "(", "os", ".", "path", ".", "join", "(", "EXP_PATH", ",", "\"log.txt\"", ")", ",", "config", ".", "logging", ".", "file_level", ",", "config", ".", "logging", ".", "console_level", ")", "\n", "# save config to the logger directory", "\n", "save_config_to_yaml", "(", "config", ")", "\n", "\n", "\n", "# load dataset. The valid_dataset can be None", "\n", "", "train_dataset", ",", "valid_dataset", ",", "test_dataset", ",", "Processor", "=", "load_dataset", "(", "config", ",", "test", "=", "args", ".", "test", "is", "not", "None", "or", "config", ".", "learning_setting", "==", "'zero_shot'", ")", "\n", "\n", "# main", "\n", "if", "config", ".", "learning_setting", "==", "'full'", ":", "\n", "        ", "res", "=", "trainer", "(", "\n", "EXP_PATH", ",", "\n", "config", ",", "\n", "Processor", ",", "\n", "resume", "=", "args", ".", "resume", ",", "\n", "test", "=", "args", ".", "test", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "valid_dataset", "=", "valid_dataset", ",", "\n", "test_dataset", "=", "test_dataset", ",", "\n", ")", "\n", "", "elif", "config", ".", "learning_setting", "==", "'few_shot'", ":", "\n", "        ", "if", "config", ".", "few_shot", ".", "few_shot_sampling", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"use few_shot setting but config.few_shot.few_shot_sampling is not specified\"", ")", "\n", "", "seeds", "=", "config", ".", "sampling_from_train", ".", "seed", "\n", "res", "=", "0", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "if", "not", "args", ".", "test", ":", "\n", "                ", "sampler", "=", "FewShotSampler", "(", "\n", "num_examples_per_label", "=", "config", ".", "sampling_from_train", ".", "num_examples_per_label", ",", "\n", "also_sample_dev", "=", "config", ".", "sampling_from_train", ".", "also_sample_dev", ",", "\n", "num_examples_per_label_dev", "=", "config", ".", "sampling_from_train", ".", "num_examples_per_label_dev", "\n", ")", "\n", "train_sampled_dataset", ",", "valid_sampled_dataset", "=", "sampler", "(", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "valid_dataset", "=", "valid_dataset", ",", "\n", "seed", "=", "seed", "\n", ")", "\n", "result", "=", "trainer", "(", "\n", "os", ".", "path", ".", "join", "(", "EXP_PATH", ",", "f\"seed-{seed}\"", ")", ",", "\n", "config", ",", "\n", "Processor", ",", "\n", "resume", "=", "args", ".", "resume", ",", "\n", "test", "=", "args", ".", "test", ",", "\n", "train_dataset", "=", "train_sampled_dataset", ",", "\n", "valid_dataset", "=", "valid_sampled_dataset", ",", "\n", "test_dataset", "=", "test_dataset", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "result", "=", "trainer", "(", "\n", "os", ".", "path", ".", "join", "(", "EXP_PATH", ",", "f\"seed-{seed}\"", ")", ",", "\n", "config", ",", "\n", "Processor", ",", "\n", "test", "=", "args", ".", "test", ",", "\n", "test_dataset", "=", "test_dataset", ",", "\n", ")", "\n", "", "res", "+=", "result", "\n", "", "res", "/=", "len", "(", "seeds", ")", "\n", "", "elif", "config", ".", "learning_setting", "==", "'zero_shot'", ":", "\n", "        ", "res", "=", "trainer", "(", "\n", "EXP_PATH", ",", "\n", "config", ",", "\n", "Processor", ",", "\n", "zero", "=", "True", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "valid_dataset", "=", "valid_dataset", ",", "\n", "test_dataset", "=", "test_dataset", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.experiments.cli.trainer": [[120, 194], ["openprompt.utils.reproduciblity.set_seed", "openprompt.plms.load_plm_from_config", "os.path.exists", "os.mkdir", "openprompt.prompts.load_template", "openprompt.prompts.load_verbalizer", "openprompt.pipeline_base.PromptForClassification", "cli.build_dataloader", "cli.build_dataloader", "cli.build_dataloader", "openprompt.trainer.ClassificationRunner.test", "openprompt.prompts.load_template", "openprompt.pipeline_base.PromptForGeneration", "NotImplementedError", "openprompt.lm_bff_trainer.LMBFFClassificationRunner", "openprompt.trainer.GenerationRunner", "openprompt.trainer.ClassificationRunner.test", "openprompt.protoverb_trainer.ProtoVerbClassificationRunner", "openprompt.trainer.ClassificationRunner", "openprompt.trainer.ClassificationRunner.run", "openprompt.trainer.ClassificationRunner.run"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.reproduciblity.set_seed", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.load_plm_from_config", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_template", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_verbalizer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.test", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_template", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.test", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner.run", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner.run"], ["", "", "def", "trainer", "(", "EXP_PATH", ",", "config", ",", "Processor", ",", "train_dataset", "=", "None", ",", "valid_dataset", "=", "None", ",", "test_dataset", "=", "None", ",", "resume", "=", "None", ",", "test", "=", "None", ",", "zero", "=", "False", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "EXP_PATH", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "EXP_PATH", ")", "\n", "", "config", ".", "logging", ".", "path", "=", "EXP_PATH", "\n", "# set seed", "\n", "set_seed", "(", "config", ".", "reproduce", ".", "seed", ")", "\n", "\n", "# load the pretrained models, its model, tokenizer, and config.", "\n", "plm_model", ",", "plm_tokenizer", ",", "plm_config", ",", "plm_wrapper_class", "=", "load_plm_from_config", "(", "config", ")", "\n", "\n", "\n", "\n", "# define template and verbalizer", "\n", "if", "config", ".", "task", "==", "\"classification\"", ":", "\n", "# define prompt", "\n", "        ", "template", "=", "load_template", "(", "config", "=", "config", ",", "model", "=", "plm_model", ",", "tokenizer", "=", "plm_tokenizer", ",", "plm_config", "=", "plm_config", ")", "\n", "verbalizer", "=", "load_verbalizer", "(", "config", "=", "config", ",", "model", "=", "plm_model", ",", "tokenizer", "=", "plm_tokenizer", ",", "plm_config", "=", "plm_config", ",", "classes", "=", "Processor", ".", "labels", ")", "\n", "# load prompt\u2019s pipeline model", "\n", "prompt_model", "=", "PromptForClassification", "(", "plm_model", ",", "template", ",", "verbalizer", ",", "freeze_plm", "=", "config", ".", "plm", ".", "optimize", ".", "freeze_para", ")", "\n", "\n", "", "elif", "config", ".", "task", "==", "\"generation\"", ":", "\n", "        ", "template", "=", "load_template", "(", "config", "=", "config", ",", "model", "=", "plm_model", ",", "tokenizer", "=", "plm_tokenizer", ",", "plm_config", "=", "plm_config", ")", "\n", "prompt_model", "=", "PromptForGeneration", "(", "plm_model", ",", "template", ",", "freeze_plm", "=", "config", ".", "plm", ".", "optimize", ".", "freeze_para", ",", "gen_config", "=", "config", ".", "generation", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"config.task {config.task} is not implemented yet. Only classification and generation are supported.\"", ")", "\n", "\n", "# process data and get data_loader", "\n", "", "train_dataloader", "=", "build_dataloader", "(", "train_dataset", ",", "template", ",", "plm_tokenizer", ",", "plm_wrapper_class", ",", "config", ",", "\"train\"", ")", "if", "train_dataset", "else", "None", "\n", "valid_dataloader", "=", "build_dataloader", "(", "valid_dataset", ",", "template", ",", "plm_tokenizer", ",", "plm_wrapper_class", ",", "config", ",", "\"dev\"", ")", "if", "valid_dataset", "else", "None", "\n", "test_dataloader", "=", "build_dataloader", "(", "test_dataset", ",", "template", ",", "plm_tokenizer", ",", "plm_wrapper_class", ",", "config", ",", "\"test\"", ")", "if", "test_dataset", "else", "None", "\n", "\n", "if", "config", ".", "task", "==", "\"classification\"", ":", "\n", "        ", "if", "config", ".", "classification", ".", "auto_t", "or", "config", ".", "classification", ".", "auto_v", ":", "\n", "            ", "runner", "=", "LMBFFClassificationRunner", "(", "train_dataset", "=", "train_dataset", ",", "\n", "valid_dataset", "=", "valid_dataset", ",", "\n", "test_dataset", "=", "test_dataset", ",", "\n", "template", "=", "template", ",", "\n", "verbalizer", "=", "verbalizer", ",", "\n", "config", "=", "config", "\n", ")", "\n", "", "elif", "config", ".", "verbalizer", "==", "\"proto_verbalizer\"", ":", "\n", "            ", "runner", "=", "ProtoVerbClassificationRunner", "(", "model", "=", "prompt_model", ",", "\n", "train_dataloader", "=", "train_dataloader", ",", "\n", "valid_dataloader", "=", "valid_dataloader", ",", "\n", "test_dataloader", "=", "test_dataloader", ",", "\n", "id2label", "=", "Processor", ".", "id2label", ",", "\n", "config", "=", "config", "\n", ")", "\n", "", "else", ":", "\n", "            ", "runner", "=", "ClassificationRunner", "(", "model", "=", "prompt_model", ",", "\n", "train_dataloader", "=", "train_dataloader", ",", "\n", "valid_dataloader", "=", "valid_dataloader", ",", "\n", "test_dataloader", "=", "test_dataloader", ",", "\n", "id2label", "=", "Processor", ".", "id2label", ",", "\n", "config", "=", "config", "\n", ")", "\n", "", "", "elif", "config", ".", "task", "==", "\"generation\"", ":", "\n", "        ", "runner", "=", "GenerationRunner", "(", "\n", "model", "=", "prompt_model", ",", "\n", "train_dataloader", "=", "train_dataloader", ",", "\n", "valid_dataloader", "=", "valid_dataloader", ",", "\n", "test_dataloader", "=", "test_dataloader", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "", "if", "zero", ":", "\n", "        ", "res", "=", "runner", ".", "test", "(", ")", "\n", "", "elif", "test", ":", "\n", "        ", "res", "=", "runner", ".", "test", "(", "ckpt", "=", "'best'", ")", "\n", "", "elif", "resume", ":", "\n", "        ", "res", "=", "runner", ".", "run", "(", "ckpt", "=", "'last'", ")", "\n", "", "else", ":", "\n", "        ", "res", "=", "runner", ".", "run", "(", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_config_from_file": [[14, 18], ["yacs.config.CfgNode", "yacs.config.CfgNode.merge_from_file"], "function", ["None"], ["def", "get_config_from_file", "(", "path", ")", ":", "\n", "    ", "cfg", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "merge_from_file", "(", "path", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_user_config": [[19, 30], ["config.get_config_from_file", "default_config.get_default_config.merge_from_other_cfg", "config.get_conditional_config", "default_config.get_default_config"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_config_from_file", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_conditional_config", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.default_config.get_default_config"], ["", "def", "get_user_config", "(", "usr_config_path", ",", "default_config", "=", "None", ")", ":", "\n", "    ", "if", "default_config", "is", "None", ":", "\n", "        ", "config", "=", "get_default_config", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "default_config", "\n", "# get user config", "\n", "", "usr_config", "=", "get_config_from_file", "(", "usr_config_path", ")", "\n", "config", ".", "merge_from_other_cfg", "(", "usr_config", ")", "\n", "\n", "config", "=", "get_conditional_config", "(", "config", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_conditional_config": [[32, 60], ["yacs.config.CfgNode", "list", "config.keys", "len", "queue.pop", "OrderedDict", "config.pop", "queue.pop.copy", "len", "OrderedDict.popitem", "isinstance", "setattr", "isinstance", "isinstance", "yacs.config.CfgNode.keys", "queue.append", "queue.append"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["", "def", "get_conditional_config", "(", "config", ")", ":", "\n", "    ", "r\"\"\"Extract the config entries that do not have ``parent_config`` key.\n    \"\"\"", "\n", "deeper_config", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "# parent key to child node", "\n", "configkeys", "=", "list", "(", "config", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "configkeys", ":", "\n", "        ", "if", "config", "[", "key", "]", "is", "not", "None", "and", "'parent_config'", "in", "config", "[", "key", "]", ":", "\n", "            ", "deeper_config", "[", "key", "]", "=", "config", "[", "key", "]", "\n", "config", ".", "pop", "(", "key", ")", "\n", "\n", "# breadth first search over all config nodes", "\n", "", "", "queue", "=", "[", "config", "]", "\n", "\n", "while", "len", "(", "queue", ")", ">", "0", ":", "\n", "        ", "v", "=", "queue", ".", "pop", "(", "0", ")", "\n", "ordv", "=", "OrderedDict", "(", "v", ".", "copy", "(", ")", ")", "\n", "while", "(", "len", "(", "ordv", ")", ">", "0", ")", ":", "\n", "            ", "leaf", "=", "ordv", ".", "popitem", "(", ")", "\n", "if", "isinstance", "(", "leaf", "[", "1", "]", ",", "str", ")", "and", "leaf", "[", "1", "]", "in", "deeper_config", ".", "keys", "(", ")", ":", "\n", "                ", "retrieved", "=", "deeper_config", "[", "leaf", "[", "1", "]", "]", "\n", "setattr", "(", "config", ",", "leaf", "[", "1", "]", ",", "retrieved", ")", "\n", "if", "isinstance", "(", "retrieved", ",", "CfgNode", ")", ":", "\n", "# also BFS the newly added CfgNode.", "\n", "                    ", "queue", ".", "append", "(", "retrieved", ")", "\n", "", "", "elif", "isinstance", "(", "leaf", "[", "1", "]", ",", "CfgNode", ")", ":", "\n", "                ", "queue", ".", "append", "(", "leaf", "[", "1", "]", ")", "\n", "", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.convert_cfg_to_dict": [[65, 77], ["isinstance", "dict", "dict.items", "type", "print", "config.convert_cfg_to_dict", "type"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.convert_cfg_to_dict"], ["def", "convert_cfg_to_dict", "(", "cfg_node", ",", "key_list", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\" Convert a config node to dictionary \"\"\"", "\n", "if", "not", "isinstance", "(", "cfg_node", ",", "CfgNode", ")", ":", "\n", "        ", "if", "type", "(", "cfg_node", ")", "not", "in", "_VALID_TYPES", ":", "\n", "            ", "print", "(", "\"Key {} with value {} is not a valid type; valid types: {}\"", ".", "format", "(", "\n", "\".\"", ".", "join", "(", "key_list", ")", ",", "type", "(", "cfg_node", ")", ",", "_VALID_TYPES", ")", ",", ")", "\n", "", "return", "cfg_node", "\n", "", "else", ":", "\n", "        ", "cfg_dict", "=", "dict", "(", "cfg_node", ")", "\n", "for", "k", ",", "v", "in", "cfg_dict", ".", "items", "(", ")", ":", "\n", "            ", "cfg_dict", "[", "k", "]", "=", "convert_cfg_to_dict", "(", "v", ",", "key_list", "+", "[", "k", "]", ")", "\n", "", "return", "cfg_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.add_cfg_to_argparser": [[78, 97], ["isinstance", "config.add_cfg_to_argparser", "type", "parser.add_argument", "type", "parser.add_argument", "type", "type", "parser.add_argument", "type", "type", "type", "parser.add_argument", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.add_cfg_to_argparser"], ["", "", "def", "add_cfg_to_argparser", "(", "cfg", ",", "parser", ",", "prefix", "=", "None", ")", ":", "\n", "    ", "r\"\"\"To support argument parser style in addition to yaml style\n    \"\"\"", "\n", "for", "key", "in", "cfg", ":", "\n", "        ", "value", "=", "cfg", "[", "key", "]", "\n", "full_key_name", "=", "prefix", "+", "\".\"", "+", "key", "if", "prefix", "is", "not", "None", "else", "key", "\n", "if", "isinstance", "(", "value", ",", "CfgNode", ")", ":", "\n", "            ", "add_cfg_to_argparser", "(", "value", ",", "parser", "=", "parser", ",", "prefix", "=", "full_key_name", ")", "\n", "", "else", ":", "\n", "            ", "if", "type", "(", "value", ")", "in", "[", "str", ",", "int", ",", "float", "]", ":", "\n", "                ", "parser", ".", "add_argument", "(", "\"--\"", "+", "full_key_name", ",", "type", "=", "type", "(", "value", ")", ",", "default", "=", "value", ")", "\n", "", "elif", "type", "(", "value", ")", "in", "[", "tuple", ",", "list", "]", ":", "\n", "                ", "parser", ".", "add_argument", "(", "\"--\"", "+", "full_key_name", ",", "type", "=", "type", "(", "value", ")", ",", "default", "=", "value", ",", "nargs", "=", "\"+\"", ")", "\n", "", "elif", "type", "(", "value", ")", "==", "bool", ":", "\n", "                ", "parser", ".", "add_argument", "(", "\"--\"", "+", "full_key_name", ",", "action", "=", "'store_{}'", ".", "format", "(", "not", "value", ")", ".", "lower", "(", ")", ")", "\n", "", "elif", "type", "(", "value", ")", "==", "type", "(", "None", ")", ":", "\n", "                ", "parser", ".", "add_argument", "(", "\"--\"", "+", "full_key_name", ",", "default", "=", "None", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"The type of config value is not supported\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.update_cfg_with_argparser": [[99, 114], ["isinstance", "config.update_cfg_with_argparser", "getattr", "type", "type", "print"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.update_cfg_with_argparser"], ["", "", "", "", "def", "update_cfg_with_argparser", "(", "cfg", ",", "args", ",", "prefix", "=", "None", ")", ":", "\n", "    ", "r\"\"\"To support update cfg with command line\n    \"\"\"", "\n", "for", "key", "in", "cfg", ":", "\n", "        ", "value", "=", "cfg", "[", "key", "]", "\n", "full_key_name", "=", "prefix", "+", "\".\"", "+", "key", "if", "prefix", "is", "not", "None", "else", "key", "\n", "if", "isinstance", "(", "value", ",", "CfgNode", ")", ":", "\n", "            ", "update_cfg_with_argparser", "(", "value", ",", "args", ",", "prefix", "=", "full_key_name", ")", "\n", "", "else", ":", "\n", "            ", "v", "=", "getattr", "(", "args", ",", "full_key_name", ")", "\n", "if", "type", "(", "v", ")", "!=", "type", "(", "value", ")", ":", "\n", "                ", "raise", "TypeError", "\n", "", "if", "v", "!=", "value", ":", "\n", "                ", "cfg", "[", "key", "]", "=", "v", "\n", "print", "(", "\"Update key {}, value {} -> {}\"", ".", "format", "(", "full_key_name", ",", "value", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.save_config_to_yaml": [[116, 122], ["os.path.join", "openprompt.utils.logging.logger.info", "open", "redirect_stdout", "print", "config.dump"], "function", ["None"], ["", "", "", "", "def", "save_config_to_yaml", "(", "config", ")", ":", "\n", "    ", "from", "contextlib", "import", "redirect_stdout", "\n", "saved_yaml_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "logging", ".", "path", ",", "\"config.yaml\"", ")", "\n", "with", "open", "(", "saved_yaml_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "with", "redirect_stdout", "(", "f", ")", ":", "print", "(", "config", ".", "dump", "(", ")", ")", "\n", "", "logger", ".", "info", "(", "\"Config saved as {}\"", ".", "format", "(", "saved_yaml_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_config": [[123, 139], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "config.get_user_config", "config.add_cfg_to_argparser", "argparse.ArgumentParser.parse_args", "config.update_cfg_with_argparser", "openprompt.utils.utils.check_config_conflicts"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.get_user_config", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.add_cfg_to_argparser", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.update_cfg_with_argparser", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.check_config_conflicts"], ["", "def", "get_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Global Config Argument Parser\"", ",", "allow_abbrev", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_yaml\"", ",", "required", "=", "True", ",", "type", "=", "str", ",", "help", "=", "'the configuration file for this experiment.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume\"", ",", "type", "=", "str", ",", "help", "=", "'a specified logging path to resume training.\\\n           It will fall back to run from initialization if no latest checkpoint are found.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "type", "=", "str", ",", "help", "=", "'a specified logging path to test'", ")", "\n", "args", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "config", "=", "get_user_config", "(", "args", ".", "config_yaml", ")", "\n", "\n", "add_cfg_to_argparser", "(", "config", ",", "parser", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "update_cfg_with_argparser", "(", "config", ",", "args", ")", "\n", "check_config_conflicts", "(", "config", ")", "\n", "# print(config)", "\n", "return", "config", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptDataLoader.__init__": [[44, 114], ["hasattr", "hasattr", "hasattr", "pipeline_base.PromptDataLoader.wrap", "pipeline_base.PromptDataLoader.tokenize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "tokenizer_wrapper_class", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.RandomSampler", "RuntimeError", "RuntimeError", "openprompt.utils.signature"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptDataLoader.wrap", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptDataLoader.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ":", "Union", "[", "Dataset", ",", "List", "]", ",", "\n", "template", ":", "Template", ",", "\n", "tokenizer_wrapper", ":", "Optional", "[", "TokenizerWrapper", "]", "=", "None", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", "=", "None", ",", "\n", "tokenizer_wrapper_class", "=", "None", ",", "\n", "verbalizer", ":", "Optional", "[", "Verbalizer", "]", "=", "None", ",", "\n", "max_seq_length", ":", "Optional", "[", "str", "]", "=", "512", ",", "\n", "batch_size", ":", "Optional", "[", "int", "]", "=", "1", ",", "\n", "shuffle", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "teacher_forcing", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "decoder_max_length", ":", "Optional", "[", "int", "]", "=", "-", "1", ",", "\n", "predict_eos_token", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "truncate_method", ":", "Optional", "[", "str", "]", "=", "\"tail\"", ",", "\n", "drop_last", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "assert", "hasattr", "(", "dataset", ",", "\"__iter__\"", ")", ",", "f\"The dataset must have __iter__ method. dataset is {dataset}\"", "\n", "assert", "hasattr", "(", "dataset", ",", "\"__len__\"", ")", ",", "f\"The dataset must have __len__ method. dataset is {dataset}\"", "\n", "self", ".", "raw_dataset", "=", "dataset", "\n", "\n", "self", ".", "wrapped_dataset", "=", "[", "]", "\n", "self", ".", "tensor_dataset", "=", "[", "]", "\n", "self", ".", "template", "=", "template", "\n", "self", ".", "verbalizer", "=", "verbalizer", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "teacher_forcing", "=", "teacher_forcing", "\n", "\n", "if", "tokenizer_wrapper", "is", "None", ":", "\n", "            ", "if", "tokenizer_wrapper_class", "is", "None", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Either wrapped_tokenizer or tokenizer_wrapper_class should be specified.\"", ")", "\n", "", "if", "tokenizer", "is", "None", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"No tokenizer specified to instantiate tokenizer_wrapper.\"", ")", "\n", "\n", "", "tokenizer_wrapper_init_keys", "=", "signature", "(", "tokenizer_wrapper_class", ".", "__init__", ")", ".", "args", "\n", "prepare_kwargs", "=", "{", "\n", "\"max_seq_length\"", ":", "max_seq_length", ",", "\n", "\"truncate_method\"", ":", "truncate_method", ",", "\n", "\"decoder_max_length\"", ":", "decoder_max_length", ",", "\n", "\"predict_eos_token\"", ":", "predict_eos_token", ",", "\n", "\"tokenizer\"", ":", "tokenizer", ",", "\n", "**", "kwargs", ",", "\n", "}", "\n", "\n", "to_pass_kwargs", "=", "{", "key", ":", "prepare_kwargs", "[", "key", "]", "for", "key", "in", "prepare_kwargs", "if", "key", "in", "tokenizer_wrapper_init_keys", "}", "\n", "self", ".", "tokenizer_wrapper", "=", "tokenizer_wrapper_class", "(", "**", "to_pass_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer_wrapper", "=", "tokenizer_wrapper", "\n", "\n", "# check the satisfiability of each component", "\n", "", "assert", "hasattr", "(", "self", ".", "template", ",", "'wrap_one_example'", ")", ",", "\"Your prompt has no function variable \\\n                                                         named wrap_one_example\"", "\n", "\n", "# process", "\n", "self", ".", "wrap", "(", ")", "\n", "self", ".", "tokenize", "(", ")", "\n", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "sampler", "=", "RandomSampler", "(", "self", ".", "tensor_dataset", ")", "\n", "", "else", ":", "\n", "            ", "sampler", "=", "None", "\n", "\n", "", "self", ".", "dataloader", "=", "DataLoader", "(", "\n", "self", ".", "tensor_dataset", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "InputFeatures", ".", "collate_fct", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptDataLoader.wrap": [[117, 130], ["isinstance", "isinstance", "enumerate", "len", "pipeline_base.PromptDataLoader.template.wrap_one_example", "pipeline_base.PromptDataLoader.wrapped_dataset.append", "hasattr", "pipeline_base.PromptDataLoader.verbalizer.wrap_one_example"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.wrap_one_example", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.wrap_one_example"], ["", "def", "wrap", "(", "self", ")", ":", "\n", "        ", "r\"\"\"A simple interface to pass the examples to prompt, and wrap the text with template.\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "raw_dataset", ",", "Dataset", ")", "or", "isinstance", "(", "self", ".", "raw_dataset", ",", "List", ")", ":", "\n", "            ", "assert", "len", "(", "self", ".", "raw_dataset", ")", ">", "0", ",", "'The dataset to be wrapped is empty.'", "\n", "# for idx, example in tqdm(enumerate(self.raw_dataset),desc='Wrapping'):", "\n", "for", "idx", ",", "example", "in", "enumerate", "(", "self", ".", "raw_dataset", ")", ":", "\n", "                ", "if", "self", ".", "verbalizer", "is", "not", "None", "and", "hasattr", "(", "self", ".", "verbalizer", ",", "'wrap_one_example'", ")", ":", "# some verbalizer may also process the example.", "\n", "                    ", "example", "=", "self", ".", "verbalizer", ".", "wrap_one_example", "(", "example", ")", "\n", "", "wrapped_example", "=", "self", ".", "template", ".", "wrap_one_example", "(", "example", ")", "\n", "self", ".", "wrapped_dataset", ".", "append", "(", "wrapped_example", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptDataLoader.tokenize": [[131, 139], ["tqdm.std.tqdm.std.tqdm", "enumerate", "openprompt.data_utils.InputFeatures().to_tensor", "pipeline_base.PromptDataLoader.tensor_dataset.append", "openprompt.data_utils.InputFeatures", "pipeline_base.PromptDataLoader.tokenizer_wrapper.tokenize_one_example"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_tensor", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.tokenize_one_example"], ["", "", "def", "tokenize", "(", "self", ")", "->", "None", ":", "\n", "        ", "r\"\"\"Pass the wrapped text into a prompt-specialized tokenizer,\n           the true PretrainedTokenizer inside the tokenizer is flexible, e.g. AlBert, Bert, T5,...\n        \"\"\"", "\n", "for", "idx", ",", "wrapped_example", "in", "tqdm", "(", "enumerate", "(", "self", ".", "wrapped_dataset", ")", ",", "desc", "=", "'tokenizing'", ")", ":", "\n", "# for idx, wrapped_example in enumerate(self.wrapped_dataset):", "\n", "            ", "inputfeatures", "=", "InputFeatures", "(", "**", "self", ".", "tokenizer_wrapper", ".", "tokenize_one_example", "(", "wrapped_example", ",", "self", ".", "teacher_forcing", ")", ",", "**", "wrapped_example", "[", "1", "]", ")", ".", "to_tensor", "(", ")", "\n", "self", ".", "tensor_dataset", ".", "append", "(", "inputfeatures", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptDataLoader.__len__": [[140, 142], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataloader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptDataLoader.__iter__": [[143, 145], ["pipeline_base.PromptDataLoader.dataloader.__iter__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__iter__"], ["", "def", "__iter__", "(", "self", ",", ")", ":", "\n", "        ", "return", "self", ".", "dataloader", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.__init__": [[158, 181], ["torch.Module.__init__", "pipeline_base.PromptModel._prepare_main_input_name", "pipeline_base.PromptModel.plm.parameters", "pipeline_base.PromptModel.plm.eval", "pipeline_base.PromptModel.plm.parameters", "openprompt.utils.signature"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel._prepare_main_input_name", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature"], ["def", "__init__", "(", "self", ",", "\n", "plm", ":", "PreTrainedModel", ",", "\n", "template", ":", "Template", ",", "\n", "freeze_plm", ":", "bool", "=", "False", ",", "\n", "plm_eval_mode", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "plm", "=", "plm", "\n", "self", ".", "template", "=", "template", "\n", "self", ".", "freeze_plm", "=", "freeze_plm", "\n", "self", ".", "plm_eval_mode", "=", "plm_eval_mode", "\n", "if", "freeze_plm", ":", "\n", "            ", "for", "param", "in", "self", ".", "plm", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "if", "plm_eval_mode", ":", "\n", "            ", "self", ".", "plm", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "plm", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "# get model's forward function's keywords", "\n", "", "", "self", ".", "forward_keys", "=", "signature", "(", "self", ".", "plm", ".", "forward", ")", ".", "args", "\n", "\n", "self", ".", "_prepare_main_input_name", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel._prepare_main_input_name": [[182, 192], ["hasattr", "hasattr", "getattr"], "methods", ["None"], ["", "def", "_prepare_main_input_name", "(", "self", ")", ":", "\n", "        ", "model", "=", "self", ".", "plm", "\n", "if", "hasattr", "(", "model", ",", "\"encoder\"", ")", "and", "hasattr", "(", "model", ".", "encoder", ",", "\"main_input_name\"", ")", ":", "\n", "            ", "if", "model", ".", "encoder", ".", "main_input_name", "!=", "model", ".", "main_input_name", ":", "\n", "                ", "main_input_name", "=", "model", ".", "encoder", ".", "main_input_name", "\n", "", "else", ":", "\n", "                ", "main_input_name", "=", "model", ".", "main_input_name", "\n", "", "", "else", ":", "\n", "            ", "main_input_name", "=", "getattr", "(", "model", ",", "\"main_input_name\"", ",", "\"input_ids\"", ")", "\n", "", "self", ".", "main_input_name", "=", "main_input_name", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.train": [[193, 201], ["pipeline_base.PromptModel.named_children", "isinstance", "ValueError", "module.train"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.train"], ["", "def", "train", "(", "self", ",", "mode", ":", "bool", "=", "True", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "mode", ",", "bool", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"training mode is expected to be boolean\"", ")", "\n", "", "self", ".", "training", "=", "mode", "\n", "for", "name", ",", "module", "in", "self", ".", "named_children", "(", ")", ":", "\n", "            ", "if", "not", "(", "self", ".", "plm_eval_mode", "and", "'plm'", "in", "name", "and", "mode", ")", ":", "\n", "                ", "module", ".", "train", "(", "mode", ")", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.forward": [[202, 215], ["pipeline_base.PromptModel.template.process_batch", "pipeline_base.PromptModel.plm", "pipeline_base.PromptModel.template.post_processing_outputs"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.process_batch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.plm", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_template.SoftTemplate.post_processing_outputs"], ["", "def", "forward", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n        This is a forward method to make wrapped input data go through the model, and return the output logits.\n        Typically, this function aims to predict the ``<mask>`` position.\n\n        Args:\n            batch (:obj:`Union[Dict, InputFeatures]`): The input features of batchified data sequences.\n        \"\"\"", "\n", "batch", "=", "self", ".", "template", ".", "process_batch", "(", "batch", ")", "\n", "input_batch", "=", "{", "key", ":", "batch", "[", "key", "]", "for", "key", "in", "batch", "if", "key", "in", "self", ".", "forward_keys", "}", "\n", "outputs", "=", "self", ".", "plm", "(", "**", "input_batch", ",", "output_hidden_states", "=", "True", ")", "\n", "outputs", "=", "self", ".", "template", ".", "post_processing_outputs", "(", "outputs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.prepare_model_inputs": [[216, 222], ["pipeline_base.PromptModel.template.process_batch"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.process_batch"], ["", "def", "prepare_model_inputs", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "Dict", ":", "\n", "        ", "r\"\"\"Will be used in generation\n        \"\"\"", "\n", "batch", "=", "self", ".", "template", ".", "process_batch", "(", "batch", ")", "\n", "input_batch", "=", "{", "key", ":", "batch", "[", "key", "]", "for", "key", "in", "batch", "if", "key", "in", "self", ".", "forward_keys", "}", "\n", "return", "input_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.__init__": [[235, 245], ["torch.Module.__init__", "pipeline_base.PromptModel"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "plm", ":", "PreTrainedModel", ",", "\n", "template", ":", "Template", ",", "\n", "verbalizer", ":", "Verbalizer", ",", "\n", "freeze_plm", ":", "bool", "=", "False", ",", "\n", "plm_eval_mode", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "prompt_model", "=", "PromptModel", "(", "plm", ",", "template", ",", "freeze_plm", ",", "plm_eval_mode", ")", "\n", "self", ".", "verbalizer", "=", "verbalizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.plm": [[246, 249], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "plm", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "prompt_model", ".", "plm", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.template": [[250, 253], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "template", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "prompt_model", ".", "template", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.device": [[254, 258], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"Register the device parameter.\"\"\"", "\n", "return", "self", ".", "plm", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.extract_at_mask": [[259, 284], ["outputs.view.view.view", "outputs.view.view.view", "torch.where", "torch.where", "torch.where", "torch.where"], "methods", ["None"], ["", "def", "extract_at_mask", "(", "self", ",", "\n", "outputs", ":", "torch", ".", "Tensor", ",", "\n", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", ":", "\n", "        ", "r\"\"\"Get outputs at all <mask> token\n        E.g., project the logits of shape\n        (``batch_size``, ``max_seq_length``, ``vocab_size``)\n        into logits of shape (if num_mask_token > 1)\n        (``batch_size``, ``num_mask_token``, ``vocab_size``)\n        or into logits of shape (if ``num_mask_token`` = 1)\n        (``batch_size``, ``vocab_size``).\n\n        Args:\n            outputs (:obj:`torch.Tensor`): The original outputs (maybe process by verbalizer's\n                 `gather_outputs` before) etc. of the whole sequence.\n            batch (:obj:`Union[Dict, InputFeatures]`): The original batch\n\n        Returns:\n            :obj:`torch.Tensor`: The extracted outputs of ``<mask>`` tokens.\n\n        \"\"\"", "\n", "outputs", "=", "outputs", "[", "torch", ".", "where", "(", "batch", "[", "'loss_ids'", "]", ">", "0", ")", "]", "\n", "outputs", "=", "outputs", ".", "view", "(", "batch", "[", "'loss_ids'", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "outputs", ".", "shape", "[", "1", "]", ")", "\n", "if", "outputs", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "            ", "outputs", "=", "outputs", ".", "view", "(", "outputs", ".", "shape", "[", "0", "]", ",", "outputs", ".", "shape", "[", "2", "]", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.forward": [[285, 303], ["pipeline_base.PromptForClassification.prompt_model", "pipeline_base.PromptForClassification.verbalizer.gather_outputs", "isinstance", "pipeline_base.PromptForClassification.verbalizer.process_outputs", "pipeline_base.PromptForClassification.extract_at_mask", "pipeline_base.PromptForClassification.extract_at_mask"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.gather_outputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.process_outputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.extract_at_mask", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.extract_at_mask"], ["", "def", "forward", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n        Get the logits of label words.\n\n        Args:\n            batch (:obj:`Union[Dict, InputFeatures]`): The original batch\n\n        Returns:\n            :obj:`torch.Tensor`: The logits of the label words (obtained by the current verbalizer).\n        \"\"\"", "\n", "outputs", "=", "self", ".", "prompt_model", "(", "batch", ")", "\n", "outputs", "=", "self", ".", "verbalizer", ".", "gather_outputs", "(", "outputs", ")", "\n", "if", "isinstance", "(", "outputs", ",", "tuple", ")", ":", "\n", "            ", "outputs_at_mask", "=", "[", "self", ".", "extract_at_mask", "(", "output", ",", "batch", ")", "for", "output", "in", "outputs", "]", "\n", "", "else", ":", "\n", "            ", "outputs_at_mask", "=", "self", ".", "extract_at_mask", "(", "outputs", ",", "batch", ")", "\n", "", "label_words_logits", "=", "self", ".", "verbalizer", ".", "process_outputs", "(", "outputs_at_mask", ",", "batch", "=", "batch", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.predict": [[304, 306], ["None"], "methods", ["None"], ["", "def", "predict", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.forward_without_verbalize": [[307, 312], ["pipeline_base.PromptForClassification.prompt_model", "pipeline_base.PromptForClassification.verbalizer.gather_outputs", "pipeline_base.PromptForClassification.extract_at_mask"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.gather_outputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.extract_at_mask"], ["", "def", "forward_without_verbalize", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "outputs", "=", "self", ".", "prompt_model", "(", "batch", ")", "\n", "outputs", "=", "self", ".", "verbalizer", ".", "gather_outputs", "(", "outputs", ")", "\n", "outputs_at_mask", "=", "self", ".", "extract_at_mask", "(", "outputs", ",", "batch", ")", "\n", "return", "outputs_at_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.tokenizer": [[313, 318], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "tokenizer", "(", "self", ")", ":", "\n", "        ", "r'''Utility property, to get the tokenizer more easily.\n        '''", "\n", "return", "self", ".", "verbalizer", ".", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.parallelize": [[336, 346], ["hasattr", "pipeline_base.PromptForClassification.plm.parallelize", "pipeline_base.PromptForClassification.template.cuda", "pipeline_base.PromptForClassification.verbalizer.cuda", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.parallelize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda"], ["", "def", "parallelize", "(", "self", ",", "device_map", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Parallelize the model across device\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "plm", ",", "\"parallelize\"", ")", ":", "\n", "            ", "self", ".", "plm", ".", "parallelize", "(", "device_map", ")", "\n", "self", ".", "device_map", "=", "self", ".", "plm", ".", "device_map", "\n", "self", ".", "template", ".", "cuda", "(", ")", "\n", "self", ".", "verbalizer", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"parallelize method was not implemented for this plm.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.deparallelize": [[347, 357], ["hasattr", "pipeline_base.PromptForClassification.plm.deparallelize", "pipeline_base.PromptForClassification.template.cpu", "pipeline_base.PromptForClassification.verbalizer.cpu", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.deparallelize"], ["", "", "def", "deparallelize", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Deparallelize the model across device\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "plm", ",", "\"deparallelize\"", ")", ":", "\n", "            ", "self", ".", "plm", ".", "deparallelize", "(", ")", "\n", "self", ".", "device_map", "=", "None", "\n", "self", ".", "template", ".", "cpu", "(", ")", "\n", "self", ".", "verbalizer", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"parallelize method was not implemented for this plm.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.__init__": [[372, 397], ["super().__init__", "pipeline_base.PromptModel", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "setattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "plm", ":", "PreTrainedModel", ",", "\n", "template", ":", "Template", ",", "\n", "freeze_plm", ":", "bool", "=", "False", ",", "\n", "plm_eval_mode", ":", "bool", "=", "False", ",", "\n", "gen_config", ":", "Optional", "[", "CfgNode", "]", "=", "None", ",", "\n", "tokenizer", ":", "Optional", "[", "PreTrainedTokenizer", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "freeze_plm", "=", "freeze_plm", "\n", "if", "tokenizer", "is", "None", ":", "\n", "            ", "assert", "template", ".", "tokenizer", "is", "not", "None", ",", "\"Tokenizer can't be set from input args or template\"", "\n", "self", ".", "tokenizer", "=", "template", ".", "tokenizer", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "", "self", ".", "prompt_model", "=", "PromptModel", "(", "plm", ",", "template", ",", "freeze_plm", ",", "plm_eval_mode", ")", "\n", "\n", "self", ".", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "self", ".", "config", "=", "plm", ".", "config", "\n", "if", "gen_config", ":", "\n", "            ", "for", "key", "in", "gen_config", ":", "\n", "                ", "setattr", "(", "self", ".", "config", ",", "key", ",", "gen_config", "[", "key", "]", ")", "\n", "", "", "self", ".", "in_generation_function", "=", "False", "\n", "\n", "self", ".", "main_input_name", "=", "self", ".", "prompt_model", ".", "main_input_name", "# for transformers 4.17.0 and higher.", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.plm": [[398, 401], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "plm", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "prompt_model", ".", "plm", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.template": [[402, 405], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "template", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "prompt_model", ".", "template", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.device": [[406, 409], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "plm", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.shift_logits_and_labels": [[411, 436], ["logits[].contiguous", "loss_ids[].contiguous", "reference_ids[].contiguous", "torch.where", "torch.where", "torch.where", "torch.where"], "methods", ["None"], ["", "def", "shift_logits_and_labels", "(", "self", ",", "\n", "logits", ",", "\n", "loss_ids", ",", "\n", "reference_ids", ")", ":", "\n", "\n", "        ", "r\"\"\"\n        Left shift the label, and make label of the positions that are\n        not loss position to -100, which is the ignore index in pytorch's\n        loss function.\n\n        Args:\n            logits (:obj:`torch.Tensor`):\n            batch (:obj:`InputFeatures`): The input features of batchified data sequences.\n\n        Returns:\n            shift_logits (:obj:`torch.Tensor`):\n            shift_input_ids (:obj:`List[int]`):\n\n        \"\"\"", "\n", "\n", "shift_logits", "=", "logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_loss_ids", "=", "loss_ids", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_input_ids", "=", "reference_ids", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_input_ids", "=", "torch", ".", "where", "(", "shift_loss_ids", ">", "0", ",", "shift_input_ids", ",", "-", "100", ")", "\n", "return", "shift_logits", ",", "shift_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.forward": [[437, 450], ["pipeline_base.PromptForGeneration.plm.forward", "pipeline_base.PromptForGeneration._forward"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.forward", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration._forward"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"In generation process, it will use the plm's forward function.\n        This is because, in the first step we will directly call the process_batch function to\n        generate initial input with the template, after that the all template\n        have been processed into the past_key_value,\n        then we can use the normal generation function.\n        In learning process, the forward is linked to ``_forward`` functions.\n        in which the loss will be calculated for all the positions in the same time.\n        \"\"\"", "\n", "if", "self", ".", "in_generation_function", ":", "\n", "            ", "return", "self", ".", "plm", ".", "forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration._forward": [[451, 473], ["pipeline_base.PromptForGeneration.prompt_model", "pipeline_base.PromptForGeneration.shift_logits_and_labels", "pipeline_base.PromptForGeneration.loss_fct", "loss.mean.mean.view().sum", "loss.mean.mean.mean", "logits.view", "labels.view", "logits.size", "loss.mean.mean.view"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.shift_logits_and_labels"], ["", "", "def", "_forward", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n        This is the forward method of the training of generation in prompt-learning framework.\n\n        Args:\n            batch (:obj:`Union[Dict, InputFeatures]`): The input features of batchified data sequences.\n\n        Returns:\n            loss(:obj:torch.Tensor): The loss of the current generation procedure.\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "            ", "reference_ids", "=", "batch", "[", "'decoder_input_ids'", "]", "\n", "", "else", ":", "\n", "            ", "reference_ids", "=", "batch", "[", "'input_ids'", "]", "# in case in some template, these field is dropped", "\n", "", "outputs", "=", "self", ".", "prompt_model", "(", "batch", ")", "\n", "logits", "=", "outputs", ".", "logits", "\n", "logits", ",", "labels", "=", "self", ".", "shift_logits_and_labels", "(", "logits", ",", "batch", "[", "'loss_ids'", "]", ",", "reference_ids", ")", "\n", "batch_size", ",", "seq_len", ",", "vocab_size", "=", "logits", ".", "shape", "\n", "loss", "=", "self", ".", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", "=", "loss", ".", "view", "(", "batch_size", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "# TODO support more objectives", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.generate": [[475, 527], ["batch[].argmax", "batch[].size", "batch[].size", "super().generate", "output_sequences.cpu().tolist.cpu().tolist.cpu().tolist", "pipeline_base.PromptForGeneration.post_processing", "batch[].size", "batch[].size", "range", "pipeline_base.PromptForGeneration.post_processing", "openprompt.utils.logging.logger.info", "generation_kwargs.items", "batch[].argmax.min", "batch[].argmax.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "super().generate", "output_sequences.cpu().tolist.cpu().tolist.extend", "output_sequences.cpu().tolist.cpu().tolist.cpu", "super().generate.cpu().tolist", "torch.sum.cpu().tolist", "torch.sum.cpu().tolist", "openprompt.utils.signature", "batch[].argmax.min", "isinstance", "super().generate.cpu", "torch.sum.cpu", "torch.sum.cpu", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.post_processing", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.post_processing", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature"], ["", "def", "generate", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ",", "verbose", ":", "Optional", "[", "bool", "]", "=", "False", ",", "**", "generation_kwargs", ")", ":", "\n", "        ", "r\"\"\" This function wraps the generate() methods in parent class ``GenerationMixin``.\n        Forward uses the ``PretrainedModel``'s forward method.\n        generation_kwargs include all the parameters that are passed in to\n        ``transformers.generation_util.GenerationMixin.generate``\n\n        Args:\n            batch (:obj:`Union[Dict, InputFeatures]`): The input features of batchified data sequences.\n            verbose (:obj:`Optional[bool]`): Set to true to verbose the generated sentence.\n\n        Returns:\n            output_sequences (:obj:`List[torch.Tensor]`): The raw sequences generated by the generation model.\n            generated_sentences (:obj:`List[torch.Tensor]`): The generated sentences that have been post-processed.\n        \"\"\"", "\n", "input_generation_kwargs", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "generation_kwargs", ".", "items", "(", ")", "if", "key", "in", "signature", "(", "GenerationMixin", ".", "generate", ")", ".", "args", "}", "\n", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "            ", "loss_ids_start", "=", "batch", "[", "'loss_ids'", "]", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", "assert", "loss_ids_start", ".", "min", "(", ")", "==", "loss_ids_start", ".", "max", "(", ")", ",", "\"The generation start from different position in a batch.\"", "\n", "batch", "[", "'decoder_input_ids'", "]", "=", "batch", "[", "'decoder_input_ids'", "]", "[", ":", ",", ":", "loss_ids_start", ".", "min", "(", ")", "+", "1", "]", "\n", "input_length", "=", "batch", "[", "'decoder_input_ids'", "]", ".", "size", "(", "1", ")", "\n", "batch_size", "=", "batch", "[", "'decoder_input_ids'", "]", ".", "size", "(", "0", ")", "\n", "\n", "self", ".", "generate_ith_token", "=", "0", "\n", "self", ".", "in_generation_function", "=", "True", "\n", "output_sequences", "=", "super", "(", ")", ".", "generate", "(", "**", "batch", ",", "**", "input_generation_kwargs", ",", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", ",", "eos_token_id", "=", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "self", ".", "in_generation_function", "=", "False", "\n", "output_sequences", "=", "output_sequences", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "generated_sentences", "=", "self", ".", "post_processing", "(", "output_sequences", "=", "output_sequences", ",", "input_lengths", "=", "input_length", ")", "\n", "", "else", ":", "\n", "            ", "input_length", "=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "1", ")", "\n", "batch_size", "=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "\n", "# Currently huggingface transformers only support single sample generation, or padding to the left (instead of the right).", "\n", "# because it will only extract the last position of the output", "\n", "# generate one_by_one", "\n", "if", "'input_ids_len'", "in", "batch", ":", "\n", "                ", "input_real_lens", "=", "batch", "[", "'input_ids_len'", "]", "\n", "", "else", ":", "\n", "                ", "input_real_lens", "=", "torch", ".", "sum", "(", "(", "batch", "[", "'input_ids'", "]", "!=", "self", ".", "tokenizer", ".", "pad_token_id", ")", ".", "to", "(", "torch", ".", "int", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "output_sequences", "=", "[", "]", "\n", "for", "instance_id", "in", "range", "(", "batch_size", ")", ":", "\n", "# remove the pad token", "\n", "                ", "instance", "=", "{", "key", ":", "batch", "[", "key", "]", "[", "instance_id", ":", "instance_id", "+", "1", "]", "[", ":", ",", ":", "input_real_lens", "[", "instance_id", "]", "]", "for", "key", "in", "batch", "if", "isinstance", "(", "batch", "[", "key", "]", ",", "torch", ".", "Tensor", ")", "and", "batch", "[", "key", "]", ".", "shape", "[", ":", "2", "]", "==", "torch", ".", "Size", "(", "[", "batch_size", ",", "input_length", "]", ")", "}", "\n", "self", ".", "generate_ith_token", "=", "0", "\n", "self", ".", "in_generation_function", "=", "True", "\n", "output_sequence", "=", "super", "(", ")", ".", "generate", "(", "**", "instance", ",", "**", "input_generation_kwargs", ",", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", ",", "eos_token_id", "=", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "self", ".", "in_generation_function", "=", "False", "\n", "output_sequences", ".", "extend", "(", "output_sequence", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "# TODO: to support generate multiple sentence", "\n", "", "generated_sentences", "=", "self", ".", "post_processing", "(", "output_sequences", "=", "output_sequences", ",", "input_lengths", "=", "input_real_lens", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Generated:{generated_sentences}\"", ")", "\n", "", "return", "output_sequences", ",", "generated_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.post_processing": [[530, 557], ["enumerate", "type", "pipeline_base.PromptForGeneration.strip", "generated_sentences.append", "len", "hasattr", "pipeline_base.PromptForGeneration.tokenizer.decode", "pipeline_base.PromptForGeneration.find", "pipeline_base.PromptForGeneration.tokenizer.decode"], "methods", ["None"], ["", "def", "post_processing", "(", "self", ",", "output_sequences", ",", "input_lengths", ")", ":", "\n", "        ", "r\"\"\"\n            Post-process the sequences generated by the generation model.\n\n            Args:\n                output_sequences (:obj:`torch.Tensor`): The raw sequences generated by the generation model.\n                input_lengths (:obj:`int` or `list`): The length(s) of the input sequence.\n\n            Returns:\n                :obj:`List`: The generated sentences that have been post-processed.\n        \"\"\"", "\n", "generated_sentences", "=", "[", "]", "\n", "if", "type", "(", "input_lengths", ")", "==", "int", ":", "\n", "            ", "input_lengths", "=", "[", "input_lengths", "]", "*", "len", "(", "output_sequences", ")", "\n", "", "for", "sent_id", ",", "seq", "in", "enumerate", "(", "output_sequences", ")", ":", "\n", "            ", "seq", "=", "seq", "[", "input_lengths", "[", "sent_id", "]", ":", "]", "\n", "\n", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"eos_token\"", ")", "and", "self", ".", "tokenizer", ".", "eos_token", "is", "not", "None", ":", "\n", "                ", "text_output", "=", "self", ".", "tokenizer", ".", "decode", "(", "seq", ",", "clean_up_tokenization_spaces", "=", "True", ",", "skip_special_tokens", "=", "False", ")", "\n", "idx", "=", "text_output", ".", "find", "(", "self", ".", "tokenizer", ".", "eos_token", ")", "\n", "if", "idx", ">=", "0", ":", "\n", "                    ", "text_output", "=", "text_output", "[", ":", "idx", "]", "\n", "", "", "else", ":", "\n", "                ", "text_output", "=", "self", ".", "tokenizer", ".", "decode", "(", "seq", ",", "clean_up_tokenization_spaces", "=", "True", ",", "skip_special_tokens", "=", "True", ")", "\n", "", "text_output", "=", "text_output", ".", "strip", "(", ")", "\n", "generated_sentences", ".", "append", "(", "text_output", ")", "\n", "", "return", "generated_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.prepare_inputs_for_generation": [[560, 583], ["openprompt.data_utils.InputFeatures", "pipeline_base.PromptForGeneration.prompt_model.prepare_model_inputs", "pipeline_base.PromptForGeneration.plm.prepare_inputs_for_generation"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.prepare_model_inputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.prepare_inputs_for_generation"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "**", "model_kwargs", ")", ":", "\n", "        ", "r\"\"\"This function wraps the ``prepare_inputs_for_generation`` function in the huggingface transformers.\n\n        When the `past` not in model_kwargs, we prepare the input from scratch.\n        When `past` is in model_kwargs, we don't need to prepare the template wrapped input,\n        instead we use the inner pretrain_models' function to prepare the next step's input.\n        `model_kwargs` includes all the argument passed in the `batch`: InputFeatures, except ``input_ids``\n        , as long as they do not conflict with keywords in ``generation_kwargs``.    if 'past' not in model_kwargs: # the past_key_value not in model_kwargs, then we need to prepare input from scrath\n        , as long as they do not conflict with keywords in ``generation_kwargs``.\n\n        Args:\n            input_ids(:obj:`torch.Tensor`): Indices of input sequence tokens in the vocabulary.\n        \"\"\"", "\n", "if", "self", ".", "generate_ith_token", "==", "0", "and", "'encoder_outputs'", "not", "in", "model_kwargs", ":", "# generating the first token in decoder only setting.", "\n", "\n", "            ", "batch", "=", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "**", "model_kwargs", ")", "\n", "model_inputs", "=", "self", ".", "prompt_model", ".", "prepare_model_inputs", "(", "batch", ")", "\n", "# check the compatibility for more models. Having checked gpt2, T5", "\n", "", "else", ":", "# generating the subsequence generation can use the default setting", "\n", "            ", "model_inputs", "=", "self", ".", "plm", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "**", "model_kwargs", ")", "\n", "", "self", ".", "last_model_inputs", "=", "model_inputs", "# to update the model_kwargs in _update_model_kwargs_for_generation, in-place operation.", "\n", "return", "model_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration._update_model_kwargs_for_generation": [[585, 608], ["super()._update_model_kwargs_for_generation"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration._update_model_kwargs_for_generation"], ["", "def", "_update_model_kwargs_for_generation", "(", "self", ",", "\n", "outputs", ",", "model_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "is_encoder_decoder", ":", "bool", "=", "False", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "r\"\"\" The parents class's ``_update_model_kwargs_for_generation`` method will\n        add ``past_key_values`` to model_kwargs, and update ``token_type_ids``, and ``attention_mask_ids``.\n\n        In case some of the model_kwargs are modified in the prepare_inputs_for_generation function\n        and should be used as the subsequent model_kwargs, we update these kwargs before the parent class\n        call.\n\n        Other updates should be added here after the parent's function call.\n\n        Args:\n            outputs (:obj:`torch.Tensor`):\n            is_encoder_decoder (:obj:`bool`, defaults to False):\n        \"\"\"", "\n", "if", "self", ".", "generate_ith_token", "==", "0", ":", "\n", "            ", "for", "key", "in", "self", ".", "last_model_inputs", ":", "\n", "                ", "if", "key", "in", "model_kwargs", ":", "\n", "                    ", "model_kwargs", "[", "key", "]", "=", "self", ".", "last_model_inputs", "[", "key", "]", "\n", "", "", "", "model_kwargs", "=", "super", "(", "PromptForGeneration", ",", "PromptForGeneration", ")", ".", "_update_model_kwargs_for_generation", "(", "outputs", "=", "outputs", ",", "model_kwargs", "=", "model_kwargs", ",", "is_encoder_decoder", "=", "is_encoder_decoder", ")", "\n", "self", ".", "generate_ith_token", "+=", "1", "\n", "return", "model_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration._prepare_encoder_decoder_kwargs_for_generation": [[610, 637], ["pipeline_base.PromptForGeneration.plm.get_encoder", "pipeline_base.PromptForGeneration.prompt_model.prepare_model_inputs", "pipeline_base.PromptForGeneration.", "model_kwargs.items", "argument.startswith", "argument.startswith"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.prepare_model_inputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items"], ["", "def", "_prepare_encoder_decoder_kwargs_for_generation", "(", "\n", "self", ",", "input_ids", ":", "torch", ".", "LongTensor", ",", "model_kwargs", ",", "model_input_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "r\"\"\" This function resemble the function in GeneraionMix\n\n        Args:\n            input_ids (:obj:`torch.LongTensor`) The input ids for\n        \"\"\"", "\n", "if", "\"encoder_outputs\"", "not", "in", "model_kwargs", ":", "\n", "# retrieve encoder hidden states", "\n", "            ", "encoder", "=", "self", ".", "plm", ".", "get_encoder", "(", ")", "\n", "encoder_kwargs", "=", "{", "\n", "argument", ":", "value", "\n", "for", "argument", ",", "value", "in", "model_kwargs", ".", "items", "(", ")", "\n", "if", "not", "(", "argument", ".", "startswith", "(", "\"decoder_\"", ")", "or", "argument", ".", "startswith", "(", "\"cross_attn\"", ")", ")", "\n", "}", "\n", "model_input_name", "=", "model_input_name", "if", "model_input_name", "is", "not", "None", "else", "self", ".", "main_input_name", "\n", "batch", "=", "{", "model_input_name", ":", "input_ids", ",", "**", "encoder_kwargs", "}", "\n", "model_inputs", "=", "self", ".", "prompt_model", ".", "prepare_model_inputs", "(", "batch", ")", "# This line differs from the orinigal code base, we should process the input", "\n", "# with our template, then pass it into the model.", "\n", "# some of the arguments may have been changed by the template,", "\n", "# e.g. the attention mask. Here we update the model_kwargs", "\n", "for", "key", "in", "model_kwargs", ":", "\n", "                ", "if", "key", "in", "model_inputs", ":", "\n", "                    ", "model_kwargs", "[", "key", "]", "=", "model_inputs", "[", "key", "]", "\n", "", "", "model_kwargs", "[", "\"encoder_outputs\"", "]", "=", "encoder", "(", "return_dict", "=", "True", ",", "**", "model_inputs", ")", "\n", "", "return", "model_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration._reorder_cache": [[653, 657], ["pipeline_base.PromptForGeneration.plm._reorder_cache"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration._reorder_cache"], ["", "def", "_reorder_cache", "(", "self", ",", "past", ",", "beam_idx", ")", ":", "\n", "        ", "r\"\"\"Use the plm's default _reorder_cache function\n        \"\"\"", "\n", "return", "self", ".", "plm", ".", "_reorder_cache", "(", "past", ",", "beam_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.parallelize": [[658, 666], ["hasattr", "pipeline_base.PromptForGeneration.plm.parallelize", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.parallelize"], ["", "def", "parallelize", "(", "self", ",", "device_map", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Parallelize the model across device\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "plm", ",", "\"parallelize\"", ")", ":", "\n", "            ", "self", ".", "plm", ".", "parallelize", "(", "device_map", ")", "\n", "self", ".", "device_map", "=", "self", ".", "plm", ".", "device_map", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"parallelize method was not implemented for this plm.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.deparallelize": [[667, 675], ["hasattr", "pipeline_base.PromptForGeneration.plm.deparallelize", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.deparallelize"], ["", "", "def", "deparallelize", "(", "self", ")", ":", "\n", "        ", "r\"\"\"Deparallelize the model across device\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ".", "plm", ",", "\"deparallelize\"", ")", ":", "\n", "            ", "self", ".", "plm", ".", "deparallelize", "(", ")", "\n", "self", ".", "device_map", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"parallelize method was not implemented for this plm.\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.default_config.get_default_config": [[3, 291], ["yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode", "yacs.config.CfgNode"], "function", ["None"], ["def", "get_default_config", "(", ")", ":", "\n", "# OpenPrompt's default configuration options", "\n", "    ", "cfg", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "\n", "# ENVIRONMENT", "\n", "###################################", "\n", "cfg", ".", "environment", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "environment", ".", "num_gpus", "=", "1", "# number of gpus to use", "\n", "cfg", ".", "environment", ".", "cuda_visible_devices", "=", "[", "0", "]", "# which index of cuda devices is visible to the program", "\n", "cfg", ".", "environment", ".", "local_rank", "=", "0", "# the main device in the cuda visible devices that your DataParallel model will put the model on.", "\n", "# The following should holds: local_rank < len(cuda_visible_devices)", "\n", "cfg", ".", "environment", ".", "model_parallel", "=", "False", "# whether to perform model parallel", "\n", "cfg", ".", "environment", ".", "device_map", "=", "None", "# the device_map, such as \"{0: [0, 1, 2], 1: [3, 4, 5, 6, 7, 8, 9], 2: [10, 11, 12, 13, 14, 15, 16],3: [17, 18, 19, 20, 21, 22, 23]}", "\n", "\n", "cfg", ".", "reproduce", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "# seed for reproduction", "\n", "cfg", ".", "reproduce", ".", "seed", "=", "100", "# a seed for all everything", "\n", "\n", "# PLM PARAMETERS", "\n", "##################################", "\n", "cfg", ".", "plm", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "plm", ".", "model_name", "=", "None", "# the model name, e.g. bert, roberta, gpt2, ...", "\n", "# for all the available model, please check the ./plms directory.", "\n", "cfg", ".", "plm", ".", "model_path", "=", "None", "\n", "cfg", ".", "plm", ".", "specials_to_add", "=", "[", "'<pad>'", "]", "# always need to add pad token, if the tokenizer doesn't have one.", "\n", "cfg", ".", "plm", ".", "optimize", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "plm", ".", "optimize", ".", "name", "=", "'AdamW'", "# TODO: currently not in use.", "\n", "cfg", ".", "plm", ".", "optimize", ".", "freeze_para", "=", "False", "\n", "cfg", ".", "plm", ".", "optimize", ".", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "cfg", ".", "plm", ".", "optimize", ".", "lr", "=", "0.0005", "\n", "cfg", ".", "plm", ".", "optimize", ".", "weight_decay", "=", "0.01", "\n", "cfg", ".", "plm", ".", "optimize", ".", "betas", "=", "[", "0.9", ",", "0.999", "]", "\n", "cfg", ".", "plm", ".", "optimize", ".", "eps", "=", "1.0e-8", "\n", "cfg", ".", "plm", ".", "optimize", ".", "scheduler", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "plm", ".", "optimize", ".", "scheduler", ".", "type", "=", "None", "# by default, it will choose get_linear_schedule_with_warmup", "\n", "cfg", ".", "plm", ".", "optimize", ".", "scheduler", ".", "num_warmup_steps", "=", "500", "\n", "\n", "## LOGIN and CHECKPOINTING ##################################################", "\n", "## in logging, each experiment will create a separate folder for saving log.txt", "\n", "## , (full) config.json, and the checkpoint (if use the same path).", "\n", "## logging is in the following format\uff1a", "\n", "## ./log", "\n", "##  - DIR_NAME_1", "\n", "##    - log.txt", "\n", "##    - config.yaml", "\n", "##    - checkpoint.pt", "\n", "##    - ...", "\n", "##  - DIR_NAME_2", "\n", "##    - ...", "\n", "##", "\n", "cfg", ".", "logging", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "logging", ".", "path_base", "=", "'logs'", "# the path base of all the logs.", "\n", "cfg", ".", "logging", ".", "file_level", "=", "'NOTSET'", "# make sure it's an option of logging package", "\n", "cfg", ".", "logging", ".", "console_level", "=", "'INFO'", "# make sure it's an option of logging package", "\n", "cfg", ".", "logging", ".", "unique_string", "=", "None", "# the generated (or usr defined) unique string for one experiment.", "\n", "cfg", ".", "logging", ".", "unique_string_keys", "=", "[", "'dataset.name'", ",", "'plm.model_path'", ",", "'template'", ",", "'verbalizer'", ",", "'datetime'", "]", "# used to generate the unique string for saving", "\n", "#- dataset.name", "\n", "#- plm.model_path # only keep the last folder name in code,", "\n", "# .i.e ../.cache/roberta-large/ will save as roberta-large", "\n", "#- template", "\n", "#- verbalizer", "\n", "#- datetime  # a 12-digit string recording the date time of running the experiment, i.e., YYMMDDHHMMSS.", "\n", "cfg", ".", "logging", ".", "datetime_format", "=", "\"%m%d%H%M%S%f\"", "# only useful when unique_string_keys includes `datetime`.", "\n", "#  make sure it's a valid format for datetime package.", "\n", "cfg", ".", "logging", ".", "path", "=", "None", "# always keep none to let the config generate a full path according to", "\n", "# path_base and unique_string.", "\n", "cfg", ".", "logging", ".", "overwrite", "=", "True", "# if a same log path exists, overwrite it.", "\n", "\n", "# CHECKPOINT", "\n", "######################################", "\n", "cfg", ".", "checkpoint", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "# checkpoint use the same directory as logging.", "\n", "cfg", ".", "checkpoint", ".", "save_latest", "=", "True", "# Normally set to False to reduce memory use, set", "\n", "# to true to allow resuming learning process.", "\n", "cfg", ".", "checkpoint", ".", "save_best", "=", "True", "# Keep saving the epoch of the best-performance.", "\n", "cfg", ".", "checkpoint", ".", "higher_better", "=", "True", "# is the metric to determine best checkpoint higher better?", "\n", "\n", "\n", "## PIPELINE #######################################################", "\n", "\n", "cfg", ".", "train", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "train", ".", "num_epochs", "=", "5", "# the number of training epochs.", "\n", "cfg", ".", "train", ".", "num_training_steps", "=", "None", "\n", "cfg", ".", "train", ".", "batch_size", "=", "2", "# the batch_size.", "\n", "cfg", ".", "train", ".", "shuffle_data", "=", "True", "# whether shuffle the training data.", "\n", "cfg", ".", "train", ".", "teacher_forcing", "=", "False", "# whether perform teacher forcing in training.", "\n", "# if true, the desired prediction on each mask will", "\n", "# be filled in the mask.", "\n", "cfg", ".", "train", ".", "gradient_accumulation_steps", "=", "1", "# update weight  every N step of training.", "\n", "# set 1 to disable gradient accumulation.", "\n", "cfg", ".", "train", ".", "max_grad_norm", "=", "-", "1.0", "# <0 for unlimited gradients norm", "\n", "cfg", ".", "train", ".", "clean", "=", "False", "# set to True for not saving checkpoint and no tensorboard logging", "\n", "\n", "cfg", ".", "dev", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "dev", ".", "batch_size", "=", "2", "# evaluationn batch_size, can be a bit larger than training batch_size", "\n", "cfg", ".", "dev", ".", "shuffle_data", "=", "False", "# whether to perform data shuffling in evaluation", "\n", "\n", "cfg", ".", "test", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "test", ".", "batch_size", "=", "2", "# evaluationn batch_size, can be a bit larger than training batch_size", "\n", "cfg", ".", "test", ".", "shuffle_data", "=", "False", "# whether to perform data shuffling in evaluation", "\n", "\n", "## TASK ##########################################################@", "\n", "cfg", ".", "task", "=", "'classification'", "\n", "\n", "cfg", ".", "classification", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "classification", ".", "parent_config", "=", "'task'", "\n", "cfg", ".", "classification", ".", "metric", "=", "[", "'micro-f1'", "]", "# the first one will be the main  to determine checkpoint. whether the higher metric value is better.", "\n", "cfg", ".", "classification", ".", "loss_function", "=", "'cross_entropy'", "# the loss function for classification", "\n", "\n", "# LMBFF-classification config ###########################################################W", "\n", "cfg", ".", "classification", ".", "auto_t", "=", "False", "\n", "cfg", ".", "classification", ".", "auto_v", "=", "False", "\n", "\n", "cfg", ".", "template_generator", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "template_generator", ".", "plm", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "template_generator", ".", "plm", ".", "model_name", "=", "'t5'", "# the model name, e.g. bert, roberta, gpt2, ...", "\n", "# for all the available model, please check the ./plms directory.", "\n", "cfg", ".", "template_generator", ".", "plm", ".", "model_path", "=", "None", "\n", "cfg", ".", "template_generator", ".", "plm", ".", "specials_to_add", "=", "[", "'<pad>'", "]", "# always need to add pad token, if the tokenizer doesn't have one.", "\n", "\n", "cfg", ".", "template_generator", ".", "max_length", "=", "20", "# maximum length of generated template", "\n", "cfg", ".", "template_generator", ".", "target_number", "=", "2", "# number of parts to generate, e.g. in T5, every <extra_id_{}> token is one part", "\n", "cfg", ".", "template_generator", ".", "beam_width", "=", "5", "\n", "cfg", ".", "template_generator", ".", "length_limit", "=", "None", "# List[str] length limit for each part of content", "\n", "cfg", ".", "template_generator", ".", "template", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "template_generator", ".", "template", ".", "text", "=", "None", "\n", "cfg", ".", "template_generator", ".", "template", ".", "mask_token", "=", "'<mask>'", "\n", "cfg", ".", "template_generator", ".", "template", ".", "placeholder_mapping", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "template_generator", ".", "template", ".", "placeholder_mapping", "[", "'<text_a>'", "]", "=", "'text_a'", "\n", "cfg", ".", "template_generator", ".", "template", ".", "placeholder_mapping", "[", "'<text_b>'", "]", "=", "'text_b'", "\n", "cfg", ".", "template_generator", ".", "template", ".", "file_path", "=", "None", "\n", "cfg", ".", "template_generator", ".", "template", ".", "choice", "=", "0", "\n", "\n", "# verbalizer_generator, refer to https://arxiv.org/abs/2010.13641", "\n", "cfg", ".", "verbalizer_generator", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "verbalizer_generator", ".", "candidate_num", "=", "1", "# the number of candidates for further selection", "\n", "cfg", ".", "verbalizer_generator", ".", "label_word_num_per_class", "=", "1", "\n", "cfg", ".", "verbalizer_generator", ".", "score_fct", "=", "'llr'", "# the scoring function of label words selection. ``llr'' means log likelihood ratio, corresponding to Equation (7); ``ce'' means cross entropy, corresponding to Equation (6). As the paper points out, ``llr'' is significantly better than 'ce', we only keep it to matchthe original code.", "\n", "cfg", ".", "verbalizer_generator", ".", "normalize", "=", "True", "# whether to perform normalization of unbalanced training dataset, as Equation (5)", "\n", "\n", "\n", "\n", "cfg", ".", "generation", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "# Adding any arguments for generation here.", "\n", "cfg", ".", "generation", ".", "parent_config", "=", "'task'", "\n", "cfg", ".", "generation", ".", "metric", "=", "[", "'sentence_bleu'", "]", "\n", "cfg", ".", "generation", ".", "max_length", "=", "512", "# the max_length of the generated sentence. INCLUDING the input_ids. So: generation.max_length > dataloader.max_seq_length", "\n", "cfg", ".", "generation", ".", "max_new_tokens", "=", "None", "\n", "cfg", ".", "generation", ".", "min_length", "=", "5", "\n", "cfg", ".", "generation", ".", "temperature", "=", "1.0", "\n", "cfg", ".", "generation", ".", "do_sample", "=", "False", "\n", "cfg", ".", "generation", ".", "top_k", "=", "0", "\n", "cfg", ".", "generation", ".", "top_p", "=", "0.9", "\n", "cfg", ".", "generation", ".", "repetition_penalty", "=", "1.0", "##args.repetition_penalty,", "\n", "cfg", ".", "generation", ".", "num_beams", "=", "5", "\n", "cfg", ".", "generation", ".", "bad_words_ids", "=", "[", "[", "628", ",", "198", "]", "]", "\n", "\n", "\n", "cfg", ".", "relation_classification", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "relation_classification", ".", "parent_config", "=", "'task'", "\n", "\n", "## DATASET #########################################################", "\n", "cfg", ".", "dataset", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "dataset", ".", "name", "=", "None", "# the name of the dataset, for the supported choices,", "\n", "# please see the processors in ./data_utils/", "\n", "cfg", ".", "dataset", ".", "path", "=", "None", "# whether is the dataset saved in your local machine.", "\n", "cfg", ".", "dataset", ".", "label_path_sep", "=", "None", "# label path separation token, only for hierarchical label", "\n", "\n", "## DATALOADER ######################################################", "\n", "cfg", ".", "dataloader", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "dataloader", ".", "max_seq_length", "=", "256", "# max_seq_length", "\n", "cfg", ".", "dataloader", ".", "decoder_max_length", "=", "256", "# the decoder max length to truncate decoder input sequence", "\n", "# if it is an encoder-decoder architecture. Note that it's not equavalent", "\n", "# to generation.max_length which is used merely in the generation phase.", "\n", "cfg", ".", "dataloader", ".", "truncate_method", "=", "\"head\"", "# choosing from balanced, head, tail", "\n", "\n", "## LEARINING SETTING  ####################################################", "\n", "cfg", ".", "learning_setting", "=", "None", "# selecting from \"full\", \"zero-shot\", \"few-shot\"", "\n", "\n", "cfg", ".", "zero_shot", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "zero_shot", ".", "parent_config", "=", "'learning_setting'", "\n", "\n", "cfg", ".", "few_shot", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "few_shot", ".", "parent_config", "=", "'learning_setting'", "\n", "cfg", ".", "few_shot", ".", "few_shot_sampling", "=", "None", "\n", "\n", "cfg", ".", "sampling_from_train", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "sampling_from_train", ".", "parent_config", "=", "'few_shot_sampling'", "\n", "cfg", ".", "sampling_from_train", ".", "num_examples_per_label", "=", "10", "\n", "cfg", ".", "sampling_from_train", ".", "also_sample_dev", "=", "True", "\n", "cfg", ".", "sampling_from_train", ".", "num_examples_per_label_dev", "=", "10", "\n", "cfg", ".", "sampling_from_train", ".", "seed", "=", "[", "123", "]", "\n", "\n", "## CALIBRATION ###########################################################", "\n", "cfg", ".", "calibrate", "=", "None", "# leave blank to use no calibrate", "\n", "\n", "cfg", ".", "contextualized_calibrate", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "contextualized_calibrate", ".", "parent_config", "=", "'calibrate'", "\n", "cfg", ".", "contextualized_calibrate", ".", "num_example", "=", "None", "\n", "cfg", ".", "contextualized_calibrate", ".", "use_split", "=", "'train'", "\n", "\n", "cfg", ".", "pmi_calibrate", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "pmi_calibrate", ".", "parent_config", "=", "'calibrate'", "\n", "\n", "## PROMPT SPECIFIC CONFIG ############################################", "\n", "cfg", ".", "template", "=", "None", "\n", "cfg", ".", "verbalizer", "=", "None", "\n", "\n", "cfg", ".", "manual_template", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "manual_template", ".", "parent_config", "=", "'template'", "\n", "cfg", ".", "manual_template", ".", "text", "=", "None", "\n", "cfg", ".", "manual_template", ".", "mask_token", "=", "'<mask>'", "\n", "cfg", ".", "manual_template", ".", "placeholder_mapping", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "manual_template", ".", "placeholder_mapping", "[", "'<text_a>'", "]", "=", "'text_a'", "\n", "cfg", ".", "manual_template", ".", "placeholder_mapping", "[", "'<text_b>'", "]", "=", "'text_b'", "\n", "cfg", ".", "manual_template", ".", "file_path", "=", "None", "\n", "cfg", ".", "manual_template", ".", "choice", "=", "0", "\n", "cfg", ".", "manual_template", ".", "optimize", "=", "None", "# the parameters related to optimize the template", "\n", "\n", "\n", "cfg", ".", "automatic_verbalizer", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "automatic_verbalizer", ".", "parent_config", "=", "'verbalizer'", "\n", "cfg", ".", "automatic_verbalizer", ".", "num_cadidates", "=", "1000", "\n", "cfg", ".", "automatic_verbalizer", ".", "label_word_num_per_class", "=", "1", "\n", "cfg", ".", "automatic_verbalizer", ".", "num_searches", "=", "1", "\n", "cfg", ".", "automatic_verbalizer", ".", "score_fct", "=", "'llr'", "\n", "cfg", ".", "automatic_verbalizer", ".", "balance", "=", "True", "\n", "cfg", ".", "automatic_verbalizer", ".", "optimize", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "automatic_verbalizer", ".", "optimize", ".", "level", "=", "'epoch'", "\n", "cfg", ".", "automatic_verbalizer", ".", "num_classes", "=", "None", "\n", "cfg", ".", "automatic_verbalizer", ".", "init_using_split", "=", "'valid'", "\n", "\n", "cfg", ".", "one2one_verbalizer", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "one2one_verbalizer", ".", "parent_config", "=", "'verbalizer'", "\n", "cfg", ".", "one2one_verbalizer", ".", "label_words", "=", "None", "\n", "cfg", ".", "one2one_verbalizer", ".", "prefix", "=", "\" \"", "\n", "cfg", ".", "one2one_verbalizer", ".", "multi_token_handler", "=", "'first'", "\n", "cfg", ".", "one2one_verbalizer", ".", "file_path", "=", "None", "\n", "cfg", ".", "one2one_verbalizer", ".", "choice", "=", "None", "\n", "cfg", ".", "one2one_verbalizer", ".", "num_classes", "=", "None", "\n", "cfg", ".", "one2one_verbalizer", ".", "optimize", "=", "None", "\n", "\n", "cfg", ".", "manual_verbalizer", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "manual_verbalizer", ".", "parent_config", "=", "'verbalizer'", "\n", "cfg", ".", "manual_verbalizer", ".", "label_words", "=", "None", "\n", "cfg", ".", "manual_verbalizer", ".", "prefix", "=", "\" \"", "\n", "cfg", ".", "manual_verbalizer", ".", "multi_token_handler", "=", "'first'", "\n", "cfg", ".", "manual_verbalizer", ".", "file_path", "=", "None", "\n", "cfg", ".", "manual_verbalizer", ".", "choice", "=", "None", "\n", "cfg", ".", "manual_verbalizer", ".", "num_classes", "=", "None", "\n", "cfg", ".", "manual_verbalizer", ".", "optimize", "=", "None", "\n", "\n", "cfg", ".", "prefix_tuning_template", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "prefix_tuning_template", ".", "parent_config", "=", "'template'", "\n", "cfg", ".", "prefix_tuning_template", ".", "text", "=", "None", "\n", "cfg", ".", "prefix_tuning_template", ".", "mask_token", "=", "'<mask>'", "\n", "cfg", ".", "prefix_tuning_template", ".", "num_token", "=", "5", "\n", "cfg", ".", "prefix_tuning_template", ".", "placeholder_mapping", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "prefix_tuning_template", ".", "placeholder_mapping", "[", "'<text_a>'", "]", "=", "'text_a'", "\n", "cfg", ".", "prefix_tuning_template", ".", "placeholder_mapping", "[", "'<text_b>'", "]", "=", "'text_b'", "\n", "cfg", ".", "prefix_tuning_template", ".", "prefix_dropout", "=", "0.0", "\n", "cfg", ".", "prefix_tuning_template", ".", "mid_dim", "=", "512", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "name", "=", "'AdamW'", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "lr", "=", "0.00005", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "betas", "=", "[", "0.9", ",", "0.999", "]", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "adam_epsilon", "=", "1.0e-8", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "weight_decay", "=", "0.0", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "scheduler", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "prefix_tuning_template", ".", "optimize", ".", "scheduler", ".", "num_warmup_steps", "=", "0", "\n", "\n", "cfg", ".", "mixed_template", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "mixed_template", ".", "parent_config", "=", "'template'", "\n", "cfg", ".", "mixed_template", ".", "text", "=", "None", "\n", "cfg", ".", "mixed_template", ".", "mask_token", "=", "'<mask>'", "\n", "cfg", ".", "mixed_template", ".", "placeholder_mapping", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "mixed_template", ".", "placeholder_mapping", "[", "'<text_a>'", "]", "=", "'text_a'", "\n", "cfg", ".", "mixed_template", ".", "placeholder_mapping", "[", "'<text_b>'", "]", "=", "'text_b'", "\n", "cfg", ".", "mixed_template", ".", "optimize", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "name", "=", "'AdamW'", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "lr", "=", "0.00005", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "betas", "=", "[", "0.9", ",", "0.999", "]", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "adam_epsilon", "=", "1.0e-8", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "weight_decay", "=", "0.0", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "scheduler", "=", "CfgNode", "(", "new_allowed", "=", "True", ")", "\n", "cfg", ".", "mixed_template", ".", "optimize", ".", "scheduler", ".", "num_warmup_steps", "=", "0", "\n", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.__init__": [[46, 69], ["trainer.BaseRunner.wrap_model", "tensorboardX.SummaryWriter", "os.path.join", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.wrap_model"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PromptForClassification", ",", "\n", "config", ":", "CfgNode", "=", "None", ",", "\n", "train_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "valid_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "test_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "train_dataloader", "=", "train_dataloader", "\n", "self", ".", "valid_dataloader", "=", "valid_dataloader", "\n", "self", ".", "test_dataloader", "=", "test_dataloader", "\n", "\n", "self", ".", "wrap_model", "(", ")", "\n", "\n", "self", ".", "cur_epoch", "=", "0", "\n", "self", ".", "best_score", "=", "None", "\n", "self", ".", "global_step", "=", "0", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "config", ".", "logging", ".", "path", ",", "'tensorboard'", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "config", ".", "logging", ".", "path", ",", "'checkpoints'", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "config", ".", "logging", ".", "path", ",", "'checkpoints'", ")", ")", "\n", "\n", "", "self", ".", "clean", "=", "self", ".", "config", ".", "train", ".", "clean", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.__del__": [[70, 73], ["hasattr", "trainer.BaseRunner.writer.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'writer'", ")", ":", "\n", "            ", "self", ".", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log": [[74, 77], ["trainer.BaseRunner.writer.add_scalar"], "methods", ["None"], ["", "", "def", "log", "(", "self", ",", "name", ",", "y", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "clean", ":", "return", "#TODO add more types", "\n", "self", ".", "writer", ".", "add_scalar", "(", "name", ",", "y", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.set_stop_criterion": [[78, 90], ["hasattr", "int", "openprompt.utils.logging.logger.warning", "RuntimeError"], "methods", ["None"], ["", "def", "set_stop_criterion", "(", "self", ")", ":", "\n", "        ", "\"\"\"Total training steps, either controlled by num_training_steps or num_epochs\"\"\"", "\n", "if", "hasattr", "(", "self", ".", "config", ".", "train", ",", "\"num_training_steps\"", ")", "and", "self", ".", "config", ".", "train", ".", "num_training_steps", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "train", ".", "num_epochs", "is", "not", "None", ":", "\n", "                ", "logger", ".", "warning", "(", "\"num_training_steps set explicitly, num_epochs is not in use.\"", ")", "\n", "", "self", ".", "num_training_steps", "=", "self", ".", "config", ".", "train", ".", "num_training_steps", "\n", "self", ".", "num_epochs", "=", "int", "(", "1e8", ")", "# set to a large number", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "train", ".", "num_epochs", "is", "None", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"At least num_training_steps & num_epochs should be specified.\"", ")", "\n", "", "self", ".", "num_training_steps", "=", "self", ".", "steps_per_epoch", "*", "self", ".", "config", ".", "train", ".", "num_epochs", "\n", "self", ".", "num_epochs", "=", "self", ".", "config", ".", "train", ".", "num_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.steps_per_epoch": [[91, 97], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "steps_per_epoch", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"num of training steps per epoch\"\"\"", "\n", "batches", "=", "len", "(", "self", ".", "train_dataloader", ")", "\n", "effective_accum", "=", "self", ".", "config", ".", "train", ".", "gradient_accumulation_steps", "\n", "return", "(", "batches", "//", "effective_accum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.wrap_model": [[98, 100], ["openprompt.utils.cuda.model_to_device"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.cuda.model_to_device"], ["", "def", "wrap_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "model_to_device", "(", "self", ".", "model", ",", "self", ".", "config", ".", "environment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.inner_model": [[101, 104], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "inner_model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "module", "if", "isinstance", "(", "self", ".", "model", ",", "DataParallel", ")", "else", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.configure_optimizers": [[105, 198], ["transformers.AdamW", "optimizers.append", "hasattr", "hasattr", "transformers.get_linear_schedule_with_warmup", "schedulers.append", "hasattr", "Dummy", "setattr", "setattr", "optimizers.append", "hasattr", "template_config.optimize.name.lower", "transformers.AdamW", "optimizers.append", "hasattr", "transformers.AdamW", "optimizers.append", "Dummy", "setattr", "setattr", "optimizers.append", "hasattr", "transformers.get_linear_schedule_with_warmup", "schedulers.append", "template_config.optimize.name.lower", "transformers.optimization.Adafactor", "optimizers.append", "NotImplementedError", "trainer.BaseRunner.inner_model.verbalizer.parameters", "hasattr", "transformers.get_linear_schedule_with_warmup", "schedulers.append", "trainer.BaseRunner.inner_model.plm.named_parameters", "trainer.BaseRunner.inner_model.plm.named_parameters", "any", "any", "trainer.BaseRunner.inner_model.template.named_parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "r\"\"\"config the optimizer and scheduler for\n\n        1. model\n\n        2. template\n\n        3. verbalizer(optional)\n        \"\"\"", "\n", "\n", "optimizers", "=", "[", "]", "\n", "schedulers", "=", "[", "]", "\n", "\n", "if", "not", "self", ".", "config", ".", "plm", ".", "optimize", ".", "freeze_para", ":", "\n", "            ", "no_decay", "=", "self", ".", "config", ".", "plm", ".", "optimize", ".", "no_decay", "\n", "weight_decay", "=", "self", ".", "config", ".", "plm", ".", "optimize", ".", "weight_decay", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "inner_model", ".", "plm", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "inner_model", ".", "plm", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "plm_optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "config", ".", "plm", ".", "optimize", ".", "lr", ",", "\n", "betas", "=", "self", ".", "config", ".", "plm", ".", "optimize", ".", "betas", ",", "\n", "eps", "=", "self", ".", "config", ".", "plm", ".", "optimize", ".", "eps", "\n", ")", "\n", "optimizers", ".", "append", "(", "plm_optimizer", ")", "\n", "if", "self", ".", "config", ".", "plm", ".", "optimize", ".", "scheduler", "is", "not", "None", ":", "\n", "                ", "plm_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "plm_optimizer", ",", "\n", "num_warmup_steps", "=", "self", ".", "config", ".", "plm", ".", "optimize", ".", "scheduler", ".", "num_warmup_steps", ",", "\n", "num_training_steps", "=", "self", ".", "num_training_steps", "\n", ")", "\n", "schedulers", ".", "append", "(", "plm_scheduler", ")", "\n", "\n", "", "", "class", "Dummy", ":", "\n", "            ", "pass", "\n", "\n", "", "template_config", "=", "self", ".", "config", "[", "self", ".", "config", ".", "template", "]", "\n", "if", "hasattr", "(", "template_config", ",", "\"optimize\"", ")", "and", "template_config", ".", "optimize", "is", "not", "None", ":", "# TODO should add optimize config in each yaml", "\n", "            ", "if", "not", "hasattr", "(", "self", ".", "inner_model", ".", "template", ",", "\"optimize\"", ")", ":", "\n", "# using default gradient descent optimizer.", "\n", "                ", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "name", ",", "p", "in", "self", ".", "inner_model", ".", "template", ".", "named_parameters", "(", ")", "if", "'raw_embedding'", "not", "in", "name", "]", "}", "\n", "]", "\n", "if", "template_config", ".", "optimize", ".", "name", ".", "lower", "(", ")", "==", "\"adamw\"", ":", "\n", "                    ", "template_optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "template_config", ".", "optimize", ".", "lr", ",", "eps", "=", "template_config", ".", "optimize", ".", "adam_epsilon", ")", "\n", "optimizers", ".", "append", "(", "template_optimizer", ")", "\n", "if", "hasattr", "(", "template_config", ".", "optimize", ",", "\"scheduler\"", ")", "and", "template_config", ".", "optimize", ".", "scheduler", "is", "not", "None", ":", "\n", "                        ", "template_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "template_optimizer", ",", "\n", "num_warmup_steps", "=", "template_config", ".", "optimize", ".", "scheduler", ".", "num_warmup_steps", ",", "\n", "num_training_steps", "=", "self", ".", "num_training_steps", "\n", ")", "\n", "schedulers", ".", "append", "(", "template_scheduler", ")", "\n", "", "", "elif", "template_config", ".", "optimize", ".", "name", ".", "lower", "(", ")", "==", "\"adafactor\"", ":", "\n", "                    ", "template_optimizer", "=", "Adafactor", "(", "optimizer_grouped_parameters", ",", "lr", "=", "template_config", ".", "optimize", ".", "lr", ",", "weight_decay", "=", "1e-5", ",", "relative_step", "=", "False", ",", "scale_parameter", "=", "False", ",", "warmup_init", "=", "False", ")", "\n", "# template_scheduler = AdafactorSchedule(template_optimizer)", "\n", "optimizers", ".", "append", "(", "template_optimizer", ")", "\n", "# schedulers.append(template_scheduler)", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"Template Optimizer not Implemented!\"", ")", "\n", "", "", "else", ":", "\n", "                ", "template_optimizer", "=", "Dummy", "(", ")", "\n", "# resemble a pytorch optimizer for unified training.", "\n", "setattr", "(", "template_optimizer", ",", "\"step\"", ",", "self", ".", "inner_model", ".", "template", ".", "optimize", ")", "\n", "setattr", "(", "template_optimizer", ",", "\"zero_grad\"", ",", "lambda", ":", "None", ")", "\n", "optimizers", ".", "append", "(", "template_optimizer", ")", "\n", "\n", "", "", "if", "hasattr", "(", "self", ".", "inner_model", ",", "\"verbalizer\"", ")", "and", "self", ".", "inner_model", ".", "verbalizer", ":", "\n", "            ", "verbalizer_config", "=", "self", ".", "config", "[", "self", ".", "config", ".", "verbalizer", "]", "\n", "if", "hasattr", "(", "verbalizer_config", ",", "\"optimize\"", ")", "and", "verbalizer_config", ".", "optimize", "is", "not", "None", ":", "\n", "                ", "if", "not", "hasattr", "(", "self", ".", "inner_model", ".", "verbalizer", ",", "\"optimize\"", ")", ":", "\n", "# using default gradient descent optimizer.", "\n", "                    ", "verbalizer_optimizer", "=", "AdamW", "(", "self", ".", "inner_model", ".", "verbalizer", ".", "parameters", "(", ")", ",", "lr", "=", "verbalizer_config", ".", "optimize", ".", "lr", ")", "\n", "optimizers", ".", "append", "(", "verbalizer_optimizer", ")", "\n", "if", "hasattr", "(", "verbalizer_config", ".", "optimize", ",", "\"scheduler\"", ")", "and", "verbalizer_config", ".", "optimize", ".", "scheduler", "is", "not", "None", ":", "\n", "                        ", "verbalizer_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "verbalizer_optimizer", ",", "\n", "num_warmup_steps", "=", "verbalizer_config", ".", "optimize", ".", "scheduler", ".", "num_warmup_steps", ",", "\n", "num_training_steps", "=", "self", ".", "num_training_steps", "\n", ")", "\n", "schedulers", ".", "append", "(", "verbalizer_scheduler", ")", "\n", "", "", "else", ":", "\n", "                    ", "verbalizer_optimizer", "=", "Dummy", "(", ")", "\n", "# resemble a pytorch optimizer for unified training.", "\n", "setattr", "(", "verbalizer_optimizer", ",", "\"step\"", ",", "self", ".", "inner_model", ".", "verbalizer", ".", "optimize", ")", "\n", "setattr", "(", "verbalizer_optimizer", ",", "\"zero_grad\"", ",", "lambda", ":", "None", ")", "\n", "optimizers", ".", "append", "(", "verbalizer_optimizer", ")", "\n", "\n", "", "", "", "self", ".", "optimizers", "=", "optimizers", "\n", "self", ".", "schedulers", "=", "schedulers", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path": [[199, 201], ["os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "checkpoint_path", "(", "self", ",", "ckpt", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "self", ".", "config", ".", "logging", ".", "path", ",", "\"checkpoints\"", ")", ",", "f'{ckpt}.ckpt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.load_checkpoint": [[202, 230], ["openprompt.utils.logging.logger.info", "trainer.BaseRunner.model.load_state_dict", "openprompt.utils.logging.logger.info", "torch.load", "zip", "zip", "trainer.BaseRunner.checkpoint_path", "openprompt.utils.logging.logger.warning", "isinstance", "isinstance", "trainer.BaseRunner.checkpoint_path", "optimizer.load_state_dict", "warnings.catch_warnings", "scheduler.load_state_dict", "trainer.BaseRunner.checkpoint_path"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path"], ["", "def", "load_checkpoint", "(", "self", ",", "ckpt", ":", "str", ",", "load_state", "=", "True", ")", "->", "bool", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Loading Checkpoint {self.checkpoint_path(ckpt)}...\"", ")", "\n", "try", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "self", ".", "checkpoint_path", "(", "ckpt", ")", ",", "pickle_module", "=", "dill", ",", "map_location", "=", "\"cpu\"", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Checkpoint {self.checkpoint_path(ckpt)} not found\"", ")", "\n", "return", "False", "\n", "\n", "# load state to model", "\n", "", "self", ".", "model", "=", "self", ".", "inner_model", "\n", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", "[", "'state_dict'", "]", ")", "\n", "\n", "if", "load_state", ":", "\n", "# load state to optimizers", "\n", "            ", "for", "optimizer", ",", "op_state", "in", "zip", "(", "self", ".", "optimizers", ",", "state_dict", "[", "'optimizer'", "]", ")", ":", "\n", "                ", "if", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", ":", "\n", "                    ", "optimizer", ".", "load_state_dict", "(", "op_state", ")", "\n", "", "", "for", "scheduler", ",", "sc_state", "in", "zip", "(", "self", ".", "schedulers", ",", "state_dict", "[", "'scheduler'", "]", ")", ":", "\n", "                ", "if", "isinstance", "(", "scheduler", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "_LRScheduler", ")", ":", "\n", "                    ", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", ":", "\n", "                        ", "scheduler", ".", "load_state_dict", "(", "sc_state", ")", "\n", "\n", "# load training state", "\n", "", "", "", "self", ".", "cur_epoch", "=", "state_dict", "[", "'cur_epoch'", "]", "+", "1", "\n", "self", ".", "best_score", "=", "state_dict", "[", "'best_score'", "]", "\n", "self", ".", "global_step", "=", "state_dict", "[", "'global_step'", "]", "\n", "", "logger", ".", "info", "(", "f\"Load Checkpoint finished, the current validation metric: {state_dict['validation_metric']}\"", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.save_checkpoint": [[231, 254], ["openprompt.utils.logging.logger.info", "state_dict.update", "torch.save", "openprompt.utils.logging.logger.info", "trainer.BaseRunner.inner_model.state_dict", "state_dict.update", "trainer.BaseRunner.checkpoint_path", "openprompt.utils.logging.logger.info", "shutil.copyfile", "warnings.catch_warnings", "trainer.BaseRunner.checkpoint_path", "trainer.BaseRunner.checkpoint_path", "trainer.BaseRunner.checkpoint_path", "isinstance", "opt.state_dict", "isinstance", "sch.state_dict", "trainer.BaseRunner.checkpoint_path", "trainer.BaseRunner.checkpoint_path"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.save", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.checkpoint_path"], ["", "def", "save_checkpoint", "(", "self", ",", "ckpt", ":", "str", ",", "save_state", "=", "True", ",", "extra", ":", "dict", "=", "{", "}", ",", "copy", ":", "str", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "clean", ":", "return", "\n", "logger", ".", "info", "(", "f\"Saving checkpoint {self.checkpoint_path(ckpt)}...\"", ")", "\n", "state_dict", "=", "{", "\n", "\"state_dict\"", ":", "self", ".", "inner_model", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "state_dict", ".", "update", "(", "extra", ")", "\n", "\n", "if", "save_state", ":", "\n", "            ", "state_dict", "[", "\"optimizer\"", "]", "=", "[", "opt", ".", "state_dict", "(", ")", "if", "isinstance", "(", "opt", ",", "torch", ".", "optim", ".", "Optimizer", ")", "else", "None", "for", "opt", "in", "self", ".", "optimizers", "]", "\n", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", ":", "\n", "                ", "state_dict", "[", "\"scheduler\"", "]", "=", "[", "sch", ".", "state_dict", "(", ")", "if", "isinstance", "(", "sch", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "_LRScheduler", ")", "else", "None", "for", "sch", "in", "self", ".", "schedulers", "]", "\n", "\n", "", "state_dict", ".", "update", "(", "{", "\n", "\"cur_epoch\"", ":", "self", ".", "cur_epoch", ",", "\n", "\"best_score\"", ":", "self", ".", "best_score", ",", "\n", "\"global_step\"", ":", "self", ".", "global_step", ",", "\n", "}", ")", "\n", "", "torch", ".", "save", "(", "state_dict", ",", "self", ".", "checkpoint_path", "(", "ckpt", ")", ",", "pickle_module", "=", "dill", ")", "\n", "if", "copy", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Copying checkpoint {self.checkpoint_path(ckpt)} to {self.checkpoint_path(copy)}...\"", ")", "\n", "shutil", ".", "copyfile", "(", "self", ".", "checkpoint_path", "(", "ckpt", ")", ",", "self", ".", "checkpoint_path", "(", "copy", ")", ")", "\n", "", "logger", ".", "info", "(", "f\"Save Checkpoint finished\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.save_results": [[255, 262], ["results.items", "os.path.join", "open", "print"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items"], ["", "def", "save_results", "(", "self", ",", "split", ",", "results", ":", "dict", ")", ":", "\n", "        ", "if", "self", ".", "clean", ":", "return", "\n", "for", "name", ",", "values", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "file_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "config", ".", "logging", ".", "path", ",", "f\"{split}_{name}.txt\"", ")", "\n", "with", "open", "(", "file_name", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "for", "value", "in", "values", ":", "\n", "                    ", "print", "(", "value", ",", "file", "=", "fout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.inference_epoch": [[263, 278], ["trainer.BaseRunner.model.eval", "trainer.BaseRunner.inference_epoch_end", "openprompt.utils.logging.logger.info", "trainer.BaseRunner.items", "torch.no_grad", "enumerate", "trainer.BaseRunner.log", "trainer.BaseRunner.popitem", "tqdm.tqdm.tqdm", "batch.to().to_dict.to().to_dict.to().to_dict", "outputs.append", "trainer.BaseRunner.inference_step", "batch.to().to_dict.to().to_dict.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.inference_epoch_end", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.inference_step", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "", "", "", "def", "inference_epoch", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "        ", "outputs", "=", "[", "]", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data_loader", "=", "self", ".", "valid_dataloader", "if", "split", "==", "'validation'", "else", "self", ".", "test_dataloader", "\n", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "data_loader", ",", "desc", "=", "split", ")", ")", ":", "\n", "                ", "batch", "=", "batch", ".", "to", "(", "\"cuda:{}\"", ".", "format", "(", "self", ".", "config", ".", "environment", ".", "local_rank", ")", ")", ".", "to_dict", "(", ")", "\n", "\n", "outputs", ".", "append", "(", "self", ".", "inference_step", "(", "batch", ",", "batch_idx", ")", ")", "\n", "\n", "", "", "metrics", "=", "self", ".", "inference_epoch_end", "(", "split", ",", "outputs", ")", "\n", "logger", ".", "info", "(", "f\"{split} Performance: {metrics}\"", ")", "\n", "for", "metric_name", ",", "metric", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "log", "(", "f'{split}/{metric_name}'", ",", "metric", ",", "self", ".", "cur_epoch", ")", "\n", "", "return", "metrics", ".", "popitem", "(", "last", "=", "False", ")", "[", "1", "]", "# TODO the first metric is the most important one", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.training_epoch": [[279, 318], ["trainer.BaseRunner.model.train", "trainer.BaseRunner.model.zero_grad", "openprompt.utils.logging.logger.info", "tqdm.tqdm.tqdm", "enumerate", "batch.to().to_dict.to().to_dict.to().to_dict", "trainer.BaseRunner.training_step", "trainer.BaseRunner.item", "trainer.BaseRunner.backward", "pbar.set_postfix", "trainer.BaseRunner.log", "pbar.update", "openprompt.utils.logging.logger.info", "batch.to().to_dict.to().to_dict.to", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "optimizer.zero_grad", "trainer.BaseRunner.model.parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.train", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.training_step", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "training_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "total_loss", "=", "0.0", "\n", "sum_loss", "=", "0.0", "\n", "with", "tqdm", "(", "total", "=", "self", ".", "steps_per_epoch", ",", "desc", "=", "f\"train epoch: {epoch}\"", ")", "as", "pbar", ":", "\n", "            ", "for", "batch_idx", ",", "batch", "in", "enumerate", "(", "self", ".", "train_dataloader", ")", ":", "\n", "                ", "batch", "=", "batch", ".", "to", "(", "\"cuda:{}\"", ".", "format", "(", "self", ".", "config", ".", "environment", ".", "local_rank", ")", ")", ".", "to_dict", "(", ")", "\n", "\n", "loss", "=", "self", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n", "if", "self", ".", "config", ".", "train", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "self", ".", "config", ".", "train", ".", "gradient_accumulation_steps", "\n", "", "sum_loss", "+=", "loss", ".", "item", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "(", "batch_idx", "+", "1", ")", "%", "self", ".", "config", ".", "train", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                    ", "pbar", ".", "set_postfix", "(", "{", "'loss'", ":", "sum_loss", "}", ")", "\n", "self", ".", "log", "(", "'train/loss'", ",", "sum_loss", ",", "self", ".", "global_step", ")", "\n", "# logger.info(\"{} {}\".format(self.inner_model.template.soft_embeds.data.mean().item(),self.global_step))", "\n", "\n", "if", "self", ".", "config", ".", "train", ".", "max_grad_norm", ">", "0", ":", "\n", "                        ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "config", ".", "train", ".", "max_grad_norm", ")", "\n", "\n", "", "for", "optimizer", "in", "self", ".", "optimizers", ":", "\n", "                        ", "optimizer", ".", "step", "(", ")", "\n", "", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "                        ", "scheduler", ".", "step", "(", ")", "\n", "", "for", "optimizer", "in", "self", ".", "optimizers", ":", "\n", "                        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "total_loss", "+=", "sum_loss", "\n", "sum_loss", "=", "0.", "\n", "self", ".", "global_step", "+=", "1", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "if", "self", ".", "global_step", ">=", "self", ".", "num_training_steps", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Training epoch {epoch}, num_steps {self.global_step}, avg_loss: {total_loss/self.steps_per_epoch:.4f}, total_loss: {total_loss:.4f}\"", ")", "\n", "return", "-", "1", "# an indicator of stopping the training", "\n", "", "", "", "logger", ".", "info", "(", "f\"Training epoch {epoch}, num_steps {self.global_step},  avg_loss: {total_loss/self.steps_per_epoch:.4f}, total_loss: {total_loss:.4f}\"", ")", "\n", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.on_fit_start": [[319, 322], ["None"], "methods", ["None"], ["", "def", "on_fit_start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Some initialization works\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.fit": [[323, 346], ["trainer.BaseRunner.set_stop_criterion", "trainer.BaseRunner.configure_optimizers", "range", "trainer.BaseRunner.on_fit_start", "trainer.BaseRunner.training_epoch", "trainer.BaseRunner.inference_epoch", "trainer.BaseRunner.save_checkpoint", "trainer.BaseRunner.load_checkpoint", "openprompt.utils.logging.logger.warning", "openprompt.utils.logging.logger.info"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.set_stop_criterion", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.configure_optimizers", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.on_fit_start", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.training_epoch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.inference_epoch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.save_checkpoint", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.load_checkpoint"], ["", "def", "fit", "(", "self", ",", "ckpt", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "set_stop_criterion", "(", ")", "\n", "self", ".", "configure_optimizers", "(", ")", "\n", "\n", "\n", "if", "ckpt", ":", "\n", "            ", "if", "not", "self", ".", "load_checkpoint", "(", "ckpt", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Train from scratch instead ...\"", ")", "\n", "", "", "if", "self", ".", "cur_epoch", "==", "0", ":", "\n", "            ", "self", ".", "on_fit_start", "(", ")", "\n", "\n", "", "for", "self", ".", "cur_epoch", "in", "range", "(", "self", ".", "cur_epoch", ",", "self", ".", "num_epochs", ")", ":", "\n", "            ", "continue_training", "=", "self", ".", "training_epoch", "(", "self", ".", "cur_epoch", ")", "\n", "score", "=", "self", ".", "inference_epoch", "(", "\"validation\"", ")", "\n", "copy", "=", "None", "\n", "if", "self", ".", "best_score", "is", "None", "or", "(", "(", "score", "-", "self", ".", "best_score", ")", ">=", "0", ")", "==", "self", ".", "config", ".", "checkpoint", ".", "higher_better", ":", "\n", "                ", "copy", "=", "'best'", "\n", "self", ".", "best_score", "=", "score", "\n", "", "self", ".", "save_checkpoint", "(", "'last'", ",", "extra", "=", "{", "\"validation_metric\"", ":", "score", "}", ",", "copy", "=", "copy", ")", "\n", "if", "continue_training", "==", "-", "1", ":", "\n", "                ", "logger", ".", "info", "(", "\"Stop training by reaching maximum num_training_steps\"", ")", "\n", "break", "\n", "", "", "return", "self", ".", "best_score", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.test": [[347, 353], ["trainer.BaseRunner.inference_epoch", "trainer.BaseRunner.load_checkpoint", "openprompt.utils.logging.logger.error", "exit"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.inference_epoch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.load_checkpoint"], ["", "def", "test", "(", "self", ",", "ckpt", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "dict", ":", "\n", "        ", "if", "ckpt", ":", "\n", "            ", "if", "not", "self", ".", "load_checkpoint", "(", "ckpt", ",", "load_state", "=", "False", ")", ":", "\n", "                ", "logger", ".", "error", "(", "\"Test cannot be performed\"", ")", "\n", "exit", "(", ")", "\n", "", "", "return", "self", ".", "inference_epoch", "(", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.run": [[354, 357], ["trainer.BaseRunner.fit", "trainer.BaseRunner.test"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.fit", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.test"], ["", "def", "run", "(", "self", ",", "ckpt", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "fit", "(", "ckpt", ")", "\n", "return", "self", ".", "test", "(", "ckpt", "=", "None", "if", "self", ".", "clean", "else", "'best'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.ClassificationRunner.__init__": [[375, 393], ["trainer.BaseRunner.__init__", "trainer.ClassificationRunner.configure_loss_function"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.configure_loss_function"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PromptForClassification", ",", "\n", "config", ":", "CfgNode", "=", "None", ",", "\n", "train_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "valid_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "test_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "loss_function", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "id2label", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "\n", "config", "=", "config", ",", "\n", "train_dataloader", "=", "train_dataloader", ",", "\n", "valid_dataloader", "=", "valid_dataloader", ",", "\n", "test_dataloader", "=", "test_dataloader", ",", "\n", ")", "\n", "self", ".", "loss_function", "=", "loss_function", "if", "loss_function", "else", "self", ".", "configure_loss_function", "(", ")", "\n", "self", ".", "id2label", "=", "id2label", "\n", "self", ".", "label_path_sep", "=", "config", ".", "dataset", ".", "label_path_sep", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.ClassificationRunner.configure_loss_function": [[394, 402], ["torch.nn.CrossEntropyLoss", "torch.nn.NLLLoss"], "methods", ["None"], ["", "def", "configure_loss_function", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"config the loss function if it's not passed.\"\"\"", "\n", "if", "self", ".", "config", ".", "classification", ".", "loss_function", "==", "\"cross_entropy\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "elif", "self", ".", "config", ".", "classification", ".", "loss_function", "==", "\"nll_loss\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "NLLLoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.ClassificationRunner.inference_step": [[403, 408], ["batch.pop", "trainer.ClassificationRunner.model", "torch.argmax", "torch.argmax.cpu().tolist", "batch.pop.cpu().tolist", "torch.argmax.cpu", "batch.pop.cpu"], "methods", ["None"], ["", "", "def", "inference_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "label", "=", "batch", ".", "pop", "(", "'label'", ")", "\n", "logits", "=", "self", ".", "model", "(", "batch", ")", "\n", "pred", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "pred", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ",", "label", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.ClassificationRunner.inference_epoch_end": [[409, 426], ["trainer.ClassificationRunner.save_results", "OrderedDict", "preds.extend", "labels.extend", "openprompt.utils.metrics.classification_metrics"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.save_results", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.classification_metrics"], ["", "def", "inference_epoch_end", "(", "self", ",", "split", ",", "outputs", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "pred", ",", "label", "in", "outputs", ":", "\n", "            ", "preds", ".", "extend", "(", "pred", ")", "\n", "labels", ".", "extend", "(", "label", ")", "\n", "\n", "", "self", ".", "save_results", "(", "split", ",", "{", "\n", "'preds'", ":", "preds", ",", "\n", "'labels'", ":", "labels", ",", "\n", "}", ")", "\n", "\n", "metrics", "=", "OrderedDict", "(", ")", "\n", "for", "metric_name", "in", "self", ".", "config", ".", "classification", ".", "metric", ":", "\n", "            ", "metric", "=", "classification_metrics", "(", "preds", ",", "labels", ",", "metric_name", ",", "id2label", "=", "self", ".", "id2label", ",", "label_path_sep", "=", "self", ".", "label_path_sep", ")", "\n", "metrics", "[", "metric_name", "]", "=", "metric", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.ClassificationRunner.training_step": [[427, 431], ["trainer.ClassificationRunner.model", "trainer.ClassificationRunner.loss_function"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "logits", "=", "self", ".", "model", "(", "batch", ")", "\n", "loss", "=", "self", ".", "loss_function", "(", "logits", ",", "batch", "[", "'label'", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.ClassificationRunner.on_fit_start": [[432, 435], ["trainer.ClassificationRunner.prompt_initialize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.prompt_initialize"], ["", "def", "on_fit_start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Some initialization works\"\"\"", "\n", "self", ".", "prompt_initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.ClassificationRunner.prompt_initialize": [[436, 466], ["hasattr", "trainer.ClassificationRunner.wrap_model", "hasattr", "torch.no_grad", "tqdm.tqdm.tqdm", "hasattr", "hasattr", "hasattr", "hasattr", "batch.to().to_dict.to().to_dict.to().to_dict", "trainer.ClassificationRunner.model", "trainer.ClassificationRunner.inner_model.verbalizer.optimize_to_initialize", "trainer.ClassificationRunner.inner_model.template.optimize_to_initialize", "batch.to().to_dict.to().to_dict.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.wrap_model", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.optimize_to_initialize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.optimize_to_initialize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "prompt_initialize", "(", "self", ")", ":", "\n", "        ", "verbalizer_config", "=", "self", ".", "config", "[", "self", ".", "config", ".", "verbalizer", "]", "\n", "template_config", "=", "self", ".", "config", "[", "self", ".", "config", ".", "template", "]", "\n", "if", "not", "hasattr", "(", "self", ".", "inner_model", ".", "verbalizer", ",", "\"optimize_to_initialize\"", ")", "and", "not", "hasattr", "(", "self", ".", "inner_model", ".", "template", ",", "\"optimize_to_initialize\"", ")", ":", "\n", "            ", "return", "None", "\n", "", "if", "hasattr", "(", "verbalizer_config", ",", "\"init_using_split\"", ")", ":", "\n", "            ", "using_split", "=", "verbalizer_config", ".", "init_using_split", "\n", "", "elif", "hasattr", "(", "template_config", ",", "\"init_using_split\"", ")", ":", "\n", "            ", "using_split", "=", "template_config", ".", "init_using_split", "\n", "", "else", ":", "\n", "            ", "using_split", "=", "\"valid\"", "\n", "\n", "", "if", "using_split", "==", "\"train\"", ":", "\n", "            ", "dataloader", "=", "self", ".", "train_dataloader", "\n", "", "elif", "using_split", "==", "\"valid\"", ":", "\n", "            ", "dataloader", "=", "self", ".", "valid_dataloader", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch", "in", "tqdm", "(", "dataloader", ",", "desc", "=", "\"Init_using_{}\"", ".", "format", "(", "using_split", ")", ")", ":", "\n", "                ", "batch", "=", "batch", ".", "to", "(", "\"cuda:{}\"", ".", "format", "(", "self", ".", "config", ".", "environment", ".", "local_rank", ")", ")", ".", "to_dict", "(", ")", "\n", "logits", "=", "self", ".", "model", "(", "batch", ")", "\n", "", "if", "hasattr", "(", "self", ".", "inner_model", ".", "verbalizer", ",", "\"optimize_to_initialize\"", ")", ":", "\n", "                ", "self", ".", "inner_model", ".", "verbalizer", ".", "optimize_to_initialize", "(", ")", "\n", "", "if", "hasattr", "(", "self", ".", "inner_model", ".", "template", ",", "\"optimize_to_initialize\"", ")", ":", "\n", "                ", "self", ".", "inner_model", ".", "template", ".", "optimize_to_initialize", "(", ")", "\n", "\n", "", "", "self", ".", "wrap_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.GenerationRunner.__init__": [[481, 493], ["trainer.BaseRunner.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PromptForGeneration", ",", "\n", "config", ":", "CfgNode", "=", "None", ",", "\n", "train_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "valid_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "test_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "\n", "config", "=", "config", ",", "\n", "train_dataloader", "=", "train_dataloader", ",", "\n", "valid_dataloader", "=", "valid_dataloader", ",", "\n", "test_dataloader", "=", "test_dataloader", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.GenerationRunner.inference_step": [[495, 499], ["trainer.GenerationRunner.model.generate"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate"], ["", "def", "inference_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "target", "=", "batch", "[", "'tgt_text'", "]", "# TODO pop?", "\n", "_", ",", "pred", "=", "self", ".", "model", ".", "generate", "(", "batch", ",", "**", "self", ".", "config", ".", "generation", ")", "\n", "return", "pred", ",", "target", "# these are already a cpu list", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.GenerationRunner.inference_epoch_end": [[500, 517], ["trainer.GenerationRunner.save_results", "OrderedDict", "preds.extend", "targets.extend", "openprompt.utils.metrics.generation_metric"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.save_results", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.generation_metric"], ["", "def", "inference_epoch_end", "(", "self", ",", "split", ",", "outputs", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "for", "pred", ",", "target", "in", "outputs", ":", "\n", "            ", "preds", ".", "extend", "(", "pred", ")", "\n", "targets", ".", "extend", "(", "target", ")", "\n", "\n", "", "self", ".", "save_results", "(", "split", ",", "{", "\n", "'preds'", ":", "preds", ",", "\n", "'targets'", ":", "targets", "\n", "}", ")", "\n", "\n", "metrics", "=", "OrderedDict", "(", ")", "\n", "for", "metric_name", "in", "self", ".", "config", ".", "generation", ".", "metric", ":", "\n", "            ", "metric", "=", "generation_metric", "(", "preds", ",", "targets", ",", "metric_name", ")", "\n", "metrics", "[", "metric_name", "]", "=", "metric", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.GenerationRunner.training_step": [[518, 521], ["trainer.GenerationRunner.model"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "model", "(", "batch", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner.__init__": [[49, 68], ["openprompt.plms.load_plm_from_config", "lm_bff_trainer.LMBFFClassificationRunner._check_param"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.load_plm_from_config", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._check_param"], ["def", "__init__", "(", "self", ",", "\n", "train_dataset", ":", "List", "[", "InputExample", "]", ",", "\n", "valid_dataset", ":", "List", "[", "InputExample", "]", ",", "\n", "test_dataset", ":", "List", "[", "InputExample", "]", ",", "\n", "verbalizer", ":", "Optional", "[", "Verbalizer", "]", "=", "None", ",", "\n", "template", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "config", ":", "CfgNode", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "train_dataset", "=", "train_dataset", "\n", "self", ".", "valid_dataset", "=", "valid_dataset", "\n", "self", ".", "test_dataset", "=", "test_dataset", "\n", "self", ".", "model", ",", "self", ".", "tokenizer", ",", "self", ".", "model_config", ",", "self", ".", "tokenizer_wrapper", "=", "load_plm_from_config", "(", "config", ")", "\n", "self", ".", "auto_t", "=", "config", ".", "classification", ".", "auto_t", "\n", "self", ".", "auto_v", "=", "config", ".", "classification", ".", "auto_v", "\n", "\n", "self", ".", "verbalizer", "=", "verbalizer", "\n", "self", ".", "template", "=", "template", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "_check_param", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._check_param": [[69, 82], ["ValueError", "warnings.warn", "warnings.warn", "ValueError", "warnings.warn"], "methods", ["None"], ["", "def", "_check_param", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "auto_t", ":", "\n", "            ", "if", "self", ".", "verbalizer", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"no verbalizer for template generation provided!\"", ")", "\n", "", "if", "self", ".", "template", "is", "not", "None", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"auto_t is set True, ignore the given template\"", ")", "\n", "", "", "elif", "self", ".", "auto_v", ":", "\n", "            ", "if", "self", ".", "template", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"no template for verbalizer generation provided, or set auto_t=True to automatically generate one\"", ")", "\n", "", "if", "self", ".", "verbalizer", "is", "not", "None", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"auto_v is set True, ignore the given verbalizer\"", ")", "\n", "", "", "else", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"auto_t and auto_v are both False, the trainer will degenerate to a simple classification trainer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._auto_t": [[84, 93], ["openprompt.utils.logging.logger.info", "openprompt.plms.load_plm_from_config", "openprompt.utils.cuda.model_to_device", "openprompt.prompts.load_template_generator", "openprompt.prompts.load_template_generator.generate", "openprompt.prompts.load_template_generator.release_memory"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.load_plm_from_config", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.cuda.model_to_device", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_template_generator", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.release_memory"], ["", "", "def", "_auto_t", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"performing auto-t...\"", ")", "\n", "template_generate_model", ",", "template_generate_tokenizer", ",", "template_generate_model_config", ",", "template_tokenizer_wrapper", "=", "load_plm_from_config", "(", "self", ".", "config", ".", "template_generator", ")", "\n", "model", "=", "model_to_device", "(", "template_generate_model", ",", "self", ".", "config", ".", "environment", ")", "\n", "template_generator", "=", "load_template_generator", "(", "config", "=", "self", ".", "config", ",", "model", "=", "model", ",", "tokenizer", "=", "template_generate_tokenizer", ",", "tokenizer_wrapper", "=", "template_tokenizer_wrapper", ",", "verbalizer", "=", "self", ".", "verbalizer", ")", "\n", "template_texts", "=", "template_generator", ".", "generate", "(", "self", ".", "train_dataset", ")", "# List[str]", "\n", "template_generator", ".", "release_memory", "(", ")", "\n", "del", "template_generator", ",", "model", "\n", "return", "template_texts", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._auto_v": [[94, 109], ["openprompt.utils.logging.logger.info", "copy.deepcopy", "openprompt.utils.cuda.model_to_device", "openprompt.prompts.load_verbalizer_generator", "openprompt.PromptDataLoader", "openprompt.prompts.load_verbalizer_generator.generate", "openprompt.prompts.load_verbalizer_generator.release_memory", "template.process_batch", "openprompt.prompts.load_verbalizer_generator.register_buffer", "data.to.to.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.cuda.model_to_device", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_verbalizer_generator", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.release_memory", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.process_batch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.register_buffer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "_auto_v", "(", "self", ",", "template", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"performing auto-v...\"", ")", "\n", "model", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "model", "=", "model_to_device", "(", "model", ",", "self", ".", "config", ".", "environment", ")", "\n", "verbalizer_generator", "=", "load_verbalizer_generator", "(", "config", "=", "self", ".", "config", ",", "model", "=", "model", ",", "tokenizer", "=", "self", ".", "tokenizer", ")", "\n", "dataloader", "=", "PromptDataLoader", "(", "self", ".", "train_dataset", ",", "template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "batch_size", "=", "self", ".", "config", ".", "test", ".", "batch_size", ")", "\n", "for", "data", "in", "dataloader", ":", "\n", "            ", "data", "=", "template", ".", "process_batch", "(", "data", ")", "\n", "if", "self", ".", "config", ".", "environment", ".", "num_gpus", ">", "0", ":", "\n", "                ", "data", "=", "data", ".", "to", "(", "\"cuda:{}\"", ".", "format", "(", "self", ".", "config", ".", "environment", ".", "local_rank", ")", ")", "\n", "", "verbalizer_generator", ".", "register_buffer", "(", "data", ")", "\n", "", "label_words_list", "=", "verbalizer_generator", ".", "generate", "(", ")", "# List[List[str]]", "\n", "verbalizer_generator", ".", "release_memory", "(", ")", "\n", "del", "verbalizer_generator", ",", "model", "\n", "return", "label_words_list", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._get_best_template_text": [[111, 124], ["openprompt.prompts.ManualTemplate", "lm_bff_trainer.build_dataloader", "lm_bff_trainer.build_dataloader", "lm_bff_trainer.LMBFFClassificationRunner._train_eval", "openprompt.utils.logging.logger.info", "str"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._train_eval"], ["", "def", "_get_best_template_text", "(", "self", ",", "template_texts_candidates", ",", "verbalizer", ")", ":", "\n", "        ", "best_metrics", "=", "0.0", "\n", "best_template_text", "=", "None", "\n", "for", "template_text", "in", "template_texts_candidates", ":", "\n", "            ", "template", "=", "ManualTemplate", "(", "self", ".", "tokenizer", ",", "template_text", ")", "\n", "train_dataloader", "=", "build_dataloader", "(", "self", ".", "train_dataset", ",", "template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "self", ".", "config", ",", "'train'", ")", "\n", "valid_dataloader", "=", "build_dataloader", "(", "self", ".", "valid_dataset", ",", "template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "self", ".", "config", ",", "'dev'", ")", "\n", "score", "=", "self", ".", "_train_eval", "(", "template", ",", "verbalizer", ",", "train_dataloader", ",", "valid_dataloader", ")", "\n", "if", "score", ">", "best_metrics", ":", "\n", "                ", "best_metrics", "=", "score", "\n", "best_template_text", "=", "template_text", "\n", "logger", ".", "info", "(", "'best template:'", "+", "str", "(", "best_template_text", ")", ")", "\n", "", "", "return", "best_template_text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._get_best_label_words": [[125, 139], ["copy.deepcopy", "lm_bff_trainer.build_dataloader", "lm_bff_trainer.build_dataloader", "lm_bff_trainer.LMBFFClassificationRunner._train_eval", "openprompt.utils.logging.logger.info", "str"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._train_eval"], ["", "def", "_get_best_label_words", "(", "self", ",", "verbalizer_labelwords_candidates", ",", "template", ",", "verbalizer", ")", ":", "\n", "        ", "current_verbalizer", "=", "copy", ".", "deepcopy", "(", "verbalizer", ")", "\n", "best_metrics", "=", "0.0", "\n", "best_label_words", "=", "None", "\n", "for", "label_words", "in", "verbalizer_labelwords_candidates", ":", "\n", "            ", "current_verbalizer", ".", "label_words", "=", "label_words", "\n", "train_dataloader", "=", "build_dataloader", "(", "self", ".", "train_dataset", ",", "template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "self", ".", "config", ",", "'train'", ")", "\n", "valid_dataloader", "=", "build_dataloader", "(", "self", ".", "valid_dataset", ",", "template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "self", ".", "config", ",", "'dev'", ")", "\n", "score", "=", "self", ".", "_train_eval", "(", "template", ",", "current_verbalizer", ",", "train_dataloader", ",", "valid_dataloader", ")", "\n", "if", "score", ">", "best_metrics", ":", "\n", "                ", "best_metrics", "=", "score", "\n", "best_label_words", "=", "label_words", "\n", "logger", ".", "info", "(", "'best label words:'", "+", "str", "(", "best_label_words", ")", ")", "\n", "", "", "return", "best_label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._train_eval": [[140, 146], ["openprompt.PromptForClassification", "trainer.ClassificationRunner", "trainer.ClassificationRunner.fit", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.fit"], ["", "def", "_train_eval", "(", "self", ",", "template", ",", "verbalizer", ",", "train_dataloader", ",", "valid_dataloader", ")", ":", "\n", "        ", "model", "=", "PromptForClassification", "(", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", ",", "template", ",", "verbalizer", ")", "\n", "runner", "=", "ClassificationRunner", "(", "model", ",", "config", "=", "self", ".", "config", ",", "train_dataloader", "=", "train_dataloader", ",", "valid_dataloader", "=", "valid_dataloader", ")", "\n", "runner", ".", "clean", "=", "True", "\n", "best_score", "=", "runner", ".", "fit", "(", ")", "\n", "return", "best_score", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner.run": [[147, 169], ["lm_bff_trainer.build_dataloader", "lm_bff_trainer.build_dataloader", "lm_bff_trainer.build_dataloader", "openprompt.PromptForClassification", "trainer.ClassificationRunner", "trainer.ClassificationRunner.run", "lm_bff_trainer.LMBFFClassificationRunner._auto_t", "lm_bff_trainer.LMBFFClassificationRunner._get_best_template_text", "openprompt.prompts.ManualTemplate", "lm_bff_trainer.LMBFFClassificationRunner._auto_v", "lm_bff_trainer.LMBFFClassificationRunner._get_best_label_words", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner.run", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._auto_t", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._get_best_template_text", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._auto_v", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.LMBFFClassificationRunner._get_best_label_words"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "r\"\"\"\n        Run LM-BFF. if both `auto_v` and `auto_v` are set to True in ``config``, automatic template generation will be performed first.\n        \"\"\"", "\n", "best_template", "=", "self", ".", "template", "\n", "best_verbalizer", "=", "self", ".", "verbalizer", "\n", "if", "self", ".", "auto_t", ":", "\n", "            ", "template_texts", "=", "self", ".", "_auto_t", "(", ")", "\n", "best_template_text", "=", "self", ".", "_get_best_template_text", "(", "template_texts", ",", "best_verbalizer", ")", "\n", "best_template", "=", "ManualTemplate", "(", "self", ".", "tokenizer", ",", "best_template_text", ")", "\n", "", "if", "self", ".", "auto_v", ":", "\n", "            ", "label_words_list", "=", "self", ".", "_auto_v", "(", "best_template", ")", "\n", "best_label_words", "=", "self", ".", "_get_best_label_words", "(", "label_words_list", ",", "best_template", ",", "best_verbalizer", ")", "\n", "best_verbalizer", ".", "label_words", "=", "best_label_words", "\n", "\n", "", "train_dataloader", "=", "build_dataloader", "(", "self", ".", "train_dataset", ",", "best_template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "self", ".", "config", ",", "'train'", ")", "\n", "valid_dataloader", "=", "build_dataloader", "(", "self", ".", "valid_dataset", ",", "best_template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "self", ".", "config", ",", "'dev'", ")", "\n", "test_dataloader", "=", "build_dataloader", "(", "self", ".", "test_dataset", ",", "best_template", ",", "self", ".", "tokenizer", ",", "self", ".", "tokenizer_wrapper", ",", "self", ".", "config", ",", "'test'", ")", "\n", "model", "=", "PromptForClassification", "(", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", ",", "best_template", ",", "best_verbalizer", ")", "\n", "runner", "=", "ClassificationRunner", "(", "model", ",", "config", "=", "self", ".", "config", ",", "train_dataloader", "=", "train_dataloader", ",", "valid_dataloader", "=", "valid_dataloader", ",", "test_dataloader", "=", "test_dataloader", ")", "\n", "runner", ".", "clean", "=", "False", "\n", "return", "runner", ".", "run", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.lm_bff_trainer.build_dataloader": [[22, 35], ["openprompt.PromptDataLoader", "hasattr"], "function", ["None"], ["def", "build_dataloader", "(", "dataset", ",", "template", ",", "tokenizer", ",", "tokenizer_wrapper_class", ",", "config", ",", "split", ")", ":", "\n", "    ", "dataloader", "=", "PromptDataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "template", "=", "template", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "tokenizer_wrapper_class", "=", "tokenizer_wrapper_class", ",", "\n", "batch_size", "=", "config", "[", "split", "]", ".", "batch_size", ",", "\n", "shuffle", "=", "config", "[", "split", "]", ".", "shuffle_data", ",", "\n", "teacher_forcing", "=", "config", "[", "split", "]", ".", "teacher_forcing", "if", "hasattr", "(", "config", "[", "split", "]", ",", "'teacher_forcing'", ")", "else", "None", ",", "\n", "predict_eos_token", "=", "True", "if", "config", ".", "task", "==", "\"generation\"", "else", "False", ",", "\n", "**", "config", ".", "dataloader", "\n", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.__init__": [[45, 63], ["openprompt.trainer.BaseRunner.__init__", "protoverb_trainer.ProtoVerbClassificationRunner.configure_loss_function"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.configure_loss_function"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PromptForClassification", ",", "\n", "config", ":", "CfgNode", "=", "None", ",", "\n", "train_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "valid_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "test_dataloader", ":", "Optional", "[", "PromptDataLoader", "]", "=", "None", ",", "\n", "loss_function", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "id2label", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "\n", "config", "=", "config", ",", "\n", "train_dataloader", "=", "train_dataloader", ",", "\n", "valid_dataloader", "=", "valid_dataloader", ",", "\n", "test_dataloader", "=", "test_dataloader", ",", "\n", ")", "\n", "self", ".", "loss_function", "=", "loss_function", "if", "loss_function", "else", "self", ".", "configure_loss_function", "(", ")", "\n", "self", ".", "id2label", "=", "id2label", "\n", "self", ".", "label_path_sep", "=", "config", ".", "dataset", ".", "label_path_sep", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.configure_loss_function": [[64, 72], ["torch.nn.CrossEntropyLoss", "torch.nn.NLLLoss"], "methods", ["None"], ["", "def", "configure_loss_function", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"config the loss function if it's not passed.\"\"\"", "\n", "if", "self", ".", "config", ".", "classification", ".", "loss_function", "==", "\"cross_entropy\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "elif", "self", ".", "config", ".", "classification", ".", "loss_function", "==", "\"nll_loss\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "NLLLoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.inference_step": [[73, 78], ["batch.pop", "protoverb_trainer.ProtoVerbClassificationRunner.model", "torch.argmax", "torch.argmax.cpu().tolist", "batch.pop.cpu().tolist", "torch.argmax.cpu", "batch.pop.cpu"], "methods", ["None"], ["", "", "def", "inference_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "label", "=", "batch", ".", "pop", "(", "'label'", ")", "\n", "logits", "=", "self", ".", "model", "(", "batch", ")", "\n", "pred", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "pred", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ",", "label", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.inference_epoch_end": [[79, 96], ["protoverb_trainer.ProtoVerbClassificationRunner.save_results", "OrderedDict", "preds.extend", "labels.extend", "openprompt.utils.metrics.classification_metrics"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.save_results", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.classification_metrics"], ["", "def", "inference_epoch_end", "(", "self", ",", "split", ",", "outputs", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "pred", ",", "label", "in", "outputs", ":", "\n", "            ", "preds", ".", "extend", "(", "pred", ")", "\n", "labels", ".", "extend", "(", "label", ")", "\n", "\n", "", "self", ".", "save_results", "(", "split", ",", "{", "\n", "'preds'", ":", "preds", ",", "\n", "'labels'", ":", "labels", ",", "\n", "}", ")", "\n", "\n", "metrics", "=", "OrderedDict", "(", ")", "\n", "for", "metric_name", "in", "self", ".", "config", ".", "classification", ".", "metric", ":", "\n", "            ", "metric", "=", "classification_metrics", "(", "preds", ",", "labels", ",", "metric_name", ",", "id2label", "=", "self", ".", "id2label", ",", "label_path_sep", "=", "self", ".", "label_path_sep", ")", "\n", "metrics", "[", "metric_name", "]", "=", "metric", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.training_step": [[97, 101], ["protoverb_trainer.ProtoVerbClassificationRunner.model", "protoverb_trainer.ProtoVerbClassificationRunner.loss_function"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "logits", "=", "self", ".", "model", "(", "batch", ")", "\n", "loss", "=", "self", ".", "loss_function", "(", "logits", ",", "batch", "[", "'label'", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.prompt_initialize": [[102, 130], ["hasattr", "hasattr", "torch.no_grad", "tqdm.tqdm.tqdm", "hasattr", "hasattr", "hasattr", "hasattr", "batch.to().to_dict.to().to_dict.to().to_dict", "protoverb_trainer.ProtoVerbClassificationRunner.model", "protoverb_trainer.ProtoVerbClassificationRunner.inner_model.verbalizer.optimize_to_initialize", "protoverb_trainer.ProtoVerbClassificationRunner.inner_model.template.optimize_to_initialize", "batch.to().to_dict.to().to_dict.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.optimize_to_initialize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.optimize_to_initialize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "prompt_initialize", "(", "self", ")", ":", "\n", "        ", "verbalizer_config", "=", "self", ".", "config", "[", "self", ".", "config", ".", "verbalizer", "]", "\n", "template_config", "=", "self", ".", "config", "[", "self", ".", "config", ".", "template", "]", "\n", "if", "not", "hasattr", "(", "self", ".", "inner_model", ".", "verbalizer", ",", "\"optimize_to_initialize\"", ")", "and", "not", "hasattr", "(", "self", ".", "inner_model", ".", "template", ",", "\"optimize_to_initialize\"", ")", ":", "\n", "            ", "return", "None", "\n", "", "if", "hasattr", "(", "verbalizer_config", ",", "\"init_using_split\"", ")", ":", "\n", "            ", "using_split", "=", "verbalizer_config", ".", "init_using_split", "\n", "", "elif", "hasattr", "(", "template_config", ",", "\"init_using_split\"", ")", ":", "\n", "            ", "using_split", "=", "template_config", ".", "init_using_split", "\n", "", "else", ":", "\n", "            ", "using_split", "=", "\"valid\"", "\n", "\n", "", "if", "using_split", "==", "\"train\"", ":", "\n", "            ", "dataloader", "=", "self", ".", "train_dataloader", "\n", "", "elif", "using_split", "==", "\"valid\"", ":", "\n", "            ", "dataloader", "=", "self", ".", "valid_dataloader", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch", "in", "tqdm", "(", "dataloader", ",", "desc", "=", "\"Init_using_{}\"", ".", "format", "(", "using_split", ")", ")", ":", "\n", "                ", "batch", "=", "batch", ".", "to", "(", "\"cuda:{}\"", ".", "format", "(", "self", ".", "config", ".", "environment", ".", "local_rank", ")", ")", ".", "to_dict", "(", ")", "\n", "logits", "=", "self", ".", "model", "(", "batch", ")", "\n", "", "if", "hasattr", "(", "self", ".", "inner_model", ".", "verbalizer", ",", "\"optimize_to_initialize\"", ")", ":", "\n", "                ", "self", ".", "inner_model", ".", "verbalizer", ".", "optimize_to_initialize", "(", ")", "\n", "", "if", "hasattr", "(", "self", ".", "inner_model", ".", "template", ",", "\"optimize_to_initialize\"", ")", ":", "\n", "                ", "self", ".", "inner_model", ".", "template", ".", "optimize_to_initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.on_fit_start": [[132, 136], ["protoverb_trainer.ProtoVerbClassificationRunner.inner_model.verbalizer.train_proto"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.train_proto"], ["", "", "", "def", "on_fit_start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Some initialization works\"\"\"", "\n", "if", "self", ".", "config", ".", "train", ".", "train_verblizer", "!=", "\"post\"", ":", "\n", "            ", "self", ".", "inner_model", ".", "verbalizer", ".", "train_proto", "(", "self", ".", "model", ",", "self", ".", "train_dataloader", ",", "self", ".", "config", ".", "environment", ".", "local_rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.fit": [[137, 165], ["protoverb_trainer.ProtoVerbClassificationRunner.set_stop_criterion", "protoverb_trainer.ProtoVerbClassificationRunner.configure_optimizers", "range", "protoverb_trainer.ProtoVerbClassificationRunner.on_fit_start", "protoverb_trainer.ProtoVerbClassificationRunner.training_epoch", "protoverb_trainer.ProtoVerbClassificationRunner.inference_epoch", "protoverb_trainer.ProtoVerbClassificationRunner.save_checkpoint", "protoverb_trainer.ProtoVerbClassificationRunner.inner_model.verbalizer.train_proto", "protoverb_trainer.ProtoVerbClassificationRunner.load_checkpoint", "openprompt.utils.logging.logger.warning", "openprompt.utils.logging.logger.info", "protoverb_trainer.ProtoVerbClassificationRunner.inner_model.verbalizer.train_proto"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.set_stop_criterion", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.configure_optimizers", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.protoverb_trainer.ProtoVerbClassificationRunner.on_fit_start", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.training_epoch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.inference_epoch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.save_checkpoint", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.train_proto", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.load_checkpoint", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.train_proto"], ["", "", "def", "fit", "(", "self", ",", "ckpt", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "set_stop_criterion", "(", ")", "\n", "self", ".", "configure_optimizers", "(", ")", "\n", "\n", "if", "ckpt", ":", "\n", "            ", "if", "not", "self", ".", "load_checkpoint", "(", "ckpt", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Train from scratch instead ...\"", ")", "\n", "", "", "if", "self", ".", "cur_epoch", "==", "0", ":", "\n", "            ", "self", ".", "on_fit_start", "(", ")", "\n", "\n", "", "for", "self", ".", "cur_epoch", "in", "range", "(", "self", ".", "cur_epoch", ",", "self", ".", "num_epochs", ")", ":", "\n", "            ", "continue_training", "=", "self", ".", "training_epoch", "(", "self", ".", "cur_epoch", ")", "\n", "score", "=", "self", ".", "inference_epoch", "(", "\"validation\"", ")", "\n", "copy", "=", "None", "\n", "if", "self", ".", "best_score", "is", "None", "or", "(", "(", "score", "-", "self", ".", "best_score", ")", ">=", "0", ")", "==", "self", ".", "config", ".", "checkpoint", ".", "higher_better", ":", "\n", "                ", "copy", "=", "'best'", "\n", "self", ".", "best_score", "=", "score", "\n", "", "self", ".", "save_checkpoint", "(", "'last'", ",", "extra", "=", "{", "\"validation_metric\"", ":", "score", "}", ",", "copy", "=", "copy", ")", "\n", "if", "continue_training", "==", "-", "1", ":", "\n", "                ", "logger", ".", "info", "(", "\"Stop training by reaching maximum num_training_steps\"", ")", "\n", "break", "\n", "", "if", "self", ".", "config", ".", "train", ".", "train_verblizer", "==", "\"alternate\"", ":", "\n", "                ", "self", ".", "inner_model", ".", "verbalizer", ".", "train_proto", "(", "self", ".", "model", ",", "self", ".", "train_dataloader", ",", "self", ".", "config", ".", "environment", ".", "local_rank", ")", "\n", "\n", "", "", "if", "self", ".", "config", ".", "train", ".", "train_verblizer", "==", "\"post\"", ":", "\n", "            ", "self", ".", "inner_model", ".", "verbalizer", ".", "train_proto", "(", "self", ".", "model", ",", "self", ".", "train_dataloader", ",", "self", ".", "config", ".", "environment", ".", "local_rank", ")", "\n", "\n", "", "return", "self", ".", "best_score", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.__init__": [[34, 45], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "placeholder_mapping", "=", "placeholder_mapping", "\n", "self", ".", "_in_on_text_set", "=", "False", "\n", "\n", "self", ".", "mixed_token_start", "=", "\"{\"", "\n", "self", ".", "mixed_token_end", "=", "\"}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.get_default_loss_ids": [[47, 59], ["None"], "methods", ["None"], ["", "def", "get_default_loss_ids", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "'''Get the loss indices for the template using mask.\n        e.g. when self.text is ``'{\"placeholder\": \"text_a\"}. {\"meta\": \"word\"} is {\"mask\"}.'``,\n        output is ``[0, 0, 0, 0, 1, 0]``.\n\n        Returns:\n            :obj:`List[int]`: A list of integers in the range [0, 1]:\n\n            - 1 for a masked tokens.\n            - 0 for a sequence tokens.\n        '''", "\n", "return", "[", "1", "if", "'mask'", "in", "d", "else", "0", "for", "d", "in", "self", ".", "text", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.get_default_shortenable_ids": [[60, 81], ["idx.append", "idx.append"], "methods", ["None"], ["", "def", "get_default_shortenable_ids", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"Every template needs shortenable_ids, denoting which part of the template can be truncate to fit\n        the language model's ``max_seq_length``. Default: the input text is shortenable, while the template text and other\n        special tokens are not shortenable.\n\n        e.g. when self.text is ``'{\"placeholder\": \"text_a\"} {\"placeholder\": \"text_b\", \"shortenable\": False} {\"meta\": \"word\"} is {\"mask\"}.'``,\n        output is ``[1, 0, 0, 0, 0, 0, 0]``.\n\n        Returns:\n            :obj:`List[int]`: A list of integers in the range ``[0, 1]``:\n\n            - 1 for the input tokens.\n            - 0 for the template sequence tokens.\n        \"\"\"", "\n", "idx", "=", "[", "]", "\n", "for", "d", "in", "self", ".", "text", ":", "\n", "            ", "if", "'shortenable'", "in", "d", ":", "\n", "                ", "idx", ".", "append", "(", "1", "if", "d", "[", "'shortenable'", "]", "else", "0", ")", "\n", "", "else", ":", "\n", "                ", "idx", ".", "append", "(", "1", "if", "'placeholder'", "in", "d", "else", "0", ")", "\n", "", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.get_default_soft_token_ids": [[82, 94], ["None"], "methods", ["None"], ["", "def", "get_default_soft_token_ids", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "r'''\n        This function identifies which tokens are soft tokens.\n\n        Sometimes tokens in the template are not from the vocabulary,\n        but a sequence of soft tokens.\n        In this case, you need to implement this function\n\n        Raises:\n            NotImplementedError: if needed, add ``soft_token_ids`` into ``registered_inputflag_names`` attribute of Template class and implement this method.\n        '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.incorporate_text_example": [[95, 120], ["enumerate", "prompt_base.Template.text.copy", "text.copy.copy.copy", "d.get", "getattr", "d.get", "ValueError"], "methods", ["None"], ["", "def", "incorporate_text_example", "(", "self", ",", "\n", "example", ":", "InputExample", ",", "\n", "text", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "text", "is", "None", ":", "\n", "            ", "text", "=", "self", ".", "text", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "            ", "text", "=", "text", ".", "copy", "(", ")", "\n", "\n", "", "for", "i", ",", "d", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "'placeholder'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", ".", "get", "(", "\"post_processing\"", ",", "lambda", "x", ":", "x", ")", "(", "getattr", "(", "example", ",", "d", "[", "'placeholder'", "]", ")", ")", "\n", "", "elif", "'meta'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", ".", "get", "(", "\"post_processing\"", ",", "lambda", "x", ":", "x", ")", "(", "example", ".", "meta", "[", "d", "[", "'meta'", "]", "]", ")", "\n", "", "elif", "'soft'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "''", ";", "# unused", "\n", "", "elif", "'mask'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "'<mask>'", "\n", "", "elif", "'special'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "'special'", "]", "\n", "", "elif", "'text'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", "[", "'text'", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'can not parse {d}'", ")", "\n", "", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template._check_template_format": [[121, 132], ["enumerate", "RuntimeError"], "methods", ["None"], ["", "def", "_check_template_format", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"check whether the template format is correct.\n        TODO: add more\n        \"\"\"", "\n", "mask_num", "=", "0", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "text", ")", ":", "\n", "            ", "if", "'mask'", "in", "d", ":", "\n", "                ", "mask_num", "+=", "1", "\n", "\n", "", "", "if", "mask_num", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"'mask' position not found in the template: {self.text}. Please Check!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.parse_text": [[136, 183], ["len", "parsed.append", "len", "text[].rstrip", "len", "len", "len", "len", "ValueError", "eval", "isinstance", "d.update", "print", "print", "exit", "traceback.format_exc"], "methods", ["None"], ["", "", "def", "parse_text", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "parsed", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "text", ")", ":", "\n", "            ", "d", "=", "{", "\"add_prefix_space\"", ":", "' '", "if", "(", "i", ">", "0", "and", "text", "[", "i", "-", "1", "]", "==", "' '", ")", "else", "''", "}", "\n", "while", "i", "<", "len", "(", "text", ")", "and", "text", "[", "i", "]", "==", "' '", ":", "\n", "                ", "d", "[", "\"add_prefix_space\"", "]", "=", "' '", "\n", "i", "=", "i", "+", "1", "\n", "", "if", "i", "==", "len", "(", "text", ")", ":", "break", "\n", "\n", "if", "text", "[", "i", "]", "!=", "self", ".", "mixed_token_start", ":", "\n", "                ", "j", "=", "i", "+", "1", "\n", "while", "j", "<", "len", "(", "text", ")", ":", "\n", "                    ", "if", "text", "[", "j", "]", "==", "self", ".", "mixed_token_start", ":", "\n", "                        ", "break", "\n", "", "j", "=", "j", "+", "1", "\n", "", "d", "[", "\"text\"", "]", "=", "text", "[", "i", ":", "j", "]", ".", "rstrip", "(", "' '", ")", "\n", "i", "=", "j", "\n", "\n", "", "else", ":", "\n", "                ", "j", "=", "i", "+", "1", "\n", "mixed_token_cnt", "=", "1", "# { {} {} } nested support", "\n", "while", "j", "<", "len", "(", "text", ")", ":", "\n", "                    ", "if", "text", "[", "j", "]", "==", "self", ".", "mixed_token_end", ":", "\n", "                        ", "mixed_token_cnt", "-=", "1", "\n", "if", "mixed_token_cnt", "==", "0", ":", "break", "\n", "", "elif", "text", "[", "j", "]", "==", "self", ".", "mixed_token_start", ":", "\n", "                        ", "mixed_token_cnt", "+=", "1", "\n", "", "j", "=", "j", "+", "1", "\n", "", "if", "j", "==", "len", "(", "text", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"mixed_token_start {self.mixed_token_start} at position {i} has no corresponding mixed_token_end {self.mixed_token_end}\"", ")", "\n", "", "dict_str", "=", "'{'", "+", "text", "[", "i", "+", "1", ":", "j", "]", "+", "'}'", "\n", "try", ":", "\n", "                    ", "val", "=", "eval", "(", "dict_str", ")", "\n", "if", "isinstance", "(", "val", ",", "set", ")", ":", "\n", "                        ", "val", "=", "{", "k", ":", "None", "for", "k", "in", "val", "}", "\n", "", "d", ".", "update", "(", "val", ")", "\n", "", "except", ":", "\n", "                    ", "import", "traceback", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "print", "(", "f\"syntax error in {dict_str}\"", ")", "\n", "exit", "(", ")", "\n", "", "i", "=", "j", "+", "1", "\n", "\n", "", "parsed", ".", "append", "(", "d", ")", "\n", "\n", "", "return", "parsed", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.wrap_one_example": [[185, 240], ["isinstance", "ValueError", "prompt_base.Template.incorporate_text_example", "example.keys", "example.keys.remove", "list", "TypeError", "example.keys.remove", "keys.append", "values.append", "zip", "wrapped_parts_to_tokenize.append", "getattr", "hasattr", "getattr", "hasattr", "len", "len", "ValueError", "dict", "getattr", "setattr", "ValueError", "zip", "getattr", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.incorporate_text_example", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["", "def", "wrap_one_example", "(", "self", ",", "\n", "example", ":", "InputExample", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "r'''Given an input example which contains input text, which can be referenced\n        by self.template.placeholder_mapping 's value.\n        This function process the example into a list of dict,\n        Each dict functions as a group, which has the sample properties, such as\n        whether it's shortenable, whether it's the masked position, whether it's soft token, etc.\n        Since a text will be tokenized in the subsequent processing procedure,\n        these attributes are broadcasted along the tokenized sentence.\n\n        Args:\n            example (:obj:`InputExample`): An :py:class:`~openprompt.data_utils.data_utils.InputExample` object, which should have attributes that are able to be filled in the template.\n\n        Returns:\n            :obj:`List[Dict]`: A list of dict of the same length as self.text. e.g. ``[{\"loss_ids\": 0, \"text\": \"It was\"}, {\"loss_ids\": 1, \"text\": \"<mask>\"}, ]``\n        '''", "\n", "\n", "if", "self", ".", "text", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"template text has not been initialized\"", ")", "\n", "", "if", "isinstance", "(", "example", ",", "InputExample", ")", ":", "\n", "            ", "text", "=", "self", ".", "incorporate_text_example", "(", "example", ")", "\n", "\n", "not_empty_keys", "=", "example", ".", "keys", "(", ")", "\n", "for", "placeholder_token", "in", "self", ".", "placeholder_mapping", ":", "\n", "                ", "not_empty_keys", ".", "remove", "(", "self", ".", "placeholder_mapping", "[", "placeholder_token", "]", ")", "# placeholder has been processed, remove", "\n", "", "not_empty_keys", ".", "remove", "(", "'meta'", ")", "# meta has been processed", "\n", "\n", "keys", ",", "values", "=", "[", "'text'", "]", ",", "[", "text", "]", "\n", "for", "inputflag_name", "in", "self", ".", "registered_inputflag_names", ":", "\n", "                ", "keys", ".", "append", "(", "inputflag_name", ")", "\n", "v", "=", "None", "\n", "if", "hasattr", "(", "self", ",", "inputflag_name", ")", "and", "getattr", "(", "self", ",", "inputflag_name", ")", "is", "not", "None", ":", "\n", "                    ", "v", "=", "getattr", "(", "self", ",", "inputflag_name", ")", "\n", "", "elif", "hasattr", "(", "self", ",", "\"get_default_\"", "+", "inputflag_name", ")", ":", "\n", "                    ", "v", "=", "getattr", "(", "self", ",", "\"get_default_\"", "+", "inputflag_name", ")", "(", ")", "\n", "setattr", "(", "self", ",", "inputflag_name", ",", "v", ")", "# cache", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"\"\"\n                    Template's inputflag '{}' is registered but not initialize.\n                    Try using template.{} = [...] to initialize\n                    or create an method get_default_{}(self) in your template.\n                    \"\"\"", ".", "format", "(", "inputflag_name", ",", "inputflag_name", ",", "inputflag_name", ")", ")", "\n", "\n", "", "if", "len", "(", "v", ")", "!=", "len", "(", "text", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Template: len({})={} doesn't match len(text)={}.\"", ".", "format", "(", "inputflag_name", ",", "len", "(", "v", ")", ",", "len", "(", "text", ")", ")", ")", "\n", "", "values", ".", "append", "(", "v", ")", "\n", "", "wrapped_parts_to_tokenize", "=", "[", "]", "\n", "for", "piece", "in", "list", "(", "zip", "(", "*", "values", ")", ")", ":", "\n", "                ", "wrapped_parts_to_tokenize", ".", "append", "(", "dict", "(", "zip", "(", "keys", ",", "piece", ")", ")", ")", "\n", "\n", "", "wrapped_parts_not_tokenize", "=", "{", "key", ":", "getattr", "(", "example", ",", "key", ")", "for", "key", "in", "not_empty_keys", "}", "\n", "return", "[", "wrapped_parts_to_tokenize", ",", "wrapped_parts_not_tokenize", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"InputExample\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.process_batch": [[241, 246], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "process_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "r\"\"\"Template should rewrite this method if you need to process the batch input such as substituting embeddings.\n        \"\"\"", "\n", "return", "batch", "# not being processed", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.post_processing_outputs": [[247, 255], ["None"], "methods", ["None"], ["", "def", "post_processing_outputs", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "r\"\"\"Post processing the outputs of language models according\n        to the need of template. Most templates don't need post processing,\n        The template like SoftTemplate, which appends soft template as a module\n        (rather than a sequence of input tokens) to the input,\n        should remove the outputs on these positions to keep the seq_len the same\n        \"\"\"", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.save": [[256, 266], ["None"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "\n", "path", ":", "str", ",", "\n", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "r'''\n        A save method API.\n\n        Args:\n            path (str): A path to save your template.\n        '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.text": [[271, 279], ["prompt_base.Template._check_template_format", "prompt_base.Template.safe_on_text_set"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template._check_template_format", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.safe_on_text_set"], ["", "@", "text", ".", "setter", "\n", "def", "text", "(", "self", ",", "text", ")", ":", "\n", "        ", "self", ".", "_text", "=", "text", "\n", "if", "text", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "not", "self", ".", "_in_on_text_set", ":", "\n", "            ", "self", ".", "safe_on_text_set", "(", ")", "\n", "", "self", ".", "_check_template_format", "(", ")", "\n", "# else:", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.safe_on_text_set": [[282, 289], ["prompt_base.Template.on_text_set"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.on_text_set"], ["", "def", "safe_on_text_set", "(", "self", ")", "->", "None", ":", "\n", "        ", "r\"\"\"With this wrapper function, setting text inside ``on_text_set()``\n            will not trigger ``on_text_set()`` again to prevent endless recursion.\n        \"\"\"", "\n", "self", ".", "_in_on_text_set", "=", "True", "\n", "self", ".", "on_text_set", "(", ")", "\n", "self", ".", "_in_on_text_set", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.on_text_set": [[290, 297], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "on_text_set", "(", "self", ")", ":", "\n", "        ", "r\"\"\"\n        A hook to do something when template text was set.\n        The designer of the template should explicitly know what should be down when the template text is set.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.from_file": [[298, 314], ["open", "[].rstrip", "openprompt.utils.logging.logger.info", "fin.readlines"], "methods", ["None"], ["", "def", "from_file", "(", "self", ",", "\n", "path", ":", "str", ",", "\n", "choice", ":", "int", "=", "0", ",", "\n", ")", ":", "\n", "        ", "r'''\n        Read the template from a local file.\n\n        Args:\n            path (:obj:`str`): The path of the local template file.\n            choice (:obj:`int`): The id-th line of the file.\n        '''", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "text", "=", "fin", ".", "readlines", "(", ")", "[", "choice", "]", ".", "rstrip", "(", ")", "\n", "logger", ".", "info", "(", "f\"using template: {text}\"", ")", "\n", "", "self", ".", "text", "=", "text", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Template.from_config": [[315, 343], ["cls", "hasattr", "openprompt.utils.utils.signature", "openprompt.config.convert_cfg_to_dict", "hasattr", "cls.from_file", "RuntimeError", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.convert_cfg_to_dict", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.from_file"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "\n", "config", ":", "CfgNode", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"load a template from template's configuration node.\n\n        Args:\n            config (:obj:`CfgNode`): the sub-configuration of template, i.e. config[config.template]\n                        if config is a global config node.\n            kwargs: Other kwargs that might be used in initialize the verbalizer.\n                    The actual value should match the arguments of __init__ functions.\n        \"\"\"", "\n", "\n", "init_args", "=", "signature", "(", "cls", ".", "__init__", ")", ".", "args", "\n", "_init_dict", "=", "{", "**", "convert_cfg_to_dict", "(", "config", ")", ",", "**", "kwargs", "}", "\n", "init_dict", "=", "{", "key", ":", "_init_dict", "[", "key", "]", "for", "key", "in", "_init_dict", "if", "key", "in", "init_args", "}", "\n", "template", "=", "cls", "(", "**", "init_dict", ")", "\n", "if", "hasattr", "(", "template", ",", "\"from_file\"", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "\"file_path\"", ")", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "if", "(", "not", "hasattr", "(", "config", ",", "\"text\"", ")", "or", "config", ".", "text", "is", "None", ")", "and", "config", ".", "file_path", "is", "not", "None", ":", "\n", "                    ", "if", "config", ".", "choice", "is", "None", ":", "\n", "                        ", "config", ".", "choice", "=", "0", "\n", "", "template", ".", "from_file", "(", "config", ".", "file_path", ",", "config", ".", "choice", ")", "\n", "", "elif", "(", "hasattr", "(", "config", ",", "\"text\"", ")", "and", "config", ".", "text", "is", "not", "None", ")", "and", "config", ".", "file_path", "is", "not", "None", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"The text can't be both set from `text` and `file_path`.\"", ")", "\n", "", "", "", "return", "template", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.__init__": [[356, 375], ["torch.Module.__init__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Optional", "[", "PreTrainedTokenizer", "]", "=", "None", ",", "\n", "classes", ":", "Optional", "[", "Sequence", "[", "str", "]", "]", "=", "None", ",", "\n", "num_classes", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "classes", "=", "classes", "\n", "if", "classes", "is", "not", "None", "and", "num_classes", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "classes", ")", "==", "num_classes", ",", "\"len(classes) != num_classes, Check you config.\"", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "", "elif", "num_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "num_classes", "=", "num_classes", "\n", "", "elif", "classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "num_classes", "=", "len", "(", "classes", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_classes", "=", "None", "\n", "# raise AttributeError(\"No able to configure num_classes\")", "\n", "", "self", ".", "_in_on_label_words_set", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.label_words": [[387, 394], ["prompt_base.Verbalizer._match_label_words_to_label_ids", "prompt_base.Verbalizer.safe_on_label_words_set"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer._match_label_words_to_label_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.safe_on_label_words_set"], ["", "@", "label_words", ".", "setter", "\n", "def", "label_words", "(", "self", ",", "label_words", ")", ":", "\n", "        ", "if", "label_words", "is", "None", ":", "\n", "            ", "return", "\n", "", "self", ".", "_label_words", "=", "self", ".", "_match_label_words_to_label_ids", "(", "label_words", ")", "\n", "if", "not", "self", ".", "_in_on_label_words_set", ":", "\n", "            ", "self", ".", "safe_on_label_words_set", "(", ")", "\n", "# else:", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer._match_label_words_to_label_ids": [[397, 423], ["isinstance", "ValueError", "set", "set", "ValueError", "isinstance", "isinstance", "ValueError", "label_words.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["", "", "def", "_match_label_words_to_label_ids", "(", "self", ",", "label_words", ")", ":", "# TODO newly add function after docs written # TODO rename this function", "\n", "        ", "\"\"\"\n        sort label words dict of verbalizer to match the label order of the classes\n        \"\"\"", "\n", "if", "isinstance", "(", "label_words", ",", "dict", ")", ":", "\n", "            ", "if", "self", ".", "classes", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"\n                classes attribute of the Verbalizer should be set since your given label words is a dict.\n                Since we will match the label word with respect to class A, to A's index in classes\n                \"\"\"", ")", "\n", "", "if", "set", "(", "label_words", ".", "keys", "(", ")", ")", "!=", "set", "(", "self", ".", "classes", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"name of classes in verbalizer are different from those of dataset\"", ")", "\n", "", "label_words", "=", "[", "# sort the dict to match dataset", "\n", "label_words", "[", "c", "]", "\n", "for", "c", "in", "self", ".", "classes", "\n", "]", "# length: label_size of the whole task", "\n", "", "elif", "isinstance", "(", "label_words", ",", "list", ")", "or", "isinstance", "(", "label_words", ",", "tuple", ")", ":", "\n", "            ", "pass", "\n", "# logger.info(\"\"\"", "\n", "# Your given label words is a list, by default, the ith label word in the list will match class i of the dataset.", "\n", "# Please make sure that they have the same order.", "\n", "# Or you can pass label words as a dict, mapping from class names to label words.", "\n", "# \"\"\")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Verbalizer label words must be list, tuple or dict\"", ")", "\n", "", "return", "label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.safe_on_label_words_set": [[424, 428], ["prompt_base.Verbalizer.on_label_words_set"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.on_label_words_set"], ["", "def", "safe_on_label_words_set", "(", "self", ",", ")", ":", "\n", "        ", "self", ".", "_in_on_label_words_set", "=", "True", "\n", "self", ".", "on_label_words_set", "(", ")", "\n", "self", ".", "_in_on_label_words_set", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.on_label_words_set": [[429, 433], ["None"], "methods", ["None"], ["", "def", "on_label_words_set", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"A hook to do something when textual label words were set.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.vocab": [[434, 439], ["hasattr", "prompt_base.Verbalizer.tokenizer.convert_ids_to_tokens", "numpy.arange().tolist", "numpy.arange"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab", "(", "self", ",", ")", "->", "Dict", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'_vocab'", ")", ":", "\n", "            ", "self", ".", "_vocab", "=", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "np", ".", "arange", "(", "self", ".", "vocab_size", ")", ".", "tolist", "(", ")", ")", "\n", "", "return", "self", ".", "_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.vocab_size": [[440, 443], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ",", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.generate_parameters": [[444, 461], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "generate_parameters", "(", "self", ",", "**", "kwargs", ")", "->", "List", ":", "\n", "        ", "r\"\"\"\n        The verbalizer can be seen as an extra layer on top of the original\n        pre-trained models. In manual verbalizer, it is a fixed one-hot vector of dimension\n        ``vocab_size``, with the position of the label word being 1 and 0 everywhere else.\n        In other situation, the parameters may be a continuous vector over the\n        vocab, with each dimension representing a weight of that token.\n        Moreover, the parameters may be set to trainable to allow label words selection.\n\n        Therefore, this function serves as an abstract methods for generating the parameters\n        of the verbalizer, and must be instantiated in any derived class.\n\n        Note that the parameters need to be registered as a part of pytorch's module to\n        It can be achieved by wrapping a tensor using ``nn.Parameter()``.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.register_calibrate_logits": [[462, 469], ["logits.detach.detach.detach"], "methods", ["None"], ["", "def", "register_calibrate_logits", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "r\"\"\"\n        This function aims to register logits that need to be calibrated, and detach the original logits from the current graph.\n        \"\"\"", "\n", "if", "logits", ".", "requires_grad", ":", "\n", "            ", "logits", "=", "logits", ".", "detach", "(", ")", "\n", "", "self", ".", "_calibrate_logits", "=", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.process_outputs": [[470, 483], ["prompt_base.Verbalizer.process_logits"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.process_logits"], ["", "def", "process_outputs", "(", "self", ",", "\n", "outputs", ":", "torch", ".", "Tensor", ",", "\n", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"By default, the verbalizer will process the logits of the PLM's\n        output.\n\n        Args:\n            logits (:obj:`torch.Tensor`): The current logits generated by pre-trained language models.\n            batch (:obj:`Union[Dict, InputFeatures]`): The input features of the data.\n        \"\"\"", "\n", "\n", "return", "self", ".", "process_logits", "(", "outputs", ",", "batch", "=", "batch", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.gather_outputs": [[484, 496], ["None"], "methods", ["None"], ["", "def", "gather_outputs", "(", "self", ",", "outputs", ":", "ModelOutput", ")", ":", "\n", "        ", "r\"\"\" retrieve useful output for the verbalizer from the whole model output\n        By default, it will only retrieve the logits\n\n        Args:\n            outputs (:obj:`ModelOutput`) The output from the pretrained language model.\n\n        Return:\n            :obj:`torch.Tensor` The gathered output, should be of shape (``batch_size``,\n            ``seq_len``, ``any``)\n        \"\"\"", "\n", "return", "outputs", ".", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.aggregate": [[497, 513], ["label_words_logits.dim", "label_words_logits.mean"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "aggregate", "(", "label_words_logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\" To aggregate logits on multiple label words into the label's logits\n        Basic aggregator: mean of each label words' logits to a label's logits\n        Can be re-implemented in advanced verbaliezer.\n\n        Args:\n            label_words_logits (:obj:`torch.Tensor`): The logits of the label words only.\n\n        Return:\n            :obj:`torch.Tensor`: The final logits calculated by the label words.\n        \"\"\"", "\n", "if", "label_words_logits", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "return", "label_words_logits", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.normalize": [[515, 527], ["torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax", "torch.softmax", "torch.softmax", "logits.reshape"], "methods", ["None"], ["", "", "def", "normalize", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n        Given logits regarding the entire vocab, calculate the probs over the label words set by softmax.\n\n        Args:\n            logits(:obj:`Tensor`): The logits of the entire vocab.\n\n        Returns:\n            :obj:`Tensor`: The probability distribution over the label words set.\n        \"\"\"", "\n", "batch_size", "=", "logits", ".", "shape", "[", "0", "]", "\n", "return", "F", ".", "softmax", "(", "logits", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ".", "reshape", "(", "*", "logits", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.project": [[528, 543], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "project", "(", "self", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"This method receives input logits of shape ``[batch_size, vocab_size]``, and use the\n        parameters of this verbalizer to project the logits over entire vocab into the\n        logits of labels words.\n\n        Args:\n            logits (:obj:`Tensor`): The logits over entire vocab generated by the pre-trained language model with shape [``batch_size``, ``max_seq_length``, ``vocab_size``]\n\n        Returns:\n            :obj:`Tensor`: The normalized probs (sum to 1) of each label .\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.handle_multi_token": [[544, 566], ["label_words_logits.select.select.select", "label_words_logits.select.select.max", "ValueError", "mask.unsqueeze", "mask.unsqueeze().sum", "mask.unsqueeze", "mask.unsqueeze"], "methods", ["None"], ["", "def", "handle_multi_token", "(", "self", ",", "label_words_logits", ",", "mask", ")", ":", "\n", "        ", "r\"\"\"\n        Support multiple methods to handle the multi tokens produced by the tokenizer.\n        We suggest using 'first' or 'max' if the some parts of the tokenization is not meaningful.\n        Can broadcast to 3-d tensor.\n\n        Args:\n            label_words_logits (:obj:`torch.Tensor`):\n\n        Returns:\n            :obj:`torch.Tensor`\n        \"\"\"", "\n", "if", "self", ".", "multi_token_handler", "==", "\"first\"", ":", "\n", "            ", "label_words_logits", "=", "label_words_logits", ".", "select", "(", "dim", "=", "-", "1", ",", "index", "=", "0", ")", "\n", "", "elif", "self", ".", "multi_token_handler", "==", "\"max\"", ":", "\n", "            ", "label_words_logits", "=", "label_words_logits", "-", "1000", "*", "(", "1", "-", "mask", ".", "unsqueeze", "(", "0", ")", ")", "\n", "label_words_logits", "=", "label_words_logits", ".", "max", "(", "dim", "=", "-", "1", ")", ".", "values", "\n", "", "elif", "self", ".", "multi_token_handler", "==", "\"mean\"", ":", "\n", "            ", "label_words_logits", "=", "(", "label_words_logits", "*", "mask", ".", "unsqueeze", "(", "0", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "/", "(", "mask", ".", "unsqueeze", "(", "0", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "+", "1e-15", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"multi_token_handler {} not configured\"", ".", "format", "(", "self", ".", "multi_token_handler", ")", ")", "\n", "", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.from_config": [[567, 595], ["cls", "hasattr", "openprompt.utils.utils.signature", "openprompt.config.convert_cfg_to_dict", "hasattr", "cls.from_file", "RuntimeError", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.convert_cfg_to_dict", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.from_file"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "\n", "config", ":", "CfgNode", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"load a verbalizer from verbalizer's configuration node.\n\n        Args:\n            config (:obj:`CfgNode`): the sub-configuration of verbalizer, i.e. ``config[config.verbalizer]``\n                        if config is a global config node.\n            kwargs: Other kwargs that might be used in initialize the verbalizer.\n                    The actual value should match the arguments of ``__init__`` functions.\n        \"\"\"", "\n", "\n", "init_args", "=", "signature", "(", "cls", ".", "__init__", ")", ".", "args", "\n", "_init_dict", "=", "{", "**", "convert_cfg_to_dict", "(", "config", ")", ",", "**", "kwargs", "}", "if", "config", "is", "not", "None", "else", "kwargs", "\n", "init_dict", "=", "{", "key", ":", "_init_dict", "[", "key", "]", "for", "key", "in", "_init_dict", "if", "key", "in", "init_args", "}", "\n", "verbalizer", "=", "cls", "(", "**", "init_dict", ")", "\n", "if", "hasattr", "(", "verbalizer", ",", "\"from_file\"", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "config", ",", "\"file_path\"", ")", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "if", "(", "not", "hasattr", "(", "config", ",", "\"label_words\"", ")", "or", "config", ".", "label_words", "is", "None", ")", "and", "config", ".", "file_path", "is", "not", "None", ":", "\n", "                    ", "if", "config", ".", "choice", "is", "None", ":", "\n", "                        ", "config", ".", "choice", "=", "0", "\n", "", "verbalizer", ".", "from_file", "(", "config", ".", "file_path", ",", "config", ".", "choice", ")", "\n", "", "elif", "(", "hasattr", "(", "config", ",", "\"label_words\"", ")", "and", "config", ".", "label_words", "is", "not", "None", ")", "and", "config", ".", "file_path", "is", "not", "None", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"The text can't be both set from `text` and `file_path`.\"", ")", "\n", "", "", "", "return", "verbalizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.from_file": [[596, 662], ["path.endswith", "path.endswith", "len", "open", "f.readlines", "path.endswith", "path.endswith", "line.strip().strip.strip().strip.strip().strip", "len", "json.load.append", "len", "RuntimeError", "label_words_per_label.strip().split", "open", "json.load", "isinstance", "label_words_single_group.append", "isinstance", "line.strip().strip.strip().strip.strip", "len", "json.load.append", "len", "label_words_per_label.strip", "len", "RuntimeError", "openprompt.utils.logging.logger.warning", "len"], "methods", ["None"], ["", "def", "from_file", "(", "self", ",", "\n", "path", ":", "str", ",", "\n", "choice", ":", "Optional", "[", "int", "]", "=", "0", ")", ":", "\n", "        ", "r\"\"\"Load the predefined label words from verbalizer file.\n        Currently support three types of file format:\n        1. a .jsonl or .json file, in which is a single verbalizer\n        in dict format.\n        2. a .jsonal or .json file, in which is a list of verbalizers in dict format\n        3.  a .txt or a .csv file, in which is the label words of a class are listed in line,\n        separated by commas. Begin a new verbalizer by an empty line.\n        This format is recommended when you don't know the name of each class.\n\n        The details of verbalizer format can be seen in :ref:`How_to_write_a_verbalizer`.\n\n        Args:\n            path (:obj:`str`): The path of the local template file.\n            choice (:obj:`int`): The choice of verbalizer in a file containing\n                             multiple verbalizers.\n\n        Returns:\n            Template : `self` object\n        \"\"\"", "\n", "if", "path", ".", "endswith", "(", "\".txt\"", ")", "or", "path", ".", "endswith", "(", "\".csv\"", ")", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "label_words_all", "=", "[", "]", "\n", "label_words_single_group", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", ".", "strip", "(", "\" \"", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "                        ", "if", "len", "(", "label_words_single_group", ")", ">", "0", ":", "\n", "                            ", "label_words_all", ".", "append", "(", "label_words_single_group", ")", "\n", "", "label_words_single_group", "=", "[", "]", "\n", "", "else", ":", "\n", "                        ", "label_words_single_group", ".", "append", "(", "line", ")", "\n", "", "", "if", "len", "(", "label_words_single_group", ")", ">", "0", ":", "# if no empty line in the last", "\n", "                    ", "label_words_all", ".", "append", "(", "label_words_single_group", ")", "\n", "", "if", "choice", ">=", "len", "(", "label_words_all", ")", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"choice {} exceed the number of verbalizers {}\"", "\n", ".", "format", "(", "choice", ",", "len", "(", "label_words_all", ")", ")", ")", "\n", "\n", "", "label_words", "=", "label_words_all", "[", "choice", "]", "\n", "label_words", "=", "[", "label_words_per_label", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "for", "label_words_per_label", "in", "label_words", "]", "\n", "\n", "", "", "elif", "path", ".", "endswith", "(", "\".jsonl\"", ")", "or", "path", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "            ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "label_words_all", "=", "json", ".", "load", "(", "f", ")", "\n", "# if it is a file containing multiple verbalizers", "\n", "if", "isinstance", "(", "label_words_all", ",", "list", ")", ":", "\n", "                    ", "if", "choice", ">=", "len", "(", "label_words_all", ")", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\"choice {} exceed the number of verbalizers {}\"", "\n", ".", "format", "(", "choice", ",", "len", "(", "label_words_all", ")", ")", ")", "\n", "", "label_words", "=", "label_words_all", "[", "choice", "]", "\n", "", "elif", "isinstance", "(", "label_words_all", ",", "dict", ")", ":", "\n", "                    ", "label_words", "=", "label_words_all", "\n", "if", "choice", ">", "0", ":", "\n", "                        ", "logger", ".", "warning", "(", "\"Choice of verbalizer is 1, but the file  \\\n                        only contains one verbalizer.\"", ")", "\n", "\n", "", "", "", "", "self", ".", "label_words", "=", "label_words", "\n", "if", "self", ".", "num_classes", "is", "not", "None", ":", "\n", "            ", "num_classes", "=", "len", "(", "self", ".", "label_words", ")", "\n", "assert", "num_classes", "==", "self", ".", "num_classes", ",", "'number of classes in the verbalizer file\\\n                                            does not match the predefined num_classes.'", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.logging.config_experiment_dir": [[8, 60], ["os.path.join", "os.path.exists", "os.path.exists", "NotADirectoryError", "os.mkdir", "item.split.split", "temp_strs.append", "datetime.datetime.now().strftime", "temp_strs.append", "shutil.rmtree", "os.mkdir", "FileExistsError", "isinstance", "str.split", "str", "datetime.datetime.now", "ValueError", "print"], "function", ["None"], ["def", "config_experiment_dir", "(", "config", ")", ":", "\n", "    ", "r\"\"\" Automatic generate log directory for experiments.\n    First generate the unique_string of one experiment, if the user\n    didn't specify one, according\n    to the user-defined keys logging.unique_string_keys.\n    Then create the directory.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "logging", ".", "path_base", ")", ":", "\n", "        ", "raise", "NotADirectoryError", "(", "f\"logging base directory `{config.logging.path_base}` not found, you should create one.\"", ")", "\n", "\n", "# generate unique string", "\n", "", "temp_strs", "=", "[", "]", "\n", "if", "config", ".", "logging", ".", "unique_string", "is", "None", ":", "\n", "        ", "for", "item", "in", "config", ".", "logging", ".", "unique_string_keys", ":", "\n", "            ", "if", "item", "==", "\"datetime\"", ":", "\n", "                ", "continue", "\n", "", "item", "=", "item", ".", "split", "(", "\".\"", ")", "# split into sub items.", "\n", "subconfig", "=", "config", "\n", "for", "key", "in", "item", ":", "\n", "                ", "try", ":", "\n", "                    ", "subconfig", "=", "subconfig", "[", "key", "]", "\n", "", "except", ":", "\n", "                    ", "raise", "ValueError", "(", "\"The unique string_key is not a config option \"", ")", "\n", "", "", "if", "not", "isinstance", "(", "subconfig", ",", "str", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "subconfig", "=", "str", "(", "subconfig", ")", "\n", "", "except", ":", "\n", "                    ", "print", "(", "\"The value of subconfig key {} can't be converted to a string\"", ".", "format", "(", "\".\"", ".", "join", "(", "item", ")", ")", ")", "\n", "continue", "\n", "\n", "", "", "subconfig", "=", "subconfig", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "temp_strs", ".", "append", "(", "subconfig", ")", "\n", "\n", "", "if", "'datetime'", "in", "config", ".", "logging", ".", "unique_string_keys", ":", "\n", "            ", "if", "config", ".", "logging", ".", "datetime_format", "is", "None", ":", "\n", "                ", "config", ".", "logging", ".", "datetime_format", "=", "'%y%m%d%H%M%S'", "\n", "", "time_str", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "config", ".", "logging", ".", "datetime_format", ")", "\n", "temp_strs", ".", "append", "(", "time_str", ")", "\n", "", "config", ".", "logging", ".", "unique_string", "=", "\"_\"", ".", "join", "(", "temp_strs", ")", "\n", "", "config", ".", "logging", ".", "path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "logging", ".", "path_base", ",", "config", ".", "logging", ".", "unique_string", ")", "\n", "\n", "# create the log directory", "\n", "if", "os", ".", "path", ".", "exists", "(", "config", ".", "logging", ".", "path", ")", ":", "\n", "        ", "if", "config", ".", "logging", ".", "overwrite", ":", "\n", "            ", "import", "shutil", "\n", "shutil", ".", "rmtree", "(", "config", ".", "logging", ".", "path", ")", "\n", "os", ".", "mkdir", "(", "config", ".", "logging", ".", "path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "FileExistsError", "(", "\"Log dir {} exists and can't overwrite!\"", ")", "\n", "", "", "else", ":", "\n", "        ", "os", ".", "mkdir", "(", "config", ".", "logging", ".", "path", ")", "\n", "", "return", "config", ".", "logging", ".", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.logging.init_logger": [[62, 85], ["isinstance", "isinstance", "logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "getattr", "getattr", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["", "def", "init_logger", "(", "\n", "log_file", ",", "\n", "log_file_level", "=", "logging", ".", "NOTSET", ",", "\n", "log_level", "=", "logging", ".", "INFO", ",", "\n", ")", ":", "\n", "    ", "if", "isinstance", "(", "log_file_level", ",", "str", ")", ":", "\n", "        ", "log_file_level", "=", "getattr", "(", "logging", ",", "log_file_level", ")", "\n", "", "if", "isinstance", "(", "log_level", ",", "str", ")", ":", "\n", "        ", "log_level", "=", "getattr", "(", "logging", ",", "log_level", ")", "\n", "", "log_format", "=", "logging", ".", "Formatter", "(", "\"[\\033[032m%(asctime)s\\033[0m %(levelname)s] %(module)s.%(funcName)s %(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "\n", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "handlers", "=", "[", "console_handler", "]", "\n", "\n", "if", "log_file", "and", "log_file", "!=", "''", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "file_handler", ".", "setLevel", "(", "log_file_level", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "", "return", "logger", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.f1": [[5, 9], ["None"], "function", ["None"], ["def", "f1", "(", "p", ",", "r", ")", ":", "\n", "    ", "if", "p", "==", "0.", "or", "r", "==", "0.", ":", "\n", "        ", "return", "0.", "\n", "", "return", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.label_path": [[10, 17], ["label.strip.strip", "label.strip.split", "range", "len", "label_set.append", "label_path_sep.join"], "function", ["None"], ["", "def", "label_path", "(", "label", ",", "label_path_sep", ")", ":", "\n", "    ", "label", "=", "label", ".", "strip", "(", "label_path_sep", ")", "\n", "label_path", "=", "label", ".", "split", "(", "label_path_sep", ")", "\n", "label_set", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "label_path", ")", ")", ":", "\n", "        ", "label_set", ".", "append", "(", "label_path_sep", ".", "join", "(", "label_path", "[", ":", "i", "+", "1", "]", ")", ")", "\n", "", "return", "label_set", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_micro": [[18, 36], ["zip", "metrics.f1", "ValueError", "metrics.label_path", "metrics.label_path", "set", "set", "len", "len", "len", "set.intersection"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.f1", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.label_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.label_path"], ["", "def", "loose_micro", "(", "labels", ",", "preds", ",", "id2label", ",", "label_path_sep", ")", ":", "\n", "    ", "if", "id2label", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"no id2label dict provided, cannot calculate loose_micro_f1 !\"", ")", "\n", "", "labels", "=", "[", "label_path", "(", "id2label", "[", "i", "]", ",", "label_path_sep", ")", "for", "i", "in", "labels", "]", "\n", "preds", "=", "[", "label_path", "(", "id2label", "[", "i", "]", ",", "label_path_sep", ")", "for", "i", "in", "preds", "]", "\n", "cnt_pred", "=", "0", "\n", "cnt_label", "=", "0", "\n", "cnt_correct", "=", "0", "\n", "for", "label", ",", "pred", "in", "zip", "(", "labels", ",", "preds", ")", ":", "\n", "        ", "label", "=", "set", "(", "label", ")", "\n", "pred", "=", "set", "(", "pred", ")", "\n", "cnt_pred", "+=", "len", "(", "pred", ")", "\n", "cnt_label", "+=", "len", "(", "label", ")", "\n", "cnt_correct", "+=", "len", "(", "label", ".", "intersection", "(", "pred", ")", ")", "\n", "", "p", "=", "cnt_correct", "/", "cnt_pred", "\n", "r", "=", "cnt_correct", "/", "cnt_label", "\n", "f", "=", "f1", "(", "p", ",", "r", ")", "\n", "return", "{", "'precision'", ":", "p", ",", "'recall'", ":", "r", ",", "'f1'", ":", "f", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_macro": [[37, 55], ["zip", "len", "len", "metrics.f1", "ValueError", "metrics.label_path", "metrics.label_path", "set", "set", "len", "len", "len", "len", "len", "len", "set.intersection", "set.intersection"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.f1", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.label_path", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.label_path"], ["", "def", "loose_macro", "(", "labels", ",", "preds", ",", "id2label", ",", "label_path_sep", ")", ":", "\n", "    ", "if", "id2label", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"no id2label dict provided, cannot calculate loose_micro_f1 !\"", ")", "\n", "", "labels", "=", "[", "label_path", "(", "id2label", "[", "i", "]", ",", "label_path_sep", ")", "for", "i", "in", "labels", "]", "\n", "preds", "=", "[", "label_path", "(", "id2label", "[", "i", "]", ",", "label_path_sep", ")", "for", "i", "in", "preds", "]", "\n", "p", "=", "0.", "\n", "r", "=", "0.", "\n", "for", "label", ",", "pred", "in", "zip", "(", "labels", ",", "preds", ")", ":", "\n", "        ", "label", "=", "set", "(", "label", ")", "\n", "pred", "=", "set", "(", "pred", ")", "\n", "if", "len", "(", "pred", ")", ">", "0", ":", "\n", "            ", "p", "+=", "len", "(", "label", ".", "intersection", "(", "pred", ")", ")", "/", "len", "(", "pred", ")", "\n", "", "if", "len", "(", "label", ")", ">", "0", ":", "\n", "            ", "r", "+=", "len", "(", "label", ".", "intersection", "(", "pred", ")", ")", "/", "len", "(", "label", ")", "\n", "", "", "p", "/=", "len", "(", "labels", ")", "\n", "r", "/=", "len", "(", "labels", ")", "\n", "f", "=", "f1", "(", "p", ",", "r", ")", "\n", "return", "{", "'precision'", ":", "p", ",", "'recall'", ":", "r", ",", "'f1'", ":", "f", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.classification_metrics": [[57, 100], ["sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "metrics.loose_micro", "metrics.loose_macro", "metrics.loose_micro", "metrics.loose_macro", "metrics.loose_micro", "ValueError", "metrics.loose_macro"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_micro", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_macro", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_micro", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_macro", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_micro", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.loose_macro"], ["", "def", "classification_metrics", "(", "preds", ":", "Sequence", "[", "int", "]", ",", "\n", "labels", ":", "Sequence", "[", "int", "]", ",", "\n", "metric", ":", "Optional", "[", "str", "]", "=", "\"micro-f1\"", ",", "\n", "id2label", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "label_path_sep", ":", "Optional", "[", "str", "]", "=", "'-'", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"evaluation metrics for classification task.\n\n    Args:\n        preds (Sequence[int]): predicted label ids for each examples\n        labels (Sequence[int]): gold label ids for each examples\n        metric (str, optional): type of evaluation function, support 'micro-f1', 'macro-f1', 'accuracy', 'precision', 'recall'. Defaults to \"micro-f1\".\n\n    Returns:\n        score (float): evaluation score\n    \"\"\"", "\n", "\n", "if", "metric", "==", "\"micro-f1\"", ":", "\n", "        ", "score", "=", "f1_score", "(", "labels", ",", "preds", ",", "average", "=", "'micro'", ")", "\n", "", "elif", "metric", "==", "\"macro-f1\"", ":", "\n", "        ", "score", "=", "f1_score", "(", "labels", ",", "preds", ",", "average", "=", "'macro'", ")", "\n", "", "elif", "metric", "==", "\"accuracy\"", ":", "\n", "        ", "score", "=", "accuracy_score", "(", "labels", ",", "preds", ")", "\n", "", "elif", "metric", "==", "\"precision\"", ":", "\n", "        ", "score", "=", "precision_score", "(", "labels", ",", "preds", ")", "\n", "", "elif", "metric", "==", "\"recall\"", ":", "\n", "        ", "score", "=", "recall_score", "(", "labels", ",", "preds", ")", "\n", "# only hierarchical label loose metric is supported TODO naive multilabel ?", "\n", "", "elif", "metric", "==", "'loose-micro-f1'", ":", "\n", "        ", "score", "=", "loose_micro", "(", "labels", ",", "preds", ",", "id2label", "=", "id2label", ",", "label_path_sep", "=", "label_path_sep", ")", "[", "'f1'", "]", "\n", "", "elif", "metric", "==", "'loose-macro-f1'", ":", "\n", "        ", "score", "=", "loose_macro", "(", "labels", ",", "preds", ",", "id2label", "=", "id2label", ",", "label_path_sep", "=", "label_path_sep", ")", "[", "'f1'", "]", "\n", "", "elif", "metric", "==", "'loose-micro-precision'", ":", "\n", "        ", "score", "=", "loose_micro", "(", "labels", ",", "preds", ",", "id2label", "=", "id2label", ",", "label_path_sep", "=", "label_path_sep", ")", "[", "'precision'", "]", "\n", "", "elif", "metric", "==", "'loose-macro-precision'", ":", "\n", "        ", "score", "=", "loose_macro", "(", "labels", ",", "preds", ",", "id2label", "=", "id2label", ",", "label_path_sep", "=", "label_path_sep", ")", "[", "'precision'", "]", "\n", "", "elif", "metric", "==", "'loose-micro-recall'", ":", "\n", "        ", "score", "=", "loose_micro", "(", "labels", ",", "preds", ",", "id2label", "=", "id2label", ",", "label_path_sep", "=", "label_path_sep", ")", "[", "'recall'", "]", "\n", "", "elif", "metric", "==", "'loose-macro-recall'", ":", "\n", "        ", "score", "=", "loose_macro", "(", "labels", ",", "preds", ",", "id2label", "=", "id2label", ",", "label_path_sep", "=", "label_path_sep", ")", "[", "'recall'", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"'{}' is not a valid evaluation type\"", ".", "format", "(", "metric", ")", ")", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.generation_metric": [[101, 146], ["zip", "ValueError", "str", "openprompt.utils.logging.logger.info", "SmoothingFunction", "ref.split.split", "word_tokenize", "scores.append", "sum", "len", "nltk.data.find", "nltk.download", "tokenized_rs.append", "sentence_bleu", "word_tokenize", "openprompt.utils.logging.logger.warning"], "function", ["None"], ["", "def", "generation_metric", "(", "hypos", ",", "\n", "refs", ",", "\n", "metric", ":", "Optional", "[", "str", "]", "=", "\"sentence_bleu\"", ")", ":", "\n", "    ", "r\"\"\"Some basic metric function for generation. However, many generation tasks\n    has their own evaluation bash scripts.\n\n    Args:\n        hypos (:obj:`str`) : the generated sentence.\n        refs (:obj:`list(str)`) : the referenced (ground-truth) sentence.\n        metric (:obj:`str`, `optional`) : the type of metric option\n\n    Returns:\n        score (float): evaluate score\n    \"\"\"", "\n", "if", "metric", "==", "\"sentence_bleu\"", ":", "\n", "# a simple criterion to visualize the performance, not rigorous.", "\n", "        ", "import", "nltk", "\n", "try", ":", "\n", "            ", "nltk_path", "=", "str", "(", "nltk", ".", "data", ".", "find", "(", "\"tokenizers/punkt\"", ")", ")", "\n", "logger", ".", "info", "(", "f\"using nltk from: {nltk_path}\"", ")", "\n", "", "except", "LookupError", ":", "\n", "            ", "nltk", ".", "download", "(", "'punkt'", ")", "\n", "\n", "", "from", "nltk", ".", "translate", ".", "bleu_score", "import", "sentence_bleu", "\n", "from", "nltk", ".", "tokenize", "import", "word_tokenize", "\n", "from", "nltk", ".", "translate", ".", "bleu_score", "import", "SmoothingFunction", "\n", "smoothie", "=", "SmoothingFunction", "(", ")", ".", "method4", "# a function for smooth", "\n", "scores", "=", "[", "]", "\n", "\n", "for", "ref", ",", "hypo", "in", "zip", "(", "refs", ",", "hypos", ")", ":", "\n", "            ", "tokenized_rs", "=", "[", "]", "\n", "ref", "=", "ref", ".", "split", "(", "\"\\n\"", ")", "\n", "for", "r", "in", "ref", ":", "\n", "                ", "tokenized_rs", ".", "append", "(", "word_tokenize", "(", "r", ")", ")", "\n", "", "hypo", "=", "word_tokenize", "(", "hypo", ")", "\n", "try", ":", "\n", "                ", "sc", "=", "sentence_bleu", "(", "tokenized_rs", ",", "hypo", ",", "smoothing_function", "=", "smoothie", ")", "\n", "", "except", "ValueError", ":", "# TODO ZeroDivisionError", "\n", "                ", "logger", ".", "warning", "(", "\"math domain error in bleu, set to 0.0. generated sentence: {}\"", ".", "format", "(", "hypo", ")", ")", "\n", "sc", "=", "0.0", "\n", "", "scores", ".", "append", "(", "sc", ")", "\n", "", "score", "=", "sum", "(", "scores", ")", "/", "len", "(", "scores", ")", "\n", "return", "score", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"'{}' is not a valid metric type.\"", ".", "format", "(", "metric", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.evaluate": [[177, 217], ["len", "len", "zip", "numpy.mean", "len", "len", "ems.append", "zip", "numpy.mean", "new_predictions.append", "crossfit_metrics.get_exact_match_over_list", "accs.append", "zip", "numpy.mean", "float", "new_predictions.append", "crossfit_metrics.get_accruacy_over_list", "f1s.append", "sklearn.metrics.f1_score", "prediction.strip", "float", "crossfit_metrics.get_f1_over_list", "crossfit_metrics.get_matthews_corr", "crossfit_metrics.evaluate.cast_to_float"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_exact_match_over_list", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_accruacy_over_list", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_f1_over_list", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_matthews_corr"], ["def", "evaluate", "(", "predictions", ",", "data", ",", "metric", ",", "**", "kwargs", ")", ":", "\n", "    ", "def", "cast_to_float", "(", "predictions", ")", ":", "\n", "        ", "new_predictions", "=", "[", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "            ", "try", ":", "\n", "                ", "new_predictions", ".", "append", "(", "float", "(", "prediction", ".", "strip", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "new_predictions", ".", "append", "(", "float", "(", "'NaN'", ")", ")", "\n", "", "", "assert", "len", "(", "new_predictions", ")", "==", "len", "(", "predictions", ")", "\n", "return", "new_predictions", "\n", "\n", "", "assert", "len", "(", "predictions", ")", "==", "len", "(", "data", ")", "\n", "\n", "if", "metric", "==", "\"EM\"", ":", "\n", "        ", "ems", "=", "[", "]", "\n", "for", "(", "prediction", ",", "dp", ")", "in", "zip", "(", "predictions", ",", "data", ")", ":", "\n", "            ", "ems", ".", "append", "(", "get_exact_match_over_list", "(", "prediction", ",", "dp", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "ems", ")", "\n", "", "elif", "metric", "==", "\"ACC\"", ":", "\n", "        ", "accs", "=", "[", "]", "\n", "for", "(", "prediction", ",", "dp", ")", "in", "zip", "(", "predictions", ",", "data", ")", ":", "\n", "            ", "accs", ".", "append", "(", "get_accruacy_over_list", "(", "prediction", ",", "dp", ",", "**", "kwargs", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "accs", ")", "\n", "", "elif", "metric", "==", "\"QA-F1\"", ":", "# haven't be tested", "\n", "        ", "f1s", "=", "[", "]", "\n", "for", "(", "prediction", ",", "dp", ")", "in", "zip", "(", "predictions", ",", "data", ")", ":", "\n", "            ", "f1s", ".", "append", "(", "get_f1_over_list", "(", "prediction", ",", "dp", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "f1s", ")", "\n", "", "elif", "metric", "==", "\"Classification-F1\"", ":", "\n", "        ", "return", "f1_score", "(", "[", "dp", "for", "dp", "in", "data", "]", ",", "predictions", ",", "average", "=", "\"macro\"", ")", "\n", "", "elif", "metric", "==", "\"Matthew-Correlation\"", ":", "# haven't be tested", "\n", "        ", "return", "get_matthews_corr", "(", "data", ",", "predictions", ")", "\n", "", "elif", "metric", "==", "\"Pearson-Correlation\"", ":", "# haven't be tested", "\n", "        ", "predictions", "=", "cast_to_float", "(", "predictions", ")", "\n", "return", "pearsonr", "(", "[", "float", "(", "dp", "[", "0", "]", ")", "for", "dp", "in", "data", "]", ",", "predictions", ")", "[", "0", "]", "\n", "", "elif", "metric", "==", "\"Rouge-L\"", ":", "# haven't be tested", "\n", "        ", "rouges", "=", "[", "]", "\n", "for", "(", "prediction", ",", "dp", ")", "in", "zip", "(", "predictions", ",", "data", ")", ":", "\n", "            ", "rouges", ".", "append", "(", "get_rouge_over_list", "(", "prediction", ",", "dp", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "rouges", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_matthews_corr": [[218, 233], ["sklearn.metrics.matthews_corrcoef", "prediction.strip", "new_predictions.append", "new_predictions.append", "new_gold.append", "new_gold.append"], "function", ["None"], ["", "", "def", "get_matthews_corr", "(", "data", ",", "predictions", ")", ":", "\n", "# only cola is using this...?", "\n", "    ", "new_predictions", "=", "[", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "        ", "if", "prediction", ".", "strip", "(", ")", "==", "\"acceptable\"", ":", "\n", "            ", "new_predictions", ".", "append", "(", "1.0", ")", "\n", "", "else", ":", "\n", "            ", "new_predictions", ".", "append", "(", "0.0", ")", "\n", "", "", "new_gold", "=", "[", "]", "\n", "for", "dp", "in", "data", ":", "\n", "        ", "if", "dp", "[", "0", "]", "==", "\"acceptable\"", ":", "\n", "            ", "new_gold", ".", "append", "(", "1.0", ")", "\n", "", "else", ":", "\n", "            ", "new_gold", ".", "append", "(", "0.0", ")", "\n", "", "", "return", "matthews_corrcoef", "(", "new_gold", ",", "new_predictions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.qa_f1_score": [[234, 245], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "crossfit_metrics.normalize_answer", "crossfit_metrics.normalize_answer"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.values", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.normalize_answer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.normalize_answer"], ["", "def", "qa_f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.accuracy": [[246, 253], ["isinstance", "isinstance", "kwargs.get", "prediction.lower", "ground_truth.lower", "len"], "function", ["None"], ["", "def", "accuracy", "(", "prediction", ",", "ground_truth", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "isinstance", "(", "prediction", ",", "str", ")", "and", "isinstance", "(", "ground_truth", ",", "str", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "\"only_compare_prefix\"", ",", "False", ")", ":", "\n", "            ", "prediction", "=", "prediction", "[", ":", "len", "(", "ground_truth", ")", "]", "\n", "", "return", "prediction", ".", "lower", "(", ")", "==", "ground_truth", ".", "lower", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "prediction", "==", "ground_truth", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_rouge_over_list": [[254, 267], ["rouge.Rouge", "set", "len", "type", "numpy.max", "crossfit_metrics.get_rouge_over_list.remove_punc"], "function", ["None"], ["", "", "def", "get_rouge_over_list", "(", "prediction", ",", "groundtruth", ")", ":", "\n", "    ", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "if", "len", "(", "remove_punc", "(", "prediction", ")", ")", "==", "0", ":", "\n", "        ", "return", "0.0", "# during early stages, it might generate nothing?", "\n", "# print(prediction)", "\n", "", "rouge", "=", "Rouge", "(", ")", "\n", "if", "type", "(", "groundtruth", ")", "==", "list", ":", "\n", "        ", "if", "len", "(", "groundtruth", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "np", ".", "max", "(", "[", "rouge", ".", "get_scores", "(", "prediction", ",", "gt", ",", "avg", "=", "True", ")", "[", "\"rouge-l\"", "]", "[", "\"f\"", "]", "for", "gt", "in", "groundtruth", "]", ")", "\n", "", "return", "rouge", ".", "get_scores", "(", "prediction", ",", "groundtruth", ",", "avg", "=", "True", ")", "[", "\"rouge-l\"", "]", "[", "\"f\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_accruacy_over_list": [[268, 274], ["crossfit_metrics.accuracy", "type", "numpy.max", "len", "crossfit_metrics.accuracy"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.accuracy", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.accuracy"], ["", "def", "get_accruacy_over_list", "(", "prediction", ",", "groundtruth", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "type", "(", "groundtruth", ")", "==", "list", ":", "\n", "        ", "if", "len", "(", "groundtruth", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "np", ".", "max", "(", "[", "accuracy", "(", "prediction", ",", "gt", ",", "**", "kwargs", ")", "for", "gt", "in", "groundtruth", "]", ")", "\n", "", "return", "accuracy", "(", "prediction", ",", "groundtruth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_f1_over_list": [[275, 281], ["crossfit_metrics.qa_f1_score", "type", "numpy.max", "len", "crossfit_metrics.qa_f1_score"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.qa_f1_score", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.qa_f1_score"], ["", "def", "get_f1_over_list", "(", "prediction", ",", "groundtruth", ")", ":", "\n", "    ", "if", "type", "(", "groundtruth", ")", "==", "list", ":", "\n", "        ", "if", "len", "(", "groundtruth", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "np", ".", "max", "(", "[", "qa_f1_score", "(", "prediction", ",", "gt", ")", "for", "gt", "in", "groundtruth", "]", ")", "\n", "", "return", "qa_f1_score", "(", "prediction", ",", "groundtruth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_exact_match_over_list": [[282, 288], ["type", "numpy.max", "crossfit_metrics.normalize_answer", "crossfit_metrics.normalize_answer", "len", "crossfit_metrics.get_exact_match_over_list"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.normalize_answer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.normalize_answer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.get_exact_match_over_list"], ["", "def", "get_exact_match_over_list", "(", "prediction", ",", "groundtruth", ")", ":", "\n", "    ", "if", "type", "(", "groundtruth", ")", "==", "list", ":", "\n", "        ", "if", "len", "(", "groundtruth", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "np", ".", "max", "(", "[", "get_exact_match_over_list", "(", "prediction", ",", "gt", ")", "for", "gt", "in", "groundtruth", "]", ")", "\n", "", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "groundtruth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.crossfit_metrics.normalize_answer": [[289, 300], ["crossfit_metrics.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.calibrate.calibrate": [[27, 45], ["prompt_model.eval", "tqdm.tqdm", "torch.cat", "torch.cat.mean", "batch.to.to", "prompt_model.forward_without_verbalize", "torch.cat.append", "prompt_model.forward_without_verbalize.detach"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.forward_without_verbalize"], ["def", "calibrate", "(", "prompt_model", ":", "PromptForClassification", ",", "dataloader", ":", "PromptDataLoader", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "r\"\"\"Calibrate. See `Paper <https://arxiv.org/abs/2108.02035>`_\n    \n    Args:\n        prompt_model (:obj:`PromptForClassification`): the PromptForClassification model.\n        dataloader (:obj:`List`): the dataloader to conduct the calibrate, could be a virtual one, i.e. contain an only-template example.\n    \n    Return:\n        (:obj:`torch.Tensor`) A tensor of shape  (vocabsize) or (mask_num, vocabsize), the logits calculated for each word in the vocabulary\n    \"\"\"", "\n", "all_logits", "=", "[", "]", "\n", "prompt_model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ",", "desc", "=", "'ContextCali'", ")", ":", "\n", "        ", "batch", "=", "batch", ".", "to", "(", "prompt_model", ".", "device", ")", "\n", "logits", "=", "prompt_model", ".", "forward_without_verbalize", "(", "batch", ")", "\n", "all_logits", ".", "append", "(", "logits", ".", "detach", "(", ")", ")", "\n", "", "all_logits", "=", "torch", ".", "cat", "(", "all_logits", ",", "dim", "=", "0", ")", "\n", "return", "all_logits", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.cuda.model_to_device": [[4, 34], ["hasattr", "model.cuda.to", "torch.nn.parallel.DataParallel", "openprompt.utils.logging.logger.info", "openprompt.utils.logging.logger.info", "RuntimeError", "model.cuda.cuda", "openprompt.utils.logging.logger.info", "openprompt.utils.logging.logger.info", "str", "model.cuda.parallelize", "model.cuda.parallelize"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.parallelize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.parallelize"], ["def", "model_to_device", "(", "model", ",", "config", ")", ":", "\n", "    ", "r\"\"\"\n    model: the model to be wrapped\n    config: the environment subconfig.\n    \"\"\"", "\n", "import", "os", "\n", "if", "\"CUDA_VISIBLE_DEVICES\"", "not", "in", "os", ".", "environ", "and", "config", ".", "cuda_visible_devices", "is", "not", "None", ":", "\n", "        ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "\",\"", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "config", ".", "cuda_visible_devices", "]", ")", "\n", "\n", "", "if", "config", ".", "model_parallel", ":", "# currently not support dataparallel and model parallel simultaneously. ", "\n", "        ", "if", "hasattr", "(", "model", ",", "\"parallelize\"", ")", ":", "\n", "            ", "if", "config", ".", "device_map", "is", "None", ":", "\n", "                ", "model", ".", "parallelize", "(", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "parallelize", "(", "config", ".", "device_map", ")", "\n", "", "logger", ".", "info", "(", "\"Using model parallel, spread across device map: {}\"", ".", "format", "(", "model", ".", "device_map", ")", ")", "\n", "return", "model", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"The model doesn't has parallelize method.\"", ")", "\n", "", "", "if", "config", ".", "num_gpus", ">", "1", ":", "\n", "        ", "local_rank_device", "=", "\"cuda:{}\"", ".", "format", "(", "config", ".", "local_rank", ")", "\n", "model", "=", "model", ".", "to", "(", "local_rank_device", ")", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DataParallel", "(", "model", ",", "output_device", "=", "local_rank_device", ")", "\n", "logger", ".", "info", "(", "\"Using DataParallel\"", ")", "\n", "", "elif", "config", ".", "num_gpus", ">", "0", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "logger", ".", "info", "(", "\"Using cuda of single gpu\"", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using cpu\"", ")", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.reproduciblity.set_seed": [[9, 21], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "openprompt.utils.logging.logger.info"], "function", ["None"], ["def", "set_seed", "(", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"set seed for reproducibility\n\n    Args:\n        seed (:obj:`int`): the seed to seed everything for reproducibility. if None, do nothing.\n    \"\"\"", "\n", "if", "seed", ":", "\n", "        ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "logger", ".", "info", "(", "f\"Global seed set to {seed}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.round_list": [[14, 31], ["enumerate", "math.ceil", "sum", "int"], "function", ["None"], ["def", "round_list", "(", "l", ":", "List", "[", "float", "]", ",", "max_sum", ":", "int", ")", ":", "\n", "    ", "r\"\"\"round a list of float e.g. [0.2,1.5, 4.5]\n    to [1,2,4] # ceil and restrict the sum to `max_sum`\n    used into balanced truncate.\n    \"\"\"", "\n", "s", "=", "0", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "l", ")", ":", "\n", "        ", "i", "=", "ceil", "(", "i", ")", "\n", "if", "s", "<=", "max_sum", ":", "\n", "            ", "s", "+=", "i", "\n", "if", "s", "<=", "max_sum", ":", "\n", "                ", "l", "[", "idx", "]", "=", "i", "\n", "", "else", ":", "\n", "                ", "l", "[", "idx", "]", "=", "i", "-", "(", "s", "-", "max_sum", ")", "\n", "", "", "else", ":", "\n", "            ", "l", "[", "idx", "]", "=", "int", "(", "0", ")", "\n", "", "", "assert", "sum", "(", "l", ")", "==", "max_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature": [[33, 67], ["inspect.signature", "collections.namedtuple", "collections.namedtuple.", "inspect.signature.parameters.values", "inspect.signature.parameters.values", "inspect.signature.parameters.values", "inspect.signature.parameters.values"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.values", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.values", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.values", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.values"], ["", "def", "signature", "(", "f", ")", ":", "\n", "    ", "r\"\"\"Get the function f 's input arguments. A useful gadget\n    when some function slot might be instantiated into multiple functions.\n    \n    Args:\n        f (:obj:`function`) : the function to get the input arguments.\n    \n    Returns:\n        namedtuple : of args, default, varargs, keywords, respectively.s\n\n    \"\"\"", "\n", "sig", "=", "inspect", ".", "signature", "(", "f", ")", "\n", "args", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "POSITIONAL_OR_KEYWORD", "\n", "]", "\n", "varargs", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "VAR_POSITIONAL", "\n", "]", "\n", "varargs", "=", "varargs", "[", "0", "]", "if", "varargs", "else", "None", "\n", "keywords", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "VAR_KEYWORD", "\n", "]", "\n", "keywords", "=", "keywords", "[", "0", "]", "if", "keywords", "else", "None", "\n", "defaults", "=", "[", "\n", "p", ".", "default", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "POSITIONAL_OR_KEYWORD", "\n", "and", "p", ".", "default", "is", "not", "p", ".", "empty", "\n", "]", "or", "None", "\n", "argspec", "=", "namedtuple", "(", "'Signature'", ",", "[", "'args'", ",", "'defaults'", ",", "\n", "'varargs'", ",", "'keywords'", "]", ")", "\n", "return", "argspec", "(", "args", ",", "defaults", ",", "varargs", ",", "keywords", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.check_config_conflicts": [[68, 80], ["openprompt.utils.logging.logger.warning"], "function", ["None"], ["", "def", "check_config_conflicts", "(", "config", ":", "CfgNode", ")", ":", "\n", "    ", "r\"\"\"check the conflicts of global config.\n    \"\"\"", "\n", "if", "config", ".", "task", "==", "\"generation\"", ":", "\n", "        ", "assert", "config", "[", "'train'", "]", ".", "teacher_forcing", "==", "True", ",", "\"You should use teacher forcing to train generation!\"", "\n", "\n", "", "if", "config", ".", "task", "==", "\"generation\"", ":", "\n", "        ", "if", "config", ".", "dataloader", ".", "max_seq_length", ">=", "config", ".", "generation", ".", "max_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\"In generation, your config.generation.max_length is shorter than config.max_seq_length\"", "\n", "\"This can lead to unexpected behavior. You should consider increasing ``config.generation.max_length``.\"", "\n", ")", "\n", "raise", "RuntimeError", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.__init__": [[27, 54], ["ValueError", "ValueError", "ValueError", "openprompt.utils.logging.logger.warning"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_examples_total", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_examples_per_label", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "also_sample_dev", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "num_examples_total_dev", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_examples_per_label_dev", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "num_examples_total", "is", "None", "and", "num_examples_per_label", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_examples_total and num_examples_per_label can't be both None.\"", ")", "\n", "", "elif", "num_examples_total", "is", "not", "None", "and", "num_examples_per_label", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_examples_total and num_examples_per_label can't be both set.\"", ")", "\n", "\n", "", "if", "also_sample_dev", ":", "\n", "            ", "if", "num_examples_total_dev", "is", "not", "None", "and", "num_examples_per_label_dev", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"num_examples_total and num_examples_per_label can't be both set.\"", ")", "\n", "", "elif", "num_examples_total_dev", "is", "None", "and", "num_examples_per_label_dev", "is", "None", ":", "\n", "                ", "logger", ".", "warning", "(", "r\"specify neither num_examples_total_dev nor num_examples_per_label_dev,\\\n                                set to default (equal to train set setting).\"", ")", "\n", "self", ".", "num_examples_total_dev", "=", "num_examples_total", "\n", "self", ".", "num_examples_per_label_dev", "=", "num_examples_per_label", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_examples_total_dev", "=", "num_examples_total_dev", "\n", "self", ".", "num_examples_per_label_dev", "=", "num_examples_per_label_dev", "\n", "\n", "", "", "self", ".", "num_examples_total", "=", "num_examples_total", "\n", "self", ".", "num_examples_per_label", "=", "num_examples_per_label", "\n", "self", ".", "also_sample_dev", "=", "also_sample_dev", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.__call__": [[55, 82], ["data_sampler.FewShotSampler._sample", "data_sampler.FewShotSampler._sample", "data_sampler.FewShotSampler._sample", "data_sampler.FewShotSampler._sample"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler._sample", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler._sample", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler._sample", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler._sample"], ["", "def", "__call__", "(", "self", ",", "\n", "train_dataset", ":", "Union", "[", "Dataset", ",", "List", "]", ",", "\n", "valid_dataset", ":", "Optional", "[", "Union", "[", "Dataset", ",", "List", "]", "]", "=", "None", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", "->", "Union", "[", "Dataset", ",", "List", "]", ":", "\n", "        ", "'''\n        The ``__call__`` function of the few-shot sampler.\n\n        Args:\n            train_dataset (:obj:`Union[Dataset, List]`): The train dataset for the sampler.\n            valid_dataset (:obj:`Union[Dataset, List]`, optional): The valid dataset for the sampler. Default to None.\n            seed (:obj:`int`, optional): The random seed for the sampling.\n\n        Returns:\n            :obj:`(Union[Dataset, List], Union[Dataset, List])`: The sampled dataset (train_dataset, valid_dataset), whose type is identical to the input.\n\n        '''", "\n", "if", "valid_dataset", "is", "None", ":", "\n", "            ", "if", "self", ".", "also_sample_dev", ":", "\n", "                ", "return", "self", ".", "_sample", "(", "train_dataset", ",", "seed", ",", "sample_twice", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_sample", "(", "train_dataset", ",", "seed", ",", "sample_twice", "=", "False", ")", "\n", "", "", "else", ":", "\n", "            ", "train_dataset", "=", "self", ".", "_sample", "(", "train_dataset", ",", "seed", ")", "\n", "if", "self", ".", "also_sample_dev", ":", "\n", "                ", "valid_dataset", "=", "self", ".", "_sample", "(", "valid_dataset", ",", "seed", ")", "\n", "", "return", "train_dataset", ",", "valid_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler._sample": [[83, 121], ["numpy.random.RandomState", "numpy.random.RandomState", "hasattr", "data_sampler.FewShotSampler.sample_per_label", "data_sampler.FewShotSampler.sample_total", "set", "isinstance", "isinstance", "range", "hasattr", "data_sampler.FewShotSampler.sample_per_label", "data_sampler.FewShotSampler.sample_total", "isinstance", "torch.utils.data.dataset.Subset", "isinstance", "len", "range", "torch.utils.data.dataset.Subset", "torch.utils.data.dataset.Subset", "len", "enumerate"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.sample_per_label", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.sample_total", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.sample_per_label", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.sample_total"], ["", "", "def", "_sample", "(", "self", ",", "\n", "data", ":", "Union", "[", "Dataset", ",", "List", "]", ",", "\n", "seed", ":", "Optional", "[", "int", "]", ",", "\n", "sample_twice", "=", "False", ",", "\n", ")", "->", "Union", "[", "Dataset", ",", "List", "]", ":", "\n", "        ", "if", "seed", "is", "not", "None", ":", "\n", "            ", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "", "indices", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", "]", "\n", "\n", "if", "self", ".", "num_examples_per_label", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "data", "[", "0", "]", ",", "'label'", ")", ",", "\"sample by label requires the data has a 'label' attribute.\"", "\n", "labels", "=", "[", "x", ".", "label", "for", "x", "in", "data", "]", "\n", "selected_ids", "=", "self", ".", "sample_per_label", "(", "indices", ",", "labels", ",", "self", ".", "num_examples_per_label", ")", "# TODO fix: use num_examples_per_label_dev for dev", "\n", "", "else", ":", "\n", "            ", "selected_ids", "=", "self", ".", "sample_total", "(", "indices", ",", "self", ".", "num_examples_total", ")", "\n", "\n", "", "if", "sample_twice", ":", "\n", "            ", "selected_set", "=", "set", "(", "selected_ids", ")", "\n", "remain_ids", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", "if", "i", "not", "in", "selected_set", "]", "\n", "if", "self", ".", "num_examples_per_label_dev", "is", "not", "None", ":", "\n", "                ", "assert", "hasattr", "(", "data", "[", "0", "]", ",", "'label'", ")", ",", "\"sample by label requires the data has a 'label' attribute.\"", "\n", "remain_labels", "=", "[", "x", ".", "label", "for", "idx", ",", "x", "in", "enumerate", "(", "data", ")", "if", "idx", "not", "in", "selected_set", "]", "\n", "selected_ids_dev", "=", "self", ".", "sample_per_label", "(", "remain_ids", ",", "remain_labels", ",", "self", ".", "num_examples_per_label_dev", ")", "\n", "", "else", ":", "\n", "                ", "selected_ids_dev", "=", "self", ".", "sample_total", "(", "remain_ids", ",", "self", ".", "num_examples_total_dev", ")", "\n", "\n", "", "if", "isinstance", "(", "data", ",", "Dataset", ")", ":", "\n", "                ", "return", "Subset", "(", "data", ",", "selected_ids", ")", ",", "Subset", "(", "data", ",", "selected_ids_dev", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "List", ")", ":", "\n", "                ", "return", "[", "data", "[", "i", "]", "for", "i", "in", "selected_ids", "]", ",", "[", "data", "[", "i", "]", "for", "i", "in", "selected_ids_dev", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "data", ",", "Dataset", ")", ":", "\n", "                ", "return", "Subset", "(", "data", ",", "selected_ids", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "List", ")", ":", "\n", "                ", "return", "[", "data", "[", "i", "]", "for", "i", "in", "selected_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.sample_total": [[123, 139], ["data_sampler.FewShotSampler.rng.shuffle", "openprompt.utils.logging.logger.info"], "methods", ["None"], ["", "", "", "def", "sample_total", "(", "self", ",", "indices", ":", "List", ",", "num_examples_total", ")", ":", "\n", "        ", "'''\n        Use the total number of examples for few-shot sampling (Strategy ``I``).\n\n        Args:\n            indices(:obj:`List`): The random indices of the whole datasets.\n            num_examples_total(:obj:`int`): The total number of examples.\n\n        Returns:\n            :obj:`List`: The selected indices with the size of ``num_examples_total``.\n\n        '''", "\n", "self", ".", "rng", ".", "shuffle", "(", "indices", ")", "\n", "selected_ids", "=", "indices", "[", ":", "num_examples_total", "]", "\n", "logger", ".", "info", "(", "\"Selected examples (mixed) {}\"", ".", "format", "(", "selected_ids", ")", ")", "\n", "return", "selected_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_sampler.FewShotSampler.sample_per_label": [[140, 169], ["collections.defaultdict", "zip", "collections.defaultdict.items", "numpy.array", "data_sampler.FewShotSampler.rng.shuffle", "selected_ids.tolist.tolist.tolist", "openprompt.utils.logging.logger.info", "ids_per_label[].append", "numpy.array", "data_sampler.FewShotSampler.rng.shuffle", "selected_ids.tolist.tolist.extend", "len", "openprompt.utils.logging.logger.info", "tmp[].tolist"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items"], ["", "def", "sample_per_label", "(", "self", ",", "indices", ":", "List", ",", "labels", ",", "num_examples_per_label", ")", ":", "\n", "        ", "'''\n        Use the number of examples per class for few-shot sampling (Strategy ``II``).\n        If the number of examples is not enough, a warning will pop up.\n\n        Args:\n            indices(:obj:`List`): The random indices of the whole datasets.\n            labels(:obj:`List`): The list of the labels.\n            num_examples_per_label(:obj:`int`): The total number of examples for each class.\n\n        Returns:\n            :obj:`List`: The selected indices with the size of ``num_examples_total``.\n        '''", "\n", "\n", "ids_per_label", "=", "defaultdict", "(", "list", ")", "\n", "selected_ids", "=", "[", "]", "\n", "for", "idx", ",", "label", "in", "zip", "(", "indices", ",", "labels", ")", ":", "\n", "            ", "ids_per_label", "[", "label", "]", ".", "append", "(", "idx", ")", "\n", "", "for", "label", ",", "ids", "in", "ids_per_label", ".", "items", "(", ")", ":", "\n", "            ", "tmp", "=", "np", ".", "array", "(", "ids", ")", "\n", "self", ".", "rng", ".", "shuffle", "(", "tmp", ")", "\n", "if", "len", "(", "tmp", ")", "<", "num_examples_per_label", ":", "\n", "                ", "logger", ".", "info", "(", "\"Not enough examples of label {} can be sampled\"", ".", "format", "(", "label", ")", ")", "\n", "", "selected_ids", ".", "extend", "(", "tmp", "[", ":", "num_examples_per_label", "]", ".", "tolist", "(", ")", ")", "\n", "", "selected_ids", "=", "np", ".", "array", "(", "selected_ids", ")", "\n", "self", ".", "rng", ".", "shuffle", "(", "selected_ids", ")", "\n", "selected_ids", "=", "selected_ids", ".", "tolist", "(", ")", "\n", "logger", ".", "info", "(", "\"Selected examples {}\"", ".", "format", "(", "selected_ids", ")", ")", "\n", "return", "selected_ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.conditional_generation_dataset.WebNLGProcessor.__init__": [[54, 57], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.conditional_generation_dataset.WebNLGProcessor.get_examples": [[58, 108], ["os.path.join", "enumerate", "open", "json.load", "enumerate", "len", "len", "len", "len", "split.lower", "enumerate", "enumerate", "rela_lst.append", "split.lower", "full_src_lst.append", "full_rela_lst.append", "full_tgt_lst.append", "zip", "openprompt.data_utils.utils.InputExample", "examples.append", "zip", "openprompt.data_utils.utils.InputExample", "examples.append", "str", "str", "full_tgt_lst.append", "full_src_lst.append", "full_rela_lst.append", "temp.append", "str", "str"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ":", "str", ",", "split", ":", "str", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.json\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "            ", "lines_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "full_rela_lst", "=", "[", "]", "\n", "full_src_lst", "=", "[", "]", "\n", "full_tgt_lst", "=", "[", "]", "\n", "guid_lst", "=", "[", "]", "\n", "\n", "for", "i", ",", "example", "in", "enumerate", "(", "lines_dict", "[", "'entries'", "]", ")", ":", "\n", "            ", "sents", "=", "example", "[", "str", "(", "i", "+", "1", ")", "]", "[", "'lexicalisations'", "]", "\n", "triples", "=", "example", "[", "str", "(", "i", "+", "1", ")", "]", "[", "'modifiedtripleset'", "]", "\n", "\n", "rela_lst", "=", "[", "]", "\n", "temp_triples", "=", "''", "\n", "for", "j", ",", "tripleset", "in", "enumerate", "(", "triples", ")", ":", "\n", "                ", "subj", ",", "rela", ",", "obj", "=", "tripleset", "[", "'subject'", "]", ",", "tripleset", "[", "'property'", "]", ",", "tripleset", "[", "'object'", "]", "\n", "rela_lst", ".", "append", "(", "rela", ")", "\n", "temp_triples", "+=", "' | '", "\n", "temp_triples", "+=", "'{} : {} : {}'", ".", "format", "(", "subj", ",", "rela", ",", "obj", ")", "\n", "\n", "", "if", "split", ".", "lower", "(", ")", "==", "\"train\"", ":", "\n", "                ", "for", "sent", "in", "sents", ":", "\n", "                    ", "if", "sent", "[", "\"comment\"", "]", "==", "'good'", ":", "\n", "                        ", "full_tgt_lst", ".", "append", "(", "sent", "[", "\"lex\"", "]", ")", "\n", "full_src_lst", ".", "append", "(", "temp_triples", ")", "\n", "full_rela_lst", ".", "append", "(", "rela_lst", ")", "\n", "", "", "", "else", ":", "\n", "                ", "full_src_lst", ".", "append", "(", "temp_triples", ")", "\n", "full_rela_lst", ".", "append", "(", "rela_lst", ")", "\n", "temp", "=", "[", "]", "\n", "for", "sent", "in", "sents", ":", "\n", "                    ", "if", "sent", "[", "\"comment\"", "]", "==", "'good'", ":", "\n", "                        ", "temp", ".", "append", "(", "sent", "[", "\"lex\"", "]", ")", "\n", "", "", "full_tgt_lst", ".", "append", "(", "\"\\n\"", ".", "join", "(", "temp", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "full_rela_lst", ")", "==", "len", "(", "full_src_lst", ")", "\n", "assert", "len", "(", "full_rela_lst", ")", "==", "len", "(", "full_tgt_lst", ")", "\n", "\n", "if", "split", ".", "lower", "(", ")", "==", "\"train\"", ":", "\n", "            ", "for", "i", ",", "(", "src", ",", "tgt", ")", "in", "enumerate", "(", "zip", "(", "full_src_lst", ",", "full_tgt_lst", ")", ")", ":", "\n", "                ", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "i", ")", ",", "text_a", "=", "src", ",", "tgt_text", "=", "tgt", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", ",", "(", "src", ",", "tgt", ")", "in", "enumerate", "(", "zip", "(", "full_src_lst", ",", "full_tgt_lst", ")", ")", ":", "\n", "                ", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "i", ")", ",", "text_a", "=", "src", ",", "tgt_text", "=", "tgt", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.conditional_generation_dataset.WebNLGProcessor.get_src_tgt_len_ratio": [[110, 112], ["None"], "methods", ["None"], ["", "def", "get_src_tgt_len_ratio", "(", "self", ",", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.MnliProcessor.__init__": [[32, 35], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.MnliProcessor.get_examples": [[36, 51], ["os.path.join", "open", "csv.reader", "enumerate", "headline.replace", "body.replace", "openprompt.data_utils.utils.InputExample", "examples.append", "str", "int"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "\n", "                ", "label", ",", "headline", ",", "body", "=", "row", "\n", "text_a", "=", "headline", ".", "replace", "(", "'\\\\'", ",", "' '", ")", "\n", "text_b", "=", "body", ".", "replace", "(", "'\\\\'", ",", "' '", ")", "\n", "example", "=", "InputExample", "(", "\n", "guid", "=", "str", "(", "idx", ")", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "int", "(", "label", ")", "-", "1", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.AgnewsProcessor.__init__": [[83, 86], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"World\"", ",", "\"Sports\"", ",", "\"Business\"", ",", "\"Tech\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.AgnewsProcessor.get_examples": [[87, 99], ["os.path.join", "open", "csv.reader", "enumerate", "headline.replace", "body.replace", "openprompt.data_utils.utils.InputExample", "examples.append", "str", "int"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "label", ",", "headline", ",", "body", "=", "row", "\n", "text_a", "=", "headline", ".", "replace", "(", "'\\\\'", ",", "' '", ")", "\n", "text_b", "=", "body", ".", "replace", "(", "'\\\\'", ",", "' '", ")", "\n", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "idx", ")", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "int", "(", "label", ")", "-", "1", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.DBpediaProcessor.__init__": [[125, 128], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"company\"", ",", "\"school\"", ",", "\"artist\"", ",", "\"athlete\"", ",", "\"politics\"", ",", "\"transportation\"", ",", "\"building\"", ",", "\"river\"", ",", "\"village\"", ",", "\"animal\"", ",", "\"plant\"", ",", "\"album\"", ",", "\"film\"", ",", "\"book\"", ",", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.DBpediaProcessor.get_examples": [[129, 142], ["open", "os.path.join", "int", "open", "enumerate", "x.strip", "open.readlines", "os.path.join", "line.strip().split", "openprompt.data_utils.utils.InputExample", "examples.append", "line.strip", "str", "int"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "label_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}_labels.txt\"", ".", "format", "(", "split", ")", ")", ",", "'r'", ")", "\n", "labels", "=", "[", "int", "(", "x", ".", "strip", "(", ")", ")", "for", "x", "in", "label_file", ".", "readlines", "(", ")", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'{}.txt'", ".", "format", "(", "split", ")", ")", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "fin", ")", ":", "\n", "                ", "splited", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\". \"", ")", "\n", "text_a", ",", "text_b", "=", "splited", "[", "0", "]", ",", "splited", "[", "1", ":", "]", "\n", "text_a", "=", "text_a", "+", "\".\"", "\n", "text_b", "=", "\". \"", ".", "join", "(", "text_b", ")", "\n", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "idx", ")", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "int", "(", "labels", "[", "idx", "]", ")", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.ImdbProcessor.__init__": [[169, 172], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"negative\"", ",", "\"positive\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.ImdbProcessor.get_examples": [[173, 183], ["open", "os.path.join", "int", "open", "enumerate", "x.strip", "open.readlines", "os.path.join", "line.strip", "openprompt.data_utils.utils.InputExample", "examples.append", "str", "int"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "label_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}_labels.txt\"", ".", "format", "(", "split", ")", ")", ",", "'r'", ")", "\n", "labels", "=", "[", "int", "(", "x", ".", "strip", "(", ")", ")", "for", "x", "in", "label_file", ".", "readlines", "(", ")", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'{}.txt'", ".", "format", "(", "split", ")", ")", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "fin", ")", ":", "\n", "                ", "text_a", "=", "line", ".", "strip", "(", ")", "\n", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "idx", ")", ",", "text_a", "=", "text_a", ",", "label", "=", "int", "(", "labels", "[", "idx", "]", ")", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.ImdbProcessor.get_test_labels_only": [[185, 190], ["open", "os.path.join", "int", "x.strip", "open.readlines"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_test_labels_only", "(", "data_dir", ",", "dirname", ")", ":", "\n", "        ", "label_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "dirname", ",", "\"{}_labels.txt\"", ".", "format", "(", "'test'", ")", ")", ",", "'r'", ")", "\n", "labels", "=", "[", "int", "(", "x", ".", "strip", "(", ")", ")", "for", "x", "in", "label_file", ".", "readlines", "(", ")", "]", "\n", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.AmazonProcessor.__init__": [[237, 240], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"bad\"", ",", "\"good\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.AmazonProcessor.get_examples": [[241, 251], ["open", "os.path.join", "int", "open", "enumerate", "x.strip", "open.readlines", "os.path.join", "line.strip", "openprompt.data_utils.utils.InputExample", "examples.append", "str", "int"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "label_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}_labels.txt\"", ".", "format", "(", "split", ")", ")", ",", "'r'", ")", "\n", "labels", "=", "[", "int", "(", "x", ".", "strip", "(", ")", ")", "for", "x", "in", "label_file", ".", "readlines", "(", ")", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'{}.txt'", ".", "format", "(", "split", ")", ")", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "fin", ")", ":", "\n", "                ", "text_a", "=", "line", ".", "strip", "(", ")", "\n", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "idx", ")", ",", "text_a", "=", "text_a", ",", "label", "=", "int", "(", "labels", "[", "idx", "]", ")", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.YahooProcessor.__init__": [[266, 270], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"Society & Culture\"", ",", "\"Science & Mathematics\"", ",", "\"Health\"", ",", "\"Education & Reference\"", ",", "\"Computers & Internet\"", ",", "\"Sports\"", ",", "\"Business & Finance\"", ",", "\"Entertainment & Music\"", "\n", ",", "\"Family & Relationships\"", ",", "\"Politics & Government\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.YahooProcessor.get_examples": [[271, 284], ["os.path.join", "open", "csv.reader", "enumerate", "answer.replace().replace", "openprompt.data_utils.utils.InputExample", "examples.append", "question_title.replace().replace", "question_body.replace().replace", "answer.replace", "str", "int", "question_title.replace", "question_body.replace"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "label", ",", "question_title", ",", "question_body", ",", "answer", "=", "row", "\n", "text_a", "=", "' '", ".", "join", "(", "[", "question_title", ".", "replace", "(", "'\\\\n'", ",", "' '", ")", ".", "replace", "(", "'\\\\'", ",", "' '", ")", ",", "\n", "question_body", ".", "replace", "(", "'\\\\n'", ",", "' '", ")", ".", "replace", "(", "'\\\\'", ",", "' '", ")", "]", ")", "\n", "text_b", "=", "answer", ".", "replace", "(", "'\\\\n'", ",", "' '", ")", ".", "replace", "(", "'\\\\'", ",", "' '", ")", "\n", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "idx", ")", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "int", "(", "label", ")", "-", "1", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.SST2Processor.__init__": [[335, 338], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "'0'", ",", "'1'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.text_classification_dataset.SST2Processor.get_examples": [[339, 352], ["os.path.join", "open", "f.readlines", "enumerate", "line.strip().split", "openprompt.data_utils.utils.InputExample", "examples.append", "line.strip", "text_classification_dataset.SST2Processor.get_label_id"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.tsv\"", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "lines", "[", "1", ":", "]", ")", ":", "\n", "                ", "linelist", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "text_a", "=", "linelist", "[", "0", "]", "\n", "label", "=", "linelist", "[", "1", "]", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "split", ",", "idx", ")", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "label", "=", "self", ".", "get_label_id", "(", "label", ")", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.relation_classification_dataset.TACREDProcessor.__init__": [[51, 54], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "labels", "=", "[", "\n", "\"no_relation\"", ",", "\"org:founded\"", ",", "\"org:subsidiaries\"", ",", "\"per:date_of_birth\"", ",", "\"per:cause_of_death\"", ",", "\"per:age\"", ",", "\"per:stateorprovince_of_birth\"", ",", "\"per:countries_of_residence\"", ",", "\"per:country_of_birth\"", ",", "\"per:stateorprovinces_of_residence\"", ",", "\"org:website\"", ",", "\"per:cities_of_residence\"", ",", "\"per:parents\"", ",", "\"per:employee_of\"", ",", "\"per:city_of_birth\"", ",", "\"org:parents\"", ",", "\"org:political/religious_affiliation\"", ",", "\"per:schools_attended\"", ",", "\"per:country_of_death\"", ",", "\"per:children\"", ",", "\"org:top_members/employees\"", ",", "\"per:date_of_death\"", ",", "\"org:members\"", ",", "\"org:alternate_names\"", ",", "\"per:religion\"", ",", "\"org:member_of\"", ",", "\"org:city_of_headquarters\"", ",", "\"per:origin\"", ",", "\"org:shareholders\"", ",", "\"per:charges\"", ",", "\"per:title\"", ",", "\"org:number_of_employees/members\"", ",", "\"org:dissolved\"", ",", "\"org:country_of_headquarters\"", ",", "\"per:alternate_names\"", ",", "\"per:siblings\"", ",", "\"org:stateorprovince_of_headquarters\"", ",", "\"per:spouse\"", ",", "\"per:other_family\"", ",", "\"per:city_of_death\"", ",", "\"per:stateorprovince_of_death\"", ",", "\"org:founded_by\"", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.relation_classification_dataset.TACREDProcessor.get_examples": [[56, 74], ["os.path.join", "open", "json.load", "relation_classification_dataset.TACREDProcessor.get_label_id", "openprompt.data_utils.utils.InputExample", "examples.append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.json\"", ".", "format", "(", "split", ")", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "example_jsons", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "example_json", "in", "example_jsons", ":", "\n", "                ", "guid", "=", "example_json", "[", "\"id\"", "]", "\n", "label", "=", "self", ".", "get_label_id", "(", "example_json", "[", "\"relation\"", "]", ")", "\n", "tokens", "=", "example_json", "[", "\"token\"", "]", "\n", "text_a", "=", "\" \"", ".", "join", "(", "tokens", ")", "\n", "meta", "=", "{", "\n", "\"head\"", ":", "\" \"", ".", "join", "(", "tokens", "[", "example_json", "[", "\"subj_start\"", "]", ":", "example_json", "[", "\"subj_end\"", "]", "+", "1", "]", ")", ",", "\n", "\"tail\"", ":", "\" \"", ".", "join", "(", "tokens", "[", "example_json", "[", "\"obj_start\"", "]", ":", "example_json", "[", "\"obj_end\"", "]", "+", "1", "]", ")", ",", "\n", "}", "\n", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "meta", "=", "meta", ",", "label", "=", "label", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.relation_classification_dataset.TACREVProcessor.__init__": [[103, 107], ["relation_classification_dataset.TACREDProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\n", "\"no_relation\"", ",", "\"org:founded\"", ",", "\"org:subsidiaries\"", ",", "\"per:date_of_birth\"", ",", "\"per:cause_of_death\"", ",", "\"per:age\"", ",", "\"per:stateorprovince_of_birth\"", ",", "\"per:countries_of_residence\"", ",", "\"per:country_of_birth\"", ",", "\"per:stateorprovinces_of_residence\"", ",", "\"org:website\"", ",", "\"per:cities_of_residence\"", ",", "\"per:parents\"", ",", "\"per:employee_of\"", ",", "\"per:city_of_birth\"", ",", "\"org:parents\"", ",", "\"org:political/religious_affiliation\"", ",", "\"per:schools_attended\"", ",", "\"per:country_of_death\"", ",", "\"per:children\"", ",", "\"org:top_members/employees\"", ",", "\"per:date_of_death\"", ",", "\"org:members\"", ",", "\"org:alternate_names\"", ",", "\"per:religion\"", ",", "\"org:member_of\"", ",", "\"org:city_of_headquarters\"", ",", "\"per:origin\"", ",", "\"org:shareholders\"", ",", "\"per:charges\"", ",", "\"per:title\"", ",", "\"org:number_of_employees/members\"", ",", "\"org:dissolved\"", ",", "\"org:country_of_headquarters\"", ",", "\"per:alternate_names\"", ",", "\"per:siblings\"", ",", "\"org:stateorprovince_of_headquarters\"", ",", "\"per:spouse\"", ",", "\"per:other_family\"", ",", "\"per:city_of_death\"", ",", "\"per:stateorprovince_of_death\"", ",", "\"org:founded_by\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.relation_classification_dataset.ReTACREDProcessor.__init__": [[137, 141], ["relation_classification_dataset.TACREDProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\n", "\"no_relation\"", ",", "\"org:members\"", ",", "\"per:siblings\"", ",", "\"per:spouse\"", ",", "\"org:country_of_branch\"", ",", "\"per:country_of_death\"", ",", "\"per:parents\"", ",", "\"per:stateorprovinces_of_residence\"", ",", "\"org:top_members/employees\"", ",", "\"org:dissolved\"", ",", "\"org:number_of_employees/members\"", ",", "\"per:stateorprovince_of_death\"", ",", "\"per:origin\"", ",", "\"per:children\"", ",", "\"org:political/religious_affiliation\"", ",", "\"per:city_of_birth\"", ",", "\"per:title\"", ",", "\"org:shareholders\"", ",", "\"per:employee_of\"", ",", "\"org:member_of\"", ",", "\"org:founded_by\"", ",", "\"per:countries_of_residence\"", ",", "\"per:other_family\"", ",", "\"per:religion\"", ",", "\"per:identity\"", ",", "\"per:date_of_birth\"", ",", "\"org:city_of_branch\"", ",", "\"org:alternate_names\"", ",", "\"org:website\"", ",", "\"per:cause_of_death\"", ",", "\"org:stateorprovince_of_branch\"", ",", "\"per:schools_attended\"", ",", "\"per:country_of_birth\"", ",", "\"per:date_of_death\"", ",", "\"per:city_of_death\"", ",", "\"org:founded\"", ",", "\"per:cities_of_residence\"", ",", "\"per:age\"", ",", "\"per:charges\"", ",", "\"per:stateorprovince_of_birth\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.relation_classification_dataset.SemEvalProcessor.__init__": [[174, 177], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"Other\"", ",", "\"Member-Collection(e1,e2)\"", ",", "\"Entity-Destination(e1,e2)\"", ",", "\"Content-Container(e1,e2)\"", ",", "\"Message-Topic(e1,e2)\"", ",", "\"Entity-Origin(e1,e2)\"", ",", "\"Cause-Effect(e1,e2)\"", ",", "\"Product-Producer(e1,e2)\"", ",", "\"Instrument-Agency(e1,e2)\"", ",", "\"Component-Whole(e1,e2)\"", ",", "\"Member-Collection(e2,e1)\"", ",", "\"Entity-Destination(e2,e1)\"", ",", "\"Content-Container(e2,e1)\"", ",", "\"Message-Topic(e2,e1)\"", ",", "\"Entity-Origin(e2,e1)\"", ",", "\"Cause-Effect(e2,e1)\"", ",", "\"Product-Producer(e2,e1)\"", ",", "\"Instrument-Agency(e2,e1)\"", ",", "\"Component-Whole(e2,e1)\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.relation_classification_dataset.SemEvalProcessor.get_examples": [[178, 194], ["os.path.join", "open", "enumerate", "json.loads", "relation_classification_dataset.SemEvalProcessor.get_label_id", "openprompt.data_utils.utils.InputExample", "examples.append", "str"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "choicex", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "label", "=", "self", ".", "get_label_id", "(", "example_json", "[", "\"relation\"", "]", ")", "\n", "text_a", "=", "\" \"", ".", "join", "(", "example_json", "[", "\"token\"", "]", ")", "\n", "meta", "=", "{", "\n", "\"head\"", ":", "example_json", "[", "\"h\"", "]", "[", "\"name\"", "]", ",", "\n", "\"tail\"", ":", "example_json", "[", "\"t\"", "]", "[", "\"name\"", "]", ",", "\n", "}", "\n", "\n", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "choicex", ")", ",", "text_a", "=", "text_a", ",", "meta", "=", "meta", ",", "label", "=", "label", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.nli_dataset.SNLIProcessor.__init__": [[52, 55], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "'entailment'", ",", "'neutral'", ",", "'contradiction'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.nli_dataset.SNLIProcessor.get_examples": [[56, 70], ["os.path.join", "open", "f.readlines", "enumerate", "line.strip().split", "openprompt.data_utils.InputExample", "examples.append", "line.strip", "nli_dataset.SNLIProcessor.get_label_id"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.tsv\"", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "lines", "[", "1", ":", "]", ")", ":", "\n", "                ", "linelist", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "split", ",", "idx", ")", "\n", "label", "=", "linelist", "[", "-", "1", "]", "\n", "text_a", "=", "linelist", "[", "7", "]", "\n", "text_b", "=", "linelist", "[", "8", "]", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "self", ".", "get_label_id", "(", "label", ")", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.__init__": [[27, 36], ["open", "f.readlines"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "labels", ":", "Optional", "[", "Sequence", "[", "Any", "]", "]", "=", "None", ",", "\n", "labels_path", ":", "Optional", "[", "str", "]", "=", "None", "\n", ")", ":", "\n", "        ", "if", "labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "labels", "=", "labels", "\n", "", "elif", "labels_path", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "labels_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "self", ".", "labels", "=", "' '", ".", "join", "(", "f", ".", "readlines", "(", ")", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.labels": [[43, 48], ["enumerate"], "methods", ["None"], ["", "@", "labels", ".", "setter", "\n", "def", "labels", "(", "self", ",", "labels", ":", "Sequence", "[", "Any", "]", ")", ":", "\n", "        ", "if", "labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "_labels", "=", "labels", "\n", "self", ".", "_label_mapping", "=", "{", "k", ":", "i", "for", "(", "i", ",", "k", ")", "in", "enumerate", "(", "labels", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.label_mapping": [[55, 59], ["sorted", "label_mapping.items"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items"], ["", "@", "label_mapping", ".", "setter", "\n", "def", "label_mapping", "(", "self", ",", "label_mapping", ":", "Mapping", "[", "Any", ",", "int", "]", ")", ":", "\n", "        ", "self", ".", "_labels", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sorted", "(", "label_mapping", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ")", "]", "\n", "self", ".", "_label_mapping", "=", "label_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.id2label": [[60, 65], ["hasattr", "ValueError", "enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "id2label", "(", "self", ")", "->", "Dict", "[", "int", ",", "Any", "]", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"_labels\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"DataProcessor doesn't set labels or label_mapping yet\"", ")", "\n", "", "return", "{", "i", ":", "k", "for", "(", "i", ",", "k", ")", "in", "enumerate", "(", "self", ".", "_labels", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id": [[67, 77], ["None"], "methods", ["None"], ["", "def", "get_label_id", "(", "self", ",", "label", ":", "Any", ")", "->", "int", ":", "\n", "        ", "\"\"\"get label id of the corresponding label\n\n        Args:\n            label: label in dataset\n\n        Returns:\n            int: the index of label\n        \"\"\"", "\n", "return", "self", ".", "label_mapping", "[", "label", "]", "if", "label", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_labels": [[78, 85], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "\"\"\"get labels of the dataset\n\n        Returns:\n            List[Any]: labels of the dataset\n        \"\"\"", "\n", "return", "self", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_num_labels": [[86, 93], ["len"], "methods", ["None"], ["", "def", "get_num_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"get the number of labels in the dataset\n\n        Returns:\n            int: number of labels in the dataset\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_train_examples": [[94, 101], ["data_processor.DataProcessor.get_examples"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "InputExample", ":", "\n", "        ", "\"\"\"\n        get train examples from the training file under :obj:`data_dir`\n\n        call ``get_examples(data_dir, \"train\")``, see :py:meth:`~openprompt.data_utils.data_processor.DataProcessor.get_examples`\n        \"\"\"", "\n", "return", "self", ".", "get_examples", "(", "data_dir", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_dev_examples": [[102, 109], ["data_processor.DataProcessor.get_examples"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "\"\"\"\n        get dev examples from the development file under :obj:`data_dir`\n\n        call ``get_examples(data_dir, \"dev\")``, see :py:meth:`~openprompt.data_utils.data_processor.DataProcessor.get_examples`\n        \"\"\"", "\n", "return", "self", ".", "get_examples", "(", "data_dir", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_test_examples": [[110, 117], ["data_processor.DataProcessor.get_examples"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "\"\"\"\n        get test examples from the test file under :obj:`data_dir`\n\n        call ``get_examples(data_dir, \"test\")``, see :py:meth:`~openprompt.data_utils.data_processor.DataProcessor.get_examples`\n        \"\"\"", "\n", "return", "self", ".", "get_examples", "(", "data_dir", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_unlabeled_examples": [[118, 125], ["data_processor.DataProcessor.get_examples"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples"], ["", "def", "get_unlabeled_examples", "(", "self", ",", "data_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "\"\"\"\n        get unlabeled examples from the unlabeled file under :obj:`data_dir`\n\n        call ``get_examples(data_dir, \"unlabeled\")``, see :py:meth:`~openprompt.data_utils.data_processor.DataProcessor.get_examples`\n        \"\"\"", "\n", "return", "self", ".", "get_examples", "(", "data_dir", ",", "\"unlabeled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_examples": [[126, 142], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_examples", "(", "self", ",", "data_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "split", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "\"\"\"get the :obj:`split` of dataset under :obj:`data_dir`\n\n        :obj:`data_dir` is the base path of the dataset, for example:\n\n        training file could be located in ``data_dir/train.txt``\n\n        Args:\n            data_dir (str): the base path of the dataset\n            split (str): ``train`` / ``dev`` / ``test`` / ``unlabeled``\n\n        Returns:\n            List[InputExample]: return a list of :py:class:`~openprompt.data_utils.data_utils.InputExample`\n        \"\"\"", "\n", "raise", "NotImplementedError", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.typing_dataset.FewNERDProcessor.__init__": [[57, 68], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\n", "\"person-actor\"", ",", "\"person-director\"", ",", "\"person-artist/author\"", ",", "\"person-athlete\"", ",", "\"person-politician\"", ",", "\"person-scholar\"", ",", "\"person-soldier\"", ",", "\"person-other\"", ",", "\n", "\"organization-showorganization\"", ",", "\"organization-religion\"", ",", "\"organization-company\"", ",", "\"organization-sportsteam\"", ",", "\"organization-education\"", ",", "\"organization-government/governmentagency\"", ",", "\"organization-media/newspaper\"", ",", "\"organization-politicalparty\"", ",", "\"organization-sportsleague\"", ",", "\"organization-other\"", ",", "\n", "\"location-GPE\"", ",", "\"location-road/railway/highway/transit\"", ",", "\"location-bodiesofwater\"", ",", "\"location-park\"", ",", "\"location-mountain\"", ",", "\"location-island\"", ",", "\"location-other\"", ",", "\n", "\"product-software\"", ",", "\"product-food\"", ",", "\"product-game\"", ",", "\"product-ship\"", ",", "\"product-train\"", ",", "\"product-airplane\"", ",", "\"product-car\"", ",", "\"product-weapon\"", ",", "\"product-other\"", ",", "\n", "\"building-theater\"", ",", "\"building-sportsfacility\"", ",", "\"building-airport\"", ",", "\"building-hospital\"", ",", "\"building-library\"", ",", "\"building-hotel\"", ",", "\"building-restaurant\"", ",", "\"building-other\"", ",", "\n", "\"event-sportsevent\"", ",", "\"event-attack/battle/war/militaryconflict\"", ",", "\"event-disaster\"", ",", "\"event-election\"", ",", "\"event-protest\"", ",", "\"event-other\"", ",", "\n", "\"art-music\"", ",", "\"art-writtenart\"", ",", "\"art-film\"", ",", "\"art-painting\"", ",", "\"art-broadcastprogram\"", ",", "\"art-other\"", ",", "\n", "\"other-biologything\"", ",", "\"other-chemicalthing\"", ",", "\"other-livingthing\"", ",", "\"other-astronomything\"", ",", "\"other-god\"", ",", "\"other-law\"", ",", "\"other-award\"", ",", "\"other-disease\"", ",", "\"other-medical\"", ",", "\"other-language\"", ",", "\"other-currency\"", ",", "\"other-educationaldegree\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.typing_dataset.FewNERDProcessor.get_examples": [[70, 87], ["os.path.join", "open", "typing_dataset.FewNERDProcessor.load_data", "enumerate", "openprompt.data_utils.utils.InputExample", "examples.append", "str", "typing_dataset.FewNERDProcessor.get_label_id"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.typing_dataset.FewNERDProcessor.load_data", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"supervised/{}.txt\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "data", "=", "FewNERDProcessor", ".", "load_data", "(", "f", ")", "\n", "\n", "examples", "=", "[", "]", "\n", "\n", "for", "idx", ",", "(", "xs", ",", "ys", ",", "spans", ")", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "span", "in", "spans", ":", "\n", "                    ", "text_a", "=", "\" \"", ".", "join", "(", "xs", ")", "\n", "meta", "=", "{", "\n", "\"entity\"", ":", "\" \"", ".", "join", "(", "xs", "[", "span", "[", "0", "]", ":", "span", "[", "1", "]", "+", "1", "]", ")", "\n", "}", "\n", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "idx", ")", ",", "text_a", "=", "text_a", ",", "meta", "=", "meta", ",", "label", "=", "self", ".", "get_label_id", "(", "ys", "[", "span", "[", "0", "]", "]", "[", "2", ":", "]", ")", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.typing_dataset.FewNERDProcessor.load_data": [[88, 116], ["file.readlines", "line.split", "xs.append", "ys.append", "data.append", "spans.append", "len", "len", "len", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "load_data", "(", "file", ")", ":", "\n", "        ", "data", "=", "[", "]", "\n", "xs", "=", "[", "]", "\n", "ys", "=", "[", "]", "\n", "spans", "=", "[", "]", "\n", "\n", "for", "line", "in", "file", ".", "readlines", "(", ")", ":", "\n", "            ", "pair", "=", "line", ".", "split", "(", ")", "\n", "if", "pair", "==", "[", "]", ":", "\n", "                ", "if", "xs", "!=", "[", "]", ":", "\n", "                    ", "data", ".", "append", "(", "(", "xs", ",", "ys", ",", "spans", ")", ")", "\n", "", "xs", "=", "[", "]", "\n", "ys", "=", "[", "]", "\n", "spans", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "xs", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "\n", "tag", "=", "pair", "[", "-", "1", "]", "\n", "if", "tag", "!=", "'O'", ":", "\n", "                    ", "if", "len", "(", "ys", ")", "==", "0", "or", "tag", "!=", "ys", "[", "-", "1", "]", "[", "2", ":", "]", ":", "\n", "                        ", "tag", "=", "'B-'", "+", "tag", "\n", "spans", ".", "append", "(", "[", "len", "(", "ys", ")", ",", "len", "(", "ys", ")", "]", ")", "\n", "", "else", ":", "\n", "                        ", "tag", "=", "'I-'", "+", "tag", "\n", "spans", "[", "-", "1", "]", "[", "-", "1", "]", "=", "len", "(", "ys", ")", "\n", "", "", "ys", ".", "append", "(", "tag", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples": [[40, 42], ["fewglue_dataset.FewGLUEDataProcessor.get_examples"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "get_examples", "(", "data_dir", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples": [[43, 45], ["fewglue_dataset.FewGLUEDataProcessor.get_examples"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "get_examples", "(", "data_dir", ",", "\"dev32\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples": [[46, 48], ["fewglue_dataset.FewGLUEDataProcessor.get_examples"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "return", "self", ".", "get_examples", "(", "data_dir", ",", "\"val\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.RteProcessor.__init__": [[53, 56], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.RteProcessor.get_examples": [[57, 78], ["os.path.join", "open", "enumerate", "json.loads", "isinstance", "fewglue_dataset.RteProcessor.get_label_id", "openprompt.data_utils.utils.InputExample", "examples.append", "int"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ":", "str", ",", "split", ":", "str", ",", "hypothesis_name", ":", "str", "=", "\"hypothesis\"", ",", "\n", "premise_name", ":", "str", "=", "\"premise\"", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "choicex", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "idx", "=", "example_json", "[", "'idx'", "]", "\n", "if", "isinstance", "(", "idx", ",", "str", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "idx", "=", "int", "(", "idx", ")", "\n", "", "except", "ValueError", ":", "\n", "                        ", "idx", "=", "choicex", "\n", "", "", "label", "=", "self", ".", "get_label_id", "(", "example_json", "[", "\"label\"", "]", ")", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "split", ",", "idx", ")", "\n", "text_a", "=", "example_json", "[", "premise_name", "]", "\n", "text_b", "=", "example_json", "[", "hypothesis_name", "]", "\n", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.CbProcessor.__init__": [[83, 86], ["fewglue_dataset.RteProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"entailment\"", ",", "\"contradiction\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.WicProcessor.__init__": [[90, 93], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "True", ",", "False", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.WicProcessor.get_examples": [[94, 111], ["os.path.join", "open", "json.loads", "isinstance", "fewglue_dataset.WicProcessor.get_label_id", "openprompt.data_utils.utils.InputExample", "examples.append", "int"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ":", "str", ",", "split", ":", "str", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "idx", "=", "example_json", "[", "'idx'", "]", "\n", "if", "isinstance", "(", "idx", ",", "str", ")", ":", "\n", "                    ", "idx", "=", "int", "(", "idx", ")", "\n", "", "label", "=", "self", ".", "get_label_id", "(", "example_json", "[", "\"label\"", "]", ")", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "split", ",", "idx", ")", "\n", "text_a", "=", "example_json", "[", "'sentence1'", "]", "\n", "text_b", "=", "example_json", "[", "'sentence2'", "]", "\n", "meta", "=", "{", "'word'", ":", "example_json", "[", "'word'", "]", "}", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ",", "idx", "=", "idx", ",", "meta", "=", "meta", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.WscProcessor.__init__": [[116, 119], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "True", ",", "False", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.WscProcessor.get_examples": [[120, 176], ["os.path.join", "open", "json.loads", "fewglue_dataset.WscProcessor.get_label_id", "text_a.split", "text_a.lower().split", "span1_text.lower().split", "len", "openprompt.data_utils.utils.InputExample", "examples.append", "openprompt.utils.logging.logger.warning", "text_a.lower", "span1_text.lower", "words_a[].startswith", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ":", "str", ",", "split", ":", "str", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "idx", "=", "example_json", "[", "'idx'", "]", "\n", "label", "=", "self", ".", "get_label_id", "(", "example_json", "[", "\"label\"", "]", ")", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "split", ",", "idx", ")", "\n", "text_a", "=", "example_json", "[", "'text'", "]", "\n", "meta", "=", "{", "\n", "'span1_text'", ":", "example_json", "[", "'target'", "]", "[", "'span1_text'", "]", ",", "\n", "'span2_text'", ":", "example_json", "[", "'target'", "]", "[", "'span2_text'", "]", ",", "\n", "'span1_index'", ":", "example_json", "[", "'target'", "]", "[", "'span1_index'", "]", ",", "\n", "'span2_index'", ":", "example_json", "[", "'target'", "]", "[", "'span2_index'", "]", "\n", "}", "\n", "\n", "# the indices in the dataset are wrong for some examples, so we manually fix them", "\n", "span1_index", ",", "span1_text", "=", "meta", "[", "'span1_index'", "]", ",", "meta", "[", "'span1_text'", "]", "\n", "span2_index", ",", "span2_text", "=", "meta", "[", "'span2_index'", "]", ",", "meta", "[", "'span2_text'", "]", "\n", "words_a", "=", "text_a", ".", "split", "(", ")", "\n", "words_a_lower", "=", "text_a", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "words_span1_text", "=", "span1_text", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "span1_len", "=", "len", "(", "words_span1_text", ")", "\n", "\n", "if", "words_a_lower", "[", "span1_index", ":", "span1_index", "+", "span1_len", "]", "!=", "words_span1_text", ":", "\n", "                    ", "for", "offset", "in", "[", "-", "1", ",", "+", "1", "]", ":", "\n", "                        ", "if", "words_a_lower", "[", "span1_index", "+", "offset", ":", "span1_index", "+", "span1_len", "+", "offset", "]", "==", "words_span1_text", ":", "\n", "                            ", "span1_index", "+=", "offset", "\n", "\n", "", "", "", "if", "words_a_lower", "[", "span1_index", ":", "span1_index", "+", "span1_len", "]", "!=", "words_span1_text", ":", "\n", "                    ", "logger", ".", "warning", "(", "f\"Got '{words_a_lower[span1_index:span1_index + span1_len]}' but expected \"", "\n", "f\"'{words_span1_text}' at index {span1_index} for '{words_a}'\"", ")", "\n", "\n", "", "if", "words_a", "[", "span2_index", "]", "!=", "span2_text", ":", "\n", "                    ", "for", "offset", "in", "[", "-", "1", ",", "+", "1", "]", ":", "\n", "                        ", "if", "words_a", "[", "span2_index", "+", "offset", "]", "==", "span2_text", ":", "\n", "                            ", "span2_index", "+=", "offset", "\n", "\n", "", "", "if", "words_a", "[", "span2_index", "]", "!=", "span2_text", "and", "words_a", "[", "span2_index", "]", ".", "startswith", "(", "span2_text", ")", ":", "\n", "                        ", "words_a", "=", "words_a", "[", ":", "span2_index", "]", "+", "[", "words_a", "[", "span2_index", "]", "[", ":", "len", "(", "span2_text", ")", "]", ",", "words_a", "[", "span2_index", "]", "[", "len", "(", "span2_text", ")", ":", "]", "]", "+", "words_a", "[", "span2_index", "+", "1", ":", "]", "\n", "\n", "", "", "assert", "words_a", "[", "span2_index", "]", "==", "span2_text", ",", "f\"Got '{words_a[span2_index]}' but expected '{span2_text}' at index {span2_index} for '{words_a}'\"", "\n", "\n", "text_a", "=", "' '", ".", "join", "(", "words_a", ")", "\n", "meta", "[", "'span1_index'", "]", ",", "meta", "[", "'span2_index'", "]", "=", "span1_index", ",", "span2_index", "\n", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "label", "=", "label", ",", "meta", "=", "meta", ",", "idx", "=", "idx", ")", "\n", "if", "split", "==", "'train'", "and", "label", "!=", "'True'", ":", "\n", "                    ", "continue", "\n", "", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.BoolQProcessor.__init__": [[181, 184], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "True", ",", "False", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.BoolQProcessor.get_examples": [[185, 200], ["os.path.join", "open", "json.loads", "fewglue_dataset.BoolQProcessor.get_label_id", "openprompt.data_utils.utils.InputExample", "examples.append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ":", "str", ",", "split", ":", "str", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "idx", "=", "example_json", "[", "'idx'", "]", "\n", "label", "=", "self", ".", "get_label_id", "(", "example_json", "[", "\"label\"", "]", ")", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "split", ",", "idx", ")", "\n", "text_a", "=", "example_json", "[", "'passage'", "]", "\n", "text_b", "=", "example_json", "[", "'question'", "]", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.CopaProcessor.__init__": [[205, 208], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.CopaProcessor.get_examples": [[209, 241], ["os.path.join", "open", "openprompt.utils.logging.logger.info", "json.loads", "fewglue_dataset.CopaProcessor.get_label_id", "openprompt.data_utils.utils.InputExample", "examples.append", "openprompt.data_utils.utils.InputExample", "mirror_examples.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ":", "str", ",", "split", ":", "str", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "label", "=", "self", ".", "get_label_id", "(", "example_json", "[", "\"label\"", "]", ")", "\n", "idx", "=", "example_json", "[", "'idx'", "]", "\n", "guid", "=", "\"%s-%s\"", "%", "(", "split", ",", "idx", ")", "\n", "text_a", "=", "example_json", "[", "'premise'", "]", "\n", "meta", "=", "{", "\n", "'choice1'", ":", "example_json", "[", "'choice1'", "]", ",", "\n", "'choice2'", ":", "example_json", "[", "'choice2'", "]", ",", "\n", "'question'", ":", "example_json", "[", "'question'", "]", "\n", "}", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "label", "=", "label", ",", "meta", "=", "meta", ",", "idx", "=", "idx", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "if", "split", "==", "'train'", "or", "split", "==", "'unlabeled'", ":", "\n", "            ", "mirror_examples", "=", "[", "]", "\n", "for", "ex", "in", "examples", ":", "\n", "                ", "label", "=", "\"1\"", "if", "ex", ".", "label", "==", "\"0\"", "else", "\"0\"", "\n", "meta", "=", "{", "\n", "'choice1'", ":", "ex", ".", "meta", "[", "'choice2'", "]", ",", "\n", "'choice2'", ":", "ex", ".", "meta", "[", "'choice1'", "]", ",", "\n", "'question'", ":", "ex", ".", "meta", "[", "'question'", "]", "\n", "}", "\n", "mirror_example", "=", "InputExample", "(", "guid", "=", "ex", ".", "guid", "+", "'m'", ",", "text_a", "=", "ex", ".", "text_a", ",", "label", "=", "label", ",", "meta", "=", "meta", ")", "\n", "mirror_examples", ".", "append", "(", "mirror_example", ")", "\n", "", "examples", "+=", "mirror_examples", "\n", "logger", ".", "info", "(", "f\"Added {len(mirror_examples)} mirror examples, total size is {len(examples)}...\"", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.MultiRcProcessor.__init__": [[246, 249], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.MultiRcProcessor.get_examples": [[250, 283], ["os.path.join", "list", "collections.Counter", "openprompt.utils.logging.logger.info", "open", "set", "json.loads", "len", "len", "list", "fewglue_dataset.MultiRcProcessor.get_label_id", "openprompt.data_utils.utils.InputExample", "examples.append", "collections.Counter.items"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.data_processor.DataProcessor.get_label_id", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ":", "str", ",", "split", ":", "str", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "passage_idx", "=", "example_json", "[", "'idx'", "]", "\n", "text", "=", "example_json", "[", "'passage'", "]", "[", "'text'", "]", "\n", "questions", "=", "example_json", "[", "'passage'", "]", "[", "'questions'", "]", "\n", "for", "question_json", "in", "questions", ":", "\n", "                    ", "question", "=", "question_json", "[", "\"question\"", "]", "\n", "question_idx", "=", "question_json", "[", "'idx'", "]", "\n", "answers", "=", "question_json", "[", "\"answers\"", "]", "\n", "for", "answer_json", "in", "answers", ":", "\n", "                        ", "label", "=", "self", ".", "get_label_id", "(", "answer_json", "[", "\"label\"", "]", ")", "\n", "answer_idx", "=", "answer_json", "[", "\"idx\"", "]", "\n", "guid", "=", "f'{split}-p{passage_idx}-q{question_idx}-a{answer_idx}'", "\n", "meta", "=", "{", "\n", "'passage_idx'", ":", "passage_idx", ",", "\n", "'question_idx'", ":", "question_idx", ",", "\n", "'answer_idx'", ":", "answer_idx", ",", "\n", "'answer'", ":", "answer_json", "[", "\"text\"", "]", "\n", "}", "\n", "idx", "=", "[", "passage_idx", ",", "question_idx", ",", "answer_idx", "]", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text", ",", "text_b", "=", "question", ",", "label", "=", "label", ",", "meta", "=", "meta", ",", "idx", "=", "idx", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "", "", "question_indices", "=", "list", "(", "set", "(", "example", ".", "meta", "[", "'question_idx'", "]", "for", "example", "in", "examples", ")", ")", "\n", "label_distribution", "=", "Counter", "(", "example", ".", "label", "for", "example", "in", "examples", ")", "\n", "logger", ".", "info", "(", "f\"Returning {len(examples)} examples corresponding to {len(question_indices)} questions with label \"", "\n", "f\"distribution {list(label_distribution.items())}\"", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.RecordProcessor.__init__": [[288, 291], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.RecordProcessor.get_examples": [[292, 366], ["os.path.join", "random.Random", "list", "collections.Counter", "openprompt.utils.logging.logger.info", "open", "enumerate", "set", "json.loads", "set", "list", "text.replace.replace.replace", "list.add", "set", "question_json.get", "list", "len", "len", "list", "list.add", "enumerate", "openprompt.data_utils.utils.InputExample", "examples.append", "collections.Counter.items", "openprompt.data_utils.utils.InputExample", "examples.append", "len", "random.Random.shuffle"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items"], ["", "@", "staticmethod", "\n", "def", "get_examples", "(", "path", ",", "split", ",", "seed", "=", "42", ",", "max_train_candidates_per_question", ":", "int", "=", "10", ")", "->", "List", "[", "InputExample", "]", ":", "\n", "        ", "examples", "=", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}.jsonl\"", ".", "format", "(", "split", ")", ")", "\n", "\n", "entity_shuffler", "=", "random", ".", "Random", "(", "seed", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "idx", "=", "example_json", "[", "'idx'", "]", "\n", "text", "=", "example_json", "[", "'passage'", "]", "[", "'text'", "]", "\n", "entities", "=", "set", "(", ")", "\n", "\n", "for", "entity_json", "in", "example_json", "[", "'passage'", "]", "[", "'entities'", "]", ":", "\n", "                    ", "start", "=", "entity_json", "[", "'start'", "]", "\n", "end", "=", "entity_json", "[", "'end'", "]", "\n", "entity", "=", "text", "[", "start", ":", "end", "+", "1", "]", "\n", "entities", ".", "add", "(", "entity", ")", "\n", "\n", "", "entities", "=", "list", "(", "entities", ")", "\n", "\n", "text", "=", "text", ".", "replace", "(", "\"@highlight\\n\"", ",", "\"- \"", ")", "# we follow the GPT-3 paper wrt @highlight annotations", "\n", "questions", "=", "example_json", "[", "'qas'", "]", "\n", "\n", "for", "question_json", "in", "questions", ":", "\n", "                    ", "question", "=", "question_json", "[", "'query'", "]", "\n", "question_idx", "=", "question_json", "[", "'idx'", "]", "\n", "answers", "=", "set", "(", ")", "\n", "\n", "for", "answer_json", "in", "question_json", ".", "get", "(", "'answers'", ",", "[", "]", ")", ":", "\n", "                        ", "answer", "=", "answer_json", "[", "'text'", "]", "\n", "answers", ".", "add", "(", "answer", ")", "\n", "\n", "", "answers", "=", "list", "(", "answers", ")", "\n", "\n", "if", "split", "==", "'train'", ":", "\n", "# create a single example per *correct* answer", "\n", "                        ", "for", "answer_idx", ",", "answer", "in", "enumerate", "(", "answers", ")", ":", "\n", "                            ", "candidates", "=", "[", "ent", "for", "ent", "in", "entities", "if", "ent", "not", "in", "answers", "]", "\n", "if", "len", "(", "candidates", ")", ">", "max_train_candidates_per_question", "-", "1", ":", "\n", "                                ", "entity_shuffler", ".", "shuffle", "(", "candidates", ")", "\n", "candidates", "=", "candidates", "[", ":", "max_train_candidates_per_question", "-", "1", "]", "\n", "\n", "", "guid", "=", "f'{split}-p{idx}-q{question_idx}-a{answer_idx}'", "\n", "meta", "=", "{", "\n", "'passage_idx'", ":", "idx", ",", "\n", "'question_idx'", ":", "question_idx", ",", "\n", "'candidates'", ":", "[", "answer", "]", "+", "candidates", ",", "\n", "'answers'", ":", "[", "answer", "]", "\n", "}", "\n", "ex_idx", "=", "[", "idx", ",", "question_idx", ",", "answer_idx", "]", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text", ",", "text_b", "=", "question", ",", "label", "=", "\"1\"", ",", "meta", "=", "meta", ",", "\n", "idx", "=", "ex_idx", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "else", ":", "\n", "# create just one example with *all* correct answers and *all* answer candidates", "\n", "                        ", "guid", "=", "f'{split}-p{idx}-q{question_idx}'", "\n", "meta", "=", "{", "\n", "'passage_idx'", ":", "idx", ",", "\n", "'question_idx'", ":", "question_idx", ",", "\n", "'candidates'", ":", "entities", ",", "\n", "'answers'", ":", "answers", "\n", "}", "\n", "example", "=", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text", ",", "text_b", "=", "question", ",", "label", "=", "\"1\"", ",", "meta", "=", "meta", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "", "", "question_indices", "=", "list", "(", "set", "(", "example", ".", "meta", "[", "'question_idx'", "]", "for", "example", "in", "examples", ")", ")", "\n", "label_distribution", "=", "Counter", "(", "example", ".", "label", "for", "example", "in", "examples", ")", "\n", "logger", ".", "info", "(", "f\"Returning {len(examples)} examples corresponding to {len(question_indices)} questions with label \"", "\n", "f\"distribution {list(label_distribution.items())}\"", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset": [[29, 76], ["processor.get_test_examples", "openprompt.utils.logging.logger.error", "exit", "processor.get_train_examples", "processor.get_dev_examples", "openprompt.utils.logging.logger.warning", "dataset_config.name.lower", "openprompt.utils.logging.logger.warning", "openprompt.utils.logging.logger.warning"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_test_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_train_examples", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.fewglue_dataset.FewGLUEDataProcessor.get_dev_examples"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.lama_dataset.LAMAProcessor.__init__": [[43, 63], ["openprompt.data_utils.data_processor.DataProcessor.__init__", "os.path.join", "tokenizer.get_vocab", "open", "json.loads", "re.sub", "template.replace().replace", "lama_dataset.LAMAProcessor._get_allowed_vocab", "f.readline", "template.replace", "template.replace"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.lama_dataset.LAMAProcessor._get_allowed_vocab"], ["def", "__init__", "(", "self", ",", "\n", "base_path", ":", "str", ",", "\n", "model_name", ":", "str", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "vocab_strategy", ":", "str", ",", "\n", "relation_id", ":", "str", "=", "\"P1001\"", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "relation_id", "=", "relation_id", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "\"single_relations/{}.jsonl\"", ".", "format", "(", "relation_id", ")", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "template", "=", "json", ".", "loads", "(", "f", ".", "readline", "(", ")", ")", "[", "\"template\"", "]", "\n", "if", "'gpt'", "in", "model_name", "or", "'megatron'", "in", "model_name", ":", "# TODO generalize to all LM kind model", "\n", "                ", "self", ".", "manual_template", "=", "re", ".", "sub", "(", "r'\\[Y\\].*'", ",", "''", ",", "template", ".", "replace", "(", "'[X]'", ",", "\"<text_a>\"", ")", ")", "\n", "", "else", ":", "# TODO generalize to all MLM kind model", "\n", "                ", "self", ".", "manual_template", "=", "template", ".", "replace", "(", "\"[X]\"", ",", "\"<text_a>\"", ")", ".", "replace", "(", "\"[Y]\"", ",", "\"<mask>\"", ")", "# dataset defined", "\n", "# TODO Seq2Seq support?", "\n", "", "", "self", ".", "label_mapping", "=", "tokenizer", ".", "get_vocab", "(", ")", "\n", "self", ".", "allowed_vocab_ids", "=", "[", "self", ".", "label_mapping", "[", "vocab", "]", "for", "vocab", "in", "self", ".", "_get_allowed_vocab", "(", "model_name", ",", "vocab_strategy", ",", "base_path", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.lama_dataset.LAMAProcessor._get_allowed_vocab": [[64, 89], ["open", "json.load", "ValueError", "os.path.join", "open", "json.load", "os.path.join"], "methods", ["None"], ["", "def", "_get_allowed_vocab", "(", "self", ",", "model_name", ",", "strategy", ",", "base_path", ")", ":", "\n", "        ", "if", "strategy", "==", "\"original\"", ":", "\n", "            ", "return", "self", ".", "labels", "\n", "", "elif", "strategy", "==", "\"share\"", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "base_path", ",", "'29k-vocab.json'", ")", ")", "as", "f", ":", "\n", "                ", "shared_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "if", "'gpt'", "in", "model_name", ":", "\n", "                    ", "return", "shared_vocab", "[", "'gpt2-xl'", "]", "\n", "", "elif", "'roberta'", "in", "model_name", "or", "'megatron'", "in", "model_name", ":", "\n", "                    ", "return", "shared_vocab", "[", "'roberta-large'", "]", "\n", "", "else", ":", "\n", "                    ", "assert", "model_name", "in", "shared_vocab", "\n", "return", "shared_vocab", "[", "model_name", "]", "\n", "", "", "", "elif", "strategy", "==", "\"lama\"", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "base_path", ",", "'34k-vocab.json'", ")", ")", "as", "f", ":", "\n", "                ", "lama_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "if", "'gpt'", "in", "model_name", ":", "\n", "                    ", "return", "lama_vocab", "[", "'gpt2-xl'", "]", "\n", "", "elif", "'roberta'", "in", "model_name", "or", "'megatron'", "in", "model_name", ":", "\n", "                    ", "return", "lama_vocab", "[", "'roberta-large'", "]", "\n", "", "else", ":", "\n", "                    ", "assert", "model_name", "in", "lama_vocab", "\n", "return", "lama_vocab", "[", "model_name", "]", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'vocab_strategy must be \"original\", \"share\" or \"lama\"'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.lama_dataset.LAMAProcessor.get_manual_template": [[90, 92], ["None"], "methods", ["None"], ["", "", "def", "get_manual_template", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "manual_template", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.lama_dataset.LAMAProcessor.get_examples": [[93, 105], ["os.path.join", "open", "enumerate", "json.loads", "openprompt.data_utils.utils.InputExample", "examples.append", "lama_dataset.LAMAProcessor.tokenizer", "len", "str"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.tokenizer"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"fact-retrieval/original/{}/{}.jsonl\"", ".", "format", "(", "self", ".", "relation_id", ",", "split", ")", ")", "# TODO oprinal_rob or trex option", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "choicex", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "token_ids", "=", "self", ".", "tokenizer", "(", "\" \"", "+", "example_json", "[", "\"obj_label\"", "]", ",", "add_special_tokens", "=", "False", ")", "[", "\"input_ids\"", "]", "\n", "if", "len", "(", "token_ids", ")", "!=", "1", "or", "token_ids", "[", "0", "]", "not", "in", "self", ".", "allowed_vocab_ids", ":", "\n", "                    ", "continue", "\n", "", "example", "=", "InputExample", "(", "guid", "=", "str", "(", "choicex", ")", ",", "text_a", "=", "example_json", "[", "\"sub_label\"", "]", ",", "label", "=", "token_ids", "[", "0", "]", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputExample.__init__": [[28, 43], ["None"], "methods", ["None"], ["", "", "else", ":", "\n", "            ", "l", "[", "idx", "]", "=", "int", "(", "0", ")", "\n", "", "", "assert", "sum", "(", "l", ")", "==", "max_sum", "\n", "\n", "\n", "", "def", "signature", "(", "f", ")", ":", "\n", "    ", "r\"\"\"Get the function f 's input arguments. A useful gadget\n    when some function slot might be instantiated into multiple functions.\n    \n    Args:\n        f (:obj:`function`) : the function to get the input arguments.\n    \n    Returns:\n        namedtuple : of args, default, varargs, keywords, respectively.s\n\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputExample.__repr__": [[44, 46], ["str", "utils.InputExample.to_json_string"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_json_string"], ["sig", "=", "inspect", ".", "signature", "(", "f", ")", "\n", "args", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputExample.to_dict": [[47, 51], ["copy.deepcopy"], "methods", ["None"], ["if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "POSITIONAL_OR_KEYWORD", "\n", "]", "\n", "varargs", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "VAR_POSITIONAL", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputExample.to_json_string": [[52, 55], ["json.dumps", "utils.InputExample.to_dict"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_dict"], ["]", "\n", "varargs", "=", "varargs", "[", "0", "]", "if", "varargs", "else", "None", "\n", "keywords", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputExample.keys": [[56, 58], ["utils.InputExample.__dict__.keys", "getattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "VAR_KEYWORD", "\n", "]", "\n", "keywords", "=", "keywords", "[", "0", "]", "if", "keywords", "else", "None", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputExample.load_examples": [[59, 64], ["open", "pickle.load"], "methods", ["None"], ["defaults", "=", "[", "\n", "p", ".", "default", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "POSITIONAL_OR_KEYWORD", "\n", "and", "p", ".", "default", "is", "not", "p", ".", "empty", "\n", "]", "or", "None", "\n", "argspec", "=", "namedtuple", "(", "'Signature'", ",", "[", "'args'", ",", "'defaults'", ",", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputExample.save_examples": [[65, 70], ["open", "pickle.dump"], "methods", ["None"], ["'varargs'", ",", "'keywords'", "]", ")", "\n", "return", "argspec", "(", "args", ",", "defaults", ",", "varargs", ",", "keywords", ")", "\n", "\n", "", "def", "check_config_conflicts", "(", "config", ":", "CfgNode", ")", ":", "\n", "    ", "r\"\"\"check the conflicts of global config.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__init__": [[114, 151], ["kwargs.keys", "openprompt.utils.logging.logger.warning", "setattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.add_tensorable_keys": [[152, 155], ["cls.tensorable_keys.extend"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.add_not_tensorable_keys": [[156, 159], ["cls.not_tensorable_keys.extend"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.add_keys": [[160, 163], ["cls.all_keys.extend"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__repr__": [[164, 166], ["str", "utils.InputFeatures.to_json_string"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_json_string"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__len__": [[167, 169], ["len", "utils.InputFeatures.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_tensor": [[170, 177], ["getattr", "setattr", "torch.tensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to": [[178, 186], ["getattr", "setattr", "getattr.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda": [[187, 191], ["utils.InputFeatures.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_json_string": [[192, 204], ["getattr", "isinstance", "json.dumps", "getattr.detach().cpu().tolist", "getattr.detach().cpu", "getattr.detach"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys": [[205, 218], ["getattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_dict": [[219, 236], ["getattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__getitem__": [[237, 239], ["getattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__iter__": [[240, 242], ["iter", "utils.InputFeatures.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__setitem__": [[243, 247], ["setattr", "KeyError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.values": [[248, 258], ["getattr", "utils.InputFeatures.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__contains__": [[259, 261], ["utils.InputFeatures.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items": [[262, 272], ["utils.InputFeatures.__getitem__", "utils.InputFeatures.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.__getitem__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.collate_fct": [[273, 298], ["utils.InputFeatures", "torch.utils.data._utils.collate.default_collate", "print", "range", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueMultiRCProcessor.__init__": [[29, 32], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"No\"", ",", "\"Yes\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueMultiRCProcessor.get_examples": [[33, 41], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'multirc'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.multirc\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueMultiRCProcessor.transform": [[42, 49], ["int", "openprompt.data_utils.utils.InputExample"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "text_a", "=", "example", "[", "'paragraph'", "]", "\n", "text_b", "=", "example", "[", "'question'", "]", "\n", "meta", "=", "{", "\"answer\"", ":", "example", "[", "\"answer\"", "]", "}", "\n", "label", "=", "int", "(", "example", "[", "'label'", "]", ")", "\n", "guid", "=", "\"p{}-q{}-a{}\"", ".", "format", "(", "example", "[", "'idx'", "]", "[", "'paragraph'", "]", ",", "example", "[", "'idx'", "]", "[", "'question'", "]", ",", "example", "[", "'idx'", "]", "[", "'answer'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "meta", "=", "meta", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueBoolQProcessor.__init__": [[51, 54], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"No\"", ",", "\"Yes\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueBoolQProcessor.get_examples": [[55, 63], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'boolq'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.boolq\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueBoolQProcessor.transform": [[64, 70], ["int", "openprompt.data_utils.utils.InputExample"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "text_a", "=", "example", "[", "'passage'", "]", "\n", "text_b", "=", "example", "[", "'question'", "]", "\n", "label", "=", "int", "(", "example", "[", "'label'", "]", ")", "\n", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "'idx'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueCBProcessor.__init__": [[72, 75], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"Entailment\"", ",", "\"Not Entailment\"", ",", "\"Neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueCBProcessor.get_examples": [[76, 84], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'cb'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.cb\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueCBProcessor.transform": [[85, 91], ["int", "openprompt.data_utils.utils.InputExample"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "text_a", "=", "example", "[", "'premise'", "]", "\n", "text_b", "=", "example", "[", "'hypothesis'", "]", "\n", "label", "=", "int", "(", "example", "[", "'label'", "]", ")", "\n", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "'idx'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueCOPAProcessor.__init__": [[94, 97], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"No\"", ",", "\"Yes\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueCOPAProcessor.get_examples": [[98, 106], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'copa'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.copa\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueCOPAProcessor.transform": [[107, 120], ["int", "openprompt.data_utils.utils.InputExample"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "choice1", "=", "example", "[", "'choice1'", "]", "\n", "choice2", "=", "example", "[", "'choice2'", "]", "\n", "premise", "=", "example", "[", "'premise'", "]", "\n", "question", "=", "example", "[", "'question'", "]", "\n", "\n", "meta", "=", "{", "}", "\n", "meta", "[", "'choice1'", "]", "=", "choice1", "\n", "meta", "[", "'choice2'", "]", "=", "choice2", "\n", "meta", "[", "'question'", "]", "=", "question", "\n", "label", "=", "int", "(", "example", "[", "'label'", "]", ")", "\n", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "'idx'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "premise", ",", "meta", "=", "meta", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueRTEProcessor.__init__": [[122, 125], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"Entailment\"", ",", "\"Not Entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueRTEProcessor.get_examples": [[126, 134], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'rte'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.rte\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueRTEProcessor.transform": [[135, 141], ["int", "openprompt.data_utils.utils.InputExample"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "text_a", "=", "example", "[", "'premise'", "]", "\n", "text_b", "=", "example", "[", "'hypothesis'", "]", "\n", "label", "=", "int", "(", "example", "[", "'label'", "]", ")", "\n", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "'idx'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueWiCProcessor.__init__": [[143, 146], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"Same\"", ",", "\"Different\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueWiCProcessor.get_examples": [[147, 155], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'wic'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.wic\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueWiCProcessor.transform": [[156, 164], ["int", "openprompt.data_utils.utils.InputExample"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "meta", "=", "{", "}", "\n", "text_a", "=", "example", "[", "\"sentence1\"", "]", "\n", "text_b", "=", "example", "[", "\"sentence2\"", "]", "\n", "meta", "[", "'word'", "]", "=", "example", "[", "'word'", "]", "\n", "label", "=", "int", "(", "example", "[", "'label'", "]", ")", "\n", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "'idx'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "meta", "=", "meta", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueWSCProcessor.__init__": [[166, 169], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\"Different\"", ",", "\"Same\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueWSCProcessor.get_examples": [[170, 178], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'wsc'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.wsc\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueWSCProcessor.transform": [[179, 193], ["example[].split", "sorted", "int", "openprompt.data_utils.utils.InputExample", "example[].split.insert", "example[].split.insert"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "modified_text", "=", "example", "[", "\"text\"", "]", ".", "split", "(", ")", "\n", "indices", "=", "sorted", "(", "[", "example", "[", "'span2_index'", "]", ",", "example", "[", "'span1_index'", "]", "]", ")", "\n", "for", "idx", "in", "indices", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "modified_text", ".", "insert", "(", "idx", "+", "1", ",", "\"*\"", ")", "\n", "modified_text", ".", "insert", "(", "idx", ",", "\"*\"", ")", "\n", "", "modified_text", "=", "\" \"", ".", "join", "(", "modified_text", ")", "\n", "\n", "meta", "=", "{", "}", "\n", "meta", "[", "'span1_text'", "]", "=", "example", "[", "'span1_text'", "]", "\n", "meta", "[", "'span2_text'", "]", "=", "example", "[", "'span2_text'", "]", "\n", "label", "=", "int", "(", "example", "[", "'label'", "]", ")", "\n", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "'idx'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "modified_text", ",", "meta", "=", "meta", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueRecordProcessor.__init__": [[196, 199], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueRecordProcessor.get_examples": [[200, 208], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "path", "=", "HUGGING_FACE_SCRIPTS", ",", "name", "=", "'record'", ",", "cache_dir", "=", "data_dir", ",", "split", "=", "split", ")", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}/super_glue.record\"", ")", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.SuperglueRecordProcessor.transform": [[209, 220], ["example[].replace", "openprompt.data_utils.utils.InputExample", "len"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "meta", "=", "{", "}", "\n", "meta", "[", "'passage'", "]", "=", "example", "[", "\"passage\"", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "meta", "[", "'query'", "]", "=", "example", "[", "\"query\"", "]", "\n", "meta", "[", "'entities'", "]", "=", "\", \"", ".", "join", "(", "example", "[", "'entities'", "]", ")", "\n", "if", "len", "(", "example", "[", "'answers'", "]", ")", ">", "0", ":", "\n", "            ", "meta", "[", "'answers'", "]", "=", "example", "[", "'answers'", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "meta", "[", "'answers'", "]", "=", "''", "\n", "", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "'idx'", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "meta", "=", "meta", ",", "label", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.YahooAnswersTopicsProcessor.__init__": [[223, 236], ["openprompt.data_utils.data_processor.DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "labels", "=", "[", "\n", "\"Society & Culture\"", ",", "\n", "\"Science & Mathematics\"", ",", "\n", "\"Health\"", ",", "\n", "\"Education & Reference\"", ",", "\n", "\"Computers & Internet\"", ",", "\n", "\"Sports\"", ",", "\n", "\"Business & Finance\"", ",", "\n", "\"Entertainment & Music\"", ",", "\n", "\"Family & Relationships\"", ",", "\n", "\"Politics & Government\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.YahooAnswersTopicsProcessor.get_examples": [[238, 247], ["list", "datasets.load_dataset", "map", "datasets.load_from_disk"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.__init__.load_dataset"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "\"valid\"", "or", "split", "==", "\"dev\"", ":", "\n", "            ", "split", "=", "\"train\"", "# \"validation\"", "\n", "", "try", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "\"yahoo_answers_topics\"", ",", "split", "=", "split", ")", "# If you have network issues, we use the manually downloaded datasets.", "\n", "", "except", ":", "\n", "            ", "dataset", "=", "load_from_disk", "(", "f\"{data_dir}\"", ")", "#[split]", "\n", "dataset", "=", "dataset", "[", "split", "]", "\n", "", "return", "list", "(", "map", "(", "self", ".", "transform", ",", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.huggingface_dataset.YahooAnswersTopicsProcessor.transform": [[248, 255], ["int", "openprompt.data_utils.utils.InputExample"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "example", ")", ":", "\n", "        ", "meta", "=", "{", "}", "\n", "text_a", "=", "example", "[", "\"question_title\"", "]", "\n", "text_b", "=", "example", "[", "\"question_content\"", "]", "\n", "label", "=", "int", "(", "example", "[", "'topic'", "]", ")", "\n", "guid", "=", "\"{}\"", ".", "format", "(", "example", "[", "\"id\"", "]", ")", "\n", "return", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.coreference.Mandarinograd.__init__": [[13, 20], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u4e0d\u53ef\u4ee5\"", ",", "\"\u53ef\u4ee5\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.coreference.Mandarinograd.get_examples": [[23, 37], ["os.path.join", "open", "json.load().values", "InputExample", "examples.append", "json.load", "coreference.Mandarinograd.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.values", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "example_json", "in", "json", ".", "load", "(", "f", ")", ".", "values", "(", ")", ":", "\n", "                ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"before\"", ":", "example_json", "[", "\"text\"", "]", ",", "\n", "\"after\"", ":", "example_json", "[", "\"hypothesis\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"class_id\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.coreference.Mandarinograd.get_templates": [[40, 43], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{before} \u95ee\u9898\uff1a\u4e0a\u8ff0\u6587\u672c\u8fdb\u884c\u6307\u4ee3\u6d88\u89e3\u540e\uff0c\u53ef\u4ee5\u7406\u89e3\u4e3a \"{after}\" \u5417\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.coreference.CLUEWSC2020.__init__": [[49, 56], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"false\"", ",", "\"true\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u5426\"", ",", "\"\u662f\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.coreference.CLUEWSC2020.get_examples": [[59, 75], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "coreference.CLUEWSC2020.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"that\"", ":", "example_json", "[", "\"target\"", "]", "[", "\"span1_text\"", "]", ",", "\n", "\"it\"", ":", "example_json", "[", "\"target\"", "]", "[", "\"span2_text\"", "]", ",", "\n", "\"text\"", ":", "example_json", "[", "\"text\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.coreference.CLUEWSC2020.get_templates": [[78, 81], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{text} \u95ee\u9898\uff1a\u5728\u4e0a\u6587\u4e2d\uff0c\u201c{it}\u201c \u6307\u4ee3 \"{that}\" \u5417\uff1f{options}'", ",", "\n", "]", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.paraphrase.ChineseSTS.__init__": [[6, 13], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0.0\"", ",", "\"1.0\"", ",", "\"2.0\"", ",", "\"3.0\"", ",", "\"4.0\"", ",", "\"5.0\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u5b8c\u5168\u6ca1\u5173\u7cfb\"", ",", "\"\u57fa\u672c\u6ca1\u5173\u7cfb\"", ",", "\"\u6ca1\u4ec0\u4e48\u5173\u7cfb\"", ",", "\"\u6709\u70b9\u5173\u7cfb\"", ",", "\"\u57fa\u672c\u4e00\u6837\"", ",", "\"\u5b8c\u5168\u4e00\u6837\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.paraphrase.ChineseSTS.get_examples": [[16, 31], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "paraphrase.ChineseSTS.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text_1\"", ":", "example_json", "[", "\"text_1\"", "]", ",", "\n", "\"text_2\"", ":", "example_json", "[", "\"text_2\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.paraphrase.ChineseSTS.get_templates": [[34, 37], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u6bb5\u4e00\uff1a{text_1} \u6587\u6bb5\u4e8c\uff1a{text_2} \u95ee\u9898\uff1a\u4e0a\u8ff0\u4e24\u4e2a\u6587\u6bb5\u6709\u4ec0\u4e48\u5173\u7cfb\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.paraphrase.AFQMC.__init__": [[43, 50], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u5426\"", ",", "\"\u662f\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.paraphrase.AFQMC.get_examples": [[53, 68], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "paraphrase.AFQMC.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text_1\"", ":", "example_json", "[", "\"sentence1\"", "]", ",", "\n", "\"text_2\"", ":", "example_json", "[", "\"sentence2\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", "if", "\"label\"", "in", "example_json", "else", "None", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.paraphrase.AFQMC.get_templates": [[71, 74], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u6bb5\u4e00\uff1a{text_1} \u6587\u6bb5\u4e8c\uff1a{text_2} \u95ee\u9898\uff1a\u4e0a\u8ff0\u4e24\u4e2a\u6587\u6bb5\u8868\u8fbe\u7684\u610f\u601d\u662f\u5426\u4e00\u81f4\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.closed_QA.ZhiDao.__init__": [[6, 8], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.closed_QA.ZhiDao.get_examples": [[9, 26], ["os.path.join", "open", "csv.reader", "enumerate", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "!=", "'train'", ":", "raise", "ValueError", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.csv\"", ")", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "title", ",", "question", ",", "reply", ",", "is_best", "=", "row", "\n", "if", "not", "is_best", ":", "continue", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"title\"", ":", "title", ",", "\n", "\"question\"", ":", "question", ",", "\n", "}", ",", "\n", "tgt_text", "=", "reply", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.closed_QA.ZhiDao.get_templates": [[27, 30], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u95ee\u9898\uff1a{title} {question} \u56de\u7b54\uff1a'", ",", "\n", "]", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.__init__": [[5, 10], ["enumerate", "zip"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "labels_origin", ",", "labels_mapped", ")", ":", "\n", "        ", "self", ".", "labels_origin", "=", "labels_origin", "\n", "self", ".", "labels_mapped", "=", "labels_mapped", "\n", "self", ".", "labels_mapping", "=", "{", "\n", "origin", ":", "kth", "for", "kth", ",", "(", "origin", ",", "mapped", ")", "in", "enumerate", "(", "zip", "(", "labels_origin", ",", "labels_mapped", ")", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label": [[12, 14], ["None"], "methods", ["None"], ["", "def", "get_label", "(", "self", ",", "origin", ")", ":", "\n", "        ", "return", "self", ".", "labels_mapping", "[", "origin", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.relation.FinRE.__init__": [[18, 25], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "21", ",", "22", ",", "23", ",", "24", ",", "25", ",", "26", ",", "27", ",", "28", ",", "29", ",", "30", ",", "31", ",", "32", ",", "33", ",", "34", ",", "35", ",", "36", ",", "37", ",", "38", ",", "39", ",", "40", ",", "41", ",", "42", ",", "43", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u65e0\u5173\u7cfb\"", ",", "\"\u6ce8\u8d44\"", ",", "\"\u62e5\u6709\"", ",", "\"\u7ea0\u7eb7\"", ",", "\"\u540c\u4e00\u4e2a\"", ",", "\"\u589e\u6301\"", ",", "\"\u91cd\u7ec4\"", ",", "\"\u4e70\u8d44\"", ",", "\"\u7b7e\u7ea6\"", ",", "\"\u6301\u80a1\"", ",", "\"\u4ea4\u6613\"", ",", "\"\u5165\u80a1\"", ",", "\"\u8f6c\u8ba9\"", ",", "\"\u6210\u7acb\"", ",", "\"\u5206\u6790\"", ",", "\"\u5408\u4f5c\"", ",", "\"\u5e2e\u52a9\"", ",", "\"\u53d1\u884c\"", ",", "\"\u5546\u8ba8\"", ",", "\"\u5408\u5e76\"", ",", "\"\u7ade\u4e89\"", ",", "\"\u8ba2\u5355\"", ",", "\"\u51cf\u6301\"", ",", "\"\u5408\u8d44\"", ",", "\"\u6536\u8d2d\"", ",", "\"\u501f\u58f3\"", ",", "\"\u6b20\u6b3e\"", ",", "\"\u88ab\u53d1\u884c\"", ",", "\"\u88ab\u8f6c\u8ba9\"", ",", "\"\u88ab\u6210\u7acb\"", ",", "\"\u88ab\u6ce8\u8d44\"", ",", "\"\u88ab\u6301\u80a1\"", ",", "\"\u88ab\u62e5\u6709\"", ",", "\"\u88ab\u6536\u8d2d\"", ",", "\"\u88ab\u5e2e\u52a9\"", ",", "\"\u88ab\u501f\u58f3\"", ",", "\"\u88ab\u4e70\u8d44\"", ",", "\"\u88ab\u6b20\u6b3e\"", ",", "\"\u88ab\u589e\u6301\"", ",", "\"\u62df\u6536\u8d2d\"", ",", "\"\u88ab\u51cf\u6301\"", ",", "\"\u88ab\u5206\u6790\"", ",", "\"\u88ab\u5165\u80a1\"", ",", "\"\u88ab\u62df\u6536\u8d2d\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.relation.FinRE.get_examples": [[28, 44], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "relation.FinRE.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "example_json", "[", "\"text\"", "]", ",", "\n", "\"head\"", ":", "example_json", "[", "\"head\"", "]", "[", "\"mention\"", "]", ",", "\n", "\"tail\"", ":", "example_json", "[", "\"tail\"", "]", "[", "\"mention\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.relation.FinRE.get_templates": [[47, 50], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{text} \u95ee\u9898:\u4e0a\u8ff0\u6587\u672c\u4e2d\uff0c\u201c{head}\u201d\u548c\u201c{tail}\u201d\u7684\u5173\u7cfb\u4e3a\uff1f{options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.relation.Chinese_Literature_NER_RE.__init__": [[62, 69], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u4f4d\u4e8e\"", ",", "\"\u5c40\u90e8\u6574\u4f53\"", ",", "\"\u5bb6\u4eba\"", ",", "\"\u666e\u904d\u7279\u6b8a\"", ",", "\"\u793e\u4f1a\"", ",", "\"\u6240\u6709\u8005\"", ",", "\"\u4f7f\u7528\"", ",", "\"\u5236\u4f5c\"", ",", "\"\u90bb\u8fd1\"", ",", "\n", "]", "#Located, Part-Whole, Family, General-Special, Social, Ownership, Use, Create, Near", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.relation.Chinese_Literature_NER_RE.get_examples": [[72, 89], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "relation.Chinese_Literature_NER_RE.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "for", "relation", "in", "example_json", "[", "\"relations\"", "]", ":", "\n", "                    ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "example_json", "[", "\"text\"", "]", ",", "\n", "\"head\"", ":", "example_json", "[", "\"entities\"", "]", "[", "relation", "[", "\"head\"", "]", "]", "[", "0", "]", "[", "\"mention\"", "]", ",", "\n", "\"tail\"", ":", "example_json", "[", "\"entities\"", "]", "[", "relation", "[", "\"tail\"", "]", "]", "[", "0", "]", "[", "\"mention\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "relation", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.relation.Chinese_Literature_NER_RE.get_templates": [[92, 95], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{text} \u95ee\u9898:\u4e0a\u8ff0\u6587\u672c\u4e2d\uff0c\u201c{head}\u201d\u548c\u201c{tail}\u201d\u7684\u5173\u7cfb\u4e3a\uff1f{options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.E_reviews.__init__": [[19, 21], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.E_reviews.get_examples": [[22, 35], ["os.path.join", "open", "json.loads", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"key_values\"", ":", "\",\"", ".", "join", "(", "[", "f\"{k}:{v}\"", "for", "(", "k", ",", "v", ")", "in", "example_json", "[", "\"feature\"", "]", "]", ")", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"desc\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.E_reviews.get_templates": [[38, 41], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "\"\u5173\u952e\u8bcd\uff1a{key_values} \u76ee\u6807\uff1a\u6839\u636e\u4e0a\u8ff0\u5173\u952e\u8bcd\u4fe1\u606f\uff0c\u751f\u6210\u4e00\u6bb5\u5e7f\u544a\u6587\u6848. \u6587\u6848\uff1a\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.OutGen.__init__": [[48, 50], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.OutGen.get_examples": [[51, 65], ["os.path.join", "open", "json.loads", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"title\"", ":", "example_json", "[", "\"title\"", "]", ",", "\n", "\"outline\"", ":", "\",\"", ".", "join", "(", "example_json", "[", "\"outline\"", "]", ")", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"story\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.OutGen.get_templates": [[68, 71], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6807\u9898:{title} \u5927\u7eb2:{outline} \u76ee\u6807:\u6839\u636e\u4e0a\u8ff0\u6807\u9898\u548c\u5927\u7eb2, \u5199\u4e00\u4e2a\u6545\u4e8b\u3002\u6545\u4e8b\uff1a'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.PC.__init__": [[78, 80], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.PC.get_examples": [[81, 96], ["os.path.join", "open", "json.loads", "example_json[].split", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "story", "=", "example_json", "[", "\"story\"", "]", ".", "split", "(", "\"<MASK>\"", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "story", "[", "0", "]", "+", "\"[\u7a7a\u767d]\"", "+", "story", "[", "1", "]", ",", "\n", "\"blank\"", ":", "\"[\u7a7a\u767d]\"", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"plot\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.PC.get_templates": [[99, 102], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{text} \u76ee\u6807\uff1a\u6839\u636e\u4e0a\u6587\uff0c\u586b\u5145{blank}\u5904\u7f3a\u5931\u7684\u60c5\u8282\u3002\u60c5\u8282\uff1a'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.STORAL1.__init__": [[109, 111], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.STORAL1.get_examples": [[112, 125], ["os.path.join", "open", "json.loads", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"story\"", ":", "example_json", "[", "\"story\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"moral\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.STORAL1.get_templates": [[128, 131], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "\"\u6545\u4e8b\uff1a{story} \u76ee\u6807\uff1a\u6839\u636e\u6545\u4e8b\uff0c\u63d0\u70bc\u4e00\u53e5\u54f2\u7406\u53e5\u3002\u54f2\u7406\u53e5\uff1a\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.STORAL2.__init__": [[138, 140], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.STORAL2.get_examples": [[141, 156], ["os.path.join", "open", "json.loads", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"beginning\"", ":", "example_json", "[", "\"beginning\"", "]", ",", "\n", "\"outline\"", ":", "\",\"", ".", "join", "(", "example_json", "[", "\"outline\"", "]", ")", ",", "\n", "\"moral\"", ":", "example_json", "[", "\"moral\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"beginning\"", "]", "+", "example_json", "[", "\"story\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.generation.STORAL2.get_templates": [[159, 162], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "\"\u5f00\u5934\uff1a{beginning} \u5927\u7eb2\uff1a{outline} \u54f2\u7406\uff1a{moral} \u76ee\u6807\uff1a\u6839\u636e\u4e0a\u8ff0\u5185\u5bb9\uff0c\u5199\u51fa\u4e00\u4e2a\u6545\u4e8b\u3002\u6545\u4e8b:\"", ",", "\n", "]", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.CMeEE_NER.__init__": [[14, 21], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"dis\"", ",", "\"sym\"", ",", "\"dru\"", ",", "\"equ\"", ",", "\"pro\"", ",", "\"bod\"", ",", "\"ite\"", ",", "\"mic\"", ",", "\"dep\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u75be\u75c5\"", ",", "\"\u4e34\u5e8a\u8868\u73b0\"", ",", "\"\u836f\u7269\"", ",", "\"\u533b\u7597\u8bbe\u5907\"", ",", "\"\u533b\u7597\u7a0b\u5e8f\"", ",", "\"\u8eab\u4f53\"", ",", "\"\u533b\u5b66\u68c0\u9a8c\u9879\u76ee\"", ",", "\"\u5fae\u751f\u7269\u7c7b\"", ",", "\"\u79d1\u5ba4\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.CMeEE_NER.get_examples": [[24, 41], ["os.path.join", "open", "json.load", "InputExample", "examples.append", "entity_typing.CMeEE_NER.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "example_json", "in", "json", ".", "load", "(", "f", ")", ":", "\n", "                ", "for", "span", "in", "example_json", "[", "\"entities\"", "]", ":", "\n", "\n", "                    ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "example_json", "[", "\"text\"", "]", ",", "\n", "\"entity\"", ":", "span", "[", "\"entity\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "label", "=", "self", ".", "get_label", "(", "span", "[", "\"type\"", "]", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.CMeEE_NER.get_templates": [[44, 47], ["None"], "methods", ["None"], ["", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898\uff1a\u4e0a\u6587\u4e2d\uff0c\u5b9e\u4f53\u201c{entity}\u201d\u662f\u4ec0\u4e48\u7c7b\u578b\u7684? {options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.Resume_NER.__init__": [[59, 66], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"NAME\"", ",", "\"CONT\"", ",", "\"LOC\"", ",", "\"RACE\"", ",", "\"PRO\"", ",", "\"EDU\"", ",", "\"ORG\"", ",", "\"TITLE\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u4eba\u540d\"", ",", "\"\u56fd\u7c4d\"", ",", "\"\u7c4d\u8d2f\"", ",", "\"\u79cd\u65cf\"", ",", "\"\u4e13\u4e1a\"", ",", "\"\u5b66\u4f4d\"", ",", "\"\u673a\u6784\"", ",", "\"\u804c\u79f0\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.Resume_NER.get_examples": [[69, 85], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "entity_typing.Resume_NER.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonline\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "for", "span", "in", "example_json", "[", "\"span_list\"", "]", ":", "\n", "                    ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "\"\"", ".", "join", "(", "example_json", "[", "\"tokens\"", "]", ")", ",", "\n", "\"entity\"", ":", "\"\"", ".", "join", "(", "example_json", "[", "\"tokens\"", "]", "[", "span", "[", "\"start\"", "]", ":", "span", "[", "\"end\"", "]", "+", "1", "]", ")", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "span", "[", "\"type\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.Resume_NER.get_templates": [[88, 91], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898\uff1a\u4e0a\u6587\u4e2d\uff0c\u5b9e\u4f53\u201c{entity}\u201d\u662f\u4ec0\u4e48\u7c7b\u578b\u7684? {options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.Weibo_NER.__init__": [[124, 131], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "# TODO \u533a\u5206 NAM \u7279\u6307 NOM \u6cdb\u6307", "\n", "\"PER.NAM\"", ",", "\"PER.NOM\"", ",", "\"LOC.NAM\"", ",", "\"LOC.NOM\"", ",", "\"ORG.NAM\"", ",", "\"ORG.NOM\"", ",", "\"GPE.NAM\"", ",", "\"GPE.NOM\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u4eba\"", ",", "\"\u6cdb\u6307\u4eba\"", ",", "\"\u5730\u70b9\"", ",", "\"\u6cdb\u6307\u5730\u70b9\"", ",", "\"\u673a\u6784\"", ",", "\"\u6cdb\u6307\u673a\u6784\"", ",", "\"\u5730\u7406\u653f\u6cbb\u5b9e\u4f53\"", ",", "\"\u6cdb\u6307\u5730\u7406\u653f\u6cbb\u5b9e\u4f53\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.Weibo_NER.get_examples": [[134, 150], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "entity_typing.Weibo_NER.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonline\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "for", "span", "in", "example_json", "[", "\"span_list\"", "]", ":", "\n", "                    ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "\"\"", ".", "join", "(", "example_json", "[", "\"tokens\"", "]", ")", ",", "\n", "\"entity\"", ":", "\"\"", ".", "join", "(", "example_json", "[", "\"tokens\"", "]", "[", "span", "[", "\"start\"", "]", ":", "span", "[", "\"end\"", "]", "+", "1", "]", ")", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "span", "[", "\"type\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.Weibo_NER.get_templates": [[153, 156], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898\uff1a\u4e0a\u6587\u4e2d\uff0c\u5b9e\u4f53\u201c{entity}\u201d\u662f\u4ec0\u4e48\u7c7b\u578b\u7684? {options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.DH_MSRA.__init__": [[162, 169], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"PER\"", ",", "\"LOC\"", ",", "\"ORG\"", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u4eba\"", ",", "\"\u5730\u70b9\"", ",", "\"\u673a\u6784\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.DH_MSRA.get_examples": [[172, 207], ["os.path.join", "open", "line.split", "len", "xs.append", "ys.append", "len", "InputExample", "examples.append", "len", "entity_typing.DH_MSRA.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "!=", "'train'", ":", "raise", "ValueError", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.txt\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "xs", ",", "ys", "=", "[", "]", ",", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "l", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "l", ")", "==", "0", ":", "\n", "                    ", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "xs", ")", ":", "\n", "                        ", "if", "ys", "[", "i", "]", "[", "0", "]", "==", "'B'", ":", "\n", "                            ", "j", "=", "i", "+", "1", "\n", "while", "j", "<", "len", "(", "xs", ")", ":", "\n", "                                ", "if", "ys", "[", "j", "]", "[", "0", "]", "==", "'O'", ":", "break", "\n", "j", "=", "j", "+", "1", "\n", "\n", "", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "\"\"", ".", "join", "(", "xs", ")", ",", "\n", "\"entity\"", ":", "\"\"", ".", "join", "(", "xs", "[", "i", ":", "j", "]", ")", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "ys", "[", "i", "]", "[", "2", ":", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n", "i", "=", "j", "\n", "", "else", ":", "\n", "                            ", "i", "=", "i", "+", "1", "\n", "\n", "", "", "xs", ",", "ys", "=", "[", "]", ",", "[", "]", "\n", "", "else", ":", "\n", "                    ", "xs", ".", "append", "(", "l", "[", "0", "]", ")", "\n", "ys", ".", "append", "(", "l", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.entity_typing.DH_MSRA.get_templates": [[211, 214], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898\uff1a\u4e0a\u6587\u4e2d\uff0c\u5b9e\u4f53\u201c{entity}\u201d\u662f\u4ec0\u4e48\u7c7b\u578b\u7684? {options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.THUCNews.__init__": [[11, 18], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"\u8d22\u7ecf\"", ",", "\"\u5f69\u7968\"", ",", "\"\u623f\u4ea7\"", ",", "\"\u80a1\u7968\"", ",", "\"\u5bb6\u5c45\"", ",", "\"\u6559\u80b2\"", ",", "\"\u79d1\u6280\"", ",", "\"\u793e\u4f1a\"", ",", "\"\u65f6\u5c1a\"", ",", "\"\u65f6\u653f\"", ",", "\"\u4f53\u80b2\"", ",", "\"\u661f\u5ea7\"", ",", "\"\u6e38\u620f\"", ",", "\"\u5a31\u4e50\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u8d22\u7ecf\"", ",", "\"\u5f69\u7968\"", ",", "\"\u623f\u4ea7\"", ",", "\"\u80a1\u7968\"", ",", "\"\u5bb6\u5c45\"", ",", "\"\u6559\u80b2\"", ",", "\"\u79d1\u6280\"", ",", "\"\u793e\u4f1a\"", ",", "\"\u65f6\u5c1a\"", ",", "\"\u65f6\u653f\"", ",", "\"\u4f53\u80b2\"", ",", "\"\u661f\u5ea7\"", ",", "\"\u6e38\u620f\"", ",", "\"\u5a31\u4e50\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.THUCNews.get_examples": [[21, 36], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "topic_classification.THUCNews.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"headline\"", ":", "example_json", "[", "\"headline\"", "]", ",", "\n", "\"content\"", ":", "example_json", "[", "\"context\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"class\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.THUCNews.get_templates": [[39, 42], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u65b0\u95fb\u6807\u9898\uff1a{headline} \u65b0\u95fb\u6b63\u6587\uff1a{content} \u95ee\u9898\uff1a\u4e0a\u8ff0\u65b0\u95fb\u5c5e\u4e8e\u4ec0\u4e48\u4ec0\u4e48\u7c7b\u522b\uff1f{options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.TNews.__init__": [[49, 56], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\"6\"", ",", "\"7\"", ",", "\"8\"", ",", "\"9\"", ",", "\"10\"", ",", "\"11\"", ",", "\"12\"", ",", "\"13\"", ",", "\"14\"", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u6587\u5316\"", ",", "\"\u5a31\u4e50\"", ",", "\"\u4f53\u80b2\"", ",", "\"\u8d22\u7ecf\"", ",", "\"\u623f\u4ea7\"", ",", "\"\u6c7d\u8f66\"", ",", "\"\u6559\u80b2\"", ",", "\"\u79d1\u6280\"", ",", "\"\u519b\u4e8b\"", ",", "\"\u65c5\u6e38\"", ",", "\"\u56fd\u9645\"", ",", "\"\u8bc1\u5238\"", ",", "\"\u519c\u4e1a\"", ",", "\"\u7535\u7ade\"", ",", "\"\u6c11\u751f\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.TNews.get_examples": [[59, 75], ["os.path.join", "open", "csv.reader", "enumerate", "InputExample", "examples.append", "topic_classification.TNews.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.tsv\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "'\\t'", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "label", ",", "text", "=", "row", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "text", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "label", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.TNews.get_templates": [[78, 81], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u65b0\u95fb\uff1a{text} \u95ee\u9898\uff1a\u4e0a\u8ff0\u65b0\u95fb\u5c5e\u4e8e\u4ec0\u4e48\u4ec0\u4e48\u7c7b\u522b\uff1f{options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.IFLYTEK.__init__": [[88, 95], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "labels_des", "=", "[", "\n", "\"\u6253\u8f66\"", ",", "\"\u5730\u56fe\u5bfc\u822a\"", ",", "\"\u514d\u8d39WIFI\"", ",", "\"\u79df\u8f66\"", ",", "\"\u540c\u57ce\u670d\u52a1\"", ",", "\"\u5feb\u9012\u7269\u6d41\"", ",", "\"\u5a5a\u5e86\"", ",", "\"\u5bb6\u653f\"", ",", "\"\u516c\u5171\u4ea4\u901a\"", ",", "\"\u653f\u52a1\"", ",", "\"\u793e\u533a\u670d\u52a1\"", ",", "\"\u8585\u7f8a\u6bdb\"", ",", "\"\u9b54\u5e7b\"", ",", "\"\u4ed9\u4fa0\"", ",", "\"\u5361\u724c\"", ",", "\"\u98de\u884c\u7a7a\u6218\"", ",", "\"\u5c04\u51fb\u6e38\u620f\"", ",", "\"\u4f11\u95f2\u76ca\u667a\"", ",", "\"\u52a8\u4f5c\u7c7b\"", ",", "\"\u4f53\u80b2\u7ade\u6280\"", ",", "\"\u68cb\u724c\u4e2d\u5fc3\"", ",", "\"\u7ecf\u8425\u517b\u6210\"", ",", "\"\u7b56\u7565\"", ",", "\"MOBA\"", ",", "\"\u8f85\u52a9\u5de5\u5177\"", ",", "\"\u7ea6\u4f1a\u793e\u4ea4\"", ",", "\"\u5373\u65f6\u901a\u8baf\"", ",", "\"\u5de5\u4f5c\u793e\u4ea4\"", ",", "\"\u8bba\u575b\u5708\u5b50\"", ",", "\"\u5a5a\u604b\u793e\u4ea4\"", ",", "\"\u60c5\u4fa3\u793e\u4ea4\"", ",", "\"\u793e\u4ea4\u5de5\u5177\"", ",", "\"\u751f\u6d3b\u793e\u4ea4\"", ",", "\"\u5fae\u535a\u535a\u5ba2\"", ",", "\"\u65b0\u95fb\"", ",", "\"\u6f2b\u753b\"", ",", "\"\u5c0f\u8bf4\"", ",", "\"\u6280\u672f\"", ",", "\"\u6559\u8f85\"", ",", "\"\u95ee\u7b54\u4ea4\u6d41\"", ",", "\"\u641e\u7b11\"", ",", "\"\u6742\u5fd7\"", ",", "\"\u767e\u79d1\"", ",", "\"\u5f71\u89c6\u5a31\u4e50\"", ",", "\"\u6c42\u804c\"", ",", "\"\u517c\u804c\"", ",", "\"\u89c6\u9891\"", ",", "\"\u77ed\u89c6\u9891\"", ",", "\"\u97f3\u4e50\"", ",", "\"\u76f4\u64ad\"", ",", "\"\u7535\u53f0\"", ",", "\"K\u6b4c\"", ",", "\"\u6210\u4eba\"", ",", "\"\u4e2d\u5c0f\u5b66\"", ",", "\"\u804c\u8003\"", ",", "\"\u516c\u52a1\u5458\"", ",", "\"\u82f1\u8bed\"", ",", "\"\u89c6\u9891\u6559\u80b2\"", ",", "\"\u9ad8\u7b49\u6559\u80b2\"", ",", "\"\u6210\u4eba\u6559\u80b2\"", ",", "\"\u827a\u672f\"", ",", "\"\u8bed\u8a00(\u975e\u82f1\u8bed)\"", ",", "\"\u65c5\u6e38\u8d44\u8baf\"", ",", "\"\u7efc\u5408\u9884\u5b9a\"", ",", "\"\u6c11\u822a\"", ",", "\"\u94c1\u8def\"", ",", "\"\u9152\u5e97\"", ",", "\"\u884c\u7a0b\u7ba1\u7406\"", ",", "\"\u6c11\u5bbf\u77ed\u79df\"", ",", "\"\u51fa\u56fd\"", ",", "\"\u5de5\u5177\"", ",", "\"\u4eb2\u5b50\u513f\u7ae5\"", ",", "\"\u6bcd\u5a74\"", ",", "\"\u9a7e\u6821\"", ",", "\"\u8fdd\u7ae0\"", ",", "\"\u6c7d\u8f66\u54a8\u8be2\"", ",", "\"\u6c7d\u8f66\u4ea4\u6613\"", ",", "\"\u65e5\u5e38\u517b\u8f66\"", ",", "\"\u884c\u8f66\u8f85\u52a9\"", ",", "\"\u79df\u623f\"", ",", "\"\u4e70\u623f\"", ",", "\"\u88c5\u4fee\u5bb6\u5c45\"", ",", "\"\u7535\u5b50\u4ea7\u54c1\"", ",", "\"\u95ee\u8bca\u6302\u53f7\"", ",", "\"\u517b\u751f\u4fdd\u5065\"", ",", "\"\u533b\u7597\u670d\u52a1\"", ",", "\"\u51cf\u80a5\u7626\u8eab\"", ",", "\"\u7f8e\u5986\u7f8e\u4e1a\"", ",", "\"\u83dc\u8c31\"", ",", "\"\u9910\u996e\u5e97\"", ",", "\"\u4f53\u80b2\u54a8\u8baf\"", ",", "\"\u8fd0\u52a8\u5065\u8eab\"", ",", "\"\u652f\u4ed8\"", ",", "\"\u4fdd\u9669\"", ",", "\"\u80a1\u7968\"", ",", "\"\u501f\u8d37\"", ",", "\"\u7406\u8d22\"", ",", "\"\u5f69\u7968\"", ",", "\"\u8bb0\u8d26\"", ",", "\"\u94f6\u884c\"", ",", "\"\u7f8e\u989c\"", ",", "\"\u5f71\u50cf\u526a\u8f91\"", ",", "\"\u6444\u5f71\u4fee\u56fe\"", ",", "\"\u76f8\u673a\"", ",", "\"\u7ed8\u753b\"", ",", "\"\u4e8c\u624b\"", ",", "\"\u7535\u5546\"", ",", "\"\u56e2\u8d2d\"", ",", "\"\u5916\u5356\"", ",", "\"\u7535\u5f71\u7968\u52a1\"", ",", "\"\u793e\u533a\u8d85\u5e02\"", ",", "\"\u8d2d\u7269\u54a8\u8be2\"", ",", "\"\u7b14\u8bb0\"", ",", "\"\u529e\u516c\"", ",", "\"\u65e5\u7a0b\u7ba1\u7406\"", ",", "\"\u5973\u6027\"", ",", "\"\u7ecf\u8425\"", ",", "\"\u6536\u6b3e\"", ",", "\"\u5176\u4ed6\"", ",", "\n", "]", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "labels_des", ",", "\n", "labels_mapped", "=", "labels_des", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.IFLYTEK.get_examples": [[97, 111], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "topic_classification.IFLYTEK.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "example_json", "[", "\"sentence\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label_des\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.topic_classification.IFLYTEK.get_templates": [[114, 117], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{text} \u95ee\u9898\uff1a\u4e0a\u8ff0\u6587\u6bb5\u5c5e\u4e8e\u4ec0\u4e48\u4ec0\u4e48\u7c7b\u522b\uff1f{options}'", "\n", "]", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.C3.__init__": [[15, 17], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.C3.get_examples": [[18, 32], ["os.path.join", "open", "json.load", "InputExample", "examples.append", "[].index"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "example_json", "in", "json", ".", "load", "(", "f", ")", ":", "\n", "                ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "example_json", "[", "0", "]", "[", "0", "]", ",", "\n", "\"question\"", ":", "example_json", "[", "1", "]", "[", "0", "]", "[", "\"question\"", "]", ",", "\n", "\"options\"", ":", "example_json", "[", "1", "]", "[", "0", "]", "[", "\"choice\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "1", "]", "[", "0", "]", "[", "\"choice\"", "]", ".", "index", "(", "example_json", "[", "1", "]", "[", "0", "]", "[", "\"answer\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.C3.get_templates": [[35, 38], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{text} \u95ee\u9898: {question} {options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CCPM.__init__": [[44, 46], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CCPM.get_examples": [[47, 61], ["os.path.join", "open", "json.loads", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "example_json", "[", "\"translation\"", "]", ",", "\n", "\"options\"", ":", "example_json", "[", "\"choices\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"answer\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CCPM.get_templates": [[64, 67], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u91ca\u4e49\uff1a{text} \u95ee\u9898: \u8fd9\u53e5\u91ca\u4e49\u5bf9\u5e94\u7684\u53e4\u6587\u662f? {options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.SPP.__init__": [[73, 75], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.SPP.get_examples": [[76, 105], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "len", "modified.append", "modified.append", "int", "range"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "story", "=", "example_json", "[", "\"story\"", "]", "\n", "modified", "=", "[", "]", "\n", "count", "=", "0", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "story", ")", ":", "\n", "                    ", "if", "story", "[", "i", ":", "i", "+", "6", "]", "==", "'[MASK]'", ":", "\n", "                        ", "count", "+=", "1", "\n", "modified", ".", "append", "(", "f\"[\u7a7a\u767d{count}]\"", ")", "\n", "i", "=", "i", "+", "6", "\n", "", "else", ":", "\n", "                        ", "modified", ".", "append", "(", "story", "[", "i", "]", ")", "\n", "i", "=", "i", "+", "1", "\n", "\n", "", "", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"story\"", ":", "\"\"", ".", "join", "(", "modified", ")", ",", "\n", "\"plot\"", ":", "example_json", "[", "\"sentence\"", "]", ",", "\n", "\"blank\"", ":", "\"[\u7a7a\u767d]\"", ",", "\n", "\"options\"", ":", "\",\"", ".", "join", "(", "f'[\u7a7a\u767d{i}]'", "for", "i", "in", "range", "(", "1", ",", "count", "+", "1", ")", ")", "\n", "}", ",", "\n", "tgt_text", "=", "int", "(", "example_json", "[", "\"label\"", "]", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.SPP.get_templates": [[108, 111], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6545\u4e8b\uff1a{story} \u60c5\u8282\uff1a{plot} \u95ee\u9898\uff1a\u4e0a\u8ff0\u60c5\u8282\u5e94\u8be5\u586b\u5145\u5230\u6545\u4e8b\u4e2d\u7684\u54ea\u4e00\u4e2a{blank}\u5904\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMedQA.__init__": [[140, 142], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMedQA.get_examples": [[143, 182], ["os.path.join", "open", "csv.reader", "enumerate", "open", "csv.reader", "enumerate", "open", "csv.reader", "enumerate", "os.path.join", "os.path.join", "InputExample", "examples.append", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "questions", "=", "{", "}", "\n", "answers", "=", "{", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"questions.csv\"", ")", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "q_id", ",", "content", "=", "row", "[", ":", "2", "]", "\n", "questions", "[", "q_id", "]", "=", "content", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"answers.csv\"", ")", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "a_id", ",", "_", ",", "content", "=", "row", "\n", "answers", "[", "a_id", "]", "=", "content", "\n", "\n", "", "", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}_candidates.txt\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "q_id", ",", "pos_id", ",", "neg_id", "=", "row", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"question\"", ":", "questions", "[", "q_id", "]", ",", "\n", "\"options\"", ":", "[", "answers", "[", "pos_id", "]", ",", "answers", "[", "neg_id", "]", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "0", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"question\"", ":", "questions", "[", "q_id", "]", ",", "\n", "\"options\"", ":", "[", "answers", "[", "neg_id", "]", ",", "answers", "[", "pos_id", "]", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "1", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMedQA.get_templates": [[185, 188], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u95ee\u9898\uff1a{question} {options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.ChiD.__init__": [[209, 211], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.ChiD.get_examples": [[212, 250], ["os.path.join", "os.path.join", "open", "json.load", "open", "json.loads", "InputExample", "examples.append", "len", "modified.append", "answers.append", "modified.append", "len"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}_answer.json\"", ")", "\n", "answer_map", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "answer_map", "=", "json", ".", "load", "(", "f", ")", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "candidates", "=", "example_json", "[", "\"candidates\"", "]", "\n", "for", "content", "in", "example_json", "[", "\"content\"", "]", ":", "\n", "                    ", "modified", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "content", ")", ":", "\n", "                        ", "if", "content", "[", "i", ":", "i", "+", "6", "]", "==", "'#idiom'", ":", "\n", "                            ", "modified", ".", "append", "(", "f\"[\u7a7a\u767d]\"", ")", "\n", "j", "=", "i", "+", "6", "\n", "while", "j", "<", "len", "(", "content", ")", ":", "\n", "                                ", "if", "content", "[", "j", "]", "==", "'#'", ":", "break", "\n", "j", "=", "j", "+", "1", "\n", "", "j", "+=", "1", "\n", "answers", ".", "append", "(", "candidates", "[", "answer_map", "[", "content", "[", "i", ":", "j", "]", "]", "]", ")", "\n", "i", "=", "j", "\n", "", "else", ":", "\n", "                            ", "modified", ".", "append", "(", "content", "[", "i", "]", ")", "\n", "i", "=", "i", "+", "1", "\n", "\n", "", "", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "\"\"", ".", "join", "(", "modified", ")", ",", "\n", "\"blank\"", ":", "\"[\u7a7a\u767d]\"", ",", "\n", "\"candidates\"", ":", "\",\"", ".", "join", "(", "candidates", ")", ",", "\n", "}", ",", "\n", "tgt_text", "=", "\",\"", ".", "join", "(", "answers", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.ChiD.get_templates": [[253, 256], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u6bb5\uff1a{text} \u6210\u8bed\uff1a{candidates} \u95ee\u9898\uff1a\u6587\u6bb5\u7684{blank}\u5904\u5e94\u4f9d\u6b21\u586b\u5165\u54ea\u4e9b\u6210\u8bed? \u56de\u7b54\uff1a'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CSL.__init__": [[263, 270], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u4e0d\u662f\"", ",", "\"\u662f\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CSL.get_examples": [[273, 289], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "reading_comprehensation.CSL.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "example_json", "[", "\"abst\"", "]", ",", "\n", "\"keywords\"", ":", "\",\"", ".", "join", "(", "example_json", "[", "\"keyword\"", "]", ")", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CSL.get_templates": [[292, 295], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u7ae0\u6458\u8981\uff1a{text} \u5173\u952e\u8bcd\uff1a{keywords} \u95ee\u9898\uff1a\u4e0a\u8ff0\u5173\u952e\u8bcd\u548c\u8fd9\u7bc7\u6587\u7ae0\u5173\u8054\u5417\uff1f\u56de\u7b54\uff1a'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CJRC.__init__": [[310, 312], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CJRC.get_examples": [[313, 331], ["os.path.join", "open", "json.load", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "jsons", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "example_json", "in", "jsons", "[", "\"data\"", "]", ":", "\n", "                ", "for", "paragraph", "in", "example_json", "[", "\"paragraphs\"", "]", ":", "\n", "                    ", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                        ", "if", "qa", "[", "\"is_impossible\"", "]", "==", "'true'", ":", "continue", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"casename\"", ":", "paragraph", "[", "\"casename\"", "]", ",", "\n", "\"context\"", ":", "paragraph", "[", "\"context\"", "]", ",", "\n", "\"question\"", ":", "qa", "[", "\"question\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "qa", "[", "\"answers\"", "]", "[", "0", "]", "[", "\"text\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CJRC.get_templates": [[334, 337], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6cd5\u5f8b\u6848\u4f8b\uff1a{casename}:{context} \u95ee\u9898\uff1a\u6839\u636e\u4e0a\u8ff0\u6cd5\u5f8b\u6848\u4f8b\uff0c{question} \u56de\u7b54\uff1a'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMRC2018.__init__": [[362, 364], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMRC2018.get_examples": [[365, 380], ["os.path.join", "open", "json.load", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"data/{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "jsons", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "example_json", "in", "jsons", ":", "\n", "                ", "for", "qa", "in", "example_json", "[", "\"qas\"", "]", ":", "\n", "                    ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "example_json", "[", "\"context_text\"", "]", ",", "\n", "\"question\"", ":", "qa", "[", "\"query_text\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "qa", "[", "\"answers\"", "]", "[", "0", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMRC2018.get_templates": [[383, 386], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898\uff1a\u6839\u636e\u4e0a\u6587\uff0c{question} \u56de\u7b54\uff1a'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMRC2019.__init__": [[398, 400], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMRC2019.get_examples": [[401, 416], ["os.path.join", "open", "json.load", "InputExample", "examples.append", "example_json[].replace"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"data/{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "jsons", "=", "json", ".", "load", "(", "f", ")", "[", "\"data\"", "]", "\n", "for", "example_json", "in", "jsons", ":", "\n", "                ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"story\"", ":", "example_json", "[", "\"context\"", "]", ".", "replace", "(", "'[BLANK'", ",", "'[\u7a7a\u767d'", ")", ",", "\n", "'blank'", ":", "'[\u7a7a\u767d]'", ",", "\n", "\"plots\"", ":", "\",\"", ".", "join", "(", "example_json", "[", "\"choices\"", "]", ")", ",", "\n", "}", ",", "\n", "tgt_text", "=", "\",\"", ".", "join", "(", "[", "example_json", "[", "\"choices\"", "]", "[", "a", "]", "for", "a", "in", "example_json", "[", "\"answers\"", "]", "]", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.CMRC2019.get_templates": [[419, 422], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6545\u4e8b\uff1a{story} \u60c5\u8282:{plots} \u95ee\u9898\uff1a\u6545\u4e8b\u4e2d{blank}\u5904\u4f9d\u6b21\u586b\u5165\u4ec0\u4e48\u60c5\u8282\uff1f\u56de\u7b54\uff1a'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.DuReader.__init__": [[453, 455], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.DuReader.get_examples": [[456, 471], ["os.path.join", "open", "json.loads", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "for", "which", "in", "[", "\"search\"", ",", "\"zhidao\"", "]", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}set/{which}.{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "\";\"", ".", "join", "(", "[", "para", "for", "doc", "in", "example_json", "[", "\"documents\"", "]", "for", "para", "in", "doc", "[", "\"paragraphs\"", "]", "]", ")", ",", "\n", "\"question\"", ":", "example_json", "[", "\"question\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "\";\"", ".", "join", "(", "example_json", "[", "\"answers\"", "]", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.reading_comprehensation.DuReader.get_templates": [[474, 477], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898:\u6839\u636e\u4e0a\u6587\uff0c{question} \u56de\u7b54\uff1a'", ",", "\n", "]", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.summarization.CEPSUM.__init__": [[19, 21], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.summarization.CEPSUM.get_examples": [[22, 38], ["os.path.join", "open", "json.loads", "example_json[].split", "InputExample", "examples.append", "range", "len"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "kvs", "=", "example_json", "[", "\"table\"", "]", ".", "split", "(", "'\\t'", ")", "\n", "kvs", "=", "[", "(", "kvs", "[", "i", "]", ",", "kvs", "[", "i", "+", "1", "]", ")", "for", "i", "in", "range", "(", "0", ",", "len", "(", "kvs", ")", ",", "2", ")", "]", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"properties\"", ":", "\",\"", ".", "join", "(", "[", "f\"{k}:{v}\"", "for", "k", ",", "v", "in", "kvs", "]", ")", ",", "\n", "\"description\"", ":", "example_json", "[", "\"source\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"targets\"", "]", "[", "0", "]", ",", "# TODO on dev and test, there's more than one answer available", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.summarization.CEPSUM.get_templates": [[41, 44], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u4ea7\u54c1\u5c5e\u6027\uff1a{properties} \u4ea7\u54c1\u63cf\u8ff0\uff1a{description} \u76ee\u6807\uff1a\u6839\u636e\u4ea7\u54c1\u7684\u5c5e\u6027\u548c\u63cf\u8ff0\uff0c\u4e3a\u8be5\u4ea7\u54c1\u5199\u4e00\u4e2a\u6458\u8981\u3002 \u6458\u8981\uff1a'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.summarization.LCSTS.__init__": [[57, 59], ["DataProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.summarization.LCSTS.get_examples": [[60, 73], ["os.path.join", "open", "json.loads", "InputExample", "examples.append"], "methods", ["None"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "example_json", "[", "\"text\"", "]", ",", "\n", "}", ",", "\n", "tgt_text", "=", "example_json", "[", "\"summary\"", "]", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.summarization.LCSTS.get_templates": [[76, 79], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{text} \u76ee\u6807\uff1a\u4e3a\u4e0a\u8ff0\u6587\u672c\u5199\u4e00\u4e2a\u6458\u8981\u3002\u6458\u8981\uff1a'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.ChnSentiCorp.__init__": [[13, 20], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u6d88\u6781\"", ",", "\"\u79ef\u6781\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.ChnSentiCorp.get_examples": [[23, 39], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "sentiment.ChnSentiCorp.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "example_json", "[", "\"text_a\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "label", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.ChnSentiCorp.get_templates": [[42, 45], ["None"], "methods", ["None"], ["", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898:\u4e0a\u8ff0\u6587\u672c\u6240\u8868\u8fbe\u7684\u60c5\u611f\u4e3a\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.ECISA.__init__": [[60, 67], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u4e0d\u542b\u60c5\u611f\"", ",", "\"\u8912\u4e49\"", ",", "\"\u8d2c\u4e49\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.ECISA.get_examples": [[70, 94], ["os.path.join", "open", "json.load", "isinstance", "enumerate", "InputExample", "examples.append", "sentiment.ECISA.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "'dev'", ":", "return", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "example_json", "in", "json", ".", "load", "(", "f", ")", ":", "\n", "                ", "sents", "=", "example_json", "[", "\"Sentence\"", "]", "\n", "if", "isinstance", "(", "sents", ",", "dict", ")", ":", "sents", "=", "[", "sents", "]", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "sents", ")", ":", "\n", "                    ", "if", "\"label\"", "in", "sent", ":", "\n", "                        ", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context_before\"", ":", "\"\"", ".", "join", "(", "[", "\n", "s", "[", "\"text\"", "]", "for", "s", "in", "sents", "[", ":", "i", "]", "\n", "]", ")", ",", "\n", "\"text\"", ":", "sent", "[", "\"text\"", "]", ",", "\n", "\"context_after\"", ":", "\"\"", ".", "join", "(", "[", "\n", "s", "[", "\"text\"", "]", "for", "s", "in", "sents", "[", "i", "+", "1", ":", "]", "\n", "]", ")", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "sent", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.ECISA.get_templates": [[97, 100], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context_before} {text} {context_after} \u95ee\u9898\uff1a\u4e0a\u8ff0\u6587\u672c\u4e2d\uff0c\"{text}\"\u6240\u8868\u8fbe\u7684\u60c5\u611f\u4e3a\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.JD_FULL.__init__": [[116, 123], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\n", "# \"\u5f88\u5dee \", \"\u5dee\", \"\u4e2d\", \"\u597d\", \"\u5f88\u597d\",", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.JD_FULL.get_examples": [[127, 143], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "sentiment.JD_FULL.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "'dev'", ":", "return", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"title\"", ":", "example_json", "[", "\"title\"", "]", ",", "\n", "\"review\"", ":", "example_json", "[", "\"review\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.JD_FULL.get_templates": [[146, 149], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u8bc4\u4ef7\uff1a{title} {review} \u95ee\u9898\uff1a\u636e\u6b64\u5206\u6790\uff0c\u8fd9\u6bb5\u8bc4\u4ef7\u7ed9\u51fa\u7684\u8bc4\u5206\u4e3a\uff1f{options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.SimplifyWeibo4Moods.__init__": [[155, 162], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u559c\u60a6\"", ",", "\"\u6124\u6012\"", ",", "\"\u538c\u6076\"", ",", "\"\u4f4e\u843d\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.SimplifyWeibo4Moods.get_examples": [[165, 182], ["os.path.join", "open", "csv.reader", "enumerate", "InputExample", "examples.append", "sentiment.SimplifyWeibo4Moods.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "!=", "'train'", ":", "return", "[", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.csv\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "label", ",", "review", "=", "row", "[", "0", "]", ",", "\",\"", ".", "join", "(", "row", "[", "1", ":", "]", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "review", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "label", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.SimplifyWeibo4Moods.get_templates": [[185, 188], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898\uff1a\u4e0a\u8ff0\u6587\u672c\u6240\u8868\u8fbe\u7684\u60c5\u611f\u4e3a\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.PositiveNegative.__init__": [[194, 201], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"0\"", ",", "\"1\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u6d88\u6781\"", ",", "\"\u79ef\u6781\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.PositiveNegative.get_examples": [[204, 221], ["os.path.join", "open", "csv.reader", "enumerate", "InputExample", "examples.append", "sentiment.PositiveNegative.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "!=", "'train'", ":", "raise", "ValueError", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.csv\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "label", ",", "review", "=", "row", "[", "0", "]", ",", "\",\"", ".", "join", "(", "row", "[", "1", ":", "]", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"context\"", ":", "review", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "label", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.PositiveNegative.get_templates": [[224, 227], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u6587\u672c\uff1a{context} \u95ee\u9898\uff1a\u4e0a\u8ff0\u6587\u672c\u6240\u8868\u8fbe\u7684\u60c5\u611f\u4e3a\uff1f{options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingMovie.__init__": [[233, 240], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingMovie.get_examples": [[243, 260], ["os.path.join", "open", "csv.reader", "enumerate", "InputExample", "examples.append", "sentiment.RatingMovie.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "!=", "'train'", ":", "raise", "ValueError", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.csv\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "rating", ",", "text", "=", "row", "[", "2", "]", ",", "row", "[", "4", "]", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "text", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "rating", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingMovie.get_templates": [[263, 266], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u8bc4\u4ef7\uff1a{text} \u95ee\u9898\uff1a\u636e\u6b64\u4f30\u8ba1\uff0c\u8fd9\u6bb5\u5bf9\u7535\u5f71\u7684\u8bc4\u4ef7\u5bf9\u5e94\u7684\u8bc4\u5206\u4e3a\uff1f{options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingShopping.__init__": [[272, 279], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingShopping.get_examples": [[282, 300], ["os.path.join", "open", "csv.reader", "enumerate", "InputExample", "examples.append", "sentiment.RatingShopping.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "!=", "'train'", ":", "raise", "ValueError", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.csv\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "rating", ",", "text", "=", "row", "[", "2", "]", ",", "row", "[", "4", "]", "+", "\",\"", "+", "row", "[", "5", "]", "\n", "if", "rating", "not", "in", "self", ".", "labels_origin", ":", "continue", "# illegal", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "text", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "rating", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingShopping.get_templates": [[303, 306], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u8bc4\u4ef7\uff1a{text} \u95ee\u9898\uff1a\u8fd9\u6bb5\u8bc4\u4ef7\u5bf9\u5546\u54c1\u7684\u8bc4\u5206\u4e3a\uff1f{options}'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingDianping.__init__": [[312, 319], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"1.0\"", ",", "\"2.0\"", ",", "\"3.0\"", ",", "\"4.0\"", ",", "\"5.0\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"1\"", ",", "\"2\"", ",", "\"3\"", ",", "\"4\"", ",", "\"5\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingDianping.get_examples": [[322, 359], ["os.path.join", "open", "csv.reader", "enumerate", "InputExample", "examples.append", "InputExample", "examples.append", "InputExample", "examples.append", "sentiment.RatingDianping.get_label", "sentiment.RatingDianping.get_label", "sentiment.RatingDianping.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "if", "split", "!=", "'train'", ":", "raise", "ValueError", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.csv\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "continue", "\n", "rating_env", ",", "rating_flavor", ",", "rating_service", ",", "text", "=", "row", "[", "3", "]", ",", "row", "[", "4", "]", ",", "row", "[", "5", "]", ",", "row", "[", "7", "]", "\n", "if", "rating_env", "==", "\"\"", ":", "continue", "# illegal data", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "text", ",", "\n", "\"question\"", ":", "\"\u73af\u5883\"", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "rating_env", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "text", ",", "\n", "\"question\"", ":", "\"\u7279\u8272\"", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "rating_flavor", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"text\"", ":", "text", ",", "\n", "\"question\"", ":", "\"\u8bbe\u65bd\"", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "rating_service", ")", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.sentiment.RatingDianping.get_templates": [[361, 364], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u8bc4\u4ef7:{text} \u95ee\u9898\uff1a\u636e\u6b64\u4f30\u8ba1\uff0c\u8fd9\u6bb5\u8bc4\u4ef7\u5bf9{question}\u7684\u8bc4\u5206\u4e3a\uff1f{options}'", "\n", "]", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.CMNLI.__init__": [[6, 13], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"entailment\"", ",", "\"contradiction\"", ",", "\"neutral\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u8574\u542b\"", ",", "\"\u77db\u76fe\"", ",", "\"\u65e0\u5173\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.CMNLI.get_examples": [[16, 33], ["os.path.join", "open", "enumerate", "json.loads", "InputExample", "examples.append", "nli.CMNLI.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line_i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "# print(line_i)", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"premise\"", ":", "example_json", "[", "\"sentence1\"", "]", ",", "\n", "\"hypothesis\"", ":", "example_json", "[", "\"sentence2\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "label", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.CMNLI.get_templates": [[36, 39], ["None"], "methods", ["None"], ["", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u524d\u63d0\uff1a{premise} \u5047\u8bbe: {hypothesis} \u95ee\u9898\uff1a\u524d\u63d0\u548c\u5047\u8bbe\u662f\u4ec0\u4e48\u5173\u7cfb? {options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.CSNLI.__init__": [[44, 51], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"entailment\"", ",", "\"contradiction\"", ",", "\"neutral\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u8574\u542b\"", ",", "\"\u77db\u76fe\"", ",", "\"\u65e0\u5173\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.CSNLI.get_examples": [[54, 69], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "nli.CSNLI.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.jsonl\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"premise\"", ":", "example_json", "[", "\"sentence1\"", "]", ",", "\n", "\"hypothesis\"", ":", "example_json", "[", "\"sentence2\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.CSNLI.get_templates": [[72, 75], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u524d\u63d0\uff1a{premise} \u5047\u8bbe: {hypothesis} \u95ee\u9898\uff1a\u524d\u63d0\u548c\u5047\u8bbe\u662f\u4ec0\u4e48\u5173\u7cfb? {options}'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.__init__": [[88, 95], ["processor.CLSProcessor.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels_origin", "=", "[", "\n", "\"entailment\"", ",", "\"contradiction\"", ",", "\"neutral\"", ",", "\n", "]", ",", "\n", "labels_mapped", "=", "[", "\n", "\"\u8574\u542b\"", ",", "\"\u77db\u76fe\"", ",", "\"\u65e0\u5173\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_examples": [[98, 114], ["os.path.join", "open", "json.loads", "InputExample", "examples.append", "nli.OCNLI.get_label"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.processor.CLSProcessor.get_label"], ["", "def", "get_examples", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f\"{split}.json\"", ")", "\n", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "example_json", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "\"label\"", "not", "in", "example_json", "or", "example_json", "[", "\"label\"", "]", "not", "in", "self", ".", "labels_origin", ":", "continue", "\n", "example", "=", "InputExample", "(", "\n", "meta", "=", "{", "\n", "\"premise\"", ":", "example_json", "[", "\"sentence1\"", "]", ",", "\n", "\"hypothesis\"", ":", "example_json", "[", "\"sentence2\"", "]", ",", "\n", "\"options\"", ":", "self", ".", "labels_mapped", ",", "\n", "}", ",", "\n", "tgt_text", "=", "self", ".", "get_label", "(", "example_json", "[", "\"label\"", "]", ")", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.ZH.nli.OCNLI.get_templates": [[117, 120], ["None"], "methods", ["None"], ["", "", "", "def", "get_templates", "(", "self", ")", ":", "\n", "        ", "return", "[", "\n", "'\u524d\u63d0\uff1a{premise} \u5047\u8bbe: {hypothesis} \u95ee\u9898\uff1a\u524d\u63d0\u548c\u5047\u8bbe\u662f\u4ec0\u4e48\u5173\u7cfb? {options}'", ",", "\n", "]", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptuning_prompts.PtuningTemplate.__init__": [[23, 36], ["openprompt.prompts.MixedTemplate.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "text", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "prompt_encoder_type", ":", "str", "=", "\"lstm\"", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "placeholder_mapping", "=", "placeholder_mapping", ",", "\n", ")", "\n", "self", ".", "prompt_encoder_type", "=", "prompt_encoder_type", "\n", "self", ".", "text", "=", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptuning_prompts.PtuningTemplate.on_text_set": [[37, 44], ["super().on_text_set", "sum", "ptuning_prompts.PtuningTemplate.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.on_text_set", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["", "def", "on_text_set", "(", "self", ")", ":", "\n", "        ", "r\"\"\"\n        when template text was set, generate parameters needed in p-tuning input embedding phrase\n        \"\"\"", "\n", "super", "(", ")", ".", "on_text_set", "(", ")", "\n", "self", ".", "num_soft_token", "=", "sum", "(", "[", "soft_id", "!=", "0", "for", "soft_id", "in", "self", ".", "soft_token_ids", "]", ")", "\n", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptuning_prompts.PtuningTemplate.generate_parameters": [[45, 73], ["torch.nn.Embedding", "torch.nn.Parameter", "torch.LongTensor", "torch.nn.LSTM", "torch.nn.Sequential", "list", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Sequential", "ValueError", "range", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ")", "->", "None", ":", "\n", "        ", "r\"\"\"\n        generate parameters needed for new tokens' embedding in P-tuning\n        \"\"\"", "\n", "if", "self", ".", "num_soft_token", "==", "0", ":", "return", "\n", "self", ".", "new_embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "num_soft_token", ",", "self", ".", "embedding_size", ")", "\n", "self", ".", "new_ids", "=", "nn", ".", "Parameter", "(", "torch", ".", "LongTensor", "(", "list", "(", "range", "(", "self", ".", "num_soft_token", ")", ")", ")", ",", "requires_grad", "=", "False", ")", "\n", "if", "self", ".", "prompt_encoder_type", "==", "\"lstm\"", ":", "\n", "            ", "self", ".", "new_lstm_head", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "self", ".", "embedding_size", ",", "\n", "hidden_size", "=", "self", ".", "embedding_size", ",", "\n", "num_layers", "=", "2", ",", "\n", "bidirectional", "=", "True", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "self", ".", "new_mlp_head", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "self", ".", "embedding_size", ",", "self", ".", "embedding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_size", ",", "self", ".", "embedding_size", ")", "\n", ")", "\n", "", "elif", "self", ".", "prompt_encoder_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "new_mlp_head", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_size", ",", "self", ".", "embedding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_size", ",", "self", ".", "embedding_size", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"unknown prompt_enocder_type\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptuning_prompts.PtuningTemplate.process_batch": [[74, 96], ["ptuning_prompts.PtuningTemplate.raw_embedding", "ptuning_prompts.PtuningTemplate.new_embedding().unsqueeze", "ptuning_prompts.PtuningTemplate.new_mlp_head", "torch.nonzero().view", "range", "range", "ptuning_prompts.PtuningTemplate.new_embedding", "ptuning_prompts.PtuningTemplate.new_lstm_head", "torch.nonzero"], "methods", ["None"], ["", "", "def", "process_batch", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "Union", "[", "Dict", ",", "InputFeatures", "]", ":", "\n", "        ", "r\"\"\"\n        Convert input_ids to inputs_embeds\n        for normal tokens, use the embedding layer of PLM\n        for new tokens, use a brand new embedding layer, with MLP or LSTM head\n        \"\"\"", "\n", "inputs_embeds", "=", "self", ".", "raw_embedding", "(", "batch", "[", "'input_ids'", "]", ")", "\n", "\n", "if", "self", ".", "num_soft_token", "!=", "0", ":", "\n", "            ", "new_embeds", "=", "self", ".", "new_embedding", "(", "self", ".", "new_ids", ")", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "prompt_encoder_type", "==", "\"lstm\"", ":", "\n", "                ", "new_embeds", "=", "self", ".", "new_lstm_head", "(", "new_embeds", ")", "[", "0", "]", "\n", "", "new_embeds", "=", "self", ".", "new_mlp_head", "(", "new_embeds", ")", "\n", "\n", "replace_idxs", "=", "torch", ".", "nonzero", "(", "batch", "[", "'soft_token_ids'", "]", ">", "0", ")", ".", "view", "(", "-", "1", ",", "self", ".", "num_soft_token", ",", "2", ")", "\n", "for", "b", "in", "range", "(", "replace_idxs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "self", ".", "num_soft_token", ")", ":", "\n", "                    ", "inputs_embeds", "[", "b", "]", "[", "replace_idxs", "[", "b", "]", "[", "i", "]", "[", "1", "]", "]", "=", "new_embeds", "[", "0", "]", "[", "i", "]", "\n", "\n", "", "", "", "batch", "[", "'input_ids'", "]", "=", "None", "\n", "batch", "[", "'inputs_embeds'", "]", "=", "inputs_embeds", "\n", "return", "batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptr_prompts.PTRTemplate.__init__": [[22, 33], ["openprompt.prompts.PtuningTemplate.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "text", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "prompt_encoder_type", "=", "\"mlp\"", ",", "\n", "text", "=", "text", ",", "\n", "placeholder_mapping", "=", "placeholder_mapping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptr_prompts.PTRVerbalizer.__init__": [[46, 54], ["openprompt.Verbalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "classes", ":", "Sequence", "[", "str", "]", "=", "None", ",", "\n", "num_classes", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "label_words", ":", "Optional", "[", "Union", "[", "Sequence", "[", "Sequence", "[", "str", "]", "]", ",", "Mapping", "[", "str", ",", "Sequence", "[", "str", "]", "]", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "classes", "=", "classes", ",", "num_classes", "=", "num_classes", ")", "\n", "self", ".", "label_words", "=", "label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptr_prompts.PTRVerbalizer.on_label_words_set": [[55, 79], ["super().on_label_words_set", "len", "torch.nn.ModuleList", "torch.nn.Parameter", "list", "torch.LongTensor", "len", "ValueError", "set", "range", "openprompt.prompts.One2oneVerbalizer", "labels.index", "enumerate"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.on_label_words_set"], ["", "def", "on_label_words_set", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Prepare One2oneVerbalizer for each `<mask>` separately\n        \"\"\"", "\n", "super", "(", ")", ".", "on_label_words_set", "(", ")", "\n", "\n", "self", ".", "num_masks", "=", "len", "(", "self", ".", "label_words", "[", "0", "]", ")", "\n", "for", "words", "in", "self", ".", "label_words", ":", "\n", "            ", "if", "len", "(", "words", ")", "!=", "self", ".", "num_masks", ":", "\n", "                ", "raise", "ValueError", "(", "\"number of mask tokens for different classes are not consistent\"", ")", "\n", "", "", "self", ".", "sub_labels", "=", "[", "\n", "list", "(", "set", "(", "[", "words", "[", "i", "]", "for", "words", "in", "self", ".", "label_words", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_masks", ")", "\n", "]", "# [num_masks, label_size of the corresponding mask]", "\n", "\n", "self", ".", "verbalizers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "One2oneVerbalizer", "(", "tokenizer", "=", "self", ".", "tokenizer", ",", "label_words", "=", "labels", ",", "post_log_softmax", "=", "False", ")", "\n", "for", "labels", "in", "self", ".", "sub_labels", "\n", "]", ")", "# [num_masks]", "\n", "\n", "self", ".", "label_mappings", "=", "nn", ".", "Parameter", "(", "torch", ".", "LongTensor", "(", "[", "\n", "[", "labels", ".", "index", "(", "words", "[", "j", "]", ")", "for", "words", "in", "self", ".", "label_words", "]", "\n", "for", "j", ",", "labels", "in", "enumerate", "(", "self", ".", "sub_labels", ")", "\n", "]", ")", ",", "requires_grad", "=", "False", ")", "# [num_masks, label_size of the whole task]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.ptr_prompts.PTRVerbalizer.process_logits": [[80, 116], ["torch.nn.functional.log_softmax", "ptr_prompts.PTRVerbalizer.verbalizers[].process_logits", "sum", "range", "enumerate", "torch.nn.functional.log_softmax", "enumerate", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.process_logits"], ["", "def", "process_logits", "(", "self", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "# [batch_size, num_masks, vocab_size]", "\n", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        1) Process vocab logits of each `<mask>` into label logits of each `<mask>`\n\n        2) Combine these logits into a single label logits of the whole task\n\n        Args:\n            logits (:obj:`torch.Tensor`): vocab logits of each `<mask>` (shape: `[batch_size, num_masks, vocab_size]`)\n\n        Returns:\n            :obj:`torch.Tensor`: logits (label logits of whole task (shape: `[batch_size, label_size of the whole task]`))\n        \"\"\"", "\n", "each_logits", "=", "[", "# logits of each verbalizer", "\n", "self", ".", "verbalizers", "[", "i", "]", ".", "process_logits", "(", "logits", "=", "logits", "[", ":", ",", "i", ",", ":", "]", ",", "batch", "=", "batch", ",", "**", "kwargs", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_masks", ")", "\n", "]", "# num_masks * [batch_size, label_size of the corresponding mask]", "\n", "\n", "label_logits", "=", "[", "\n", "logits", "[", ":", ",", "self", ".", "label_mappings", "[", "j", "]", "]", "\n", "for", "j", ",", "logits", "in", "enumerate", "(", "each_logits", ")", "\n", "]", "\n", "\n", "logsoftmax", "=", "nn", ".", "functional", ".", "log_softmax", "(", "sum", "(", "label_logits", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "'label'", "in", "batch", ":", "# TODO not an elegant solution", "\n", "            ", "each_logsoftmax", "=", "[", "# (logits of each label) of each mask", "\n", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "[", ":", ",", "self", ".", "label_mappings", "[", "j", "]", "]", "\n", "for", "j", ",", "logits", "in", "enumerate", "(", "each_logits", ")", "\n", "]", "# num_masks * [batch_size, label_size of the whole task]", "\n", "\n", "return", "logsoftmax", "+", "sum", "(", "each_logsoftmax", ")", "/", "len", "(", "each_logits", ")", "# [batch_size, label_size of the whole task]", "\n", "\n", "", "return", "logsoftmax", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_template.SoftTemplate.__init__": [[30, 59], ["openprompt.Template.__init__", "model.get_input_embeddings", "soft_template.SoftTemplate.raw_embedding.requires_grad_", "len", "soft_template.SoftTemplate.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "text", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "soft_embeds", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", "num_tokens", ":", "int", "=", "20", ",", "\n", "initialize_from_vocab", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "random_range", ":", "Optional", "[", "float", "]", "=", "0.5", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "\n", "placeholder_mapping", "=", "placeholder_mapping", ")", "\n", "self", ".", "raw_embedding", "=", "model", ".", "get_input_embeddings", "(", ")", "\n", "self", ".", "raw_embedding", ".", "requires_grad_", "(", "False", ")", "\n", "self", ".", "model_is_encoder_decoder", "=", "model", ".", "config", ".", "is_encoder_decoder", "\n", "self", ".", "random_range", "=", "random_range", "\n", "self", ".", "num_tokens", "=", "num_tokens", "\n", "self", ".", "initialize_from_vocab", "=", "initialize_from_vocab", "\n", "\n", "self", ".", "text", "=", "text", "\n", "# self.default_text1 = {\"placeholder<text_a> <mask>\"", "\n", "# self.default_text2 = \"<text_a> <text_b> <mask>\".split()", "\n", "\n", "if", "soft_embeds", "is", "not", "None", ":", "\n", "            ", "self", ".", "soft_embeds", "=", "soft_embeds", "\n", "self", ".", "num_tokens", "=", "len", "(", "soft_embeds", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "num_tokens", ">", "0", ":", "\n", "                ", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_template.SoftTemplate.on_text_set": [[61, 63], ["soft_template.SoftTemplate.parse_text"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.parse_text"], ["", "", "", "def", "on_text_set", "(", "self", ")", ":", "\n", "        ", "self", ".", "text", "=", "self", ".", "parse_text", "(", "self", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_template.SoftTemplate.wrap_one_example": [[65, 73], ["super().wrap_one_example", "openprompt.utils.logging.logger.warning"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.wrap_one_example"], ["", "def", "wrap_one_example", "(", "self", ",", "example", ")", "->", "List", "[", "Dict", "]", ":", "#TODO this automatic generated template may not be able to process diverse data format.", "\n", "        ", "if", "self", ".", "text", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You didn't provide text template for softprompt. Using default template, is this intended?\"", ")", "\n", "if", "example", ".", "text_b", "is", "None", ":", "\n", "                ", "self", ".", "text", "=", "self", ".", "default_text1", "\n", "", "else", ":", "\n", "                ", "self", ".", "text", "=", "self", ".", "default_text2", "\n", "", "", "return", "super", "(", ")", ".", "wrap_one_example", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_template.SoftTemplate.generate_parameters": [[75, 85], ["torch.nn.Parameter", "soft_template.SoftTemplate.raw_embedding.weight[].clone().detach", "torch.FloatTensor().uniform_", "soft_template.SoftTemplate.raw_embedding.weight[].clone", "torch.FloatTensor", "soft_template.SoftTemplate.raw_embedding.weight.size"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        generate parameters needed for soft tokens embedding in soft-prompt\n        for soft tokens, use a new embedding layer which is initialized with their corresponding embedding of hard tokens\n        \"\"\"", "\n", "if", "self", ".", "initialize_from_vocab", ":", "\n", "            ", "soft_embeds", "=", "self", ".", "raw_embedding", ".", "weight", "[", ":", "self", ".", "num_tokens", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "soft_embeds", "=", "torch", ".", "FloatTensor", "(", "self", ".", "num_tokens", ",", "self", ".", "raw_embedding", ".", "weight", ".", "size", "(", "1", ")", ")", ".", "uniform_", "(", "-", "self", ".", "random_range", ",", "self", ".", "random_range", ")", "\n", "", "self", ".", "soft_embeds", "=", "nn", ".", "Parameter", "(", "soft_embeds", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_template.SoftTemplate.process_batch": [[88, 106], ["soft_template.SoftTemplate.raw_embedding", "torch.cat.size", "soft_template.SoftTemplate.soft_embeds.repeat", "torch.cat", "torch.cat", "torch.ones"], "methods", ["None"], ["", "def", "process_batch", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "Union", "[", "Dict", ",", "InputFeatures", "]", ":", "\n", "        ", "\"\"\"\n        Convert input_ids to inputs_embeds\n        for normal tokens, use the embedding layer of PLM\n        for soft tokens, use a new embedding layer which is initialized with their corresponding embedding of hard tokens\n        \"\"\"", "\n", "inputs_embeds", "=", "self", ".", "raw_embedding", "(", "batch", "[", "'input_ids'", "]", ")", "\n", "batch_size", "=", "inputs_embeds", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "num_tokens", ">", "0", ":", "\n", "            ", "soft_embeds", "=", "self", ".", "soft_embeds", ".", "repeat", "(", "batch_size", ",", "1", ",", "1", ")", "\n", "inputs_embeds", "=", "torch", ".", "cat", "(", "[", "soft_embeds", ",", "inputs_embeds", "]", ",", "1", ")", "\n", "\n", "", "batch", "[", "'input_ids'", "]", "=", "None", "\n", "batch", "[", "'inputs_embeds'", "]", "=", "inputs_embeds", "\n", "if", "'attention_mask'", "in", "batch", "and", "self", ".", "num_tokens", ">", "0", ":", "\n", "            ", "am", "=", "batch", "[", "'attention_mask'", "]", "\n", "batch", "[", "'attention_mask'", "]", "=", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "(", "batch_size", ",", "self", ".", "num_tokens", ")", ",", "dtype", "=", "am", ".", "dtype", ",", "device", "=", "am", ".", "device", ")", ",", "am", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_template.SoftTemplate.post_processing_outputs": [[108, 118], ["None"], "methods", ["None"], ["", "def", "post_processing_outputs", "(", "self", ",", "outputs", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "r\"\"\"Post processing the outputs of language models according\n        to the need of template. Most templates don't need post processing,\n        The template like SoftTemplate, which appends soft template as a module\n        (rather than a sequence of input tokens) to the input,\n        should remove the outputs on these positions to keep the seq_len the same\n        \"\"\"", "\n", "if", "not", "self", ".", "model_is_encoder_decoder", ":", "\n", "            ", "outputs", ".", "logits", "=", "outputs", ".", "logits", "[", ":", ",", "self", ".", "num_tokens", ":", ",", ":", "]", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.__init__": [[39, 64], ["openprompt.Verbalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", "=", "None", ",", "\n", "num_candidates", ":", "Optional", "[", "int", "]", "=", "1000", ",", "\n", "label_word_num_per_class", ":", "Optional", "[", "int", "]", "=", "1", ",", "\n", "num_searches", ":", "Optional", "[", "int", "]", "=", "1", ",", "\n", "score_fct", ":", "Optional", "[", "str", "]", "=", "'llr'", ",", "\n", "balance", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "num_classes", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "classes", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "init_using_split", ":", "Optional", "[", "str", "]", "=", "\"train\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", "=", "num_classes", ",", "tokenizer", "=", "tokenizer", ",", "classes", "=", "classes", ")", "\n", "self", ".", "num_candidates", "=", "num_candidates", "\n", "self", ".", "label_word_num_per_class", "=", "label_word_num_per_class", "\n", "self", ".", "probs_buffer", ",", "self", ".", "labels_buffer", "=", "None", ",", "None", "\n", "assert", "num_searches", ">", "0", ",", "\"You requires the verbalizer to perform {} searches. Invalid.\"", ".", "format", "(", "num_searches", ")", "\n", "self", ".", "num_searches", "=", "num_searches", "\n", "self", ".", "search_id", "=", "0", "\n", "self", ".", "accumulate_step", "=", "0", "# currently not used, to support not epoch-level optimize.", "\n", "self", ".", "accumulate", "=", "True", "# A flag to indicate whether to", "\n", "# accumulate examples for optimization.", "\n", "# set to False after finish optimization.", "\n", "self", ".", "score_fct", "=", "score_fct", "\n", "self", ".", "balance", "=", "balance", "\n", "self", ".", "init_using_split", "=", "init_using_split", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.register_buffer": [[65, 81], ["torch.softmax", "torch.softmax", "torch.softmax", "labels.detach.detach.detach", "torch.softmax.detach", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack"], "methods", ["None"], ["", "def", "register_buffer", "(", "self", ",", "logits", ",", "labels", ")", ":", "\n", "        ", "r'''\n\n        Args:\n            logits (:obj:`torch.Tensor`):\n            labels (:obj:`List`):\n        '''", "\n", "\n", "logits", "=", "F", ".", "softmax", "(", "logits", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", "\n", "if", "self", ".", "probs_buffer", "is", "None", ":", "\n", "            ", "self", ".", "probs_buffer", "=", "logits", "\n", "self", ".", "labels_buffer", "=", "labels", "\n", "", "else", ":", "\n", "            ", "self", ".", "probs_buffer", "=", "torch", ".", "vstack", "(", "[", "self", ".", "probs_buffer", ",", "logits", "]", ")", "\n", "self", ".", "labels_buffer", "=", "torch", ".", "hstack", "(", "[", "self", ".", "labels_buffer", ",", "labels", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.process_logits": [[82, 111], ["hasattr", "automatic_verbalizer.AutomaticVerbalizer.register_buffer", "automatic_verbalizer.AutomaticVerbalizer.project", "automatic_verbalizer.AutomaticVerbalizer.normalize", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "hasattr", "automatic_verbalizer.AutomaticVerbalizer.calibrate", "torch.log.dim", "torch.log.dim", "torch.log.dim", "automatic_verbalizer.AutomaticVerbalizer.aggregate", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "logits.size"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.register_buffer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.calibrate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.aggregate"], ["", "", "def", "process_logits", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "self", ".", "accumulate", ":", "# inherit from nn.Module, only store buffer in training mode.", "\n", "            ", "self", ".", "accumulate_step", "+=", "1", "\n", "self", ".", "register_buffer", "(", "logits", ",", "kwargs", "[", "'batch'", "]", "[", "'label'", "]", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "\"label_words_ids\"", ")", ":", "# TODO the content in this \"if\" is same as super()", "\n", "# project", "\n", "            ", "label_words_logits", "=", "self", ".", "project", "(", "logits", ",", "**", "kwargs", ")", "#Output: (batch_size, num_classes) or  (batch_size, num_classes, num_label_words_per_label)", "\n", "\n", "# normalize", "\n", "label_words_probs", "=", "self", ".", "normalize", "(", "label_words_logits", ")", "\n", "\n", "# calibrate", "\n", "if", "hasattr", "(", "self", ",", "\"_calibrate_logits\"", ")", "and", "self", ".", "_calibrate_logits", "is", "not", "None", ":", "\n", "                ", "label_words_probs", "=", "self", ".", "calibrate", "(", "label_words_probs", "=", "label_words_probs", ")", "\n", "\n", "# convert to logits", "\n", "", "label_words_logits", "=", "torch", ".", "log", "(", "label_words_probs", "+", "1e-15", ")", "\n", "\n", "# aggregate", "\n", "if", "label_words_logits", ".", "dim", "(", ")", ">", "2", ":", "\n", "                ", "label_logits", "=", "self", ".", "aggregate", "(", "label_words_logits", ")", "\n", "", "else", ":", "\n", "                ", "label_logits", "=", "label_words_logits", "\n", "", "return", "label_logits", "\n", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "randn", "(", "(", "logits", ".", "size", "(", "0", ")", ",", "self", ".", "num_classes", ")", ",", "requires_grad", "=", "True", ")", ".", "to", "(", "logits", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.project": [[112, 128], ["None"], "methods", ["None"], ["", "", "def", "project", "(", "self", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ",", "# TODO", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"When this verbalizer hasn't perform optimize(), it has no\n        ``label_words_ids``, thus will give random predictions, and should\n        have no connection to the model to give (miss-leading) grads.\n\n        Args:\n            logits (:obj:`torch.Tensor`): The original logits over the vocabulary.\n\n        Returns:\n            :obj:`torch.Tensor`: The projected logits of label words.\n        \"\"\"", "\n", "label_words_logits", "=", "logits", "[", ":", ",", "self", ".", "label_words_ids", "]", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.optimize": [[130, 132], ["None"], "methods", ["None"], ["", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.optimize_to_initialize": [[134, 152], ["automatic_verbalizer.AutomaticVerbalizer._show_verbalizer", "automatic_verbalizer.AutomaticVerbalizer._find_verbalizer", "openprompt.utils.logging.logger.info"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._show_verbalizer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._find_verbalizer"], ["", "def", "optimize_to_initialize", "(", "self", ")", ":", "\n", "        ", "r\"\"\"This is an epoch-level optimize. If used in batch-level like an ordinary\n        gradient descend optimizer, the result may not be very satisfying since the accumated\n        examples (i.e., the probs_buffer and the labels_buffer) are not enough if the batchsize\n        is small.\n        \"\"\"", "\n", "if", "self", ".", "search_id", "<", "self", ".", "num_searches", ":", "\n", "            ", "self", ".", "label_words_ids", "=", "self", ".", "_find_verbalizer", "(", "words_per_label", "=", "self", ".", "label_word_num_per_class", ",", "\n", "num_candidates", "=", "self", ".", "num_candidates", ",", "\n", "score_fct", "=", "self", ".", "score_fct", ",", "\n", "balance", "=", "self", ".", "balance", ")", "\n", "self", ".", "probs_buffer", ",", "self", ".", "labels_buffer", "=", "None", ",", "None", "\n", "self", ".", "search_id", "+=", "1", "\n", "if", "self", ".", "search_id", "==", "self", ".", "num_searches", ":", "# finish optimization", "\n", "                ", "self", ".", "accumulate", "=", "False", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Verbalizer's max num_searches reached, use the previous label words.\"", ")", "\n", "", "self", ".", "_show_verbalizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._show_verbalizer": [[154, 157], ["openprompt.utils.logging.logger.info", "automatic_verbalizer.AutomaticVerbalizer.tokenizer.convert_ids_to_tokens"], "methods", ["None"], ["", "def", "_show_verbalizer", "(", "self", ")", ":", "\n", "        ", "tokens", "=", "[", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "i", ")", "for", "i", "in", "self", ".", "label_words_ids", "]", "\n", "logger", ".", "info", "(", "\"Verbalizer is {}\"", ".", "format", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._find_verbalizer": [[159, 171], ["openprompt.utils.logging.logger.info", "automatic_verbalizer.AutomaticVerbalizer._get_candidates", "automatic_verbalizer.AutomaticVerbalizer._get_top_words"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._get_candidates", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._get_top_words"], ["", "def", "_find_verbalizer", "(", "self", ",", "words_per_label", ":", "int", "=", "1", ",", "num_candidates", ":", "int", "=", "1000", ",", "balance", ":", "bool", "=", "True", ",", "\n", "score_fct", ":", "str", "=", "'llr'", ")", ":", "\n", "\n", "# if score_fct == 'random':", "\n", "#      return {label: random.sample(self.word2idx.keys(), words_per_label) for label in self.labels}", "\n", "        ", "logger", ".", "info", "(", "\"Finding verbalizer ...\"", ")", "\n", "probs", "=", "self", ".", "probs_buffer", "\n", "labels", "=", "self", ".", "labels_buffer", "\n", "candidates", "=", "self", ".", "_get_candidates", "(", "num_candidates", "=", "num_candidates", ",", "probs", "=", "probs", ",", "labels", "=", "labels", ")", "\n", "label_words", "=", "self", ".", "_get_top_words", "(", "probs", "=", "probs", ",", "candidates", "=", "candidates", ",", "balance", "=", "balance", ",", "words_per_label", "=", "words_per_label", ",", "\n", "score_fct", "=", "score_fct", ")", "\n", "return", "label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._get_candidates": [[172, 188], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "range", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "candidate_ids.append", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "range"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log"], ["", "def", "_get_candidates", "(", "self", ",", "\n", "num_candidates", ":", "int", ",", "\n", "probs", ":", "torch", ".", "Tensor", ",", "\n", "labels", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "if", "num_candidates", "<=", "0", ":", "\n", "            ", "return", "[", "torch", ".", "arange", "(", "self", ".", "vocab_size", ")", "for", "label_id", "in", "range", "(", "self", ".", "num_classes", ")", "]", "\n", "\n", "", "log_probs", "=", "torch", ".", "log", "(", "probs", "+", "1e-15", ")", "\n", "candidate_ids", "=", "[", "]", "\n", "for", "label_id", "in", "range", "(", "self", ".", "num_classes", ")", ":", "\n", "            ", "label_mask", "=", "(", "labels", "==", "label_id", ")", ".", "to", "(", "torch", ".", "float", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "score", "=", "torch", ".", "sum", "(", "log_probs", "*", "label_mask", ",", "dim", "=", "0", ")", "\n", "candidate_id", "=", "torch", ".", "argsort", "(", "score", ",", "descending", "=", "True", ")", "[", ":", "num_candidates", "]", "\n", "candidate_ids", ".", "append", "(", "candidate_id", ")", "\n", "", "return", "candidate_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._get_top_words": [[189, 210], ["range", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack.append", "torch.vstack.append", "torch.vstack.append", "automatic_verbalizer.AutomaticVerbalizer._log_likelihood_ratio", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "automatic_verbalizer.AutomaticVerbalizer._cross_entropy", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._log_likelihood_ratio", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._cross_entropy"], ["", "def", "_get_top_words", "(", "self", ",", "\n", "probs", ":", "torch", ".", "Tensor", ",", "\n", "candidates", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "balance", ":", "bool", "=", "True", ",", "\n", "words_per_label", ":", "int", "=", "10", ",", "\n", "score_fct", ":", "Optional", "[", "str", "]", "=", "'llr'", ")", ":", "\n", "        ", "label_words_ids", "=", "[", "]", "\n", "for", "label_id", "in", "range", "(", "self", ".", "num_classes", ")", ":", "\n", "            ", "label_mask", "=", "(", "self", ".", "labels_buffer", "==", "label_id", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "probs_per_label", "=", "probs", "[", ":", ",", "candidates", "[", "label_id", "]", "]", "\n", "if", "score_fct", "==", "'llr'", ":", "\n", "                ", "s", "=", "self", ".", "_log_likelihood_ratio", "(", "probs_per_label", ",", "label_mask", ",", "balance", ")", "\n", "", "elif", "score_fct", "==", "'ce'", ":", "\n", "                ", "s", "=", "self", ".", "_cross_entropy", "(", "probs_per_label", ",", "label_mask", ",", "balance", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Score function '{score_fct}' not implemented\"", ")", "\n", "", "sorted_ids", "=", "torch", ".", "argsort", "(", "s", ",", "descending", "=", "True", ")", "[", ":", "words_per_label", "]", "\n", "selected_ids", "=", "candidates", "[", "label_id", "]", "[", "sorted_ids", "]", "\n", "label_words_ids", ".", "append", "(", "selected_ids", ")", "\n", "", "label_words_ids", "=", "torch", ".", "vstack", "(", "label_words_ids", ")", "\n", "return", "label_words_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._log_likelihood_ratio": [[211, 222], ["label_mask.unsqueeze.unsqueeze.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log"], ["", "def", "_log_likelihood_ratio", "(", "self", ",", "probs", ",", "label_mask", ",", "balance", ")", ":", "\n", "        ", "if", "balance", ":", "\n", "            ", "scale_factor", "=", "torch", ".", "sum", "(", "label_mask", ")", "/", "torch", ".", "sum", "(", "1", "-", "label_mask", ")", "*", "(", "1", "-", "label_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "scale_factor", "=", "(", "1", "-", "label_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "label_mask", "=", "label_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "pos_score", "=", "torch", ".", "sum", "(", "torch", ".", "log", "(", "probs", "+", "1e-15", ")", "*", "label_mask", ",", "dim", "=", "0", ")", "-", "torch", ".", "sum", "(", "torch", ".", "log", "(", "1", "-", "probs", "+", "1e-15", ")", "*", "label_mask", ",", "dim", "=", "0", ")", "\n", "neg_score", "=", "torch", ".", "sum", "(", "torch", ".", "log", "(", "1", "-", "probs", "+", "1e-15", ")", "*", "scale_factor", ",", "dim", "=", "0", ")", "-", "torch", ".", "sum", "(", "torch", ".", "log", "(", "probs", "+", "1e-15", ")", "*", "scale_factor", ",", "dim", "=", "0", ")", "\n", "return", "pos_score", "+", "neg_score", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer._cross_entropy": [[223, 234], ["label_mask.unsqueeze.unsqueeze.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log"], ["", "def", "_cross_entropy", "(", "self", ",", "probs", ",", "label_mask", ",", "balance", ")", ":", "\n", "        ", "if", "balance", ":", "\n", "            ", "scale_factor", "=", "torch", ".", "sum", "(", "label_mask", ")", "/", "torch", ".", "sum", "(", "1", "-", "label_mask", ")", "*", "(", "1", "-", "label_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "scale_factor", "=", "(", "1", "-", "label_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "label_mask", "=", "label_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "pos_score", "=", "torch", ".", "sum", "(", "torch", ".", "log", "(", "probs", "+", "1e-15", ")", "*", "label_mask", ",", "dim", "=", "0", ")", "\n", "neg_score", "=", "torch", ".", "sum", "(", "torch", ".", "log", "(", "1", "-", "probs", "+", "1e-15", ")", "*", "scale_factor", ",", "dim", "=", "0", ")", "\n", "return", "pos_score", "+", "neg_score", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.automatic_verbalizer.AutomaticVerbalizer.from_file": [[235, 239], ["NotImplementedError"], "methods", ["None"], ["", "def", "from_file", "(", "self", ",", "\n", "path", ":", "str", ",", "\n", "choice", ":", "Optional", "[", "int", "]", "=", "0", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"This verbalizer is learned and can't be set from file.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.generation_verbalizer.GenerationVerbalizer.__init__": [[62, 79], ["openprompt.Verbalizer.__init__", "list", "label_words.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "classes", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "num_classes", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "is_rule", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "label_words", ":", "Optional", "[", "dict", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "classes", "is", "None", "and", "label_words", "is", "not", "None", ":", "\n", "            ", "classes", "=", "list", "(", "label_words", ".", "keys", "(", ")", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "num_classes", "=", "num_classes", ",", "classes", "=", "classes", ")", "\n", "self", ".", "prefix", "=", "''", "\n", "self", ".", "is_rule", "=", "is_rule", "\n", "self", ".", "mixed_token_start", "=", "\"{\"", "\n", "self", ".", "mixed_token_end", "=", "\"}\"", "\n", "\n", "if", "label_words", "is", "not", "None", ":", "# use label words as an initialization", "\n", "            ", "self", ".", "label_words", "=", "label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.generation_verbalizer.GenerationVerbalizer.wrap_one_example": [[80, 100], ["isinstance", "openprompt.utils.logging.logger.warning", "len", "i"], "methods", ["None"], ["", "", "def", "wrap_one_example", "(", "self", ",", "example", ":", "InputExample", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "r\"\"\"Take an InputExample, and fill the tgt_text with label words\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "self", ".", "label_words", "[", "example", ".", "label", "]", ",", "list", ")", ":", "\n", "            ", "label_word", "=", "[", "self", ".", "label_words", "[", "example", ".", "label", "]", "]", "\n", "", "else", ":", "\n", "            ", "label_word", "=", "self", ".", "label_words", "[", "example", ".", "label", "]", "\n", "\n", "", "if", "example", ".", "tgt_text", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"The example already has tgt_text {example.tgt_text}, and will be filled with new label words, is this intended?\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "is_rule", ":", "\n", "                ", "instance_label_word", "=", "label_word", "\n", "", "else", ":", "\n", "                ", "instance_label_word", "=", "[", "i", "(", "example", ")", "for", "i", "in", "label_word", "]", "#(example)", "\n", "", "", "if", "len", "(", "instance_label_word", ")", "==", "1", ":", "\n", "            ", "example", ".", "tgt_text", "=", "instance_label_word", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "example", ".", "tgt_text", "=", "instance_label_word", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.generation_verbalizer.GenerationVerbalizer.on_label_words_set": [[102, 116], ["isinstance", "enumerate", "functools.partial", "generation_verbalizer.GenerationVerbalizer.parse_text", "RuntimeError", "generation_verbalizer.GenerationVerbalizer.incorporate_text_example"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.parse_text", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.incorporate_text_example"], ["", "def", "on_label_words_set", "(", "self", ")", ":", "\n", "        ", "r\"\"\"\n        Process the text into the label words (sometimes a function) according to the syntax of MixedTemplate\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "label_words", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "self", ".", "label_words", "=", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "label_words", "]", "\n", "\n", "", "if", "self", ".", "is_rule", ":", "\n", "            ", "for", "id", ",", "label_word", "in", "enumerate", "(", "self", ".", "label_words", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "d", "=", "self", ".", "parse_text", "(", "label_word", ")", "\n", "", "except", ":", "\n", "                    ", "raise", "RuntimeError", "(", "f\"is_rule={self.is_rule} but label_word: {label_word} can't be converted to object.\"", ")", "\n", "", "self", ".", "label_words", "[", "id", "]", "=", "partial", "(", "lambda", "x", ",", "text", ":", "self", ".", "incorporate_text_example", "(", "text", ",", "x", ")", ",", "text", "=", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.generation_verbalizer.GenerationVerbalizer.parse_text": [[119, 162], ["len", "parsed.append", "len", "text[].rstrip", "len", "len", "len", "len", "ValueError", "eval", "isinstance", "d.update", "print", "print", "exit", "traceback.format_exc"], "methods", ["None"], ["", "", "", "def", "parse_text", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "parsed", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "text", ")", ":", "\n", "            ", "d", "=", "{", "\"add_prefix_space\"", ":", "' '", "if", "(", "i", ">", "0", "and", "text", "[", "i", "-", "1", "]", "==", "' '", ")", "else", "''", "}", "\n", "while", "i", "<", "len", "(", "text", ")", "and", "text", "[", "i", "]", "==", "' '", ":", "\n", "                ", "d", "[", "\"add_prefix_space\"", "]", "=", "''", "\n", "i", "=", "i", "+", "1", "\n", "", "if", "i", "==", "len", "(", "text", ")", ":", "break", "\n", "\n", "if", "text", "[", "i", "]", "!=", "self", ".", "mixed_token_start", ":", "\n", "                ", "j", "=", "i", "+", "1", "\n", "while", "j", "<", "len", "(", "text", ")", ":", "\n", "                    ", "if", "text", "[", "j", "]", "==", "self", ".", "mixed_token_start", ":", "\n", "                        ", "break", "\n", "", "j", "=", "j", "+", "1", "\n", "", "d", "[", "\"text\"", "]", "=", "text", "[", "i", ":", "j", "]", ".", "rstrip", "(", "' '", ")", "\n", "i", "=", "j", "\n", "\n", "", "else", ":", "\n", "                ", "j", "=", "i", "+", "1", "\n", "while", "j", "<", "len", "(", "text", ")", ":", "\n", "                    ", "if", "text", "[", "j", "]", "==", "self", ".", "mixed_token_end", ":", "\n", "                        ", "break", "\n", "", "j", "=", "j", "+", "1", "\n", "", "if", "j", "==", "len", "(", "text", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"mixed_token_start {self.mixed_token_start} at position {i} has no corresponding mixed_token_end {self.mixed_token_end}\"", ")", "\n", "", "dict_str", "=", "'{'", "+", "text", "[", "i", "+", "1", ":", "j", "]", "+", "'}'", "\n", "try", ":", "\n", "                    ", "val", "=", "eval", "(", "dict_str", ")", "\n", "if", "isinstance", "(", "val", ",", "set", ")", ":", "\n", "                        ", "val", "=", "{", "k", ":", "None", "for", "k", "in", "val", "}", "\n", "", "d", ".", "update", "(", "val", ")", "\n", "", "except", ":", "\n", "                    ", "import", "traceback", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "print", "(", "f\"syntax error in {dict_str}\"", ")", "\n", "exit", "(", ")", "\n", "", "i", "=", "j", "+", "1", "\n", "\n", "", "parsed", ".", "append", "(", "d", ")", "\n", "\n", "", "return", "parsed", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.generation_verbalizer.GenerationVerbalizer.incorporate_text_example": [[163, 185], ["text.copy.copy.copy", "enumerate", "d.get", "getattr", "RuntimeError", "d.get", "RuntimeError", "RuntimeError", "ValueError"], "methods", ["None"], ["", "def", "incorporate_text_example", "(", "self", ",", "\n", "text", ",", "\n", "example", ":", "InputExample", "\n", ")", ":", "\n", "        ", "text", "=", "text", ".", "copy", "(", ")", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "'placeholder'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", ".", "get", "(", "\"post_processing\"", ",", "lambda", "x", ":", "x", ")", "(", "getattr", "(", "example", ",", "d", "[", "'placeholder'", "]", ")", ")", "\n", "", "elif", "'meta'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", ".", "get", "(", "\"post_processing\"", ",", "lambda", "x", ":", "x", ")", "(", "example", ".", "meta", "[", "d", "[", "'meta'", "]", "]", ")", "\n", "", "elif", "'soft'", "in", "d", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"soft token not supported in verbalizer\"", ")", "# unused", "\n", "", "elif", "'mask'", "in", "d", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"mask token not supported in verbalizer\"", ")", "\n", "", "elif", "'special'", "in", "d", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"special token not supported in verbalizer\"", ")", "\n", "", "elif", "'text'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", "[", "'text'", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'can not parse {d}'", ")", "\n", "", "", "text", "=", "\" \"", ".", "join", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.__init__": [[30, 45], ["openprompt.prompts.manual_verbalizer.ManualVerbalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", "=", "None", ",", "\n", "classes", ":", "Sequence", "[", "str", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "\" \"", ",", "\n", "multi_token_handler", ":", "Optional", "[", "str", "]", "=", "\"first\"", ",", "\n", "max_token_split", ":", "Optional", "[", "int", "]", "=", "-", "1", ",", "\n", "verbalizer_lr", ":", "Optional", "[", "float", "]", "=", "5e-2", ",", "\n", "candidate_frac", ":", "Optional", "[", "float", "]", "=", "0.5", ",", "\n", "pred_temp", ":", "Optional", "[", "float", "]", "=", "1.0", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "classes", "=", "classes", ",", "prefix", "=", "prefix", ",", "multi_token_handler", "=", "multi_token_handler", ",", "tokenizer", "=", "tokenizer", ",", "**", "kwargs", ")", "\n", "self", ".", "max_token_split", "=", "max_token_split", "\n", "self", ".", "verbalizer_lr", "=", "verbalizer_lr", "\n", "self", ".", "candidate_frac", "=", "candidate_frac", "\n", "self", ".", "pred_temp", "=", "pred_temp", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.on_label_words_set": [[46, 50], ["knowledgeable_verbalizer.KnowledgeableVerbalizer.delete_common_words", "knowledgeable_verbalizer.KnowledgeableVerbalizer.add_prefix", "knowledgeable_verbalizer.KnowledgeableVerbalizer.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.delete_common_words", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.add_prefix", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["", "def", "on_label_words_set", "(", "self", ")", ":", "\n", "        ", "self", ".", "label_words", "=", "self", ".", "delete_common_words", "(", "self", ".", "label_words", ")", "\n", "self", ".", "label_words", "=", "self", ".", "add_prefix", "(", "self", ".", "label_words", ",", "self", ".", "prefix", ")", "\n", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.delete_common_words": [[51, 66], ["d_perclass[].index", "d_perclass.pop"], "methods", ["None"], ["", "def", "delete_common_words", "(", "self", ",", "d", ")", ":", "\n", "        ", "word_count", "=", "{", "}", "\n", "for", "d_perclass", "in", "d", ":", "\n", "            ", "for", "w", "in", "d_perclass", ":", "\n", "                ", "if", "w", "not", "in", "word_count", ":", "\n", "                    ", "word_count", "[", "w", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "word_count", "[", "w", "]", "+=", "1", "\n", "", "", "", "for", "w", "in", "word_count", ":", "\n", "            ", "if", "word_count", "[", "w", "]", ">=", "2", ":", "\n", "                ", "for", "d_perclass", "in", "d", ":", "\n", "                    ", "if", "w", "in", "d_perclass", "[", "1", ":", "]", ":", "\n", "                        ", "findidx", "=", "d_perclass", "[", "1", ":", "]", ".", "index", "(", "w", ")", "\n", "d_perclass", ".", "pop", "(", "findidx", "+", "1", ")", "\n", "", "", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.add_prefix": [[67, 76], ["new_label_words.append", "word.lstrip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_prefix", "(", "label_words", ",", "prefix", ")", ":", "\n", "        ", "r\"\"\"add prefix to label words. For example, if a label words is in the middle of a template,\n        the prefix should be ' '.\n        \"\"\"", "\n", "new_label_words", "=", "[", "]", "\n", "for", "words", "in", "label_words", ":", "\n", "            ", "new_label_words", ".", "append", "(", "[", "prefix", "+", "word", ".", "lstrip", "(", "prefix", ")", "for", "word", "in", "words", "]", ")", "\n", "", "return", "new_label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.generate_parameters": [[77, 122], ["max", "max", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "print", "label_words.append", "all_ids.append", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "knowledgeable_verbalizer.KnowledgeableVerbalizer.tokenizer.encode", "max", "len", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.sum", "knowledgeable_verbalizer.KnowledgeableVerbalizer.label_words_mask.sum().cpu().tolist", "openprompt.utils.logging.logger.warning", "words_keep_per_label.append", "ids_per_label.append", "len", "len", "len", "len", "knowledgeable_verbalizer.KnowledgeableVerbalizer.label_words_mask.sum().cpu", "len", "knowledgeable_verbalizer.KnowledgeableVerbalizer.tokenizer.convert_ids_to_tokens", "len", "len", "len", "knowledgeable_verbalizer.KnowledgeableVerbalizer.label_words_mask.sum"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ")", "->", "List", ":", "\n", "        ", "r\"\"\"In basic manual template, the parameters are generated from label words directly.\n        In this implementation, the label_words should not be tokenized into more one token.\n        \"\"\"", "\n", "all_ids", "=", "[", "]", "\n", "label_words", "=", "[", "]", "\n", "# print([len(x) for x in self.label_words], flush=True)", "\n", "for", "words_per_label", "in", "self", ".", "label_words", ":", "\n", "            ", "ids_per_label", "=", "[", "]", "\n", "words_keep_per_label", "=", "[", "]", "\n", "for", "word", "in", "words_per_label", ":", "\n", "                ", "ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "word", ",", "add_special_tokens", "=", "False", ")", "\n", "if", "self", ".", "max_token_split", ">", "0", "and", "len", "(", "ids", ")", ">", "self", ".", "max_token_split", ":", "\n", "# in knowledgebale verbalizer, the labelwords may be very rare, so we may", "\n", "# want to remove the label words which are not recogonized by tokenizer.", "\n", "                    ", "logger", ".", "warning", "(", "\"Word {} is split into {} (>{}) tokens: {}. Ignored.\"", ".", "format", "(", "word", ",", "len", "(", "ids", ")", ",", "self", ".", "max_token_split", ",", "\n", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", ")", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "words_keep_per_label", ".", "append", "(", "word", ")", "\n", "ids_per_label", ".", "append", "(", "ids", ")", "\n", "", "", "label_words", ".", "append", "(", "words_keep_per_label", ")", "\n", "all_ids", ".", "append", "(", "ids_per_label", ")", "\n", "", "self", ".", "label_words", "=", "label_words", "\n", "\n", "\n", "\n", "max_len", "=", "max", "(", "[", "max", "(", "[", "len", "(", "ids", ")", "for", "ids", "in", "ids_per_label", "]", ")", "for", "ids_per_label", "in", "all_ids", "]", ")", "\n", "max_num_label_words", "=", "max", "(", "[", "len", "(", "ids_per_label", ")", "for", "ids_per_label", "in", "all_ids", "]", ")", "\n", "words_ids_mask", "=", "torch", ".", "zeros", "(", "max_num_label_words", ",", "max_len", ")", "\n", "words_ids_mask", "=", "[", "[", "[", "1", "]", "*", "len", "(", "ids", ")", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "ids_per_label", "]", "\n", "+", "[", "[", "0", "]", "*", "max_len", "]", "*", "(", "max_num_label_words", "-", "len", "(", "ids_per_label", ")", ")", "\n", "for", "ids_per_label", "in", "all_ids", "]", "\n", "words_ids", "=", "[", "[", "ids", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "ids_per_label", "]", "\n", "+", "[", "[", "0", "]", "*", "max_len", "]", "*", "(", "max_num_label_words", "-", "len", "(", "ids_per_label", ")", ")", "\n", "for", "ids_per_label", "in", "all_ids", "]", "\n", "\n", "words_ids_tensor", "=", "torch", ".", "tensor", "(", "words_ids", ")", "\n", "words_ids_mask", "=", "torch", ".", "tensor", "(", "words_ids_mask", ")", "\n", "self", ".", "label_words_ids", "=", "nn", ".", "Parameter", "(", "words_ids_tensor", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "words_ids_mask", "=", "nn", ".", "Parameter", "(", "words_ids_mask", ",", "requires_grad", "=", "False", ")", "# A 3-d mask", "\n", "self", ".", "label_words_mask", "=", "nn", ".", "Parameter", "(", "torch", ".", "clamp", "(", "words_ids_mask", ".", "sum", "(", "dim", "=", "-", "1", ")", ",", "max", "=", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "label_words_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "num_classes", ",", "max_num_label_words", ")", ",", "requires_grad", "=", "True", ")", "\n", "print", "(", "\"##Num of label words for each label: {}\"", ".", "format", "(", "self", ".", "label_words_mask", ".", "sum", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", ",", "flush", "=", "True", ")", "\n", "# print(self.label_words_ids.data.shape, flush=True)", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.register_calibrate_logits": [[130, 150], ["knowledgeable_verbalizer.KnowledgeableVerbalizer.label_words_ids.data.cpu().tolist", "set", "enumerate", "knowledgeable_verbalizer.KnowledgeableVerbalizer.to", "logits.detach.detach.detach", "[].cpu().tolist", "new_label_words.append", "enumerate", "knowledgeable_verbalizer.KnowledgeableVerbalizer.label_words_ids.data.cpu", "[].cpu", "len", "len", "new_label_words[].append", "set().difference().intersection", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "set().difference", "int", "set", "set"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "register_calibrate_logits", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "r\"\"\"For Knowledgeable Verbalizer, it's nessessory to filter the words with has low prior probability.\n        Therefore we re-compute the label words after register calibration logits.\n        \"\"\"", "\n", "if", "logits", ".", "requires_grad", ":", "\n", "            ", "logits", "=", "logits", ".", "detach", "(", ")", "\n", "", "self", ".", "_calibrate_logits", "=", "logits", "\n", "cur_label_words_ids", "=", "self", ".", "label_words_ids", ".", "data", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "rm_calibrate_ids", "=", "set", "(", "torch", ".", "argsort", "(", "self", ".", "_calibrate_logits", ")", "[", ":", "int", "(", "self", ".", "candidate_frac", "*", "logits", ".", "shape", "[", "-", "1", "]", ")", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "new_label_words", "=", "[", "]", "\n", "for", "i_label", ",", "words_ids_per_label", "in", "enumerate", "(", "cur_label_words_ids", ")", ":", "\n", "            ", "new_label_words", ".", "append", "(", "[", "]", ")", "\n", "for", "j_word", ",", "word_ids", "in", "enumerate", "(", "words_ids_per_label", ")", ":", "\n", "                ", "if", "j_word", ">=", "len", "(", "self", ".", "label_words", "[", "i_label", "]", ")", ":", "\n", "                    ", "break", "\n", "", "if", "len", "(", "(", "set", "(", "word_ids", ")", ".", "difference", "(", "set", "(", "[", "0", "]", ")", ")", ")", ".", "intersection", "(", "rm_calibrate_ids", ")", ")", "==", "0", ":", "\n", "                    ", "new_label_words", "[", "-", "1", "]", ".", "append", "(", "self", ".", "label_words", "[", "i_label", "]", "[", "j_word", "]", ")", "\n", "", "", "", "self", ".", "label_words", "=", "new_label_words", "\n", "self", ".", "to", "(", "self", ".", "_calibrate_logits", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.project": [[152, 162], ["knowledgeable_verbalizer.KnowledgeableVerbalizer.handle_multi_token"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.handle_multi_token"], ["", "def", "project", "(", "self", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"The return value if the normalized (sum to 1) probs of label words.\n        \"\"\"", "\n", "label_words_logits", "=", "logits", "[", ":", ",", "self", ".", "label_words_ids", "]", "\n", "label_words_logits", "=", "self", ".", "handle_multi_token", "(", "label_words_logits", ",", "self", ".", "words_ids_mask", ")", "\n", "label_words_logits", "-=", "10000", "*", "(", "1", "-", "self", ".", "label_words_mask", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.knowledgeable_verbalizer.KnowledgeableVerbalizer.aggregate": [[163, 178], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "aggregate", "(", "self", ",", "label_words_logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"Use weight to aggregate the logots of label words.\n\n        Args:\n            label_words_logits(:obj:`torch.Tensor`): The logits of the label words.\n\n        Returns:\n            :obj:`torch.Tensor`: The aggregated logits from the label words.\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "label_words_weights", "=", "F", ".", "softmax", "(", "self", ".", "pred_temp", "*", "self", ".", "label_words_weights", "-", "10000", "*", "(", "1", "-", "self", ".", "label_words_mask", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "label_words_weights", "=", "F", ".", "softmax", "(", "self", ".", "label_words_weights", "-", "10000", "*", "(", "1", "-", "self", ".", "label_words_mask", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "label_words_logits", "=", "(", "label_words_logits", "*", "self", ".", "label_words_mask", "*", "label_words_weights", ")", ".", "sum", "(", "-", "1", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.__init__": [[30, 44], ["openprompt.Verbalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "num_classes", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "classes", ":", "Optional", "[", "List", "]", "=", "None", ",", "\n", "label_words", ":", "Optional", "[", "Union", "[", "Sequence", "[", "str", "]", ",", "Mapping", "[", "str", ",", "str", "]", "]", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "\" \"", ",", "\n", "multi_token_handler", ":", "Optional", "[", "str", "]", "=", "\"first\"", ",", "\n", "post_log_softmax", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "num_classes", "=", "num_classes", ",", "classes", "=", "classes", ")", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "multi_token_handler", "=", "multi_token_handler", "\n", "self", ".", "label_words", "=", "label_words", "\n", "self", ".", "post_log_softmax", "=", "post_log_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.on_label_words_set": [[45, 49], ["super().on_label_words_set", "one2one_verbalizer.One2oneVerbalizer.add_prefix", "one2one_verbalizer.One2oneVerbalizer.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.on_label_words_set", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.add_prefix", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["", "def", "on_label_words_set", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "on_label_words_set", "(", ")", "\n", "self", ".", "label_words", "=", "self", ".", "add_prefix", "(", "self", ".", "label_words", ",", "self", ".", "prefix", ")", "\n", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.add_prefix": [[50, 74], ["isinstance", "word.startswith", "max", "new_label_words.append", "new_label_words.append", "len", "word.split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_prefix", "(", "label_words", ",", "prefix", ")", ":", "\n", "        ", "r\"\"\"Add prefix to label words. For example, if a label words is in the middle of a template,\n        the prefix should be ``' '``.\n\n        Args:\n            label_words (:obj:`Union[Sequence[str], Mapping[str, str]]`, optional): The label words that are projected by the labels.\n            prefix (:obj:`str`, optional): The prefix string of the verbalizer.\n\n        Returns:\n            :obj:`Sequence[str]`: New label words with prefix.\n        \"\"\"", "\n", "new_label_words", "=", "[", "]", "\n", "if", "isinstance", "(", "label_words", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "assert", "max", "(", "[", "len", "(", "w", ")", "for", "w", "in", "label_words", "]", ")", "==", "1", ",", "\"Providing multiple label words, you should use other verbalizers instead.\"", "\n", "label_words", "=", "[", "w", "[", "0", "]", "for", "w", "in", "label_words", "]", "\n", "\n", "", "for", "word", "in", "label_words", ":", "\n", "            ", "if", "word", ".", "startswith", "(", "\"<!>\"", ")", ":", "\n", "                ", "new_label_words", ".", "append", "(", "word", ".", "split", "(", "\"<!>\"", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "new_label_words", ".", "append", "(", "prefix", "+", "word", ")", "\n", "\n", "", "", "return", "new_label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.generate_parameters": [[75, 97], ["max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "one2one_verbalizer.One2oneVerbalizer.tokenizer.encode", "words_ids.append", "len", "openprompt.utils.logging.logger.warning", "len", "len", "one2one_verbalizer.One2oneVerbalizer.tokenizer.convert_ids_to_tokens", "len", "len"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ")", "->", "List", ":", "\n", "        ", "r\"\"\"In basic manual template, the parameters are generated from label words directly.\n        In this implementation, the label_words should not be tokenized into more than one token.\n        \"\"\"", "\n", "words_ids", "=", "[", "]", "\n", "for", "word", "in", "self", ".", "label_words", ":", "\n", "            ", "word_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "word", ",", "add_special_tokens", "=", "False", ")", "\n", "if", "len", "(", "word_ids", ")", ">", "1", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Word {} is split into multiple tokens: {}. \\\n                    If this is not what you expect, try using another word for this verbalizer\"", ".", "format", "(", "word", ",", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "word_ids", ")", ")", ")", "\n", "", "words_ids", ".", "append", "(", "word_ids", ")", "\n", "\n", "\n", "", "max_len", "=", "max", "(", "[", "len", "(", "ids", ")", "for", "ids", "in", "words_ids", "]", ")", "\n", "words_ids_mask", "=", "[", "[", "1", "]", "*", "len", "(", "ids", ")", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "words_ids", "]", "\n", "words_ids", "=", "[", "ids", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "words_ids", "]", "\n", "\n", "words_ids_tensor", "=", "torch", ".", "tensor", "(", "words_ids", ")", "\n", "words_ids_mask", "=", "torch", ".", "tensor", "(", "words_ids_mask", ")", "\n", "self", ".", "label_words_ids", "=", "nn", ".", "Parameter", "(", "words_ids_tensor", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "label_words_mask", "=", "nn", ".", "Parameter", "(", "words_ids_mask", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.project": [[98, 114], ["one2one_verbalizer.One2oneVerbalizer.handle_multi_token"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.handle_multi_token"], ["", "def", "project", "(", "self", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n        Project the labels, the return value is the normalized (sum to 1) probs of label words.\n\n        Args:\n            logits (:obj:`torch.Tensor`): The original logits of label words.\n\n        Returns:\n            :obj:`torch.Tensor`: The normalized logits of label words\n        \"\"\"", "\n", "label_words_logits", "=", "logits", "[", ":", ",", "self", ".", "label_words_ids", "]", "\n", "label_words_logits", "=", "self", ".", "handle_multi_token", "(", "label_words_logits", ",", "self", ".", "label_words_mask", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.process_logits": [[115, 147], ["one2one_verbalizer.One2oneVerbalizer.project", "one2one_verbalizer.One2oneVerbalizer.normalize", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "hasattr", "one2one_verbalizer.One2oneVerbalizer.calibrate"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.calibrate"], ["", "def", "process_logits", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"A whole framework to process the original logits over the vocabulary, which contains four steps:\n\n        (1) Project the logits into logits of label words\n\n        if self.post_log_softmax is True:\n\n            (2) Normalize over all label words\n\n            (3) Calibrate (optional)\n\n        Args:\n            logits (:obj:`torch.Tensor`): The original logits.\n\n        Returns:\n            (:obj:`torch.Tensor`): The final processed logits over the label words set.\n        \"\"\"", "\n", "# project", "\n", "label_words_logits", "=", "self", ".", "project", "(", "logits", ",", "**", "kwargs", ")", "#Output: (batch_size, num_classes) or  (batch_size, num_classes, num_label_words_per_label)", "\n", "\n", "if", "self", ".", "post_log_softmax", ":", "\n", "# normalize", "\n", "            ", "label_words_probs", "=", "self", ".", "normalize", "(", "label_words_logits", ")", "\n", "\n", "# calibrate", "\n", "if", "hasattr", "(", "self", ",", "\"_calibrate_logits\"", ")", "and", "self", ".", "_calibrate_logits", "is", "not", "None", ":", "\n", "                ", "label_words_probs", "=", "self", ".", "calibrate", "(", "label_words_probs", "=", "label_words_probs", ")", "\n", "\n", "# convert to logits", "\n", "", "label_words_logits", "=", "torch", ".", "log", "(", "label_words_probs", "+", "1e-15", ")", "\n", "\n", "", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.normalize": [[148, 161], ["torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax", "torch.softmax", "torch.softmax", "logits.reshape"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Given logits regarding the entire vocabulary, return the probs over the label words set.\n\n        Args:\n            logits (:obj:`Tensor`): The logits over the entire vocabulary.\n\n        Returns:\n            :obj:`Tensor`: The logits over the label words set.\n\n        \"\"\"", "\n", "batch_size", "=", "logits", ".", "shape", "[", "0", "]", "\n", "return", "F", ".", "softmax", "(", "logits", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ".", "reshape", "(", "*", "logits", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.one2one_verbalizer.One2oneVerbalizer.calibrate": [[163, 182], ["one2one_verbalizer.One2oneVerbalizer.normalize", "label_words_probs.reshape().sum", "one2one_verbalizer.One2oneVerbalizer._calibrate_logits.dim", "one2one_verbalizer.One2oneVerbalizer.project", "one2one_verbalizer.One2oneVerbalizer._calibrate_logits.unsqueeze", "label_words_probs.reshape"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project"], ["", "def", "calibrate", "(", "self", ",", "label_words_probs", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n\n        Args:\n            label_words_probs (:obj:`torch.Tensor`): The probability distribution of the label words with the shape of [``batch_size``, ``num_classes``, ``num_label_words_per_class``]\n\n        Returns:\n            :obj:`torch.Tensor`: The calibrated probability of label words.\n        \"\"\"", "\n", "shape", "=", "label_words_probs", ".", "shape", "\n", "assert", "self", ".", "_calibrate_logits", ".", "dim", "(", ")", "==", "1", ",", "\"self._calibrate_logits are not 1-d tensor\"", "\n", "calibrate_label_words_probs", "=", "self", ".", "normalize", "(", "self", ".", "project", "(", "self", ".", "_calibrate_logits", ".", "unsqueeze", "(", "0", ")", ",", "**", "kwargs", ")", ")", "\n", "assert", "calibrate_label_words_probs", ".", "shape", "[", "1", ":", "]", "==", "label_words_probs", ".", "shape", "[", "1", ":", "]", "and", "calibrate_label_words_probs", ".", "shape", "[", "0", "]", "==", "1", ",", "\"shape not match\"", "\n", "label_words_probs", "/=", "(", "calibrate_label_words_probs", "+", "1e-15", ")", "\n", "# normalize # TODO Test the performance", "\n", "norm", "=", "label_words_probs", ".", "reshape", "(", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "# TODO Test the performance of detaching()", "\n", "label_words_probs", "/=", "norm", "\n", "return", "label_words_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.__init__": [[26, 38], ["openprompt.Template.__init__", "model.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "text", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "placeholder_mapping", "=", "placeholder_mapping", ")", "\n", "\n", "self", ".", "raw_embedding", "=", "model", ".", "get_input_embeddings", "(", ")", "\n", "self", ".", "embedding_size", "=", "self", ".", "raw_embedding", ".", "weight", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "text", "=", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.get_default_soft_token_ids": [[39, 41], ["None"], "methods", ["None"], ["", "def", "get_default_soft_token_ids", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "self", ".", "soft_token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.prepare": [[42, 111], ["torch.nn.Embedding", "emb_mp.items", "soft_token_ids.extend", "mixed_template.MixedTemplate.raw_embedding.weight.data[].clone().detach().requires_grad_", "text.append", "soft_token_ids.append", "text.extend", "mixed_template.MixedTemplate.tokenizer.convert_ids_to_tokens", "len", "list", "enumerate", "text.extend", "ValueError", "text.extend", "soft_token_ids.extend", "mixed_template.MixedTemplate.tokenizer", "len", "len", "range", "mixed_template.MixedTemplate.raw_embedding.weight.data[].clone().detach", "isinstance", "list", "range", "range", "mixed_template.MixedTemplate.raw_embedding.weight.data[].clone", "range", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.tokenizer"], ["", "def", "prepare", "(", "self", ")", ":", "\n", "        ", "r\"\"\"get the soft token indices ( soft_token_ids ) for the template\n\n        ``\"soft_id\"`` can be used to reference the previous soft token, which means these tokens use the same embeddings.\n        **Note that ``\"soft_id\"`` should have index start from 1 but not 0**\n\n        e.g. when self.text is ``'{\"soft\": None} {\"soft\": \"the\", \"soft_id\": 1} {\"soft\": None} {\"soft\": \"it\", \"soft_id\": 3} {\"soft_id\": 1} {\"soft\": \"was\"} {\"mask\"}'``,\n        output is [1, 2, 3, 4, 2, 5, 0]\n        \"\"\"", "\n", "num_soft_token", "=", "0", "\n", "text", "=", "[", "]", "\n", "soft_token_ids", "=", "[", "]", "\n", "idx_mp", "=", "{", "}", "\n", "emb_mp", "=", "{", "}", "\n", "for", "d", "in", "self", ".", "text", ":", "\n", "            ", "if", "\"soft\"", "not", "in", "d", "and", "\"soft_id\"", "not", "in", "d", ":", "\n", "                ", "text", ".", "append", "(", "d", ")", "\n", "soft_token_ids", ".", "append", "(", "0", ")", "\n", "continue", "\n", "\n", "", "old_num", "=", "num_soft_token", "\n", "\n", "if", "\"soft_id\"", "in", "d", ":", "\n", "                ", "if", "not", "isinstance", "(", "d", "[", "\"soft_id\"", "]", ",", "int", ")", "or", "d", "[", "\"soft_id\"", "]", "<=", "0", ":", "\n", "                    ", "raise", "ValueError", "(", "f'soft_id should be integer greater than zero, but get {d[\"soft_id\"]}'", ")", "\n", "", "if", "d", "[", "\"soft_id\"", "]", "in", "idx_mp", ":", "\n", "                    ", "id_list", "=", "idx_mp", "[", "d", "[", "\"soft_id\"", "]", "]", "\n", "text", ".", "extend", "(", "[", "{", "\"soft\"", ":", "None", "}", "for", "_", "in", "range", "(", "len", "(", "id_list", ")", ")", "]", ")", "\n", "soft_token_ids", ".", "extend", "(", "id_list", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                    ", "if", "\"soft\"", "not", "in", "d", ":", "d", "[", "\"soft\"", "]", "=", "None", "\n", "\n", "", "", "if", "d", "[", "\"soft\"", "]", "is", "None", ":", "\n", "                ", "if", "\"duplicate\"", "in", "d", ":", "\n", "                    ", "if", "\"same\"", "in", "d", "and", "d", "[", "\"same\"", "]", ":", "\n", "                        ", "num_soft_token", "+=", "1", "\n", "id_list", "=", "[", "num_soft_token", "for", "_", "in", "range", "(", "len", "(", "d", "[", "\"duplicate\"", "]", ")", ")", "]", "\n", "", "else", ":", "\n", "                        ", "num_soft_token", "+=", "d", "[", "\"duplicate\"", "]", "\n", "id_list", "=", "list", "(", "range", "(", "old_num", "+", "1", ",", "num_soft_token", "+", "1", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "num_soft_token", "+=", "1", "\n", "id_list", "=", "[", "num_soft_token", "]", "\n", "", "text", ".", "extend", "(", "[", "{", "\"soft\"", ":", "\"\"", "}", "for", "_", "in", "range", "(", "len", "(", "id_list", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "token_ids", "=", "self", ".", "tokenizer", "(", "d", "[", "\"add_prefix_space\"", "]", "+", "d", "[", "\"soft\"", "]", ",", "add_special_tokens", "=", "False", ")", "[", "\"input_ids\"", "]", "\n", "surface_forms", "=", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "token_ids", ")", "\n", "assert", "len", "(", "token_ids", ")", "==", "len", "(", "surface_forms", ")", "\n", "num_soft_token", "+=", "len", "(", "token_ids", ")", "\n", "id_list", "=", "list", "(", "range", "(", "old_num", "+", "1", ",", "num_soft_token", "+", "1", ")", ")", "\n", "for", "idx", ",", "soft_id", "in", "enumerate", "(", "id_list", ")", ":", "\n", "                    ", "emb_mp", "[", "soft_id", "]", "=", "token_ids", "[", "idx", "]", "\n", "\n", "", "text", ".", "extend", "(", "[", "{", "\"soft\"", ":", "surface_form", "}", "for", "surface_form", "in", "surface_forms", "]", ")", "\n", "", "soft_token_ids", ".", "extend", "(", "id_list", ")", "\n", "\n", "if", "\"soft_id\"", "in", "d", ":", "\n", "                ", "idx_mp", "[", "d", "[", "\"soft_id\"", "]", "]", "=", "id_list", "\n", "\n", "", "", "self", ".", "num_soft_token", "=", "num_soft_token", "\n", "self", ".", "text", "=", "text", "\n", "self", ".", "soft_token_ids", "=", "soft_token_ids", "\n", "\n", "# Generate the embedding needed for soft tokens", "\n", "\n", "self", ".", "soft_embedding", "=", "nn", ".", "Embedding", "(", "1", "+", "self", ".", "num_soft_token", ",", "self", ".", "embedding_size", ")", "\n", "for", "soft_id", ",", "token_id", "in", "emb_mp", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "soft_embedding", ".", "weight", ".", "data", "[", "soft_id", ",", ":", "]", "=", "self", ".", "raw_embedding", ".", "weight", ".", "data", "[", "token_id", ",", ":", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.parse_text": [[118, 165], ["len", "parsed.append", "len", "text[].rstrip", "len", "len", "len", "len", "ValueError", "eval", "isinstance", "d.update", "print", "print", "exit", "traceback.format_exc"], "methods", ["None"], ["", "", "def", "parse_text", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "parsed", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "text", ")", ":", "\n", "            ", "d", "=", "{", "\"add_prefix_space\"", ":", "' '", "if", "(", "i", ">", "0", "and", "text", "[", "i", "-", "1", "]", "==", "' '", ")", "else", "''", "}", "\n", "while", "i", "<", "len", "(", "text", ")", "and", "text", "[", "i", "]", "==", "' '", ":", "\n", "                ", "d", "[", "\"add_prefix_space\"", "]", "=", "' '", "\n", "i", "=", "i", "+", "1", "\n", "", "if", "i", "==", "len", "(", "text", ")", ":", "break", "\n", "\n", "if", "text", "[", "i", "]", "!=", "self", ".", "mixed_token_start", ":", "\n", "                ", "j", "=", "i", "+", "1", "\n", "while", "j", "<", "len", "(", "text", ")", ":", "\n", "                    ", "if", "text", "[", "j", "]", "==", "self", ".", "mixed_token_start", ":", "\n", "                        ", "break", "\n", "", "j", "=", "j", "+", "1", "\n", "", "d", "[", "\"text\"", "]", "=", "text", "[", "i", ":", "j", "]", ".", "rstrip", "(", "' '", ")", "\n", "i", "=", "j", "\n", "\n", "", "else", ":", "\n", "                ", "j", "=", "i", "+", "1", "\n", "mixed_token_cnt", "=", "1", "# { {} {} } nested support", "\n", "while", "j", "<", "len", "(", "text", ")", ":", "\n", "                    ", "if", "text", "[", "j", "]", "==", "self", ".", "mixed_token_end", ":", "\n", "                        ", "mixed_token_cnt", "-=", "1", "\n", "if", "mixed_token_cnt", "==", "0", ":", "break", "\n", "", "elif", "text", "[", "j", "]", "==", "self", ".", "mixed_token_start", ":", "\n", "                        ", "mixed_token_cnt", "+=", "1", "\n", "", "j", "=", "j", "+", "1", "\n", "", "if", "j", "==", "len", "(", "text", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"mixed_token_start {self.mixed_token_start} at position {i} has no corresponding mixed_token_end {self.mixed_token_end}\"", ")", "\n", "", "dict_str", "=", "'{'", "+", "text", "[", "i", "+", "1", ":", "j", "]", "+", "'}'", "\n", "try", ":", "\n", "                    ", "val", "=", "eval", "(", "dict_str", ")", "\n", "if", "isinstance", "(", "val", ",", "set", ")", ":", "\n", "                        ", "val", "=", "{", "k", ":", "None", "for", "k", "in", "val", "}", "\n", "", "d", ".", "update", "(", "val", ")", "\n", "", "except", ":", "\n", "                    ", "import", "traceback", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "print", "(", "f\"syntax error in {dict_str}\"", ")", "\n", "exit", "(", ")", "\n", "", "i", "=", "j", "+", "1", "\n", "\n", "", "parsed", ".", "append", "(", "d", ")", "\n", "\n", "", "return", "parsed", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.on_text_set": [[167, 178], ["mixed_template.MixedTemplate.parse_text", "mixed_template.MixedTemplate.prepare"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.parse_text", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.prepare"], ["", "def", "on_text_set", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        when template text was set\n\n        1. parse text\n\n        2. generate parameter needed\n        \"\"\"", "\n", "\n", "self", ".", "text", "=", "self", ".", "parse_text", "(", "self", ".", "text", ")", "\n", "self", ".", "prepare", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.incorporate_text_example": [[180, 200], ["mixed_template.MixedTemplate.text.copy", "enumerate", "d.get", "getattr", "d.get", "ValueError"], "methods", ["None"], ["", "def", "incorporate_text_example", "(", "self", ",", "\n", "example", ":", "InputExample", "\n", ")", ":", "\n", "        ", "text", "=", "self", ".", "text", ".", "copy", "(", ")", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "'placeholder'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", ".", "get", "(", "\"post_processing\"", ",", "lambda", "x", ":", "x", ")", "(", "getattr", "(", "example", ",", "d", "[", "'placeholder'", "]", ")", ")", "\n", "", "elif", "'meta'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", ".", "get", "(", "\"post_processing\"", ",", "lambda", "x", ":", "x", ")", "(", "example", ".", "meta", "[", "d", "[", "'meta'", "]", "]", ")", "\n", "", "elif", "'soft'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "'soft'", "]", ";", "# unused", "\n", "", "elif", "'mask'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "'<mask>'", "\n", "", "elif", "'special'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "'special'", "]", "\n", "", "elif", "'text'", "in", "d", ":", "\n", "                ", "text", "[", "i", "]", "=", "d", "[", "\"add_prefix_space\"", "]", "+", "d", "[", "'text'", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'can not parse {d}'", ")", "\n", "", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.process_batch": [[202, 215], ["mixed_template.MixedTemplate.raw_embedding", "mixed_template.MixedTemplate.soft_embedding", "torch.where"], "methods", ["None"], ["", "def", "process_batch", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "Union", "[", "Dict", ",", "InputFeatures", "]", ":", "\n", "        ", "\"\"\"\n        Convert input_ids to inputs_embeds\n        for normal tokens, use the embedding layer of PLM\n        for soft tokens, use a new embedding layer which is initialized with their corresponding embedding of hard tokens\n        \"\"\"", "\n", "raw_embeds", "=", "self", ".", "raw_embedding", "(", "batch", "[", "'input_ids'", "]", ")", "\n", "soft_embeds", "=", "self", ".", "soft_embedding", "(", "batch", "[", "'soft_token_ids'", "]", ")", "\n", "inputs_embeds", "=", "torch", ".", "where", "(", "(", "batch", "[", "'soft_token_ids'", "]", ">", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "soft_embeds", ",", "raw_embeds", ")", "\n", "\n", "batch", "[", "'input_ids'", "]", "=", "None", "\n", "batch", "[", "'inputs_embeds'", "]", "=", "inputs_embeds", "\n", "return", "batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.__init__": [[37, 71], ["openprompt.Verbalizer.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Optional", "[", "PreTrainedTokenizer", "]", ",", "\n", "model", ":", "Optional", "[", "PreTrainedModel", "]", ",", "\n", "classes", ":", "Optional", "[", "List", "]", "=", "None", ",", "\n", "num_classes", ":", "Optional", "[", "Sequence", "[", "str", "]", "]", "=", "None", ",", "\n", "label_words", ":", "Optional", "[", "Union", "[", "Sequence", "[", "str", "]", ",", "Mapping", "[", "str", ",", "str", "]", "]", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "\" \"", ",", "\n", "multi_token_handler", ":", "Optional", "[", "str", "]", "=", "\"first\"", ",", "\n", "post_log_softmax", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "lr", ":", "Optional", "[", "float", "]", "=", "1e-3", ",", "\n", "mid_dim", ":", "Optional", "[", "int", "]", "=", "64", ",", "\n", "epochs", ":", "Optional", "[", "int", "]", "=", "5", ",", "\n", "multi_verb", ":", "Optional", "[", "str", "]", "=", "\"multi\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "num_classes", "=", "num_classes", ",", "classes", "=", "classes", ")", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "multi_token_handler", "=", "multi_token_handler", "\n", "self", ".", "post_log_softmax", "=", "post_log_softmax", "\n", "self", ".", "multi_verb", "=", "multi_verb", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "mid_dim", "=", "mid_dim", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "trained", "=", "False", "\n", "\n", "self", ".", "hidden_dims", "=", "model", ".", "config", ".", "hidden_size", "\n", "\n", "self", ".", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "hidden_dims", ",", "self", ".", "mid_dim", ",", "bias", "=", "False", ")", "\n", "\n", "if", "label_words", "is", "not", "None", ":", "# use label words as an initialization", "\n", "            ", "self", ".", "label_words", "=", "label_words", "\n", "", "w", "=", "torch", ".", "empty", "(", "(", "self", ".", "num_classes", ",", "self", ".", "mid_dim", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "w", ")", "\n", "self", ".", "proto", "=", "nn", ".", "Parameter", "(", "w", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "group_parameters_proto", ",", "lr", "=", "self", ".", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.group_parameters_proto": [[72, 80], ["isinstance", "prototypical_verbalizer.ProtoVerbalizer.head.named_parameters", "prototypical_verbalizer.ProtoVerbalizer.head.named_parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "group_parameters_proto", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"Include the last layer's parameters\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "head", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "            ", "return", "[", "p", "for", "n", ",", "p", "in", "self", ".", "head", ".", "named_parameters", "(", ")", "]", "+", "[", "self", ".", "proto", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "p", "for", "n", ",", "p", "in", "self", ".", "head", ".", "named_parameters", "(", ")", "]", "+", "[", "self", ".", "proto", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.on_label_words_set": [[81, 84], ["prototypical_verbalizer.ProtoVerbalizer.add_prefix", "prototypical_verbalizer.ProtoVerbalizer.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.add_prefix", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["", "", "def", "on_label_words_set", "(", "self", ")", ":", "\n", "        ", "self", ".", "label_words", "=", "self", ".", "add_prefix", "(", "self", ".", "label_words", ",", "self", ".", "prefix", ")", "\n", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.add_prefix": [[85, 110], ["isinstance", "new_label_words.append", "word.startswith", "new_label_words_per_label.append", "new_label_words_per_label.append", "word.split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_prefix", "(", "label_words", ",", "prefix", ")", ":", "\n", "        ", "r\"\"\"Add prefix to label words. For example, if a label words is in the middle of a template,\n        the prefix should be ``' '``.\n\n        Args:\n            label_words (:obj:`Union[Sequence[str], Mapping[str, str]]`, optional): The label words that are projected by the labels.\n            prefix (:obj:`str`, optional): The prefix string of the verbalizer.\n\n        Returns:\n            :obj:`Sequence[str]`: New label words with prefix.\n        \"\"\"", "\n", "new_label_words", "=", "[", "]", "\n", "if", "isinstance", "(", "label_words", "[", "0", "]", ",", "str", ")", ":", "\n", "            ", "label_words", "=", "[", "[", "w", "]", "for", "w", "in", "label_words", "]", "#wrapped it to a list of list of label words.", "\n", "\n", "", "for", "label_words_per_label", "in", "label_words", ":", "\n", "            ", "new_label_words_per_label", "=", "[", "]", "\n", "for", "word", "in", "label_words_per_label", ":", "\n", "                ", "if", "word", ".", "startswith", "(", "\"<!>\"", ")", ":", "\n", "                    ", "new_label_words_per_label", ".", "append", "(", "word", ".", "split", "(", "\"<!>\"", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "new_label_words_per_label", ".", "append", "(", "prefix", "+", "word", ")", "\n", "", "", "new_label_words", ".", "append", "(", "new_label_words_per_label", ")", "\n", "", "return", "new_label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.generate_parameters": [[111, 138], ["max", "max", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "all_ids.append", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "prototypical_verbalizer.ProtoVerbalizer.tokenizer.encode", "ids_per_label.append", "max", "len", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.sum", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ")", "->", "List", ":", "\n", "        ", "r\"\"\"In basic manual template, the parameters are generated from label words directly.\n        In this implementation, the label_words should not be tokenized into more than one token.\n        \"\"\"", "\n", "all_ids", "=", "[", "]", "\n", "for", "words_per_label", "in", "self", ".", "label_words", ":", "\n", "            ", "ids_per_label", "=", "[", "]", "\n", "for", "word", "in", "words_per_label", ":", "\n", "                ", "ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "word", ",", "add_special_tokens", "=", "False", ")", "\n", "ids_per_label", ".", "append", "(", "ids", ")", "\n", "", "all_ids", ".", "append", "(", "ids_per_label", ")", "\n", "\n", "", "max_len", "=", "max", "(", "[", "max", "(", "[", "len", "(", "ids", ")", "for", "ids", "in", "ids_per_label", "]", ")", "for", "ids_per_label", "in", "all_ids", "]", ")", "\n", "max_num_label_words", "=", "max", "(", "[", "len", "(", "ids_per_label", ")", "for", "ids_per_label", "in", "all_ids", "]", ")", "\n", "words_ids_mask", "=", "torch", ".", "zeros", "(", "max_num_label_words", ",", "max_len", ")", "\n", "words_ids_mask", "=", "[", "[", "[", "1", "]", "*", "len", "(", "ids", ")", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "ids_per_label", "]", "\n", "+", "[", "[", "0", "]", "*", "max_len", "]", "*", "(", "max_num_label_words", "-", "len", "(", "ids_per_label", ")", ")", "\n", "for", "ids_per_label", "in", "all_ids", "]", "\n", "words_ids", "=", "[", "[", "ids", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "ids_per_label", "]", "\n", "+", "[", "[", "0", "]", "*", "max_len", "]", "*", "(", "max_num_label_words", "-", "len", "(", "ids_per_label", ")", ")", "\n", "for", "ids_per_label", "in", "all_ids", "]", "\n", "\n", "words_ids_tensor", "=", "torch", ".", "tensor", "(", "words_ids", ")", "\n", "words_ids_mask", "=", "torch", ".", "tensor", "(", "words_ids_mask", ")", "\n", "self", ".", "label_words_ids", "=", "nn", ".", "Parameter", "(", "words_ids_tensor", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "words_ids_mask", "=", "nn", ".", "Parameter", "(", "words_ids_mask", ",", "requires_grad", "=", "False", ")", "# A 3-d mask", "\n", "self", ".", "label_words_mask", "=", "nn", ".", "Parameter", "(", "torch", ".", "clamp", "(", "words_ids_mask", ".", "sum", "(", "dim", "=", "-", "1", ")", ",", "max", "=", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.process_hiddens": [[139, 144], ["prototypical_verbalizer.ProtoVerbalizer.sim", "prototypical_verbalizer.ProtoVerbalizer.head"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.sim"], ["", "def", "process_hiddens", "(", "self", ",", "hiddens", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"A whole framework to process the original logits over the vocabulary, which contains four steps:\n        \"\"\"", "\n", "proto_logits", "=", "self", ".", "sim", "(", "self", ".", "head", "(", "hiddens", ")", ",", "self", ".", "proto", ")", "\n", "return", "proto_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.project": [[145, 163], ["prototypical_verbalizer.ProtoVerbalizer.handle_multi_token"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.handle_multi_token"], ["", "def", "project", "(", "self", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n        Project the labels, the return value is the normalized (sum to 1) probs of label words.\n\n        Args:\n            logits (:obj:`torch.Tensor`): The original logits of label words.\n\n        Returns:\n            :obj:`torch.Tensor`: The normalized logits of label words\n        \"\"\"", "\n", "\n", "label_words_logits", "=", "logits", "[", ":", ",", "self", ".", "label_words_ids", "]", "\n", "label_words_logits", "=", "self", ".", "handle_multi_token", "(", "label_words_logits", ",", "self", ".", "words_ids_mask", ")", "\n", "label_words_logits", "-=", "10000", "*", "(", "1", "-", "self", ".", "label_words_mask", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.process_logits": [[164, 201], ["prototypical_verbalizer.ProtoVerbalizer.project", "prototypical_verbalizer.ProtoVerbalizer.aggregate", "hasattr", "prototypical_verbalizer.ProtoVerbalizer.calibrate"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.aggregate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.calibrate"], ["", "def", "process_logits", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"A whole framework to process the original logits over the vocabulary, which contains four steps:\n\n        (1) Project the logits into logits of label words\n\n        if self.post_log_softmax is True:\n\n            (2) Normalize over all label words\n\n            (3) Calibrate (optional)\n\n        (4) Aggregate (for multiple label words)\n\n        Args:\n            logits (:obj:`torch.Tensor`): The original logits.\n\n        Returns:\n            (:obj:`torch.Tensor`): The final processed logits over the labels (classes).\n        \"\"\"", "\n", "# project", "\n", "label_words_logits", "=", "self", ".", "project", "(", "logits", ",", "**", "kwargs", ")", "#Output: (batch_size, num_classes) or  (batch_size, num_classes, num_label_words_per_label)", "\n", "\n", "\n", "if", "self", ".", "post_log_softmax", ":", "\n", "# normalize", "\n", "# label_words_probs = self.normalize(label_words_logits)", "\n", "\n", "# calibrate", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"_calibrate_logits\"", ")", "and", "self", ".", "_calibrate_logits", "is", "not", "None", ":", "\n", "                ", "label_words_probs", "=", "self", ".", "calibrate", "(", "label_words_probs", "=", "label_words_probs", ")", "\n", "\n", "# convert to logits", "\n", "# label_words_logits = torch.log(label_words_probs+1e-15)", "\n", "\n", "# aggregate", "\n", "", "", "label_logits", "=", "self", ".", "aggregate", "(", "label_words_logits", ")", "\n", "return", "label_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.normalize": [[202, 215], ["torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax", "torch.softmax", "torch.softmax", "logits.reshape"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Given logits regarding the entire vocabulary, return the probs over the label words set.\n\n        Args:\n            logits (:obj:`Tensor`): The logits over the entire vocabulary.\n\n        Returns:\n            :obj:`Tensor`: The logits over the label words set.\n\n        \"\"\"", "\n", "batch_size", "=", "logits", ".", "shape", "[", "0", "]", "\n", "return", "F", ".", "softmax", "(", "logits", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ".", "reshape", "(", "*", "logits", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.aggregate": [[217, 228], ["prototypical_verbalizer.ProtoVerbalizer.label_words_mask.sum"], "methods", ["None"], ["", "def", "aggregate", "(", "self", ",", "label_words_logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"Use weight to aggregate the logits of label words.\n\n        Args:\n            label_words_logits(:obj:`torch.Tensor`): The logits of the label words.\n\n        Returns:\n            :obj:`torch.Tensor`: The aggregated logits from the label words.\n        \"\"\"", "\n", "label_words_logits", "=", "(", "label_words_logits", "*", "self", ".", "label_words_mask", ")", ".", "sum", "(", "-", "1", ")", "/", "self", ".", "label_words_mask", ".", "sum", "(", "-", "1", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.calibrate": [[229, 249], ["prototypical_verbalizer.ProtoVerbalizer.normalize", "label_words_probs.reshape.reshape.reshape().sum", "label_words_probs.reshape.reshape.reshape", "prototypical_verbalizer.ProtoVerbalizer._calibrate_logits.dim", "prototypical_verbalizer.ProtoVerbalizer.project", "label_words_probs.reshape.reshape.reshape", "prototypical_verbalizer.ProtoVerbalizer._calibrate_logits.unsqueeze", "label_words_probs.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project"], ["", "def", "calibrate", "(", "self", ",", "label_words_probs", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n\n        Args:\n            label_words_probs (:obj:`torch.Tensor`): The probability distribution of the label words with the shape of [``batch_size``, ``num_classes``, ``num_label_words_per_class``]\n\n        Returns:\n            :obj:`torch.Tensor`: The calibrated probability of label words.\n        \"\"\"", "\n", "shape", "=", "label_words_probs", ".", "shape", "\n", "assert", "self", ".", "_calibrate_logits", ".", "dim", "(", ")", "==", "1", ",", "\"self._calibrate_logits are not 1-d tensor\"", "\n", "calibrate_label_words_probs", "=", "self", ".", "normalize", "(", "self", ".", "project", "(", "self", ".", "_calibrate_logits", ".", "unsqueeze", "(", "0", ")", ",", "**", "kwargs", ")", ")", "\n", "assert", "calibrate_label_words_probs", ".", "shape", "[", "1", ":", "]", "==", "label_words_probs", ".", "shape", "[", "1", ":", "]", "and", "calibrate_label_words_probs", ".", "shape", "[", "0", "]", "==", "1", ",", "\"shape not match\"", "\n", "label_words_probs", "/=", "(", "calibrate_label_words_probs", "+", "1e-15", ")", "\n", "# normalize # TODO Test the performance", "\n", "norm", "=", "label_words_probs", ".", "reshape", "(", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "# TODO Test the performance of detaching()", "\n", "label_words_probs", "=", "label_words_probs", ".", "reshape", "(", "shape", "[", "0", "]", ",", "-", "1", ")", "/", "norm", "\n", "label_words_probs", "=", "label_words_probs", ".", "reshape", "(", "*", "shape", ")", "\n", "return", "label_words_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.ensemble_logits": [[250, 257], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.mean.permute", "torch.mean.permute", "torch.mean.permute", "prototypical_verbalizer.ProtoVerbalizer.scaler", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.scaler"], ["", "def", "ensemble_logits", "(", "self", ",", "manual_logits", ",", "proto_logits", ")", ":", "\n", "\n", "        ", "logits", "=", "torch", ".", "stack", "(", "[", "manual_logits", ",", "proto_logits", "]", ")", "\n", "logits", "=", "logits", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "logits", "=", "self", ".", "scaler", "(", "logits", ")", "\n", "logits", "=", "torch", ".", "mean", "(", "logits", ",", "1", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.scaler": [[258, 263], ["logits.mean", "logits.std"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "scaler", "(", "logits", ")", ":", "\n", "        ", "m", "=", "logits", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "s", "=", "logits", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "(", "logits", "-", "m", ")", "/", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.process_outputs": [[264, 274], ["prototypical_verbalizer.ProtoVerbalizer.process_logits", "prototypical_verbalizer.ProtoVerbalizer.process_hiddens", "prototypical_verbalizer.ProtoVerbalizer.ensemble_logits"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.process_logits", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.process_hiddens", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.ensemble_logits"], ["", "def", "process_outputs", "(", "self", ",", "outputs", ":", "Union", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "manual_logits", "=", "self", ".", "process_logits", "(", "outputs", "[", "1", "]", ")", "\n", "if", "self", ".", "trained", "is", "False", ":", "\n", "            ", "return", "manual_logits", "\n", "\n", "", "proto_logits", "=", "self", ".", "process_hiddens", "(", "outputs", "[", "0", "]", ")", "\n", "if", "self", ".", "trained", "and", "self", ".", "multi_verb", "==", "\"proto\"", ":", "\n", "            ", "return", "proto_logits", "\n", "\n", "", "return", "self", ".", "ensemble_logits", "(", "manual_logits", ",", "proto_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.gather_outputs": [[275, 288], ["isinstance", "isinstance", "isinstance", "NotImplementedError", "type"], "methods", ["None"], ["", "def", "gather_outputs", "(", "self", ",", "outputs", ":", "ModelOutput", ")", ":", "\n", "        ", "logits", "=", "outputs", ".", "logits", "\n", "if", "isinstance", "(", "outputs", ",", "Seq2SeqLMOutput", ")", ":", "\n", "            ", "ret", "=", "outputs", ".", "decoder_hidden_states", "[", "-", "1", "]", "\n", "", "elif", "isinstance", "(", "outputs", ",", "MaskedLMOutput", ")", "or", "isinstance", "(", "outputs", ",", "CausalLMOutputWithCrossAttentions", ")", ":", "\n", "            ", "ret", "=", "outputs", ".", "hidden_states", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "ret", "=", "outputs", ".", "hidden_states", "[", "-", "1", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "raise", "NotImplementedError", "(", "f\"Gather outputs method for outputs' type {type(outputs)} not implemented\"", ")", "\n", "\n", "", "", "return", "ret", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.sim": [[289, 294], ["torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize.transpose"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize"], ["", "@", "staticmethod", "\n", "def", "sim", "(", "x", ",", "y", ")", ":", "\n", "        ", "norm_x", "=", "F", ".", "normalize", "(", "x", ",", "dim", "=", "-", "1", ")", "\n", "norm_y", "=", "F", ".", "normalize", "(", "y", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "matmul", "(", "norm_x", ",", "norm_y", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.pcl_loss": [[295, 319], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "range", "range", "prototypical_verbalizer.ProtoVerbalizer.sim", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "sim_mat[].sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "prototypical_verbalizer.ProtoVerbalizer.sim", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log().sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp.sum", "torch.exp.sum", "torch.exp.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.sim", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.sim", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log"], ["", "def", "pcl_loss", "(", "self", ",", "v_ins", ")", ":", "\n", "# instance-prototype loss", "\n", "\n", "        ", "sim_mat", "=", "torch", ".", "exp", "(", "self", ".", "sim", "(", "v_ins", ",", "self", ".", "proto", ")", ")", "\n", "num", "=", "sim_mat", ".", "shape", "[", "1", "]", "\n", "loss", "=", "0.", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "            ", "pos_score", "=", "torch", ".", "diag", "(", "sim_mat", "[", ":", ",", "i", ",", ":", "]", ")", "\n", "neg_score", "=", "(", "sim_mat", "[", ":", ",", "i", ",", ":", "]", ".", "sum", "(", "1", ")", "-", "pos_score", ")", "\n", "loss", "+=", "-", "torch", ".", "log", "(", "pos_score", "/", "(", "pos_score", "+", "neg_score", ")", ")", ".", "sum", "(", ")", "\n", "", "loss", "=", "loss", "/", "(", "num", "*", "self", ".", "num_classes", "*", "self", ".", "num_classes", ")", "\n", "\n", "# instance-instance loss", "\n", "\n", "loss_ins", "=", "0.", "\n", "for", "i", "in", "range", "(", "v_ins", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "sim_instance", "=", "torch", ".", "exp", "(", "self", ".", "sim", "(", "v_ins", ",", "v_ins", "[", "i", "]", ")", ")", "\n", "pos_ins", "=", "sim_instance", "[", "i", "]", "\n", "neg_ins", "=", "(", "sim_instance", ".", "sum", "(", "0", ")", "-", "pos_ins", ")", ".", "sum", "(", "0", ")", "\n", "loss_ins", "+=", "-", "torch", ".", "log", "(", "pos_ins", "/", "(", "pos_ins", "+", "neg_ins", ")", ")", ".", "sum", "(", ")", "\n", "", "loss_ins", "=", "loss_ins", "/", "(", "num", "*", "self", ".", "num_classes", "*", "num", "*", "self", ".", "num_classes", ")", "\n", "loss", "=", "loss", "+", "loss_ins", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.train_proto": [[321, 346], ["model.eval", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "range", "openprompt.utils.logging.logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "prototypical_verbalizer.ProtoVerbalizer.head", "prototypical_verbalizer.ProtoVerbalizer.optimizer.zero_grad", "prototypical_verbalizer.ProtoVerbalizer.pcl_loss", "prototypical_verbalizer.ProtoVerbalizer.backward", "prototypical_verbalizer.ProtoVerbalizer.optimizer.step", "range", "batch.to().to_dict.to().to_dict.to().to_dict", "model.prompt_model", "prototypical_verbalizer.ProtoVerbalizer.gather_outputs", "model.extract_at_mask", "range", "len", "embeds[].append", "batch.to().to_dict.to().to_dict.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prototypical_verbalizer.ProtoVerbalizer.pcl_loss", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.gather_outputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForClassification.extract_at_mask", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "train_proto", "(", "self", ",", "model", ",", "dataloader", ",", "device", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "embeds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_classes", ")", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "                ", "batch", "=", "batch", ".", "to", "(", "\"cuda:{}\"", ".", "format", "(", "device", ")", ")", ".", "to_dict", "(", ")", "\n", "outputs", "=", "model", ".", "prompt_model", "(", "batch", ")", "\n", "hidden", ",", "_", "=", "self", ".", "gather_outputs", "(", "outputs", ")", "\n", "outputs_at_mask", "=", "model", ".", "extract_at_mask", "(", "hidden", ",", "batch", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "outputs_at_mask", ")", ")", ":", "\n", "                    ", "label", "=", "batch", "[", "'label'", "]", "[", "j", "]", "\n", "embeds", "[", "label", "]", ".", "append", "(", "outputs_at_mask", "[", "j", "]", ")", "\n", "", "", "", "embeds", "=", "[", "torch", ".", "stack", "(", "e", ")", "for", "e", "in", "embeds", "]", "\n", "embeds", "=", "torch", ".", "stack", "(", "embeds", ")", "\n", "\n", "instance_mean", "=", "embeds", ".", "mean", "(", "1", ")", "\n", "loss", "=", "0.", "\n", "for", "epoch", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "            ", "x", "=", "self", ".", "head", "(", "embeds", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "pcl_loss", "(", "x", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Total epoch: {}. ProtoVerb loss: {}\"", ".", "format", "(", "self", ".", "epochs", ",", "loss", ")", ")", "\n", "self", ".", "trained", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_template.ManualTemplate.__init__": [[22, 30], ["openprompt.Template.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "text", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "\n", "placeholder_mapping", "=", "placeholder_mapping", ")", "\n", "self", ".", "text", "=", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_template.ManualTemplate.on_text_set": [[31, 39], ["manual_template.ManualTemplate.parse_text"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.parse_text"], ["", "def", "on_text_set", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        when template text was set\n\n        1. parse text\n        \"\"\"", "\n", "\n", "self", ".", "text", "=", "self", ".", "parse_text", "(", "self", ".", "text", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.LMBFFTemplateGenerationTemplate.__init__": [[34, 44], ["openprompt.prompts.ManualTemplate.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "T5Tokenizer", ",", "\n", "verbalizer", ":", "ManualVerbalizer", ",", "\n", "text", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "\n", "text", "=", "text", ",", "\n", "placeholder_mapping", "=", "placeholder_mapping", ")", "\n", "self", ".", "verbalizer", "=", "verbalizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.LMBFFTemplateGenerationTemplate.wrap_one_example": [[45, 50], ["[].strip", "super().wrap_one_example"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.wrap_one_example"], ["", "def", "wrap_one_example", "(", "self", ",", "\n", "example", ":", "InputExample", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "example", ".", "meta", "[", "'labelword'", "]", "=", "self", ".", "verbalizer", ".", "label_words", "[", "example", ".", "label", "]", "[", "0", "]", ".", "strip", "(", ")", "\n", "wrapped_example", "=", "super", "(", ")", ".", "wrap_one_example", "(", "example", ")", "\n", "return", "wrapped_example", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.__init__": [[64, 92], ["prompt_generator.TemplateGenerator.tokenizer.convert_tokens_to_ids"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "tokenizer_wrapper", ":", "Tokenizer", ",", "\n", "verbalizer", ":", "Verbalizer", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "20", ",", "\n", "target_number", ":", "Optional", "[", "int", "]", "=", "2", ",", "\n", "beam_width", ":", "Optional", "[", "int", "]", "=", "100", ",", "\n", "length_limit", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "forbidden_word_ids", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "]", ",", "\n", "config", ":", "CfgNode", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "tokenizer_wrapper", "=", "tokenizer_wrapper", "\n", "self", ".", "verbalizer", "=", "verbalizer", "\n", "self", ".", "target_number", "=", "target_number", "# number of parts to generate in one sample", "\n", "self", ".", "beam_width", "=", "beam_width", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "length_limit", "=", "length_limit", "\n", "self", ".", "probs_buffer", ",", "self", ".", "labels_buffer", "=", "None", ",", "None", "\n", "\n", "# Forbid single space token, \"....\", and \"..........\", and some other tokens based on vocab", "\n", "self", ".", "forbidden_word_ids", "=", "forbidden_word_ids", "\n", "self", ".", "sent_end_id", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "'.'", ")", "\n", "\n", "self", ".", "input_ids_buffer", ",", "self", ".", "attention_mask_buffer", ",", "self", ".", "labels_buffer", "=", "None", ",", "None", ",", "None", "\n", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.device": [[93, 102], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "r\"\"\"\n        return the device of the model\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "DataParallel", ")", ":", "\n", "            ", "return", "self", ".", "model", ".", "module", ".", "device", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "model", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator._register_buffer": [[103, 112], ["data.input_ids.detach", "data.attention_mask.detach", "data.label.detach", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "data.input_ids.detach", "data.attention_mask.detach", "data.label.detach"], "methods", ["None"], ["", "", "def", "_register_buffer", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "input_ids_buffer", "is", "None", ":", "\n", "            ", "self", ".", "input_ids_buffer", "=", "data", ".", "input_ids", ".", "detach", "(", ")", "\n", "self", ".", "attention_mask_buffer", "=", "data", ".", "attention_mask", ".", "detach", "(", ")", "\n", "self", ".", "labels_buffer", "=", "data", ".", "label", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_ids_buffer", "=", "torch", ".", "vstack", "(", "[", "self", ".", "input_ids_buffer", ",", "data", ".", "input_ids", ".", "detach", "(", ")", "]", ")", "\n", "self", ".", "attention_mask_buffer", "=", "torch", ".", "vstack", "(", "[", "self", ".", "attention_mask_buffer", ",", "data", ".", "attention_mask", ".", "detach", "(", ")", "]", ")", "\n", "self", ".", "labels_buffer", "=", "torch", ".", "hstack", "(", "[", "self", ".", "labels_buffer", ",", "data", ".", "label", ".", "detach", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.get_part_token_id": [[113, 123], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "get_part_token_id", "(", "self", ",", "part_id", ":", "int", ")", "->", "int", ":", "\n", "        ", "r\"\"\"\n        Get the start token id for the current part. It should be specified according to the specific model type. For T5 model, for example, the start token for `part_id=0` is `<extra_id_0>`, this method should return the corresponding token_id.\n        Args:\n            part_id (:obj:`int`): The current part id (starts with 0).\n        Returns:\n            token_id (:obj:`int`): The corresponding start token_id.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.convert_template": [[124, 158], ["print", "output.append", "len", "output.append", "d.get", "prompt_generator.TemplateGenerator.tokenizer.convert_tokens_to_string", "output.append", "d.get", "output.append", "len", "d.get", "d.pop", "d.get", "json.dumps"], "methods", ["None"], ["", "def", "convert_template", "(", "self", ",", "generated_template", ":", "List", "[", "str", "]", ",", "original_template", ":", "List", "[", "Dict", "]", ")", "->", "str", ":", "\n", "        ", "r\"\"\"\n        Given original template used for template generation,convert the generated template into a standard template for downstream prompt model, return a ``str``\n        Example:\n        generated_template: ['<extra_id_0>', 'it', 'is', '<extra_id_1>', 'one', '</s>']\n        original_template: [{'add_prefix_space': '', 'placeholder': 'text_a'}, {'add_prefix_space': ' ', 'mask': None}, {'add_prefix_space': ' ', 'meta': 'labelword'}, {'add_prefix_space': ' ', 'mask': None}, {'add_prefix_space': '', 'text': '.'}]\n        return: \"{'placeholder':'text_a'} it is {\"mask\"} one.\"\n        \"\"\"", "\n", "i", "=", "0", "\n", "part_id", "=", "0", "\n", "while", "generated_template", "[", "i", "]", "!=", "self", ".", "tokenizer", ".", "additional_special_tokens", "[", "part_id", "]", "and", "i", "<", "len", "(", "generated_template", ")", "-", "1", ":", "\n", "            ", "i", "+=", "1", "\n", "", "assert", "generated_template", "[", "i", "]", "==", "self", ".", "tokenizer", ".", "additional_special_tokens", "[", "part_id", "]", ",", "print", "(", "'invalid generated_template {}, missing token {}'", ".", "format", "(", "generated_template", ",", "self", ".", "tokenizer", ".", "additional_special_tokens", "[", "part_id", "]", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "output", "=", "[", "]", "\n", "for", "d", "in", "original_template", ":", "\n", "            ", "if", "'mask'", "in", "d", ":", "\n", "                ", "j", "=", "i", "+", "1", "\n", "part_id", "+=", "1", "\n", "while", "generated_template", "[", "j", "]", "!=", "self", ".", "tokenizer", ".", "additional_special_tokens", "[", "part_id", "]", "and", "j", "<", "len", "(", "generated_template", ")", "-", "1", ":", "\n", "                    ", "j", "+=", "1", "\n", "", "output", ".", "append", "(", "d", ".", "get", "(", "'add_prefix_space'", ",", "''", ")", "+", "self", ".", "tokenizer", ".", "convert_tokens_to_string", "(", "generated_template", "[", "i", ":", "j", "]", ")", ")", "\n", "i", "=", "j", "+", "1", "\n", "", "elif", "'meta'", "in", "d", "and", "d", "[", "'meta'", "]", "==", "'labelword'", ":", "\n", "                ", "output", ".", "append", "(", "d", ".", "get", "(", "'add_prefix_space'", ",", "''", ")", "+", "'{\"mask\"}'", ")", "\n", "", "elif", "'text'", "in", "d", ":", "\n", "                ", "output", ".", "append", "(", "d", ".", "get", "(", "'add_prefix_space'", ",", "''", ")", "+", "d", "[", "'text'", "]", ")", "\n", "", "else", ":", "\n", "                ", "prefix", "=", "d", ".", "get", "(", "'add_prefix_space'", ",", "''", ")", "\n", "if", "'add_prefix_space'", "in", "d", ":", "\n", "                    ", "d", ".", "pop", "(", "'add_prefix_space'", ")", "\n", "", "output", ".", "append", "(", "prefix", "+", "json", ".", "dumps", "(", "d", ")", ")", "\n", "", "", "return", "''", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator._get_templates": [[160, 246], ["torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "tqdm.tqdm.tqdm", "isinstance", "range", "new_current_output.sort", "prompt_generator.TemplateGenerator.tokenizer.convert_ids_to_tokens", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "aggr_output.mean.mean.mean", "torch.logsumexp().item", "torch.logsumexp().item", "torch.logsumexp().item", "torch.logsumexp().item", "list", "list.sort", "len", "new_current_output.append", "input_ids.size", "min", "range", "decoder_input_ids.new_zeros", "input_ids.size", "input_ids.size", "input_ids.size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "aggr_output.mean.mean.append", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "decoder_input_ids.size", "new_current_output.append", "[].item", "prompt_generator.TemplateGenerator.get_part_token_id", "len", "prompt_generator.TemplateGenerator.model", "decoder_input_ids.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.T5TemplateGenerator.get_part_token_id", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "_get_templates", "(", "self", ")", ":", "\n", "        ", "inner_model", "=", "self", ".", "model", ".", "module", "if", "isinstance", "(", "self", ".", "model", ",", "DataParallel", ")", "else", "self", ".", "model", "\n", "input_ids", "=", "self", ".", "input_ids_buffer", "\n", "attention_mask", "=", "self", ".", "attention_mask_buffer", "\n", "\n", "ori_decoder_input_ids", "=", "torch", ".", "zeros", "(", "(", "input_ids", ".", "size", "(", "0", ")", ",", "self", ".", "max_length", ")", ")", ".", "long", "(", ")", "\n", "ori_decoder_input_ids", "[", "...", ",", "0", "]", "=", "inner_model", ".", "config", ".", "decoder_start_token_id", "\n", "\n", "\n", "# decoder_input_ids: decoder inputs for next regressive generation", "\n", "# ll: log likelihood", "\n", "# output_id: which part of generated contents we are at", "\n", "# output: generated content so far", "\n", "# last_length (deprecated): how long we have generated for this part", "\n", "current_output", "=", "[", "{", "'decoder_input_ids'", ":", "ori_decoder_input_ids", ",", "'ll'", ":", "0", ",", "'output_id'", ":", "1", ",", "'output'", ":", "[", "]", ",", "'last_length'", ":", "-", "1", "}", "]", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "self", ".", "max_length", "-", "2", ")", ")", ":", "\n", "            ", "new_current_output", "=", "[", "]", "\n", "for", "item", "in", "current_output", ":", "\n", "                ", "if", "item", "[", "'output_id'", "]", ">", "self", ".", "target_number", ":", "\n", "# Enough contents", "\n", "                    ", "new_current_output", ".", "append", "(", "item", ")", "\n", "continue", "\n", "", "decoder_input_ids", "=", "item", "[", "'decoder_input_ids'", "]", "\n", "\n", "# Forward", "\n", "batch_size", "=", "32", "\n", "turn", "=", "input_ids", ".", "size", "(", "0", ")", "//", "batch_size", "\n", "if", "input_ids", ".", "size", "(", "0", ")", "%", "batch_size", "!=", "0", ":", "\n", "                    ", "turn", "+=", "1", "\n", "", "aggr_output", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "turn", ")", ":", "\n", "                    ", "start", "=", "t", "*", "batch_size", "\n", "end", "=", "min", "(", "(", "t", "+", "1", ")", "*", "batch_size", ",", "input_ids", ".", "size", "(", "0", ")", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "aggr_output", ".", "append", "(", "self", ".", "model", "(", "input_ids", "[", "start", ":", "end", "]", ",", "attention_mask", "=", "attention_mask", "[", "start", ":", "end", "]", ",", "decoder_input_ids", "=", "decoder_input_ids", ".", "to", "(", "input_ids", ".", "device", ")", "[", "start", ":", "end", "]", ")", "[", "0", "]", ")", "\n", "", "", "aggr_output", "=", "torch", ".", "cat", "(", "aggr_output", ",", "0", ")", "\n", "\n", "# Gather results across all input sentences, and sort generated tokens by log likelihood", "\n", "aggr_output", "=", "aggr_output", ".", "mean", "(", "0", ")", "\n", "log_denominator", "=", "torch", ".", "logsumexp", "(", "aggr_output", "[", "i", "]", ",", "-", "1", ")", ".", "item", "(", ")", "\n", "ids", "=", "list", "(", "range", "(", "inner_model", ".", "config", ".", "vocab_size", ")", ")", "\n", "ids", ".", "sort", "(", "key", "=", "lambda", "x", ":", "aggr_output", "[", "i", "]", "[", "x", "]", ".", "item", "(", ")", ",", "reverse", "=", "True", ")", "\n", "ids", "=", "ids", "[", ":", "self", ".", "beam_width", "+", "3", "]", "\n", "\n", "for", "word_id", "in", "ids", ":", "\n", "                    ", "output_id", "=", "item", "[", "'output_id'", "]", "\n", "\n", "if", "word_id", "==", "self", ".", "get_part_token_id", "(", "output_id", ")", "or", "word_id", "==", "self", ".", "tokenizer", ".", "eos_token_id", ":", "\n", "# Finish one part", "\n", "                        ", "if", "self", ".", "length_limit", "is", "not", "None", "and", "item", "[", "'last_length'", "]", "<", "self", ".", "length_limit", "[", "output_id", "-", "1", "]", ":", "\n", "                            ", "check", "=", "False", "\n", "", "else", ":", "\n", "                            ", "check", "=", "True", "\n", "", "output_id", "+=", "1", "\n", "last_length", "=", "0", "\n", "", "else", ":", "\n", "                        ", "last_length", "=", "item", "[", "'last_length'", "]", "+", "1", "\n", "check", "=", "True", "\n", "\n", "", "output_text", "=", "item", "[", "'output'", "]", "+", "[", "word_id", "]", "\n", "ll", "=", "item", "[", "'ll'", "]", "+", "aggr_output", "[", "i", "]", "[", "word_id", "]", "-", "log_denominator", "\n", "new_decoder_input_ids", "=", "decoder_input_ids", ".", "new_zeros", "(", "decoder_input_ids", ".", "size", "(", ")", ")", "\n", "new_decoder_input_ids", "[", ":", "]", "=", "decoder_input_ids", "\n", "new_decoder_input_ids", "[", "...", ",", "i", "+", "1", "]", "=", "word_id", "\n", "\n", "if", "word_id", "in", "self", ".", "forbidden_word_ids", ":", "\n", "                        ", "check", "=", "False", "\n", "\n", "# Forbid continuous \".\"", "\n", "", "if", "len", "(", "output_text", ")", ">", "1", "and", "output_text", "[", "-", "2", "]", "==", "self", ".", "sent_end_id", "and", "output_text", "[", "-", "1", "]", "==", "self", ".", "sent_end_id", ":", "\n", "                        ", "check", "=", "False", "\n", "\n", "", "if", "check", ":", "\n", "# Add new results to beam search pool", "\n", "                        ", "new_item", "=", "{", "'decoder_input_ids'", ":", "new_decoder_input_ids", ",", "'ll'", ":", "ll", ",", "'output_id'", ":", "output_id", ",", "'output'", ":", "output_text", ",", "'last_length'", ":", "last_length", "}", "\n", "new_current_output", ".", "append", "(", "new_item", ")", "\n", "\n", "", "", "", "if", "len", "(", "new_current_output", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "new_current_output", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "'ll'", "]", ",", "reverse", "=", "True", ")", "\n", "new_current_output", "=", "new_current_output", "[", ":", "self", ".", "beam_width", "]", "\n", "current_output", "=", "new_current_output", "\n", "\n", "", "return", "[", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "item", "[", "'output'", "]", ")", "for", "item", "in", "current_output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator._show_template": [[247, 249], ["utils.logger.info"], "methods", ["None"], ["", "def", "_show_template", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Templates are \\n{}\"", ".", "format", "(", "'\\n'", ".", "join", "(", "self", ".", "templates_text", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.from_config": [[251, 263], ["cls", "utils.signature", "config.convert_cfg_to_dict"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.convert_cfg_to_dict"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ":", "CfgNode", ",", "**", "kwargs", ",", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n            template_generator (:obj:`TemplateGenerator`)\n        \"\"\"", "\n", "init_args", "=", "signature", "(", "cls", ".", "__init__", ")", ".", "args", "\n", "_init_dict", "=", "{", "**", "convert_cfg_to_dict", "(", "config", ")", ",", "**", "kwargs", "}", "\n", "init_dict", "=", "{", "key", ":", "_init_dict", "[", "key", "]", "for", "key", "in", "_init_dict", "if", "key", "in", "init_args", "}", "\n", "init_dict", "[", "'config'", "]", "=", "config", "\n", "template_generator", "=", "cls", "(", "**", "init_dict", ")", "\n", "return", "template_generator", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.release_memory": [[264, 266], ["prompt_generator.TemplateGenerator.model.cpu"], "methods", ["None"], ["", "def", "release_memory", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "model", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.generate": [[267, 288], ["LMBFFTemplateGenerationTemplate.from_config", "openprompt.pipeline_base.PromptDataLoader", "prompt_generator.TemplateGenerator.model.eval", "data.to.to.to", "prompt_generator.TemplateGenerator._register_buffer", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "prompt_generator.TemplateGenerator._get_templates", "prompt_generator.TemplateGenerator._show_template", "len", "prompt_generator.TemplateGenerator.convert_template"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.from_config", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator._register_buffer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator._get_templates", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator._show_template", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.TemplateGenerator.convert_template"], ["", "def", "generate", "(", "self", ",", "dataset", ":", "List", "[", "InputExample", "]", ")", ":", "\n", "        ", "r\"\"\"\n        Args:\n            dataset (:obj:`List[InputExample]`): The dataset based on which template it to be generated.\n        Returns:\n            template_text (:obj:`List[str]`): The generated template text\n        \"\"\"", "\n", "template_for_auto_t", "=", "LMBFFTemplateGenerationTemplate", ".", "from_config", "(", "config", "=", "self", ".", "config", ".", "template", ",", "tokenizer", "=", "self", ".", "tokenizer", ",", "verbalizer", "=", "self", ".", "verbalizer", ")", "\n", "\n", "dataloader", "=", "PromptDataLoader", "(", "dataset", ",", "template_for_auto_t", ",", "tokenizer", "=", "self", ".", "tokenizer", ",", "tokenizer_wrapper_class", "=", "self", ".", "tokenizer_wrapper", ",", "batch_size", "=", "len", "(", "dataset", ")", ",", "decoder_max_length", "=", "128", ")", "# register all data at once", "\n", "for", "data", "in", "dataloader", ":", "\n", "            ", "data", "=", "data", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "_register_buffer", "(", "data", ")", "\n", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "templates_text", "=", "self", ".", "_get_templates", "(", ")", "# List[str]", "\n", "original_template", "=", "template_for_auto_t", ".", "text", "\n", "self", ".", "templates_text", "=", "[", "self", ".", "convert_template", "(", "template_text", ",", "original_template", ")", "for", "template_text", "in", "self", ".", "templates_text", "]", "\n", "self", ".", "_show_template", "(", ")", "\n", "", "return", "self", ".", "templates_text", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.T5TemplateGenerator.__init__": [[293, 314], ["prompt_generator.TemplateGenerator.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "T5ForConditionalGeneration", ",", "\n", "tokenizer", ":", "T5Tokenizer", ",", "\n", "tokenizer_wrapper", ":", "Tokenizer", ",", "\n", "verbalizer", ":", "Verbalizer", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "20", ",", "\n", "target_number", ":", "Optional", "[", "int", "]", "=", "2", ",", "\n", "beam_width", ":", "Optional", "[", "int", "]", "=", "100", ",", "\n", "length_limit", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "forbidden_word_ids", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "3", ",", "19794", ",", "22354", "]", ",", "\n", "config", ":", "CfgNode", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "tokenizer_wrapper", "=", "tokenizer_wrapper", ",", "\n", "verbalizer", "=", "verbalizer", ",", "\n", "max_length", "=", "max_length", ",", "\n", "target_number", "=", "target_number", ",", "\n", "beam_width", "=", "beam_width", ",", "\n", "length_limit", "=", "length_limit", ",", "\n", "forbidden_word_ids", "=", "forbidden_word_ids", ",", "\n", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.T5TemplateGenerator.get_part_token_id": [[315, 317], ["None"], "methods", ["None"], ["", "def", "get_part_token_id", "(", "self", ",", "part_id", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "additional_special_tokens_ids", "[", "part_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.__init__": [[339, 349], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "candidate_num", ":", "Optional", "[", "int", "]", "=", "100", ",", "\n", "label_word_num_per_class", ":", "Optional", "[", "int", "]", "=", "100", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "candidate_num", "=", "candidate_num", "\n", "self", ".", "label_word_num_per_class", "=", "label_word_num_per_class", "\n", "self", ".", "probs_buffer", ",", "self", ".", "labels_buffer", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.register_buffer": [[350, 364], ["prompt_generator.VerbalizerGenerator.model.eval", "torch.softmax", "torch.softmax", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.softmax.detach", "data.label.detach", "torch.vstack", "torch.vstack", "torch.vstack", "torch.vstack", "torch.hstack", "torch.hstack", "torch.hstack", "torch.hstack", "isinstance", "utils.signature", "prompt_generator.VerbalizerGenerator.model.forward", "data.label.detach"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptForGeneration.forward"], ["", "def", "register_buffer", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inner_model", "=", "self", ".", "model", ".", "module", "if", "isinstance", "(", "self", ".", "model", ",", "DataParallel", ")", "else", "self", ".", "model", "\n", "forward_keys", "=", "signature", "(", "inner_model", ".", "forward", ")", ".", "args", "\n", "input_batch", "=", "{", "key", ":", "data", "[", "key", "]", "for", "key", "in", "data", "if", "key", "in", "forward_keys", "}", "\n", "logits", "=", "self", ".", "model", ".", "forward", "(", "**", "input_batch", ")", ".", "logits", "[", "data", "[", "'loss_ids'", "]", "==", "1", "]", "\n", "", "logits", "=", "F", ".", "softmax", "(", "logits", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "probs_buffer", "is", "None", ":", "\n", "            ", "self", ".", "probs_buffer", "=", "logits", "\n", "self", ".", "labels_buffer", "=", "data", ".", "label", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "probs_buffer", "=", "torch", ".", "vstack", "(", "[", "self", ".", "probs_buffer", ",", "logits", "]", ")", "\n", "self", ".", "labels_buffer", "=", "torch", ".", "hstack", "(", "[", "self", ".", "labels_buffer", ",", "data", ".", "label", ".", "detach", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.post_process": [[365, 383], ["isinstance", "isinstance", "word.lstrip", "isinstance", "RuntimeError", "type"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "post_process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "r\"\"\"\n        Post-processing for generated labrl word.\n\n        Args:\n            word (:obj:`str`): The original word token.\n\n        Returns:\n            processed_word (:obj:`str`): The post-processed token.\n        \"\"\"", "\n", "inner_model", "=", "self", ".", "model", ".", "module", "if", "isinstance", "(", "self", ".", "model", ",", "DataParallel", ")", "else", "self", ".", "model", "\n", "if", "isinstance", "(", "inner_model", ",", "RobertaForMaskedLM", ")", ":", "\n", "            ", "return", "word", ".", "lstrip", "(", "'\u0120'", ")", "\n", "", "elif", "isinstance", "(", "inner_model", ",", "BertForMaskedLM", ")", ":", "\n", "            ", "return", "word", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"{} is not supported yet\"", ".", "format", "(", "type", "(", "inner_model", ")", ")", ")", "# TODO add more model", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.invalid_label_word": [[384, 401], ["isinstance", "isinstance", "isinstance", "word.startswith", "RuntimeError", "type"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "invalid_label_word", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "r\"\"\"\n        Decide whether the generated token is a valid label word. Heuristic strategy can be implemented here, e.g. requiring that a label word must be the start token of a word.\n\n        Args:\n            word (:obj:`str`): The token.\n        Returns:\n            is_invalid (:obj:`bool`): `True` if it cannot be a label word.\n        \"\"\"", "\n", "inner_model", "=", "self", ".", "model", ".", "module", "if", "isinstance", "(", "self", ".", "model", ",", "DataParallel", ")", "else", "self", ".", "model", "\n", "if", "isinstance", "(", "inner_model", ",", "RobertaForMaskedLM", ")", ":", "\n", "            ", "return", "(", "not", "word", ".", "startswith", "(", "'\u0120'", ")", ")", "\n", "", "elif", "isinstance", "(", "inner_model", ",", "BertForMaskedLM", ")", ":", "\n", "            ", "return", "False", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"{} is not supported yet\"", ".", "format", "(", "type", "(", "inner_model", ")", ")", ")", "# TODO", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._show_verbalizer": [[402, 404], ["utils.logger.info"], "methods", ["None"], ["", "", "def", "_show_verbalizer", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Verbalizer is {}\"", ".", "format", "(", "self", ".", "label_words", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._find_verbalizer": [[406, 411], ["utils.logger.info", "prompt_generator.VerbalizerGenerator._get_top_words", "prompt_generator.VerbalizerGenerator._get_top_group"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._get_top_words", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._get_top_group"], ["", "def", "_find_verbalizer", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Finding verbalizer ...\"", ")", "\n", "label_words", "=", "self", ".", "_get_top_words", "(", ")", "\n", "label_words", "=", "self", ".", "_get_top_group", "(", "candidates", "=", "label_words", ")", "\n", "return", "label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._eval_group": [[412, 417], ["torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["None"], ["", "def", "_eval_group", "(", "self", ",", "group", ")", ":", "\n", "        ", "label_logits", "=", "self", ".", "probs_buffer", "[", ":", ",", "torch", ".", "tensor", "(", "group", ")", "]", "\n", "preds", "=", "torch", ".", "argmax", "(", "label_logits", ",", "axis", "=", "-", "1", ")", "\n", "correct", "=", "torch", ".", "sum", "(", "preds", "==", "self", ".", "labels_buffer", ")", "\n", "return", "(", "correct", "/", "len", "(", "self", ".", "labels_buffer", ")", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._get_top_group": [[418, 426], ["list", "list", "itertools.product", "map", "numpy.argsort", "numpy.array"], "methods", ["None"], ["", "def", "_get_top_group", "(", "self", ",", "candidates", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "groups", "=", "list", "(", "itertools", ".", "product", "(", "*", "candidates", ")", ")", "\n", "group_scores", "=", "list", "(", "map", "(", "self", ".", "_eval_group", ",", "groups", ")", ")", "\n", "\n", "# Take top-n.", "\n", "best_idx", "=", "np", ".", "argsort", "(", "-", "np", ".", "array", "(", "group_scores", ")", ")", "[", ":", "self", ".", "candidate_num", "]", "\n", "best_groups", "=", "[", "groups", "[", "i", "]", "for", "i", "in", "best_idx", "]", "\n", "return", "best_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._get_top_words": [[427, 439], ["torch.unique", "torch.unique", "torch.unique", "torch.unique", "prompt_generator.VerbalizerGenerator.probs_buffer[].mean().cpu().numpy", "numpy.argsort", "label_words_ids.append", "prompt_generator.VerbalizerGenerator.invalid_label_word", "kept.append", "prompt_generator.VerbalizerGenerator.probs_buffer[].mean().cpu", "prompt_generator.VerbalizerGenerator.tokenizer.convert_ids_to_tokens", "prompt_generator.VerbalizerGenerator.probs_buffer[].mean"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.RobertaVerbalizerGenerator.invalid_label_word"], ["", "def", "_get_top_words", "(", "self", ")", ":", "\n", "        ", "label_words_ids", "=", "[", "]", "\n", "for", "label_id", "in", "torch", ".", "unique", "(", "self", ".", "labels_buffer", ")", ":", "\n", "            ", "scores", "=", "self", ".", "probs_buffer", "[", "self", ".", "labels_buffer", "==", "label_id", "]", ".", "mean", "(", "axis", "=", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "kept", "=", "[", "]", "\n", "for", "i", "in", "np", ".", "argsort", "(", "-", "scores", ")", ":", "\n", "                ", "word", "=", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "[", "i", "]", ")", "[", "0", "]", "\n", "if", "self", ".", "invalid_label_word", "(", "word", ")", ":", "\n", "                    ", "continue", "\n", "", "kept", ".", "append", "(", "i", ")", "\n", "", "label_words_ids", ".", "append", "(", "kept", "[", ":", "self", ".", "label_word_num_per_class", "]", ")", "\n", "", "return", "label_words_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.from_config": [[440, 451], ["cls", "utils.signature", "config.convert_cfg_to_dict"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.signature", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.config.convert_cfg_to_dict"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ":", "CfgNode", ",", "**", "kwargs", ",", ")", ":", "\n", "        ", "r\"\"\"\n        Returns:\n            verbalizer_generator (:obj:`VerbalizerGenerator`)\n        \"\"\"", "\n", "init_args", "=", "signature", "(", "cls", ".", "__init__", ")", ".", "args", "\n", "_init_dict", "=", "{", "**", "convert_cfg_to_dict", "(", "config", ")", ",", "**", "kwargs", "}", "\n", "init_dict", "=", "{", "key", ":", "_init_dict", "[", "key", "]", "for", "key", "in", "_init_dict", "if", "key", "in", "init_args", "}", "\n", "verbalizer_generator", "=", "cls", "(", "**", "init_dict", ")", "\n", "return", "verbalizer_generator", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.release_memory": [[452, 454], ["prompt_generator.VerbalizerGenerator.model.cpu"], "methods", ["None"], ["", "def", "release_memory", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "model", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate": [[455, 467], ["prompt_generator.VerbalizerGenerator._find_verbalizer", "prompt_generator.VerbalizerGenerator._show_verbalizer", "prompt_generator.VerbalizerGenerator.post_process", "prompt_generator.VerbalizerGenerator.tokenizer.convert_ids_to_tokens"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._find_verbalizer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator._show_verbalizer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.RobertaVerbalizerGenerator.post_process"], ["", "def", "generate", "(", "self", ")", ":", "\n", "        ", "r\"\"\"\n        Generate label words.\n\n        Returns:\n            label_words (:obj:`List[List[str]]`): A list of generated label word.\n        \"\"\"", "\n", "\n", "self", ".", "label_words_ids", "=", "self", ".", "_find_verbalizer", "(", ")", "\n", "self", ".", "label_words", "=", "[", "[", "self", ".", "post_process", "(", "word", ")", "for", "word", "in", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "i", ")", "]", "for", "i", "in", "self", ".", "label_words_ids", "]", "\n", "self", ".", "_show_verbalizer", "(", ")", "\n", "return", "self", ".", "label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.RobertaVerbalizerGenerator.__init__": [[469, 479], ["prompt_generator.VerbalizerGenerator.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ":", "RobertaForMaskedLM", ",", "\n", "tokenizer", ":", "RobertaTokenizer", ",", "\n", "candidate_num", ":", "Optional", "[", "int", "]", "=", "100", ",", "\n", "label_word_num_per_class", ":", "Optional", "[", "int", "]", "=", "100", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "candidate_num", "=", "candidate_num", ",", "\n", "label_word_num_per_class", "=", "label_word_num_per_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.RobertaVerbalizerGenerator.invalid_label_word": [[480, 482], ["word.startswith"], "methods", ["None"], ["", "def", "invalid_label_word", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "return", "(", "not", "word", ".", "startswith", "(", "'\u0120'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.RobertaVerbalizerGenerator.post_process": [[483, 485], ["word.lstrip"], "methods", ["None"], ["", "def", "post_process", "(", "self", ",", "word", ":", "str", ")", ":", "\n", "        ", "return", "word", ".", "lstrip", "(", "'\u0120'", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.__init__": [[33, 77], ["openprompt.Verbalizer.__init__", "openprompt.utils.logging.logger.info", "copy.deepcopy", "getattr", "isinstance", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "setattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "last_layer_full_name.append", "getattr", "isinstance", "RuntimeError", "model.named_children", "getattr", "getattr.named_children"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Optional", "[", "PreTrainedTokenizer", "]", ",", "\n", "model", ":", "Optional", "[", "PreTrainedModel", "]", ",", "\n", "classes", ":", "Optional", "[", "List", "]", "=", "None", ",", "\n", "num_classes", ":", "Optional", "[", "Sequence", "[", "str", "]", "]", "=", "None", ",", "\n", "label_words", ":", "Optional", "[", "Union", "[", "Sequence", "[", "str", "]", ",", "Mapping", "[", "str", ",", "str", "]", "]", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "\" \"", ",", "\n", "multi_token_handler", ":", "Optional", "[", "str", "]", "=", "\"first\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "num_classes", "=", "num_classes", ",", "classes", "=", "classes", ")", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "multi_token_handler", "=", "multi_token_handler", "\n", "\n", "head_name", "=", "[", "n", "for", "n", ",", "c", "in", "model", ".", "named_children", "(", ")", "]", "[", "-", "1", "]", "\n", "logger", ".", "info", "(", "f\"The LM head named {head_name} was retrieved.\"", ")", "\n", "self", ".", "head", "=", "copy", ".", "deepcopy", "(", "getattr", "(", "model", ",", "head_name", ")", ")", "\n", "max_loop", "=", "5", "\n", "if", "not", "isinstance", "(", "self", ".", "head", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "            ", "module", "=", "self", ".", "head", "\n", "found", "=", "False", "\n", "last_layer_full_name", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "max_loop", ")", ":", "\n", "                ", "last_layer_name", "=", "[", "n", "for", "n", ",", "c", "in", "module", ".", "named_children", "(", ")", "]", "[", "-", "1", "]", "\n", "last_layer_full_name", ".", "append", "(", "last_layer_name", ")", "\n", "parent_module", "=", "module", "\n", "module", "=", "getattr", "(", "module", ",", "last_layer_name", ")", "\n", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "                    ", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "                ", "raise", "RuntimeError", "(", "f\"Can't not retrieve a linear layer in {max_loop} loop from the plm.\"", ")", "\n", "", "self", ".", "original_head_last_layer", "=", "module", ".", "weight", ".", "data", "\n", "self", ".", "hidden_dims", "=", "self", ".", "original_head_last_layer", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "head_last_layer_full_name", "=", "\".\"", ".", "join", "(", "last_layer_full_name", ")", "\n", "self", ".", "head_last_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "hidden_dims", ",", "self", ".", "num_classes", ",", "bias", "=", "False", ")", "\n", "setattr", "(", "parent_module", ",", "last_layer_name", ",", "self", ".", "head_last_layer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hidden_dims", "=", "self", ".", "head", ".", "weight", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "original_head_last_layer", "=", "getattr", "(", "model", ",", "head_name", ")", ".", "weight", ".", "data", "\n", "self", ".", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "hidden_dims", ",", "self", ".", "num_classes", ",", "bias", "=", "False", ")", "\n", "\n", "\n", "", "if", "label_words", "is", "not", "None", ":", "# use label words as an initialization", "\n", "            ", "self", ".", "label_words", "=", "label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.group_parameters_1": [[81, 92], ["isinstance", "soft_verbalizer.SoftVerbalizer.head.named_parameters"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "group_parameters_1", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"Include the parameters of head's layer but not the last layer\n        In soft verbalizer, note that some heads may contain modules\n        other than the final projection layer. The parameters of these part should be\n        optimized (or freezed) together with the plm.\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "head", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "p", "for", "n", ",", "p", "in", "self", ".", "head", ".", "named_parameters", "(", ")", "if", "self", ".", "head_last_layer_full_name", "not", "in", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.group_parameters_2": [[93, 101], ["isinstance", "soft_verbalizer.SoftVerbalizer.head.named_parameters", "soft_verbalizer.SoftVerbalizer.head.named_parameters"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "group_parameters_2", "(", "self", ",", ")", ":", "\n", "        ", "r\"\"\"Include the last layer's parameters\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "head", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "            ", "return", "[", "p", "for", "n", ",", "p", "in", "self", ".", "head", ".", "named_parameters", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "p", "for", "n", ",", "p", "in", "self", ".", "head", ".", "named_parameters", "(", ")", "if", "self", ".", "head_last_layer_full_name", "in", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.on_label_words_set": [[102, 105], ["soft_verbalizer.SoftVerbalizer.add_prefix", "soft_verbalizer.SoftVerbalizer.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.add_prefix", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["", "", "def", "on_label_words_set", "(", "self", ")", ":", "\n", "        ", "self", ".", "label_words", "=", "self", ".", "add_prefix", "(", "self", ".", "label_words", ",", "self", ".", "prefix", ")", "\n", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.add_prefix": [[106, 131], ["isinstance", "new_label_words.append", "word.startswith", "new_label_words_per_label.append", "new_label_words_per_label.append", "word.split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_prefix", "(", "label_words", ",", "prefix", ")", ":", "\n", "        ", "r\"\"\"Add prefix to label words. For example, if a label words is in the middle of a template,\n        the prefix should be ``' '``.\n\n        Args:\n            label_words (:obj:`Union[Sequence[str], Mapping[str, str]]`, optional): The label words that are projected by the labels.\n            prefix (:obj:`str`, optional): The prefix string of the verbalizer.\n\n        Returns:\n            :obj:`Sequence[str]`: New label words with prefix.\n        \"\"\"", "\n", "new_label_words", "=", "[", "]", "\n", "if", "isinstance", "(", "label_words", "[", "0", "]", ",", "str", ")", ":", "\n", "            ", "label_words", "=", "[", "[", "w", "]", "for", "w", "in", "label_words", "]", "#wrapped it to a list of list of label words.", "\n", "\n", "", "for", "label_words_per_label", "in", "label_words", ":", "\n", "            ", "new_label_words_per_label", "=", "[", "]", "\n", "for", "word", "in", "label_words_per_label", ":", "\n", "                ", "if", "word", ".", "startswith", "(", "\"<!>\"", ")", ":", "\n", "                    ", "new_label_words_per_label", ".", "append", "(", "word", ".", "split", "(", "\"<!>\"", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "new_label_words_per_label", ".", "append", "(", "prefix", "+", "word", ")", "\n", "", "", "new_label_words", ".", "append", "(", "new_label_words_per_label", ")", "\n", "", "return", "new_label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.generate_parameters": [[132, 170], ["max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "isinstance", "isinstance", "soft_verbalizer.SoftVerbalizer.tokenizer.encode", "words_ids.append", "soft_verbalizer.SoftVerbalizer.label_words_mask.to().unsqueeze", "init_data.sum", "soft_verbalizer.SoftVerbalizer.label_words_mask.sum", "openprompt.utils.logging.logger.warning", "len", "openprompt.utils.logging.logger.warning", "len", "len", "soft_verbalizer.SoftVerbalizer.label_words_mask.to", "soft_verbalizer.SoftVerbalizer.tokenizer.convert_ids_to_tokens", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to"], ["", "def", "generate_parameters", "(", "self", ")", "->", "List", ":", "\n", "        ", "r\"\"\"In basic manual template, the parameters are generated from label words directly.\n        In this implementation, the label_words should not be tokenized into more than one token.\n        \"\"\"", "\n", "words_ids", "=", "[", "]", "\n", "for", "word", "in", "self", ".", "label_words", ":", "\n", "            ", "if", "isinstance", "(", "word", ",", "list", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Label word for a class is a list, only use the first word.\"", ")", "\n", "", "word", "=", "word", "[", "0", "]", "\n", "word_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "word", ",", "add_special_tokens", "=", "False", ")", "\n", "if", "len", "(", "word_ids", ")", ">", "1", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Word {} is split into multiple tokens: {}. \\\n                    If this is not what you expect, try using another word for this verbalizer\"", ".", "format", "(", "word", ",", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "word_ids", ")", ")", ")", "\n", "", "words_ids", ".", "append", "(", "word_ids", ")", "\n", "\n", "", "max_len", "=", "max", "(", "[", "len", "(", "ids", ")", "for", "ids", "in", "words_ids", "]", ")", "\n", "words_ids_mask", "=", "[", "[", "1", "]", "*", "len", "(", "ids", ")", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "words_ids", "]", "\n", "words_ids", "=", "[", "ids", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "words_ids", "]", "\n", "\n", "words_ids_tensor", "=", "torch", ".", "tensor", "(", "words_ids", ")", "\n", "words_ids_mask", "=", "torch", ".", "tensor", "(", "words_ids_mask", ")", "\n", "self", ".", "label_words_ids", "=", "nn", ".", "Parameter", "(", "words_ids_tensor", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "label_words_mask", "=", "nn", ".", "Parameter", "(", "words_ids_mask", ",", "requires_grad", "=", "False", ")", "\n", "\n", "init_data", "=", "self", ".", "original_head_last_layer", "[", "self", ".", "label_words_ids", ",", ":", "]", "*", "self", ".", "label_words_mask", ".", "to", "(", "self", ".", "original_head_last_layer", ".", "dtype", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "init_data", "=", "init_data", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "label_words_mask", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "head", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "            ", "self", ".", "head", ".", "weight", ".", "data", "=", "init_data", "\n", "self", ".", "head", ".", "weight", ".", "data", ".", "requires_grad", "=", "True", "\n", "", "else", ":", "\n", "            ", "'''\n            getattr(self.head, self.head_last_layer_full_name).weight.data = init_data\n            getattr(self.head, self.head_last_layer_full_name).weight.data.requires_grad=True # To be sure\n            '''", "\n", "self", ".", "head_last_layer", ".", "weight", ".", "data", "=", "init_data", "\n", "self", ".", "head_last_layer", ".", "weight", ".", "data", ".", "requires_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.process_hiddens": [[171, 176], ["soft_verbalizer.SoftVerbalizer.head"], "methods", ["None"], ["", "", "def", "process_hiddens", "(", "self", ",", "hiddens", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"A whole framework to process the original logits over the vocabulary, which contains four steps:\n        \"\"\"", "\n", "label_logits", "=", "self", ".", "head", "(", "hiddens", ")", "\n", "return", "label_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.process_outputs": [[177, 179], ["soft_verbalizer.SoftVerbalizer.process_hiddens"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.process_hiddens"], ["", "def", "process_outputs", "(", "self", ",", "outputs", ":", "torch", ".", "Tensor", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "process_hiddens", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.soft_verbalizer.SoftVerbalizer.gather_outputs": [[180, 192], ["isinstance", "isinstance", "isinstance", "NotImplementedError", "type"], "methods", ["None"], ["", "def", "gather_outputs", "(", "self", ",", "outputs", ":", "ModelOutput", ")", ":", "\n", "        ", "if", "isinstance", "(", "outputs", ",", "Seq2SeqLMOutput", ")", ":", "\n", "            ", "ret", "=", "outputs", ".", "decoder_hidden_states", "[", "-", "1", "]", "\n", "", "elif", "isinstance", "(", "outputs", ",", "MaskedLMOutput", ")", "or", "isinstance", "(", "outputs", ",", "CausalLMOutputWithCrossAttentions", ")", ":", "\n", "            ", "ret", "=", "outputs", ".", "hidden_states", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "ret", "=", "outputs", ".", "hidden_states", "[", "-", "1", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "raise", "NotImplementedError", "(", "f\"Gather outputs method for outputs' type {type(outputs)} not implemented\"", ")", "\n", "\n", "", "", "return", "ret", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.__init__": [[38, 91], ["openprompt.Template.__init__", "model.get_input_embeddings", "isinstance", "torch.nn.Dropout", "prefix_tuning_template.PrefixTuningTemplate.generate_parameters", "prefix_tuning_template.PrefixTuningTemplate.modify_plm", "openprompt.utils.logging.logger.warning", "isinstance"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.modify_plm"], ["def", "__init__", "(", "self", ",", "\n", "model", ":", "PreTrainedModel", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "mapping_hook", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "text", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "num_token", ":", "Optional", "[", "int", "]", "=", "5", ",", "\n", "placeholder_mapping", ":", "dict", "=", "{", "'<text_a>'", ":", "'text_a'", ",", "'<text_b>'", ":", "'text_b'", "}", ",", "\n", "prefix_dropout", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "mid_dim", ":", "Optional", "[", "int", "]", "=", "512", ",", "\n", "using_encoder_past_key_values", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "using_decoder_past_key_values", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "\n", "placeholder_mapping", "=", "placeholder_mapping", ")", "\n", "raw_embedding", "=", "model", ".", "get_input_embeddings", "(", ")", "\n", "self", ".", "config", "=", "model", ".", "config", "\n", "self", ".", "mapping_hook", "=", "mapping_hook", "\n", "self", ".", "embedding_size", "=", "raw_embedding", ".", "weight", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "num_token", "=", "num_token", "\n", "\n", "self", ".", "using_encoder_past_key_values", "=", "using_encoder_past_key_values", "\n", "self", ".", "using_decoder_past_key_values", "=", "using_decoder_past_key_values", "\n", "assert", "(", "self", ".", "using_encoder_past_key_values", "or", "self", ".", "using_decoder_past_key_values", ")", ",", "\"Can't be both False.\"", "\n", "if", "not", "self", ".", "config", ".", "is_encoder_decoder", "and", "not", "self", ".", "using_decoder_past_key_values", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Ignore using_decoder_past_key_values=False in a decoder-only LM.\"", ")", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "config", ",", "T5Config", ")", ":", "\n", "            ", "self", ".", "n_layer", "=", "self", ".", "config", ".", "num_layers", "\n", "self", ".", "n_embd", "=", "self", ".", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "self", ".", "config", ".", "num_heads", "\n", "self", ".", "n_decoder_layer", "=", "self", ".", "config", ".", "num_decoder_layers", "\n", "self", ".", "match_n_decoder_layer", "=", "self", ".", "n_decoder_layer", "\n", "self", ".", "match_n_layer", "=", "self", ".", "n_layer", "\n", "", "elif", "isinstance", "(", "self", ".", "config", ",", "GPT2Config", ")", ":", "\n", "            ", "self", ".", "n_decoder_layer", "=", "self", ".", "config", ".", "n_layer", "\n", "self", ".", "n_embd", "=", "self", ".", "config", ".", "n_embd", "\n", "self", ".", "n_head", "=", "self", ".", "config", ".", "n_head", "\n", "self", ".", "match_n_decoder_layer", "=", "self", ".", "n_decoder_layer", "\n", "", "self", ".", "mid_dim", "=", "mid_dim", "\n", "self", ".", "match_n_head", "=", "self", ".", "n_head", "\n", "self", ".", "match_n_embd", "=", "self", ".", "n_embd", "//", "self", ".", "n_head", "\n", "self", ".", "prefix_dropout", "=", "prefix_dropout", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "prefix_dropout", ")", "\n", "\n", "self", ".", "default_text1", "=", "'{\"placeholder\": \"text_a\"} {\"mask\"}'", "\n", "self", ".", "default_text2", "=", "'{\"placeholder\": \"text_a\"} {\"placeholder\": \"text_b\"} {\"mask\"}'", "\n", "\n", "self", ".", "text", "=", "text", "\n", "\n", "self", ".", "generate_parameters", "(", ")", "# in prefix tuning the template text has no interact with the parameters.", "\n", "\n", "self", ".", "plm_modified", "=", "False", "# flag to indicate whether the function of plm are replaced for prefix tuning.", "\n", "self", ".", "modify_plm", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.on_text_set": [[93, 96], ["prefix_tuning_template.PrefixTuningTemplate.parse_text", "prefix_tuning_template.PrefixTuningTemplate.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.mixed_template.MixedTemplate.parse_text", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["", "def", "on_text_set", "(", "self", ")", ":", "\n", "        ", "self", ".", "text", "=", "self", ".", "parse_text", "(", "self", ".", "text", ")", "\n", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.get_past_key_values": [[98, 126], ["prefix_tuning_template.PrefixTuningTemplate.input_tokens.unsqueeze().expand", "prefix_tuning_template.PrefixTuningTemplate.wte", "prefix_tuning_template.PrefixTuningTemplate.control_trans", "past_key_values.permute().split.permute().split.view", "prefix_tuning_template.PrefixTuningTemplate.dropout", "past_key_values.permute().split.permute().split.permute().split", "pvs.append", "pvs.append", "prefix_tuning_template.PrefixTuningTemplate.input_tokens.unsqueeze().expand", "prefix_tuning_template.PrefixTuningTemplate.decoder_wte", "prefix_tuning_template.PrefixTuningTemplate.decoder_control_trans", "decoder_past_key_values.permute().split.permute().split.view", "prefix_tuning_template.PrefixTuningTemplate.dropout", "decoder_past_key_values.permute().split.permute().split.permute().split", "pvs.append", "pvs.append", "prefix_tuning_template.PrefixTuningTemplate.input_tokens.unsqueeze", "past_key_values.permute().split.permute().split.permute", "prefix_tuning_template.PrefixTuningTemplate.input_tokens.unsqueeze", "decoder_past_key_values.permute().split.permute().split.permute"], "methods", ["None"], ["", "def", "get_past_key_values", "(", "self", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "pvs", "=", "[", "]", "\n", "if", "self", ".", "config", ".", "is_encoder_decoder", "and", "self", ".", "using_encoder_past_key_values", ":", "\n", "            ", "input_tokens", "=", "self", ".", "input_tokens", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", "temp_control", "=", "self", ".", "wte", "(", "input_tokens", ")", "\n", "past_key_values", "=", "self", ".", "control_trans", "(", "temp_control", ")", "#bsz, seqlen, layer*emb", "\n", "_", ",", "seqlen", ",", "_", "=", "past_key_values", ".", "shape", "\n", "past_key_values", "=", "past_key_values", ".", "view", "(", "batch_size", ",", "seqlen", ",", "self", ".", "match_n_layer", "*", "2", ",", "self", ".", "match_n_head", ",", "\n", "self", ".", "match_n_embd", ")", "\n", "past_key_values", "=", "self", ".", "dropout", "(", "past_key_values", ")", "\n", "past_key_values", "=", "past_key_values", ".", "permute", "(", "[", "2", ",", "0", ",", "3", ",", "1", ",", "4", "]", ")", ".", "split", "(", "2", ")", "\n", "pvs", ".", "append", "(", "past_key_values", ")", "\n", "", "else", ":", "\n", "            ", "pvs", ".", "append", "(", "None", ")", "\n", "\n", "", "if", "(", "not", "self", ".", "config", ".", "is_encoder_decoder", ")", "or", "self", ".", "using_decoder_past_key_values", ":", "\n", "            ", "decoder_input_tokens", "=", "self", ".", "input_tokens", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", "decoder_temp_control", "=", "self", ".", "decoder_wte", "(", "decoder_input_tokens", ")", "\n", "decoder_past_key_values", "=", "self", ".", "decoder_control_trans", "(", "decoder_temp_control", ")", "#bsz, seqlen, layer*emb", "\n", "_", ",", "decoder_seqlen", ",", "_", "=", "decoder_past_key_values", ".", "shape", "\n", "decoder_past_key_values", "=", "decoder_past_key_values", ".", "view", "(", "batch_size", ",", "decoder_seqlen", ",", "self", ".", "match_n_decoder_layer", "*", "2", ",", "self", ".", "match_n_head", ",", "\n", "self", ".", "match_n_embd", ")", "\n", "decoder_past_key_values", "=", "self", ".", "dropout", "(", "decoder_past_key_values", ")", "\n", "decoder_past_key_values", "=", "decoder_past_key_values", ".", "permute", "(", "[", "2", ",", "0", ",", "3", ",", "1", ",", "4", "]", ")", ".", "split", "(", "2", ")", "\n", "pvs", ".", "append", "(", "decoder_past_key_values", ")", "\n", "", "else", ":", "\n", "            ", "pvs", ".", "append", "(", "None", ")", "\n", "", "return", "pvs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.generate_parameters": [[127, 150], ["torch.nn.Parameter", "torch.arange().long", "torch.nn.Embedding", "torch.nn.Sequential", "torch.nn.Embedding", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear", "torch.arange"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ")", "->", "None", ":", "\n", "        ", "r\"\"\"\n        Generate parameters needed for new tokens' embedding in P-tuning\n        \"\"\"", "\n", "\n", "self", ".", "input_tokens", "=", "nn", ".", "Parameter", "(", "torch", ".", "arange", "(", "self", ".", "num_token", ")", ".", "long", "(", ")", ",", "requires_grad", "=", "False", ")", "# to allow automatic devicing", "\n", "if", "self", ".", "config", ".", "is_encoder_decoder", "and", "self", ".", "using_encoder_past_key_values", ":", "\n", "            ", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "self", ".", "num_token", ",", "self", ".", "n_embd", ")", "\n", "self", ".", "control_trans", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "n_embd", ",", "self", ".", "mid_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "# nn.Linear(self.mid_dim, self.mid_dim),", "\n", "# nn.Tanh(),", "\n", "nn", ".", "Linear", "(", "self", ".", "mid_dim", ",", "self", ".", "n_layer", "*", "2", "*", "self", ".", "n_embd", ")", ")", "\n", "\n", "", "if", "(", "not", "self", ".", "config", ".", "is_encoder_decoder", ")", "or", "self", ".", "using_decoder_past_key_values", ":", "\n", "            ", "self", ".", "decoder_wte", "=", "nn", ".", "Embedding", "(", "self", ".", "num_token", ",", "self", ".", "n_embd", ")", "\n", "self", ".", "decoder_control_trans", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "n_embd", ",", "self", ".", "mid_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "# nn.Linear(self.mid_dim, self.mid_dim),", "\n", "# nn.Tanh(),", "\n", "nn", ".", "Linear", "(", "self", ".", "mid_dim", ",", "self", ".", "n_decoder_layer", "*", "2", "*", "self", ".", "n_embd", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.wrap_one_example": [[152, 159], ["super().wrap_one_example"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.wrap_one_example"], ["", "", "def", "wrap_one_example", "(", "self", ",", "example", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "if", "self", ".", "text", "is", "None", ":", "\n", "            ", "if", "example", ".", "text_b", "is", "None", ":", "\n", "                ", "self", ".", "text", "=", "self", ".", "default_text1", "\n", "", "else", ":", "\n", "                ", "self", ".", "text", "=", "self", ".", "default_text2", "\n", "", "", "return", "super", "(", ")", ".", "wrap_one_example", "(", "example", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize": [[160, 162], ["tuple", "t.expand"], "methods", ["None"], ["", "def", "expand_to_batchsize", "(", "self", ",", "tup", ",", "batch_size", ")", ":", "\n", "        ", "return", "tuple", "(", "t", ".", "expand", "(", "-", "1", ",", "batch_size", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "for", "t", "in", "tup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize_for_layer": [[163, 165], ["tup[].expand"], "methods", ["None"], ["", "def", "expand_to_batchsize_for_layer", "(", "self", ",", "tup", ",", "batch_size", ",", "layer_id", ")", ":", "\n", "        ", "return", "tup", "[", "layer_id", "]", ".", "expand", "(", "-", "1", ",", "batch_size", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.process_batch": [[168, 187], ["batch[].size", "prefix_tuning_template.PrefixTuningTemplate.get_past_key_values", "prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize", "torch.cat", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.get_past_key_values", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize"], ["", "def", "process_batch", "(", "self", ",", "batch", ":", "Union", "[", "Dict", ",", "InputFeatures", "]", ")", "->", "Union", "[", "Dict", ",", "InputFeatures", "]", ":", "\n", "        ", "r\"\"\"\n        Convert input_ids to inputs_embeds\n        for normal token, use the embedding inside PLM\n        for new token, use MLP or LSTM\n        \"\"\"", "\n", "batch_size", "=", "batch", "[", "'input_ids'", "]", ".", "size", "(", "0", ")", "\n", "self", ".", "past_key_values", "=", "self", ".", "get_past_key_values", "(", ")", "\n", "\n", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "# the attention_mask is encoder attention mask, the new token mask will be added in modified_encoder_forward.", "\n", "            ", "pass", "\n", "", "else", ":", "# the attention_mask is decoder attention mask", "\n", "            ", "past_key_values", "=", "self", ".", "expand_to_batchsize", "(", "self", ".", "past_key_values", "[", "1", "]", ",", "batch_size", ")", "\n", "if", "'attention_mask'", "in", "batch", ":", "\n", "                ", "am", "=", "batch", "[", "'attention_mask'", "]", "\n", "batch", "[", "'attention_mask'", "]", "=", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "(", "batch_size", ",", "self", ".", "num_token", ")", ",", "dtype", "=", "am", ".", "dtype", ",", "device", "=", "am", ".", "device", ")", ",", "am", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "batch", "[", "'past_key_values'", "]", "=", "past_key_values", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.modify_plm": [[188, 236], ["isinstance", "isinstance", "enumerate", "enumerate", "backup_encoder_forward_functions.append", "functools.partial", "prefix_tuning_template.PrefixTuningTemplate.append", "functools.partial", "kwargs.pop", "kwargs.pop", "prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize_for_layer().to", "torch.cat", "prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize_for_layer().to", "kwargs[].size", "[].size", "args[].size", "torch.cat", "RuntimeError", "prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize_for_layer", "prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize_for_layer", "[].size", "args[].size", "kwargs[].size", "torch.zeros", "torch.zeros", "[].size", "args[].size", "kwargs[].size"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.to", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize_for_layer", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prefix_tuning_template.PrefixTuningTemplate.expand_to_batchsize_for_layer"], ["", "def", "modify_plm", "(", "self", ",", "model", ")", ":", "\n", "        ", "if", "self", ".", "plm_modified", ":", "\n", "            ", "return", "None", "\n", "", "if", "isinstance", "(", "model", ",", "T5ForConditionalGeneration", ")", ":", "\n", "            ", "if", "self", ".", "using_encoder_past_key_values", ":", "\n", "                ", "backup_encoder_forward_functions", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "model", ".", "encoder", ".", "block", ")", ":", "\n", "                    ", "backup_encoder_forward_functions", ".", "append", "(", "layer_module", ".", "layer", "[", "0", "]", ".", "forward", ")", "\n", "def", "modified_encoder_forward", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                        ", "layer_id", "=", "kwargs", ".", "pop", "(", "'layer_id'", ")", "\n", "batch_size", "=", "args", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "device", "=", "args", "[", "0", "]", ".", "device", "\n", "if", "kwargs", "[", "'past_key_value'", "]", "is", "None", ":", "\n", "                            ", "kwargs", "[", "'past_key_value'", "]", "=", "self", ".", "expand_to_batchsize_for_layer", "(", "self", ".", "past_key_values", "[", "0", "]", ",", "batch_size", ",", "layer_id", ")", ".", "to", "(", "device", ")", "\n", "", "if", "kwargs", "[", "'attention_mask'", "]", "is", "not", "None", ":", "\n", "                            ", "am", "=", "kwargs", "[", "'attention_mask'", "]", "# Should check the format of the attention_mask when moving to a new plm.", "\n", "kwargs", "[", "'attention_mask'", "]", "=", "torch", ".", "cat", "(", "[", "-", "torch", ".", "zeros", "(", "(", "*", "am", ".", "shape", "[", ":", "-", "1", "]", ",", "self", ".", "num_token", ")", ",", "dtype", "=", "am", ".", "dtype", ",", "device", "=", "am", ".", "device", ")", ",", "am", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "backup_encoder_forward_functions", "[", "layer_id", "]", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "layer_module", ".", "layer", "[", "0", "]", ".", "forward", "=", "partial", "(", "modified_encoder_forward", ",", "layer_id", "=", "i", ")", "\n", "\n", "", "", "if", "self", ".", "using_decoder_past_key_values", ":", "\n", "                ", "backup_decoder_self_attn_forward_functions", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "model", ".", "decoder", ".", "block", ")", ":", "\n", "                    ", "backup_decoder_self_attn_forward_functions", ".", "append", "(", "layer_module", ".", "layer", "[", "0", "]", ".", "forward", ")", "\n", "def", "modified_decoder_self_attn_forward", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                        ", "batch_size", "=", "args", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "layer_id", "=", "kwargs", ".", "pop", "(", "'layer_id'", ")", "\n", "device", "=", "args", "[", "0", "]", ".", "device", "\n", "if", "kwargs", "[", "'past_key_value'", "]", "is", "None", ":", "\n", "                            ", "kwargs", "[", "'past_key_value'", "]", "=", "self", ".", "expand_to_batchsize_for_layer", "(", "self", ".", "past_key_values", "[", "1", "]", ",", "batch_size", ",", "layer_id", ")", ".", "to", "(", "device", ")", "\n", "", "if", "kwargs", "[", "'past_key_value'", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "+", "args", "[", "0", "]", ".", "size", "(", "-", "2", ")", "==", "kwargs", "[", "'attention_mask'", "]", ".", "size", "(", "-", "1", ")", ":", "\n", "                            ", "pass", "\n", "", "elif", "kwargs", "[", "'past_key_value'", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "+", "args", "[", "0", "]", ".", "size", "(", "-", "2", ")", "==", "kwargs", "[", "'attention_mask'", "]", ".", "size", "(", "-", "1", ")", "+", "self", ".", "num_token", ":", "\n", "                            ", "am", "=", "kwargs", "[", "'attention_mask'", "]", "\n", "kwargs", "[", "'attention_mask'", "]", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "(", "*", "am", ".", "shape", "[", ":", "-", "1", "]", ",", "self", ".", "num_token", ")", ",", "dtype", "=", "am", ".", "dtype", ",", "device", "=", "am", ".", "device", ")", ",", "am", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                            ", "raise", "RuntimeError", "(", "\"Size not match: past length: {}, inputlength:{},\\\n                                attention mask length {}\"", ".", "format", "(", "kwargs", "[", "'past_key_value'", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", ",", "\n", "args", "[", "0", "]", ".", "size", "(", "-", "2", ")", ",", "kwargs", "[", "'attention_mask'", "]", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "\n", "", "return", "backup_decoder_self_attn_forward_functions", "[", "layer_id", "]", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "layer_module", ".", "layer", "[", "0", "]", ".", "forward", "=", "partial", "(", "modified_decoder_self_attn_forward", ",", "layer_id", "=", "i", ")", "\n", "\n", "", "", "", "elif", "isinstance", "(", "model", ",", "GPT2LMHeadModel", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "plm_modified", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_template": [[55, 74], ["template_class.from_config"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.from_config"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_verbalizer": [[75, 94], ["verbalizer_class.from_config"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.from_config"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_template_generator": [[95, 101], ["template_generator_class.from_config"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.from_config"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.__init__.load_verbalizer_generator": [[102, 108], ["verbalizer_generator_class.from_config"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.from_config"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.__init__": [[27, 41], ["openprompt.Verbalizer.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "classes", ":", "Optional", "[", "List", "]", "=", "None", ",", "\n", "num_classes", ":", "Optional", "[", "Sequence", "[", "str", "]", "]", "=", "None", ",", "\n", "label_words", ":", "Optional", "[", "Union", "[", "Sequence", "[", "str", "]", ",", "Mapping", "[", "str", ",", "str", "]", "]", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "\" \"", ",", "\n", "multi_token_handler", ":", "Optional", "[", "str", "]", "=", "\"first\"", ",", "\n", "post_log_softmax", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokenizer", "=", "tokenizer", ",", "num_classes", "=", "num_classes", ",", "classes", "=", "classes", ")", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "multi_token_handler", "=", "multi_token_handler", "\n", "self", ".", "label_words", "=", "label_words", "\n", "self", ".", "post_log_softmax", "=", "post_log_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.on_label_words_set": [[42, 50], ["super().on_label_words_set", "manual_verbalizer.ManualVerbalizer.add_prefix", "manual_verbalizer.ManualVerbalizer.generate_parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.on_label_words_set", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.add_prefix", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters"], ["", "def", "on_label_words_set", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "on_label_words_set", "(", ")", "\n", "self", ".", "label_words", "=", "self", ".", "add_prefix", "(", "self", ".", "label_words", ",", "self", ".", "prefix", ")", "\n", "\n", "# TODO should Verbalizer base class has label_words property and setter?", "\n", "# it don't have label_words init argument or label words from_file option at all", "\n", "\n", "self", ".", "generate_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.add_prefix": [[51, 76], ["isinstance", "new_label_words.append", "word.startswith", "new_label_words_per_label.append", "new_label_words_per_label.append", "word.split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_prefix", "(", "label_words", ",", "prefix", ")", ":", "\n", "        ", "r\"\"\"Add prefix to label words. For example, if a label words is in the middle of a template,\n        the prefix should be ``' '``.\n\n        Args:\n            label_words (:obj:`Union[Sequence[str], Mapping[str, str]]`, optional): The label words that are projected by the labels.\n            prefix (:obj:`str`, optional): The prefix string of the verbalizer.\n\n        Returns:\n            :obj:`Sequence[str]`: New label words with prefix.\n        \"\"\"", "\n", "new_label_words", "=", "[", "]", "\n", "if", "isinstance", "(", "label_words", "[", "0", "]", ",", "str", ")", ":", "\n", "            ", "label_words", "=", "[", "[", "w", "]", "for", "w", "in", "label_words", "]", "#wrapped it to a list of list of label words.", "\n", "\n", "", "for", "label_words_per_label", "in", "label_words", ":", "\n", "            ", "new_label_words_per_label", "=", "[", "]", "\n", "for", "word", "in", "label_words_per_label", ":", "\n", "                ", "if", "word", ".", "startswith", "(", "\"<!>\"", ")", ":", "\n", "                    ", "new_label_words_per_label", ".", "append", "(", "word", ".", "split", "(", "\"<!>\"", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "new_label_words_per_label", ".", "append", "(", "prefix", "+", "word", ")", "\n", "", "", "new_label_words", ".", "append", "(", "new_label_words_per_label", ")", "\n", "", "return", "new_label_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.generate_parameters": [[77, 104], ["max", "max", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "all_ids.append", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "manual_verbalizer.ManualVerbalizer.tokenizer.encode", "ids_per_label.append", "max", "len", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.sum", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ")", "->", "List", ":", "\n", "        ", "r\"\"\"In basic manual template, the parameters are generated from label words directly.\n        In this implementation, the label_words should not be tokenized into more than one token.\n        \"\"\"", "\n", "all_ids", "=", "[", "]", "\n", "for", "words_per_label", "in", "self", ".", "label_words", ":", "\n", "            ", "ids_per_label", "=", "[", "]", "\n", "for", "word", "in", "words_per_label", ":", "\n", "                ", "ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "word", ",", "add_special_tokens", "=", "False", ")", "\n", "ids_per_label", ".", "append", "(", "ids", ")", "\n", "", "all_ids", ".", "append", "(", "ids_per_label", ")", "\n", "\n", "", "max_len", "=", "max", "(", "[", "max", "(", "[", "len", "(", "ids", ")", "for", "ids", "in", "ids_per_label", "]", ")", "for", "ids_per_label", "in", "all_ids", "]", ")", "\n", "max_num_label_words", "=", "max", "(", "[", "len", "(", "ids_per_label", ")", "for", "ids_per_label", "in", "all_ids", "]", ")", "\n", "words_ids_mask", "=", "torch", ".", "zeros", "(", "max_num_label_words", ",", "max_len", ")", "\n", "words_ids_mask", "=", "[", "[", "[", "1", "]", "*", "len", "(", "ids", ")", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "ids_per_label", "]", "\n", "+", "[", "[", "0", "]", "*", "max_len", "]", "*", "(", "max_num_label_words", "-", "len", "(", "ids_per_label", ")", ")", "\n", "for", "ids_per_label", "in", "all_ids", "]", "\n", "words_ids", "=", "[", "[", "ids", "+", "[", "0", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "for", "ids", "in", "ids_per_label", "]", "\n", "+", "[", "[", "0", "]", "*", "max_len", "]", "*", "(", "max_num_label_words", "-", "len", "(", "ids_per_label", ")", ")", "\n", "for", "ids_per_label", "in", "all_ids", "]", "\n", "\n", "words_ids_tensor", "=", "torch", ".", "tensor", "(", "words_ids", ")", "\n", "words_ids_mask", "=", "torch", ".", "tensor", "(", "words_ids_mask", ")", "\n", "self", ".", "label_words_ids", "=", "nn", ".", "Parameter", "(", "words_ids_tensor", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "words_ids_mask", "=", "nn", ".", "Parameter", "(", "words_ids_mask", ",", "requires_grad", "=", "False", ")", "# A 3-d mask", "\n", "self", ".", "label_words_mask", "=", "nn", ".", "Parameter", "(", "torch", ".", "clamp", "(", "words_ids_mask", ".", "sum", "(", "dim", "=", "-", "1", ")", ",", "max", "=", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project": [[105, 123], ["manual_verbalizer.ManualVerbalizer.handle_multi_token"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.prompt_base.Verbalizer.handle_multi_token"], ["", "def", "project", "(", "self", ",", "\n", "logits", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n        Project the labels, the return value is the normalized (sum to 1) probs of label words.\n\n        Args:\n            logits (:obj:`torch.Tensor`): The original logits of label words.\n\n        Returns:\n            :obj:`torch.Tensor`: The normalized logits of label words\n        \"\"\"", "\n", "\n", "label_words_logits", "=", "logits", "[", ":", ",", "self", ".", "label_words_ids", "]", "\n", "label_words_logits", "=", "self", ".", "handle_multi_token", "(", "label_words_logits", ",", "self", ".", "words_ids_mask", ")", "\n", "label_words_logits", "-=", "10000", "*", "(", "1", "-", "self", ".", "label_words_mask", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.process_logits": [[124, 161], ["manual_verbalizer.ManualVerbalizer.project", "manual_verbalizer.ManualVerbalizer.aggregate", "manual_verbalizer.ManualVerbalizer.normalize", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "hasattr", "manual_verbalizer.ManualVerbalizer.calibrate"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.aggregate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.trainer.BaseRunner.log", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.calibrate"], ["", "def", "process_logits", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"A whole framework to process the original logits over the vocabulary, which contains four steps:\n\n        (1) Project the logits into logits of label words\n\n        if self.post_log_softmax is True:\n\n            (2) Normalize over all label words\n\n            (3) Calibrate (optional)\n\n        (4) Aggregate (for multiple label words)\n\n        Args:\n            logits (:obj:`torch.Tensor`): The original logits.\n\n        Returns:\n            (:obj:`torch.Tensor`): The final processed logits over the labels (classes).\n        \"\"\"", "\n", "# project", "\n", "label_words_logits", "=", "self", ".", "project", "(", "logits", ",", "**", "kwargs", ")", "#Output: (batch_size, num_classes) or  (batch_size, num_classes, num_label_words_per_label)", "\n", "\n", "\n", "if", "self", ".", "post_log_softmax", ":", "\n", "# normalize", "\n", "            ", "label_words_probs", "=", "self", ".", "normalize", "(", "label_words_logits", ")", "\n", "\n", "# calibrate", "\n", "if", "hasattr", "(", "self", ",", "\"_calibrate_logits\"", ")", "and", "self", ".", "_calibrate_logits", "is", "not", "None", ":", "\n", "                ", "label_words_probs", "=", "self", ".", "calibrate", "(", "label_words_probs", "=", "label_words_probs", ")", "\n", "\n", "# convert to logits", "\n", "", "label_words_logits", "=", "torch", ".", "log", "(", "label_words_probs", "+", "1e-15", ")", "\n", "\n", "# aggregate", "\n", "", "label_logits", "=", "self", ".", "aggregate", "(", "label_words_logits", ")", "\n", "return", "label_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize": [[162, 175], ["torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax().reshape", "torch.softmax", "torch.softmax", "torch.softmax", "logits.reshape"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Given logits regarding the entire vocabulary, return the probs over the label words set.\n\n        Args:\n            logits (:obj:`Tensor`): The logits over the entire vocabulary.\n\n        Returns:\n            :obj:`Tensor`: The logits over the label words set.\n\n        \"\"\"", "\n", "batch_size", "=", "logits", ".", "shape", "[", "0", "]", "\n", "return", "F", ".", "softmax", "(", "logits", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ".", "reshape", "(", "*", "logits", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.aggregate": [[177, 188], ["manual_verbalizer.ManualVerbalizer.label_words_mask.sum"], "methods", ["None"], ["", "def", "aggregate", "(", "self", ",", "label_words_logits", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"Use weight to aggregate the logits of label words.\n\n        Args:\n            label_words_logits(:obj:`torch.Tensor`): The logits of the label words.\n\n        Returns:\n            :obj:`torch.Tensor`: The aggregated logits from the label words.\n        \"\"\"", "\n", "label_words_logits", "=", "(", "label_words_logits", "*", "self", ".", "label_words_mask", ")", ".", "sum", "(", "-", "1", ")", "/", "self", ".", "label_words_mask", ".", "sum", "(", "-", "1", ")", "\n", "return", "label_words_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.calibrate": [[189, 209], ["manual_verbalizer.ManualVerbalizer.normalize", "label_words_probs.reshape.reshape.reshape().sum", "label_words_probs.reshape.reshape.reshape", "manual_verbalizer.ManualVerbalizer._calibrate_logits.dim", "manual_verbalizer.ManualVerbalizer.project", "label_words_probs.reshape.reshape.reshape", "manual_verbalizer.ManualVerbalizer._calibrate_logits.unsqueeze", "label_words_probs.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.normalize", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.manual_verbalizer.ManualVerbalizer.project"], ["", "def", "calibrate", "(", "self", ",", "label_words_probs", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"\n\n        Args:\n            label_words_probs (:obj:`torch.Tensor`): The probability distribution of the label words with the shape of [``batch_size``, ``num_classes``, ``num_label_words_per_class``]\n\n        Returns:\n            :obj:`torch.Tensor`: The calibrated probability of label words.\n        \"\"\"", "\n", "shape", "=", "label_words_probs", ".", "shape", "\n", "assert", "self", ".", "_calibrate_logits", ".", "dim", "(", ")", "==", "1", ",", "\"self._calibrate_logits are not 1-d tensor\"", "\n", "calibrate_label_words_probs", "=", "self", ".", "normalize", "(", "self", ".", "project", "(", "self", ".", "_calibrate_logits", ".", "unsqueeze", "(", "0", ")", ",", "**", "kwargs", ")", ")", "\n", "assert", "calibrate_label_words_probs", ".", "shape", "[", "1", ":", "]", "==", "label_words_probs", ".", "shape", "[", "1", ":", "]", "and", "calibrate_label_words_probs", ".", "shape", "[", "0", "]", "==", "1", ",", "\"shape not match\"", "\n", "label_words_probs", "/=", "(", "calibrate_label_words_probs", "+", "1e-15", ")", "\n", "# normalize # TODO Test the performance", "\n", "norm", "=", "label_words_probs", ".", "reshape", "(", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "# TODO Test the performance of detaching()", "\n", "label_words_probs", "=", "label_words_probs", ".", "reshape", "(", "shape", "[", "0", "]", ",", "-", "1", ")", "/", "norm", "\n", "label_words_probs", "=", "label_words_probs", ".", "reshape", "(", "*", "shape", ")", "\n", "return", "label_words_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.mlm.MLMTokenizerWrapper.mask_token": [[11, 14], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "mask_token", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "mask_token", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.mlm.MLMTokenizerWrapper.mask_token_ids": [[15, 18], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mask_token_ids", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "mask_token_id", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.mlm.MLMTokenizerWrapper.num_special_tokens_to_add": [[19, 24], ["hasattr", "mlm.MLMTokenizerWrapper.tokenizer.num_special_tokens_to_add"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.num_special_tokens_to_add"], ["", "@", "property", "\n", "def", "num_special_tokens_to_add", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'_num_specials'", ")", ":", "\n", "            ", "self", ".", "_num_specials", "=", "self", ".", "tokenizer", ".", "num_special_tokens_to_add", "(", ")", "\n", "", "return", "self", ".", "_num_specials", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.mlm.MLMTokenizerWrapper.tokenize_one_example": [[25, 90], ["collections.defaultdict", "mlm.MLMTokenizerWrapper.truncate", "mlm.MLMTokenizerWrapper.pop", "mlm.MLMTokenizerWrapper.concate_parts", "mlm.MLMTokenizerWrapper.add_special_tokens", "mlm.MLMTokenizerWrapper.padding", "isinstance", "len", "encoder_inputs[].append", "len", "len", "encoded_tgt_text.append", "mlm.MLMTokenizerWrapper.special_tokens_maps.keys", "mlm.MLMTokenizerWrapper.tokenizer.encode", "len", "mlm.MLMTokenizerWrapper.tokenizer.encode", "RuntimeError", "KeyError", "encoder_inputs[].append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.concate_parts", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["", "def", "tokenize_one_example", "(", "self", ",", "wrapped_example", ",", "teacher_forcing", ")", ":", "\n", "        ", "''' # TODO doesn't consider the situation that input has two parts\n        '''", "\n", "\n", "wrapped_example", ",", "others", "=", "wrapped_example", "\n", "\n", "# for some dataset like SuperGLUE.COPA, the answer requires prediction an span of", "\n", "# the input. Or in generation tasks, we need to generate a piece of target_text.", "\n", "# In these case, it tokenized to the encoded_tgt_text for future use.", "\n", "encoded_tgt_text", "=", "[", "]", "\n", "if", "'tgt_text'", "in", "others", ":", "\n", "            ", "tgt_text", "=", "others", "[", "'tgt_text'", "]", "\n", "if", "isinstance", "(", "tgt_text", ",", "str", ")", ":", "\n", "                ", "tgt_text", "=", "[", "tgt_text", "]", "\n", "", "for", "t", "in", "tgt_text", ":", "\n", "                ", "encoded_tgt_text", ".", "append", "(", "self", ".", "tokenizer", ".", "encode", "(", "t", ",", "add_special_tokens", "=", "False", ")", ")", "\n", "\n", "\n", "", "", "mask_id", "=", "0", "# the i-th the mask token in the template.", "\n", "\n", "encoder_inputs", "=", "defaultdict", "(", "list", ")", "\n", "for", "piece", "in", "wrapped_example", ":", "\n", "            ", "if", "piece", "[", "'loss_ids'", "]", "==", "1", ":", "\n", "                ", "if", "teacher_forcing", ":", "# fill the mask with the tgt task", "\n", "                    ", "raise", "RuntimeError", "(", "\"Masked Language Model can't perform teacher forcing training!\"", ")", "\n", "", "else", ":", "\n", "                    ", "encode_text", "=", "[", "self", ".", "mask_token_ids", "]", "\n", "", "mask_id", "+=", "1", "\n", "\n", "", "if", "piece", "[", "'text'", "]", "in", "self", ".", "special_tokens_maps", ".", "keys", "(", ")", ":", "\n", "                ", "to_replace", "=", "self", ".", "special_tokens_maps", "[", "piece", "[", "'text'", "]", "]", "\n", "if", "to_replace", "is", "not", "None", ":", "\n", "                    ", "piece", "[", "'text'", "]", "=", "to_replace", "\n", "", "else", ":", "\n", "                    ", "raise", "KeyError", "(", "\"This tokenizer doesn't specify {} token.\"", ".", "format", "(", "piece", "[", "'text'", "]", ")", ")", "\n", "\n", "", "", "if", "'soft_token_ids'", "in", "piece", "and", "piece", "[", "'soft_token_ids'", "]", "!=", "0", ":", "\n", "                ", "encode_text", "=", "[", "0", "]", "# can be replace by any token, since these token will use their own embeddings", "\n", "", "else", ":", "\n", "                ", "encode_text", "=", "self", ".", "tokenizer", ".", "encode", "(", "piece", "[", "'text'", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "encoding_length", "=", "len", "(", "encode_text", ")", "\n", "encoder_inputs", "[", "'input_ids'", "]", ".", "append", "(", "encode_text", ")", "\n", "for", "key", "in", "piece", ":", "\n", "                ", "if", "key", "not", "in", "[", "'text'", "]", ":", "\n", "                    ", "encoder_inputs", "[", "key", "]", ".", "append", "(", "[", "piece", "[", "key", "]", "]", "*", "encoding_length", ")", "\n", "\n", "", "", "", "encoder_inputs", "=", "self", ".", "truncate", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "# delete shortenable ids", "\n", "encoder_inputs", ".", "pop", "(", "\"shortenable_ids\"", ")", "\n", "encoder_inputs", "=", "self", ".", "concate_parts", "(", "input_dict", "=", "encoder_inputs", ")", "\n", "encoder_inputs", "=", "self", ".", "add_special_tokens", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "# create special input ids", "\n", "encoder_inputs", "[", "'attention_mask'", "]", "=", "[", "1", "]", "*", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "if", "self", ".", "create_token_type_ids", ":", "\n", "            ", "encoder_inputs", "[", "'token_type_ids'", "]", "=", "[", "0", "]", "*", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "# padding", "\n", "", "encoder_inputs", "=", "self", ".", "padding", "(", "input_dict", "=", "encoder_inputs", ",", "max_len", "=", "self", ".", "max_seq_length", ",", "pad_id_for_inputs", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "\n", "if", "len", "(", "encoded_tgt_text", ")", ">", "0", ":", "\n", "            ", "encoder_inputs", "=", "{", "**", "encoder_inputs", ",", "\"encoded_tgt_text\"", ":", "encoded_tgt_text", "}", "# convert defaultdict to dict", "\n", "", "else", ":", "\n", "            ", "encoder_inputs", "=", "{", "**", "encoder_inputs", "}", "\n", "", "return", "encoder_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5TokenizerWrapper.__init__": [[17, 31], ["openprompt.plms.utils.TokenizerWrapper.__init__", "openprompt.utils.logging.logger.warning"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "truncate_method", ":", "Optional", "[", "str", "]", "=", "'tail'", ",", "\n", "decoder_max_length", ":", "Optional", "[", "int", "]", "=", "128", ",", "\n", "decode_from_pad", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "predict_eos_token", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "max_seq_length", "=", "max_seq_length", ",", "tokenizer", "=", "tokenizer", ",", "truncate_method", "=", "truncate_method", ")", "\n", "self", ".", "decoder_max_length", "=", "decoder_max_length", "\n", "self", ".", "decode_from_pad", "=", "decode_from_pad", "\n", "self", ".", "predict_eos", "=", "predict_eos_token", "\n", "if", "self", ".", "create_token_type_ids", ":", "\n", "            ", "logger", ".", "warning", "(", "\"token_type_ids is not valid in T5. will be depreciated.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5TokenizerWrapper.mask_token": [[32, 34], ["None"], "methods", ["None"], ["", "", "def", "mask_token", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "additional_special_tokens", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5TokenizerWrapper.mask_token_ids": [[36, 38], ["None"], "methods", ["None"], ["", "def", "mask_token_ids", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "additional_special_tokens_ids", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5TokenizerWrapper.num_special_tokens_to_add": [[39, 44], ["hasattr", "seq2seq.T5TokenizerWrapper.tokenizer.num_special_tokens_to_add"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.num_special_tokens_to_add"], ["", "@", "property", "\n", "def", "num_special_tokens_to_add", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'_num_specials'", ")", ":", "\n", "            ", "self", ".", "_num_specials", "=", "self", ".", "tokenizer", ".", "num_special_tokens_to_add", "(", ")", "\n", "", "return", "self", ".", "_num_specials", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5TokenizerWrapper.tokenize_one_example": [[46, 121], ["collections.defaultdict", "enumerate", "seq2seq.T5TokenizerWrapper.truncate_decoder_inputs", "seq2seq.T5TokenizerWrapper.truncate", "seq2seq.T5TokenizerWrapper.pop", "seq2seq.T5TokenizerWrapper.concate_parts", "seq2seq.T5TokenizerWrapper.add_special_tokens", "seq2seq.T5TokenizerWrapper.padding", "isinstance", "len", "encoder_inputs[].append", "len", "decoder_input_ids.append", "seq2seq.T5TokenizerWrapper.tokenizer.encode", "decoder_input_ids.extend", "loss_ids.extend", "decoder_input_ids.append", "loss_ids.append", "seq2seq.T5TokenizerWrapper.special_tokens_maps.keys", "seq2seq.T5TokenizerWrapper.tokenizer.encode", "encoder_inputs[].append", "seq2seq.T5TokenizerWrapper.mask_token_ids", "loss_ids.append", "loss_ids.append", "seq2seq.T5TokenizerWrapper.mask_token_ids", "seq2seq.T5TokenizerWrapper.mask_token_ids", "seq2seq.T5TokenizerWrapper.mask_token_ids", "KeyError", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.truncate_decoder_inputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.concate_parts", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids"], ["", "def", "tokenize_one_example", "(", "self", ",", "wrapped_example", ",", "teacher_forcing", ")", ":", "\n", "        ", "''' # TODO doesn't consider the situation that input has two parts\n        '''", "\n", "wrapped_example", ",", "others", "=", "wrapped_example", "\n", "\n", "if", "teacher_forcing", ":", "\n", "            ", "tgt_text", "=", "others", "[", "'tgt_text'", "]", "\n", "if", "isinstance", "(", "tgt_text", ",", "str", ")", ":", "\n", "                ", "tgt_text", "=", "[", "tgt_text", "]", "\n", "\n", "\n", "", "", "encoder_inputs", "=", "defaultdict", "(", "list", ")", "\n", "\n", "num_mask_token_used", "=", "0", "\n", "\n", "decoder_input_ids", "=", "[", "]", "\n", "loss_ids", "=", "[", "]", "\n", "\n", "for", "piece_id", ",", "piece", "in", "enumerate", "(", "wrapped_example", ")", ":", "\n", "            ", "if", "piece", "[", "'text'", "]", "==", "self", ".", "template_mask_token", ":", "\n", "                ", "if", "teacher_forcing", ":", "\n", "                    ", "decoder_input_ids", ".", "append", "(", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", ")", "\n", "if", "num_mask_token_used", ">", "0", ":", "\n", "# if used in multiple mask setting, the <extra_id_1> etc. are also required", "\n", "# to be predicted.", "\n", "                        ", "loss_ids", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "loss_ids", ".", "append", "(", "0", ")", "\n", "", "encode_text", "=", "[", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", "]", "\n", "tgt_text_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\" \"", "+", "tgt_text", "[", "num_mask_token_used", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "decoder_input_ids", ".", "extend", "(", "tgt_text_ids", ")", "\n", "loss_ids", ".", "extend", "(", "[", "1", "]", "*", "len", "(", "tgt_text_ids", ")", ")", "\n", "", "else", ":", "\n", "                    ", "decoder_input_ids", ".", "append", "(", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", ")", "\n", "encode_text", "=", "[", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", "]", "\n", "loss_ids", ".", "append", "(", "1", ")", "\n", "", "num_mask_token_used", "+=", "1", "\n", "", "else", ":", "\n", "                ", "if", "piece", "[", "'text'", "]", "in", "self", ".", "special_tokens_maps", ".", "keys", "(", ")", ":", "\n", "                    ", "to_replace", "=", "self", ".", "special_tokens_maps", "[", "piece", "[", "'text'", "]", "]", "\n", "if", "to_replace", "is", "not", "None", ":", "\n", "                        ", "piece", "[", "'text'", "]", "=", "to_replace", "\n", "", "else", ":", "\n", "                        ", "raise", "KeyError", "(", "\"This tokenizer doesn't specify {} token.\"", ".", "format", "(", "piece", "[", "'text'", "]", ")", ")", "\n", "\n", "", "", "if", "'soft_token_ids'", "in", "piece", "and", "piece", "[", "'soft_token_ids'", "]", "!=", "0", ":", "\n", "                    ", "encode_text", "=", "[", "0", "]", "# can be replace by any token, since these token will use their own embeddings", "\n", "", "else", ":", "\n", "                    ", "encode_text", "=", "self", ".", "tokenizer", ".", "encode", "(", "piece", "[", "'text'", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "", "encoding_length", "=", "len", "(", "encode_text", ")", "\n", "\n", "encoder_inputs", "[", "'input_ids'", "]", ".", "append", "(", "encode_text", ")", "\n", "for", "key", "in", "piece", ":", "\n", "                ", "if", "key", "not", "in", "[", "'text'", ",", "'loss_ids'", "]", ":", "\n", "                    ", "encoder_inputs", "[", "key", "]", ".", "append", "(", "[", "piece", "[", "key", "]", "]", "*", "encoding_length", ")", "\n", "\n", "# decoder input ids", "\n", "", "", "", "decoder_inputs", "=", "{", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "'loss_ids'", ":", "loss_ids", "}", "\n", "decoder_inputs", "=", "self", ".", "truncate_decoder_inputs", "(", "decoder_inputs", ")", "\n", "\n", "encoder_inputs", "=", "self", ".", "truncate", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "\n", "# delete shortenable ids", "\n", "encoder_inputs", ".", "pop", "(", "\"shortenable_ids\"", ")", "\n", "encoder_inputs", "=", "self", ".", "concate_parts", "(", "input_dict", "=", "encoder_inputs", ")", "\n", "encoder_inputs", "=", "self", ".", "add_special_tokens", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "\n", "# create special input ids", "\n", "encoder_inputs", "[", "'attention_mask'", "]", "=", "[", "1", "]", "*", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "# padding", "\n", "encoder_inputs", "=", "self", ".", "padding", "(", "input_dict", "=", "encoder_inputs", ",", "max_len", "=", "self", ".", "max_seq_length", ",", "pad_id_for_inputs", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "all_input_ids", "=", "{", "**", "encoder_inputs", ",", "**", "decoder_inputs", "}", "\n", "return", "all_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5TokenizerWrapper.truncate_decoder_inputs": [[122, 135], ["seq2seq.T5TokenizerWrapper.padding", "inputs[].insert", "inputs[].insert", "inputs[].append", "inputs[].append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding"], ["", "def", "truncate_decoder_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "decode_from_pad", ":", "\n", "            ", "inputs", "[", "'decoder_input_ids'", "]", ".", "insert", "(", "0", ",", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "inputs", "[", "'loss_ids'", "]", ".", "insert", "(", "0", ",", "0", ")", "\n", "\n", "", "for", "key", "in", "inputs", ":", "\n", "            ", "inputs", "[", "key", "]", "=", "inputs", "[", "key", "]", "[", ":", "self", ".", "decoder_max_length", "-", "1", "]", "\n", "\n", "", "if", "self", ".", "predict_eos", ":", "\n", "            ", "inputs", "[", "'decoder_input_ids'", "]", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "inputs", "[", "'loss_ids'", "]", ".", "append", "(", "1", ")", "\n", "", "inputs", "=", "self", ".", "padding", "(", "inputs", ",", "max_len", "=", "self", ".", "decoder_max_length", ",", "pad_id_for_inputs", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5LMTokenizerWrapper.__init__": [[150, 164], ["openprompt.plms.utils.TokenizerWrapper.__init__", "openprompt.utils.logging.logger.warning"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "truncate_method", ":", "Optional", "[", "str", "]", "=", "'tail'", ",", "\n", "decoder_max_length", ":", "Optional", "[", "int", "]", "=", "128", ",", "\n", "decode_from_pad", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "predict_eos_token", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "max_seq_length", "=", "max_seq_length", ",", "tokenizer", "=", "tokenizer", ",", "truncate_method", "=", "truncate_method", ")", "\n", "self", ".", "decoder_max_length", "=", "decoder_max_length", "\n", "self", ".", "decode_from_pad", "=", "decode_from_pad", "\n", "self", ".", "predict_eos", "=", "predict_eos_token", "\n", "if", "self", ".", "create_token_type_ids", ":", "\n", "            ", "logger", ".", "warning", "(", "\"token_type_ids is not valid in T5. will be depreciated.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5LMTokenizerWrapper.mask_token": [[165, 167], ["None"], "methods", ["None"], ["", "", "def", "mask_token", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "additional_special_tokens", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5LMTokenizerWrapper.mask_token_ids": [[169, 171], ["None"], "methods", ["None"], ["", "def", "mask_token_ids", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "additional_special_tokens_ids", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5LMTokenizerWrapper.num_special_tokens_to_add": [[172, 177], ["hasattr", "seq2seq.T5LMTokenizerWrapper.tokenizer.num_special_tokens_to_add"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.num_special_tokens_to_add"], ["", "@", "property", "\n", "def", "num_special_tokens_to_add", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'_num_specials'", ")", ":", "\n", "            ", "self", ".", "_num_specials", "=", "self", ".", "tokenizer", ".", "num_special_tokens_to_add", "(", ")", "\n", "", "return", "self", ".", "_num_specials", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5LMTokenizerWrapper.tokenize_one_example": [[179, 245], ["collections.defaultdict", "enumerate", "seq2seq.T5LMTokenizerWrapper.truncate_decoder_inputs", "seq2seq.T5LMTokenizerWrapper.truncate", "seq2seq.T5LMTokenizerWrapper.pop", "seq2seq.T5LMTokenizerWrapper.concate_parts", "seq2seq.T5LMTokenizerWrapper.add_special_tokens", "seq2seq.T5LMTokenizerWrapper.padding", "isinstance", "len", "encoder_inputs[].append", "len", "decoder_input_ids.append", "loss_ids.append", "seq2seq.T5LMTokenizerWrapper.tokenizer.encode", "decoder_input_ids.extend", "loss_ids.extend", "decoder_input_ids.append", "loss_ids.append", "seq2seq.T5LMTokenizerWrapper.special_tokens_maps.keys", "seq2seq.T5LMTokenizerWrapper.tokenizer.encode", "encoder_inputs[].append", "seq2seq.T5LMTokenizerWrapper.mask_token_ids", "seq2seq.T5LMTokenizerWrapper.mask_token_ids", "KeyError", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.truncate_decoder_inputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.concate_parts", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids"], ["", "def", "tokenize_one_example", "(", "self", ",", "wrapped_example", ",", "teacher_forcing", ")", ":", "\n", "        ", "wrapped_example", ",", "others", "=", "wrapped_example", "\n", "if", "teacher_forcing", ":", "\n", "            ", "tgt_text", "=", "others", "[", "'tgt_text'", "]", "\n", "if", "isinstance", "(", "tgt_text", ",", "str", ")", ":", "\n", "                ", "tgt_text", "=", "[", "tgt_text", "]", "\n", "\n", "", "", "encoder_inputs", "=", "defaultdict", "(", "list", ")", "\n", "\n", "num_mask_token_used", "=", "0", "\n", "\n", "decoder_input_ids", "=", "[", "]", "\n", "loss_ids", "=", "[", "]", "\n", "\n", "for", "piece_id", ",", "piece", "in", "enumerate", "(", "wrapped_example", ")", ":", "\n", "            ", "if", "piece", "[", "'text'", "]", "==", "self", ".", "template_mask_token", ":", "\n", "                ", "if", "teacher_forcing", ":", "\n", "                    ", "decoder_input_ids", ".", "append", "(", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", ")", "\n", "loss_ids", ".", "append", "(", "0", ")", "\n", "encode_text", "=", "[", "]", "\n", "tgt_text_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\" \"", "+", "tgt_text", "[", "num_mask_token_used", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "decoder_input_ids", ".", "extend", "(", "tgt_text_ids", ")", "\n", "loss_ids", ".", "extend", "(", "[", "1", "]", "*", "len", "(", "tgt_text_ids", ")", ")", "\n", "", "else", ":", "\n", "                    ", "decoder_input_ids", ".", "append", "(", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", ")", "\n", "encode_text", "=", "[", "]", "# not add extra_id_0 to input_ids", "\n", "loss_ids", ".", "append", "(", "1", ")", "\n", "", "break", "\n", "", "else", ":", "\n", "                ", "if", "piece", "[", "'text'", "]", "in", "self", ".", "special_tokens_maps", ".", "keys", "(", ")", ":", "\n", "                    ", "to_replace", "=", "self", ".", "special_tokens_maps", "[", "piece", "[", "'text'", "]", "]", "\n", "if", "to_replace", "is", "not", "None", ":", "\n", "                        ", "piece", "[", "'text'", "]", "=", "to_replace", "\n", "", "else", ":", "\n", "                        ", "raise", "KeyError", "(", "\"This tokenizer doesn't specify {} token.\"", ".", "format", "(", "piece", "[", "'text'", "]", ")", ")", "\n", "\n", "", "", "if", "'soft_token_ids'", "in", "piece", "and", "piece", "[", "'soft_token_ids'", "]", "!=", "0", ":", "\n", "                    ", "encode_text", "=", "[", "0", "]", "# can be replace by any token, since these token will use their own embeddings", "\n", "", "else", ":", "\n", "                    ", "encode_text", "=", "self", ".", "tokenizer", ".", "encode", "(", "piece", "[", "'text'", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "", "encoding_length", "=", "len", "(", "encode_text", ")", "\n", "\n", "encoder_inputs", "[", "'input_ids'", "]", ".", "append", "(", "encode_text", ")", "\n", "for", "key", "in", "piece", ":", "\n", "                ", "if", "key", "not", "in", "[", "'text'", ",", "'loss_ids'", "]", ":", "\n", "                    ", "encoder_inputs", "[", "key", "]", ".", "append", "(", "[", "piece", "[", "key", "]", "]", "*", "encoding_length", ")", "\n", "\n", "# decoder input ids", "\n", "", "", "", "decoder_inputs", "=", "{", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "'loss_ids'", ":", "loss_ids", "}", "\n", "decoder_inputs", "=", "self", ".", "truncate_decoder_inputs", "(", "decoder_inputs", ")", "\n", "\n", "encoder_inputs", "=", "self", ".", "truncate", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "\n", "# delete shortenable ids", "\n", "encoder_inputs", ".", "pop", "(", "\"shortenable_ids\"", ")", "\n", "encoder_inputs", "=", "self", ".", "concate_parts", "(", "input_dict", "=", "encoder_inputs", ")", "\n", "encoder_inputs", "=", "self", ".", "add_special_tokens", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "\n", "# create special input ids", "\n", "encoder_inputs", "[", "'attention_mask'", "]", "=", "[", "1", "]", "*", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "# padding", "\n", "encoder_inputs", "=", "self", ".", "padding", "(", "input_dict", "=", "encoder_inputs", ",", "max_len", "=", "self", ".", "max_seq_length", ",", "pad_id_for_inputs", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "all_input_ids", "=", "{", "**", "encoder_inputs", ",", "**", "decoder_inputs", "}", "\n", "return", "all_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.T5LMTokenizerWrapper.truncate_decoder_inputs": [[246, 261], ["inputs[].append", "seq2seq.T5LMTokenizerWrapper.padding", "inputs[].insert", "inputs[].insert", "inputs[].append", "inputs[].append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding"], ["", "def", "truncate_decoder_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "decode_from_pad", ":", "\n", "            ", "inputs", "[", "'decoder_input_ids'", "]", ".", "insert", "(", "0", ",", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "inputs", "[", "'loss_ids'", "]", ".", "insert", "(", "0", ",", "0", ")", "\n", "\n", "", "for", "key", "in", "inputs", ":", "\n", "            ", "inputs", "[", "key", "]", "=", "inputs", "[", "key", "]", "[", ":", "self", ".", "decoder_max_length", "-", "1", "]", "\n", "\n", "", "inputs", "[", "'decoder_input_ids'", "]", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "if", "self", ".", "predict_eos", ":", "\n", "            ", "inputs", "[", "'loss_ids'", "]", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "inputs", "[", "'loss_ids'", "]", ".", "append", "(", "0", ")", "\n", "", "inputs", "=", "self", ".", "padding", "(", "inputs", ",", "max_len", "=", "self", ".", "decoder_max_length", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.__init__": [[274, 288], ["openprompt.plms.utils.TokenizerWrapper.__init__", "openprompt.utils.logging.logger.warning"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "truncate_method", ":", "Optional", "[", "str", "]", "=", "'tail'", ",", "\n", "decoder_max_length", ":", "Optional", "[", "int", "]", "=", "128", ",", "\n", "decode_from_start", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "predict_eos_token", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "max_seq_length", "=", "max_seq_length", ",", "tokenizer", "=", "tokenizer", ",", "truncate_method", "=", "truncate_method", ")", "\n", "self", ".", "decoder_max_length", "=", "decoder_max_length", "\n", "self", ".", "decode_from_start", "=", "decode_from_start", "\n", "self", ".", "predict_eos", "=", "predict_eos_token", "\n", "if", "self", ".", "create_token_type_ids", ":", "\n", "            ", "logger", ".", "warning", "(", "\"token_type_ids is not valid in T5. will be depreciated.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.mask_token": [[289, 291], ["None"], "methods", ["None"], ["", "", "def", "mask_token", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "additional_special_tokens", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.mask_token_ids": [[293, 295], ["None"], "methods", ["None"], ["", "def", "mask_token_ids", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "additional_special_tokens_ids", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.num_special_tokens_to_add": [[296, 301], ["hasattr", "seq2seq.CPM2TokenizerWrapper.tokenizer.num_special_tokens_to_add"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.num_special_tokens_to_add"], ["", "@", "property", "\n", "def", "num_special_tokens_to_add", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'_num_specials'", ")", ":", "\n", "            ", "self", ".", "_num_specials", "=", "self", ".", "tokenizer", ".", "num_special_tokens_to_add", "(", ")", "\n", "", "return", "self", ".", "_num_specials", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.tokenize_one_example": [[303, 375], ["collections.defaultdict", "enumerate", "seq2seq.CPM2TokenizerWrapper.truncate_decoder_inputs", "seq2seq.CPM2TokenizerWrapper.truncate", "seq2seq.CPM2TokenizerWrapper.pop", "seq2seq.CPM2TokenizerWrapper.concate_parts", "seq2seq.CPM2TokenizerWrapper.add_special_tokens", "seq2seq.CPM2TokenizerWrapper.padding", "isinstance", "len", "encoder_inputs[].append", "len", "decoder_input_ids.append", "seq2seq.CPM2TokenizerWrapper.tokenizer.encode", "decoder_input_ids.extend", "loss_ids.extend", "loss_ids.append", "decoder_input_ids.append", "loss_ids.append", "seq2seq.CPM2TokenizerWrapper.special_tokens_maps.keys", "seq2seq.CPM2TokenizerWrapper.tokenizer.encode", "encoder_inputs[].append", "seq2seq.CPM2TokenizerWrapper.mask_token_ids", "seq2seq.CPM2TokenizerWrapper.mask_token_ids", "seq2seq.CPM2TokenizerWrapper.mask_token_ids", "seq2seq.CPM2TokenizerWrapper.mask_token_ids", "KeyError", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.truncate_decoder_inputs", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.concate_parts", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids"], ["", "def", "tokenize_one_example", "(", "self", ",", "wrapped_example", ",", "teacher_forcing", ")", ":", "\n", "        ", "''' # TODO doesn't consider the situation that input has two parts\n        '''", "\n", "wrapped_example", ",", "others", "=", "wrapped_example", "\n", "\n", "if", "teacher_forcing", ":", "\n", "            ", "tgt_text", "=", "others", "[", "'tgt_text'", "]", "\n", "if", "isinstance", "(", "tgt_text", ",", "str", ")", ":", "\n", "                ", "tgt_text", "=", "[", "tgt_text", "]", "\n", "\n", "", "", "encoder_inputs", "=", "defaultdict", "(", "list", ")", "\n", "\n", "num_mask_token_used", "=", "0", "\n", "\n", "decoder_input_ids", "=", "[", "]", "\n", "loss_ids", "=", "[", "0", "]", "\n", "\n", "for", "piece_id", ",", "piece", "in", "enumerate", "(", "wrapped_example", ")", ":", "\n", "            ", "if", "piece", "[", "'text'", "]", "==", "self", ".", "template_mask_token", ":", "\n", "                ", "if", "teacher_forcing", ":", "\n", "                    ", "decoder_input_ids", ".", "append", "(", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", ")", "\n", "encode_text", "=", "[", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", "]", "\n", "tgt_text_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "\" \"", "+", "tgt_text", "[", "num_mask_token_used", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "decoder_input_ids", ".", "extend", "(", "tgt_text_ids", ")", "\n", "loss_ids", ".", "extend", "(", "[", "1", "]", "*", "len", "(", "tgt_text_ids", ")", ")", "\n", "# decoder_input_ids.append(self.mask_token_ids(num_mask_token_used+1))", "\n", "loss_ids", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                    ", "decoder_input_ids", ".", "append", "(", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", ")", "\n", "encode_text", "=", "[", "self", ".", "mask_token_ids", "(", "num_mask_token_used", ")", "]", "\n", "# decoder_input_ids.append(self.mask_token_ids(num_mask_token_used+1))", "\n", "loss_ids", "[", "-", "1", "]", "=", "1", "# shift loss_ids", "\n", "loss_ids", ".", "append", "(", "0", ")", "\n", "", "num_mask_token_used", "+=", "1", "\n", "", "else", ":", "\n", "                ", "if", "piece", "[", "'text'", "]", "in", "self", ".", "special_tokens_maps", ".", "keys", "(", ")", ":", "\n", "                    ", "to_replace", "=", "self", ".", "special_tokens_maps", "[", "piece", "[", "'text'", "]", "]", "\n", "if", "to_replace", "is", "not", "None", ":", "\n", "                        ", "piece", "[", "'text'", "]", "=", "to_replace", "\n", "", "else", ":", "\n", "                        ", "raise", "KeyError", "(", "\"This tokenizer doesn't specify {} token.\"", ".", "format", "(", "piece", "[", "'text'", "]", ")", ")", "\n", "\n", "", "", "if", "'soft_token_ids'", "in", "piece", "and", "piece", "[", "'soft_token_ids'", "]", "!=", "0", ":", "\n", "                    ", "encode_text", "=", "[", "0", "]", "# can be replace by any token, since these token will use their own embeddings", "\n", "", "else", ":", "\n", "                    ", "encode_text", "=", "self", ".", "tokenizer", ".", "encode", "(", "piece", "[", "'text'", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "", "encoding_length", "=", "len", "(", "encode_text", ")", "\n", "\n", "encoder_inputs", "[", "'input_ids'", "]", ".", "append", "(", "encode_text", ")", "\n", "for", "key", "in", "piece", ":", "\n", "                ", "if", "key", "not", "in", "[", "'text'", ",", "'loss_ids'", "]", ":", "\n", "                    ", "encoder_inputs", "[", "key", "]", ".", "append", "(", "[", "piece", "[", "key", "]", "]", "*", "encoding_length", ")", "\n", "\n", "# decoder input ids", "\n", "", "", "", "decoder_inputs", "=", "{", "'decoder_input_ids'", ":", "decoder_input_ids", ",", "'loss_ids'", ":", "loss_ids", "}", "\n", "decoder_inputs", "=", "self", ".", "truncate_decoder_inputs", "(", "decoder_inputs", ")", "\n", "\n", "encoder_inputs", "=", "self", ".", "truncate", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "\n", "# delete shortenable ids", "\n", "encoder_inputs", ".", "pop", "(", "\"shortenable_ids\"", ")", "\n", "encoder_inputs", "=", "self", ".", "concate_parts", "(", "input_dict", "=", "encoder_inputs", ")", "\n", "encoder_inputs", "=", "self", ".", "add_special_tokens", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "\n", "# create special input ids", "\n", "encoder_inputs", "[", "'attention_mask'", "]", "=", "[", "1", "]", "*", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "# padding", "\n", "encoder_inputs", "=", "self", ".", "padding", "(", "input_dict", "=", "encoder_inputs", ",", "max_len", "=", "self", ".", "max_seq_length", ",", "pad_id_for_inputs", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "all_input_ids", "=", "{", "**", "encoder_inputs", ",", "**", "decoder_inputs", "}", "\n", "return", "all_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.seq2seq.CPM2TokenizerWrapper.truncate_decoder_inputs": [[376, 389], ["seq2seq.CPM2TokenizerWrapper.padding", "inputs[].insert", "inputs[].insert", "inputs[].append", "inputs[].append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding"], ["", "def", "truncate_decoder_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "decode_from_start", ":", "\n", "            ", "inputs", "[", "'decoder_input_ids'", "]", ".", "insert", "(", "0", ",", "self", ".", "tokenizer", ".", "sod_token_id", ")", "\n", "inputs", "[", "'loss_ids'", "]", ".", "insert", "(", "0", ",", "0", ")", "\n", "\n", "", "for", "key", "in", "inputs", ":", "\n", "            ", "inputs", "[", "key", "]", "=", "inputs", "[", "key", "]", "[", ":", "self", ".", "decoder_max_length", "-", "1", "]", "\n", "\n", "", "if", "self", ".", "predict_eos", ":", "\n", "            ", "inputs", "[", "'decoder_input_ids'", "]", ".", "append", "(", "self", ".", "tokenizer", ".", "eos_token_id", ")", "\n", "inputs", "[", "'loss_ids'", "]", ".", "append", "(", "1", ")", "\n", "", "inputs", "=", "self", ".", "padding", "(", "inputs", ",", "max_len", "=", "self", ".", "decoder_max_length", ",", "pad_id_for_inputs", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.get_model_class": [[68, 70], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.load_plm": [[72, 102], ["__init__.get_model_class", "get_model_class.config.from_pretrained", "get_model_class.model.from_pretrained", "get_model_class.tokenizer.from_pretrained", "__init__.add_special_tokens"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.get_model_class", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.load_plm_from_config": [[103, 130], ["__init__.get_model_class", "get_model_class.config.from_pretrained", "get_model_class.model.from_pretrained", "get_model_class.tokenizer.from_pretrained", "__init__.add_special_tokens", "config.plm.specials_to_add.append"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.get_model_class", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.__init__.add_special_tokens": [[131, 156], ["token.lower", "tokenizer.add_special_tokens", "model.resize_token_embeddings", "openprompt.utils.logging.logger.info", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.__init__": [[20, 28], ["openprompt.plms.utils.TokenizerWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__"], ["def", "__init__", "(", "self", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "truncate_method", ":", "Optional", "[", "str", "]", "=", "'tail'", ",", "\n", "predict_eos_token", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "max_seq_length", "=", "max_seq_length", ",", "tokenizer", "=", "tokenizer", ",", "truncate_method", "=", "truncate_method", ")", "\n", "self", ".", "predict_eos", "=", "predict_eos_token", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.num_special_tokens_to_add": [[29, 34], ["hasattr", "lm.LMTokenizerWrapper.tokenizer.num_special_tokens_to_add"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.num_special_tokens_to_add"], ["", "@", "property", "\n", "def", "num_special_tokens_to_add", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'_num_specials'", ")", ":", "\n", "            ", "self", ".", "_num_specials", "=", "self", ".", "tokenizer", ".", "num_special_tokens_to_add", "(", ")", "\n", "", "return", "self", ".", "_num_specials", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.lm.LMTokenizerWrapper.tokenize_one_example": [[36, 107], ["collections.defaultdict", "enumerate", "lm.LMTokenizerWrapper.truncate", "lm.LMTokenizerWrapper.pop", "lm.LMTokenizerWrapper.concate_parts", "lm.LMTokenizerWrapper.add_special_tokens", "len", "lm.LMTokenizerWrapper.padding", "isinstance", "len", "encoder_inputs[].append", "len", "[].endswith", "wrapped_example.append", "len", "lm.LMTokenizerWrapper.special_tokens_maps.keys", "lm.LMTokenizerWrapper.tokenizer.encode", "len", "KeyError", "encoder_inputs[].append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.concate_parts", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["", "def", "tokenize_one_example", "(", "self", ",", "wrapped_example", ",", "teacher_forcing", ")", ":", "\n", "        ", "''' # TODO doesn't consider the situation that input has two parts\n        '''", "\n", "wrapped_example", ",", "others", "=", "wrapped_example", "\n", "\n", "if", "teacher_forcing", ":", "\n", "\n", "            ", "tgt_text", "=", "others", "[", "'tgt_text'", "]", "\n", "if", "isinstance", "(", "tgt_text", ",", "str", ")", ":", "\n", "                ", "tgt_text", "=", "[", "tgt_text", "]", "\n", "\n", "", "", "if", "self", ".", "predict_eos", ":", "\n", "            ", "if", "not", "wrapped_example", "[", "-", "1", "]", "[", "'text'", "]", ".", "endswith", "(", "self", ".", "tokenizer", ".", "eos_token", ")", ":", "\n", "                ", "wrapped_example", ".", "append", "(", "{", "\"text\"", ":", "self", ".", "tokenizer", ".", "eos_token", ",", "\"shortenable_ids\"", ":", "0", ",", "\"loss_ids\"", ":", "1", "}", ")", "\n", "\n", "", "", "encoder_inputs", "=", "defaultdict", "(", "list", ")", "\n", "\n", "num_mask_token_used", "=", "0", "\n", "\n", "for", "piece_id", ",", "piece", "in", "enumerate", "(", "wrapped_example", ")", ":", "\n", "            ", "if", "len", "(", "piece", "[", "'text'", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "piece", "[", "'text'", "]", "==", "self", ".", "tokenizer", ".", "eos_token", "and", "self", ".", "predict_eos", "and", "wrapped_example", "[", "piece_id", "-", "1", "]", "[", "'loss_ids'", "]", "==", "1", ":", "# eos after the mask also need to be pred", "\n", "                ", "piece", "[", "'loss_ids'", "]", "=", "1", "\n", "\n", "", "if", "piece", "[", "'text'", "]", "==", "self", ".", "template_mask_token", ":", "\n", "                ", "if", "teacher_forcing", ":", "\n", "                    ", "piece", "[", "'text'", "]", "=", "\" \"", "+", "tgt_text", "[", "num_mask_token_used", "]", "+", "\" \"", "\n", "", "else", ":", "\n", "                    ", "encoder_inputs", "[", "'loss_ids'", "]", "[", "-", "1", "]", "[", "-", "1", "]", "=", "1", "\n", "break", "\n", "\n", "", "", "if", "piece", "[", "'text'", "]", "in", "self", ".", "special_tokens_maps", ".", "keys", "(", ")", ":", "\n", "                ", "to_replace", "=", "self", ".", "special_tokens_maps", "[", "piece", "[", "'text'", "]", "]", "\n", "if", "to_replace", "is", "not", "None", ":", "\n", "                    ", "piece", "[", "'text'", "]", "=", "to_replace", "\n", "", "else", ":", "\n", "                    ", "raise", "KeyError", "(", "\"This tokenizer doesn't specify {} token.\"", ".", "format", "(", "piece", "[", "'text'", "]", ")", ")", "\n", "\n", "", "", "if", "'soft_token_ids'", "in", "piece", "and", "piece", "[", "'soft_token_ids'", "]", "!=", "0", ":", "\n", "                ", "encode_text", "=", "[", "0", "]", "# can be replace by any token, since these token will use their own embeddings", "\n", "", "else", ":", "\n", "                ", "encode_text", "=", "self", ".", "tokenizer", ".", "encode", "(", "piece", "[", "'text'", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "encoding_length", "=", "len", "(", "encode_text", ")", "\n", "\n", "encoder_inputs", "[", "'input_ids'", "]", ".", "append", "(", "encode_text", ")", "\n", "for", "key", "in", "piece", ":", "\n", "                ", "if", "key", "not", "in", "[", "'text'", "]", ":", "\n", "                    ", "encoder_inputs", "[", "key", "]", ".", "append", "(", "[", "piece", "[", "key", "]", "]", "*", "encoding_length", ")", "\n", "\n", "", "", "", "encoder_inputs", "=", "self", ".", "truncate", "(", "encoder_inputs", "=", "encoder_inputs", ")", "\n", "\n", "# delete shortenable ids", "\n", "encoder_inputs", ".", "pop", "(", "\"shortenable_ids\"", ")", "\n", "encoder_inputs", "=", "self", ".", "concate_parts", "(", "input_dict", "=", "encoder_inputs", ")", "\n", "encoder_inputs", "=", "self", ".", "add_special_tokens", "(", "encoder_inputs", "=", "encoder_inputs", ")", "# this will do nothing in GPT2 tokenizer", "\n", "# create special input ids", "\n", "encoder_inputs", "[", "'attention_mask'", "]", "=", "[", "1", "]", "*", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "if", "self", ".", "create_token_type_ids", ":", "\n", "            ", "encoder_inputs", "[", "'token_type_ids'", "]", "=", "[", "0", "]", "*", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "# pad to max length", "\n", "", "input_ids_len", "=", "len", "(", "encoder_inputs", "[", "'input_ids'", "]", ")", "\n", "encoder_inputs", "=", "self", ".", "padding", "(", "\n", "input_dict", "=", "encoder_inputs", ",", "\n", "max_len", "=", "self", ".", "max_seq_length", ",", "\n", "pad_id_for_inputs", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", ")", "\n", "encoder_inputs", "=", "{", "**", "encoder_inputs", ",", "\"input_ids_len\"", ":", "input_ids_len", "}", "\n", "return", "encoder_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.__init__": [[15, 55], ["logging.get_verbosity", "logging.set_verbosity", "logging.set_verbosity", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["    ", "r\"\"\"round a list of float e.g. [0.2,1.5, 4.5]\n    to [1,2,4] # ceil and restrict the sum to `max_sum`\n    used into balanced truncate.\n    \"\"\"", "\n", "s", "=", "0", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "l", ")", ":", "\n", "        ", "i", "=", "ceil", "(", "i", ")", "\n", "if", "s", "<=", "max_sum", ":", "\n", "            ", "s", "+=", "i", "\n", "if", "s", "<=", "max_sum", ":", "\n", "                ", "l", "[", "idx", "]", "=", "i", "\n", "", "else", ":", "\n", "                ", "l", "[", "idx", "]", "=", "i", "-", "(", "s", "-", "max_sum", ")", "\n", "", "", "else", ":", "\n", "            ", "l", "[", "idx", "]", "=", "int", "(", "0", ")", "\n", "", "", "assert", "sum", "(", "l", ")", "==", "max_sum", "\n", "\n", "\n", "", "def", "signature", "(", "f", ")", ":", "\n", "    ", "r\"\"\"Get the function f 's input arguments. A useful gadget\n    when some function slot might be instantiated into multiple functions.\n    \n    Args:\n        f (:obj:`function`) : the function to get the input arguments.\n    \n    Returns:\n        namedtuple : of args, default, varargs, keywords, respectively.s\n\n    \"\"\"", "\n", "sig", "=", "inspect", ".", "signature", "(", "f", ")", "\n", "args", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "POSITIONAL_OR_KEYWORD", "\n", "]", "\n", "varargs", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "VAR_POSITIONAL", "\n", "]", "\n", "varargs", "=", "varargs", "[", "0", "]", "if", "varargs", "else", "None", "\n", "keywords", "=", "[", "\n", "p", ".", "name", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate_rate": [[56, 64], ["None"], "methods", ["None"], ["if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "VAR_KEYWORD", "\n", "]", "\n", "keywords", "=", "keywords", "[", "0", "]", "if", "keywords", "else", "None", "\n", "defaults", "=", "[", "\n", "p", ".", "default", "for", "p", "in", "sig", ".", "parameters", ".", "values", "(", ")", "\n", "if", "p", ".", "kind", "==", "inspect", ".", "Parameter", ".", "POSITIONAL_OR_KEYWORD", "\n", "and", "p", ".", "default", "is", "not", "p", ".", "empty", "\n", "]", "or", "None", "\n", "argspec", "=", "namedtuple", "(", "'Signature'", ",", "[", "'args'", ",", "'defaults'", ",", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.special_tokens_maps": [[65, 75], ["hasattr", "utils.TokenizerWrapper.__dict__.keys", "attrname.endswith", "_special_tokens_map.update", "getattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.keys"], ["'varargs'", ",", "'keywords'", "]", ")", "\n", "return", "argspec", "(", "args", ",", "defaults", ",", "varargs", ",", "keywords", ")", "\n", "\n", "", "def", "check_config_conflicts", "(", "config", ":", "CfgNode", ")", ":", "\n", "    ", "r\"\"\"check the conflicts of global config.\n    \"\"\"", "\n", "if", "config", ".", "task", "==", "\"generation\"", ":", "\n", "        ", "assert", "config", "[", "'train'", "]", ".", "teacher_forcing", "==", "True", ",", "\"You should use teacher forcing to train generation!\"", "\n", "\n", "", "if", "config", ".", "task", "==", "\"generation\"", ":", "\n", "        ", "if", "config", ".", "dataloader", ".", "max_seq_length", ">=", "config", ".", "generation", ".", "max_length", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.tokenize_with_mask": [[76, 80], ["None"], "methods", ["None"], ["            ", "logger", ".", "warning", "(", "\"In generation, your config.generation.max_length is shorter than config.max_seq_length\"", "\n", "\"This can lead to unexpected behavior. You should consider increasing ``config.generation.max_length``.\"", "\n", ")", "\n", "raise", "RuntimeError", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.tokenize_without_mask": [[81, 85], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.balanced_truncate": [[86, 104], ["sum", "openprompt.utils.round_list", "collections.defaultdict", "zip", "len", "truncated_example[].append", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.utils.round_list"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate_from_tail": [[105, 126], ["collections.defaultdict", "enumerate", "len", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate_from_head": [[127, 146], ["collections.defaultdict", "enumerate", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.concate_parts": [[147, 152], ["list", "itertools.chain"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.padding": [[153, 166], ["input_dict.items", "len", "ValueError", "input_dict[].extend", "input_dict[].extend", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.items"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.add_special_tokens": [[168, 184], ["numpy.array", "numpy.array", "warnings.catch_warnings", "warnings.simplefilter", "utils.TokenizerWrapper.tokenizer.build_inputs_with_special_tokens", "utils.TokenizerWrapper.tokenizer.get_special_tokens_mask", "utils.TokenizerWrapper.tokenizer.build_inputs_with_special_tokens"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.plms.utils.TokenizerWrapper.truncate": [[185, 195], ["sum", "utils.TokenizerWrapper.truncate_fct", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.source.conf.setup": [[60, 78], ["app.connect", "app.connect", "app.builder.templates.render_string"], "function", ["None"], ["def", "setup", "(", "app", ")", ":", "\n", "    ", "def", "skip", "(", "app", ",", "what", ",", "name", ",", "obj", ",", "skip", ",", "options", ")", ":", "\n", "        ", "members", "=", "[", "\n", "'__init__'", ",", "\n", "'__repr__'", ",", "\n", "'__weakref__'", ",", "\n", "'__dict__'", ",", "\n", "'__module__'", ",", "\n", "]", "\n", "return", "True", "if", "name", "in", "members", "else", "skip", "\n", "\n", "", "def", "rst_jinja_render", "(", "app", ",", "docname", ",", "source", ")", ":", "\n", "        ", "src", "=", "source", "[", "0", "]", "\n", "rendered", "=", "app", ".", "builder", ".", "templates", ".", "render_string", "(", "src", ",", "rst_context", ")", "\n", "source", "[", "0", "]", "=", "rendered", "\n", "\n", "", "app", ".", "connect", "(", "'autodoc-skip-member'", ",", "skip", ")", "\n", "app", ".", "connect", "(", "\"source-read\"", ",", "rst_jinja_render", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.1.evaluate": [[274, 288], ["prompt_model.eval", "enumerate", "prompt_model", "alllabels.extend", "allpreds.extend", "sum", "len", "inputs.cuda.cuda", "labels.cpu().tolist", "torch.argmax().cpu().tolist", "int", "labels.cpu", "torch.argmax().cpu", "zip", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.2.evaluate": [[100, 114], ["prompt_model.eval", "enumerate", "openprompt.utils.metrics.generation_metric", "print", "prompt_model.generate", "generated_sentence.extend", "groundtruth_sentence.extend", "inputs.cuda.cuda"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.utils.metrics.generation_metric", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.4.evaluate": [[291, 308], ["enumerate", "print", "openprompt.utils.crossfit_metrics.evaluate", "prompt_model.generate", "predictions.extend", "ground_truths.extend", "len", "len", "len", "len", "prediction.strip", "ground_truth.strip", "inputs.cuda.cuda"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.evaluate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token": [[49, 51], ["None"], "methods", ["None"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.T5BertTokenizerWrapper.mask_token_ids": [[52, 54], ["6.T5BertTokenizerWrapper.tokenizer.convert_tokens_to_ids"], "methods", ["None"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.load_local_dataset": [[75, 88], ["open", "fin.readlines", "json.loads", "enumerate", "json.loads.pop", "data.append", "openprompt.data_utils.utils.InputExample", "int"], "function", ["None"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.6.evaluate": [[125, 142], ["enumerate", "print", "prompt_model.generate", "predictions.extend", "ground_truths.extend", "len", "len", "len", "len", "prediction.strip", "ground_truth.strip", "sum", "len", "inputs.cuda.cuda", "zip", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.prompts.prompt_generator.VerbalizerGenerator.generate", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.fit": [[64, 72], ["range", "3.train_epoch", "3.evaluate"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.train_epoch", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.evaluate"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.train_epoch": [[74, 85], ["model.train", "enumerate", "model", "loss_func", "loss_func.backward", "optimizer.step", "optimizer.zero_grad", "inputs.cuda.cuda"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.openprompt.pipeline_base.PromptModel.train", "home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda"]], "home.repos.pwc.inspect_result.thunlp_OpenPrompt.tutorial.3.evaluate": [[86, 100], ["model.eval", "torch.no_grad", "enumerate", "sum", "len", "model", "alllabels.extend", "allpreds.extend", "inputs.cuda.cuda", "labels.cpu().tolist", "torch.argmax().cpu().tolist", "int", "zip", "labels.cpu", "torch.argmax().cpu", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenPrompt.data_utils.utils.InputFeatures.cuda"]]}