{"home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_model_config_args": [[25, 65], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["def", "add_model_config_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"Model arguments\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'model'", ",", "'model configuration'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--attention-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "'dropout probability for attention weights'", ")", "\n", "group", ".", "add_argument", "(", "'--num-attention-heads'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "'num of transformer attention heads'", ")", "\n", "group", ".", "add_argument", "(", "'--hidden-size'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "'tansformer hidden size'", ")", "\n", "group", ".", "add_argument", "(", "'--num-layers'", ",", "type", "=", "int", ",", "default", "=", "24", ",", "\n", "help", "=", "'num decoder layers'", ")", "\n", "group", ".", "add_argument", "(", "'--layernorm-epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "\n", "help", "=", "'layer norm epsilon'", ")", "\n", "group", ".", "add_argument", "(", "'--hidden-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "'dropout probability for hidden state transformer'", ")", "\n", "group", ".", "add_argument", "(", "'--max-position-embeddings'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'maximum number of position embeddings to use'", ")", "\n", "group", ".", "add_argument", "(", "'--vocab-size'", ",", "type", "=", "int", ",", "default", "=", "30522", ",", "\n", "help", "=", "'vocab size to use for non-character-level '", "\n", "'tokenization. This value will only be used when '", "\n", "'creating a tokenizer'", ")", "\n", "group", ".", "add_argument", "(", "'--deep-init'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'initialize bert model similar to gpt2 model.'", "\n", "'scales initialization of projection layers by a '", "\n", "'factor of 1/sqrt(2N). Necessary to train bert '", "\n", "'models larger than BERT-Large.'", ")", "\n", "group", ".", "add_argument", "(", "'--make-vocab-size-divisible-by'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "'Pad the vocab size to be divisible by this value.'", "\n", "'This is added for computational efficieny reasons.'", ")", "\n", "group", ".", "add_argument", "(", "'--cpu-optimizer'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Run optimizer on CPU'", ")", "\n", "group", ".", "add_argument", "(", "'--cpu_torch_adam'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Use Torch Adam as optimizer on CPU.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--max-position-embeddings-finetune'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'maximum number of position embeddings to use in finetune'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_fp16_config_args": [[67, 94], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_fp16_config_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"Mixed precision arguments.\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'fp16'", ",", "'fp16 configurations'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Run model in fp16 mode'", ")", "\n", "group", ".", "add_argument", "(", "'--fp32-embedding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'embedding in fp32'", ")", "\n", "group", ".", "add_argument", "(", "'--fp32-layernorm'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'layer norm in fp32'", ")", "\n", "group", ".", "add_argument", "(", "'--fp32-tokentypes'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'embedding token types in fp32'", ")", "\n", "group", ".", "add_argument", "(", "'--fp32-allreduce'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'all-reduce in fp32'", ")", "\n", "group", ".", "add_argument", "(", "'--hysteresis'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'hysteresis for dynamic loss scaling'", ")", "\n", "group", ".", "add_argument", "(", "'--loss-scale'", ",", "type", "=", "float", ",", "default", "=", "None", ",", "\n", "help", "=", "'Static loss scaling, positive power of 2 '", "\n", "'values can improve fp16 convergence. If None, dynamic'", "\n", "'loss scaling is used.'", ")", "\n", "group", ".", "add_argument", "(", "'--loss-scale-window'", ",", "type", "=", "float", ",", "default", "=", "1000", ",", "\n", "help", "=", "'Window over which to raise/lower dynamic scale'", ")", "\n", "group", ".", "add_argument", "(", "'--min-scale'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Minimum loss scale for dynamic loss scale'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_training_args": [[96, 186], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_training_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"Training arguments.\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'train'", ",", "'training configurations'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--experiment-name'", ",", "type", "=", "str", ",", "default", "=", "\"CogView\"", ",", "\n", "help", "=", "\"The experiment name for summary and checkpoint\"", ")", "\n", "group", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "'Data Loader batch size'", ")", "\n", "group", ".", "add_argument", "(", "'--weight-decay'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "'weight decay coefficient for L2 regularization'", ")", "\n", "group", ".", "add_argument", "(", "'--checkpoint-activations'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'checkpoint activation to allow for training '", "\n", "'with larger models and sequences'", ")", "\n", "group", ".", "add_argument", "(", "'--checkpoint-num-layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'chunk size (number of layers) for checkpointing'", ")", "\n", "group", ".", "add_argument", "(", "'--deepspeed-activation-checkpointing'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'uses activation checkpointing from deepspeed'", ")", "\n", "group", ".", "add_argument", "(", "'--clip-grad'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'gradient clipping'", ")", "\n", "group", ".", "add_argument", "(", "'--train-iters'", ",", "type", "=", "int", ",", "default", "=", "1000000", ",", "\n", "help", "=", "'total number of iterations to train over all training runs'", ")", "\n", "group", ".", "add_argument", "(", "'--log-interval'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'report interval'", ")", "\n", "group", ".", "add_argument", "(", "'--exit-interval'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Exit the program after this many new iterations.'", ")", "\n", "group", ".", "add_argument", "(", "'--summary-dir'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"The directory to store the summary\"", ")", "\n", "group", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ",", "\n", "help", "=", "'random seed'", ")", "\n", "group", ".", "add_argument", "(", "'--img-tokenizer-path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'The checkpoint file path of image tokenizer.'", ")", "\n", "group", ".", "add_argument", "(", "'--img-tokenizer-num-tokens'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'The num tokens of image tokenizer. ONLY use for pretraining with img-tokenizer UNKNOW.'", ")", "\n", "# Batch prodecuer arguments", "\n", "group", ".", "add_argument", "(", "'--reset-position-ids'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Reset posistion ids after end-of-document token.'", ")", "\n", "group", ".", "add_argument", "(", "'--reset-attention-mask'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Reset self attention maske after '", "\n", "'end-of-document token.'", ")", "\n", "\n", "# Learning rate.", "\n", "group", ".", "add_argument", "(", "'--lr-decay-iters'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'number of iterations to decay LR over,'", "\n", "' If None defaults to `--train-iters`*`--epochs`'", ")", "\n", "group", ".", "add_argument", "(", "'--lr-decay-style'", ",", "type", "=", "str", ",", "default", "=", "'linear'", ",", "\n", "choices", "=", "[", "'constant'", ",", "'linear'", ",", "'cosine'", ",", "'exponential'", "]", ",", "\n", "help", "=", "'learning rate decay function'", ")", "\n", "group", ".", "add_argument", "(", "'--lr-decay-ratio'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "group", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1.0e-4", ",", "\n", "help", "=", "'initial learning rate'", ")", "\n", "group", ".", "add_argument", "(", "'--warmup'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "'percentage of data to warmup on (.01 = 1% of all '", "\n", "'training iters). Default 0.01'", ")", "\n", "# model checkpointing", "\n", "group", ".", "add_argument", "(", "'--save'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'Output directory to save checkpoints to.'", ")", "\n", "group", ".", "add_argument", "(", "'--save-interval'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "'number of iterations between saves'", ")", "\n", "group", ".", "add_argument", "(", "'--no-save-optim'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Do not save current optimizer.'", ")", "\n", "group", ".", "add_argument", "(", "'--no-save-rng'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Do not save current rng state.'", ")", "\n", "group", ".", "add_argument", "(", "'--load'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'Path to a directory containing a model checkpoint.'", ")", "\n", "group", ".", "add_argument", "(", "'--no-load-optim'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Do not load optimizer when loading checkpoint.'", ")", "\n", "group", ".", "add_argument", "(", "'--no-load-rng'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Do not load rng state when loading checkpoint.'", ")", "\n", "group", ".", "add_argument", "(", "'--finetune'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Load model for finetuning. Do not load optimizer '", "\n", "'or rng state from checkpoint and set iteration to 0. '", "\n", "'Assumed when loading a release checkpoint.'", ")", "\n", "group", ".", "add_argument", "(", "'--resume-dataloader'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Resume the dataloader when resuming training. '", "\n", "'Does not apply to tfrecords dataloader, try resuming'", "\n", "'with a different seed in this case.'", ")", "\n", "# distributed training args", "\n", "group", ".", "add_argument", "(", "'--distributed-backend'", ",", "default", "=", "'nccl'", ",", "\n", "help", "=", "'which backend to use for distributed '", "\n", "'training. One of [gloo, nccl]'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'local rank passed from distributed launcher'", ")", "\n", "\n", "# loss scale", "\n", "group", ".", "add_argument", "(", "'--txt-loss-scale'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "group", ".", "add_argument", "(", "'--fast-load'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'load checkpoints without locks.'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_evaluation_args": [[188, 203], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_evaluation_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"Evaluation arguments.\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'validation'", ",", "'validation configurations'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--eval-batch-size'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Data Loader batch size for evaluation datasets.'", "\n", "'Defaults to `--batch-size`'", ")", "\n", "group", ".", "add_argument", "(", "'--eval-iters'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'number of iterations to run for evaluation'", "\n", "'validation/test for'", ")", "\n", "group", ".", "add_argument", "(", "'--eval-interval'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "'interval between running evaluation on validation set'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_text_generate_args": [[205, 233], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_text_generate_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"Text generate arguments.\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Text generation'", ",", "'configurations'", ")", "\n", "group", ".", "add_argument", "(", "\"--temperature\"", ",", "type", "=", "float", ",", "default", "=", "1.0", ")", "\n", "group", ".", "add_argument", "(", "\"--top_p\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "group", ".", "add_argument", "(", "\"--top_k\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "# group.add_argument(\"--out-seq-length\", type=int, default=256)", "\n", "group", ".", "add_argument", "(", "\"--generation-task\"", ",", "type", "=", "str", ",", "\n", "default", "=", "'text2image'", ",", "\n", "choices", "=", "[", "'text2image'", ",", "\n", "'image2text'", ",", "\n", "'super-resolution'", ",", "\n", "'low-level super-resolution'", ",", "\n", "'post-selection'", ",", "\n", "'raw'", "\n", "]", ",", "\n", "help", "=", "'what type of inference task to use'", ")", "\n", "group", ".", "add_argument", "(", "'--input-source'", ",", "type", "=", "str", ",", "default", "=", "'interactive'", ",", "\n", "help", "=", "'what input mode to use, interactive or path'", ")", "\n", "group", ".", "add_argument", "(", "'--output-path'", ",", "type", "=", "str", ",", "default", "=", "'./samples'", ",", "\n", "help", "=", "'path to place the generated samples'", ")", "\n", "group", ".", "add_argument", "(", "'--debug'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Debug will merge all outputs.'", ")", "\n", "group", ".", "add_argument", "(", "'--with-id'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If each line is prepended with an id.'", ")", "\n", "group", ".", "add_argument", "(", "'--max-inference-batch-size'", ",", "type", "=", "int", ",", "default", "=", "12", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_data_args": [[235, 274], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_data_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"Train/valid/test data arguments.\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'data'", ",", "'data configurations'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--model-parallel-size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'size of the model parallel.'", ")", "\n", "group", ".", "add_argument", "(", "'--shuffle'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Shuffle data. Shuffling is deterministic '", "\n", "'based on seed and current epoch.'", ")", "\n", "group", ".", "add_argument", "(", "'--train-data'", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Whitespace separated filenames or corpora names '", "\n", "'for training.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--valid-data'", ",", "nargs", "=", "'*'", ",", "default", "=", "None", ",", "\n", "help", "=", "\"\"\"Filename for validation data.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'--split'", ",", "default", "=", "'1000,1,1'", ",", "\n", "help", "=", "'comma-separated list of proportions for training,'", "\n", "' validation, and test split'", ")", "\n", "group", ".", "add_argument", "(", "'--test-data'", ",", "nargs", "=", "'*'", ",", "default", "=", "None", ",", "\n", "help", "=", "\"\"\"Filename for testing\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--num-workers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "\"\"\"Number of workers to use for dataloading\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--dataset-type'", ",", "type", "=", "str", ",", "\n", "default", "=", "'TokenizedDataset'", ",", "\n", "choices", "=", "[", "'TokenizedDataset'", ",", "\n", "'TextCodeDataset'", ",", "\n", "'CompactBinaryDataset'", "\n", "]", ",", "\n", "help", "=", "'what type of dataset to use'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--max-memory-length'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "\"max memory buffer for attention\"", ")", "\n", "group", ".", "add_argument", "(", "'--new-dataset-path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'The folder we will dynamically check for lmdbs during training.'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_generation_api_args": [[275, 288], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_generation_api_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"generation api arguments\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'api'", ",", "'api configurations'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--img_folder_path'", ",", "default", "=", "'image/'", ")", "\n", "group", ".", "add_argument", "(", "'--input_folder_path'", ",", "default", "=", "'input/'", ")", "\n", "group", ".", "add_argument", "(", "'--input_rec_path'", ",", "default", "=", "'input/'", ")", "\n", "group", ".", "add_argument", "(", "'--check_mode'", ",", "default", "=", "'code'", ")", "\n", "group", ".", "add_argument", "(", "'--time_interval'", ",", "default", "=", "10", ")", "\n", "group", ".", "add_argument", "(", "'--device'", ",", "default", "=", "None", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_sparse_args": [[289, 300], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "add_sparse_args", "(", "parser", ")", ":", "\n", "    ", "\"\"\"sparse attention arguments.\"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Sparse Attention'", ",", "'sparse configurations'", ")", "\n", "group", ".", "add_argument", "(", "'--is-sparse'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "choices", "=", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "help", "=", "'whether use sparse attention. 0 not 1 train 2 inference'", ")", "# TODO: Temporally not using is-sparse==2 (not optimized), use 0 for inference.", "\n", "group", ".", "add_argument", "(", "\"--query-window\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "group", ".", "add_argument", "(", "\"--key-window-times\"", ",", "type", "=", "int", ",", "default", "=", "6", ")", "\n", "group", ".", "add_argument", "(", "\"--num-pivot\"", ",", "type", "=", "int", ",", "default", "=", "768", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.get_args": [[301, 376], ["argparse.ArgumentParser", "arguments.add_model_config_args", "arguments.add_fp16_config_args", "arguments.add_training_args", "arguments.add_evaluation_args", "arguments.add_text_generate_args", "arguments.add_data_args", "arguments.add_generation_api_args", "arguments.add_sparse_args", "deepspeed.add_config_arguments", "deepspeed.add_config_arguments.parse_args", "torch.cuda.is_available", "int", "int", "min", "print", "os.getenv", "os.getenv", "hasattr", "arguments.mpi_define_env", "os.getenv", "print", "hasattr", "ValueError", "int", "int", "int", "int", "print", "open", "json.load", "deepspeed_config[].get", "deepspeed_config[].get.get", "deepspeed_config[].get.get", "os.getenv", "os.getenv", "os.getenv", "os.getenv"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_model_config_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_fp16_config_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_training_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_evaluation_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_text_generate_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_data_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_generation_api_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.add_sparse_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.mpi_define_env"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "\"\"\"Parse all the args.\"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch CogView Model'", ")", "\n", "parser", "=", "add_model_config_args", "(", "parser", ")", "\n", "parser", "=", "add_fp16_config_args", "(", "parser", ")", "\n", "parser", "=", "add_training_args", "(", "parser", ")", "\n", "parser", "=", "add_evaluation_args", "(", "parser", ")", "\n", "parser", "=", "add_text_generate_args", "(", "parser", ")", "\n", "parser", "=", "add_data_args", "(", "parser", ")", "\n", "parser", "=", "add_generation_api_args", "(", "parser", ")", "\n", "parser", "=", "add_sparse_args", "(", "parser", ")", "\n", "\n", "# Include DeepSpeed configuration arguments", "\n", "parser", "=", "deepspeed", ".", "add_config_arguments", "(", "parser", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "not", "args", ".", "train_data", ":", "\n", "        ", "print", "(", "'WARNING: No training data specified'", ")", "\n", "assert", "args", ".", "is_sparse", "!=", "1", ",", "'use is-sparse == 2 for inference'", "\n", "", "elif", "args", ".", "is_sparse", "==", "1", "and", "(", "args", ".", "max_position_embeddings", "-", "1", ")", "%", "args", ".", "query_window", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'During sparse training, the sequence length must be exactly divided by window_size.'", ")", "\n", "\n", "", "args", ".", "cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "args", ".", "rank", "=", "int", "(", "os", ".", "getenv", "(", "'RANK'", ",", "'0'", ")", ")", "\n", "args", ".", "world_size", "=", "int", "(", "os", ".", "getenv", "(", "\"WORLD_SIZE\"", ",", "'1'", ")", ")", "\n", "if", "hasattr", "(", "args", ",", "'deepspeed_mpi'", ")", "and", "args", ".", "deepspeed_mpi", ":", "\n", "        ", "mpi_define_env", "(", "args", ")", "\n", "", "elif", "os", ".", "getenv", "(", "'OMPI_COMM_WORLD_LOCAL_RANK'", ")", ":", "\n", "# We are using (OpenMPI) mpirun for launching distributed data parallel processes", "\n", "        ", "local_rank", "=", "int", "(", "os", ".", "getenv", "(", "'OMPI_COMM_WORLD_LOCAL_RANK'", ")", ")", "\n", "local_size", "=", "int", "(", "os", ".", "getenv", "(", "'OMPI_COMM_WORLD_LOCAL_SIZE'", ")", ")", "\n", "\n", "# Possibly running with Slurm", "\n", "num_nodes", "=", "int", "(", "os", ".", "getenv", "(", "'SLURM_JOB_NUM_NODES'", ",", "'1'", ")", ")", "\n", "nodeid", "=", "int", "(", "os", ".", "getenv", "(", "'SLURM_NODEID'", ",", "'0'", ")", ")", "\n", "\n", "args", ".", "local_rank", "=", "local_rank", "\n", "args", ".", "rank", "=", "nodeid", "*", "local_size", "+", "local_rank", "\n", "args", ".", "world_size", "=", "num_nodes", "*", "local_size", "\n", "\n", "", "args", ".", "model_parallel_size", "=", "min", "(", "args", ".", "model_parallel_size", ",", "args", ".", "world_size", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "print", "(", "'using world size: {} and model-parallel size: {} '", ".", "format", "(", "\n", "args", ".", "world_size", ",", "args", ".", "model_parallel_size", ")", ")", "\n", "\n", "", "args", ".", "dynamic_loss_scale", "=", "False", "\n", "if", "args", ".", "loss_scale", "is", "None", ":", "\n", "        ", "args", ".", "dynamic_loss_scale", "=", "True", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "print", "(", "' > using dynamic loss scaling'", ")", "\n", "\n", "# The args fp32_* or fp16_* meant to be active when the", "\n", "# args fp16 is set. So the default behaviour should all", "\n", "# be false.", "\n", "", "", "if", "not", "args", ".", "fp16", ":", "\n", "        ", "args", ".", "fp32_embedding", "=", "False", "\n", "args", ".", "fp32_tokentypes", "=", "False", "\n", "args", ".", "fp32_layernorm", "=", "False", "\n", "\n", "", "if", "hasattr", "(", "args", ",", "\"deepspeed\"", ")", "and", "args", ".", "deepspeed", "and", "args", ".", "deepspeed_config", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "args", ".", "deepspeed_config", ")", "as", "file", ":", "\n", "            ", "deepspeed_config", "=", "json", ".", "load", "(", "file", ")", "\n", "", "if", "\"train_micro_batch_size_per_gpu\"", "in", "deepspeed_config", ":", "\n", "            ", "args", ".", "batch_size", "=", "deepspeed_config", "[", "\"train_micro_batch_size_per_gpu\"", "]", "\n", "", "if", "\"gradient_accumulation_steps\"", "in", "deepspeed_config", ":", "\n", "            ", "args", ".", "gradient_accumulation_steps", "=", "deepspeed_config", "[", "\"gradient_accumulation_steps\"", "]", "\n", "", "else", ":", "\n", "            ", "args", ".", "gradient_accumulation_steps", "=", "None", "\n", "", "if", "\"optimizer\"", "in", "deepspeed_config", ":", "\n", "            ", "optimizer_params_config", "=", "deepspeed_config", "[", "\"optimizer\"", "]", ".", "get", "(", "\"params\"", ",", "{", "}", ")", "\n", "args", ".", "lr", "=", "optimizer_params_config", ".", "get", "(", "\"lr\"", ",", "args", ".", "lr", ")", "\n", "args", ".", "weight_decay", "=", "optimizer_params_config", ".", "get", "(", "\"weight_decay\"", ",", "args", ".", "weight_decay", ")", "\n", "", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.mpi_define_env": [[378, 415], ["comm.Get_rank", "comm.Get_size", "comm.bcast", "MPI.Get_processor_name", "comm.allgather", "sum", "str", "str", "print", "subprocess.check_output", "subprocess.check_output.decode().split", "subprocess.check_output.decode"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.decode"], ["", "def", "mpi_define_env", "(", "args", ")", ":", "\n", "    ", "''' For training CogView via MPI to setup the connection.\n        Omit this function if use the basic deepspeed pdsh runner. \n    '''", "\n", "from", "mpi4py", "import", "MPI", "\n", "import", "subprocess", "\n", "comm", "=", "MPI", ".", "COMM_WORLD", "\n", "rank", "=", "comm", ".", "Get_rank", "(", ")", "\n", "world_size", "=", "comm", ".", "Get_size", "(", ")", "\n", "\n", "master_addr", "=", "None", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "hostname_cmd", "=", "[", "\"hostname -I\"", "]", "\n", "result", "=", "subprocess", ".", "check_output", "(", "hostname_cmd", ",", "shell", "=", "True", ")", "\n", "master_addr", "=", "result", ".", "decode", "(", "'utf-8'", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "", "master_addr", "=", "comm", ".", "bcast", "(", "master_addr", ",", "root", "=", "0", ")", "\n", "\n", "# Determine local rank by assuming hostnames are unique", "\n", "proc_name", "=", "MPI", ".", "Get_processor_name", "(", ")", "\n", "all_procs", "=", "comm", ".", "allgather", "(", "proc_name", ")", "\n", "local_rank", "=", "sum", "(", "[", "i", "==", "proc_name", "for", "i", "in", "all_procs", "[", ":", "rank", "]", "]", ")", "\n", "\n", "os", ".", "environ", "[", "'RANK'", "]", "=", "str", "(", "rank", ")", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "=", "str", "(", "world_size", ")", "\n", "args", ".", "local_rank", "=", "local_rank", "\n", "args", ".", "world_size", "=", "world_size", "\n", "args", ".", "rank", "=", "rank", "\n", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "master_addr", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "=", "\"29500\"", "# TORCH_DISTRIBUTED_DEFAULT_PORT = 29500", "\n", "\n", "print", "(", "\n", "\"Discovered MPI settings of world_rank={}, local_rank={}, world_size={}, master_addr={}, master_port={}\"", "\n", ".", "format", "(", "os", ".", "environ", "[", "'RANK'", "]", ",", "\n", "args", ".", "local_rank", ",", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ",", "\n", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", ",", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.setup_model": [[49, 67], ["pretrain_gpt2.get_model", "utils.get_checkpoint_iteration", "os.path.join", "print", "torch.load", "torch.load", "torch.load", "pretrain_gpt2.get_model.load_state_dict", "print", "utils.load_checkpoint", "str", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.device", "torch.device", "torch.device"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_model", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_iteration", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_checkpoint"], ["def", "setup_model", "(", "args", ")", ":", "\n", "    ", "\"\"\"Setup model and optimizer.\"\"\"", "\n", "\n", "model", "=", "get_model", "(", "args", ")", "\n", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "        ", "if", "args", ".", "deepspeed", ":", "\n", "            ", "iteration", ",", "release", ",", "success", "=", "get_checkpoint_iteration", "(", "args", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "load", ",", "str", "(", "iteration", ")", ",", "\"mp_rank_00_model_states.pt\"", ")", "\n", "print", "(", "'current device:'", ",", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "path", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"module\"", "]", ")", "\n", "print", "(", "f\"Load model file {path}\"", ")", "\n", "", "else", ":", "\n", "            ", "_", "=", "load_checkpoint", "(", "\n", "model", ",", "None", ",", "None", ",", "args", ",", "load_optimizer_states", "=", "False", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples._parse_and_to_tensor": [[68, 74], ["data_utils.get_tokenizer", "query_template.format", "data_utils.get_tokenizer.parse_query", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "query_template.format.split"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.parse_query"], ["", "def", "_parse_and_to_tensor", "(", "text", ",", "img_size", "=", "256", ",", "query_template", "=", "'{}'", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "text", "=", "query_template", ".", "format", "(", "*", "text", ".", "split", "(", "'\\t'", ")", ")", "\n", "seq", "=", "tokenizer", ".", "parse_query", "(", "text", ",", "img_size", "=", "img_size", ")", "\n", "seq", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "seq", ")", "\n", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.get_context": [[75, 141], ["data_utils.get_tokenizer", "max", "enumerate", "ValueError", "input", "open", "fin.readlines", "torch.get_rank", "print", "raw_text.strip.strip", "print", "generate_samples._parse_and_to_tensor", "len", "print", "torch.get_rank", "len", "raw_text.strip.split", "os.path.join", "raw_text.strip.split", "torch.stack", "torch.stack", "torch.stack", "print", "len", "torch.get_world_size", "generate_samples._parse_and_to_tensor", "len", "print", "generate_samples._parse_and_to_tensor", "seqs.append", "print", "len", "print"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples._parse_and_to_tensor", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples._parse_and_to_tensor", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples._parse_and_to_tensor"], ["", "def", "get_context", "(", "args", ",", "query_template", "=", "'{}'", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "terminate_runs", "=", "0", "\n", "img_size", "=", "256", "if", "args", ".", "generation_task", "!=", "'low-level super-resolution'", "else", "128", "\n", "ml", "=", "max", "(", "args", ".", "max_position_embeddings", ",", "args", ".", "max_position_embeddings_finetune", ")", "\n", "output_path", "=", "args", ".", "output_path", "\n", "\n", "if", "args", ".", "input_source", "==", "'interactive'", ":", "\n", "        ", "assert", "not", "args", ".", "with_id", ",", "'--with-id is only used with file inputs.'", "\n", "if", "args", ".", "generation_task", "==", "'post-selection'", ":", "\n", "            ", "raise", "ValueError", "(", "'post-selection only takes file inputs!'", ")", "\n", "", "while", "True", ":", "\n", "            ", "raw_text", "=", "input", "(", "\"\\nPlease Input Query (stop to exit) >>> \"", ")", "\n", "if", "not", "raw_text", ":", "\n", "                ", "print", "(", "'Query should not be empty!'", ")", "\n", "continue", "\n", "", "if", "raw_text", "==", "\"stop\"", ":", "\n", "                ", "return", "\n", "", "try", ":", "\n", "                ", "seq", "=", "_parse_and_to_tensor", "(", "raw_text", ",", "img_size", "=", "img_size", ",", "query_template", "=", "query_template", ")", "\n", "", "except", "(", "ValueError", ",", "FileNotFoundError", ")", "as", "e", ":", "\n", "                ", "print", "(", "e", ")", "\n", "continue", "\n", "", "if", "len", "(", "seq", ")", ">", "ml", ":", "\n", "                ", "print", "(", "\"\\nSeq length\"", ",", "len", "(", "seq", ")", ",", "\n", "f\"\\nPlease give smaller context than {ml}!\"", ")", "\n", "continue", "\n", "", "yield", "(", "raw_text", ",", "seq", ",", "output_path", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "args", ".", "input_source", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "inputs", "=", "fin", ".", "readlines", "(", ")", "\n", "", "for", "line_no", ",", "raw_text", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "if", "line_no", "%", "dist", ".", "get_world_size", "(", ")", "!=", "dist", ".", "get_rank", "(", ")", ":", "\n", "                ", "continue", "\n", "", "rk", "=", "dist", ".", "get_rank", "(", ")", "\n", "print", "(", "f'Working on No. {line_no} on {rk}... '", ")", "\n", "raw_text", "=", "raw_text", ".", "strip", "(", ")", "\n", "if", "len", "(", "raw_text", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "if", "args", ".", "with_id", ":", "# with id", "\n", "                ", "parts", "=", "raw_text", ".", "split", "(", "'\\t'", ")", "\n", "output_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_path", ",", "parts", "[", "0", "]", ")", "\n", "raw_text", "=", "'\\t'", ".", "join", "(", "parts", "[", "1", ":", "]", ")", "\n", "\n", "", "if", "args", ".", "generation_task", "==", "'post-selection'", ":", "\n", "                ", "parts", "=", "raw_text", ".", "split", "(", "'\\t'", ")", "\n", "seqs", "=", "[", "]", "\n", "for", "part", "in", "parts", "[", "1", ":", "]", ":", "\n", "                    ", "try", ":", "\n", "                        ", "seq_single", "=", "_parse_and_to_tensor", "(", "'\\t'", ".", "join", "(", "[", "part", ",", "parts", "[", "0", "]", "]", ")", ",", "img_size", "=", "img_size", ",", "query_template", "=", "query_template", ")", "\n", "seqs", ".", "append", "(", "seq_single", ")", "\n", "", "except", "(", "ValueError", ",", "FileNotFoundError", ")", "as", "e", ":", "\n", "                        ", "print", "(", "e", ")", "\n", "continue", "\n", "", "", "seq", "=", "torch", ".", "stack", "(", "seqs", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "seq", "=", "_parse_and_to_tensor", "(", "raw_text", ",", "img_size", "=", "img_size", ",", "query_template", "=", "query_template", ")", "\n", "", "except", "(", "ValueError", ",", "FileNotFoundError", ")", "as", "e", ":", "\n", "                    ", "print", "(", "e", ")", "\n", "continue", "\n", "", "if", "len", "(", "seq", ")", ">", "ml", ":", "\n", "                    ", "print", "(", "\"\\nSeq length\"", ",", "len", "(", "seq", ")", ",", "\n", "f\"\\nPlease give smaller context than {ml}!\"", ")", "\n", "continue", "\n", "", "", "yield", "(", "raw_text", ",", "seq", ",", "output_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.generate_images_once": [[143, 201], ["data_utils.get_tokenizer", "model.eval", "os.path.exists", "os.makedirs", "generate_samples._parse_and_to_tensor", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "time.time", "generation.add_interlacing_beam_marks", "range", "torch.cat", "torch.cat", "torch.cat", "print", "print", "max", "torch.cat.append", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "data_utils.get_tokenizer.DecodeIds", "range", "txts.append", "print", "os.path.join", "torch.cat", "torch.cat", "torch.cat", "print", "print", "torchvision.utils.save_image", "print", "range", "torchvision.utils.save_image", "os.chmod", "slice", "min", "generation.filling_sequence", "_parse_and_to_tensor.tolist", "len", "torch.cat.extend", "torch.cat.append", "raw_text.replace", "len", "torchvision.utils.save_image", "os.chmod", "torch.cat", "torch.cat", "torch.cat", "os.path.join", "os.path.join", "slice", "_parse_and_to_tensor.clone", "time.time", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "os.path.join", "os.path.join", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples._parse_and_to_tensor", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.add_interlacing_beam_marks", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.DecodeIds", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.filling_sequence"], ["", "", "", "def", "generate_images_once", "(", "model", ",", "args", ",", "raw_text", ",", "seq", "=", "None", ",", "num", "=", "8", ",", "query_template", "=", "'{}'", ",", "output_path", "=", "'./samples'", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "", "if", "seq", "is", "None", ":", "# need parse", "\n", "        ", "img_size", "=", "256", "if", "args", ".", "generation_task", "!=", "'low-level super-resolution'", "else", "128", "\n", "seq", "=", "_parse_and_to_tensor", "(", "raw_text", ",", "img_size", "=", "img_size", ",", "query_template", "=", "query_template", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "print", "(", "'show raw text:'", ",", "raw_text", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "generation_task", "in", "[", "'text2image'", ",", "'low-level super-resolution'", "]", ":", "\n", "            ", "invalid_slices", "=", "[", "slice", "(", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ",", "None", ")", "]", "\n", "", "elif", "args", ".", "generation_task", "==", "'image2text'", ":", "\n", "            ", "invalid_slices", "=", "[", "slice", "(", "0", ",", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ")", "]", "\n", "", "else", ":", "\n", "            ", "NotImplementedError", "\n", "\n", "", "mbz", "=", "args", ".", "max_inference_batch_size", "\n", "add_interlacing_beam_marks", "(", "seq", ",", "nb", "=", "min", "(", "num", ",", "mbz", ")", ")", "\n", "assert", "num", "<", "mbz", "or", "num", "%", "mbz", "==", "0", "\n", "output_tokens_list", "=", "[", "]", "\n", "for", "tim", "in", "range", "(", "max", "(", "num", "//", "mbz", ",", "1", ")", ")", ":", "\n", "            ", "output_tokens_list", ".", "append", "(", "filling_sequence", "(", "model", ",", "seq", ".", "clone", "(", ")", ",", "args", ")", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "output_tokens_list", "=", "torch", ".", "cat", "(", "output_tokens_list", ",", "dim", "=", "0", ")", "\n", "\n", "print", "(", "\"\\nTaken time {:.2f}\\n\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "\"\\nContext:\"", ",", "raw_text", ",", "flush", "=", "True", ")", "\n", "imgs", ",", "txts", "=", "[", "]", ",", "[", "]", "\n", "for", "seq", "in", "output_tokens_list", ":", "\n", "            ", "decoded_txts", ",", "decoded_imgs", "=", "tokenizer", ".", "DecodeIds", "(", "seq", ".", "tolist", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "decoded_imgs", ")", ")", ":", "\n", "                ", "if", "decoded_imgs", "[", "i", "]", ".", "shape", "[", "-", "1", "]", "==", "128", ":", "\n", "                    ", "decoded_imgs", "[", "i", "]", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "decoded_imgs", "[", "i", "]", ",", "size", "=", "(", "256", ",", "256", ")", ")", "\n", "", "", "if", "args", ".", "debug", ":", "\n", "                ", "imgs", ".", "extend", "(", "decoded_imgs", ")", "\n", "", "else", ":", "\n", "                ", "imgs", ".", "append", "(", "decoded_imgs", "[", "-", "1", "]", ")", "# only the last image (target)", "\n", "", "txts", ".", "append", "(", "decoded_txts", ")", "\n", "", "if", "args", ".", "generation_task", "==", "'image2text'", ":", "\n", "            ", "print", "(", "txts", ")", "\n", "return", "\n", "", "if", "args", ".", "debug", ":", "\n", "            ", "output_file_prefix", "=", "raw_text", ".", "replace", "(", "'/'", ",", "''", ")", "[", ":", "20", "]", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "f\"{output_file_prefix}-{datetime.now().strftime('%m-%d-%H-%M-%S')}.jpg\"", ")", "\n", "imgs", "=", "torch", ".", "cat", "(", "imgs", ",", "dim", "=", "0", ")", "\n", "print", "(", "txts", ")", "\n", "print", "(", "\"\\nSave to: \"", ",", "output_file", ",", "flush", "=", "True", ")", "\n", "save_image", "(", "imgs", ",", "output_file", ",", "normalize", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"\\nSave to: \"", ",", "output_path", ",", "flush", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "imgs", ")", ")", ":", "\n", "                ", "save_image", "(", "imgs", "[", "i", "]", ",", "os", ".", "path", ".", "join", "(", "output_path", ",", "f'{i}.jpg'", ")", ",", "normalize", "=", "True", ")", "\n", "os", ".", "chmod", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "f'{i}.jpg'", ")", ",", "stat", ".", "S_IRWXO", "+", "stat", ".", "S_IRWXG", "+", "stat", ".", "S_IRWXU", ")", "\n", "", "save_image", "(", "torch", ".", "cat", "(", "imgs", ",", "dim", "=", "0", ")", ",", "os", ".", "path", ".", "join", "(", "output_path", ",", "f'concat.jpg'", ")", ",", "normalize", "=", "True", ")", "\n", "os", ".", "chmod", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "f'concat.jpg'", ")", ",", "stat", ".", "S_IRWXO", "+", "stat", ".", "S_IRWXG", "+", "stat", ".", "S_IRWXU", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.generate_images_continually": [[202, 222], ["generate_samples.get_context", "generate_samples.super_resolution", "generate_samples.post_selection", "generate_samples.generate_images_once"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.get_context", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.super_resolution", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.post_selection", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.generate_images_once"], ["", "", "", "def", "generate_images_continually", "(", "model", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "generation_task", "==", "'text2image'", ":", "\n", "        ", "query_template", "=", "'[ROI1] {} [BASE] [BOI1] [MASK]*1024'", "\n", "", "elif", "args", ".", "generation_task", "==", "'image2text'", ":", "\n", "        ", "query_template", "=", "'[BASE] [BOI1] [Image]{} [EOI1] [ROI1] [MASK]*20'", "\n", "", "elif", "args", ".", "generation_task", "==", "'low-level super-resolution'", ":", "\n", "        ", "query_template", "=", "'[ROI1] {} [BASE] [BOI1] [Image]{} [EOI1] [ROI2] [POS0] [BASE] [BOI2] [MASK]*1024'", "\n", "", "elif", "args", ".", "generation_task", "==", "'super-resolution'", ":", "\n", "        ", "query_template", "=", "'[ROI1] {} [BASE] [BOI1] [Image]{}'", "\n", "", "elif", "args", ".", "generation_task", "==", "'post-selection'", ":", "\n", "        ", "query_template", "=", "'[BASE] [BOI1] [Image]{} [EOI1] [ROI1] {}'", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "for", "raw_text", ",", "seq", ",", "output_path", "in", "get_context", "(", "args", ",", "query_template", ")", ":", "\n", "        ", "if", "args", ".", "generation_task", "==", "'super-resolution'", ":", "\n", "            ", "super_resolution", "(", "model", ",", "args", ",", "raw_text", ",", "seq", ",", "output_path", "=", "output_path", ")", "\n", "", "elif", "args", ".", "generation_task", "==", "'post-selection'", ":", "\n", "            ", "post_selection", "(", "model", ",", "args", ",", "raw_text", ",", "seq", ",", "output_path", "=", "output_path", ")", "\n", "", "else", ":", "\n", "            ", "generate_images_once", "(", "model", ",", "args", ",", "raw_text", ",", "seq", ",", "num", "=", "args", ".", "batch_size", ",", "output_path", "=", "output_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.super_resolution": [[223, 245], ["data_utils.get_tokenizer", "model.eval", "os.path.exists", "os.makedirs", "torch.no_grad", "torch.no_grad", "torch.no_grad", "time.time", "generation.magnify", "print", "print", "os.path.join", "torch.cat", "torch.cat", "torch.cat", "print", "torchvision.utils.save_image", "raw_text.replace", "torch.cat.append", "data_utils.get_tokenizer.DecodeIds", "torch.cat.extend", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "seq.tolist", "time.time", "datetime.datetime.now().strftime", "data_utils.get_tokenizer.img_tokenizer.DecodeIds", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.generation.magnify.magnify", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.DecodeIds", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.DecodeIds"], ["", "", "", "def", "super_resolution", "(", "model", ",", "args", ",", "raw_text", ",", "seq", ",", "output_path", "=", "\"./samples\"", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "output_tokens_list", "=", "magnify", "(", "model", ",", "tokenizer", ",", "seq", "[", "-", "32", "**", "2", ":", "]", ",", "seq", "[", ":", "-", "32", "**", "2", "]", ",", "args", ")", "\n", "\n", "print", "(", "\"\\nTaken time {:.2f}\\n\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "\"\\nContext:\"", ",", "raw_text", ",", "flush", "=", "True", ")", "\n", "output_file_prefix", "=", "raw_text", ".", "replace", "(", "'/'", ",", "''", ")", "[", ":", "20", "]", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "f\"{output_file_prefix}-{datetime.now().strftime('%m-%d-%H-%M-%S')}.jpg\"", ")", "\n", "imgs", "=", "[", "]", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "imgs", ".", "append", "(", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "tokenizer", ".", "img_tokenizer", ".", "DecodeIds", "(", "seq", "[", "-", "32", "**", "2", ":", "]", ")", ",", "size", "=", "(", "512", ",", "512", ")", ")", ")", "\n", "", "for", "seq", "in", "output_tokens_list", ":", "\n", "            ", "decoded_txts", ",", "decoded_imgs", "=", "tokenizer", ".", "DecodeIds", "(", "seq", ".", "tolist", "(", ")", ")", "\n", "imgs", ".", "extend", "(", "decoded_imgs", ")", "\n", "", "imgs", "=", "torch", ".", "cat", "(", "imgs", ",", "dim", "=", "0", ")", "\n", "print", "(", "\"\\nSave to: \"", ",", "output_file", ",", "flush", "=", "True", ")", "\n", "save_image", "(", "imgs", ",", "output_file", ",", "normalize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.post_selection": [[246, 271], ["data_utils.get_tokenizer", "model.eval", "os.path.exists", "os.makedirs", "torch.no_grad", "torch.no_grad", "torch.no_grad", "time.time", "torch.cat", "torch.cat", "torch.cat", "print", "print", "torch.get_rank", "os.path.join", "print", "generation.inverse_prompt_score", "open", "fout.write", "fout.write", "range", "max", "time.time", "str", "torch.cat.tolist"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.inverse_prompt_score"], ["", "", "def", "post_selection", "(", "model", ",", "args", ",", "raw_text", ",", "seq", ",", "output_path", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "num", "=", "seq", ".", "shape", "[", "0", "]", "\n", "mbz", "=", "args", ".", "max_inference_batch_size", "\n", "assert", "num", "<", "mbz", "or", "num", "%", "mbz", "==", "0", "\n", "scores", "=", "[", "inverse_prompt_score", "(", "model", ",", "seq", "[", "tim", "*", "mbz", ":", "(", "tim", "+", "1", ")", "*", "mbz", "]", ",", "args", ")", "\n", "for", "tim", "in", "range", "(", "max", "(", "num", "//", "mbz", ",", "1", ")", ")", "\n", "]", "\n", "scores", "=", "torch", ".", "cat", "(", "scores", ",", "dim", "=", "0", ")", "\n", "# scores = inverse_prompt_score(model, seq, args) # once", "\n", "\n", "print", "(", "\"\\nTaken time {:.2f}\\n\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "\"\\nContext:\"", ",", "raw_text", ",", "flush", "=", "True", ")", "\n", "rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "f\"scores_rank_{rank}.txt\"", ")", "\n", "with", "open", "(", "output_file", ",", "'a'", ")", "as", "fout", ":", "\n", "            ", "fout", ".", "write", "(", "raw_text", "+", "'\\n'", ")", "\n", "fout", ".", "write", "(", "'\\t'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "scores", ".", "tolist", "(", ")", "]", ")", "+", "'\\n'", ")", "\n", "", "print", "(", "\"\\nSave to: \"", ",", "output_file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.prepare_tokenizer": [[274, 293], ["data_utils.get_tokenizer", "utils.print_rank_0", "print", "mpu.get_model_parallel_world_size"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size"], ["", "", "def", "prepare_tokenizer", "(", "args", ")", ":", "\n", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", "args", ")", "\n", "\n", "num_tokens", "=", "tokenizer", ".", "num_tokens", "\n", "before", "=", "num_tokens", "\n", "after", "=", "before", "\n", "multiple", "=", "args", ".", "make_vocab_size_divisible_by", "*", "mpu", ".", "get_model_parallel_world_size", "(", ")", "\n", "while", "(", "after", "%", "multiple", ")", "!=", "0", ":", "\n", "        ", "after", "+=", "1", "\n", "", "print_rank_0", "(", "'> padded vocab (size: {}) with {} dummy '", "\n", "'tokens (new size: {})'", ".", "format", "(", "\n", "before", ",", "after", "-", "before", ",", "after", ")", ")", "\n", "\n", "args", ".", "vocab_size", "=", "after", "\n", "print", "(", "\"prepare tokenizer done\"", ",", "flush", "=", "True", ")", "\n", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.main": [[295, 324], ["print", "arguments.get_args", "pretrain_gpt2.initialize_distributed", "pretrain_gpt2.set_random_seed", "generate_samples.prepare_tokenizer", "generate_samples.setup_model", "generate_samples.generate_images_continually", "int", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.get_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.initialize_distributed", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.set_random_seed", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.prepare_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.setup_model", "home.repos.pwc.inspect_result.THUDM_CogView.None.generate_samples.generate_images_continually"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Main training program.\"\"\"", "\n", "\n", "print", "(", "'Generate Samples'", ")", "\n", "\n", "# Disable CuDNN.", "\n", "torch", ".", "backends", ".", "cudnn", ".", "enabled", "=", "False", "\n", "\n", "# Arguments.", "\n", "args", "=", "get_args", "(", ")", "\n", "\n", "# Pytorch distributed.", "\n", "initialize_distributed", "(", "args", ")", "\n", "\n", "# set device, this args.device is only used in inference", "\n", "if", "args", ".", "device", "is", "not", "None", ":", "\n", "        ", "device", "=", "int", "(", "args", ".", "device", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "device", ")", "\n", "\n", "# Random seeds for reproducability.", "\n", "", "set_random_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# get the tokenizer", "\n", "tokenizer", "=", "prepare_tokenizer", "(", "args", ")", "\n", "\n", "# Model, optimizer, and learning rate.", "\n", "model", "=", "setup_model", "(", "args", ")", "\n", "\n", "generate_images_continually", "(", "model", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_model": [[58, 108], ["utils.print_rank_0", "model.GPT2Model", "DDP.cuda", "mpu.get_data_parallel_rank", "print", "hasattr", "DDP.half", "torch.cuda.current_device", "torch.cuda.current_device", "fp16.FP16_Module", "torch.cuda.current_device", "torch.cuda.current_device", "DDP", "DDP", "mpu.get_model_parallel_rank", "sum", "mpu.get_data_parallel_group", "p.nelement", "DDP.parameters"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group"], ["def", "get_model", "(", "args", ")", ":", "\n", "    ", "\"\"\"Build the model.\"\"\"", "\n", "\n", "print_rank_0", "(", "'building CogView2 model ...'", ")", "\n", "# print(args.vocab_size)", "\n", "# ml = max(args.max_position_embeddings, args.max_position_embeddings_finetune)", "\n", "ml", "=", "args", ".", "max_position_embeddings", "\n", "model", "=", "GPT2Model", "(", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "num_attention_heads", "=", "args", ".", "num_attention_heads", ",", "\n", "embedding_dropout_prob", "=", "args", ".", "hidden_dropout", ",", "\n", "attention_dropout_prob", "=", "args", ".", "attention_dropout", ",", "\n", "output_dropout_prob", "=", "args", ".", "hidden_dropout", ",", "\n", "max_sequence_length", "=", "ml", ",", "\n", "max_memory_length", "=", "args", ".", "max_memory_length", ",", "\n", "checkpoint_activations", "=", "args", ".", "checkpoint_activations", ",", "\n", "checkpoint_num_layers", "=", "args", ".", "checkpoint_num_layers", ",", "\n", "parallel_output", "=", "True", ",", "\n", "query_window", "=", "args", ".", "query_window", ",", "\n", "key_window_times", "=", "args", ".", "key_window_times", ",", "\n", "num_pivot", "=", "args", ".", "num_pivot", "\n", ")", "\n", "\n", "if", "mpu", ".", "get_data_parallel_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "' > number of parameters on model parallel rank {}: {}'", ".", "format", "(", "\n", "mpu", ".", "get_model_parallel_rank", "(", ")", ",", "\n", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# To prevent OOM for model sizes that cannot fit in GPU memory in full precision", "\n", "", "if", "hasattr", "(", "args", ",", "\"deepspeed\"", ")", "and", "args", ".", "deepspeed", "and", "args", ".", "fp16", ":", "\n", "        ", "model", ".", "half", "(", ")", "\n", "\n", "# GPU allocation.", "\n", "", "model", ".", "cuda", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "\n", "# Fp16 conversion.", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "model", "=", "FP16_Module", "(", "model", ")", "\n", "\n", "# Wrap model for distributed training.", "\n", "", "if", "not", "args", ".", "deepspeed", ":", "\n", "        ", "if", "USE_TORCH_DDP", ":", "\n", "            ", "i", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "model", "=", "DDP", "(", "model", ",", "device_ids", "=", "[", "i", "]", ",", "output_device", "=", "i", ",", "\n", "process_group", "=", "mpu", ".", "get_data_parallel_group", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "DDP", "(", "model", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_optimizer_param_groups": [[110, 123], ["isinstance", "model.gpt2_get_params_for_weight_decay_optimization", "hasattr"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.model.gpt2_modeling.gpt2_get_params_for_weight_decay_optimization"], ["", "def", "get_optimizer_param_groups", "(", "model", ")", ":", "\n", "# Build parameter groups (weight decay and non-decay).", "\n", "    ", "while", "isinstance", "(", "model", ",", "(", "DDP", ",", "FP16_Module", ")", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "param_groups", "=", "gpt2_get_params_for_weight_decay_optimization", "(", "model", ")", "\n", "\n", "# Add model parallel attribute if it is not set.", "\n", "for", "param_group", "in", "param_groups", ":", "\n", "        ", "for", "param", "in", "param_group", "[", "'params'", "]", ":", "\n", "            ", "if", "not", "hasattr", "(", "param", ",", "'model_parallel'", ")", ":", "\n", "                ", "param", ".", "model_parallel", "=", "False", "\n", "\n", "", "", "", "return", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_optimizer": [[125, 159], ["print", "cpu_adam_optimizer", "apex.optimizers.FusedAdam", "hasattr", "fp16.FP16_Optimizer"], "function", ["None"], ["", "def", "get_optimizer", "(", "param_groups", ",", "args", ")", ":", "\n", "    ", "\"\"\"Set up the optimizer.\"\"\"", "\n", "if", "args", ".", "cpu_optimizer", ":", "\n", "#Apex FusedAdam uses decoupled weight decay so use the same here", "\n", "        ", "if", "args", ".", "cpu_torch_adam", ":", "\n", "            ", "cpu_adam_optimizer", "=", "torch", ".", "optim", ".", "AdamW", "\n", "", "else", ":", "\n", "#TODO add option for decoupled weight decay in DeepCPUAdam", "\n", "            ", "from", "deepspeed", ".", "ops", ".", "adam", "import", "DeepSpeedCPUAdam", "\n", "cpu_adam_optimizer", "=", "DeepSpeedCPUAdam", "\n", "", "optimizer", "=", "cpu_adam_optimizer", "(", "param_groups", ",", "\n", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "", "else", ":", "\n", "# Use FusedAdam.", "\n", "        ", "optimizer", "=", "Adam", "(", "param_groups", ",", "\n", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "\n", "", "print", "(", "f'Optimizer = {optimizer.__class__.__name__}'", ")", "\n", "if", "hasattr", "(", "args", ",", "\"deepspeed\"", ")", "and", "args", ".", "deepspeed", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "# fp16 wrapper is not required for DeepSpeed.", "\n", "# return optimizer", "\n", "\n", "# Wrap into fp16 optimizer.", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "\n", "static_loss_scale", "=", "args", ".", "loss_scale", ",", "\n", "dynamic_loss_scale", "=", "args", ".", "dynamic_loss_scale", ",", "\n", "dynamic_loss_args", "=", "{", "\n", "'scale_window'", ":", "args", ".", "loss_scale_window", ",", "\n", "'min_scale'", ":", "args", ".", "min_scale", ",", "\n", "'delayed_shift'", ":", "args", ".", "hysteresis", "}", ")", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_learning_rate_scheduler": [[161, 181], ["max", "learning_rates.AnnealingLR"], "function", ["None"], ["", "def", "get_learning_rate_scheduler", "(", "optimizer", ",", "args", ")", ":", "\n", "    ", "\"\"\"Build the learning rate scheduler.\"\"\"", "\n", "\n", "# Add linear learning rate scheduler.", "\n", "if", "args", ".", "lr_decay_iters", "is", "not", "None", ":", "\n", "        ", "num_iters", "=", "args", ".", "lr_decay_iters", "\n", "", "else", ":", "\n", "        ", "num_iters", "=", "args", ".", "train_iters", "\n", "", "num_iters", "=", "max", "(", "1", ",", "num_iters", ")", "\n", "init_step", "=", "-", "1", "\n", "warmup_iter", "=", "args", ".", "warmup", "*", "num_iters", "\n", "lr_scheduler", "=", "AnnealingLR", "(", "optimizer", ",", "\n", "start_lr", "=", "args", ".", "lr", ",", "\n", "warmup_iter", "=", "warmup_iter", ",", "\n", "num_iters", "=", "num_iters", ",", "\n", "decay_style", "=", "args", ".", "lr_decay_style", ",", "\n", "last_iter", "=", "init_step", ",", "\n", "decay_ratio", "=", "args", ".", "lr_decay_ratio", ")", "\n", "\n", "return", "lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.setup_model_and_optimizer": [[183, 208], ["pretrain_gpt2.get_model", "pretrain_gpt2.get_optimizer_param_groups", "pretrain_gpt2.get_learning_rate_scheduler", "utils.print_rank_0", "deepspeed.initialize", "pretrain_gpt2.get_optimizer"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_model", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_optimizer_param_groups", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_learning_rate_scheduler", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.None.test_lmdb.initialize", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_optimizer"], ["", "def", "setup_model_and_optimizer", "(", "args", ")", ":", "\n", "    ", "\"\"\"Setup model and optimizer.\"\"\"", "\n", "\n", "model", "=", "get_model", "(", "args", ")", "\n", "\n", "param_groups", "=", "get_optimizer_param_groups", "(", "model", ")", "\n", "\n", "if", "args", ".", "train_data", "is", "not", "None", ":", "\n", "        ", "if", "args", ".", "deepspeed", ":", "\n", "            ", "print_rank_0", "(", "\"DeepSpeed is enabled.\"", ")", "\n", "\n", "model", ",", "optimizer", ",", "_", ",", "_", "=", "deepspeed", ".", "initialize", "(", "\n", "model", "=", "model", ",", "\n", "model_parameters", "=", "param_groups", ",", "\n", "args", "=", "args", ",", "\n", "mpu", "=", "mpu", ",", "\n", "dist_init_required", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "get_optimizer", "(", "param_groups", ",", "args", ")", "\n", "", "lr_scheduler", "=", "get_learning_rate_scheduler", "(", "optimizer", ",", "args", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", ",", "lr_scheduler", "=", "None", ",", "None", "\n", "\n", "", "return", "model", ",", "optimizer", ",", "lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_masks_and_position_ids": [[210, 254], ["data.size", "torch.ones", "torch.ones", "torch.tril", "torch.tril", "attention_mask.unsqueeze.unsqueeze", "torch.ones", "torch.ones", "torch.nonzero", "torch.nonzero", "torch.zeros", "torch.zeros", "range", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as", "data.size", "data_utils.get_tokenizer", "min", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer"], ["", "def", "get_masks_and_position_ids", "(", "data", ",", "\n", "loss_mask", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "args", "=", "None", ")", ":", "\n", "# Extract batch size and sequence length.", "\n", "    ", "batch_size", ",", "seq_length", "=", "data", ".", "size", "(", ")", "\n", "\n", "# Attention mask (lower triangular).", "\n", "if", "attention_mask", "is", "None", ":", "\n", "# single direction, [PAD]s are at the end of the seq, so doesn't matter.", "\n", "        ", "attention_mask", "=", "torch", ".", "ones", "(", "(", "1", ",", "seq_length", ",", "seq_length", ")", ",", "device", "=", "data", ".", "device", ")", "\n", "attention_mask", "=", "torch", ".", "tril", "(", "attention_mask", ")", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# Loss mask.", "\n", "", "if", "loss_mask", "is", "None", ":", "\n", "        ", "loss_mask", "=", "torch", ".", "ones", "(", "data", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "data", ".", "device", ")", "\n", "\n", "# Position ids.", "\n", "", "if", "args", "is", "not", "None", "and", "args", ".", "finetune", "and", "args", ".", "max_position_embeddings", "<", "args", ".", "max_position_embeddings_finetune", ":", "\n", "# for each sample, find [ROI2] and split", "\n", "# ([ROI1] text... [BOI1] img... [EOI1] [ROI2]<pos_id==1089> ...)", "\n", "        ", "start_token", "=", "get_tokenizer", "(", ")", "[", "'[ROI2]'", "]", "\n", "tmp", "=", "torch", ".", "nonzero", "(", "data", "==", "start_token", ",", "as_tuple", "=", "False", ")", "\n", "start_token_poses", "=", "[", "100000", "]", "*", "batch_size", "\n", "for", "x", ",", "y", "in", "tmp", ":", "\n", "            ", "start_token_poses", "[", "x", "]", "=", "min", "(", "start_token_poses", "[", "x", "]", ",", "y", ")", "\n", "", "assert", "100000", "not", "in", "start_token_poses", ",", "'Some samples do not have [ROI2]!'", "\n", "position_ids", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "data", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "sep", "=", "start_token_poses", "[", "i", "]", "\n", "torch", ".", "arange", "(", "start", "=", "0", ",", "end", "=", "sep", ",", "out", "=", "position_ids", "[", "i", ",", ":", "sep", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "data", ".", "device", ")", "\n", "second_pos", "=", "0", "# reuse", "\n", "torch", ".", "arange", "(", "start", "=", "second_pos", ",", "end", "=", "second_pos", "+", "seq_length", "-", "sep", ",", "\n", "out", "=", "position_ids", "[", "i", ",", "sep", ":", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "data", ".", "device", ")", "\n", "", "position_ids", "[", "position_ids", ">=", "args", ".", "max_position_embeddings", "]", "=", "args", ".", "max_position_embeddings", "-", "1", "\n", "", "else", ":", "\n", "        ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "data", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "data", ")", "\n", "\n", "", "return", "attention_mask", ",", "loss_mask", ",", "position_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_batch": [[256, 290], ["timers().start", "timers().stop", "mpu.broadcast_data", "data_b[].long", "data_b[].float", "tokens_[].contiguous", "loss_mask[].contiguous", "tokens_[].contiguous", "pretrain_gpt2.get_masks_and_position_ids", "next", "attention_mask.half.half", "timers", "timers"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.data.broadcast_data", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_masks_and_position_ids"], ["", "def", "get_batch", "(", "data_iterator", ",", "args", ",", "timers", ")", ":", "\n", "# Items and their type.", "\n", "    ", "keys", "=", "[", "'text'", ",", "'loss_mask'", "]", "\n", "datatype", "=", "torch", ".", "int64", "\n", "\n", "# Broadcast data.", "\n", "timers", "(", "'data loader'", ")", ".", "start", "(", ")", "\n", "if", "data_iterator", "is", "not", "None", ":", "\n", "        ", "data", "=", "next", "(", "data_iterator", ")", "\n", "", "else", ":", "\n", "        ", "data", "=", "None", "\n", "", "timers", "(", "'data loader'", ")", ".", "stop", "(", ")", "\n", "\n", "data_b", "=", "mpu", ".", "broadcast_data", "(", "keys", ",", "data", ",", "datatype", ")", "\n", "# Unpack.", "\n", "tokens_", "=", "data_b", "[", "'text'", "]", ".", "long", "(", ")", "\n", "loss_mask", "=", "data_b", "[", "'loss_mask'", "]", ".", "float", "(", ")", "\n", "labels", "=", "tokens_", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_mask", "=", "loss_mask", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "tokens", "=", "tokens_", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "attention_mask", "=", "None", "\n", "\n", "# Get the masks and postition ids.", "\n", "attention_mask", ",", "loss_mask", ",", "position_ids", "=", "get_masks_and_position_ids", "(", "\n", "tokens", ",", "\n", "loss_mask", "=", "loss_mask", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "args", "=", "args", "\n", ")", "\n", "# Convert", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "attention_mask", "=", "attention_mask", ".", "half", "(", ")", "\n", "\n", "", "return", "tokens", ",", "labels", ",", "loss_mask", ",", "attention_mask", ",", "position_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.forward_step": [[292, 342], ["timers().start", "pretrain_gpt2.get_batch", "timers().stop", "data_utils.get_tokenizer", "model", "mpu.vocab_parallel_cross_entropy", "loss_mask.view.view", "img_indices_bool.view.view", "txt_indices_bool.view.view", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "tokens.detach", "logits.contiguous().float", "mpu.vocab_parallel_cross_entropy.view", "torch.sum", "torch.sum", "loss_mask.view.sum", "losses[].detach().sum", "max", "timers", "timers", "img_indices_bool.view.sum", "losses[].detach().sum", "max", "logits.contiguous", "losses[].detach", "txt_indices_bool.view.sum", "losses[].detach"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.get_batch", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.cross_entropy.vocab_parallel_cross_entropy", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce"], ["", "def", "forward_step", "(", "data_iterator", ",", "model", ",", "args", ",", "timers", ",", "mems", ")", ":", "\n", "    ", "\"\"\"Forward step.\"\"\"", "\n", "\n", "# Get the batch.", "\n", "timers", "(", "'batch generator'", ")", ".", "start", "(", ")", "\n", "tokens", ",", "labels", ",", "loss_mask", ",", "attention_mask", ",", "position_ids", "=", "get_batch", "(", "\n", "data_iterator", ",", "args", ",", "timers", ")", "\n", "\n", "timers", "(", "'batch generator'", ")", ".", "stop", "(", ")", "\n", "\n", "# split img & txt positions, [PAD] not included # TODO check enough", "\n", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "img_txt_sep", "=", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", "\n", "img_indices_bool", "=", "(", "tokens", ".", "detach", "(", ")", "<", "img_txt_sep", ")", "\n", "txt_indices_bool", "=", "(", "~", "img_indices_bool", ")", "&", "(", "loss_mask", ">", "0", ")", "\n", "\n", "# Forward model.", "\n", "logits", ",", "*", "mems", "=", "model", "(", "tokens", ",", "position_ids", ",", "attention_mask", ",", "txt_indices_bool", ",", "img_indices_bool", ",", "args", ".", "is_sparse", ",", "*", "mems", ")", "\n", "losses", "=", "mpu", ".", "vocab_parallel_cross_entropy", "(", "logits", ".", "contiguous", "(", ")", ".", "float", "(", ")", ",", "\n", "labels", ")", "\n", "# scaling loss mask", "\n", "loss_mask", "[", "txt_indices_bool", "]", "*=", "args", ".", "txt_loss_scale", "\n", "loss_mask", "=", "loss_mask", ".", "view", "(", "-", "1", ")", "\n", "\n", "# precalc outlier point, uncomment this if needed", "\n", "# if args.iteration > 10000:", "\n", "#     outliers = (losses.detach().view(-1) * loss_mask) > 20.", "\n", "#     if outliers.sum() > 0:", "\n", "#         print(f'Remove {outliers.sum()} outliers.')", "\n", "#         loss_mask[outliers] = 1e-4", "\n", "\n", "\n", "losses", "=", "losses", ".", "view", "(", "-", "1", ")", "*", "loss_mask", "\n", "loss", "=", "torch", ".", "sum", "(", "losses", ")", "/", "loss_mask", ".", "sum", "(", ")", "\n", "\n", "# =====================   Log partial losses   ======================== #", "\n", "img_indices_bool", "=", "img_indices_bool", ".", "view", "(", "-", "1", ")", "\n", "txt_indices_bool", "=", "txt_indices_bool", ".", "view", "(", "-", "1", ")", "\n", "img_loss", "=", "losses", "[", "img_indices_bool", "]", ".", "detach", "(", ")", ".", "sum", "(", ")", "/", "max", "(", "img_indices_bool", ".", "sum", "(", ")", ",", "1", ")", "\n", "txt_loss", "=", "losses", "[", "txt_indices_bool", "]", ".", "detach", "(", ")", ".", "sum", "(", ")", "/", "max", "(", "txt_indices_bool", ".", "sum", "(", ")", ",", "1", ")", "/", "args", ".", "txt_loss_scale", "\n", "\n", "# Reduce losses for logging", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "img_loss", ".", "data", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "txt_loss", ".", "data", ")", "\n", "img_loss", ".", "data", "=", "img_loss", ".", "data", "/", "args", ".", "world_size", "\n", "txt_loss", ".", "data", "=", "txt_loss", ".", "data", "/", "args", ".", "world_size", "\n", "\n", "# ===================== END OF BLOCK ======================= #", "\n", "\n", "return", "loss", ",", "mems", ",", "img_loss", ",", "txt_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.backward_step": [[344, 392], ["lm_loss.view", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "model.backward", "optimizer.zero_grad", "timers().reset", "optimizer.backward", "loss.backward", "timers().start", "model.allreduce_params", "timers().stop", "optimizer.update_master_grads", "timers", "mpu.clip_grad_norm", "optimizer.clip_master_grads", "timers", "timers", "model.parameters"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.zero_grad", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.reset", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.update_master_grads", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.grads.clip_grad_norm", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.clip_master_grads"], ["", "def", "backward_step", "(", "optimizer", ",", "model", ",", "lm_loss", ",", "args", ",", "timers", ")", ":", "\n", "    ", "\"\"\"Backward step.\"\"\"", "\n", "\n", "# Total loss.", "\n", "loss", "=", "lm_loss", "\n", "\n", "# Backward pass.", "\n", "if", "args", ".", "deepspeed", ":", "\n", "        ", "model", ".", "backward", "(", "loss", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "            ", "optimizer", ".", "backward", "(", "loss", ",", "update_master_grads", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "", "reduced_losses", "=", "lm_loss", ".", "view", "(", "1", ")", "\n", "\n", "# Reduce losses for logging", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "reduced_losses", ".", "data", ")", "\n", "reduced_losses", ".", "data", "=", "reduced_losses", ".", "data", "/", "args", ".", "world_size", "\n", "\n", "if", "args", ".", "deepspeed", ":", "\n", "# DeepSpeed backward propagation already addressed all reduce communication.", "\n", "# Reset the timer to avoid breaking timer logs below.", "\n", "        ", "timers", "(", "'allreduce'", ")", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "USE_TORCH_DDP", ":", "\n", "            ", "timers", "(", "'allreduce'", ")", ".", "start", "(", ")", "\n", "model", ".", "allreduce_params", "(", "reduce_after", "=", "False", ",", "\n", "fp32_allreduce", "=", "args", ".", "fp32_allreduce", ")", "\n", "timers", "(", "'allreduce'", ")", ".", "stop", "(", ")", "\n", "\n", "", "", "lm_loss_reduced", "=", "reduced_losses", "\n", "\n", "# Update master gradients.", "\n", "if", "not", "args", ".", "deepspeed", ":", "\n", "        ", "if", "args", ".", "fp16", ":", "\n", "            ", "optimizer", ".", "update_master_grads", "(", ")", "\n", "\n", "# Clipping gradients helps prevent the exploding gradient.", "\n", "", "if", "args", ".", "clip_grad", ">", "0", ":", "\n", "            ", "if", "not", "args", ".", "fp16", ":", "\n", "                ", "mpu", ".", "clip_grad_norm", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip_grad", ")", "\n", "", "else", ":", "\n", "                ", "optimizer", ".", "clip_master_grads", "(", "args", ".", "clip_grad", ")", "\n", "\n", "", "", "", "return", "lm_loss_reduced", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.see_memory_usage": [[394, 405], ["torch.barrier", "torch.get_rank", "print", "print", "print", "print", "print", "print", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.memory_cached", "torch.cuda.memory_cached", "torch.cuda.max_memory_cached", "torch.cuda.max_memory_cached"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["", "def", "see_memory_usage", "(", "message", ",", "force", "=", "False", ")", ":", "\n", "    ", "if", "not", "force", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "message", ")", "\n", "print", "(", "\"Memory Allocated \"", ",", "torch", ".", "cuda", ".", "memory_allocated", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\"Max Memory Allocated \"", ",", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\"Cache Allocated \"", ",", "torch", ".", "cuda", ".", "memory_cached", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\"Max cache Allocated \"", ",", "torch", ".", "cuda", ".", "max_memory_cached", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.train_step": [[406, 449], ["timers().start", "pretrain_gpt2.forward_step", "timers().stop", "timers().start", "pretrain_gpt2.backward_step", "timers().stop", "timers().start", "timers().stop", "print", "model.is_gradient_accumulation_boundary", "optimizer.step", "timers", "timers", "timers", "timers", "timers", "model.step", "model.step", "lr_scheduler.step", "timers", "lr_scheduler.step"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.forward_step", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.backward_step", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step"], ["", "", "def", "train_step", "(", "data_iterator", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "\n", "args", ",", "timers", ",", "mems", ")", ":", "\n", "    ", "\"\"\"Single training step.\"\"\"", "\n", "while", "True", ":", "\n", "# Forward model for one step.", "\n", "        ", "timers", "(", "'forward'", ")", ".", "start", "(", ")", "\n", "lm_loss", ",", "mems", ",", "img_loss", ",", "txt_loss", "=", "forward_step", "(", "data_iterator", ",", "model", ",", "args", ",", "timers", ",", "mems", ")", "\n", "timers", "(", "'forward'", ")", ".", "stop", "(", ")", "\n", "\n", "if", "(", "img_loss", "+", "txt_loss", ")", ".", "isnan", "(", ")", ".", "any", "(", ")", "or", "(", "img_loss", "+", "txt_loss", ")", ".", "isinf", "(", ")", ".", "any", "(", ")", ":", "\n", "            ", "print", "(", "'Skipping backward and optimizer step for nan or inf in forwarding!'", ")", "\n", "return", "(", "img_loss", "+", "txt_loss", ")", ",", "1", ",", "mems", ",", "img_loss", ",", "txt_loss", "\n", "\n", "# Calculate gradients, reduce across processes, and clip.", "\n", "", "timers", "(", "'backward'", ")", ".", "start", "(", ")", "\n", "lm_loss_reduced", "=", "backward_step", "(", "optimizer", ",", "model", ",", "lm_loss", ",", "args", ",", "timers", ")", "\n", "timers", "(", "'backward'", ")", ".", "stop", "(", ")", "\n", "\n", "# Update parameters.", "\n", "skipped_iter", ",", "complete", "=", "0", ",", "False", "\n", "timers", "(", "'optimizer'", ")", ".", "start", "(", ")", "\n", "if", "args", ".", "deepspeed", ":", "\n", "            ", "if", "model", ".", "is_gradient_accumulation_boundary", "(", ")", ":", "\n", "                ", "model", ".", "step", "(", ")", "\n", "complete", "=", "True", "\n", "if", "not", "(", "args", ".", "fp16", "and", "optimizer", ".", "overflow", ")", ":", "\n", "                    ", "lr_scheduler", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                    ", "skipped_iter", "=", "1", "\n", "", "", "else", ":", "\n", "                ", "model", ".", "step", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "complete", "=", "True", "\n", "# Update learning rate.", "\n", "if", "not", "(", "args", ".", "fp16", "and", "optimizer", ".", "overflow", ")", ":", "\n", "                ", "lr_scheduler", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                ", "skipped_iter", "=", "1", "\n", "", "", "timers", "(", "'optimizer'", ")", ".", "stop", "(", ")", "\n", "if", "complete", ":", "\n", "            ", "break", "\n", "", "", "return", "lm_loss_reduced", ",", "skipped_iter", ",", "mems", ",", "img_loss", ",", "txt_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.report_iteration_metrics": [[451, 466], ["utils.print_rank_0", "summary_writer.add_scalar", "summary_writer.add_scalar", "summary_writer.add_scalar"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0"], ["", "def", "report_iteration_metrics", "(", "summary_writer", ",", "optimizer", ",", "lr", ",", "loss", ",", "elapsed_time", ",", "step", ",", "total_step", ",", "args", ",", "img_loss", ",", "txt_loss", ")", ":", "\n", "    ", "log_string", "=", "' iteration {:8d}/{:8d} |'", ".", "format", "(", "step", ",", "total_step", ")", "\n", "log_string", "+=", "' elapsed time per iteration (ms): {:.1f} |'", ".", "format", "(", "elapsed_time", ")", "\n", "log_string", "+=", "' learning rate {:.3E} |'", ".", "format", "(", "lr", ")", "\n", "log_string", "+=", "' lm loss {:.6E} |'", ".", "format", "(", "loss", ")", "\n", "log_string", "+=", "' img loss {:.6E} |'", ".", "format", "(", "img_loss", ")", "\n", "log_string", "+=", "' unscaled txt loss {:.6E} |'", ".", "format", "(", "txt_loss", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "log_string", "+=", "' loss scale {:.1f} |'", ".", "format", "(", "\n", "optimizer", ".", "cur_scale", "if", "args", ".", "deepspeed", "else", "optimizer", ".", "loss_scale", ")", "\n", "", "print_rank_0", "(", "log_string", ")", "\n", "if", "summary_writer", "is", "not", "None", ":", "\n", "        ", "summary_writer", ".", "add_scalar", "(", "f'Train/lr'", ",", "lr", ",", "step", ")", "\n", "summary_writer", ".", "add_scalar", "(", "f'Train/train_loss'", ",", "loss", ",", "step", ")", "\n", "summary_writer", ".", "add_scalar", "(", "f'Train/elapsed_time'", ",", "elapsed_time", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.report_evaluate_metrics": [[468, 480], ["utils.print_rank_0", "utils.print_rank_0", "utils.print_rank_0", "utils.print_rank_0", "len", "summary_writer.add_scalar", "summary_writer.add_scalar"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0"], ["", "", "def", "report_evaluate_metrics", "(", "summary_writer", ",", "prefix", ",", "loss", ",", "ppl", ",", "step", ")", ":", "\n", "    ", "string", "=", "' validation loss at {} | '", ".", "format", "(", "prefix", ")", "\n", "string", "+=", "'LM loss: {:.6E} | '", ".", "format", "(", "loss", ")", "\n", "string", "+=", "'LM PPL: {:.6E}'", ".", "format", "(", "ppl", ")", "\n", "length", "=", "len", "(", "string", ")", "+", "1", "\n", "print_rank_0", "(", "'-'", "*", "100", ")", "\n", "print_rank_0", "(", "'-'", "*", "length", ")", "\n", "print_rank_0", "(", "string", ")", "\n", "print_rank_0", "(", "'-'", "*", "length", ")", "\n", "if", "summary_writer", "is", "not", "None", ":", "\n", "        ", "summary_writer", ".", "add_scalar", "(", "f'Train/valid_ppl'", ",", "ppl", ",", "step", ")", "\n", "summary_writer", ".", "add_scalar", "(", "f'Train/valid_loss'", ",", "loss", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.train": [[482, 567], ["model.train", "timers().start", "pretrain_gpt2.train_step", "lm_loss.data.detach().float", "img_loss.data.detach().float", "txt_loss.data.detach().float", "timers", "data_utils.detect_new_datasets", "timers().elapsed", "pretrain_gpt2.report_iteration_metrics", "utils.save_checkpoint", "pretrain_gpt2.evaluate_and_print_results", "torch.distributed.barrier", "torch.distributed.barrier", "datetime.datetime.now().strftime", "torch.distributed.get_rank", "torch.distributed.get_rank", "print", "exit", "print", "iter", "iter", "lm_loss.data.detach", "img_loss.data.detach", "txt_loss.data.detach", "total_lm_loss.item", "total_img_loss.item", "total_txt_loss.item", "utils.report_memory", "timers.log", "timers.log", "timers", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.train", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.train_step", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.detect_new_datasets", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.report_iteration_metrics", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_checkpoint", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.evaluate_and_print_results", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.report_memory", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log"], ["", "", "def", "train", "(", "model", ",", "optimizer", ",", "lr_scheduler", ",", "\n", "train_data_iterator", ",", "val_data_iterator", ",", "timers", ",", "args", ",", "summary_writer", "=", "None", ")", ":", "\n", "    ", "\"\"\"Train the model.\"\"\"", "\n", "# Turn on training mode which enables dropout.", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# Tracking loss.", "\n", "total_lm_loss", "=", "0.0", "\n", "total_img_loss", "=", "total_txt_loss", "=", "0.0", "\n", "\n", "# Iterations.", "\n", "skipped_iters", "=", "0", "\n", "\n", "timers", "(", "'interval time'", ")", ".", "start", "(", ")", "\n", "report_memory_flag", "=", "True", "\n", "mems", "=", "[", "]", "\n", "while", "args", ".", "iteration", "<", "args", ".", "train_iters", ":", "\n", "\n", "        ", "if", "args", ".", "iteration", "%", "100", "==", "0", ":", "\n", "            ", "new_loaders", "=", "detect_new_datasets", "(", "args", ")", "\n", "if", "new_loaders", "is", "not", "None", ":", "\n", "                ", "print", "(", "f'Loatding new datasets ... Now we train models on {args.train_data}.'", ")", "\n", "train_data_iterator", "=", "iter", "(", "new_loaders", "[", "0", "]", ")", "\n", "val_data_iterator", "=", "iter", "(", "new_loaders", "[", "1", "]", ")", "\n", "# TODO close the original", "\n", "\n", "\n", "", "", "lm_loss", ",", "skipped_iter", ",", "mems", ",", "img_loss", ",", "txt_loss", "=", "train_step", "(", "train_data_iterator", ",", "\n", "model", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "args", ",", "timers", ",", "mems", ")", "\n", "skipped_iters", "+=", "skipped_iter", "\n", "args", ".", "iteration", "+=", "1", "\n", "\n", "# Update losses.", "\n", "total_lm_loss", "+=", "lm_loss", ".", "data", ".", "detach", "(", ")", ".", "float", "(", ")", "\n", "total_img_loss", "+=", "img_loss", ".", "data", ".", "detach", "(", ")", ".", "float", "(", ")", "\n", "total_txt_loss", "+=", "txt_loss", ".", "data", ".", "detach", "(", ")", ".", "float", "(", ")", "\n", "\n", "# Logging.", "\n", "if", "args", ".", "iteration", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "            ", "learning_rate", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "avg_lm_loss", "=", "total_lm_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "# average img & txt loss", "\n", "avg_img_loss", "=", "total_img_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "avg_txt_loss", "=", "total_txt_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "\n", "elapsed_time", "=", "timers", "(", "'interval time'", ")", ".", "elapsed", "(", ")", "\n", "report_iteration_metrics", "(", "summary_writer", ",", "optimizer", ",", "learning_rate", ",", "avg_lm_loss", ",", "\n", "elapsed_time", "*", "1000.0", "/", "args", ".", "log_interval", ",", "args", ".", "iteration", ",", "args", ".", "train_iters", ",", "args", ",", "\n", "avg_img_loss", ",", "avg_txt_loss", ")", "\n", "total_lm_loss", "=", "0.0", "\n", "total_img_loss", "=", "0.0", "\n", "total_txt_loss", "=", "0.0", "\n", "if", "report_memory_flag", ":", "\n", "                ", "report_memory", "(", "'after {} iterations'", ".", "format", "(", "args", ".", "iteration", ")", ")", "\n", "report_memory_flag", "=", "False", "\n", "", "if", "USE_TORCH_DDP", ":", "\n", "                ", "timers", ".", "log", "(", "[", "'forward'", ",", "'backward'", ",", "'optimizer'", ",", "\n", "'batch generator'", ",", "'data loader'", "]", ",", "\n", "normalizer", "=", "args", ".", "log_interval", ")", "\n", "", "else", ":", "\n", "                ", "timers", ".", "log", "(", "[", "'forward'", ",", "'backward'", ",", "'allreduce'", ",", "'optimizer'", ",", "\n", "'batch generator'", ",", "'data loader'", "]", ",", "\n", "normalizer", "=", "args", ".", "log_interval", ")", "\n", "# Checkpointing", "\n", "", "", "if", "args", ".", "save", "and", "args", ".", "save_interval", "and", "args", ".", "iteration", "%", "args", ".", "save_interval", "==", "0", ":", "\n", "            ", "save_checkpoint", "(", "args", ".", "iteration", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "args", ".", "eval_interval", "and", "args", ".", "iteration", "%", "args", ".", "eval_interval", "==", "0", "and", "args", ".", "do_valid", ":", "\n", "            ", "prefix", "=", "'iteration {}'", ".", "format", "(", "args", ".", "iteration", ")", "\n", "evaluate_and_print_results", "(", "\n", "prefix", ",", "val_data_iterator", ",", "model", ",", "args", ",", "timers", ",", "False", ",", "step", "=", "args", ".", "iteration", ",", "summary_writer", "=", "summary_writer", ")", "\n", "\n", "", "if", "args", ".", "exit_interval", "and", "args", ".", "iteration", "%", "args", ".", "exit_interval", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "print", "(", "'rank: {} | time: {} | exiting the program at iteration {}'", ".", "\n", "format", "(", "rank", ",", "time_str", ",", "args", ".", "iteration", ")", ",", "flush", "=", "True", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "return", "args", ".", "iteration", ",", "skipped_iters", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.evaluate": [[569, 608], ["model.eval", "model.train", "torch.no_grad", "torch.no_grad", "pretrain_gpt2.forward_step", "isinstance", "lm_loss.data.detach().float().item", "utils.print_rank_0", "deepspeed.checkpointing.reset", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "lm_loss.data.detach().float", "lm_loss.data.detach"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.train", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.forward_step", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.reset", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce"], ["", "def", "evaluate", "(", "data_iterator", ",", "model", ",", "args", ",", "timers", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Evaluation.\"\"\"", "\n", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "model", ".", "eval", "(", ")", "\n", "is_sparse_raw", "=", "args", ".", "is_sparse", "\n", "args", ".", "is_sparse", "=", "0", "\n", "\n", "total_lm_loss", "=", "0", "\n", "mems", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "iteration", "=", "0", "\n", "while", "iteration", "<", "args", ".", "eval_iters", ":", "\n", "            ", "iteration", "+=", "1", "\n", "if", "verbose", "and", "iteration", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "                ", "print_rank_0", "(", "'Evaluating iter {}/{}'", ".", "format", "(", "iteration", ",", "args", ".", "eval_iters", ")", ")", "\n", "# Forward evaluation.", "\n", "", "lm_loss", ",", "mems", ",", "img_loss", ",", "txt_loss", "=", "forward_step", "(", "data_iterator", ",", "model", ",", "args", ",", "timers", ",", "mems", "=", "mems", ")", "\n", "\n", "'''when contiguous memory optimizations are enabled, the buffers\n            allocated by the optimizations are deallocated during backward pass\n            in the absence of backward pass the buffers should be reset after each\n            forward pass'''", "\n", "if", "args", ".", "deepspeed", "and", "args", ".", "deepspeed_activation_checkpointing", ":", "\n", "                ", "deepspeed", ".", "checkpointing", ".", "reset", "(", ")", "\n", "\n", "# Reduce across processes.", "\n", "", "if", "isinstance", "(", "model", ",", "DDP", ")", ":", "\n", "                ", "torch", ".", "distributed", ".", "all_reduce", "(", "lm_loss", ".", "data", ")", "\n", "lm_loss", ".", "data", "=", "lm_loss", ".", "data", "/", "args", ".", "world_size", "\n", "\n", "", "total_lm_loss", "+=", "lm_loss", ".", "data", ".", "detach", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Move model back to the train mode.", "\n", "", "", "model", ".", "train", "(", ")", "\n", "args", ".", "is_sparse", "=", "is_sparse_raw", "\n", "\n", "total_lm_loss", "/=", "args", ".", "eval_iters", "\n", "return", "total_lm_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.evaluate_and_print_results": [[610, 618], ["pretrain_gpt2.evaluate", "math.exp", "pretrain_gpt2.report_evaluate_metrics", "min"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.evaluate", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.report_evaluate_metrics"], ["", "def", "evaluate_and_print_results", "(", "prefix", ",", "data_iterator", ",", "model", ",", "\n", "args", ",", "timers", ",", "verbose", "=", "False", ",", "step", "=", "None", ",", "summary_writer", "=", "None", ")", ":", "\n", "    ", "\"\"\"Helper function to evaluate and dump results on screen.\"\"\"", "\n", "lm_loss", "=", "evaluate", "(", "data_iterator", ",", "model", ",", "args", ",", "timers", ",", "verbose", ")", "\n", "lm_ppl", "=", "math", ".", "exp", "(", "min", "(", "20", ",", "lm_loss", ")", ")", "\n", "report_evaluate_metrics", "(", "summary_writer", ",", "prefix", ",", "lm_loss", ",", "lm_ppl", ",", "step", ")", "\n", "\n", "return", "lm_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.set_deepspeed_activation_checkpointing": [[636, 641], ["deepspeed.checkpointing.configure"], "function", ["None"], ["def", "set_deepspeed_activation_checkpointing", "(", "args", ")", ":", "\n", "    ", "deepspeed", ".", "checkpointing", ".", "configure", "(", "mpu", ",", "deepspeed_config", "=", "args", ".", "deepspeed_config", ",", "num_checkpoints", "=", "args", ".", "num_layers", ")", "\n", "mpu", ".", "checkpoint", "=", "deepspeed", ".", "checkpointing", ".", "checkpoint", "\n", "mpu", ".", "get_cuda_rng_tracker", "=", "deepspeed", ".", "checkpointing", ".", "get_cuda_rng_tracker", "\n", "mpu", ".", "model_parallel_cuda_manual_seed", "=", "deepspeed", ".", "checkpointing", ".", "model_parallel_cuda_manual_seed", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.initialize_distributed": [[643, 668], ["torch.cuda.set_device", "torch.cuda.set_device", "os.getenv", "os.getenv", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "mpu.initialize_model_parallel", "torch.cuda.device_count", "torch.cuda.device_count", "hasattr", "pretrain_gpt2.set_deepspeed_activation_checkpointing"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.initialize_model_parallel", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.set_deepspeed_activation_checkpointing"], ["", "def", "initialize_distributed", "(", "args", ")", ":", "\n", "    ", "\"\"\"Initialize torch.distributed.\"\"\"", "\n", "\n", "# Manually set the device ids.", "\n", "device", "=", "args", ".", "rank", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "args", ".", "local_rank", "is", "not", "None", ":", "\n", "        ", "device", "=", "args", ".", "local_rank", "\n", "", "torch", ".", "cuda", ".", "set_device", "(", "device", ")", "\n", "# Call the init process", "\n", "init_method", "=", "'tcp://'", "\n", "master_ip", "=", "os", ".", "getenv", "(", "'MASTER_ADDR'", ",", "'localhost'", ")", "\n", "master_port", "=", "os", ".", "getenv", "(", "'MASTER_PORT'", ",", "'6000'", ")", "\n", "init_method", "+=", "master_ip", "+", "':'", "+", "master_port", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "args", ".", "distributed_backend", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "rank", "=", "args", ".", "rank", ",", "\n", "init_method", "=", "init_method", ")", "\n", "\n", "# Set the model-parallel / data-parallel communicators.", "\n", "mpu", ".", "initialize_model_parallel", "(", "args", ".", "model_parallel_size", ")", "\n", "\n", "# Optional DeepSpeed Activation Checkpointing Features", "\n", "#", "\n", "if", "hasattr", "(", "args", ",", "\"deepspeed\"", ")", "and", "args", ".", "deepspeed", "and", "args", ".", "deepspeed_activation_checkpointing", ":", "\n", "        ", "set_deepspeed_activation_checkpointing", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.set_random_seed": [[670, 678], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "mpu.model_parallel_cuda_manual_seed"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.model_parallel_cuda_manual_seed"], ["", "", "def", "set_random_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"Set random seed for reproducability.\"\"\"", "\n", "\n", "if", "seed", "is", "not", "None", "and", "seed", ">", "0", ":", "\n", "        ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "mpu", ".", "model_parallel_cuda_manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_train_val_test_data": [[680, 713], ["torch.distributed.broadcast", "torch.distributed.broadcast", "token_counts[].item", "token_counts[].item", "token_counts[].item", "token_counts[].item", "mpu.get_model_parallel_rank", "data_utils.make_loaders", "utils.print_rank_0", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "mpu.get_model_parallel_src_rank", "data_utils.get_tokenizer", "mpu.get_model_parallel_world_size", "mpu.get_model_parallel_group", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_loaders", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_src_rank", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group"], ["", "", "def", "get_train_val_test_data", "(", "args", ")", ":", "\n", "    ", "\"\"\"Load the data on rank zero and boradcast number of tokens to all GPUS.\"\"\"", "\n", "\n", "(", "train_data", ",", "val_data", ",", "test_data", ")", "=", "(", "None", ",", "None", ",", "None", ")", "\n", "\n", "# Data loader only on rank 0 of each model parallel group.", "\n", "if", "mpu", ".", "get_model_parallel_rank", "(", ")", "==", "0", ":", "\n", "        ", "train_data", ",", "val_data", ",", "test_data", "=", "make_loaders", "(", "args", ")", "\n", "num_tokens", "=", "get_tokenizer", "(", ")", ".", "num_tokens", "\n", "\n", "before", "=", "num_tokens", "\n", "after", "=", "before", "\n", "multiple", "=", "args", ".", "make_vocab_size_divisible_by", "*", "mpu", ".", "get_model_parallel_world_size", "(", ")", "\n", "while", "(", "after", "%", "multiple", ")", "!=", "0", ":", "\n", "            ", "after", "+=", "1", "\n", "", "print_rank_0", "(", "'> padded vocab (size: {}) with {} dummy '", "\n", "'tokens (new size: {})'", ".", "format", "(", "\n", "before", ",", "after", "-", "before", ",", "after", ")", ")", "\n", "token_counts", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "\n", "[", "after", ",", "int", "(", "args", ".", "do_train", ")", ",", "int", "(", "args", ".", "do_valid", ")", ",", "int", "(", "args", ".", "do_test", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "token_counts", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "# Broadcast num tokens.", "\n", "", "torch", ".", "distributed", ".", "broadcast", "(", "token_counts", ",", "\n", "mpu", ".", "get_model_parallel_src_rank", "(", ")", ",", "\n", "group", "=", "mpu", ".", "get_model_parallel_group", "(", ")", ")", "\n", "num_tokens", "=", "token_counts", "[", "0", "]", ".", "item", "(", ")", "\n", "args", ".", "do_train", "=", "token_counts", "[", "1", "]", ".", "item", "(", ")", "\n", "args", ".", "do_valid", "=", "token_counts", "[", "2", "]", ".", "item", "(", ")", "\n", "args", ".", "do_test", "=", "token_counts", "[", "3", "]", ".", "item", "(", ")", "\n", "\n", "return", "train_data", ",", "val_data", ",", "test_data", ",", "num_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.main": [[715, 816], ["utils.Timers", "arguments.get_args", "pretrain_gpt2.initialize_distributed", "pretrain_gpt2.set_random_seed", "data_utils.get_tokenizer", "pretrain_gpt2.get_train_val_test_data", "pretrain_gpt2.setup_model_and_optimizer", "torch.distributed.barrier", "torch.distributed.barrier", "os.path.basename", "os.path.join", "torch.distributed.get_rank", "torch.distributed.get_rank", "utils.print_args", "utils.get_sample_writer", "iter", "iter", "utils.save_checkpoint", "iter", "pretrain_gpt2.evaluate_and_print_results", "os.path.normpath", "datetime.datetime.now().strftime", "utils.load_checkpoint", "print", "print", "pretrain_gpt2.evaluate_and_print_results", "filelock.FileLock", "utils.load_checkpoint", "len", "len", "contextlib.ExitStack", "pretrain_gpt2.train", "datetime.datetime.now", "utils.save_checkpoint"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.arguments.get_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.initialize_distributed", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.set_random_seed", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_train_val_test_data", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.setup_model_and_optimizer", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_args", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_sample_writer", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_checkpoint", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.evaluate_and_print_results", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_checkpoint", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.evaluate_and_print_results", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_checkpoint", "home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.train", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_checkpoint"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Main training program.\"\"\"", "\n", "\n", "# Disable CuDNN.", "\n", "torch", ".", "backends", ".", "cudnn", ".", "enabled", "=", "False", "\n", "# Timer.", "\n", "timers", "=", "Timers", "(", ")", "\n", "\n", "# Arguments.", "\n", "args", "=", "get_args", "(", ")", "\n", "if", "args", ".", "load", ":", "\n", "        ", "args", ".", "experiment_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "normpath", "(", "args", ".", "load", ")", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "experiment_name", "=", "args", ".", "experiment_name", "+", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%m-%d-%H-%M\"", ")", "\n", "", "if", "args", ".", "save", ":", "\n", "        ", "args", ".", "save", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "args", ".", "experiment_name", ")", "\n", "# Pytorch distributed.", "\n", "", "initialize_distributed", "(", "args", ")", "\n", "\n", "# Random seeds for reproducability.", "\n", "set_random_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# init tokenizer", "\n", "tokenizer", "=", "get_tokenizer", "(", "args", ")", "\n", "\n", "# Data stuff.", "\n", "train_data", ",", "val_data", ",", "test_data", ",", "args", ".", "vocab_size", "=", "get_train_val_test_data", "(", "args", ")", "\n", "\n", "# Model, optimizer, and learning rate.", "\n", "model", ",", "optimizer", ",", "lr_scheduler", "=", "setup_model_and_optimizer", "(", "args", ")", "\n", "\n", "if", "args", ".", "load", "is", "not", "None", ":", "\n", "        ", "if", "args", ".", "fast_load", ":", "\n", "            ", "args", ".", "iteration", "=", "load_checkpoint", "(", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ")", "\n", "", "else", ":", "\n", "            ", "with", "FileLock", "(", "\"/root/checkpoint_lock\"", ",", "timeout", "=", "-", "1", ")", ":", "\n", "                ", "args", ".", "iteration", "=", "load_checkpoint", "(", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ")", "\n", "", "", "", "else", ":", "\n", "        ", "args", ".", "iteration", "=", "0", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "summary_writer", "=", "None", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "if", "args", ".", "finetune", ":", "\n", "            ", "print", "(", "'Finetune CogView model'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Pretrain CogView model'", ")", "\n", "", "print_args", "(", "args", ")", "\n", "summary_writer", "=", "get_sample_writer", "(", "base", "=", "args", ".", "summary_dir", ",", "name", "=", "args", ".", "experiment_name", ",", "iteration", "=", "args", ".", "iteration", ")", "\n", "\n", "# Resume data loader if necessary.", "\n", "", "if", "args", ".", "resume_dataloader", ":", "\n", "        ", "if", "train_data", "is", "not", "None", ":", "\n", "            ", "train_data", ".", "batch_sampler", ".", "start_iter", "=", "args", ".", "iteration", "%", "len", "(", "train_data", ")", "\n", "", "if", "val_data", "is", "not", "None", ":", "\n", "            ", "start_iter_val", "=", "(", "args", ".", "train_iters", "//", "args", ".", "save_interval", ")", "*", "args", ".", "eval_interval", "\n", "val_data", ".", "batch_sampler", ".", "start_iter", "=", "start_iter_val", "%", "len", "(", "val_data", ")", "\n", "", "", "if", "train_data", "is", "not", "None", ":", "\n", "        ", "train_data_iterator", "=", "iter", "(", "train_data", ")", "\n", "", "else", ":", "\n", "        ", "train_data_iterator", "=", "None", "\n", "", "if", "val_data", "is", "not", "None", ":", "\n", "        ", "val_data_iterator", "=", "iter", "(", "val_data", ")", "\n", "", "else", ":", "\n", "        ", "val_data_iterator", "=", "None", "\n", "\n", "# TODO: figure out how to properly set this especially when resuming training", "\n", "", "iteration", "=", "0", "\n", "if", "args", ".", "train_iters", ">", "0", ":", "\n", "        ", "if", "args", ".", "do_train", ":", "\n", "            ", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "                ", "def", "save_on_exit", "(", "args_", ",", "model_", ",", "optimizer_", ",", "lr_scheduler_", ")", ":", "\n", "                    ", "save_checkpoint", "(", "args_", ".", "iteration", ",", "model_", ",", "optimizer_", ",", "lr_scheduler_", ",", "args_", ")", "\n", "# stack.callback(save_on_exit, args, model, optimizer, lr_scheduler)", "\n", "", "iteration", ",", "skipped", "=", "train", "(", "model", ",", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "train_data_iterator", ",", "\n", "val_data_iterator", ",", "\n", "timers", ",", "args", ",", "summary_writer", "=", "summary_writer", ")", "\n", "\n", "", "", "if", "args", ".", "do_valid", ":", "\n", "            ", "prefix", "=", "'the end of training for val data'", "\n", "val_loss", "=", "evaluate_and_print_results", "(", "prefix", ",", "val_data_iterator", ",", "\n", "model", ",", "args", ",", "timers", ",", "False", ")", "\n", "\n", "", "", "if", "args", ".", "save", "and", "iteration", "!=", "0", ":", "\n", "        ", "save_checkpoint", "(", "iteration", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ")", "\n", "\n", "", "if", "test_data", "is", "not", "None", ":", "\n", "        ", "test_data_iterator", "=", "iter", "(", "test_data", ")", "\n", "", "else", ":", "\n", "        ", "test_data_iterator", "=", "None", "\n", "\n", "", "if", "args", ".", "do_test", ":", "\n", "# Run on test data.", "\n", "        ", "prefix", "=", "'the end of training for test data'", "\n", "evaluate_and_print_results", "(", "prefix", ",", "test_data_iterator", ",", "\n", "model", ",", "args", ",", "timers", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.learning_rates.AnnealingLR.__init__": [[26, 38], ["learning_rates.AnnealingLR.step", "isinstance", "decay_style.lower", "print", "torch.distributed.is_initialized", "torch.distributed.get_rank"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "start_lr", ",", "warmup_iter", ",", "num_iters", ",", "decay_style", "=", "None", ",", "last_iter", "=", "-", "1", ",", "decay_ratio", "=", "0.5", ")", ":", "\n", "        ", "assert", "warmup_iter", "<=", "num_iters", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "start_lr", "=", "start_lr", "\n", "self", ".", "warmup_iter", "=", "warmup_iter", "\n", "self", ".", "num_iters", "=", "last_iter", "+", "1", "\n", "self", ".", "end_iter", "=", "num_iters", "\n", "self", ".", "decay_style", "=", "decay_style", ".", "lower", "(", ")", "if", "isinstance", "(", "decay_style", ",", "str", ")", "else", "None", "\n", "self", ".", "decay_ratio", "=", "1", "/", "decay_ratio", "\n", "self", ".", "step", "(", "self", ".", "num_iters", ")", "\n", "if", "not", "torch", ".", "distributed", ".", "is_initialized", "(", ")", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "f'learning rate decaying style {self.decay_style}, ratio {self.decay_ratio}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.learning_rates.AnnealingLR.get_lr": [[39, 55], ["float", "min", "math.cos"], "methods", ["None"], ["", "", "def", "get_lr", "(", "self", ")", ":", "\n", "# https://openreview.net/pdf?id=BJYwwY9ll pg. 4", "\n", "        ", "if", "self", ".", "warmup_iter", ">", "0", "and", "self", ".", "num_iters", "<=", "self", ".", "warmup_iter", ":", "\n", "            ", "return", "float", "(", "self", ".", "start_lr", ")", "*", "self", ".", "num_iters", "/", "self", ".", "warmup_iter", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "decay_style", "==", "self", ".", "DECAY_STYLES", "[", "0", "]", ":", "\n", "                ", "return", "self", ".", "start_lr", "*", "(", "(", "self", ".", "end_iter", "-", "(", "self", ".", "num_iters", "-", "self", ".", "warmup_iter", ")", ")", "/", "self", ".", "end_iter", ")", "\n", "", "elif", "self", ".", "decay_style", "==", "self", ".", "DECAY_STYLES", "[", "1", "]", ":", "\n", "                ", "decay_step_ratio", "=", "min", "(", "1.0", ",", "(", "self", ".", "num_iters", "-", "self", ".", "warmup_iter", ")", "/", "self", ".", "end_iter", ")", "\n", "return", "self", ".", "start_lr", "/", "self", ".", "decay_ratio", "*", "(", "\n", "(", "math", ".", "cos", "(", "math", ".", "pi", "*", "decay_step_ratio", ")", "+", "1", ")", "*", "(", "self", ".", "decay_ratio", "-", "1", ")", "/", "2", "+", "1", ")", "\n", "", "elif", "self", ".", "decay_style", "==", "self", ".", "DECAY_STYLES", "[", "2", "]", ":", "\n", "#TODO: implement exponential decay", "\n", "                ", "return", "self", ".", "start_lr", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "start_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.learning_rates.AnnealingLR.step": [[56, 63], ["learning_rates.AnnealingLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.None.learning_rates.AnnealingLR.get_lr"], ["", "", "", "def", "step", "(", "self", ",", "step_num", "=", "None", ")", ":", "\n", "        ", "if", "step_num", "is", "None", ":", "\n", "            ", "step_num", "=", "self", ".", "num_iters", "+", "1", "\n", "", "self", ".", "num_iters", "=", "step_num", "\n", "new_lr", "=", "self", ".", "get_lr", "(", ")", "\n", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "group", "[", "'lr'", "]", "=", "new_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.learning_rates.AnnealingLR.state_dict": [[64, 74], ["None"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "sd", "=", "{", "\n", "# 'start_lr': self.start_lr,", "\n", "'warmup_iter'", ":", "self", ".", "warmup_iter", ",", "\n", "'num_iters'", ":", "self", ".", "num_iters", ",", "\n", "'decay_style'", ":", "self", ".", "decay_style", ",", "\n", "'end_iter'", ":", "self", ".", "end_iter", ",", "\n", "'decay_ratio'", ":", "self", ".", "decay_ratio", "\n", "}", "\n", "return", "sd", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.learning_rates.AnnealingLR.load_state_dict": [[75, 84], ["learning_rates.AnnealingLR.step"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step"], ["", "def", "load_state_dict", "(", "self", ",", "sd", ")", ":", "\n", "# self.start_lr = sd['start_lr']", "\n", "        ", "self", ".", "warmup_iter", "=", "sd", "[", "'warmup_iter'", "]", "\n", "self", ".", "num_iters", "=", "sd", "[", "'num_iters'", "]", "\n", "# self.end_iter = sd['end_iter']", "\n", "self", ".", "decay_style", "=", "sd", "[", "'decay_style'", "]", "\n", "if", "'decay_ratio'", "in", "sd", ":", "\n", "            ", "self", ".", "decay_ratio", "=", "sd", "[", "'decay_ratio'", "]", "\n", "", "self", ".", "step", "(", "self", ".", "num_iters", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.None.test_lmdb.initialize": [[5, 8], ["lmdb.open"], "function", ["None"], ["def", "initialize", "(", "file_name", ")", ":", "\n", "    ", "env", "=", "lmdb", ".", "open", "(", "file_name", ",", "\"r\"", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.test_lmdb.insert": [[9, 13], ["env.begin", "env.begin.put", "env.begin.commit", "str().encode", "name.encode", "str"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "def", "insert", "(", "env", ",", "sid", ",", "name", ")", ":", "\n", "    ", "txn", "=", "env", ".", "begin", "(", "write", "=", "True", ")", "\n", "txn", ".", "put", "(", "str", "(", "sid", ")", ".", "encode", "(", "'utf-8'", ")", ",", "name", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "txn", ".", "commit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.test_lmdb.delete": [[14, 18], ["env.begin", "env.begin.delete", "env.begin.commit", "str().encode", "str"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.test_lmdb.delete", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "def", "delete", "(", "env", ",", "sid", ")", ":", "\n", "    ", "txn", "=", "env", ".", "begin", "(", "write", "=", "True", ")", "\n", "txn", ".", "delete", "(", "str", "(", "sid", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "txn", ".", "commit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.test_lmdb.update": [[19, 23], ["env.begin", "env.begin.put", "env.begin.commit", "str().encode", "name.encode", "str"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "def", "update", "(", "env", ",", "sid", ",", "name", ")", ":", "\n", "    ", "txn", "=", "env", ".", "begin", "(", "write", "=", "True", ")", "\n", "txn", ".", "put", "(", "str", "(", "sid", ")", ".", "encode", "(", "'utf-8'", ")", ",", "name", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "txn", ".", "commit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.test_lmdb.search": [[26, 30], ["env.begin", "pickle.loads", "env.begin.get", "str().encode", "str"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["def", "search", "(", "env", ",", "sid", ")", ":", "\n", "    ", "txn", "=", "env", ".", "begin", "(", ")", "\n", "data", "=", "pickle", ".", "loads", "(", "txn", ".", "get", "(", "str", "(", "sid", ")", ".", "encode", "(", "'utf-8'", ")", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.__init__": [[124, 126], ["None"], "methods", ["None"], ["", "", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "timers", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.__call__": [[127, 131], ["utils.Timers.Timer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "not", "in", "self", ".", "timers", ":", "\n", "            ", "self", ".", "timers", "[", "name", "]", "=", "self", ".", "Timer", "(", "name", ")", "\n", "", "return", "self", ".", "timers", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log": [[132, 141], ["utils.print_rank_0", "utils.Timers.timers[].elapsed"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0"], ["", "def", "log", "(", "self", ",", "names", ",", "normalizer", "=", "1.0", ",", "reset", "=", "True", ")", ":", "\n", "        ", "\"\"\"Log a group of timers.\"\"\"", "\n", "assert", "normalizer", ">", "0.0", "\n", "string", "=", "'time (ms)'", "\n", "for", "name", "in", "names", ":", "\n", "            ", "elapsed_time", "=", "self", ".", "timers", "[", "name", "]", ".", "elapsed", "(", "\n", "reset", "=", "reset", ")", "*", "1000.0", "/", "normalizer", "\n", "string", "+=", "' | {}: {:.2f}'", ".", "format", "(", "name", ",", "elapsed_time", ")", "\n", "", "print_rank_0", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_sample_writer": [[33, 38], ["tensorboardX.SummaryWriter", "os.path.join"], "function", ["None"], ["def", "get_sample_writer", "(", "name", ",", "base", "=", "\"..\"", ",", "iteration", "=", "0", ")", ":", "\n", "    ", "\"\"\"Returns a tensorboard summary writer\n    \"\"\"", "\n", "return", "SummaryWriter", "(", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "base", ",", "SUMMARY_WRITER_DIR_NAME", ",", "name", ")", ",", "purge_step", "=", "iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0": [[40, 46], ["torch.distributed.is_initialized", "print", "torch.distributed.get_rank", "print"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["", "def", "print_rank_0", "(", "message", ")", ":", "\n", "    ", "if", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "message", ",", "flush", "=", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "message", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_args": [[48, 55], ["print", "vars", "print", "len", "getattr"], "function", ["None"], ["", "", "def", "print_args", "(", "args", ")", ":", "\n", "    ", "\"\"\"Print arguments.\"\"\"", "\n", "\n", "print", "(", "'arguments:'", ",", "flush", "=", "True", ")", "\n", "for", "arg", "in", "vars", "(", "args", ")", ":", "\n", "        ", "dots", "=", "'.'", "*", "(", "29", "-", "len", "(", "arg", ")", ")", "\n", "print", "(", "'  {} {} {}'", ".", "format", "(", "arg", ",", "dots", ",", "getattr", "(", "args", ",", "arg", ")", ")", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_params_min_max_norm": [[57, 75], ["torch.distributed.get_rank", "isinstance", "print", "param.data.min", "param.data.max", "param.data.norm", "int"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["", "", "def", "print_params_min_max_norm", "(", "optimizer", ",", "iteration", ")", ":", "\n", "    ", "\"\"\"Print min, max, and norm of all parameters.\"\"\"", "\n", "index", "=", "0", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "string", "=", "'iteration, rank, index, model-parallel,min, max, norm\\n'", "\n", "optimizer_", "=", "optimizer", "\n", "if", "isinstance", "(", "optimizer", ",", "FP16_Optimizer", ")", ":", "\n", "        ", "optimizer_", "=", "optimizer", ".", "optimizer", "\n", "", "for", "param_group", "in", "optimizer_", ".", "param_groups", ":", "\n", "        ", "for", "param", "in", "param_group", "[", "'params'", "]", ":", "\n", "            ", "index", "+=", "1", "\n", "min_", "=", "param", ".", "data", ".", "min", "(", ")", "\n", "max_", "=", "param", ".", "data", ".", "max", "(", ")", "\n", "norm", "=", "param", ".", "data", ".", "norm", "(", ")", "\n", "string", "+=", "'{:7d}, {:4d}, {:4d}, {:2d}, '", ".", "format", "(", "\n", "iteration", ",", "rank", ",", "index", ",", "int", "(", "param", ".", "model_parallel", ")", ")", "\n", "string", "+=", "'{:.6E}, {:.6E}, {:.6E}\\n'", ".", "format", "(", "min_", ",", "max_", ",", "norm", ")", "\n", "", "", "print", "(", "string", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.report_memory": [[143, 156], ["utils.print_rank_0", "torch.cuda.memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.memory_cached", "torch.cuda.memory_reserved"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0"], ["", "", "def", "report_memory", "(", "name", ")", ":", "\n", "    ", "\"\"\"Simple GPU memory report.\"\"\"", "\n", "\n", "mega_bytes", "=", "1024.0", "*", "1024.0", "\n", "string", "=", "name", "+", "' memory (MB)'", "\n", "string", "+=", "' | allocated: {}'", ".", "format", "(", "\n", "torch", ".", "cuda", ".", "memory_allocated", "(", ")", "/", "mega_bytes", ")", "\n", "string", "+=", "' | max allocated: {}'", ".", "format", "(", "\n", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "mega_bytes", ")", "\n", "string", "+=", "' | cached: {}'", ".", "format", "(", "torch", ".", "cuda", ".", "memory_cached", "(", ")", "/", "mega_bytes", ")", "\n", "string", "+=", "' | max cached: {}'", ".", "format", "(", "\n", "torch", ".", "cuda", ".", "memory_reserved", "(", ")", "/", "mega_bytes", ")", "\n", "print_rank_0", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_name": [[158, 167], ["os.path.join", "mpu.get_data_parallel_rank", "mpu.get_model_parallel_rank"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank"], ["", "def", "get_checkpoint_name", "(", "checkpoints_path", ",", "iteration", ",", "release", "=", "False", ",", "zero", "=", "False", ")", ":", "\n", "    ", "if", "release", ":", "\n", "        ", "d", "=", "'release'", "\n", "", "else", ":", "\n", "        ", "d", "=", "'{:d}'", ".", "format", "(", "iteration", ")", "\n", "", "if", "zero", ":", "\n", "        ", "dp_rank", "=", "mpu", ".", "get_data_parallel_rank", "(", ")", "\n", "d", "+=", "'_zero_dp_rank_{}'", ".", "format", "(", "dp_rank", ")", "\n", "", "return", "os", ".", "path", ".", "join", "(", "checkpoints_path", ",", "d", ",", "'mp_rank_{:02d}_model_states.pt'", ".", "format", "(", "mpu", ".", "get_model_parallel_rank", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.ensure_directory_exists": [[169, 173], ["os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "ensure_directory_exists", "(", "filename", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_tracker_filename": [[175, 177], ["os.path.join"], "function", ["None"], ["", "", "def", "get_checkpoint_tracker_filename", "(", "checkpoints_path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "checkpoints_path", ",", "'latest_checkpointed_iteration.txt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_zero_checkpoint": [[179, 186], ["utils.get_checkpoint_name", "utils.ensure_directory_exists", "torch.save", "print", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_name", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.ensure_directory_exists", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict"], ["", "def", "save_zero_checkpoint", "(", "args", ",", "iteration", ",", "optimizer", ")", ":", "\n", "    ", "zero_sd", "=", "{", "'iteration'", ":", "iteration", ",", "\n", "'optimizer_state_dict'", ":", "optimizer", ".", "state_dict", "(", ")", "}", "\n", "zero_checkpoint_name", "=", "get_checkpoint_name", "(", "args", ".", "save", ",", "iteration", ",", "zero", "=", "True", ")", "\n", "ensure_directory_exists", "(", "zero_checkpoint_name", ")", "\n", "torch", ".", "save", "(", "zero_sd", ",", "zero_checkpoint_name", ")", "\n", "print", "(", "'  successfully saved {}'", ".", "format", "(", "zero_checkpoint_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_checkpoint": [[188, 235], ["torch.distributed.barrier", "torch.distributed.barrier", "utils.save_ds_checkpoint", "isinstance", "torch.distributed.get_rank", "utils.get_checkpoint_tracker_filename", "mpu.get_data_parallel_rank", "utils.get_checkpoint_name", "print", "model.state_dict", "utils.ensure_directory_exists", "torch.save", "print", "open", "f.write", "random.getstate", "numpy.random.get_state", "torch.get_rng_state", "torch.cuda.get_rng_state", "mpu.get_cuda_rng_tracker().get_states", "str", "torch.distributed.get_rank", "optimizer.state_dict", "lr_scheduler.state_dict", "mpu.get_cuda_rng_tracker"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_ds_checkpoint", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_tracker_filename", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_name", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.ensure_directory_exists", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.get_states", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker"], ["", "def", "save_checkpoint", "(", "iteration", ",", "model", ",", "optimizer", ",", "\n", "lr_scheduler", ",", "args", ")", ":", "\n", "    ", "\"\"\"Save a model checkpoint.\"\"\"", "\n", "if", "args", ".", "deepspeed", ":", "\n", "        ", "save_ds_checkpoint", "(", "iteration", ",", "model", ",", "lr_scheduler", ",", "args", ")", "\n", "", "else", ":", "\n", "# Only rank zer0 of the data parallel writes to the disk.", "\n", "        ", "if", "isinstance", "(", "model", ",", "torchDDP", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "\n", "", "if", "mpu", ".", "get_data_parallel_rank", "(", ")", "==", "0", ":", "\n", "            ", "checkpoint_name", "=", "get_checkpoint_name", "(", "args", ".", "save", ",", "iteration", ")", "\n", "print", "(", "'global rank {} is saving checkpoint at iteration {:7d} to {}'", ".", "\n", "format", "(", "torch", ".", "distributed", ".", "get_rank", "(", ")", ",", "iteration", ",", "checkpoint_name", ")", ")", "\n", "\n", "sd", "=", "{", "}", "\n", "sd", "[", "'iteration'", "]", "=", "iteration", "\n", "sd", "[", "'module'", "]", "=", "model", ".", "state_dict", "(", ")", "\n", "\n", "# Optimizer stuff.", "\n", "if", "not", "args", ".", "no_save_optim", ":", "\n", "                ", "if", "optimizer", "is", "not", "None", ":", "\n", "                    ", "sd", "[", "'optimizer'", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "                    ", "sd", "[", "'lr_scheduler'", "]", "=", "lr_scheduler", ".", "state_dict", "(", ")", "\n", "\n", "# rng states.", "\n", "", "", "if", "not", "args", ".", "no_save_rng", ":", "\n", "                ", "sd", "[", "'random_rng_state'", "]", "=", "random", ".", "getstate", "(", ")", "\n", "sd", "[", "'np_rng_state'", "]", "=", "np", ".", "random", ".", "get_state", "(", ")", "\n", "sd", "[", "'torch_rng_state'", "]", "=", "torch", ".", "get_rng_state", "(", ")", "\n", "sd", "[", "'cuda_rng_state'", "]", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "sd", "[", "'rng_tracker_states'", "]", "=", "mpu", ".", "get_cuda_rng_tracker", "(", ")", ".", "get_states", "(", ")", "\n", "\n", "", "ensure_directory_exists", "(", "checkpoint_name", ")", "\n", "torch", ".", "save", "(", "sd", ",", "checkpoint_name", ")", "\n", "print", "(", "'  successfully saved {}'", ".", "format", "(", "checkpoint_name", ")", ")", "\n", "\n", "# Wait so everyone is done (necessary)", "\n", "", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "# And update the latest iteration", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "tracker_filename", "=", "get_checkpoint_tracker_filename", "(", "args", ".", "save", ")", "\n", "with", "open", "(", "tracker_filename", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "iteration", ")", ")", "\n", "# Wait so everyone is done (not necessary)", "\n", "", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_ds_checkpoint": [[237, 253], ["model.save_checkpoint", "lr_scheduler.state_dict", "random.getstate", "numpy.random.get_state", "torch.get_rng_state", "torch.cuda.get_rng_state", "mpu.get_cuda_rng_tracker().get_states", "str", "mpu.get_cuda_rng_tracker"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.save_checkpoint", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.get_states", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker"], ["", "def", "save_ds_checkpoint", "(", "iteration", ",", "model", ",", "lr_scheduler", ",", "args", ")", ":", "\n", "    ", "\"\"\"Save a model checkpoint.\"\"\"", "\n", "\n", "sd", "=", "{", "}", "\n", "sd", "[", "'iteration'", "]", "=", "iteration", "\n", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "        ", "sd", "[", "'client_lr_scheduler'", "]", "=", "lr_scheduler", ".", "state_dict", "(", ")", "\n", "# rng states.", "\n", "", "if", "not", "args", ".", "no_save_rng", ":", "\n", "        ", "sd", "[", "'random_rng_state'", "]", "=", "random", ".", "getstate", "(", ")", "\n", "sd", "[", "'np_rng_state'", "]", "=", "np", ".", "random", ".", "get_state", "(", ")", "\n", "sd", "[", "'torch_rng_state'", "]", "=", "torch", ".", "get_rng_state", "(", ")", "\n", "sd", "[", "'cuda_rng_state'", "]", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "sd", "[", "'rng_tracker_states'", "]", "=", "mpu", ".", "get_cuda_rng_tracker", "(", ")", ".", "get_states", "(", ")", "\n", "\n", "", "model", ".", "save_checkpoint", "(", "args", ".", "save", ",", "str", "(", "iteration", ")", ",", "client_state", "=", "sd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_iteration": [[255, 281], ["utils.get_checkpoint_tracker_filename", "os.path.isfile", "utils.print_rank_0", "utils.print_rank_0", "open", "f.read().strip", "int", "f.read", "utils.print_rank_0", "exit"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_tracker_filename", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0"], ["", "def", "get_checkpoint_iteration", "(", "args", ")", ":", "\n", "# Read the tracker file and set the iteration.", "\n", "    ", "tracker_filename", "=", "get_checkpoint_tracker_filename", "(", "args", ".", "load", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "tracker_filename", ")", ":", "\n", "        ", "print_rank_0", "(", "'WARNING: could not find the metadata file {} '", ".", "format", "(", "\n", "tracker_filename", ")", ")", "\n", "print_rank_0", "(", "'    will not load any checkpoints and will start from '", "\n", "'random'", ")", "\n", "return", "0", ",", "False", ",", "False", "\n", "", "iteration", "=", "0", "\n", "release", "=", "False", "\n", "with", "open", "(", "tracker_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "metastring", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "try", ":", "\n", "            ", "iteration", "=", "int", "(", "metastring", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "release", "=", "metastring", "==", "'release'", "\n", "if", "not", "release", ":", "\n", "                ", "print_rank_0", "(", "'ERROR: Invalid metadata file {}. Exiting'", ".", "format", "(", "\n", "tracker_filename", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "", "assert", "iteration", ">", "0", "or", "release", ",", "'error parsing metadata file {}'", ".", "format", "(", "\n", "tracker_filename", ")", "\n", "\n", "return", "iteration", ",", "release", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.extend_position_embedding": [[283, 288], ["weight.expand().reshape", "weight.expand"], "function", ["None"], ["", "def", "extend_position_embedding", "(", "weight", ",", "length", ")", ":", "\n", "    ", "ori_length", ",", "hidden_size", "=", "weight", ".", "shape", "\n", "assert", "length", "%", "ori_length", "==", "0", "\n", "position_embeddings", "=", "weight", ".", "expand", "(", "length", "//", "ori_length", ",", "-", "1", ",", "-", "1", ")", ".", "reshape", "(", "length", ",", "hidden_size", ")", "\n", "return", "position_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_checkpoint": [[289, 381], ["utils.get_checkpoint_iteration", "model.load_checkpoint", "utils.get_checkpoint_name", "torch.load", "isinstance", "mpu.get_data_parallel_rank", "print", "model.optimizer.refresh_fp32_params", "lr_scheduler.load_state_dict", "utils.print_rank_0", "mpu.get_data_parallel_rank", "print", "model.load_state_dict", "random.setstate", "numpy.random.set_state", "torch.set_rng_state", "torch.cuda.set_rng_state", "mpu.get_cuda_rng_tracker().set_states", "mpu.get_data_parallel_rank", "print", "utils.print_rank_0", "exit", "utils.print_rank_0", "exit", "torch.distributed.get_rank", "optimizer.load_state_dict", "lr_scheduler.load_state_dict", "utils.print_rank_0", "exit", "mpu.get_cuda_rng_tracker", "utils.print_rank_0", "exit"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_iteration", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_checkpoint", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.get_checkpoint_name", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.set_states", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.print_rank_0"], ["", "def", "load_checkpoint", "(", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ",", "load_optimizer_states", "=", "True", ")", ":", "\n", "    ", "\"\"\"Load a model checkpoint.\"\"\"", "\n", "\n", "iteration", ",", "release", ",", "success", "=", "get_checkpoint_iteration", "(", "args", ")", "\n", "\n", "if", "not", "success", ":", "\n", "        ", "return", "0", "\n", "\n", "", "if", "args", ".", "deepspeed", ":", "\n", "\n", "        ", "checkpoint_name", ",", "sd", "=", "model", ".", "load_checkpoint", "(", "args", ".", "load", ",", "iteration", ",", "load_optimizer_states", "=", "not", "args", ".", "no_load_optim", ")", "\n", "if", "args", ".", "fp16", "and", "args", ".", "no_load_optim", ":", "\n", "            ", "model", ".", "optimizer", ".", "refresh_fp32_params", "(", ")", "\n", "\n", "", "if", "\"client_lr_scheduler\"", "in", "sd", ":", "\n", "            ", "lr_scheduler", ".", "load_state_dict", "(", "sd", "[", "\"client_lr_scheduler\"", "]", ")", "\n", "print_rank_0", "(", "\"Load lr scheduler state\"", ")", "\n", "", "if", "checkpoint_name", "is", "None", ":", "\n", "            ", "if", "mpu", ".", "get_data_parallel_rank", "(", ")", "==", "0", ":", "\n", "                ", "print", "(", "\"Unable to load checkpoint.\"", ")", "\n", "", "return", "iteration", "\n", "\n", "", "", "else", ":", "\n", "\n", "# Checkpoint.", "\n", "        ", "checkpoint_name", "=", "get_checkpoint_name", "(", "args", ".", "load", ",", "iteration", ",", "release", ")", "\n", "\n", "if", "mpu", ".", "get_data_parallel_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "'global rank {} is loading checkpoint {}'", ".", "format", "(", "\n", "torch", ".", "distributed", ".", "get_rank", "(", ")", ",", "checkpoint_name", ")", ")", "\n", "\n", "# Load the checkpoint.", "\n", "", "sd", "=", "torch", ".", "load", "(", "checkpoint_name", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "if", "isinstance", "(", "model", ",", "torchDDP", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "\n", "# Model.", "\n", "", "try", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "sd", "[", "'module'", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "print_rank_0", "(", "'A metadata file exists but unable to load model '", "\n", "'from checkpoint {}, exiting'", ".", "format", "(", "checkpoint_name", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "# Optimizer.", "\n", "", "if", "not", "release", "and", "not", "args", ".", "finetune", "and", "not", "args", ".", "no_load_optim", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "optimizer", "is", "not", "None", "and", "load_optimizer_states", ":", "\n", "                    ", "optimizer", ".", "load_state_dict", "(", "sd", "[", "'optimizer'", "]", ")", "\n", "", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "                    ", "lr_scheduler", ".", "load_state_dict", "(", "sd", "[", "'lr_scheduler'", "]", ")", "\n", "", "", "except", "KeyError", ":", "\n", "                ", "print_rank_0", "(", "'Unable to load optimizer from checkpoint {}, exiting. '", "\n", "'Specify --no-load-optim or --finetune to prevent '", "\n", "'attempting to load the optimizer '", "\n", "'state.'", ".", "format", "(", "checkpoint_name", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "# Iterations.", "\n", "", "", "", "if", "args", ".", "finetune", "or", "release", ":", "\n", "        ", "iteration", "=", "0", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "iteration", "=", "sd", "[", "'iteration'", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "try", ":", "# Backward compatible with older checkpoints", "\n", "                ", "iteration", "=", "sd", "[", "'total_iters'", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "print_rank_0", "(", "'A metadata file exists but Unable to load iteration '", "\n", "' from checkpoint {}, exiting'", ".", "format", "(", "checkpoint_name", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "# rng states.", "\n", "", "", "", "if", "not", "release", "and", "not", "args", ".", "finetune", "and", "not", "args", ".", "no_load_rng", ":", "\n", "        ", "try", ":", "\n", "            ", "random", ".", "setstate", "(", "sd", "[", "'random_rng_state'", "]", ")", "\n", "np", ".", "random", ".", "set_state", "(", "sd", "[", "'np_rng_state'", "]", ")", "\n", "torch", ".", "set_rng_state", "(", "sd", "[", "'torch_rng_state'", "]", ")", "\n", "torch", ".", "cuda", ".", "set_rng_state", "(", "sd", "[", "'cuda_rng_state'", "]", ")", "\n", "mpu", ".", "get_cuda_rng_tracker", "(", ")", ".", "set_states", "(", "sd", "[", "'rng_tracker_states'", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "print_rank_0", "(", "'Unable to load optimizer from checkpoint {}, exiting. '", "\n", "'Specify --no-load-rng or --finetune to prevent '", "\n", "'attempting to load the random '", "\n", "'state.'", ".", "format", "(", "checkpoint_name", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "if", "mpu", ".", "get_data_parallel_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "'  successfully loaded {}'", ".", "format", "(", "checkpoint_name", ")", ")", "\n", "\n", "", "return", "iteration", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights": [[383, 401], ["src.named_parameters", "str", "load.copy_", "type", "data.t().contiguous.t().contiguous", "data.t().contiguous.t"], "function", ["None"], ["", "def", "load_weights", "(", "src", ",", "dst", ",", "dst2src", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Loads weights from src to dst via in place copy.\n    src is a huggingface gpt2model, while dst is one of our models.\n    dst2src=True loads parameters from our models into huggingface's.\n    ^dst2src is still untested\n    \"\"\"", "\n", "conv_layer", "=", "'Conv1D'", "in", "str", "(", "type", "(", "src", ")", ")", "\n", "for", "n", ",", "p", "in", "src", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "dst2src", ":", "\n", "            ", "data", "=", "dst", ".", "_parameters", "[", "n", "]", ".", "data", "\n", "load", "=", "p", ".", "data", "\n", "", "else", ":", "\n", "            ", "data", "=", "p", ".", "data", "\n", "load", "=", "dst", ".", "_parameters", "[", "n", "]", ".", "data", "\n", "", "if", "conv_layer", "and", "'weight'", "in", "n", ":", "\n", "            ", "data", "=", "data", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "", "load", ".", "copy_", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_mlp": [[405, 408], ["utils.load_weights", "utils.load_weights"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights"], ["", "", "def", "load_mlp", "(", "our", ",", "oai", ",", "dst2src", "=", "False", ")", ":", "\n", "    ", "load_weights", "(", "oai", ".", "c_fc", ",", "our", ".", "dense_h_to_4h", ",", "dst2src", ")", "\n", "load_weights", "(", "oai", ".", "c_proj", ",", "our", ".", "dense_4h_to_h", ",", "dst2src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_attention": [[410, 413], ["utils.load_weights", "utils.load_weights"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights"], ["", "def", "load_attention", "(", "our", ",", "oai", ",", "dst2src", "=", "False", ")", ":", "\n", "    ", "load_weights", "(", "oai", ".", "c_attn", ",", "our", ".", "query_key_value", ",", "dst2src", ")", "\n", "load_weights", "(", "oai", ".", "c_proj", ",", "our", ".", "dense", ",", "dst2src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_transformer_layer": [[415, 420], ["utils.load_weights", "utils.load_weights", "utils.load_mlp", "utils.load_attention"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_mlp", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_attention"], ["", "def", "load_transformer_layer", "(", "our", ",", "oai", ",", "dst2src", "=", "False", ")", ":", "\n", "    ", "load_weights", "(", "oai", ".", "ln_1", ",", "our", ".", "input_layernorm", ",", "dst2src", ")", "\n", "load_weights", "(", "oai", ".", "ln_2", ",", "our", ".", "post_attention_layernorm", ",", "dst2src", ")", "\n", "load_mlp", "(", "our", ".", "mlp", ",", "oai", ".", "mlp", ",", "dst2src", ")", "\n", "load_attention", "(", "our", ".", "attention", ",", "oai", ".", "attn", ",", "dst2src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.move_weights": [[422, 438], ["utils.load_weights", "utils.load_weights", "utils.load_weights", "zip", "utils.load_transformer_layer"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_weights", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.load_transformer_layer"], ["", "def", "move_weights", "(", "our", ",", "oai", ",", "dst2src", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Loads weights from `oai` to `our` via in place copy.\n    `oai` is a huggingface gpt2model, while `our` is one of our models.\n    dst2src=True loads parameters from our models into huggingface's.\n    ^dst2src=True is still untested\n    \"\"\"", "\n", "#    while isinstance(our, (torchDDP, model.distributed.DistributedDataParallel, FP16_Module)):", "\n", "#        our=our.module", "\n", "transformer_model", "=", "oai", ".", "transformer", "\n", "load_weights", "(", "transformer_model", ".", "ln_f", ",", "our", ".", "transformer", ".", "final_layernorm", ",", "dst2src", ")", "\n", "load_weights", "(", "transformer_model", ".", "wte", ",", "our", ".", "word_embeddings", ",", "dst2src", ")", "\n", "load_weights", "(", "transformer_model", ".", "wpe", ",", "our", ".", "position_embeddings", ",", "dst2src", ")", "\n", "\n", "for", "our_layer", ",", "oai_layer", "in", "zip", "(", "our", ".", "transformer", ".", "layers", ",", "oai", ".", "transformer", ".", "h", ")", ":", "\n", "        ", "load_transformer_layer", "(", "our_layer", ",", "oai_layer", ",", "dst2src", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.generation.magnify.magnify": [[22, 44], ["int", "tokens_list.view", "torch.tensor", "torch.tensor", "tqdm.tqdm", "magnified_code.view", "math.sqrt", "tokens_list.view.new_zeros", "code[].reshape", "magnified_code[].reshape", "torch.cat", "torch.cat", "len", "torch.cat", "torch.cat", "sampling.filling_sequence", "magnified_code_part_completed[].view", "len", "slice"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.filling_sequence"], ["def", "magnify", "(", "model", ",", "tokenizer", ",", "tokens_list", ",", "text_token_list", ",", "args", ")", ":", "\n", "# 32 * 32 to 4 16 * 16", "\n", "        ", "s", "=", "int", "(", "math", ".", "sqrt", "(", "len", "(", "tokens_list", ")", "+", "1e-6", ")", ")", "\n", "assert", "s", "==", "32", "\n", "code", "=", "tokens_list", ".", "view", "(", "s", ",", "s", ")", "\n", "\n", "midfix", "=", "torch", ".", "tensor", "(", "[", "tokenizer", "[", "'[EOI1]'", "]", ",", "tokenizer", "[", "'[ROI2]'", "]", ",", "tokenizer", "[", "'[POS0]'", "]", ",", "tokenizer", "[", "'[BASE]'", "]", ",", "tokenizer", "[", "'[BOI2]'", "]", "]", ",", "device", "=", "code", ".", "device", ")", "\n", "\n", "magnified_code", "=", "code", ".", "new_zeros", "(", "(", "s", "*", "2", ",", "s", "*", "2", ")", ",", "dtype", "=", "torch", ".", "long", ")", "-", "1", "\n", "\n", "windows", "=", "[", "(", "0", ",", "0", ",", "18", ")", ",", "(", "0", ",", "1", ",", "30", ")", ",", "(", "0", ",", "2", ",", "30", ")", ",", "(", "1", ",", "1", ",", "30", ")", ",", "(", "1", ",", "0", ",", "30", ")", ",", "(", "1", ",", "2", ",", "30", ")", ",", "(", "2", ",", "0", ",", "32", ")", ",", "(", "2", ",", "1", ",", "32", ")", ",", "(", "2", ",", "2", ",", "32", ")", "]", "\n", "for", "i", ",", "j", ",", "line", "in", "tqdm", "(", "windows", ")", ":", "\n", "                ", "code_part", "=", "code", "[", "8", "*", "i", ":", "8", "*", "(", "i", "+", "2", ")", ",", "8", "*", "j", ":", "8", "*", "(", "j", "+", "2", ")", "]", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "magnified_code_part", "=", "magnified_code", "[", "16", "*", "i", ":", "16", "*", "i", "+", "line", ",", "16", "*", "j", ":", "16", "*", "(", "j", "+", "2", ")", "]", ".", "reshape", "(", "-", "1", ")", "\n", "context_tokens_tensor", "=", "torch", ".", "cat", "(", "[", "text_token_list", ",", "code_part", ",", "midfix", "]", ",", "dim", "=", "0", ")", "\n", "context_len", "=", "len", "(", "context_tokens_tensor", ")", "\n", "seq", "=", "torch", ".", "cat", "(", "[", "context_tokens_tensor", ",", "magnified_code_part", "]", ",", "dim", "=", "0", ")", "\n", "\n", "magnified_code_part_completed", "=", "filling_sequence", "(", "model", ",", "seq", ",", "args", ",", "invalid_slices", "=", "[", "slice", "(", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ",", "None", ")", "]", ")", "\n", "magnified_code", "[", "16", "*", "i", ":", "16", "*", "i", "+", "line", ",", "16", "*", "j", ":", "16", "*", "(", "j", "+", "2", ")", "]", "=", "magnified_code_part_completed", "[", "0", ",", "context_len", ":", "]", ".", "view", "(", "line", ",", "32", ")", "\n", "", "return", "magnified_code", ".", "view", "(", "1", ",", "s", "*", "s", "*", "4", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.top_k_logits": [[24, 50], ["float", "logits.view().contiguous.view().contiguous", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "logits.view().contiguous.view().contiguous", "torch.softmax", "logits.view().contiguous.view", "logits.view().contiguous.view", "torch.topk", "torch.topk", "logits.view().contiguous.size"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.ConcatDataset.cumsum"], ["def", "top_k_logits", "(", "logits", ",", "top_k", "=", "0", ",", "top_p", "=", "0.0", ",", "filter_value", "=", "-", "float", "(", "'Inf'", ")", ")", ":", "\n", "# This function has been mostly taken from huggingface conversational ai code at", "\n", "# https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313", "\n", "\n", "    ", "if", "top_k", ">", "0", ":", "\n", "# Remove all tokens with a probability less than the last token of the top-k", "\n", "        ", "indices_to_remove", "=", "logits", "<", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "\n", "", "if", "top_p", ">", "0.0", ":", "\n", "# convert to 1D", "\n", "        ", "logits", "=", "logits", ".", "view", "(", "logits", ".", "size", "(", ")", "[", "1", "]", ")", ".", "contiguous", "(", ")", "\n", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "top_p", "\n", "# Shift the indices to the right to keep also the first token above the threshold", "\n", "sorted_indices_to_remove", "[", "...", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "indices_to_remove", "=", "sorted_indices", "[", "sorted_indices_to_remove", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "# going back to 2D", "\n", "logits", "=", "logits", ".", "view", "(", "1", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.get_batch": [[51, 63], ["tokens.view().contiguous.to", "pretrain_gpt2.get_masks_and_position_ids", "len", "tokens.view().contiguous.unsqueeze().contiguous", "tokens.view().contiguous.view().contiguous", "tokens.view().contiguous.unsqueeze", "tokens.view().contiguous.view"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.pretrain_gpt2.get_masks_and_position_ids"], ["", "def", "get_batch", "(", "context_tokens", ",", "device", ",", "args", ")", ":", "\n", "    ", "tokens", "=", "context_tokens", "\n", "if", "len", "(", "tokens", ".", "shape", ")", "==", "1", ":", "\n", "        ", "tokens", "=", "tokens", ".", "unsqueeze", "(", "0", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "        ", "tokens", "=", "tokens", ".", "view", "(", "tokens", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "", "tokens", "=", "tokens", ".", "to", "(", "device", ")", "\n", "\n", "# Get the masks and postition ids.", "\n", "attention_mask", ",", "loss_mask", ",", "position_ids", "=", "get_masks_and_position_ids", "(", "\n", "tokens", ")", "\n", "return", "tokens", ",", "attention_mask", ",", "position_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.filling_sequence": [[64, 187], ["data_utils.get_tokenizer", "len", "sampling.get_batch", "torch.cat.view().contiguous", "len", "slice", "data_utils.get_tokenizer", "sampling.top_k_logits", "torch.softmax", "torch.cat", "torch.cat", "ValueError", "model", "torch.cat.expand().contiguous", "torch.multinomial", "torch.multinomial", "torch.log().tolist", "torch.log().tolist", "torch.multinomial", "torch.multinomial", "torch.log", "torch.log", "range", "torch.cat.view", "slice", "slice", "sampling.shrink_beams", "torch.cat", "torch.cat", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "sampling.shrink_beams", "model", "float", "mem.expand", "torch.multinomial.view", "slice", "slice", "slice", "slice", "torch.cat.expand", "torch.log", "torch.log", "torch.gather", "torch.gather", "seq[].expand", "torch.arange", "torch.arange", "torch.gather", "torch.gather"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.get_batch", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.top_k_logits", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.shrink_beams", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.shrink_beams", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log"], ["", "def", "filling_sequence", "(", "\n", "model", ",", "\n", "seq", ",", "\n", "args", ",", "\n", "mems", "=", "None", ",", "\n", "invalid_slices", "=", "[", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "'''\n        seq: [2, 3, 5, ..., -1(to be generated), -N (N beams), -1]\n        context_length: first non(-1)s\n    '''", "\n", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "device", "=", "seq", ".", "device", "\n", "assert", "len", "(", "seq", ".", "shape", ")", "==", "1", "\n", "out_seq_length", "=", "len", "(", "seq", ")", "\n", "# building the initial tokens, attention_mask, and position_ids", "\n", "context_length", "=", "0", "\n", "offset", "=", "100000", "\n", "\n", "invalid_slices", "=", "[", "slice", "(", "0", ",", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ")", "]", "\n", "\n", "while", "seq", "[", "context_length", "]", ">=", "0", ":", "\n", "# change what to generate", "\n", "        ", "if", "seq", "[", "context_length", "]", "in", "[", "tokenizer", "[", "'[BOI1]'", "]", ",", "tokenizer", "[", "'[BOI2]'", "]", "]", ":", "\n", "            ", "invalid_slices", "=", "[", "slice", "(", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ",", "None", ")", "]", "\n", "", "elif", "seq", "[", "context_length", "]", "in", "[", "tokenizer", "[", "'[EOI1]'", "]", ",", "tokenizer", "[", "'[EOI2]'", "]", "]", ":", "\n", "            ", "invalid_slices", "=", "[", "\n", "slice", "(", "0", ",", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ")", ",", "\n", "slice", "(", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", "+", "tokenizer", ".", "txt_tokenizer", ".", "num_tokens", ",", "None", ")", "]", "\n", "\n", "", "if", "seq", "[", "context_length", "]", "==", "tokenizer", "[", "'[ROI2]'", "]", ":", "\n", "            ", "offset", "=", "context_length", "\n", "", "context_length", "+=", "1", "\n", "", "tokens", ",", "attention_mask", ",", "position_ids", "=", "get_batch", "(", "seq", "[", ":", "context_length", "]", ",", "device", ",", "args", ")", "\n", "\n", "counter", "=", "context_length", "-", "1", "# == len(tokens) - 1", "\n", "index", "=", "0", "# len(mems)", "\n", "if", "mems", "is", "None", ":", "\n", "        ", "mems", "=", "[", "]", "\n", "", "score", "=", "[", "0", "]", "# sum log likelihood for beams", "\n", "\n", "if", "args", ".", "is_sparse", "==", "2", ":", "\n", "        ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "img_txt_sep", "=", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", "\n", "img_indices_bool", "=", "(", "tokens", "<", "img_txt_sep", ")", "\n", "txt_indices_bool", "=", "(", "~", "img_indices_bool", ")", "\n", "", "elif", "args", ".", "is_sparse", "==", "0", ":", "\n", "        ", "txt_indices_bool", "=", "img_indices_bool", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'set is_sparse==2 for inference.'", ")", "\n", "\n", "", "while", "counter", "<", "(", "out_seq_length", "-", "1", ")", ":", "\n", "# Now, we want to generate seq[counter + 1]", "\n", "# token[:, index: counter+1] are just added.", "\n", "\n", "        ", "if", "seq", "[", "counter", "+", "1", "]", "in", "[", "tokenizer", "[", "'[BOI1]'", "]", ",", "tokenizer", "[", "'[BOI2]'", "]", "]", ":", "\n", "            ", "invalid_slices", "=", "[", "slice", "(", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ",", "None", ")", "]", "\n", "", "elif", "seq", "[", "counter", "+", "1", "]", "in", "[", "tokenizer", "[", "'[EOI1]'", "]", ",", "tokenizer", "[", "'[EOI2]'", "]", "]", ":", "\n", "            ", "invalid_slices", "=", "[", "\n", "slice", "(", "0", ",", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", ")", ",", "\n", "slice", "(", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", "+", "tokenizer", ".", "txt_tokenizer", ".", "num_tokens", ",", "None", ")", "]", "\n", "\n", "", "if", "index", "==", "0", ":", "# first ", "\n", "            ", "position_ids", "[", "position_ids", ">", "offset", "]", "-=", "offset", "\n", "logits", ",", "*", "mems", "=", "model", "(", "tokens", ",", "position_ids", ",", "attention_mask", ",", "txt_indices_bool", ",", "img_indices_bool", ",", "is_sparse", "=", "args", ".", "is_sparse", ",", "*", "mems", ")", "\n", "index", "=", "counter", "\n", "", "elif", "seq", "[", "counter", "+", "1", "]", ">=", "0", ":", "# provided", "\n", "            ", "if", "seq", "[", "counter", "+", "1", "]", "==", "tokenizer", "[", "'[ROI2]'", "]", ":", "\n", "                ", "offset", "=", "counter", "+", "1", "\n", "", "tokens", ",", "mems", ",", "score", "=", "shrink_beams", "(", "tokens", ",", "mems", ",", "1", ",", "score", ")", "\n", "nb", "=", "1", "\n", "counter", "+=", "1", "\n", "tokens", "=", "torch", ".", "cat", "(", "(", "tokens", ",", "seq", "[", "counter", ":", "counter", "+", "1", "]", ".", "expand", "(", "tokens", ".", "shape", "[", "0", "]", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "if", "args", ".", "is_sparse", "==", "2", ":", "\n", "                ", "img_indices_bool", "=", "(", "tokens", "<", "img_txt_sep", ")", "\n", "txt_indices_bool", "=", "(", "~", "img_indices_bool", ")", "\n", "", "continue", "\n", "", "else", ":", "\n", "            ", "assert", "tokens", ".", "shape", "[", "1", "]", "==", "counter", "+", "1", "\n", "position_ids", "=", "torch", ".", "arange", "(", "index", ",", "counter", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "tokens", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "position_ids", "[", "position_ids", ">", "offset", "]", "-=", "offset", "\n", "# TODO each time, the feed input cannot be too long (window size), or it will have a discrepcy from sparse training, but this is not very important. ", "\n", "tokens", ",", "mems", ",", "score", "=", "shrink_beams", "(", "tokens", ",", "mems", ",", "-", "seq", "[", "counter", "+", "1", "]", ",", "score", ")", "\n", "logits", ",", "*", "mems", "=", "model", "(", "tokens", "[", ":", ",", "index", ":", "]", ",", "\n", "position_ids", ",", "\n", "0", ",", "# rebuild in transformers (sep version)", "\n", "txt_indices_bool", ",", "img_indices_bool", ",", "args", ".", "is_sparse", ",", "\n", "*", "mems", ")", "\n", "index", "=", "counter", "\n", "", "nb", "=", "-", "seq", "[", "counter", "+", "1", "]", "\n", "counter", "+=", "1", "\n", "index", "+=", "1", "\n", "\n", "logits", "=", "logits", "[", ":", ",", "-", "1", "]", "# [batch size, vocab size]", "\n", "\n", "temp", "=", "args", ".", "temperature", "\n", "# TODO since the temperature is crucial, how can we find a good setting?", "\n", "logits", "/=", "temp", "\n", "for", "invalid_slice", "in", "invalid_slices", ":", "# forbide to generate other tokens", "\n", "            ", "logits", "[", "...", ",", "invalid_slice", "]", "=", "-", "float", "(", "'Inf'", ")", "\n", "", "logits", "=", "top_k_logits", "(", "logits", ",", "top_k", "=", "args", ".", "top_k", ",", "top_p", "=", "args", ".", "top_p", ")", "\n", "log_probs", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# expand beams", "\n", "if", "nb", ">", "1", "and", "tokens", ".", "shape", "[", "0", "]", "==", "1", ":", "# 1->nb", "\n", "            ", "tokens", "=", "tokens", ".", "expand", "(", "nb", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "mems", "=", "[", "mem", ".", "expand", "(", "nb", ",", "-", "1", ",", "-", "1", ")", "for", "mem", "in", "mems", "]", "\n", "prev", "=", "torch", ".", "multinomial", "(", "log_probs", ",", "num_samples", "=", "nb", ",", "replacement", "=", "True", ")", "\n", "score", "=", "torch", ".", "log", "(", "torch", ".", "gather", "(", "log_probs", ",", "dim", "=", "1", ",", "index", "=", "prev", ")", "[", "0", "]", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "# nb -> nb", "\n", "            ", "assert", "tokens", ".", "shape", "[", "0", "]", "==", "nb", "\n", "prev", "=", "torch", ".", "multinomial", "(", "log_probs", ",", "num_samples", "=", "1", ")", "\n", "score_plus", "=", "torch", ".", "log", "(", "torch", ".", "gather", "(", "log_probs", ",", "dim", "=", "1", ",", "index", "=", "prev", ")", "[", ":", ",", "0", "]", ")", "\n", "for", "idx", "in", "range", "(", "nb", ")", ":", "\n", "                ", "score", "[", "idx", "]", "+=", "score_plus", "[", "idx", "]", "\n", "\n", "", "", "tokens", "=", "torch", ".", "cat", "(", "(", "tokens", ",", "prev", ".", "view", "(", "tokens", ".", "shape", "[", "0", "]", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "if", "args", ".", "is_sparse", "==", "2", ":", "# update indices", "\n", "            ", "img_indices_bool", "=", "(", "tokens", "<", "img_txt_sep", ")", "\n", "txt_indices_bool", "=", "(", "~", "img_indices_bool", ")", "\n", "\n", "", "", "output_tokens_list", "=", "tokens", ".", "view", "(", "tokens", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "output_tokens_list", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.shrink_beams": [[188, 199], ["max", "score.index", "tokens[].unsqueeze"], "function", ["None"], ["", "def", "shrink_beams", "(", "tokens", ",", "mems", ",", "nb", ",", "score", ")", ":", "\n", "# beam search is a failed attempt, will be removed soon...", "\n", "    ", "if", "tokens", ".", "shape", "[", "0", "]", "==", "nb", ":", "\n", "        ", "return", "tokens", ",", "mems", ",", "score", "\n", "# shrink", "\n", "", "maximum", "=", "max", "(", "score", ")", "\n", "max_idx", "=", "score", ".", "index", "(", "maximum", ")", "\n", "tokens", "=", "tokens", "[", "max_idx", "]", ".", "unsqueeze", "(", "0", ")", "\n", "score", "=", "[", "0", "]", "\n", "new_mems", "=", "[", "mem", "[", "max_idx", ":", "max_idx", "+", "1", "]", "for", "mem", "in", "mems", "]", "\n", "return", "tokens", ",", "new_mems", ",", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.add_interlacing_beam_marks": [[200, 212], ["range", "isinstance", "len", "len"], "function", ["None"], ["", "def", "add_interlacing_beam_marks", "(", "seq", ",", "nb", "=", "12", ",", "period", "=", "3000", ")", ":", "\n", "    ", "assert", "isinstance", "(", "seq", ",", "list", ")", "or", "len", "(", "seq", ".", "shape", ")", "==", "1", "\n", "blk_cnt", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "seq", ")", ")", ":", "\n", "        ", "if", "seq", "[", "i", "]", "==", "-", "1", ":", "\n", "            ", "blk_cnt", "+=", "1", "\n", "seq", "[", "i", "]", "=", "-", "nb", "\n", "if", "blk_cnt", "==", "period", ":", "\n", "                ", "nb", "+=", "(", "nb", "%", "2", ")", "*", "2", "-", "1", "\n", "blk_cnt", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "blk_cnt", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.inverse_prompt_score": [[214, 231], ["data_utils.get_tokenizer", "sampling.get_batch", "model", "torch.log", "torch.log", "tokens[].unsqueeze", "torch.gather().squeeze().sum", "torch.gather().squeeze().sum", "len", "float", "torch.softmax", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather", "torch.gather"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.generation.sampling.get_batch", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log"], ["", "", "", "def", "inverse_prompt_score", "(", "model", ",", "seq", ",", "args", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "device", "=", "seq", ".", "device", "\n", "assert", "len", "(", "seq", ".", "shape", ")", "==", "2", "\n", "\n", "botext", "=", "2", "+", "1024", "+", "1", "\n", "assert", "tokenizer", "[", "'[ROI1]'", "]", "==", "seq", "[", "0", "]", "[", "botext", "]", "\n", "\n", "tokens", ",", "attention_mask", ",", "position_ids", "=", "get_batch", "(", "seq", ",", "device", ",", "args", ")", "\n", "logits", ",", "*", "mems", "=", "model", "(", "tokens", ",", "position_ids", ",", "attention_mask", ",", "None", ",", "None", ",", "is_sparse", "=", "args", ".", "is_sparse", ")", "\n", "logits", "[", "...", ",", ":", "tokenizer", ".", "img_tokenizer", ".", "num_tokens", "]", "=", "-", "float", "(", "'Inf'", ")", "\n", "log_probs", "=", "torch", ".", "log", "(", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "pred", "=", "log_probs", "[", ":", ",", "botext", ":", "-", "1", ",", ":", "]", "\n", "target", "=", "tokens", "[", ":", ",", "botext", "+", "1", ":", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "scores", "=", "torch", ".", "gather", "(", "pred", ",", "dim", "=", "2", ",", "index", "=", "target", ")", ".", "squeeze", "(", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "return", "scores", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.tofp16.__init__": [[32, 34], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "tofp16", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.tofp16.forward": [[35, 37], ["input.half"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", ".", "half", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.FP16Model.__init__": [[93, 96], ["torch.Module.__init__", "fp16util.convert_network"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.convert_network"], ["def", "__init__", "(", "self", ",", "network", ")", ":", "\n", "        ", "super", "(", "FP16Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "network", "=", "convert_network", "(", "network", ",", "dtype", "=", "torch", ".", "half", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.FP16Model.forward": [[97, 100], ["tuple", "fp16util.FP16Model.network", "t.half"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ")", ":", "\n", "        ", "inputs", "=", "tuple", "(", "t", ".", "half", "(", ")", "for", "t", "in", "inputs", ")", "\n", "return", "self", ".", "network", "(", "*", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.BN_convert_float": [[39, 50], ["module.children", "isinstance", "module.float", "fp16util.BN_convert_float"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.BN_convert_float"], ["", "", "def", "BN_convert_float", "(", "module", ")", ":", "\n", "    ", "\"\"\"\n    Utility function for network_to_half().\n\n    Retained for legacy purposes.\n    \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "_BatchNorm", ")", "and", "module", ".", "affine", "is", "True", ":", "\n", "        ", "module", ".", "float", "(", ")", "\n", "", "for", "child", "in", "module", ".", "children", "(", ")", ":", "\n", "        ", "BN_convert_float", "(", "child", ")", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.network_to_half": [[52, 59], ["torch.Sequential", "fp16util.tofp16", "fp16util.BN_convert_float", "network.half"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.BN_convert_float"], ["", "def", "network_to_half", "(", "network", ")", ":", "\n", "    ", "\"\"\"\n    Convert model to half precision in a batchnorm-safe way.\n\n    Retained for legacy purposes. It is recommended to use FP16Model.\n    \"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "tofp16", "(", ")", ",", "BN_convert_float", "(", "network", ".", "half", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.convert_module": [[61, 75], ["module.parameters", "module.buffers", "buf.data.to", "param.data.to", "param._grad.data.to"], "function", ["None"], ["", "def", "convert_module", "(", "module", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"\n    Converts a module's immediate parameters and buffers to dtype.\n    \"\"\"", "\n", "for", "param", "in", "module", ".", "parameters", "(", "recurse", "=", "False", ")", ":", "\n", "        ", "if", "param", "is", "not", "None", ":", "\n", "            ", "if", "param", ".", "data", ".", "dtype", ".", "is_floating_point", ":", "\n", "                ", "param", ".", "data", "=", "param", ".", "data", ".", "to", "(", "dtype", "=", "dtype", ")", "\n", "", "if", "param", ".", "_grad", "is", "not", "None", "and", "param", ".", "_grad", ".", "data", ".", "dtype", ".", "is_floating_point", ":", "\n", "                ", "param", ".", "_grad", ".", "data", "=", "param", ".", "_grad", ".", "data", ".", "to", "(", "dtype", "=", "dtype", ")", "\n", "\n", "", "", "", "for", "buf", "in", "module", ".", "buffers", "(", "recurse", "=", "False", ")", ":", "\n", "        ", "if", "buf", "is", "not", "None", "and", "buf", ".", "data", ".", "dtype", ".", "is_floating_point", ":", "\n", "            ", "buf", ".", "data", "=", "buf", ".", "data", ".", "to", "(", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.convert_network": [[77, 86], ["network.modules", "fp16util.convert_module", "isinstance"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.convert_module"], ["", "", "", "def", "convert_network", "(", "network", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"\n    Converts a network's parameters and buffers to dtype.\n    \"\"\"", "\n", "for", "module", "in", "network", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "_BatchNorm", ")", "and", "module", ".", "affine", "is", "True", ":", "\n", "            ", "continue", "\n", "", "convert_module", "(", "module", ",", "dtype", ")", "\n", "", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.backwards_debug_hook": [[102, 104], ["RuntimeError"], "function", ["None"], ["", "", "def", "backwards_debug_hook", "(", "grad", ")", ":", "\n", "    ", "raise", "RuntimeError", "(", "\"master_params recieved a gradient in the backward pass!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.prep_param_lists": [[105, 149], ["torch.nn.Parameter", "torch.nn.Parameter", "model.parameters", "torch._utils._flatten_dense_tensors().float", "_flatten_dense_tensors().float.new", "param.clone().float().detach", "print", "torch._utils._flatten_dense_tensors", "_flatten_dense_tensors().float.size", "param.clone().float", "param.clone"], "function", ["None"], ["", "def", "prep_param_lists", "(", "model", ",", "flat_master", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Creates a list of FP32 master parameters for a given model, as in\n    `Training Neural Networks with Mixed Precision:  Real Examples`_.\n\n    Args:\n        model (torch.nn.Module): Existing Pytorch model\n        flat_master (bool, optional, default=False):  Flatten the master parameters into a single tensor, as a performance optimization.\n    Returns:\n        A tuple (``model_params``, ``master_params``). ``model_params`` is a list of the model's parameters for later use with :func:`model_grads_to_master_grads` and :func:`master_params_to_model_params`.  ``master_params`` is a list of FP32 master gradients.  If ``flat_master=True``, ``master_params`` will be a list with one element.\n\n    Example::\n\n        model_params, master_params = prep_param_lists(model)\n\n    .. warning::\n        Currently, if ``flat_master=True``, all the model's parameters must be the same type.  If the model has parameters of different types, use ``flat_master=False``, or use :class:`FP16_Optimizer`.\n\n    .. _`Training Neural Networks with Mixed Precision:  Real Examples`:\n        http://on-demand.gputechconf.com/gtc/2018/video/S81012/\n    \"\"\"", "\n", "model_params", "=", "[", "param", "for", "param", "in", "model", ".", "parameters", "(", ")", "if", "param", ".", "requires_grad", "]", "\n", "\n", "if", "flat_master", ":", "\n", "# Give the user some more useful error messages", "\n", "        ", "try", ":", "\n", "# flatten_dense_tensors returns a contiguous flat array.", "\n", "# http://pytorch.org/docs/master/_modules/torch/_utils.html", "\n", "            ", "master_params", "=", "_flatten_dense_tensors", "(", "[", "param", ".", "data", "for", "param", "in", "model_params", "]", ")", ".", "float", "(", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"Error in prep_param_lists:  model may contain a mixture of parameters \"", "\n", "\"of different types.  Use flat_master=False, or use F16_Optimizer.\"", ")", "\n", "raise", "\n", "", "master_params", "=", "torch", ".", "nn", ".", "Parameter", "(", "master_params", ")", "\n", "master_params", ".", "requires_grad", "=", "True", "\n", "# master_params.register_hook(backwards_debug_hook)", "\n", "if", "master_params", ".", "grad", "is", "None", ":", "\n", "            ", "master_params", ".", "grad", "=", "master_params", ".", "new", "(", "*", "master_params", ".", "size", "(", ")", ")", "\n", "", "return", "model_params", ",", "[", "master_params", "]", "\n", "", "else", ":", "\n", "        ", "master_params", "=", "[", "param", ".", "clone", "(", ")", ".", "float", "(", ")", ".", "detach", "(", ")", "for", "param", "in", "model_params", "]", "\n", "for", "param", "in", "master_params", ":", "\n", "            ", "param", ".", "requires_grad", "=", "True", "\n", "", "return", "model_params", ",", "master_params", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.model_grads_to_master_grads": [[151, 171], ["master_params[].grad.data.copy_", "zip", "torch._utils._flatten_dense_tensors", "master.grad.data.copy_", "torch.autograd.Variable", "master.data.new", "master.data.size"], "function", ["None"], ["", "", "def", "model_grads_to_master_grads", "(", "model_params", ",", "master_params", ",", "flat_master", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Copy model gradients to master gradients.  \n\n    Args:\n        model_params:  List of model parameters created by :func:`prep_param_lists`.\n        master_params:  List of FP32 master parameters created by :func:`prep_param_lists`.  If ``master_params`` was created with ``flat_master=True``, ``flat_master=True`` should also be supplied to :func:`model_grads_to_master_grads`.\n    \"\"\"", "\n", "if", "flat_master", ":", "\n", "# The flattening may incur one more deep copy than is necessary.", "\n", "        ", "master_params", "[", "0", "]", ".", "grad", ".", "data", ".", "copy_", "(", "\n", "_flatten_dense_tensors", "(", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "model_params", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "for", "model", ",", "master", "in", "zip", "(", "model_params", ",", "master_params", ")", ":", "\n", "            ", "if", "model", ".", "grad", "is", "not", "None", ":", "\n", "                ", "if", "master", ".", "grad", "is", "None", ":", "\n", "                    ", "master", ".", "grad", "=", "Variable", "(", "master", ".", "data", ".", "new", "(", "*", "master", ".", "data", ".", "size", "(", ")", ")", ")", "\n", "", "master", ".", "grad", ".", "data", ".", "copy_", "(", "model", ".", "grad", ".", "data", ")", "\n", "", "else", ":", "\n", "                ", "master", ".", "grad", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.master_params_to_model_params": [[173, 188], ["zip", "zip", "torch._utils._unflatten_dense_tensors", "model.data.copy_", "model.data.copy_"], "function", ["None"], ["", "", "", "", "def", "master_params_to_model_params", "(", "model_params", ",", "master_params", ",", "flat_master", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Copy master parameters to model parameters.\n\n    Args:\n        model_params:  List of model parameters created by :func:`prep_param_lists`.\n        master_params:  List of FP32 master parameters created by :func:`prep_param_lists`.  If ``master_params`` was created with ``flat_master=True``, ``flat_master=True`` should also be supplied to :func:`master_params_to_model_params`.\n    \"\"\"", "\n", "if", "flat_master", ":", "\n", "        ", "for", "model", ",", "master", "in", "zip", "(", "model_params", ",", "\n", "_unflatten_dense_tensors", "(", "master_params", "[", "0", "]", ".", "data", ",", "model_params", ")", ")", ":", "\n", "            ", "model", ".", "data", ".", "copy_", "(", "master", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "model", ",", "master", "in", "zip", "(", "model_params", ",", "master_params", ")", ":", "\n", "            ", "model", ".", "data", ".", "copy_", "(", "master", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.to_python_float": [[191, 196], ["hasattr", "t.item"], "function", ["None"], ["", "", "", "def", "to_python_float", "(", "t", ")", ":", "\n", "    ", "if", "hasattr", "(", "t", ",", "'item'", ")", ":", "\n", "        ", "return", "t", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "t", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.LossScaler.__init__": [[38, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "scale", "=", "1", ")", ":", "\n", "        ", "self", ".", "cur_scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.LossScaler.has_overflow": [[42, 44], ["None"], "methods", ["None"], ["", "def", "has_overflow", "(", "self", ",", "params", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.LossScaler._has_inf_or_nan": [[46, 48], ["None"], "methods", ["None"], ["", "def", "_has_inf_or_nan", "(", "x", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.LossScaler.update_scale": [[49, 51], ["None"], "methods", ["None"], ["", "def", "update_scale", "(", "self", ",", "overflow", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.LossScaler.loss_scale": [[52, 55], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss_scale", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.LossScaler.scale_gradient": [[56, 58], ["tuple"], "methods", ["None"], ["", "def", "scale_gradient", "(", "self", ",", "module", ",", "grad_in", ",", "grad_out", ")", ":", "\n", "        ", "return", "tuple", "(", "self", ".", "loss_scale", "*", "g", "for", "g", "in", "grad_in", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.LossScaler.backward": [[59, 62], ["scaled_loss.backward"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward"], ["", "def", "backward", "(", "self", ",", "loss", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "scaled_loss", "=", "loss", "*", "self", ".", "loss_scale", "\n", "scaled_loss", ".", "backward", "(", "retain_graph", "=", "retain_graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.__init__": [[89, 105], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "init_scale", "=", "2", "**", "32", ",", "\n", "scale_factor", "=", "2.", ",", "\n", "scale_window", "=", "1000", ",", "\n", "min_scale", "=", "1", ",", "\n", "delayed_shift", "=", "1", ",", "\n", "consecutive_hysteresis", "=", "False", ")", ":", "\n", "        ", "self", ".", "cur_scale", "=", "init_scale", "\n", "self", ".", "cur_iter", "=", "0", "\n", "self", ".", "last_overflow_iter", "=", "-", "1", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "self", ".", "scale_window", "=", "scale_window", "\n", "self", ".", "min_scale", "=", "min_scale", "\n", "self", ".", "delayed_shift", "=", "delayed_shift", "\n", "self", ".", "cur_hysteresis", "=", "delayed_shift", "\n", "self", ".", "consecutive_hysteresis", "=", "consecutive_hysteresis", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.has_overflow_serial": [[107, 113], ["loss_scaler.DynamicLossScaler._has_inf_or_nan"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler._has_inf_or_nan"], ["", "def", "has_overflow_serial", "(", "self", ",", "params", ")", ":", "\n", "        ", "for", "p", "in", "params", ":", "\n", "            ", "if", "p", ".", "grad", "is", "not", "None", "and", "DynamicLossScaler", ".", "_has_inf_or_nan", "(", "p", ".", "grad", ".", "data", ")", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.has_overflow": [[114, 124], ["loss_scaler.DynamicLossScaler.has_overflow_serial", "torch.cuda.ByteTensor", "torch.distributed.all_reduce", "overflow_gpu[].item", "bool", "mpu.get_model_parallel_group"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.has_overflow_serial", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group"], ["", "def", "has_overflow", "(", "self", ",", "params", ")", ":", "\n", "        ", "overflow", "=", "self", ".", "has_overflow_serial", "(", "params", ")", "\n", "# Since each model parallel GPU carries only part of the model,", "\n", "# make sure overflow flag is synced across all the model parallel GPUs", "\n", "overflow_gpu", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "[", "overflow", "]", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "overflow_gpu", ",", "\n", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "MAX", ",", "\n", "group", "=", "mpu", ".", "get_model_parallel_group", "(", ")", ")", "\n", "overflow", "=", "overflow_gpu", "[", "0", "]", ".", "item", "(", ")", "\n", "return", "bool", "(", "overflow", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler._has_inf_or_nan": [[127, 146], ["float", "x.float().sum", "float", "x.float", "float"], "methods", ["None"], ["", "def", "_has_inf_or_nan", "(", "x", ")", ":", "\n", "        ", "try", ":", "\n", "# if x is half, the .float() incurs an additional deep copy, but it's necessary if ", "\n", "# Pytorch's .sum() creates a one-element tensor of the same type as x ", "\n", "# (which is true for some recent version of pytorch).", "\n", "            ", "cpu_sum", "=", "float", "(", "x", ".", "float", "(", ")", ".", "sum", "(", ")", ")", "\n", "# More efficient version that can be used if .sum() returns a Python scalar", "\n", "# cpu_sum = float(x.sum())", "\n", "", "except", "RuntimeError", "as", "instance", ":", "\n", "# We want to check if inst is actually an overflow exception.", "\n", "# RuntimeError could come from a different error.", "\n", "# If so, we still want the exception to propagate.", "\n", "            ", "if", "\"value cannot be converted\"", "not", "in", "instance", ".", "args", "[", "0", "]", ":", "\n", "                ", "raise", "\n", "", "return", "True", "\n", "", "else", ":", "\n", "            ", "if", "cpu_sum", "==", "float", "(", "'inf'", ")", "or", "cpu_sum", "==", "-", "float", "(", "'inf'", ")", "or", "cpu_sum", "!=", "cpu_sum", ":", "\n", "                ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.update_scale": [[148, 173], ["hasattr", "hasattr", "hasattr", "hasattr", "max"], "methods", ["None"], ["", "", "def", "update_scale", "(", "self", ",", "overflow", ")", ":", "\n", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'min_scale'", ")", ":", "\n", "            ", "self", ".", "min_scale", "=", "1", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'delayed_shift'", ")", ":", "\n", "            ", "self", ".", "delayed_shift", "=", "1", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'cur_hysteresis'", ")", ":", "\n", "            ", "self", ".", "cur_hysteresis", "=", "1", "\n", "", "if", "not", "hasattr", "(", "self", ",", "'consecutive_hysteresis'", ")", ":", "\n", "            ", "self", ".", "consecutive_hysteresis", "=", "True", "\n", "", "if", "overflow", ":", "\n", "# self.cur_scale /= self.scale_factor", "\n", "            ", "if", "self", ".", "delayed_shift", "==", "1", "or", "self", ".", "cur_hysteresis", "==", "1", ":", "\n", "                ", "self", ".", "cur_scale", "=", "max", "(", "self", ".", "cur_scale", "/", "self", ".", "scale_factor", ",", "self", ".", "min_scale", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "cur_hysteresis", "-=", "1", "\n", "", "self", ".", "last_overflow_iter", "=", "self", ".", "cur_iter", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "consecutive_hysteresis", ":", "\n", "                ", "self", ".", "cur_hysteresis", "=", "self", ".", "delayed_shift", "\n", "", "if", "(", "self", ".", "cur_iter", "-", "self", ".", "last_overflow_iter", ")", "%", "self", ".", "scale_window", "==", "0", ":", "\n", "                ", "if", "not", "self", ".", "consecutive_hysteresis", ":", "\n", "                    ", "self", ".", "cur_hysteresis", "=", "self", ".", "delayed_shift", "\n", "", "self", ".", "cur_scale", "*=", "self", ".", "scale_factor", "\n", "", "", "self", ".", "cur_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.loss_scale": [[174, 177], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss_scale", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.scale_gradient": [[178, 180], ["tuple"], "methods", ["None"], ["", "def", "scale_gradient", "(", "self", ",", "module", ",", "grad_in", ",", "grad_out", ")", ":", "\n", "        ", "return", "tuple", "(", "self", ".", "loss_scale", "*", "g", "for", "g", "in", "grad_in", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.backward": [[181, 184], ["scaled_loss.backward"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward"], ["", "def", "backward", "(", "self", ",", "loss", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "scaled_loss", "=", "loss", "*", "self", ".", "loss_scale", "\n", "scaled_loss", ".", "backward", "(", "retain_graph", "=", "retain_graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.to_python_float": [[20, 25], ["hasattr", "t.item"], "function", ["None"], ["def", "to_python_float", "(", "t", ")", ":", "\n", "    ", "if", "hasattr", "(", "t", ",", "'item'", ")", ":", "\n", "        ", "return", "t", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "t", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Module.__init__": [[60, 63], ["torch.nn.Module.__init__", "fp16.FP16_Module.add_module", "module.half"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module", ")", ":", "\n", "        ", "super", "(", "FP16_Module", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'module'", ",", "module", ".", "half", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Module.forward": [[64, 66], ["fp16.fp16_to_fp32", "fp16.FP16_Module.module", "fp16.fp32_to_fp16"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.fp16_to_fp32", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.fp32_to_fp16"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "fp16_to_fp32", "(", "self", ".", "module", "(", "*", "(", "fp32_to_fp16", "(", "inputs", ")", ")", ",", "**", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Module.state_dict": [[67, 69], ["fp16.FP16_Module.module.state_dict"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict"], ["", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "module", ".", "state_dict", "(", "destination", ",", "prefix", ",", "keep_vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Module.load_state_dict": [[70, 72], ["fp16.FP16_Module.module.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.__init__": [[168, 241], ["enumerate", "fp16.FP16_Optimizer.optimizer.load_state_dict", "SystemError", "fp16.FP16_Optimizer.maybe_print", "enumerate", "fp16.FP16_Optimizer.fp16_groups.append", "fp16.FP16_Optimizer.fp32_from_fp16_groups.append", "fp16.FP16_Optimizer.fp32_from_fp32_groups.append", "fp16.FP16_Optimizer.optimizer.state_dict", "loss_scaler.LossScaler", "loss_scaler.DynamicLossScaler", "loss_scaler.DynamicLossScaler", "param.type", "fp16.FP16_Optimizer.maybe_print", "fp16_params_this_group.append", "param.detach().clone().float", "fp32_from_fp16_params_this_group.append", "fp16.FP16_Optimizer.optimizer.state.pop", "param.type", "fp16.FP16_Optimizer.maybe_print", "fp32_params_this_group.append", "TypeError", "param.size", "param.detach().clone", "param.size", "param.type", "param.detach"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.maybe_print", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.maybe_print", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.maybe_print"], ["def", "__init__", "(", "self", ",", "\n", "init_optimizer", ",", "\n", "static_loss_scale", "=", "1.0", ",", "\n", "dynamic_loss_scale", "=", "False", ",", "\n", "dynamic_loss_args", "=", "None", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "not", "torch", ".", "cuda", ".", "is_available", ":", "\n", "            ", "raise", "SystemError", "(", "\"Cannot use fp16 without CUDA.\"", ")", "\n", "\n", "", "self", ".", "verbose", "=", "verbose", "\n", "\n", "self", ".", "optimizer", "=", "init_optimizer", "\n", "# init_state_dict sets up an alternative way to cast per-param state tensors.", "\n", "# Stashing here in case https://github.com/pytorch/pytorch/issues/7733 makes it necessary.", "\n", "# init_state_dict = init_optimizer.state_dict()", "\n", "\n", "self", ".", "fp16_groups", "=", "[", "]", "\n", "self", ".", "fp32_from_fp16_groups", "=", "[", "]", "\n", "self", ".", "fp32_from_fp32_groups", "=", "[", "]", "\n", "for", "i", ",", "param_group", "in", "enumerate", "(", "self", ".", "optimizer", ".", "param_groups", ")", ":", "\n", "            ", "self", ".", "maybe_print", "(", "\"FP16_Optimizer processing param group {}:\"", ".", "format", "(", "i", ")", ")", "\n", "fp16_params_this_group", "=", "[", "]", "\n", "fp32_params_this_group", "=", "[", "]", "\n", "fp32_from_fp16_params_this_group", "=", "[", "]", "\n", "for", "i", ",", "param", "in", "enumerate", "(", "param_group", "[", "'params'", "]", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", ":", "\n", "                    ", "if", "param", ".", "type", "(", ")", "==", "'torch.cuda.HalfTensor'", ":", "\n", "                        ", "self", ".", "maybe_print", "(", "\"FP16_Optimizer received torch.cuda.HalfTensor with {}\"", "\n", ".", "format", "(", "param", ".", "size", "(", ")", ")", ")", "\n", "fp16_params_this_group", ".", "append", "(", "param", ")", "\n", "master_param", "=", "param", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "float", "(", ")", "\n", "master_param", ".", "requires_grad", "=", "True", "\n", "# Copythe model parallel flag.", "\n", "master_param", ".", "model_parallel", "=", "param", ".", "model_parallel", "\n", "param_group", "[", "'params'", "]", "[", "i", "]", "=", "master_param", "\n", "fp32_from_fp16_params_this_group", ".", "append", "(", "master_param", ")", "\n", "# Reset existing state dict key to the new master param.", "\n", "# We still need to recast per-param state tensors, if any, to FP32.", "\n", "if", "param", "in", "self", ".", "optimizer", ".", "state", ":", "\n", "                           ", "self", ".", "optimizer", ".", "state", "[", "master_param", "]", "=", "self", ".", "optimizer", ".", "state", ".", "pop", "(", "param", ")", "\n", "", "", "elif", "param", ".", "type", "(", ")", "==", "'torch.cuda.FloatTensor'", ":", "\n", "                        ", "self", ".", "maybe_print", "(", "\"FP16_Optimizer received torch.cuda.FloatTensor with {}\"", "\n", ".", "format", "(", "param", ".", "size", "(", ")", ")", ")", "\n", "fp32_params_this_group", ".", "append", "(", "param", ")", "\n", "param_group", "[", "'params'", "]", "[", "i", "]", "=", "param", "\n", "", "else", ":", "\n", "                        ", "raise", "TypeError", "(", "\"Wrapped parameters must be either \"", "\n", "\"torch.cuda.FloatTensor or torch.cuda.HalfTensor. \"", "\n", "\"Received {}\"", ".", "format", "(", "param", ".", "type", "(", ")", ")", ")", "\n", "\n", "", "", "", "self", ".", "fp16_groups", ".", "append", "(", "fp16_params_this_group", ")", "\n", "self", ".", "fp32_from_fp16_groups", ".", "append", "(", "fp32_from_fp16_params_this_group", ")", "\n", "self", ".", "fp32_from_fp32_groups", ".", "append", "(", "fp32_params_this_group", ")", "\n", "\n", "# Leverage state_dict() and load_state_dict() to recast preexisting per-param state tensors", "\n", "", "self", ".", "optimizer", ".", "load_state_dict", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "# alternative way to cast per-param state tensors:", "\n", "# self.optimizer.load_state_dict(init_state_dict)", "\n", "\n", "if", "dynamic_loss_scale", ":", "\n", "            ", "self", ".", "dynamic_loss_scale", "=", "True", "\n", "if", "dynamic_loss_args", "is", "not", "None", ":", "\n", "                ", "self", ".", "loss_scaler", "=", "DynamicLossScaler", "(", "**", "dynamic_loss_args", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "loss_scaler", "=", "DynamicLossScaler", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "dynamic_loss_scale", "=", "False", "\n", "self", ".", "loss_scaler", "=", "LossScaler", "(", "static_loss_scale", ")", "\n", "\n", "", "self", ".", "overflow", "=", "False", "\n", "self", ".", "first_closure_call_this_step", "=", "True", "\n", "\n", "self", ".", "clip_grad_norm", "=", "clip_grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.maybe_print": [[242, 245], ["print"], "methods", ["None"], ["", "def", "maybe_print", "(", "self", ",", "msg", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.__getstate__": [[246, 248], ["RuntimeError"], "methods", ["None"], ["", "", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"FP16_Optimizer should be serialized using state_dict().\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.__setstate__": [[249, 251], ["RuntimeError"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"FP16_Optimizer should be deserialized using load_state_dict().\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.zero_grad": [[252, 277], ["p.grad.detach_", "p.grad.zero_", "param.grad.detach_", "param.grad.zero_"], "methods", ["None"], ["", "def", "zero_grad", "(", "self", ",", "set_grads_to_None", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Zero fp32 and fp16 parameter grads.\n        \"\"\"", "\n", "# In principle, only the .grad attributes of the model params need to be zeroed,", "\n", "# because gradients are copied into the FP32 master params.  However, we zero", "\n", "# all gradients owned by the optimizer, just to be safe:", "\n", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "             ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                 ", "if", "set_grads_to_None", ":", "\n", "                     ", "p", ".", "grad", "=", "None", "\n", "", "else", ":", "\n", "                     ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                         ", "p", ".", "grad", ".", "detach_", "(", ")", "\n", "p", ".", "grad", ".", "zero_", "(", ")", "\n", "\n", "# Zero fp16 gradients owned by the model:", "\n", "", "", "", "", "for", "fp16_group", "in", "self", ".", "fp16_groups", ":", "\n", "            ", "for", "param", "in", "fp16_group", ":", "\n", "                ", "if", "set_grads_to_None", ":", "\n", "                    ", "param", ".", "grad", "=", "None", "\n", "", "else", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "param", ".", "grad", ".", "detach_", "(", ")", "# as in torch.optim.optimizer.zero_grad()", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._check_overflow": [[278, 287], ["fp16.FP16_Optimizer.loss_scaler.has_overflow", "params.append", "params.append"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.has_overflow"], ["", "", "", "", "", "def", "_check_overflow", "(", "self", ")", ":", "\n", "        ", "params", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "fp16_groups", ":", "\n", "            ", "for", "param", "in", "group", ":", "\n", "                ", "params", ".", "append", "(", "param", ")", "\n", "", "", "for", "group", "in", "self", ".", "fp32_from_fp32_groups", ":", "\n", "            ", "for", "param", "in", "group", ":", "\n", "                ", "params", ".", "append", "(", "param", ")", "\n", "", "", "self", ".", "overflow", "=", "self", ".", "loss_scaler", ".", "has_overflow", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._update_scale": [[288, 290], ["fp16.FP16_Optimizer.loss_scaler.update_scale"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.loss_scaler.DynamicLossScaler.update_scale"], ["", "def", "_update_scale", "(", "self", ",", "has_overflow", "=", "False", ")", ":", "\n", "        ", "self", ".", "loss_scaler", ".", "update_scale", "(", "has_overflow", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._master_params_to_model_params": [[291, 294], ["zip", "fp16util.master_params_to_model_params"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.master_params_to_model_params"], ["", "def", "_master_params_to_model_params", "(", "self", ")", ":", "\n", "        ", "for", "fp16_group", ",", "fp32_from_fp16_group", "in", "zip", "(", "self", ".", "fp16_groups", ",", "self", ".", "fp32_from_fp16_groups", ")", ":", "\n", "            ", "master_params_to_model_params", "(", "fp16_group", ",", "fp32_from_fp16_group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._model_params_to_master_params": [[295, 298], ["zip", "fp16util.master_params_to_model_params"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.master_params_to_model_params"], ["", "", "def", "_model_params_to_master_params", "(", "self", ")", ":", "\n", "        ", "for", "fp16_group", ",", "fp32_from_fp16_group", "in", "zip", "(", "self", ".", "fp16_groups", ",", "self", ".", "fp32_from_fp16_groups", ")", ":", "\n", "            ", "master_params_to_model_params", "(", "fp32_from_fp16_group", ",", "fp16_group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._model_grads_to_master_grads": [[301, 304], ["zip", "fp16util.model_grads_to_master_grads"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16util.model_grads_to_master_grads"], ["", "", "def", "_model_grads_to_master_grads", "(", "self", ")", ":", "\n", "        ", "for", "fp16_group", ",", "fp32_from_fp16_group", "in", "zip", "(", "self", ".", "fp16_groups", ",", "self", ".", "fp32_from_fp16_groups", ")", ":", "\n", "            ", "model_grads_to_master_grads", "(", "fp16_group", ",", "fp32_from_fp16_group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._downscale_master": [[305, 311], ["param.grad.data.mul_"], "methods", ["None"], ["", "", "def", "_downscale_master", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "loss_scale", "!=", "1.0", ":", "\n", "            ", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "for", "param", "in", "group", "[", "'params'", "]", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "param", ".", "grad", ".", "data", ".", "mul_", "(", "1.", "/", "self", ".", "loss_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.clip_master_grads": [[312, 335], ["fp16.FP16_Optimizer.clip_grad_norm", "fp32_params.append"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.grads.clip_grad_norm"], ["", "", "", "", "", "def", "clip_master_grads", "(", "self", ",", "max_norm", ",", "norm_type", "=", "2", ")", ":", "\n", "        ", "\"\"\"\n        Clips fp32 master gradients via ``torch.nn.utils.clip_grad_norm``.\n\n        Args:\n            max_norm (float or int): max norm of the gradients\n            norm_type (float or int): type of the used p-norm. Can be ``'inf'`` for\n                infinity norm.\n\n        Returns:\n            Total norm of the current fp32 gradients (viewed as a single vector).\n\n        .. warning::\n            Returns -1 if the most recently computed fp16 gradients overflowed (that is, if ``self.overflow`` is ``True``).\n        \"\"\"", "\n", "if", "not", "self", ".", "overflow", ":", "\n", "            ", "fp32_params", "=", "[", "]", "\n", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "for", "param", "in", "param_group", "[", "'params'", "]", ":", "\n", "                    ", "fp32_params", ".", "append", "(", "param", ")", "\n", "", "", "return", "self", ".", "clip_grad_norm", "(", "fp32_params", ",", "max_norm", ",", "norm_type", ")", "\n", "", "else", ":", "\n", "            ", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.state_dict": [[336, 356], ["fp16.FP16_Optimizer.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns a dict containing the current state of this :class:`FP16_Optimizer` instance.\n        This dict contains attributes of :class:`FP16_Optimizer`, as well as the state_dict\n        of the contained Pytorch optimizer.\n        Example::\n\n            checkpoint = {}\n            checkpoint['model'] = model.state_dict()\n            checkpoint['optimizer'] = optimizer.state_dict()\n            torch.save(checkpoint, \"saved.pth\")\n        \"\"\"", "\n", "state_dict", "=", "{", "}", "\n", "state_dict", "[", "'loss_scaler'", "]", "=", "self", ".", "loss_scaler", "\n", "state_dict", "[", "'dynamic_loss_scale'", "]", "=", "self", ".", "dynamic_loss_scale", "\n", "state_dict", "[", "'overflow'", "]", "=", "self", ".", "overflow", "\n", "state_dict", "[", "'first_closure_call_this_step'", "]", "=", "self", ".", "first_closure_call_this_step", "\n", "state_dict", "[", "'optimizer_state_dict'", "]", "=", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "state_dict", "[", "'fp32_from_fp16'", "]", "=", "self", ".", "fp32_from_fp16_groups", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.load_state_dict": [[357, 398], ["fp16.FP16_Optimizer.optimizer.load_state_dict", "zip", "zip", "current.data.copy_"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"\n        Loads a state_dict created by an earlier call to state_dict(). \n        If ``fp16_optimizer_instance`` was constructed from some ``init_optimizer``, \n        whose parameters in turn came from ``model``, it is expected that the user \n        will call ``model.load_state_dict()`` before\n        ``fp16_optimizer_instance.load_state_dict()`` is called.\n\n        Example::\n\n            model = torch.nn.Linear(D_in, D_out).cuda().half()\n            optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n            optimizer = FP16_Optimizer(optimizer, static_loss_scale = 128.0)\n            ...\n            checkpoint = torch.load(\"saved.pth\")\n            model.load_state_dict(checkpoint['model'])\n            optimizer.load_state_dict(checkpoint['optimizer'])\n        \"\"\"", "\n", "# I think it should actually be ok to reload the optimizer before the model.", "\n", "self", ".", "loss_scaler", "=", "state_dict", "[", "'loss_scaler'", "]", "\n", "self", ".", "dynamic_loss_scale", "=", "state_dict", "[", "'dynamic_loss_scale'", "]", "\n", "self", ".", "overflow", "=", "state_dict", "[", "'overflow'", "]", "\n", "self", ".", "first_closure_call_this_step", "=", "state_dict", "[", "'first_closure_call_this_step'", "]", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "'optimizer_state_dict'", "]", ")", "\n", "# At this point, the optimizer's references to the model's fp32 parameters are up to date.", "\n", "# The optimizer's hyperparameters and internal buffers are also up to date.  ", "\n", "# However, the fp32 master copies of the model's fp16 params stored by the optimizer are still", "\n", "# out of date.  There are two options.  ", "\n", "# 1:  Refresh the master params from the model's fp16 params.  ", "\n", "# This requires less storage but incurs precision loss.", "\n", "# 2:  Save and restore the fp32 master copies separately.", "\n", "# We choose option 2.", "\n", "# ", "\n", "# Pytorch Optimizer.load_state_dict casts saved buffers (e.g. momentum) to the type and device ", "\n", "# of their associated parameters, because it's possible those buffers might not exist yet in ", "\n", "# the current optimizer instance.  In our case, as long as the current FP16_Optimizer has been ", "\n", "# constructed in the same way as the one whose state_dict we are loading, the same master params", "\n", "# are guaranteed to exist, so we can just copy_() from the saved master params.", "\n", "for", "current_group", ",", "saved_group", "in", "zip", "(", "self", ".", "fp32_from_fp16_groups", ",", "state_dict", "[", "'fp32_from_fp16'", "]", ")", ":", "\n", "            ", "for", "current", ",", "saved", "in", "zip", "(", "current_group", ",", "saved_group", ")", ":", "\n", "                ", "current", ".", "data", ".", "copy_", "(", "saved", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step": [[399, 454], ["fp16.FP16_Optimizer._update_scale", "fp16.FP16_Optimizer._master_params_to_model_params", "fp16.FP16_Optimizer.maybe_print", "fp16.FP16_Optimizer._step_with_closure", "fp16.FP16_Optimizer.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._update_scale", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._master_params_to_model_params", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.maybe_print", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._step_with_closure", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step"], ["", "", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "# could add clip option.", "\n", "        ", "\"\"\"\n        If no closure is supplied, :attr:`step` should be called after \n        ``fp16_optimizer_obj.backward(loss)``.\n        :attr:`step` updates the fp32 master copy of parameters using the optimizer supplied to\n        :class:`FP16_Optimizer`'s constructor, then copies the updated fp32 params into the fp16 params\n        originally referenced by :class:`FP16_Optimizer`'s constructor, so the user may immediately run\n        another forward pass using their model.\n\n        If a closure is supplied, :attr:`step` may be called without a prior call to \n        :attr:`backward(loss)`.\n        This control flow is identical to `ordinary Pytorch optimizer use`_ with closures.\n        However, the user should take care that any ``loss.backward()`` call within the closure\n        has been replaced by ``fp16_optimizer_obj.backward(loss)``.\n\n        Args:\n           closure (optional):  Closure that will be supplied to the underlying optimizer originally passed to :class:`FP16_Optimizer`'s constructor.  closure should call :attr:`zero_grad()` on the :class:`FP16_Optimizer` object, compute the loss, call :attr:`backward(loss)`, and return the loss.\n\n        Example with closure::\n\n            # optimizer is assumed to be an FP16_Optimizer object, previously constructed from an \n            # existing pytorch optimizer.\n            for input, target in dataset:\n                def closure():\n                    optimizer.zero_grad()\n                    output = model(input)\n                    loss = loss_fn(output, target)\n                    # loss.backward() becomes:\n                    optimizer.backward(loss)\n                    return loss\n                optimizer.step(closure)\n\n        .. warning::\n            Currently, calling :attr:`step` with a closure is not compatible with dynamic loss scaling.\n\n        .. _`ordinary Pytorch optimizer use`:\n            http://pytorch.org/docs/master/optim.html#optimizer-step-closure\n        \"\"\"", "\n", "\n", "scale", "=", "self", ".", "loss_scaler", ".", "loss_scale", "\n", "self", ".", "_update_scale", "(", "self", ".", "overflow", ")", "\n", "\n", "if", "self", ".", "overflow", ":", "\n", "            ", "self", ".", "maybe_print", "(", "\"OVERFLOW! Skipping step. Attempted loss scale: {}, reducing to {}\"", "\n", ".", "format", "(", "scale", ",", "self", ".", "loss_scale", ")", ")", "\n", "return", "\n", "\n", "", "if", "closure", "is", "not", "None", ":", "\n", "            ", "retval", "=", "self", ".", "_step_with_closure", "(", "closure", ")", "\n", "", "else", ":", "\n", "            ", "retval", "=", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "self", ".", "_master_params_to_model_params", "(", ")", "\n", "\n", "return", "retval", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._step_with_closure": [[455, 493], ["fp16.FP16_Optimizer.optimizer.step", "closure", "fp16.FP16_Optimizer._master_params_to_model_params", "fp16.FP16_Optimizer._update_scale", "fp16.FP16_Optimizer.maybe_print", "closure"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.step", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._master_params_to_model_params", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._update_scale", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.maybe_print"], ["", "def", "_step_with_closure", "(", "self", ",", "closure", ")", ":", "\n", "        ", "def", "wrapped_closure", "(", ")", ":", "\n", "# helpful for debugging", "\n", "# print(\"Calling wrapped_closure, first_closure_call_this_step = {}\"", "\n", "#       .format(self.first_closure_call_this_step))", "\n", "            ", "if", "self", ".", "first_closure_call_this_step", ":", "\n", "# We expect that the fp16 params are initially fresh on entering self.step(),", "\n", "# so _master_params_to_model_params() is unnecessary the first time wrapped_closure()", "\n", "# is called within self.optimizer.step().", "\n", "                ", "self", ".", "first_closure_call_this_step", "=", "False", "\n", "", "else", ":", "\n", "# If self.optimizer.step() internally calls wrapped_closure more than once,", "\n", "# it may update the fp32 params after each call.  However, self.optimizer ", "\n", "# doesn't know about the fp16 params at all.  If the fp32 params get updated,", "\n", "# we can't rely on self.optimizer to refresh the fp16 params.  We need", "\n", "# to handle that manually:", "\n", "                ", "self", ".", "_master_params_to_model_params", "(", ")", "\n", "# Our API expects the user to give us ownership of the backward() call by", "\n", "# replacing all calls to loss.backward() with optimizer.backward(loss).", "\n", "# This requirement holds whether or not the call to backward() is made within a closure.", "\n", "# If the user is properly calling optimizer.backward(loss) within \"closure,\" ", "\n", "# calling closure() here will give the fp32 master params fresh gradients", "\n", "# for the optimizer to play with, so all wrapped_closure needs to do is call ", "\n", "# closure() and return the loss.", "\n", "", "temp_loss", "=", "closure", "(", ")", "\n", "while", "(", "self", ".", "overflow", ")", ":", "\n", "                ", "scale", "=", "self", ".", "loss_scaler", ".", "loss_scale", "\n", "self", ".", "_update_scale", "(", "self", ".", "overflow", ")", "\n", "self", ".", "maybe_print", "(", "\"OVERFLOW within closure! Skipping step. Attempted loss scale: {}, \"", "\n", "\"reducing to {}\"", ".", "format", "(", "scale", ",", "self", ".", "loss_scale", ")", ")", "\n", "temp_loss", "=", "closure", "(", ")", "\n", "", "return", "temp_loss", "\n", "\n", "", "retval", "=", "self", ".", "optimizer", ".", "step", "(", "wrapped_closure", ")", "\n", "\n", "self", ".", "first_closure_call_this_step", "=", "True", "\n", "\n", "return", "retval", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.backward": [[494, 555], ["fp16.FP16_Optimizer.loss_scaler.backward", "loss.float", "fp16.FP16_Optimizer.update_master_grads"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.update_master_grads"], ["", "def", "backward", "(", "self", ",", "loss", ",", "update_master_grads", "=", "True", ",", "retain_graph", "=", "False", ")", ":", "\n", "        ", "\"\"\" \n        :attr:`backward` performs the following conceptual steps:\n\n        1. fp32_loss = loss.float() (see first Note below)\n        2. scaled_loss = fp32_loss*loss_scale\n        3. scaled_loss.backward(), which accumulates scaled gradients into the ``.grad`` attributes of the model's leaves (which may be fp16, fp32, or a mixture, depending how your model was defined).\n        4. fp16 grads are then copied to the master params' ``.grad`` attributes (see second Note), which are guaranteed to be fp32.\n        5. Finally, master grads are divided by loss_scale.\n\n        In this way, after :attr:`backward`, the master params have fresh gradients,\n        and :attr:`step` may be called.\n\n        .. note::\n            :attr:`backward` internally converts the loss to fp32 before applying the loss scale.\n            This provides some additional safety against overflow if the user has supplied an \n            fp16 loss value.  \n            However, for maximum overflow safety, the user should\n            compute the loss criterion (MSE, cross entropy, etc) in fp32 before supplying it to \n            :attr:`backward`.\n\n        .. warning::\n            The gradients found in a model's leaves after the call to \n            :attr:`backward` should not be regarded as valid in general, \n            because it's possible \n            they have been scaled (and in the case of dynamic loss scaling, \n            the scale factor may change over time).  \n            If the user wants to inspect gradients after a call to :attr:`backward`,  \n            only the master gradients should be regarded as valid.  These can be retrieved via\n            :attr:`inspect_master_grad_data()`.\n\n        Args:\n            loss:  The loss output by the user's model.  loss may be either float or half (but see first Note above).\n            update_master_grads (bool, optional, default=True):  Option to copy fp16 grads to fp32 grads on this call.  By setting this to False, the user can delay the copy, which is useful to eliminate redundant fp16->fp32 grad copies if :attr:`backward` is being called on multiple losses in one iteration.  If set to False, the user becomes responsible for calling :attr:`update_master_grads` before calling :attr:`step`.\n            retain_graph (bool, optional, default=False):  Forwards the usual ``retain_graph=True`` option to the internal call to ``loss.backward``.  If ``retain_graph`` is being used to accumulate gradient values from multiple backward passes before calling ``optimizer.step``, passing ``update_master_grads=False`` is also recommended (see Example below).\n\n        Example::\n\n            # Ordinary operation:\n            optimizer.backward(loss)\n\n            # Naive operation with multiple losses (technically valid, but less efficient):\n            # fp32 grads will be correct after the second call,  but \n            # the first call incurs an unnecessary fp16->fp32 grad copy.\n            optimizer.backward(loss1)\n            optimizer.backward(loss2)\n\n            # More efficient way to handle multiple losses:\n            # The fp16->fp32 grad copy is delayed until fp16 grads from all \n            # losses have been accumulated.\n            optimizer.backward(loss1, update_master_grads=False)\n            optimizer.backward(loss2, update_master_grads=False)\n            optimizer.update_master_grads()\n        \"\"\"", "\n", "# To consider:  try multiple backward passes using retain_grad=True to find ", "\n", "# a loss scale that works.  After you find a loss scale that works, do a final dummy", "\n", "# backward pass with retain_graph=False to tear down the graph.  Doing this would avoid ", "\n", "# discarding the iteration,  but probably wouldn't improve overall efficiency.  ", "\n", "self", ".", "loss_scaler", ".", "backward", "(", "loss", ".", "float", "(", ")", ",", "retain_graph", "=", "retain_graph", ")", "\n", "if", "update_master_grads", ":", "\n", "            ", "self", ".", "update_master_grads", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.update_master_grads": [[556, 568], ["fp16.FP16_Optimizer._model_grads_to_master_grads", "fp16.FP16_Optimizer._downscale_master", "fp16.FP16_Optimizer._check_overflow"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._model_grads_to_master_grads", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._downscale_master", "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._check_overflow"], ["", "", "def", "update_master_grads", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Copy the ``.grad`` attribute from stored references to fp16 parameters to \n        the ``.grad`` attribute of the fp32 master parameters that are directly \n        updated by the optimizer.  :attr:`update_master_grads` only needs to be called if\n        ``fp16_optimizer_obj.backward`` was called with ``update_master_grads=False``.\n        \"\"\"", "\n", "if", "self", ".", "dynamic_loss_scale", ":", "\n", "            ", "self", ".", "_check_overflow", "(", ")", "\n", "if", "self", ".", "overflow", ":", "return", "\n", "", "self", ".", "_model_grads_to_master_grads", "(", ")", "\n", "self", ".", "_downscale_master", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer.inspect_master_grad_data": [[569, 601], ["print", "master_grads_data.append", "master_grads_this_group.append", "master_grads_this_group.append"], "methods", ["None"], ["", "def", "inspect_master_grad_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        When running with :class:`FP16_Optimizer`, \n        ``.grad`` attributes of a model's fp16 leaves should not be\n        regarded as truthful, because they might be scaled.  \n        After a call to :attr:`fp16_optimizer_obj.backward(loss)`, if no overflow was encountered,\n        the fp32 master params' ``.grad``\n        attributes will contain valid gradients properly divided by the loss scale.  However, \n        because :class:`FP16_Optimizer` flattens some parameters, accessing them may be \n        nonintuitive.  :attr:`inspect_master_grad_data`\n        allows those gradients to be viewed with shapes corresponding to their associated model leaves.\n\n        Returns:\n            List of lists (one list for each parameter group).  The list for each parameter group\n            is a list of the ``.grad.data`` attributes of the fp32 master params belonging to that group.                 \n        \"\"\"", "\n", "if", "self", ".", "overflow", ":", "\n", "            ", "print", "(", "\"Warning:  calling FP16_Optimizer.inspect_master_grad_data while in an overflow state.  \"", "\n", "\"Gradients are currently invalid (may be inf, nan, or stale).  Returning None.\"", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "# The optimizer owns only references to master params.", "\n", "            ", "master_grads_data", "=", "[", "]", "\n", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "master_grads_this_group", "=", "[", "]", "\n", "for", "param", "in", "param_group", "[", "'params'", "]", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "master_grads_this_group", ".", "append", "(", "param", ".", "grad", ".", "data", ")", "\n", "", "else", ":", "\n", "                        ", "master_grads_this_group", ".", "append", "(", "None", ")", "\n", "", "", "master_grads_data", ".", "append", "(", "master_grads_this_group", ")", "\n", "", "return", "master_grads_data", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._get_loss_scale": [[604, 606], ["None"], "methods", ["None"], ["", "", "def", "_get_loss_scale", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "loss_scaler", ".", "loss_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._set_loss_scale": [[607, 609], ["None"], "methods", ["None"], ["", "def", "_set_loss_scale", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "loss_scaler", ".", "cur_scale", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._get_state": [[613, 615], ["None"], "methods", ["None"], ["def", "_get_state", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._set_state": [[616, 618], ["None"], "methods", ["None"], ["", "def", "_set_state", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "state", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._get_param_groups": [[623, 625], ["None"], "methods", ["None"], ["def", "_get_param_groups", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.FP16_Optimizer._set_param_groups": [[626, 628], ["None"], "methods", ["None"], ["", "def", "_set_param_groups", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "param_groups", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.conversion_helper": [[28, 36], ["isinstance", "isinstance", "conversion", "fp16.conversion_helper", "tuple"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.conversion_helper"], ["def", "conversion_helper", "(", "val", ",", "conversion", ")", ":", "\n", "    ", "\"\"\"Apply conversion to val. Recursively apply conversion if `val` is a nested tuple/list structure.\"\"\"", "\n", "if", "not", "isinstance", "(", "val", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "return", "conversion", "(", "val", ")", "\n", "", "rtn", "=", "[", "conversion_helper", "(", "v", ",", "conversion", ")", "for", "v", "in", "val", "]", "\n", "if", "isinstance", "(", "val", ",", "tuple", ")", ":", "\n", "        ", "rtn", "=", "tuple", "(", "rtn", ")", "\n", "", "return", "rtn", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.fp32_to_fp16": [[37, 47], ["fp16.conversion_helper", "isinstance", "isinstance", "val.half.half"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.conversion_helper"], ["", "def", "fp32_to_fp16", "(", "val", ")", ":", "\n", "    ", "\"\"\"Convert fp32 `val` to fp16\"\"\"", "\n", "def", "half_conversion", "(", "val", ")", ":", "\n", "        ", "val_typecheck", "=", "val", "\n", "if", "isinstance", "(", "val_typecheck", ",", "(", "Parameter", ",", "Variable", ")", ")", ":", "\n", "            ", "val_typecheck", "=", "val", ".", "data", "\n", "", "if", "isinstance", "(", "val_typecheck", ",", "FLOAT_TYPES", ")", ":", "\n", "            ", "val", "=", "val", ".", "half", "(", ")", "\n", "", "return", "val", "\n", "", "return", "conversion_helper", "(", "val", ",", "half_conversion", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.fp16_to_fp32": [[48, 58], ["fp16.conversion_helper", "isinstance", "isinstance", "val.float.float"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.fp16.fp16.conversion_helper"], ["", "def", "fp16_to_fp32", "(", "val", ")", ":", "\n", "    ", "\"\"\"Convert fp16 `val` to fp32\"\"\"", "\n", "def", "float_conversion", "(", "val", ")", ":", "\n", "        ", "val_typecheck", "=", "val", "\n", "if", "isinstance", "(", "val_typecheck", ",", "(", "Parameter", ",", "Variable", ")", ")", ":", "\n", "            ", "val_typecheck", "=", "val", ".", "data", "\n", "", "if", "isinstance", "(", "val_typecheck", ",", "HALF_TYPES", ")", ":", "\n", "            ", "val", "=", "val", ".", "float", "(", ")", "\n", "", "return", "val", "\n", "", "return", "conversion_helper", "(", "val", ",", "float_conversion", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.VQVAETokenizer.__init__": [[34, 53], ["torch.load", "torch.load", "torch.load", "torch.load", "vqvae.new_model", "[].startswith", "model.to.to.load_state_dict", "model.to.to.to", "model.to.to.eval", "torch.device", "torch.device", "torch.device", "torch.device", "list", "torch.load.items", "torch.load.items", "torch.load.keys", "torch.load.keys"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.new_model", "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model_path", ",", "\n", "device", "=", "'cuda'", "\n", ")", ":", "\n", "        ", "ckpt", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "torch", ".", "device", "(", "device", ")", ")", "\n", "\n", "model", "=", "new_model", "(", ")", "\n", "\n", "if", "list", "(", "ckpt", ".", "keys", "(", ")", ")", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "            ", "ckpt", "=", "{", "k", "[", "7", ":", "]", ":", "v", "for", "k", ",", "v", "in", "ckpt", ".", "items", "(", ")", "}", "\n", "\n", "", "model", ".", "load_state_dict", "(", "ckpt", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "image_tokens", "=", "model", ".", "quantize_t", ".", "n_embed", "\n", "self", ".", "num_tokens", "=", "model", ".", "quantize_t", ".", "n_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.VQVAETokenizer.__len__": [[54, 56], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.VQVAETokenizer.EncodeAsIds": [[57, 60], ["vqvae.img2code", "len"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.img2code"], ["", "def", "EncodeAsIds", "(", "self", ",", "img", ")", ":", "\n", "        ", "assert", "len", "(", "img", ".", "shape", ")", "==", "4", "# [b, c, h, w]", "\n", "return", "img2code", "(", "self", ".", "model", ",", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.VQVAETokenizer.DecodeIds": [[61, 71], ["torch.tensor.view", "torch.tensor.view", "vqvae.code2img", "isinstance", "vqvae_tokenizer.sqrt_int", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "torch.tensor.view", "torch.tensor.view", "torch.tensor.view", "torch.tensor.view"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.code2img", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.sqrt_int"], ["", "def", "DecodeIds", "(", "self", ",", "code", ",", "shape", "=", "None", ")", ":", "\n", "        ", "if", "shape", "is", "None", ":", "\n", "            ", "if", "isinstance", "(", "code", ",", "list", ")", ":", "\n", "                ", "code", "=", "torch", ".", "tensor", "(", "code", ",", "device", "=", "self", ".", "device", ")", "\n", "", "s", "=", "sqrt_int", "(", "len", "(", "code", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "assert", "s", "*", "s", "==", "len", "(", "code", ".", "view", "(", "-", "1", ")", ")", "\n", "shape", "=", "(", "1", ",", "s", ",", "s", ")", "\n", "", "code", "=", "code", ".", "view", "(", "shape", ")", "\n", "out", "=", "code2img", "(", "self", ".", "model", ",", "code", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.VQVAETokenizer.read_img": [[72, 85], ["torchvision.transforms.Compose", "torchvision.transforms.Compose.", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize.", "img.unsqueeze().float().to.unsqueeze().float().to.unsqueeze().float().to", "PIL.Image.open", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "img.unsqueeze().float().to.unsqueeze().float().to.unsqueeze().float", "img.unsqueeze().float().to.unsqueeze().float().to.unsqueeze"], "methods", ["None"], ["", "def", "read_img", "(", "self", ",", "path", ",", "img_size", "=", "256", ")", ":", "\n", "        ", "tr", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "img_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "img_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "img", "=", "tr", "(", "Image", ".", "open", "(", "path", ")", ")", "\n", "if", "img", ".", "shape", "[", "0", "]", "==", "4", ":", "\n", "            ", "img", "=", "img", "[", ":", "-", "1", "]", "\n", "", "tr_normalize", "=", "transforms", ".", "Normalize", "(", "[", "0.79093", ",", "0.76271", ",", "0.75340", "]", ",", "[", "0.30379", ",", "0.32279", ",", "0.32800", "]", ")", "\n", "img", "=", "tr_normalize", "(", "img", ")", "\n", "img", "=", "img", ".", "unsqueeze", "(", "0", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "# size [1, 3, h, w]", "\n", "return", "img", "", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.is_exp2": [[25, 28], ["math.log2", "abs", "int"], "function", ["None"], ["def", "is_exp2", "(", "x", ")", ":", "\n", "    ", "t", "=", "math", ".", "log2", "(", "x", ")", "\n", "return", "abs", "(", "t", "-", "int", "(", "t", ")", ")", "<", "1e-4", "\n", "", "def", "sqrt_int", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.sqrt_int": [[28, 32], ["int", "math.sqrt"], "function", ["None"], ["", "def", "sqrt_int", "(", "x", ")", ":", "\n", "    ", "r", "=", "int", "(", "math", ".", "sqrt", "(", "x", ")", "+", "1e-4", ")", "\n", "assert", "r", "*", "r", "==", "x", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.RandomSampler.__init__": [[36, 52], ["ValueError", "ValueError", "isinstance", "ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ",", "replacement", "=", "False", ",", "num_samples", "=", "None", ")", ":", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "replacement", "=", "replacement", "\n", "self", ".", "_num_samples", "=", "num_samples", "\n", "self", ".", "epoch", "=", "-", "1", "\n", "\n", "if", "self", ".", "_num_samples", "is", "not", "None", "and", "replacement", "is", "False", ":", "\n", "            ", "raise", "ValueError", "(", "\"With replacement=False, num_samples should not be specified, \"", "\n", "\"since a random permute will be performed.\"", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "num_samples", ",", "int", ")", "or", "self", ".", "num_samples", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_samples should be a positive integer \"", "\n", "\"value, but got num_samples={}\"", ".", "format", "(", "self", ".", "num_samples", ")", ")", "\n", "", "if", "not", "isinstance", "(", "self", ".", "replacement", ",", "bool", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"replacement should be a boolean value, but got \"", "\n", "\"replacement={}\"", ".", "format", "(", "self", ".", "replacement", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.RandomSampler.num_samples": [[53, 59], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "num_samples", "(", "self", ")", ":", "\n", "# dataset size might change at runtime", "\n", "        ", "if", "self", ".", "_num_samples", "is", "None", ":", "\n", "            ", "return", "len", "(", "self", ".", "data_source", ")", "\n", "", "return", "self", ".", "_num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.RandomSampler.__iter__": [[60, 68], ["len", "torch.Generator", "iter", "torch.Generator.manual_seed", "iter", "torch.randperm().tolist", "torch.randint().tolist", "torch.randperm", "torch.randint"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "n", "=", "len", "(", "self", ".", "data_source", ")", "\n", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "if", "self", ".", "epoch", ">=", "0", ":", "\n", "            ", "g", ".", "manual_seed", "(", "self", ".", "epoch", ")", "\n", "", "if", "self", ".", "replacement", ":", "\n", "            ", "return", "iter", "(", "torch", ".", "randint", "(", "high", "=", "n", ",", "size", "=", "(", "self", ".", "num_samples", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", ")", "\n", "", "return", "iter", "(", "torch", ".", "randperm", "(", "n", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.RandomSampler.__len__": [[69, 71], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.RandomSampler.set_epoch": [[72, 74], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedSequentialSampler.__init__": [[77, 89], ["super().__init__", "range"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_samples", ",", "train_iters", ",", "batch_size", ",", "rank", "=", "-", "1", ",", "world_size", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_samples", ")", "\n", "if", "rank", "==", "-", "1", ":", "\n", "            ", "rank", "=", "0", "\n", "world_size", "=", "1", "\n", "", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "start_iter", "=", "0", "\n", "self", ".", "train_iters", "=", "train_iters", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_bias", "=", "[", "i", "*", "(", "num_samples", "//", "batch_size", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedSequentialSampler.__iter__": [[90, 95], ["range", "samplers.DistributedSequentialSampler._batch"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler._batch"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "self", ".", "start_iter", ",", "self", ".", "train_iters", "*", "10", ")", ":", "\n", "            ", "batch", "=", "[", "(", "idx", "+", "bias", ")", "%", "self", ".", "num_samples", "for", "bias", "in", "self", ".", "batch_bias", "]", "\n", "tbatch", "=", "self", ".", "_batch", "(", "batch", ")", "\n", "yield", "tbatch", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedSequentialSampler.__len__": [[96, 98], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "train_iters", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedSequentialSampler._batch": [[99, 104], ["None"], "methods", ["None"], ["", "def", "_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"extracts samples only pertaining to this worker's batch\"\"\"", "\n", "start", "=", "self", ".", "rank", "*", "self", ".", "batch_size", "//", "self", ".", "world_size", "\n", "end", "=", "(", "self", ".", "rank", "+", "1", ")", "*", "self", ".", "batch_size", "//", "self", ".", "world_size", "\n", "return", "batch", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler.__init__": [[112, 123], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["def", "__init__", "(", "self", ",", "sampler", ",", "batch_size", ",", "drop_last", ",", "rank", "=", "-", "1", ",", "world_size", "=", "2", ",", "wrap_last", "=", "False", ",", "gradient_accumulation_steps", "=", "None", ")", ":", "\n", "        ", "super", "(", "DistributedBatchSampler", ",", "self", ")", ".", "__init__", "(", "sampler", ",", "batch_size", ",", "drop_last", ")", "\n", "if", "rank", "==", "-", "1", ":", "\n", "            ", "assert", "False", ",", "'should not be here'", "\n", "", "self", ".", "rank", "=", "rank", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "sampler", ".", "wrap_around", "=", "0", "\n", "self", ".", "wrap_around", "=", "0", "\n", "self", ".", "wrap_last", "=", "wrap_last", "\n", "self", ".", "start_iter", "=", "0", "\n", "self", ".", "effective_batch_size", "=", "batch_size", "if", "gradient_accumulation_steps", "is", "None", "else", "batch_size", "*", "gradient_accumulation_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler.__iter__": [[124, 153], ["samplers.DistributedBatchSampler.data_iterator", "len", "batch.append", "len", "samplers.DistributedBatchSampler._batch", "len", "len", "isinstance", "samplers.DistributedBatchSampler._batch", "enumerate", "samplers.DistributedBatchSampler.data_iterator", "batch.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler.data_iterator", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler._batch", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler._batch", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler.data_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "batch", "=", "[", "]", "\n", "i", "=", "0", "\n", "for", "idx", "in", "self", ".", "data_iterator", "(", "self", ".", "sampler", ",", "wrap_around", "=", "False", ")", ":", "\n", "            ", "batch", ".", "append", "(", "idx", ")", "\n", "if", "len", "(", "batch", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "tbatch", "=", "self", ".", "_batch", "(", "batch", ")", "\n", "if", "i", ">=", "self", ".", "start_iter", "*", "self", ".", "effective_batch_size", ":", "\n", "                    ", "yield", "tbatch", "\n", "self", ".", "start_iter", "=", "0", "\n", "", "i", "+=", "len", "(", "batch", ")", "\n", "batch", "=", "[", "]", "\n", "", "", "batch_len", "=", "len", "(", "batch", ")", "\n", "if", "batch_len", ">", "0", "and", "not", "self", ".", "drop_last", ":", "\n", "            ", "if", "self", ".", "wrap_last", ":", "\n", "                ", "self", ".", "sampler", ".", "wrap_around", "-=", "(", "self", ".", "batch_size", ")", "\n", "self", ".", "wrap_around", "+=", "(", "len", "(", "batch", ")", ")", "\n", "self", ".", "wrap_around", "%=", "self", ".", "batch_size", "\n", "if", "isinstance", "(", "self", ".", "sampler", ",", "TransposedSampler", ")", ":", "\n", "                    ", "for", "i", ",", "idx", "in", "enumerate", "(", "self", ".", "data_iterator", "(", "self", ".", "sampler", ",", "wrap_around", "=", "True", ")", ")", ":", "\n", "                        ", "if", "i", "==", "0", ":", "\n", "                            ", "continue", "\n", "", "batch", ".", "append", "(", "idx", ")", "\n", "new_batch_len", "=", "len", "(", "batch", ")", "\n", "if", "len", "(", "batch", ")", "==", "self", ".", "batch_size", ":", "\n", "                            ", "break", "\n", "", "", "", "", "yield", "self", ".", "_batch", "(", "batch", ")", "\n", "", "if", "self", ".", "wrap_last", ":", "\n", "            ", "self", ".", "sampler", ".", "wrap_around", "+=", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler.data_iterator": [[154, 163], ["enumerate"], "methods", ["None"], ["", "", "def", "data_iterator", "(", "self", ",", "_iter", ",", "wrap_around", "=", "False", ")", ":", "\n", "        ", "\"\"\"iterates through data and handles wrap around\"\"\"", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "_iter", ")", ":", "\n", "            ", "if", "i", "<", "self", ".", "wrap_around", "%", "self", ".", "batch_size", ":", "\n", "                ", "continue", "\n", "", "if", "wrap_around", ":", "\n", "                ", "self", ".", "wrap_around", "+=", "1", "\n", "self", ".", "wrap_around", "%=", "self", ".", "batch_size", "\n", "", "yield", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.samplers.DistributedBatchSampler._batch": [[164, 169], ["None"], "methods", ["None"], ["", "", "def", "_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"extracts samples only pertaining to this worker's batch\"\"\"", "\n", "start", "=", "self", ".", "rank", "*", "self", ".", "batch_size", "//", "self", ".", "world_size", "\n", "end", "=", "(", "self", ".", "rank", "+", "1", ")", "*", "self", ".", "batch_size", "//", "self", ".", "world_size", "\n", "return", "batch", "[", "start", ":", "end", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.ConcatDataset.cumsum": [[223, 231], ["len", "r.append"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "cumsum", "(", "sequence", ")", ":", "\n", "        ", "r", ",", "s", "=", "[", "]", ",", "0", "\n", "for", "e", "in", "sequence", ":", "\n", "            ", "l", "=", "len", "(", "e", ")", "\n", "r", ".", "append", "(", "l", "+", "s", ")", "\n", "s", "+=", "l", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.ConcatDataset.__init__": [[232, 237], ["torch.utils.data.Dataset.__init__", "list", "configure_data.ConcatDataset.cumsum", "len"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.ConcatDataset.cumsum"], ["", "def", "__init__", "(", "self", ",", "datasets", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ConcatDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "datasets", ")", ">", "0", ",", "'datasets should not be an empty iterable'", "\n", "self", ".", "datasets", "=", "list", "(", "datasets", ")", "\n", "self", ".", "cumulative_sizes", "=", "self", ".", "cumsum", "(", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.ConcatDataset.__len__": [[238, 240], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cumulative_sizes", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.ConcatDataset.__getitem__": [[241, 248], ["bisect.bisect_right"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "dataset_idx", "=", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "idx", ")", "\n", "if", "dataset_idx", "==", "0", ":", "\n", "            ", "sample_idx", "=", "idx", "\n", "", "else", ":", "\n", "            ", "sample_idx", "=", "idx", "-", "self", ".", "cumulative_sizes", "[", "dataset_idx", "-", "1", "]", "\n", "", "return", "self", ".", "datasets", "[", "dataset_idx", "]", "[", "sample_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.SplitDataset.__init__": [[260, 263], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ds", ",", "split_range", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "split_range", "=", "split_range", "\n", "self", ".", "wrapped_data", "=", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.SplitDataset.__len__": [[264, 266], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "split_range", "[", "1", "]", "-", "self", ".", "split_range", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.SplitDataset.__getitem__": [[267, 271], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "index", "+=", "self", ".", "split_range", "[", "0", "]", "\n", "assert", "index", "<", "self", ".", "split_range", "[", "1", "]", "\n", "return", "self", ".", "wrapped_data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.SplitDataset.__iter__": [[272, 275], ["range"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "*", "self", ".", "split_range", ")", ":", "\n", "            ", "yield", "self", ".", "wrapped_data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.RandomMappingDataset.__init__": [[281, 283], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ds", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "wrapped_data", "=", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.RandomMappingDataset.__len__": [[284, 286], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "wrapped_data", ")", "*", "200", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.RandomMappingDataset.__getitem__": [[287, 292], ["random.Random", "numpy.random.RandomState", "numpy.random.RandomState.randint", "len", "numpy.random.RandomState.randint", "range"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "rng", "=", "random", ".", "Random", "(", "index", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "[", "rng", ".", "randint", "(", "0", ",", "2", "**", "32", "-", "1", ")", "for", "_", "in", "range", "(", "16", ")", "]", ")", "\n", "index", "=", "rng", ".", "randint", "(", "len", "(", "self", ".", "wrapped_data", ")", ")", "\n", "return", "self", ".", "wrapped_data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_data_loader": [[30, 55], ["torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "samplers.DistributedBatchSampler", "torch.utils.data.BatchSampler", "torch.utils.data.BatchSampler", "mpu.get_data_parallel_group", "mpu.get_data_parallel_group"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group"], ["def", "make_data_loader", "(", "dataset", ",", "batch_size", ",", "num_iters", ",", "args", ")", ":", "\n", "    ", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", "\n", "group", "=", "mpu", ".", "get_data_parallel_group", "(", ")", ")", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", "group", "=", "mpu", ".", "get_data_parallel_group", "(", ")", ")", "\n", "distributed", "=", "world_size", ">", "1", "\n", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "SequentialSampler", "(", "dataset", ")", "\n", "drop_last", "=", "distributed", "\n", "# the GPUs in the same model parallel group receive the same data", "\n", "if", "distributed", ":", "\n", "        ", "batch_sampler", "=", "DistributedBatchSampler", "(", "sampler", ",", "\n", "batch_size", ",", "\n", "drop_last", ",", "\n", "rank", ",", "\n", "world_size", ",", "\n", "gradient_accumulation_steps", "=", "args", ".", "gradient_accumulation_steps", ")", "\n", "", "else", ":", "\n", "        ", "batch_sampler", "=", "torch", ".", "utils", ".", "data", ".", "BatchSampler", "(", "sampler", ",", "\n", "batch_size", ",", "\n", "drop_last", ")", "\n", "", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "True", ")", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_dataset": [[57, 85], ["print", "isinstance", "configure_data.RandomMappingDataset", "configure_data.should_split", "datasets.get_dataset_by_type", "configure_data.ConcatDataset", "configure_data.split_ds", "p.find", "split_ds.extend", "print", "p.find", "split_ds.extend", "print", "split_ds.append"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.should_split", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.get_dataset_by_type", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.split_ds"], ["", "def", "make_dataset", "(", "dataset_type", ",", "path", ",", "split", ",", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"function to create datasets+tokenizers for common options\"\"\"", "\n", "print", "(", "'make dataset ...'", ",", "path", ")", "\n", "if", "split", "is", "None", ":", "\n", "        ", "split", "=", "[", "1.", "]", "\n", "\n", "", "assert", "isinstance", "(", "path", ",", "list", ")", "\n", "# TODO other dsclass, e.g. odps", "\n", "# ds = [get_dataset_by_type(dataset_type, p, args) for p in path]", "\n", "# dataset object can be copied N times", "\n", "ds", "=", "[", "]", "\n", "for", "p", "in", "path", ":", "\n", "        ", "d", "=", "get_dataset_by_type", "(", "dataset_type", ",", "p", ",", "args", ")", "\n", "if", "p", ".", "find", "(", "'t2i'", ")", ">=", "0", ":", "\n", "            ", "ds", ".", "extend", "(", "[", "d", "]", "*", "4", ")", "\n", "print", "(", "f'Enlarge {p} 4 times...'", ")", "\n", "", "elif", "p", ".", "find", "(", "'i2t'", ")", ">=", "0", ":", "\n", "            ", "ds", ".", "extend", "(", "[", "d", "]", "*", "2", ")", "\n", "print", "(", "f'Enlarge {p} 2 times...'", ")", "\n", "", "else", ":", "\n", "            ", "ds", ".", "append", "(", "d", ")", "\n", "\n", "", "", "ds", "=", "RandomMappingDataset", "(", "ConcatDataset", "(", "ds", ")", ")", "\n", "\n", "if", "should_split", "(", "split", ")", ":", "\n", "        ", "ds", "=", "split_ds", "(", "ds", ",", "split", ")", "# Large dataset, cannot shuffle, randomly mapping", "\n", "# FIXME this will merge valid set and train set.", "\n", "", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_loaders": [[86, 144], ["torch.distributed.get_world_size", "torch.distributed.get_world_size", "configure_data.get_split", "copy.copy", "configure_data.make_dataset", "configure_data.should_split", "configure_data.make_dataset", "configure_data.make_dataset", "configure_data.make_data_loader", "configure_data.make_data_loader", "configure_data.make_data_loader", "mpu.get_data_parallel_group", "len"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.get_split", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_dataset", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.should_split", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_dataset", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_dataset", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_data_loader", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_data_loader", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_data_loader", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group"], ["", "def", "make_loaders", "(", "args", ")", ":", "\n", "    ", "\"\"\"makes training/val/test\"\"\"", "\n", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", "\n", "group", "=", "mpu", ".", "get_data_parallel_group", "(", ")", ")", "\n", "batch_size", "=", "args", ".", "batch_size", "*", "world_size", "\n", "eval_batch_size", "=", "batch_size", "\n", "if", "args", ".", "eval_batch_size", "is", "not", "None", ":", "\n", "        ", "eval_batch_size", "=", "args", ".", "eval_batch_size", "*", "world_size", "\n", "\n", "", "split", "=", "get_split", "(", "args", ")", "\n", "\n", "data_set_args", "=", "{", "\n", "'path'", ":", "args", ".", "train_data", ",", "\n", "'dataset_type'", ":", "args", ".", "dataset_type", ",", "\n", "'split'", ":", "split", ",", "\n", "}", "\n", "\n", "eval_set_args", "=", "copy", ".", "copy", "(", "data_set_args", ")", "\n", "eval_set_args", "[", "'split'", "]", "=", "[", "1.", "]", "\n", "\n", "# make datasets splits and tokenizer", "\n", "train", "=", "None", "\n", "valid", "=", "None", "\n", "test", "=", "None", "\n", "\n", "if", "args", ".", "train_data", "is", "not", "None", ":", "\n", "        ", "train", "=", "make_dataset", "(", "**", "data_set_args", ",", "args", "=", "args", ")", "\n", "if", "should_split", "(", "split", ")", ":", "\n", "            ", "train", ",", "valid", ",", "test", "=", "train", "\n", "\n", "# make training and val dataset if necessary", "\n", "", "", "if", "valid", "is", "None", "and", "args", ".", "valid_data", "is", "not", "None", ":", "\n", "        ", "eval_set_args", "[", "'path'", "]", "=", "args", ".", "valid_data", "\n", "valid", "=", "make_dataset", "(", "**", "eval_set_args", ",", "args", "=", "args", ")", "\n", "", "if", "test", "is", "None", "and", "args", ".", "test_data", "is", "not", "None", ":", "\n", "        ", "eval_set_args", "[", "'path'", "]", "=", "args", ".", "test_data", "\n", "test", "=", "make_dataset", "(", "**", "eval_set_args", ",", "args", "=", "args", ")", "\n", "\n", "# wrap datasets with data loader", "\n", "", "if", "train", "is", "not", "None", "and", "args", ".", "batch_size", ">", "0", ":", "\n", "        ", "train", "=", "make_data_loader", "(", "train", ",", "batch_size", ",", "args", ".", "train_iters", ",", "args", ")", "\n", "args", ".", "do_train", "=", "True", "\n", "", "else", ":", "\n", "        ", "args", ".", "do_train", "=", "False", "\n", "", "eval_batch_size", "=", "eval_batch_size", "if", "eval_batch_size", "!=", "0", "else", "batch_size", "\n", "if", "valid", "is", "not", "None", ":", "\n", "        ", "valid", "=", "make_data_loader", "(", "valid", ",", "eval_batch_size", ",", "args", ".", "train_iters", ",", "args", ")", "\n", "args", ".", "do_valid", "=", "True", "\n", "", "else", ":", "\n", "        ", "args", ".", "do_valid", "=", "False", "\n", "", "if", "test", "is", "not", "None", ":", "\n", "        ", "test", "=", "make_data_loader", "(", "test", ",", "eval_batch_size", ",", "len", "(", "test", ")", "//", "eval_batch_size", "+", "1", ",", "args", ")", "\n", "args", ".", "do_test", "=", "True", "\n", "", "else", ":", "\n", "        ", "args", ".", "do_test", "=", "False", "\n", "\n", "", "return", "train", ",", "valid", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.get_split": [[147, 170], ["sum", "sum", "args.split.find", "splits.append", "len", "splits.append", "float", "args.split.find", "args.split.split", "float", "float", "args.split.split"], "function", ["None"], ["", "def", "get_split", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Get dataset splits from comma separated string list\n    \"\"\"", "\n", "splits", "=", "[", "]", "\n", "if", "args", ".", "split", ".", "find", "(", "','", ")", "!=", "-", "1", ":", "\n", "        ", "splits", "=", "[", "float", "(", "s", ")", "for", "s", "in", "args", ".", "split", ".", "split", "(", "','", ")", "]", "\n", "", "elif", "args", ".", "split", ".", "find", "(", "'/'", ")", "!=", "-", "1", ":", "\n", "        ", "splits", "=", "[", "float", "(", "s", ")", "for", "s", "in", "args", ".", "split", ".", "split", "(", "'/'", ")", "]", "\n", "", "else", ":", "\n", "        ", "splits", "=", "[", "float", "(", "args", ".", "split", ")", "]", "\n", "", "split_total", "=", "sum", "(", "splits", ")", "\n", "if", "split_total", "<", "1.", ":", "\n", "        ", "splits", ".", "append", "(", "1", "-", "split_total", ")", "\n", "", "while", "len", "(", "splits", ")", "<", "3", ":", "\n", "        ", "splits", ".", "append", "(", "0.", ")", "\n", "", "splits", "=", "splits", "[", ":", "3", "]", "\n", "if", "args", ".", "valid_data", "is", "not", "None", ":", "\n", "        ", "splits", "[", "1", "]", "=", "0.", "\n", "", "if", "args", ".", "test_data", "is", "not", "None", ":", "\n", "        ", "splits", "[", "2", "]", "=", "0.", "\n", "", "final_sum", "=", "sum", "(", "splits", ")", "\n", "return", "[", "s", "/", "final_sum", "for", "s", "in", "splits", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.should_split": [[171, 181], ["max", "sum"], "function", ["None"], ["", "def", "should_split", "(", "split", ")", ":", "\n", "    ", "\"\"\"\n    given split proportions checks if should split\n    Examples:\n    >>> should_split([10,0,0]) \n    False\n    >>> should_split([1,.1,.2])\n    True\n    \"\"\"", "\n", "return", "max", "(", "split", ")", "/", "sum", "(", "split", ")", "!=", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.split_ds": [[182, 212], ["sum", "numpy.array", "len", "enumerate", "Exception", "len", "int", "configure_data.SplitDataset", "int", "max"], "function", ["None"], ["", "def", "split_ds", "(", "ds", ",", "split", "=", "[", ".8", ",", ".2", ",", ".0", "]", ")", ":", "\n", "    ", "\"\"\"\n    Split a dataset into subsets given proportions of how\n    much to allocate per split. If a split is 0% returns None for that split.\n    Purpose: Useful for creating train/val/test splits\n    Arguments:\n        ds (Dataset or array-like): Data to be split.\n        split (1D array-like): proportions to split `ds`. `sum(splits) != 0`\n        shuffle (boolean): Randomly split dataset. Default: True\n    \"\"\"", "\n", "split_sum", "=", "sum", "(", "split", ")", "\n", "if", "split_sum", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "'Split cannot sum to 0.'", ")", "\n", "", "split", "=", "np", ".", "array", "(", "split", ")", "\n", "split", "/=", "split_sum", "\n", "ds_len", "=", "len", "(", "ds", ")", "\n", "\n", "start_idx", "=", "0", "\n", "residual_idx", "=", "0", "\n", "rtn_ds", "=", "[", "None", "]", "*", "len", "(", "split", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "split", ")", ":", "\n", "        ", "if", "f", "!=", "0", ":", "\n", "            ", "proportion", "=", "ds_len", "*", "split", "[", "i", "]", "\n", "residual_idx", "+=", "proportion", "%", "1", "\n", "split_", "=", "int", "(", "int", "(", "proportion", ")", "+", "residual_idx", ")", "\n", "split_range", "=", "(", "start_idx", ",", "start_idx", "+", "max", "(", "split_", ",", "1", ")", ")", "\n", "rtn_ds", "[", "i", "]", "=", "SplitDataset", "(", "ds", ",", "split_range", ")", "\n", "start_idx", "+=", "split_", "\n", "residual_idx", "%=", "1", "\n", "", "", "return", "rtn_ds", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.detect_new_datasets": [[293, 311], ["os.listdir", "os.path.exists", "print", "str", "os.path.join", "len", "configure_data.make_loaders", "os.path.abspath", "found.append", "str().endswith", "str().endswith", "str", "str", "str", "os.path.abspath"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.configure_data.make_loaders"], ["", "", "def", "detect_new_datasets", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "new_dataset_path", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "new_dataset_path", ")", ":", "\n", "        ", "print", "(", "'Warning: new_dataset_path not exists... skip detection.'", ")", "\n", "return", "None", "\n", "", "current_datasets", "=", "[", "str", "(", "os", ".", "path", ".", "abspath", "(", "path", ")", ")", "for", "path", "in", "args", ".", "train_data", "]", "\n", "\n", "found", "=", "[", "]", "\n", "for", "_p", "in", "os", ".", "listdir", "(", "args", ".", "new_dataset_path", ")", ":", "\n", "        ", "p", "=", "os", ".", "path", ".", "join", "(", "args", ".", "new_dataset_path", ",", "_p", ")", "\n", "if", "(", "str", "(", "p", ")", ".", "endswith", "(", "'lmdb'", ")", "or", "str", "(", "p", ")", ".", "endswith", "(", "'bin'", ")", ")", "and", "not", "str", "(", "os", ".", "path", ".", "abspath", "(", "p", ")", ")", "in", "current_datasets", ":", "\n", "            ", "found", ".", "append", "(", "p", ")", "\n", "", "", "if", "len", "(", "found", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "args", ".", "train_data", "=", "args", ".", "train_data", "+", "found", "\n", "return", "make_loaders", "(", "args", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.concat_codes": [[23, 51], ["isinstance", "isinstance", "torch.cat", "torch.cat", "numpy.concatenate", "torch.tensor", "torch.tensor", "numpy.array"], "function", ["None"], ["def", "concat_codes", "(", "*", "codes", ")", ":", "\n", "    ", "is_numpy", "=", "is_tensor", "=", "False", "\n", "for", "code", "in", "codes", ":", "\n", "        ", "if", "isinstance", "(", "code", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "is_numpy", "=", "True", "\n", "", "if", "isinstance", "(", "code", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "is_tensor", "=", "True", "\n", "device", "=", "code", ".", "device", "\n", "", "", "if", "is_tensor", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "\n", "[", "\n", "torch", ".", "tensor", "(", "code", ",", "device", "=", "device", ")", "\n", "for", "code", "in", "codes", "\n", "]", "\n", ")", "\n", "", "elif", "is_numpy", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "\n", "[", "\n", "np", ".", "array", "(", "code", ")", "\n", "for", "code", "in", "codes", "\n", "]", ",", "\n", "axis", "=", "0", "\n", ")", "\n", "", "else", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "code", "in", "codes", ":", "\n", "            ", "ret", "=", "ret", "+", "code", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.TextCodeTemplate": [[52, 66], ["unified_tokenizer.get_tokenizer", "isinstance", "unified_tokenizer.get_tokenizer.wrap_code", "templates.concat_codes", "numpy.concatenate", "unified_tokenizer.get_tokenizer.", "numpy.array"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.wrap_code", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.concat_codes"], ["", "", "def", "TextCodeTemplate", "(", "text", ",", "code", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "        ", "text_ids", "=", "[", "tokenizer", "[", "'[ROI1]'", "]", "]", "+", "tokenizer", "(", "text", ")", "\n", "", "else", ":", "\n", "        ", "text_ids", "=", "np", ".", "concatenate", "(", "\n", "(", "\n", "np", ".", "array", "(", "[", "tokenizer", "[", "'[ROI1]'", "]", "]", ")", ",", "\n", "text", ",", "\n", ")", ",", "\n", "axis", "=", "0", "\n", ")", "\n", "", "code", "=", "tokenizer", ".", "wrap_code", "(", "code", ")", "\n", "return", "concat_codes", "(", "text_ids", ",", "code", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.Code2CodeTemplate": [[67, 73], ["unified_tokenizer.get_tokenizer", "unified_tokenizer.get_tokenizer.wrap_code", "unified_tokenizer.get_tokenizer.wrap_code", "templates.concat_codes", "isinstance", "unified_tokenizer.get_tokenizer.parse_query"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.wrap_code", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.wrap_code", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.concat_codes", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.parse_query"], ["", "def", "Code2CodeTemplate", "(", "text", ",", "code0", ",", "code1", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "text_ids", "=", "tokenizer", ".", "parse_query", "(", "text", ")", "if", "isinstance", "(", "text", ",", "str", ")", "else", "text", "\n", "code0", "=", "tokenizer", ".", "wrap_code", "(", "code0", ")", "\n", "code1", "=", "tokenizer", ".", "wrap_code", "(", "code1", ",", "idx", "=", "2", ")", "\n", "return", "concat_codes", "(", "text_ids", ",", "code0", ",", "code1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.PureTextTemplate": [[74, 77], ["unified_tokenizer.get_tokenizer", "unified_tokenizer.get_tokenizer."], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer"], ["", "def", "PureTextTemplate", "(", "text", ")", ":", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "return", "tokenizer", "(", "text", ")", "+", "[", "tokenizer", "[", "'[SEP]'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder.__init__": [[35, 41], ["dict", "zip", "sp_tokenizer.Encoder.encoder.items", "range", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "bpe_merges", ")", ":", "\n", "        ", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "max_len", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder.bpe": [[42, 81], ["tuple", "sp_tokenizer.get_pairs", "min", "tuple", "len", "len", "sp_tokenizer.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "sp_tokenizer.Encoder.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.get_pairs", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder.encode": [[82, 84], ["sp_tokenizer.Encoder.encoder.get", "sp_tokenizer.Encoder.tokenize"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.tokenize"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "[", "self", ".", "encoder", ".", "get", "(", "token", ",", "1", ")", "for", "token", "in", "self", ".", "tokenize", "(", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder.decode": [[85, 88], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "text", "=", "''", ".", "join", "(", "[", "self", ".", "decoder", "[", "token", "]", "for", "token", "in", "tokens", "]", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder.tokenize": [[89, 93], ["bpe_tokens.extend", "sp_tokenizer.Encoder.bpe().split", "sp_tokenizer.Encoder.bpe"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder.bpe"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "text", ")", ".", "split", "(", "' '", ")", ")", "\n", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder.convert_tokens_to_ids": [[94, 96], ["sp_tokenizer.Encoder.encoder.get"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "[", "self", ".", "encoder", ".", "get", "(", "token", ",", "1", ")", "for", "token", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.__init__": [[99, 103], ["sentencepiece.SentencePieceProcessor", "sp_tokenizer.Encoder_SP.sp.Load", "sp_tokenizer.Encoder_SP.sp.vocab_size"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "self", ".", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp", ".", "Load", "(", "model_path", ")", "\n", "self", ".", "num_tokens", "=", "self", ".", "sp", ".", "vocab_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.encode": [[104, 109], ["sp_tokenizer.Encoder_SP.sp.EncodeAsIds"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"\n        text=\"....\"\n        \"\"\"", "\n", "return", "self", ".", "sp", ".", "EncodeAsIds", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.decode": [[110, 116], ["sp_tokenizer.Encoder_SP.sp.DecodeIds", "int"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.DecodeIds"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"\n        tokens=[x1,x2,...]\n        \"\"\"", "\n", "text", "=", "[", "int", "(", "token", ")", "for", "token", "in", "tokens", "]", "\n", "return", "self", ".", "sp", ".", "DecodeIds", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.tokenize": [[117, 119], ["sp_tokenizer.Encoder_SP.sp.EncodeAsPieces"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "self", ".", "sp", ".", "EncodeAsPieces", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.convert_tokens_to_ids": [[120, 122], ["sp_tokenizer.Encoder_SP.sp.PieceToId"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "[", "self", ".", "sp", ".", "PieceToId", "(", "token", ")", "for", "token", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.convert_token_to_id": [[123, 125], ["sp_tokenizer.Encoder_SP.sp.PieceToId"], "methods", ["None"], ["", "def", "convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "return", "self", ".", "sp", ".", "PieceToId", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.Encoder_SP.convert_id_to_token": [[126, 128], ["sp_tokenizer.Encoder_SP.sp.IdToPiece"], "methods", ["None"], ["", "def", "convert_id_to_token", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "sp", ".", "IdToPiece", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.get_pairs": [[25, 32], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.add"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.get_encoder": [[130, 146], ["os.path.split", "os.path.splitext", "sp_tokenizer.Encoder_SP", "sp_tokenizer.Encoder", "open", "json.load", "open", "f.read", "tuple", "merge_str.split", "f.read.split"], "function", ["None"], ["", "", "def", "get_encoder", "(", "encoder_file", ",", "bpe_file", ")", ":", "\n", "# \u4ee5\u4e0b\u662f\u4e3a\u4e86\u540c\u4e00\u4e2a\u51fd\u6570\u5165\u517c\u5bb9sentencepiece", "\n", "    ", "filepath", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "encoder_file", ")", "\n", "shotname", ",", "extension", "=", "os", ".", "path", ".", "splitext", "(", "filename", ")", "\n", "\n", "if", "(", "\".model\"", "==", "extension", ")", "and", "(", "bpe_file", "==", "\"\"", ")", ":", "\n", "        ", "return", "Encoder_SP", "(", "encoder_file", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "encoder_file", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "encoder", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "bpe_file", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "bpe_data", "=", "f", ".", "read", "(", ")", "\n", "", "bpe_merges", "=", "[", "tuple", "(", "merge_str", ".", "split", "(", ")", ")", "for", "merge_str", "in", "bpe_data", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "]", "\n", "return", "Encoder", "(", "\n", "encoder", "=", "encoder", ",", "\n", "bpe_merges", "=", "bpe_merges", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.from_pretrained": [[149, 151], ["sp_tokenizer.get_encoder"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.get_encoder"], ["", "", "def", "from_pretrained", "(", ")", ":", "\n", "    ", "return", "get_encoder", "(", "PRETRAINED_MODEL_FILE", ",", "\"\"", ")", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.__init__": [[24, 68], ["sp_tokenizer.from_pretrained", "len", "unified_tokenizer.FakeTokenizer", "vqvae_tokenizer.VQVAETokenizer"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.sp_tokenizer.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "img_tokenizer_path", ",", "device", ",", "img_tokenizer_num_tokens", "=", "None", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "if", "img_tokenizer_path", "is", "None", "and", "img_tokenizer_num_tokens", "is", "not", "None", ":", "\n", "# pretraining but only know the vocab size of VQVAE, which is developing fast", "\n", "            ", "self", ".", "img_tokenizer", "=", "FakeTokenizer", "(", "img_tokenizer_num_tokens", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_tokenizer", "=", "VQVAETokenizer", "(", "model_path", "=", "img_tokenizer_path", ",", "device", "=", "self", ".", "device", ")", "\n", "", "self", ".", "txt_tokenizer", "=", "from_pretrained", "(", ")", "\n", "self", ".", "num_tokens", "=", "self", ".", "img_tokenizer", ".", "num_tokens", "+", "self", ".", "txt_tokenizer", ".", "num_tokens", "\n", "self", ".", "raw_command_tokens", "=", "[", "\n", "(", "'[PAD]'", ",", "0", ")", ",", "\n", "(", "'[BOI1]'", ",", "1", ")", ",", "# Begin", "\n", "(", "'[BOI2]'", ",", "2", ")", ",", "\n", "(", "'[BOI3]'", ",", "3", ")", ",", "\n", "(", "'[EOI1]'", ",", "4", ")", ",", "# End", "\n", "(", "'[EOI2]'", ",", "5", ")", ",", "\n", "(", "'[EOI3]'", ",", "6", ")", ",", "\n", "(", "'[ROI1]'", ",", "7", ")", ",", "# Reference", "\n", "(", "'[ROI2]'", ",", "8", ")", ",", "\n", "(", "'[ROI3]'", ",", "9", ")", ",", "\n", "(", "'[SEP]'", ",", "10", ")", ",", "\n", "(", "'[MASK]'", ",", "11", ")", ",", "\n", "(", "'[CLS]'", ",", "12", ")", ",", "\n", "(", "'[ENC]'", ",", "13", ")", ",", "\n", "(", "'[TINY]'", ",", "14", ")", ",", "# 8 * 8", "\n", "(", "'[SMALL]'", ",", "15", ")", ",", "# 16 * 16", "\n", "(", "'[BASE]'", ",", "16", ")", ",", "# 32 * 32", "\n", "(", "'[BIG]'", ",", "17", ")", ",", "# 64 * 64", "\n", "(", "'[POS0]'", ",", "18", ")", ",", "# 58210", "\n", "(", "'[POS1]'", ",", "19", ")", ",", "\n", "(", "'[POS2]'", ",", "20", ")", ",", "\n", "(", "'[POS3]'", ",", "21", ")", ",", "\n", "(", "'[POS4]'", ",", "22", ")", ",", "\n", "(", "'[POS5]'", ",", "23", ")", ",", "\n", "(", "'[POS6]'", ",", "24", ")", ",", "\n", "(", "'[POS7]'", ",", "25", ")", ",", "\n", "(", "'[POS8]'", ",", "26", ")", "\n", "# Please leave the ``size tokens'' at the back of command tokens", "\n", "]", "\n", "self", ".", "command_tokens", "=", "{", "\n", "k", ":", "v", "+", "self", ".", "num_tokens", "\n", "for", "k", ",", "v", "in", "self", ".", "raw_command_tokens", "\n", "}", "\n", "self", ".", "num_tokens", "+=", "len", "(", "self", ".", "raw_command_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.__getitem__": [[69, 71], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "command_token", ")", ":", "\n", "        ", "return", "self", ".", "command_tokens", "[", "command_token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.__len__": [[72, 75], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"total number of tokens\"\"\"", "\n", "return", "self", ".", "num_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.__call__": [[76, 84], ["isinstance", "unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "unified_tokenizer.UnifiedTokenizer.img_tokenizer.EncodeAsIds", "len", "inputs.unsqueeze.unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "process_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"run preprocessing and encode inputs as Ids\n            CANNOT contain command tokens\"\"\"", "\n", "if", "isinstance", "(", "inputs", ",", "torch", ".", "Tensor", ")", ":", "# image", "\n", "            ", "if", "len", "(", "inputs", ".", "shape", ")", "==", "3", ":", "\n", "                ", "inputs", "=", "inputs", ".", "unsqueeze", "(", "0", ")", "\n", "", "return", "self", ".", "img_tokenizer", ".", "EncodeAsIds", "(", "inputs", ")", "\n", "", "return", "self", ".", "EncodeAsIds", "(", "inputs", ",", "process_fn", "=", "process_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds": [[85, 91], ["unified_tokenizer.UnifiedTokenizer.txt_tokenizer.encode", "process_fn"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "def", "EncodeAsIds", "(", "self", ",", "text", ",", "process_fn", "=", "None", ")", ":", "\n", "        ", "processed_text", "=", "text", "\n", "if", "process_fn", "is", "not", "None", ":", "\n", "            ", "processed_text", "=", "process_fn", "(", "processed_text", ")", "\n", "", "ids", "=", "self", ".", "txt_tokenizer", ".", "encode", "(", "processed_text", ")", "\n", "return", "[", "x", "+", "self", ".", "img_tokenizer", ".", "num_tokens", "for", "x", "in", "ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.DecodeIds": [[92, 124], ["len", "ret_imgs.append", "len", "ret.append", "print", "ret.append", "unified_tokenizer.UnifiedTokenizer.img_tokenizer.DecodeIds", "unified_tokenizer.UnifiedTokenizer.txt_tokenizer.decode", "len", "token.startswith", "ret_imgs.append", "len", "ret.append", "img_buffer.append", "txt_buffer.append", "len", "unified_tokenizer.UnifiedTokenizer.img_tokenizer.DecodeIds", "unified_tokenizer.UnifiedTokenizer.txt_tokenizer.decode", "len"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.DecodeIds", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.decode", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.DecodeIds", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.decode"], ["", "def", "DecodeIds", "(", "self", ",", "ids", ")", ":", "\n", "        ", "ret", ",", "img_buffer", ",", "txt_buffer", ",", "ret_imgs", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "try", ":", "\n", "            ", "for", "x", "in", "ids", ":", "\n", "                ", "if", "self", ".", "num_tokens", "-", "len", "(", "self", ".", "raw_command_tokens", ")", "<=", "x", ":", "\n", "# command tokens", "\n", "                    ", "token", "=", "self", ".", "raw_command_tokens", "[", "x", "-", "(", "self", ".", "num_tokens", "-", "len", "(", "self", ".", "raw_command_tokens", ")", ")", "]", "[", "0", "]", "\n", "if", "token", ".", "startswith", "(", "'[EOI'", ")", "and", "len", "(", "img_buffer", ")", ">", "0", ":", "\n", "# dump image", "\n", "                        ", "ret_imgs", ".", "append", "(", "self", ".", "img_tokenizer", ".", "DecodeIds", "(", "img_buffer", ")", ")", "\n", "img_buffer", "=", "[", "]", "\n", "", "if", "len", "(", "txt_buffer", ")", ">", "0", ":", "\n", "# dump text", "\n", "                        ", "ret", ".", "append", "(", "self", ".", "txt_tokenizer", ".", "decode", "(", "txt_buffer", ")", ")", "\n", "txt_buffer", "=", "[", "]", "\n", "", "ret", ".", "append", "(", "token", ")", "\n", "", "elif", "x", "<", "self", ".", "img_tokenizer", ".", "num_tokens", ":", "\n", "                    ", "img_buffer", ".", "append", "(", "x", ")", "\n", "", "else", ":", "\n", "                    ", "txt_buffer", ".", "append", "(", "x", "-", "self", ".", "img_tokenizer", ".", "num_tokens", ")", "\n", "\n", "", "", "if", "len", "(", "img_buffer", ")", ">", "0", ":", "\n", "# dump image", "\n", "                ", "ret_imgs", ".", "append", "(", "self", ".", "img_tokenizer", ".", "DecodeIds", "(", "img_buffer", ")", ")", "\n", "img_buffer", "=", "[", "]", "\n", "", "if", "len", "(", "txt_buffer", ")", ">", "0", ":", "\n", "# dump text", "\n", "                ", "ret", ".", "append", "(", "self", ".", "txt_tokenizer", ".", "decode", "(", "txt_buffer", ")", ")", "\n", "txt_buffer", "=", "[", "]", "\n", "", "", "except", "ValueError", ":", "\n", "            ", "print", "(", "'Value error in tokenization, skipping...'", ")", "\n", "", "return", "ret", ",", "ret_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.wrap_code": [[125, 153], ["vqvae_tokenizer.sqrt_int", "isinstance", "len", "isinstance", "numpy.concatenate", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ValueError", "numpy.array", "numpy.array", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.sqrt_int"], ["", "def", "wrap_code", "(", "self", ",", "code", ",", "idx", "=", "1", ")", ":", "\n", "        ", "s", "=", "sqrt_int", "(", "len", "(", "code", ")", ")", "\n", "prefix", "=", "{", "8", ":", "'[TINY]'", ",", "16", ":", "'[SMALL]'", ",", "32", ":", "'[BASE]'", ",", "64", ":", "'[BIG]'", "}", "[", "s", "]", "\n", "boi", "=", "{", "1", ":", "'[BOI1]'", ",", "2", ":", "'[BOI2]'", ",", "3", ":", "'[BOI3]'", "}", "[", "idx", "]", "\n", "eoi", "=", "{", "1", ":", "'[EOI1]'", ",", "2", ":", "'[EOI2]'", ",", "3", ":", "'[EOI3]'", "}", "[", "idx", "]", "\n", "\n", "if", "isinstance", "(", "code", ",", "list", ")", ":", "\n", "            ", "return", "[", "self", ".", "command_tokens", "[", "prefix", "]", ",", "self", ".", "command_tokens", "[", "boi", "]", "]", "+", "code", "+", "[", "self", ".", "command_tokens", "[", "eoi", "]", "]", "\n", "", "elif", "isinstance", "(", "code", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "\n", "(", "\n", "np", ".", "array", "(", "[", "self", ".", "command_tokens", "[", "prefix", "]", ",", "self", ".", "command_tokens", "[", "boi", "]", "]", ")", ",", "\n", "code", ",", "\n", "np", ".", "array", "(", "[", "self", ".", "command_tokens", "[", "eoi", "]", "]", ")", "\n", ")", ",", "\n", "axis", "=", "0", "\n", ")", "\n", "", "elif", "isinstance", "(", "code", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "\n", "(", "\n", "torch", ".", "tensor", "(", "[", "self", ".", "command_tokens", "[", "prefix", "]", ",", "self", ".", "command_tokens", "[", "boi", "]", "]", ")", ",", "\n", "code", ",", "\n", "np", ".", "array", "(", "[", "self", ".", "command_tokens", "[", "eoi", "]", "]", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.parse_query": [[154, 197], ["query.split", "len", "ret.extend", "part.startswith", "unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "len", "ret.extend", "ret.append", "ret.append", "int", "ret.extend", "part.startswith", "unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "len", "ret.extend", "int.split", "unified_tokenizer.UnifiedTokenizer.img_tokenizer.read_img", "unified_tokenizer.UnifiedTokenizer.img_tokenizer.EncodeAsIds", "img_codes[].tolist", "ret.extend", "text_buffer.append", "unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "len", "int"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.vqvae_tokenizer.VQVAETokenizer.read_img", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.UnifiedTokenizer.EncodeAsIds"], ["", "", "def", "parse_query", "(", "self", ",", "query", ",", "img_size", "=", "256", ")", ":", "\n", "        ", "text_buffer", "=", "[", "]", "\n", "ret", "=", "[", "]", "\n", "for", "part", "in", "query", ".", "split", "(", "' '", ")", ":", "\n", "            ", "if", "part", "in", "self", ".", "command_tokens", ":", "\n", "                ", "if", "len", "(", "text_buffer", ")", ">", "0", ":", "\n", "# dump text ids", "\n", "                    ", "ret", ".", "extend", "(", "self", ".", "EncodeAsIds", "(", "' '", ".", "join", "(", "text_buffer", ")", ")", ")", "\n", "text_buffer", "=", "[", "]", "\n", "", "if", "part", "==", "'[MASK]'", ":", "\n", "                    ", "ret", ".", "append", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "ret", ".", "append", "(", "self", ".", "command_tokens", "[", "part", "]", ")", "\n", "", "", "elif", "part", ".", "startswith", "(", "'[MASK]*'", ")", ":", "# special lang *N", "\n", "                ", "c", "=", "int", "(", "part", "[", "7", ":", "]", ")", "\n", "assert", "c", ">", "0", "\n", "if", "len", "(", "text_buffer", ")", ">", "0", ":", "\n", "# dump text ids", "\n", "                    ", "ret", ".", "extend", "(", "self", ".", "EncodeAsIds", "(", "' '", ".", "join", "(", "text_buffer", ")", ")", ")", "\n", "text_buffer", "=", "[", "]", "\n", "", "ret", ".", "extend", "(", "[", "-", "1", "]", "*", "c", ")", "\n", "", "elif", "part", ".", "startswith", "(", "'[Image'", ")", ":", "# [Image*N]path", "\n", "                ", "c", "=", "part", "[", "6", ":", "]", "\n", "assert", "len", "(", "c", ")", ">", "0", "\n", "num_codes", ",", "img_path", "=", "c", ".", "split", "(", "']'", ")", "\n", "if", "num_codes", "==", "''", ":", "\n", "                    ", "num_codes", "=", "1024", "\n", "", "else", ":", "\n", "                    ", "num_codes", "=", "int", "(", "num_codes", ")", "\n", "\n", "", "raw_img", "=", "self", ".", "img_tokenizer", ".", "read_img", "(", "img_path", ",", "img_size", "=", "img_size", ")", "\n", "img_codes", "=", "self", ".", "img_tokenizer", ".", "EncodeAsIds", "(", "raw_img", ")", "# [1, 32*32]", "\n", "img_codes", "[", "0", ",", "num_codes", ":", "]", "=", "-", "1", "\n", "img_codes", "=", "img_codes", "[", "0", "]", ".", "tolist", "(", ")", "\n", "ret", ".", "extend", "(", "img_codes", ")", "\n", "", "else", ":", "\n", "                ", "text_buffer", ".", "append", "(", "part", ")", "\n", "\n", "", "", "if", "len", "(", "text_buffer", ")", ">", "0", ":", "\n", "# dump text ids", "\n", "            ", "ret", ".", "extend", "(", "self", ".", "EncodeAsIds", "(", "' '", ".", "join", "(", "text_buffer", ")", ")", ")", "\n", "text_buffer", "=", "[", "]", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.FakeTokenizer.__init__": [[209, 211], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_tokens", ")", ":", "\n", "        ", "self", ".", "num_tokens", "=", "num_tokens", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.FakeTokenizer.__len__": [[211, 213], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_tokens", "", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer": [[198, 207], ["hasattr", "unified_tokenizer.UnifiedTokenizer", "torch.cuda.current_device", "torch.cuda.current_device"], "function", ["None"], ["", "", "def", "get_tokenizer", "(", "args", "=", "None", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "get_tokenizer", ",", "'tokenizer'", ")", ":", "\n", "# the first time to load the tokenizer, specify img_tokenizer_path", "\n", "        ", "get_tokenizer", ".", "tokenizer", "=", "UnifiedTokenizer", "(", "\n", "args", ".", "img_tokenizer_path", ",", "\n", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", ",", "\n", "img_tokenizer_num_tokens", "=", "args", ".", "img_tokenizer_num_tokens", "\n", ")", "\n", "", "return", "get_tokenizer", ".", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.LMDBDataset.__init__": [[35, 50], ["lmdb.open", "IOError", "torchvision.datasets.LMDBDataset.env.begin", "int", "txn.get().decode", "txn.get"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.decode"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "process_fn", ")", ":", "\n", "        ", "self", ".", "env", "=", "lmdb", ".", "open", "(", "\n", "path", ",", "\n", "max_readers", "=", "32", ",", "\n", "readonly", "=", "True", ",", "\n", "lock", "=", "False", ",", "\n", "readahead", "=", "False", ",", "\n", "meminit", "=", "False", ",", "\n", ")", "\n", "self", ".", "process_fn", "=", "process_fn", "\n", "if", "not", "self", ".", "env", ":", "\n", "            ", "raise", "IOError", "(", "'Cannot open lmdb dataset'", ",", "path", ")", "\n", "\n", "", "with", "self", ".", "env", ".", "begin", "(", "write", "=", "False", ")", "as", "txn", ":", "\n", "            ", "self", ".", "length", "=", "int", "(", "txn", ".", "get", "(", "'length'", ".", "encode", "(", "'utf-8'", ")", ")", ".", "decode", "(", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.LMDBDataset.__len__": [[51, 53], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.LMDBDataset.__getitem__": [[54, 62], ["torchvision.datasets.LMDBDataset.env.begin", "str().encode", "pickle.loads", "torchvision.datasets.LMDBDataset.process_fn", "txn.get", "str"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "with", "self", ".", "env", ".", "begin", "(", "write", "=", "False", ")", "as", "txn", ":", "\n", "            ", "key", "=", "str", "(", "idx", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "row", "=", "pickle", ".", "loads", "(", "txn", ".", "get", "(", "key", ")", ")", "\n", "\n", "return", "self", ".", "process_fn", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.BinaryDataset.__init__": [[64, 76], ["numpy.dtype", "numpy.fromfile().reshape", "numpy.memmap", "open", "fid.seek", "numpy.fromfile", "fid.tell"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "process_fn", ",", "length_per_sample", "=", "64", "+", "1024", ",", "dtype", "=", "'int32'", ",", "preload", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "length_per_sample", "is", "not", "None", "\n", "self", ".", "length_per_sample", "=", "length_per_sample", "\n", "self", ".", "dtype", "=", "np", ".", "dtype", "(", "dtype", ")", "\n", "self", ".", "process_fn", "=", "process_fn", "\n", "if", "preload", ":", "\n", "            ", "self", ".", "bin", "=", "np", ".", "fromfile", "(", "path", ",", "dtype", "=", "self", ".", "dtype", ")", ".", "reshape", "(", "-", "1", ",", "length_per_sample", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "fid", ":", "\n", "                ", "nbytes", "=", "fid", ".", "seek", "(", "0", ",", "2", ")", "\n", "flen", "=", "fid", ".", "tell", "(", ")", "//", "self", ".", "dtype", ".", "itemsize", "\n", "", "self", ".", "bin", "=", "np", ".", "memmap", "(", "path", ",", "dtype", "=", "self", ".", "dtype", ",", "shape", "=", "(", "flen", "//", "length_per_sample", ",", "length_per_sample", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.BinaryDataset.__len__": [[77, 79], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "bin", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.BinaryDataset.__getitem__": [[80, 82], ["torchvision.datasets.BinaryDataset.process_fn"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "process_fn", "(", "self", ".", "bin", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.datasets.get_dataset_by_type": [[83, 131], ["unified_tokenizer.get_tokenizer", "DS_CLASS", "len", "datasets.get_dataset_by_type.pad_to_len"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer"], ["", "", "def", "get_dataset_by_type", "(", "dataset_type", ",", "path", ":", "str", ",", "args", ",", "DS_CLASS", "=", "LMDBDataset", ")", ":", "\n", "\n", "    ", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "if", "args", ".", "finetune", "and", "args", ".", "max_position_embeddings_finetune", ">", "args", ".", "max_position_embeddings", ":", "\n", "        ", "ml", "=", "args", ".", "max_position_embeddings_finetune", "\n", "", "else", ":", "\n", "        ", "ml", "=", "args", ".", "max_position_embeddings", "\n", "\n", "", "def", "pad_to_len", "(", "ret", ")", ":", "\n", "\n", "        ", "if", "len", "(", "ret", ")", "<", "ml", ":", "# pad", "\n", "            ", "return", "np", ".", "concatenate", "(", "(", "ret", ",", "\n", "np", ".", "array", "(", "[", "tokenizer", "[", "'[PAD]'", "]", "]", "*", "(", "ml", "-", "len", "(", "ret", ")", ")", ")", ")", ",", "\n", "axis", "=", "0", ")", ",", "len", "(", "ret", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "ret", ")", ">", "ml", ":", "\n", "                ", "logger", ".", "warning", "(", "'Out of max len, truncated.'", ")", "\n", "", "return", "ret", "[", ":", "ml", "]", ",", "ml", "\n", "\n", "", "", "if", "dataset_type", "==", "'TokenizedDataset'", ":", "\n", "# already tokenized when saved", "\n", "        ", "def", "process_fn", "(", "row", ")", ":", "\n", "            ", "ret", ",", "attention_mask_sep", "=", "pad_to_len", "(", "row", ".", "flatten", "(", ")", ")", "\n", "return", "{", "'text'", ":", "ret", ",", "\n", "'loss_mask'", ":", "np", ".", "array", "(", "[", "1", "]", "*", "attention_mask_sep", "+", "[", "0", "]", "*", "(", "len", "(", "ret", ")", "-", "attention_mask_sep", ")", ")", "\n", "}", "\n", "\n", "", "", "elif", "dataset_type", "==", "'TextCodeDataset'", ":", "\n", "        ", "def", "process_fn", "(", "row", ")", ":", "\n", "            ", "text", ",", "code", "=", "row", "[", "0", "]", ",", "row", "[", "1", "]", ".", "flatten", "(", ")", "\n", "ret", "=", "TextCodeTemplate", "(", "text", ",", "code", ")", "\n", "ret", ",", "attention_mask_sep", "=", "pad_to_len", "(", "ret", ")", "\n", "return", "{", "'text'", ":", "ret", ",", "\n", "'loss_mask'", ":", "np", ".", "array", "(", "[", "1", "]", "*", "attention_mask_sep", "+", "[", "0", "]", "*", "(", "len", "(", "ret", ")", "-", "attention_mask_sep", ")", ")", "\n", "}", "\n", "\n", "", "", "elif", "dataset_type", "==", "'CompactBinaryDataset'", ":", "\n", "        ", "DS_CLASS", "=", "BinaryDataset", "\n", "def", "process_fn", "(", "row", ")", ":", "\n", "            ", "text", ",", "code", "=", "row", "[", ":", "64", "]", ".", "astype", "(", "np", ".", "int64", ")", ",", "row", "[", "64", ":", "]", ".", "astype", "(", "np", ".", "int64", ")", "# must 64 + 1024", "\n", "text", "=", "text", "[", "text", ">", "-", "1", "]", "\n", "ret", "=", "TextCodeTemplate", "(", "text", ",", "code", ")", "\n", "ret", ",", "attention_mask_sep", "=", "pad_to_len", "(", "ret", ")", "\n", "return", "{", "'text'", ":", "ret", ",", "\n", "'loss_mask'", ":", "np", ".", "array", "(", "[", "1", "]", "*", "attention_mask_sep", "+", "[", "0", "]", "*", "(", "len", "(", "ret", ")", "-", "attention_mask_sep", ")", ")", "\n", "}", "\n", "\n", "", "", "return", "DS_CLASS", "(", "path", ",", "process_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.PyTorchDistributedDataParallel.state_dict": [[27, 30], ["distributed.PyTorchDistributedDataParallel.module.state_dict"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict"], ["    ", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "sd", "=", "self", ".", "module", ".", "state_dict", "(", "destination", ",", "prefix", ",", "keep_vars", ")", "\n", "return", "sd", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.PyTorchDistributedDataParallel.load_state_dict": [[31, 33], ["distributed.PyTorchDistributedDataParallel.module.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.__init__": [[37, 86], ["torch.nn.modules.Module.__init__", "mpu.get_data_parallel_group", "mpu.get_model_parallel_rank", "distributed.DistributedDataParallel.module.parameters", "list", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "distributed.DistributedDataParallel.module.parameters", "torch.broadcast", "torch.broadcast", "distributed.DistributedDataParallel.module.named_parameters", "torch.autograd.Variable._execution_engine.queue_callback", "torch.autograd.Variable._execution_engine.queue_callback", "torch._utils._flatten_dense_tensors", "torch._utils._flatten_dense_tensors", "torch.all_reduce", "torch.all_reduce", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "zip", "param.data.type", "buckets[].append", "print", "coalesced.float.float.float", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch._utils._unflatten_dense_tensors", "torch._utils._unflatten_dense_tensors", "buf.copy_"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size"], ["    ", "def", "__init__", "(", "self", ",", "module", ")", ":", "\n", "        ", "super", "(", "DistributedDataParallel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "warn_on_half", "=", "True", "if", "dist", ".", "_backend", "==", "dist", ".", "dist_backend", ".", "GLOO", "else", "False", "\n", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "data_parallel_group", "=", "mpu", ".", "get_data_parallel_group", "(", ")", "\n", "src_rank", "=", "mpu", ".", "get_model_parallel_rank", "(", ")", "\n", "for", "p", "in", "self", ".", "module", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "p", ")", ":", "\n", "                ", "dist", ".", "broadcast", "(", "p", ",", "src_rank", ",", "group", "=", "self", ".", "data_parallel_group", ")", "\n", "\n", "", "", "def", "allreduce_params", "(", "reduce_after", "=", "True", ",", "no_scale", "=", "False", ",", "fp32_allreduce", "=", "False", ")", ":", "\n", "            ", "if", "(", "self", ".", "needs_reduction", ")", ":", "\n", "                ", "self", ".", "needs_reduction", "=", "False", "\n", "buckets", "=", "{", "}", "\n", "for", "name", ",", "param", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "param", ".", "requires_grad", "and", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "tp", "=", "(", "param", ".", "data", ".", "type", "(", ")", ")", "\n", "if", "tp", "not", "in", "buckets", ":", "\n", "                            ", "buckets", "[", "tp", "]", "=", "[", "]", "\n", "", "buckets", "[", "tp", "]", ".", "append", "(", "param", ")", "\n", "", "", "if", "self", ".", "warn_on_half", ":", "\n", "                    ", "if", "torch", ".", "cuda", ".", "HalfTensor", "in", "buckets", ":", "\n", "                        ", "print", "(", "\"WARNING: gloo dist backend for half parameters may be extremely slow.\"", "+", "\n", "\" It is recommended to use the NCCL backend in this case.\"", ")", "\n", "self", ".", "warn_on_half", "=", "False", "\n", "", "", "for", "tp", "in", "buckets", ":", "\n", "                    ", "bucket", "=", "buckets", "[", "tp", "]", "\n", "grads", "=", "[", "param", ".", "grad", ".", "data", "for", "param", "in", "bucket", "]", "\n", "coalesced", "=", "_flatten_dense_tensors", "(", "grads", ")", "\n", "if", "fp32_allreduce", ":", "\n", "                        ", "coalesced", "=", "coalesced", ".", "float", "(", ")", "\n", "", "if", "not", "no_scale", "and", "not", "reduce_after", ":", "\n", "                        ", "coalesced", "/=", "dist", ".", "get_world_size", "(", "group", "=", "self", ".", "data_parallel_group", ")", "\n", "", "dist", ".", "all_reduce", "(", "coalesced", ",", "group", "=", "self", ".", "data_parallel_group", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "if", "not", "no_scale", "and", "reduce_after", ":", "\n", "                        ", "coalesced", "/=", "dist", ".", "get_world_size", "(", "group", "=", "self", ".", "data_parallel_group", ")", "\n", "", "for", "buf", ",", "synced", "in", "zip", "(", "grads", ",", "_unflatten_dense_tensors", "(", "coalesced", ",", "grads", ")", ")", ":", "\n", "                        ", "buf", ".", "copy_", "(", "synced", ")", "\n", "", "", "", "", "self", ".", "hook_handles", "=", "[", "]", "\n", "self", ".", "hooks", "=", "[", "]", "\n", "for", "param", "in", "list", "(", "self", ".", "module", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "def", "allreduce_hook", "(", "*", "unused", ")", ":", "\n", "                ", "Variable", ".", "_execution_engine", ".", "queue_callback", "(", "allreduce_params", ")", "\n", "#    handle = param.register_hook(allreduce_hook)", "\n", "#self.hooks.append(allreduce_hook)", "\n", "#self.hook_handles.append(handle)", "\n", "", "", "self", ".", "allreduce_params", "=", "allreduce_params", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.forward": [[87, 90], ["distributed.DistributedDataParallel.module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "needs_reduction", "=", "True", "\n", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict": [[91, 99], ["distributed.DistributedDataParallel.module.state_dict"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.state_dict"], ["", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "#[h.remove() for h in self.hook_handles]", "\n", "        ", "sd", "=", "self", ".", "module", ".", "state_dict", "(", "destination", ",", "prefix", ",", "keep_vars", ")", "\n", "# for handle, hook in zip(self.hook_handles, self.hooks):", "\n", "#     d = handle.hooks_dict_ref()", "\n", "#     d[handle.id] = hook", "\n", "\n", "return", "sd", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict": [[100, 102], ["distributed.DistributedDataParallel.module.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.model.distributed.DistributedDataParallel.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.gpt2_modeling.GPT2Model.__init__": [[62, 104], ["super().__init__", "gpt2_modeling.init_method_normal", "mpu.VocabParallelEmbedding", "mpu.GPT2ParallelTransformer"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.model.gpt2_modeling.init_method_normal"], ["def", "__init__", "(", "self", ",", "\n", "num_layers", ",", "\n", "vocab_size", ",", "\n", "hidden_size", ",", "\n", "num_attention_heads", ",", "\n", "embedding_dropout_prob", ",", "\n", "attention_dropout_prob", ",", "\n", "output_dropout_prob", ",", "\n", "max_sequence_length", ",", "\n", "max_memory_length", ",", "\n", "checkpoint_activations", ",", "\n", "checkpoint_num_layers", "=", "1", ",", "\n", "parallel_output", "=", "True", ",", "\n", "query_window", "=", "128", ",", "\n", "key_window_times", "=", "6", ",", "\n", "num_pivot", "=", "768", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "GPT2Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "parallel_output", "=", "parallel_output", "\n", "\n", "init_method", "=", "init_method_normal", "(", "std", "=", "0.02", ")", "\n", "\n", "# Word embeddings (parallel).", "\n", "self", ".", "word_embeddings", "=", "mpu", ".", "VocabParallelEmbedding", "(", "\n", "vocab_size", ",", "hidden_size", ",", "init_method", "=", "init_method", ")", "\n", "\n", "# Transformer", "\n", "self", ".", "transformer", "=", "mpu", ".", "GPT2ParallelTransformer", "(", "num_layers", ",", "\n", "hidden_size", ",", "\n", "num_attention_heads", ",", "\n", "max_sequence_length", ",", "\n", "max_memory_length", ",", "\n", "embedding_dropout_prob", ",", "\n", "attention_dropout_prob", ",", "\n", "output_dropout_prob", ",", "\n", "checkpoint_activations", ",", "\n", "checkpoint_num_layers", ",", "\n", "query_window", "=", "query_window", ",", "\n", "key_window_times", "=", "key_window_times", ",", "\n", "num_pivot", "=", "num_pivot", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.gpt2_modeling.GPT2Model.forward": [[106, 124], ["gpt2_modeling.GPT2Model.word_embeddings", "gpt2_modeling.GPT2Model.transformer", "mpu.copy_to_model_parallel_region", "torch.linear", "torch.linear", "mpu.gather_from_model_parallel_region"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.copy_to_model_parallel_region", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.gather_from_model_parallel_region"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", ",", "attention_mask", ",", "txt_indices_bool", ",", "img_indices_bool", ",", "is_sparse", ",", "*", "mems", ")", ":", "\n", "# Embeddings.", "\n", "        ", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "embeddings", "=", "words_embeddings", "\n", "\n", "# Transformer.", "\n", "transformer_output", "=", "self", ".", "transformer", "(", "embeddings", ",", "position_ids", ",", "attention_mask", ",", "txt_indices_bool", ",", "img_indices_bool", ",", "is_sparse", ",", "*", "mems", ")", "\n", "logits", ",", "*", "hidden_layers", "=", "transformer_output", "\n", "# Parallel logits.", "\n", "logits_parallel", "=", "mpu", ".", "copy_to_model_parallel_region", "(", "\n", "logits", ")", "\n", "logits_parallel", "=", "F", ".", "linear", "(", "logits_parallel", ",", "\n", "self", ".", "word_embeddings", ".", "weight", ")", "\n", "\n", "if", "self", ".", "parallel_output", ":", "\n", "            ", "return", "(", "logits_parallel", ",", "*", "hidden_layers", ")", "\n", "\n", "", "return", "(", "mpu", ".", "gather_from_model_parallel_region", "(", "logits_parallel", ")", ",", "*", "hidden_layers", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.model.gpt2_modeling.init_method_normal": [[24, 33], ["torch.nn.init.normal_", "torch.nn.init.normal_"], "function", ["None"], ["def", "init_method_normal", "(", "std", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Init method based on normal distribution.\n\n    This is only used for embeddings. The transformer has its\n    own initializer.\n    \"\"\"", "\n", "def", "init_", "(", "tensor", ")", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "tensor", ",", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "", "return", "init_", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.model.gpt2_modeling.gpt2_get_params_for_weight_decay_optimization": [[35, 53], ["module.modules", "isinstance", "no_weight_decay_params[].extend", "weight_decay_params[].extend", "no_weight_decay_params[].extend", "list", "list", "list", "module_._parameters.values", "module_._parameters.items", "module_._parameters.items"], "function", ["None"], ["", "def", "gpt2_get_params_for_weight_decay_optimization", "(", "module", ")", ":", "\n", "\n", "    ", "weight_decay_params", "=", "{", "'params'", ":", "[", "]", "}", "\n", "no_weight_decay_params", "=", "{", "'params'", ":", "[", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "for", "module_", "in", "module", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "module_", ",", "(", "mpu", ".", "LayerNorm", ",", "torch", ".", "nn", ".", "LayerNorm", ")", ")", ":", "\n", "            ", "no_weight_decay_params", "[", "'params'", "]", ".", "extend", "(", "\n", "[", "p", "for", "p", "in", "list", "(", "module_", ".", "_parameters", ".", "values", "(", ")", ")", "\n", "if", "p", "is", "not", "None", "]", ")", "\n", "", "else", ":", "\n", "            ", "weight_decay_params", "[", "'params'", "]", ".", "extend", "(", "\n", "[", "p", "for", "n", ",", "p", "in", "list", "(", "module_", ".", "_parameters", ".", "items", "(", ")", ")", "\n", "if", "p", "is", "not", "None", "and", "n", "!=", "'bias'", "]", ")", "\n", "no_weight_decay_params", "[", "'params'", "]", ".", "extend", "(", "\n", "[", "p", "for", "n", ",", "p", "in", "list", "(", "module_", ".", "_parameters", ".", "items", "(", ")", ")", "\n", "if", "p", "is", "not", "None", "and", "n", "==", "'bias'", "]", ")", "\n", "\n", "", "", "return", "weight_decay_params", ",", "no_weight_decay_params", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.preprocess_text_jsonformat_data.extract_code": [[26, 47], ["lmdb.open", "print", "lmdb.open.begin", "txn.put", "tqdm.tqdm", "str().encode", "open", "print", "range", "pretokenized_data.make_cut_text_batch", "ujson.load", "len", "txn.put", "str", "str().encode", "pickle.dumps", "str"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode", "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_cut_text_batch", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["def", "extract_code", "(", "datasets", ",", "name", ",", "seq_len", ")", ":", "\n", "    ", "'''\n        datasets: [json_name1, json_name2, ...]\n    '''", "\n", "index", "=", "0", "\n", "map_size", "=", "1024", "*", "1024", "*", "1024", "*", "1024", "\n", "lmdb_env", "=", "lmdb", ".", "open", "(", "f'/root/mnt/lmdb/{name}'", ",", "map_size", "=", "map_size", ",", "writemap", "=", "True", ")", "\n", "with", "lmdb_env", ".", "begin", "(", "write", "=", "True", ")", "as", "txn", ":", "\n", "        ", "for", "dataset", "in", "datasets", ":", "\n", "            ", "with", "open", "(", "dataset", ",", "'r'", ")", "as", "fin", ":", "\n", "                ", "print", "(", "f'Loading {dataset}...'", ")", "\n", "raw_json", "=", "json", ".", "load", "(", "fin", ")", "[", "\"RECORDS\"", "]", "\n", "", "bs", "=", "512", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "raw_json", ")", ",", "bs", ")", ")", ":", "\n", "                ", "txts", "=", "[", "t", "[", "\"content\"", "]", "for", "t", "in", "raw_json", "[", "i", ":", "i", "+", "bs", "]", "]", "\n", "txts", "=", "make_cut_text_batch", "(", "txts", ",", "seq_len", ")", "\n", "for", "code", "in", "txts", ":", "\n", "                    ", "txn", ".", "put", "(", "str", "(", "index", ")", ".", "encode", "(", "'utf-8'", ")", ",", "pickle", ".", "dumps", "(", "code", ")", ")", "\n", "index", "+=", "1", "\n", "", "", "", "txn", ".", "put", "(", "'length'", ".", "encode", "(", "'utf-8'", ")", ",", "str", "(", "index", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "print", "(", "f'/root/mnt/lmdb/{name}, length={index}'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_super_resolution_batch": [[89, 141], ["data_utils.get_tokenizer", "list", "random.choices", "torch.stack", "torch.stack", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "img2code().cpu().numpy", "img2code().cpu().numpy", "range", "zip", "range", "len", "range", "range", "range", "img2code().cpu", "img2code().cpu", "ret.append", "data_utils.get_tokenizer.", "data_utils.concat_codes", "img2code", "img2code"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.concat_codes", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.img2code", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.img2code"], ["", "def", "make_super_resolution_batch", "(", "model", ",", "txts", ",", "imgs", ",", "img_size", "=", "512", ",", "sampling_num", "=", "4", ")", ":", "\n", "    ", "'''\n        [text...small_img...base_img]\n    '''", "\n", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "t0", ",", "t1", "=", "img_size", "//", "4", ",", "img_size", "//", "2", "\n", "if", "img_size", "==", "512", ":", "\n", "        ", "size_tk", "=", "tokenizer", "[", "'[BASE]'", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "pw", "=", "[", "0", ",", "t0", ",", "t1", "]", "*", "3", "\n", "ph", "=", "[", "0", ",", "0", ",", "0", ",", "t0", ",", "t0", ",", "t0", ",", "t1", ",", "t1", ",", "t1", "]", "\n", "ptk", "=", "[", "[", "tokenizer", "[", "'[EOI1]'", "]", ",", "tokenizer", "[", "'[ROI2]'", "]", ",", "tokenizer", "[", "f'[POS{i}]'", "]", ",", "size_tk", ",", "tokenizer", "[", "'[BOI2]'", "]", "]", "\n", "for", "i", "in", "range", "(", "9", ")", "\n", "]", "\n", "pos", "=", "list", "(", "zip", "(", "ptk", ",", "ph", ",", "pw", ")", ")", "\n", "weights", "=", "[", "1", "]", "*", "9", "\n", "\n", "\n", "s", "=", "imgs", ".", "shape", "[", "-", "1", "]", "\n", "assert", "s", "==", "imgs", ".", "shape", "[", "-", "2", "]", "==", "img_size", "\n", "# Crop img_size/2 * img_size/2 patch", "\n", "selected_poses", "=", "random", ".", "choices", "(", "range", "(", "9", ")", ",", "weights", "=", "weights", ",", "k", "=", "sampling_num", ")", "\n", "pos", "=", "pos", "\n", "patches", "=", "[", "\n", "imgs", "[", "i", ",", ":", ",", "pos", "[", "p", "]", "[", "1", "]", ":", "pos", "[", "p", "]", "[", "1", "]", "+", "t1", ",", "pos", "[", "p", "]", "[", "2", "]", ":", "pos", "[", "p", "]", "[", "2", "]", "+", "t1", "]", "\n", "for", "i", "in", "range", "(", "imgs", ".", "shape", "[", "0", "]", ")", "\n", "for", "p", "in", "selected_poses", "\n", "]", "\n", "patch_prefix", "=", "[", "\n", "pos", "[", "p", "]", "[", "0", "]", "\n", "for", "p", "in", "selected_poses", "\n", "]", "*", "imgs", ".", "shape", "[", "0", "]", "\n", "patches", "=", "torch", ".", "stack", "(", "patches", ")", "\n", "overviews", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "imgs", ",", "size", "=", "(", "t1", ",", "t1", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "codes_patches", "=", "img2code", "(", "model", ",", "patches", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "codes_overviews", "=", "img2code", "(", "model", ",", "overviews", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "txts", ")", ")", ":", "\n", "        ", "code_text", "=", "[", "tokenizer", "[", "'[ROI1]'", "]", "]", "+", "tokenizer", "(", "txts", "[", "i", "]", ")", "+", "[", "size_tk", ",", "tokenizer", "[", "'[BOI1]'", "]", "]", "\n", "for", "j", "in", "range", "(", "sampling_num", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "concat_codes", "(", "code_text", ",", "\n", "codes_overviews", "[", "i", "]", ",", "\n", "patch_prefix", "[", "i", "*", "sampling_num", "+", "j", "]", ",", "\n", "codes_patches", "[", "i", "*", "sampling_num", "+", "j", "]", ",", "\n", "[", "tokenizer", "[", "'[EOI2]'", "]", "]", "\n", ")", "\n", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_text_image_batch": [[142, 154], ["data_utils.get_tokenizer", "img2code().cpu().numpy", "range", "len", "ret.append", "img2code().cpu", "TextCodeTemplate", "img2code"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.unified_tokenizer.get_tokenizer", "home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.TextCodeTemplate", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.img2code"], ["", "def", "make_text_image_batch", "(", "model", ",", "txts", ",", "imgs", ")", ":", "\n", "    ", "from", "data_utils", "import", "TextCodeTemplate", "\n", "s", "=", "imgs", ".", "shape", "[", "-", "1", "]", "\n", "assert", "s", "==", "imgs", ".", "shape", "[", "-", "2", "]", "==", "256", "\n", "tokenizer", "=", "get_tokenizer", "(", ")", "\n", "codes", "=", "img2code", "(", "model", ",", "imgs", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "txts", ")", ")", ":", "\n", "        ", "ret", ".", "append", "(", "\n", "TextCodeTemplate", "(", "txts", "[", "i", "]", ",", "codes", "[", "i", "]", ")", "\n", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_tuple_text_image_batch": [[155, 165], ["img2code().cpu().numpy", "range", "len", "ret.append", "img2code().cpu", "img2code"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.img2code"], ["", "def", "make_tuple_text_image_batch", "(", "model", ",", "txts", ",", "imgs", ")", ":", "\n", "    ", "s", "=", "imgs", ".", "shape", "[", "-", "1", "]", "\n", "assert", "s", "==", "imgs", ".", "shape", "[", "-", "2", "]", "==", "256", "\n", "codes", "=", "img2code", "(", "model", ",", "imgs", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "txts", ")", ")", ":", "\n", "        ", "ret", ".", "append", "(", "\n", "(", "txts", "[", "i", "]", ",", "codes", "[", "i", "]", ")", "\n", ")", "\n", "", "return", "codes", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_cut_text_batch": [[167, 177], ["numpy.array", "list", "itertools.chain", "range", "len", "PureTextTemplate"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.data_utils.templates.PureTextTemplate"], ["def", "make_cut_text_batch", "(", "txts", ",", "seq_len", ")", ":", "\n", "    ", "from", "data_utils", "import", "PureTextTemplate", "\n", "tmp_list", "=", "np", ".", "array", "(", "list", "(", "\n", "itertools", ".", "chain", "(", "*", "(", "PureTextTemplate", "(", "txt", ")", "for", "txt", "in", "txts", ")", ")", "\n", ")", ")", "\n", "ret", "=", "[", "\n", "tmp_list", "[", "en", "-", "seq_len", ":", "en", "]", "\n", "for", "en", "in", "range", "(", "seq_len", ",", "len", "(", "tmp_list", ")", ",", "seq_len", ")", "\n", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.preprocess_text_image_data.extract_code": [[28, 65], ["torch.no_grad", "torch.no_grad", "lmdb.open", "print", "lmdb.open.begin", "txn.put", "torch.utils.data.DataLoader", "print", "tqdm.tqdm", "str().encode", "enumerate", "torch.stack", "torch.stack", "imgs.to.to", "str", "text_dict.__contains__", "imgs.to.append", "filenames.numpy.append", "print", "filenames.numpy.numpy", "pretokenized_data.make_text_image_batch", "pretokenized_data.make_tuple_text_image_batch", "txn.put", "print", "str().encode", "pickle.dumps", "str"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode", "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_text_image_batch", "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_tuple_text_image_batch", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "extract_code", "(", "model", ",", "datasets", ",", "text_dict", ",", "name", ",", "device", ",", "txt_type", ")", ":", "\n", "    ", "index", "=", "0", "\n", "map_size", "=", "1024", "*", "1024", "*", "1024", "*", "1024", "\n", "lmdb_env", "=", "lmdb", ".", "open", "(", "f'/root/mnt/lmdb/{name}'", ",", "map_size", "=", "map_size", ",", "writemap", "=", "True", ")", "\n", "print", "(", "f'/root/mnt/lmdb/{name}'", ")", "\n", "with", "lmdb_env", ".", "begin", "(", "write", "=", "True", ")", "as", "txn", ":", "\n", "        ", "for", "dataset", "in", "datasets", ":", "\n", "            ", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "128", ",", "shuffle", "=", "False", ",", "num_workers", "=", "1", ")", "\n", "print", "(", "dataset", ")", "\n", "pbar", "=", "tqdm", "(", "loader", ")", "\n", "for", "raw_imgs", ",", "raw_filenames", "in", "pbar", ":", "\n", "                ", "imgs", "=", "[", "]", "\n", "filenames", "=", "[", "]", "\n", "for", "i", ",", "filename", "in", "enumerate", "(", "raw_filenames", ")", ":", "\n", "                    ", "if", "filename", "!=", "\"not_a_image\"", "and", "text_dict", ".", "__contains__", "(", "filename", ")", ":", "\n", "                        ", "imgs", ".", "append", "(", "raw_imgs", "[", "i", "]", ")", "\n", "filenames", ".", "append", "(", "filename", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"warning: deleted damaged image\"", ")", "\n", "", "", "imgs", "=", "torch", ".", "stack", "(", "imgs", ")", "\n", "imgs", "=", "imgs", ".", "to", "(", "device", ")", "\n", "try", ":", "\n", "                    ", "if", "txt_type", "==", "\"h5\"", ":", "\n", "                        ", "filenames", "=", "filenames", ".", "numpy", "(", ")", "\n", "", "txts", "=", "[", "text_dict", "[", "filename", "]", "for", "filename", "in", "filenames", "]", "\n", "if", "txt_type", "!=", "\"h5\"", ":", "\n", "                        ", "codes", "=", "make_text_image_batch", "(", "model", ",", "txts", ",", "imgs", ")", "\n", "", "else", ":", "\n", "                        ", "codes", "=", "make_tuple_text_image_batch", "(", "model", ",", "txts", ",", "imgs", ")", "\n", "", "for", "code", "in", "codes", ":", "\n", "                        ", "txn", ".", "put", "(", "str", "(", "index", ")", ".", "encode", "(", "'utf-8'", ")", ",", "pickle", ".", "dumps", "(", "code", ")", ")", "\n", "index", "+=", "1", "\n", "", "", "except", "KeyError", ":", "\n", "                    ", "print", "(", "\"warning: KeyError. The text cannot be find\"", ")", "\n", "pass", "\n", "", "", "", "txn", ".", "put", "(", "'length'", ".", "encode", "(", "'utf-8'", ")", ",", "str", "(", "index", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.preprocess_text_image_data.extract_code_super_resolution_patches": [[67, 104], ["torch.no_grad", "torch.no_grad", "lmdb.open", "print", "lmdb.open.begin", "txn.put", "torch.utils.data.DataLoader", "print", "tqdm.tqdm", "str().encode", "enumerate", "torch.stack", "torch.stack", "imgs.to.to", "str", "text_dict.__contains__", "imgs.to.append", "filenames.numpy.append", "print", "filenames.numpy.numpy", "pretokenized_data.make_super_resolution_batch", "pretokenized_data.make_tuple_text_image_batch", "txn.put", "print", "str().encode", "pickle.dumps", "str"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode", "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_super_resolution_batch", "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.pretokenized_data.make_tuple_text_image_batch", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "extract_code_super_resolution_patches", "(", "model", ",", "datasets", ",", "text_dict", ",", "name", ",", "device", ",", "txt_type", ")", ":", "\n", "    ", "index", "=", "0", "\n", "map_size", "=", "1024", "*", "1024", "*", "1024", "*", "1024", "\n", "lmdb_env", "=", "lmdb", ".", "open", "(", "f'/root/mnt/lmdb/{name}_super_resolution'", ",", "map_size", "=", "map_size", ",", "writemap", "=", "True", ")", "\n", "print", "(", "f'/root/mnt/lmdb/{name}_super_resolution'", ")", "\n", "with", "lmdb_env", ".", "begin", "(", "write", "=", "True", ")", "as", "txn", ":", "\n", "        ", "for", "dataset", "in", "datasets", ":", "\n", "            ", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "32", ",", "shuffle", "=", "False", ",", "num_workers", "=", "1", ")", "\n", "print", "(", "dataset", ")", "\n", "pbar", "=", "tqdm", "(", "loader", ")", "\n", "for", "raw_imgs", ",", "raw_filenames", "in", "pbar", ":", "\n", "                ", "imgs", "=", "[", "]", "\n", "filenames", "=", "[", "]", "\n", "for", "i", ",", "filename", "in", "enumerate", "(", "raw_filenames", ")", ":", "\n", "                    ", "if", "filename", "!=", "\"not_a_image\"", "and", "text_dict", ".", "__contains__", "(", "filename", ")", ":", "\n", "                        ", "imgs", ".", "append", "(", "raw_imgs", "[", "i", "]", ")", "\n", "filenames", ".", "append", "(", "filename", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"warning: deleted damaged image\"", ")", "\n", "", "", "imgs", "=", "torch", ".", "stack", "(", "imgs", ")", "\n", "imgs", "=", "imgs", ".", "to", "(", "device", ")", "\n", "try", ":", "\n", "                    ", "if", "txt_type", "==", "\"h5\"", ":", "\n", "                        ", "filenames", "=", "filenames", ".", "numpy", "(", ")", "\n", "", "txts", "=", "[", "text_dict", "[", "filename", "]", "for", "filename", "in", "filenames", "]", "\n", "if", "txt_type", "!=", "\"h5\"", ":", "\n", "                        ", "codes", "=", "make_super_resolution_batch", "(", "model", ",", "txts", ",", "imgs", ")", "\n", "", "else", ":", "\n", "                        ", "codes", "=", "make_tuple_text_image_batch", "(", "model", ",", "txts", ",", "imgs", ")", "\n", "", "for", "code", "in", "codes", ":", "\n", "                        ", "txn", ".", "put", "(", "str", "(", "index", ")", ".", "encode", "(", "'utf-8'", ")", ",", "pickle", ".", "dumps", "(", "code", ")", ")", "\n", "index", "+=", "1", "\n", "", "", "except", "KeyError", ":", "\n", "                    ", "print", "(", "\"warning: KeyError. The text cannot be find\"", ")", "\n", "pass", "\n", "", "", "", "txn", ".", "put", "(", "'length'", ".", "encode", "(", "'utf-8'", ")", ",", "str", "(", "index", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.ImageFileDataset.__getitem__": [[31, 37], ["torchvision.datasets.ImageFolder.__getitem__", "os.path.split", "filename.split"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.H5Dataset.__getitem__"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", ",", "target", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "path", ",", "_", "=", "self", ".", "samples", "[", "index", "]", "\n", "dirs", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "path", ")", "\n", "filename", "=", "filename", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "return", "sample", ",", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.RarDataset.__init__": [[39, 44], ["unrar.rarfile.RarFile", "raw_datasets.RarDataset.rar.infolist"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "transform", "=", "None", ")", ":", "\n", "        ", "from", "unrar", "import", "rarfile", "\n", "self", ".", "rar", "=", "rarfile", ".", "RarFile", "(", "path", ")", "\n", "self", ".", "infos", "=", "self", ".", "rar", ".", "infolist", "(", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.RarDataset.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "infos", ")", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.RarDataset.__getitem__": [[46, 54], ["PIL.Image.open", "os.path.split", "raw_datasets.RarDataset.rar.open", "filename.split", "raw_datasets.RarDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "target_info", "=", "self", ".", "infos", "[", "idx", "]", "\n", "img", "=", "Image", ".", "open", "(", "self", ".", "rar", ".", "open", "(", "target_info", ")", ")", "\n", "dirs", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "self", ".", "infos", "[", "idx", "]", ".", "filename", ")", "\n", "filename", "=", "filename", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.ZipDataset.__init__": [[63, 75], ["zipfile.ZipFile", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "raw_datasets.ZipDataset.zip.infolist", "raw_datasets.ZipDataset.zip.infolist", "enumerate"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "zip", "=", "zipfile", ".", "ZipFile", "(", "path", ")", "\n", "worker_info", "=", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", ":", "\n", "            ", "self", ".", "members", "=", "[", "info", "for", "info", "in", "self", ".", "zip", ".", "infolist", "(", ")", "if", "info", ".", "filename", "[", "-", "1", "]", "!=", "os", ".", "sep", "]", "\n", "", "else", ":", "\n", "            ", "all_members", "=", "[", "info", "for", "info", "in", "self", ".", "zip", ".", "infolist", "(", ")", "if", "info", ".", "filename", "[", "-", "1", "]", "!=", "os", ".", "sep", "]", "\n", "num_workers", "=", "worker_info", ".", "num_workers", "\n", "worker_id", "=", "worker_info", ".", "id", "\n", "self", ".", "members", "=", "[", "x", "for", "i", ",", "x", "in", "enumerate", "(", "all_members", ")", "if", "i", "%", "num_workers", "==", "worker_id", "]", "\n", "\n", "", "self", ".", "transform", "=", "transform", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.ZipDataset.__len__": [[75, 77], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "members", ")", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.ZipDataset.__getitem__": [[77, 85], ["PIL.Image.open", "os.path.split", "raw_datasets.ZipDataset.zip.open", "filename.split", "raw_datasets.ZipDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "target_info", "=", "self", ".", "members", "[", "idx", "]", "\n", "img", "=", "Image", ".", "open", "(", "self", ".", "zip", ".", "open", "(", "target_info", ")", ")", "\n", "dirs", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "self", ".", "members", "[", "idx", "]", ".", "filename", ")", "\n", "filename", "=", "filename", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.H5Dataset.__init__": [[89, 94], ["h5py.File"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "h5", "=", "h5py", ".", "File", "(", "path", ",", "\"r\"", ")", "\n", "self", ".", "images", "=", "self", ".", "h5", "[", "\"input_image\"", "]", "\n", "self", ".", "members", "=", "None", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.H5Dataset.create_members": [[95, 104], ["torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "enumerate"], "methods", ["None"], ["", "def", "create_members", "(", "self", ")", ":", "\n", "        ", "worker_info", "=", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", ":", "\n", "            ", "self", ".", "members", "=", "self", ".", "h5", "[", "'index'", "]", "[", ":", "]", "\n", "", "else", ":", "\n", "            ", "all_members", "=", "self", ".", "h5", "[", "'index'", "]", "[", ":", "]", "\n", "num_workers", "=", "worker_info", ".", "num_workers", "\n", "worker_id", "=", "worker_info", ".", "id", "\n", "self", ".", "members", "=", "[", "x", "for", "i", ",", "x", "in", "enumerate", "(", "all_members", ")", "if", "i", "%", "num_workers", "==", "worker_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.H5Dataset.__len__": [[105, 109], ["len", "raw_datasets.H5Dataset.create_members"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.H5Dataset.create_members"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "members", "is", "None", ":", "\n", "            ", "self", ".", "create_members", "(", ")", "\n", "", "return", "len", "(", "self", ".", "members", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.H5Dataset.__getitem__": [[110, 122], ["raw_datasets.H5Dataset.create_members", "PIL.Image.fromarray", "raw_datasets.H5Dataset.transform", "int", "print", "PIL.Image.new"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.H5Dataset.create_members"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "members", "is", "None", ":", "\n", "            ", "self", ".", "create_members", "(", ")", "\n", "", "target_info", "=", "self", ".", "members", "[", "idx", "]", "\n", "try", ":", "\n", "            ", "img", "=", "Image", ".", "fromarray", "(", "self", ".", "images", "[", "target_info", "]", "[", "0", "]", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "int", "(", "target_info", ")", "\n", "", "except", "(", "OSError", ",", "IndexError", ")", ":", "\n", "            ", "print", "(", "\"warning: OSError or IndexError\"", ")", "\n", "return", "Image", ".", "new", "(", "'RGB'", ",", "(", "256", ",", "256", ")", ",", "(", "255", ",", "255", ",", "255", ")", ")", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.StreamingRarDataset.__init__": [[148, 170], ["print", "unrar.rarfile.RarFile", "print", "PIL.Image.open().convert", "os.path.split", "filename.split", "raw_datasets.StreamingRarDataset.transform", "print", "PIL.Image.open", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "file_buffer.get_bytes"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "transform", "=", "None", ",", "default_size", "=", "256", ")", ":", "\n", "        ", "from", "PIL", "import", "ImageFile", "\n", "ImageFile", ".", "LOAD_TRUNCATED_IMAGES", "=", "True", "\n", "print", "(", "\"begin open rar\"", ")", "\n", "self", ".", "rar", "=", "rarfile", ".", "RarFile", "(", "path", ")", "\n", "print", "(", "\"finish open rar\"", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "def", "callback_fn", "(", "file_buffer", ",", "filename", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "img", "=", "Image", ".", "open", "(", "file_buffer", ".", "get_bytes", "(", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "dirs", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "filename", ")", "\n", "filename", "=", "filename", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                    ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "filename", "\n", "", "except", "PIL", ".", "UnidentifiedImageError", ":", "\n", "                ", "print", "(", "\"UnidentifiedImageError\"", ")", "\n", "return", "torch", ".", "zeros", "(", "(", "3", ",", "default_size", ",", "default_size", ")", ")", ",", "\"not_a_image\"", "\n", "", "", "self", ".", "callback_fn", "=", "callback_fn", "\n", "# new handle", "\n", "self", ".", "handle", "=", "None", "\n", "self", ".", "callback_fn", "=", "callback_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.StreamingRarDataset.__len__": [[171, 173], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "rar", ".", "filelist", ")", "\n", "", "def", "__next__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.StreamingRarDataset.__next__": [[173, 210], ["unrar.rarfile._ReadIntoMemory", "unrar.unrarlib.UNRARCALLBACK", "unrar.unrarlib.RARSetCallback", "len", "StopIteration", "unrar.unrarlib.RAROpenArchiveDataEx", "raw_datasets.StreamingRarDataset.rar._open", "raw_datasets.StreamingRarDataset.rar._read_header", "KeyError", "raw_datasets.StreamingRarDataset.callback_fn", "raw_datasets.StreamingRarDataset.rar._read_header", "unrar.rarfile.BadRarFile", "raw_datasets.StreamingRarDataset.rar._process_current", "raw_datasets.StreamingRarDataset.rar._process_current"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "pointer", ">=", "len", "(", "self", ".", "members", ")", ":", "\n", "            ", "raise", "StopIteration", "(", ")", "\n", "", "if", "self", ".", "handle", "==", "None", ":", "\n", "            ", "archive", "=", "unrarlib", ".", "RAROpenArchiveDataEx", "(", "\n", "self", ".", "rar", ".", "filename", ",", "mode", "=", "constants", ".", "RAR_OM_EXTRACT", ")", "\n", "self", ".", "handle", "=", "self", ".", "rar", ".", "_open", "(", "archive", ")", "\n", "# callback to memory", "\n", "", "self", ".", "data_storage", "=", "_ReadIntoMemory", "(", ")", "\n", "c_callback", "=", "unrarlib", ".", "UNRARCALLBACK", "(", "self", ".", "data_storage", ".", "_callback", ")", "\n", "unrarlib", ".", "RARSetCallback", "(", "self", ".", "handle", ",", "c_callback", ",", "0", ")", "\n", "handle", "=", "self", ".", "handle", "\n", "try", ":", "\n", "            ", "rarinfo", "=", "self", ".", "rar", ".", "_read_header", "(", "handle", ")", "\n", "while", "rarinfo", "is", "not", "None", ":", "\n", "                ", "if", "rarinfo", ".", "filename", "==", "self", ".", "members", "[", "self", ".", "pointer", "]", ":", "\n", "                    ", "self", ".", "rar", ".", "_process_current", "(", "handle", ",", "constants", ".", "RAR_TEST", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "self", ".", "rar", ".", "_process_current", "(", "handle", ",", "constants", ".", "RAR_SKIP", ")", "\n", "", "rarinfo", "=", "self", ".", "rar", ".", "_read_header", "(", "handle", ")", "\n", "\n", "", "if", "rarinfo", "is", "None", ":", "\n", "                ", "self", ".", "data_storage", "=", "None", "\n", "\n", "", "", "except", "unrarlib", ".", "UnrarException", ":", "\n", "            ", "raise", "BadRarFile", "(", "\"Bad RAR archive data.\"", ")", "\n", "\n", "", "if", "self", ".", "data_storage", "is", "None", ":", "\n", "            ", "raise", "KeyError", "(", "'There is no item named %r in the archive'", "%", "self", ".", "members", "[", "self", ".", "pointer", "]", ")", "\n", "\n", "# return file-like object", "\n", "", "ret", "=", "self", ".", "data_storage", "\n", "if", "self", ".", "callback_fn", "is", "not", "None", ":", "\n", "            ", "ret", "=", "self", ".", "callback_fn", "(", "ret", ",", "self", ".", "members", "[", "self", ".", "pointer", "]", ")", "\n", "", "self", ".", "pointer", "+=", "1", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.StreamingRarDataset.__iter__": [[211, 222], ["torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info", "raw_datasets.StreamingRarDataset.rar.namelist", "raw_datasets.StreamingRarDataset.rar.namelist", "enumerate"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "worker_info", "=", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", ":", "\n", "            ", "self", ".", "members", "=", "self", ".", "rar", ".", "namelist", "(", ")", "\n", "", "else", ":", "\n", "            ", "all_members", "=", "self", ".", "rar", ".", "namelist", "(", ")", "\n", "num_workers", "=", "worker_info", ".", "num_workers", "\n", "worker_id", "=", "worker_info", ".", "id", "\n", "self", ".", "members", "=", "[", "x", "for", "i", ",", "x", "in", "enumerate", "(", "all_members", ")", "if", "i", "%", "num_workers", "==", "worker_id", "]", "\n", "", "self", ".", "pointer", "=", "0", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.StreamingRarDataset.__del__": [[223, 225], ["raw_datasets.StreamingRarDataset.rar._close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "rar", ".", "_close", "(", "self", ".", "handle", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.utils.show_recover_results": [[23, 32], ["vqvae.img2code", "vqvae.code2img", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.cat", "torch.cat", "torchvision.utils.save_image", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.img2code", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.code2img"], ["\n", "from", "torch", ".", "nn", ".", "parallel", ".", "distributed", "import", "DistributedDataParallel", "as", "torchDDP", "\n", "from", "fp16", "import", "FP16_Optimizer", "\n", "import", "mpu", "\n", "import", "model", "\n", "from", "tensorboardX", "import", "SummaryWriter", "\n", "\n", "SUMMARY_WRITER_DIR_NAME", "=", "'runs'", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.grads.clip_grad_norm": [[28, 75], ["isinstance", "list", "float", "float", "filter", "max", "torch.cuda.FloatTensor", "torch.distributed.all_reduce", "total_norm_cuda[].item", "torch.cuda.FloatTensor", "torch.distributed.all_reduce", "total_norm_cuda[].item", "p.grad.data.mul_", "p.grad.data.abs().max", "float", "initialize.get_model_parallel_group", "p.grad.data.norm", "float", "initialize.get_model_parallel_group", "initialize.get_model_parallel_rank", "p.grad.data.norm.item", "p.grad.data.abs"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank"], ["def", "clip_grad_norm", "(", "parameters", ",", "max_norm", ",", "norm_type", "=", "2", ")", ":", "\n", "    ", "\"\"\"Clips gradient norm of an iterable of parameters.\n\n    This is adapted from torch.nn.utils.clip_grad.clip_grad_norm_ and\n    added functionality to handle model parallel parameters. Note that\n    the gradients are modified in place.\n\n    Arguments:\n        parameters (Iterable[Tensor] or Tensor): an iterable of Tensors or a\n            single Tensor that will have gradients normalized\n        max_norm (float or int): max norm of the gradients\n        norm_type (float or int): type of the used p-norm. Can be ``'inf'`` for\n            infinity norm.\n\n    Returns:\n        Total norm of the parameters (viewed as a single vector).\n    \"\"\"", "\n", "if", "isinstance", "(", "parameters", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "parameters", "=", "[", "parameters", "]", "\n", "", "parameters", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "parameters", ")", ")", "\n", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "norm_type", "=", "float", "(", "norm_type", ")", "\n", "if", "norm_type", "==", "inf", ":", "\n", "        ", "total_norm", "=", "max", "(", "p", ".", "grad", ".", "data", ".", "abs", "(", ")", ".", "max", "(", ")", "for", "p", "in", "parameters", ")", "\n", "total_norm_cuda", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "[", "float", "(", "total_norm", ")", "]", ")", "\n", "# Take max across all GPUs.", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "total_norm_cuda", ",", "\n", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "MAX", ",", "\n", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "total_norm", "=", "total_norm_cuda", "[", "0", "]", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "        ", "total_norm", "=", "0", "\n", "for", "p", "in", "parameters", ":", "\n", "            ", "if", "p", ".", "model_parallel", "or", "(", "get_model_parallel_rank", "(", ")", "==", "0", ")", ":", "\n", "                ", "param_norm", "=", "p", ".", "grad", ".", "data", ".", "norm", "(", "norm_type", ")", "\n", "total_norm", "+=", "param_norm", ".", "item", "(", ")", "**", "norm_type", "\n", "# Sum across all model parallel GPUs.", "\n", "", "", "total_norm_cuda", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "[", "float", "(", "total_norm", ")", "]", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "total_norm_cuda", ",", "\n", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "SUM", ",", "\n", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "total_norm", "=", "total_norm_cuda", "[", "0", "]", ".", "item", "(", ")", "**", "(", "1.", "/", "norm_type", ")", "\n", "", "clip_coef", "=", "max_norm", "/", "(", "total_norm", "+", "1e-6", ")", "\n", "if", "clip_coef", "<", "1", ":", "\n", "        ", "for", "p", "in", "parameters", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "clip_coef", ")", "\n", "", "", "return", "total_norm", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._CopyToModelParallelRegion.forward": [[82, 85], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input_", ")", ":", "\n", "        ", "return", "input_", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._CopyToModelParallelRegion.backward": [[86, 89], ["mappings._reduce"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._reduce"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "return", "_reduce", "(", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._ReduceFromModelParallelRegion.forward": [[94, 97], ["mappings._reduce"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._reduce"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input_", ")", ":", "\n", "        ", "return", "_reduce", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._ReduceFromModelParallelRegion.backward": [[98, 101], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "return", "grad_output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._ScatterToModelParallelRegion.forward": [[106, 109], ["mappings._split"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._split"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input_", ")", ":", "\n", "        ", "return", "_split", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._ScatterToModelParallelRegion.backward": [[110, 113], ["mappings._gather"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._gather"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "return", "_gather", "(", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._GatherFromModelParallelRegion.forward": [[118, 121], ["mappings._gather"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._gather"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input_", ")", ":", "\n", "        ", "return", "_gather", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._GatherFromModelParallelRegion.backward": [[122, 125], ["mappings._split"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._split"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "return", "_split", "(", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._reduce": [[22, 34], ["initialize.get_model_parallel_group", "torch.distributed.all_reduce", "torch.distributed.get_world_size"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size"], ["def", "_reduce", "(", "input_", ")", ":", "\n", "    ", "\"\"\"All-reduce the the input tensor across model parallel group.\"\"\"", "\n", "group", "=", "get_model_parallel_group", "(", ")", "\n", "\n", "# Bypass the function if we are using only 1 GPU.", "\n", "if", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "input_", "\n", "\n", "# All-reduce.", "\n", "", "torch", ".", "distributed", ".", "all_reduce", "(", "input_", ",", "group", "=", "group", ")", "\n", "\n", "return", "input_", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._split": [[36, 54], ["initialize.get_model_parallel_group", "torch.distributed.get_world_size", "utils.split_tensor_along_last_dim", "torch.distributed.get_rank", "input_list[].contiguous", "torch.distributed.get_world_size"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.split_tensor_along_last_dim", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size"], ["", "def", "_split", "(", "input_", ")", ":", "\n", "    ", "\"\"\"Split the tensor along its last dimension and keep the\n    corresponding slice.\"\"\"", "\n", "group", "=", "get_model_parallel_group", "(", ")", "\n", "\n", "# Bypass the function if we are using only 1 GPU.", "\n", "if", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "input_", "\n", "\n", "# Split along last dimension.", "\n", "", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "input_list", "=", "split_tensor_along_last_dim", "(", "input_", ",", "world_size", ")", "\n", "\n", "# Note: torch.split does not create contiguous tensors by default.", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "output", "=", "input_list", "[", "rank", "]", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings._gather": [[56, 77], ["initialize.get_model_parallel_group", "torch.distributed.get_rank", "torch.distributed.get_world_size", "torch.distributed.all_gather", "torch.cat().contiguous", "torch.distributed.get_world_size", "input_.dim", "torch.empty_like", "range", "torch.cat"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_gather", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size"], ["", "def", "_gather", "(", "input_", ")", ":", "\n", "    ", "\"\"\"Gather tensors and concatinate along the last dimension.\"\"\"", "\n", "group", "=", "get_model_parallel_group", "(", ")", "\n", "\n", "# Bypass the function if we are using only 1 GPU.", "\n", "if", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "input_", "\n", "\n", "# Size and dimension.", "\n", "", "last_dim", "=", "input_", ".", "dim", "(", ")", "-", "1", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "\n", "tensor_list", "=", "[", "torch", ".", "empty_like", "(", "input_", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "tensor_list", "[", "rank", "]", "=", "input_", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "tensor_list", ",", "input_", ",", "group", "=", "group", ")", "\n", "\n", "# Note: torch.cat already creates a contiguous tensor.", "\n", "output", "=", "torch", ".", "cat", "(", "tensor_list", ",", "dim", "=", "last_dim", ")", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.copy_to_model_parallel_region": [[131, 133], ["_CopyToModelParallelRegion.apply"], "function", ["None"], ["", "", "def", "copy_to_model_parallel_region", "(", "input_", ")", ":", "\n", "    ", "return", "_CopyToModelParallelRegion", ".", "apply", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.reduce_from_model_parallel_region": [[134, 136], ["_ReduceFromModelParallelRegion.apply"], "function", ["None"], ["", "def", "reduce_from_model_parallel_region", "(", "input_", ")", ":", "\n", "    ", "return", "_ReduceFromModelParallelRegion", ".", "apply", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.scatter_to_model_parallel_region": [[137, 139], ["_ScatterToModelParallelRegion.apply"], "function", ["None"], ["", "def", "scatter_to_model_parallel_region", "(", "input_", ")", ":", "\n", "    ", "return", "_ScatterToModelParallelRegion", ".", "apply", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.gather_from_model_parallel_region": [[140, 142], ["_GatherFromModelParallelRegion.apply"], "function", ["None"], ["", "def", "gather_from_model_parallel_region", "(", "input_", ")", ":", "\n", "    ", "return", "_GatherFromModelParallelRegion", ".", "apply", "(", "input_", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.cross_entropy._VocabParallelCrossEntropy.forward": [[27, 82], ["vocab_parallel_logits.clone", "torch.distributed.all_reduce", "vocab_parallel_logits.clone.sub_", "vocab_parallel_logits.clone.exp", "vocab_parallel_logits.clone.exp.sum", "torch.distributed.all_reduce", "initialize.get_model_parallel_rank", "initialize.get_model_parallel_world_size", "get_vocab_range", "vocab_parallel_logits.clone.view", "masked_target.view", "torch.arange", "predicted_logits_1d.view_as", "torch.distributed.all_reduce", "vocab_parallel_logits.clone.exp.div_", "ctx.save_for_backward", "torch.max", "logits_max.unsqueeze", "vocab_parallel_logits.size", "target.clone", "torch.log", "logits.exp.sum.unsqueeze", "initialize.get_model_parallel_group", "initialize.get_model_parallel_group", "initialize.get_model_parallel_group", "vocab_parallel_logits.clone.view.size"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "vocab_parallel_logits", ",", "target", ")", ":", "\n", "\n", "# Copy so the input remains unchanged.", "\n", "        ", "logits", "=", "vocab_parallel_logits", ".", "clone", "(", ")", "\n", "# Maximum value along vocab dimension across all GPUs.", "\n", "logits_max", "=", "torch", ".", "max", "(", "logits", ",", "dim", "=", "-", "1", ")", "[", "0", "]", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "logits_max", ",", "\n", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "MAX", ",", "\n", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "# Subtract the maximum value.", "\n", "logits", ".", "sub_", "(", "logits_max", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", ")", "\n", "# Sum of exponential of logits along vocab dimension across all GPUs.", "\n", "exp_logits", "=", "logits", ".", "exp", "(", ")", "\n", "sum_exp_logits", "=", "exp_logits", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "sum_exp_logits", ",", "\n", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "SUM", ",", "\n", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "\n", "# Get the partition's vocab indecies", "\n", "get_vocab_range", "=", "VocabUtility", ".", "vocab_range_from_per_partition_vocab_size", "\n", "partition_vocab_size", "=", "vocab_parallel_logits", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "rank", "=", "get_model_parallel_rank", "(", ")", "\n", "world_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "vocab_start_index", ",", "vocab_end_index", "=", "get_vocab_range", "(", "\n", "partition_vocab_size", ",", "rank", ",", "world_size", ")", "\n", "\n", "# Create a mask of valid vocab ids (1 means it needs to be masked).", "\n", "target_mask", "=", "(", "target", "<", "vocab_start_index", ")", "|", "(", "target", ">=", "vocab_end_index", ")", "\n", "masked_target", "=", "target", ".", "clone", "(", ")", "-", "vocab_start_index", "\n", "masked_target", "[", "target_mask", "]", "=", "0", "\n", "\n", "# Get predicted-logits = logits[target].", "\n", "# For Simplicity, we convert logits to a 2-D tensor with size", "\n", "# [*, partition-vocab-size] and target to a 1-D tensor of size [*].", "\n", "logits_2d", "=", "logits", ".", "view", "(", "-", "1", ",", "partition_vocab_size", ")", "\n", "masked_target_1d", "=", "masked_target", ".", "view", "(", "-", "1", ")", "\n", "arange_1d", "=", "torch", ".", "arange", "(", "start", "=", "0", ",", "end", "=", "logits_2d", ".", "size", "(", ")", "[", "0", "]", ",", "\n", "device", "=", "logits_2d", ".", "device", ")", "\n", "predicted_logits_1d", "=", "logits_2d", "[", "arange_1d", ",", "masked_target_1d", "]", "\n", "predicted_logits", "=", "predicted_logits_1d", ".", "view_as", "(", "target", ")", "\n", "predicted_logits", "[", "target_mask", "]", "=", "0.0", "\n", "# All reduce is needed to get the chunks from other GPUs.", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "predicted_logits", ",", "\n", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "SUM", ",", "\n", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "\n", "# Loss = log(sum(exp(logits))) - predicted-logit.", "\n", "loss", "=", "torch", ".", "log", "(", "sum_exp_logits", ")", "-", "predicted_logits", "\n", "\n", "# Store softmax, target-mask and masked-target for backward pass.", "\n", "exp_logits", ".", "div_", "(", "sum_exp_logits", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", ")", "\n", "ctx", ".", "save_for_backward", "(", "exp_logits", ",", "target_mask", ",", "masked_target_1d", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.cross_entropy._VocabParallelCrossEntropy.backward": [[83, 105], ["grad_input.view", "torch.arange", "grad_input.mul_", "softmax.size", "target_mask.view().float", "grad_output.unsqueeze", "grad_input.view.size", "target_mask.view"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "\n", "# Retreive tensors from the forward path.", "\n", "        ", "softmax", ",", "target_mask", ",", "masked_target_1d", "=", "ctx", ".", "saved_tensors", "\n", "\n", "# All the inputs have softmax as thier gradient.", "\n", "grad_input", "=", "softmax", "\n", "# For simplicity, work with the 2D gradient.", "\n", "partition_vocab_size", "=", "softmax", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "grad_2d", "=", "grad_input", ".", "view", "(", "-", "1", ",", "partition_vocab_size", ")", "\n", "\n", "# Add the gradient from matching classes.", "\n", "arange_1d", "=", "torch", ".", "arange", "(", "start", "=", "0", ",", "end", "=", "grad_2d", ".", "size", "(", ")", "[", "0", "]", ",", "\n", "device", "=", "grad_2d", ".", "device", ")", "\n", "grad_2d", "[", "arange_1d", ",", "masked_target_1d", "]", "-=", "(", "\n", "1.0", "-", "target_mask", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ")", "\n", "\n", "# Finally elementwise multiplication with the output gradients.", "\n", "grad_input", ".", "mul_", "(", "grad_output", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", ")", "\n", "\n", "return", "grad_input", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.cross_entropy.vocab_parallel_cross_entropy": [[107, 110], ["_VocabParallelCrossEntropy.apply"], "function", ["None"], ["", "", "def", "vocab_parallel_cross_entropy", "(", "vocab_parallel_logits", ",", "target", ")", ":", "\n", "    ", "\"\"\"Helper function for the cross entropy.\"\"\"", "\n", "return", "_VocabParallelCrossEntropy", ".", "apply", "(", "vocab_parallel_logits", ",", "target", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.LayerNorm.__init__": [[41, 43], ["apex.normalization.fused_layer_norm.FusedLayerNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.LayerNorm.forward": [[43, 45], ["super().forward", "x.abs().max().detach", "x.abs().max", "x.abs"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.inception.InceptionV3.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "forward", "(", "x", "/", "(", "x", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "detach", "(", ")", "/", "8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelSelfAttention.__init__": [[72, 111], ["super().__init__", "initialize.get_model_parallel_world_size", "utils.divide", "utils.divide", "utils.divide", "layers.ColumnParallelLinear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "layers.RowParallelLinear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "deepspeed.checkpointing.is_configured"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "num_attention_heads", ",", "\n", "attention_dropout_prob", ",", "output_dropout_prob", ",", "\n", "init_method", ",", "output_layer_init_method", "=", "None", ",", "query_window", "=", "128", ",", "key_window_times", "=", "6", ")", ":", "\n", "        ", "super", "(", "GPT2ParallelSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Set output layer initialization if not provided.", "\n", "if", "output_layer_init_method", "is", "None", ":", "\n", "            ", "output_layer_init_method", "=", "init_method", "\n", "# Per attention head and per partition values.", "\n", "", "world_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "self", ".", "hidden_size_per_partition", "=", "divide", "(", "hidden_size", ",", "world_size", ")", "\n", "self", ".", "hidden_size_per_attention_head", "=", "divide", "(", "hidden_size", ",", "\n", "num_attention_heads", ")", "\n", "self", ".", "num_attention_heads_per_partition", "=", "divide", "(", "num_attention_heads", ",", "\n", "world_size", ")", "\n", "self", ".", "query_window", "=", "query_window", "\n", "self", ".", "key_window_times", "=", "key_window_times", "\n", "\n", "# Strided linear layer.", "\n", "self", ".", "query_key_value", "=", "ColumnParallelLinear", "(", "hidden_size", ",", "3", "*", "hidden_size", ",", "\n", "stride", "=", "3", ",", "\n", "gather_output", "=", "False", ",", "\n", "init_method", "=", "init_method", ")", "\n", "\n", "# Dropout. Note that for a single iteration, this layer will generate", "\n", "# different outputs on different number of parallel partitions but", "\n", "# on average it should not be partition dependent.", "\n", "self", ".", "attention_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "attention_dropout_prob", ")", "\n", "\n", "# Output.", "\n", "self", ".", "dense", "=", "RowParallelLinear", "(", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "input_is_parallel", "=", "True", ",", "\n", "init_method", "=", "output_layer_init_method", ")", "\n", "self", ".", "output_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "output_dropout_prob", ")", "\n", "\n", "if", "deepspeed", ".", "checkpointing", ".", "is_configured", "(", ")", ":", "\n", "            ", "global", "get_cuda_rng_tracker", ",", "checkpoint", "\n", "get_cuda_rng_tracker", "=", "deepspeed", ".", "checkpointing", ".", "get_cuda_rng_tracker", "\n", "checkpoint", "=", "deepspeed", ".", "checkpointing", ".", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelSelfAttention._transpose_for_scores": [[112, 121], ["tensor.view.view.view", "tensor.view.view.permute", "tensor.view.view.size"], "methods", ["None"], ["", "", "def", "_transpose_for_scores", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "\"\"\"Transpose a 3D tensor [b, s, np*hn] into a 4D tensor with\n        size [b, np, s, hn].\n        \"\"\"", "\n", "new_tensor_shape", "=", "tensor", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads_per_partition", ",", "\n", "self", ".", "hidden_size_per_attention_head", ")", "\n", "tensor", "=", "tensor", ".", "view", "(", "*", "new_tensor_shape", ")", "\n", "return", "tensor", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelSelfAttention.forward": [[123, 170], ["hidden_states.size", "sparse_transformer.GPT2ParallelSelfAttention._transpose_for_scores", "sparse_transformer.GPT2ParallelSelfAttention._transpose_for_scores", "sparse_transformer.GPT2ParallelSelfAttention._transpose_for_scores", "standard_attention.permute().contiguous", "standard_attention.view", "sparse_transformer.GPT2ParallelSelfAttention.dense", "sparse_transformer.GPT2ParallelSelfAttention.output_dropout", "sparse_transformer.GPT2ParallelSelfAttention.query_key_value", "utils.split_tensor_along_last_dim", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sparse_transformer.GPT2ParallelSelfAttention.query_key_value", "utils.split_tensor_along_last_dim", "sparse_transformer.sparse_attention", "sparse_transformer.sparse_attention_inference", "sparse_transformer.standard_attention", "standard_attention.permute", "standard_attention.size"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelSelfAttention._transpose_for_scores", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelSelfAttention._transpose_for_scores", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelSelfAttention._transpose_for_scores", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.split_tensor_along_last_dim", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.split_tensor_along_last_dim", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.sparse_attention", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.sparse_attention_inference", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.standard_attention"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "ltor_mask", ",", "pivot_idx", "=", "None", ",", "is_sparse", "=", "0", ",", "mem", "=", "None", ")", ":", "\n", "# hidden_states: [b, s, h]", "\n", "# ltor_mask: [1, 1, s, s]", "\n", "\n", "# Attention heads. [b, s, hp]", "\n", "        ", "query_length", "=", "hidden_states", ".", "size", "(", "1", ")", "\n", "\n", "if", "mem", "is", "None", ":", "\n", "            ", "mixed_x_layer", "=", "self", ".", "query_key_value", "(", "hidden_states", ")", "\n", "(", "mixed_query_layer", ",", "\n", "mixed_key_layer", ",", "\n", "mixed_value_layer", ")", "=", "split_tensor_along_last_dim", "(", "mixed_x_layer", ",", "3", ")", "\n", "", "else", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "(", "mem", ",", "hidden_states", ")", ",", "1", ")", "\n", "mixed_x_layer", "=", "self", ".", "query_key_value", "(", "cat", ")", "\n", "(", "mixed_query_layer", ",", "\n", "mixed_key_layer", ",", "\n", "mixed_value_layer", ")", "=", "split_tensor_along_last_dim", "(", "mixed_x_layer", ",", "3", ")", "\n", "mixed_query_layer", "=", "mixed_query_layer", "[", ":", ",", "-", "query_length", ":", "]", "\n", "\n", "# Reshape and transpose [b, np, s, hn]", "\n", "", "query_layer", "=", "self", ".", "_transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "_transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "_transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# =====================   Core Attention Code  ======================== #", "\n", "if", "is_sparse", "==", "1", ":", "\n", "            ", "context_layer", "=", "sparse_attention", "(", "query_layer", ",", "key_layer", ",", "value_layer", ",", "pivot_idx", ",", "ltor_mask", ",", "self", ".", "query_window", ",", "self", ".", "key_window_times", ",", "self", ".", "attention_dropout", ")", "\n", "", "elif", "is_sparse", "==", "2", ":", "\n", "            ", "context_layer", "=", "sparse_attention_inference", "(", "query_layer", ",", "key_layer", ",", "value_layer", ",", "pivot_idx", ")", "\n", "", "else", ":", "\n", "            ", "context_layer", "=", "standard_attention", "(", "query_layer", ",", "key_layer", ",", "value_layer", ",", "ltor_mask", ",", "self", ".", "attention_dropout", ")", "\n", "\n", "# ===================== END OF BLOCK ======================= #", "\n", "\n", "# [b, s, np, hn]", "\n", "", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "hidden_size_per_partition", ",", ")", "\n", "# [b, s, hp]", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "# Output. [b, s, h]", "\n", "output", "=", "self", ".", "dense", "(", "context_layer", ")", "\n", "output", "=", "self", ".", "output_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelMLP.__init__": [[208, 225], ["super().__init__", "layers.ColumnParallelLinear", "layers.RowParallelLinear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "output_dropout_prob", ",", "init_method", ",", "\n", "output_layer_init_method", "=", "None", ")", ":", "\n", "        ", "super", "(", "GPT2ParallelMLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Set output layer initialization if not provided.", "\n", "if", "output_layer_init_method", "is", "None", ":", "\n", "            ", "output_layer_init_method", "=", "init_method", "\n", "# Project to 4h.", "\n", "", "self", ".", "dense_h_to_4h", "=", "ColumnParallelLinear", "(", "hidden_size", ",", "4", "*", "hidden_size", ",", "\n", "gather_output", "=", "False", ",", "\n", "init_method", "=", "init_method", ")", "\n", "# Project back to h.", "\n", "self", ".", "dense_4h_to_h", "=", "RowParallelLinear", "(", "\n", "4", "*", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "input_is_parallel", "=", "True", ",", "\n", "init_method", "=", "output_layer_init_method", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "output_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelMLP.forward": [[226, 235], ["sparse_transformer.GPT2ParallelMLP.dense_h_to_4h", "sparse_transformer.gelu", "sparse_transformer.GPT2ParallelMLP.dense_4h_to_h", "sparse_transformer.GPT2ParallelMLP.dropout"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.gelu"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# [b, s, 4hp]", "\n", "        ", "intermediate_parallel", "=", "self", ".", "dense_h_to_4h", "(", "hidden_states", ")", "\n", "intermediate_parallel", "=", "gelu", "(", "intermediate_parallel", ")", "\n", "\n", "# [b, s, h]", "\n", "output", "=", "self", ".", "dense_4h_to_h", "(", "intermediate_parallel", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelTransformerLayer.__init__": [[265, 313], ["super().__init__", "sparse_transformer.LayerNorm", "sparse_transformer.GPT2ParallelSelfAttention", "sparse_transformer.LayerNorm", "sparse_transformer.GPT2ParallelMLP", "sparse_transformer.LayerNorm", "sparse_transformer.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["def", "__init__", "(", "self", ",", "\n", "hidden_size", ",", "\n", "num_attention_heads", ",", "\n", "attention_dropout_prob", ",", "\n", "output_dropout_prob", ",", "\n", "layernorm_epsilon", ",", "\n", "init_method", ",", "\n", "output_layer_init_method", "=", "None", ",", "\n", "query_window", "=", "128", ",", "\n", "key_window_times", "=", "6", ",", "\n", "scale_normalization", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", "GPT2ParallelTransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Set output layer initialization if not provided.", "\n", "if", "output_layer_init_method", "is", "None", ":", "\n", "            ", "output_layer_init_method", "=", "init_method", "\n", "\n", "# Layernorm on the input data.", "\n", "", "self", ".", "input_layernorm", "=", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "layernorm_epsilon", ")", "\n", "\n", "\n", "# Self attention.", "\n", "self", ".", "attention", "=", "GPT2ParallelSelfAttention", "(", "\n", "hidden_size", ",", "\n", "num_attention_heads", ",", "\n", "attention_dropout_prob", ",", "\n", "output_dropout_prob", ",", "\n", "init_method", ",", "\n", "output_layer_init_method", "=", "output_layer_init_method", ",", "\n", "query_window", "=", "query_window", ",", "\n", "key_window_times", "=", "key_window_times", ")", "\n", "\n", "# Layernorm on the input data.", "\n", "self", ".", "post_attention_layernorm", "=", "LayerNorm", "(", "hidden_size", ",", "\n", "eps", "=", "layernorm_epsilon", ")", "\n", "self", ".", "scale_normalization", "=", "scale_normalization", "\n", "if", "scale_normalization", ":", "\n", "            ", "self", ".", "third_layernorm", "=", "LayerNorm", "(", "hidden_size", ",", "\n", "eps", "=", "layernorm_epsilon", ")", "\n", "self", ".", "fourth_layernorm", "=", "LayerNorm", "(", "hidden_size", ",", "\n", "eps", "=", "layernorm_epsilon", ")", "\n", "\n", "# MLP", "\n", "", "self", ".", "mlp", "=", "GPT2ParallelMLP", "(", "\n", "hidden_size", ",", "\n", "output_dropout_prob", ",", "\n", "init_method", ",", "\n", "output_layer_init_method", "=", "output_layer_init_method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelTransformerLayer.forward": [[314, 343], ["sparse_transformer.GPT2ParallelTransformerLayer.input_layernorm", "sparse_transformer.GPT2ParallelTransformerLayer.attention", "sparse_transformer.GPT2ParallelTransformerLayer.post_attention_layernorm", "sparse_transformer.GPT2ParallelTransformerLayer.mlp", "sparse_transformer.GPT2ParallelTransformerLayer.input_layernorm", "sparse_transformer.GPT2ParallelTransformerLayer.third_layernorm", "sparse_transformer.GPT2ParallelTransformerLayer.fourth_layernorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "ltor_mask", ",", "pivot_idx", "=", "None", ",", "is_sparse", "=", "0", ",", "mem", "=", "None", ")", ":", "\n", "# hidden_states: [b, s, h]", "\n", "# ltor_mask: [1, 1, s, s]", "\n", "\n", "# Layer norm at the begining of the transformer layer.", "\n", "        ", "layernorm_output1", "=", "self", ".", "input_layernorm", "(", "hidden_states", ")", "\n", "mem", "=", "self", ".", "input_layernorm", "(", "mem", ")", "if", "mem", "is", "not", "None", "else", "None", "\n", "# Self attention.", "\n", "attention_output", "=", "self", ".", "attention", "(", "layernorm_output1", ",", "ltor_mask", ",", "pivot_idx", ",", "is_sparse", ",", "mem", ")", "\n", "\n", "# Third LayerNorm", "\n", "if", "self", ".", "scale_normalization", ":", "\n", "            ", "attention_output", "=", "self", ".", "third_layernorm", "(", "attention_output", ")", "\n", "\n", "# Residual connection.", "\n", "", "layernorm_input", "=", "hidden_states", "+", "attention_output", "\n", "# Layer norm post the self attention.", "\n", "layernorm_output", "=", "self", ".", "post_attention_layernorm", "(", "layernorm_input", ")", "\n", "# MLP.", "\n", "mlp_output", "=", "self", ".", "mlp", "(", "layernorm_output", ")", "\n", "\n", "# Fourth LayerNorm", "\n", "if", "self", ".", "scale_normalization", ":", "\n", "            ", "mlp_output", "=", "self", ".", "fourth_layernorm", "(", "mlp_output", ")", "\n", "\n", "# Second residual connection.", "\n", "", "output", "=", "layernorm_input", "+", "mlp_output", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelTransformer.__init__": [[395, 470], ["super().__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "sparse_transformer.LayerNorm", "deepspeed.checkpointing.is_configured", "sparse_transformer.scaled_init_method", "sparse_transformer.GPT2ParallelTransformerLayer", "sparse_transformer.unscaled_init_method", "sparse_transformer.GPT2ParallelTransformer.__init__.get_layer"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.scaled_init_method", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.unscaled_init_method"], ["def", "__init__", "(", "self", ",", "\n", "num_layers", ",", "\n", "hidden_size", ",", "\n", "num_attention_heads", ",", "\n", "max_sequence_length", ",", "\n", "max_memory_length", ",", "\n", "embedding_dropout_prob", ",", "\n", "attention_dropout_prob", ",", "\n", "output_dropout_prob", ",", "\n", "checkpoint_activations", ",", "\n", "checkpoint_num_layers", "=", "1", ",", "\n", "layernorm_epsilon", "=", "1.0e-5", ",", "\n", "init_method_std", "=", "0.02", ",", "\n", "use_scaled_init_for_output_weights", "=", "True", ",", "\n", "query_window", "=", "128", ",", "\n", "key_window_times", "=", "6", ",", "\n", "num_pivot", "=", "768", "\n", ")", ":", "\n", "        ", "super", "(", "GPT2ParallelTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Store activation checkpoiting flag.", "\n", "self", ".", "checkpoint_activations", "=", "checkpoint_activations", "\n", "self", ".", "checkpoint_num_layers", "=", "checkpoint_num_layers", "\n", "self", ".", "max_memory_length", "=", "max_memory_length", "\n", "self", ".", "max_sequence_length", "=", "max_sequence_length", "\n", "\n", "output_layer_init_method", "=", "None", "\n", "if", "use_scaled_init_for_output_weights", ":", "\n", "            ", "output_layer_init_method", "=", "scaled_init_method", "(", "init_method_std", ",", "\n", "num_layers", ")", "\n", "# Embeddings dropout", "\n", "", "self", ".", "embedding_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "embedding_dropout_prob", ")", "\n", "\n", "# Position embedding (serial).", "\n", "self", ".", "position_embeddings", "=", "torch", ".", "nn", ".", "Embedding", "(", "max_sequence_length", ",", "\n", "hidden_size", ")", "\n", "# Initialize the position embeddings.", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "position_embeddings", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "init_method_std", ")", "\n", "\n", "# TODO: after testing, this is not useful.", "\n", "# self.img_type_embeddings = torch.nn.Parameter(torch.Tensor(64, hidden_size)) ", "\n", "# torch.nn.init.normal_(self.img_type_embeddings, mean=0.0, std=init_method_std)", "\n", "# self.txt_type_embeddings = torch.nn.Parameter(torch.Tensor(hidden_size)) ", "\n", "# torch.nn.init.normal_(self.txt_type_embeddings, mean=0.0, std=init_method_std)", "\n", "\n", "\n", "def", "get_layer", "(", "layer_id", ")", ":", "\n", "            ", "return", "GPT2ParallelTransformerLayer", "(", "\n", "hidden_size", ",", "\n", "num_attention_heads", ",", "\n", "attention_dropout_prob", ",", "\n", "output_dropout_prob", ",", "\n", "layernorm_epsilon", ",", "\n", "unscaled_init_method", "(", "init_method_std", ")", ",", "\n", "output_layer_init_method", "=", "output_layer_init_method", ",", "\n", "query_window", "=", "query_window", ",", "\n", "key_window_times", "=", "key_window_times", ",", "\n", "scale_normalization", "=", "True", "\n", ")", "\n", "\n", "", "self", ".", "query_window", "=", "query_window", "\n", "self", ".", "key_window_times", "=", "key_window_times", "\n", "self", ".", "num_pivot", "=", "num_pivot", "\n", "\n", "# Transformer layers.", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "get_layer", "(", "layer_id", ")", "for", "layer_id", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "# Final layer norm before output.", "\n", "self", ".", "final_layernorm", "=", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "layernorm_epsilon", ")", "\n", "\n", "if", "deepspeed", ".", "checkpointing", ".", "is_configured", "(", ")", ":", "\n", "            ", "global", "get_cuda_rng_tracker", ",", "checkpoint", "\n", "get_cuda_rng_tracker", "=", "deepspeed", ".", "checkpointing", ".", "get_cuda_rng_tracker", "\n", "checkpoint", "=", "deepspeed", ".", "checkpointing", ".", "checkpoint", "\n", "", "self", ".", "rmask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelTransformer.forward": [[471, 614], ["sparse_transformer.GPT2ParallelTransformer.position_embeddings", "sparse_transformer.GPT2ParallelTransformer.embedding_dropout", "sparse_transformer.GPT2ParallelTransformer.final_layernorm", "layer.size", "mems[].size", "isinstance", "sparse_transformer.GPT2ParallelTransformer.forward.build_mask_matrix"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "position_ids", ",", "attention_mask", ",", "txt_indices_bool", ",", "img_indices_bool", ",", "is_sparse", "=", "0", ",", "*", "mems", ")", ":", "\n", "\n", "        ", "batch_size", ",", "query_length", "=", "hidden_states", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "memory_length", "=", "mems", "[", "0", "]", ".", "size", "(", "1", ")", "if", "mems", "else", "0", "\n", "key_length", "=", "query_length", "+", "memory_length", "\n", "\n", "if", "isinstance", "(", "attention_mask", ",", "int", ")", "or", "attention_mask", ".", "numel", "(", ")", "==", "1", ":", "\n", "# if given a int \"sep\", means the seperation of full attention part and single direction part", "\n", "# attention mask is the beginning postion of B region, \\in [0, query_len)", "\n", "            ", "sep", "=", "attention_mask", "\n", "# conventional transformer", "\n", "def", "build_mask_matrix", "(", "query_length", ",", "key_length", ",", "sep", ")", ":", "\n", "                ", "m", "=", "torch", ".", "ones", "(", "(", "1", ",", "query_length", ",", "key_length", ")", ",", "device", "=", "hidden_states", ".", "device", ",", "dtype", "=", "hidden_states", ".", "dtype", ")", "\n", "assert", "query_length", "<=", "key_length", "\n", "m", "[", "0", ",", ":", ",", "-", "query_length", ":", "]", "=", "torch", ".", "tril", "(", "m", "[", "0", ",", ":", ",", "-", "query_length", ":", "]", ")", "\n", "m", "[", "0", ",", ":", ",", ":", "sep", "+", "(", "key_length", "-", "query_length", ")", "]", "=", "1", "\n", "m", "=", "m", ".", "unsqueeze", "(", "1", ")", "\n", "return", "m", "\n", "", "attention_mask", "=", "build_mask_matrix", "(", "query_length", ",", "key_length", ",", "sep", ")", "\n", "\n", "", "if", "is_sparse", "==", "1", "and", "(", "self", ".", "rmask", "is", "None", ")", ":", "\n", "            ", "w", ",", "times", "=", "self", ".", "query_window", ",", "self", ".", "key_window_times", "\n", "g", "=", "key_length", "//", "w", "\n", "tmp", "=", "torch", ".", "ones", "(", "(", "g", "-", "times", "+", "1", ",", "w", ",", "w", ")", ",", "device", "=", "hidden_states", ".", "device", ",", "dtype", "=", "hidden_states", ".", "dtype", ")", "\n", "tmp", "=", "torch", ".", "tril", "(", "1", "-", "torch", ".", "block_diag", "(", "*", "tmp", ")", ")", "\n", "self", ".", "rmask", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "tmp", ",", "(", "0", ",", "(", "times", "-", "1", ")", "*", "w", ",", "(", "times", "-", "1", ")", "*", "w", ",", "0", ")", ")", "# pad (left, right, top, bottom)  ", "\n", "\n", "", "if", "is_sparse", "==", "2", ":", "\n", "            ", "left_boundary", "=", "max", "(", "0", ",", "key_length", "-", "self", ".", "key_window_times", "*", "self", ".", "query_window", ")", "\n", "window_idx", "=", "torch", ".", "arange", "(", "left_boundary", ",", "key_length", ",", "device", "=", "hidden_states", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", "", "elif", "is_sparse", "==", "1", ":", "\n", "            ", "left_boundary", "=", "key_length", "\n", "num_pivot", "=", "self", ".", "num_pivot", "\n", "\n", "# =====================   Image & Text Type Embedding   ======================== #", "\n", "# TODO: after testing, this is not useful.", "\n", "# extend_len = (key_length + 63) // 64", "\n", "# hidden_states = hidden_states + txt_indices_bool.unsqueeze(-1) * self.txt_type_embeddings.view(1, 1, -1) + \\", "\n", "#     img_indices_bool.unsqueeze(-1) * self.img_type_embeddings.expand(extend_len, 64, -1).reshape(extend_len * 64, -1)[memory_length: key_length]", "\n", "# ===================== END OF BLOCK ======================= #", "\n", "\n", "", "if", "is_sparse", ":", "# 1 or 2                ", "\n", "# select out the real indices for sampling", "\n", "            ", "img_indices", "=", "[", "img_indices_bool", "[", "i", "]", "[", ":", "left_boundary", "]", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "view", "(", "-", "1", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "txt_indices", "=", "[", "txt_indices_bool", "[", "i", "]", "[", ":", "left_boundary", "]", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "view", "(", "-", "1", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "", "if", "is_sparse", "==", "2", ":", "\n", "            ", "ratio", "=", "self", ".", "num_pivot", "/", "self", ".", "max_sequence_length", "\n", "max_text_num", "=", "max", "(", "len", "(", "text_idx", ")", "for", "text_idx", "in", "txt_indices", ")", "\n", "num_pivot", "=", "max_text_num", "+", "int", "(", "(", "left_boundary", "-", "max_text_num", ")", "*", "ratio", ")", "\n", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "hidden_states", "=", "hidden_states", "+", "position_embeddings", "\n", "hidden_states", "=", "self", ".", "embedding_dropout", "(", "hidden_states", ")", "\n", "\n", "if", "self", ".", "max_memory_length", ">", "0", ":", "\n", "            ", "mem_layers", "=", "[", "hidden_states", ".", "detach", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "mem_layers", "=", "[", "]", "\n", "", "def", "custom", "(", "start", ",", "end", ")", ":", "\n", "            ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                ", "layers_", "=", "self", ".", "layers", "[", "start", ":", "end", "]", "\n", "x_", ",", "inputs", "=", "inputs", "[", "0", "]", ",", "inputs", "[", "1", ":", "]", "\n", "\n", "if", "is_sparse", ">", "0", ":", "\n", "                    ", "inputs", ",", "mems_", "=", "inputs", "[", ":", "3", "]", ",", "inputs", "[", "3", ":", "]", "\n", "", "else", ":", "\n", "                    ", "inputs", ",", "mems_", "=", "inputs", "[", ":", "1", "]", ",", "inputs", "[", "1", ":", "]", "\n", "\n", "", "for", "i", ",", "layer", "in", "enumerate", "(", "layers_", ")", ":", "\n", "                    ", "mem_i_", "=", "mems_", "[", "i", "]", "if", "mems_", "else", "None", "\n", "x_", "=", "layer", "(", "x_", ",", "*", "inputs", ",", "mem", "=", "mem_i_", ")", "\n", "if", "self", ".", "max_memory_length", ">", "0", ":", "\n", "                        ", "mem_layers", ".", "append", "(", "x_", ".", "detach", "(", ")", ")", "\n", "", "", "return", "x_", "\n", "", "return", "custom_forward", "\n", "\n", "", "attention_mask_saved", "=", "attention_mask", "\n", "\n", "if", "self", ".", "checkpoint_activations", ":", "\n", "            ", "l", "=", "0", "\n", "num_layers", "=", "len", "(", "self", ".", "layers", ")", "\n", "chunk_length", "=", "self", ".", "checkpoint_num_layers", "\n", "while", "l", "<", "num_layers", ":", "\n", "                ", "if", "is_sparse", ">", "0", ":", "\n", "# =====================   Pivot Mask   ======================== #", "\n", "                    ", "pivot_idx", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "cat", "(", "(", "\n", "text_idx", ",", "\n", "img_indices", "[", "i", "]", "[", "\n", "torch", ".", "tensor", "(", "random", ".", "sample", "(", "range", "(", "len", "(", "img_indices", "[", "i", "]", ")", ")", ",", "k", "=", "num_pivot", "-", "len", "(", "text_idx", ")", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "text_idx", ".", "device", ")", "\n", "]", "\n", ")", ",", "dim", "=", "0", ")", "\n", "for", "i", ",", "text_idx", "in", "enumerate", "(", "txt_indices", ")", "\n", "]", ")", "\n", "if", "is_sparse", "==", "1", ":", "# sparse training", "\n", "                        ", "assert", "key_length", "==", "query_length", "\n", "b", ",", "s", "=", "batch_size", ",", "key_length", "\n", "pivot_attention_mask", "=", "self", ".", "rmask", ".", "expand", "(", "b", ",", "s", ",", "s", ")", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "pivot_idx", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "b", ",", "s", ",", "self", ".", "num_pivot", ")", ")", "\n", "args", "=", "[", "hidden_states", ",", "pivot_attention_mask", ",", "pivot_idx", ",", "torch", ".", "tensor", "(", "is_sparse", ")", "]", "\n", "", "elif", "is_sparse", "==", "2", ":", "# sparse inference", "\n", "                        ", "pw_idx", "=", "torch", ".", "cat", "(", "(", "pivot_idx", ",", "window_idx", ")", ",", "dim", "=", "-", "1", ")", "\n", "args", "=", "[", "hidden_states", ",", "attention_mask_saved", ",", "pw_idx", ",", "torch", ".", "tensor", "(", "is_sparse", ")", "]", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "# ===================== END OF BLOCK ======================= #", "\n", "", "", "else", ":", "\n", "                    ", "args", "=", "[", "hidden_states", ",", "attention_mask_saved", "]", "\n", "\n", "", "if", "mems", ":", "\n", "                    ", "args", "+=", "mems", "[", "l", ":", "l", "+", "chunk_length", "]", "\n", "\n", "", "hidden_states", "=", "checkpoint", "(", "custom", "(", "l", ",", "l", "+", "chunk_length", ")", ",", "*", "args", ")", "\n", "l", "+=", "chunk_length", "\n", "", "", "else", ":", "\n", "            ", "assert", "is_sparse", "!=", "1", ",", "'Please use checkpoint_activations for sparse attention training.'", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "if", "is_sparse", "==", "0", ":", "\n", "                    ", "args", "=", "[", "hidden_states", ",", "attention_mask_saved", "]", "\n", "", "elif", "is_sparse", "==", "2", ":", "\n", "                    ", "pivot_idx", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "cat", "(", "(", "\n", "text_idx", ",", "\n", "img_indices", "[", "i", "]", "[", "\n", "torch", ".", "tensor", "(", "random", ".", "sample", "(", "range", "(", "len", "(", "img_indices", "[", "i", "]", ")", ")", ",", "k", "=", "num_pivot", "-", "len", "(", "text_idx", ")", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "text_idx", ".", "device", ")", "\n", "]", "\n", ")", ",", "dim", "=", "0", ")", "\n", "for", "i", ",", "text_idx", "in", "enumerate", "(", "txt_indices", ")", "\n", "]", ")", "\n", "pw_idx", "=", "torch", ".", "cat", "(", "(", "pivot_idx", ",", "window_idx", ")", ",", "dim", "=", "-", "1", ")", "\n", "args", "=", "[", "hidden_states", ",", "attention_mask_saved", ",", "pw_idx", ",", "torch", ".", "tensor", "(", "is_sparse", ")", "]", "\n", "\n", "", "mem_i", "=", "mems", "[", "i", "]", "if", "mems", "else", "None", "\n", "hidden_states", "=", "layer", "(", "*", "args", ",", "mem", "=", "mem_i", ")", "\n", "if", "self", ".", "max_memory_length", ">", "0", ":", "\n", "                    ", "mem_layers", ".", "append", "(", "hidden_states", ".", "detach", "(", ")", ")", "\n", "\n", "# Final layer norm.", "\n", "", "", "", "output", "=", "self", ".", "final_layernorm", "(", "hidden_states", ")", "\n", "if", "self", ".", "max_memory_length", ">", "0", ":", "\n", "            ", "mem_layers", "=", "self", ".", "update_mems", "(", "mem_layers", ",", "mems", ")", "\n", "\n", "", "return", "(", "output", ",", "*", "mem_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.GPT2ParallelTransformer.update_mems": [[615, 627], ["hiddens[].size", "min", "mems[].size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "len", "new_mems.append", "new_mems.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "update_mems", "(", "self", ",", "hiddens", ",", "mems", ")", ":", "\n", "        ", "memory_length", "=", "mems", "[", "0", "]", ".", "size", "(", "1", ")", "if", "mems", "else", "0", "\n", "query_length", "=", "hiddens", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "new_memory_length", "=", "min", "(", "self", ".", "max_memory_length", ",", "memory_length", "+", "query_length", ")", "\n", "new_mems", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "hiddens", ")", ")", ":", "\n", "                ", "if", "new_memory_length", "<=", "query_length", ":", "\n", "                    ", "new_mems", ".", "append", "(", "hiddens", "[", "i", "]", "[", ":", ",", "-", "new_memory_length", ":", "]", ")", "\n", "", "else", ":", "\n", "                    ", "new_mems", ".", "append", "(", "torch", ".", "cat", "(", "(", "mems", "[", "i", "]", "[", ":", ",", "-", "new_memory_length", "+", "query_length", ":", "]", ",", "hiddens", "[", "i", "]", ")", ",", "dim", "=", "1", ")", ")", "\n", "", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.gelu_impl": [[172, 177], ["torch.tanh", "torch.tanh", "torch.tanh"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "gelu_impl", "(", "x", ")", ":", "\n", "     ", "\"\"\"OpenAI's gelu implementation.\"\"\"", "\n", "return", "0.5", "*", "x", "*", "(", "1.0", "+", "torch", ".", "tanh", "(", "0.7978845608028654", "*", "x", "*", "\n", "(", "1.0", "+", "0.044715", "*", "x", "*", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.gelu": [[178, 180], ["sparse_transformer.gelu_impl"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.gelu_impl"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "gelu_impl", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.elu1_impl": [[181, 185], ["torch.nn.functional.elu", "torch.nn.functional.elu", "torch.nn.functional.elu"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "elu1_impl", "(", "x", ")", ":", "\n", "     ", "\"\"\"OpenAI's gelu implementation.\"\"\"", "\n", "return", "torch", ".", "nn", ".", "functional", ".", "elu", "(", "x", ")", "+", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.elu1": [[186, 188], ["sparse_transformer.elu1_impl"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.elu1_impl"], ["", "def", "elu1", "(", "x", ")", ":", "\n", "    ", "return", "elu1_impl", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.unscaled_init_method": [[344, 350], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_"], "function", ["None"], ["", "", "def", "unscaled_init_method", "(", "sigma", ")", ":", "\n", "    ", "\"\"\"Init method based on N(0, sigma).\"\"\"", "\n", "def", "init_", "(", "tensor", ")", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "tensor", ",", "mean", "=", "0.0", ",", "std", "=", "sigma", ")", "\n", "\n", "", "return", "init_", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.scaled_init_method": [[352, 359], ["math.sqrt", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_"], "function", ["None"], ["", "def", "scaled_init_method", "(", "sigma", ",", "num_layers", ")", ":", "\n", "    ", "\"\"\"Init method based on N(0, sigma/sqrt(2*num_layers).\"\"\"", "\n", "std", "=", "sigma", "/", "math", ".", "sqrt", "(", "2.0", "*", "num_layers", ")", "\n", "def", "init_", "(", "tensor", ")", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "tensor", ",", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "\n", "", "return", "init_", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer._chunk": [[629, 651], ["x.view.size", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "x.view.view", "list", "list", "x.view.as_strided", "x.view.size", "x.view.size", "x.view.size", "x.view.size", "x.view.stride", "x.view.size"], "function", ["None"], ["", "", "def", "_chunk", "(", "x", ",", "w", ",", "times", ")", ":", "\n", "    ", "'''convert into overlapping chunkings. Chunk size = times * w, overlap size = w\n    Args:\n        x: [b, np, s, hn]\n        ...\n    '''", "\n", "s", "=", "x", ".", "size", "(", "2", ")", "\n", "# x pad to [b, np, s+xx to k*w + w*(times-1), hn]", "\n", "assert", "s", "%", "w", "==", "0", "\n", "npad", "=", "(", "times", "-", "1", ")", "*", "w", "\n", "x", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "npad", ",", "0", ")", ",", "value", "=", "0", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", "//", "w", ",", "w", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "\n", "chunk_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "chunk_stride", "=", "list", "(", "x", ".", "stride", "(", ")", ")", "\n", "\n", "chunk_size", "[", "2", "]", "=", "chunk_size", "[", "2", "]", "-", "times", "+", "1", "\n", "\n", "chunk_size", "[", "3", "]", "=", "w", "*", "times", "\n", "\n", "return", "x", ".", "as_strided", "(", "size", "=", "chunk_size", ",", "stride", "=", "chunk_stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.standard_attention": [[652, 674], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "len", "attention_mask.unsqueeze.unsqueeze", "key_layer.transpose", "torch.mul", "torch.mul", "torch.mul", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "math.sqrt", "random.get_cuda_rng_tracker().fork", "attention_dropout", "random.get_cuda_rng_tracker"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.fork", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker"], ["", "def", "standard_attention", "(", "query_layer", ",", "key_layer", ",", "value_layer", ",", "attention_mask", ",", "attention_dropout", "=", "None", ")", ":", "\n", "# We disable the PB-relax-Attention and only changes the order of computation, because it is enough for most of training. ", "\n", "# The implementation in the paper can be done very easily, if you really need it to train very deep transformers. ", "\n", "\n", "    ", "if", "len", "(", "attention_mask", ".", "shape", ")", "==", "3", ":", "\n", "        ", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", "\n", "# Raw attention scores. [b, np, s, s]", "\n", "", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", "/", "math", ".", "sqrt", "(", "query_layer", ".", "shape", "[", "-", "1", "]", ")", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "\n", "# Apply the left to right attention mask.", "\n", "attention_scores", "=", "torch", ".", "mul", "(", "attention_scores", ",", "attention_mask", ")", "-", "10000.0", "*", "(", "1.0", "-", "attention_mask", ")", "\n", "# Attention probabilities. [b, np, s, s]", "\n", "attention_probs", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "if", "attention_dropout", "is", "not", "None", ":", "\n", "        ", "with", "get_cuda_rng_tracker", "(", ")", ".", "fork", "(", ")", ":", "\n", "            ", "attention_probs", "=", "attention_dropout", "(", "attention_probs", ")", "\n", "# Context layer.", "\n", "# [b, np, s, hn]", "\n", "", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.sparse_attention": [[675, 726], ["pivot_idx.view().expand", "torch.matmul", "torch.matmul", "torch.matmul", "pivot_attention_mask.unsqueeze.unsqueeze", "sparse_transformer._chunk", "sparse_transformer._chunk", "attention_scores_window.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "pivot_k.transpose", "torch.mul", "torch.mul", "torch.mul", "math.log", "q.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.ones().tril_", "torch.ones().tril_", "torch.ones().tril_", "range", "ValueError", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.einsum().view", "torch.einsum().view", "torch.einsum().view", "pivot_idx.view", "_chunk.transpose", "torch.mul", "torch.mul", "torch.mul", "random.get_cuda_rng_tracker().fork", "attention_dropout", "math.sqrt", "torch.ones", "torch.ones", "torch.ones", "torch.einsum", "torch.einsum", "torch.einsum", "math.sqrt", "random.get_cuda_rng_tracker", "attention_probs[].view"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer._chunk", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer._chunk", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.fork", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker"], ["", "def", "sparse_attention", "(", "q", ",", "k", ",", "v", ",", "pivot_idx", ",", "pivot_attention_mask", ",", "query_window", "=", "128", ",", "key_window_times", "=", "6", ",", "attention_dropout", "=", "None", ")", ":", "\n", "    ", "''' Sparse Attention\n    Args:\n        q, k, v: inputs, [b, num_heads, s, hn], k is padded to n * query_window\n        pivot_idx: [b, num_pivots]\n        pivot_attention_mask: [b, s, num_pivots]\n        query_window: .\n        key_window_times: key_window = query_window * key_window_times\n    '''", "\n", "\n", "b", ",", "n_head", ",", "s", ",", "hn", "=", "q", ".", "shape", "\n", "b", ",", "n_piv", "=", "pivot_idx", ".", "shape", "\n", "w", "=", "query_window", "\n", "\n", "pivot_idx_dummy", "=", "pivot_idx", ".", "view", "(", "b", ",", "1", ",", "n_piv", ",", "1", ")", ".", "expand", "(", "b", ",", "n_head", ",", "n_piv", ",", "hn", ")", "\n", "# =====================   Pivot Attention   ======================== #", "\n", "pivot_k", ",", "pivot_v", "=", "torch", ".", "gather", "(", "k", ",", "2", ",", "pivot_idx_dummy", ")", ",", "torch", ".", "gather", "(", "v", ",", "2", ",", "pivot_idx_dummy", ")", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "q", ",", "pivot_k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "pivot_attention_mask", "=", "pivot_attention_mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "attention_scores_pivot", "=", "torch", ".", "mul", "(", "attention_scores", ",", "pivot_attention_mask", "/", "math", ".", "sqrt", "(", "hn", ")", ")", "-", "10000.0", "*", "(", "1.0", "-", "pivot_attention_mask", ")", "\n", "\n", "attention_scores_pivot", "=", "attention_scores_pivot", "+", "math", ".", "log", "(", "s", "//", "n_piv", ")", "\n", "# =====================   Window Attention   ======================= #", "\n", "window_k", "=", "_chunk", "(", "k", ",", "query_window", ",", "key_window_times", ")", "\n", "window_v", "=", "_chunk", "(", "v", ",", "query_window", ",", "key_window_times", ")", "\n", "# window_k [b, n_head, s // w up int, w*times, hn]", "\n", "\n", "if", "s", "%", "w", "==", "0", ":", "# training # TODO args check", "\n", "        ", "assert", "k", ".", "shape", "[", "2", "]", "==", "s", "\n", "assert", "window_k", ".", "shape", "[", "2", "]", "==", "s", "//", "w", "\n", "window_q", "=", "q", ".", "view", "(", "b", ",", "n_head", ",", "s", "//", "w", ",", "w", ",", "hn", ")", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "window_q", ",", "window_k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "window_attention_mask", "=", "torch", ".", "ones", "(", "(", "w", ",", "w", "*", "key_window_times", ")", ",", "dtype", "=", "attention_scores", ".", "dtype", ",", "device", "=", "q", ".", "device", ")", ".", "tril_", "(", "diagonal", "=", "w", "*", "(", "key_window_times", "-", "1", ")", ")", "\n", "attention_scores_window", "=", "torch", ".", "mul", "(", "attention_scores", ",", "window_attention_mask", "/", "math", ".", "sqrt", "(", "hn", ")", ")", "-", "10000.0", "*", "(", "1.0", "-", "window_attention_mask", ")", "\n", "for", "t", "in", "range", "(", "1", ",", "key_window_times", ")", ":", "\n", "            ", "attention_scores_window", "[", ":", ",", ":", ",", "t", "-", "1", ",", ":", ",", ":", "w", "*", "key_window_times", "-", "w", "*", "t", "]", "-=", "10000.0", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'The seq_len must be exactly divided by window_size.'", ")", "\n", "# =====================   Joint Softmax   ======================= #", "\n", "", "attention_scores_window", "=", "attention_scores_window", ".", "view", "(", "b", ",", "n_head", ",", "s", ",", "w", "*", "key_window_times", ")", "\n", "attention_scores", "=", "torch", ".", "cat", "(", "(", "attention_scores_pivot", ",", "attention_scores_window", ")", ",", "dim", "=", "-", "1", ")", "\n", "attention_probs", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "if", "attention_dropout", "is", "not", "None", ":", "\n", "        ", "with", "get_cuda_rng_tracker", "(", ")", ".", "fork", "(", ")", ":", "\n", "            ", "attention_probs", "=", "attention_dropout", "(", "attention_probs", ")", "\n", "\n", "", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", "[", "...", ",", ":", "-", "w", "*", "key_window_times", "]", ",", "pivot_v", ")", "+", "torch", ".", "einsum", "(", "'bcgwk,bcgkh->bcgwh'", ",", "attention_probs", "[", "...", ",", "-", "w", "*", "key_window_times", ":", "]", ".", "view", "(", "b", ",", "n_head", ",", "s", "//", "w", ",", "w", ",", "w", "*", "key_window_times", ")", ",", "window_v", ")", ".", "view", "(", "b", ",", "n_head", ",", "s", ",", "hn", ")", "\n", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.sparse_attention_inference": [[727, 751], ["pivot_and_window_idx.view().expand", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "pivot_k.transpose", "m.triu_", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "pivot_and_window_idx.view", "math.sqrt", "torch.ones", "torch.ones", "torch.ones"], "function", ["None"], ["", "def", "sparse_attention_inference", "(", "q", ",", "k", ",", "v", ",", "pivot_and_window_idx", ",", "**", "kwargs", ")", ":", "\n", "    ", "'''the inference process of sparse attention.\n    The Qs are in the same block, but seq_len mod window size might != 0.\n\n    The Qs are the final tokens of Ks. the pivot_and_window_idx[-query_len] are Qs.\n\n    '''", "\n", "b", ",", "n_head", ",", "sq", ",", "hn", "=", "q", ".", "shape", "\n", "sk", "=", "k", ".", "shape", "[", "2", "]", "\n", "_b", ",", "n_piv", "=", "pivot_and_window_idx", ".", "shape", "\n", "\n", "pivot_and_window_idx_dummy", "=", "pivot_and_window_idx", ".", "view", "(", "b", ",", "1", ",", "n_piv", ",", "1", ")", ".", "expand", "(", "b", ",", "n_head", ",", "n_piv", ",", "hn", ")", "\n", "pivot_k", ",", "pivot_v", "=", "torch", ".", "gather", "(", "k", ",", "2", ",", "pivot_and_window_idx_dummy", ")", ",", "torch", ".", "gather", "(", "v", ",", "2", ",", "pivot_and_window_idx_dummy", ")", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "q", "/", "math", ".", "sqrt", "(", "hn", ")", ",", "pivot_k", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "if", "sq", ">", "1", ":", "\n", "        ", "query_part_scores", "=", "attention_scores", "[", ":", ",", ":", ",", "-", "sq", ":", ",", "-", "sq", ":", "]", "\n", "m", "=", "torch", ".", "ones", "(", "(", "sq", ",", "sq", ")", ",", "device", "=", "q", ".", "device", ",", "dtype", "=", "q", ".", "dtype", ")", "*", "-", "10000.", "\n", "m", ".", "triu_", "(", "diagonal", "=", "1", ")", "\n", "query_part_scores", "+=", "m", "\n", "\n", "", "attention_probs", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "pivot_v", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.test_sparse_attention": [[753, 820], ["torch.rand", "torch.rand", "torch.rand", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.ones", "torch.ones", "torch.ones", "torch.tril", "torch.tril", "torch.tril", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad.expand().gather", "range", "sparse_transformer.standard_attention", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "time.time", "sparse_transformer.standard_attention", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "time.time", "sparse_transformer.sparse_attention", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "time.time", "print", "print", "torch.rand.retain_grad", "sparse_attention.mean", "standard_attention.mean", "r2.mean.backward", "r1.mean.backward", "print", "torch.rand.cpu().detach().numpy", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.ones", "torch.ones", "torch.ones", "real_mask[].tril_", "torch.cat", "torch.cat", "torch.cat", "torch.block_diag", "torch.block_diag", "torch.block_diag", "torch.nn.functional.pad.expand", "torch.stack.unsqueeze().expand", "torch.rand.cpu().detach", "enumerate", "torch.stack.unsqueeze", "torch.rand.cpu", "standard_attention.abs", "sparse_attention.abs", "torch.tensor", "torch.tensor", "torch.tensor", "random.sample", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.standard_attention", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.standard_attention", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.sparse_transformer.sparse_attention", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward"], ["", "def", "test_sparse_attention", "(", ")", ":", "\n", "\n", "    ", "s", ",", "w", ",", "times", "=", "4096", "+", "128", ",", "128", ",", "2", "\n", "num_pivot", "=", "768", "\n", "b", "=", "2", "\n", "g", "=", "s", "//", "w", "\n", "\n", "q", ",", "k", ",", "v", "=", "raw", "=", "torch", ".", "rand", "(", "3", ",", "b", ",", "16", ",", "s", ",", "64", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "'cuda'", ",", "requires_grad", "=", "True", ")", "\n", "q1", ",", "k1", ",", "v1", "=", "raw1", "=", "torch", ".", "tensor", "(", "raw", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "'cuda'", ",", "requires_grad", "=", "True", ")", "\n", "txt_indices", "=", "[", "torch", ".", "arange", "(", "0", ",", "128", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", ",", "torch", ".", "arange", "(", "0", ",", "22", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", "]", "\n", "img_indices", "=", "[", "torch", ".", "arange", "(", "128", ",", "s", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", ",", "torch", ".", "arange", "(", "22", ",", "s", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "'cuda'", ")", "]", "\n", "\n", "pivot_idx", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "cat", "(", "(", "\n", "text_idx", ",", "\n", "img_indices", "[", "i", "]", "[", "\n", "torch", ".", "tensor", "(", "random", ".", "sample", "(", "range", "(", "len", "(", "img_indices", "[", "i", "]", ")", "-", "times", "*", "w", ")", ",", "k", "=", "num_pivot", "-", "len", "(", "text_idx", ")", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "text_idx", ".", "device", ")", "\n", "]", "\n", ")", ",", "dim", "=", "0", ")", "\n", "for", "i", ",", "text_idx", "in", "enumerate", "(", "txt_indices", ")", "\n", "]", ")", "# -times * w to verify inference", "\n", "\n", "tmp", "=", "torch", ".", "ones", "(", "(", "g", "-", "times", "+", "1", ",", "w", ",", "w", ")", ",", "device", "=", "'cuda'", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "tmp", "=", "torch", ".", "tril", "(", "1", "-", "torch", ".", "block_diag", "(", "*", "tmp", ")", ")", "\n", "rmask", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "tmp", ",", "(", "0", ",", "(", "times", "-", "1", ")", "*", "w", ",", "(", "times", "-", "1", ")", "*", "w", ",", "0", ")", ")", "# pad (left, right, top, bottom)", "\n", "\n", "pivot_attention_mask", "=", "rmask", ".", "expand", "(", "b", ",", "s", ",", "s", ")", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "pivot_idx", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "b", ",", "s", ",", "num_pivot", ")", ")", "\n", "\n", "real_mask", "=", "torch", ".", "ones", "(", "(", "b", ",", "s", ",", "s", ")", ",", "device", "=", "'cuda'", ",", "dtype", "=", "torch", ".", "long", ")", "-", "rmask", "\n", "for", "i", "in", "range", "(", "b", ")", ":", "\n", "        ", "real_mask", "[", "i", "]", "[", ":", ",", "pivot_idx", "[", "i", "]", "]", "=", "1", "\n", "real_mask", "[", "i", "]", ".", "tril_", "(", ")", "\n", "\n", "# test inference", "\n", "\n", "# q_part = q[..., -1:, :]", "\n", "# r0 = standard_attention(q, k, v, real_mask)", "\n", "# r0 = r0[..., -1:, :]", "\n", "# pw_idx = torch.cat((pivot_idx, torch.arange(s-times*w, s, device='cuda', dtype=torch.long).expand(b, -1)), dim=-1)", "\n", "\n", "# r1 = sparse_attention_inference(q_part, k, v, pw_idx)", "\n", "# print(( (r1-r0).abs() / (r1.abs()+r0.abs())).max())", "\n", "\n", "", "import", "time", "\n", "\n", "r0", "=", "standard_attention", "(", "q1", ",", "k1", ",", "v1", ",", "real_mask", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "r1", "=", "standard_attention", "(", "q1", ",", "k1", ",", "v1", ",", "real_mask", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "r2", "=", "sparse_attention", "(", "q", ",", "k", ",", "v", ",", "pivot_idx", ",", "pivot_attention_mask", ",", "w", ",", "times", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'times: standard '", ",", "t1", "-", "t0", ",", "' sparse '", ",", "t2", "-", "t1", ")", "\n", "\n", "print", "(", "(", "(", "r1", "-", "r2", ")", ".", "abs", "(", ")", "/", "(", "r1", ".", "abs", "(", ")", "+", "r2", ".", "abs", "(", ")", ")", ")", ".", "max", "(", ")", ")", "\n", "\n", "raw", ".", "retain_grad", "(", ")", "\n", "l2", "=", "r2", ".", "mean", "(", ")", "\n", "l1", "=", "r1", ".", "mean", "(", ")", "\n", "l2", ".", "backward", "(", ")", "\n", "l1", ".", "backward", "(", ")", "\n", "\n", "g1", "=", "raw1", ".", "grad", "\n", "g2", "=", "raw", ".", "grad", "\n", "print", "(", "(", "g1", "-", "g2", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.initialize_model_parallel": [[30, 79], ["torch.distributed.is_initialized", "torch.distributed.get_world_size", "min", "utils.ensure_divisibility", "torch.distributed.get_rank", "range", "range", "torch.distributed.get_rank", "print", "range", "torch.distributed.new_group", "range", "torch.distributed.new_group"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.ensure_divisibility", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["def", "initialize_model_parallel", "(", "model_parallel_size_", ")", ":", "\n", "    ", "\"\"\"\n    Initialize model data parallel groups.\n\n    Arguments:\n        model_parallel_size: number of GPUs used to parallelize model.\n\n    Let's say we have a total of 8 GPUs denoted by g0 ... g7 and we\n    use 2 GPUs to parallelize the model. The present function will\n    create 4 model parallel groups and 2 data parallel grous as:\n        4 model parallel groups:\n            [g0, g1], [g2, g3], [g4, g5], [g6, g7]\n        2 data parallel groups:\n            [g0, g2, g4, g6], [g1, g3, g5, g7]\n    Note that for efficiency, the caller should make sure adjacent ranks\n    are on the same DGX box. For example if we are using 2 DGX-1 boxes\n    with a total of 16 GPUs, rank 0 to 7 belong to the first box and\n    ranks 8 to 15 belong to the second box.\n    \"\"\"", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "'> initializing model parallel with size {}'", ".", "format", "(", "\n", "model_parallel_size_", ")", ")", "\n", "# Get world size and rank. Ensure some consistencies.", "\n", "", "assert", "torch", ".", "distributed", ".", "is_initialized", "(", ")", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "model_parallel_size", "=", "min", "(", "model_parallel_size_", ",", "world_size", ")", "\n", "ensure_divisibility", "(", "world_size", ",", "model_parallel_size", ")", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "\n", "# Build the data parallel groups.", "\n", "global", "_DATA_PARALLEL_GROUP", "\n", "assert", "_DATA_PARALLEL_GROUP", "is", "None", ",", "'data parallel group is already initialized'", "\n", "for", "i", "in", "range", "(", "model_parallel_size", ")", ":", "\n", "        ", "ranks", "=", "range", "(", "i", ",", "world_size", ",", "model_parallel_size", ")", "\n", "group", "=", "torch", ".", "distributed", ".", "new_group", "(", "ranks", ")", "\n", "if", "i", "==", "(", "rank", "%", "model_parallel_size", ")", ":", "\n", "            ", "_DATA_PARALLEL_GROUP", "=", "group", "\n", "\n", "# Build the model parallel groups.", "\n", "", "", "global", "_MODEL_PARALLEL_GROUP", "\n", "assert", "_MODEL_PARALLEL_GROUP", "is", "None", ",", "'model parallel group is already initialized'", "\n", "for", "i", "in", "range", "(", "world_size", "//", "model_parallel_size", ")", ":", "\n", "        ", "ranks", "=", "range", "(", "i", "*", "model_parallel_size", ",", "\n", "(", "i", "+", "1", ")", "*", "model_parallel_size", ")", "\n", "group", "=", "torch", ".", "distributed", ".", "new_group", "(", "ranks", ")", "\n", "if", "i", "==", "(", "rank", "//", "model_parallel_size", ")", ":", "\n", "            ", "_MODEL_PARALLEL_GROUP", "=", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.model_parallel_is_initialized": [[81, 86], ["None"], "function", ["None"], ["", "", "", "def", "model_parallel_is_initialized", "(", ")", ":", "\n", "    ", "\"\"\"Check if model and data parallel groups are initialized.\"\"\"", "\n", "if", "_MODEL_PARALLEL_GROUP", "is", "None", "or", "_DATA_PARALLEL_GROUP", "is", "None", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group": [[88, 93], ["None"], "function", ["None"], ["", "def", "get_model_parallel_group", "(", ")", ":", "\n", "    ", "\"\"\"Get the model parallel group the caller rank belongs to.\"\"\"", "\n", "assert", "_MODEL_PARALLEL_GROUP", "is", "not", "None", ",", "'model parallel group is not initialized'", "\n", "return", "_MODEL_PARALLEL_GROUP", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group": [[95, 100], ["None"], "function", ["None"], ["", "def", "get_data_parallel_group", "(", ")", ":", "\n", "    ", "\"\"\"Get the data parallel group the caller rank belongs to.\"\"\"", "\n", "assert", "_DATA_PARALLEL_GROUP", "is", "not", "None", ",", "'data parallel group is not initialized'", "\n", "return", "_DATA_PARALLEL_GROUP", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size": [[102, 105], ["torch.distributed.get_world_size", "initialize.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group"], ["", "def", "get_model_parallel_world_size", "(", ")", ":", "\n", "    ", "\"\"\"Return world size for the model parallel group.\"\"\"", "\n", "return", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank": [[107, 110], ["torch.distributed.get_rank", "initialize.get_model_parallel_group"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group"], ["", "def", "get_model_parallel_rank", "(", ")", ":", "\n", "    ", "\"\"\"Return my rank for the model parallel group.\"\"\"", "\n", "return", "torch", ".", "distributed", ".", "get_rank", "(", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_src_rank": [[112, 118], ["torch.distributed.get_rank", "initialize.get_model_parallel_world_size"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size"], ["", "def", "get_model_parallel_src_rank", "(", ")", ":", "\n", "    ", "\"\"\"Calculate the global rank corresponding to a local rank zeor\n    in the model parallel group.\"\"\"", "\n", "global_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "local_world_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "return", "(", "global_rank", "//", "local_world_size", ")", "*", "local_world_size", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_world_size": [[120, 123], ["torch.distributed.get_world_size", "initialize.get_data_parallel_group"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group"], ["", "def", "get_data_parallel_world_size", "(", ")", ":", "\n", "    ", "\"\"\"Return world size for the data parallel group.\"\"\"", "\n", "return", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "get_data_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank": [[125, 128], ["torch.distributed.get_rank", "initialize.get_data_parallel_group"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_group"], ["", "def", "get_data_parallel_rank", "(", ")", ":", "\n", "    ", "\"\"\"Return my rank for the data parallel group.\"\"\"", "\n", "return", "torch", ".", "distributed", ".", "get_rank", "(", "group", "=", "get_data_parallel_group", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.destroy_model_parallel": [[130, 136], ["None"], "function", ["None"], ["", "def", "destroy_model_parallel", "(", ")", ":", "\n", "    ", "\"\"\"Set the groups to none.\"\"\"", "\n", "global", "_MODEL_PARALLEL_GROUP", "\n", "_MODEL_PARALLEL_GROUP", "=", "None", "\n", "global", "_DATA_PARALLEL_GROUP", "\n", "_DATA_PARALLEL_GROUP", "=", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.data._check_data_types": [[26, 31], ["None"], "function", ["None"], ["def", "_check_data_types", "(", "keys", ",", "data", ",", "target_dtype", ")", ":", "\n", "    ", "\"\"\"Check that all the keys have the same target data type.\"\"\"", "\n", "for", "key", "in", "keys", ":", "\n", "        ", "assert", "data", "[", "key", "]", ".", "dtype", "==", "target_dtype", ",", "'{} has data type {} which '", "'is different than {}'", ".", "format", "(", "key", ",", "data", "[", "key", "]", ".", "dtype", ",", "target_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.data._build_key_size_numel_dictionaries": [[33, 74], ["torch.cuda.LongTensor", "torch.distributed.broadcast", "torch.cuda.LongTensor.cpu", "initialize.get_model_parallel_rank", "initialize.get_model_parallel_src_rank", "range", "data[].size", "enumerate", "initialize.get_model_parallel_group", "data[].size.append", "data[].dim"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_src_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group"], ["", "", "def", "_build_key_size_numel_dictionaries", "(", "keys", ",", "data", ")", ":", "\n", "    ", "\"\"\"Build the size on rank 0 and broadcast.\"\"\"", "\n", "max_dim", "=", "_MAX_DATA_DIM", "\n", "sizes", "=", "[", "0", "for", "_", "in", "range", "(", "max_dim", ")", "for", "_", "in", "keys", "]", "\n", "\n", "# Pack the sizes on rank zero.", "\n", "if", "get_model_parallel_rank", "(", ")", "==", "0", ":", "\n", "        ", "offset", "=", "0", "\n", "for", "key", "in", "keys", ":", "\n", "            ", "assert", "data", "[", "key", "]", ".", "dim", "(", ")", "<", "max_dim", ",", "'you should increase MAX_DATA_DIM'", "\n", "size", "=", "data", "[", "key", "]", ".", "size", "(", ")", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "size", ")", ":", "\n", "                ", "sizes", "[", "i", "+", "offset", "]", "=", "s", "\n", "", "offset", "+=", "max_dim", "\n", "\n", "# Move to GPU and broadcast.", "\n", "", "", "sizes_cuda", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "sizes", ")", "\n", "torch", ".", "distributed", ".", "broadcast", "(", "sizes_cuda", ",", "get_model_parallel_src_rank", "(", ")", ",", "\n", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "\n", "# Move back to cpu and unpack.", "\n", "sizes_cpu", "=", "sizes_cuda", ".", "cpu", "(", ")", "\n", "key_size", "=", "{", "}", "\n", "key_numel", "=", "{", "}", "\n", "total_numel", "=", "0", "\n", "offset", "=", "0", "\n", "for", "key", "in", "keys", ":", "\n", "        ", "i", "=", "0", "\n", "size", "=", "[", "]", "\n", "numel", "=", "1", "\n", "while", "sizes_cpu", "[", "offset", "+", "i", "]", ">", "0", ":", "\n", "            ", "this_size", "=", "sizes_cpu", "[", "offset", "+", "i", "]", "\n", "size", ".", "append", "(", "this_size", ")", "\n", "numel", "*=", "this_size", "\n", "i", "+=", "1", "\n", "", "key_size", "[", "key", "]", "=", "size", "\n", "key_numel", "[", "key", "]", "=", "numel", "\n", "total_numel", "+=", "numel", "\n", "offset", "+=", "max_dim", "\n", "\n", "", "return", "key_size", ",", "key_numel", ",", "total_numel", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.data.broadcast_data": [[76, 117], ["data._build_key_size_numel_dictionaries", "torch.distributed.broadcast", "initialize.get_model_parallel_rank", "data._check_data_types", "torch.cat().cuda", "torch.empty", "initialize.get_model_parallel_src_rank", "torch.empty.narrow().view", "initialize.get_model_parallel_group", "torch.cat", "torch.cuda.current_device", "torch.empty.narrow", "data[].contiguous().view", "data[].contiguous"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.data._build_key_size_numel_dictionaries", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.data._check_data_types", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_src_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group"], ["", "def", "broadcast_data", "(", "keys", ",", "data", ",", "datatype", ")", ":", "\n", "    ", "\"\"\"Broadcast data from rank zero of each model parallel group to the\n    members of the same model parallel group.\n\n    Arguments:\n        keys: list of keys in the data disctionary to be broadcasted\n        data: data dictionary of string keys and cpu tensor values.\n        datatype: torch data type of all tensors in data associated\n                  with keys.\n    \"\"\"", "\n", "# Build (key, size) and (key, number of elements) dictionaries along", "\n", "# with the total number of elements on all ranks.", "\n", "key_size", ",", "key_numel", ",", "total_numel", "=", "_build_key_size_numel_dictionaries", "(", "keys", ",", "\n", "data", ")", "\n", "\n", "# Pack on rank zero.", "\n", "if", "get_model_parallel_rank", "(", ")", "==", "0", ":", "\n", "# Check that all keys have the same data type.", "\n", "        ", "_check_data_types", "(", "keys", ",", "data", ",", "datatype", ")", "\n", "# Flatten the data associated with the keys", "\n", "flatten_data", "=", "torch", ".", "cat", "(", "\n", "[", "data", "[", "key", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "for", "key", "in", "keys", "]", ",", "dim", "=", "0", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "flatten_data", "=", "torch", ".", "empty", "(", "total_numel", ",", "\n", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", ",", "\n", "dtype", "=", "datatype", ")", "\n", "\n", "# Boradcast", "\n", "", "torch", ".", "distributed", ".", "broadcast", "(", "flatten_data", ",", "get_model_parallel_src_rank", "(", ")", ",", "\n", "group", "=", "get_model_parallel_group", "(", ")", ")", "\n", "\n", "# Unpack", "\n", "output", "=", "{", "}", "\n", "offset", "=", "0", "\n", "for", "key", "in", "keys", ":", "\n", "        ", "size", "=", "key_size", "[", "key", "]", "\n", "numel", "=", "key_numel", "[", "key", "]", "\n", "output", "[", "key", "]", "=", "flatten_data", ".", "narrow", "(", "0", ",", "offset", ",", "numel", ")", ".", "view", "(", "size", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.VocabParallelEmbedding.__init__": [[87, 116], ["super().__init__", "utils.VocabUtility.vocab_range_from_global_vocab_size", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "layers._initialize_affine_weight", "initialize.get_model_parallel_rank", "initialize.get_model_parallel_world_size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.VocabUtility.vocab_range_from_global_vocab_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers._initialize_affine_weight", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size"], ["def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "\n", "init_method", "=", "init", ".", "xavier_normal_", ")", ":", "\n", "        ", "super", "(", "VocabParallelEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Keep the input dimensions.", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "# Set the detauls for compatibility.", "\n", "self", ".", "padding_idx", "=", "None", "\n", "self", ".", "max_norm", "=", "None", "\n", "self", ".", "norm_type", "=", "2.", "\n", "self", ".", "scale_grad_by_freq", "=", "False", "\n", "self", ".", "sparse", "=", "False", "\n", "self", ".", "_weight", "=", "None", "\n", "# Divide the weight matrix along the vocaburaly dimension.", "\n", "self", ".", "vocab_start_index", ",", "self", ".", "vocab_end_index", "=", "VocabUtility", ".", "vocab_range_from_global_vocab_size", "(", "\n", "self", ".", "num_embeddings", ",", "get_model_parallel_rank", "(", ")", ",", "\n", "get_model_parallel_world_size", "(", ")", ")", "\n", "self", ".", "num_embeddings_per_partition", "=", "self", ".", "vocab_end_index", "-", "self", ".", "vocab_start_index", "\n", "\n", "# Allocate weights.", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_embeddings_per_partition", ",", "\n", "self", ".", "embedding_dim", ")", ")", "\n", "self", ".", "weight", ".", "model_parallel", "=", "True", "\n", "# And initialize.", "\n", "_initialize_affine_weight", "(", "\n", "self", ".", "weight", ",", "self", ".", "num_embeddings", ",", "self", ".", "embedding_dim", ",", "\n", "self", ".", "num_embeddings_per_partition", ",", "0", ",", "init_method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.VocabParallelEmbedding.forward": [[117, 134], ["torch.embedding", "torch.embedding", "torch.embedding", "mappings.reduce_from_model_parallel_region", "input_.clone"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.reduce_from_model_parallel_region"], ["", "def", "forward", "(", "self", ",", "input_", ")", ":", "\n", "# Build the mask.", "\n", "        ", "input_mask", "=", "(", "input_", "<", "self", ".", "vocab_start_index", ")", "|", "(", "input_", ">=", "self", ".", "vocab_end_index", ")", "\n", "# Mask the input.", "\n", "masked_input", "=", "input_", ".", "clone", "(", ")", "-", "self", ".", "vocab_start_index", "\n", "masked_input", "[", "input_mask", "]", "=", "0", "\n", "# Get the embeddings.", "\n", "output_parallel", "=", "F", ".", "embedding", "(", "masked_input", ",", "self", ".", "weight", ",", "\n", "self", ".", "padding_idx", ",", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "self", ".", "scale_grad_by_freq", ",", "\n", "self", ".", "sparse", ")", "\n", "# Mask the output embedding.", "\n", "output_parallel", "[", "input_mask", ",", ":", "]", "=", "0.0", "\n", "# Reduce across all the model parallel GPUs.", "\n", "output", "=", "reduce_from_model_parallel_region", "(", "output_parallel", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.ParallelEmbedding.__init__": [[146, 174], ["super().__init__", "initialize.get_model_parallel_world_size", "utils.divide", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "layers._initialize_affine_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers._initialize_affine_weight"], ["def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "\n", "init_method", "=", "init", ".", "xavier_normal_", ",", "\n", "keep_master_weight_for_test", "=", "False", ")", ":", "\n", "        ", "super", "(", "ParallelEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Keep the input dimensions.", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "# Set some detauls for compatibility.", "\n", "self", ".", "padding_idx", "=", "None", "\n", "self", ".", "max_norm", "=", "None", "\n", "self", ".", "norm_type", "=", "2.", "\n", "self", ".", "scale_grad_by_freq", "=", "False", "\n", "self", ".", "sparse", "=", "False", "\n", "self", ".", "_weight", "=", "None", "\n", "# Divide the weight matrix along the embedding dimension.", "\n", "world_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "self", ".", "embedding_dim_per_partition", "=", "divide", "(", "self", ".", "embedding_dim", ",", "\n", "world_size", ")", "\n", "\n", "# Allocate weights.", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_embeddings", ",", "\n", "self", ".", "embedding_dim_per_partition", ")", ")", "\n", "self", ".", "weight", ".", "model_parallel", "=", "True", "\n", "# And initialize.", "\n", "_initialize_affine_weight", "(", "\n", "self", ".", "weight", ",", "self", ".", "num_embeddings", ",", "self", ".", "embedding_dim", ",", "\n", "self", ".", "embedding_dim_per_partition", ",", "1", ",", "init_method", ",", "\n", "stride", "=", "1", ",", "return_master_weight", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.ParallelEmbedding.forward": [[175, 183], ["mappings.copy_to_model_parallel_region", "torch.embedding", "torch.embedding", "torch.embedding", "mappings.gather_from_model_parallel_region"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.copy_to_model_parallel_region", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.gather_from_model_parallel_region"], ["", "def", "forward", "(", "self", ",", "input_", ")", ":", "\n", "        ", "input_parallel", "=", "copy_to_model_parallel_region", "(", "input_", ")", "\n", "output_parallel", "=", "F", ".", "embedding", "(", "input_parallel", ",", "self", ".", "weight", ",", "\n", "self", ".", "padding_idx", ",", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "self", ".", "scale_grad_by_freq", ",", "\n", "self", ".", "sparse", ")", "\n", "output", "=", "gather_from_model_parallel_region", "(", "output_parallel", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.ColumnParallelLinear.__init__": [[205, 238], ["super().__init__", "initialize.get_model_parallel_world_size", "utils.divide", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "layers._initialize_affine_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "layers.ColumnParallelLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "layers.ColumnParallelLinear.bias.zero_"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers._initialize_affine_weight"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "bias", "=", "True", ",", "gather_output", "=", "True", ",", "\n", "init_method", "=", "init", ".", "xavier_normal_", ",", "stride", "=", "1", ",", "\n", "keep_master_weight_for_test", "=", "False", ")", ":", "\n", "        ", "super", "(", "ColumnParallelLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Keep input parameters", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "gather_output", "=", "gather_output", "\n", "# Divide the weight matrix along the last dimension.", "\n", "world_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "self", ".", "output_size_per_partition", "=", "divide", "(", "output_size", ",", "world_size", ")", "\n", "\n", "# Parameters.", "\n", "# Note: torch.nn.functional.linear performs XA^T + b and as a result", "\n", "# we allocate the transpose.", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "output_size_per_partition", ",", "\n", "self", ".", "input_size", ")", ")", "\n", "self", ".", "weight", ".", "model_parallel", "=", "True", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "output_size_per_partition", ")", ")", "\n", "self", ".", "bias", ".", "model_parallel", "=", "True", "\n", "# Always initialize bias to zero.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "bias", ".", "zero_", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "# Initialize weight.", "\n", "", "self", ".", "master_weight", "=", "_initialize_affine_weight", "(", "\n", "self", ".", "weight", ",", "self", ".", "output_size", ",", "self", ".", "input_size", ",", "\n", "self", ".", "output_size_per_partition", ",", "0", ",", "init_method", ",", "\n", "stride", "=", "stride", ",", "return_master_weight", "=", "keep_master_weight_for_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.ColumnParallelLinear.forward": [[239, 250], ["mappings.copy_to_model_parallel_region", "torch.linear", "torch.linear", "torch.linear", "mappings.gather_from_model_parallel_region"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.copy_to_model_parallel_region", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.gather_from_model_parallel_region"], ["", "def", "forward", "(", "self", ",", "input_", ")", ":", "\n", "# Set up backprop all-reduce.", "\n", "        ", "input_parallel", "=", "copy_to_model_parallel_region", "(", "input_", ")", "\n", "# Matrix multiply.", "\n", "output_parallel", "=", "F", ".", "linear", "(", "input_parallel", ",", "self", ".", "weight", ",", "self", ".", "bias", ")", "\n", "if", "self", ".", "gather_output", ":", "\n", "# All-gather across the partitions.", "\n", "            ", "output", "=", "gather_from_model_parallel_region", "(", "output_parallel", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "output_parallel", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.RowParallelLinear.__init__": [[278, 311], ["super().__init__", "initialize.get_model_parallel_world_size", "utils.divide", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "layers._initialize_affine_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "layers.RowParallelLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "layers.RowParallelLinear.bias.zero_"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers._initialize_affine_weight"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "bias", "=", "True", ",", "\n", "input_is_parallel", "=", "False", ",", "\n", "init_method", "=", "init", ".", "xavier_normal_", ",", "stride", "=", "1", ",", "\n", "keep_master_weight_for_test", "=", "False", ")", ":", "\n", "        ", "super", "(", "RowParallelLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Keep input parameters", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "input_is_parallel", "=", "input_is_parallel", "\n", "# Divide the weight matrix along the last dimension.", "\n", "world_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "self", ".", "input_size_per_partition", "=", "divide", "(", "input_size", ",", "world_size", ")", "\n", "\n", "# Parameters.", "\n", "# Note: torch.nn.functional.linear performs XA^T + b and as a result", "\n", "# we allocate the transpose.", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "output_size", ",", "\n", "self", ".", "input_size_per_partition", ")", ")", "\n", "self", ".", "weight", ".", "model_parallel", "=", "True", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "output_size", ")", ")", "\n", "# Always initialize bias to zero.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "bias", ".", "zero_", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "# Initialize weight.", "\n", "", "self", ".", "master_weight", "=", "_initialize_affine_weight", "(", "\n", "self", ".", "weight", ",", "self", ".", "output_size", ",", "self", ".", "input_size", ",", "\n", "self", ".", "input_size_per_partition", ",", "1", ",", "init_method", ",", "\n", "stride", "=", "stride", ",", "return_master_weight", "=", "keep_master_weight_for_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers.RowParallelLinear.forward": [[312, 327], ["torch.linear", "torch.linear", "torch.linear", "mappings.reduce_from_model_parallel_region", "mappings.scatter_to_model_parallel_region"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.reduce_from_model_parallel_region", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.mappings.scatter_to_model_parallel_region"], ["", "def", "forward", "(", "self", ",", "input_", ")", ":", "\n", "# Set up backprop all-reduce.", "\n", "        ", "if", "self", ".", "input_is_parallel", ":", "\n", "            ", "input_parallel", "=", "input_", "\n", "", "else", ":", "\n", "            ", "input_parallel", "=", "scatter_to_model_parallel_region", "(", "input_", ")", "\n", "# Matrix multiply.", "\n", "", "output_parallel", "=", "F", ".", "linear", "(", "input_parallel", ",", "self", ".", "weight", ")", "\n", "# All-reduce across all the partitions.", "\n", "output_", "=", "reduce_from_model_parallel_region", "(", "output_parallel", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output_", "+", "self", ".", "bias", "\n", "", "else", ":", "\n", "            ", "output", "=", "output_", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.layers._initialize_affine_weight": [[42, 75], ["initialize.get_model_parallel_world_size", "torch.empty", "torch.empty", "torch.empty", "init_method", "utils.divide", "torch.split", "torch.split", "torch.split", "initialize.get_model_parallel_rank", "init_method", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.cat", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank"], ["def", "_initialize_affine_weight", "(", "weight", ",", "output_size", ",", "input_size", ",", "\n", "per_partition_size", ",", "partition_dim", ",", "init_method", ",", "\n", "stride", "=", "1", ",", "return_master_weight", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initialize affine weight for model parallel.\n\n    Build the master weight on all processes and scatter\n    the relevant chunk.\"\"\"", "\n", "# If we only use 1 process for model parallelism, bypass scatter.", "\n", "world_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "init_method", "(", "weight", ")", "\n", "if", "return_master_weight", ":", "\n", "            ", "return", "weight", "\n", "", "return", "None", "\n", "\n", "# Initialize master weight", "\n", "", "master_weight", "=", "torch", ".", "empty", "(", "output_size", ",", "input_size", ",", "\n", "dtype", "=", "weight", ".", "dtype", ",", "\n", "requires_grad", "=", "False", ")", "\n", "init_method", "(", "master_weight", ")", "\n", "\n", "# Split and copy", "\n", "per_partition_per_stride_size", "=", "divide", "(", "per_partition_size", ",", "stride", ")", "\n", "weight_list", "=", "torch", ".", "split", "(", "master_weight", ",", "per_partition_per_stride_size", ",", "\n", "dim", "=", "partition_dim", ")", "\n", "rank", "=", "get_model_parallel_rank", "(", ")", "\n", "my_weight_list", "=", "weight_list", "[", "rank", ":", ":", "world_size", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "torch", ".", "cat", "(", "my_weight_list", ",", "dim", "=", "partition_dim", ",", "out", "=", "weight", ")", "\n", "", "if", "return_master_weight", ":", "\n", "        ", "return", "master_weight", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.__init__": [[127, 132], ["set"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Map from a string name to the cuda rng state.", "\n", "        ", "self", ".", "states_", "=", "{", "}", "\n", "# Seeds are just for book keeping and ensure no seed is set twice.", "\n", "self", ".", "seeds_", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.reset": [[133, 137], ["set"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set to the initial state (no tracker).\"\"\"", "\n", "self", ".", "states_", "=", "{", "}", "\n", "self", ".", "seeds_", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.get_states": [[138, 145], ["None"], "methods", ["None"], ["", "def", "get_states", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get rng states. Copy the dictionary so we have direct\n        pointers to the states, not just a pointer to the dictionary.\"\"\"", "\n", "states", "=", "{", "}", "\n", "for", "name", "in", "self", ".", "states_", ":", "\n", "            ", "states", "[", "name", "]", "=", "self", ".", "states_", "[", "name", "]", "\n", "", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.set_states": [[146, 150], ["None"], "methods", ["None"], ["", "def", "set_states", "(", "self", ",", "states", ")", ":", "\n", "        ", "\"\"\"Set the rng states. For efficiency purposes, we do not check\n        the size of seed for compatibility.\"\"\"", "\n", "self", ".", "states_", "=", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.add": [[151, 167], ["random.CudaRNGStatesTracker.seeds_.add", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "random._set_cuda_rng_state", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.add", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random._set_cuda_rng_state"], ["", "def", "add", "(", "self", ",", "name", ",", "seed", ")", ":", "\n", "        ", "\"\"\"Track the rng state.\"\"\"", "\n", "# Check seed is not already used.", "\n", "if", "seed", "in", "self", ".", "seeds_", ":", "\n", "            ", "raise", "Exception", "(", "'seed {} already exists'", ".", "format", "(", "seed", ")", ")", "\n", "", "self", ".", "seeds_", ".", "add", "(", "seed", ")", "\n", "# Check that state is not already defined.", "\n", "if", "name", "in", "self", ".", "states_", ":", "\n", "            ", "raise", "Exception", "(", "'cuda rng state {} already exists'", ".", "format", "(", "name", ")", ")", "\n", "# Get the current rng state.", "\n", "", "orig_rng_state", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "# Set the new state and store it.", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "self", ".", "states_", "[", "name", "]", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "# Reset rng state to what it was.", "\n", "_set_cuda_rng_state", "(", "orig_rng_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.fork": [[168, 187], ["torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "random._set_cuda_rng_state", "Exception", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "random._set_cuda_rng_state"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random._set_cuda_rng_state", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random._set_cuda_rng_state"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "fork", "(", "self", ",", "name", "=", "_MODEL_PARALLEL_RNG_TRACKER_NAME", ")", ":", "\n", "        ", "\"\"\"Fork the cuda rng state, perform operations, and exit with\n        the original state.\"\"\"", "\n", "# Check if we have added the state", "\n", "if", "name", "not", "in", "self", ".", "states_", ":", "\n", "            ", "raise", "Exception", "(", "'cuda rng state {} is not added'", ".", "format", "(", "name", ")", ")", "\n", "# Store current rng state.", "\n", "", "orig_cuda_rng_state", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "# Set rng state to the desired one", "\n", "_set_cuda_rng_state", "(", "self", ".", "states_", "[", "name", "]", ")", "\n", "# Do the stuff we wanted to do.", "\n", "try", ":", "\n", "            ", "yield", "\n", "", "finally", ":", "\n", "# Update the current rng state for later use.", "\n", "            ", "self", ".", "states_", "[", "name", "]", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "# And set the state to the original state we started with.", "\n", "_set_cuda_rng_state", "(", "orig_cuda_rng_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.forward": [[280, 330], ["torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "get_cuda_rng_tracker().get_states", "initialize.get_model_parallel_rank", "initialize.get_model_parallel_world_size", "initialize.get_model_parallel_group", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.Stream", "torch.cuda.Stream", "torch.cuda.Stream", "torch.cuda.Stream", "torch.cuda.Stream", "torch.cuda.Stream", "torch.cuda.Stream", "torch.cuda.Stream", "torch.cuda.Stream", "inputs.append", "item.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "run_function", "zip", "ctx.save_for_backward", "ctx.save_for_backward", "torch.get_rank", "torch.get_rank", "torch.get_rank", "print", "item.detach().contiguous().view().narrow().clone", "random.get_cuda_rng_tracker", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "new_args.append", "new_args.append", "arg.size", "item.detach().contiguous().view().narrow", "random.get_partition_start", "random.get_partition_size", "item.detach().contiguous().view", "item.detach().contiguous", "item.detach"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.get_states", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_group", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_partition_start", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_partition_size"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "run_function", ",", "*", "args", ")", ":", "\n", "        ", "ctx", ".", "run_function", "=", "run_function", "\n", "global", "mp_rank", ",", "mp_size", ",", "mp_group", "\n", "if", "mp_rank", "is", "None", ":", "\n", "            ", "mp_rank", "=", "get_model_parallel_rank", "(", ")", "\n", "mp_size", "=", "get_model_parallel_world_size", "(", ")", "\n", "mp_group", "=", "get_model_parallel_group", "(", ")", "\n", "\n", "\n", "", "global", "cuda_device", ",", "transport_stream", ",", "PARTITION_ACTIVATIONS", "\n", "if", "cuda_device", "is", "None", ":", "\n", "            ", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "print", "(", "f\"Partition Activations {PARTITION_ACTIVATIONS} and Correctness Check {PA_CORRECTNESS_TEST}\"", ")", "\n", "\n", "", "cuda_device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "#The transport stream is used to overlap the allgather communication for the activations", "\n", "#with the computation in the backward pass", "\n", "transport_stream", "=", "torch", ".", "cuda", ".", "Stream", "(", "device", "=", "cuda_device", ")", "\n", "\n", "", "if", "PARTITION_ACTIVATIONS", ":", "\n", "            ", "inputs", "=", "[", "item", ".", "detach", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "narrow", "(", "0", ",", "get_partition_start", "(", "item", ")", ",", "get_partition_size", "(", "item", ")", ")", ".", "clone", "(", ")", "for", "item", "in", "args", "[", ":", "-", "1", "]", "]", "\n", "inputs", ".", "append", "(", "args", "[", "-", "1", "]", ")", "\n", "\n", "#just in case something funky is happening such as reuse of inputs", "\n", "", "inputs_cuda", "=", "[", "item", ".", "to", "(", "cuda_device", ")", "for", "item", "in", "args", "]", "\n", "\n", "# Copy the rng states.", "\n", "ctx", ".", "fwd_cpu_rng_state", "=", "torch", ".", "get_rng_state", "(", ")", "\n", "ctx", ".", "fwd_cuda_rng_state", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "ctx", ".", "fwd_cuda_rng_state_tracker", "=", "get_cuda_rng_tracker", "(", ")", ".", "get_states", "(", ")", "\n", "\n", "#ctx.save_for_backward(*args)", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "run_function", "(", "*", "inputs_cuda", ")", "\n", "\n", "", "del", "inputs_cuda", "\n", "\n", "if", "PARTITION_ACTIVATIONS", ":", "\n", "            ", "new_args", "=", "[", "]", "\n", "for", "arg", ",", "inp", "in", "zip", "(", "args", ",", "inputs", ")", ":", "\n", "                ", "size", "=", "torch", ".", "tensor", "(", "arg", ".", "size", "(", ")", ")", "\n", "arg", ".", "data", "=", "inp", ".", "data", "\n", "new_args", ".", "append", "(", "arg", ")", "\n", "new_args", ".", "append", "(", "size", ")", "\n", "", "ctx", ".", "save_for_backward", "(", "*", "new_args", ")", "\n", "", "else", ":", "\n", "            ", "ctx", ".", "save_for_backward", "(", "*", "args", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward": [[331, 373], ["torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state", "get_cuda_rng_tracker().get_states", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "random._set_cuda_rng_state", "get_cuda_rng_tracker().set_states", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "torch.set_rng_state", "random._set_cuda_rng_state", "get_cuda_rng_tracker().set_states", "isinstance", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "torch.autograd._is_checkpoint_valid", "RuntimeError", "random.detach_variable", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream", "torch.cuda.current_stream.wait_stream", "torch.cuda.current_stream.wait_stream", "torch.cuda.current_stream.wait_stream", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "torch.enable_grad", "ctx.run_function", "tuple", "torch.cuda.stream", "torch.cuda.stream", "torch.cuda.stream", "torch.cuda.stream", "torch.cuda.stream", "torch.cuda.stream", "torch.cuda.stream", "torch.cuda.stream", "torch.cuda.stream", "random.get_full_inputs", "random.detach_variable", "random.get_cuda_rng_tracker", "random.get_cuda_rng_tracker", "random.get_cuda_rng_tracker"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.get_states", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random._set_cuda_rng_state", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.set_states", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random._set_cuda_rng_state", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.set_states", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CheckpointFunction.backward", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.detach_variable", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_full_inputs", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.detach_variable", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "args", ")", ":", "\n", "        ", "if", "not", "torch", ".", "autograd", ".", "_is_checkpoint_valid", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Checkpointing is not compatible with .grad(), \"", "\n", "\"please use .backward() if possible\"", ")", "\n", "\n", "", "global", "cuda_device", ",", "transport_stream", ",", "PARTITION_ACTIVATIONS", "\n", "\n", "if", "PARTITION_ACTIVATIONS", ":", "\n", "            ", "with", "torch", ".", "cuda", ".", "stream", "(", "transport_stream", ")", ":", "\n", "                ", "inputs", "=", "get_full_inputs", "(", "ctx", ".", "saved_tensors", ")", "\n", "detached_inputs", "=", "detach_variable", "(", "inputs", ")", "\n", "", "", "else", ":", "\n", "            ", "inputs", "=", "ctx", ".", "saved_tensors", "\n", "detached_inputs", "=", "detach_variable", "(", "inputs", ")", "\n", "\n", "# Store the current states.", "\n", "", "bwd_cpu_rng_state", "=", "torch", ".", "get_rng_state", "(", ")", "\n", "bwd_cuda_rng_state", "=", "torch", ".", "cuda", ".", "get_rng_state", "(", ")", "\n", "bwd_cuda_rng_state_tracker", "=", "get_cuda_rng_tracker", "(", ")", ".", "get_states", "(", ")", "\n", "\n", "# Set the states to what it used to be before the forward pass.", "\n", "torch", ".", "set_rng_state", "(", "ctx", ".", "fwd_cpu_rng_state", ")", "\n", "_set_cuda_rng_state", "(", "ctx", ".", "fwd_cuda_rng_state", ")", "\n", "get_cuda_rng_tracker", "(", ")", ".", "set_states", "(", "ctx", ".", "fwd_cuda_rng_state_tracker", ")", "\n", "\n", "if", "PARTITION_ACTIVATIONS", ":", "\n", "            ", "current_stream", "=", "torch", ".", "cuda", ".", "current_stream", "(", ")", "\n", "current_stream", ".", "wait_stream", "(", "transport_stream", ")", "\n", "\n", "", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "ctx", ".", "run_function", "(", "*", "detached_inputs", ")", "\n", "\n", "# Set the states back to what it was at the start of this function.", "\n", "", "torch", ".", "set_rng_state", "(", "bwd_cpu_rng_state", ")", "\n", "_set_cuda_rng_state", "(", "bwd_cuda_rng_state", ")", "\n", "get_cuda_rng_tracker", "(", ")", ".", "set_states", "(", "bwd_cuda_rng_state_tracker", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "outputs", "=", "(", "outputs", ",", ")", "\n", "", "torch", ".", "autograd", ".", "backward", "(", "outputs", ",", "args", ")", "\n", "return", "(", "None", ",", ")", "+", "tuple", "(", "inp", ".", "grad", "for", "inp", "in", "detached_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.see_memory_usage": [[35, 46], ["torch.barrier", "torch.get_rank", "print", "print", "print", "print", "print", "print", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.memory_cached", "torch.cuda.memory_cached", "torch.cuda.memory_cached", "torch.cuda.max_memory_cached", "torch.cuda.max_memory_cached", "torch.cuda.max_memory_cached"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["def", "see_memory_usage", "(", "message", ",", "force", "=", "False", ")", ":", "\n", "    ", "if", "not", "force", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "message", ")", "\n", "print", "(", "\"Memory Allocated \"", ",", "torch", ".", "cuda", ".", "memory_allocated", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\"Max Memory Allocated \"", ",", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\"Cache Allocated \"", ",", "torch", ".", "cuda", ".", "memory_cached", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\"Max cache Allocated \"", ",", "torch", ".", "cuda", ".", "max_memory_cached", "(", ")", "/", "(", "1024", "*", "1024", "*", "1024", ")", ",", "\"GigaBytes\"", ")", "\n", "print", "(", "\" \"", ")", "\n", "#input(\"Press Any Key To Continue ..\")", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.detach_variable": [[62, 84], ["isinstance", "tuple", "RuntimeError", "inp.to.detach", "out.append", "isinstance", "out.append", "inp.to", "type"], "function", ["None"], ["def", "detach_variable", "(", "inputs", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "        ", "out", "=", "[", "]", "\n", "for", "inp", "in", "inputs", ":", "\n", "            ", "if", "not", "isinstance", "(", "inp", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "out", ".", "append", "(", "inp", ")", "\n", "continue", "\n", "\n", "", "requires_grad", "=", "inp", ".", "requires_grad", "\n", "\n", "if", "device", "is", "not", "None", ":", "\n", "                ", "x", "=", "inp", ".", "to", "(", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "inp", "\n", "\n", "", "x", "=", "x", ".", "detach", "(", ")", "\n", "x", ".", "requires_grad", "=", "requires_grad", "\n", "out", ".", "append", "(", "x", ")", "\n", "", "return", "tuple", "(", "out", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"Only tuple of tensors is supported. Got Unsupported input type: \"", ",", "type", "(", "inputs", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random._set_cuda_rng_state": [[85, 116], ["torch.cuda._lazy_call", "hasattr", "callable", "torch.device", "torch.device", "torch.device", "isinstance", "default_generator.set_state", "torch.cuda.device", "torch._C._cuda_setRNGState", "torch.device", "torch.device", "torch.device", "isinstance", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.device", "torch.device", "torch.device"], "function", ["None"], ["", "", "def", "_set_cuda_rng_state", "(", "new_state", ",", "device", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"Sets the random number generator state of the current GPU.\n\n    Argumentss:\n        new_state (torch.ByteTensor): The desired state\n    This function is adapted from PyTorch repo (torch.cuda.set_rng_state)\n    with a single change: the input state is not cloned. Cloning caused\n    major performance issues for +4 GPU cases.\n    \"\"\"", "\n", "if", "hasattr", "(", "_C", ",", "'_cuda_setRNGState'", ")", "and", "callable", "(", "_C", ".", "_cuda_setRNGState", ")", ":", "\n", "# older PyTorch", "\n", "        ", "def", "cb", "(", ")", ":", "\n", "            ", "with", "device_ctx_manager", "(", "device", ")", ":", "\n", "                ", "_C", ".", "_cuda_setRNGState", "(", "new_state", ")", "\n", "", "", "", "else", ":", "\n", "# newer PyTorch", "\n", "        ", "if", "device", "==", "-", "1", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "elif", "isinstance", "(", "device", ",", "str", ")", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "", "elif", "isinstance", "(", "device", ",", "int", ")", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cuda'", ",", "device", ")", "\n", "\n", "", "def", "cb", "(", ")", ":", "\n", "            ", "idx", "=", "device", ".", "index", "\n", "if", "idx", "is", "None", ":", "\n", "                ", "idx", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "", "default_generator", "=", "torch", ".", "cuda", ".", "default_generators", "[", "idx", "]", "\n", "default_generator", ".", "set_state", "(", "new_state", ")", "\n", "\n", "", "", "_lazy_call", "(", "cb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_cuda_rng_tracker": [[193, 196], ["None"], "function", ["None"], ["def", "get_cuda_rng_tracker", "(", ")", ":", "\n", "    ", "\"\"\"Get cuda rng tracker.\"\"\"", "\n", "return", "_CUDA_RNG_STATE_TRACKER", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.model_parallel_cuda_manual_seed": [[198, 234], ["_CUDA_RNG_STATE_TRACKER.reset", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "_CUDA_RNG_STATE_TRACKER.add", "initialize.get_model_parallel_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "print", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "initialize.get_model_parallel_rank", "initialize.get_data_parallel_rank"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.reset", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.CudaRNGStatesTracker.add", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_model_parallel_rank", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.initialize.get_data_parallel_rank"], ["", "def", "model_parallel_cuda_manual_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"Initialize model parallel cuda seed.\n\n    This function should be called after the model parallel is\n    initialized. Also, no torch.cuda.manual_seed should be called\n    after this function. Basically, this is replacement for that\n    function.\n    Two set of RNG states are tracked:\n        default state: This is for data parallelism and is the same among a\n                       set of model parallel GPUs but different across\n                       different model paralle groups. This is used for\n                       example for dropout in the non-model-parallel regions.\n        model-parallel state: This state is different among a set of model\n                              parallel GPUs, but the same across data parallel\n                              groups. This is used for example for dropout in\n                              model parallel regions.\n    \"\"\"", "\n", "# 2718 is just for fun and any POSITIVE value will work.", "\n", "offset", "=", "seed", "+", "2718", "\n", "model_parallel_seed", "=", "offset", "+", "get_model_parallel_rank", "(", ")", "\n", "# Data parallel gets the original sedd.", "\n", "data_parallel_seed", "=", "seed", "\n", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "'> initializing model parallel cuda seeds on global rank {}, '", "\n", "'model parallel rank {}, and data parallel rank {} with '", "\n", "'model parallel seed: {} and data parallel seed: {}'", ".", "format", "(", "\n", "torch", ".", "distributed", ".", "get_rank", "(", ")", ",", "get_model_parallel_rank", "(", ")", ",", "\n", "get_data_parallel_rank", "(", ")", ",", "model_parallel_seed", ",", "\n", "data_parallel_seed", ")", ",", "flush", "=", "True", ")", "\n", "", "_CUDA_RNG_STATE_TRACKER", ".", "reset", "(", ")", "\n", "# Set the default state.", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "data_parallel_seed", ")", "\n", "# and model parallel state.", "\n", "_CUDA_RNG_STATE_TRACKER", ".", "add", "(", "_MODEL_PARALLEL_RNG_TRACKER_NAME", ",", "\n", "model_parallel_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_partition_start": [[236, 241], ["random.get_partition_size", "int"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_partition_size"], ["", "def", "get_partition_start", "(", "item", ")", ":", "\n", "    ", "global", "mp_rank", ",", "mp_size", ",", "mp_group", "\n", "partition_size", "=", "get_partition_size", "(", "item", ")", "\n", "start", "=", "partition_size", "*", "mp_rank", "\n", "return", "int", "(", "start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_partition_size": [[242, 247], ["item.numel", "int"], "function", ["None"], ["", "def", "get_partition_size", "(", "item", ")", ":", "\n", "    ", "global", "mp_rank", ",", "mp_size", ",", "mp_group", "\n", "size", "=", "item", ".", "numel", "(", ")", "\n", "partition_size", "=", "size", "/", "mp_size", "\n", "return", "int", "(", "partition_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.get_full_inputs": [[248, 270], ["range", "inputs.append", "tuple", "item.numel", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.all_gather", "torch.zeros.view", "inputs.append", "int", "torch.zeros.narrow", "partitions.append", "list", "flat_tensor.narrow.copy_", "size.numpy", "len"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_gather"], ["", "def", "get_full_inputs", "(", "tensors", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "tensors", ")", "/", "2", ")", "-", "1", ")", ":", "\n", "        ", "item", "=", "tensors", "[", "2", "*", "i", "]", "\n", "size", "=", "tensors", "[", "2", "*", "i", "+", "1", "]", "\n", "partition_size", "=", "item", ".", "numel", "(", ")", "\n", "tensor_size", "=", "partition_size", "*", "mp_size", "\n", "flat_tensor", "=", "torch", ".", "zeros", "(", "[", "tensor_size", "]", ",", "dtype", "=", "item", ".", "dtype", ",", "device", "=", "item", ".", "device", ")", "\n", "partitions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "mp_size", ")", ":", "\n", "            ", "part_i", "=", "flat_tensor", ".", "narrow", "(", "0", ",", "partition_size", "*", "i", ",", "partition_size", ")", "\n", "if", "i", "==", "mp_rank", ":", "\n", "                ", "part_i", ".", "copy_", "(", "item", ")", "\n", "", "partitions", ".", "append", "(", "part_i", ")", "\n", "", "dist", ".", "all_gather", "(", "partitions", ",", "partitions", "[", "mp_rank", "]", ",", "group", "=", "mp_group", ")", "\n", "input_tensor", "=", "flat_tensor", ".", "view", "(", "list", "(", "size", ".", "numpy", "(", ")", ")", ")", "\n", "item", ".", "data", "=", "input_tensor", ".", "data", "\n", "\n", "inputs", ".", "append", "(", "item", ")", "\n", "", "inputs", ".", "append", "(", "tensors", "[", "-", "2", "]", ")", "\n", "\n", "return", "tuple", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.checkpoint": [[375, 379], ["CheckpointFunction.apply"], "function", ["None"], ["", "", "def", "checkpoint", "(", "function", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Checkpoint a model or part of the model.\n    This has been directly copied from torch.utils.checkpoint.\"\"\"", "\n", "return", "CheckpointFunction", ".", "apply", "(", "function", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.random.partition_activations_in_checkpoint": [[380, 385], ["torch.get_rank", "print"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["", "def", "partition_activations_in_checkpoint", "(", "partition_activation", ")", ":", "\n", "    ", "global", "PARTITION_ACTIVATIONS", "\n", "PARTITION_ACTIVATIONS", "=", "partition_activation", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "f\"**************Partition Activations {PARTITION_ACTIVATIONS}************\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.VocabUtility.vocab_range_from_per_partition_vocab_size": [[59, 65], ["None"], "methods", ["None"], ["index", "=", "0", "\n", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "string", "=", "'iteration, rank, index, model-parallel,min, max, norm\\n'", "\n", "optimizer_", "=", "optimizer", "\n", "if", "isinstance", "(", "optimizer", ",", "FP16_Optimizer", ")", ":", "\n", "        ", "optimizer_", "=", "optimizer", ".", "optimizer", "\n", "", "for", "param_group", "in", "optimizer_", ".", "param_groups", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.VocabUtility.vocab_range_from_global_vocab_size": [[66, 71], ["utils.divide", "utils.VocabUtility.vocab_range_from_per_partition_vocab_size"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide", "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.VocabUtility.vocab_range_from_per_partition_vocab_size"], ["        ", "for", "param", "in", "param_group", "[", "'params'", "]", ":", "\n", "            ", "index", "+=", "1", "\n", "min_", "=", "param", ".", "data", ".", "min", "(", ")", "\n", "max_", "=", "param", ".", "data", ".", "max", "(", ")", "\n", "norm", "=", "param", ".", "data", ".", "norm", "(", ")", "\n", "string", "+=", "'{:7d}, {:4d}, {:4d}, {:2d}, '", ".", "format", "(", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.ensure_divisibility": [[20, 24], ["None"], "function", ["None"], ["import", "time", "\n", "import", "numpy", "as", "np", "\n", "import", "torch", "\n", "\n", "from", "torch", ".", "nn", ".", "parallel", ".", "distributed", "import", "DistributedDataParallel", "as", "torchDDP", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide": [[26, 31], ["utils.ensure_divisibility"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.ensure_divisibility"], ["import", "mpu", "\n", "import", "model", "\n", "from", "tensorboardX", "import", "SummaryWriter", "\n", "\n", "SUMMARY_WRITER_DIR_NAME", "=", "'runs'", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.split_tensor_along_last_dim": [[33, 52], ["utils.divide", "torch.split", "tensor.dim", "tuple", "tensor.size", "chunk.contiguous"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.divide"], ["def", "get_sample_writer", "(", "name", ",", "base", "=", "\"..\"", ",", "iteration", "=", "0", ")", ":", "\n", "    ", "\"\"\"Returns a tensorboard summary writer\n    \"\"\"", "\n", "return", "SummaryWriter", "(", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "base", ",", "SUMMARY_WRITER_DIR_NAME", ",", "name", ")", ",", "purge_step", "=", "iteration", ")", "\n", "\n", "\n", "", "def", "print_rank_0", "(", "message", ")", ":", "\n", "    ", "if", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "message", ",", "flush", "=", "True", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "message", ",", "flush", "=", "True", ")", "\n", "\n", "\n", "", "", "def", "print_args", "(", "args", ")", ":", "\n", "    ", "\"\"\"Print arguments.\"\"\"", "\n", "\n", "print", "(", "'arguments:'", ",", "flush", "=", "True", ")", "\n", "for", "arg", "in", "vars", "(", "args", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.mpu.utils.split_out_sums": [[72, 81], ["x.view.view", "x.view.split", "sums.reshape", "oris.reshape", "sums.reshape"], "function", ["None"], ["iteration", ",", "rank", ",", "index", ",", "int", "(", "param", ".", "model_parallel", ")", ")", "\n", "string", "+=", "'{:.6E}, {:.6E}, {:.6E}\\n'", ".", "format", "(", "min_", ",", "max_", ",", "norm", ")", "\n", "", "", "print", "(", "string", ",", "flush", "=", "True", ")", "\n", "\n", "\n", "", "class", "Timers", ":", "\n", "    ", "\"\"\"Group of timers.\"\"\"", "\n", "\n", "class", "Timer", ":", "\n", "        ", "\"\"\"Timer.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.new_model": [[12, 20], ["vqvae_zc.VQVAE"], "function", ["None"], ["def", "new_model", "(", ")", ":", "\n", "    ", "'''Return a New Instance of VQVAE, the same parameters with the pretrained model.\n        This is for torch.load().\n    '''", "\n", "return", "VQVAE", "(", "\n", "channel", "=", "512", ",", "n_res_block", "=", "0", ",", "\n", "n_res_channel", "=", "32", ",", "embed_dim", "=", "256", ",", "\n", "n_embed", "=", "8192", ",", "stride", "=", "6", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.img2code": [[22, 31], ["id_t1.view", "torch.no_grad", "model.encode"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "def", "img2code", "(", "model", ",", "img", ")", ":", "\n", "    ", "'''Convert a batch of img to code\n    Args:\n        model: The tokenizer model.\n        img: [b, c, h, w]\n    '''", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "quant_t1", ",", "_", ",", "id_t1", "=", "model", ".", "encode", "(", "img", ")", "\n", "", "return", "id_t1", ".", "view", "(", "img", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.api.code2img": [[32, 45], ["len", "int", "code.view.view", "torch.no_grad", "model.decode_code", "torch.tensor().view", "math.sqrt", "torch.tensor().view", "len", "torch.tensor", "code.view.view", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.decode_code"], ["", "def", "code2img", "(", "model", ",", "code", ")", ":", "\n", "    ", "'''Convert a batch of code to imgs\n    Args:\n        model: ...\n        code: [b, h, w] or [b, h*w] LongTensor\n    '''", "\n", "if", "len", "(", "code", ".", "shape", ")", "==", "2", ":", "\n", "        ", "s", "=", "int", "(", "math", ".", "sqrt", "(", "len", "(", "code", ".", "view", "(", "-", "1", ")", ")", ")", "+", "1e-5", ")", "\n", "code", "=", "code", ".", "view", "(", "code", ".", "shape", "[", "0", "]", ",", "s", ",", "s", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "out", "=", "model", ".", "decode_code", "(", "code", ")", "\n", "out", "=", "out", "*", "torch", ".", "tensor", "(", "[", "0.30379", ",", "0.32279", ",", "0.32800", "]", ",", "device", "=", "out", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "+", "torch", ".", "tensor", "(", "[", "0.79093", ",", "0.76271", ",", "0.75340", "]", ",", "device", "=", "out", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Quantize.__init__": [[27, 40], ["torch.nn.Module.__init__", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "vqvae_zc.Quantize.register_buffer", "vqvae_zc.Quantize.register_buffer", "vqvae_zc.Quantize.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.randn.clone", "torch.randn.clone", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "n_embed", ",", "decay", "=", "0.99", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "n_embed", "=", "n_embed", "\n", "self", ".", "decay", "=", "decay", "\n", "self", ".", "eps", "=", "eps", "\n", "\n", "embed", "=", "torch", ".", "randn", "(", "dim", ",", "n_embed", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "embed", ",", "gain", "=", "torch", ".", "nn", ".", "init", ".", "calculate_gain", "(", "'tanh'", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"embed\"", ",", "embed", ")", "\n", "self", ".", "register_buffer", "(", "\"cluster_size\"", ",", "torch", ".", "zeros", "(", "n_embed", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"embed_avg\"", ",", "embed", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Quantize.forward_": [[41, 94], ["input.reshape", "vqvae_zc.Quantize.embed.pow().sum", "torch.nn.functional.one_hot().type", "torch.nn.functional.one_hot().type", "embed_ind.view.view.view", "vqvae_zc.Quantize.embed_code", "torch.nn.functional.one_hot().type.sum", "vqvae_zc.Quantize.cluster_size.data.mul_().add_", "vqvae_zc.Quantize.embed_avg.data.mul_().add_", "vqvae_zc.Quantize.cluster_size.sum", "vqvae_zc.Quantize.embed.data.copy_", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "vqvae_zc.Quantize.to", "input.reshape.pow().sum", "vqvae_zc.gumbel_softmax", "embed_ind.view.view.view", "embed_soft.view.view.view", "vqvae_zc.gumbel_softmax", "embed_ind.view.view.view", "vqvae_zc.Quantize.embed_code", "input.reshape.transpose", "cluster_size.unsqueeze", "vqvae_zc.Quantize.embed.pow", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "vqvae_zc.Quantize.embed.transpose", "vqvae_zc.Quantize.cluster_size.data.mul_", "vqvae_zc.Quantize.embed_avg.data.mul_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "input.reshape.pow", "torch.log", "torch.log", "torch.log", "torch.log", "vqvae_zc.Quantize.detach"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Quantize.embed_code", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.gumbel_softmax", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.gumbel_softmax", "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Quantize.embed_code", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log"], ["", "def", "forward_", "(", "self", ",", "input", ",", "continuous_relax", "=", "False", ",", "temperature", "=", "1.", ",", "hard", "=", "False", ")", ":", "\n", "        ", "flatten", "=", "input", ".", "reshape", "(", "-", "1", ",", "self", ".", "dim", ")", "\n", "dist", "=", "(", "\n", "flatten", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "-", "2", "*", "flatten", "@", "self", ".", "embed", "\n", "+", "self", ".", "embed", ".", "pow", "(", "2", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", ")", "# dist map, shape=[*, n_embed]", "\n", "\n", "if", "not", "continuous_relax", ":", "\n", "# argmax + lookup", "\n", "            ", "_", ",", "embed_ind", "=", "(", "-", "dist", ")", ".", "max", "(", "1", ")", "\n", "embed_onehot", "=", "F", ".", "one_hot", "(", "embed_ind", ",", "self", ".", "n_embed", ")", ".", "type", "(", "flatten", ".", "dtype", ")", "\n", "embed_ind", "=", "embed_ind", ".", "view", "(", "*", "input", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "quantize", "=", "self", ".", "embed_code", "(", "embed_ind", ")", "\n", "", "elif", "not", "hard", ":", "\n", "# gumbel softmax weighted sum", "\n", "            ", "embed_soft", ",", "embed_ind", "=", "gumbel_softmax", "(", "-", "dist", ",", "tau", "=", "temperature", ",", "hard", "=", "False", ")", "\n", "embed_ind", "=", "embed_ind", ".", "view", "(", "*", "input", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "embed_soft", "=", "embed_soft", ".", "view", "(", "*", "input", ".", "shape", "[", ":", "-", "1", "]", ",", "self", ".", "n_embed", ")", "\n", "quantize", "=", "embed_soft", "@", "self", ".", "embed", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "# gumbel softmax hard lookup", "\n", "            ", "embed_onehot", ",", "embed_ind", "=", "gumbel_softmax", "(", "-", "dist", ",", "tau", "=", "temperature", ",", "hard", "=", "True", ")", "\n", "embed_ind", "=", "embed_ind", ".", "view", "(", "*", "input", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "quantize", "=", "self", ".", "embed_code", "(", "embed_ind", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "(", "(", "continuous_relax", "and", "hard", ")", "or", "(", "not", "continuous_relax", ")", ")", ":", "\n", "            ", "embed_onehot_sum", "=", "embed_onehot", ".", "sum", "(", "0", ")", "\n", "embed_sum", "=", "flatten", ".", "transpose", "(", "0", ",", "1", ")", "@", "embed_onehot", "\n", "\n", "# dist_fn.all_reduce(embed_onehot_sum)", "\n", "# dist_fn.all_reduce(embed_sum)", "\n", "\n", "self", ".", "cluster_size", ".", "data", ".", "mul_", "(", "self", ".", "decay", ")", ".", "add_", "(", "\n", "embed_onehot_sum", ",", "alpha", "=", "1", "-", "self", ".", "decay", "\n", ")", "\n", "self", ".", "embed_avg", ".", "data", ".", "mul_", "(", "self", ".", "decay", ")", ".", "add_", "(", "embed_sum", ",", "alpha", "=", "1", "-", "self", ".", "decay", ")", "\n", "n", "=", "self", ".", "cluster_size", ".", "sum", "(", ")", "\n", "cluster_size", "=", "(", "\n", "(", "self", ".", "cluster_size", "+", "self", ".", "eps", ")", "/", "(", "n", "+", "self", ".", "n_embed", "*", "self", ".", "eps", ")", "*", "n", "\n", ")", "\n", "embed_normalized", "=", "self", ".", "embed_avg", "/", "cluster_size", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "embed", ".", "data", ".", "copy_", "(", "embed_normalized", ")", "\n", "", "if", "not", "continuous_relax", ":", "\n", "            ", "diff", "=", "(", "quantize", ".", "detach", "(", ")", "-", "input", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "quantize", "=", "input", "+", "(", "quantize", "-", "input", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "# maybe need replace a KL term here", "\n", "            ", "qy", "=", "(", "-", "dist", ")", ".", "softmax", "(", "-", "1", ")", "\n", "diff", "=", "torch", ".", "sum", "(", "qy", "*", "torch", ".", "log", "(", "qy", "*", "self", ".", "n_embed", "+", "1e-20", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "# KL", "\n", "#diff = (quantize - input).pow(2).mean().detach() # gumbel softmax do not need diff", "\n", "quantize", "=", "quantize", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "", "return", "quantize", ",", "diff", ",", "embed_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Quantize.embed_code": [[95, 97], ["torch.nn.functional.embedding", "torch.nn.functional.embedding", "vqvae_zc.Quantize.embed.transpose"], "methods", ["None"], ["", "def", "embed_code", "(", "self", ",", "embed_id", ")", ":", "\n", "        ", "return", "F", ".", "embedding", "(", "embed_id", ",", "self", ".", "embed", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.ResBlock.__init__": [[100, 108], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", ",", "channel", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channel", ",", "channel", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "in_channel", ",", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.ResBlock.forward": [[110, 115], ["vqvae_zc.ResBlock.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv", "(", "input", ")", "\n", "out", "+=", "input", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Encoder.__init__": [[118, 162], ["torch.nn.Module.__init__", "range", "blocks.append", "blocks.append", "torch.nn.Sequential", "torch.nn.Sequential", "blocks.append", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "vqvae_zc.ResBlock", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", ",", "channel", ",", "n_res_block", ",", "n_res_channel", ",", "stride", ",", "embed_dim", ",", "n_embed", ",", "simple", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "stride", "==", "6", ":", "\n", "            ", "if", "simple", ":", "\n", "                ", "blocks", "=", "[", "\n", "nn", ".", "Conv2d", "(", "in_channel", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "                ", "blocks", "=", "[", "\n", "nn", ".", "Conv2d", "(", "in_channel", ",", "channel", "//", "4", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", "//", "4", ",", "channel", "//", "2", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", "//", "2", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", "\n", "\n", "", "", "elif", "stride", "==", "4", ":", "\n", "            ", "blocks", "=", "[", "\n", "nn", ".", "Conv2d", "(", "in_channel", ",", "channel", "//", "2", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", "//", "2", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", "\n", "", "elif", "stride", "==", "2", ":", "\n", "            ", "blocks", "=", "[", "\n", "nn", ".", "Conv2d", "(", "in_channel", ",", "channel", "//", "2", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", "//", "2", ",", "channel", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_res_block", ")", ":", "\n", "            ", "blocks", ".", "append", "(", "ResBlock", "(", "channel", ",", "n_res_channel", ")", ")", "\n", "\n", "", "blocks", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "blocks", ".", "append", "(", "nn", ".", "Conv2d", "(", "channel", ",", "embed_dim", ",", "1", ")", ")", "\n", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Encoder.forward": [[163, 165], ["vqvae_zc.Encoder.blocks().permute", "vqvae_zc.Encoder.blocks"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "blocks", "(", "input", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Decoder.__init__": [[168, 212], ["torch.nn.Module.__init__", "range", "blocks.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "blocks.append", "torch.nn.ReLU", "torch.nn.ReLU", "blocks.extend", "vqvae_zc.ResBlock", "blocks.extend", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "blocks.append", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_channel", ",", "out_channel", ",", "channel", ",", "n_res_block", ",", "n_res_channel", ",", "stride", ",", "simple", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "blocks", "=", "[", "\n", "nn", ".", "ConvTranspose2d", "(", "in_channel", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_res_block", ")", ":", "\n", "            ", "blocks", ".", "append", "(", "ResBlock", "(", "channel", ",", "n_res_channel", ")", ")", "\n", "\n", "", "blocks", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "if", "stride", "==", "4", "and", "simple", ":", "\n", "            ", "blocks", ".", "extend", "(", "\n", "[", "\n", "nn", ".", "ConvTranspose2d", "(", "channel", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "\n", "channel", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", "\n", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "channel", ",", "out_channel", ",", "1", ")", "\n", "]", "\n", ")", "\n", "", "elif", "stride", "==", "4", ":", "\n", "            ", "blocks", ".", "extend", "(", "\n", "[", "\n", "nn", ".", "ConvTranspose2d", "(", "channel", ",", "channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "channel", ",", "channel", "//", "2", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "\n", "channel", "//", "2", ",", "out_channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", "\n", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "", "elif", "stride", "==", "2", ":", "\n", "            ", "blocks", ".", "append", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "channel", ",", "out_channel", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "", "self", ".", "blocks", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Decoder.forward": [[213, 215], ["vqvae_zc.Decoder.blocks"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "blocks", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.__init__": [[218, 243], ["torch.nn.Module.__init__", "vqvae_zc.Encoder", "vqvae_zc.Quantize", "vqvae_zc.Decoder"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channel", "=", "3", ",", "\n", "channel", "=", "128", ",", "\n", "n_res_block", "=", "2", ",", "\n", "n_res_channel", "=", "32", ",", "\n", "embed_dim", "=", "64", ",", "\n", "n_embed", "=", "1024", ",", "\n", "stride", "=", "4", ",", "\n", "simple", "=", "True", ",", "\n", "decay", "=", "0.99", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "channel", "==", "2048", ":", "\n", "            ", "n_res_block", "=", "0", "\n", "", "self", ".", "enc_b", "=", "Encoder", "(", "in_channel", ",", "channel", ",", "n_res_block", ",", "n_res_channel", ",", "stride", ",", "embed_dim", ",", "n_embed", ",", "simple", ")", "\n", "self", ".", "quantize_t", "=", "Quantize", "(", "embed_dim", ",", "n_embed", ")", "\n", "self", ".", "dec", "=", "Decoder", "(", "\n", "in_channel", "=", "embed_dim", ",", "\n", "out_channel", "=", "in_channel", ",", "\n", "channel", "=", "channel", ",", "\n", "n_res_block", "=", "n_res_block", ",", "\n", "n_res_channel", "=", "n_res_channel", ",", "\n", "stride", "=", "stride", "-", "2", ",", "\n", "simple", "=", "simple", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.forward": [[245, 250], ["vqvae_zc.VQVAE.encode", "vqvae_zc.VQVAE.dec"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode"], ["", "def", "forward", "(", "self", ",", "input", ",", "continuous_relax", "=", "False", ",", "temperature", "=", "1.", ",", "hard", "=", "False", ",", "KL", "=", "False", ")", ":", "\n", "        ", "quant_t", ",", "diff", ",", "_", ",", "=", "self", ".", "encode", "(", "input", ",", "continuous_relax", ",", "temperature", ",", "hard", ",", "KL", ")", "\n", "dec", "=", "self", ".", "dec", "(", "quant_t", ")", "\n", "\n", "return", "dec", ",", "diff", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.encode": [[251, 260], ["vqvae_zc.VQVAE.enc_b", "vqvae_zc.VQVAE.quantize_t.forward_", "quant_t.permute.permute.permute", "torch.zeros_like().unsqueeze.unsqueeze", "torch.zeros_like().unsqueeze.unsqueeze", "torch.zeros_like().unsqueeze", "torch.zeros_like().unsqueeze", "torch.zeros_like().unsqueeze", "torch.zeros_like().unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Quantize.forward_"], ["", "def", "encode", "(", "self", ",", "input", ",", "continuous_relax", "=", "False", ",", "temperature", "=", "1.", ",", "hard", "=", "False", ",", "KL", "=", "False", ")", ":", "\n", "        ", "logits", "=", "self", ".", "enc_b", "(", "input", ")", "\n", "quant_t", ",", "diff_t", ",", "id_t", "=", "self", ".", "quantize_t", ".", "forward_", "(", "logits", ",", "continuous_relax", ",", "temperature", ",", "hard", ")", "\n", "quant_t", "=", "quant_t", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "if", "not", "continuous_relax", "or", "KL", ":", "\n", "            ", "diff_t", "=", "diff_t", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "diff_t", "=", "torch", ".", "zeros_like", "(", "diff_t", ")", ".", "unsqueeze", "(", "0", ")", "# placeholder to return right shape ", "\n", "", "return", "quant_t", ",", "diff_t", ",", "id_t", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.decode": [[261, 263], ["vqvae_zc.VQVAE.dec"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "code", ")", ":", "\n", "        ", "return", "self", ".", "dec", "(", "code", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.VQVAE.decode_code": [[264, 270], ["vqvae_zc.VQVAE.quantize_t.embed_code", "quant_t.permute.permute.permute", "vqvae_zc.VQVAE.dec"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.Quantize.embed_code"], ["", "def", "decode_code", "(", "self", ",", "code_t", ")", ":", "\n", "        ", "quant_t", "=", "self", ".", "quantize_t", ".", "embed_code", "(", "code_t", ")", "\n", "quant_t", "=", "quant_t", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "dec", "=", "self", ".", "dec", "(", "quant_t", ")", "\n", "\n", "return", "dec", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.vqvae.vqvae_zc.gumbel_softmax": [[284, 347], ["gumbels.softmax", "torch.jit.is_scripting", "torch.jit.is_scripting", "warnings.warn", "torch.empty_like().exponential_().log", "torch.empty_like().exponential_().log", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "has_torch_function", "handle_torch_function", "gumbels.softmax.max", "gumbels.softmax.max", "type", "torch.empty_like().exponential_", "torch.empty_like().exponential_", "torch.zeros_like", "torch.zeros_like", "gumbels.softmax.detach", "torch.empty_like", "torch.empty_like"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log", "home.repos.pwc.inspect_result.THUDM_CogView.None.utils.Timers.log"], ["def", "gumbel_softmax", "(", "logits", ",", "tau", "=", "1", ",", "hard", "=", "False", ",", "eps", "=", "1e-10", ",", "dim", "=", "-", "1", ")", ":", "\n", "# type: (Tensor, float, bool, float, int) -> Tensor", "\n", "    ", "r\"\"\"\n    Samples from the Gumbel-Softmax distribution (`Link 1`_  `Link 2`_) and optionally discretizes.\n\n    Args:\n      logits: `[..., num_features]` unnormalized log probabilities\n      tau: non-negative scalar temperature\n      hard: if ``True``, the returned samples will be discretized as one-hot vectors,\n            but will be differentiated as if it is the soft sample in autograd\n      dim (int): A dimension along which softmax will be computed. Default: -1.\n\n    Returns:\n      Sampled tensor of same shape as `logits` from the Gumbel-Softmax distribution.\n      If ``hard=True``, the returned samples will be one-hot, otherwise they will\n      be probability distributions that sum to 1 across `dim`.\n\n    .. note::\n      This function is here for legacy reasons, may be removed from nn.Functional in the future.\n\n    .. note::\n      The main trick for `hard` is to do  `y_hard - y_soft.detach() + y_soft`\n\n      It achieves two things:\n      - makes the output value exactly one-hot\n      (since we add then subtract y_soft value)\n      - makes the gradient equal to y_soft gradient\n      (since we strip all other gradients)\n\n    Examples::\n        >>> logits = torch.randn(20, 32)\n        >>> # Sample soft categorical using reparametrization trick:\n        >>> F.gumbel_softmax(logits, tau=1, hard=False)\n        >>> # Sample hard categorical using \"Straight-through\" trick:\n        >>> F.gumbel_softmax(logits, tau=1, hard=True)\n\n    .. _Link 1:\n        https://arxiv.org/abs/1611.00712\n    .. _Link 2:\n        https://arxiv.org/abs/1611.01144\n    \"\"\"", "\n", "if", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "        ", "if", "type", "(", "logits", ")", "is", "not", "Tensor", "and", "has_torch_function", "(", "(", "logits", ",", ")", ")", ":", "\n", "            ", "return", "handle_torch_function", "(", "\n", "gumbel_softmax", ",", "(", "logits", ",", ")", ",", "logits", ",", "tau", "=", "tau", ",", "hard", "=", "hard", ",", "eps", "=", "eps", ",", "dim", "=", "dim", ")", "\n", "", "", "if", "eps", "!=", "1e-10", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"`eps` parameter is deprecated and has no effect.\"", ")", "\n", "\n", "", "gumbels", "=", "-", "torch", ".", "empty_like", "(", "logits", ",", "memory_format", "=", "torch", ".", "legacy_contiguous_format", ")", ".", "exponential_", "(", ")", ".", "log", "(", ")", "# ~Gumbel(0,1)", "\n", "gumbels", "=", "(", "logits", "+", "gumbels", ")", "/", "tau", "# ~Gumbel(logits,tau)", "\n", "y_soft", "=", "gumbels", ".", "softmax", "(", "dim", ")", "\n", "\n", "if", "hard", ":", "\n", "# Straight through.", "\n", "        ", "index", "=", "y_soft", ".", "max", "(", "dim", ",", "keepdim", "=", "True", ")", "[", "1", "]", "\n", "y_hard", "=", "torch", ".", "zeros_like", "(", "logits", ",", "memory_format", "=", "torch", ".", "legacy_contiguous_format", ")", ".", "scatter_", "(", "dim", ",", "index", ",", "1.0", ")", "\n", "ret", "=", "y_hard", "-", "y_soft", ".", "detach", "(", ")", "+", "y_soft", "\n", "return", "ret", ",", "index", "\n", "", "else", ":", "\n", "# Reparametrization trick.", "\n", "        ", "ret", "=", "y_soft", "\n", "index", "=", "y_soft", ".", "max", "(", "dim", ",", "keepdim", "=", "True", ")", "[", "1", "]", "\n", "return", "ret", ",", "index", "", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.is_primary": [[12, 14], ["distributed.get_rank"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.", "\n", "# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank": [[16, 24], ["torch.distributed.get_rank", "torch.distributed.is_available", "torch.distributed.is_initialized"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["import", "torch", "\n", "from", "torch", ".", "_utils", "import", "_flatten_dense_tensors", ",", "_unflatten_dense_tensors", "\n", "import", "torch", ".", "distributed", "as", "dist", "\n", "from", "torch", ".", "nn", ".", "modules", "import", "Module", "\n", "from", "torch", ".", "autograd", "import", "Variable", "\n", "from", "torch", ".", "nn", ".", "parallel", ".", "distributed", "import", "DistributedDataParallel", "as", "DDP", "\n", "\n", "import", "mpu", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_local_rank": [[26, 37], ["torch.distributed.get_rank", "torch.distributed.is_available", "torch.distributed.is_initialized", "ValueError"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["class", "PyTorchDistributedDataParallel", "(", "DDP", ")", ":", "\n", "    ", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "sd", "=", "self", ".", "module", ".", "state_dict", "(", "destination", ",", "prefix", ",", "keep_vars", ")", "\n", "return", "sd", "\n", "\n", "", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")", "\n", "\n", "\n", "", "", "class", "DistributedDataParallel", "(", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize": [[39, 52], ["torch.distributed.get_world_size", "torch.distributed.barrier", "torch.distributed.is_available", "torch.distributed.is_initialized"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size"], ["self", ".", "warn_on_half", "=", "True", "if", "dist", ".", "_backend", "==", "dist", ".", "dist_backend", ".", "GLOO", "else", "False", "\n", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "data_parallel_group", "=", "mpu", ".", "get_data_parallel_group", "(", ")", "\n", "src_rank", "=", "mpu", ".", "get_model_parallel_rank", "(", ")", "\n", "for", "p", "in", "self", ".", "module", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "p", ")", ":", "\n", "                ", "dist", ".", "broadcast", "(", "p", ",", "src_rank", ",", "group", "=", "self", ".", "data_parallel_group", ")", "\n", "\n", "", "", "def", "allreduce_params", "(", "reduce_after", "=", "True", ",", "no_scale", "=", "False", ",", "fp32_allreduce", "=", "False", ")", ":", "\n", "            ", "if", "(", "self", ".", "needs_reduction", ")", ":", "\n", "                ", "self", ".", "needs_reduction", "=", "False", "\n", "buckets", "=", "{", "}", "\n", "for", "name", ",", "param", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size": [[54, 62], ["torch.distributed.get_world_size", "torch.distributed.is_available", "torch.distributed.is_initialized"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size"], ["                        ", "tp", "=", "(", "param", ".", "data", ".", "type", "(", ")", ")", "\n", "if", "tp", "not", "in", "buckets", ":", "\n", "                            ", "buckets", "[", "tp", "]", "=", "[", "]", "\n", "", "buckets", "[", "tp", "]", ".", "append", "(", "param", ")", "\n", "", "", "if", "self", ".", "warn_on_half", ":", "\n", "                    ", "if", "torch", ".", "cuda", ".", "HalfTensor", "in", "buckets", ":", "\n", "                        ", "print", "(", "\"WARNING: gloo dist backend for half parameters may be extremely slow.\"", "+", "\n", "\" It is recommended to use the NCCL backend in this case.\"", ")", "\n", "self", ".", "warn_on_half", "=", "False", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce": [[64, 73], ["distributed.get_world_size", "torch.distributed.all_reduce"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_reduce"], ["                    ", "bucket", "=", "buckets", "[", "tp", "]", "\n", "grads", "=", "[", "param", ".", "grad", ".", "data", "for", "param", "in", "bucket", "]", "\n", "coalesced", "=", "_flatten_dense_tensors", "(", "grads", ")", "\n", "if", "fp32_allreduce", ":", "\n", "                        ", "coalesced", "=", "coalesced", ".", "float", "(", ")", "\n", "", "if", "not", "no_scale", "and", "not", "reduce_after", ":", "\n", "                        ", "coalesced", "/=", "dist", ".", "get_world_size", "(", "group", "=", "self", ".", "data_parallel_group", ")", "\n", "", "dist", ".", "all_reduce", "(", "coalesced", ",", "group", "=", "self", ".", "data_parallel_group", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "if", "not", "no_scale", "and", "reduce_after", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_gather": [[75, 108], ["distributed.get_world_size", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.IntTensor().to", "torch.distributed.all_gather", "max", "torch.distributed.all_gather", "zip", "torch.IntTensor().to", "int", "tensor_list.append", "torch.ByteTensor().to", "torch.cat", "data_list.append", "torch.ByteTensor", "torch.IntTensor", "range", "size.item", "torch.ByteTensor().to", "torch.cat.cpu().numpy().tobytes", "pickle.loads", "torch.IntTensor", "torch.ByteTensor", "torch.cat.numel", "torch.ByteTensor", "torch.cat.cpu().numpy", "torch.cat.cpu"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_gather", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.all_gather"], ["", "for", "buf", ",", "synced", "in", "zip", "(", "grads", ",", "_unflatten_dense_tensors", "(", "coalesced", ",", "grads", ")", ")", ":", "\n", "                        ", "buf", ".", "copy_", "(", "synced", ")", "\n", "", "", "", "", "self", ".", "hook_handles", "=", "[", "]", "\n", "self", ".", "hooks", "=", "[", "]", "\n", "for", "param", "in", "list", "(", "self", ".", "module", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "def", "allreduce_hook", "(", "*", "unused", ")", ":", "\n", "                ", "Variable", ".", "_execution_engine", ".", "queue_callback", "(", "allreduce_params", ")", "\n", "#    handle = param.register_hook(allreduce_hook)", "\n", "#self.hooks.append(allreduce_hook)", "\n", "#self.hook_handles.append(handle)", "\n", "", "", "self", ".", "allreduce_params", "=", "allreduce_params", "\n", "\n", "", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "needs_reduction", "=", "True", "\n", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "#[h.remove() for h in self.hook_handles]", "\n", "        ", "sd", "=", "self", ".", "module", ".", "state_dict", "(", "destination", ",", "prefix", ",", "keep_vars", ")", "\n", "# for handle, hook in zip(self.hook_handles, self.hooks):", "\n", "#     d = handle.hooks_dict_ref()", "\n", "#     d[handle.id] = hook", "\n", "\n", "return", "sd", "\n", "\n", "", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")", "\n", "\n", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.reduce_dict": [[110, 133], ["distributed.get_world_size", "torch.no_grad", "sorted", "torch.stack", "torch.distributed.reduce", "input_dict.keys", "keys.append", "torch.stack.append", "torch.distributed.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_world_size", "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.get_rank"], ["\n", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.data_sampler": [[135, 144], ["torch.utils.data.distributed.DistributedSampler", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler"], "function", ["None"], []], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.launch.find_free_port": [[10, 20], ["socket.socket", "socket.socket.bind", "socket.socket.close", "socket.socket.getsockname"], "function", ["None"], ["def", "find_free_port", "(", ")", ":", "\n", "    ", "import", "socket", "\n", "\n", "sock", "=", "socket", ".", "socket", "(", "socket", ".", "AF_INET", ",", "socket", ".", "SOCK_STREAM", ")", "\n", "\n", "sock", ".", "bind", "(", "(", "\"\"", ",", "0", ")", ")", "\n", "port", "=", "sock", ".", "getsockname", "(", ")", "[", "1", "]", "\n", "sock", ".", "close", "(", ")", "\n", "\n", "return", "port", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.launch.launch": [[22, 50], ["torch.multiprocessing.spawn", "fn", "launch.find_free_port", "dist_url.startswith", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.launch.find_free_port"], ["", "def", "launch", "(", "fn", ",", "n_gpu_per_machine", ",", "n_machine", "=", "1", ",", "machine_rank", "=", "0", ",", "dist_url", "=", "None", ",", "args", "=", "(", ")", ")", ":", "\n", "    ", "world_size", "=", "n_machine", "*", "n_gpu_per_machine", "\n", "\n", "if", "world_size", ">", "1", ":", "\n", "        ", "if", "\"OMP_NUM_THREADS\"", "not", "in", "os", ".", "environ", ":", "\n", "            ", "os", ".", "environ", "[", "\"OMP_NUM_THREADS\"", "]", "=", "\"1\"", "\n", "\n", "", "if", "dist_url", "==", "\"auto\"", ":", "\n", "            ", "if", "n_machine", "!=", "1", ":", "\n", "                ", "raise", "ValueError", "(", "'dist_url=\"auto\" not supported in multi-machine jobs'", ")", "\n", "\n", "", "port", "=", "find_free_port", "(", ")", "\n", "dist_url", "=", "f\"tcp://127.0.0.1:{port}\"", "\n", "\n", "", "if", "n_machine", ">", "1", "and", "dist_url", ".", "startswith", "(", "\"file://\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"file:// is not a reliable init method in multi-machine jobs. Prefer tcp://\"", "\n", ")", "\n", "\n", "", "mp", ".", "spawn", "(", "\n", "distributed_worker", ",", "\n", "nprocs", "=", "n_gpu_per_machine", ",", "\n", "args", "=", "(", "fn", ",", "world_size", ",", "n_gpu_per_machine", ",", "machine_rank", ",", "dist_url", ",", "args", ")", ",", "\n", "daemon", "=", "False", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "fn", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.distributed.launch.distributed_worker": [[52, 93], ["distributed.synchronize", "torch.cuda.set_device", "range", "fn", "torch.cuda.is_available", "OSError", "torch.distributed.init_process_group", "torch.cuda.device_count", "ValueError", "ValueError", "list", "torch.distributed.new_group", "OSError", "range", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.distributed.distributed.synchronize"], ["", "", "def", "distributed_worker", "(", "\n", "local_rank", ",", "fn", ",", "world_size", ",", "n_gpu_per_machine", ",", "machine_rank", ",", "dist_url", ",", "args", "\n", ")", ":", "\n", "    ", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "raise", "OSError", "(", "\"CUDA is not available. Please check your environments\"", ")", "\n", "\n", "", "global_rank", "=", "machine_rank", "*", "n_gpu_per_machine", "+", "local_rank", "\n", "\n", "try", ":", "\n", "        ", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "\"NCCL\"", ",", "\n", "init_method", "=", "dist_url", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "global_rank", ",", "\n", ")", "\n", "\n", "", "except", "Exception", ":", "\n", "        ", "raise", "OSError", "(", "\"failed to initialize NCCL groups\"", ")", "\n", "\n", "", "dist_fn", ".", "synchronize", "(", ")", "\n", "\n", "if", "n_gpu_per_machine", ">", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"specified n_gpu_per_machine larger than available device ({torch.cuda.device_count()})\"", "\n", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "\n", "if", "dist_fn", ".", "LOCAL_PROCESS_GROUP", "is", "not", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"torch.distributed.LOCAL_PROCESS_GROUP is not None\"", ")", "\n", "\n", "", "n_machine", "=", "world_size", "//", "n_gpu_per_machine", "\n", "\n", "for", "i", "in", "range", "(", "n_machine", ")", ":", "\n", "        ", "ranks_on_i", "=", "list", "(", "range", "(", "i", "*", "n_gpu_per_machine", ",", "(", "i", "+", "1", ")", "*", "n_gpu_per_machine", ")", ")", "\n", "pg", "=", "dist", ".", "new_group", "(", "ranks_on_i", ")", "\n", "\n", "if", "i", "==", "machine_rank", ":", "\n", "            ", "dist_fn", ".", "distributed", ".", "LOCAL_PROCESS_GROUP", "=", "pg", "\n", "\n", "", "", "fn", "(", "*", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.inception_score.inception_score": [[10, 66], ["len", "torch.utils.data.DataLoader", "torchvision.models.inception.inception_v3().type", "inception_v3().type.eval", "torch.nn.Upsample().type", "numpy.zeros", "enumerate", "range", "torch.cuda.is_available", "inception_v3().type.", "torch.nn.functional.softmax().data.cpu().numpy", "batch.type.type", "torch.autograd.Variable", "inception_score.inception_score.get_pred"], "function", ["None"], ["def", "inception_score", "(", "imgs", ",", "cuda", "=", "True", ",", "batch_size", "=", "32", ",", "resize", "=", "False", ",", "splits", "=", "1", ")", ":", "\n", "    ", "\"\"\"Computes the inception score of the generated images imgs\n    imgs -- Torch dataset of (3xHxW) numpy images normalized in the range [-1, 1]\n    cuda -- whether or not to run on GPU\n    batch_size -- batch size for feeding into Inception v3\n    splits -- number of splits\n    \"\"\"", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "\n", "assert", "batch_size", ">", "0", "\n", "assert", "N", ">", "batch_size", "\n", "\n", "# Set up dtype", "\n", "if", "cuda", ":", "\n", "        ", "dtype", "=", "torch", ".", "cuda", ".", "FloatTensor", "\n", "", "else", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "print", "(", "\"WARNING: You have a CUDA device, so you should probably set cuda=True\"", ")", "\n", "", "dtype", "=", "torch", ".", "FloatTensor", "\n", "\n", "# Set up dataloader", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "imgs", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# Load inception model", "\n", "inception_model", "=", "inception_v3", "(", "pretrained", "=", "True", ",", "transform_input", "=", "False", ")", ".", "type", "(", "dtype", ")", "\n", "inception_model", ".", "eval", "(", ")", "\n", "up", "=", "nn", ".", "Upsample", "(", "size", "=", "(", "299", ",", "299", ")", ",", "mode", "=", "'bilinear'", ")", ".", "type", "(", "dtype", ")", "\n", "def", "get_pred", "(", "x", ")", ":", "\n", "        ", "if", "resize", ":", "\n", "            ", "x", "=", "up", "(", "x", ")", "\n", "", "x", "=", "inception_model", "(", "x", ")", "\n", "return", "F", ".", "softmax", "(", "x", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Get predictions", "\n", "", "preds", "=", "np", ".", "zeros", "(", "(", "N", ",", "1000", ")", ")", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ",", "0", ")", ":", "\n", "        ", "batch", "=", "batch", ".", "type", "(", "dtype", ")", "\n", "batchv", "=", "Variable", "(", "batch", ")", "\n", "batch_size_i", "=", "batch", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "preds", "[", "i", "*", "batch_size", ":", "i", "*", "batch_size", "+", "batch_size_i", "]", "=", "get_pred", "(", "batchv", ")", "\n", "\n", "# Now compute the mean kl-div", "\n", "", "split_scores", "=", "[", "]", "\n", "\n", "for", "k", "in", "range", "(", "splits", ")", ":", "\n", "        ", "part", "=", "preds", "[", "k", "*", "(", "N", "//", "splits", ")", ":", "(", "k", "+", "1", ")", "*", "(", "N", "//", "splits", ")", ",", ":", "]", "\n", "py", "=", "np", ".", "mean", "(", "part", ",", "axis", "=", "0", ")", "\n", "scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "part", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "pyx", "=", "part", "[", "i", ",", ":", "]", "\n", "scores", ".", "append", "(", "entropy", "(", "pyx", ",", "py", ")", ")", "\n", "", "split_scores", ".", "append", "(", "np", ".", "exp", "(", "np", ".", "mean", "(", "scores", ")", ")", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "split_scores", ")", ",", "np", ".", "std", "(", "split_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.inception.InceptionV3.__init__": [[21, 106], ["torch.Module.__init__", "sorted", "max", "torch.ModuleList", "torch.ModuleList", "torchvision.models.inception_v3", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.parameters", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__"], ["def", "__init__", "(", "self", ",", "\n", "output_blocks", "=", "[", "DEFAULT_BLOCK_INDEX", "]", ",", "\n", "resize_input", "=", "True", ",", "\n", "normalize_input", "=", "True", ",", "\n", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Build pretrained InceptionV3\n\n        Parameters\n        ----------\n        output_blocks : list of int\n            Indices of blocks to return features of. Possible values are:\n                - 0: corresponds to output of first max pooling\n                - 1: corresponds to output of second max pooling\n                - 2: corresponds to output which is fed to aux classifier\n                - 3: corresponds to output of final average pooling\n        resize_input : bool\n            If true, bilinearly resizes input to width and height 299 before\n            feeding input to model. As the network without fully connected\n            layers is fully convolutional, it should be able to handle inputs\n            of arbitrary size, so resizing might not be strictly needed\n        normalize_input : bool\n            If true, normalizes the input to the statistics the pretrained\n            Inception network expects\n        requires_grad : bool\n            If true, parameters of the model require gradient. Possibly useful\n            for finetuning the network\n        \"\"\"", "\n", "super", "(", "InceptionV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "resize_input", "=", "resize_input", "\n", "self", ".", "normalize_input", "=", "normalize_input", "\n", "self", ".", "output_blocks", "=", "sorted", "(", "output_blocks", ")", "\n", "self", ".", "last_needed_block", "=", "max", "(", "output_blocks", ")", "\n", "\n", "assert", "self", ".", "last_needed_block", "<=", "3", ",", "'Last possible output block index is 3'", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "inception", "=", "models", ".", "inception_v3", "(", "pretrained", "=", "True", ")", "\n", "\n", "# Block 0: input to maxpool1", "\n", "block0", "=", "[", "\n", "inception", ".", "Conv2d_1a_3x3", ",", "\n", "inception", ".", "Conv2d_2a_3x3", ",", "\n", "inception", ".", "Conv2d_2b_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block0", ")", ")", "\n", "\n", "# Block 1: maxpool1 to maxpool2", "\n", "if", "self", ".", "last_needed_block", ">=", "1", ":", "\n", "            ", "block1", "=", "[", "\n", "inception", ".", "Conv2d_3b_1x1", ",", "\n", "inception", ".", "Conv2d_4a_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block1", ")", ")", "\n", "\n", "# Block 2: maxpool2 to aux classifier", "\n", "", "if", "self", ".", "last_needed_block", ">=", "2", ":", "\n", "            ", "block2", "=", "[", "\n", "inception", ".", "Mixed_5b", ",", "\n", "inception", ".", "Mixed_5c", ",", "\n", "inception", ".", "Mixed_5d", ",", "\n", "inception", ".", "Mixed_6a", ",", "\n", "inception", ".", "Mixed_6b", ",", "\n", "inception", ".", "Mixed_6c", ",", "\n", "inception", ".", "Mixed_6d", ",", "\n", "inception", ".", "Mixed_6e", ",", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block2", ")", ")", "\n", "\n", "# Block 3: aux classifier to final avgpool", "\n", "", "if", "self", ".", "last_needed_block", ">=", "3", ":", "\n", "            ", "block3", "=", "[", "\n", "inception", ".", "Mixed_7a", ",", "\n", "inception", ".", "Mixed_7b", ",", "\n", "inception", ".", "Mixed_7c", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block3", ")", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.inception.InceptionV3.forward": [[107, 142], ["enumerate", "torch.upsample", "torch.upsample", "block.clone", "block", "outp.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"Get Inception feature maps\n\n        Parameters\n        ----------\n        inp : torch.autograd.Variable\n            Input tensor of shape Bx3xHxW. Values are expected to be in \n            range (0, 1)\n\n        Returns\n        -------\n        List of torch.autograd.Variable, corresponding to the selected output \n        block, sorted ascending by index\n        \"\"\"", "\n", "outp", "=", "[", "]", "\n", "x", "=", "inp", "\n", "\n", "if", "self", ".", "resize_input", ":", "\n", "            ", "x", "=", "F", ".", "upsample", "(", "x", ",", "size", "=", "(", "299", ",", "299", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "x", ".", "clone", "(", ")", "\n", "x", "[", ":", ",", "0", "]", "=", "x", "[", ":", ",", "0", "]", "*", "(", "0.229", "/", "0.5", ")", "+", "(", "0.485", "-", "0.5", ")", "/", "0.5", "\n", "x", "[", ":", ",", "1", "]", "=", "x", "[", ":", ",", "1", "]", "*", "(", "0.224", "/", "0.5", ")", "+", "(", "0.456", "-", "0.5", ")", "/", "0.5", "\n", "x", "[", ":", ",", "2", "]", "=", "x", "[", ":", ",", "2", "]", "*", "(", "0.225", "/", "0.5", ")", "+", "(", "0.406", "-", "0.5", ")", "/", "0.5", "\n", "\n", "", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "if", "idx", "in", "self", ".", "output_blocks", ":", "\n", "                ", "outp", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "idx", "==", "self", ".", "last_needed_block", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "outp", "\n", "", "", ""]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.get_activations": [[69, 131], ["model.eval", "numpy.empty", "enumerate", "images.__len__", "print", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy().reshape", "print", "batch.cuda.cuda", "model", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy", "torch.nn.functional.adaptive_avg_pool2d.cpu"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.StreamingRarDataset.__len__"], ["def", "get_activations", "(", "images", ",", "model", ",", "batch_size", "=", "64", ",", "dims", "=", "2048", ",", "cuda", "=", "False", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- images      : Numpy array of dimension (n_images, 3, hi, wi). The values\n                     must lie between 0 and 1.\n    -- model       : Instance of inception model\n    -- batch_size  : the images numpy array is split into batches with\n                     batch size batch_size. A reasonable batch size depends\n                     on the hardware.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the number\n                     of calculated batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, dims) that contains the\n       activations of the given tensor when feeding inception with the\n       query tensor.\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "#d0 = images.shape[0]", "\n", "\n", "d0", "=", "images", ".", "__len__", "(", ")", "*", "batch_size", "\n", "if", "batch_size", ">", "d0", ":", "\n", "        ", "print", "(", "(", "'Warning: batch size is bigger than the data size. '", "\n", "'Setting batch size to data size'", ")", ")", "\n", "batch_size", "=", "d0", "\n", "\n", "", "n_batches", "=", "d0", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "dims", ")", ")", "\n", "#for i in range(n_batches):", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "images", ")", ":", "\n", "#batch = batch[0]", "\n", "#if verbose:", "\n", "#print('\\rPropagating batch %d/%d' % (i + 1, n_batches), end='', flush=True)", "\n", "#import ipdb", "\n", "#ipdb.set_trace()", "\n", "        ", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "#batch = torch.from_numpy(images[start:end]).type(torch.FloatTensor)", "\n", "#batch = Variable(batch, volatile=True)", "\n", "\n", "if", "cuda", ":", "\n", "            ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "\n", "", "pred", "=", "model", "(", "batch", ")", "[", "0", "]", "\n", "\n", "# If model output is not scalar, apply global spatial average pooling.", "\n", "# This happens if you choose a dimensionality not equal 2048.", "\n", "if", "pred", ".", "shape", "[", "2", "]", "!=", "1", "or", "pred", ".", "shape", "[", "3", "]", "!=", "1", ":", "\n", "            ", "pred", "=", "adaptive_avg_pool2d", "(", "pred", ",", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "' done'", ")", "\n", "\n", "", "return", "pred_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_frechet_distance": [[133, 188], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "print", "scipy.linalg.sqrtm", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["", "def", "calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n\n    Stable version by Dougal J. Sutherland.\n\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an \n               representive data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an \n               representive data set.\n\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# Product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "        ", "msg", "=", "(", "'fid calculation produces singular product; '", "\n", "'adding %s to diagonal of cov estimates'", ")", "%", "eps", "\n", "print", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# Numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "        ", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "            ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "'Imaginary component {}'", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "return", "(", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "\n", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_activation_statistics": [[190, 214], ["fid_score.get_activations", "numpy.mean", "numpy.cov"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.get_activations"], ["", "def", "calculate_activation_statistics", "(", "images", ",", "model", ",", "batch_size", "=", "64", ",", "\n", "dims", "=", "2048", ",", "cuda", "=", "False", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Calculation of the statistics used by the FID.\n    Params:\n    -- images      : Numpy array of dimension (n_images, 3, hi, wi). The values\n                     must lie between 0 and 1.\n    -- model       : Instance of inception model\n    -- batch_size  : The images numpy array is split into batches with\n                     batch size batch_size. A reasonable batch size\n                     depends on the hardware.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the\n                     number of calculated batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the inception model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the inception model.\n    \"\"\"", "\n", "act", "=", "get_activations", "(", "images", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ",", "verbose", ")", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score._compute_statistics_of_path": [[215, 230], ["path.endswith", "numpy.load", "np.load.close", "img_data.Dataset", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "fid_score.calculate_activation_statistics", "torchvision.Compose", "img_data.Dataset.__len__", "torchvision.Resize", "torchvision.ToTensor"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_activation_statistics", "home.repos.pwc.inspect_result.THUDM_CogView.preprocess.raw_datasets.StreamingRarDataset.__len__"], ["", "def", "_compute_statistics_of_path", "(", "path", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", ":", "\n", "    ", "if", "path", ".", "endswith", "(", "'.npz'", ")", ":", "\n", "        ", "f", "=", "np", ".", "load", "(", "path", ")", "\n", "m", ",", "s", "=", "f", "[", "'mu'", "]", "[", ":", "]", ",", "f", "[", "'sigma'", "]", "[", ":", "]", "\n", "f", ".", "close", "(", ")", "\n", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "img_data", ".", "Dataset", "(", "path", ",", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "299", ",", "299", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", ")", "\n", "print", "(", "dataset", ".", "__len__", "(", ")", ")", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "drop_last", "=", "True", ",", "num_workers", "=", "8", ")", "\n", "m", ",", "s", "=", "calculate_activation_statistics", "(", "dataloader", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "", "return", "m", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_fid_given_dataset": [[231, 244], ["inception.InceptionV3", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "fid_score.calculate_activation_statistics", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "fid_score.calculate_activation_statistics", "fid_score.calculate_frechet_distance", "inception.InceptionV3.cuda"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_activation_statistics", "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_activation_statistics", "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_frechet_distance"], ["", "def", "calculate_fid_given_dataset", "(", "dataset1", ",", "dataset2", ",", "batch_size", ",", "cuda", "=", "True", ",", "dims", "=", "2048", ")", ":", "\n", "    ", "\"\"\"Calculates the FID of two dataset\"\"\"", "\n", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", "\n", "if", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "loader1", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset1", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "drop_last", "=", "True", ",", "num_workers", "=", "8", ")", "\n", "m1", ",", "s1", "=", "calculate_activation_statistics", "(", "loader1", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "loader2", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset2", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "drop_last", "=", "True", ",", "num_workers", "=", "8", ")", "\n", "m2", ",", "s2", "=", "calculate_activation_statistics", "(", "loader2", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "return", "fid_value", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_fid_given_paths": [[246, 261], ["inception.InceptionV3", "fid_score._compute_statistics_of_path", "fid_score._compute_statistics_of_path", "fid_score.calculate_frechet_distance", "inception.InceptionV3.cuda", "os.path.exists", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score._compute_statistics_of_path", "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score._compute_statistics_of_path", "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.fid_score.calculate_frechet_distance"], ["", "def", "calculate_fid_given_paths", "(", "paths", ",", "batch_size", ",", "cuda", ",", "dims", ")", ":", "\n", "    ", "\"\"\"Calculates the FID of two paths\"\"\"", "\n", "for", "p", "in", "paths", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "p", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Invalid path: %s'", "%", "p", ")", "\n", "\n", "", "", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", "\n", "if", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "m1", ",", "s1", "=", "_compute_statistics_of_path", "(", "paths", "[", "0", "]", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "m2", ",", "s2", "=", "_compute_statistics_of_path", "(", "paths", "[", "1", "]", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "return", "fid_value", "\n", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__init__": [[10, 25], ["open", "csv.reader", "Image.open().convert", "dataset.TsvDataset.transform", "print", "Image.open", "torch.zeros", "io.BytesIO", "base64.urlsafe_b64decode"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "transform", "=", "None", ",", "caption_only", "=", "False", ")", ":", "\n", "        ", "self", ".", "f", "=", "open", "(", "path", ",", "\"r\"", ")", "\n", "self", ".", "tsvreader", "=", "csv", ".", "reader", "(", "self", ".", "f", ",", "delimiter", "=", "'\\t'", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "caption_only", "=", "caption_only", "\n", "def", "callback_fn", "(", "image_base64", ",", "id", ",", "caption", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "img", "=", "Image", ".", "open", "(", "BytesIO", "(", "base64", ".", "urlsafe_b64decode", "(", "image_base64", ")", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                    ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "id", ",", "caption", "\n", "", "except", "(", "PIL", ".", "UnidentifiedImageError", ",", "PIL", ".", "Image", ".", "DecompressionBombError", ")", ":", "\n", "                ", "print", "(", "\"UnidentifiedImageError\"", ")", "\n", "return", "torch", ".", "zeros", "(", "(", "3", ",", "256", ",", "256", ")", ")", ",", "\"not_a_image\"", ",", "\"not_a_caption\"", "\n", "", "", "self", ".", "callback_fn", "=", "callback_fn", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__iter__": [[25, 34], ["iter", "dataset.TsvDataset.__iter__.get_next"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "def", "get_next", "(", ")", ":", "\n", "            ", "if", "self", ".", "caption_only", ":", "\n", "                ", "for", "line", "in", "self", ".", "tsvreader", ":", "\n", "                    ", "yield", "self", ".", "callback_fn", "(", "torch", ".", "zeros", "(", "(", "3", ",", "256", ",", "256", ")", ")", ",", "line", "[", "0", "]", ",", "line", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "line", "in", "self", ".", "tsvreader", ":", "\n", "                    ", "yield", "self", ".", "callback_fn", "(", "line", "[", "3", "]", ",", "line", "[", "0", "]", ",", "line", "[", "2", "]", ")", "\n", "", "", "", "return", "iter", "(", "get_next", "(", ")", ")", "\n", "", "def", "__del__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THUDM_CogView.eval_utils.dataset.TsvDataset.__del__": [[34, 36], ["dataset.TsvDataset.f.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "f", ".", "close", "(", ")", "", "", "", ""]]}