{"home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.stochastic_policy.StochasticNNPolicy.__init__": [[14, 36], ["garage.core.serializable.Serializable.quick_init", "garage.envs.util.flat_dim", "garage.envs.util.flat_dim", "tensorflow.placeholder", "stochastic_policy.StochasticNNPolicy.actions_for", "nn_policy.NNPolicy.__init__", "locals", "list"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.stochastic_policy.StochasticNNPolicy.actions_for", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["def", "__init__", "(", "self", ",", "\n", "env_spec", ",", "\n", "hidden_layer_sizes", ",", "\n", "squash", "=", "True", ",", "\n", "name", "=", "'policy'", ")", ":", "\n", "        ", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "self", ".", "_action_dim", "=", "flat_dim", "(", "env_spec", ".", "action_space", ")", "\n", "self", ".", "_observation_dim", "=", "flat_dim", "(", "env_spec", ".", "observation_space", ")", "\n", "self", ".", "_layer_sizes", "=", "list", "(", "hidden_layer_sizes", ")", "+", "[", "self", ".", "_action_dim", "]", "\n", "self", ".", "_squash", "=", "squash", "\n", "self", ".", "_name", "=", "name", "\n", "\n", "self", ".", "_observation_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "self", ".", "_observation_dim", "]", ",", "\n", "name", "=", "'observation'", ")", "\n", "\n", "self", ".", "_actions", "=", "self", ".", "actions_for", "(", "self", ".", "_observation_ph", ")", "\n", "\n", "super", "(", "StochasticNNPolicy", ",", "self", ")", ".", "__init__", "(", "\n", "env_spec", ",", "self", ".", "_observation_ph", ",", "self", ".", "_actions", ",", "self", ".", "_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.stochastic_policy.StochasticNNPolicy.actions_for": [[37, 58], ["tensorflow.random_normal", "tensorflow.shape", "tensorflow.variable_scope", "softqlearning.misc.nn.feedforward_net", "tensorflow.tanh"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.feedforward_net"], ["", "def", "actions_for", "(", "self", ",", "observations", ",", "n_action_samples", "=", "1", ",", "reuse", "=", "False", ")", ":", "\n", "\n", "        ", "n_state_samples", "=", "tf", ".", "shape", "(", "observations", ")", "[", "0", "]", "\n", "\n", "if", "n_action_samples", ">", "1", ":", "\n", "            ", "observations", "=", "observations", "[", ":", ",", "None", ",", ":", "]", "\n", "latent_shape", "=", "(", "n_state_samples", ",", "n_action_samples", ",", "\n", "self", ".", "_action_dim", ")", "\n", "", "else", ":", "\n", "            ", "latent_shape", "=", "(", "n_state_samples", ",", "self", ".", "_action_dim", ")", "\n", "\n", "", "latents", "=", "tf", ".", "random_normal", "(", "latent_shape", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "_name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "raw_actions", "=", "feedforward_net", "(", "\n", "(", "observations", ",", "latents", ")", ",", "\n", "layer_sizes", "=", "self", ".", "_layer_sizes", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "output_nonlinearity", "=", "None", ")", "\n", "\n", "", "return", "tf", ".", "tanh", "(", "raw_actions", ")", "if", "self", ".", "_squash", "else", "raw_actions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.__init__": [[9, 17], ["garage.core.serializable.Serializable.quick_init", "garage.tf.policies.base.Policy.__init__", "locals", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env_spec", ",", "obs_pl", ",", "action", ",", "scope_name", "=", "None", ")", ":", "\n", "        ", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "self", ".", "_obs_pl", "=", "obs_pl", "\n", "self", ".", "_action", "=", "action", "\n", "self", ".", "_scope_name", "=", "(", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "if", "not", "scope_name", "else", "scope_name", ")", "\n", "super", "(", "NNPolicy", ",", "self", ")", ".", "__init__", "(", "env_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.get_action": [[18, 21], ["nn_policy.NNPolicy.get_actions"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.get_actions"], ["", "@", "overrides", "\n", "def", "get_action", "(", "self", ",", "observation", ")", ":", "\n", "        ", "return", "self", ".", "get_actions", "(", "observation", "[", "None", "]", ")", "[", "0", "]", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.get_actions": [[22, 27], ["tensorflow.get_default_session().run", "tensorflow.get_default_session"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session"], ["", "@", "overrides", "\n", "def", "get_actions", "(", "self", ",", "observations", ")", ":", "\n", "        ", "feeds", "=", "{", "self", ".", "_obs_pl", ":", "observations", "}", "\n", "actions", "=", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "self", ".", "_action", ",", "feeds", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.log_diagnostics": [[28, 31], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "log_diagnostics", "(", "self", ",", "paths", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.get_params_internal": [[32, 42], ["tensorflow.get_collection"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_params_internal", "(", "self", ",", "**", "tags", ")", ":", "\n", "# TODO: rewrite this using tensorflow collections", "\n", "        ", "if", "tags", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "scope", "=", "self", ".", "_scope_name", "\n", "# Add \"/\" to 'scope' unless it's empty (otherwise get_collection will", "\n", "# return all parameters that start with 'scope'.", "\n", "scope", "=", "scope", "if", "scope", "==", "''", "else", "scope", "+", "'/'", "\n", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.union_buffer.UnionBuffer.__init__": [[7, 13], ["numpy.array", "sum"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "buffers", ")", ":", "\n", "        ", "buffer_sizes", "=", "np", ".", "array", "(", "[", "b", ".", "size", "for", "b", "in", "buffers", "]", ")", "\n", "self", ".", "_total_size", "=", "sum", "(", "buffer_sizes", ")", "\n", "self", ".", "_normalized_buffer_sizes", "=", "buffer_sizes", "/", "self", ".", "_total_size", "\n", "\n", "self", ".", "buffers", "=", "buffers", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.union_buffer.UnionBuffer.add_sample": [[14, 16], ["None"], "methods", ["None"], ["", "def", "add_sample", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.union_buffer.UnionBuffer.terminate_episode": [[17, 19], ["None"], "methods", ["None"], ["", "def", "terminate_episode", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.union_buffer.UnionBuffer.size": [[20, 23], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_total_size", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.union_buffer.UnionBuffer.add_path": [[24, 26], ["None"], "methods", ["None"], ["", "def", "add_path", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.union_buffer.UnionBuffer.random_batch": [[27, 45], ["partial_batch_sizes.astype.astype.astype", "partial_batches[].keys", "sum", "buffer.random_batch", "numpy.concatenate", "zip", "union_buffer.UnionBuffer.random_batch.all_values"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.random_batch"], ["", "def", "random_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "\n", "# TODO: Hack", "\n", "        ", "partial_batch_sizes", "=", "self", ".", "_normalized_buffer_sizes", "*", "batch_size", "\n", "partial_batch_sizes", "=", "partial_batch_sizes", ".", "astype", "(", "int", ")", "\n", "partial_batch_sizes", "[", "0", "]", "=", "batch_size", "-", "sum", "(", "partial_batch_sizes", "[", "1", ":", "]", ")", "\n", "\n", "partial_batches", "=", "[", "\n", "buffer", ".", "random_batch", "(", "partial_batch_size", ")", "for", "buffer", ",", "\n", "partial_batch_size", "in", "zip", "(", "self", ".", "buffers", ",", "partial_batch_sizes", ")", "\n", "]", "\n", "\n", "def", "all_values", "(", "key", ")", ":", "\n", "            ", "return", "[", "partial_batch", "[", "key", "]", "for", "partial_batch", "in", "partial_batches", "]", "\n", "\n", "", "keys", "=", "partial_batches", "[", "0", "]", ".", "keys", "(", ")", "\n", "\n", "return", "{", "key", ":", "np", ".", "concatenate", "(", "all_values", "(", "key", ")", ",", "axis", "=", "0", ")", "for", "key", "in", "keys", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.replay_buffer.ReplayBuffer.add_sample": [[9, 16], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "add_sample", "(", "self", ",", "observation", ",", "action", ",", "reward", ",", "next_observation", ",", "\n", "terminal", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Add a transition tuple.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.replay_buffer.ReplayBuffer.terminate_episode": [[17, 25], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "terminate_episode", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Let the replay buffer know that the episode has terminated in case some\n        special book-keeping has to happen.\n        :return:\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.replay_buffer.ReplayBuffer.size": [[26, 33], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abc", ".", "abstractmethod", "\n", "def", "size", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        :return: # of unique items that can be sampled.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.replay_buffer.ReplayBuffer.add_path": [[34, 73], ["enumerate", "replay_buffer.ReplayBuffer.terminate_episode", "zip", "replay_buffer.ReplayBuffer.add_sample", "path.get", "path.get"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.terminate_episode", "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.add_sample"], ["", "def", "add_path", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        Add a path to the replay buffer.\n\n        This default implementation naively goes through every step, but you\n        may want to optimize this.\n\n        NOTE: You should NOT call \"terminate_episode\" after calling add_path.\n        It's assumed that this function handles the episode termination.\n\n        :param path: Dict like one outputted by railrl.samplers.util.rollout\n        \"\"\"", "\n", "for", "i", ",", "(", "\n", "obs", ",", "\n", "action", ",", "\n", "reward", ",", "\n", "next_obs", ",", "\n", "terminal", ",", "\n", "agent_info", ",", "\n", "env_info", "\n", ")", "in", "enumerate", "(", "zip", "(", "\n", "path", "[", "\"observations\"", "]", ",", "\n", "path", "[", "\"actions\"", "]", ",", "\n", "path", "[", "\"rewards\"", "]", ",", "\n", "path", "[", "\"next_observations\"", "]", ",", "\n", "path", "[", "\"terminals\"", "]", ",", "\n", "path", ".", "get", "(", "\"agent_infos\"", ",", "{", "}", ")", ",", "\n", "path", ".", "get", "(", "\"env_infos\"", ",", "{", "}", ")", ",", "\n", ")", ")", ":", "\n", "            ", "self", ".", "add_sample", "(", "\n", "observation", "=", "obs", ",", "\n", "action", "=", "action", ",", "\n", "reward", "=", "reward", ",", "\n", "next_observation", "=", "next_obs", ",", "\n", "terminal", "=", "terminal", ",", "\n", "agent_info", "=", "agent_info", ",", "\n", "env_info", "=", "env_info", ",", "\n", ")", "\n", "", "self", ".", "terminate_episode", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.replay_buffer.ReplayBuffer.random_batch": [[74, 82], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "random_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Return a batch of size `batch_size`.\n        :param batch_size:\n        :return:\n        \"\"\"", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.__init__": [[10, 33], ["replay_buffer.ReplayBuffer.__init__", "garage.core.serializable.Serializable.quick_init", "int", "garage.envs.util.flat_dim", "garage.envs.util.flat_dim", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "locals"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env_spec", ",", "max_replay_buffer_size", ")", ":", "\n", "        ", "super", "(", "SimpleReplayBuffer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "max_replay_buffer_size", "=", "int", "(", "max_replay_buffer_size", ")", "\n", "\n", "self", ".", "_env_spec", "=", "env_spec", "\n", "self", ".", "_observation_dim", "=", "flat_dim", "(", "env_spec", ".", "observation_space", ")", "\n", "self", ".", "_action_dim", "=", "flat_dim", "(", "env_spec", ".", "action_space", ")", "\n", "self", ".", "_max_buffer_size", "=", "max_replay_buffer_size", "\n", "self", ".", "_observations", "=", "np", ".", "zeros", "(", "(", "max_replay_buffer_size", ",", "\n", "self", ".", "_observation_dim", ")", ")", "\n", "# It's a bit memory inefficient to save the observations twice,", "\n", "# but it makes the code *much* easier since you no longer have to", "\n", "# worry about termination conditions.", "\n", "self", ".", "_next_obs", "=", "np", ".", "zeros", "(", "(", "max_replay_buffer_size", ",", "\n", "self", ".", "_observation_dim", ")", ")", "\n", "self", ".", "_actions", "=", "np", ".", "zeros", "(", "(", "max_replay_buffer_size", ",", "self", ".", "_action_dim", ")", ")", "\n", "self", ".", "_rewards", "=", "np", ".", "zeros", "(", "max_replay_buffer_size", ")", "\n", "# self._terminals[i] = a terminal was received at time i", "\n", "self", ".", "_terminals", "=", "np", ".", "zeros", "(", "max_replay_buffer_size", ",", "dtype", "=", "'uint8'", ")", "\n", "self", ".", "_top", "=", "0", "\n", "self", ".", "_size", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.add_sample": [[34, 43], ["simple_replay_buffer.SimpleReplayBuffer._advance"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer._advance"], ["", "def", "add_sample", "(", "self", ",", "observation", ",", "action", ",", "reward", ",", "terminal", ",", "\n", "next_observation", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_observations", "[", "self", ".", "_top", "]", "=", "observation", "\n", "self", ".", "_actions", "[", "self", ".", "_top", "]", "=", "action", "\n", "self", ".", "_rewards", "[", "self", ".", "_top", "]", "=", "reward", "\n", "self", ".", "_terminals", "[", "self", ".", "_top", "]", "=", "terminal", "\n", "self", ".", "_next_obs", "[", "self", ".", "_top", "]", "=", "next_observation", "\n", "\n", "self", ".", "_advance", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.terminate_episode": [[44, 46], ["None"], "methods", ["None"], ["", "def", "terminate_episode", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer._advance": [[47, 51], ["None"], "methods", ["None"], ["", "def", "_advance", "(", "self", ")", ":", "\n", "        ", "self", ".", "_top", "=", "(", "self", ".", "_top", "+", "1", ")", "%", "self", ".", "_max_buffer_size", "\n", "if", "self", ".", "_size", "<", "self", ".", "_max_buffer_size", ":", "\n", "            ", "self", ".", "_size", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.random_batch": [[52, 60], ["numpy.random.randint"], "methods", ["None"], ["", "", "def", "random_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "indices", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "_size", ",", "batch_size", ")", "\n", "return", "{", "\n", "'observations'", ":", "self", ".", "_observations", "[", "indices", "]", ",", "\n", "'actions'", ":", "self", ".", "_actions", "[", "indices", "]", ",", "\n", "'rewards'", ":", "self", ".", "_rewards", "[", "indices", "]", ",", "\n", "'terminals'", ":", "self", ".", "_terminals", "[", "indices", "]", ",", "\n", "'next_observations'", ":", "self", ".", "_next_obs", "[", "indices", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.size": [[62, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.__getstate__": [[66, 78], ["super().__getstate__", "super().__getstate__.update", "simple_replay_buffer.SimpleReplayBuffer._observations.tobytes", "simple_replay_buffer.SimpleReplayBuffer._actions.tobytes", "simple_replay_buffer.SimpleReplayBuffer._rewards.tobytes", "simple_replay_buffer.SimpleReplayBuffer._terminals.tobytes", "simple_replay_buffer.SimpleReplayBuffer._next_obs.tobytes"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.__getstate__"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "buffer_state", "=", "super", "(", "SimpleReplayBuffer", ",", "self", ")", ".", "__getstate__", "(", ")", "\n", "buffer_state", ".", "update", "(", "{", "\n", "'observations'", ":", "self", ".", "_observations", ".", "tobytes", "(", ")", ",", "\n", "'actions'", ":", "self", ".", "_actions", ".", "tobytes", "(", ")", ",", "\n", "'rewards'", ":", "self", ".", "_rewards", ".", "tobytes", "(", ")", ",", "\n", "'terminals'", ":", "self", ".", "_terminals", ".", "tobytes", "(", ")", ",", "\n", "'next_observations'", ":", "self", ".", "_next_obs", ".", "tobytes", "(", ")", ",", "\n", "'top'", ":", "self", ".", "_top", ",", "\n", "'size'", ":", "self", ".", "_size", ",", "\n", "}", ")", "\n", "return", "buffer_state", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.__setstate__": [[79, 96], ["super().__setstate__", "numpy.fromstring", "numpy.fromstring", "numpy.fromstring", "numpy.fromstring", "numpy.fromstring", "numpy.fromstring.reshape", "numpy.fromstring.reshape", "numpy.fromstring.reshape", "numpy.fromstring.reshape", "numpy.fromstring.reshape"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "buffer_state", ")", ":", "\n", "        ", "super", "(", "SimpleReplayBuffer", ",", "self", ")", ".", "__setstate__", "(", "buffer_state", ")", "\n", "\n", "flat_obs", "=", "np", ".", "fromstring", "(", "buffer_state", "[", "'observations'", "]", ")", "\n", "flat_next_obs", "=", "np", ".", "fromstring", "(", "buffer_state", "[", "'next_observations'", "]", ")", "\n", "flat_actions", "=", "np", ".", "fromstring", "(", "buffer_state", "[", "'actions'", "]", ")", "\n", "flat_reward", "=", "np", ".", "fromstring", "(", "buffer_state", "[", "'rewards'", "]", ")", "\n", "flat_terminals", "=", "np", ".", "fromstring", "(", "\n", "buffer_state", "[", "'terminals'", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "self", ".", "_observations", "=", "flat_obs", ".", "reshape", "(", "self", ".", "_max_buffer_size", ",", "-", "1", ")", "\n", "self", ".", "_next_obs", "=", "flat_next_obs", ".", "reshape", "(", "self", ".", "_max_buffer_size", ",", "-", "1", ")", "\n", "self", ".", "_actions", "=", "flat_actions", ".", "reshape", "(", "self", ".", "_max_buffer_size", ",", "-", "1", ")", "\n", "self", ".", "_rewards", "=", "flat_reward", ".", "reshape", "(", "self", ".", "_max_buffer_size", ")", "\n", "self", ".", "_terminals", "=", "flat_terminals", ".", "reshape", "(", "self", ".", "_max_buffer_size", ")", "\n", "self", ".", "_top", "=", "buffer_state", "[", "'top'", "]", "\n", "self", ".", "_size", "=", "buffer_state", "[", "'size'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.NNVFunction.__init__": [[12, 26], ["garage.core.serializable.Serializable.quick_init", "garage.envs.util.flat_dim", "tensorflow.placeholder", "softqlearning.misc.nn.MLPFunction.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "env_spec", ",", "\n", "hidden_layer_sizes", "=", "(", "100", ",", "100", ")", ",", "\n", "name", "=", "'value_function'", ")", ":", "\n", "        ", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "self", ".", "_Do", "=", "flat_dim", "(", "env_spec", ".", "observation_space", ")", "\n", "self", ".", "_observations_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "_Do", "]", ",", "name", "=", "'observations'", ")", "\n", "\n", "super", "(", "NNVFunction", ",", "self", ")", ".", "__init__", "(", "\n", "inputs", "=", "(", "self", ".", "_observations_ph", ",", ")", ",", "\n", "name", "=", "name", ",", "\n", "hidden_layer_sizes", "=", "hidden_layer_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.NNVFunction.eval": [[27, 29], ["super()._eval"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction._eval"], ["", "def", "eval", "(", "self", ",", "observations", ")", ":", "\n", "        ", "return", "super", "(", "NNVFunction", ",", "self", ")", ".", "_eval", "(", "(", "observations", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.NNVFunction.output_for": [[30, 33], ["super()._output_for"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction._output_for"], ["", "def", "output_for", "(", "self", ",", "observations", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "return", "super", "(", "NNVFunction", ",", "self", ")", ".", "_output_for", "(", "\n", "(", "observations", ",", ")", ",", "reuse", "=", "reuse", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.NNQFunction.__init__": [[36, 54], ["garage.core.serializable.Serializable.quick_init", "garage.envs.util.flat_dim", "garage.envs.util.flat_dim", "tensorflow.placeholder", "tensorflow.placeholder", "softqlearning.misc.nn.MLPFunction.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "env_spec", ",", "\n", "hidden_layer_sizes", "=", "(", "100", ",", "100", ")", ",", "\n", "name", "=", "'q_function'", ")", ":", "\n", "        ", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "self", ".", "_Da", "=", "flat_dim", "(", "env_spec", ".", "action_space", ")", "\n", "self", ".", "_Do", "=", "flat_dim", "(", "env_spec", ".", "observation_space", ")", "\n", "\n", "self", ".", "_observations_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "_Do", "]", ",", "name", "=", "'observations'", ")", "\n", "self", ".", "_actions_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "_Da", "]", ",", "name", "=", "'actions'", ")", "\n", "\n", "super", "(", "NNQFunction", ",", "self", ")", ".", "__init__", "(", "\n", "inputs", "=", "(", "self", ".", "_observations_ph", ",", "self", ".", "_actions_ph", ")", ",", "\n", "name", "=", "name", ",", "\n", "hidden_layer_sizes", "=", "hidden_layer_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.NNQFunction.output_for": [[55, 58], ["super()._output_for"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction._output_for"], ["", "def", "output_for", "(", "self", ",", "observations", ",", "actions", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "return", "super", "(", "NNQFunction", ",", "self", ")", ".", "_output_for", "(", "\n", "(", "observations", ",", "actions", ")", ",", "reuse", "=", "reuse", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.NNQFunction.eval": [[59, 61], ["super()._eval"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction._eval"], ["", "def", "eval", "(", "self", ",", "observations", ",", "actions", ")", ":", "\n", "        ", "return", "super", "(", "NNQFunction", ",", "self", ")", ".", "_eval", "(", "(", "observations", ",", "actions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.__init__": [[64, 79], ["garage.core.serializable.Serializable.quick_init", "garage.envs.util.flat_dim", "garage.envs.util.flat_dim", "tensorflow.placeholder", "tensorflow.placeholder", "value_function.SumQFunction.output_for", "locals"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.output_for"], ["    ", "def", "__init__", "(", "self", ",", "env_spec", ",", "q_functions", ")", ":", "\n", "        ", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "self", ".", "q_functions", "=", "q_functions", "\n", "\n", "self", ".", "_Da", "=", "flat_dim", "(", "env_spec", ".", "action_space", ")", "\n", "self", ".", "_Do", "=", "flat_dim", "(", "env_spec", ".", "observation_space", ")", "\n", "\n", "self", ".", "_observations_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "_Do", "]", ",", "name", "=", "'observations'", ")", "\n", "self", ".", "_actions_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "_Da", "]", ",", "name", "=", "'actions'", ")", "\n", "\n", "self", ".", "_output", "=", "self", ".", "output_for", "(", "\n", "self", ".", "_observations_ph", ",", "self", ".", "_actions_ph", ",", "reuse", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.output_for": [[80, 87], ["tensorflow.add_n", "qf.output_for"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.output_for"], ["", "def", "output_for", "(", "self", ",", "observations", ",", "actions", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "outputs", "=", "[", "\n", "qf", ".", "output_for", "(", "observations", ",", "actions", ",", "reuse", "=", "reuse", ")", "\n", "for", "qf", "in", "self", ".", "q_functions", "\n", "]", "\n", "output", "=", "tf", ".", "add_n", "(", "outputs", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction._eval": [[88, 95], ["softqlearning.misc.tf_utils.get_default_session().run", "softqlearning.misc.tf_utils.get_default_session"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session"], ["", "def", "_eval", "(", "self", ",", "observations", ",", "actions", ")", ":", "\n", "        ", "feeds", "=", "{", "\n", "self", ".", "_observations_ph", ":", "observations", ",", "\n", "self", ".", "_actions_ph", ":", "actions", "\n", "}", "\n", "\n", "return", "tf_utils", ".", "get_default_session", "(", ")", ".", "run", "(", "self", ".", "_output", ",", "feeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.get_param_values": [[96, 100], ["numpy.concatenate", "qf.get_param_values"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_param_values"], ["", "def", "get_param_values", "(", "self", ")", ":", "\n", "        ", "all_values_list", "=", "[", "qf", ".", "get_param_values", "(", ")", "for", "qf", "in", "self", ".", "q_functions", "]", "\n", "\n", "return", "np", ".", "concatenate", "(", "all_values_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.set_param_values": [[101, 109], ["numpy.split", "zip", "numpy.cumsum", "qf.set_param_values", "qf.get_param_values"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.set_param_values", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_param_values"], ["", "def", "set_param_values", "(", "self", ",", "all_values", ")", ":", "\n", "        ", "param_sizes", "=", "[", "qf", ".", "get_param_values", "(", ")", ".", "size", "for", "qf", "in", "self", ".", "q_functions", "]", "\n", "split_points", "=", "np", ".", "cumsum", "(", "param_sizes", ")", "[", ":", "-", "1", "]", "\n", "\n", "all_values_list", "=", "np", ".", "split", "(", "all_values", ",", "split_points", ")", "\n", "\n", "for", "values", ",", "qf", "in", "zip", "(", "all_values_list", ",", "self", ".", "q_functions", ")", ":", "\n", "            ", "qf", ".", "set_param_values", "(", "values", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.__init__": [[34, 137], ["rl_algorithm.RLAlgorithm.__init__", "garage.envs.util.flat_dim", "garage.envs.util.flat_dim", "sql.SQL._create_placeholders", "sql.SQL._create_td_update", "sql.SQL._create_svgd_update", "sql.SQL._create_target_ops", "softqlearning.misc.tf_utils.get_default_session", "sql.SQL._sess.run", "qf.get_param_values", "policy.get_param_values", "tensorflow.global_variables_initializer", "sql.SQL.qf.set_param_values", "sql.SQL.policy.set_param_values"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_placeholders", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_td_update", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_svgd_update", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_target_ops", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_param_values", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_param_values", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.set_param_values", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.set_param_values"], ["def", "__init__", "(", "\n", "self", ",", "\n", "base_kwargs", ",", "\n", "env", ",", "\n", "pool", ",", "\n", "qf", ",", "\n", "policy", ",", "\n", "plotter", "=", "None", ",", "\n", "policy_lr", "=", "1E-3", ",", "\n", "qf_lr", "=", "1E-3", ",", "\n", "value_n_particles", "=", "16", ",", "\n", "td_target_update_interval", "=", "1", ",", "\n", "kernel_fn", "=", "adaptive_isotropic_gaussian_kernel", ",", "\n", "kernel_n_particles", "=", "16", ",", "\n", "kernel_update_ratio", "=", "0.5", ",", "\n", "discount", "=", "0.99", ",", "\n", "reward_scale", "=", "1", ",", "\n", "use_saved_qf", "=", "False", ",", "\n", "use_saved_policy", "=", "False", ",", "\n", "save_full_state", "=", "False", ",", "\n", "train_qf", "=", "True", ",", "\n", "train_policy", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            base_kwargs (dict): Dictionary of base arguments that are directly\n                passed to the base `RLAlgorithm` constructor.\n            env (`rllab.Env`): rllab environment object.\n            pool (`PoolBase`): Replay buffer to add gathered samples to.\n            qf (`NNQFunction`): Q-function approximator.\n            policy: (`rllab.NNPolicy`): A policy function approximator.\n            plotter (`QFPolicyPlotter`): Plotter instance to be used for\n                visualizing Q-function during training.\n            qf_lr (`float`): Learning rate used for the Q-function approximator.\n            value_n_particles (`int`): The number of action samples used for\n                estimating the value of next state.\n            td_target_update_interval (`int`): How often the target network is\n                updated to match the current Q-function.\n            kernel_fn (function object): A function object that represents\n                a kernel function.\n            kernel_n_particles (`int`): Total number of particles per state\n                used in SVGD updates.\n            kernel_update_ratio ('float'): The ratio of SVGD particles used for\n                the computation of the inner/outer empirical expectation.\n            discount ('float'): Discount factor.\n            reward_scale ('float'): A factor that scales the raw rewards.\n                Useful for adjusting the temperature of the optimal Boltzmann\n                distribution.\n            use_saved_qf ('boolean'): If true, use the initial parameters provided\n                in the Q-function instead of reinitializing.\n            use_saved_policy ('boolean'): If true, use the initial parameters provided\n                in the policy instead of reinitializing.\n            save_full_state ('boolean'): If true, saves the full algorithm\n                state, including the replay buffer.\n        \"\"\"", "\n", "super", "(", "SQL", ",", "self", ")", ".", "__init__", "(", "**", "base_kwargs", ")", "\n", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "pool", "=", "pool", "\n", "self", ".", "qf", "=", "qf", "\n", "self", ".", "policy", "=", "policy", "\n", "self", ".", "plotter", "=", "plotter", "\n", "\n", "self", ".", "_qf_lr", "=", "qf_lr", "\n", "self", ".", "_policy_lr", "=", "policy_lr", "\n", "self", ".", "_discount", "=", "discount", "\n", "self", ".", "_reward_scale", "=", "reward_scale", "\n", "\n", "self", ".", "_value_n_particles", "=", "value_n_particles", "\n", "self", ".", "_qf_target_update_interval", "=", "td_target_update_interval", "\n", "\n", "self", ".", "_kernel_fn", "=", "kernel_fn", "\n", "self", ".", "_kernel_n_particles", "=", "kernel_n_particles", "\n", "self", ".", "_kernel_update_ratio", "=", "kernel_update_ratio", "\n", "\n", "self", ".", "_save_full_state", "=", "save_full_state", "\n", "self", ".", "_train_qf", "=", "train_qf", "\n", "self", ".", "_train_policy", "=", "train_policy", "\n", "\n", "self", ".", "_observation_dim", "=", "flat_dim", "(", "self", ".", "env", ".", "observation_space", ")", "\n", "self", ".", "_action_dim", "=", "flat_dim", "(", "self", ".", "env", ".", "action_space", ")", "\n", "\n", "self", ".", "_create_placeholders", "(", ")", "\n", "\n", "self", ".", "_training_ops", "=", "[", "]", "\n", "self", ".", "_target_ops", "=", "[", "]", "\n", "\n", "self", ".", "_create_td_update", "(", ")", "\n", "self", ".", "_create_svgd_update", "(", ")", "\n", "self", ".", "_create_target_ops", "(", ")", "\n", "\n", "if", "use_saved_qf", ":", "\n", "            ", "saved_qf_params", "=", "qf", ".", "get_param_values", "(", ")", "\n", "", "if", "use_saved_policy", ":", "\n", "            ", "saved_policy_params", "=", "policy", ".", "get_param_values", "(", ")", "\n", "\n", "", "self", ".", "_sess", "=", "tf_utils", ".", "get_default_session", "(", ")", "\n", "self", ".", "_sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "if", "use_saved_qf", ":", "\n", "            ", "self", ".", "qf", ".", "set_param_values", "(", "saved_qf_params", ")", "\n", "", "if", "use_saved_policy", ":", "\n", "            ", "self", ".", "policy", ".", "set_param_values", "(", "saved_policy_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_placeholders": [[138, 162], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "", "def", "_create_placeholders", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create all necessary placeholders.\"\"\"", "\n", "\n", "self", ".", "_observations_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "self", ".", "_observation_dim", "]", ",", "\n", "name", "=", "'observations'", ")", "\n", "\n", "self", ".", "_next_observations_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "self", ".", "_observation_dim", "]", ",", "\n", "name", "=", "'next_observations'", ")", "\n", "\n", "self", ".", "_actions_pl", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "_action_dim", "]", ",", "name", "=", "'actions'", ")", "\n", "\n", "self", ".", "_next_actions_ph", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "self", ".", "_action_dim", "]", ",", "name", "=", "'next_actions'", ")", "\n", "\n", "self", ".", "_rewards_pl", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "'rewards'", ")", "\n", "\n", "self", ".", "_terminals_pl", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "'terminals'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_td_update": [[163, 201], ["sql.SQL.qf.output_for", "sql.assert_shape", "tensorflow.reduce_logsumexp", "sql.assert_shape", "tensorflow.log", "tensorflow.stop_gradient", "sql.assert_shape", "tensorflow.variable_scope", "tensorflow.random_uniform", "sql.SQL.qf.output_for", "sql.assert_shape", "tensorflow.cast", "numpy.log", "tensorflow.reduce_mean", "tensorflow.train.AdamOptimizer().minimize", "sql.SQL._training_ops.append", "tensorflow.train.AdamOptimizer", "sql.SQL.qf.get_params_internal"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.output_for", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.output_for", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.get_params_internal"], ["", "def", "_create_td_update", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create a minimization operation for Q-function update.\"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'target'", ")", ":", "\n", "# The value of the next state is approximated with uniform samples.", "\n", "            ", "target_actions", "=", "tf", ".", "random_uniform", "(", "\n", "(", "1", ",", "self", ".", "_value_n_particles", ",", "self", ".", "_action_dim", ")", ",", "-", "1", ",", "1", ")", "\n", "q_value_targets", "=", "self", ".", "qf", ".", "output_for", "(", "\n", "observations", "=", "self", ".", "_next_observations_ph", "[", ":", ",", "None", ",", ":", "]", ",", "\n", "actions", "=", "target_actions", ")", "\n", "assert_shape", "(", "q_value_targets", ",", "[", "None", ",", "self", ".", "_value_n_particles", "]", ")", "\n", "\n", "", "self", ".", "_q_values", "=", "self", ".", "qf", ".", "output_for", "(", "\n", "self", ".", "_observations_ph", ",", "self", ".", "_actions_pl", ",", "reuse", "=", "True", ")", "\n", "assert_shape", "(", "self", ".", "_q_values", ",", "[", "None", "]", ")", "\n", "\n", "# Equation 10:", "\n", "next_value", "=", "tf", ".", "reduce_logsumexp", "(", "q_value_targets", ",", "axis", "=", "1", ")", "\n", "assert_shape", "(", "next_value", ",", "[", "None", "]", ")", "\n", "\n", "# Importance weights add just a constant to the value.", "\n", "next_value", "-=", "tf", ".", "log", "(", "tf", ".", "cast", "(", "self", ".", "_value_n_particles", ",", "tf", ".", "float32", ")", ")", "\n", "next_value", "+=", "self", ".", "_action_dim", "*", "np", ".", "log", "(", "2", ")", "\n", "\n", "# \\hat Q in Equation 11:", "\n", "ys", "=", "tf", ".", "stop_gradient", "(", "self", ".", "_reward_scale", "*", "self", ".", "_rewards_pl", "+", "(", "\n", "1", "-", "self", ".", "_terminals_pl", ")", "*", "self", ".", "_discount", "*", "next_value", ")", "\n", "assert_shape", "(", "ys", ",", "[", "None", "]", ")", "\n", "\n", "# Equation 11:", "\n", "bellman_residual", "=", "0.5", "*", "tf", ".", "reduce_mean", "(", "(", "ys", "-", "self", ".", "_q_values", ")", "**", "2", ")", "\n", "\n", "if", "self", ".", "_train_qf", ":", "\n", "            ", "td_train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "_qf_lr", ")", ".", "minimize", "(", "\n", "loss", "=", "bellman_residual", ",", "var_list", "=", "self", ".", "qf", ".", "get_params_internal", "(", ")", ")", "\n", "self", ".", "_training_ops", ".", "append", "(", "td_train_op", ")", "\n", "\n", "", "self", ".", "_bellman_residual", "=", "bellman_residual", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_svgd_update": [[202, 270], ["sql.SQL.policy.actions_for", "sql.assert_shape", "int", "tensorflow.split", "tensorflow.stop_gradient", "sql.assert_shape", "sql.assert_shape", "sql.SQL.qf.output_for", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.stop_gradient", "sql.assert_shape", "sql.SQL._kernel_fn", "tensorflow.expand_dims", "sql.assert_shape", "tensorflow.reduce_mean", "sql.assert_shape", "tensorflow.gradients", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.gradients", "sql.SQL.policy.get_params_internal", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize", "sql.SQL._training_ops.append", "tensorflow.reduce_sum", "zip", "sql.SQL.policy.get_params_internal", "tensorflow.stop_gradient", "sql.SQL.policy.get_params_internal"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.stochastic_policy.StochasticNNPolicy.actions_for", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.SumQFunction.output_for", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.get_params_internal", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.get_params_internal", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.get_params_internal"], ["", "def", "_create_svgd_update", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create a minimization operation for policy update (SVGD).\"\"\"", "\n", "\n", "actions", "=", "self", ".", "policy", ".", "actions_for", "(", "\n", "observations", "=", "self", ".", "_observations_ph", ",", "\n", "n_action_samples", "=", "self", ".", "_kernel_n_particles", ",", "\n", "reuse", "=", "True", ")", "\n", "assert_shape", "(", "actions", ",", "\n", "[", "None", ",", "self", ".", "_kernel_n_particles", ",", "self", ".", "_action_dim", "]", ")", "\n", "\n", "# SVGD requires computing two empirical expectations over actions", "\n", "# (see Appendix C1.1.). To that end, we first sample a single set of", "\n", "# actions, and later split them into two sets: `fixed_actions` are used", "\n", "# to evaluate the expectation indexed by `j` and `updated_actions`", "\n", "# the expectation indexed by `i`.", "\n", "n_updated_actions", "=", "int", "(", "\n", "self", ".", "_kernel_n_particles", "*", "self", ".", "_kernel_update_ratio", ")", "\n", "n_fixed_actions", "=", "self", ".", "_kernel_n_particles", "-", "n_updated_actions", "\n", "\n", "fixed_actions", ",", "updated_actions", "=", "tf", ".", "split", "(", "\n", "actions", ",", "[", "n_fixed_actions", ",", "n_updated_actions", "]", ",", "axis", "=", "1", ")", "\n", "fixed_actions", "=", "tf", ".", "stop_gradient", "(", "fixed_actions", ")", "\n", "assert_shape", "(", "fixed_actions", ",", "[", "None", ",", "n_fixed_actions", ",", "self", ".", "_action_dim", "]", ")", "\n", "assert_shape", "(", "updated_actions", ",", "\n", "[", "None", ",", "n_updated_actions", ",", "self", ".", "_action_dim", "]", ")", "\n", "\n", "svgd_target_values", "=", "self", ".", "qf", ".", "output_for", "(", "\n", "self", ".", "_observations_ph", "[", ":", ",", "None", ",", ":", "]", ",", "fixed_actions", ",", "reuse", "=", "True", ")", "\n", "\n", "# Target log-density. Q_soft in Equation 13:", "\n", "squash_correction", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "log", "(", "1", "-", "fixed_actions", "**", "2", "+", "EPS", ")", ",", "axis", "=", "-", "1", ")", "\n", "log_p", "=", "svgd_target_values", "+", "squash_correction", "\n", "\n", "grad_log_p", "=", "tf", ".", "gradients", "(", "log_p", ",", "fixed_actions", ")", "[", "0", "]", "\n", "grad_log_p", "=", "tf", ".", "expand_dims", "(", "grad_log_p", ",", "axis", "=", "2", ")", "\n", "grad_log_p", "=", "tf", ".", "stop_gradient", "(", "grad_log_p", ")", "\n", "assert_shape", "(", "grad_log_p", ",", "[", "None", ",", "n_fixed_actions", ",", "1", ",", "self", ".", "_action_dim", "]", ")", "\n", "\n", "kernel_dict", "=", "self", ".", "_kernel_fn", "(", "xs", "=", "fixed_actions", ",", "ys", "=", "updated_actions", ")", "\n", "\n", "# Kernel function in Equation 13:", "\n", "kappa", "=", "tf", ".", "expand_dims", "(", "kernel_dict", "[", "\"output\"", "]", ",", "dim", "=", "3", ")", "\n", "assert_shape", "(", "kappa", ",", "[", "None", ",", "n_fixed_actions", ",", "n_updated_actions", ",", "1", "]", ")", "\n", "\n", "# Stein Variational Gradient in Equation 13:", "\n", "action_gradients", "=", "tf", ".", "reduce_mean", "(", "\n", "kappa", "*", "grad_log_p", "+", "kernel_dict", "[", "\"gradient\"", "]", ",", "reduction_indices", "=", "1", ")", "\n", "assert_shape", "(", "action_gradients", ",", "\n", "[", "None", ",", "n_updated_actions", ",", "self", ".", "_action_dim", "]", ")", "\n", "\n", "# Propagate the gradient through the policy network (Equation 14).", "\n", "gradients", "=", "tf", ".", "gradients", "(", "\n", "updated_actions", ",", "\n", "self", ".", "policy", ".", "get_params_internal", "(", ")", ",", "\n", "grad_ys", "=", "action_gradients", ")", "\n", "\n", "surrogate_loss", "=", "tf", ".", "reduce_sum", "(", "[", "\n", "tf", ".", "reduce_sum", "(", "w", "*", "tf", ".", "stop_gradient", "(", "g", ")", ")", "\n", "for", "w", ",", "g", "in", "zip", "(", "self", ".", "policy", ".", "get_params_internal", "(", ")", ",", "gradients", ")", "\n", "]", ")", "\n", "\n", "if", "self", ".", "_train_policy", ":", "\n", "            ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "_policy_lr", ")", "\n", "svgd_training_op", "=", "optimizer", ".", "minimize", "(", "\n", "loss", "=", "-", "surrogate_loss", ",", "\n", "var_list", "=", "self", ".", "policy", ".", "get_params_internal", "(", ")", ")", "\n", "self", ".", "_training_ops", ".", "append", "(", "svgd_training_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._create_target_ops": [[271, 282], ["sql.SQL.qf.get_params_internal", "sql.SQL.qf.get_params_internal", "tensorflow.assign", "zip"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.get_params_internal", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.get_params_internal"], ["", "", "def", "_create_target_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create tensorflow operation for updating the target Q-function.\"\"\"", "\n", "if", "not", "self", ".", "_train_qf", ":", "\n", "            ", "return", "\n", "\n", "", "source_params", "=", "self", ".", "qf", ".", "get_params_internal", "(", ")", "\n", "target_params", "=", "self", ".", "qf", ".", "get_params_internal", "(", "scope", "=", "'target'", ")", "\n", "\n", "self", ".", "_target_ops", "=", "[", "\n", "tf", ".", "assign", "(", "tgt", ",", "src", ")", "\n", "for", "tgt", ",", "src", "in", "zip", "(", "target_params", ",", "source_params", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.train": [[285, 287], ["sql.SQL._train"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "_train", "(", "self", ".", "env", ",", "self", ".", "policy", ",", "self", ".", "pool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._init_training": [[288, 291], ["sql.SQL._sess.run"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "_init_training", "(", "self", ")", ":", "\n", "        ", "self", ".", "_sess", ".", "run", "(", "self", ".", "_target_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._do_training": [[292, 301], ["sql.SQL._get_feed_dict", "sql.SQL._sess.run", "sql.SQL._sess.run"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._get_feed_dict"], ["", "@", "overrides", "\n", "def", "_do_training", "(", "self", ",", "iteration", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Run the operations for updating training and target ops.\"\"\"", "\n", "\n", "feed_dict", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "self", ".", "_sess", ".", "run", "(", "self", ".", "_training_ops", ",", "feed_dict", ")", "\n", "\n", "if", "iteration", "%", "self", ".", "_qf_target_update_interval", "==", "0", "and", "self", ".", "_train_qf", ":", "\n", "            ", "self", ".", "_sess", ".", "run", "(", "self", ".", "_target_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._get_feed_dict": [[302, 314], ["None"], "methods", ["None"], ["", "", "def", "_get_feed_dict", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Construct a TensorFlow feed dictionary from a sample batch.\"\"\"", "\n", "\n", "feeds", "=", "{", "\n", "self", ".", "_observations_ph", ":", "batch", "[", "'observations'", "]", ",", "\n", "self", ".", "_actions_pl", ":", "batch", "[", "'actions'", "]", ",", "\n", "self", ".", "_next_observations_ph", ":", "batch", "[", "'next_observations'", "]", ",", "\n", "self", ".", "_rewards_pl", ":", "batch", "[", "'rewards'", "]", ",", "\n", "self", ".", "_terminals_pl", ":", "batch", "[", "'terminals'", "]", ",", "\n", "}", "\n", "\n", "return", "feeds", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.log_diagnostics": [[315, 337], ["sql.SQL._get_feed_dict", "sql.SQL._sess.run", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "sql.SQL.policy.log_diagnostics", "numpy.mean", "numpy.std", "sql.SQL.plotter.draw"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL._get_feed_dict", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.log_diagnostics", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter.draw"], ["", "@", "overrides", "\n", "def", "log_diagnostics", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Record diagnostic information.\n\n        Records the mean and standard deviation of Q-function and the\n        squared Bellman residual of the  s (mean squared Bellman error)\n        for a sample batch.\n\n        Also call the `draw` method of the plotter, if plotter is defined.\n        \"\"\"", "\n", "\n", "feeds", "=", "self", ".", "_get_feed_dict", "(", "batch", ")", "\n", "qf", ",", "bellman_residual", "=", "self", ".", "_sess", ".", "run", "(", "\n", "[", "self", ".", "_q_values", ",", "self", ".", "_bellman_residual", "]", ",", "feeds", ")", "\n", "\n", "logger", ".", "record_tabular", "(", "'qf-avg'", ",", "np", ".", "mean", "(", "qf", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'qf-std'", ",", "np", ".", "std", "(", "qf", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'mean-sq-bellman-error'", ",", "bellman_residual", ")", "\n", "\n", "self", ".", "policy", ".", "log_diagnostics", "(", "batch", ")", "\n", "if", "self", ".", "plotter", ":", "\n", "            ", "self", ".", "plotter", ".", "draw", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.get_snapshot": [[338, 358], ["state.update"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_snapshot", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Return loggable snapshot of the SQL algorithm.\n\n        If `self._save_full_state == True`, returns snapshot including the\n        replay buffer. If `self._save_full_state == False`, returns snapshot\n        of policy, Q-function, and environment instances.\n        \"\"\"", "\n", "\n", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'policy'", ":", "self", ".", "policy", ",", "\n", "'qf'", ":", "self", ".", "qf", ",", "\n", "'env'", ":", "self", ".", "env", ",", "\n", "}", "\n", "\n", "if", "self", ".", "_save_full_state", ":", "\n", "            ", "state", ".", "update", "(", "{", "'replay_buffer'", ":", "self", ".", "pool", "}", ")", "\n", "\n", "", "return", "state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.assert_shape": [[16, 20], ["tensor.shape.as_list", "all", "len", "len", "zip"], "function", ["None"], ["def", "assert_shape", "(", "tensor", ",", "expected_shape", ")", ":", "\n", "    ", "tensor_shape", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "\n", "assert", "len", "(", "tensor_shape", ")", "==", "len", "(", "expected_shape", ")", "\n", "assert", "all", "(", "[", "a", "==", "b", "for", "a", ",", "b", "in", "zip", "(", "tensor_shape", ",", "expected_shape", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm.__init__": [[21, 52], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "sampler", ",", "\n", "n_epochs", "=", "1000", ",", "\n", "n_train_repeat", "=", "1", ",", "\n", "epoch_length", "=", "1000", ",", "\n", "eval_n_episodes", "=", "10", ",", "\n", "eval_render", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_epochs (`int`): Number of epochs to run the training for.\n            n_train_repeat (`int`): Number of times to repeat the training\n                for single time step.\n            epoch_length (`int`): Epoch length.\n            eval_n_episodes (`int`): Number of rollouts to evaluate.\n            eval_render (`int`): Whether or not to render the evaluation\n                environment.\n        \"\"\"", "\n", "self", ".", "sampler", "=", "sampler", "\n", "\n", "self", ".", "_n_epochs", "=", "n_epochs", "\n", "self", ".", "_n_train_repeat", "=", "n_train_repeat", "\n", "self", ".", "_epoch_length", "=", "epoch_length", "\n", "\n", "self", ".", "_eval_n_episodes", "=", "eval_n_episodes", "\n", "self", ".", "_eval_render", "=", "eval_render", "\n", "\n", "self", ".", "env", "=", "None", "\n", "self", ".", "policy", "=", "None", "\n", "self", ".", "pool", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._train": [[53, 109], ["rl_algorithm.RLAlgorithm._init_training", "rl_algorithm.RLAlgorithm.sampler.initialize", "softqlearning.misc.utils.deep_clone", "softqlearning.misc.tf_utils.get_default_session().as_default", "gtimer.rename_root", "gtimer.reset", "gtimer.set_def_unique", "gtimer.timed_for", "range", "garage.misc.logger.push_prefix", "range", "rl_algorithm.RLAlgorithm._evaluate", "gtimer.stamp", "rl_algorithm.RLAlgorithm.get_snapshot", "garage.misc.logger.save_itr_params", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "rl_algorithm.RLAlgorithm.sampler.log_diagnostics", "garage.misc.logger.dump_tabular", "garage.misc.logger.pop_prefix", "softqlearning.misc.tf_utils.get_default_session", "rl_algorithm.RLAlgorithm.sampler.sample", "gtimer.stamp", "range", "gtimer.stamp", "gtimer.get_times", "time_itrs.get", "time_itrs.get", "rl_algorithm.RLAlgorithm.sampler.batch_ready", "rl_algorithm.RLAlgorithm._do_training", "gtimer.get_times", "rl_algorithm.RLAlgorithm.sampler.random_batch"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._init_training", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.initialize", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.deep_clone", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._evaluate", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm.get_snapshot", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.log_diagnostics", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.DummySampler.sample", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.batch_ready", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._do_training", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.random_batch"], ["", "def", "_train", "(", "self", ",", "env", ",", "policy", ",", "pool", ")", ":", "\n", "        ", "\"\"\"Perform RL training.\n\n        Args:\n            env (`rllab.Env`): Environment used for training\n            policy (`Policy`): Policy used for training\n            pool (`PoolBase`): Sample pool to add samples to\n        \"\"\"", "\n", "self", ".", "_init_training", "(", ")", "\n", "self", ".", "sampler", ".", "initialize", "(", "env", ",", "policy", ",", "pool", ")", "\n", "\n", "evaluation_env", "=", "deep_clone", "(", "env", ")", "if", "self", ".", "_eval_n_episodes", "else", "None", "\n", "\n", "with", "tf_utils", ".", "get_default_session", "(", ")", ".", "as_default", "(", ")", ":", "\n", "            ", "gt", ".", "rename_root", "(", "'RLAlgorithm'", ")", "\n", "gt", ".", "reset", "(", ")", "\n", "gt", ".", "set_def_unique", "(", "False", ")", "\n", "\n", "for", "epoch", "in", "gt", ".", "timed_for", "(", "\n", "range", "(", "self", ".", "_n_epochs", "+", "1", ")", ",", "save_itrs", "=", "True", ")", ":", "\n", "                ", "logger", ".", "push_prefix", "(", "'Epoch #%d | '", "%", "epoch", ")", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "_epoch_length", ")", ":", "\n", "                    ", "self", ".", "sampler", ".", "sample", "(", ")", "\n", "if", "not", "self", ".", "sampler", ".", "batch_ready", "(", ")", ":", "\n", "                        ", "continue", "\n", "", "gt", ".", "stamp", "(", "'sample'", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "_n_train_repeat", ")", ":", "\n", "                        ", "self", ".", "_do_training", "(", "\n", "iteration", "=", "t", "+", "epoch", "*", "self", ".", "_epoch_length", ",", "\n", "batch", "=", "self", ".", "sampler", ".", "random_batch", "(", ")", ")", "\n", "", "gt", ".", "stamp", "(", "'train'", ")", "\n", "\n", "", "self", ".", "_evaluate", "(", "policy", ",", "evaluation_env", ")", "\n", "gt", ".", "stamp", "(", "'eval'", ")", "\n", "\n", "params", "=", "self", ".", "get_snapshot", "(", "epoch", ")", "\n", "logger", ".", "save_itr_params", "(", "epoch", ",", "params", ")", "\n", "\n", "time_itrs", "=", "gt", ".", "get_times", "(", ")", ".", "stamps", ".", "itrs", "\n", "time_eval", "=", "time_itrs", "[", "'eval'", "]", "[", "-", "1", "]", "\n", "time_total", "=", "gt", ".", "get_times", "(", ")", ".", "total", "\n", "time_train", "=", "time_itrs", ".", "get", "(", "'train'", ",", "[", "0", "]", ")", "[", "-", "1", "]", "\n", "time_sample", "=", "time_itrs", ".", "get", "(", "'sample'", ",", "[", "0", "]", ")", "[", "-", "1", "]", "\n", "\n", "logger", ".", "record_tabular", "(", "'time-train'", ",", "time_train", ")", "\n", "logger", ".", "record_tabular", "(", "'time-eval'", ",", "time_eval", ")", "\n", "logger", ".", "record_tabular", "(", "'time-sample'", ",", "time_sample", ")", "\n", "logger", ".", "record_tabular", "(", "'time-total'", ",", "time_total", ")", "\n", "logger", ".", "record_tabular", "(", "'epoch'", ",", "epoch", ")", "\n", "\n", "self", ".", "sampler", ".", "log_diagnostics", "(", ")", "\n", "\n", "logger", ".", "dump_tabular", "(", "with_prefix", "=", "False", ")", "\n", "logger", ".", "pop_prefix", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._evaluate": [[110, 139], ["softqlearning.misc.sampler.rollouts", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "evaluation_env.log_diagnostics", "rl_algorithm.RLAlgorithm.sampler.batch_ready", "path[].sum", "len", "numpy.mean", "numpy.min", "numpy.max", "numpy.std", "numpy.mean", "numpy.min", "numpy.max", "numpy.std", "evaluation_env.render", "rl_algorithm.RLAlgorithm.sampler.random_batch", "rl_algorithm.RLAlgorithm.log_diagnostics"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.rollouts", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.log_diagnostics", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.batch_ready", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.render", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.random_batch", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.log_diagnostics"], ["", "", "", "def", "_evaluate", "(", "self", ",", "policy", ",", "evaluation_env", ")", ":", "\n", "        ", "\"\"\"Perform evaluation for the current policy.\"\"\"", "\n", "\n", "if", "self", ".", "_eval_n_episodes", "<", "1", ":", "\n", "            ", "return", "\n", "\n", "# TODO: max_path_length should be a property of environment.", "\n", "", "paths", "=", "rollouts", "(", "evaluation_env", ",", "policy", ",", "self", ".", "sampler", ".", "_max_path_length", ",", "\n", "self", ".", "_eval_n_episodes", ")", "\n", "\n", "total_returns", "=", "[", "path", "[", "'rewards'", "]", ".", "sum", "(", ")", "for", "path", "in", "paths", "]", "\n", "episode_lengths", "=", "[", "len", "(", "p", "[", "'rewards'", "]", ")", "for", "p", "in", "paths", "]", "\n", "\n", "logger", ".", "record_tabular", "(", "'return-average'", ",", "np", ".", "mean", "(", "total_returns", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'return-min'", ",", "np", ".", "min", "(", "total_returns", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'return-max'", ",", "np", ".", "max", "(", "total_returns", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'return-std'", ",", "np", ".", "std", "(", "total_returns", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'episode-length-avg'", ",", "np", ".", "mean", "(", "episode_lengths", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'episode-length-min'", ",", "np", ".", "min", "(", "episode_lengths", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'episode-length-max'", ",", "np", ".", "max", "(", "episode_lengths", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'episode-length-std'", ",", "np", ".", "std", "(", "episode_lengths", ")", ")", "\n", "\n", "evaluation_env", ".", "log_diagnostics", "(", "paths", ")", "\n", "if", "self", ".", "_eval_render", ":", "\n", "            ", "evaluation_env", ".", "render", "(", "paths", ")", "\n", "\n", "", "if", "self", ".", "sampler", ".", "batch_ready", "(", ")", ":", "\n", "            ", "batch", "=", "self", ".", "sampler", ".", "random_batch", "(", ")", "\n", "self", ".", "log_diagnostics", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm.log_diagnostics": [[140, 143], ["None"], "methods", ["None"], ["", "", "@", "abc", ".", "abstractmethod", "\n", "def", "log_diagnostics", "(", "self", ",", "batch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm.get_snapshot": [[144, 147], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_snapshot", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._do_training": [[148, 151], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_do_training", "(", "self", ",", "iteration", ",", "batch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.rl_algorithm.RLAlgorithm._init_training": [[152, 155], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_init_training", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.pusher.PusherEnv.__init__": [[28, 48], ["garage.envs.mujoco.mujoco_env.MujocoEnv.__init__", "garage.core.serializable.Serializable.quick_init", "[].astype", "locals", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["def", "__init__", "(", "self", ",", "goal", "=", "(", "0", ",", "-", "1", ")", ",", "arm_distance_coeff", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        goal (`list`): List of two elements denoting the x and y coordinates of\n            the goal location. Either of the coordinate can also be a string\n            'any' to make the reward not to depend on the corresponding\n            coordinate.\n        arm_distance_coeff ('float'): Coefficient for the arm-to-object distance\n            cost.\n        \"\"\"", "\n", "super", "(", "PusherEnv", ",", "self", ")", ".", "__init__", "(", "file_path", "=", "self", ".", "FILE_PATH", ")", "\n", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "self", ".", "_goal_mask", "=", "[", "coordinate", "!=", "'any'", "for", "coordinate", "in", "goal", "]", "\n", "self", ".", "_goal", "=", "np", ".", "array", "(", "goal", ")", "[", "self", ".", "_goal_mask", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "self", ".", "_arm_distance_coeff", "=", "arm_distance_coeff", "\n", "self", ".", "_action_cost_coeff", "=", "0.1", "\n", "\n", "# Make the the complete robot visible when visualizing.", "\n", "self", ".", "model", ".", "stat", ".", "extent", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.pusher.PusherEnv.step": [[49, 57], ["pusher.PusherEnv.compute_reward", "pusher.PusherEnv.forward_dynamics", "pusher.PusherEnv.get_current_obs", "pusher.PusherEnv.get_current_obs"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.compute_reward", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_current_obs", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_current_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "reward", ",", "info", "=", "self", ".", "compute_reward", "(", "self", ".", "get_current_obs", "(", ")", ",", "action", ")", "\n", "\n", "self", ".", "forward_dynamics", "(", "action", ")", "\n", "observation", "=", "self", ".", "get_current_obs", "(", ")", "\n", "done", "=", "False", "\n", "\n", "return", "observation", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.pusher.PusherEnv.compute_reward": [[58, 84], ["numpy.linalg.norm", "numpy.linalg.norm", "numpy.sum", "rewards.squeeze.squeeze.squeeze", "arm_dists.squeeze.squeeze.squeeze", "goal_dists.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "observations", ",", "actions", ")", ":", "\n", "        ", "is_batch", "=", "False", "\n", "if", "observations", ".", "ndim", "==", "1", ":", "\n", "            ", "observations", "=", "observations", "[", "None", "]", "\n", "actions", "=", "actions", "[", "None", "]", "\n", "is_batch", "=", "True", "\n", "\n", "", "arm_pos", "=", "observations", "[", ":", ",", "-", "6", ":", "-", "3", "]", "\n", "obj_pos", "=", "observations", "[", ":", ",", "-", "3", ":", "]", "\n", "obj_pos_masked", "=", "obj_pos", "[", ":", ",", ":", "2", "]", "[", ":", ",", "self", ".", "_goal_mask", "]", "\n", "\n", "goal_dists", "=", "np", ".", "linalg", ".", "norm", "(", "self", ".", "_goal", "[", "None", "]", "-", "obj_pos_masked", ",", "axis", "=", "1", ")", "\n", "arm_dists", "=", "np", ".", "linalg", ".", "norm", "(", "arm_pos", "-", "obj_pos", ",", "axis", "=", "1", ")", "\n", "ctrl_costs", "=", "np", ".", "sum", "(", "actions", "**", "2", ",", "axis", "=", "1", ")", "\n", "\n", "rewards", "=", "-", "self", ".", "_action_cost_coeff", "*", "ctrl_costs", "-", "goal_dists", "\n", "rewards", "-=", "self", ".", "_arm_distance_coeff", "*", "arm_dists", "\n", "\n", "if", "not", "is_batch", ":", "\n", "            ", "rewards", "=", "rewards", ".", "squeeze", "(", ")", "\n", "arm_dists", "=", "arm_dists", ".", "squeeze", "(", ")", "\n", "goal_dists", "=", "goal_dists", ".", "squeeze", "(", ")", "\n", "\n", "", "return", "rewards", ",", "{", "\n", "'arm_distance'", ":", "arm_dists", ",", "\n", "'goal_distance'", ":", "goal_dists", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.pusher.PusherEnv.viewer_setup": [[86, 100], ["numpy.random.uniform", "numpy.array", "range", "hasattr"], "methods", ["None"], ["", "def", "viewer_setup", "(", "self", ")", ":", "\n", "        ", "self", ".", "viewer", ".", "cam", ".", "trackbodyid", "=", "0", "\n", "self", ".", "viewer", ".", "cam", ".", "distance", "=", "4.0", "\n", "rotation_angle", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0", ",", "high", "=", "360", ")", "\n", "if", "hasattr", "(", "self", ",", "\"_kwargs\"", ")", "and", "'vp'", "in", "self", ".", "_kwargs", ":", "\n", "            ", "rotation_angle", "=", "self", ".", "_kwargs", "[", "'vp'", "]", "\n", "", "cam_dist", "=", "4", "\n", "cam_pos", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "cam_dist", ",", "-", "45", ",", "rotation_angle", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "self", ".", "viewer", ".", "cam", ".", "lookat", "[", "i", "]", "=", "cam_pos", "[", "i", "]", "\n", "", "self", ".", "viewer", ".", "cam", ".", "distance", "=", "cam_pos", "[", "3", "]", "\n", "self", ".", "viewer", ".", "cam", ".", "elevation", "=", "cam_pos", "[", "4", "]", "\n", "self", ".", "viewer", ".", "cam", ".", "azimuth", "=", "cam_pos", "[", "5", "]", "\n", "self", ".", "viewer", ".", "cam", ".", "trackbodyid", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.pusher.PusherEnv.reset": [[101, 133], ["pusher.PusherEnv.init_qvel.copy().squeeze", "numpy.zeros", "numpy.zeros", "numpy.concatenate", "super().reset", "pusher.PusherEnv.get_current_obs", "super().reset", "numpy.random.uniform", "pusher.PusherEnv.init_qpos.squeeze", "pusher.PusherEnv.init_qpos.squeeze", "numpy.array", "numpy.random.uniform", "numpy.linalg.norm", "pusher.PusherEnv.init_qvel.copy"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_current_obs", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset"], ["", "def", "reset", "(", "self", ",", "init_state", "=", "None", ")", ":", "\n", "        ", "if", "init_state", ":", "\n", "            ", "super", "(", "PusherEnv", ",", "self", ")", ".", "reset", "(", "init_state", ")", "\n", "return", "\n", "\n", "", "qpos", "=", "np", ".", "random", ".", "uniform", "(", "\n", "low", "=", "-", "0.1", ",", "high", "=", "0.1", ",", "size", "=", "self", ".", "model", ".", "nq", ")", "+", "self", ".", "init_qpos", ".", "squeeze", "(", ")", "\n", "qpos", "[", "self", ".", "TARGET_INDS", "]", "=", "self", ".", "init_qpos", ".", "squeeze", "(", ")", "[", "self", ".", "TARGET_INDS", "]", "\n", "\n", "# TODO.before_release: Hack for reproducing the exact results we have in", "\n", "# paper, remove before release.", "\n", "while", "True", ":", "\n", "            ", "puck_position", "=", "np", ".", "random", ".", "uniform", "(", "\n", "low", "=", "[", "0.3", ",", "-", "1.0", "]", ",", "high", "=", "[", "1.0", ",", "-", "0.4", "]", ")", ",", "\n", "\n", "bottom_right_corner", "=", "np", ".", "array", "(", "[", "1", ",", "-", "1", "]", ")", "\n", "if", "np", ".", "linalg", ".", "norm", "(", "puck_position", "-", "bottom_right_corner", ")", ">", "0.45", ":", "\n", "                ", "break", "\n", "\n", "", "", "qpos", "[", "self", ".", "PUCK_INDS", "]", "=", "puck_position", "\n", "\n", "qvel", "=", "self", ".", "init_qvel", ".", "copy", "(", ")", ".", "squeeze", "(", ")", "\n", "qvel", "[", "self", ".", "PUCK_INDS", "]", "=", "0", "\n", "qvel", "[", "self", ".", "TARGET_INDS", "]", "=", "0", "\n", "\n", "qacc", "=", "np", ".", "zeros", "(", "self", ".", "sim", ".", "data", ".", "qacc", ".", "shape", "[", "0", "]", ")", "\n", "ctrl", "=", "np", ".", "zeros", "(", "self", ".", "sim", ".", "data", ".", "ctrl", ".", "shape", "[", "0", "]", ")", "\n", "\n", "full_state", "=", "np", ".", "concatenate", "(", "(", "qpos", ",", "qvel", ",", "qacc", ",", "ctrl", ")", ")", "\n", "super", "(", "PusherEnv", ",", "self", ")", ".", "reset", "(", "full_state", ")", "\n", "\n", "return", "self", ".", "get_current_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.pusher.PusherEnv.get_current_obs": [[134, 142], ["numpy.concatenate().reshape", "numpy.concatenate", "pusher.PusherEnv.get_body_com", "pusher.PusherEnv.get_body_com"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_current_obs", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "sim", ".", "data", ".", "qpos", ".", "flat", "[", "self", ".", "JOINT_INDS", "]", ",", "\n", "self", ".", "sim", ".", "data", ".", "qvel", ".", "flat", "[", "self", ".", "JOINT_INDS", "]", ",", "\n", "self", ".", "get_body_com", "(", "\"distal_4\"", ")", ",", "\n", "self", ".", "get_body_com", "(", "\"object\"", ")", ",", "\n", "]", ")", ".", "reshape", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.pusher.PusherEnv.log_diagnostics": [[143, 157], ["garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "numpy.mean", "numpy.max", "numpy.min", "numpy.std", "numpy.mean", "numpy.max", "numpy.min", "numpy.std"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "log_diagnostics", "(", "self", ",", "paths", ")", ":", "\n", "        ", "arm_dists", "=", "[", "p", "[", "'env_infos'", "]", "[", "-", "1", "]", "[", "'arm_distance'", "]", "for", "p", "in", "paths", "]", "\n", "goal_dists", "=", "[", "p", "[", "'env_infos'", "]", "[", "-", "1", "]", "[", "'goal_distance'", "]", "for", "p", "in", "paths", "]", "\n", "\n", "logger", ".", "record_tabular", "(", "'FinalArmDistanceAvg'", ",", "np", ".", "mean", "(", "arm_dists", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'FinalArmDistanceMax'", ",", "np", ".", "max", "(", "arm_dists", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'FinalArmDistanceMin'", ",", "np", ".", "min", "(", "arm_dists", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'FinalArmDistanceStd'", ",", "np", ".", "std", "(", "arm_dists", ")", ")", "\n", "\n", "logger", ".", "record_tabular", "(", "'FinalGoalDistanceAvg'", ",", "np", ".", "mean", "(", "goal_dists", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'FinalGoalDistanceMax'", ",", "np", ".", "max", "(", "goal_dists", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'FinalGoalDistanceMin'", ",", "np", ".", "min", "(", "goal_dists", ")", ")", "\n", "logger", ".", "record_tabular", "(", "'FinalGoalDistanceStd'", ",", "np", ".", "std", "(", "goal_dists", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.CappedCubicVideoSchedule.__call__": [[38, 43], ["int", "round"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "count", ")", ":", "\n", "        ", "if", "count", "<", "1000", ":", "\n", "            ", "return", "int", "(", "round", "(", "count", "**", "(", "1.", "/", "3", ")", ")", ")", "**", "3", "==", "count", "\n", "", "else", ":", "\n", "            ", "return", "count", "%", "1000", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.FixedIntervalVideoSchedule.__init__": [[46, 48], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "interval", ")", ":", "\n", "        ", "self", ".", "interval", "=", "interval", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.FixedIntervalVideoSchedule.__call__": [[49, 51], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "count", ")", ":", "\n", "        ", "return", "count", "%", "self", ".", "interval", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.NoVideoSchedule.__call__": [[54, 56], ["None"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "count", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.__init__": [[59, 99], ["garage.core.serializable.Serializable.quick_init", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym.envs.make", "gym_env.convert_gym_space", "garage.misc.logger.log", "gym_env.convert_gym_space", "garage.misc.logger.log", "locals", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "gym.wrappers.Monitor", "garage.misc.logger.get_snapshot_dir", "garage.misc.logger.log", "os.path.join", "gym_env.NoVideoSchedule", "garage.misc.logger.get_snapshot_dir", "gym_env.CappedCubicVideoSchedule"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.convert_gym_space", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.convert_gym_space"], ["    ", "def", "__init__", "(", "self", ",", "env_name", ",", "record_video", "=", "False", ",", "video_schedule", "=", "None", ",", "log_dir", "=", "None", ",", "record_log", "=", "False", ",", "\n", "force_reset", "=", "True", ")", ":", "\n", "        ", "if", "log_dir", "is", "None", ":", "\n", "            ", "if", "logger", ".", "get_snapshot_dir", "(", ")", "is", "None", ":", "\n", "                ", "logger", ".", "log", "(", "\"Warning: skipping Gym environment monitoring since snapshot_dir not configured.\"", ")", "\n", "", "else", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "logger", ".", "get_snapshot_dir", "(", ")", ",", "\"gym_log\"", ")", "\n", "", "", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "env", "=", "gym", ".", "envs", ".", "make", "(", "env_name", ")", "\n", "\n", "# HACK: Gets rid of the TimeLimit wrapper that sets 'done = True' when", "\n", "# the time limit specified for each environment has been passed and", "\n", "# therefore the environment is not Markovian (terminal condition depends", "\n", "# on time rather than state).", "\n", "env", "=", "env", ".", "env", "\n", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "env_id", "=", "env", ".", "spec", ".", "id", "\n", "\n", "assert", "not", "(", "not", "record_log", "and", "record_video", ")", "\n", "\n", "if", "log_dir", "is", "None", "or", "record_log", "is", "False", ":", "\n", "            ", "self", ".", "monitoring", "=", "False", "\n", "", "else", ":", "\n", "            ", "if", "not", "record_video", ":", "\n", "                ", "video_schedule", "=", "NoVideoSchedule", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "video_schedule", "is", "None", ":", "\n", "                    ", "video_schedule", "=", "CappedCubicVideoSchedule", "(", ")", "\n", "", "", "self", ".", "env", "=", "gym", ".", "wrappers", ".", "Monitor", "(", "self", ".", "env", ",", "log_dir", ",", "video_callable", "=", "video_schedule", ",", "force", "=", "True", ")", "\n", "self", ".", "monitoring", "=", "True", "\n", "\n", "", "self", ".", "_observation_space", "=", "convert_gym_space", "(", "env", ".", "observation_space", ")", "\n", "logger", ".", "log", "(", "\"observation space: {}\"", ".", "format", "(", "self", ".", "_observation_space", ")", ")", "\n", "self", ".", "_action_space", "=", "convert_gym_space", "(", "env", ".", "action_space", ")", "\n", "logger", ".", "log", "(", "\"action space: {}\"", ".", "format", "(", "self", ".", "_action_space", ")", ")", "\n", "self", ".", "_horizon", "=", "env", ".", "spec", ".", "tags", "[", "'wrapper_config.TimeLimit.max_episode_steps'", "]", "\n", "self", ".", "_log_dir", "=", "log_dir", "\n", "self", ".", "_force_reset", "=", "force_reset", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.observation_space": [[100, 103], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_observation_space", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.action_space": [[104, 107], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.horizon": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "horizon", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_horizon", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.reset": [[112, 120], ["gym_env.GymEnv.env.reset", "isinstance"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_force_reset", "and", "self", ".", "monitoring", ":", "\n", "            ", "from", "gym", ".", "wrappers", ".", "monitoring", "import", "Monitor", "\n", "assert", "isinstance", "(", "self", ".", "env", ",", "Monitor", ")", "\n", "recorder", "=", "self", ".", "env", ".", "stats_recorder", "\n", "if", "recorder", "is", "not", "None", ":", "\n", "                ", "recorder", ".", "done", "=", "True", "\n", "", "", "return", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.step": [[121, 124], ["gym_env.GymEnv.env.step", "garage.envs.base.Step"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.delayed_env.DelayedEnv.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "next_obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "Step", "(", "next_obs", ",", "reward", ",", "done", ",", "**", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.render": [[125, 127], ["gym_env.GymEnv.env.render"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "close", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "render", "(", "mode", ",", "close", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.GymEnv.terminate": [[128, 141], ["gym_env.GymEnv.env._close", "print"], "methods", ["None"], ["", "def", "terminate", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "monitoring", ":", "\n", "            ", "self", ".", "env", ".", "_close", "(", ")", "\n", "if", "self", ".", "_log_dir", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"\"\"\n    ***************************\n\n    Training finished! You can upload results to OpenAI Gym by running the following command:\n\n    python scripts/submit_gym.py %s\n\n    ***************************\n                \"\"\"", "%", "self", ".", "_log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.convert_gym_space": [[25, 34], ["isinstance", "garage.spaces.box.Box", "isinstance", "garage.spaces.discrete.Discrete", "isinstance", "garage.spaces.tuple.Tuple", "gym_env.convert_gym_space"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.gym_env.convert_gym_space"], ["def", "convert_gym_space", "(", "space", ")", ":", "\n", "    ", "if", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "        ", "return", "Box", "(", "low", "=", "space", ".", "low", ",", "high", "=", "space", ".", "high", ")", "\n", "", "elif", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "        ", "return", "Discrete", "(", "n", "=", "space", ".", "n", ")", "\n", "", "elif", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Tuple", ")", ":", "\n", "        ", "return", "Tuple", "(", "[", "convert_gym_space", "(", "x", ")", "for", "x", "in", "space", ".", "spaces", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.__init__": [[18, 54], ["multigoal.PointDynamics", "numpy.zeros", "numpy.array", "multigoal.MultiGoalEnv.reset", "garage.core.serializable.Serializable.__init__", "garage.core.serializable.Serializable.quick_init", "float", "locals", "float"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["def", "__init__", "(", "self", ",", "goal_reward", "=", "10", ",", "actuation_cost_coeff", "=", "30", ",", "\n", "distance_cost_coeff", "=", "1", ",", "init_sigma", "=", "0.1", ")", ":", "\n", "\n", "        ", "self", ".", "dynamics", "=", "PointDynamics", "(", "dim", "=", "2", ",", "sigma", "=", "0", ")", "\n", "self", ".", "init_mu", "=", "np", ".", "zeros", "(", "2", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "init_sigma", "=", "init_sigma", "\n", "self", ".", "goal_positions", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "5", ",", "0", "]", ",", "\n", "[", "-", "5", ",", "0", "]", ",", "\n", "[", "0", ",", "5", "]", ",", "\n", "[", "0", ",", "-", "5", "]", "\n", "]", ",", "\n", "dtype", "=", "np", ".", "float32", "\n", ")", "\n", "self", ".", "goal_threshold", "=", "1.", "\n", "self", ".", "goal_reward", "=", "goal_reward", "\n", "self", ".", "action_cost_coeff", "=", "actuation_cost_coeff", "\n", "self", ".", "distance_cost_coeff", "=", "distance_cost_coeff", "\n", "self", ".", "xlim", "=", "(", "-", "7", ",", "7", ")", "\n", "self", ".", "ylim", "=", "(", "-", "7", ",", "7", ")", "\n", "self", ".", "vel_bound", "=", "1.", "\n", "self", ".", "reset", "(", ")", "\n", "self", ".", "observation", "=", "None", "\n", "\n", "self", ".", "reward_range", "=", "(", "-", "float", "(", "'inf'", ")", ",", "float", "(", "'inf'", ")", ")", "\n", "self", ".", "metadata", "=", "{", "'render.modes'", ":", "[", "]", "}", "\n", "self", ".", "spec", "=", "None", "\n", "\n", "self", ".", "_ax", "=", "None", "\n", "self", ".", "_env_lines", "=", "[", "]", "\n", "self", ".", "fixed_plots", "=", "None", "\n", "self", ".", "dynamic_plots", "=", "[", "]", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset": [[55, 61], ["numpy.clip", "numpy.random.normal"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "unclipped_observation", "=", "self", ".", "init_mu", "+", "self", ".", "init_sigma", "*", "np", ".", "random", ".", "normal", "(", "size", "=", "self", ".", "dynamics", ".", "s_dim", ")", "\n", "o_lb", ",", "o_ub", "=", "self", ".", "observation_space", ".", "low", ",", "self", ".", "observation_space", ".", "high", "\n", "self", ".", "observation", "=", "np", ".", "clip", "(", "unclipped_observation", ",", "o_lb", ",", "o_ub", ")", "\n", "return", "self", ".", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.observation_space": [[62, 69], ["gym.spaces.Box", "numpy.array", "numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "        ", "return", "Box", "(", "\n", "low", "=", "np", ".", "array", "(", "(", "self", ".", "xlim", "[", "0", "]", ",", "self", ".", "ylim", "[", "0", "]", ")", ")", ",", "\n", "high", "=", "np", ".", "array", "(", "(", "self", ".", "xlim", "[", "1", "]", ",", "self", ".", "ylim", "[", "1", "]", ")", ")", ",", "\n", "shape", "=", "None", ",", "\n", "dtype", "=", "np", ".", "float32", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.action_space": [[71, 78], ["gym.spaces.Box"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "Box", "(", "\n", "low", "=", "-", "self", ".", "vel_bound", ",", "\n", "high", "=", "self", ".", "vel_bound", ",", "\n", "shape", "=", "(", "self", ".", "dynamics", ".", "a_dim", ",", ")", ",", "\n", "dtype", "=", "np", ".", "float32", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_current_obs": [[80, 82], ["numpy.copy"], "methods", ["None"], ["", "def", "get_current_obs", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "copy", "(", "self", ".", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.step": [[83, 106], ["numpy.clip().ravel.ravel", "numpy.clip().ravel", "multigoal.MultiGoalEnv.dynamics.forward", "numpy.clip", "numpy.copy", "multigoal.MultiGoalEnv.compute_reward", "numpy.amin", "numpy.clip", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.PointDynamics.forward", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.compute_reward"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "action", "=", "action", ".", "ravel", "(", ")", "\n", "\n", "a_lb", ",", "a_ub", "=", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", "\n", "action", "=", "np", ".", "clip", "(", "action", ",", "a_lb", ",", "a_ub", ")", ".", "ravel", "(", ")", "\n", "\n", "next_obs", "=", "self", ".", "dynamics", ".", "forward", "(", "self", ".", "observation", ",", "action", ")", "\n", "o_lb", ",", "o_ub", "=", "self", ".", "observation_space", ".", "low", ",", "self", ".", "observation_space", ".", "high", "\n", "next_obs", "=", "np", ".", "clip", "(", "next_obs", ",", "o_lb", ",", "o_ub", ")", "\n", "\n", "self", ".", "observation", "=", "np", ".", "copy", "(", "next_obs", ")", "\n", "\n", "reward", "=", "self", ".", "compute_reward", "(", "self", ".", "observation", ",", "action", ")", "\n", "cur_position", "=", "self", ".", "observation", "\n", "dist_to_goal", "=", "np", ".", "amin", "(", "[", "\n", "np", ".", "linalg", ".", "norm", "(", "cur_position", "-", "goal_position", ")", "\n", "for", "goal_position", "in", "self", ".", "goal_positions", "\n", "]", ")", "\n", "done", "=", "dist_to_goal", "<", "self", ".", "goal_threshold", "\n", "if", "done", ":", "\n", "            ", "reward", "+=", "self", ".", "goal_reward", "\n", "\n", "", "return", "next_obs", ",", "reward", ",", "done", ",", "{", "'pos'", ":", "next_obs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv._init_plot": [[107, 121], ["matplotlib.figure", "matplotlib.figure.add_subplot", "multigoal.MultiGoalEnv._ax.axis", "multigoal.MultiGoalEnv._ax.set_xlim", "multigoal.MultiGoalEnv._ax.set_ylim", "multigoal.MultiGoalEnv._ax.set_title", "multigoal.MultiGoalEnv._ax.set_xlabel", "multigoal.MultiGoalEnv._ax.set_ylabel", "multigoal.MultiGoalEnv._plot_position_cost"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv._plot_position_cost"], ["", "def", "_init_plot", "(", "self", ")", ":", "\n", "        ", "fig_env", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "7", ",", "7", ")", ")", "\n", "self", ".", "_ax", "=", "fig_env", ".", "add_subplot", "(", "111", ")", "\n", "self", ".", "_ax", ".", "axis", "(", "'equal'", ")", "\n", "\n", "self", ".", "_env_lines", "=", "[", "]", "\n", "self", ".", "_ax", ".", "set_xlim", "(", "(", "-", "7", ",", "7", ")", ")", "\n", "self", ".", "_ax", ".", "set_ylim", "(", "(", "-", "7", ",", "7", ")", ")", "\n", "\n", "self", ".", "_ax", ".", "set_title", "(", "'Multigoal Environment'", ")", "\n", "self", ".", "_ax", ".", "set_xlabel", "(", "'x'", ")", "\n", "self", ".", "_ax", ".", "set_ylabel", "(", "'y'", ")", "\n", "\n", "self", ".", "_plot_position_cost", "(", "self", ".", "_ax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.render": [[122, 138], ["matplotlib.draw", "matplotlib.pause", "multigoal.MultiGoalEnv._init_plot", "line.remove", "numpy.stack", "multigoal.MultiGoalEnv._ax.plot"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter.draw", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv._init_plot"], ["", "def", "render", "(", "self", ",", "paths", ")", ":", "\n", "        ", "if", "self", ".", "_ax", "is", "None", ":", "\n", "            ", "self", ".", "_init_plot", "(", ")", "\n", "\n", "# noinspection PyArgumentList", "\n", "", "[", "line", ".", "remove", "(", ")", "for", "line", "in", "self", ".", "_env_lines", "]", "\n", "self", ".", "_env_lines", "=", "[", "]", "\n", "\n", "for", "path", "in", "paths", ":", "\n", "            ", "positions", "=", "np", ".", "stack", "(", "[", "info", "[", "'pos'", "]", "for", "info", "in", "path", "[", "'env_infos'", "]", "]", ")", "\n", "xx", "=", "positions", "[", ":", ",", "0", "]", "\n", "yy", "=", "positions", "[", ":", ",", "1", "]", "\n", "self", ".", "_env_lines", "+=", "self", ".", "_ax", ".", "plot", "(", "xx", ",", "yy", ",", "'b'", ")", "\n", "\n", "", "plt", ".", "draw", "(", ")", "\n", "plt", ".", "pause", "(", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.compute_reward": [[139, 156], ["numpy.sum", "numpy.amin", "numpy.sum", "numpy.sum"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "observation", ",", "action", ")", ":", "\n", "# penalize the L2 norm of acceleration", "\n", "# noinspection PyTypeChecker", "\n", "        ", "action_cost", "=", "np", ".", "sum", "(", "action", "**", "2", ")", "*", "self", ".", "action_cost_coeff", "\n", "\n", "# penalize squared dist to goal", "\n", "cur_position", "=", "observation", "\n", "# noinspection PyTypeChecker", "\n", "goal_cost", "=", "self", ".", "distance_cost_coeff", "*", "np", ".", "amin", "(", "[", "\n", "np", ".", "sum", "(", "(", "cur_position", "-", "goal_position", ")", "**", "2", ")", "\n", "for", "goal_position", "in", "self", ".", "goal_positions", "\n", "]", ")", "\n", "\n", "# penalize staying with the log barriers", "\n", "costs", "=", "[", "action_cost", ",", "goal_cost", "]", "\n", "reward", "=", "-", "np", ".", "sum", "(", "costs", ")", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv._plot_position_cost": [[157, 178], ["tuple", "tuple", "numpy.meshgrid", "numpy.amin", "ax.contour", "ax.clabel", "ax.set_xlim", "ax.set_ylim", "ax.plot", "numpy.arange", "numpy.arange", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_plot_position_cost", "(", "self", ",", "ax", ")", ":", "\n", "        ", "delta", "=", "0.01", "\n", "x_min", ",", "x_max", "=", "tuple", "(", "1.1", "*", "np", ".", "array", "(", "self", ".", "xlim", ")", ")", "\n", "y_min", ",", "y_max", "=", "tuple", "(", "1.1", "*", "np", ".", "array", "(", "self", ".", "ylim", ")", ")", "\n", "X", ",", "Y", "=", "np", ".", "meshgrid", "(", "\n", "np", ".", "arange", "(", "x_min", ",", "x_max", ",", "delta", ")", ",", "\n", "np", ".", "arange", "(", "y_min", ",", "y_max", ",", "delta", ")", "\n", ")", "\n", "goal_costs", "=", "np", ".", "amin", "(", "[", "\n", "(", "X", "-", "goal_x", ")", "**", "2", "+", "(", "Y", "-", "goal_y", ")", "**", "2", "\n", "for", "goal_x", ",", "goal_y", "in", "self", ".", "goal_positions", "\n", "]", ",", "axis", "=", "0", ")", "\n", "costs", "=", "goal_costs", "\n", "\n", "contours", "=", "ax", ".", "contour", "(", "X", ",", "Y", ",", "costs", ",", "20", ")", "\n", "ax", ".", "clabel", "(", "contours", ",", "inline", "=", "1", ",", "fontsize", "=", "10", ",", "fmt", "=", "'%.0f'", ")", "\n", "ax", ".", "set_xlim", "(", "[", "x_min", ",", "x_max", "]", ")", "\n", "ax", ".", "set_ylim", "(", "[", "y_min", ",", "y_max", "]", ")", "\n", "goal", "=", "ax", ".", "plot", "(", "self", ".", "goal_positions", "[", ":", ",", "0", "]", ",", "\n", "self", ".", "goal_positions", "[", ":", ",", "1", "]", ",", "'ro'", ")", "\n", "return", "[", "contours", ",", "goal", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_param_values": [[179, 181], ["None"], "methods", ["None"], ["", "def", "get_param_values", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.set_param_values": [[182, 184], ["None"], "methods", ["None"], ["", "def", "set_param_values", "(", "self", ",", "params", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.log_diagnostics": [[185, 196], ["len", "garage.misc.logger.record_tabular", "enumerate", "goal_reached.count", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "log_diagnostics", "(", "self", ",", "paths", ")", ":", "\n", "        ", "n_goal", "=", "len", "(", "self", ".", "goal_positions", ")", "\n", "goal_reached", "=", "[", "False", "]", "*", "n_goal", "\n", "\n", "for", "path", "in", "paths", ":", "\n", "            ", "last_obs", "=", "path", "[", "\"observations\"", "]", "[", "-", "1", "]", "\n", "for", "i", ",", "goal", "in", "enumerate", "(", "self", ".", "goal_positions", ")", ":", "\n", "                ", "if", "np", ".", "linalg", ".", "norm", "(", "last_obs", "-", "goal", ")", "<", "self", ".", "goal_threshold", ":", "\n", "                    ", "goal_reached", "[", "i", "]", "=", "True", "\n", "\n", "", "", "", "logger", ".", "record_tabular", "(", "'env:goals_reached'", ",", "goal_reached", ".", "count", "(", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.horizon": [[197, 199], ["None"], "methods", ["None"], ["", "def", "horizon", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.PointDynamics.__init__": [[207, 212], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dim", ",", "sigma", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "s_dim", "=", "dim", "\n", "self", ".", "a_dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.PointDynamics.forward": [[213, 218], ["numpy.random.normal"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "        ", "mu_next", "=", "state", "+", "action", "\n", "state_next", "=", "mu_next", "+", "self", ".", "sigma", "*", "np", ".", "random", ".", "normal", "(", "size", "=", "self", ".", "s_dim", ")", "\n", "return", "state_next", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.delayed_env.DelayedEnv.__init__": [[8, 13], ["garage.core.serializable.Serializable.quick_init", "gym.Wrapper.__init__", "locals"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "delay", "=", "0.01", ")", ":", "\n", "        ", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "\n", "self", ".", "_delay", "=", "delay", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.delayed_env.DelayedEnv.step": [[14, 17], ["time.sleep", "delayed_env.DelayedEnv.step"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.delayed_env.DelayedEnv.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "time", ".", "sleep", "(", "self", ".", "_delay", ")", "\n", "return", "self", ".", "step", "(", "action", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session": [[5, 7], ["tensorflow.get_default_session", "tf_utils.create_session"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.create_session"], ["def", "get_default_session", "(", ")", ":", "\n", "    ", "return", "tf", ".", "get_default_session", "(", ")", "or", "create_session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.create_session": [[9, 14], ["tensorflow.InteractiveSession", "tf_utils.get_configuration"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_configuration"], ["", "def", "create_session", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Create new tensorflow session with given configuration. \"\"\"", "\n", "if", "\"config\"", "not", "in", "kwargs", ":", "\n", "        ", "kwargs", "[", "\"config\"", "]", "=", "get_configuration", "(", ")", "\n", "", "return", "tf", ".", "InteractiveSession", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_configuration": [[16, 23], ["tensorflow.ConfigProto"], "function", ["None"], ["", "def", "get_configuration", "(", ")", ":", "\n", "    ", "\"\"\" Returns personal tensorflow configuration. \"\"\"", "\n", "if", "config", ".", "USE_GPU", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "config_args", "=", "{", "}", "\n", "return", "tf", ".", "ConfigProto", "(", "**", "config_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.kernel.adaptive_isotropic_gaussian_kernel": [[7, 74], ["tensorflow.concat", "tensorflow.nn.top_k", "tensorflow.maximum", "tensorflow.stop_gradient", "tensorflow.expand_dims", "tensorflow.exp", "tensorflow.expand_dims", "tensorflow.expand_dims", "xs.get_shape().as_list", "ys.get_shape().as_list", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "distutils.version.StrictVersion", "distutils.version.StrictVersion", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "numpy.log", "tensorflow.expand_dims", "tensorflow.reshape", "xs.get_shape", "ys.get_shape"], "function", ["None"], ["def", "adaptive_isotropic_gaussian_kernel", "(", "xs", ",", "ys", ",", "h_min", "=", "1e-3", ")", ":", "\n", "    ", "\"\"\"Gaussian kernel with dynamic bandwidth.\n\n    The bandwidth is adjusted dynamically to match median_distance / log(Kx).\n    See [2] for more information.\n\n    Args:\n        xs(`tf.Tensor`): A tensor of shape (N x Kx x D) containing N sets of Kx\n            particles of dimension D. This is the first kernel argument.\n        ys(`tf.Tensor`): A tensor of shape (N x Ky x D) containing N sets of Kx\n            particles of dimension D. This is the second kernel argument.\n        h_min(`float`): Minimum bandwidth.\n\n    Returns:\n        `dict`: Returned dictionary has two fields:\n            'output': A `tf.Tensor` object of shape (N x Kx x Ky) representing\n                the kernel matrix for inputs `xs` and `ys`.\n            'gradient': A 'tf.Tensor` object of shape (N x Kx x Ky x D)\n                representing the gradient of the kernel with respect to `xs`.\n\n    Reference:\n        [2] Qiang Liu,Dilin Wang, \"Stein Variational Gradient Descent: A General\n            Purpose Bayesian Inference Algorithm,\" Neural Information Processing\n            Systems (NIPS), 2016.\n    \"\"\"", "\n", "Kx", ",", "D", "=", "xs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "2", ":", "]", "\n", "Ky", ",", "D2", "=", "ys", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "2", ":", "]", "\n", "assert", "D", "==", "D2", "\n", "\n", "leading_shape", "=", "tf", ".", "shape", "(", "xs", ")", "[", ":", "-", "2", "]", "\n", "\n", "# Compute the pairwise distances of left and right particles.", "\n", "diff", "=", "tf", ".", "expand_dims", "(", "xs", ",", "-", "2", ")", "-", "tf", ".", "expand_dims", "(", "ys", ",", "-", "3", ")", "\n", "# ... x Kx x Ky x D", "\n", "\n", "if", "StrictVersion", "(", "tf", ".", "__version__", ")", "<", "StrictVersion", "(", "'1.5.0'", ")", ":", "\n", "        ", "dist_sq", "=", "tf", ".", "reduce_sum", "(", "diff", "**", "2", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "dist_sq", "=", "tf", ".", "reduce_sum", "(", "diff", "**", "2", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "False", ")", "\n", "# ... x Kx x Ky", "\n", "\n", "# Get median.", "\n", "", "input_shape", "=", "tf", ".", "concat", "(", "(", "leading_shape", ",", "[", "Kx", "*", "Ky", "]", ")", ",", "axis", "=", "0", ")", "\n", "values", ",", "_", "=", "tf", ".", "nn", ".", "top_k", "(", "\n", "input", "=", "tf", ".", "reshape", "(", "dist_sq", ",", "input_shape", ")", ",", "\n", "k", "=", "(", "Kx", "*", "Ky", "//", "2", "+", "1", ")", ",", "# This is exactly true only if Kx*Ky is odd.", "\n", "sorted", "=", "True", ")", "# ... x floor(Ks*Kd/2)", "\n", "\n", "medians_sq", "=", "values", "[", "...", ",", "-", "1", "]", "# ... (shape) (last element is the median)", "\n", "\n", "h", "=", "medians_sq", "/", "np", ".", "log", "(", "Kx", ")", "# ... (shape)", "\n", "h", "=", "tf", ".", "maximum", "(", "h", ",", "h_min", ")", "\n", "h", "=", "tf", ".", "stop_gradient", "(", "h", ")", "# Just in case.", "\n", "h_expanded_twice", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "h", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "# ... x 1 x 1", "\n", "\n", "kappa", "=", "tf", ".", "exp", "(", "-", "dist_sq", "/", "h_expanded_twice", ")", "# ... x Kx x Ky", "\n", "\n", "# Construct the gradient", "\n", "h_expanded_thrice", "=", "tf", ".", "expand_dims", "(", "h_expanded_twice", ",", "-", "1", ")", "\n", "# ... x 1 x 1 x 1", "\n", "kappa_expanded", "=", "tf", ".", "expand_dims", "(", "kappa", ",", "-", "1", ")", "# ... x Kx x Ky x 1", "\n", "\n", "kappa_grad", "=", "-", "2", "*", "diff", "/", "h_expanded_thrice", "*", "kappa_expanded", "\n", "# ... x Kx x Ky x D", "\n", "\n", "return", "{", "\"output\"", ":", "kappa", ",", "\"gradient\"", ":", "kappa_grad", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.remote_sampler.RemoteSampler.__init__": [[14, 23], ["sampler.Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RemoteSampler", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_remote_environment", "=", "None", "\n", "self", ".", "_remote_path", "=", "None", "\n", "self", ".", "_n_episodes", "=", "0", "\n", "self", ".", "_total_samples", "=", "0", "\n", "self", ".", "_last_path_return", "=", "0", "\n", "self", ".", "_max_path_return", "=", "-", "np", ".", "inf", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.remote_sampler.RemoteSampler.initialize": [[24, 34], ["super().initialize", "ray.init", "pickle.dumps", "pickle.dumps", "_RemoteEnv.remote"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.initialize"], ["", "@", "overrides", "\n", "def", "initialize", "(", "self", ",", "env", ",", "policy", ",", "pool", ")", ":", "\n", "        ", "super", "(", "RemoteSampler", ",", "self", ")", ".", "initialize", "(", "env", ",", "policy", ",", "pool", ")", "\n", "\n", "ray", ".", "init", "(", ")", "\n", "\n", "env_pkl", "=", "pickle", ".", "dumps", "(", "env", ")", "\n", "policy_pkl", "=", "pickle", ".", "dumps", "(", "policy", ")", "\n", "\n", "self", ".", "_remote_environment", "=", "_RemoteEnv", ".", "remote", "(", "env_pkl", ",", "policy_pkl", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.remote_sampler.RemoteSampler.sample": [[35, 52], ["ray.wait", "remote_sampler.RemoteSampler.policy.get_param_values", "remote_sampler.RemoteSampler._remote_environment.rollout.remote", "len", "ray.get", "remote_sampler.RemoteSampler.pool.add_path", "len", "numpy.sum", "max", "remote_sampler.RemoteSampler.batch_ready"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.get_param_values", "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.replay_buffer.ReplayBuffer.add_path", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.batch_ready"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_remote_path", "is", "None", ":", "\n", "            ", "policy_params", "=", "self", ".", "policy", ".", "get_param_values", "(", ")", "\n", "self", ".", "_remote_path", "=", "self", ".", "_remote_environment", ".", "rollout", ".", "remote", "(", "\n", "policy_params", ",", "self", ".", "_max_path_length", ")", "\n", "\n", "", "path_ready", ",", "_", "=", "ray", ".", "wait", "(", "[", "self", ".", "_remote_path", "]", ",", "timeout", "=", "0", ")", "\n", "\n", "if", "len", "(", "path_ready", ")", "or", "not", "self", ".", "batch_ready", "(", ")", ":", "\n", "            ", "path", "=", "ray", ".", "get", "(", "self", ".", "_remote_path", ")", "\n", "self", ".", "pool", ".", "add_path", "(", "path", ")", "\n", "self", ".", "_remote_path", "=", "None", "\n", "self", ".", "_total_samples", "+=", "len", "(", "path", "[", "'observations'", "]", ")", "\n", "self", ".", "_last_path_return", "=", "np", ".", "sum", "(", "path", "[", "'rewards'", "]", ")", "\n", "self", ".", "_max_path_return", "=", "max", "(", "self", ".", "_max_path_return", ",", "\n", "self", ".", "_last_path_return", ")", "\n", "self", ".", "_n_episodes", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.remote_sampler.RemoteSampler.log_diagnostics": [[53, 59], ["garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular"], "methods", ["None"], ["", "", "def", "log_diagnostics", "(", "self", ")", ":", "\n", "        ", "logger", ".", "record_tabular", "(", "'max-path-return'", ",", "self", ".", "_max_path_return", ")", "\n", "logger", ".", "record_tabular", "(", "'last-path-return'", ",", "self", ".", "_last_path_return", ")", "\n", "logger", ".", "record_tabular", "(", "'pool-size'", ",", "self", ".", "pool", ".", "size", ")", "\n", "logger", ".", "record_tabular", "(", "'episodes'", ",", "self", ".", "_n_episodes", ")", "\n", "logger", ".", "record_tabular", "(", "'total-samples'", ",", "self", ".", "_total_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.remote_sampler._RemoteEnv.__init__": [[63, 72], ["tf_utils.create_session", "remote_sampler._RemoteEnv._sess.run", "pickle.loads", "pickle.loads", "hasattr", "tensorflow.global_variables_initializer", "remote_sampler._RemoteEnv._env.initialize"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.create_session", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.initialize"], ["    ", "def", "__init__", "(", "self", ",", "env_pkl", ",", "policy_pkl", ")", ":", "\n", "        ", "self", ".", "_sess", "=", "tf_utils", ".", "create_session", "(", ")", "\n", "self", ".", "_sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "self", ".", "_env", "=", "pickle", ".", "loads", "(", "env_pkl", ")", "\n", "self", ".", "_policy", "=", "pickle", ".", "loads", "(", "policy_pkl", ")", "\n", "\n", "if", "hasattr", "(", "self", ".", "_env", ",", "'initialize'", ")", ":", "\n", "            ", "self", ".", "_env", ".", "initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.remote_sampler._RemoteEnv.rollout": [[73, 78], ["remote_sampler._RemoteEnv._policy.set_param_values", "sampler.rollout"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.set_param_values", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.rollout"], ["", "", "def", "rollout", "(", "self", ",", "policy_params", ",", "path_length", ")", ":", "\n", "        ", "self", ".", "_policy", ".", "set_param_values", "(", "policy_params", ")", "\n", "path", "=", "rollout", "(", "self", ".", "_env", ",", "self", ".", "_policy", ",", "path_length", ")", "\n", "\n", "return", "path", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter.__init__": [[6, 31], ["len", "matplotlib.figure", "range", "list", "numpy.where", "len", "matplotlib.figure.add_subplot", "plt.figure.add_subplot.set_xlim", "plt.figure.add_subplot.set_ylim", "plt.figure.add_subplot.grid", "plotter.QFPolicyPlotter._ax_lst.append", "numpy.isnan"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "qf", ",", "policy", ",", "obs_lst", ",", "default_action", ",", "n_samples", ")", ":", "\n", "        ", "self", ".", "_qf", "=", "qf", "\n", "self", ".", "_policy", "=", "policy", "\n", "self", ".", "_obs_lst", "=", "obs_lst", "\n", "self", ".", "_default_action", "=", "default_action", "\n", "self", ".", "_n_samples", "=", "n_samples", "\n", "\n", "self", ".", "_var_inds", "=", "np", ".", "where", "(", "np", ".", "isnan", "(", "default_action", ")", ")", "[", "0", "]", "\n", "assert", "len", "(", "self", ".", "_var_inds", ")", "==", "2", "\n", "\n", "n_plots", "=", "len", "(", "obs_lst", ")", "\n", "\n", "x_size", "=", "5", "*", "n_plots", "\n", "y_size", "=", "5", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "x_size", ",", "y_size", ")", ")", "\n", "self", ".", "_ax_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_plots", ")", ":", "\n", "            ", "ax", "=", "fig", ".", "add_subplot", "(", "100", "+", "n_plots", "*", "10", "+", "i", "+", "1", ")", "\n", "ax", ".", "set_xlim", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "ax", ".", "set_ylim", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "ax", ".", "grid", "(", "True", ")", "\n", "self", ".", "_ax_lst", ".", "append", "(", "ax", ")", "\n", "\n", "", "self", ".", "_line_objects", "=", "list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter.draw": [[32, 42], ["list", "plotter.QFPolicyPlotter._plot_level_curves", "plotter.QFPolicyPlotter._plot_action_samples", "matplotlib.draw", "matplotlib.pause", "h.remove"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter._plot_level_curves", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter._plot_action_samples", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter.draw"], ["", "def", "draw", "(", "self", ")", ":", "\n", "# noinspection PyArgumentList", "\n", "        ", "[", "h", ".", "remove", "(", ")", "for", "h", "in", "self", ".", "_line_objects", "]", "\n", "self", ".", "_line_objects", "=", "list", "(", ")", "\n", "\n", "self", ".", "_plot_level_curves", "(", ")", "\n", "self", ".", "_plot_action_samples", "(", ")", "\n", "\n", "plt", ".", "draw", "(", ")", "\n", "plt", ".", "pause", "(", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter._plot_level_curves": [[43, 65], ["numpy.linspace", "numpy.linspace", "numpy.meshgrid", "numpy.tile", "xgrid.ravel", "ygrid.ravel", "zip", "len", "len", "plotter.QFPolicyPlotter._qf.eval", "qs.reshape.reshape.reshape", "ax.contour", "ax.clabel"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.value_functions.value_function.NNQFunction.eval"], ["", "def", "_plot_level_curves", "(", "self", ")", ":", "\n", "# Create mesh grid.", "\n", "        ", "xs", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "50", ")", "\n", "ys", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "50", ")", "\n", "xgrid", ",", "ygrid", "=", "np", ".", "meshgrid", "(", "xs", ",", "ys", ")", "\n", "N", "=", "len", "(", "xs", ")", "*", "len", "(", "ys", ")", "\n", "\n", "# Copy default values along the first axis and replace nans with", "\n", "# the mesh grid points.", "\n", "actions", "=", "np", ".", "tile", "(", "self", ".", "_default_action", ",", "(", "N", ",", "1", ")", ")", "\n", "actions", "[", ":", ",", "self", ".", "_var_inds", "[", "0", "]", "]", "=", "xgrid", ".", "ravel", "(", ")", "\n", "actions", "[", ":", ",", "self", ".", "_var_inds", "[", "1", "]", "]", "=", "ygrid", ".", "ravel", "(", ")", "\n", "\n", "for", "ax", ",", "obs", "in", "zip", "(", "self", ".", "_ax_lst", ",", "self", ".", "_obs_lst", ")", ":", "\n", "            ", "qs", "=", "self", ".", "_qf", ".", "eval", "(", "obs", "[", "None", "]", ",", "actions", ")", "\n", "\n", "qs", "=", "qs", ".", "reshape", "(", "xgrid", ".", "shape", ")", "\n", "\n", "cs", "=", "ax", ".", "contour", "(", "xgrid", ",", "ygrid", ",", "qs", ",", "20", ")", "\n", "self", ".", "_line_objects", "+=", "cs", ".", "collections", "\n", "self", ".", "_line_objects", "+=", "ax", ".", "clabel", "(", "\n", "cs", ",", "inline", "=", "1", ",", "fontsize", "=", "10", ",", "fmt", "=", "'%.2f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.plotter.QFPolicyPlotter._plot_action_samples": [[66, 72], ["zip", "plotter.QFPolicyPlotter._policy.get_actions", "ax.plot", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.get_actions"], ["", "", "def", "_plot_action_samples", "(", "self", ")", ":", "\n", "        ", "for", "ax", ",", "obs", "in", "zip", "(", "self", ".", "_ax_lst", ",", "self", ".", "_obs_lst", ")", ":", "\n", "            ", "actions", "=", "self", ".", "_policy", ".", "get_actions", "(", "\n", "np", ".", "ones", "(", "(", "self", ".", "_n_samples", ",", "1", ")", ")", "*", "obs", "[", "None", ",", ":", "]", ")", "\n", "x", ",", "y", "=", "actions", "[", ":", ",", "0", "]", ",", "actions", "[", ":", ",", "1", "]", "\n", "self", ".", "_line_objects", "+=", "ax", ".", "plot", "(", "x", ",", "y", ",", "'b*'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.__init__": [[70, 78], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "max_path_length", ",", "min_pool_size", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "_max_path_length", "=", "max_path_length", "\n", "self", ".", "_min_pool_size", "=", "min_pool_size", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "\n", "self", ".", "env", "=", "None", "\n", "self", ".", "policy", "=", "None", "\n", "self", ".", "pool", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.initialize": [[79, 83], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "env", ",", "policy", ",", "pool", ")", ":", "\n", "        ", "self", ".", "env", "=", "env", "\n", "self", ".", "policy", "=", "policy", "\n", "self", ".", "pool", "=", "pool", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.sample": [[84, 86], ["None"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.batch_ready": [[87, 90], ["None"], "methods", ["None"], ["", "def", "batch_ready", "(", "self", ")", ":", "\n", "        ", "enough_samples", "=", "self", ".", "pool", ".", "size", ">=", "self", ".", "_min_pool_size", "\n", "return", "enough_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.random_batch": [[91, 93], ["sampler.Sampler.pool.random_batch"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.random_batch"], ["", "def", "random_batch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pool", ".", "random_batch", "(", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.terminate": [[94, 96], ["sampler.Sampler.env.terminate"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.terminate"], ["", "def", "terminate", "(", "self", ")", ":", "\n", "        ", "self", ".", "env", ".", "terminate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.Sampler.log_diagnostics": [[97, 99], ["garage.misc.logger.record_tabular"], "methods", ["None"], ["", "def", "log_diagnostics", "(", "self", ")", ":", "\n", "        ", "logger", ".", "record_tabular", "(", "'pool-size'", ",", "self", ".", "pool", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.__init__": [[102, 112], ["sampler.Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SimpleSampler", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_path_length", "=", "0", "\n", "self", ".", "_path_return", "=", "0", "\n", "self", ".", "_last_path_return", "=", "0", "\n", "self", ".", "_max_path_return", "=", "-", "np", ".", "inf", "\n", "self", ".", "_n_episodes", "=", "0", "\n", "self", ".", "_current_observation", "=", "None", "\n", "self", ".", "_total_samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.sample": [[113, 143], ["sampler.SimpleSampler.policy.get_action", "sampler.SimpleSampler.env.step", "sampler.SimpleSampler.pool.add_sample", "sampler.SimpleSampler.env.reset", "sampler.SimpleSampler.policy.reset", "sampler.SimpleSampler.env.reset", "max"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.get_action", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.delayed_env.DelayedEnv.step", "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.add_sample", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_current_observation", "is", "None", ":", "\n", "            ", "self", ".", "_current_observation", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "", "action", ",", "_", "=", "self", ".", "policy", ".", "get_action", "(", "self", ".", "_current_observation", ")", "\n", "next_observation", ",", "reward", ",", "terminal", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "_path_length", "+=", "1", "\n", "self", ".", "_path_return", "+=", "reward", "\n", "self", ".", "_total_samples", "+=", "1", "\n", "\n", "self", ".", "pool", ".", "add_sample", "(", "\n", "observation", "=", "self", ".", "_current_observation", ",", "\n", "action", "=", "action", ",", "\n", "reward", "=", "reward", ",", "\n", "terminal", "=", "terminal", ",", "\n", "next_observation", "=", "next_observation", ")", "\n", "\n", "if", "terminal", "or", "self", ".", "_path_length", ">=", "self", ".", "_max_path_length", ":", "\n", "            ", "self", ".", "policy", ".", "reset", "(", ")", "\n", "self", ".", "_current_observation", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "_path_length", "=", "0", "\n", "self", ".", "_max_path_return", "=", "max", "(", "self", ".", "_max_path_return", ",", "\n", "self", ".", "_path_return", ")", "\n", "self", ".", "_last_path_return", "=", "self", ".", "_path_return", "\n", "\n", "self", ".", "_path_return", "=", "0", "\n", "self", ".", "_n_episodes", "+=", "1", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "_current_observation", "=", "next_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.log_diagnostics": [[144, 150], ["sampler.Sampler.log_diagnostics", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular", "garage.misc.logger.record_tabular"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.SimpleSampler.log_diagnostics"], ["", "", "def", "log_diagnostics", "(", "self", ")", ":", "\n", "        ", "super", "(", "SimpleSampler", ",", "self", ")", ".", "log_diagnostics", "(", ")", "\n", "logger", ".", "record_tabular", "(", "'max-path-return'", ",", "self", ".", "_max_path_return", ")", "\n", "logger", ".", "record_tabular", "(", "'last-path-return'", ",", "self", ".", "_last_path_return", ")", "\n", "logger", ".", "record_tabular", "(", "'episodes'", ",", "self", ".", "_n_episodes", ")", "\n", "logger", ".", "record_tabular", "(", "'total-samples'", ",", "self", ".", "_total_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.DummySampler.__init__": [[153, 158], ["sampler.Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "max_path_length", ")", ":", "\n", "        ", "super", "(", "DummySampler", ",", "self", ")", ".", "__init__", "(", "\n", "max_path_length", "=", "max_path_length", ",", "\n", "min_pool_size", "=", "0", ",", "\n", "batch_size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.DummySampler.sample": [[159, 161], ["None"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.rollout": [[8, 59], ["garage.envs.util.flat_dim", "garage.envs.util.flat_dim", "env.reset", "policy.reset", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "policy.get_action", "env.step", "agent_infos.append", "env_infos.append", "env.render", "time.sleep"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.reset", "home.repos.pwc.inspect_result.haarnoja_softqlearning.policies.nn_policy.NNPolicy.get_action", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.delayed_env.DelayedEnv.step", "home.repos.pwc.inspect_result.haarnoja_softqlearning.environments.multigoal.MultiGoalEnv.render"], ["def", "rollout", "(", "env", ",", "policy", ",", "path_length", ",", "render", "=", "False", ",", "speedup", "=", "None", ")", ":", "\n", "    ", "Da", "=", "flat_dim", "(", "env", ".", "action_space", ")", "\n", "Do", "=", "flat_dim", "(", "env", ".", "observation_space", ")", "\n", "\n", "observation", "=", "env", ".", "reset", "(", ")", "\n", "policy", ".", "reset", "(", ")", "\n", "\n", "observations", "=", "np", ".", "zeros", "(", "(", "path_length", "+", "1", ",", "Do", ")", ")", "\n", "actions", "=", "np", ".", "zeros", "(", "(", "path_length", ",", "Da", ")", ")", "\n", "terminals", "=", "np", ".", "zeros", "(", "(", "path_length", ",", ")", ")", "\n", "rewards", "=", "np", ".", "zeros", "(", "(", "path_length", ",", ")", ")", "\n", "agent_infos", "=", "[", "]", "\n", "env_infos", "=", "[", "]", "\n", "\n", "t", "=", "0", "\n", "for", "t", "in", "range", "(", "path_length", ")", ":", "\n", "\n", "        ", "action", ",", "agent_info", "=", "policy", ".", "get_action", "(", "observation", ")", "\n", "next_obs", ",", "reward", ",", "terminal", ",", "env_info", "=", "env", ".", "step", "(", "action", ")", "\n", "\n", "agent_infos", ".", "append", "(", "agent_info", ")", "\n", "env_infos", ".", "append", "(", "env_info", ")", "\n", "\n", "actions", "[", "t", "]", "=", "action", "\n", "terminals", "[", "t", "]", "=", "terminal", "\n", "rewards", "[", "t", "]", "=", "reward", "\n", "observations", "[", "t", "]", "=", "observation", "\n", "\n", "observation", "=", "next_obs", "\n", "\n", "if", "render", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "time_step", "=", "0.05", "\n", "time", ".", "sleep", "(", "time_step", "/", "speedup", ")", "\n", "\n", "", "if", "terminal", ":", "\n", "            ", "break", "\n", "\n", "", "", "observations", "[", "t", "+", "1", "]", "=", "observation", "\n", "\n", "path", "=", "{", "\n", "'observations'", ":", "observations", "[", ":", "t", "+", "1", "]", ",", "\n", "'actions'", ":", "actions", "[", ":", "t", "+", "1", "]", ",", "\n", "'rewards'", ":", "rewards", "[", ":", "t", "+", "1", "]", ",", "\n", "'terminals'", ":", "terminals", "[", ":", "t", "+", "1", "]", ",", "\n", "'next_observations'", ":", "observations", "[", "1", ":", "t", "+", "2", "]", ",", "\n", "'agent_infos'", ":", "agent_infos", ",", "\n", "'env_infos'", ":", "env_infos", "\n", "}", "\n", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.rollouts": [[61, 67], ["list", "range", "list.append", "sampler.rollout"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.rollout"], ["", "def", "rollouts", "(", "env", ",", "policy", ",", "path_length", ",", "n_paths", ")", ":", "\n", "    ", "paths", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "n_paths", ")", ":", "\n", "        ", "paths", ".", "append", "(", "rollout", "(", "env", ",", "policy", ",", "path_length", ")", ")", "\n", "\n", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__": [[49, 58], ["garage.tf.core.parameterized.Parameterized.__init__", "garage.core.serializable.Serializable.quick_init", "nn.MLPFunction._output_for", "locals", "list"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.__init__", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction._output_for"], ["    ", "def", "__init__", "(", "self", ",", "inputs", ",", "name", ",", "hidden_layer_sizes", ")", ":", "\n", "        ", "Parameterized", ".", "__init__", "(", "self", ")", "\n", "Serializable", ".", "quick_init", "(", "self", ",", "locals", "(", ")", ")", "\n", "\n", "self", ".", "_name", "=", "name", "\n", "self", ".", "_inputs", "=", "inputs", "\n", "self", ".", "_layer_sizes", "=", "list", "(", "hidden_layer_sizes", ")", "+", "[", "1", "]", "\n", "\n", "self", ".", "_output", "=", "self", ".", "_output_for", "(", "self", ".", "_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction._output_for": [[59, 67], ["tensorflow.variable_scope", "nn.feedforward_net"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.feedforward_net"], ["", "def", "_output_for", "(", "self", ",", "inputs", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "_name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "out", "=", "feedforward_net", "(", "\n", "inputs", "=", "inputs", ",", "\n", "output_nonlinearity", "=", "None", ",", "\n", "layer_sizes", "=", "self", ".", "_layer_sizes", ")", "\n", "\n", "", "return", "out", "[", "...", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction._eval": [[68, 72], ["softqlearning.misc.tf_utils.get_default_session().run", "zip", "softqlearning.misc.tf_utils.get_default_session"], "methods", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session"], ["", "def", "_eval", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "feeds", "=", "{", "pl", ":", "val", "for", "pl", ",", "val", "in", "zip", "(", "self", ".", "_inputs", ",", "inputs", ")", "}", "\n", "\n", "return", "tf_utils", ".", "get_default_session", "(", ")", ".", "run", "(", "self", ".", "_output", ",", "feeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.MLPFunction.get_params_internal": [[73, 80], ["tensorflow.get_collection", "len"], "methods", ["None"], ["", "def", "get_params_internal", "(", "self", ",", "scope", "=", "''", ",", "**", "tags", ")", ":", "\n", "        ", "if", "len", "(", "tags", ")", ">", "0", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "scope", "+=", "'/'", "+", "self", ".", "_name", "if", "scope", "else", "self", ".", "_name", "\n", "\n", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "scope", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.nn.feedforward_net": [[9, 46], ["enumerate", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.tensordot", "output_nonlinearity", "tensorflow.variable_scope", "nn.feedforward_net.bias"], "function", ["None"], ["def", "feedforward_net", "(", "inputs", ",", "\n", "layer_sizes", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "output_nonlinearity", "=", "None", ")", ":", "\n", "    ", "def", "bias", "(", "n_units", ")", ":", "\n", "        ", "return", "tf", ".", "get_variable", "(", "\n", "name", "=", "'bias'", ",", "shape", "=", "n_units", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "", "def", "linear", "(", "x", ",", "n_units", ",", "postfix", "=", "None", ")", ":", "\n", "        ", "input_size", "=", "x", ".", "shape", "[", "-", "1", "]", ".", "value", "\n", "weight_name", "=", "'weight'", "+", "'_'", "+", "str", "(", "postfix", ")", "if", "postfix", "else", "'weight'", "\n", "weight", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "weight_name", ",", "\n", "shape", "=", "(", "input_size", ",", "n_units", ")", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ")", "\n", "\n", "# `tf.tensordot` supports broadcasting", "\n", "return", "tf", ".", "tensordot", "(", "x", ",", "weight", ",", "axes", "=", "(", "(", "-", "1", ",", ")", ",", "(", "0", ",", ")", ")", ")", "\n", "\n", "", "out", "=", "0", "\n", "for", "i", ",", "layer_size", "in", "enumerate", "(", "layer_sizes", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'layer_{i}'", ".", "format", "(", "i", "=", "i", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "for", "j", ",", "input_tensor", "in", "enumerate", "(", "inputs", ")", ":", "\n", "                    ", "out", "+=", "linear", "(", "input_tensor", ",", "layer_size", ",", "j", ")", "\n", "", "", "else", ":", "\n", "                ", "out", "=", "linear", "(", "out", ",", "layer_size", ")", "\n", "\n", "", "out", "+=", "bias", "(", "layer_size", ")", "\n", "\n", "if", "i", "<", "len", "(", "layer_sizes", ")", "-", "1", "and", "activation_fn", ":", "\n", "                ", "out", "=", "activation_fn", "(", "out", ")", "\n", "\n", "", "", "", "if", "output_nonlinearity", ":", "\n", "        ", "out", "=", "output_nonlinearity", "(", "out", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument._create_symlink": [[10, 21], ["os.path.join", "os.makedirs", "os.symlink", "str", "os.path.join", "os.path.join", "uuid.uuid4"], "function", ["None"], ["def", "_create_symlink", "(", "folder", ")", ":", "\n", "    ", "\"\"\"Create a symbolic link that points to the sql folder.\"\"\"", "\n", "\n", "# Unique filename for the symlink.", "\n", "include_path", "=", "os", ".", "path", ".", "join", "(", "'/tmp/'", ",", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", ")", "\n", "os", ".", "makedirs", "(", "include_path", ")", "\n", "\n", "os", ".", "symlink", "(", "\n", "os", ".", "path", ".", "join", "(", "PROJECT_PATH", ",", "folder", ")", ",", "os", ".", "path", ".", "join", "(", "include_path", ",", "folder", ")", ")", "\n", "\n", "return", "include_path", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument.run_sql_experiment": [[23, 56], ["garage.experiment.experiment.run_experiment", "softqlearning.misc.utils.timestamp", "os.path.join", "list", "list.append", "list", "kwargs.update", "exp_prefix.replace", "list.append", "instrument._create_symlink"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.run_experiment", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument._create_symlink"], ["", "def", "run_sql_experiment", "(", "main", ",", "\n", "mode", ",", "\n", "include_folders", "=", "None", ",", "\n", "log_dir", "=", "None", ",", "\n", "exp_prefix", "=", "\"experiment\"", ",", "\n", "exp_name", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "if", "exp_name", "is", "None", ":", "\n", "        ", "exp_name", "=", "timestamp", "(", ")", "\n", "\n", "", "if", "log_dir", "is", "None", ":", "\n", "        ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "DEFAULT_LOG_DIR", ",", "\"local\"", ",", "\n", "exp_prefix", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", ",", "exp_name", ")", "\n", "\n", "", "if", "include_folders", "is", "None", ":", "\n", "        ", "include_folders", "=", "list", "(", ")", "\n", "\n", "", "if", "mode", "==", "'ec2'", ":", "\n", "        ", "include_folders", ".", "append", "(", "'softqlearning'", ")", "\n", "all_symlinks", "=", "list", "(", ")", "\n", "\n", "for", "folder", "in", "include_folders", ":", "\n", "            ", "all_symlinks", ".", "append", "(", "_create_symlink", "(", "folder", ")", ")", "\n", "\n", "", "kwargs", ".", "update", "(", "added_project_directories", "=", "all_symlinks", ")", "\n", "\n", "", "run_experiment", "(", "\n", "method_call", "=", "main", ",", "\n", "mode", "=", "mode", ",", "\n", "exp_prefix", "=", "exp_prefix", ",", "\n", "exp_name", "=", "exp_name", ",", "\n", "log_dir", "=", "log_dir", ",", "\n", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp": [[9, 12], ["datetime.datetime.now", "datetime.datetime.now.strftime", "dateutil.tz.tzlocal"], "function", ["None"], ["def", "timestamp", "(", ")", ":", "\n", "    ", "now", "=", "datetime", ".", "datetime", ".", "now", "(", "dateutil", ".", "tz", ".", "tzlocal", "(", ")", ")", "\n", "return", "now", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S-%f-%Z'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.deep_clone": [[18, 43], ["isinstance", "obj.__getstate__", "obj.__getstate__.items", "list", "enumerate", "type().__new__", "type().__new__.__setstate__", "isinstance", "utils.deep_clone.maybe_deep_clone"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.__getstate__", "home.repos.pwc.inspect_result.haarnoja_softqlearning.replay_buffers.simple_replay_buffer.SimpleReplayBuffer.__setstate__"], ["def", "deep_clone", "(", "obj", ")", ":", "\n", "    ", "assert", "isinstance", "(", "obj", ",", "Serializable", ")", "\n", "\n", "def", "maybe_deep_clone", "(", "o", ")", ":", "\n", "        ", "if", "isinstance", "(", "o", ",", "Serializable", ")", ":", "\n", "            ", "return", "deep_clone", "(", "o", ")", "\n", "", "else", ":", "\n", "            ", "return", "o", "\n", "\n", "", "", "d", "=", "obj", ".", "__getstate__", "(", ")", "\n", "for", "key", ",", "val", "in", "d", ".", "items", "(", ")", ":", "\n", "        ", "d", "[", "key", "]", "=", "maybe_deep_clone", "(", "val", ")", "\n", "\n", "", "d", "[", "'__args'", "]", "=", "list", "(", "d", "[", "'__args'", "]", ")", "# Make args mutable.", "\n", "for", "i", ",", "val", "in", "enumerate", "(", "d", "[", "'__args'", "]", ")", ":", "\n", "        ", "d", "[", "'__args'", "]", "[", "i", "]", "=", "maybe_deep_clone", "(", "val", ")", "\n", "\n", "", "for", "key", ",", "val", "in", "d", "[", "'__kwargs'", "]", ":", "\n", "        ", "d", "[", "'__kwargs'", "]", "[", "key", "]", "=", "maybe_deep_clone", "(", "val", ")", "\n", "\n", "", "out", "=", "type", "(", "obj", ")", ".", "__new__", "(", "type", "(", "obj", ")", ")", "\n", "# noinspection PyArgumentList", "\n", "out", ".", "__setstate__", "(", "d", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec": [[45, 51], ["garage.envs.EnvSpec"], "function", ["None"], ["", "def", "spec", "(", "env", ")", ":", "\n", "    ", "if", "env", ".", "spec", "is", "not", "None", ":", "\n", "        ", "return", "env", ".", "spec", "\n", "", "return", "EnvSpec", "(", "\n", "observation_space", "=", "env", ".", "observation_space", ",", "\n", "action_space", "=", "env", ".", "action_space", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql.parse_args": [[96, 106], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "softqlearning.misc.utils.timestamp"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--env'", ",", "type", "=", "str", ",", "choices", "=", "AVAILABLE_ENVS", ",", "default", "=", "DEFAULT_ENV", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_name'", ",", "type", "=", "str", ",", "default", "=", "timestamp", "(", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'local'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql.get_variants": [[108, 121], ["params.update", "garage.experiment.experiment.VariantGenerator", "params.items", "isinstance", "garage.experiment.experiment.VariantGenerator.add", "garage.experiment.experiment.VariantGenerator.add"], "function", ["None"], ["", "def", "get_variants", "(", "args", ")", ":", "\n", "    ", "env_params", "=", "ENV_PARAMS", "[", "args", ".", "env", "]", "\n", "params", "=", "SHARED_PARAMS", "\n", "params", ".", "update", "(", "env_params", ")", "\n", "\n", "vg", "=", "VariantGenerator", "(", ")", "\n", "for", "key", ",", "val", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "list", ")", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "[", "val", "]", ")", "\n", "\n", "", "", "return", "vg", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql.run_experiment": [[123, 172], ["softqlearning.replay_buffers.SimpleReplayBuffer", "softqlearning.misc.sampler.SimpleSampler", "dict", "softqlearning.value_functions.NNQFunction", "softqlearning.policies.StochasticNNPolicy", "softqlearning.algorithms.SQL", "softqlearning.algorithms.SQL.train", "garage.envs.normalized_env.normalize", "garage.envs.mujoco.humanoid_env.HumanoidEnv", "garage.envs.normalized_env.normalize", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "garage.envs.mujoco.swimmer_env.SwimmerEnv", "garage.envs.normalized_env.normalize", "garage.envs.normalized_env.normalize", "garage.envs.mujoco.ant_env.AntEnv", "softqlearning.environments.GymEnv"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.train", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec"], ["", "def", "run_experiment", "(", "variant", ")", ":", "\n", "    ", "if", "variant", "[", "'env_name'", "]", "==", "'humanoid-rllab'", ":", "\n", "        ", "env", "=", "normalize", "(", "HumanoidEnv", "(", ")", ")", "\n", "", "elif", "variant", "[", "'env_name'", "]", "==", "'swimmer-rllab'", ":", "\n", "        ", "env", "=", "normalize", "(", "SwimmerEnv", "(", ")", ")", "\n", "", "elif", "variant", "[", "'env_name'", "]", "==", "'ant-rllab'", ":", "\n", "        ", "env", "=", "normalize", "(", "AntEnv", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "normalize", "(", "GymEnv", "(", "variant", "[", "'env_name'", "]", ")", ")", "\n", "\n", "", "pool", "=", "SimpleReplayBuffer", "(", "\n", "env_spec", "=", "spec", "(", "env", ")", ",", "max_replay_buffer_size", "=", "variant", "[", "'max_pool_size'", "]", ")", "\n", "\n", "sampler", "=", "SimpleSampler", "(", "\n", "max_path_length", "=", "variant", "[", "'max_path_length'", "]", ",", "\n", "min_pool_size", "=", "variant", "[", "'max_path_length'", "]", ",", "\n", "batch_size", "=", "variant", "[", "'batch_size'", "]", ")", "\n", "\n", "base_kwargs", "=", "dict", "(", "\n", "epoch_length", "=", "variant", "[", "'epoch_length'", "]", ",", "\n", "n_epochs", "=", "variant", "[", "'n_epochs'", "]", ",", "\n", "n_train_repeat", "=", "variant", "[", "'n_train_repeat'", "]", ",", "\n", "eval_render", "=", "False", ",", "\n", "eval_n_episodes", "=", "1", ",", "\n", "sampler", "=", "sampler", ")", "\n", "\n", "M", "=", "variant", "[", "'layer_size'", "]", "\n", "qf", "=", "NNQFunction", "(", "env_spec", "=", "spec", "(", "env", ")", ",", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ")", "\n", "\n", "policy", "=", "StochasticNNPolicy", "(", "env_spec", "=", "spec", "(", "env", ")", ",", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ")", "\n", "\n", "algorithm", "=", "SQL", "(", "\n", "base_kwargs", "=", "base_kwargs", ",", "\n", "env", "=", "env", ",", "\n", "pool", "=", "pool", ",", "\n", "qf", "=", "qf", ",", "\n", "policy", "=", "policy", ",", "\n", "kernel_fn", "=", "adaptive_isotropic_gaussian_kernel", ",", "\n", "kernel_n_particles", "=", "variant", "[", "'kernel_particles'", "]", ",", "\n", "kernel_update_ratio", "=", "variant", "[", "'kernel_update_ratio'", "]", ",", "\n", "value_n_particles", "=", "variant", "[", "'value_n_particles'", "]", ",", "\n", "td_target_update_interval", "=", "variant", "[", "'td_target_update_interval'", "]", ",", "\n", "qf_lr", "=", "variant", "[", "'qf_lr'", "]", ",", "\n", "policy_lr", "=", "variant", "[", "'policy_lr'", "]", ",", "\n", "discount", "=", "variant", "[", "'discount'", "]", ",", "\n", "reward_scale", "=", "variant", "[", "'reward_scale'", "]", ",", "\n", "save_full_state", "=", "False", ")", "\n", "\n", "algorithm", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql.launch_experiments": [[174, 194], ["variant_generator.variants", "enumerate", "print", "softqlearning.misc.instrument.run_sql_experiment", "str().zfill", "len", "str"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument.run_sql_experiment"], ["", "def", "launch_experiments", "(", "variant_generator", ",", "args", ")", ":", "\n", "    ", "variants", "=", "variant_generator", ".", "variants", "(", ")", "\n", "for", "i", ",", "variant", "in", "enumerate", "(", "variants", ")", ":", "\n", "        ", "print", "(", "'Launching {} experiments.'", ".", "format", "(", "len", "(", "variants", ")", ")", ")", "\n", "full_experiment_name", "=", "variant", "[", "'prefix'", "]", "\n", "full_experiment_name", "+=", "'-'", "+", "args", ".", "exp_name", "+", "'-'", "+", "str", "(", "i", ")", ".", "zfill", "(", "2", ")", "\n", "\n", "run_sql_experiment", "(", "\n", "run_experiment", ",", "\n", "mode", "=", "args", ".", "mode", ",", "\n", "variant", "=", "variant", ",", "\n", "exp_prefix", "=", "variant", "[", "'prefix'", "]", "+", "'/'", "+", "args", ".", "exp_name", ",", "\n", "exp_name", "=", "full_experiment_name", ",", "\n", "n_parallel", "=", "1", ",", "\n", "seed", "=", "variant", "[", "'seed'", "]", ",", "\n", "terminate_machine", "=", "True", ",", "\n", "log_dir", "=", "args", ".", "log_dir", ",", "\n", "snapshot_mode", "=", "variant", "[", "'snapshot_mode'", "]", ",", "\n", "snapshot_gap", "=", "variant", "[", "'snapshot_gap'", "]", ",", "\n", "sync_s3_pkl", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql.main": [[196, 200], ["mujoco_all_sql.parse_args", "mujoco_all_sql.get_variants", "mujoco_all_sql.launch_experiments"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.get_variants", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.launch_experiments"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "variant_generator", "=", "get_variants", "(", "args", ")", "\n", "launch_experiments", "(", "variant_generator", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_pretrain.parse_args": [[50, 60], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "softqlearning.misc.utils.timestamp"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--env'", ",", "type", "=", "str", ",", "choices", "=", "AVAILABLE_ENVS", ",", "default", "=", "DEFAULT_ENV", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_name'", ",", "type", "=", "str", ",", "default", "=", "timestamp", "(", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'local'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_pretrain.get_variants": [[62, 75], ["params.update", "garage.experiment.experiment.VariantGenerator", "params.items", "isinstance", "garage.experiment.experiment.VariantGenerator.add", "garage.experiment.experiment.VariantGenerator.add"], "function", ["None"], ["", "def", "get_variants", "(", "args", ")", ":", "\n", "    ", "env_params", "=", "ENV_PARAMS", "[", "args", ".", "env", "]", "\n", "params", "=", "SHARED_PARAMS", "\n", "params", ".", "update", "(", "env_params", ")", "\n", "\n", "vg", "=", "VariantGenerator", "(", ")", "\n", "for", "key", ",", "val", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "list", ")", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "[", "val", "]", ")", "\n", "\n", "", "", "return", "vg", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_pretrain.run_experiment": [[77, 132], ["softqlearning.replay_buffers.SimpleReplayBuffer", "softqlearning.misc.sampler.SimpleSampler", "dict", "abs", "softqlearning.value_functions.NNQFunction", "softqlearning.policies.StochasticNNPolicy", "softqlearning.algorithms.SQL", "softqlearning.algorithms.SQL.train", "garage.envs.normalized_env.normalize", "pickle.dumps().__hash__", "softqlearning.environments.pusher.PusherEnv", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "pickle.dumps", "variant.get"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.train", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec"], ["", "def", "run_experiment", "(", "variant", ")", ":", "\n", "    ", "if", "variant", "[", "'env_name'", "]", "==", "'pusher'", ":", "\n", "# TODO: assumes `pusher.xml` is located in `rllab/models/` when", "\n", "# running on EC2.", "\n", "        ", "env", "=", "normalize", "(", "PusherEnv", "(", "goal", "=", "variant", ".", "get", "(", "'goal'", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n", "", "pool", "=", "SimpleReplayBuffer", "(", "\n", "env_spec", "=", "spec", "(", "env", ")", ",", "max_replay_buffer_size", "=", "variant", "[", "'max_pool_size'", "]", ")", "\n", "\n", "sampler", "=", "SimpleSampler", "(", "\n", "max_path_length", "=", "variant", "[", "'max_path_length'", "]", ",", "\n", "min_pool_size", "=", "variant", "[", "'max_path_length'", "]", ",", "\n", "batch_size", "=", "variant", "[", "'batch_size'", "]", ")", "\n", "\n", "base_kwargs", "=", "dict", "(", "\n", "epoch_length", "=", "variant", "[", "'epoch_length'", "]", ",", "\n", "n_epochs", "=", "variant", "[", "'n_epochs'", "]", ",", "\n", "n_train_repeat", "=", "variant", "[", "'n_train_repeat'", "]", ",", "\n", "eval_render", "=", "False", ",", "\n", "eval_n_episodes", "=", "1", ",", "\n", "sampler", "=", "sampler", ")", "\n", "\n", "task_id", "=", "abs", "(", "pickle", ".", "dumps", "(", "variant", ")", ".", "__hash__", "(", ")", ")", "\n", "\n", "M", "=", "variant", "[", "'layer_size'", "]", "\n", "qf", "=", "NNQFunction", "(", "\n", "env_spec", "=", "spec", "(", "env", ")", ",", "\n", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ",", "\n", "name", "=", "'qf_{i}'", ".", "format", "(", "i", "=", "task_id", ")", ")", "\n", "\n", "policy", "=", "StochasticNNPolicy", "(", "\n", "env_spec", "=", "spec", "(", "env", ")", ",", "\n", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ",", "\n", "name", "=", "'policy_{i}'", ".", "format", "(", "i", "=", "task_id", ")", ")", "\n", "\n", "algorithm", "=", "SQL", "(", "\n", "base_kwargs", "=", "base_kwargs", ",", "\n", "env", "=", "env", ",", "\n", "pool", "=", "pool", ",", "\n", "qf", "=", "qf", ",", "\n", "policy", "=", "policy", ",", "\n", "kernel_fn", "=", "adaptive_isotropic_gaussian_kernel", ",", "\n", "kernel_n_particles", "=", "variant", "[", "'kernel_particles'", "]", ",", "\n", "kernel_update_ratio", "=", "variant", "[", "'kernel_update_ratio'", "]", ",", "\n", "value_n_particles", "=", "variant", "[", "'value_n_particles'", "]", ",", "\n", "td_target_update_interval", "=", "variant", "[", "'td_target_update_interval'", "]", ",", "\n", "qf_lr", "=", "variant", "[", "'qf_lr'", "]", ",", "\n", "policy_lr", "=", "variant", "[", "'policy_lr'", "]", ",", "\n", "discount", "=", "variant", "[", "'discount'", "]", ",", "\n", "reward_scale", "=", "variant", "[", "'reward_scale'", "]", ",", "\n", "save_full_state", "=", "variant", "[", "'save_full_state'", "]", ")", "\n", "\n", "algorithm", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_pretrain.launch_experiments": [[134, 155], ["variant_generator.variants", "print", "enumerate", "softqlearning.misc.instrument.run_sql_experiment", "len", "str().zfill", "str", "str().zfill", "str"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument.run_sql_experiment"], ["", "def", "launch_experiments", "(", "variant_generator", ",", "args", ")", ":", "\n", "    ", "variants", "=", "variant_generator", ".", "variants", "(", ")", "\n", "print", "(", "'Launching {} experiments.'", ".", "format", "(", "len", "(", "variants", ")", ")", ")", "\n", "\n", "for", "i", ",", "variant", "in", "enumerate", "(", "variants", ")", ":", "\n", "        ", "full_experiment_name", "=", "variant", "[", "'prefix'", "]", "\n", "full_experiment_name", "+=", "'-'", "+", "args", ".", "exp_name", "+", "'-'", "+", "str", "(", "i", ")", ".", "zfill", "(", "2", ")", "\n", "\n", "run_sql_experiment", "(", "\n", "run_experiment", ",", "\n", "mode", "=", "args", ".", "mode", ",", "\n", "variant", "=", "variant", ",", "\n", "exp_prefix", "=", "variant", "[", "'prefix'", "]", "+", "'/'", "+", "args", ".", "exp_name", ",", "\n", "exp_name", "=", "full_experiment_name", ",", "\n", "n_parallel", "=", "1", ",", "\n", "seed", "=", "variant", "[", "'seed'", "]", ",", "\n", "terminate_machine", "=", "True", ",", "\n", "log_dir", "=", "args", ".", "log_dir", "+", "'/'", "+", "str", "(", "i", ")", ".", "zfill", "(", "2", ")", ",", "\n", "snapshot_mode", "=", "variant", "[", "'snapshot_mode'", "]", ",", "\n", "snapshot_gap", "=", "variant", "[", "'snapshot_gap'", "]", ",", "\n", "sync_s3_pkl", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_pretrain.main": [[157, 161], ["pusher_pretrain.parse_args", "pusher_pretrain.get_variants", "pusher_pretrain.launch_experiments"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.get_variants", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.launch_experiments"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "variant_generator", "=", "get_variants", "(", "args", ")", "\n", "launch_experiments", "(", "variant_generator", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.reuse_qf_policy_swimmer.run_experiment": [[17, 65], ["garage.envs.normalized_env.normalize", "softqlearning.replay_buffers.SimpleReplayBuffer", "softqlearning.misc.sampler.SimpleSampler", "dict", "garage.envs.mujoco.swimmer_env.SwimmerEnv", "tensorflow.Session().as_default", "joblib.load", "softqlearning.algorithms.SQL", "softqlearning.algorithms.SQL.train", "softqlearning.misc.utils.spec", "joblib.load.keys", "tensorflow.Session"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.train", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec"], ["def", "run_experiment", "(", "variant", ")", ":", "\n", "    ", "env", "=", "normalize", "(", "SwimmerEnv", "(", ")", ")", "\n", "\n", "pool", "=", "SimpleReplayBuffer", "(", "\n", "env_spec", "=", "spec", "(", "env", ")", ",", "max_replay_buffer_size", "=", "1e6", ")", "\n", "\n", "sampler", "=", "SimpleSampler", "(", "\n", "max_path_length", "=", "1000", ",", "\n", "min_pool_size", "=", "1000", ",", "\n", "batch_size", "=", "128", ")", "\n", "\n", "base_kwargs", "=", "dict", "(", "\n", "epoch_length", "=", "1000", ",", "\n", "n_epochs", "=", "500", ",", "\n", "n_train_repeat", "=", "1", ",", "\n", "eval_render", "=", "False", ",", "\n", "eval_n_episodes", "=", "1", ",", "\n", "sampler", "=", "sampler", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "data", "=", "joblib", ".", "load", "(", "variant", "[", "'file'", "]", ")", "\n", "if", "'algo'", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "saved_qf", "=", "data", "[", "'algo'", "]", ".", "qf", "\n", "saved_policy", "=", "data", "[", "'algo'", "]", ".", "policy", "\n", "", "else", ":", "\n", "            ", "saved_qf", "=", "data", "[", "'qf'", "]", "\n", "saved_policy", "=", "data", "[", "'policy'", "]", "\n", "\n", "", "algorithm", "=", "SQL", "(", "\n", "base_kwargs", "=", "base_kwargs", ",", "\n", "env", "=", "env", ",", "\n", "pool", "=", "pool", ",", "\n", "qf", "=", "saved_qf", ",", "\n", "policy", "=", "saved_policy", ",", "\n", "kernel_fn", "=", "adaptive_isotropic_gaussian_kernel", ",", "\n", "kernel_n_particles", "=", "16", ",", "\n", "kernel_update_ratio", "=", "0.5", ",", "\n", "value_n_particles", "=", "16", ",", "\n", "td_target_update_interval", "=", "1000", ",", "\n", "qf_lr", "=", "3E-4", ",", "\n", "policy_lr", "=", "3E-4", ",", "\n", "discount", "=", "0.99", ",", "\n", "reward_scale", "=", "30", ",", "\n", "use_saved_qf", "=", "True", ",", "\n", "use_saved_policy", "=", "True", ",", "\n", "save_full_state", "=", "False", ")", "\n", "\n", "algorithm", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.reuse_qf_policy_swimmer.parse_args": [[67, 72], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'file'", ",", "type", "=", "str", ",", "help", "=", "'Path to the snapshot file.'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.reuse_qf_policy_swimmer.main": [[74, 93], ["reuse_qf_policy_swimmer.parse_args", "softqlearning.misc.instrument.run_sql_experiment", "softqlearning.misc.utils.timestamp", "dict", "softqlearning.misc.utils.timestamp"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument.run_sql_experiment", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp"], ["", "def", "main", "(", ")", ":", "\n", "    ", "full_experiment_name", "=", "'swimmer'", "\n", "full_experiment_name", "+=", "'-'", "+", "timestamp", "(", ")", "\n", "args", "=", "parse_args", "(", ")", "\n", "saved_file", "=", "args", ".", "file", "\n", "run_sql_experiment", "(", "\n", "run_experiment", ",", "\n", "mode", "=", "'local'", ",", "\n", "variant", "=", "dict", "(", "file", "=", "saved_file", ")", ",", "\n", "exp_prefix", "=", "'swimmer'", "+", "'/'", "+", "'reuse'", "+", "'/'", "+", "timestamp", "(", ")", ",", "\n", "exp_name", "=", "full_experiment_name", ",", "\n", "n_parallel", "=", "1", ",", "\n", "seed", "=", "1", ",", "\n", "terminate_machine", "=", "True", ",", "\n", "log_dir", "=", "None", ",", "\n", "snapshot_mode", "=", "'gap'", ",", "\n", "snapshot_gap", "=", "100", ",", "\n", "sync_s3_pkl", "=", "True", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.parse_args": [[45, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "softqlearning.misc.utils.timestamp"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--env'", ",", "type", "=", "str", ",", "choices", "=", "AVAILABLE_ENVS", ",", "default", "=", "DEFAULT_ENV", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_name'", ",", "type", "=", "str", ",", "default", "=", "timestamp", "(", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'local'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--snapshot1'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--snapshot2'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.get_variants": [[59, 75], ["params.update", "garage.experiment.experiment.VariantGenerator", "params.items", "garage.experiment.experiment.VariantGenerator.add", "garage.experiment.experiment.VariantGenerator.add", "isinstance", "garage.experiment.experiment.VariantGenerator.add", "garage.experiment.experiment.VariantGenerator.add"], "function", ["None"], ["", "def", "get_variants", "(", "args", ")", ":", "\n", "    ", "env_params", "=", "ENV_PARAMS", "[", "args", ".", "env", "]", "\n", "params", "=", "SHARED_PARAMS", "\n", "params", ".", "update", "(", "env_params", ")", "\n", "\n", "vg", "=", "VariantGenerator", "(", ")", "\n", "for", "key", ",", "val", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "list", ")", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "[", "val", "]", ")", "\n", "\n", "", "", "vg", ".", "add", "(", "'snapshot1'", ",", "(", "args", ".", "snapshot1", ",", ")", ")", "\n", "vg", ".", "add", "(", "'snapshot2'", ",", "(", "args", ".", "snapshot2", ",", ")", ")", "\n", "\n", "return", "vg", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.load_buffer_and_qf": [[77, 82], ["softqlearning.misc.tf_utils.get_default_session().as_default", "joblib.load", "os.path.join", "softqlearning.misc.tf_utils.get_default_session"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.tf_utils.get_default_session"], ["", "def", "load_buffer_and_qf", "(", "filename", ")", ":", "\n", "    ", "with", "tf_utils", ".", "get_default_session", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "data", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "PROJECT_PATH", ",", "filename", ")", ")", "\n", "\n", "", "return", "data", "[", "'replay_buffer'", "]", ",", "data", "[", "'qf'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.run_experiment": [[84, 127], ["garage.envs.normalized_env.normalize", "pusher_combine.load_buffer_and_qf", "pusher_combine.load_buffer_and_qf", "softqlearning.misc.sampler.DummySampler", "softqlearning.replay_buffers.UnionBuffer", "softqlearning.value_functions.SumQFunction", "softqlearning.policies.StochasticNNPolicy", "dict", "softqlearning.algorithms.SQL", "softqlearning.algorithms.SQL.train", "softqlearning.environments.pusher.PusherEnv", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "variant.get"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.load_buffer_and_qf", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.load_buffer_and_qf", "home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.train", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec"], ["", "def", "run_experiment", "(", "variant", ")", ":", "\n", "    ", "env", "=", "normalize", "(", "PusherEnv", "(", "goal", "=", "variant", ".", "get", "(", "'goal'", ")", ")", ")", "\n", "\n", "buffer1", ",", "qf1", "=", "load_buffer_and_qf", "(", "variant", "[", "'snapshot1'", "]", ")", "\n", "buffer2", ",", "qf2", "=", "load_buffer_and_qf", "(", "variant", "[", "'snapshot2'", "]", ")", "\n", "\n", "sampler", "=", "DummySampler", "(", "\n", "batch_size", "=", "variant", "[", "'batch_size'", "]", ",", "\n", "max_path_length", "=", "variant", "[", "'max_path_length'", "]", ")", "\n", "buffer", "=", "UnionBuffer", "(", "buffers", "=", "(", "buffer1", ",", "buffer2", ")", ")", "\n", "\n", "qf", "=", "SumQFunction", "(", "spec", "(", "env", ")", ",", "q_functions", "=", "(", "qf1", ",", "qf2", ")", ")", "\n", "\n", "M", "=", "variant", "[", "'layer_size'", "]", "\n", "policy", "=", "StochasticNNPolicy", "(", "\n", "env_spec", "=", "spec", "(", "env", ")", ",", "\n", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ",", "\n", "name", "=", "'policy{i}'", ".", "format", "(", "i", "=", "0", ")", ")", "\n", "\n", "base_kwargs", "=", "dict", "(", "\n", "epoch_length", "=", "variant", "[", "'epoch_length'", "]", ",", "\n", "n_epochs", "=", "variant", "[", "'n_epochs'", "]", ",", "\n", "n_train_repeat", "=", "1", ",", "\n", "eval_render", "=", "False", ",", "\n", "eval_n_episodes", "=", "1", ",", "\n", "sampler", "=", "sampler", ")", "\n", "\n", "algorithm", "=", "SQL", "(", "\n", "base_kwargs", "=", "base_kwargs", ",", "\n", "env", "=", "env", ",", "\n", "pool", "=", "buffer", ",", "\n", "qf", "=", "qf", ",", "\n", "policy", "=", "policy", ",", "\n", "kernel_fn", "=", "adaptive_isotropic_gaussian_kernel", ",", "\n", "kernel_n_particles", "=", "variant", "[", "'kernel_particles'", "]", ",", "\n", "kernel_update_ratio", "=", "variant", "[", "'kernel_update_ratio'", "]", ",", "\n", "policy_lr", "=", "variant", "[", "'policy_lr'", "]", ",", "\n", "save_full_state", "=", "False", ",", "\n", "train_policy", "=", "True", ",", "\n", "train_qf", "=", "False", ",", "\n", "use_saved_qf", "=", "True", ")", "\n", "\n", "algorithm", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.launch_experiments": [[129, 150], ["variant_generator.variants", "print", "enumerate", "softqlearning.misc.instrument.run_sql_experiment", "len", "str().zfill", "str"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument.run_sql_experiment"], ["", "def", "launch_experiments", "(", "variant_generator", ",", "args", ")", ":", "\n", "    ", "variants", "=", "variant_generator", ".", "variants", "(", ")", "\n", "print", "(", "'Launching {} experiments.'", ".", "format", "(", "len", "(", "variants", ")", ")", ")", "\n", "\n", "for", "i", ",", "variant", "in", "enumerate", "(", "variants", ")", ":", "\n", "        ", "full_experiment_name", "=", "variant", "[", "'prefix'", "]", "\n", "full_experiment_name", "+=", "'-'", "+", "args", ".", "exp_name", "+", "'-'", "+", "str", "(", "i", ")", ".", "zfill", "(", "2", ")", "\n", "\n", "run_sql_experiment", "(", "\n", "run_experiment", ",", "\n", "mode", "=", "args", ".", "mode", ",", "\n", "variant", "=", "variant", ",", "\n", "exp_prefix", "=", "variant", "[", "'prefix'", "]", "+", "'/'", "+", "args", ".", "exp_name", ",", "\n", "exp_name", "=", "full_experiment_name", ",", "\n", "n_parallel", "=", "1", ",", "\n", "seed", "=", "variant", "[", "'seed'", "]", ",", "\n", "terminate_machine", "=", "True", ",", "\n", "log_dir", "=", "args", ".", "log_dir", ",", "\n", "snapshot_mode", "=", "variant", "[", "'snapshot_mode'", "]", ",", "\n", "snapshot_gap", "=", "variant", "[", "'snapshot_gap'", "]", ",", "\n", "sync_s3_pkl", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.pusher_combine.main": [[152, 156], ["pusher_combine.parse_args", "pusher_combine.get_variants", "pusher_combine.launch_experiments"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.get_variants", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.launch_experiments"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "variant_generator", "=", "get_variants", "(", "args", ")", "\n", "launch_experiments", "(", "variant_generator", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.multigoal_sql.test": [[17, 67], ["garage.envs.normalized_env.normalize", "softqlearning.replay_buffers.SimpleReplayBuffer", "softqlearning.misc.sampler.SimpleSampler", "softqlearning.policies.StochasticNNPolicy", "softqlearning.value_functions.NNQFunction", "softqlearning.misc.plotter.QFPolicyPlotter", "softqlearning.algorithms.SQL", "softqlearning.algorithms.SQL.train", "softqlearning.environments.MultiGoalEnv", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "numpy.array"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.train", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec"], ["def", "test", "(", ")", ":", "\n", "\n", "    ", "env", "=", "normalize", "(", "MultiGoalEnv", "(", ")", ")", "\n", "\n", "pool", "=", "SimpleReplayBuffer", "(", "env_spec", "=", "spec", "(", "env", ")", ",", "max_replay_buffer_size", "=", "1e6", ")", "\n", "\n", "sampler", "=", "SimpleSampler", "(", "\n", "max_path_length", "=", "30", ",", "min_pool_size", "=", "100", ",", "batch_size", "=", "64", ")", "\n", "\n", "base_kwargs", "=", "{", "\n", "'sampler'", ":", "sampler", ",", "\n", "'epoch_length'", ":", "100", ",", "\n", "'n_epochs'", ":", "1000", ",", "\n", "'n_train_repeat'", ":", "1", ",", "\n", "'eval_render'", ":", "True", ",", "\n", "'eval_n_episodes'", ":", "10", "\n", "}", "\n", "\n", "M", "=", "128", "\n", "policy", "=", "StochasticNNPolicy", "(", "\n", "spec", "(", "env", ")", ",", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ",", "squash", "=", "True", ")", "\n", "\n", "qf", "=", "NNQFunction", "(", "env_spec", "=", "spec", "(", "env", ")", ",", "hidden_layer_sizes", "=", "[", "M", ",", "M", "]", ")", "\n", "\n", "plotter", "=", "QFPolicyPlotter", "(", "\n", "qf", "=", "qf", ",", "\n", "policy", "=", "policy", ",", "\n", "obs_lst", "=", "np", ".", "array", "(", "[", "[", "-", "2.5", ",", "0.0", "]", ",", "[", "0.0", ",", "0.0", "]", ",", "[", "2.5", ",", "2.5", "]", "]", ")", ",", "\n", "default_action", "=", "[", "np", ".", "nan", ",", "np", ".", "nan", "]", ",", "\n", "n_samples", "=", "100", ")", "\n", "\n", "algorithm", "=", "SQL", "(", "\n", "base_kwargs", "=", "base_kwargs", ",", "\n", "env", "=", "env", ",", "\n", "pool", "=", "pool", ",", "\n", "qf", "=", "qf", ",", "\n", "policy", "=", "policy", ",", "\n", "plotter", "=", "plotter", ",", "\n", "policy_lr", "=", "3e-4", ",", "\n", "qf_lr", "=", "3e-4", ",", "\n", "value_n_particles", "=", "16", ",", "\n", "td_target_update_interval", "=", "1000", ",", "\n", "kernel_fn", "=", "adaptive_isotropic_gaussian_kernel", ",", "\n", "kernel_n_particles", "=", "32", ",", "\n", "kernel_update_ratio", "=", "0.5", ",", "\n", "discount", "=", "0.99", ",", "\n", "reward_scale", "=", "0.1", ",", "\n", "save_full_state", "=", "False", ")", "\n", "\n", "algorithm", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.parse_args": [[90, 100], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "softqlearning.misc.utils.timestamp"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.timestamp"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--env'", ",", "type", "=", "str", ",", "choices", "=", "AVAILABLE_ENVS", ",", "default", "=", "DEFAULT_ENV", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_name'", ",", "type", "=", "str", ",", "default", "=", "timestamp", "(", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'local'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.get_variants": [[102, 115], ["params.update", "garage.experiment.experiment.VariantGenerator", "params.items", "isinstance", "garage.experiment.experiment.VariantGenerator.add", "garage.experiment.experiment.VariantGenerator.add"], "function", ["None"], ["", "def", "get_variants", "(", "args", ")", ":", "\n", "    ", "env_params", "=", "ENV_PARAMS", "[", "args", ".", "env", "]", "\n", "params", "=", "SHARED_PARAMS", "\n", "params", ".", "update", "(", "env_params", ")", "\n", "\n", "vg", "=", "VariantGenerator", "(", ")", "\n", "for", "key", ",", "val", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "list", ")", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "val", ")", "\n", "", "else", ":", "\n", "            ", "vg", ".", "add", "(", "key", ",", "[", "val", "]", ")", "\n", "\n", "", "", "return", "vg", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.run_experiment": [[117, 166], ["softqlearning.environments.DelayedEnv", "softqlearning.replay_buffers.SimpleReplayBuffer", "softqlearning.misc.remote_sampler.RemoteSampler", "dict", "softqlearning.value_functions.NNQFunction", "softqlearning.policies.StochasticNNPolicy", "softqlearning.algorithms.SQL", "softqlearning.algorithms.SQL.train", "garage.envs.normalized_env.normalize", "garage.envs.mujoco.humanoid_env.HumanoidEnv", "garage.envs.normalized_env.normalize", "garage.envs.normalized_env.normalize", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "softqlearning.misc.utils.spec", "garage.envs.mujoco.swimmer_env.SwimmerEnv", "softqlearning.environments.GymEnv"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.algorithms.sql.SQL.train", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec", "home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.utils.spec"], ["", "def", "run_experiment", "(", "variant", ")", ":", "\n", "    ", "if", "variant", "[", "'env_name'", "]", "==", "'humanoid-rllab'", ":", "\n", "        ", "env", "=", "normalize", "(", "HumanoidEnv", "(", ")", ")", "\n", "", "elif", "variant", "[", "'env_name'", "]", "==", "'swimmer-rllab'", ":", "\n", "        ", "env", "=", "normalize", "(", "SwimmerEnv", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "normalize", "(", "GymEnv", "(", "variant", "[", "'env_name'", "]", ")", ")", "\n", "\n", "", "env", "=", "DelayedEnv", "(", "env", ",", "delay", "=", "0.01", ")", "\n", "\n", "pool", "=", "SimpleReplayBuffer", "(", "\n", "env_spec", "=", "spec", "(", "env", ")", ",", "max_replay_buffer_size", "=", "variant", "[", "'max_pool_size'", "]", ")", "\n", "\n", "sampler", "=", "RemoteSampler", "(", "\n", "max_path_length", "=", "variant", "[", "'max_path_length'", "]", ",", "\n", "min_pool_size", "=", "variant", "[", "'max_path_length'", "]", ",", "\n", "batch_size", "=", "variant", "[", "'batch_size'", "]", ")", "\n", "\n", "base_kwargs", "=", "dict", "(", "\n", "epoch_length", "=", "variant", "[", "'epoch_length'", "]", ",", "\n", "n_epochs", "=", "variant", "[", "'n_epochs'", "]", ",", "\n", "n_train_repeat", "=", "variant", "[", "'n_train_repeat'", "]", ",", "\n", "eval_render", "=", "False", ",", "\n", "eval_n_episodes", "=", "1", ",", "\n", "sampler", "=", "sampler", ")", "\n", "\n", "M", "=", "variant", "[", "'layer_size'", "]", "\n", "qf", "=", "NNQFunction", "(", "env_spec", "=", "spec", "(", "env", ")", ",", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ")", "\n", "\n", "policy", "=", "StochasticNNPolicy", "(", "env_spec", "=", "spec", "(", "env", ")", ",", "hidden_layer_sizes", "=", "(", "M", ",", "M", ")", ")", "\n", "\n", "algorithm", "=", "SQL", "(", "\n", "base_kwargs", "=", "base_kwargs", ",", "\n", "env", "=", "env", ",", "\n", "pool", "=", "pool", ",", "\n", "qf", "=", "qf", ",", "\n", "policy", "=", "policy", ",", "\n", "kernel_fn", "=", "adaptive_isotropic_gaussian_kernel", ",", "\n", "kernel_n_particles", "=", "32", ",", "\n", "kernel_update_ratio", "=", "0.5", ",", "\n", "value_n_particles", "=", "16", ",", "\n", "td_target_update_interval", "=", "1000", ",", "\n", "qf_lr", "=", "variant", "[", "'qf_lr'", "]", ",", "\n", "policy_lr", "=", "variant", "[", "'policy_lr'", "]", ",", "\n", "discount", "=", "variant", "[", "'discount'", "]", ",", "\n", "reward_scale", "=", "variant", "[", "'reward_scale'", "]", ",", "\n", "save_full_state", "=", "False", ")", "\n", "\n", "algorithm", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.launch_experiments": [[168, 188], ["variant_generator.variants", "enumerate", "print", "softqlearning.misc.instrument.run_sql_experiment", "str().zfill", "len", "str"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.instrument.run_sql_experiment"], ["", "def", "launch_experiments", "(", "variant_generator", ",", "args", ")", ":", "\n", "    ", "variants", "=", "variant_generator", ".", "variants", "(", ")", "\n", "for", "i", ",", "variant", "in", "enumerate", "(", "variants", ")", ":", "\n", "        ", "print", "(", "'Launching {} experiments.'", ".", "format", "(", "len", "(", "variants", ")", ")", ")", "\n", "full_experiment_name", "=", "variant", "[", "'prefix'", "]", "\n", "full_experiment_name", "+=", "'-'", "+", "args", ".", "exp_name", "+", "'-'", "+", "str", "(", "i", ")", ".", "zfill", "(", "2", ")", "\n", "\n", "run_sql_experiment", "(", "\n", "run_experiment", ",", "\n", "mode", "=", "args", ".", "mode", ",", "\n", "variant", "=", "variant", ",", "\n", "exp_prefix", "=", "variant", "[", "'prefix'", "]", "+", "'/'", "+", "args", ".", "exp_name", ",", "\n", "exp_name", "=", "full_experiment_name", ",", "\n", "n_parallel", "=", "1", ",", "\n", "seed", "=", "variant", "[", "'seed'", "]", ",", "\n", "terminate_machine", "=", "True", ",", "\n", "log_dir", "=", "args", ".", "log_dir", ",", "\n", "snapshot_mode", "=", "variant", "[", "'snapshot_mode'", "]", ",", "\n", "snapshot_gap", "=", "variant", "[", "'snapshot_gap'", "]", ",", "\n", "sync_s3_pkl", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.main": [[190, 194], ["mujoco_all_sql_remote.parse_args", "mujoco_all_sql_remote.get_variants", "mujoco_all_sql_remote.launch_experiments"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.get_variants", "home.repos.pwc.inspect_result.haarnoja_softqlearning.examples.mujoco_all_sql_remote.launch_experiments"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "variant_generator", "=", "get_variants", "(", "args", ")", "\n", "launch_experiments", "(", "variant_generator", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args": [[9, 19], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'file'", ",", "type", "=", "str", ",", "help", "=", "'Path to the snapshot file.'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-path-length'", ",", "'-l'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--speedup'", ",", "'-s'", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "set_defaults", "(", "deterministic", "=", "True", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.simulate_policy": [[21, 35], ["tensorflow.Session", "joblib.load", "joblib.load.keys", "garage.sampler.utils.rollout"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.misc.sampler.rollout"], ["", "def", "simulate_policy", "(", "args", ")", ":", "\n", "    ", "with", "tf", ".", "Session", "(", ")", ":", "\n", "        ", "data", "=", "joblib", ".", "load", "(", "args", ".", "file", ")", "\n", "if", "'algo'", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "policy", "=", "data", "[", "'algo'", "]", ".", "policy", "\n", "env", "=", "data", "[", "'algo'", "]", ".", "env", "\n", "", "else", ":", "\n", "            ", "policy", "=", "data", "[", "'policy'", "]", "\n", "env", "=", "data", "[", "'env'", "]", "\n", "\n", "", "while", "True", ":", "\n", "            ", "rollout", "(", "env", ",", "policy", ",", "\n", "max_path_length", "=", "args", ".", "max_path_length", ",", "\n", "animated", "=", "True", ",", "speedup", "=", "args", ".", "speedup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.main": [[37, 40], ["sim_policy.parse_args", "sim_policy.simulate_policy"], "function", ["home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.parse_args", "home.repos.pwc.inspect_result.haarnoja_softqlearning.scripts.sim_policy.simulate_policy"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "simulate_policy", "(", "args", ")", "\n", "\n"]]}