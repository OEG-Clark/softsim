{"home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.run_qa_prune.main": [[25, 362], ["transformers.HfArgumentParser", "os.makedirs", "logging.basicConfig", "training_args.get_process_log_level", "logger.setLevel", "datasets.load_dataset.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "logger.info", "torch.save", "torch.save", "torch.save", "transformers.set_seed", "utils.utils.log_all_parameters", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "Model.from_pretrained", "logger.info", "logger.info", "datasets.load_metric", "trainer.trainer_qa.CoFiQuestionAnsweringTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.join", "os.path.join", "os.path.join", "datasets.load_dataset", "datasets.load_dataset", "Model.from_pretrained", "Model.from_pretrained.eval", "utils.cofi_utils.initialize_layer_transformation", "utils.cofi_utils.load_zs", "utils.cofi_utils.load_model", "utils.cofi_utils.prune_model_with_z", "print", "models.l0_module.L0Module", "isinstance", "ValueError", "AutoTokenizer.from_pretrained.", "tokenizer.pop", "tokenizer.pop", "enumerate", "datasets[].map", "AutoTokenizer.from_pretrained.", "tokenizer.pop", "range", "datasets[].map", "utils.qa_utils.postprocess_qa_predictions", "transformers.EvalPrediction", "datasets.load_metric.compute", "trainer.trainer_qa.CoFiQuestionAnsweringTrainer.train", "trainer.trainer_qa.CoFiQuestionAnsweringTrainer.save_model", "AutoTokenizer.from_pretrained.save_pretrained", "len", "data_args.train_file.split", "bool", "input_ids.index", "tokenizer.sequence_ids", "len", "tokenizer.sequence_ids", "tokenized_examples[].append", "os.path.abspath", "copy.deepcopy", "utils.utils.calculate_parameters", "len", "tokenized_examples[].append", "tokenized_examples[].append", "trainer.trainer_qa.CoFiQuestionAnsweringTrainer.is_world_process_zero", "bool", "utils.utils.calculate_parameters", "len", "len", "tokenized_examples[].append", "tokenized_examples[].append", "tokenized_examples[].append", "tokenized_examples[].append", "enumerate", "utils.qa_utils.postprocess_qa_predictions.items", "utils.qa_utils.postprocess_qa_predictions.items", "len"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.log_all_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.initialize_layer_transformation", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_zs", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_model", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.prune_model_with_z", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.qa_utils.postprocess_qa_predictions", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.train", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.save_model", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "\n", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ",", "AdditionalArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", ",", "additional_args", "=", "parser", ".", "parse_json_file", "(", "\n", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", ",", "additional_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "training_args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "training_args", ".", "local_rank", "in", "[", "\n", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation.py parameters %s\"", ",", "training_args", ")", "\n", "\n", "# save args", "\n", "torch", ".", "save", "(", "data_args", ",", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"data_args.bin\"", ")", ")", "\n", "torch", ".", "save", "(", "model_args", ",", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"model_args.bin\"", ")", ")", "\n", "torch", ".", "save", "(", "additional_args", ",", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"additional_args.bin\"", ")", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# print all arguments", "\n", "log_all_parameters", "(", "logger", ",", "model_args", ",", "data_args", ",", "\n", "training_args", ",", "additional_args", ")", "\n", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ")", "\n", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "field", "=", "\"data\"", ")", "\n", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "True", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# set up configuration for distillation", "\n", "if", "additional_args", ".", "do_distil", ":", "\n", "        ", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "\n", "", "Model", "=", "CoFiBertForQuestionAnswering", "\n", "\n", "teacher_model", "=", "None", "\n", "if", "additional_args", ".", "do_distill", ":", "\n", "        ", "teacher_model", "=", "Model", ".", "from_pretrained", "(", "\n", "additional_args", ".", "distillation_path", ",", "\n", "config", "=", "deepcopy", "(", "config", ")", "\n", ")", "\n", "teacher_model", ".", "eval", "(", ")", "\n", "\n", "", "model", "=", "Model", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "# initialize the layer transformation matrix to be an identity matrix", "\n", "if", "additional_args", ".", "do_layer_distill", ":", "\n", "        ", "initialize_layer_transformation", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "model", ")", "\n", "logger", ".", "info", "(", "f\"Model size: {calculate_parameters(model)}\"", ")", "\n", "\n", "zs", "=", "None", "\n", "if", "additional_args", ".", "pretrained_pruned_model", "is", "not", "None", "and", "not", "additional_args", ".", "pretrained_pruned_model", "==", "\"None\"", ":", "\n", "        ", "zs", "=", "load_zs", "(", "additional_args", ".", "pretrained_pruned_model", ")", "\n", "\n", "model", "=", "load_model", "(", "additional_args", ".", "pretrained_pruned_model", ",", "Model", ",", "zs", ")", "\n", "prune_model_with_z", "(", "zs", ",", "model", ")", "\n", "print", "(", "\n", "f\"Model Size after pruning and padding: {calculate_parameters(model)}\"", ")", "\n", "\n", "", "l0_module", "=", "None", "\n", "if", "additional_args", ".", "str_pruning_method", "==", "\"l0_reg\"", ":", "\n", "        ", "l0_module", "=", "L0Module", "(", "config", "=", "config", ",", "\n", "droprate_init", "=", "additional_args", ".", "droprate_init", ",", "\n", "temperature", "=", "additional_args", ".", "temperature", ",", "\n", "target_sparsity", "=", "additional_args", ".", "target_sparsity", ",", "\n", "pruning_type", "=", "additional_args", ".", "pruning_type", ")", "\n", "\n", "# Tokenizer check: this script requires a fast tokenizcser.", "\n", "", "if", "not", "isinstance", "(", "tokenizer", ",", "PreTrainedTokenizerFast", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This example script only works for models that have a fast tokenizer. Checkout the big table of models \"", "\n", "\"at https://huggingface.co/transformers/index.html#bigtable to find the model types that meet this \"", "\n", "\"requirement\"", "\n", ")", "\n", "\n", "# Preprocessing the datasets.", "\n", "# Preprocessing is slighlty different for training and evaluation.py.", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "question_column_name", "=", "\"question\"", "if", "\"question\"", "in", "column_names", "else", "column_names", "[", "0", "]", "\n", "context_column_name", "=", "\"context\"", "if", "\"context\"", "in", "column_names", "else", "column_names", "[", "1", "]", "\n", "answer_column_name", "=", "\"answers\"", "if", "\"answers\"", "in", "column_names", "else", "column_names", "[", "2", "]", "\n", "\n", "# Padding side determines if we do (question|context) or (context|question).", "\n", "pad_on_right", "=", "tokenizer", ".", "padding_side", "==", "\"right\"", "\n", "\n", "# Training preprocessing", "\n", "def", "prepare_train_features", "(", "examples", ")", ":", "\n", "# Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results", "\n", "# in one example possible giving several features when a context is long, each of those features having a", "\n", "# context that overlaps a bit the context of the previous feature.", "\n", "        ", "tokenized_examples", "=", "tokenizer", "(", "\n", "examples", "[", "question_column_name", "if", "pad_on_right", "else", "context_column_name", "]", ",", "\n", "examples", "[", "context_column_name", "if", "pad_on_right", "else", "question_column_name", "]", ",", "\n", "truncation", "=", "\"only_second\"", "if", "pad_on_right", "else", "\"only_first\"", ",", "\n", "max_length", "=", "data_args", ".", "max_seq_length", ",", "\n", "stride", "=", "data_args", ".", "doc_stride", ",", "\n", "return_overflowing_tokens", "=", "True", ",", "\n", "return_offsets_mapping", "=", "True", ",", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", ",", "\n", ")", "\n", "\n", "# Since one example might give us several features if it has a long context, we need a map from a feature to", "\n", "# its corresponding example. This key gives us just that.", "\n", "sample_mapping", "=", "tokenized_examples", ".", "pop", "(", "\"overflow_to_sample_mapping\"", ")", "\n", "# The offset mappings will give us a map from token to character position in the original context. This will", "\n", "# help us compute the start_positions and end_positions.", "\n", "offset_mapping", "=", "tokenized_examples", ".", "pop", "(", "\"offset_mapping\"", ")", "\n", "\n", "# Let's label those examples!", "\n", "tokenized_examples", "[", "\"start_positions\"", "]", "=", "[", "]", "\n", "tokenized_examples", "[", "\"end_positions\"", "]", "=", "[", "]", "\n", "\n", "for", "i", ",", "offsets", "in", "enumerate", "(", "offset_mapping", ")", ":", "\n", "# We will label impossible answers with the index of the CLS token.", "\n", "            ", "input_ids", "=", "tokenized_examples", "[", "\"input_ids\"", "]", "[", "i", "]", "\n", "cls_index", "=", "input_ids", ".", "index", "(", "tokenizer", ".", "cls_token_id", ")", "\n", "\n", "# Grab the sequence corresponding to that example (to know what is the context and what is the question).", "\n", "sequence_ids", "=", "tokenized_examples", ".", "sequence_ids", "(", "i", ")", "\n", "\n", "# One example can give several spans, this is the index of the example containing this span of text.", "\n", "sample_index", "=", "sample_mapping", "[", "i", "]", "\n", "answers", "=", "examples", "[", "answer_column_name", "]", "[", "sample_index", "]", "\n", "# If no answers are given, set the cls_index as answer.", "\n", "if", "len", "(", "answers", "[", "\"answer_start\"", "]", ")", "==", "0", ":", "\n", "                ", "tokenized_examples", "[", "\"start_positions\"", "]", ".", "append", "(", "cls_index", ")", "\n", "tokenized_examples", "[", "\"end_positions\"", "]", ".", "append", "(", "cls_index", ")", "\n", "", "else", ":", "\n", "# Start/end character index of the answer in the text.", "\n", "                ", "start_char", "=", "answers", "[", "\"answer_start\"", "]", "[", "0", "]", "\n", "end_char", "=", "start_char", "+", "len", "(", "answers", "[", "\"text\"", "]", "[", "0", "]", ")", "\n", "\n", "# Start token index of the current span in the text.", "\n", "token_start_index", "=", "0", "\n", "while", "sequence_ids", "[", "token_start_index", "]", "!=", "(", "1", "if", "pad_on_right", "else", "0", ")", ":", "\n", "                    ", "token_start_index", "+=", "1", "\n", "\n", "# End token index of the current span in the text.", "\n", "", "token_end_index", "=", "len", "(", "input_ids", ")", "-", "1", "\n", "while", "sequence_ids", "[", "token_end_index", "]", "!=", "(", "1", "if", "pad_on_right", "else", "0", ")", ":", "\n", "                    ", "token_end_index", "-=", "1", "\n", "\n", "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).", "\n", "", "if", "not", "(", "offsets", "[", "token_start_index", "]", "[", "0", "]", "<=", "start_char", "and", "offsets", "[", "token_end_index", "]", "[", "1", "]", ">=", "end_char", ")", ":", "\n", "                    ", "tokenized_examples", "[", "\"start_positions\"", "]", ".", "append", "(", "cls_index", ")", "\n", "tokenized_examples", "[", "\"end_positions\"", "]", ".", "append", "(", "cls_index", ")", "\n", "", "else", ":", "\n", "# Otherwise move the token_start_index and token_end_index to the two ends of the answer.", "\n", "# Note: we could go after the last offset if the answer is the last word (edge case).", "\n", "                    ", "while", "token_start_index", "<", "len", "(", "offsets", ")", "and", "offsets", "[", "token_start_index", "]", "[", "0", "]", "<=", "start_char", ":", "\n", "                        ", "token_start_index", "+=", "1", "\n", "", "tokenized_examples", "[", "\"start_positions\"", "]", ".", "append", "(", "\n", "token_start_index", "-", "1", ")", "\n", "while", "offsets", "[", "token_end_index", "]", "[", "1", "]", ">=", "end_char", ":", "\n", "                        ", "token_end_index", "-=", "1", "\n", "", "tokenized_examples", "[", "\"end_positions\"", "]", ".", "append", "(", "\n", "token_end_index", "+", "1", ")", "\n", "\n", "", "", "", "return", "tokenized_examples", "\n", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "datasets", "[", "\"train\"", "]", ".", "map", "(", "\n", "prepare_train_features", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Validation preprocessing", "\n", "", "def", "prepare_validation_features", "(", "examples", ")", ":", "\n", "# Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results", "\n", "# in one example possible giving several features when a context is long, each of those features having a", "\n", "# context that overlaps a bit the context of the previous feature.", "\n", "        ", "tokenized_examples", "=", "tokenizer", "(", "\n", "examples", "[", "question_column_name", "if", "pad_on_right", "else", "context_column_name", "]", ",", "\n", "examples", "[", "context_column_name", "if", "pad_on_right", "else", "question_column_name", "]", ",", "\n", "truncation", "=", "\"only_second\"", "if", "pad_on_right", "else", "\"only_first\"", ",", "\n", "max_length", "=", "data_args", ".", "max_seq_length", ",", "\n", "stride", "=", "data_args", ".", "doc_stride", ",", "\n", "return_overflowing_tokens", "=", "True", ",", "\n", "return_offsets_mapping", "=", "True", ",", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", ",", "\n", ")", "\n", "\n", "# Since one example might give us several features if it has a long context, we need a map from a feature to", "\n", "# its corresponding example. This key gives us just that.", "\n", "sample_mapping", "=", "tokenized_examples", ".", "pop", "(", "\"overflow_to_sample_mapping\"", ")", "\n", "\n", "# For evaluation.py, we will need to convert our predictions to substrings of the context, so we keep the", "\n", "# corresponding example_id and we will store the offset mappings.", "\n", "tokenized_examples", "[", "\"example_id\"", "]", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "tokenized_examples", "[", "\"input_ids\"", "]", ")", ")", ":", "\n", "# Grab the sequence corresponding to that example (to know what is the context and what is the question).", "\n", "            ", "sequence_ids", "=", "tokenized_examples", ".", "sequence_ids", "(", "i", ")", "\n", "context_index", "=", "1", "if", "pad_on_right", "else", "0", "\n", "\n", "# One example can give several spans, this is the index of the example containing this span of text.", "\n", "sample_index", "=", "sample_mapping", "[", "i", "]", "\n", "tokenized_examples", "[", "\"example_id\"", "]", ".", "append", "(", "\n", "examples", "[", "\"id\"", "]", "[", "sample_index", "]", ")", "\n", "\n", "# Set to None the offset_mapping that are not part of the context so it's easy to determine if a token", "\n", "# position is part of the context or not.", "\n", "tokenized_examples", "[", "\"offset_mapping\"", "]", "[", "i", "]", "=", "[", "\n", "(", "o", "if", "sequence_ids", "[", "k", "]", "==", "context_index", "else", "None", ")", "\n", "for", "k", ",", "o", "in", "enumerate", "(", "tokenized_examples", "[", "\"offset_mapping\"", "]", "[", "i", "]", ")", "\n", "]", "\n", "\n", "", "return", "tokenized_examples", "\n", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "# validation_dataset = load_and_cache_examples(training_args, data_args, model_args, tokenizer, evaluate=True, output_examples=False)", "\n", "        ", "validation_dataset", "=", "datasets", "[", "\"validation\"", "]", ".", "map", "(", "\n", "prepare_validation_features", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Data collator", "\n", "# We have already padded to max length if the corresponding flag is True, otherwise we need to pad in the data", "\n", "# collator.", "\n", "", "data_collator", "=", "(", "default_data_collator", ")", "\n", "\n", "# Post-processing:", "\n", "def", "post_processing_function", "(", "examples", ",", "features", ",", "predictions", ")", ":", "\n", "# Post-processing: we match the start logits and end logits to answers in the original context.", "\n", "        ", "predictions", "=", "postprocess_qa_predictions", "(", "\n", "examples", "=", "examples", ",", "\n", "features", "=", "features", ",", "\n", "predictions", "=", "predictions", ",", "\n", "version_2_with_negative", "=", "data_args", ".", "version_2_with_negative", ",", "\n", "n_best_size", "=", "data_args", ".", "n_best_size", ",", "\n", "max_answer_length", "=", "data_args", ".", "max_answer_length", ",", "\n", "null_score_diff_threshold", "=", "data_args", ".", "null_score_diff_threshold", ",", "\n", "output_dir", "=", "training_args", ".", "output_dir", ",", "\n", "is_world_process_zero", "=", "trainer", ".", "is_world_process_zero", "(", ")", ",", "\n", ")", "\n", "# Format the result to the format the metric expects.", "\n", "if", "data_args", ".", "version_2_with_negative", ":", "\n", "            ", "formatted_predictions", "=", "[", "\n", "{", "\"id\"", ":", "k", ",", "\"prediction_text\"", ":", "v", ",", "\"no_answer_probability\"", ":", "0.0", "}", "for", "k", ",", "v", "in", "predictions", ".", "items", "(", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "formatted_predictions", "=", "[", "\n", "{", "\"id\"", ":", "k", ",", "\"prediction_text\"", ":", "v", "}", "for", "k", ",", "v", "in", "predictions", ".", "items", "(", ")", "]", "\n", "", "references", "=", "[", "{", "\"id\"", ":", "ex", "[", "\"id\"", "]", ",", "\"answers\"", ":", "ex", "[", "answer_column_name", "]", "}", "\n", "for", "ex", "in", "datasets", "[", "\"validation\"", "]", "]", "\n", "return", "EvalPrediction", "(", "predictions", "=", "formatted_predictions", ",", "label_ids", "=", "references", ")", "\n", "\n", "", "metric", "=", "load_metric", "(", "\n", "\"squad_v2\"", "if", "data_args", ".", "version_2_with_negative", "else", "\"squad\"", ")", "\n", "\n", "def", "compute_metrics", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "        ", "return", "metric", ".", "compute", "(", "predictions", "=", "p", ".", "predictions", ",", "references", "=", "p", ".", "label_ids", ")", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "CoFiQuestionAnsweringTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "additional_args", "=", "additional_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "validation_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "eval_examples", "=", "datasets", "[", "\"validation\"", "]", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "post_process_function", "=", "post_processing_function", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "logger", "=", "logger", ",", "\n", "l0_module", "=", "l0_module", ",", "\n", "teacher_model", "=", "teacher_model", "\n", ")", "\n", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "trainer", ".", "train", "(", ")", "\n", "trainer", ".", "save_model", "(", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.run_glue_prune.main": [[41, 384], ["transformers.HfArgumentParser", "os.makedirs", "logging.basicConfig", "training_args.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "logger.info", "torch.save", "torch.save", "torch.save", "transformers.set_seed", "utils.utils.log_all_parameters", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "Model.from_pretrained", "logger.info", "logger.info", "min", "logger.info", "logger.info", "trainer.trainer.CoFiTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.join", "os.path.join", "os.path.join", "datasets.load_dataset", "model_args.model_name_or_path.startswith", "Model.from_pretrained", "Model.from_pretrained.eval", "utils.cofi_utils.initialize_layer_transformation", "utils.cofi_utils.load_zs", "utils.cofi_utils.load_model", "print", "models.l0_module.L0Module", "logger.warning", "AutoTokenizer.from_pretrained.", "training_args.main_process_first", "datasets.load_dataset.map", "random.sample", "datasets.load_metric", "datasets.load_metric", "trainer.trainer.CoFiTrainer.train", "trainer.trainer.CoFiTrainer.save_model", "AutoTokenizer.from_pretrained.save_pretrained", "len", "data_args.task_name.replace", "datasets.load_dataset", "data_files.keys", "data_args.train_file.endswith", "len", "raw_datasets[].unique", "raw_datasets[].unique.sort", "len", "bool", "k.lower", "list", "list", "logger.warning", "ValueError", "train_dataset.select.select", "ValueError", "eval_dataset.select.select", "ValueError", "predict_dataset.select.select", "range", "logger.info", "isinstance", "numpy.squeeze", "numpy.argmax", "datasets.load_metric.compute", "transformers.DataCollatorWithPadding", "os.path.abspath", "logging.StreamHandler", "logger.info", "datasets.load_dataset", "data_args.train_file.endswith", "copy.deepcopy", "utils.utils.calculate_parameters", "len", "transformers.PretrainedConfig", "utils.cofi_utils.load_model.config.label2id.items", "sorted", "sorted", "int", "AutoConfig.from_pretrained.label2id.items", "range", "range", "range", "len", "len", "numpy.mean().item", "len", "len", "bool", "ValueError", "datasets.DatasetDict", "datasets.load_dataset", "utils.utils.calculate_parameters", "label_name_to_id.keys", "range", "enumerate", "enumerate", "AutoConfig.from_pretrained.label2id.items", "data_args.train_file.split", "data_args.test_file.split", "utils.utils.load_from_tsv", "list", "list", "numpy.mean", "sorted", "sorted", "list", "label_name_to_id.keys", "metric.compute.values"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.log_all_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.initialize_layer_transformation", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_zs", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_model", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.train", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.save_model", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.load_from_tsv"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "\n", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ",", "AdditionalArguments", ")", ")", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", ",", "additional_args", "=", "parser", ".", "parse_json_file", "(", "\n", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", ",", "additional_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "training_args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "# save args", "\n", "torch", ".", "save", "(", "data_args", ",", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"data_args.bin\"", ")", ")", "\n", "torch", ".", "save", "(", "model_args", ",", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"model_args.bin\"", ")", ")", "\n", "torch", ".", "save", "(", "additional_args", ",", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"additional_args.bin\"", ")", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# print all arguments", "\n", "log_all_parameters", "(", "logger", ",", "model_args", ",", "data_args", ",", "\n", "training_args", ",", "additional_args", ")", "\n", "\n", "\n", "t_name", "=", "None", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\n", "\"glue\"", ",", "data_args", ".", "task_name", ".", "replace", "(", "\"-\"", ",", "\"\"", ")", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "t_name", "=", "data_args", ".", "task_name", "\n", "", "elif", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ",", "cache_dir", "=", "model_args", ".", "cache_dir", "\n", ")", "\n", "t_name", "=", "data_args", ".", "dataset_name", "\n", "", "else", ":", "\n", "# Loading a dataset from your local files.", "\n", "# CSV/JSON training and evaluation files are needed.", "\n", "        ", "t_name", "=", "data_args", ".", "t_name", "\n", "data_files", "=", "{", "\"train\"", ":", "data_args", ".", "train_file", ",", "\n", "\"validation\"", ":", "data_args", ".", "validation_file", "}", "\n", "\n", "# Get the test dataset: you can provide your own CSV/JSON test file (see below)", "\n", "# when you use `do_predict` without specifying a GLUE benchmark task.", "\n", "if", "training_args", ".", "do_predict", ":", "\n", "            ", "if", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "                ", "train_extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "test_extension", "=", "data_args", ".", "test_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "(", "\n", "test_extension", "==", "train_extension", "\n", ")", ",", "\"`test_file` should have the same extension (csv or json) as `train_file`.\"", "\n", "data_files", "[", "\"test\"", "]", "=", "data_args", ".", "test_file", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Need either a GLUE task or a test file for `do_predict`.\"", ")", "\n", "\n", "", "", "for", "key", "in", "data_files", ".", "keys", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"load a local file for {key}: {data_files[key]}\"", ")", "\n", "\n", "", "if", "data_args", ".", "train_file", ".", "endswith", "(", "\".csv\"", ")", ":", "\n", "# Loading a dataset from local csv files", "\n", "            ", "raw_datasets", "=", "load_dataset", "(", "\n", "\"csv\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "", "elif", "data_args", ".", "train_file", ".", "endswith", "(", "\".tsv\"", ")", ":", "\n", "            ", "dataset_dict", "=", "{", "}", "\n", "for", "key", "in", "data_files", ":", "\n", "                ", "dataset_dict", "[", "key", "]", "=", "load_from_tsv", "(", "data_files", "[", "key", "]", ")", "\n", "", "raw_datasets", "=", "DatasetDict", "(", "dataset_dict", ")", "\n", "", "else", ":", "\n", "# Loading a dataset from local json files", "\n", "            ", "raw_datasets", "=", "load_dataset", "(", "\n", "\"json\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "# See more about loading any type of standard or custom dataset at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Labels", "\n", "", "", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "is_regression", "=", "data_args", ".", "task_name", "==", "\"stsb\"", "\n", "if", "not", "is_regression", ":", "\n", "            ", "label_list", "=", "raw_datasets", "[", "\"train\"", "]", ".", "features", "[", "\"label\"", "]", ".", "names", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "", "else", ":", "\n", "            ", "num_labels", "=", "1", "\n", "", "", "else", ":", "\n", "# Trying to have good defaults here, don't hesitate to tweak to your needs.", "\n", "        ", "is_regression", "=", "raw_datasets", "[", "\"train\"", "]", ".", "features", "[", "\"label\"", "]", ".", "dtype", "in", "[", "\n", "\"float32\"", ",", "\"float64\"", "]", "\n", "if", "is_regression", ":", "\n", "            ", "num_labels", "=", "1", "\n", "", "else", ":", "\n", "# A useful fast method:", "\n", "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique", "\n", "            ", "label_list", "=", "raw_datasets", "[", "\"train\"", "]", ".", "unique", "(", "\"label\"", ")", "\n", "label_list", ".", "sort", "(", ")", "# Let's sort it for determinism", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "t_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# set up configuration for distillation", "\n", "if", "additional_args", ".", "do_distill", ":", "\n", "        ", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "\n", "", "Model", "=", "CoFiBertForSequenceClassification", "if", "model_args", ".", "model_name_or_path", ".", "startswith", "(", "\n", "\"bert\"", ")", "else", "CoFiRobertaForSequenceClassification", "\n", "\n", "teacher_model", "=", "None", "\n", "if", "additional_args", ".", "do_distill", ":", "\n", "        ", "teacher_model", "=", "Model", ".", "from_pretrained", "(", "\n", "additional_args", ".", "distillation_path", ",", "\n", "config", "=", "deepcopy", "(", "config", ")", "\n", ")", "\n", "teacher_model", ".", "eval", "(", ")", "\n", "\n", "", "config", ".", "do_layer_distill", "=", "additional_args", ".", "do_layer_distill", "\n", "\n", "model", "=", "Model", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# initialize the layer transformation matrix to be an identity matrix", "\n", "if", "additional_args", ".", "do_layer_distill", ":", "\n", "        ", "initialize_layer_transformation", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "model", ")", "\n", "logger", ".", "info", "(", "f\"Model size: {calculate_parameters(model)}\"", ")", "\n", "\n", "zs", "=", "None", "\n", "\n", "if", "additional_args", ".", "pretrained_pruned_model", "is", "not", "None", ":", "\n", "        ", "zs", "=", "load_zs", "(", "additional_args", ".", "pretrained_pruned_model", ")", "\n", "model", "=", "load_model", "(", "additional_args", ".", "pretrained_pruned_model", ",", "Model", ",", "zs", ")", "\n", "print", "(", "\n", "f\"Model Size after pruning: {calculate_parameters(model)}\"", ")", "\n", "\n", "", "l0_module", "=", "None", "\n", "if", "additional_args", ".", "pruning_type", "is", "not", "None", ":", "\n", "        ", "l0_module", "=", "L0Module", "(", "config", "=", "config", ",", "\n", "droprate_init", "=", "additional_args", ".", "droprate_init", ",", "\n", "temperature", "=", "additional_args", ".", "temperature", ",", "\n", "target_sparsity", "=", "additional_args", ".", "target_sparsity", ",", "\n", "pruning_type", "=", "additional_args", ".", "pruning_type", ")", "\n", "\n", "", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "sentence1_key", ",", "sentence2_key", "=", "task_to_keys", "[", "data_args", ".", "task_name", "]", "\n", "", "else", ":", "\n", "# Again, we try to have some nice defaults but don't hesitate to tweak to your use case.", "\n", "        ", "non_label_column_names", "=", "[", "name", "for", "name", "in", "raw_datasets", "[", "\"train\"", "]", ".", "column_names", "if", "name", "!=", "\"label\"", "]", "\n", "if", "\"sentence1\"", "in", "non_label_column_names", "and", "\"sentence2\"", "in", "non_label_column_names", ":", "\n", "            ", "sentence1_key", ",", "sentence2_key", "=", "\"sentence1\"", ",", "\"sentence2\"", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "non_label_column_names", ")", ">=", "2", ":", "\n", "                ", "sentence1_key", ",", "sentence2_key", "=", "non_label_column_names", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "                ", "sentence1_key", ",", "sentence2_key", "=", "non_label_column_names", "[", "0", "]", ",", "None", "\n", "\n", "# Padding strategy", "\n", "", "", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "padding", "=", "\"max_length\"", "\n", "", "else", ":", "\n", "# We will pad later, dynamically at batch creation, to the max sequence length in each batch", "\n", "        ", "padding", "=", "False", "\n", "\n", "# Some models have set the order of the labels to use, so let's make sure we do use it.", "\n", "", "label_to_id", "=", "None", "\n", "if", "(", "\n", "model", ".", "config", ".", "label2id", "!=", "PretrainedConfig", "(", "num_labels", "=", "num_labels", ")", ".", "label2id", "\n", "and", "data_args", ".", "task_name", "is", "not", "None", "\n", "and", "not", "is_regression", "\n", ")", ":", "\n", "# Some have all caps in their config, some don't.", "\n", "        ", "label_name_to_id", "=", "{", "k", ".", "lower", "(", ")", ":", "v", "for", "k", ",", "v", "in", "model", ".", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "if", "list", "(", "sorted", "(", "label_name_to_id", ".", "keys", "(", ")", ")", ")", "==", "list", "(", "sorted", "(", "label_list", ")", ")", ":", "\n", "            ", "label_to_id", "=", "{", "i", ":", "int", "(", "label_name_to_id", "[", "label_list", "[", "i", "]", "]", ")", "for", "i", "in", "range", "(", "num_labels", ")", "}", "\n", "", "else", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Your model seems to have been trained with labels, but they don't match the dataset: \"", ",", "\n", "f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"", "\n", "\"\\nIgnoring the model labels as a result.\"", ",", "\n", ")", "\n", "", "", "elif", "data_args", ".", "task_name", "is", "None", "and", "not", "is_regression", ":", "\n", "        ", "label_to_id", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "", "if", "label_to_id", "is", "not", "None", ":", "\n", "        ", "model", ".", "config", ".", "label2id", "=", "label_to_id", "\n", "model", ".", "config", ".", "id2label", "=", "{", "id", ":", "label", "for", "label", ",", "id", "in", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "", "elif", "data_args", ".", "task_name", "is", "not", "None", "and", "not", "is_regression", ":", "\n", "        ", "model", ".", "config", ".", "label2id", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "label_list", ")", "}", "\n", "model", ".", "config", ".", "id2label", "=", "{", "id", ":", "label", "for", "label", ",", "id", "in", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "\n", "", "if", "data_args", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "max_seq_length", "=", "min", "(", "data_args", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "        ", "args", "=", "(", "\n", "(", "examples", "[", "sentence1_key", "]", ",", ")", "if", "sentence2_key", "is", "None", "else", "(", "examples", "[", "sentence1_key", "]", ",", "examples", "[", "sentence2_key", "]", ")", "\n", ")", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "\n", "# Map labels to IDs (not necessary for GLUE tasks)", "\n", "if", "label_to_id", "is", "not", "None", "and", "\"label\"", "in", "examples", ":", "\n", "            ", "result", "[", "\"label\"", "]", "=", "[", "(", "label_to_id", "[", "l", "]", "if", "l", "!=", "-", "1", "else", "-", "1", ")", "for", "l", "in", "examples", "[", "\"label\"", "]", "]", "\n", "", "return", "result", "\n", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"dataset map pre-processing\"", ")", ":", "\n", "        ", "raw_datasets", "=", "raw_datasets", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on dataset\"", ",", "\n", ")", "\n", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "\"train\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_train requires a train dataset\"", ")", "\n", "", "train_dataset", "=", "raw_datasets", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "if", "\"validation\"", "not", "in", "raw_datasets", "and", "\"validation_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_eval requires a validation dataset\"", ")", "\n", "", "eval_dataset", "=", "raw_datasets", "[", "\"validation_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"validation\"", "]", "\n", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_eval_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", "or", "data_args", ".", "task_name", "is", "not", "None", "or", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "        ", "if", "\"test\"", "not", "in", "raw_datasets", "and", "\"test_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_predict requires a test dataset\"", ")", "\n", "", "predict_dataset", "=", "raw_datasets", "[", "\"test_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"test\"", "]", "\n", "if", "data_args", ".", "max_predict_samples", "is", "not", "None", ":", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_predict_samples", ")", ")", "\n", "\n", "# Log a few random samples from the training set:", "\n", "", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "for", "index", "in", "random", ".", "sample", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ",", "3", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Sample {index} of the training set: {train_dataset[index]}.\"", ")", "\n", "\n", "# Get the metric function", "\n", "", "", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "metric", "=", "load_metric", "(", "\"glue\"", ",", "data_args", ".", "task_name", ")", "\n", "", "else", ":", "\n", "        ", "metric", "=", "load_metric", "(", "\"accuracy\"", ")", "\n", "\n", "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a", "\n", "# predictions and label_ids field) and has to return a dictionary string to float.", "\n", "", "def", "compute_metrics", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "            ", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "preds", ",", "references", "=", "p", ".", "label_ids", ")", "\n", "if", "len", "(", "result", ")", ">", "1", ":", "\n", "                ", "result", "[", "\"combined_score\"", "]", "=", "np", ".", "mean", "(", "list", "(", "result", ".", "values", "(", ")", ")", ")", ".", "item", "(", ")", "\n", "", "return", "result", "\n", "", "elif", "is_regression", ":", "\n", "            ", "return", "{", "\"mse\"", ":", "(", "(", "preds", "-", "p", ".", "label_ids", ")", "**", "2", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "\"accuracy\"", ":", "(", "preds", "==", "p", ".", "label_ids", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "# Data collator will default to DataCollatorWithPadding when the tokenizer is passed to Trainer, so we change it if", "\n", "# we already did the padding.", "\n", "", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "elif", "training_args", ".", "fp16", ":", "\n", "        ", "data_collator", "=", "DataCollatorWithPadding", "(", "tokenizer", ",", "pad_to_multiple_of", "=", "8", ")", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "None", "\n", "\n", "", "logger", ".", "info", "(", "\n", "f\"************* {len(train_dataset)} Training Examples Loaded *************\"", ")", "\n", "logger", ".", "info", "(", "\n", "f\"************* {len(eval_dataset)} Evaluation Examples Loaded *************\"", ")", "\n", "\n", "\n", "trainer", "=", "CoFiTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "additional_args", "=", "additional_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "l0_module", "=", "l0_module", ",", "\n", "teacher_model", "=", "teacher_model", "\n", ")", "\n", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "trainer", ".", "train", "(", ")", "\n", "trainer", ".", "save_model", "(", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation._remove_unused_columns": [[44, 57], ["inspect.signature", "list", "list", "print", "dataset.set_format", "inspect.signature.parameters.keys", "set", "set"], "function", ["None"], ["def", "_remove_unused_columns", "(", "dataset", ":", "\"datasets.Dataset\"", ",", "description", ")", ":", "\n", "# Inspect model forward signature to keep only the arguments it accepts.", "\n", "    ", "signature", "=", "inspect", ".", "signature", "(", "model", ".", "forward", ")", "\n", "signature_columns", "=", "list", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "\n", "# Labels may be named label or label_ids, the default data collator handles that.", "\n", "signature_columns", "+=", "[", "\"label\"", ",", "\"label_ids\"", "]", "\n", "columns", "=", "[", "k", "for", "k", "in", "signature_columns", "if", "k", "in", "dataset", ".", "column_names", "]", "\n", "ignored_columns", "=", "list", "(", "set", "(", "dataset", ".", "column_names", ")", "-", "set", "(", "signature_columns", ")", ")", "\n", "dset_description", "=", "\"\"", "if", "description", "is", "None", "else", "f\"in the {description} set \"", "\n", "print", "(", "\n", "f\"The following columns {dset_description} don't have a corresponding argument in `{model.__class__.__name__}.forward` and have been ignored: {', '.join(ignored_columns)}.\"", "\n", ")", "\n", "dataset", ".", "set_format", "(", "type", "=", "dataset", ".", "format", "[", "\"type\"", "]", ",", "columns", "=", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.get_dataloader": [[59, 65], ["torch.utils.data.dataloader.DataLoader", "torch.utils.data.sampler.SequentialSampler"], "function", ["None"], ["", "def", "get_dataloader", "(", "dataset", ",", "batch_size", ")", ":", "\n", "    ", "dataloader", "=", "DataLoader", "(", "dataset", ",", "\n", "sampler", "=", "SequentialSampler", "(", "dataset", ")", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collate_fn", "=", "default_data_collator", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.post_processing_function": [[66, 79], ["utils.qa_utils.postprocess_qa_predictions", "transformers.EvalPrediction", "utils.qa_utils.postprocess_qa_predictions.items"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.qa_utils.postprocess_qa_predictions"], ["", "def", "post_processing_function", "(", "examples", ",", "features", ",", "predictions", ")", ":", "\n", "# Post-processing: we match the start logits and end logits to answers in the original context.", "\n", "    ", "predictions", "=", "postprocess_qa_predictions", "(", "\n", "examples", "=", "examples", ",", "\n", "features", "=", "features", ",", "\n", "predictions", "=", "predictions", ",", "\n", ")", "\n", "# Format the result to the format the metric expects.", "\n", "formatted_predictions", "=", "[", "{", "\"id\"", ":", "k", ",", "\"prediction_text\"", ":", "v", "}", "\n", "for", "k", ",", "v", "in", "predictions", ".", "items", "(", ")", "]", "\n", "references", "=", "[", "{", "\"id\"", ":", "ex", "[", "\"id\"", "]", ",", "\"answers\"", ":", "ex", "[", "answer_column_name", "]", "}", "\n", "for", "ex", "in", "datasets", "[", "\"validation\"", "]", "]", "\n", "return", "EvalPrediction", "(", "predictions", "=", "formatted_predictions", ",", "label_ids", "=", "references", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.evaluate": [[81, 140], ["range", "round", "evaluation._remove_unused_columns", "print", "enumerate", "dataset.set_format", "evaluation.post_processing_function", "evaluation.get_glue_metric.compute_metrics", "evaluation.get_glue_metric.compute_metrics", "transformers.trainer_pt_utils.nested_numpify", "transformers.trainer_pt_utils.nested_numpify", "transformers.EvalPrediction", "inputs[].cuda", "torch.no_grad", "time.time", "torch.cuda.synchronize", "time.time", "list", "len", "model", "len", "dataset.features.keys", "model", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_pt_utils.nested_concat"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation._remove_unused_columns", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.post_processing_function"], ["", "def", "evaluate", "(", "model", ")", ":", "\n", "    ", "metrics", "=", "{", "}", "\n", "total_infer_times", "=", "0", "\n", "\n", "t", "=", "2", "if", "task_name", "in", "[", "\"squad\"", ",", "\"qqp\"", "]", "else", "5", "\n", "if", "task_name", "in", "[", "\"rte\"", ",", "\"stsb\"", ",", "\"cola\"", ",", "\"mrpc\"", "]", ":", "\n", "        ", "t", "=", "20", "\n", "", "assert", "t", ">", "1", "\n", "\n", "total_examples", "=", "0", "\n", "for", "i", "in", "range", "(", "t", ")", ":", "\n", "        ", "_remove_unused_columns", "(", "dataset", ",", "\"evaluation\"", ")", "\n", "\n", "preds", "=", "None", "\n", "label_ids", "=", "None", "\n", "total_infer_time", "=", "0", "\n", "print", "(", "f\"Round {i}: There are {len(dataloader)} batches in the dataset.\"", ")", "\n", "for", "num_batch", ",", "inputs", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "labels", "=", "inputs", "[", "\"labels\"", "]", "if", "\"labels\"", "in", "inputs", "else", "None", "\n", "for", "key", "in", "inputs", ":", "\n", "                ", "inputs", "[", "key", "]", "=", "inputs", "[", "key", "]", ".", "cuda", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "a", "=", "time", ".", "time", "(", ")", "\n", "if", "task_name", "==", "\"squad\"", ":", "\n", "                    ", "output", "=", "model", "(", "**", "inputs", ")", "\n", "logits", "=", "output", "[", "\"start_logits\"", "]", ",", "output", "[", "\"end_logits\"", "]", "\n", "", "else", ":", "\n", "                    ", "logits", "=", "model", "(", "**", "inputs", ")", "[", "\"logits\"", "]", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "b", "=", "time", ".", "time", "(", ")", "\n", "total_infer_time", "+=", "(", "b", "-", "a", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "total_examples", "+=", "len", "(", "logits", "[", "0", "]", ")", "\n", "preds", "=", "logits", "if", "preds", "is", "None", "else", "nested_concat", "(", "\n", "preds", ",", "logits", ")", "\n", "label_ids", "=", "labels", "if", "label_ids", "is", "None", "else", "nested_concat", "(", "\n", "label_ids", ",", "labels", ")", "\n", "", "", "", "if", "label_ids", "is", "not", "None", ":", "\n", "            ", "final_label_ids", "=", "nested_numpify", "(", "label_ids", ")", "\n", "", "if", "preds", "is", "not", "None", ":", "\n", "            ", "final_preds", "=", "nested_numpify", "(", "preds", ")", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "            ", "metrics", "[", "\"num_examples\"", "]", "=", "total_examples", "\n", "\n", "", "if", "i", ">", "0", ":", "\n", "            ", "total_infer_times", "+=", "total_infer_time", "\n", "", "", "if", "task_name", "==", "'squad'", ":", "\n", "        ", "dataset", ".", "set_format", "(", "\n", "type", "=", "dataset", ".", "format", "[", "\"type\"", "]", ",", "columns", "=", "list", "(", "dataset", ".", "features", ".", "keys", "(", ")", ")", ")", "\n", "eval_preds", "=", "post_processing_function", "(", "\n", "eval_examples", ",", "dataset", ",", "final_preds", ")", "\n", "metrics", "=", "compute_metrics", "(", "eval_preds", ")", "\n", "", "else", ":", "\n", "        ", "metrics", "=", "compute_metrics", "(", "EvalPrediction", "(", "\n", "predictions", "=", "final_preds", ",", "label_ids", "=", "final_label_ids", ")", ")", "\n", "", "total_infer_time", "=", "round", "(", "total_infer_times", "/", "(", "t", "-", "1", ")", ",", "4", ")", "\n", "metrics", "[", "\"seconds/example\"", "]", "=", "total_infer_times", "/", "(", "t", "-", "1", ")", "/", "total_examples", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.prepare_validation_features": [[142, 184], ["tokenizer", "tokenizer.pop", "range", "len", "tokenizer.sequence_ids", "tokenized_examples[].append", "enumerate"], "function", ["None"], ["", "def", "prepare_validation_features", "(", "examples", ")", ":", "\n", "# Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results", "\n", "# in one example possible giving several features when a context is long, each of those features having a", "\n", "# context that overlaps a bit the context of the previous feature.", "\n", "    ", "max_length", "=", "384", "\n", "doc_stride", "=", "128", "\n", "tokenized_examples", "=", "tokenizer", "(", "\n", "examples", "[", "question_column_name", "if", "pad_on_right", "else", "context_column_name", "]", ",", "\n", "examples", "[", "context_column_name", "if", "pad_on_right", "else", "question_column_name", "]", ",", "\n", "truncation", "=", "\"only_second\"", "if", "pad_on_right", "else", "\"only_first\"", ",", "\n", "max_length", "=", "max_length", ",", "\n", "stride", "=", "doc_stride", ",", "\n", "return_overflowing_tokens", "=", "True", ",", "\n", "return_offsets_mapping", "=", "True", ",", "\n", "padding", "=", "\"max_length\"", "\n", ")", "\n", "\n", "# Since one example might give us several features if it has a long context, we need a map from a feature to", "\n", "# its corresponding example. This key gives us just that.", "\n", "sample_mapping", "=", "tokenized_examples", ".", "pop", "(", "\"overflow_to_sample_mapping\"", ")", "\n", "\n", "# For evaluation.py, we will need to convert our predictions to substrings of the context, so we keep the", "\n", "# corresponding example_id and we will store the offset mappings.", "\n", "tokenized_examples", "[", "\"example_id\"", "]", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "tokenized_examples", "[", "\"input_ids\"", "]", ")", ")", ":", "\n", "# Grab the sequence corresponding to that example (to know what is the context and what is the question).", "\n", "        ", "sequence_ids", "=", "tokenized_examples", ".", "sequence_ids", "(", "i", ")", "\n", "context_index", "=", "1", "if", "pad_on_right", "else", "0", "\n", "\n", "# One example can give several spans, this is the index of the example containing this span of text.", "\n", "sample_index", "=", "sample_mapping", "[", "i", "]", "\n", "tokenized_examples", "[", "\"example_id\"", "]", ".", "append", "(", "examples", "[", "\"id\"", "]", "[", "sample_index", "]", ")", "\n", "\n", "# Set to None the offset_mapping that are not part of the context so it's easy to determine if a token", "\n", "# position is part of the context or not.", "\n", "tokenized_examples", "[", "\"offset_mapping\"", "]", "[", "i", "]", "=", "[", "\n", "(", "o", "if", "sequence_ids", "[", "k", "]", "==", "context_index", "else", "None", ")", "\n", "for", "k", ",", "o", "in", "enumerate", "(", "tokenized_examples", "[", "\"offset_mapping\"", "]", "[", "i", "]", ")", "\n", "]", "\n", "\n", "", "return", "tokenized_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.glue_preprocess_function": [[186, 204], ["tokenizer", "model_name_or_path.startswith"], "function", ["None"], ["", "def", "glue_preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "    ", "sentence1_key", ",", "sentence2_key", "=", "task_to_keys", "[", "task_name", "]", "\n", "max_seq_length", "=", "128", "\n", "padding", "=", "\"max_length\"", "\n", "args", "=", "(", "\n", "(", "examples", "[", "sentence1_key", "]", ",", ")", "if", "sentence2_key", "is", "None", "else", "(", "\n", "examples", "[", "sentence1_key", "]", ",", "examples", "[", "sentence2_key", "]", ")", "\n", ")", "\n", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "\n", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "if", "task_name", "==", "\"mnli\"", "and", "model_name_or_path", ".", "startswith", "(", "\"princeton-nlp/\"", ")", ":", "\n", "# legacy issue of using GLUEDataset", "\n", "        ", "label_to_id", "=", "{", "1", ":", "2", ",", "0", ":", "1", ",", "2", ":", "0", "}", "\n", "labels", "=", "[", "label_to_id", "[", "i", "]", "for", "i", "in", "examples", "[", "\"label\"", "]", "]", "\n", "result", "[", "\"label\"", "]", "=", "labels", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.warmup": [[206, 215], ["time.time", "torch.randn().cuda", "torch.nn.Linear().cuda", "range", "time.time", "print", "torch.nn.Linear().cuda.", "round", "torch.randn", "torch.nn.Linear"], "function", ["None"], ["", "def", "warmup", "(", ")", ":", "\n", "    ", "time1", "=", "time", ".", "time", "(", ")", "\n", "input", "=", "torch", ".", "randn", "(", "128", ",", "1024", ")", ".", "cuda", "(", ")", "\n", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "1024", ",", "1024", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "10000", ")", ":", "\n", "        ", "input", "=", "linear", "(", "input", ")", "\n", "\n", "", "time2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "round", "(", "time2", "-", "time1", ",", "2", ")", ",", "\"seconds for warmup\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.evaluation.get_glue_metric": [[216, 230], ["datasets.load_metric", "datasets.load_metric.compute", "isinstance", "numpy.squeeze", "numpy.argmax", "len", "numpy.mean().item", "numpy.mean", "list", "metric.compute.values"], "function", ["None"], ["", "def", "get_glue_metric", "(", ")", ":", "\n", "    ", "metric", "=", "load_metric", "(", "\"glue\"", ",", "task_name", ")", "\n", "is_regression", "=", "task_name", "==", "\"stsb\"", "\n", "\n", "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a", "\n", "# predictions and label_ids field) and has to return a dictionary string to float.", "\n", "def", "compute_metrics", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "preds", ",", "references", "=", "p", ".", "label_ids", ")", "\n", "if", "len", "(", "result", ")", ">", "1", ":", "\n", "            ", "result", "[", "\"combined_score\"", "]", "=", "np", ".", "mean", "(", "list", "(", "result", ".", "values", "(", ")", ")", ")", ".", "item", "(", ")", "\n", "", "return", "result", "\n", "", "return", "compute_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.args.AdditionalArguments.__post_init__": [[50, 55], ["None"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "pretrained_pruned_model", "==", "\"None\"", ":", "\n", "            ", "self", ".", "pretrained_pruned_model", "=", "None", "\n", "", "if", "self", ".", "pruning_type", "==", "\"None\"", ":", "\n", "            ", "self", ".", "pruning_type", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.None.args.DataTrainingArguments.__post_init__": [[128, 145], ["args.DataTrainingArguments.task_name.lower", "task_to_keys.keys", "ValueError", "ValueError", "args.DataTrainingArguments.t_name.lower", "args.DataTrainingArguments.train_file.split", "args.DataTrainingArguments.validation_file.split", "task_to_keys.keys"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "task_name", "is", "not", "None", ":", "\n", "            ", "self", ".", "task_name", "=", "self", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "self", ".", "task_name", "not", "in", "task_to_keys", ".", "keys", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown task, you should pick one in \"", "+", "\",\"", ".", "join", "(", "task_to_keys", ".", "keys", "(", ")", ")", ")", "\n", "", "", "elif", "self", ".", "dataset_name", "is", "not", "None", ":", "\n", "            ", "pass", "\n", "", "elif", "self", ".", "train_file", "is", "None", "or", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a GLUE task, a training/validation file or a dataset name.\"", ")", "\n", "", "else", ":", "\n", "            ", "train_extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "train_extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"tsv\"", "]", ",", "\"`train_file` should be a csv or a json file.\"", "\n", "validation_extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "self", ".", "t_name", "=", "self", ".", "t_name", ".", "lower", "(", ")", "\n", "assert", "(", "\n", "validation_extension", "==", "train_extension", "\n", ")", ",", "\"`validation_file` should have the same extension (csv or json) as `train_file`.\"", "", "", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.qa_utils.postprocess_qa_predictions": [[32, 239], ["collections.defaultdict", "enumerate", "collections.OrderedDict", "collections.OrderedDict", "logger.setLevel", "logger.info", "enumerate", "len", "len", "len", "features_per_example[].append", "collections.OrderedDict", "tqdm.auto.tqdm", "numpy.array", "numpy.exp", "zip", "os.path.isdir", "os.path.join", "os.path.join", "logger.info", "logger.info", "len", "len", "enumerate", "features[].get", "[].tolist", "[].tolist", "prelim_predictions.append", "sorted", "predictions.append", "pred.pop", "predictions.insert", "np.exp.sum", "float", "os.path.join", "open", "writer.write", "open", "writer.write", "logger.info", "len", "len", "any", "len", "pred.pop", "numpy.max", "open", "writer.write", "prelim_predictions.append", "len", "isinstance", "float", "pred.items", "json.dumps", "json.dumps", "numpy.argsort", "numpy.argsort", "json.dumps", "len", "len", "features[].get.get", "str"], "function", ["None"], ["def", "postprocess_qa_predictions", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "predictions", ":", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ",", "\n", "version_2_with_negative", ":", "bool", "=", "False", ",", "\n", "n_best_size", ":", "int", "=", "20", ",", "\n", "max_answer_length", ":", "int", "=", "30", ",", "\n", "null_score_diff_threshold", ":", "float", "=", "0.0", ",", "\n", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "is_world_process_zero", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Post-processes the predictions of a question-answering model to convert them to answers that are substrings of the\n    original contexts. This is the base postprocessing functions for models that only return start and end logits.\n    Args:\n        examples: The non-preprocessed dataset (see the main script for more information).\n        features: The processed dataset (see the main script for more information).\n        predictions (:obj:`Tuple[np.ndarray, np.ndarray]`):\n            The predictions of the model: two arrays containing the start logits and the end logits respectively. Its\n            first dimension must match the number of elements of :obj:`features`.\n        version_2_with_negative (:obj:`bool`, `optional`, defaults to :obj:`False`):\n            Whether or not the underlying dataset contains examples with no answers.\n        n_best_size (:obj:`int`, `optional`, defaults to 20):\n            The total number of n-best predictions to generate when looking for an answer.\n        max_answer_length (:obj:`int`, `optional`, defaults to 30):\n            The maximum length of an answer that can be generated. This is needed because the start and end predictions\n            are not conditioned on one another.\n        null_score_diff_threshold (:obj:`float`, `optional`, defaults to 0):\n            The threshold used to select the null answer: if the best answer has a score that is less than the score of\n            the null answer minus this threshold, the null answer is selected for this example (note that the score of\n            the null answer for an example giving several features is the minimum of the scores for the null answer on\n            each feature: all features must be aligned on the fact they `want` to predict a null answer).\n            Only useful when :obj:`version_2_with_negative` is :obj:`True`.\n        output_dir (:obj:`str`, `optional`):\n            If provided, the dictionaries of predictions, n_best predictions (with their scores and logits) and, if\n            :obj:`version_2_with_negative=True`, the dictionary of the scores differences between best and null\n            answers, are saved in `output_dir`.\n        prefix (:obj:`str`, `optional`):\n            If provided, the dictionaries mentioned above are saved with `prefix` added to their names.\n        is_world_process_zero (:obj:`bool`, `optional`, defaults to :obj:`True`):\n            Whether this process is the main process or not (used to determine if logging/saves should be done).\n    \"\"\"", "\n", "assert", "len", "(", "predictions", ")", "==", "2", ",", "\"`predictions` should be a tuple with two elements (start_logits, end_logits).\"", "\n", "all_start_logits", ",", "all_end_logits", "=", "predictions", "\n", "\n", "assert", "len", "(", "predictions", "[", "0", "]", ")", "==", "len", "(", "features", ")", ",", "f\"Got {len(predictions[0])} predictions and {len(features)} features.\"", "\n", "\n", "# Build a map example to its corresponding features.", "\n", "example_id_to_index", "=", "{", "k", ":", "i", "for", "i", ",", "k", "in", "enumerate", "(", "examples", "[", "\"id\"", "]", ")", "}", "\n", "features_per_example", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "feature", "in", "enumerate", "(", "features", ")", ":", "\n", "        ", "features_per_example", "[", "example_id_to_index", "[", "feature", "[", "\"example_id\"", "]", "]", "]", ".", "append", "(", "i", ")", "\n", "\n", "# The dictionaries we have to fill.", "\n", "", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "if", "version_2_with_negative", ":", "\n", "        ", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "# Logging.", "\n", "", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_world_process_zero", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "info", "(", "f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\"", ")", "\n", "\n", "# Let's loop over all the examples!", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "tqdm", "(", "examples", ")", ")", ":", "\n", "# Those are the indices of the features associated to the current example.", "\n", "        ", "feature_indices", "=", "features_per_example", "[", "example_index", "]", "\n", "\n", "min_null_prediction", "=", "None", "\n", "prelim_predictions", "=", "[", "]", "\n", "\n", "# Looping through all the features associated to the current example.", "\n", "for", "feature_index", "in", "feature_indices", ":", "\n", "# We grab the predictions of the model for this feature.", "\n", "            ", "start_logits", "=", "all_start_logits", "[", "feature_index", "]", "\n", "end_logits", "=", "all_end_logits", "[", "feature_index", "]", "\n", "# This is what will allow us to map some the positions in our logits to span of texts in the original", "\n", "# context.", "\n", "offset_mapping", "=", "features", "[", "feature_index", "]", "[", "\"offset_mapping\"", "]", "\n", "# Optional `token_is_max_context`, if provided we will remove answers that do not have the maximum context", "\n", "# available in the current feature.", "\n", "token_is_max_context", "=", "features", "[", "feature_index", "]", ".", "get", "(", "\"token_is_max_context\"", ",", "None", ")", "\n", "\n", "# Update minimum null prediction.", "\n", "feature_null_score", "=", "start_logits", "[", "0", "]", "+", "end_logits", "[", "0", "]", "\n", "if", "min_null_prediction", "is", "None", "or", "min_null_prediction", "[", "\"score\"", "]", ">", "feature_null_score", ":", "\n", "                ", "min_null_prediction", "=", "{", "\n", "\"offsets\"", ":", "(", "0", ",", "0", ")", ",", "\n", "\"score\"", ":", "feature_null_score", ",", "\n", "\"start_logit\"", ":", "start_logits", "[", "0", "]", ",", "\n", "\"end_logit\"", ":", "end_logits", "[", "0", "]", ",", "\n", "}", "\n", "\n", "# Go through all possibilities for the `n_best_size` greater start and end logits.", "\n", "", "start_indexes", "=", "np", ".", "argsort", "(", "start_logits", ")", "[", "-", "1", ":", "-", "n_best_size", "-", "1", ":", "-", "1", "]", ".", "tolist", "(", ")", "\n", "end_indexes", "=", "np", ".", "argsort", "(", "end_logits", ")", "[", "-", "1", ":", "-", "n_best_size", "-", "1", ":", "-", "1", "]", ".", "tolist", "(", ")", "\n", "for", "start_index", "in", "start_indexes", ":", "\n", "                ", "for", "end_index", "in", "end_indexes", ":", "\n", "# Don't consider out-of-scope answers, either because the indices are out of bounds or correspond", "\n", "# to part of the input_ids that are not in the context.", "\n", "                    ", "if", "(", "\n", "start_index", ">=", "len", "(", "offset_mapping", ")", "\n", "or", "end_index", ">=", "len", "(", "offset_mapping", ")", "\n", "or", "offset_mapping", "[", "start_index", "]", "is", "None", "\n", "or", "offset_mapping", "[", "end_index", "]", "is", "None", "\n", ")", ":", "\n", "                        ", "continue", "\n", "# Don't consider answers with a length that is either < 0 or > max_answer_length.", "\n", "", "if", "end_index", "<", "start_index", "or", "end_index", "-", "start_index", "+", "1", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "# Don't consider answer that don't have the maximum context available (if such information is", "\n", "# provided).", "\n", "", "if", "token_is_max_context", "is", "not", "None", "and", "not", "token_is_max_context", ".", "get", "(", "str", "(", "start_index", ")", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "{", "\n", "\"offsets\"", ":", "(", "offset_mapping", "[", "start_index", "]", "[", "0", "]", ",", "offset_mapping", "[", "end_index", "]", "[", "1", "]", ")", ",", "\n", "\"score\"", ":", "start_logits", "[", "start_index", "]", "+", "end_logits", "[", "end_index", "]", ",", "\n", "\"start_logit\"", ":", "start_logits", "[", "start_index", "]", ",", "\n", "\"end_logit\"", ":", "end_logits", "[", "end_index", "]", ",", "\n", "}", "\n", ")", "\n", "", "", "", "if", "version_2_with_negative", ":", "\n", "# Add the minimum null prediction", "\n", "            ", "prelim_predictions", ".", "append", "(", "min_null_prediction", ")", "\n", "null_score", "=", "min_null_prediction", "[", "\"score\"", "]", "\n", "\n", "# Only keep the best `n_best_size` predictions.", "\n", "", "predictions", "=", "sorted", "(", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"score\"", "]", ",", "reverse", "=", "True", ")", "[", ":", "n_best_size", "]", "\n", "\n", "# Add back the minimum null prediction if it was removed because of its low score.", "\n", "if", "version_2_with_negative", "and", "not", "any", "(", "p", "[", "\"offsets\"", "]", "==", "(", "0", ",", "0", ")", "for", "p", "in", "predictions", ")", ":", "\n", "            ", "predictions", ".", "append", "(", "min_null_prediction", ")", "\n", "\n", "# Use the offsets to gather the answer text in the original context.", "\n", "", "context", "=", "example", "[", "\"context\"", "]", "\n", "for", "pred", "in", "predictions", ":", "\n", "            ", "offsets", "=", "pred", ".", "pop", "(", "\"offsets\"", ")", "\n", "pred", "[", "\"text\"", "]", "=", "context", "[", "offsets", "[", "0", "]", ":", "offsets", "[", "1", "]", "]", "\n", "\n", "# In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid", "\n", "# failure.", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", "or", "(", "len", "(", "predictions", ")", "==", "1", "and", "predictions", "[", "0", "]", "[", "\"text\"", "]", "==", "\"\"", ")", ":", "\n", "            ", "predictions", ".", "insert", "(", "0", ",", "{", "\"text\"", ":", "\"empty\"", ",", "\"start_logit\"", ":", "0.0", ",", "\"end_logit\"", ":", "0.0", ",", "\"score\"", ":", "0.0", "}", ")", "\n", "\n", "# Compute the softmax of all scores (we do it with numpy to stay independent from torch/tf in this file, using", "\n", "# the LogSumExp trick).", "\n", "", "scores", "=", "np", ".", "array", "(", "[", "pred", ".", "pop", "(", "\"score\"", ")", "for", "pred", "in", "predictions", "]", ")", "\n", "exp_scores", "=", "np", ".", "exp", "(", "scores", "-", "np", ".", "max", "(", "scores", ")", ")", "\n", "probs", "=", "exp_scores", "/", "exp_scores", ".", "sum", "(", ")", "\n", "\n", "# Include the probabilities in our predictions.", "\n", "for", "prob", ",", "pred", "in", "zip", "(", "probs", ",", "predictions", ")", ":", "\n", "            ", "pred", "[", "\"probability\"", "]", "=", "prob", "\n", "\n", "# Pick the best prediction. If the null answer is not possible, this is easy.", "\n", "", "if", "not", "version_2_with_negative", ":", "\n", "            ", "all_predictions", "[", "example", "[", "\"id\"", "]", "]", "=", "predictions", "[", "0", "]", "[", "\"text\"", "]", "\n", "", "else", ":", "\n", "# Otherwise we first need to find the best non-empty prediction.", "\n", "            ", "i", "=", "0", "\n", "while", "predictions", "[", "i", "]", "[", "\"text\"", "]", "==", "\"\"", ":", "\n", "                ", "i", "+=", "1", "\n", "", "best_non_null_pred", "=", "predictions", "[", "i", "]", "\n", "\n", "# Then we compare to the null prediction using the threshold.", "\n", "score_diff", "=", "null_score", "-", "best_non_null_pred", "[", "\"start_logit\"", "]", "-", "best_non_null_pred", "[", "\"end_logit\"", "]", "\n", "scores_diff_json", "[", "example", "[", "\"id\"", "]", "]", "=", "float", "(", "score_diff", ")", "# To be JSON-serializable.", "\n", "if", "score_diff", ">", "null_score_diff_threshold", ":", "\n", "                ", "all_predictions", "[", "example", "[", "\"id\"", "]", "]", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "all_predictions", "[", "example", "[", "\"id\"", "]", "]", "=", "best_non_null_pred", "[", "\"text\"", "]", "\n", "\n", "# Make `predictions` JSON-serializable by casting np.float back to float.", "\n", "", "", "all_nbest_json", "[", "example", "[", "\"id\"", "]", "]", "=", "[", "\n", "{", "k", ":", "(", "float", "(", "v", ")", "if", "isinstance", "(", "v", ",", "(", "np", ".", "float16", ",", "np", ".", "float32", ",", "np", ".", "float64", ")", ")", "else", "v", ")", "for", "k", ",", "v", "in", "pred", ".", "items", "(", ")", "}", "\n", "for", "pred", "in", "predictions", "\n", "]", "\n", "\n", "# If we have an output_dir, let's save all those dicts.", "\n", "", "if", "output_dir", "is", "not", "None", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ",", "f\"{output_dir} is not a directory.\"", "\n", "\n", "prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"predictions.json\"", "if", "prefix", "is", "None", "else", "f\"predictions_{prefix}\"", ".", "json", "\n", ")", "\n", "nbest_file", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"nbest_predictions.json\"", "if", "prefix", "is", "None", "else", "f\"nbest_predictions_{prefix}\"", ".", "json", "\n", ")", "\n", "if", "version_2_with_negative", ":", "\n", "            ", "null_odds_file", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"null_odds.json\"", "if", "prefix", "is", "None", "else", "f\"null_odds_{prefix}\"", ".", "json", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Saving predictions to {prediction_file}.\"", ")", "\n", "with", "open", "(", "prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "", "logger", ".", "info", "(", "f\"Saving nbest_preds to {nbest_file}.\"", ")", "\n", "with", "open", "(", "nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Saving null_odds to {null_odds_file}.\"", ")", "\n", "with", "open", "(", "null_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.qa_utils.postprocess_qa_predictions_with_beam_search": [[241, 426], ["collections.defaultdict", "enumerate", "collections.OrderedDict", "collections.OrderedDict", "logger.setLevel", "logger.info", "enumerate", "len", "len", "len", "features_per_example[].append", "collections.OrderedDict", "tqdm.auto.tqdm", "numpy.array", "numpy.exp", "zip", "os.path.isdir", "os.path.join", "os.path.join", "print", "print", "len", "len", "enumerate", "features[].get", "range", "sorted", "pred.pop", "len", "predictions.insert", "np.exp.sum", "float", "os.path.join", "open", "writer.write", "open", "writer.write", "print", "len", "len", "range", "pred.pop", "numpy.max", "open", "writer.write", "prelim_predictions.append", "isinstance", "float", "pred.items", "json.dumps", "json.dumps", "json.dumps", "len", "len", "features[].get.get", "str"], "function", ["None"], ["", "def", "postprocess_qa_predictions_with_beam_search", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "predictions", ":", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ",", "\n", "version_2_with_negative", ":", "bool", "=", "False", ",", "\n", "n_best_size", ":", "int", "=", "20", ",", "\n", "max_answer_length", ":", "int", "=", "30", ",", "\n", "start_n_top", ":", "int", "=", "5", ",", "\n", "end_n_top", ":", "int", "=", "5", ",", "\n", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "prefix", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "is_world_process_zero", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Post-processes the predictions of a question-answering model with beam search to convert them to answers that are substrings of the\n    original contexts. This is the postprocessing functions for models that return start and end logits, indices, as well as\n    cls token predictions.\n    Args:\n        examples: The non-preprocessed dataset (see the main script for more information).\n        features: The processed dataset (see the main script for more information).\n        predictions (:obj:`Tuple[np.ndarray, np.ndarray]`):\n            The predictions of the model: two arrays containing the start logits and the end logits respectively. Its\n            first dimension must match the number of elements of :obj:`features`.\n        version_2_with_negative (:obj:`bool`, `optional`, defaults to :obj:`False`):\n            Whether or not the underlying dataset contains examples with no answers.\n        n_best_size (:obj:`int`, `optional`, defaults to 20):\n            The total number of n-best predictions to generate when looking for an answer.\n        max_answer_length (:obj:`int`, `optional`, defaults to 30):\n            The maximum length of an answer that can be generated. This is needed because the start and end predictions\n            are not conditioned on one another.\n        start_n_top (:obj:`int`, `optional`, defaults to 5):\n            The number of top start logits too keep when searching for the :obj:`n_best_size` predictions.\n        end_n_top (:obj:`int`, `optional`, defaults to 5):\n            The number of top end logits too keep when searching for the :obj:`n_best_size` predictions.\n        output_dir (:obj:`str`, `optional`):\n            If provided, the dictionaries of predictions, n_best predictions (with their scores and logits) and, if\n            :obj:`version_2_with_negative=True`, the dictionary of the scores differences between best and null\n            answers, are saved in `output_dir`.\n        prefix (:obj:`str`, `optional`):\n            If provided, the dictionaries mentioned above are saved with `prefix` added to their names.\n        is_world_process_zero (:obj:`bool`, `optional`, defaults to :obj:`True`):\n            Whether this process is the main process or not (used to determine if logging/saves should be done).\n    \"\"\"", "\n", "assert", "len", "(", "predictions", ")", "==", "5", ",", "\"`predictions` should be a tuple with five elements.\"", "\n", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", "=", "predictions", "\n", "\n", "assert", "len", "(", "predictions", "[", "0", "]", ")", "==", "len", "(", "\n", "features", "\n", ")", ",", "f\"Got {len(predictions[0])} predicitions and {len(features)} features.\"", "\n", "\n", "# Build a map example to its corresponding features.", "\n", "example_id_to_index", "=", "{", "k", ":", "i", "for", "i", ",", "k", "in", "enumerate", "(", "examples", "[", "\"id\"", "]", ")", "}", "\n", "features_per_example", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "feature", "in", "enumerate", "(", "features", ")", ":", "\n", "        ", "features_per_example", "[", "example_id_to_index", "[", "feature", "[", "\"example_id\"", "]", "]", "]", ".", "append", "(", "i", ")", "\n", "\n", "# The dictionaries we have to fill.", "\n", "", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "if", "version_2_with_negative", "else", "None", "\n", "\n", "# Logging.", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_world_process_zero", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "info", "(", "f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\"", ")", "\n", "\n", "# Let's loop over all the examples!", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "tqdm", "(", "examples", ")", ")", ":", "\n", "# Those are the indices of the features associated to the current example.", "\n", "        ", "feature_indices", "=", "features_per_example", "[", "example_index", "]", "\n", "\n", "min_null_score", "=", "None", "\n", "prelim_predictions", "=", "[", "]", "\n", "\n", "# Looping through all the features associated to the current example.", "\n", "for", "feature_index", "in", "feature_indices", ":", "\n", "# We grab the predictions of the model for this feature.", "\n", "            ", "start_log_prob", "=", "start_top_log_probs", "[", "feature_index", "]", "\n", "start_indexes", "=", "start_top_index", "[", "feature_index", "]", "\n", "end_log_prob", "=", "end_top_log_probs", "[", "feature_index", "]", "\n", "end_indexes", "=", "end_top_index", "[", "feature_index", "]", "\n", "feature_null_score", "=", "cls_logits", "[", "feature_index", "]", "\n", "# This is what will allow us to map some the positions in our logits to span of texts in the original", "\n", "# context.", "\n", "offset_mapping", "=", "features", "[", "feature_index", "]", "[", "\"offset_mapping\"", "]", "\n", "# Optional `token_is_max_context`, if provided we will remove answers that do not have the maximum context", "\n", "# available in the current feature.", "\n", "token_is_max_context", "=", "features", "[", "feature_index", "]", ".", "get", "(", "\"token_is_max_context\"", ",", "None", ")", "\n", "\n", "# Update minimum null prediction", "\n", "if", "min_null_score", "is", "None", "or", "feature_null_score", "<", "min_null_score", ":", "\n", "                ", "min_null_score", "=", "feature_null_score", "\n", "\n", "# Go through all possibilities for the `n_start_top`/`n_end_top` greater start and end logits.", "\n", "", "for", "i", "in", "range", "(", "start_n_top", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "end_n_top", ")", ":", "\n", "                    ", "start_index", "=", "start_indexes", "[", "i", "]", "\n", "j_index", "=", "i", "*", "end_n_top", "+", "j", "\n", "end_index", "=", "end_indexes", "[", "j_index", "]", "\n", "# Don't consider out-of-scope answers (last part of the test should be unnecessary because of the", "\n", "# p_mask but let's not take any risk)", "\n", "if", "(", "\n", "start_index", ">=", "len", "(", "offset_mapping", ")", "\n", "or", "end_index", ">=", "len", "(", "offset_mapping", ")", "\n", "or", "offset_mapping", "[", "start_index", "]", "is", "None", "\n", "or", "offset_mapping", "[", "end_index", "]", "is", "None", "\n", ")", ":", "\n", "                        ", "continue", "\n", "# Don't consider answers with a length negative or > max_answer_length.", "\n", "", "if", "end_index", "<", "start_index", "or", "end_index", "-", "start_index", "+", "1", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "# Don't consider answer that don't have the maximum context available (if such information is", "\n", "# provided).", "\n", "", "if", "token_is_max_context", "is", "not", "None", "and", "not", "token_is_max_context", ".", "get", "(", "str", "(", "start_index", ")", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "{", "\n", "\"offsets\"", ":", "(", "offset_mapping", "[", "start_index", "]", "[", "0", "]", ",", "offset_mapping", "[", "end_index", "]", "[", "1", "]", ")", ",", "\n", "\"score\"", ":", "start_log_prob", "[", "i", "]", "+", "end_log_prob", "[", "j_index", "]", ",", "\n", "\"start_log_prob\"", ":", "start_log_prob", "[", "i", "]", ",", "\n", "\"end_log_prob\"", ":", "end_log_prob", "[", "j_index", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "# Only keep the best `n_best_size` predictions.", "\n", "", "", "", "predictions", "=", "sorted", "(", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"score\"", "]", ",", "reverse", "=", "True", ")", "[", ":", "n_best_size", "]", "\n", "\n", "# Use the offsets to gather the answer text in the original context.", "\n", "context", "=", "example", "[", "\"context\"", "]", "\n", "for", "pred", "in", "predictions", ":", "\n", "            ", "offsets", "=", "pred", ".", "pop", "(", "\"offsets\"", ")", "\n", "pred", "[", "\"text\"", "]", "=", "context", "[", "offsets", "[", "0", "]", ":", "offsets", "[", "1", "]", "]", "\n", "\n", "# In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid", "\n", "# failure.", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "predictions", ".", "insert", "(", "0", ",", "{", "\"text\"", ":", "\"\"", ",", "\"start_logit\"", ":", "-", "1e-6", ",", "\"end_logit\"", ":", "-", "1e-6", ",", "\"score\"", ":", "-", "2e-6", "}", ")", "\n", "\n", "# Compute the softmax of all scores (we do it with numpy to stay independent from torch/tf in this file, using", "\n", "# the LogSumExp trick).", "\n", "", "scores", "=", "np", ".", "array", "(", "[", "pred", ".", "pop", "(", "\"score\"", ")", "for", "pred", "in", "predictions", "]", ")", "\n", "exp_scores", "=", "np", ".", "exp", "(", "scores", "-", "np", ".", "max", "(", "scores", ")", ")", "\n", "probs", "=", "exp_scores", "/", "exp_scores", ".", "sum", "(", ")", "\n", "\n", "# Include the probabilities in our predictions.", "\n", "for", "prob", ",", "pred", "in", "zip", "(", "probs", ",", "predictions", ")", ":", "\n", "            ", "pred", "[", "\"probability\"", "]", "=", "prob", "\n", "\n", "# Pick the best prediction and set the probability for the null answer.", "\n", "", "all_predictions", "[", "example", "[", "\"id\"", "]", "]", "=", "predictions", "[", "0", "]", "[", "\"text\"", "]", "\n", "if", "version_2_with_negative", ":", "\n", "            ", "scores_diff_json", "[", "example", "[", "\"id\"", "]", "]", "=", "float", "(", "min_null_score", ")", "\n", "\n", "# Make `predictions` JSON-serializable by casting np.float back to float.", "\n", "", "all_nbest_json", "[", "example", "[", "\"id\"", "]", "]", "=", "[", "\n", "{", "k", ":", "(", "float", "(", "v", ")", "if", "isinstance", "(", "v", ",", "(", "np", ".", "float16", ",", "np", ".", "float32", ",", "np", ".", "float64", ")", ")", "else", "v", ")", "for", "k", ",", "v", "in", "pred", ".", "items", "(", ")", "}", "\n", "for", "pred", "in", "predictions", "\n", "]", "\n", "\n", "# If we have an output_dir, let's save all those dicts.", "\n", "", "if", "output_dir", "is", "not", "None", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ",", "f\"{output_dir} is not a directory.\"", "\n", "\n", "prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"predictions.json\"", "if", "prefix", "is", "None", "else", "f\"predictions_{prefix}\"", ".", "json", "\n", ")", "\n", "nbest_file", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"nbest_predictions.json\"", "if", "prefix", "is", "None", "else", "f\"nbest_predictions_{prefix}\"", ".", "json", "\n", ")", "\n", "if", "version_2_with_negative", ":", "\n", "            ", "null_odds_file", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"null_odds.json\"", "if", "prefix", "is", "None", "else", "f\"null_odds_{prefix}\"", ".", "json", "\n", ")", "\n", "\n", "", "print", "(", "f\"Saving predictions to {prediction_file}.\"", ")", "\n", "with", "open", "(", "prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "", "print", "(", "f\"Saving nbest_preds to {nbest_file}.\"", ")", "\n", "with", "open", "(", "nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "print", "(", "f\"Saving null_odds to {null_odds_file}.\"", ")", "\n", "with", "open", "(", "null_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "return", "all_predictions", ",", "scores_diff_json", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.edit_config": [[10, 14], ["None"], "function", ["None"], ["def", "edit_config", "(", "config", ",", "additional_args", ")", ":", "\n", "    ", "config", ".", "transform_embedding", "=", "additional_args", ".", "transform_embedding", "\n", "config", ".", "do_distill", "=", "additional_args", ".", "do_distill", "\n", "config", ".", "do_layer_distill", "=", "additional_args", ".", "do_layer_distill", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.initialize_layer_transformation": [[15, 19], ["model.layer_transformation.weight.data.copy_", "model.layer_transformation.bias.data.fill_", "torch.eye", "len"], "function", ["None"], ["", "def", "initialize_layer_transformation", "(", "model", ")", ":", "\n", "    ", "model", ".", "layer_transformation", ".", "weight", ".", "data", ".", "copy_", "(", "\n", "torch", ".", "eye", "(", "len", "(", "model", ".", "layer_transformation", ".", "weight", ")", ")", ")", "\n", "model", ".", "layer_transformation", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_model_with_zs": [[20, 35], ["os.path.join", "os.path.exists", "model_class.from_pretrained", "os.path.join", "torch.load", "model_class.from_pretrained.load_state_dict", "print", "cofi_utils.update_params", "print", "cofi_utils.prune_model_with_z", "print", "transformers.AutoConfig.from_pretrained", "utils.utils.calculate_parameters", "utils.utils.calculate_parameters"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.update_params", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.prune_model_with_z", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters"], ["", "def", "load_model_with_zs", "(", "model_path", ",", "model_class", ",", "zs", "=", "None", ")", ":", "\n", "    ", "config_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"config.json\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "config_path", ")", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_path", ")", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "model_path", ",", "config", "=", "config", ")", "\n", "p", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"pytorch_model.bin\"", ")", "\n", "loaded_weights", "=", "torch", ".", "load", "(", "p", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "loaded_weights", ")", "\n", "print", "(", "f\"Load weights from {model_path}\"", ")", "\n", "\n", "update_params", "(", "model", ",", "zs", ")", "\n", "print", "(", "f\"Model Size before pruning: {calculate_parameters(model)}\"", ")", "\n", "prune_model_with_z", "(", "zs", ",", "model", ")", "\n", "print", "(", "f\"Model Size after pruning: {calculate_parameters(model)}\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_model": [[36, 44], ["cofi_utils.load_model_with_zs", "cofi_utils.load_pruned_model", "print", "utils.utils.calculate_parameters"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_model_with_zs", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_pruned_model", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters"], ["", "def", "load_model", "(", "model_path", ",", "model_class", ",", "zs", "=", "None", ",", "num_labels", "=", "2", ")", ":", "\n", "    ", "if", "zs", "is", "not", "None", ":", "\n", "        ", "model", "=", "load_model_with_zs", "(", "model_path", ",", "model_class", ",", "zs", ")", "\n", "", "else", ":", "\n", "# only and task name and model weights are accessible ", "\n", "        ", "model", "=", "load_pruned_model", "(", "model_path", ",", "model_class", ")", "\n", "print", "(", "f\"Model Size: {calculate_parameters(model)}\"", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_l0_module": [[46, 52], ["os.path.join", "os.path.exists", "torch.load", "torch.device"], "function", ["None"], ["", "def", "load_l0_module", "(", "model_path", ")", ":", "\n", "    ", "l0_module_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"l0_module.pt\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "l0_module_path", ")", ":", "\n", "        ", "return", "torch", ".", "load", "(", "l0_module_path", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.update_params": [[54, 106], ["hasattr", "range", "range", "zs[].cpu().squeeze().clone", "bert.embeddings.word_embeddings.weight.data.mul", "bert.embeddings.position_embeddings.weight.data.mul", "bert.embeddings.token_type_embeddings.weight.data.mul", "range", "hasattr", "hasattr", "[].cpu().squeeze().clone", "bert.encoder.layer[].output.dense.weight.data.mul", "[].cpu().squeeze().clone", "torch.repeat_interleave", "bert.encoder.layer[].attention.self.value.weight.transpose().data.mul().transpose", "bert.encoder.layer[].attention.self.value.bias.data.mul", "bert.encoder.layer[].attention.self.key.weight.data.mul", "bert.encoder.layer[].attention.self.query.weight.data.mul", "bert.encoder.layer[].attention.self.value.weight.data.mul", "bert.encoder.layer[].attention.output.dense.weight.data.transpose().mul().transpose", "bert.encoder.layer[].attention.output.dense.bias.data.mul", "bert.encoder.layer[].intermediate.dense.weight.data.mul", "bert.encoder.layer[].output.dense.weight.data.transpose().mul().transpose", "bert.pooler.dense.weight.data.mul", "model.qa_outputs.weight.data.mul", "[].cpu", "bert.encoder.layer[].output.dense.weight.data.transpose().mul().transpose", "bert.encoder.layer[].output.dense.bias.data.mul", "[].cpu", "bert.encoder.layer[].attention.output.dense.weight.transpose().data.mul().transpose", "bert.encoder.layer[].attention.output.dense.bias.data.mul", "zs[].cpu().squeeze", "[].cpu().squeeze", "[].cpu().squeeze", "bert.encoder.layer[].attention.self.value.weight.transpose().data.mul", "bert.encoder.layer[].attention.output.dense.weight.data.transpose().mul", "bert.encoder.layer[].output.dense.weight.data.transpose().mul", "bert.encoder.layer[].output.dense.weight.data.transpose().mul", "bert.encoder.layer[].attention.output.dense.weight.transpose().data.mul", "zs[].cpu", "[].cpu", "[].cpu", "bert.encoder.layer[].attention.output.dense.weight.data.transpose", "bert.encoder.layer[].output.dense.weight.data.transpose", "bert.encoder.layer[].output.dense.weight.data.transpose", "bert.encoder.layer[].attention.self.value.weight.transpose", "bert.encoder.layer[].attention.output.dense.weight.transpose"], "function", ["None"], ["", "", "def", "update_params", "(", "model", ",", "zs", ")", ":", "\n", "    ", "bert", "=", "model", ".", "bert", "if", "hasattr", "(", "model", ",", "\"bert\"", ")", "else", "model", ".", "roberta", "\n", "\n", "config", "=", "model", ".", "config", "\n", "hidden_dims", "=", "config", ".", "hidden_size", "\n", "num_heads", "=", "config", ".", "num_attention_heads", "\n", "dims_per_head", "=", "hidden_dims", "//", "num_heads", "\n", "num_layers", "=", "config", ".", "num_hidden_layers", "\n", "\n", "if", "zs", "is", "not", "None", ":", "\n", "        ", "if", "\"intermediate_z\"", "in", "zs", ":", "\n", "            ", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "intermediate_z", "=", "zs", "[", "\"intermediate_z\"", "]", "[", "layer", "]", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "clone", "(", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "weight", ".", "data", ".", "mul", "(", "intermediate_z", ")", "\n", "if", "\"mlp_z\"", "in", "zs", ":", "\n", "                    ", "mlp_z", "=", "zs", "[", "\"mlp_z\"", "]", "[", "layer", "]", ".", "cpu", "(", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "weight", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "mul", "(", "mlp_z", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "bias", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "bias", ".", "data", ".", "mul", "(", "mlp_z", ")", "\n", "\n", "", "", "", "if", "\"head_z\"", "in", "zs", ":", "\n", "            ", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "head_z", "=", "zs", "[", "\"head_z\"", "]", "[", "layer", "]", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "clone", "(", ")", "\n", "head_z", "=", "torch", ".", "repeat_interleave", "(", "head_z", ",", "dims_per_head", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ".", "weight", ".", "transpose", "(", "0", ",", "1", ")", ".", "data", ".", "mul", "(", "head_z", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ".", "bias", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ".", "bias", ".", "data", ".", "mul", "(", "head_z", ")", "\n", "if", "\"head_layer_z\"", "in", "zs", ":", "\n", "                    ", "head_layer_z", "=", "zs", "[", "\"head_layer_z\"", "]", "[", "layer", "]", ".", "cpu", "(", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "\n", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "weight", ".", "transpose", "(", "0", ",", "1", ")", ".", "data", ".", "mul", "(", "head_layer_z", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "bias", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "\n", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "bias", ".", "data", ".", "mul", "(", "head_layer_z", ")", "\n", "\n", "", "", "", "if", "\"hidden_z\"", "in", "zs", ":", "\n", "            ", "hidden_z", "=", "zs", "[", "\"hidden_z\"", "]", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "clone", "(", ")", "\n", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "data", "=", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "bert", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "data", "=", "bert", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "bert", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "=", "bert", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "key", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "key", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "query", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "query", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "weight", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "mul", "(", "hidden_z", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "bias", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "bias", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "weight", ".", "data", "=", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "weight", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "mul", "(", "hidden_z", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "if", "hasattr", "(", "bert", ".", "pooler", ",", "\"dense\"", ")", ":", "\n", "                ", "bert", ".", "pooler", ".", "dense", ".", "weight", ".", "data", "=", "bert", ".", "pooler", ".", "dense", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "", "if", "hasattr", "(", "model", ",", "\"qa_outputs\"", ")", ":", "\n", "                ", "model", ".", "qa_outputs", ".", "weight", ".", "data", "=", "model", ".", "qa_outputs", ".", "weight", ".", "data", ".", "mul", "(", "hidden_z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.prune_model_with_z": [[108, 227], ["range", "hasattr", "zs.get", "zs.get", "range", "model.prune_heads", "zs.get", "range", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "transformers.modeling_utils.prune_linear_layer", "torch.LongTensor", "[].tolist.to", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "cofi_utils.prune_model_with_z.prune_layer_norm"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertAttention.prune_heads"], ["", "", "", "", "def", "prune_model_with_z", "(", "zs", ",", "model", ")", ":", "\n", "    ", "if", "zs", "is", "None", ":", "\n", "        ", "return", "None", ",", "None", "\n", "", "bert", "=", "model", ".", "bert", "if", "hasattr", "(", "model", ",", "\"bert\"", ")", "else", "model", ".", "roberta", "\n", "\n", "if", "\"head_z\"", "in", "zs", ":", "\n", "        ", "head_z", "=", "zs", ".", "get", "(", "\"head_z\"", ",", "None", ")", "\n", "head_layer_z", "=", "zs", ".", "get", "(", "\"head_layer_z\"", ",", "None", ")", "\n", "\n", "prune_heads", "=", "{", "}", "\n", "for", "layer", "in", "range", "(", "len", "(", "head_z", ")", ")", ":", "\n", "            ", "head_z_layer", "=", "head_z", "[", "layer", "]", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "clone", "(", ")", "\n", "if", "head_layer_z", "is", "not", "None", ":", "\n", "                ", "head_z_layer", "*=", "head_layer_z", "[", "layer", "]", "\n", "", "index", "=", "torch", ".", "where", "(", "head_z_layer", "==", "0", ")", "[", "0", "]", ".", "tolist", "(", ")", "\n", "prune_heads", "[", "layer", "]", "=", "index", "\n", "\n", "print", "(", "f\"Layer {layer}, heads {' '.join([str(i) for i in index])} pruned.\"", ")", "\n", "", "model", ".", "prune_heads", "(", "prune_heads", ")", "\n", "\n", "", "kept_intermediate_dims", "=", "None", "\n", "if", "\"intermediate_z\"", "in", "zs", ":", "\n", "        ", "kept_intermediate_dims", "=", "{", "}", "\n", "intermediate_zs", "=", "zs", "[", "\"intermediate_z\"", "]", "\n", "mlp_z", "=", "zs", ".", "get", "(", "\"mlp_z\"", ",", "None", ")", "\n", "for", "layer", "in", "range", "(", "len", "(", "intermediate_zs", ")", ")", ":", "\n", "            ", "intermediate_z_layer", "=", "intermediate_zs", "[", "layer", "]", ".", "squeeze", "(", ")", "\n", "intermediate_z_layer", "=", "intermediate_z_layer", ".", "cpu", "(", ")", ".", "clone", "(", ")", "\n", "if", "mlp_z", "is", "not", "None", ":", "\n", "                ", "intermediate_z_layer", "*=", "mlp_z", "[", "layer", "]", "\n", "", "kept_intermediate_dims", "[", "layer", "]", "=", "intermediate_z_layer", ".", "nonzero", "(", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "", "", "def", "prune_layer_norm", "(", "layernorm", ",", "index", ")", ":", "\n", "        ", "layernorm", ".", "weight", "=", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "(", "\n", "layernorm", ".", "weight", ".", "index_select", "(", "0", ",", "index", ")", ")", "\n", "layernorm", ".", "bias", "=", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "(", "\n", "layernorm", ".", "bias", ".", "index_select", "(", "0", ",", "index", ")", ")", "\n", "layernorm", ".", "normalized_shape", "=", "(", "len", "(", "index", ")", ",", ")", "\n", "\n", "", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", ")", ":", "\n", "        ", "layer", "=", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "dim", ")", "\n", "return", "layer", "\n", "\n", "", "if", "\"hidden_z\"", "in", "zs", ":", "\n", "        ", "hidden_zs", "=", "zs", "[", "\"hidden_z\"", "]", "\n", "index", "=", "torch", ".", "LongTensor", "(", "hidden_zs", ".", "squeeze", "(", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", ")", "\n", "index", "=", "index", ".", "to", "(", "model", ".", "device", ")", "\n", "\n", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", "=", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "(", "\n", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "index_select", "(", "1", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "bert", ".", "embeddings", ".", "word_embeddings", ".", "embedding_dim", "=", "index", ".", "shape", "[", "0", "]", "\n", "bert", ".", "embeddings", ".", "position_embeddings", ".", "weight", "=", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "(", "\n", "bert", ".", "embeddings", ".", "position_embeddings", ".", "weight", ".", "index_select", "(", "1", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "bert", ".", "embeddings", ".", "position_embeddings", ".", "embedding_dim", "=", "index", ".", "shape", "[", "0", "]", "\n", "bert", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", "=", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "(", "\n", "bert", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "index_select", "(", "1", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "bert", ".", "embeddings", ".", "token_type_embeddings", ".", "embedding_dim", "=", "index", ".", "shape", "[", "0", "]", "\n", "prune_layer_norm", "(", "bert", ".", "embeddings", ".", "LayerNorm", ",", "index", ")", "\n", "\n", "for", "layer", "in", "range", "(", "0", ",", "12", ")", ":", "\n", "            ", "if", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "query", "is", "not", "None", ":", "\n", "                ", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "query", "=", "prune_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "query", ",", "index", ",", "dim", "=", "1", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "key", "=", "prune_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "key", ",", "index", ",", "dim", "=", "1", ")", "\n", "", "if", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", "is", "not", "None", ":", "\n", "                ", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", "=", "prune_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ",", "index", ",", "dim", "=", "1", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", "=", "prune_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "0", ")", "\n", "prune_layer_norm", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "LayerNorm", ",", "index", ")", "\n", "", "if", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", "is", "not", "None", ":", "\n", "                ", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", "=", "prune_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", "=", "prune_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "0", ")", "\n", "prune_layer_norm", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "LayerNorm", ",", "index", ")", "\n", "\n", "# accommodate for different models", "\n", "", "", "if", "hasattr", "(", "model", ",", "\"classifier\"", ")", ":", "\n", "            ", "if", "hasattr", "(", "model", ".", "classifier", ",", "\"dense\"", ")", ":", "\n", "                ", "model", ".", "classifier", ".", "dense", "=", "prune_linear_layer", "(", "model", ".", "classifier", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "", "", "if", "hasattr", "(", "model", ",", "\"cls\"", ")", ":", "\n", "            ", "if", "hasattr", "(", "model", ".", "cls", ",", "\"dense\"", ")", ":", "\n", "                ", "model", ".", "cls", ".", "dense", "=", "prune_linear_layer", "(", "model", ".", "classifier", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "", "", "if", "hasattr", "(", "bert", ".", "pooler", ",", "\"dense\"", ")", ":", "\n", "            ", "bert", ".", "pooler", ".", "dense", "=", "prune_linear_layer", "(", "bert", ".", "pooler", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "", "if", "hasattr", "(", "model", ",", "\"qa_outputs\"", ")", ":", "\n", "            ", "model", ".", "qa_outputs", "=", "prune_linear_layer", "(", "model", ".", "qa_outputs", ",", "index", ",", "dim", "=", "1", ")", "\n", "", "if", "getattr", "(", "model", ",", "\"layer_transformation\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "model", ".", "layer_transformation", "=", "prune_linear_layer", "(", "model", ".", "layer_transformation", ",", "index", ",", "dim", "=", "1", ")", "\n", "print", "(", "\"layer transformation\"", ",", "model", ".", "layer_transformation", ".", "weight", ".", "shape", ")", "\n", "", "if", "getattr", "(", "model", ",", "\"mha_layer_transformation\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "model", ".", "mha_layer_transformation", "=", "prune_linear_layer", "(", "model", ".", "mha_layer_transformation", ",", "index", ",", "dim", "=", "1", ")", "\n", "print", "(", "\"layer mha_layer_transformation\"", ",", "model", ".", "mha_layer_transformation", ".", "weight", ".", "shape", ")", "\n", "\n", "", "", "if", "kept_intermediate_dims", "is", "not", "None", ":", "\n", "        ", "prune_intermediate_layers", "(", "model", ",", "kept_intermediate_dims", ")", "\n", "\n", "", "for", "layer", "in", "range", "(", "0", ",", "12", ")", ":", "\n", "        ", "print", "(", "\"Layer:\"", ",", "layer", ")", "\n", "if", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "query", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"query:\"", ",", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "query", ".", "weight", ".", "shape", ")", "\n", "print", "(", "\"key:\"", ",", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "key", ".", "weight", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"query:\"", ",", "None", ")", "\n", "print", "(", "\"key:\"", ",", "None", ")", "\n", "", "if", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"value:\"", ",", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "self", ".", "value", ".", "weight", ".", "shape", ")", "\n", "print", "(", "\"output:\"", ",", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "output", ".", "dense", ".", "weight", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"value:\"", ",", "None", ")", "\n", "print", "(", "\"output:\"", ",", "None", ")", "\n", "", "if", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"up:\"", ",", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", ".", "weight", ".", "shape", ")", "\n", "print", "(", "\"down:\"", ",", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ".", "weight", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"up\"", ",", "None", ")", "\n", "print", "(", "\"down\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.prune_intermediate_layers": [[229, 239], ["hasattr", "len", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "", "", "def", "prune_intermediate_layers", "(", "model", ",", "keep_dims", ")", ":", "\n", "    ", "bert", "=", "model", ".", "bert", "if", "hasattr", "(", "model", ",", "\"bert\"", ")", "else", "model", ".", "roberta", "\n", "device", "=", "model", ".", "device", "\n", "for", "layer", "in", "keep_dims", ":", "\n", "        ", "if", "len", "(", "keep_dims", "[", "layer", "]", ")", "==", "0", ":", "\n", "            ", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", "=", "None", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", "=", "None", "\n", "", "else", ":", "\n", "            ", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", "=", "prune_linear_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "intermediate", ".", "dense", ",", "index", "=", "torch", ".", "LongTensor", "(", "keep_dims", "[", "layer", "]", ")", ".", "to", "(", "device", ")", ",", "dim", "=", "0", ")", "\n", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "output", ".", "dense", ",", "index", "=", "torch", ".", "LongTensor", "(", "keep_dims", "[", "layer", "]", ")", ".", "to", "(", "device", ")", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_zs": [[241, 256], ["os.path.dirname.endswith", "os.path.exists", "os.path.join", "torch.load", "os.path.dirname", "torch.load", "torch.load.forward", "os.path.join"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.forward"], ["", "", "", "def", "load_zs", "(", "model_path", ")", ":", "\n", "    ", "if", "model_path", ".", "endswith", "(", "\"zs.pt\"", ")", ":", "\n", "        ", "zs_path", "=", "model_path", "\n", "", "else", ":", "\n", "        ", "zs_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"zs.pt\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "zs_path", ")", ":", "\n", "        ", "zs", "=", "torch", ".", "load", "(", "zs_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "if", "zs", "is", "None", ":", "\n", "            ", "model_path", "=", "os", ".", "path", ".", "dirname", "(", "model_path", ")", "\n", "l0_module", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"l0_module.pt\"", ")", ",", "map_location", "=", "\"cpu\"", ")", "\n", "zs", "=", "l0_module", ".", "forward", "(", "training", "=", "False", ")", "\n", "", "return", "zs", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_pruned_model": [[257, 294], ["config.architectures[].lower", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros", "torch.zeros", "range", "cofi_utils.prune_model_with_z", "model.load_state_dict"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.prune_model_with_z"], ["", "", "def", "load_pruned_model", "(", "model", ",", "weights", ")", ":", "\n", "    ", "config", "=", "model", ".", "config", "\n", "dim_per_head", "=", "config", ".", "hidden_size", "//", "config", ".", "num_attention_heads", "\n", "zs", "=", "{", "}", "\n", "\n", "architecture", "=", "config", ".", "architectures", "[", "0", "]", ".", "lower", "(", ")", "\n", "bert_name", "=", "\"roberta\"", "if", "\"roberta\"", "in", "architecture", "else", "\"bert\"", "\n", "\n", "hidden_z", "=", "torch", ".", "zeros", "(", "config", ".", "hidden_size", ")", "\n", "hidden_z", "[", ":", "weights", "[", "f\"{bert_name}.embeddings.word_embeddings.weight\"", "]", ".", "shape", "[", "1", "]", "]", "=", "1", "\n", "zs", "[", "\"hidden_z\"", "]", "=", "hidden_z", "\n", "\n", "head_z", "=", "torch", ".", "zeros", "(", "config", ".", "num_hidden_layers", ",", "config", ".", "num_attention_heads", ")", "\n", "head_layer_z", "=", "torch", ".", "zeros", "(", "config", ".", "num_hidden_layers", ")", "\n", "for", "i", "in", "range", "(", "config", ".", "num_hidden_layers", ")", ":", "\n", "        ", "key", "=", "f\"{bert_name}.encoder.layer.{i}.attention.output.dense.weight\"", "\n", "if", "key", "in", "weights", ":", "\n", "            ", "remaining_heads", "=", "weights", "[", "key", "]", ".", "shape", "[", "-", "1", "]", "//", "dim_per_head", "\n", "head_z", "[", "i", ",", ":", "remaining_heads", "]", "=", "1", "\n", "head_layer_z", "[", "i", "]", "=", "1", "\n", "", "", "zs", "[", "\"head_z\"", "]", "=", "head_z", "\n", "zs", "[", "\"head_layer_z\"", "]", "=", "head_layer_z", "\n", "\n", "int_z", "=", "torch", ".", "zeros", "(", "config", ".", "num_hidden_layers", ",", "config", ".", "intermediate_size", ")", "\n", "mlp_z", "=", "torch", ".", "zeros", "(", "config", ".", "num_hidden_layers", ")", "\n", "for", "i", "in", "range", "(", "config", ".", "num_hidden_layers", ")", ":", "\n", "        ", "key", "=", "f\"bert.encoder.layer.{i}.output.dense.weight\"", "\n", "if", "key", "in", "weights", ":", "\n", "            ", "remaining_int_dims", "=", "weights", "[", "key", "]", ".", "shape", "[", "-", "1", "]", "\n", "int_z", "[", "i", ",", ":", "remaining_int_dims", "]", "=", "1", "\n", "mlp_z", "[", "i", "]", "=", "1", "\n", "", "", "zs", "[", "\"intermediate_z\"", "]", "=", "int_z", "\n", "zs", "[", "\"mlp_z\"", "]", "=", "mlp_z", "\n", "\n", "prune_model_with_z", "(", "zs", ",", "model", ")", "\n", "model", ".", "load_state_dict", "(", "weights", ",", "strict", "=", "False", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.get_full_model_size": [[295, 299], ["model_class.from_pretrained", "utils.utils.calculate_parameters"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters"], ["", "def", "get_full_model_size", "(", "model_class", ",", "model_name", ")", ":", "\n", "    ", "model", "=", "model_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "model_size", "=", "calculate_parameters", "(", "model", ")", "\n", "return", "model_size", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.log_all_parameters": [[5, 21], ["logger.info", "vars", "logger.info", "vars", "logger.info", "vars", "logger.info", "vars", "logger.info", "logger.info", "logger.info", "logger.info", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "log_all_parameters", "(", "logger", ",", "model_args", ",", "data_args", ",", "training_args", ",", "additional_args", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Model Arguments:\"", ")", "\n", "for", "arg", "in", "vars", "(", "model_args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"{arg} = {getattr(model_args, arg)}\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Data Arguments:\"", ")", "\n", "for", "arg", "in", "vars", "(", "data_args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"{arg} = {getattr(data_args, arg)}\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Training Arguments:\"", ")", "\n", "for", "arg", "in", "vars", "(", "training_args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"{arg} = {getattr(training_args, arg)}\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Additional Arguments:\"", ")", "\n", "for", "arg", "in", "vars", "(", "additional_args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"{arg} = {getattr(additional_args, arg)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.calculate_parameters": [[22, 25], ["sum", "p.numel", "module.named_parameters", "any"], "function", ["None"], ["", "", "def", "calculate_parameters", "(", "module", ")", ":", "\n", "    ", "keys", "=", "[", "\"embedding\"", ",", "\"layer_transformation\"", ",", "\"classifier\"", ",", "\"pooler\"", "]", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "n", ",", "p", "in", "module", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "key", "in", "n", "for", "key", "in", "keys", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.utils.load_from_tsv": [[26, 37], ["open().readlines", "lines[].strip().split", "collections.defaultdict", "enumerate", "datasets.Dataset.from_dict", "line.strip().split", "enumerate", "open", "lines[].strip", "d[].append", "line.strip"], "function", ["None"], ["", "def", "load_from_tsv", "(", "file", ")", ":", "\n", "    ", "lines", "=", "open", "(", "file", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "data", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "for", "line", "in", "lines", "[", "1", ":", "]", "]", "\n", "headers", "=", "lines", "[", "0", "]", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "d", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "head", "in", "enumerate", "(", "headers", ")", ":", "\n", "        ", "for", "j", ",", "dd", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "d", "[", "head", "]", ".", "append", "(", "dd", "[", "i", "]", ")", "\n", "\n", "", "", "dataset", "=", "Dataset", ".", "from_dict", "(", "d", ")", "\n", "return", "dataset", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.__init__": [[18, 85], ["torch.nn.modules.Module.__init__", "l0_module.L0Module.pruning_type.split", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "logger.info", "logger.info", "l0_module.L0Module.initialize_one_module", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "logger.info", "logger.info", "logger.info", "l0_module.L0Module.initialize_one_module"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_one_module", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_one_module"], ["    ", "def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "droprate_init", "=", "0.5", ",", "\n", "temperature", "=", "2.", "/", "3.", ",", "\n", "lagrangian_warmup", "=", "0", ",", "\n", "start_sparsity", "=", "0.0", ",", "\n", "target_sparsity", "=", "0.0", ",", "\n", "pruning_type", "=", "\"structured_heads+structured_mlp+hidden+layer\"", ",", "\n", "magical_number", "=", "0.8", ",", "# from Wang et al. 2020", "\n", ")", ":", "\n", "        ", "super", "(", "L0Module", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "all_types", "=", "[", "\"hidden_z\"", ",", "\"intermediate_z\"", ",", "\"mlp_z\"", ",", "\"head_layer_z\"", ",", "\"head_z\"", "]", "\n", "self", ".", "pruning_type", "=", "pruning_type", "\n", "\n", "self", ".", "hidden_size", "=", "config", ".", "hidden_size", "\n", "self", ".", "intermediate_size", "=", "config", ".", "intermediate_size", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "mlp_num_per_layer", "=", "1", "\n", "self", ".", "dim_per_head", "=", "self", ".", "hidden_size", "//", "self", ".", "num_attention_heads", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "num_hidden_layers", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "self", ".", "params_per_head_layer", "=", "self", ".", "hidden_size", "*", "self", ".", "hidden_size", "*", "4", "+", "self", ".", "hidden_size", "*", "4", "\n", "self", ".", "params_per_head", "=", "self", ".", "params_per_head_layer", "//", "self", ".", "num_attention_heads", "\n", "\n", "\n", "self", ".", "params_per_mlp_layer", "=", "self", ".", "hidden_size", "*", "self", ".", "intermediate_size", "*", "2", "+", "self", ".", "hidden_size", "+", "self", ".", "hidden_size", "*", "4", "\n", "self", ".", "params_per_intermediate_dim", "=", "self", ".", "params_per_mlp_layer", "//", "self", ".", "intermediate_size", "\n", "\n", "# we ignore the parameters in normalization layers (it takes a very small amount)", "\n", "self", ".", "full_model_size", "=", "(", "self", ".", "params_per_head_layer", "+", "self", ".", "params_per_mlp_layer", ")", "*", "self", ".", "num_hidden_layers", "\n", "self", ".", "prunable_model_size", "=", "0", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "droprate_init", "=", "droprate_init", "if", "droprate_init", "!=", "0.", "else", "0.5", "\n", "\n", "self", ".", "types", "=", "[", "]", "\n", "self", ".", "z_logas", "=", "{", "}", "\n", "self", ".", "parameters_per_dim", "=", "{", "}", "\n", "self", ".", "sizes", "=", "{", "}", "\n", "self", ".", "shapes", "=", "{", "}", "\n", "\n", "self", ".", "hidden_loga", "=", "None", "\n", "self", ".", "hidden_type", "=", "None", "\n", "\n", "types", "=", "self", ".", "pruning_type", ".", "split", "(", "\"+\"", ")", "\n", "for", "type", "in", "types", ":", "\n", "            ", "if", "type", "!=", "\"layer\"", ":", "\n", "                ", "self", ".", "initialize_one_module", "(", "type", ")", "\n", "", "", "if", "\"layer\"", "in", "types", ":", "\n", "            ", "self", ".", "initialize_one_module", "(", "\"layer\"", ")", "\n", "\n", "", "self", ".", "magical_number", "=", "magical_number", "\n", "\n", "self", ".", "lambda_1", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", "\n", "self", ".", "lambda_2", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", "\n", "\n", "self", ".", "lagrangian_warmup", "=", "lagrangian_warmup", "\n", "self", ".", "start_sparsity", "=", "start_sparsity", "\n", "self", ".", "target_sparsity", "=", "target_sparsity", "\n", "\n", "logger", ".", "info", "(", "\"********** Initializing L0 Module **********\"", ")", "\n", "for", "type", "in", "self", ".", "types", ":", "\n", "            ", "logger", ".", "info", "(", "f\"***** {type} *****\"", ")", "\n", "logger", ".", "info", "(", "f\"z.shape\"", ",", "self", ".", "z_logas", "[", "type", "]", ".", "shape", ")", "\n", "logger", ".", "info", "(", "f\"size\"", ",", "self", ".", "sizes", "[", "type", "]", ")", "\n", "", "logger", ".", "info", "(", "f\"prunable model size: {self.prunable_model_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.set_lagrangian_warmup_steps": [[86, 88], ["None"], "methods", ["None"], ["", "def", "set_lagrangian_warmup_steps", "(", "self", ",", "lagrangian_warmup", ")", ":", "\n", "        ", "self", ".", "lagrangian_warmup", "=", "lagrangian_warmup", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_one_module": [[89, 99], ["l0_module.L0Module.initialize_structured_mlp", "l0_module.L0Module.initialize_structured_head", "l0_module.L0Module.initialize_hidden", "l0_module.L0Module.initialize_whole_mlp", "l0_module.L0Module.initialized_layer_structured_heads"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_structured_mlp", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_structured_head", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_hidden", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_whole_mlp", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialized_layer_structured_heads"], ["", "def", "initialize_one_module", "(", "self", ",", "module_name", ")", ":", "\n", "        ", "if", "module_name", "==", "\"structured_mlp\"", ":", "\n", "            ", "self", ".", "initialize_structured_mlp", "(", ")", "\n", "", "elif", "module_name", "==", "\"structured_heads\"", ":", "\n", "            ", "self", ".", "initialize_structured_head", "(", ")", "\n", "", "elif", "module_name", "==", "\"hidden\"", ":", "\n", "            ", "self", ".", "initialize_hidden", "(", ")", "\n", "", "elif", "module_name", "==", "\"layer\"", ":", "\n", "            ", "self", ".", "initialize_whole_mlp", "(", ")", "\n", "self", ".", "initialized_layer_structured_heads", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.add_one_module": [[100, 106], ["l0_module.L0Module.types.append"], "methods", ["None"], ["", "", "def", "add_one_module", "(", "self", ",", "z_loga", ",", "type", ",", "parameter_per_dim", ",", "size", ",", "shape", ")", ":", "\n", "        ", "self", ".", "types", ".", "append", "(", "type", ")", "\n", "self", ".", "z_logas", "[", "type", "]", "=", "z_loga", "\n", "self", ".", "parameters_per_dim", "[", "type", "]", "=", "parameter_per_dim", "\n", "self", ".", "sizes", "[", "type", "]", "=", "size", "\n", "self", ".", "shapes", "[", "type", "]", "=", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_parameters": [[107, 112], ["torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ",", "size", ",", "num_layer", "=", "None", ")", ":", "\n", "        ", "if", "num_layer", "is", "not", "None", ":", "\n", "            ", "return", "Parameter", "(", "torch", ".", "Tensor", "(", "num_layer", ",", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "Parameter", "(", "torch", ".", "Tensor", "(", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_hidden": [[113, 120], ["l0_module.L0Module.initialize_parameters", "l0_module.L0Module.add_one_module", "l0_module.L0Module.reset_loga", "logger.info"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.add_one_module", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga"], ["", "", "def", "initialize_hidden", "(", "self", ")", ":", "\n", "        ", "self", ".", "hidden_loga", "=", "self", ".", "initialize_parameters", "(", "self", ".", "hidden_size", ")", "\n", "self", ".", "add_one_module", "(", "self", ".", "hidden_loga", ",", "type", "=", "\"hidden\"", ",", "\n", "parameter_per_dim", "=", "self", ".", "hidden_size", "*", "4", "+", "self", ".", "hidden_size", "*", "4", "*", "2", ",", "\n", "size", "=", "self", ".", "hidden_size", ",", "shape", "=", "[", "self", ".", "hidden_size", "]", ")", "\n", "self", ".", "reset_loga", "(", "self", ".", "hidden_loga", ",", "mean", "=", "10", ")", "\n", "logger", ".", "info", "(", "f\"Initialized hidden loga! Prunable_model_size = {self.prunable_model_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_structured_head": [[121, 130], ["l0_module.L0Module.initialize_parameters", "l0_module.L0Module.reset_loga", "l0_module.L0Module.add_one_module", "logger.info"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.add_one_module"], ["", "def", "initialize_structured_head", "(", "self", ",", "add_prunable_model_size", "=", "True", ")", ":", "\n", "        ", "self", ".", "head_loga", "=", "self", ".", "initialize_parameters", "(", "self", ".", "num_attention_heads", ",", "self", ".", "num_hidden_layers", ")", "\n", "self", ".", "reset_loga", "(", "self", ".", "head_loga", ",", "mean", "=", "10", ")", "\n", "self", ".", "add_one_module", "(", "self", ".", "head_loga", ",", "type", "=", "\"head\"", ",", "\n", "parameter_per_dim", "=", "self", ".", "params_per_head", ",", "size", "=", "self", ".", "num_attention_heads", ",", "\n", "shape", "=", "[", "self", ".", "num_hidden_layers", ",", "1", ",", "self", ".", "num_attention_heads", ",", "1", ",", "1", "]", ")", "\n", "if", "add_prunable_model_size", ":", "\n", "            ", "self", ".", "prunable_model_size", "+=", "self", ".", "params_per_head", "*", "self", ".", "num_hidden_layers", "*", "self", ".", "num_attention_heads", "\n", "", "logger", ".", "info", "(", "f\"Initialized structured heads! Prunable_model_size = {self.prunable_model_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialized_layer_structured_heads": [[131, 139], ["l0_module.L0Module.initialize_parameters", "l0_module.L0Module.reset_loga", "l0_module.L0Module.add_one_module", "logger.info"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.add_one_module"], ["", "def", "initialized_layer_structured_heads", "(", "self", ")", ":", "\n", "        ", "n_layer", "=", "self", ".", "num_hidden_layers", "\n", "self", ".", "headlayer_loga", "=", "self", ".", "initialize_parameters", "(", "n_layer", ")", "\n", "self", ".", "reset_loga", "(", "self", ".", "headlayer_loga", ",", "mean", "=", "10", ")", "\n", "self", ".", "add_one_module", "(", "self", ".", "headlayer_loga", ",", "type", "=", "\"head_layer\"", ",", "\n", "parameter_per_dim", "=", "self", ".", "params_per_head", "*", "self", ".", "num_attention_heads", ",", "size", "=", "1", ",", "\n", "shape", "=", "[", "n_layer", "]", ")", "\n", "logger", ".", "info", "(", "f\"Initialized layerwise structured heads! Prunable_model_size = {self.prunable_model_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_structured_mlp": [[140, 149], ["l0_module.L0Module.initialize_parameters", "l0_module.L0Module.add_one_module", "l0_module.L0Module.reset_loga", "logger.info"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.add_one_module", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga"], ["", "def", "initialize_structured_mlp", "(", "self", ")", ":", "\n", "        ", "self", ".", "int_loga", "=", "self", ".", "initialize_parameters", "(", "self", ".", "intermediate_size", ",", "self", ".", "num_hidden_layers", ")", "\n", "\n", "self", ".", "add_one_module", "(", "self", ".", "int_loga", ",", "type", "=", "\"intermediate\"", ",", "\n", "parameter_per_dim", "=", "self", ".", "params_per_intermediate_dim", ",", "size", "=", "self", ".", "intermediate_size", ",", "\n", "shape", "=", "[", "self", ".", "num_hidden_layers", ",", "1", ",", "1", ",", "self", ".", "intermediate_size", "]", ")", "\n", "self", ".", "prunable_model_size", "+=", "self", ".", "params_per_mlp_layer", "*", "self", ".", "num_hidden_layers", "\n", "self", ".", "reset_loga", "(", "self", ".", "int_loga", ")", "\n", "logger", ".", "info", "(", "f\"Initialized structured mlp! Prunable_model_size = {self.prunable_model_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_whole_mlp": [[151, 159], ["l0_module.L0Module.initialize_parameters", "l0_module.L0Module.add_one_module", "l0_module.L0Module.reset_loga", "logger.info"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.initialize_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.add_one_module", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga"], ["", "def", "initialize_whole_mlp", "(", "self", ")", ":", "\n", "        ", "n_layer", "=", "self", ".", "num_hidden_layers", "\n", "self", ".", "intlayer_loga", "=", "self", ".", "initialize_parameters", "(", "n_layer", ")", "\n", "self", ".", "add_one_module", "(", "self", ".", "intlayer_loga", ",", "type", "=", "\"mlp\"", ",", "\n", "parameter_per_dim", "=", "self", ".", "params_per_mlp_layer", ",", "size", "=", "self", ".", "mlp_num_per_layer", ",", "\n", "shape", "=", "[", "n_layer", "]", ")", "\n", "self", ".", "reset_loga", "(", "self", ".", "intlayer_loga", ",", "mean", "=", "10", ")", "\n", "logger", ".", "info", "(", "f\"Initialized whole mlps! Prunable_model_size = {self.prunable_model_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga": [[161, 165], ["tensor.data.normal_", "math.log", "math.log"], "methods", ["None"], ["", "def", "reset_loga", "(", "self", ",", "tensor", ",", "mean", "=", "None", ")", ":", "\n", "        ", "if", "mean", "is", "None", ":", "\n", "            ", "mean", "=", "math", ".", "log", "(", "1", "-", "self", ".", "droprate_init", ")", "-", "math", ".", "log", "(", "self", ".", "droprate_init", ")", "\n", "", "tensor", ".", "data", ".", "normal_", "(", "mean", ",", "1e-2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_qz_logas": [[166, 172], ["l0_module.L0Module.reset_loga", "l0_module.L0Module.reset_loga"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.reset_loga"], ["", "def", "reset_qz_logas", "(", "self", ")", ":", "\n", "        ", "for", "key", "in", "self", ".", "z_logas", ":", "\n", "            ", "if", "key", "in", "[", "\"head_layer\"", ",", "\"mlp\"", ",", "\"head\"", "]", ":", "\n", "                ", "self", ".", "reset_loga", "(", "self", ".", "z_logas", "[", "key", "]", ",", "10", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "reset_loga", "(", "self", ".", "z_logas", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.constrain_parameters": [[173, 178], ["tensor.data.clamp_", "l0_module.L0Module.constrain_parameters._constrain"], "methods", ["None"], ["", "", "", "def", "constrain_parameters", "(", "self", ")", ":", "\n", "        ", "def", "_constrain", "(", "tensor", ")", ":", "\n", "            ", "tensor", ".", "data", ".", "clamp_", "(", "min", "=", "math", ".", "log", "(", "1e-2", ")", ",", "max", "=", "math", ".", "log", "(", "1e2", ")", ")", "\n", "", "for", "key", "in", "self", ".", "z_logas", ":", "\n", "            ", "_constrain", "(", "self", ".", "z_logas", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz": [[179, 184], ["torch.sigmoid().clamp", "torch.sigmoid().clamp", "torch.sigmoid().clamp", "torch.sigmoid().clamp", "math.log", "math.log", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "", "def", "cdf_qz", "(", "self", ",", "x", ",", "loga", ")", ":", "\n", "        ", "\"\"\"Implements the CDF of the 'stretched' concrete distribution\"\"\"", "\n", "xn", "=", "(", "x", "-", "limit_a", ")", "/", "(", "limit_b", "-", "limit_a", ")", "\n", "logits", "=", "math", ".", "log", "(", "xn", ")", "-", "math", ".", "log", "(", "1", "-", "xn", ")", "\n", "return", "torch", ".", "sigmoid", "(", "logits", "*", "self", ".", "temperature", "-", "loga", ")", ".", "clamp", "(", "min", "=", "epsilon", ",", "max", "=", "1", "-", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.quantile_concrete": [[185, 188], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "quantile_concrete", "(", "self", ",", "x", ",", "loga", ")", ":", "\n", "        ", "y", "=", "torch", ".", "sigmoid", "(", "(", "torch", ".", "log", "(", "x", ")", "-", "torch", ".", "log", "(", "1", "-", "x", ")", "+", "loga", ")", "/", "self", ".", "temperature", ")", "\n", "return", "y", "*", "(", "limit_b", "-", "limit_a", ")", "+", "limit_a", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_num_parameters_for_one": [[189, 191], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "l0_module.L0Module.cdf_qz"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz"], ["", "def", "get_num_parameters_for_one", "(", "self", ",", "loga", ",", "parameter_size", ")", ":", "\n", "        ", "return", "torch", ".", "sum", "(", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "loga", ")", ")", "*", "parameter_size", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.transform_scores_for_head": [[192, 206], ["head_score.unsqueeze.unsqueeze.unsqueeze", "l0_module.L0Module.cdf_qz", "all_head_score.view.view.view", "l0_module.L0Module.cdf_qz"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz"], ["", "def", "transform_scores_for_head", "(", "self", ")", ":", "\n", "        ", "assert", "\"head\"", "in", "self", ".", "types", "\n", "\n", "if", "\"head_layer\"", "in", "self", ".", "types", ":", "\n", "            ", "all_head_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "headlayer_loga", ")", "\n", "", "else", ":", "\n", "            ", "all_head_score", "=", "None", "\n", "", "head_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "head_loga", ")", "# 12 * 12", "\n", "\n", "if", "all_head_score", "is", "not", "None", ":", "\n", "            ", "all_head_score", "=", "all_head_score", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "# 12 * 1 * 1", "\n", "", "head_score", "=", "head_score", ".", "unsqueeze", "(", "-", "1", ")", "# 12 * 12 * 1", "\n", "\n", "return", "all_head_score", ",", "head_score", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_num_parameters_for_mlp": [[207, 214], ["intlayer_score.unsqueeze.unsqueeze.unsqueeze", "l0_module.L0Module.cdf_qz", "l0_module.L0Module.cdf_qz", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz"], ["", "def", "get_num_parameters_for_mlp", "(", "self", ")", ":", "\n", "        ", "intlayer_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "intlayer_loga", ")", "# 12", "\n", "int_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "int_loga", ")", "# 12 * 3072", "\n", "intlayer_score", "=", "intlayer_score", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "num_parameters", "=", "torch", ".", "sum", "(", "intlayer_score", "*", "int_score", ")", "*", "self", ".", "parameters_per_dim", "[", "\"intermediate\"", "]", "\n", "return", "num_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_num_parameters_and_constraint_for_hidden": [[215, 237], ["l0_module.L0Module.transform_scores_for_head", "intlayer_score.unsqueeze.unsqueeze.unsqueeze", "l0_module.L0Module.cdf_qz", "head_score.reshape.reshape.reshape", "l0_module.L0Module.cdf_qz", "l0_module.L0Module.cdf_qz", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.outer", "torch.outer", "torch.outer", "torch.outer", "torch.outer", "torch.outer", "torch.outer", "torch.outer"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.transform_scores_for_head", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz"], ["", "def", "get_num_parameters_and_constraint_for_hidden", "(", "self", ")", ":", "\n", "        ", "num_parameters", "=", "0", "\n", "\n", "# 12 * 1 * 1", "\n", "# 12 * 12 * 1", "\n", "all_head_score", ",", "head_score", "=", "self", ".", "transform_scores_for_head", "(", ")", "\n", "hidden_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "hidden_loga", ")", "# 768", "\n", "\n", "if", "all_head_score", "is", "not", "None", ":", "\n", "            ", "head_score", "=", "(", "all_head_score", "*", "head_score", ")", ".", "reshape", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "head_score", "=", "head_score", ".", "reshape", "(", "-", "1", ")", "\n", "", "num_parameters", "+=", "torch", ".", "sum", "(", "torch", ".", "outer", "(", "hidden_score", ",", "head_score", ")", ")", "*", "self", ".", "parameters_per_dim", "[", "\"head\"", "]", "/", "self", ".", "hidden_size", "\n", "\n", "intlayer_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "intlayer_loga", ")", "# 12", "\n", "int_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "int_loga", ")", "# 12 * 3072", "\n", "intlayer_score", "=", "intlayer_score", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "int_score", "=", "(", "intlayer_score", "*", "int_score", ")", ".", "reshape", "(", "-", "1", ")", "\n", "num_parameters", "+=", "torch", ".", "sum", "(", "torch", ".", "outer", "(", "hidden_score", ",", "int_score", ")", ")", "*", "2", "\n", "return", "num_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_num_parameters_and_constraint": [[239, 254], ["l0_module.L0Module.transform_scores_for_head", "intlayer_score.unsqueeze.unsqueeze.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "l0_module.L0Module.cdf_qz", "l0_module.L0Module.cdf_qz", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.transform_scores_for_head", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz"], ["", "def", "get_num_parameters_and_constraint", "(", "self", ")", ":", "\n", "        ", "num_parameters", "=", "0", "\n", "\n", "all_head_score", ",", "head_score", "=", "self", ".", "transform_scores_for_head", "(", ")", "\n", "\n", "head_score", "=", "head_score", "*", "all_head_score", "\n", "num_parameters", "+=", "torch", ".", "sum", "(", "head_score", ")", "*", "self", ".", "parameters_per_dim", "[", "\"head\"", "]", "\n", "\n", "intlayer_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "intlayer_loga", ")", "# 12", "\n", "int_score", "=", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "self", ".", "int_loga", ")", "# 12 * 3072", "\n", "intlayer_score", "=", "intlayer_score", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "int_score", "=", "int_score", "*", "intlayer_score", "\n", "num_parameters", "+=", "torch", ".", "sum", "(", "int_score", ")", "*", "self", ".", "parameters_per_dim", "[", "\"intermediate\"", "]", "\n", "return", "num_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_target_sparsity": [[256, 259], ["min"], "methods", ["None"], ["", "def", "get_target_sparsity", "(", "self", ",", "pruned_steps", ")", ":", "\n", "        ", "target_sparsity", "=", "(", "self", ".", "target_sparsity", "-", "self", ".", "start_sparsity", ")", "*", "min", "(", "1", ",", "pruned_steps", "/", "self", ".", "lagrangian_warmup", ")", "+", "self", ".", "start_sparsity", "\n", "return", "target_sparsity", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.lagrangian_regularization": [[261, 275], ["l0_module.L0Module.get_num_parameters_and_constraint_for_hidden", "l0_module.L0Module.get_num_parameters_and_constraint", "l0_module.L0Module.get_target_sparsity"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_num_parameters_and_constraint_for_hidden", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_num_parameters_and_constraint", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_target_sparsity"], ["", "def", "lagrangian_regularization", "(", "self", ",", "pruned_steps", ")", ":", "\n", "        ", "target_sparsity", "=", "self", ".", "target_sparsity", "\n", "if", "\"hidden\"", "in", "self", ".", "types", ":", "\n", "            ", "expected_size", "=", "self", ".", "get_num_parameters_and_constraint_for_hidden", "(", ")", "\n", "", "else", ":", "\n", "            ", "expected_size", "=", "self", ".", "get_num_parameters_and_constraint", "(", ")", "\n", "", "expected_sparsity", "=", "1", "-", "expected_size", "/", "self", ".", "prunable_model_size", "\n", "if", "self", ".", "lagrangian_warmup", ">", "0", ":", "\n", "            ", "target_sparsity", "=", "self", ".", "get_target_sparsity", "(", "pruned_steps", ")", "\n", "", "lagrangian_loss", "=", "(", "\n", "self", ".", "lambda_1", "*", "(", "expected_sparsity", "-", "target_sparsity", ")", "\n", "+", "self", ".", "lambda_2", "*", "(", "expected_sparsity", "-", "target_sparsity", ")", "**", "2", "\n", ")", "\n", "return", "lagrangian_loss", ",", "expected_sparsity", ",", "target_sparsity", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_eps": [[276, 281], ["torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.FloatTensor().uniform_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "get_eps", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"Uniform random numbers for the concrete distribution\"\"\"", "\n", "eps", "=", "torch", ".", "FloatTensor", "(", "size", ")", ".", "uniform_", "(", "epsilon", ",", "1", "-", "epsilon", ")", "\n", "eps", "=", "Variable", "(", "eps", ")", "\n", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module._sample_z": [[283, 288], ["l0_module.L0Module.get_eps().to", "l0_module.L0Module.quantile_concrete", "torch.hardtanh", "torch.hardtanh", "l0_module.L0Module.get_eps", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.quantile_concrete", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_eps"], ["", "def", "_sample_z", "(", "self", ",", "loga", ")", ":", "\n", "        ", "eps", "=", "self", ".", "get_eps", "(", "torch", ".", "FloatTensor", "(", "*", "loga", ".", "shape", ")", ")", ".", "to", "(", "loga", ".", "device", ")", "\n", "z", "=", "self", ".", "quantile_concrete", "(", "eps", ",", "loga", ")", "\n", "z", "=", "F", ".", "hardtanh", "(", "z", ",", "min_val", "=", "0", ",", "max_val", "=", "1", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module._deterministic_z": [[290, 306], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sum.item", "torch.sum.item", "round", "l0_module.L0Module.cdf_qz", "pdb.set_trace", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.cdf_qz"], ["", "def", "_deterministic_z", "(", "self", ",", "size", ",", "loga", ")", ":", "\n", "# Following https://github.com/asappresearch/flop/blob/e80e47155de83abbe7d90190e00d30bfb85c18d5/flop/hardconcrete.py#L8 line 103", "\n", "        ", "expected_num_nonzeros", "=", "torch", ".", "sum", "(", "1", "-", "self", ".", "cdf_qz", "(", "0", ",", "loga", ")", ")", "\n", "expected_num_zeros", "=", "size", "-", "expected_num_nonzeros", ".", "item", "(", ")", "\n", "try", ":", "\n", "            ", "num_zeros", "=", "round", "(", "expected_num_zeros", ")", "\n", "", "except", ":", "\n", "            ", "pdb", ".", "set_trace", "(", ")", "\n", "", "soft_mask", "=", "torch", ".", "sigmoid", "(", "loga", "/", "self", ".", "temperature", "*", "self", ".", "magical_number", ")", "\n", "if", "num_zeros", ">", "0", ":", "\n", "            ", "if", "soft_mask", ".", "ndim", "==", "0", ":", "\n", "                ", "soft_mask", "=", "torch", ".", "tensor", "(", "0", ")", ".", "to", "(", "loga", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "_", ",", "indices", "=", "torch", ".", "topk", "(", "soft_mask", ",", "k", "=", "num_zeros", ",", "largest", "=", "False", ")", "\n", "soft_mask", "[", "indices", "]", "=", "0.", "\n", "", "", "return", "soft_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_z_from_zs": [[307, 316], ["zs.get", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "numpy.ones", "zs.get.squeeze().detach().cpu().numpy", "zs.get.squeeze().detach().cpu", "zs.get.squeeze().detach", "zs.get.squeeze"], "methods", ["None"], ["", "def", "get_z_from_zs", "(", "self", ",", "zs", ")", ":", "\n", "        ", "numpified_zs", "=", "{", "}", "\n", "for", "type", "in", "self", ".", "all_types", ":", "\n", "            ", "name", "=", "type", "[", ":", "-", "2", "]", "\n", "z", "=", "zs", ".", "get", "(", "type", ",", "np", ".", "ones", "(", "self", ".", "shapes", "[", "name", "]", ")", ")", "\n", "if", "torch", ".", "is_tensor", "(", "z", ")", ":", "\n", "                ", "new_z", "=", "z", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0", "\n", "", "numpified_zs", "[", "name", "]", "=", "new_z", "\n", "", "return", "numpified_zs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.calculate_model_size": [[317, 347], ["l0_module.L0Module.get_z_from_zs", "numpified_zs[].reshape", "numpified_zs[].reshape", "hidden_z.sum().item", "intermediate_z.reshape().sum().tolist", "head_z.reshape().sum().tolist", "numpy.outer().sum().item", "numpy.outer().sum().item", "numpified_zs[].reshape.reshape().astype().tolist", "numpified_zs[].reshape.reshape().astype().tolist", "hidden_z.sum", "intermediate_z.reshape().sum", "head_z.reshape().sum", "numpy.outer().sum", "numpy.outer().sum", "numpified_zs[].reshape.reshape().astype", "numpified_zs[].reshape.reshape().astype", "intermediate_z.reshape", "head_z.reshape", "numpy.outer", "numpy.outer", "numpified_zs[].reshape.reshape", "numpified_zs[].reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.get_z_from_zs"], ["", "def", "calculate_model_size", "(", "self", ",", "zs", ")", ":", "\n", "        ", "numpified_zs", "=", "self", ".", "get_z_from_zs", "(", "zs", ")", "\n", "hidden_z", "=", "numpified_zs", "[", "\"hidden\"", "]", "\n", "intermediate_z", "=", "numpified_zs", "[", "\"intermediate\"", "]", "\n", "mlp_z", "=", "numpified_zs", "[", "\"mlp\"", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "head_z", "=", "numpified_zs", "[", "\"head\"", "]", "\n", "head_layer_z", "=", "numpified_zs", "[", "\"head_layer\"", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "remaining_hidden_dims", "=", "hidden_z", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "remaining_intermediate_nums", "=", "intermediate_z", ".", "reshape", "(", "self", ".", "num_hidden_layers", ",", "self", ".", "intermediate_size", ")", ".", "sum", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "remaining_head_nums", "=", "head_z", ".", "reshape", "(", "self", ".", "num_hidden_layers", ",", "self", ".", "num_attention_heads", ")", ".", "sum", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "head_nums", "=", "np", ".", "outer", "(", "(", "head_z", "*", "head_layer_z", ")", ".", "reshape", "(", "-", "1", ")", ",", "hidden_z", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "intermediate_nums", "=", "np", ".", "outer", "(", "(", "intermediate_z", "*", "mlp_z", ")", ".", "reshape", "(", "-", "1", ")", ",", "hidden_z", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "remaining_model_size", "=", "head_nums", "*", "self", ".", "dim_per_head", "*", "4", "+", "intermediate_nums", "*", "2", "\n", "pruned_model_size", "=", "self", ".", "prunable_model_size", "-", "remaining_model_size", "\n", "\n", "results", "=", "{", "}", "\n", "# Not multiplied with each other", "\n", "results", "[", "\"head_layers\"", "]", "=", "head_layer_z", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "int", ")", ".", "tolist", "(", ")", "\n", "results", "[", "\"mlp_layers\"", "]", "=", "mlp_z", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "int", ")", ".", "tolist", "(", ")", "\n", "results", "[", "\"hidden_dims\"", "]", "=", "remaining_hidden_dims", "\n", "results", "[", "\"intermediate_dims\"", "]", "=", "remaining_intermediate_nums", "\n", "results", "[", "\"head_nums\"", "]", "=", "remaining_head_nums", "\n", "results", "[", "\"pruned_params\"", "]", "=", "pruned_model_size", "\n", "results", "[", "\"remaining_params\"", "]", "=", "remaining_model_size", "\n", "results", "[", "\"pruned_model_sparsity\"", "]", "=", "pruned_model_size", "/", "self", ".", "prunable_model_size", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.forward": [[357, 381], ["enumerate", "enumerate", "l0_module.L0Module._sample_z", "l0_module.L0Module.reshape", "range", "l0_module.L0Module._deterministic_z", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "l0_module.L0Module._deterministic_z", "zs[].append", "l0_module.L0Module.reshape"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module._sample_z", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module._deterministic_z", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module._deterministic_z"], ["", "def", "forward", "(", "self", ",", "training", "=", "True", ",", ")", ":", "\n", "        ", "zs", "=", "{", "f\"{type}_z\"", ":", "[", "]", "for", "type", "in", "self", ".", "types", "}", "\n", "\n", "if", "training", ":", "\n", "            ", "for", "i", ",", "type", "in", "enumerate", "(", "self", ".", "types", ")", ":", "\n", "                ", "loga", "=", "self", ".", "z_logas", "[", "type", "]", "\n", "z", "=", "self", ".", "_sample_z", "(", "loga", ")", "\n", "zs", "[", "f\"{type}_z\"", "]", "=", "z", ".", "reshape", "(", "self", ".", "shapes", "[", "type", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", ",", "type", "in", "enumerate", "(", "self", ".", "types", ")", ":", "\n", "                ", "if", "type", "!=", "\"hidden\"", ":", "# hidden is not a per layer sample", "\n", "                    ", "loga_all_layers", "=", "self", ".", "z_logas", "[", "type", "]", "\n", "for", "layer", "in", "range", "(", "len", "(", "loga_all_layers", ")", ")", ":", "\n", "                        ", "loga", "=", "loga_all_layers", "[", "layer", "]", "\n", "size", "=", "self", ".", "sizes", "[", "type", "]", "\n", "z", "=", "self", ".", "_deterministic_z", "(", "size", ",", "loga", ")", "\n", "zs", "[", "f\"{type}_z\"", "]", ".", "append", "(", "z", ".", "reshape", "(", "self", ".", "shapes", "[", "type", "]", "[", "1", ":", "]", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "z", "=", "self", ".", "_deterministic_z", "(", "self", ".", "sizes", "[", "type", "]", ",", "self", ".", "hidden_loga", ")", "\n", "zs", "[", "f\"{type}_z\"", "]", "=", "z", "\n", "", "", "for", "type", "in", "zs", ":", "\n", "                ", "if", "type", "!=", "\"hidden_z\"", ":", "\n", "                    ", "zs", "[", "type", "]", "=", "torch", ".", "stack", "(", "zs", "[", "type", "]", ")", "\n", "", "", "", "return", "zs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.CoFiRobertaForSequenceClassification.__init__": [[60, 81], ["RobertaForSequenceClassification.__init__", "modeling_roberta.NewRobertaModel", "getattr", "getattr", "getattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "roberta", "=", "NewRobertaModel", "(", "config", ")", "\n", "\n", "self", ".", "do_layer_distill", "=", "getattr", "(", "config", ",", "\"do_layer_distill\"", ",", "False", ")", "\n", "self", ".", "do_emb_distill", "=", "getattr", "(", "config", ",", "\"do_emb_distill\"", ",", "False", ")", "\n", "self", ".", "do_mha_layer_distill", "=", "getattr", "(", "config", ",", "\"do_mha_layer_distill\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "do_mha_layer_distill", ":", "\n", "            ", "self", ".", "mha_layer_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "mha_layer_transformation", "=", "None", "\n", "\n", "", "if", "self", ".", "do_layer_distill", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "None", "\n", "", "if", "self", ".", "do_emb_distill", ":", "\n", "            ", "self", ".", "emb_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "emb_transformation", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.CoFiRobertaForSequenceClassification.forward": [[82, 154], ["modeling_roberta.CoFiRobertaForSequenceClassification.roberta", "modeling_roberta.CoFiRobertaForSequenceClassification.classifier", "transformers.modeling_outputs.SequenceClassifierOutput", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.CoFiRobertaForSequenceClassification.view", "labels.view", "modeling_roberta.CoFiRobertaForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "logging", "=", "False", ",", "\n", "dims_boundary", "=", "None", ",", "\n", "ov_dims_boundary", "=", "None", ",", "\n", "qk_z", "=", "None", ",", "\n", "vo_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "inference", "=", "False", ",", "\n", "hidden_z", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "logging", "=", "logging", ",", "\n", "dims_boundary", "=", "dims_boundary", ",", "\n", "ov_dims_boundary", "=", "ov_dims_boundary", ",", "\n", "qk_z", "=", "qk_z", ",", "\n", "vo_z", "=", "vo_z", ",", "\n", "intermediate_z", "=", "intermediate_z", ",", "\n", "head_z", "=", "head_z", ",", "\n", "mlp_z", "=", "mlp_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "inference", "=", "inference", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.CoFiRobertaForSequenceClassification.prune_indices": [[157, 171], ["modeling_roberta.CoFiRobertaForSequenceClassification.base_model._prune_indices"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaModel._prune_indices"], ["", "def", "prune_indices", "(", "self", ",", "indices_to_prune", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", ",", "vo_indices_to_prune", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "q_input_index", "=", "None", ",", "k_input_index", "=", "None", ",", "\n", "v_input_index", "=", "None", ",", "o_output_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Prunes heads of the base model.\n\n        Arguments:\n            heads_to_prune (:obj:`Dict[int, List[int]]`):\n                Dictionary with keys being selected layer indices (:obj:`int`) and associated values being the list\n                of heads to prune in said layer (list of :obj:`int`). For instance {1: [0, 2], 2: [2, 3]} will\n                prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n        \"\"\"", "\n", "self", ".", "base_model", ".", "_prune_indices", "(", "indices_to_prune", ",", "vo_indices_to_prune", ",", "q_input_index", ",", "k_input_index", ",", "\n", "v_input_index", ",", "o_output_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaBertForMaskedLM.__init__": [[174, 195], ["RobertaForMaskedLM.__init__", "modeling_roberta.NewRobertaModel", "getattr", "getattr", "getattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "roberta", "=", "NewRobertaModel", "(", "config", ")", "\n", "\n", "self", ".", "do_layer_distill", "=", "getattr", "(", "config", ",", "\"do_layer_distill\"", ",", "False", ")", "\n", "self", ".", "do_emb_distill", "=", "getattr", "(", "config", ",", "\"do_emb_distill\"", ",", "False", ")", "\n", "self", ".", "do_mha_layer_distill", "=", "getattr", "(", "config", ",", "\"do_mha_layer_distill\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "do_mha_layer_distill", ":", "\n", "            ", "self", ".", "mha_layer_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "mha_layer_transformation", "=", "None", "\n", "\n", "", "if", "self", ".", "do_layer_distill", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "None", "\n", "", "if", "self", ".", "do_emb_distill", ":", "\n", "            ", "self", ".", "emb_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "emb_transformation", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaBertForMaskedLM.forward": [[196, 270], ["modeling_roberta.NewRobertaBertForMaskedLM.bert", "modeling_roberta.NewRobertaBertForMaskedLM.lm_head", "MaskedLMOutput", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.NewRobertaBertForMaskedLM.view", "labels.view"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "logging", "=", "False", ",", "\n", "dims_boundary", "=", "None", ",", "\n", "ov_dims_boundary", "=", "None", ",", "\n", "qk_z", "=", "None", ",", "\n", "vo_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "inference", "=", "False", ",", "\n", "hidden_z", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the sequence classification/regression loss.\n            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n            If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "logging", "=", "logging", ",", "\n", "dims_boundary", "=", "dims_boundary", ",", "\n", "ov_dims_boundary", "=", "ov_dims_boundary", ",", "\n", "qk_z", "=", "qk_z", ",", "\n", "vo_z", "=", "vo_z", ",", "\n", "intermediate_z", "=", "intermediate_z", ",", "\n", "head_z", "=", "head_z", ",", "\n", "mlp_z", "=", "mlp_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "inference", "=", "inference", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "masked_lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "# -100 index = padding token", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "prediction_scores", "=", "prediction_scores", "[", "labels", "!=", "-", "100", "]", "\n", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "masked_lm_loss", ",", ")", "+", "output", ")", "if", "masked_lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "MaskedLMOutput", "(", "\n", "loss", "=", "masked_lm_loss", ",", "\n", "logits", "=", "prediction_scores", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaBertForMaskedLM.prune_indices": [[272, 286], ["modeling_roberta.NewRobertaBertForMaskedLM.base_model._prune_indices"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaModel._prune_indices"], ["", "def", "prune_indices", "(", "self", ",", "indices_to_prune", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", ",", "vo_indices_to_prune", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "q_input_index", "=", "None", ",", "k_input_index", "=", "None", ",", "\n", "v_input_index", "=", "None", ",", "o_output_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Prunes heads of the base model.\n\n        Arguments:\n            heads_to_prune (:obj:`Dict[int, List[int]]`):\n                Dictionary with keys being selected layer indices (:obj:`int`) and associated values being the list\n                of heads to prune in said layer (list of :obj:`int`). For instance {1: [0, 2], 2: [2, 3]} will\n                prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n        \"\"\"", "\n", "self", ".", "base_model", ".", "_prune_indices", "(", "indices_to_prune", ",", "vo_indices_to_prune", ",", "q_input_index", ",", "k_input_index", ",", "\n", "v_input_index", ",", "o_output_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaEmbeddings.__init__": [[291, 294], ["RobertaEmbeddings.__init__", "BertLayerNorm"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaEmbeddings.forward": [[295, 331], ["modeling_roberta.NewRobertaEmbeddings.position_embeddings", "modeling_roberta.NewRobertaEmbeddings.token_type_embeddings", "modeling_roberta.NewRobertaEmbeddings.LayerNorm", "modeling_roberta.NewRobertaEmbeddings.dropout", "input_ids.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "modeling_roberta.NewRobertaEmbeddings.word_embeddings", "embeddings.mul.mul.mul", "embeddings.mul.mul.mul", "create_position_ids_from_input_ids().to", "modeling_roberta.NewRobertaEmbeddings.create_position_ids_from_inputs_embeds", "modeling_roberta.NewRobertaEmbeddings.size", "create_position_ids_from_input_ids"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ",", "hidden_z", "=", "None", ")", ":", "\n", "        ", "if", "position_ids", "is", "None", ":", "\n", "            ", "if", "input_ids", "is", "not", "None", ":", "\n", "# Create the position ids from the input token ids. Any padded tokens remain padded.", "\n", "                ", "position_ids", "=", "create_position_ids_from_input_ids", "(", "input_ids", ",", "self", ".", "padding_idx", ")", ".", "to", "(", "input_ids", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "position_ids", "=", "self", ".", "create_position_ids_from_inputs_embeds", "(", "inputs_embeds", ")", "\n", "\n", "# Copied from transformers.modeling_bert.BertEmbeddings.forward", "\n", "", "", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "self", ".", "position_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "position_ids", ".", "device", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "            ", "embeddings", "=", "embeddings", ".", "mul", "(", "hidden_z", ")", "\n", "", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ",", "hidden_z", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "            ", "embeddings", "=", "embeddings", ".", "mul", "(", "hidden_z", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaModel.__init__": [[334, 341], ["RobertaModel.__init__", "modeling_roberta.NewRobertaEncoder", "modeling_roberta.NewRobertaEmbeddings", "getattr", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "encoder", "=", "NewRobertaEncoder", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "NewRobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "embedding_transformer", "=", "None", "\n", "if", "getattr", "(", "config", ",", "\"transform_embedding\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "embedding_transformer", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaModel.forward": [[342, 450], ["modeling_roberta.NewRobertaModel.get_extended_attention_mask", "modeling_roberta.NewRobertaModel.get_head_mask", "modeling_roberta.NewRobertaModel.embeddings", "modeling_roberta.NewRobertaModel.encoder", "modeling_roberta.NewRobertaModel.pooler", "modeling_roberta.NewBaseModelOutputWithPooling", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "encoder_hidden_states.size", "modeling_roberta.NewRobertaModel.invert_attention_mask", "modeling_roberta.NewRobertaModel.embedding_transformer", "input_ids.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ValueError", "inputs_embeds.size"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "logging", "=", "False", ",", "\n", "qk_z", "=", "None", ",", "\n", "vo_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "dims_boundary", "=", "None", ",", "\n", "ov_dims_boundary", "=", "None", ",", "\n", "inference", "=", "False", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "\n", "        ", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "extended_attention_mask", ":", "torch", ".", "Tensor", "=", "self", ".", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "device", ")", "\n", "\n", "# If a 2D or 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_hidden_layers", ")", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "if", "self", ".", "embedding_transformer", "is", "not", "None", ":", "\n", "            ", "embedding_output", "=", "self", ".", "embedding_transformer", "(", "embedding_output", ")", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "qk_z", "=", "qk_z", ",", "\n", "vo_z", "=", "vo_z", ",", "\n", "intermediate_z", "=", "intermediate_z", ",", "\n", "head_z", "=", "head_z", ",", "\n", "mlp_z", "=", "mlp_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "inference", "=", "inference", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "# self.encoder_outputs = encoder_outputs", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "\n", "", "return", "NewBaseModelOutputWithPooling", "(", "\n", "last_hidden_state", "=", "sequence_output", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", "attention_layers", "=", "encoder_outputs", ".", "attention_layers", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaModel._prune_indices": [[452, 465], ["qk_indice_to_prune.items", "modeling_roberta.NewRobertaModel.encoder.layer[].attention.prune_indices"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaAttention.prune_indices"], ["", "def", "_prune_indices", "(", "self", ",", "qk_indice_to_prune", ",", "vo_indice_to_prune", "=", "None", ",", "q_input_index", "=", "None", ",", "k_input_index", "=", "None", ",", "\n", "v_input_index", "=", "None", ",", "o_output_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"Prunes heads of the model.\n        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "indices", "in", "qk_indice_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "qk_indices", "=", "indices", "\n", "if", "vo_indice_to_prune", "is", "not", "None", ":", "\n", "                ", "vo_indices", "=", "vo_indice_to_prune", "[", "layer", "]", "\n", "", "else", ":", "\n", "                ", "vo_indices", "=", "None", "\n", "", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_indices", "(", "qk_indices", ",", "vo_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaEncoder.__init__": [[468, 471], ["RobertaEncoder.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_roberta.NewRobertaLayer", "range"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "NewRobertaLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaEncoder.forward": [[472, 550], ["enumerate", "modeling_roberta.NewBaseModelOutput", "getattr", "tuple", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "layer_module", "modeling_roberta.NewRobertaEncoder.forward.create_custom_forward"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "return_dict", "=", "False", ",", "\n", "dims_boundary", "=", "None", ",", "\n", "ov_dims_boundary", "=", "None", ",", "\n", "qk_z", "=", "None", ",", "\n", "vo_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "inference", "=", "False", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_attention_outputs", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_head_mask", "=", "head_mask", "[", "i", "]", "if", "head_mask", "is", "not", "None", "else", "None", "\n", "\n", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", ":", "\n", "\n", "                ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                    ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                        ", "return", "module", "(", "*", "inputs", ",", "output_attentions", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "layer_module", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", ",", "\n", "dims_boundary", "=", "dims_boundary", "[", "i", "]", "if", "dims_boundary", "is", "not", "None", "else", "None", ",", "\n", "ov_dims_boundary", "=", "ov_dims_boundary", "[", "i", "]", "if", "ov_dims_boundary", "is", "not", "None", "else", "None", ",", "\n", "qk_z", "=", "qk_z", "[", "i", "]", "if", "qk_z", "is", "not", "None", "else", "None", ",", "\n", "vo_z", "=", "vo_z", "[", "i", "]", "if", "vo_z", "is", "not", "None", "else", "None", ",", "\n", "intermediate_z", "=", "intermediate_z", "[", "i", "]", "if", "intermediate_z", "is", "not", "None", "else", "None", ",", "\n", "head_z", "=", "head_z", "[", "i", "]", "if", "head_z", "is", "not", "None", "else", "None", ",", "\n", "mlp_z", "=", "mlp_z", "[", "i", "]", "if", "mlp_z", "is", "not", "None", "else", "None", ",", "\n", "head_layer_z", "=", "head_layer_z", "[", "i", "]", "if", "head_layer_z", "is", "not", "None", "else", "None", ",", "\n", "inference", "=", "inference", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "all_attention_outputs", "=", "all_attention_outputs", "+", "(", "layer_outputs", "[", "2", "]", ",", ")", "\n", "\n", "", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "\n", "v", "for", "v", "in", "[", "hidden_states", ",", "all_hidden_states", ",", "all_attentions", ",", "all_attention_outputs", "]", "if", "v", "is", "not", "None", ")", "\n", "", "return", "NewBaseModelOutput", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "hidden_states", "=", "all_hidden_states", ",", "attentions", "=", "all_attentions", ",", "\n", "attention_layers", "=", "all_attention_outputs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaLayer.__init__": [[554, 559], ["RobertaLayer.__init__", "modeling_roberta.NewRobertaAttention", "modeling_roberta.NewRobertaOutput"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attention", "=", "NewRobertaAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "NewRobertaOutput", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaLayer.forward": [[560, 612], ["modeling_roberta.NewRobertaLayer.attention", "transformers.modeling_utils.apply_chunking_to_forward"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "dims_boundary", "=", "None", ",", "\n", "ov_dims_boundary", "=", "None", ",", "\n", "qk_z", "=", "None", ",", "\n", "vo_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "inference", "=", "False", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "dims_boundary", "=", "dims_boundary", ",", "\n", "ov_dims_boundary", "=", "ov_dims_boundary", ",", "\n", "qk_z", "=", "qk_z", ",", "\n", "vo_z", "=", "vo_z", ",", "\n", "head_z", "=", "head_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "inference", "=", "inference", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n", "# self.attention_output = attention_output", "\n", "\n", "if", "self", ".", "intermediate", ".", "dense", "is", "None", ":", "\n", "            ", "layer_output", "=", "attention_output", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_z", "=", "intermediate_z", "\n", "self", ".", "mlp_z", "=", "mlp_z", "\n", "self", ".", "inference", "=", "inference", "\n", "self", ".", "hidden_z", "=", "hidden_z", "\n", "layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", "\n", ")", "\n", "# self.layer_output = layer_output", "\n", "", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "+", "(", "attention_output", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaLayer.feed_forward_chunk": [[613, 620], ["modeling_roberta.NewRobertaLayer.intermediate", "modeling_roberta.NewRobertaLayer.output", "intermediate_output.mul.mul.mul"], "methods", ["None"], ["", "def", "feed_forward_chunk", "(", "self", ",", "attention_output", ")", ":", "\n", "        ", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "if", "self", ".", "intermediate_z", "is", "not", "None", ":", "\n", "            ", "intermediate_output", "=", "intermediate_output", ".", "mul", "(", "self", ".", "intermediate_z", ")", "\n", "", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "self", ".", "mlp_z", ",", "self", ".", "hidden_z", ",", "\n", "inference", "=", "self", ".", "inference", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaAttention.__init__": [[623, 629], ["RobertaAttention.__init__", "modeling_roberta.NewRobertaSelfAttention", "modeling_roberta.NewRobertaSelfOutput"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "self", "=", "NewRobertaSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "NewRobertaSelfOutput", "(", "config", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaAttention.prune_indices": [[630, 655], ["isinstance", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "isinstance", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "len", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "type", "type"], "methods", ["None"], ["", "def", "prune_indices", "(", "self", ",", "qk_index", ",", "vo_index", "=", "None", ")", ":", "\n", "\n", "        ", "if", "type", "(", "qk_index", ")", "==", "list", "or", "isinstance", "(", "qk_index", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "qk_index", "=", "torch", ".", "LongTensor", "(", "qk_index", ")", "\n", "\n", "", "if", "type", "(", "vo_index", ")", "==", "list", "or", "isinstance", "(", "vo_index", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "vo_index", "=", "torch", ".", "LongTensor", "(", "vo_index", ")", "\n", "\n", "", "if", "vo_index", "is", "None", ":", "\n", "            ", "vo_index", "=", "qk_index", "\n", "\n", "# Prune linear layers", "\n", "", "if", "len", "(", "qk_index", ")", "==", "0", ":", "\n", "            ", "self", ".", "self", ".", "query", "=", "None", "\n", "self", ".", "self", ".", "key", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "qk_index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "qk_index", ")", "\n", "\n", "", "if", "len", "(", "vo_index", ")", "==", "0", ":", "\n", "            ", "self", ".", "self", ".", "value", "=", "None", "\n", "self", ".", "output", ".", "dense", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "vo_index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "vo_index", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaAttention.prune_heads": [[661, 686], ["len", "transformers.modeling_utils.find_pruneable_heads_and_indices", "modeling_roberta.NewRobertaAttention.pruned_heads.union", "len", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "len"], "methods", ["None"], ["", "", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "len_heads", "=", "len", "(", "heads", ")", "\n", "if", "len_heads", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "\n", "heads", ",", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ",", "self", ".", "pruned_heads", "\n", ")", "\n", "\n", "# Prune linear layers", "\n", "if", "len", "(", "index", ")", "==", "0", ":", "\n", "            ", "self", ".", "self", ".", "query", "=", "None", "\n", "self", ".", "self", ".", "key", "=", "None", "\n", "self", ".", "self", ".", "value", "=", "None", "\n", "self", ".", "output", ".", "dense", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaAttention.forward": [[687, 719], ["modeling_roberta.NewRobertaAttention.self", "modeling_roberta.NewRobertaAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "dims_boundary", "=", "None", ",", "\n", "ov_dims_boundary", "=", "None", ",", "\n", "qk_z", "=", "None", ",", "\n", "vo_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "inference", "=", "False", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "output_attentions", ",", "\n", "qk_z", "=", "qk_z", ",", "\n", "vo_z", "=", "vo_z", ",", "\n", "head_z", "=", "head_z", ",", "\n", "head_layer_z", "=", "head_layer_z", "\n", ")", "\n", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "head_layer_z", "=", "head_layer_z", ",", "hidden_z", "=", "hidden_z", ",", "\n", "inference", "=", "inference", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaSelfAttention.__init__": [[722, 740], ["RobertaSelfAttention.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "ValueError", "hasattr"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "config", ",", "\"embedding_size\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaSelfAttention.transpose_for_scores": [[741, 750], ["x.view.view.size", "x.view.view.view", "x.view.view.permute"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ",", "dims_boundary", "=", "None", ",", "pad", "=", "False", ",", "type", "=", "\"qk\"", ")", ":", "\n", "# head int setting", "\n", "# semi head setting, the rest of the head dimensions has been padded", "\n", "        ", "x_shape", "=", "x", ".", "size", "(", ")", "\n", "last_dim", "=", "x_shape", "[", "-", "1", "]", "\n", "size_per_head", "=", "last_dim", "//", "self", ".", "num_attention_heads", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "size_per_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaSelfAttention.forward": [[751, 825], ["modeling_roberta.NewRobertaSelfAttention.dropout", "modeling_roberta.NewRobertaSelfAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.mul.mul.permute().contiguous", "context_layer.mul.mul.view", "modeling_roberta.NewRobertaSelfAttention.query", "modeling_roberta.NewRobertaSelfAttention.key", "modeling_roberta.NewRobertaSelfAttention.value", "hasattr", "torch.ones().float().to", "torch.ones().float().to", "torch.ones().float().to", "torch.ones().float().to", "modeling_roberta.NewRobertaSelfAttention.transpose_for_scores", "modeling_roberta.NewRobertaSelfAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "math.sqrt", "torch.nn.Softmax", "torch.nn.Softmax", "getattr", "context_layer.mul.mul.mul", "getattr", "mixed_query_layer.mul.mul.mul", "mixed_query_layer.mul.mul.mul", "mixed_value_layer.mul.mul.mul", "modeling_roberta.NewRobertaSelfAttention.transpose", "context_layer.mul.mul.permute", "context_layer.mul.mul.size", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "head_mask", "=", "None", ",", "\n", "dims_boundary", "=", "None", ",", "\n", "ov_dims_boundary", "=", "None", ",", "\n", "qk_z", "=", "None", ",", "\n", "vo_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "value", "is", "None", ":", "\n", "            ", "return", "(", "None", ",", "None", ")", "if", "output_attentions", "else", "(", "None", ",", ")", "\n", "\n", "# if self.value.weight.sum() == 0: # only for updated full model", "\n", "#     return (None, None) if output_attentions else (None, )", "\n", "\n", "", "if", "self", ".", "query", "is", "None", ":", "\n", "            ", "mixed_query_layer", "=", "None", "\n", "", "else", ":", "\n", "            ", "query_hidden_states", "=", "hidden_states", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "query_hidden_states", ")", "\n", "\n", "if", "getattr", "(", "self", ",", "\"qk_s\"", ",", "None", ")", "is", "not", "None", ":", "\n", "                ", "mixed_query_layer", "=", "mixed_query_layer", ".", "mul", "(", "self", ".", "qk_s", ")", "\n", "", "if", "qk_z", "is", "not", "None", ":", "\n", "                ", "mixed_query_layer", "=", "mixed_query_layer", ".", "mul", "(", "qk_z", ")", "\n", "# self.mixed_query_layer = mixed_query_layer", "\n", "\n", "", "key_hidden_states", "=", "hidden_states", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "key_hidden_states", ")", "\n", "\n", "value_hidden_states", "=", "hidden_states", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "value_hidden_states", ")", "\n", "if", "vo_z", "is", "not", "None", ":", "\n", "                ", "mixed_value_layer", "=", "mixed_value_layer", ".", "mul", "(", "vo_z", ")", "\n", "\n", "# batch * sequence_length * dim => batch * sequence_length", "\n", "", "", "batch_size", ",", "seq_length", ",", "_", "=", "hidden_states", ".", "shape", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"ones\"", ")", ":", "\n", "            ", "self", ".", "ones", "=", "torch", ".", "ones", "(", "batch_size", ",", "seq_length", ",", "seq_length", ")", ".", "float", "(", ")", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "\n", "", "if", "mixed_query_layer", "is", "not", "None", ":", "\n", "            ", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "attention_scores", "=", "self", ".", "ones", "[", ":", "batch_size", "]", "\n", "", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ",", "dims_boundary", "=", "ov_dims_boundary", ",", "pad", "=", "False", ",", "type", "=", "\"vo\"", ")", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "if", "head_z", "is", "not", "None", ":", "\n", "            ", "context_layer", "*=", "head_z", "\n", "\n", "", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "context_layer", ".", "shape", "[", "-", "1", "]", "*", "context_layer", ".", "shape", "[", "-", "2", "]", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "# from https://github.com/pmichel31415/pytorch-pretrained-BERT/blob/paul/pytorch_pretrained_bert/modeling.py line 306", "\n", "if", "getattr", "(", "self", ",", "\"vo_s\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "context_layer", "=", "context_layer", ".", "mul", "(", "self", ".", "vo_s", ")", "\n", "# self.context_layer = context_layer", "\n", "\n", "", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaSelfOutput.__init__": [[828, 834], ["RobertaSelfOutput.__init__", "torch.nn.Linear", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaSelfOutput.forward": [[835, 853], ["modeling_roberta.NewRobertaSelfOutput.dense", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.sum().eq().item", "modeling_roberta.NewRobertaSelfOutput.dropout", "modeling_roberta.NewRobertaSelfOutput.LayerNorm", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.sum().eq", "hidden_states.mul.mul.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "head_layer_z", "=", "None", ",", "hidden_z", "=", "None", ",", "inference", "=", "False", ")", ":", "\n", "        ", "if", "hidden_states", "is", "None", ":", "\n", "            ", "return", "input_tensor", "\n", "", "batch_size", ",", "seq_length", ",", "_", "=", "input_tensor", ".", "shape", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "if", "head_layer_z", "is", "not", "None", ":", "\n", "            ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "head_layer_z", ")", "\n", "", "if", "not", "inference", "and", "hidden_states", ".", "sum", "(", ")", ".", "eq", "(", "0", ")", ".", "item", "(", ")", ":", "\n", "            ", "hidden_states", "=", "hidden_states", "+", "input_tensor", "\n", "", "else", ":", "\n", "            ", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ",", "hidden_z", ")", "\n", "# self.hidden_states = hidden_states", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaOutput.__init__": [[856, 862], ["RobertaOutput.__init__", "torch.nn.Linear", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_roberta.NewRobertaOutput.forward": [[863, 877], ["modeling_roberta.NewRobertaOutput.dense", "hidden_states.mul.mul.sum().eq().item", "modeling_roberta.NewRobertaOutput.dropout", "modeling_roberta.NewRobertaOutput.LayerNorm", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.sum().eq", "hidden_states.mul.mul.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "mlp_z", ",", "hidden_z", "=", "None", ",", "inference", "=", "False", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "if", "mlp_z", "is", "not", "None", ":", "\n", "            ", "hidden_states", "*=", "mlp_z", "\n", "", "if", "not", "inference", "and", "hidden_states", ".", "sum", "(", ")", ".", "eq", "(", "0", ")", ".", "item", "(", ")", ":", "\n", "            ", "return", "hidden_states", "+", "input_tensor", "\n", "", "else", ":", "\n", "            ", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ",", "hidden_z", ")", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiLayerNorm.__init__": [[24, 26], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "normalized_shape", ",", "eps", ":", "float", "=", "1e-5", ",", "elementwise_affine", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiLayerNorm.forward": [[27, 43], ["torch.index_select", "len", "torch.nn.functional.layer_norm", "input.clone", "torch.nn.functional.layer_norm", "torch.where", "hidden_z.eq"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden_z", "=", "None", ")", ":", "\n", "        ", "if", "hidden_z", "is", "not", "None", ":", "\n", "            ", "remaining_index", "=", "torch", ".", "where", "(", "~", "hidden_z", ".", "eq", "(", "0", ")", ")", "[", "0", "]", "\n", "compressed_input", "=", "torch", ".", "index_select", "(", "\n", "input", ",", "dim", "=", "-", "1", ",", "index", "=", "remaining_index", ")", "\n", "compressed_weight", "=", "self", ".", "weight", "[", "remaining_index", "]", "\n", "compressed_bias", "=", "self", ".", "bias", "[", "remaining_index", "]", "\n", "normalized_shape", "=", "len", "(", "remaining_index", ")", "\n", "normed_input", "=", "F", ".", "layer_norm", "(", "\n", "compressed_input", ",", "[", "normalized_shape", "]", ",", "compressed_weight", ",", "compressed_bias", ",", "self", ".", "eps", ")", "\n", "output", "=", "input", ".", "clone", "(", ")", "\n", "output", "[", ":", ",", ":", ",", "remaining_index", "]", "=", "normed_input", "\n", "", "else", ":", "\n", "            ", "output", "=", "F", ".", "layer_norm", "(", "\n", "input", ",", "self", ".", "normalized_shape", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForSequenceClassification.__init__": [[45, 56], ["transformers.models.bert.modeling_bert.BertForSequenceClassification.__init__", "modeling_bert.CoFiBertModel", "getattr", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "CoFiBertModel", "(", "config", ")", "\n", "\n", "self", ".", "do_layer_distill", "=", "getattr", "(", "config", ",", "\"do_layer_distill\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "do_layer_distill", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "nn", ".", "Linear", "(", "\n", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForSequenceClassification.from_pretrained": [[57, 92], ["os.path.exists", "torch.load.keys", "zip", "cls", "load_pruned_model", "torch.load", "transformers.file_utils.hf_bucket_url", "transformers.file_utils.cached_path", "torch.load", "torch.load.pop", "AutoConfig.from_pretrained", "os.path.join", "key.replace", "key.replace", "old_keys.append", "new_keys.append", "torch.device"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_pruned_model", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ":", "Optional", "[", "Union", "[", "str", ",", "os", ".", "PathLike", "]", "]", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "weights", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "\"pytorch_model.bin\"", ")", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "filename", "=", "\"pytorch_model.bin\"", ")", "\n", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ")", "\n", "weights", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "weights", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "\"gamma\"", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "\"gamma\"", ",", "\"weight\"", ")", "\n", "", "if", "\"beta\"", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "\"beta\"", ",", "\"bias\"", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "weights", "[", "new_key", "]", "=", "weights", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "if", "\"config\"", "not", "in", "kwargs", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ")", "\n", "config", ".", "do_layer_distill", "=", "False", "\n", "", "else", ":", "\n", "            ", "config", "=", "kwargs", "[", "\"config\"", "]", "\n", "\n", "", "model", "=", "cls", "(", "config", ")", "\n", "\n", "load_pruned_model", "(", "model", ",", "weights", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForSequenceClassification.forward": [[93, 154], ["modeling_bert.CoFiBertForSequenceClassification.bert", "modeling_bert.CoFiBertForSequenceClassification.dropout", "modeling_bert.CoFiBertForSequenceClassification.classifier", "transformers.modeling_outputs.SequenceClassifierOutput", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.CoFiBertForSequenceClassification.view", "labels.view", "modeling_bert.CoFiBertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "hidden_z", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "head_z", "=", "head_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "intermediate_z", "=", "intermediate_z", ",", "\n", "mlp_z", "=", "mlp_z", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "\n", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertEmbeddings.__init__": [[160, 164], ["transformers.models.bert.modeling_bert.BertEmbeddings.__init__", "modeling_bert.CoFiLayerNorm"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "LayerNorm", "=", "CoFiLayerNorm", "(", "\n", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertEmbeddings.forward": [[165, 195], ["modeling_bert.CoFiBertEmbeddings.position_embeddings", "modeling_bert.CoFiBertEmbeddings.token_type_embeddings", "modeling_bert.CoFiBertEmbeddings.LayerNorm", "modeling_bert.CoFiBertEmbeddings.dropout", "input_ids.size", "torch.zeros", "modeling_bert.CoFiBertEmbeddings.word_embeddings", "embeddings.mul.mul.mul", "embeddings.mul.mul.mul", "modeling_bert.CoFiBertEmbeddings.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ",", "hidden_z", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "self", ".", "position_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "\n", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "position_ids", ".", "device", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "            ", "embeddings", "=", "embeddings", ".", "mul", "(", "hidden_z", ")", "\n", "", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ",", "hidden_z", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "            ", "embeddings", "=", "embeddings", ".", "mul", "(", "hidden_z", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertModel.__init__": [[198, 202], ["transformers.models.bert.modeling_bert.BertModel.__init__", "modeling_bert.CoFiBertEncoder", "modeling_bert.CoFiBertEmbeddings"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "encoder", "=", "CoFiBertEncoder", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "CoFiBertEmbeddings", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertModel.forward": [[203, 280], ["modeling_bert.CoFiBertModel.get_extended_attention_mask", "modeling_bert.CoFiBertModel.embeddings", "modeling_bert.CoFiBertModel.encoder", "modeling_bert.CoFiBertModel.pooler", "transformers.modeling_outputs.BaseModelOutputWithPooling", "ValueError", "torch.ones", "torch.zeros", "input_ids.size", "ValueError", "inputs_embeds.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "\n", "        ", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "\n", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "extended_attention_mask", ":", "torch", ".", "Tensor", "=", "self", ".", "get_extended_attention_mask", "(", "\n", "attention_mask", ",", "input_shape", ",", "device", ")", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", ",", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "intermediate_z", "=", "intermediate_z", ",", "\n", "head_z", "=", "head_z", ",", "\n", "mlp_z", "=", "mlp_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "\n", "", "return", "BaseModelOutputWithPooling", "(", "\n", "last_hidden_state", "=", "sequence_output", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertEncoder.__init__": [[284, 288], ["transformers.models.bert.modeling_bert.BertEncoder.__init__", "torch.nn.ModuleList", "modeling_bert.CoFiBertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "CoFiBertLayer", "(", "config", ")", "\n", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertEncoder.forward": [[289, 330], ["enumerate", "transformers.modeling_outputs.BaseModelOutput", "layer_module", "tuple"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "return_dict", "=", "False", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "output_attentions", ",", "\n", "intermediate_z", "=", "intermediate_z", "[", "i", "]", "if", "intermediate_z", "is", "not", "None", "else", "None", ",", "\n", "head_z", "=", "head_z", "[", "i", "]", "if", "head_z", "is", "not", "None", "else", "None", ",", "\n", "mlp_z", "=", "mlp_z", "[", "i", "]", "if", "mlp_z", "is", "not", "None", "else", "None", ",", "\n", "head_layer_z", "=", "head_layer_z", "[", "i", "]", "if", "head_layer_z", "is", "not", "None", "else", "None", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "all_hidden_states", ",", "all_attentions", "]", "if", "v", "is", "not", "None", ")", "\n", "", "return", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "hidden_states", "=", "all_hidden_states", ",", "attentions", "=", "all_attentions", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertLayer.__init__": [[334, 339], ["transformers.models.bert.modeling_bert.BertLayer.__init__", "modeling_bert.CoFiBertAttention", "modeling_bert.CoFiBertOutput"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attention", "=", "CoFiBertAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "CoFiBertOutput", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertLayer.forward": [[340, 375], ["modeling_bert.CoFiBertLayer.attention", "transformers.modeling_utils.apply_chunking_to_forward"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "head_z", "=", "head_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "# add self attentions if we output attention weights", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "\n", "\n", "if", "self", ".", "intermediate", ".", "dense", "is", "None", ":", "\n", "            ", "layer_output", "=", "attention_output", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_z", "=", "intermediate_z", "\n", "self", ".", "mlp_z", "=", "mlp_z", "\n", "self", ".", "hidden_z", "=", "hidden_z", "\n", "layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", "\n", ")", "\n", "", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "+", "(", "attention_output", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertLayer.feed_forward_chunk": [[376, 383], ["modeling_bert.CoFiBertLayer.intermediate", "modeling_bert.CoFiBertLayer.output", "intermediate_output.mul.mul.mul"], "methods", ["None"], ["", "def", "feed_forward_chunk", "(", "self", ",", "attention_output", ")", ":", "\n", "        ", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "if", "self", ".", "intermediate_z", "is", "not", "None", ":", "\n", "            ", "intermediate_output", "=", "intermediate_output", ".", "mul", "(", "self", ".", "intermediate_z", ")", "\n", "", "layer_output", "=", "self", ".", "output", "(", "\n", "intermediate_output", ",", "attention_output", ",", "self", ".", "mlp_z", ",", "self", ".", "hidden_z", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertAttention.__init__": [[386, 391], ["transformers.models.bert.modeling_bert.BertAttention.__init__", "modeling_bert.CoFiBertSelfAttention", "modeling_bert.CoFiBertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "self", "=", "CoFiBertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "CoFiBertSelfOutput", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertAttention.prune_heads": [[392, 420], ["len", "transformers.modeling_utils.find_pruneable_heads_and_indices", "modeling_bert.CoFiBertAttention.pruned_heads.union", "len", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "transformers.modeling_utils.prune_linear_layer", "len"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "len_heads", "=", "len", "(", "heads", ")", "\n", "if", "len_heads", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "\n", "heads", ",", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ",", "self", ".", "pruned_heads", "\n", ")", "\n", "\n", "# Prune linear layers", "\n", "if", "len", "(", "index", ")", "==", "0", ":", "\n", "            ", "self", ".", "self", ".", "query", "=", "None", "\n", "self", ".", "self", ".", "key", "=", "None", "\n", "self", ".", "self", ".", "value", "=", "None", "\n", "self", ".", "output", ".", "dense", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "\n", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertAttention.forward": [[421, 441], ["modeling_bert.CoFiBertAttention.self", "modeling_bert.CoFiBertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "head_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "output_attentions", ",", "\n", "head_z", "=", "head_z", ",", "\n", ")", "\n", "\n", "attention_output", "=", "self", ".", "output", "(", "\n", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "head_layer_z", "=", "head_layer_z", ",", "hidden_z", "=", "hidden_z", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.__init__": [[444, 463], ["transformers.models.bert.modeling_bert.BertSelfAttention.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError", "hasattr"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "config", ",", "\"embedding_size\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "\n", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.transpose_for_scores": [[464, 471], ["x.view.view.size", "x.view.view.view", "x.view.view.permute"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_shape", "=", "x", ".", "size", "(", ")", "\n", "last_dim", "=", "x_shape", "[", "-", "1", "]", "\n", "size_per_head", "=", "last_dim", "//", "self", ".", "num_attention_heads", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "size_per_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.forward": [[472, 522], ["modeling_bert.CoFiBertSelfAttention.query", "modeling_bert.CoFiBertSelfAttention.key", "modeling_bert.CoFiBertSelfAttention.value", "modeling_bert.CoFiBertSelfAttention.transpose_for_scores", "modeling_bert.CoFiBertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_bert.CoFiBertSelfAttention.dropout", "modeling_bert.CoFiBertSelfAttention.transpose_for_scores", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "hasattr", "torch.ones().float().to", "modeling_bert.CoFiBertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size", "torch.ones().float", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "head_z", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "value", "is", "None", ":", "\n", "            ", "return", "(", "None", ",", "None", ")", "if", "output_attentions", "else", "(", "None", ",", ")", "\n", "\n", "", "query_hidden_states", "=", "hidden_states", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "query_hidden_states", ")", "\n", "\n", "key_hidden_states", "=", "hidden_states", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "key_hidden_states", ")", "\n", "\n", "value_hidden_states", "=", "hidden_states", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "value_hidden_states", ")", "\n", "\n", "batch_size", ",", "seq_length", ",", "_", "=", "hidden_states", ".", "shape", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"ones\"", ")", ":", "\n", "            ", "self", ".", "ones", "=", "torch", ".", "ones", "(", "batch_size", ",", "seq_length", ",", "seq_length", ")", ".", "float", "(", ")", ".", "to", "(", "\n", "hidden_states", ".", "device", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "\n", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "if", "head_z", "is", "not", "None", ":", "\n", "            ", "context_layer", "*=", "head_z", "\n", "\n", "", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", "\n", ")", "[", ":", "-", "2", "]", "+", "(", "context_layer", ".", "shape", "[", "-", "1", "]", "*", "context_layer", ".", "shape", "[", "-", "2", "]", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "output_attentions", "else", "(", "\n", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfOutput.__init__": [[525, 532], ["transformers.models.bert.modeling_bert.BertSelfOutput.__init__", "torch.nn.Linear", "modeling_bert.CoFiLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "CoFiLayerNorm", "(", "\n", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertSelfOutput.forward": [[533, 550], ["modeling_bert.CoFiBertSelfOutput.dense", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.sum().eq().item", "modeling_bert.CoFiBertSelfOutput.dropout", "modeling_bert.CoFiBertSelfOutput.LayerNorm", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.sum().eq", "hidden_states.mul.mul.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "head_layer_z", "=", "None", ",", "hidden_z", "=", "None", ",", "inference", "=", "False", ")", ":", "\n", "        ", "if", "hidden_states", "is", "None", ":", "\n", "            ", "return", "input_tensor", "\n", "", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "if", "head_layer_z", "is", "not", "None", ":", "\n", "            ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "head_layer_z", ")", "\n", "", "if", "not", "inference", "and", "hidden_states", ".", "sum", "(", ")", ".", "eq", "(", "0", ")", ".", "item", "(", ")", ":", "\n", "            ", "hidden_states", "=", "hidden_states", "+", "input_tensor", "\n", "", "else", ":", "\n", "            ", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "\n", "hidden_states", "+", "input_tensor", ",", "hidden_z", ")", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertOutput.__init__": [[553, 560], ["transformers.models.bert.modeling_bert.BertOutput.__init__", "torch.nn.Linear", "modeling_bert.CoFiLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "CoFiLayerNorm", "(", "\n", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertOutput.forward": [[561, 576], ["modeling_bert.CoFiBertOutput.dense", "hidden_states.mul.mul.sum().eq().item", "modeling_bert.CoFiBertOutput.dropout", "modeling_bert.CoFiBertOutput.LayerNorm", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.mul", "hidden_states.mul.mul.sum().eq", "hidden_states.mul.mul.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "mlp_z", ",", "hidden_z", "=", "None", ",", "inference", "=", "False", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "if", "mlp_z", "is", "not", "None", ":", "\n", "            ", "hidden_states", "*=", "mlp_z", "\n", "", "if", "not", "inference", "and", "hidden_states", ".", "sum", "(", ")", ".", "eq", "(", "0", ")", ".", "item", "(", ")", ":", "\n", "            ", "return", "hidden_states", "+", "input_tensor", "\n", "", "else", ":", "\n", "            ", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "\n", "hidden_states", "+", "input_tensor", ",", "hidden_z", ")", "\n", "if", "hidden_z", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "mul", "(", "hidden_z", ")", "\n", "", "", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.__init__": [[579, 589], ["transformers.models.bert.modeling_bert.BertForQuestionAnswering.__init__", "modeling_bert.CoFiBertModel", "getattr", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "CoFiBertModel", "(", "config", ")", "\n", "self", ".", "do_layer_distill", "=", "getattr", "(", "config", ",", "\"do_layer_distill\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "do_layer_distill", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "nn", ".", "Linear", "(", "\n", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_transformation", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained": [[590, 625], ["os.path.exists", "torch.load.keys", "zip", "AutoConfig.from_pretrained", "cls", "load_pruned_model", "torch.load", "transformers.file_utils.hf_bucket_url", "transformers.file_utils.cached_path", "torch.load", "torch.load.pop", "os.path.join", "key.replace", "key.replace", "old_keys.append", "new_keys.append", "torch.load.pop", "torch.device"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.utils.cofi_utils.load_pruned_model"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ":", "Optional", "[", "Union", "[", "str", ",", "os", ".", "PathLike", "]", "]", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "weights", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "\"pytorch_model.bin\"", ")", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "\"pytorch_model.bin\"", ")", "\n", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ")", "\n", "weights", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "weights", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "\"gamma\"", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "\"gamma\"", ",", "\"weight\"", ")", "\n", "", "if", "\"beta\"", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "\"beta\"", ",", "\"bias\"", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "weights", "[", "new_key", "]", "=", "weights", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "drop_weight_names", "=", "[", "\"layer_transformation.weight\"", ",", "\"layer_transformation.bias\"", "]", "\n", "for", "name", "in", "drop_weight_names", ":", "\n", "            ", "if", "name", "in", "weights", ":", "\n", "                ", "weights", ".", "pop", "(", "name", ")", "\n", "\n", "", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ")", "\n", "config", ".", "do_layer_distill", "=", "False", "\n", "model", "=", "cls", "(", "config", ")", "\n", "\n", "load_pruned_model", "(", "model", ",", "weights", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.forward": [[626, 695], ["modeling_bert.CoFiBertForQuestionAnswering.bert", "modeling_bert.CoFiBertForQuestionAnswering.qa_outputs", "modeling_bert.CoFiBertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "transformers.models.bert.modeling_bert.QuestionAnsweringModelOutput", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "intermediate_z", "=", "None", ",", "\n", "head_z", "=", "None", ",", "\n", "mlp_z", "=", "None", ",", "\n", "head_layer_z", "=", "None", ",", "\n", "hidden_z", "=", "None", "\n", ")", ":", "\n", "        ", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "intermediate_z", "=", "intermediate_z", ",", "\n", "head_z", "=", "head_z", ",", "\n", "head_layer_z", "=", "head_layer_z", ",", "\n", "mlp_z", "=", "mlp_z", ",", "\n", "hidden_z", "=", "hidden_z", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "total_loss", "=", "None", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "start_logits", ",", "end_logits", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "total_loss", ",", ")", "+", "output", ")", "if", "total_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "QuestionAnsweringModelOutput", "(", "\n", "loss", "=", "total_loss", ",", "\n", "start_logits", "=", "start_logits", ",", "\n", "end_logits", "=", "end_logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer_qa.CoFiQATrainer.__init__": [[12, 17], ["trainer.trainer.CoFiTrainer.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "eval_examples", "=", "None", ",", "post_process_function", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "CoFiTrainer", ".", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "eval_examples", "=", "eval_examples", "\n", "self", ".", "post_process_function", "=", "post_process_function", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer_qa.CoFiQATrainer.evaluate": [[18, 76], ["trainer_qa.CoFiQATrainer.get_eval_dataloader", "isinstance", "trainer_qa.CoFiQATrainer.update", "trainer_qa.CoFiQATrainer.callback_handler.on_evaluate", "trainer_qa.CoFiQATrainer.log", "trainer_qa.CoFiQATrainer.logger.info", "trainer_qa.CoFiQATrainer.prediction_loop", "eval_dataset.set_format", "trainer_qa.CoFiQATrainer.post_process_function", "trainer_qa.CoFiQATrainer.compute_metrics", "trainer_qa.CoFiQATrainer.log", "trainer_qa.CoFiQATrainer.eval_counter.update", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "trainer_qa.CoFiQATrainer.model.save_pretrained", "list", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "eval_dataset.features.keys"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.update", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.prediction_loop", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.update"], ["", "def", "evaluate", "(", "self", ",", "eval_dataset", "=", "None", ",", "eval_examples", "=", "None", ")", ":", "\n", "\n", "        ", "eval_dataset", "=", "self", ".", "eval_dataset", "if", "eval_dataset", "is", "None", "else", "eval_dataset", "\n", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", "eval_dataset", ")", "\n", "eval_examples", "=", "self", ".", "eval_examples", "if", "eval_examples", "is", "None", "else", "eval_examples", "\n", "\n", "# Temporarily disable metric computation, we will do it in the loop here.", "\n", "compute_metrics", "=", "self", ".", "compute_metrics", "\n", "self", ".", "compute_metrics", "=", "None", "\n", "try", ":", "\n", "            ", "output", "=", "self", ".", "prediction_loop", "(", "\n", "eval_dataloader", ",", "\n", "description", "=", "\"Evaluation\"", ",", "\n", "# No point gathering the predictions if there are no metrics, otherwise we defer to", "\n", "# self.args.prediction_loss_only", "\n", "prediction_loss_only", "=", "True", "if", "compute_metrics", "is", "None", "else", "None", ",", "\n", "# ignore_keys=ignore_keys,", "\n", ")", "\n", "", "finally", ":", "\n", "            ", "self", ".", "compute_metrics", "=", "compute_metrics", "\n", "\n", "# We might have removed columns from the dataset so we put them back.", "\n", "", "if", "isinstance", "(", "eval_dataset", ",", "datasets", ".", "Dataset", ")", ":", "\n", "            ", "eval_dataset", ".", "set_format", "(", "type", "=", "eval_dataset", ".", "format", "[", "\"type\"", "]", ",", "columns", "=", "list", "(", "eval_dataset", ".", "features", ".", "keys", "(", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "post_process_function", "is", "not", "None", "and", "self", ".", "compute_metrics", "is", "not", "None", ":", "\n", "            ", "eval_preds", "=", "self", ".", "post_process_function", "(", "eval_examples", ",", "eval_dataset", ",", "output", ".", "predictions", ")", "\n", "metrics", "=", "self", ".", "compute_metrics", "(", "eval_preds", ")", "\n", "self", ".", "log", "(", "metrics", ")", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "", "metrics", ".", "update", "(", "output", ".", "metrics", ")", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_evaluate", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ",", "metrics", ")", "\n", "\n", "self", ".", "log", "(", "metrics", ")", "\n", "metrics", "[", "\"global_step\"", "]", "=", "self", ".", "global_step", "\n", "\n", "self", ".", "logger", ".", "info", "(", "f\"Evaluating: {metrics}\"", ")", "\n", "name", "=", "\"f1\"", "\n", "eval_score", "=", "metrics", "[", "name", "]", "\n", "\n", "if", "self", ".", "start_saving_best", ":", "\n", "            ", "best_so_far", "=", "self", ".", "eval_counter", ".", "update", "(", "\n", "self", ".", "epoch", ",", "self", ".", "global_step", ",", "eval_score", ")", "\n", "\n", "if", "best_so_far", ":", "\n", "                ", "best_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "\"best\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "best_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "best_dir", ")", "\n", "", "zs", "=", "None", "\n", "\n", "torch", ".", "save", "(", "zs", ",", "os", ".", "path", ".", "join", "(", "best_dir", ",", "\"zs.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "l0_module", ",", "os", ".", "path", ".", "join", "(", "\n", "best_dir", ",", "\"l0_module.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "f\"Saving the best model so far: [Epoch {self.epoch} | Step: {self.global_step} | \\\n                                Model size: {output.metrics['remaining_params']} | Score: {eval_score}]\"", ")", "\n", "self", ".", "model", ".", "save_pretrained", "(", "best_dir", ")", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer_qa.CoFiQATrainer.predict": [[77, 101], ["trainer_qa.CoFiQATrainer.get_test_dataloader", "isinstance", "trainer_qa.CoFiQATrainer.post_process_function", "trainer_qa.CoFiQATrainer.compute_metrics", "transformers.trainer_utils.PredictionOutput", "trainer_qa.CoFiQATrainer.prediction_loop", "test_dataset.set_format", "list", "test_dataset.features.keys"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.prediction_loop"], ["", "def", "predict", "(", "self", ",", "test_dataset", ",", "test_examples", ",", "ignore_keys", "=", "None", ")", ":", "\n", "        ", "test_dataloader", "=", "self", ".", "get_test_dataloader", "(", "test_dataset", ")", "\n", "\n", "compute_metrics", "=", "self", ".", "compute_metrics", "\n", "self", ".", "compute_metrics", "=", "None", "\n", "try", ":", "\n", "            ", "output", "=", "self", ".", "prediction_loop", "(", "\n", "test_dataloader", ",", "\n", "description", "=", "\"Evaluation\"", ",", "\n", "prediction_loss_only", "=", "True", "if", "compute_metrics", "is", "None", "else", "None", ",", "\n", "ignore_keys", "=", "ignore_keys", ",", "\n", ")", "\n", "", "finally", ":", "\n", "            ", "self", ".", "compute_metrics", "=", "compute_metrics", "\n", "\n", "", "if", "self", ".", "post_process_function", "is", "None", "or", "self", ".", "compute_metrics", "is", "None", ":", "\n", "            ", "return", "output", "\n", "\n", "", "if", "isinstance", "(", "test_dataset", ",", "datasets", ".", "Dataset", ")", ":", "\n", "            ", "test_dataset", ".", "set_format", "(", "type", "=", "test_dataset", ".", "format", "[", "\"type\"", "]", ",", "columns", "=", "list", "(", "test_dataset", ".", "features", ".", "keys", "(", ")", ")", ")", "\n", "\n", "", "eval_preds", "=", "self", ".", "post_process_function", "(", "test_examples", ",", "test_dataset", ",", "output", ".", "predictions", ")", "\n", "metrics", "=", "self", ".", "compute_metrics", "(", "eval_preds", ")", "\n", "return", "PredictionOutput", "(", "predictions", "=", "eval_preds", ".", "predictions", ",", "label_ids", "=", "eval_preds", ".", "label_ids", ",", "metrics", "=", "metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer_qa.CoFiQATrainer.calculate_distillation_loss": [[102, 120], ["trainer_qa.CoFiQATrainer.calculate_layer_distillation_loss", "torch.kl_div", "torch.kl_div", "torch.kl_div", "torch.kl_div", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.calculate_layer_distillation_loss"], ["", "def", "calculate_distillation_loss", "(", "self", ",", "teacher_outputs", ",", "student_outputs", ",", "zs", ")", ":", "\n", "        ", "layer_distill_loss", "=", "self", ".", "calculate_layer_distillation_loss", "(", "zs", ")", "\n", "distill_ce_loss", "=", "F", ".", "kl_div", "(", "\n", "input", "=", "F", ".", "log_softmax", "(", "student_outputs", ".", "start_logits", "/", "self", ".", "additional_args", ".", "distill_temp", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "F", ".", "softmax", "(", "teacher_outputs", ".", "start_logits", "/", "self", ".", "additional_args", ".", "distill_temp", ",", "dim", "=", "-", "1", ")", ",", "\n", "reduction", "=", "\"batchmean\"", ",", "\n", ")", "*", "(", "self", ".", "additional_args", ".", "distill_temp", "**", "2", ")", "\n", "\n", "distill_ce_loss", "+=", "F", ".", "kl_div", "(", "\n", "input", "=", "F", ".", "log_softmax", "(", "student_outputs", ".", "end_logits", "/", "self", ".", "additional_args", ".", "distill_temp", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "F", ".", "softmax", "(", "teacher_outputs", ".", "end_logits", "/", "self", ".", "additional_args", ".", "distill_temp", ",", "dim", "=", "-", "1", ")", ",", "\n", "reduction", "=", "\"batchmean\"", ",", "\n", ")", "*", "(", "self", ".", "additional_args", ".", "distill_temp", "**", "2", ")", "\n", "\n", "distill_ce_loss", "=", "distill_ce_loss", "/", "2", "\n", "\n", "loss", "=", "self", ".", "additional_args", ".", "distill_loss_alpha", "*", "layer_distill_loss", "+", "self", ".", "additional_args", ".", "distill_ce_loss_alpha", "*", "distill_ce_loss", "\n", "return", "layer_distill_loss", ",", "distill_ce_loss", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.__init__": [[50, 57], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "0", "\n", "self", ".", "global_step", "=", "0", "\n", "self", ".", "best_eval_score", "=", "0", "\n", "self", ".", "near_sparsity_eval_times", "=", "0", "\n", "self", ".", "level_best_score", "=", "{", "0.85", ":", "0", ",", "0.8", ":", "0", ",", "0.7", ":", "0", ",", "\n", "0.6", ":", "0", ",", "0.75", ":", "0", ",", "0.9", ":", "0", ",", "0.95", ":", "0", ",", "0.65", ":", "0", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.round_nearest": [[58, 60], ["round", "round", "int", "math.floor", "math.log10"], "methods", ["None"], ["", "def", "round_nearest", "(", "self", ",", "x", ",", "a", ")", ":", "\n", "        ", "return", "round", "(", "round", "(", "x", "/", "a", ")", "*", "a", ",", "-", "int", "(", "math", ".", "floor", "(", "math", ".", "log10", "(", "a", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.update": [[61, 69], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "epoch", ",", "global_step", ",", "eval_score", ")", ":", "\n", "        ", "best_so_far", "=", "False", "\n", "if", "eval_score", ">", "self", ".", "best_eval_score", ":", "\n", "            ", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "global_step", "=", "global_step", "\n", "self", ".", "best_eval_score", "=", "eval_score", "\n", "best_so_far", "=", "True", "\n", "", "return", "best_so_far", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.clear": [[70, 72], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "eval_score", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__": [[75, 113], ["transformers.Trainer.__init__", "trainer.Eval_Counter", "args.get_process_log_level", "transformers.utils.logging.set_verbosity", "logger.setLevel", "trainer.CoFiTrainer.teacher_model.to"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "PreTrainedModel", "=", "None", ",", "\n", "args", ":", "TrainingArguments", "=", "None", ",", "\n", "additional_args", ":", "AdditionalArguments", "=", "None", ",", "\n", "data_collator", ":", "Optional", "[", "DataCollator", "]", "=", "None", ",", "\n", "train_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "tokenizer", ":", "Optional", "[", "PreTrainedTokenizerBase", "]", "=", "None", ",", "\n", "model_init", ":", "Callable", "[", "[", "]", ",", "PreTrainedModel", "]", "=", "None", ",", "\n", "compute_metrics", ":", "Optional", "[", "Callable", "[", "[", "EvalPrediction", "]", ",", "Dict", "]", "]", "=", "None", ",", "\n", "l0_module", "=", "None", ",", "\n", "teacher_model", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "Trainer", ".", "__init__", "(", "self", ",", "model", ",", "args", ",", "data_collator", ",", "train_dataset", ",", "\n", "eval_dataset", ",", "tokenizer", ",", "model_init", ",", "compute_metrics", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "additional_args", "=", "additional_args", "\n", "\n", "self", ".", "l0_module", "=", "l0_module", "\n", "self", ".", "prepruning_finetune_steps", "=", "0", "\n", "self", ".", "start_prune", "=", "False", "\n", "\n", "self", ".", "l0_optimizer", "=", "None", "\n", "self", ".", "lagrangian_optimizer", "=", "None", "\n", "\n", "self", ".", "eval_counter", "=", "Eval_Counter", "(", ")", "\n", "self", ".", "start_saving_best", "=", "True", "if", "self", ".", "additional_args", ".", "pruning_type", "is", "None", "else", "False", "\n", "\n", "self", ".", "teacher_model", "=", "teacher_model", "\n", "if", "self", ".", "teacher_model", "is", "not", "None", ":", "\n", "            ", "self", ".", "teacher_model", "=", "self", ".", "teacher_model", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "", "log_level", "=", "args", ".", "get_process_log_level", "(", ")", "\n", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.create_optimizer_and_scheduler": [[114, 173], ["enumerate", "trainer.CoFiTrainer.create_optimizer_and_scheduler.log_params"], "methods", ["None"], ["", "def", "create_optimizer_and_scheduler", "(", "self", ",", "num_training_steps", ":", "int", ")", ":", "\n", "        ", "def", "log_params", "(", "param_groups", ",", "des", ")", ":", "\n", "            ", "for", "i", ",", "grouped_parameters", "in", "enumerate", "(", "param_groups", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "f\"{des}, number of params: {sum(p.nelement() for p in grouped_parameters['params'])}, weight_decay: {grouped_parameters['weight_decay']}, lr: {grouped_parameters['lr']}\"", ")", "\n", "\n", "", "", "if", "self", ".", "optimizer", "is", "None", ":", "\n", "            ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "freeze_keywords", "=", "[", "\"embeddings\"", "]", "\n", "\n", "main_model_params", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "not", "any", "(", "fk", "in", "n", "for", "fk", "in", "freeze_keywords", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "\"lr\"", ":", "self", ".", "args", ".", "learning_rate", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "not", "any", "(", "fk", "in", "n", "for", "fk", "in", "freeze_keywords", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "\"lr\"", ":", "self", ".", "args", ".", "learning_rate", "\n", "}", ",", "\n", "]", "\n", "log_params", "(", "main_model_params", ",", "\"main params\"", ")", "\n", "self", ".", "optimizer", "=", "AdamW", "(", "\n", "main_model_params", ",", "\n", "betas", "=", "(", "self", ".", "args", ".", "adam_beta1", ",", "self", ".", "args", ".", "adam_beta2", ")", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", "\n", ")", "\n", "\n", "if", "self", ".", "l0_module", "is", "not", "None", ":", "\n", "                ", "l0_params", "=", "[", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "l0_module", ".", "named_parameters", "(", ")", "if", "\"lambda\"", "not", "in", "n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "\"lr\"", ":", "self", ".", "additional_args", ".", "reg_learning_rate", "\n", "}", "]", "\n", "log_params", "(", "l0_params", ",", "\"l0 reg params\"", ")", "\n", "self", ".", "l0_optimizer", "=", "AdamW", "(", "l0_params", ",", "\n", "betas", "=", "(", "self", ".", "args", ".", "adam_beta1", ",", "\n", "self", ".", "args", ".", "adam_beta2", ")", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", ")", "\n", "\n", "lagrangian_params", "=", "[", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "l0_module", ".", "named_parameters", "(", ")", "if", "\"lambda\"", "in", "n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "\"lr\"", ":", "-", "self", ".", "additional_args", ".", "reg_learning_rate", "\n", "}", "]", "\n", "log_params", "(", "lagrangian_params", ",", "\"l0 reg lagrangian params\"", ")", "\n", "self", ".", "lagrangian_optimizer", "=", "AdamW", "(", "lagrangian_params", ",", "\n", "betas", "=", "(", "self", ".", "args", ".", "adam_beta1", ",", "\n", "self", ".", "args", ".", "adam_beta2", ")", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", "is", "None", ":", "\n", "            ", "if", "self", ".", "additional_args", ".", "scheduler_type", "==", "\"linear\"", ":", "\n", "                ", "self", ".", "lr_scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "num_training_steps", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "lr_scheduler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.train": [[174, 377], ["trainer.CoFiTrainer.get_train_dataloader", "max", "trainer.CoFiTrainer.create_optimizer_and_scheduler", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.zero_grad", "trainer.CoFiTrainer.optimizer.zero_grad", "tqdm.auto.tqdm.auto.trange", "trainer.CoFiTrainer.evaluate", "range", "tqdm.auto.tqdm.auto.trange.close", "transformers.trainer_utils.TrainOutput", "len", "trainer.CoFiTrainer.l0_module.set_lagrangian_warmup_steps", "logger.info", "logger.info", "int", "trainer.CoFiTrainer.num_examples", "trainer.CoFiTrainer.l0_module.zero_grad", "trainer.CoFiTrainer.l0_optimizer.zero_grad", "trainer.CoFiTrainer.lagrangian_optimizer.zero_grad", "int", "int", "time.time", "tqdm.auto.tqdm.auto.tqdm", "trainer.CoFiTrainer.eval_counter.clear", "enumerate", "time.time", "logger.info", "tqdm.auto.tqdm.auto.tqdm.close", "tqdm.auto.tqdm.auto.trange.update", "hasattr", "delattr", "int", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "trainer.CoFiTrainer.is_local_process_zero", "numpy.ceil", "numpy.ceil", "isinstance", "isinstance", "trainer.CoFiTrainer.sampler.set_epoch", "trainer.CoFiTrainer.training_step", "trainer.CoFiTrainer.floating_point_ops", "tqdm.auto.tqdm.auto.tqdm.update", "torch.tensor().to.item", "torch.tensor().to.item", "trainer.CoFiTrainer.create_optimizer_and_scheduler", "logger.info", "trainer.CoFiTrainer.l0_module.forward", "trainer.CoFiTrainer.fill_inputs_with_zs", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "trainer.CoFiTrainer.optimizer.step", "model.zero_grad", "trainer.CoFiTrainer.optimizer.zero_grad", "model.parameters", "trainer.CoFiTrainer.l0_optimizer.step", "trainer.CoFiTrainer.lagrangian_optimizer.step", "trainer.CoFiTrainer.lr_scheduler.step", "trainer.CoFiTrainer.l0_module.constrain_parameters", "trainer.CoFiTrainer.l0_module.zero_grad", "trainer.CoFiTrainer.l0_optimizer.zero_grad", "trainer.CoFiTrainer.lagrangian_optimizer.zero_grad", "torch.tensor().to.item", "torch.tensor().to.item", "torch.tensor().to.item", "torch.tensor().to.item", "torch.tensor().to.item", "torch.tensor().to.item", "trainer.CoFiTrainer.log", "trainer.CoFiTrainer.evaluate", "round", "len", "len", "len", "packaging.version.parse", "packaging.version.parse", "trainer.CoFiTrainer.lr_scheduler.get_last_lr", "trainer.CoFiTrainer.lr_scheduler.get_lr"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.create_optimizer_and_scheduler", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.evaluate", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.set_lagrangian_warmup_steps", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.clear", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.update", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.training_step", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.update", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.create_optimizer_and_scheduler", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.forward", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.fill_inputs_with_zs", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.constrain_parameters", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.evaluate"], ["", "", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "train_dataloader", "=", "self", ".", "get_train_dataloader", "(", ")", "\n", "num_update_steps_per_epoch", "=", "len", "(", "\n", "train_dataloader", ")", "//", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "num_update_steps_per_epoch", "=", "max", "(", "num_update_steps_per_epoch", ",", "1", ")", "\n", "\n", "if", "self", ".", "l0_module", "is", "not", "None", ":", "\n", "            ", "lagrangian_warmup_steps", "=", "self", ".", "additional_args", ".", "lagrangian_warmup_epochs", "*", "num_update_steps_per_epoch", "\n", "self", ".", "prepruning_finetune_steps", "=", "self", ".", "additional_args", ".", "prepruning_finetune_epochs", "*", "num_update_steps_per_epoch", "\n", "self", ".", "l0_module", ".", "set_lagrangian_warmup_steps", "(", "lagrangian_warmup_steps", ")", "\n", "logger", ".", "info", "(", "f\"Prepruning finetune steps: {self.prepruning_finetune_steps}\"", ")", "\n", "logger", ".", "info", "(", "f\"Lagrangian warmup steps: {lagrangian_warmup_steps}\"", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "max_steps", ">", "0", ":", "\n", "            ", "self", ".", "t_total", "=", "self", ".", "args", ".", "max_steps", "\n", "num_train_epochs", "=", "self", ".", "args", ".", "max_steps", "//", "num_update_steps_per_epoch", "+", "int", "(", "\n", "self", ".", "args", ".", "max_steps", "%", "num_update_steps_per_epoch", ">", "0", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "t_total", "=", "int", "(", "num_update_steps_per_epoch", "*", "\n", "self", ".", "args", ".", "num_train_epochs", ")", "\n", "num_train_epochs", "=", "self", ".", "args", ".", "num_train_epochs", "\n", "self", ".", "args", ".", "max_steps", "=", "self", ".", "t_total", "\n", "\n", "", "self", ".", "create_optimizer_and_scheduler", "(", "num_training_steps", "=", "self", ".", "t_total", ")", "\n", "\n", "model", "=", "self", ".", "model", "\n", "\n", "total_train_batch_size", "=", "(", "\n", "self", ".", "args", ".", "train_batch_size", "\n", "*", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "self", ".", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "self", ".", "num_examples", "(", "train_dataloader", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per device = %d\"", ",", "\n", "self", ".", "args", ".", "per_device_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "total_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "\n", "self", ".", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "self", ".", "t_total", ")", "\n", "\n", "self", ".", "global_step", "=", "0", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "total_flos", "=", "0", "\n", "\n", "epochs_trained", "=", "0", "\n", "\n", "tr_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "reg_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "lag_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "logging_loss_scalar", "=", "0.0", "\n", "logging_reg_loss_scalar", "=", "0.0", "\n", "logging_lag_loss_scalar", "=", "0.0", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "l0_module", "is", "not", "None", ":", "\n", "            ", "self", ".", "l0_module", ".", "zero_grad", "(", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "l0_optimizer", "is", "not", "None", ":", "\n", "            ", "self", ".", "l0_optimizer", ".", "zero_grad", "(", ")", "\n", "", "if", "self", ".", "lagrangian_optimizer", "is", "not", "None", ":", "\n", "            ", "self", ".", "lagrangian_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "disable_tqdm", "=", "self", ".", "args", ".", "disable_tqdm", "or", "not", "self", ".", "is_local_process_zero", "(", ")", "\n", "train_pbar", "=", "trange", "(", "epochs_trained", ",", "int", "(", "\n", "np", ".", "ceil", "(", "num_train_epochs", ")", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "disable_tqdm", ")", "\n", "\n", "self", ".", "evaluate", "(", ")", "\n", "\n", "# training", "\n", "for", "epoch", "in", "range", "(", "epochs_trained", ",", "int", "(", "np", ".", "ceil", "(", "num_train_epochs", ")", ")", ")", ":", "\n", "            ", "epoch_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "isinstance", "(", "train_dataloader", ",", "DataLoader", ")", "and", "isinstance", "(", "train_dataloader", ".", "sampler", ",", "DistributedSampler", ")", ":", "\n", "                ", "train_dataloader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "", "epoch_iterator", "=", "train_dataloader", "\n", "\n", "# Reset the past mems state at the beginning of each epoch if necessary.", "\n", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "                ", "self", ".", "_past", "=", "None", "\n", "\n", "", "epoch_pbar", "=", "tqdm", "(", "epoch_iterator", ",", "desc", "=", "\"Iteration\"", ",", "\n", "disable", "=", "disable_tqdm", ")", "\n", "self", ".", "eval_counter", ".", "clear", "(", ")", "\n", "\n", "for", "step", ",", "inputs", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "                ", "if", "self", ".", "prepruning_finetune_steps", ">", "0", "and", "self", ".", "global_step", "==", "self", ".", "prepruning_finetune_steps", ":", "\n", "                    ", "self", ".", "start_prune", "=", "True", "\n", "\n", "self", ".", "optimizer", "=", "None", "\n", "self", ".", "lr_scheduler", "=", "None", "\n", "lr_steps", "=", "self", ".", "t_total", "-", "self", ".", "global_step", "\n", "\n", "# reset the optimizer", "\n", "self", ".", "create_optimizer_and_scheduler", "(", "lr_steps", ")", "\n", "logger", ".", "info", "(", "\"Starting l0 regularization!\"", ")", "\n", "\n", "", "if", "self", ".", "start_prune", ":", "\n", "                    ", "zs", "=", "self", ".", "l0_module", ".", "forward", "(", "training", "=", "True", ")", "\n", "self", ".", "fill_inputs_with_zs", "(", "zs", ",", "inputs", ")", "\n", "\n", "", "loss_terms", "=", "self", ".", "training_step", "(", "model", ",", "inputs", ")", "\n", "tr_loss_step", "=", "loss_terms", "[", "\"loss\"", "]", "\n", "lag_loss_step", "=", "loss_terms", "[", "\"lagrangian_loss\"", "]", "\n", "\n", "tr_loss", "+=", "tr_loss_step", "\n", "lag_loss", "+=", "lag_loss_step", "if", "lag_loss_step", "is", "not", "None", "else", "0.0", "\n", "\n", "self", ".", "total_flos", "+=", "self", ".", "floating_point_ops", "(", "inputs", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "(", "\n", "len", "(", "epoch_iterator", ")", "<=", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "and", "(", "step", "+", "1", ")", "==", "len", "(", "epoch_iterator", ")", "\n", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "self", ".", "args", ".", "max_grad_norm", ")", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "self", ".", "l0_module", "is", "not", "None", "and", "self", ".", "l0_optimizer", "is", "not", "None", ":", "\n", "                        ", "self", ".", "l0_optimizer", ".", "step", "(", ")", "\n", "self", ".", "lagrangian_optimizer", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "                        ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "l0_module", "is", "not", "None", ":", "\n", "                        ", "self", ".", "l0_module", ".", "constrain_parameters", "(", ")", "\n", "\n", "", "model", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "l0_module", "is", "not", "None", ":", "\n", "                        ", "self", ".", "l0_module", ".", "zero_grad", "(", ")", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "l0_optimizer", "is", "not", "None", ":", "\n", "                        ", "self", ".", "l0_optimizer", ".", "zero_grad", "(", ")", "\n", "", "if", "self", ".", "lagrangian_optimizer", "is", "not", "None", ":", "\n", "                        ", "self", ".", "lagrangian_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "self", ".", "global_step", "+=", "1", "\n", "self", ".", "epoch", "=", "epoch", "+", "(", "step", "+", "1", ")", "/", "len", "(", "epoch_iterator", ")", "\n", "\n", "if", "(", "self", ".", "args", ".", "logging_steps", ">", "0", "and", "self", ".", "global_step", "%", "self", ".", "args", ".", "logging_steps", "==", "0", ")", "or", "(", "\n", "self", ".", "global_step", "==", "1", "and", "self", ".", "args", ".", "logging_first_step", "\n", ")", ":", "\n", "                        ", "logs", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "tr_loss_scalar", "=", "tr_loss", ".", "item", "(", ")", "\n", "reg_loss_scalar", "=", "reg_loss", ".", "item", "(", ")", "\n", "lag_loss_scalar", "=", "lag_loss", ".", "item", "(", ")", "\n", "\n", "logs", "[", "\"loss\"", "]", "=", "(", "\n", "tr_loss_scalar", "-", "logging_loss_scalar", ")", "/", "self", ".", "args", ".", "logging_steps", "\n", "logs", "[", "\"reg_loss\"", "]", "=", "(", "\n", "reg_loss_scalar", "-", "logging_reg_loss_scalar", ")", "/", "self", ".", "args", ".", "logging_steps", "\n", "logs", "[", "\"lag_loss\"", "]", "=", "(", "\n", "lag_loss_scalar", "-", "logging_lag_loss_scalar", ")", "/", "self", ".", "args", ".", "logging_steps", "\n", "\n", "# backward compatibility for pytorch schedulers", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "                            ", "lr", "=", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", "if", "version", ".", "parse", "(", "\n", "torch", ".", "__version__", ")", ">=", "version", ".", "parse", "(", "\"1.4\"", ")", "else", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "lr", "=", "self", ".", "args", ".", "learning_rate", "\n", "\n", "", "logs", "[", "\"learning_rate\"", "]", "=", "lr", "\n", "logging_loss_scalar", "=", "tr_loss_scalar", "\n", "logging_reg_loss_scalar", "=", "reg_loss_scalar", "\n", "logging_lag_loss_scalar", "=", "lag_loss_scalar", "\n", "\n", "self", ".", "log", "(", "logs", ")", "\n", "\n", "", "if", "self", ".", "global_step", "%", "self", ".", "args", ".", "eval_steps", "==", "0", ":", "\n", "                        ", "self", ".", "evaluate", "(", ")", "\n", "\n", "", "", "epoch_pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "self", ".", "args", ".", "max_steps", ">", "0", "and", "self", ".", "global_step", ">=", "self", ".", "args", ".", "max_steps", ":", "\n", "                    ", "break", "\n", "\n", "", "", "epoch_end", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\n", "f\"Epoch {epoch} finished. Took {round(epoch_end - epoch_start, 2)} seconds.\"", ")", "\n", "\n", "epoch_pbar", ".", "close", "(", ")", "\n", "train_pbar", ".", "update", "(", "1", ")", "\n", "\n", "if", "self", ".", "args", ".", "max_steps", ">", "0", "and", "self", ".", "global_step", ">=", "self", ".", "args", ".", "max_steps", ":", "\n", "                ", "break", "\n", "\n", "", "", "train_pbar", ".", "close", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "past_index", "and", "hasattr", "(", "self", ",", "\"_past\"", ")", ":", "\n", "# Clean the state at the end of training", "\n", "            ", "delattr", "(", "self", ",", "\"_past\"", ")", "\n", "\n", "", "return", "TrainOutput", "(", "self", ".", "global_step", ",", "tr_loss", ".", "item", "(", ")", "/", "self", ".", "global_step", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.prediction_loop": [[378, 494], ["logger.info", "logger.info", "logger.info", "model.eval", "enumerate", "transformers.trainer_utils.PredictionOutput", "trainer.CoFiTrainer.num_examples", "trainer.CoFiTrainer.l0_module.eval", "trainer.CoFiTrainer.l0_module.forward", "trainer.CoFiTrainer.l0_module.calculate_model_size", "tqdm.auto.tqdm.auto.tqdm", "trainer.CoFiTrainer.prediction_step", "hasattr", "delattr", "transformers.trainer_pt_utils.nested_numpify", "transformers.trainer_pt_utils.nested_numpify", "transformers.trainer_pt_utils.nested_numpify", "trainer.CoFiTrainer.compute_metrics", "numpy.mean", "trainer.CoFiTrainer.l0_module.lagrangian_regularization", "round", "trainer.CoFiTrainer.update", "trainer.CoFiTrainer.is_local_process_zero", "trainer.CoFiTrainer.fill_inputs_with_zs", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.concatenate", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_utils.EvalPrediction", "len", "round.item", "logger.info", "logger.info", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_pt_utils.nested_concat", "type", "loss.repeat", "torch.tensor.extend", "torch.tensor.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "int", "trainer.CoFiTrainer.keys", "list", "inputs.keys"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.forward", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.calculate_model_size", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.lagrangian_regularization", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.update", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.fill_inputs_with_zs"], ["", "def", "prediction_loop", "(", "self", ",", "dataloader", ":", "DataLoader", ",", "description", ":", "str", ",", "prediction_loss_only", ":", "Optional", "[", "bool", "]", "=", "None", ")", "->", "PredictionOutput", ":", "\n", "        ", "prediction_loss_only", "=", "(", "\n", "prediction_loss_only", "if", "prediction_loss_only", "is", "not", "None", "else", "self", ".", "args", ".", "prediction_loss_only", "\n", ")", "\n", "\n", "# disable output hidden states and attention during evaluation", "\n", "self", ".", "model", ".", "config", ".", "output_hidden_states", "=", "False", "\n", "self", ".", "model", ".", "config", ".", "output_attentions", "=", "False", "\n", "\n", "model", "=", "self", ".", "model", "\n", "\n", "# multi-gpu eval", "\n", "model", "=", "self", ".", "model", "\n", "\n", "batch_size", "=", "dataloader", ".", "batch_size", "\n", "logger", ".", "info", "(", "\"***** Running %s *****\"", ",", "description", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "self", ".", "num_examples", "(", "dataloader", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "batch_size", ")", "\n", "\n", "# Initialize containers", "\n", "# losses/preds/labels on GPU/TPU (accumulated for eval_accumulation_steps)", "\n", "losses_host", "=", "None", "\n", "preds_host", "=", "None", "\n", "labels_host", "=", "None", "\n", "# losses/preds/labels on CPU (final containers)", "\n", "all_losses", "=", "None", "\n", "all_preds", "=", "None", "\n", "all_labels", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "            ", "self", ".", "_past", "=", "None", "\n", "\n", "", "disable_tqdm", "=", "not", "self", ".", "is_local_process_zero", "(", ")", "or", "self", ".", "args", ".", "disable_tqdm", "\n", "\n", "zs", "=", "None", "\n", "if", "self", ".", "start_prune", ":", "\n", "            ", "self", ".", "l0_module", ".", "eval", "(", ")", "\n", "zs", "=", "self", ".", "l0_module", ".", "forward", "(", "training", "=", "False", ")", "\n", "\n", "", "if", "zs", "is", "not", "None", ":", "\n", "            ", "pruned_model_size_info", "=", "self", ".", "l0_module", ".", "calculate_model_size", "(", "zs", ")", "\n", "\n", "", "for", "ii", ",", "inputs", "in", "enumerate", "(", "tqdm", "(", "dataloader", ",", "desc", "=", "description", ",", "disable", "=", "disable_tqdm", ")", ")", ":", "\n", "            ", "if", "zs", "is", "not", "None", ":", "\n", "                ", "if", "ii", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Putting zs {zs.keys()} into inputs:\"", ")", "\n", "", "self", ".", "fill_inputs_with_zs", "(", "zs", ",", "inputs", ")", "\n", "", "loss", ",", "logits", ",", "labels", "=", "self", ".", "prediction_step", "(", "\n", "model", ",", "inputs", ",", "prediction_loss_only", ")", "\n", "\n", "batch_size", "=", "inputs", "[", "list", "(", "inputs", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "\n", "\n", "if", "logits", "is", "not", "None", ":", "\n", "                ", "preds_host", "=", "logits", "if", "preds_host", "is", "None", "else", "nested_concat", "(", "\n", "preds_host", ",", "logits", ")", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "                ", "labels_host", "=", "labels", "if", "labels_host", "is", "None", "else", "nested_concat", "(", "\n", "labels_host", ",", "labels", ")", "\n", "", "if", "loss", "is", "not", "None", ":", "\n", "                ", "if", "type", "(", "loss", ")", "==", "float", ":", "\n", "                    ", "losses", "=", "[", "loss", "]", "*", "batch_size", "\n", "if", "losses_host", "is", "None", ":", "\n", "                        ", "losses_host", "=", "losses", "\n", "", "else", ":", "\n", "                        ", "losses_host", ".", "extend", "(", "losses", ")", "\n", "", "", "else", ":", "\n", "                    ", "losses", "=", "loss", ".", "repeat", "(", "batch_size", ")", "\n", "losses_host", "=", "losses", "if", "losses_host", "is", "None", "else", "torch", ".", "cat", "(", "\n", "(", "losses_host", ",", "losses", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "", "if", "self", ".", "args", ".", "past_index", "and", "hasattr", "(", "self", ",", "\"_past\"", ")", ":", "\n", "# Clean the state at the end of the evaluation.py loop", "\n", "            ", "delattr", "(", "self", ",", "\"_past\"", ")", "\n", "\n", "", "if", "losses_host", "is", "not", "None", ":", "\n", "            ", "if", "not", "torch", ".", "is_tensor", "(", "losses_host", ")", ":", "\n", "                ", "losses_host", "=", "torch", ".", "tensor", "(", "losses_host", ")", "\n", "", "losses", "=", "nested_numpify", "(", "losses_host", ")", "\n", "all_losses", "=", "losses", "if", "all_losses", "is", "None", "else", "np", ".", "concatenate", "(", "\n", "(", "all_losses", ",", "losses", ")", ",", "axis", "=", "0", ")", "\n", "", "if", "preds_host", "is", "not", "None", ":", "\n", "            ", "logits", "=", "nested_numpify", "(", "preds_host", ")", "\n", "all_preds", "=", "logits", "if", "all_preds", "is", "None", "else", "nested_concat", "(", "\n", "all_preds", ",", "logits", ",", "padding_index", "=", "-", "100", ")", "\n", "", "if", "labels_host", "is", "not", "None", ":", "\n", "            ", "labels", "=", "nested_numpify", "(", "labels_host", ")", "\n", "all_labels", "=", "labels", "if", "all_labels", "is", "None", "else", "nested_concat", "(", "\n", "all_labels", ",", "labels", ",", "padding_index", "=", "-", "100", ")", "\n", "\n", "", "if", "self", ".", "compute_metrics", "is", "not", "None", "and", "all_preds", "is", "not", "None", "and", "all_labels", "is", "not", "None", ":", "\n", "            ", "metrics", "=", "self", ".", "compute_metrics", "(", "EvalPrediction", "(", "\n", "predictions", "=", "all_preds", ",", "label_ids", "=", "all_labels", ")", ")", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "\n", "", "if", "all_losses", "is", "not", "None", "and", "len", "(", "all_losses", ")", ">", "0", ":", "\n", "            ", "metrics", "[", "\"eval_loss\"", "]", "=", "np", ".", "mean", "(", "all_losses", ")", "\n", "\n", "", "if", "zs", "is", "not", "None", ":", "\n", "            ", "lag_loss", ",", "expected_sparsity", ",", "target_sparsity", "=", "self", ".", "l0_module", ".", "lagrangian_regularization", "(", "\n", "self", ".", "global_step", "-", "self", ".", "prepruning_finetune_steps", ")", "\n", "\n", "expected_sparsity", "=", "round", "(", "expected_sparsity", ".", "item", "(", ")", ",", "5", ")", "\n", "metrics", ".", "update", "(", "pruned_model_size_info", ")", "\n", "metrics", "[", "\"expected_sparsity\"", "]", "=", "expected_sparsity", "\n", "metrics", "[", "\"target_sparsity\"", "]", "=", "target_sparsity", "\n", "\n", "if", "(", "not", "self", ".", "start_saving_best", ")", "and", "(", "expected_sparsity", "-", "self", ".", "additional_args", ".", "target_sparsity", ">=", "-", "self", ".", "additional_args", ".", "sparsity_epsilon", ")", ":", "\n", "                ", "self", ".", "start_saving_best", "=", "True", "\n", "logger", ".", "info", "(", "f\"Starting saving the best from epoch {int(self.epoch)} and step {self.global_step}\"", ")", "\n", "\n", "", "", "self", ".", "model", ".", "config", ".", "output_hidden_states", "=", "True", "\n", "self", ".", "model", ".", "config", ".", "output_attentions", "=", "True", "\n", "\n", "return", "PredictionOutput", "(", "predictions", "=", "all_preds", ",", "label_ids", "=", "all_labels", ",", "metrics", "=", "metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.evaluate": [[495, 536], ["trainer.CoFiTrainer.get_eval_dataloader", "trainer.CoFiTrainer.prediction_loop", "trainer.CoFiTrainer.log", "logger.info", "isinstance", "trainer.CoFiTrainer.eval_counter.update", "os.path.join", "logger.info", "trainer.CoFiTrainer.model.save_pretrained", "os.path.exists", "os.makedirs", "trainer.CoFiTrainer.l0_module.forward", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join", "int", "round"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.prediction_loop", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.Eval_Counter.update", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.forward"], ["", "def", "evaluate", "(", "self", ",", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "float", "]", ",", "List", "]", ":", "\n", "        ", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", "eval_dataset", ")", "\n", "output", "=", "self", ".", "prediction_loop", "(", "\n", "eval_dataloader", ",", "description", "=", "\"Evaluation\"", ")", "\n", "\n", "self", ".", "log", "(", "output", ".", "metrics", ")", "\n", "output", ".", "metrics", "[", "\"step\"", "]", "=", "self", ".", "global_step", "\n", "\n", "logger", ".", "info", "(", "f\"Evaluating: {output.metrics}\"", ")", "\n", "\n", "eval_score", "=", "0", "\n", "\n", "name", "=", "glue_tasks", "[", "self", ".", "model", ".", "config", ".", "finetuning_task", "]", "\n", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "            ", "if", "name", "in", "output", ".", "metrics", ":", "\n", "                ", "eval_score", "=", "output", ".", "metrics", "[", "name", "]", "\n", "", "", "else", ":", "\n", "            ", "for", "na", "in", "name", ":", "\n", "                ", "if", "na", "in", "output", ".", "metrics", ":", "\n", "                    ", "eval_score", "=", "output", ".", "metrics", "[", "na", "]", "\n", "break", "\n", "\n", "# logger.info(f\"starting saving best: {self.global_step} {self.start_saving_best}\")", "\n", "\n", "", "", "", "if", "self", ".", "start_saving_best", ":", "\n", "            ", "best_so_far", "=", "self", ".", "eval_counter", ".", "update", "(", "\n", "self", ".", "epoch", ",", "self", ".", "global_step", ",", "eval_score", ")", "\n", "if", "best_so_far", ":", "\n", "                ", "best_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "\"best\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "best_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "best_dir", ")", "\n", "\n", "", "if", "self", ".", "l0_module", "is", "not", "None", ":", "\n", "                    ", "zs", "=", "self", ".", "l0_module", ".", "forward", "(", "training", "=", "False", ")", "\n", "torch", ".", "save", "(", "zs", ",", "os", ".", "path", ".", "join", "(", "best_dir", ",", "\"zs.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "l0_module", ",", "os", ".", "path", ".", "join", "(", "\n", "best_dir", ",", "\"l0_module.pt\"", ")", ")", "\n", "", "logger", ".", "info", "(", "f\"Saving the best model so far: [Epoch {int(self.epoch)} | Step: {self.global_step} | Model size: {output.metrics['remaining_params'] if 'remaining_params' in output.metrics else 'Full' } | Score: {round(eval_score, 5)}]\"", ")", "\n", "self", ".", "model", ".", "save_pretrained", "(", "best_dir", ")", "\n", "\n", "", "", "return", "output", ".", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.save_model": [[537, 545], ["torch.save", "torch.save", "torch.save", "torch.save", "trainer.CoFiTrainer.l0_module.forward", "torch.save", "torch.save", "torch.save", "torch.save", "trainer.CoFiTrainer.model.save_pretrained", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.modeling_bert.CoFiBertForQuestionAnswering.forward"], ["", "def", "save_model", "(", "self", ",", "output_dir", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "output_dir", "=", "output_dir", "if", "output_dir", "is", "not", "None", "else", "self", ".", "args", ".", "output_dir", "\n", "torch", ".", "save", "(", "self", ".", "l0_module", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"l0_module.pt\"", ")", ")", "\n", "\n", "zs", "=", "self", ".", "l0_module", ".", "forward", "(", "training", "=", "False", ")", "\n", "torch", ".", "save", "(", "zs", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"zs.pt\"", ")", ")", "\n", "\n", "self", ".", "model", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.calculate_layer_distillation_loss": [[546, 622], ["torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "zs[].detach().cpu", "zs[].detach().cpu", "enumerate", "zip", "trainer.CoFiTrainer.model.layer_transformation", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.stack().reshape", "torch.stack().reshape", "torch.stack().reshape", "torch.stack().reshape", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "layerwiseloss[].sum", "zs[].detach", "zs[].detach", "trainer.CoFiTrainer.model.layer_transformation", "enumerate", "len", "len", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "logger.info", "torch.nn.MSELoss.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "range", "torch.tensor().to.reverse", "torch.tensor().to.reverse", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "logger.info", "sys.exit", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.tensor().to.append", "torch.tensor().to.append", "str", "layerwiseloss[].sort", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "calculate_layer_distillation_loss", "(", "self", ",", "teacher_outputs", ",", "student_outputs", ",", "zs", ")", ":", "\n", "        ", "mse_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "if", "self", ".", "additional_args", ".", "do_layer_distill", ":", "\n", "            ", "mlp_z", "=", "None", "\n", "head_layer_z", "=", "None", "\n", "if", "\"mlp_z\"", "in", "zs", ":", "\n", "                ", "mlp_z", "=", "zs", "[", "\"mlp_z\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "if", "\"head_layer_z\"", "in", "zs", ":", "\n", "                ", "head_layer_z", "=", "zs", "[", "\"head_layer_z\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "", "teacher_layer_output", "=", "teacher_outputs", "[", "2", "]", "[", "1", ":", "]", "\n", "student_layer_output", "=", "student_outputs", "[", "2", "]", "[", "1", ":", "]", "\n", "\n", "# distilliting existing layers", "\n", "if", "self", ".", "additional_args", ".", "layer_distill_version", "==", "2", ":", "\n", "                ", "for", "layer_num", ",", "(", "t_layer_o", ",", "s_layer_o", ")", "in", "enumerate", "(", "zip", "(", "teacher_layer_output", ",", "student_layer_output", ")", ")", ":", "\n", "                    ", "s_layer_o", "=", "self", ".", "model", ".", "layer_transformation", "(", "s_layer_o", ")", "\n", "l", "=", "mse_loss", "(", "t_layer_o", ",", "s_layer_o", ")", "\n", "if", "mlp_z", "[", "layer_num", "]", ">", "0", ":", "\n", "                        ", "layer_loss", "+=", "l", "\n", "\n", "# distilling layers with a minimal distance", "\n", "", "", "", "elif", "self", ".", "additional_args", ".", "layer_distill_version", ">", "2", ":", "\n", "                ", "l", "=", "[", "]", "\n", "specified_teacher_layers", "=", "[", "2", ",", "5", ",", "8", ",", "11", "]", "\n", "transformed_s_layer_o", "=", "[", "self", ".", "model", ".", "layer_transformation", "(", "\n", "s_layer_o", ")", "for", "s_layer_o", "in", "student_layer_output", "]", "\n", "specified_teacher_layer_reps", "=", "[", "\n", "teacher_layer_output", "[", "i", "]", "for", "i", "in", "specified_teacher_layers", "]", "\n", "\n", "device", "=", "transformed_s_layer_o", "[", "0", "]", ".", "device", "\n", "for", "t_layer_o", "in", "specified_teacher_layer_reps", ":", "\n", "                    ", "for", "i", ",", "s_layer_o", "in", "enumerate", "(", "transformed_s_layer_o", ")", ":", "\n", "                        ", "l", ".", "append", "(", "mse_loss", "(", "t_layer_o", ",", "s_layer_o", ")", ")", "\n", "", "", "layerwiseloss", "=", "torch", ".", "stack", "(", "l", ")", ".", "reshape", "(", "\n", "len", "(", "specified_teacher_layer_reps", ")", ",", "len", "(", "student_layer_output", ")", ")", "\n", "\n", "existing_layers", "=", "None", "\n", "if", "head_layer_z", "is", "not", "None", ":", "\n", "                    ", "existing_layers", "=", "head_layer_z", "!=", "0", "\n", "\n", "", "layer_loss", "=", "0", "\n", "# no ordering restriction specified", "\n", "if", "self", ".", "additional_args", ".", "layer_distill_version", "==", "3", ":", "\n", "                    ", "alignment", "=", "torch", ".", "argmin", "(", "layerwiseloss", ",", "dim", "=", "1", ")", "\n", "# added the ordering restriction", "\n", "", "elif", "self", ".", "additional_args", ".", "layer_distill_version", "==", "4", ":", "\n", "                    ", "last_aligned_layer", "=", "12", "\n", "alignment", "=", "[", "]", "\n", "for", "search_index", "in", "range", "(", "3", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "                        ", "indexes", "=", "layerwiseloss", "[", "search_index", "]", ".", "sort", "(", ")", "[", "1", "]", "\n", "if", "existing_layers", "is", "not", "None", ":", "\n", "                            ", "align", "=", "indexes", "[", "(", "\n", "indexes", "<", "last_aligned_layer", ")", "&", "existing_layers", "]", "\n", "", "else", ":", "\n", "                            ", "align", "=", "indexes", "[", "indexes", "<", "last_aligned_layer", "]", "\n", "", "if", "len", "(", "align", ")", ">", "0", ":", "\n", "                            ", "align", "=", "align", "[", "0", "]", "\n", "", "else", ":", "\n", "                            ", "align", "=", "last_aligned_layer", "\n", "", "alignment", ".", "append", "(", "align", ")", "\n", "last_aligned_layer", "=", "align", "\n", "", "alignment", ".", "reverse", "(", ")", "\n", "alignment", "=", "torch", ".", "tensor", "(", "alignment", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "info", "(", "\n", "f\"{self.additional_args.layer_distill_version} version is not specified.\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "layerwise", "=", "torch", ".", "arange", "(", "4", ")", ".", "to", "(", "device", ")", "\n", "layer_loss", "+=", "layerwiseloss", "[", "layerwise", ",", "alignment", "]", ".", "sum", "(", ")", "\n", "if", "self", ".", "global_step", "%", "100", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"v{self.additional_args.layer_distill_version} Global step: {self.global_step}, Alignment: \"", "+", "str", "(", "alignment", ")", ")", "\n", "", "", "return", "layer_loss", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.calculate_distillation_loss": [[623, 639], ["trainer.CoFiTrainer.calculate_layer_distillation_loss", "torch.kl_div", "torch.kl_div", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.calculate_layer_distillation_loss"], ["", "", "def", "calculate_distillation_loss", "(", "self", ",", "teacher_outputs", ",", "student_outputs", ",", "zs", ")", ":", "\n", "        ", "layer_loss", "=", "self", ".", "calculate_layer_distillation_loss", "(", "teacher_outputs", ",", "student_outputs", ",", "zs", ")", "\n", "distill_loss", "=", "layer_loss", "\n", "\n", "ce_distill_loss", "=", "F", ".", "kl_div", "(", "\n", "input", "=", "F", ".", "log_softmax", "(", "\n", "student_outputs", "[", "1", "]", "/", "self", ".", "additional_args", ".", "distill_temp", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "F", ".", "softmax", "(", "\n", "teacher_outputs", "[", "1", "]", "/", "self", ".", "additional_args", ".", "distill_temp", ",", "dim", "=", "-", "1", ")", ",", "\n", "reduction", "=", "\"batchmean\"", ")", "*", "(", "self", ".", "additional_args", ".", "distill_temp", "**", "2", ")", "\n", "\n", "loss", "=", "self", ".", "additional_args", ".", "distill_ce_loss_alpha", "*", "ce_distill_loss", "\n", "if", "distill_loss", "is", "not", "None", ":", "\n", "            ", "loss", "+=", "self", ".", "additional_args", ".", "distill_loss_alpha", "*", "distill_loss", "\n", "\n", "", "return", "distill_loss", ",", "ce_distill_loss", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.shortens_inputs": [[640, 646], ["inputs[].sum().max().item", "inputs[].sum().max", "inputs[].sum"], "methods", ["None"], ["", "def", "shortens_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "max_length", "=", "inputs", "[", "\"attention_mask\"", "]", ".", "sum", "(", "-", "1", ")", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "inputs", "[", "\"input_ids\"", "]", "=", "inputs", "[", "\"input_ids\"", "]", "[", ":", ",", ":", "max_length", "]", "\n", "inputs", "[", "\"attention_mask\"", "]", "=", "inputs", "[", "\"attention_mask\"", "]", "[", ":", ",", ":", "max_length", "]", "\n", "if", "\"token_type_ids\"", "in", "inputs", ":", "\n", "            ", "inputs", "[", "\"token_type_ids\"", "]", "=", "inputs", "[", "\"token_type_ids\"", "]", "[", ":", ",", ":", "max_length", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.training_step": [[647, 688], ["model.train", "trainer.CoFiTrainer._prepare_inputs", "trainer.CoFiTrainer.backward", "trainer.CoFiTrainer.l0_module.train", "trainer.CoFiTrainer.shortens_inputs", "model", "trainer.CoFiTrainer.calculate_distillation_loss", "trainer.CoFiTrainer.compute_loss", "trainer.CoFiTrainer.l0_module.lagrangian_regularization", "trainer.CoFiTrainer.detach", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "trainer.CoFiTrainer.shortens_inputs", "trainer.CoFiTrainer.teacher_model", "lagrangian_loss.detach", "distill_loss.detach", "distill_ce_loss.detach"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.train", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.train", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.shortens_inputs", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.calculate_distillation_loss", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.models.l0_module.L0Module.lagrangian_regularization", "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.shortens_inputs"], ["", "", "def", "training_step", "(", "self", ",", "model", ":", "torch", ".", "nn", ".", "Module", ",", "inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "l0_module", "is", "not", "None", ":", "\n", "            ", "self", ".", "l0_module", ".", "train", "(", ")", "\n", "", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "\n", "distill_loss", "=", "None", "\n", "distill_ce_loss", "=", "None", "\n", "if", "self", ".", "teacher_model", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# only retain inputs of certain keys", "\n", "                ", "teacher_inputs_keys", "=", "[", "\"input_ids\"", ",", "\"attention_mask\"", ",", "\"token_type_ids\"", ",", "\"position_ids\"", ",", "\"labels\"", ",", "\n", "\"output_attentions\"", ",", "\"output_hidden_states\"", ",", "\"return_dict\"", "]", "\n", "teacher_inputs", "=", "{", "key", ":", "inputs", "[", "key", "]", "\n", "for", "key", "in", "teacher_inputs_keys", "if", "key", "in", "inputs", "}", "\n", "self", ".", "shortens_inputs", "(", "teacher_inputs", ")", "\n", "teacher_outputs", "=", "self", ".", "teacher_model", "(", "**", "teacher_inputs", ")", "\n", "", "self", ".", "shortens_inputs", "(", "inputs", ")", "\n", "student_outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "zs", "=", "{", "key", ":", "inputs", "[", "key", "]", "for", "key", "in", "inputs", "if", "\"_z\"", "in", "key", "}", "\n", "distill_loss", ",", "distill_ce_loss", ",", "loss", "=", "self", ".", "calculate_distillation_loss", "(", "\n", "teacher_outputs", ",", "student_outputs", ",", "zs", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "compute_loss", "(", "model", ",", "inputs", ")", "\n", "\n", "", "lagrangian_loss", "=", "None", "\n", "if", "self", ".", "start_prune", ":", "\n", "            ", "lagrangian_loss", ",", "_", ",", "_", "=", "self", ".", "l0_module", ".", "lagrangian_regularization", "(", "\n", "self", ".", "global_step", "-", "self", ".", "prepruning_finetune_steps", ")", "\n", "loss", "+=", "lagrangian_loss", "\n", "\n", "", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "            ", "loss", "=", "loss", "/", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "return", "{", "\"loss\"", ":", "loss", ".", "detach", "(", ")", ",", "\n", "\"lagrangian_loss\"", ":", "lagrangian_loss", ".", "detach", "(", ")", "if", "lagrangian_loss", "is", "not", "None", "else", "None", ",", "\n", "\"distill_layer_loss\"", ":", "distill_loss", ".", "detach", "(", ")", "if", "distill_loss", "is", "not", "None", "else", "None", ",", "\n", "\"distill_ce_loss\"", ":", "distill_ce_loss", ".", "detach", "(", ")", "if", "distill_ce_loss", "is", "not", "None", "else", "None", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_cofipruning.trainer.trainer.CoFiTrainer.fill_inputs_with_zs": [[689, 692], ["None"], "methods", ["None"], ["", "def", "fill_inputs_with_zs", "(", "self", ",", "zs", ",", "inputs", ")", ":", "\n", "        ", "for", "key", "in", "zs", ":", "\n", "            ", "inputs", "[", "key", "]", "=", "zs", "[", "key", "]", "\n", "", "", "", ""]]}