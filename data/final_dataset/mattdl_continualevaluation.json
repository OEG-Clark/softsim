{"home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_scenario": [[164, 244], ["print", "print", "avalanche.benchmarks.SplitMNIST", "avalanche.benchmarks.PermutedMNIST", "avalanche.benchmarks.RotatedMNIST", "src.benchmarks.digits_benchmark.DigitsBenchmark", "range", "src.benchmarks.domainnet_benchmark.MiniDomainNetBenchmark", "torchvision.transforms.Compose", "avalanche.benchmarks.SplitCIFAR10", "range", "src.benchmarks.miniimagenet_benchmark.SplitMiniImageNet", "ValueError", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "range", "range"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.SplitMNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.PermutedMNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.RotatedMNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark.DigitsBenchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet_benchmark.MiniDomainNetBenchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar10.SplitCIFAR10", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark.SplitMiniImageNet"], ["def", "get_scenario", "(", "args", ",", "seed", ")", ":", "\n", "    ", "print", "(", "f\"[SCENARIO] {args.scenario}, Task Incr = {args.task_incr}\"", ")", "\n", "\n", "if", "args", ".", "scenario", "==", "'smnist'", ":", "#", "\n", "        ", "args", ".", "input_size", "=", "(", "1", ",", "28", ",", "28", ")", "\n", "n_classes", "=", "10", "\n", "n_experiences", "=", "5", "\n", "scenario", "=", "SplitMNIST", "(", "n_experiences", "=", "n_experiences", ",", "return_task_id", "=", "args", ".", "task_incr", ",", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "[", "i", "for", "i", "in", "range", "(", "n_classes", ")", "]", ")", "\n", "scenario", ".", "n_classes", "=", "n_classes", "\n", "args", ".", "initial_out_features", "=", "n_classes", "//", "n_experiences", "# For Multi-Head", "\n", "\n", "", "elif", "args", ".", "scenario", "==", "'pmnist'", ":", "#", "\n", "        ", "assert", "not", "args", ".", "task_incr", ",", "\"Domain incremental can't be multi-head.\"", "\n", "args", ".", "input_size", "=", "(", "1", ",", "28", ",", "28", ")", "\n", "n_classes", "=", "10", "\n", "scenario", "=", "PermutedMNIST", "(", "n_experiences", "=", "5", ",", "seed", "=", "seed", ")", "\n", "scenario", ".", "n_classes", "=", "n_classes", "\n", "\n", "", "elif", "args", ".", "scenario", "==", "'rotmnist'", ":", "# Domain-incremental", "\n", "        ", "assert", "not", "args", ".", "task_incr", ",", "\"Domain incremental can't be multi-head.\"", "\n", "args", ".", "input_size", "=", "(", "1", ",", "28", ",", "28", ")", "\n", "n_classes", "=", "10", "\n", "n_experiences", "=", "20", "\n", "scenario", "=", "RotatedMNIST", "(", "n_experiences", "=", "n_experiences", ",", "\n", "rotations_list", "=", "[", "t", "*", "(", "180", "/", "n_experiences", ")", "for", "t", "in", "range", "(", "n_experiences", ")", "]", ")", "\n", "scenario", ".", "n_classes", "=", "n_classes", "\n", "\n", "", "elif", "args", ".", "scenario", "==", "'digits'", ":", "# Domain-incremental", "\n", "        ", "assert", "not", "args", ".", "task_incr", ",", "\"Domain incremental can't be multi-head.\"", "\n", "args", ".", "input_size", "=", "(", "3", ",", "32", ",", "32", ")", "\n", "n_classes", "=", "10", "\n", "scenario", "=", "DigitsBenchmark", "(", ")", "\n", "scenario", ".", "n_classes", "=", "n_classes", "\n", "\n", "", "elif", "args", ".", "scenario", "==", "'minidomainnet'", ":", "\n", "        ", "assert", "not", "args", ".", "task_incr", ",", "\"Domain incremental can't be multi-head.\"", "\n", "args", ".", "input_size", "=", "(", "3", ",", "96", ",", "96", ")", "\n", "n_classes", "=", "126", "\n", "scenario", "=", "MiniDomainNetBenchmark", "(", "dataset_root", "=", "args", ".", "dset_rootpath", ")", "\n", "scenario", ".", "n_classes", "=", "n_classes", "\n", "\n", "", "elif", "args", ".", "scenario", "==", "'CIFAR10'", ":", "\n", "        ", "args", ".", "input_size", "=", "(", "3", ",", "32", ",", "32", ")", "\n", "n_classes", "=", "10", "\n", "n_experiences", "=", "5", "\n", "\n", "# Use minimal transforms", "\n", "train_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "\n", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", "\n", "]", ")", "\n", "test_transform", "=", "train_transform", "\n", "scenario", "=", "SplitCIFAR10", "(", "n_experiences", "=", "n_experiences", ",", "return_task_id", "=", "args", ".", "task_incr", ",", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "[", "i", "for", "i", "in", "range", "(", "n_classes", ")", "]", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "test_transform", ")", "\n", "scenario", ".", "n_classes", "=", "n_classes", "\n", "args", ".", "initial_out_features", "=", "n_classes", "//", "n_experiences", "# For Multi-Head", "\n", "\n", "", "elif", "args", ".", "scenario", "==", "'miniimgnet'", ":", "\n", "        ", "args", ".", "input_size", "=", "(", "3", ",", "84", ",", "84", ")", "\n", "n_classes", "=", "100", "\n", "n_experiences", "=", "20", "\n", "scenario", "=", "SplitMiniImageNet", "(", "args", ".", "dset_rootpath", ",", "n_experiences", "=", "n_experiences", ",", "return_task_id", "=", "args", ".", "task_incr", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "[", "i", "for", "i", "in", "range", "(", "n_classes", ")", "]", ",", "preprocessed", "=", "True", ")", "\n", "scenario", ".", "n_classes", "=", "n_classes", "\n", "args", ".", "initial_out_features", "=", "n_classes", "//", "n_experiences", "# For Multi-Head", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Wrong scenario name.\"", ")", "\n", "\n", "# Cutoff if applicable", "\n", "", "scenario", ".", "train_stream", "=", "scenario", ".", "train_stream", "[", ":", "args", ".", "partial_num_tasks", "]", "\n", "scenario", ".", "test_stream", "=", "scenario", ".", "test_stream", "[", ":", "args", ".", "partial_num_tasks", "]", "\n", "\n", "print", "(", "f\"Scenario = {args.scenario}\"", ")", "\n", "return", "scenario", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_continual_evaluation_plugins": [[246, 297], ["print", "src.eval.continual_eval_metrics.TaskTrackingLossPluginMetric", "src.eval.continual_eval_metrics.TaskTrackingAccuracyPluginMetric", "src.eval.continual_eval_metrics.TrackingLCAPluginMetric", "src.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric", "src.eval.continual_eval_metrics.TaskAveragingPluginMetric", "src.eval.continual_eval_metrics.WCACCPluginMetric", "src.eval.continual_eval_metrics.WindowedForgettingPluginMetric", "src.eval.continual_eval_metrics.TaskAveragingPluginMetric", "src.eval.continual_eval_metrics.WindowedForgettingPluginMetric", "src.eval.continual_eval_metrics.TaskAveragingPluginMetric", "src.eval.continual_eval_metrics.WindowedPlasticityPluginMetric", "src.eval.continual_eval_metrics.TaskAveragingPluginMetric", "src.eval.continual_eval_metrics.WindowedPlasticityPluginMetric", "src.eval.continual_eval_metrics.TaskAveragingPluginMetric", "src.eval.continual_eval.ContinualEvaluationPhasePlugin", "src.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric", "src.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric"], "function", ["None"], ["", "def", "get_continual_evaluation_plugins", "(", "args", ",", "scenario", ")", ":", "\n", "    ", "\"\"\"Plugins for per-iteration evaluation in Avalanche.\"\"\"", "\n", "assert", "args", ".", "eval_periodicity", ">=", "1", ",", "\"Need positive \"", "\n", "\n", "if", "args", ".", "eval_with_test_data", ":", "\n", "        ", "args", ".", "evalstream_during_training", "=", "scenario", ".", "test_stream", "# Entire test stream", "\n", "", "else", ":", "\n", "        ", "args", ".", "evalstream_during_training", "=", "scenario", ".", "train_stream", "# Entire train stream", "\n", "", "print", "(", "f\"Evaluating on stream (eval={args.eval_with_test_data}): {args.evalstream_during_training}\"", ")", "\n", "\n", "# Metrics", "\n", "loss_tracking", "=", "TaskTrackingLossPluginMetric", "(", ")", "\n", "gradnorm_tracking", "=", "TaskTrackingGradnormPluginMetric", "(", ")", "if", "args", ".", "track_gradnorm", "else", "None", "# Memory+compute expensive", "\n", "featdrift_tracking", "=", "TaskTrackingFeatureDriftPluginMetric", "(", ")", "if", "args", ".", "track_features", "else", "None", "# Memory expensive", "\n", "\n", "# Acc derived plugins", "\n", "acc_tracking", "=", "TaskTrackingAccuracyPluginMetric", "(", ")", "\n", "lca", "=", "TrackingLCAPluginMetric", "(", ")", "\n", "\n", "acc_min", "=", "TaskTrackingMINAccuracyPluginMetric", "(", ")", "\n", "acc_min_avg", "=", "TaskAveragingPluginMetric", "(", "acc_min", ")", "\n", "wc_acc_avg", "=", "WCACCPluginMetric", "(", "acc_min", ")", "\n", "\n", "wforg_10", "=", "WindowedForgettingPluginMetric", "(", "window_size", "=", "10", ")", "\n", "wforg_10_avg", "=", "TaskAveragingPluginMetric", "(", "wforg_10", ")", "\n", "wforg_100", "=", "WindowedForgettingPluginMetric", "(", "window_size", "=", "100", ")", "\n", "wforg_100_avg", "=", "TaskAveragingPluginMetric", "(", "wforg_100", ")", "\n", "\n", "wplast_10", "=", "WindowedPlasticityPluginMetric", "(", "window_size", "=", "10", ")", "\n", "wplast_10_avg", "=", "TaskAveragingPluginMetric", "(", "wplast_10", ")", "\n", "wplast_100", "=", "WindowedPlasticityPluginMetric", "(", "window_size", "=", "100", ")", "\n", "wplast_100_avg", "=", "TaskAveragingPluginMetric", "(", "wplast_100", ")", "\n", "\n", "tracking_plugins", "=", "[", "\n", "loss_tracking", ",", "gradnorm_tracking", ",", "featdrift_tracking", ",", "acc_tracking", ",", "\n", "lca", ",", "# LCA from A-GEM (is always avged)", "\n", "acc_min", ",", "acc_min_avg", ",", "wc_acc_avg", ",", "# min-acc/worst-case accuracy", "\n", "wforg_10", ",", "wforg_10_avg", ",", "# Per-task metric, than avging metric", "\n", "wforg_100", ",", "wforg_100_avg", ",", "# Per-task metric, than avging metric", "\n", "wplast_10", ",", "wplast_10_avg", ",", "# Per-task metric, than avging metric", "\n", "wplast_100", ",", "wplast_100_avg", ",", "# Per-task metric, than avging metric", "\n", "]", "\n", "tracking_plugins", "=", "[", "p", "for", "p", "in", "tracking_plugins", "if", "p", "is", "not", "None", "]", "\n", "\n", "trackerphase_plugin", "=", "ContinualEvaluationPhasePlugin", "(", "tracking_plugins", "=", "tracking_plugins", ",", "\n", "max_task_subset_size", "=", "args", ".", "eval_task_subset_size", ",", "\n", "eval_stream", "=", "args", ".", "evalstream_during_training", ",", "\n", "mb_update_freq", "=", "args", ".", "eval_periodicity", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", ")", "\n", "return", "[", "trackerphase_plugin", ",", "*", "tracking_plugins", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_metrics": [[299, 352], ["minibatch_tracker_plugins.extend", "main.get_continual_evaluation_plugins", "minibatch_tracker_plugins.extend", "range", "avalanche.evaluation.metrics.accuracy_metrics", "avalanche.evaluation.metrics.loss_metrics", "avalanche.evaluation.metrics.ExperienceForgetting", "avalanche.evaluation.metrics.StreamForgetting", "avalanche.evaluation.metrics.StreamConfusionMatrix", "avalanche.evaluation.metrics.timing_metrics", "minibatch_tracker_plugins.extend", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin", "src.eval.minibatch_logging.StrategyAttributeTrackerPlugin"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_continual_evaluation_plugins", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.accuracy_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.loss_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.timing_metrics"], ["", "def", "get_metrics", "(", "scenario", ",", "args", ")", ":", "\n", "    ", "\"\"\"Metrics are calculated efficiently as running avgs.\"\"\"", "\n", "\n", "# Pass plugins, but stat_collector must be called first", "\n", "minibatch_tracker_plugins", "=", "[", "]", "\n", "\n", "# Stats on external tracking stream", "\n", "if", "args", ".", "enable_continual_eval", ":", "\n", "        ", "tracking_plugins", "=", "get_continual_evaluation_plugins", "(", "args", ",", "scenario", ")", "\n", "minibatch_tracker_plugins", ".", "extend", "(", "tracking_plugins", ")", "\n", "\n", "# Current minibatch stats per class", "\n", "", "if", "args", ".", "track_class_stats", ":", "\n", "        ", "for", "y", "in", "range", "(", "scenario", ".", "n_classes", ")", ":", "\n", "            ", "minibatch_tracker_plugins", ".", "extend", "(", "[", "\n", "# Loss components", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "f\"Lce_numerator_c{y}\"", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "f\"Lce_denominator_c{y}\"", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "f\"Lce_c{y}\"", "]", ")", ",", "\n", "\n", "# Prototypes", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "f'protodelta_weight_c{y}'", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "f'protonorm_weight_c{y}'", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "f'protodelta_bias_c{y}'", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "f'protonorm_bias_c{y}'", "]", ")", ",", "\n", "]", ")", "\n", "\n", "# METRICS FOR STRATEGIES (Will only track if available for method)", "\n", "", "", "minibatch_tracker_plugins", ".", "extend", "(", "[", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "\"loss_new\"", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "\"loss_reg\"", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "\"gradnorm_stab\"", "]", ")", ",", "\n", "StrategyAttributeTrackerPlugin", "(", "strategy_attr", "=", "[", "\"avg_gradnorm_G\"", "]", ")", ",", "\n", "]", ")", "\n", "\n", "metrics", "=", "[", "\n", "accuracy_metrics", "(", "experience", "=", "True", ",", "stream", "=", "True", ")", ",", "\n", "loss_metrics", "(", "minibatch", "=", "True", ",", "experience", "=", "True", ",", "stream", "=", "True", ")", ",", "\n", "ExperienceForgetting", "(", ")", ",", "# Test only", "\n", "StreamForgetting", "(", ")", ",", "# Test only", "\n", "StreamConfusionMatrix", "(", "num_classes", "=", "scenario", ".", "n_classes", ",", "save_image", "=", "True", ")", ",", "\n", "\n", "# CONTINUAL EVAL", "\n", "*", "minibatch_tracker_plugins", ",", "\n", "\n", "# LOG OTHER STATS", "\n", "timing_metrics", "(", "epoch", "=", "True", ",", "experience", "=", "False", ")", ",", "\n", "# cpu_usage_metrics(experience=True),", "\n", "# DiskUsageMonitor(),", "\n", "# MinibatchMaxRAM(),", "\n", "# GpuUsageMonitor(0),", "\n", "]", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_model": [[354, 360], ["main._get_feat_extr", "main._get_classifier", "src.model.FeatClassifierModel"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main._get_feat_extr", "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main._get_classifier"], ["", "def", "get_model", "(", "args", ",", "n_classes", ")", ":", "\n", "    ", "\"\"\" Build model from feature extractor and classifier.\"\"\"", "\n", "feat_extr", "=", "_get_feat_extr", "(", "args", ")", "# Feature extractor", "\n", "classifier", "=", "_get_classifier", "(", "args", ",", "n_classes", ",", "feat_extr", ".", "feature_size", ")", "# Classifier", "\n", "model", "=", "FeatClassifierModel", "(", "feat_extr", ",", "classifier", ")", "# Combined model", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main._get_feat_extr": [[362, 378], ["math.prod", "hasattr", "src.model.MLPfeat", "src.model.ResNet18feat", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet18feat"], ["", "def", "_get_feat_extr", "(", "args", ")", ":", "\n", "    ", "\"\"\" Get embedding network. \"\"\"", "\n", "nonlin_embedding", "=", "args", ".", "classifier", "in", "[", "'linear'", "]", "# Layer before linear should have nonlinearities", "\n", "input_size", "=", "math", ".", "prod", "(", "args", ".", "input_size", ")", "\n", "\n", "if", "args", ".", "backbone", "==", "\"mlp\"", ":", "# MNIST mlp", "\n", "        ", "feat_extr", "=", "MLPfeat", "(", "hidden_sizes", "=", "(", "400", ",", "args", ".", "featsize", ")", ",", "nb_layers", "=", "2", ",", "\n", "nonlinear_embedding", "=", "nonlin_embedding", ",", "input_size", "=", "input_size", ")", "\n", "\n", "", "elif", "args", ".", "backbone", "==", "\"resnet18\"", ":", "\n", "        ", "feat_extr", "=", "ResNet18feat", "(", "nf", "=", "20", ",", "global_pooling", "=", "args", ".", "use_GAP", ",", "input_size", "=", "args", ".", "input_size", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "", "assert", "hasattr", "(", "feat_extr", ",", "'feature_size'", ")", ",", "\"Feature extractor requires attribute 'feature_size'\"", "\n", "return", "feat_extr", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main._get_classifier": [[380, 398], ["avalanche.models.dynamic_modules.MultiHeadClassifier", "torch.nn.Linear", "src.model.L2NormalizeLayer", "torch.nn.Flatten", "NotImplementedError"], "function", ["None"], ["", "def", "_get_classifier", "(", "args", ",", "n_classes", ",", "feat_size", ")", ":", "\n", "    ", "\"\"\" Get classifier head. For embedding networks this is normalization or identity layer.\"\"\"", "\n", "# No prototypes, final linear layer for classification", "\n", "if", "args", ".", "classifier", "==", "'linear'", ":", "# Lin layer", "\n", "        ", "if", "args", ".", "task_incr", ":", "\n", "            ", "classifier", "=", "MultiHeadClassifier", "(", "in_features", "=", "feat_size", ",", "\n", "initial_out_features", "=", "args", ".", "initial_out_features", ",", "\n", "use_bias", "=", "args", ".", "lin_bias", ")", "\n", "", "else", ":", "\n", "            ", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "in_features", "=", "feat_size", ",", "out_features", "=", "n_classes", ",", "bias", "=", "args", ".", "lin_bias", ")", "\n", "# Prototypes held in strategy", "\n", "", "", "elif", "args", ".", "classifier", "==", "'norm_embed'", ":", "# Get feature normalization", "\n", "        ", "classifier", "=", "L2NormalizeLayer", "(", ")", "\n", "", "elif", "args", ".", "classifier", "==", "'identity'", ":", "# Just extract embedding output", "\n", "        ", "classifier", "=", "torch", ".", "nn", ".", "Flatten", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "return", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_strategy": [[400, 483], ["torch.nn.CrossEntropyLoss", "print", "hasattr", "torch.optim.SGD", "ValueError", "src.utils.ExpLRSchedulerPlugin", "plugins.append", "print", "int", "src.utils.IterationsInsteadOfEpochs", "plugins.append", "avalanche.training.strategies.Naive", "print", "model.parameters", "int", "torch.optim.lr_scheduler.MultiStepLR", "src.methods.replay.ERStrategy", "args.lr_milestones.split", "src.methods.gem_standard.GEMStandard", "src.methods.lwf_standard.LwFStandard", "src.methods.ewc_standard.EWCStandard", "NotImplementedError"], "function", ["None"], ["", "def", "get_strategy", "(", "args", ",", "model", ",", "eval_plugin", ",", "scenario", ",", "plugins", "=", "None", ")", ":", "\n", "    ", "plugins", "=", "[", "]", "if", "plugins", "is", "None", "else", "plugins", "\n", "\n", "# CRIT/OPTIM", "\n", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "if", "args", ".", "optim", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "momentum", "=", "args", ".", "momentum", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "\n", "# lr-schedule over experiences", "\n", "", "if", "args", ".", "lr_milestones", "is", "not", "None", ":", "\n", "        ", "assert", "args", ".", "lr_decay", "is", "not", "None", ",", "\"Should specify lr_decay when specifying lr_milestones\"", "\n", "milestones", "=", "[", "int", "(", "m", ")", "for", "m", "in", "args", ".", "lr_milestones", ".", "split", "(", "','", ")", "]", "\n", "sched", "=", "ExpLRSchedulerPlugin", "(", "MultiStepLR", "(", "optimizer", ",", "milestones", "=", "milestones", ",", "gamma", "=", "args", ".", "lr_decay", ")", ")", "\n", "plugins", ".", "append", "(", "sched", ")", "\n", "print", "(", "f\"MultiStepLR schedule over experiences, decaying '{args.lr_decay}' at exps '{milestones}'\"", ")", "\n", "\n", "# Use Iterations if defined", "\n", "", "if", "args", ".", "iterations_per_task", "is", "not", "None", ":", "\n", "        ", "args", ".", "epochs", "=", "int", "(", "1e9", ")", "\n", "it_stopper", "=", "IterationsInsteadOfEpochs", "(", "max_iterations", "=", "args", ".", "iterations_per_task", ")", "\n", "plugins", ".", "append", "(", "it_stopper", ")", "\n", "\n", "# STRATEGY", "\n", "", "if", "args", ".", "strategy", "==", "'finetune'", ":", "\n", "        ", "strategy", "=", "Naive", "(", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_epochs", "=", "args", ".", "epochs", ",", "device", "=", "args", ".", "device", ",", "\n", "train_mb_size", "=", "args", ".", "bs", ",", "evaluator", "=", "eval_plugin", ",", "\n", "plugins", "=", "plugins", "\n", ")", "\n", "\n", "", "elif", "args", ".", "strategy", "==", "'ER'", ":", "\n", "        ", "strategy", "=", "ERStrategy", "(", "\n", "record_stability_gradnorm", "=", "args", ".", "record_stability_gradnorm", ",", "\n", "Lw_new", "=", "args", ".", "Lw_new", ",", "\n", "n_total_memories", "=", "args", ".", "mem_size", ",", "\n", "num_tasks", "=", "scenario", ".", "n_experiences", ",", "\n", "model", "=", "model", ",", "optimizer", "=", "optimizer", ",", "criterion", "=", "criterion", ",", "\n", "train_epochs", "=", "args", ".", "epochs", ",", "device", "=", "args", ".", "device", ",", "\n", "new_data_mb_size", "=", "args", ".", "bs", ",", "# Max batch size, disregarding of including replay samples or not", "\n", "evaluator", "=", "eval_plugin", ",", "\n", "plugins", "=", "plugins", ",", "\n", ")", "\n", "\n", "", "elif", "args", ".", "strategy", "==", "'GEM'", ":", "\n", "        ", "strategy", "=", "GEMStandard", "(", "\n", "record_stability_gradnorm", "=", "args", ".", "record_stability_gradnorm", ",", "\n", "memory_strength", "=", "args", ".", "gem_gamma", ",", "\n", "patterns_per_exp", "=", "args", ".", "mem_size", "//", "scenario", ".", "n_experiences", ",", "\n", "model", "=", "model", ",", "optimizer", "=", "optimizer", ",", "criterion", "=", "criterion", ",", "\n", "train_epochs", "=", "args", ".", "epochs", ",", "device", "=", "args", ".", "device", ",", "\n", "train_mb_size", "=", "args", ".", "bs", ",", "evaluator", "=", "eval_plugin", ",", "\n", "plugins", "=", "plugins", ",", "\n", ")", "\n", "\n", "", "elif", "args", ".", "strategy", "==", "'LWF'", ":", "\n", "        ", "strategy", "=", "LwFStandard", "(", "\n", "alpha", "=", "args", ".", "lwf_alpha", ",", "\n", "temperature", "=", "args", ".", "lwf_softmax_t", ",", "\n", "model", "=", "model", ",", "optimizer", "=", "optimizer", ",", "criterion", "=", "criterion", ",", "\n", "train_epochs", "=", "args", ".", "epochs", ",", "device", "=", "args", ".", "device", ",", "\n", "train_mb_size", "=", "args", ".", "bs", ",", "evaluator", "=", "eval_plugin", ",", "\n", "plugins", "=", "plugins", ",", "\n", ")", "\n", "\n", "", "elif", "args", ".", "strategy", "==", "'EWC'", ":", "\n", "        ", "strategy", "=", "EWCStandard", "(", "\n", "ewc_lambda", "=", "args", ".", "iw_strength", ",", "\n", "mode", "=", "'online'", ",", "keep_importance_data", "=", "False", ",", "\n", "model", "=", "model", ",", "optimizer", "=", "optimizer", ",", "criterion", "=", "criterion", ",", "\n", "train_epochs", "=", "args", ".", "epochs", ",", "device", "=", "args", ".", "device", ",", "\n", "train_mb_size", "=", "args", ".", "bs", ",", "evaluator", "=", "eval_plugin", ",", "\n", "plugins", "=", "plugins", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Non existing strategy arg: {args.strategy}\"", ")", "\n", "\n", "", "print", "(", "f\"Running strategy:{strategy}\"", ")", "\n", "if", "hasattr", "(", "strategy", ",", "'plugins'", ")", ":", "\n", "        ", "print", "(", "f\"with Plugins: {strategy.plugins}\"", ")", "\n", "", "return", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.overwrite_args_with_config": [[485, 505], ["os.path.isfile", "yaml.safe_load.items", "print", "open", "yaml.safe_load", "hasattr", "isinstance", "setattr"], "function", ["None"], ["", "def", "overwrite_args_with_config", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Directly overwrite the input args with values defined in config yaml file.\n    Only if args.config_path is defined.\n    \"\"\"", "\n", "if", "args", ".", "config_path", "is", "None", ":", "\n", "        ", "return", "\n", "", "assert", "os", ".", "path", ".", "isfile", "(", "args", ".", "config_path", ")", ",", "f\"Config file does not exist: {args.config_path}\"", "\n", "\n", "import", "yaml", "\n", "with", "open", "(", "args", ".", "config_path", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "arg_configs", "=", "yaml", ".", "safe_load", "(", "stream", ")", "\n", "\n", "", "for", "arg_name", ",", "arg_val", "in", "arg_configs", ".", "items", "(", ")", ":", "# Overwrite", "\n", "        ", "assert", "hasattr", "(", "args", ",", "arg_name", ")", ",", "f\"'{arg_name}' defined in config is not specified in args, config: {args.config_path}\"", "\n", "if", "isinstance", "(", "arg_val", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "arg_val", "=", "arg_val", "[", "0", "]", "# unpack first", "\n", "", "setattr", "(", "args", ",", "arg_name", ",", "arg_val", ")", "\n", "", "print", "(", "f\"Overriden args with config: {args.config_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.main": [[507, 566], ["parser.parse_args", "main.overwrite_args_with_config", "torch.device", "print", "pathlib.Path().resolve", "main.seed_avg_metrics", "print", "print", "uuid.uuid4", "path.mkdir", "src.utils.MetricOverSeed", "src.utils.MetricOverSeed", "src.utils.MetricOverSeed", "src.utils.MetricOverSeed", "src.utils.MetricOverSeed", "src.utils.MetricOverSeed", "src.utils.MetricOverSeed", "src.utils.MetricOverSeed", "list", "print", "main.process_seed", "str", "pathlib.Path", "range", "datetime.datetime.now().date", "str().split", "torch.cuda.is_available", "vars", "os.path.join", "len", "datetime.datetime.now", "str", "datetime.datetime.now().time", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.overwrite_args_with_config", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.device", "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.seed_avg_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.process_seed"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "overwrite_args_with_config", "(", "args", ")", "\n", "\n", "args", ".", "now", "=", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "date", "(", ")", ")", "+", "\"_\"", "+", "'-'", ".", "join", "(", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "time", "(", ")", ")", ".", "split", "(", "':'", ")", "[", ":", "-", "1", "]", ")", "\n", "args", ".", "uid", "=", "uuid", ".", "uuid4", "(", ")", ".", "hex", "\n", "args", ".", "exp_name", "=", "'_'", ".", "join", "(", "[", "args", ".", "exp_name", ",", "f\"now={args.now}\"", ",", "f\"uid={args.uid}\"", "]", ")", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "args", ".", "cuda", "else", "\"cpu\"", ")", "\n", "print", "(", "f\"STARTING TIME: {args.now}\\nEXP NAME:{args.exp_name}\\nargs: {vars(args)}\"", ")", "\n", "\n", "# Paths", "\n", "args", ".", "setupname", "=", "'_'", ".", "join", "(", "[", "args", ".", "strategy", ",", "args", ".", "scenario", ",", "f\"e={args.epochs}\"", ",", "args", ".", "exp_name", "]", ")", "\n", "args", ".", "results_path", "=", "Path", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "args", ".", "setupname", ")", ")", ".", "resolve", "(", ")", "\n", "args", ".", "eval_results_dir", "=", "args", ".", "results_path", "/", "'results_summary'", "# Eval results", "\n", "for", "path", "in", "[", "args", ".", "results_path", ",", "args", ".", "eval_results_dir", "]", ":", "\n", "        ", "path", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Metrics to track and average in runtime", "\n", "", "metrics_over_seeds", "=", "[", "\n", "# Standard metrics", "\n", "MetricOverSeed", "(", "'avg_acc_final[test]'", ",", "\n", "extract_name", "=", "'Top1_Acc_Stream/eval_phase/test_stream/Task000'", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "MetricOverSeed", "(", "'avg_forg_final[test]'", ",", "\n", "extract_name", "=", "'StreamForgetting/eval_phase/test_stream'", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "\n", "# Continual Eval metrics", "\n", "MetricOverSeed", "(", "'WCACC_final[test]'", ",", "\n", "extract_name", "=", "'TRACK_MB_WCACC/train_phase/train_stream/Task000'", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "MetricOverSeed", "(", "'avg_acc_MIN_final[test]'", ",", "\n", "extract_name", "=", "\"TRACK_MB_acc_MIN_AVG/train_phase/train_stream/Task000\"", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "MetricOverSeed", "(", "'avg_F10_final[test]'", ",", "\n", "extract_name", "=", "'TRACK_MB_F10_AVG/train_phase/train_stream/Task000'", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "MetricOverSeed", "(", "'avg_F100_final[test]'", ",", "\n", "extract_name", "=", "'TRACK_MB_F100_AVG/train_phase/train_stream/Task000'", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "MetricOverSeed", "(", "'avg_P10_final[test]'", ",", "\n", "extract_name", "=", "'TRACK_MB_P10_AVG/train_phase/train_stream/Task000'", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "MetricOverSeed", "(", "'avg_P100_final[test]'", ",", "\n", "extract_name", "=", "'TRACK_MB_P100_AVG/train_phase/train_stream/Task000'", ",", "\n", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ",", "\n", "]", "\n", "\n", "# Iterate seeds", "\n", "seeds", "=", "[", "args", ".", "seed", "]", "if", "args", ".", "seed", "is", "not", "None", "else", "list", "(", "range", "(", "args", ".", "n_seeds", ")", ")", "\n", "for", "seed", "in", "seeds", ":", "\n", "        ", "print", "(", "\"STARTING SEED {}/{}\"", ".", "format", "(", "seed", ",", "len", "(", "seeds", ")", "-", "1", ")", ")", "\n", "process_seed", "(", "args", ",", "seed", ",", "metrics_over_seeds", ")", "\n", "\n", "# Avg results over all seeds", "\n", "", "final_results_file", "=", "args", ".", "eval_results_dir", "/", "f'seed_summary.pt'", "\n", "seed_avg_metrics", "(", "metrics_over_seeds", ",", "final_results_file", ")", "\n", "print", "(", "f\"[FILE:FINAL-RESULTS]: {final_results_file}\"", ")", "\n", "print", "(", "\"FINISHED SCRIPT\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.process_seed": [[568, 631], ["main.set_seed", "main.get_scenario", "loggers.append", "os.path.join", "loggers.append", "print", "main.get_model", "main.get_metrics", "avalanche.training.plugins.EvaluationPlugin", "main.get_strategy", "print", "main.save_seed_results", "print", "avalanche.logging.TextLogger", "avalanche.logging.InteractiveLogger", "avalanche.logging.TensorboardLogger", "avalanche.logging.WandBLogger", "loggers.append", "src.eval.minibatch_logging.StrategyAttributeAdderPlugin", "print", "print", "get_strategy.train", "print", "print", "print", "task_results_file.parent.mkdir", "get_strategy.eval", "dict", "torch.save", "print", "avalanche.logging.WandBLogger.finish", "list", "vars", "range"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.set_seed", "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_scenario", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.get_model", "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.get_strategy", "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.save_seed_results", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.finish"], ["", "def", "process_seed", "(", "args", ",", "seed", ",", "metrics_over_seeds", ")", ":", "\n", "    ", "\"\"\" Single seed processing of entire data stream, both train and eval.\"\"\"", "\n", "# initialize seeds", "\n", "args", ".", "seed", "=", "seed", "\n", "set_seed", "(", "seed", ",", "deterministic", "=", "args", ".", "deterministic", ")", "\n", "\n", "# create scenario", "\n", "scenario", "=", "get_scenario", "(", "args", ",", "seed", ")", "\n", "\n", "# LOGGING", "\n", "loggers", "=", "[", "]", "\n", "print_logger", "=", "TextLogger", "(", ")", "if", "args", ".", "disable_pbar", "else", "InteractiveLogger", "(", ")", "# print to stdout", "\n", "loggers", ".", "append", "(", "print_logger", ")", "\n", "\n", "# tensorboard logging", "\n", "tb_log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "results_path", ",", "'tb_run'", ",", "f'seed={seed}'", ")", "# Group all runs", "\n", "loggers", ".", "append", "(", "TensorboardLogger", "(", "tb_log_dir", "=", "tb_log_dir", ")", ")", "# log to Tensorboard", "\n", "print", "(", "f\"[Tensorboard] tb_log_dir={tb_log_dir}\"", ")", "\n", "\n", "# wandb logging", "\n", "if", "args", ".", "wandb", ":", "\n", "        ", "wandb_logger", "=", "WandBLogger", "(", "project_name", "=", "\"ContinualEval\"", ",", "group_name", "=", "args", ".", "setupname", ",", "\n", "run_name", "=", "f\"seed={seed}_{args.setupname}\"", ",", "config", "=", "vars", "(", "args", ")", ")", "\n", "loggers", ".", "append", "(", "wandb_logger", ")", "\n", "\n", "# MODEL", "\n", "", "model", "=", "get_model", "(", "args", ",", "scenario", ".", "n_classes", ")", "\n", "\n", "# METRICS", "\n", "metrics", "=", "get_metrics", "(", "scenario", ",", "args", ")", "\n", "eval_plugin", "=", "EvaluationPlugin", "(", "*", "metrics", ",", "loggers", "=", "loggers", ",", "benchmark", "=", "scenario", ")", "\n", "\n", "# STRATEGY", "\n", "strategy_plugins", "=", "[", "StrategyAttributeAdderPlugin", "(", "list", "(", "range", "(", "scenario", ".", "n_classes", ")", ")", ")", "]", "\n", "strategy", "=", "get_strategy", "(", "args", ",", "model", ",", "eval_plugin", ",", "scenario", ",", "plugins", "=", "strategy_plugins", ")", "\n", "\n", "# train on the selected scenario with the chosen strategy", "\n", "print", "(", "'Starting experiment...'", ")", "\n", "for", "experience", "in", "scenario", ".", "train_stream", ":", "\n", "# TRAIN", "\n", "        ", "print", "(", "f\"\\n{'-' * 40} TRAIN {'-' * 40}\"", ")", "\n", "print", "(", "f\"Start training on experience {experience.current_experience}\"", ")", "\n", "strategy", ".", "train", "(", "experience", ",", "num_workers", "=", "args", ".", "num_workers", ",", "eval_streams", "=", "None", ")", "\n", "print", "(", "f\"End training on experience {experience.current_experience}\"", ")", "\n", "\n", "# EVAL ALL TASKS (ON TASK TRANSITION)", "\n", "print", "(", "f\"\\n{'=' * 40} EVAL {'=' * 40}\"", ")", "\n", "print", "(", "f'Standard Continual Learning eval on entire test set on task transition.'", ")", "\n", "task_results_file", "=", "args", ".", "eval_results_dir", "/", "f'seed={seed}'", "/", "f'task{experience.current_experience}_results.pt'", "\n", "task_results_file", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "res", "=", "strategy", ".", "eval", "(", "scenario", ".", "test_stream", ")", "# Gathered by EvalLogger", "\n", "\n", "# Store eval task results", "\n", "task_metrics", "=", "dict", "(", "strategy", ".", "evaluator", ".", "all_metric_results", ")", "\n", "torch", ".", "save", "(", "task_metrics", ",", "task_results_file", ")", "\n", "print", "(", "f\"[FILE:TASK-RESULTS]: {task_results_file}\"", ")", "\n", "\n", "# Save results for entire seed", "\n", "", "all_results_file", "=", "args", ".", "eval_results_dir", "/", "f'seed={seed}_finalresults.pt'", "# Backup all results", "\n", "save_seed_results", "(", "strategy", ",", "all_results_file", ",", "metrics_over_seeds", ",", "seed", "=", "seed", ")", "\n", "print", "(", "f\"[FILE:TB-SEED-RESULTS]: {tb_log_dir}\"", ")", "\n", "if", "args", ".", "wandb", ":", "\n", "        ", "wandb_logger", ".", "finish", "(", ")", "# Finish run", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.save_seed_results": [[633, 647], ["dict", "print", "os.path.exists", "torch.save", "print", "metric.add_result"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.MetricOverSeed.add_result"], ["", "", "def", "save_seed_results", "(", "strategy", ",", "all_results_file", ":", "str", ",", "metrics_over_seeds", ":", "List", "[", "MetricOverSeed", "]", ",", "seed", ":", "int", ")", ":", "\n", "    ", "\"\"\" Save the results from metrics in the current seed-run.\n    Append to metrics_over_seeds.\"\"\"", "\n", "# save seed results", "\n", "all_metrics", "=", "dict", "(", "strategy", ".", "evaluator", ".", "all_metric_results", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "all_results_file", ")", ":", "\n", "        ", "torch", ".", "save", "(", "all_metrics", ",", "all_results_file", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f\"Not overwriting, seed results already exists at {all_results_file}\"", ")", "\n", "", "print", "(", "f\"[FILE:SEED-RESULTS]: {all_results_file}\"", ")", "\n", "\n", "# Collect over seeds", "\n", "for", "metric", "in", "metrics_over_seeds", ":", "\n", "        ", "metric", ".", "add_result", "(", "all_metrics", ",", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.seed_avg_metrics": [[649, 670], ["print", "metric.get_mean_std_results", "avg_results.append", "torch.save", "print", "src.utils.MetricOverSeed.logging_result_format.format"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.MetricOverSeed.get_mean_std_results"], ["", "", "def", "seed_avg_metrics", "(", "metric_over_seeds", ":", "List", "[", "MetricOverSeed", "]", ",", "save_file", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save and process average and std over accuracy and forgetting metrics.\"\"\"", "\n", "\n", "avg_results", "=", "[", "]", "\n", "for", "metric", "in", "metric_over_seeds", ":", "\n", "        ", "mean", ",", "std", "=", "metric", ".", "get_mean_std_results", "(", ")", "\n", "avg_results", ".", "append", "(", "(", "metric", ".", "name", ",", "mean", ",", "std", ")", ")", "\n", "\n", "# Log results", "\n", "", "print", "(", "\"{}|{}|{}\"", ".", "format", "(", "\n", "MetricOverSeed", ".", "logging_token", ",", "\n", "f'{MetricOverSeed.loggin_result_separator}'", ".", "join", "(", "[", "entry", "[", "0", "]", "for", "entry", "in", "avg_results", "]", ")", ",", "\n", "f'{MetricOverSeed.loggin_result_separator}'", ".", "join", "(", "[", "\n", "MetricOverSeed", ".", "logging_result_format", ".", "format", "(", "entry", "[", "1", "]", ",", "entry", "[", "2", "]", ")", "for", "entry", "in", "avg_results", "]", ")", ",", "\n", ")", ")", "\n", "\n", "if", "save_file", "is", "not", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "torch", ".", "save", "(", "avg_results", ",", "save_file", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "f\"NOT SAVING SUMMARY: {e}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.None.main.set_seed": [[672, 682], ["torch.manual_seed", "torch.cuda.manual_seed_all", "random.seed", "numpy.random.seed", "str"], "function", ["None"], ["", "", "", "def", "set_seed", "(", "seed", ",", "deterministic", "=", "False", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "numpy", ".", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "\n", "if", "deterministic", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.L2NormalizeLayer.__init__": [[17, 19], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.L2NormalizeLayer.forward": [[20, 23], ["x.view.view.view", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# Flatten", "\n", "return", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.IdentityLayer.__init__": [[26, 28], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.IdentityLayer.forward": [[29, 31], ["x.view", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.MLPfeat.__init__": [[36, 82], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "range", "torch.Sequential.add_module", "torch.Sequential", "torch.Sequential", "torch.Sequential.add_module", "torch.Sequential", "torch.Sequential", "torch.Sequential.add_module", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "nonlinear_embedding", ":", "bool", ",", "input_size", "=", "28", "*", "28", ",", "\n", "hidden_sizes", ":", "tuple", "=", "None", ",", "nb_layers", "=", "2", ")", ":", "\n", "        ", "\"\"\"\n        :param nonlinear_embedding: Include non-linearity on last embedding layer.\n        This is typically True for Linear classifiers on top. But is false for embedding based algorithms.\n        :param input_size:\n        :param hidden_size:\n        :param nb_layers:\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "nb_layers", ">=", "2", "\n", "if", "hidden_sizes", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "self", ".", "def_hidden_size", "]", "*", "nb_layers", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "hidden_sizes", ")", "==", "nb_layers", "\n", "", "self", ".", "feature_size", "=", "hidden_sizes", "[", "-", "1", "]", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "\n", "# Need at least one non-linear layer", "\n", "layers", "=", "nn", ".", "Sequential", "(", "*", "(", "nn", ".", "Linear", "(", "input_size", ",", "hidden_sizes", "[", "0", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", ")", "\n", "\n", "for", "layer_idx", "in", "range", "(", "1", ",", "nb_layers", "-", "1", ")", ":", "# Not first, not last", "\n", "            ", "layers", ".", "add_module", "(", "\n", "f\"fc{layer_idx}\"", ",", "nn", ".", "Sequential", "(", "\n", "*", "(", "nn", ".", "Linear", "(", "hidden_sizes", "[", "layer_idx", "-", "1", "]", ",", "hidden_sizes", "[", "layer_idx", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", ")", ")", "\n", "\n", "# Final layer", "\n", "", "layers", ".", "add_module", "(", "\n", "f\"fc{nb_layers}\"", ",", "nn", ".", "Sequential", "(", "\n", "*", "(", "nn", ".", "Linear", "(", "hidden_sizes", "[", "nb_layers", "-", "2", "]", ",", "\n", "hidden_sizes", "[", "nb_layers", "-", "1", "]", ")", ",", "\n", ")", ")", ")", "\n", "\n", "# Optionally add final nonlinearity", "\n", "if", "nonlinear_embedding", ":", "\n", "            ", "layers", ".", "add_module", "(", "\n", "f\"final_nonlinear\"", ",", "nn", ".", "Sequential", "(", "\n", "*", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", ")", ")", ")", "\n", "\n", "", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "# self.classifier = nn.Linear(hidden_size, num_classes)", "\n", "self", ".", "_input_size", "=", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.MLPfeat.forward": [[83, 89], ["model.MLPfeat.contiguous", "model.MLPfeat.view", "model.MLPfeat.features", "model.MLPfeat.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "_input_size", ")", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "# x = self.classifier(x)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.__init__": [[92, 101], ["super().__init__", "model.FeatAvgPoolLayer"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feature_extractor", ",", "classifier", ",", "with_adaptive_pool", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "with_adaptive_pool", "=", "with_adaptive_pool", "\n", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "\n", "self", ".", "classifier", "=", "classifier", "# Linear or MultiTaskHead", "\n", "\n", "if", "self", ".", "with_adaptive_pool", ":", "\n", "            ", "self", ".", "avg_pool", "=", "FeatAvgPoolLayer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.forward_feats": [[102, 107], ["model.FeatClassifierModel.feature_extractor", "model.FeatClassifierModel.avg_pool"], "methods", ["None"], ["", "", "def", "forward_feats", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "feature_extractor", "(", "x", ")", "\n", "if", "self", ".", "with_adaptive_pool", ":", "\n", "            ", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.forward_classifier": [[108, 114], ["model.FeatClassifierModel.classifier", "model.FeatClassifierModel.classifier"], "methods", ["None"], ["", "def", "forward_classifier", "(", "self", ",", "x", ",", "task_labels", "=", "None", ")", ":", "\n", "        ", "try", ":", "# Multi-task head", "\n", "            ", "x", "=", "self", ".", "classifier", "(", "x", ",", "task_labels", ")", "\n", "", "except", ":", "# Single head", "\n", "            ", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.forward": [[115, 119], ["model.FeatClassifierModel.forward_feats", "model.FeatClassifierModel.forward_classifier"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.forward_feats", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.forward_classifier"], ["", "def", "forward", "(", "self", ",", "x", ",", "task_labels", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_feats", "(", "x", ")", "\n", "x", "=", "self", ".", "forward_classifier", "(", "x", ",", "task_labels", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatAvgPoolLayer.__init__": [[122, 125], ["super().__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "torch", ".", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatAvgPoolLayer.forward": [[126, 136], ["model.FeatAvgPoolLayer.avg_pool", "x.view.view.view", "x.view.view.dim", "x.view.view.dim", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "List", "[", "Tensor", "]", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "        ", "\"\"\" This format to be compatible with OpenSelfSup and the classifiers expecting a list.\"\"\"", "\n", "# Pool", "\n", "assert", "x", ".", "dim", "(", ")", "==", "4", ",", "\"Tensor must has 4 dims, got: {}\"", ".", "format", "(", "x", ".", "dim", "(", ")", ")", "\n", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "\n", "# Flatten", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.BasicBlock.__init__": [[146, 159], ["torch.Module.__init__", "model.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "model.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.conv3x3", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "in_planes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.BasicBlock.forward": [[161, 167], ["torch.nn.functional.relu", "torch.nn.functional.relu", "model.BasicBlock.bn2", "model.BasicBlock.shortcut", "torch.nn.functional.relu", "torch.nn.functional.relu", "model.BasicBlock.bn1", "model.BasicBlock.conv2", "model.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet.__init__": [[172, 201], ["torch.Module.__init__", "model.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "model.ResNet._make_layer", "model.ResNet._make_layer", "model.ResNet._make_layer", "model.ResNet._make_layer", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.conv3x3", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet._make_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet._make_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet._make_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet._make_layer"], ["def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "nf", ",", "global_pooling", ",", "input_size", ")", ":", "\n", "        ", "\"\"\"\n\n        :param block:\n        :param num_blocks:\n        :param nf: Number of feature maps in each conv layer.\n        \"\"\"", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "global_pooling", "=", "global_pooling", "\n", "\n", "self", ".", "in_planes", "=", "nf", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "3", ",", "nf", "*", "1", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "nf", "*", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "nf", "*", "1", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "nf", "*", "2", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "nf", "*", "4", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "nf", "*", "8", ",", "num_blocks", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n", "assert", "len", "(", "input_size", ")", ">=", "3", "\n", "input_size", "=", "input_size", "[", "-", "3", ":", "]", "# Only care about last 3", "\n", "\n", "if", "input_size", "==", "(", "3", ",", "32", ",", "32", ")", ":", "# Cifar10", "\n", "            ", "self", ".", "feature_size", "=", "160", "if", "global_pooling", "else", "2560", "\n", "", "elif", "input_size", "==", "(", "3", ",", "84", ",", "84", ")", ":", "# Mini-Imagenet", "\n", "            ", "self", ".", "feature_size", "=", "640", "if", "global_pooling", "else", "19360", "\n", "", "elif", "input_size", "==", "(", "3", ",", "96", ",", "96", ")", ":", "# TinyDomainNet", "\n", "            ", "self", ".", "feature_size", "=", "1440", "if", "global_pooling", "else", "23040", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Input size not recognized: {input_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet._make_layer": [[204, 211], ["torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "stride", "in", "strides", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet.forward": [[212, 225], ["torch.nn.functional.relu", "torch.nn.functional.relu", "model.ResNet.layer1", "model.ResNet.layer2", "model.ResNet.layer3", "model.ResNet.layer4", "torch.nn.functional.avg_pool2d.view", "torch.nn.functional.avg_pool2d.view", "len", "model.ResNet.bn1", "torch.nn.functional.avg_pool2d", "torch.nn.functional.avg_pool2d", "torch.nn.functional.avg_pool2d.size", "torch.nn.functional.avg_pool2d.size", "model.ResNet.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", ",", "\"Assuming x.view(bsz, C, W, H)\"", "\n", "out", "=", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "\n", "if", "self", ".", "global_pooling", ":", "\n", "            ", "out", "=", "avg_pool2d", "(", "out", ",", "4", ")", "\n", "", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# Flatten", "\n", "# out = self.linear(out)", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.conv3x3": [[138, 141], ["torch.Conv2d"], "function", ["None"], ["", "", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.ResNet18feat": [[227, 229], ["model.ResNet"], "function", ["None"], ["", "", "def", "ResNet18feat", "(", "input_size", ",", "nf", "=", "20", ",", "global_pooling", "=", "False", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "nf", ",", "global_pooling", "=", "global_pooling", ",", "input_size", "=", "input_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.IterationsInsteadOfEpochs.__init__": [[21, 25], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "max_iterations", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "max_iterations", ",", "int", ")", "and", "max_iterations", ">", "0", "\n", "self", ".", "max_iterations", "=", "max_iterations", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.IterationsInsteadOfEpochs.after_training_iteration": [[26, 30], ["print", "strategy.stop_training"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.stop_training"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "strategy", ".", "clock", ".", "train_exp_iterations", "==", "self", ".", "max_iterations", ":", "\n", "            ", "print", "(", "f\"Stopping training, reached max iterations: {self.max_iterations}\"", ")", "\n", "strategy", ".", "stop_training", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.MetricOverSeed.__init__": [[37, 52], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "extract_name", ",", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        :param name: Name to give in logging\n        :param extract_name: Dict name in all_metrics dict after end of training seed.\n        :param extract_idx: Which idx to extract, -1 for final one.\n        :param mul_factor: Multiplication factor before return result.\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "extract_name", "=", "extract_name", "\n", "self", ".", "extract_idx", "=", "extract_idx", "\n", "self", ".", "mul_factor", "=", "mul_factor", "\n", "\n", "# Results appended sequentially", "\n", "self", ".", "seeds", "=", "[", "]", "\n", "self", ".", "seed_results", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.MetricOverSeed.extract_metric_fn": [[53, 59], ["None"], "methods", ["None"], ["", "def", "extract_metric_fn", "(", "self", ",", "all_metrics", ":", "dict", ")", ":", "\n", "        ", "\"\"\" Extract dict of all eval results on end of seed.\n        Name-idx returns tuple of (list(<STEPS>),list(<METRIC-VALS>))\n        Select latter with [1], and apply the extraction idx.\n        \"\"\"", "\n", "return", "all_metrics", "[", "self", ".", "extract_name", "]", "[", "1", "]", "[", "self", ".", "extract_idx", "]", "*", "self", ".", "mul_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.MetricOverSeed.add_result": [[60, 69], ["utils.MetricOverSeed.seeds.append", "utils.MetricOverSeed.seed_results.append", "utils.MetricOverSeed.extract_metric_fn", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.MetricOverSeed.extract_metric_fn"], ["", "def", "add_result", "(", "self", ",", "all_metrics", ":", "dict", ",", "seed", ":", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "result", "=", "self", ".", "extract_metric_fn", "(", "all_metrics", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "f\"[WARNING] No SEED result for metric {self.name}, because of error: {e}\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "seeds", ".", "append", "(", "seed", ")", "\n", "self", ".", "seed_results", ".", "append", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.MetricOverSeed.get_mean_std_results": [[70, 74], ["torch.tensor", "torch.tensor.mean().item", "torch.tensor.std().item", "torch.tensor.mean", "torch.tensor.std"], "methods", ["None"], ["", "def", "get_mean_std_results", "(", "self", ")", ":", "\n", "        ", "result_t", "=", "torch", ".", "tensor", "(", "self", ".", "seed_results", ")", "# list to tensor", "\n", "mean", ",", "std", "=", "result_t", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "result_t", ".", "std", "(", ")", ".", "item", "(", ")", "\n", "return", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.ExpLRSchedulerPlugin.__init__": [[146, 155], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "scheduler", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``LRSchedulerPlugin`` instance, step per experience.\n\n        :param scheduler: a learning rate scheduler that can be updated through\n            a step() method and can be reset by setting last_epoch=0\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.ExpLRSchedulerPlugin.print_lrs": [[156, 158], ["print"], "methods", ["None"], ["", "def", "print_lrs", "(", "self", ")", ":", "\n", "        ", "print", "(", "f\"[LR SCHEDULER] Current lrs: \"", "\n", "f\"{['{:.1e}'.format(group['lr']) for group in self.scheduler.optimizer.param_groups]}\"", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.ExpLRSchedulerPlugin.before_training_exp": [[160, 162], ["utils.ExpLRSchedulerPlugin.print_lrs"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.ExpLRSchedulerPlugin.print_lrs"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "print_lrs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.ExpLRSchedulerPlugin.after_training_exp": [[163, 166], ["utils.ExpLRSchedulerPlugin.scheduler.step", "utils.ExpLRSchedulerPlugin.print_lrs"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.ExpLRSchedulerPlugin.print_lrs"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "self", ".", "print_lrs", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_grad_normL2": [[76, 93], ["model.parameters", "isinstance", "torch.norm", "torch.norm.item", "model.parameters", "len", "torch.stack", "torch.norm().to", "torch.norm", "p.grad.detach"], "function", ["None"], ["", "", "def", "get_grad_normL2", "(", "model", ",", "norm_type", ":", "float", "=", "2", ")", ":", "\n", "    ", "\"\"\"Returns the gradient norm of the model.\n    Calculated the same way as torch.clip_grad_norm_\"\"\"", "\n", "\n", "# Params with grad", "\n", "parameters", "=", "model", ".", "parameters", "(", ")", "\n", "if", "isinstance", "(", "model", ".", "parameters", "(", ")", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "parameters", "=", "[", "parameters", "]", "\n", "", "parameters", "=", "[", "p", "for", "p", "in", "parameters", "if", "p", ".", "grad", "is", "not", "None", "]", "\n", "if", "len", "(", "parameters", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "device", "=", "parameters", "[", "0", "]", ".", "grad", ".", "device", "\n", "\n", "# calc norm", "\n", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "norm", "(", "p", ".", "grad", ".", "detach", "(", ")", ",", "norm_type", ")", ".", "to", "(", "device", ")", "for", "p", "in", "parameters", "]", ")", ",", "norm_type", ")", "\n", "return", "total_norm", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_prototypes_from_classifier": [[95, 136], ["torch.no_grad", "isinstance", "classifier.classifiers.items", "isinstance", "taskhead.named_parameters", "classifier.named_parameters", "Exception", "param.detach().clone", "param.detach().clone", "protos_weight.items", "protos_bias.items", "range", "range", "param.detach", "param.detach", "range", "range"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "get_prototypes_from_classifier", "(", "classifier", ":", "Union", "[", "torch", ".", "nn", ".", "Linear", ",", "MultiHeadClassifier", "]", ",", "get_clone", ":", "bool", ")", ":", "\n", "    ", "\"\"\"\n    Returns individual prototypes for given classifier.\n    :param classifier:\n    :param get_clone: Get a clone of the original parameter references instead of the original ones.\n    :return:\n    \"\"\"", "\n", "protos_weight", "=", "{", "}", "\n", "protos_bias", "=", "{", "}", "\n", "\n", "if", "isinstance", "(", "classifier", ",", "MultiHeadClassifier", ")", ":", "# Multi-head", "\n", "        ", "y_offset", "=", "0", "\n", "for", "taskid", ",", "taskhead", "in", "classifier", ".", "classifiers", ".", "items", "(", ")", ":", "# Iterate heads", "\n", "            ", "nb_task_protos", "=", "0", "\n", "for", "param_name", ",", "param", "in", "taskhead", ".", "named_parameters", "(", ")", ":", "# Weight/bias of Linear layer heads", "\n", "                ", "nb_task_protos", "=", "param", ".", "shape", "[", "0", "]", "\n", "if", "'weight'", "in", "param_name", ":", "\n", "                    ", "for", "y", "in", "range", "(", "nb_task_protos", ")", ":", "# Per head params restart from 0, but total protos has offset", "\n", "                        ", "protos_weight", "[", "y", "+", "y_offset", "]", "=", "param", "[", "y", "]", "\n", "", "", "elif", "'bias'", "in", "param_name", ":", "\n", "                    ", "for", "y", "in", "range", "(", "nb_task_protos", ")", ":", "\n", "                        ", "protos_bias", "[", "y", "+", "y_offset", "]", "=", "param", "[", "y", "]", "\n", "", "", "", "y_offset", "+=", "nb_task_protos", "\n", "\n", "", "", "elif", "isinstance", "(", "classifier", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "# Single head", "\n", "        ", "for", "param_name", ",", "param", "in", "classifier", ".", "named_parameters", "(", ")", ":", "\n", "            ", "nb_protos", "=", "param", ".", "shape", "[", "0", "]", "\n", "if", "'weight'", "in", "param_name", ":", "\n", "                ", "for", "y", "in", "range", "(", "nb_protos", ")", ":", "\n", "                    ", "protos_weight", "[", "y", "]", "=", "param", "[", "y", "]", "\n", "", "", "elif", "'bias'", "in", "param_name", ":", "\n", "                ", "for", "y", "in", "range", "(", "nb_protos", ")", ":", "\n", "                    ", "protos_bias", "[", "y", "]", "=", "param", "[", "y", "]", "\n", "", "", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", ")", "\n", "\n", "", "if", "get_clone", ":", "# Make clones of original references", "\n", "        ", "protos_weight", "=", "{", "y", ":", "param", ".", "detach", "(", ")", ".", "clone", "(", ")", "for", "y", ",", "param", "in", "protos_weight", ".", "items", "(", ")", "}", "\n", "protos_bias", "=", "{", "y", ":", "param", ".", "detach", "(", ")", ".", "clone", "(", ")", "for", "y", ",", "param", "in", "protos_bias", ".", "items", "(", ")", "}", "\n", "", "return", "protos_weight", ",", "protos_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet_benchmark.MiniDomainNetBenchmark": [[38, 113], ["print", "domainnet_benchmark.produce_class_summary", "print", "domainnet_benchmark.produce_class_summary", "avalanche.benchmarks.dataset_benchmark", "avalanche.benchmarks.datasets.default_dataset_location", "train_sets.append", "test_sets.append", "src.benchmarks.domainnet.MiniDomainNet", "src.benchmarks.domainnet.MiniDomainNet", "src.benchmarks.utils.wrap_with_task_labels", "src.benchmarks.utils.wrap_with_task_labels"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet_benchmark.produce_class_summary", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet_benchmark.produce_class_summary", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.utils.wrap_with_task_labels", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.utils.wrap_with_task_labels"], ["def", "MiniDomainNetBenchmark", "(", "\n", "*", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using a sequence of 4 MiniDomainNet tasks, where each task is one domain.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default eval transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'MiniDomainNet'", ")", "\n", "\n", "", "considered_classes", "=", "MiniDomainNet", ".", "classes_list", "\n", "\n", "# Datasets", "\n", "train_sets", ",", "test_sets", "=", "[", "]", ",", "[", "]", "\n", "for", "domain", "in", "MiniDomainNet", ".", "domains", ":", "\n", "        ", "train_sets", ".", "append", "(", "MiniDomainNet", "(", "classes_list", "=", "considered_classes", ",", "ds_root", "=", "dataset_root", ",", "domain", "=", "domain", ",", "\n", "train", "=", "True", ",", "transform", "=", "train_transform", ")", ")", "\n", "test_sets", ".", "append", "(", "MiniDomainNet", "(", "classes_list", "=", "considered_classes", ",", "ds_root", "=", "dataset_root", ",", "domain", "=", "domain", ",", "\n", "train", "=", "False", ",", "transform", "=", "eval_transform", ")", ")", "\n", "\n", "# TRAINING SUMMARY", "\n", "", "print", "(", "f\"\\n\\n {'*' * 40} TRAINING SUMMARY {'*' * 40}\"", ")", "\n", "produce_class_summary", "(", "train_sets", ")", "\n", "\n", "# TESTING SUMMARY", "\n", "print", "(", "f\"\\n\\n {'*' * 40} TESTING SUMMARY {'*' * 40}\"", ")", "\n", "produce_class_summary", "(", "test_sets", ")", "\n", "\n", "return", "dataset_benchmark", "(", "\n", "train_datasets", "=", "wrap_with_task_labels", "(", "train_sets", ")", ",", "\n", "test_datasets", "=", "wrap_with_task_labels", "(", "test_sets", ")", ",", "\n", "complete_test_set_only", "=", "False", ",", "# Return test set per task (not a single test set)", "\n", "train_transform", "=", "None", ",", "# For TRAIN Add in dataset itself! (Otherwise trouble in restoring Replay state)", "\n", "eval_transform", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet_benchmark.produce_class_summary": [[116, 158], ["collections.defaultdict", "enumerate", "pandas.DataFrame.from_records", "counts_df.assign.assign", "print", "domain_headers.append", "ds.split_dataset_by_label", "ds.split_dataset_by_label.items", "datacnt_per_domain.append", "col_sum.append", "col_min.append", "col_max.append", "tabulate.tabulate", "datacnt_per_class[].append", "len", "enumerate", "counts_df.assign.iloc[].sum", "column.sum", "column.min", "column.max", "counts_df.assign.values.tolist", "len", "sorted", "list", "collections.defaultdict.keys"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.split_dataset_by_label"], ["", "def", "produce_class_summary", "(", "datasets", ":", "List", "[", "MiniDomainNet", "]", ")", ":", "\n", "    ", "\"\"\" Make a per-class summary over all classes in MiniDomainNet.\"\"\"", "\n", "datacnt_per_class", "=", "defaultdict", "(", "list", ")", "# Datapoints per class (in total)", "\n", "datacnt_per_domain", "=", "[", "]", "\n", "domain_headers", "=", "[", "]", "\n", "\n", "for", "ds_idx", ",", "ds", "in", "enumerate", "(", "datasets", ")", ":", "# Iterate tasks (domains)", "\n", "        ", "domain_headers", ".", "append", "(", "f\"#{ds.domain}\"", ")", "\n", "per_label_dict", "=", "ds", ".", "split_dataset_by_label", "(", "ds", ".", "data", ")", "\n", "\n", "for", "c", ",", "c_samples", "in", "per_label_dict", ".", "items", "(", ")", ":", "# Iterate classes with counts", "\n", "            ", "datacnt_per_class", "[", "c", "]", ".", "append", "(", "len", "(", "c_samples", ")", ")", "\n", "\n", "# Per-domain summary", "\n", "", "datacnt_per_domain", ".", "append", "(", "len", "(", "ds", ")", ")", "\n", "\n", "# Sort classes", "\n", "", "sorted_per_class", "=", "[", "[", "c_cnt", ",", "c", ",", "*", "datacnt_per_class", "[", "c", "]", "]", "\n", "for", "c_cnt", ",", "c", "in", "enumerate", "(", "sorted", "(", "list", "(", "datacnt_per_class", ".", "keys", "(", ")", ")", ")", ")", "]", "\n", "\n", "# Add min-max summary lines", "\n", "counts_df", "=", "pd", ".", "DataFrame", ".", "from_records", "(", "sorted_per_class", ")", "# Includes class-idxs in first two columns", "\n", "\n", "# Add summary count as column", "\n", "counts_df", "=", "counts_df", ".", "assign", "(", "Total", "=", "counts_df", ".", "iloc", "[", ":", ",", "2", ":", "]", ".", "sum", "(", "axis", "=", "1", ")", ")", "\n", "\n", "col_sum", ",", "col_min", ",", "col_max", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "column_name", "in", "counts_df", ".", "iloc", "[", ":", ",", "1", ":", "]", ":", "\n", "        ", "column", "=", "counts_df", "[", "column_name", "]", "\n", "col_sum", ".", "append", "(", "column", ".", "sum", "(", ")", ")", "\n", "col_min", ".", "append", "(", "column", ".", "min", "(", ")", ")", "\n", "col_max", ".", "append", "(", "column", ".", "max", "(", ")", ")", "\n", "\n", "# Append summary line", "\n", "", "totals_row", "=", "[", "'SUM'", ",", "*", "col_sum", "]", "# Class'label", "\n", "mins_row", "=", "[", "'MIN'", ",", "*", "col_min", "]", "# Class'label", "\n", "maxs_row", "=", "[", "'MAX'", ",", "*", "col_max", "]", "# Class'label", "\n", "\n", "# Display", "\n", "all_rows", "=", "[", "*", "counts_df", ".", "values", ".", "tolist", "(", ")", ",", "totals_row", ",", "mins_row", ",", "maxs_row", "]", "\n", "headers", "=", "[", "'class_idx'", ",", "'orig Class'", ",", "*", "domain_headers", ",", "'#Total'", "]", "\n", "print", "(", "tabulate", "(", "all_rows", ",", "headers", "=", "headers", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark.DigitsBenchmark": [[34, 112], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "digits_benchmark._get_MNIST_dataset", "digits_benchmark._get_SVHN_dataset", "digits_benchmark._get_USPS_dataset", "torchvision.transforms.Lambda", "avalanche.benchmarks.dataset_benchmark", "int", "src.benchmarks.utils.wrap_with_task_labels", "src.benchmarks.utils.wrap_with_task_labels"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark._get_MNIST_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark._get_SVHN_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark._get_USPS_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.utils.wrap_with_task_labels", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.utils.wrap_with_task_labels"], ["def", "DigitsBenchmark", "(", "\n", "*", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_digit_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_digit_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using a sequence of the MNIST, SVHN and USPS datasets.\n    This is domain incremental for the digits.\n\n    Input-sizes\n    MNIST: 1x28x28\n    SVHN: 3x32x32\n    USPS: 1x16x16 (Pytorch pixel values in [0,255])\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default eval transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'cifar10' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "# Transforms with different normalizations (e.g. same for 3 channel copies in grayscale)", "\n", "train_grayscale_transform", "=", "transforms", ".", "Compose", "(", "[", "train_transform", ",", "grayscale_normalize", "]", ")", "\n", "eval_grayscale_transform", "=", "transforms", ".", "Compose", "(", "[", "eval_transform", ",", "grayscale_normalize", "]", ")", "\n", "\n", "train_rgb_transform", "=", "transforms", ".", "Compose", "(", "[", "train_transform", ",", "rgb_normalize", "]", ")", "\n", "eval_rgb_transform", "=", "transforms", ".", "Compose", "(", "[", "eval_transform", ",", "rgb_normalize", "]", ")", "\n", "\n", "# Datasets", "\n", "\"\"\" All datasets return in range [0,255]\"\"\"", "\n", "mnist_train", ",", "mnist_test", "=", "_get_MNIST_dataset", "(", "dataset_root", ",", "train_grayscale_transform", ",", "eval_grayscale_transform", ")", "\n", "svhn_train", ",", "svhn_test", "=", "_get_SVHN_dataset", "(", "dataset_root", ",", "train_rgb_transform", ",", "eval_rgb_transform", ")", "\n", "usps_train", ",", "usps_test", "=", "_get_USPS_dataset", "(", "dataset_root", ",", "train_grayscale_transform", ",", "eval_grayscale_transform", ")", "\n", "\n", "train_sets", "=", "[", "mnist_train", ",", "svhn_train", ",", "usps_train", "]", "\n", "test_sets", "=", "[", "mnist_test", ",", "svhn_test", ",", "usps_test", "]", "\n", "\n", "target_to_int", "=", "transforms", ".", "Lambda", "(", "lambda", "x", ":", "int", "(", "x", ")", ")", "\n", "return", "dataset_benchmark", "(", "\n", "train_datasets", "=", "wrap_with_task_labels", "(", "train_sets", ",", "target_transform", "=", "target_to_int", ")", ",", "\n", "test_datasets", "=", "wrap_with_task_labels", "(", "test_sets", ",", "target_transform", "=", "target_to_int", ")", ",", "\n", "complete_test_set_only", "=", "False", ",", "# Return test set per task (not a single test set)", "\n", "train_transform", "=", "None", ",", "# For TRAIN Add in dataset itself! (Otherwise trouble in restoring Replay state)", "\n", "eval_transform", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark._get_MNIST_dataset": [[115, 123], ["torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.MNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.MNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "def", "_get_MNIST_dataset", "(", "dataset_root", ",", "train_transform", ",", "test_transform", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'MNIST'", ")", "\n", "\n", "", "train_set", "=", "torchvision", ".", "datasets", ".", "MNIST", "(", "dataset_root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "train_transform", ")", "\n", "test_set", "=", "torchvision", ".", "datasets", ".", "MNIST", "(", "dataset_root", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "test_transform", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark._get_SVHN_dataset": [[125, 133], ["torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SVHN", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SVHN", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "def", "_get_SVHN_dataset", "(", "dataset_root", ",", "train_transform", ",", "test_transform", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'SVHN'", ")", "\n", "\n", "", "train_set", "=", "torchvision", ".", "datasets", ".", "SVHN", "(", "dataset_root", ",", "split", "=", "\"train\"", ",", "download", "=", "True", ",", "transform", "=", "train_transform", ")", "\n", "test_set", "=", "torchvision", ".", "datasets", ".", "SVHN", "(", "dataset_root", ",", "split", "=", "\"test\"", ",", "download", "=", "True", ",", "transform", "=", "test_transform", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.digits_benchmark._get_USPS_dataset": [[135, 143], ["torchvision.datasets.USPS", "torchvision.datasets.USPS", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.USPS", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.USPS", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "def", "_get_USPS_dataset", "(", "dataset_root", ",", "train_transform", ",", "test_transform", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'USPS'", ")", "\n", "\n", "", "train_set", "=", "torchvision", ".", "datasets", ".", "USPS", "(", "dataset_root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "train_transform", ")", "\n", "test_set", "=", "torchvision", ".", "datasets", ".", "USPS", "(", "dataset_root", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "test_transform", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark.XYDataset.__init__": [[140, 144], ["kwargs.items", "setattr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "x", ",", "y", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "x", ",", "self", ".", "targets", "=", "x", ",", "y", "\n", "for", "name", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark.XYDataset.__len__": [[145, 147], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark.XYDataset.__getitem__": [[148, 151], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "x", ",", "y", "=", "self", ".", "x", "[", "idx", "]", ",", "self", ".", "targets", "[", "idx", "]", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark.SplitMiniImageNet": [[31, 101], ["miniimagenet_benchmark._get_preprocessed_split_mini_imagenet", "miniimagenet_benchmark._get_mini_imagenet_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark._get_preprocessed_split_mini_imagenet", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark._get_mini_imagenet_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitMiniImageNet", "(", "root_path", ",", "n_experiences", "=", "20", ",", "return_task_id", "=", "False", ",", "seed", "=", "0", ",", "\n", "fixed_class_order", "=", "None", ",", "\n", "train_transform", "=", "_default_train_transform", ",", "\n", "test_transform", "=", "_default_test_transform", ",", "\n", "preprocessed", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL scenario using the Mini ImageNet dataset.\n    If the dataset is not present in the computer the method automatically\n    download it and store the data in the data folder.\n\n    :param preprocessed: Use preprocessed images for Mini-Imagenet if True, otherwise use original Imagenet.\n    :param root_path: Root path of the downloaded dataset.\n    :param n_experiences: The number of experiences in the current scenario.\n    :param return_task_id: if True, for every experience the task id is returned\n        and the Scenario is Multi Task. This means that the scenario returned\n        will be of type ``NCMultiTaskScenario``. If false the task index is\n        not returned (default to 0 for every batch) and the returned scenario\n        is of type ``NCSingleTaskScenario``.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param test_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n\n    :returns: A :class:`NCMultiTaskScenario` instance initialized for the the\n        MT scenario if the parameter ``return_task_id`` is True,\n        a :class:`NCSingleTaskScenario` initialized for the SIT scenario otherwise.\n        \"\"\"", "\n", "\n", "if", "preprocessed", ":", "\n", "        ", "train_set", ",", "test_set", "=", "_get_preprocessed_split_mini_imagenet", "(", "root_path", ")", "\n", "", "else", ":", "\n", "        ", "train_set", ",", "test_set", "=", "_get_mini_imagenet_dataset", "(", "root_path", ")", "\n", "\n", "", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "per_exp_classes", "=", "None", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "test_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "per_exp_classes", "=", "None", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "test_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark._get_mini_imagenet_dataset": [[103, 109], ["avalanche.benchmarks.datasets.mini_imagenet.mini_imagenet.MiniImageNetDataset", "avalanche.benchmarks.datasets.mini_imagenet.mini_imagenet.MiniImageNetDataset"], "function", ["None"], ["", "", "def", "_get_mini_imagenet_dataset", "(", "path", ")", ":", "\n", "    ", "\"\"\" Create from ImageNet. \"\"\"", "\n", "train_set", "=", "MiniImageNetDataset", "(", "path", ",", "split", "=", "'train'", ")", "\n", "test_set", "=", "MiniImageNetDataset", "(", "path", ",", "split", "=", "'test'", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.miniimagenet_benchmark._get_preprocessed_split_mini_imagenet": [[111, 135], ["range", "open", "pickle.load", "len", "train_x.extend", "test_x.extend", "train_y.extend", "test_y.extend", "np.array", "np.array", "np.array", "np.array", "miniimagenet_benchmark.XYDataset", "miniimagenet_benchmark.XYDataset"], "function", ["None"], ["", "def", "_get_preprocessed_split_mini_imagenet", "(", "root_path", ")", ":", "\n", "    ", "\"\"\"\n    Use preprocessed train (500 imgs) /test (100 imgs) split in Numpy Array. For 100 classes.\n    Download: https://github.com/yaoyao-liu/mini-imagenet-tools\n    \"\"\"", "\n", "import", "pickle", "\n", "import", "numpy", "as", "np", "\n", "\n", "with", "open", "(", "f\"{root_path}/miniImageNet.pkl\"", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "dataset", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "train_x", ",", "test_x", "=", "[", "]", ",", "[", "]", "\n", "train_y", ",", "test_y", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "dataset", "[", "\"labels\"", "]", ")", ",", "600", ")", ":", "\n", "        ", "train_x", ".", "extend", "(", "dataset", "[", "\"data\"", "]", "[", "i", ":", "i", "+", "500", "]", ")", "\n", "test_x", ".", "extend", "(", "dataset", "[", "\"data\"", "]", "[", "i", "+", "500", ":", "i", "+", "600", "]", ")", "\n", "train_y", ".", "extend", "(", "dataset", "[", "\"labels\"", "]", "[", "i", ":", "i", "+", "500", "]", ")", "\n", "test_y", ".", "extend", "(", "dataset", "[", "\"labels\"", "]", "[", "i", "+", "500", ":", "i", "+", "600", "]", ")", "\n", "\n", "", "train_x", ",", "test_x", "=", "np", ".", "array", "(", "train_x", ")", ",", "np", ".", "array", "(", "test_x", ")", "\n", "train_y", ",", "test_y", "=", "np", ".", "array", "(", "train_y", ")", ",", "np", ".", "array", "(", "test_y", ")", "\n", "\n", "return", "XYDataset", "(", "train_x", ",", "train_y", ")", ",", "XYDataset", "(", "test_x", ",", "test_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.Datum.__init__": [[26, 33], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "impath", "=", "\"\"", ",", "label", "=", "0", ",", "domain", "=", "0", ",", "classname", "=", "\"\"", ")", ":", "\n", "        ", "assert", "isinstance", "(", "impath", ",", "str", ")", "\n", "\n", "self", ".", "_impath", "=", "impath", "\n", "self", ".", "_label", "=", "label", "\n", "self", ".", "_domain", "=", "domain", "\n", "self", ".", "_classname", "=", "classname", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.Datum.impath": [[34, 37], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "impath", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_impath", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.Datum.label": [[38, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "label", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_label", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.Datum.domain": [[42, 45], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "domain", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_domain", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.Datum.classname": [[46, 49], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "classname", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_classname", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.__init__": [[113, 140], ["os.join", "avalanche.benchmarks.datasets.downloadable_dataset.DownloadableDataset.__init__", "domainnet.DomainNet._load_dataset", "domainnet.DomainNet._read_data", "domainnet.DomainNet.set_meta_data"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet._read_data", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.set_meta_data"], ["def", "__init__", "(", "self", ",", "ds_root", ",", "domain", ":", "str", ",", "train", ":", "bool", "=", "True", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "loader", "=", "default_loader", ",", "download", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "train", "=", "train", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "domain", "=", "domain", "\n", "assert", "domain", "in", "self", ".", "domains", "\n", "assert", "domain", "in", "self", ".", "domain_to_urls", "\n", "\n", "# Paths", "\n", "self", ".", "dataset_dir", "=", "osp", ".", "join", "(", "ds_root", ",", "self", ".", "dataset_dir", ")", "\n", "super", "(", ")", ".", "__init__", "(", "root", "=", "self", ".", "dataset_dir", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "self", ".", "split_dir", "=", "self", ".", "dataset_dir", "# Same dir as main", "\n", "\"\"\" root/domainnet\"\"\"", "\n", "\n", "# Download", "\n", "self", ".", "url_data", "=", "self", ".", "domain_to_urls", "[", "self", ".", "domain", "]", "[", "0", "]", "# Download link", "\n", "self", ".", "url_trainsplit", "=", "self", ".", "domain_to_urls", "[", "self", ".", "domain", "]", "[", "1", "]", "# Download link", "\n", "self", ".", "url_testsplit", "=", "self", ".", "domain_to_urls", "[", "self", ".", "domain", "]", "[", "2", "]", "# Download link", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n", "# Preprocessing: Read Original dataset", "\n", "self", ".", "split", "=", "\"train\"", "if", "self", ".", "train", "else", "\"test\"", "\n", "self", ".", "data", ":", "list", "=", "self", ".", "_read_data", "(", "[", "self", ".", "domain", "]", ",", "split", "=", "self", ".", "split", ")", "\n", "self", ".", "set_meta_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.targets": [[141, 148], ["targets.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "targets", "(", "self", ")", ":", "\n", "        ", "\"\"\" For compatibility with AvalancheDataset.\"\"\"", "\n", "targets", "=", "[", "]", "\n", "for", "item", "in", "self", ".", "data", ":", "\n", "            ", "targets", ".", "append", "(", "item", ".", "label", ")", "\n", "", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.set_meta_data": [[149, 152], ["domainnet.DomainNet.get_num_classes", "domainnet.DomainNet.get_lab2cname"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.get_num_classes", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.get_lab2cname"], ["", "def", "set_meta_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "_num_classes", "=", "self", ".", "get_num_classes", "(", "self", ".", "data", ")", "\n", "self", ".", "_lab2cname", ",", "self", ".", "_classnames", "=", "self", ".", "get_lab2cname", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet._read_data": [[153, 178], ["isinstance", "enumerate", "os.join", "open", "f.readlines", "line.strip.strip.strip", "line.strip.strip.split", "os.join", "int", "domainnet.Datum", "items.append", "os.join.split"], "methods", ["None"], ["", "def", "_read_data", "(", "self", ",", "input_domains", ":", "list", ",", "split", "=", "\"train\"", ")", ":", "\n", "        ", "if", "isinstance", "(", "input_domains", ",", "str", ")", ":", "\n", "            ", "input_domains", "=", "[", "input_domains", "]", "\n", "\n", "", "items", "=", "[", "]", "\n", "for", "domain", ",", "dname", "in", "enumerate", "(", "input_domains", ")", ":", "\n", "            ", "filename", "=", "dname", "+", "\"_\"", "+", "split", "+", "\".txt\"", "\n", "split_file", "=", "osp", ".", "join", "(", "self", ".", "split_dir", ",", "filename", ")", "\n", "\n", "with", "open", "(", "split_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "impath", ",", "label", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "classname", "=", "impath", ".", "split", "(", "\"/\"", ")", "[", "1", "]", "\n", "impath", "=", "osp", ".", "join", "(", "self", ".", "dataset_dir", ",", "impath", ")", "\n", "label", "=", "int", "(", "label", ")", "\n", "item", "=", "Datum", "(", "\n", "impath", "=", "impath", ",", "\n", "label", "=", "label", ",", "\n", "domain", "=", "domain", ",", "\n", "classname", "=", "classname", "\n", ")", "\n", "items", ".", "append", "(", "item", ")", "\n", "", "", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.get_num_classes": [[179, 188], ["set", "len", "set.add"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "\"\"\"Count number of classes.\n        Args:\n            data_source (list): a list of Datum objects.\n        \"\"\"", "\n", "label_set", "=", "set", "(", ")", "\n", "for", "item", "in", "data_source", ":", "\n", "            ", "label_set", ".", "add", "(", "item", ".", "label", ")", "\n", "", "return", "len", "(", "label_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.get_lab2cname": [[189, 202], ["set", "list", "list.sort", "set.add", "mapping.keys"], "methods", ["None"], ["", "def", "get_lab2cname", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "\"\"\"Get a label-to-classname mapping (dict).\n        Args:\n            data_source (list): a list of Datum objects.\n        \"\"\"", "\n", "container", "=", "set", "(", ")", "\n", "for", "item", "in", "data_source", ":", "\n", "            ", "container", ".", "add", "(", "(", "item", ".", "label", ",", "item", ".", "classname", ")", ")", "\n", "", "mapping", "=", "{", "label", ":", "classname", "for", "label", ",", "classname", "in", "container", "}", "\n", "labels", "=", "list", "(", "mapping", ".", "keys", "(", ")", ")", "\n", "labels", ".", "sort", "(", ")", "\n", "classnames", "=", "[", "mapping", "[", "label", "]", "for", "label", "in", "labels", "]", "\n", "return", "mapping", ",", "classnames", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet._download_error_message": [[203, 207], ["str"], "methods", ["None"], ["", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "'Error downloading the dataset. Consider downloading '", "'it manually at: '", "+", "self", ".", "url_data", "+", "' and placing it '", "'in: '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet._download_dataset": [[208, 239], ["print", "os.basename", "os.join", "os.isfile", "print", "domainnet.DomainNet._download_and_extract_archive", "open().close", "print", "os.basename.split", "open"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_and_extract_archive", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close"], ["", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        The download procedure.\n\n        This procedure is called only if `_load_metadata` fails.\n\n        This method must raise an error if the dataset can't be downloaded.\n\n        Hints: don't re-invent the wheel! There are ready-to-use helper methods\n        like `_download_and_extract_archive`, `_download_file` and\n        `_extract_archive` that can be used.\n\n        :return: None\n        \"\"\"", "\n", "print", "(", "f\"Downloading dataset on {self.url_data}\"", ")", "\n", "zip_filename", "=", "osp", ".", "basename", "(", "self", ".", "url_data", ")", "# How to store zip-file", "\n", "\n", "# Download the dataset, downloaded to the root given to super", "\n", "finished_token_file", "=", "f\"{zip_filename.split('.')[0]}.DOWNLOADED_EXTRACTED\"", "\n", "finished_token_path", "=", "osp", ".", "join", "(", "self", ".", "root", ",", "finished_token_file", ")", "\n", "\n", "if", "osp", ".", "isfile", "(", "finished_token_path", ")", ":", "\n", "            ", "print", "(", "f\"Skipping downloading/extraction of dataset, processing token exists: {finished_token_path}\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_download_and_extract_archive", "(", "self", ".", "url_data", ",", "zip_filename", ",", "None", ",", "\n", "sub_directory", "=", "None", ",", "# Already has sub_dir with name", "\n", "remove_archive", "=", "True", "# True", "\n", ")", "\n", "# Save finished token (empty file)", "\n", "open", "(", "finished_token_path", ",", "'a'", ")", ".", "close", "(", ")", "\n", "print", "(", "f\"Saved processing token: {finished_token_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet._load_metadata": [[240, 257], ["domainnet.DomainNet._download_file", "domainnet.DomainNet._download_file", "domainnet.DomainNet._download_dataset", "os.basename", "os.basename"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_file", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_file", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._download_dataset"], ["", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        The dataset metadata loading procedure.\n\n        This procedure is called at least once to load the dataset metadata.\n\n        This procedure should return False if the dataset is corrupted or if it\n        can't be loaded.\n\n        :return: True if the dataset is not corrupted and could be successfully\n        loaded.\n        \"\"\"", "\n", "# Downlaod both metadata and the", "\n", "self", ".", "_download_file", "(", "self", ".", "url_trainsplit", ",", "file_name", "=", "osp", ".", "basename", "(", "self", ".", "url_trainsplit", ")", ",", "checksum", "=", "None", ")", "\n", "self", ".", "_download_file", "(", "self", ".", "url_testsplit", ",", "file_name", "=", "osp", ".", "basename", "(", "self", ".", "url_testsplit", ")", ",", "checksum", "=", "None", ")", "\n", "self", ".", "_download_dataset", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.__getitem__": [[258, 278], ["domainnet.DomainNet.loader", "str", "domainnet.DomainNet.transform", "domainnet.DomainNet.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target\n            class.\n        \"\"\"", "\n", "fpath", "=", "self", ".", "data", "[", "index", "]", ".", "impath", "\n", "target", "=", "self", ".", "data", "[", "index", "]", ".", "label", "\n", "\n", "sample", "=", "self", ".", "loader", "(", "str", "(", "self", ".", "root", "/", "fpath", ")", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.__len__": [[279, 281], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.__repr__": [[282, 297], ["domainnet.DomainNet.__len__", "domainnet.DomainNet.transform.__repr__().replace", "domainnet.DomainNet.target_transform.__repr__().replace", "domainnet.DomainNet.transform.__repr__", "domainnet.DomainNet.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__len__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__repr__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Domain: {}\\n'", ".", "format", "(", "self", ".", "domain", ")", "\n", "fmt_str", "+=", "'    Train: {}\\n'", ".", "format", "(", "self", ".", "train", ")", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "\n", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "\n", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.__init__": [[321, 341], ["domainnet.DomainNet.__init__", "domainnet.MiniDomainNet.subset_only_with_labels", "domainnet.MiniDomainNet.set_meta_data", "int", "enumerate", "len", "sorted", "set", "int"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.subset_only_with_labels", "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.DomainNet.set_meta_data"], ["def", "__init__", "(", "self", ",", "classes_list", ":", "List", "[", "int", "]", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "# Loads all data", "\n", "\n", "if", "classes_list", "is", "None", ":", "\n", "            ", "classes_list", "=", "self", ".", "classes_list", "\n", "\n", "# Keep original labels for summaries, but return adapted (in [0,N] range) label with adapter", "\n", "", "self", ".", "orig_to_new_target_map", "=", "{", "old_target", ":", "new_target", "\n", "for", "new_target", ",", "old_target", "in", "enumerate", "(", "sorted", "(", "classes_list", ")", ")", "}", "\n", "self", ".", "targets_adapter", "=", "lambda", "x", ":", "int", "(", "self", ".", "orig_to_new_target_map", "[", "int", "(", "x", ")", "]", ")", "\n", "\"\"\"targets_adapter: Function mapping target to other target. (e.g. transform label-subset to valid\n                                [0,N] range). Mapped at __get_item__ and calling the .target property.\"\"\"", "\n", "\n", "# Subset the data", "\n", "self", ".", "data", "=", "self", ".", "subset_only_with_labels", "(", "self", ".", "data", ",", "classes_list", ")", "\n", "self", ".", "set_meta_data", "(", ")", "\n", "\n", "# Checks", "\n", "if", "classes_list", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "_num_classes", "==", "len", "(", "set", "(", "classes_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.targets": [[342, 354], ["list", "map"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "targets", "(", "self", ")", ":", "\n", "        ", "\"\"\" For compatibility with AvalancheDataset.\n        Adapt targets to appropriate range [0,N]\"\"\"", "\n", "orig_targets", ":", "list", "=", "super", "(", ")", ".", "targets", "\n", "\n", "if", "self", ".", "targets_adapter", ":", "\n", "            ", "targets", "=", "list", "(", "map", "(", "self", ".", "targets_adapter", ",", "orig_targets", ")", ")", "\n", "", "else", ":", "\n", "            ", "targets", "=", "orig_targets", "\n", "\n", "", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.__getitem__": [[355, 363], ["domainnet.DomainNet.__getitem__", "domainnet.MiniDomainNet.targets_adapter"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Apply targets adapter on targets.\"\"\"", "\n", "sample", ",", "target", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "\n", "if", "self", ".", "targets_adapter", ":", "\n", "            ", "target", "=", "self", ".", "targets_adapter", "(", "target", ")", "\n", "\n", "", "return", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.subset_only_with_labels": [[364, 372], ["set", "out_list.append"], "methods", ["None"], ["", "def", "subset_only_with_labels", "(", "self", ",", "data_source", ":", "List", "[", "Datum", "]", ",", "labels", ":", "list", ")", "->", "List", "[", "Datum", "]", ":", "\n", "        ", "\"\"\"Return new list only containing Datum from data_source with label in labels.\"\"\"", "\n", "out_list", "=", "[", "]", "\n", "unique_labels", "=", "set", "(", "labels", ")", "\n", "for", "item", "in", "data_source", ":", "\n", "            ", "if", "item", ".", "label", "in", "unique_labels", ":", "\n", "                ", "out_list", ".", "append", "(", "item", ")", "\n", "", "", "return", "out_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.split_dataset_by_label": [[373, 385], ["collections.defaultdict", "output[].append"], "methods", ["None"], ["", "def", "split_dataset_by_label", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "\"\"\"Split a dataset, i.e. a list of Datum objects,\n        into class-specific groups stored in a dictionary.\n        Args:\n            data_source (list): a list of Datum objects.\n        \"\"\"", "\n", "output", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "item", "in", "data_source", ":", "\n", "            ", "output", "[", "item", ".", "label", "]", ".", "append", "(", "item", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.datapoints_per_class": [[386, 395], ["domainnet.MiniDomainNet.split_dataset_by_label", "sorted", "list", "dp_per_class.append", "domainnet.MiniDomainNet.keys", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.domainnet.MiniDomainNet.split_dataset_by_label"], ["", "def", "datapoints_per_class", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "\"\"\"Return list of (class,nb_datapoints) tuples.\"\"\"", "\n", "dp_per_class", "=", "[", "]", "\n", "per_class_dict", "=", "self", ".", "split_dataset_by_label", "(", "data_source", ")", "\n", "\n", "for", "c", "in", "sorted", "(", "list", "(", "per_class_dict", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "dp_per_class", ".", "append", "(", "(", "c", ",", "len", "(", "per_class_dict", "[", "c", "]", ")", ")", ")", "\n", "\n", "", "return", "dp_per_class", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.benchmarks.utils.wrap_with_task_labels": [[11, 13], ["avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset", "enumerate"], "function", ["None"], ["from", "avalanche", ".", "training", ".", "plugins", ".", "strategy_plugin", "import", "StrategyPlugin", "\n", "from", "avalanche", ".", "models", ".", "dynamic_modules", "import", "MultiHeadClassifier", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingCollector.__init__": [[29, 46], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# CONFIG", "\n", "        ", "self", ".", "collect_features", "=", "False", "\n", "self", ".", "forward_with_grad", "=", "False", "\n", "\n", "# COLLECTED", "\n", "self", ".", "pre_update_features", ":", "dict", "=", "{", "}", "# Featuredrift detection per task", "\n", "self", ".", "post_update_features", "=", "None", "# Features current task only", "\n", "self", ".", "loss", "=", "None", "\n", "self", ".", "gradnorm", "=", "None", "\n", "self", ".", "current_tracking_task", "=", "None", "\n", "\n", "# Running", "\n", "self", ".", "is_first_preupdate_step", "=", "True", "# Before doing any updates, all other tracking is after iterations", "\n", "self", ".", "is_tracking_iteration", "=", "False", "\n", "self", ".", "x", ",", "self", ".", "y", ",", "self", ".", "task_id", "=", "None", ",", "None", ",", "None", "\n", "self", ".", "preds_batch", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.__init__": [[53, 62], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "name", ",", "metric", ",", "reset_at", "=", "'iteration'", ")", ":", "\n", "        ", "\"\"\"Emits and updates metrics at each iteration\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_metric", "=", "metric", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# Mode is train", "\n", "assert", "reset_at", "in", "{", "'iteration'", ",", "'never'", "}", "# Not at stream", "\n", "self", ".", "_reset_at", "=", "reset_at", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.reset": [[64, 67], ["continual_eval_metrics.TrackerPluginMetric._metric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ",", "strategy", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"Default behavior metric.\"\"\"", "\n", "self", ".", "_metric", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.result": [[68, 71], ["continual_eval_metrics.TrackerPluginMetric._metric.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", ":", "\n", "        ", "\"\"\"Default behavior metric.\"\"\"", "\n", "return", "self", ".", "_metric", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.update": [[72, 77], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "strategy", "=", "None", ")", ":", "\n", "        ", "\"\"\"(Optional) Template method to overwrite by subclass.\n        Subclass can define own update methods instead.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.before_training_iteration": [[79, 84], ["continual_eval_metrics.TrackerPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "\"\"\"Enable passing the first pre-update step.\"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "if", "col", ".", "is_first_preupdate_step", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ",", "x_pos", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.init_tracking": [[85, 88], ["None"], "methods", ["None"], ["", "", "def", "init_tracking", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "\"\"\" Init config params. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.before_tracking": [[89, 93], ["continual_eval_metrics.TrackerPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "before_tracking", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "\"\"\" Reset metrics just before a new tracking on after_training_iteration. \"\"\"", "\n", "if", "self", ".", "_reset_at", "==", "'iteration'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.before_tracking_step": [[94, 96], ["None"], "methods", ["None"], ["", "", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.before_tracking_batch": [[97, 99], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.after_tracking_batch": [[100, 102], ["None"], "methods", ["None"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.after_tracking_step": [[103, 105], ["None"], "methods", ["None"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.after_tracking": [[106, 108], ["None"], "methods", ["None"], ["", "def", "after_tracking", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.after_training_iteration": [[109, 115], ["continual_eval_metrics.TrackerPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "\"\"\" Pass to evaluator plugin.\"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "\n", "if", "col", ".", "is_tracking_iteration", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric._package_result": [[116, 133], ["continual_eval_metrics.TrackerPluginMetric.result", "isinstance", "continual_eval_metrics.TrackerPluginMetric.items", "avalanche.evaluation.metric_utils.get_metric_name", "avalanche.evaluation.metric_utils.get_metric_name", "metrics.append", "avalanche.evaluation.metric_results.MetricValue", "avalanche.evaluation.metric_results.MetricValue"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name"], ["", "", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "x_pos", "=", "None", ")", "->", "'MetricResult'", ":", "\n", "        ", "metric_value", "=", "self", ".", "result", "(", "strategy", ")", "\n", "add_exp", "=", "False", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "if", "x_pos", "is", "None", "else", "x_pos", "# Allows pre-update step at -1", "\n", "\n", "if", "isinstance", "(", "metric_value", ",", "dict", ")", ":", "\n", "            ", "metrics", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "metric_value", ".", "items", "(", ")", ":", "\n", "                ", "metric_name", "=", "get_metric_name", "(", "\n", "self", ",", "strategy", ",", "add_experience", "=", "add_exp", ",", "add_task", "=", "k", ")", "\n", "metrics", ".", "append", "(", "MetricValue", "(", "self", ",", "metric_name", ",", "v", ",", "plot_x_position", ")", ")", "\n", "", "return", "metrics", "\n", "", "else", ":", "\n", "            ", "metric_name", "=", "get_metric_name", "(", "self", ",", "strategy", ",", "\n", "add_experience", "=", "add_exp", ",", "\n", "add_task", "=", "True", ")", "\n", "return", "[", "MetricValue", "(", "self", ",", "metric_name", ",", "metric_value", ",", "plot_x_position", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackerPluginMetric.__str__": [[134, 139], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Task label is determined by subclass, not current name. (e.g. Accuracy returns dict of per-task results.)\"\"\"", "\n", "reset_map", "=", "{", "'iteration'", ":", "'MB'", ",", "'never'", ":", "'STREAM'", "}", "\n", "assert", "self", ".", "_reset_at", "in", "reset_map", "\n", "return", "f\"TRACK_{reset_map[self._reset_at]}_{self.name}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingLossPluginMetric.__init__": [[144, 147], ["avalanche.evaluation.metrics.loss.Loss", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_loss", "=", "Loss", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"loss\"", ",", "metric", "=", "self", ".", "_loss", ",", "reset_at", "=", "'iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingLossPluginMetric.update": [[148, 152], ["continual_eval_metrics.TaskTrackingLossPluginMetric._loss.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Loss is updated externally from common stat collector.\"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "self", ".", "_loss", ".", "update", "(", "col", ".", "loss", ",", "patterns", "=", "1", ",", "task_label", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingLossPluginMetric.before_tracking_step": [[153, 155], ["None"], "methods", ["None"], ["", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingLossPluginMetric.before_tracking_batch": [[156, 158], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingLossPluginMetric.after_tracking_batch": [[159, 161], ["None"], "methods", ["None"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingLossPluginMetric.after_tracking_step": [[162, 164], ["continual_eval_metrics.TaskTrackingLossPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "self", ".", "update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingAccuracyPluginMetric.__init__": [[169, 172], ["avalanche.evaluation.metrics.accuracy.Accuracy", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_acc", "=", "Accuracy", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"acc\"", ",", "metric", "=", "self", ".", "_acc", ",", "reset_at", "=", "'iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingAccuracyPluginMetric.update": [[173, 177], ["continual_eval_metrics.TaskTrackingAccuracyPluginMetric._acc.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Loss is updated externally from common stat collector.\"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "self", ".", "_acc", ".", "update", "(", "col", ".", "preds_batch", ",", "col", ".", "y", ",", "task_labels", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingAccuracyPluginMetric.before_tracking_step": [[178, 180], ["None"], "methods", ["None"], ["", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingAccuracyPluginMetric.before_tracking_batch": [[181, 183], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingAccuracyPluginMetric.after_tracking_batch": [[184, 186], ["continual_eval_metrics.TaskTrackingAccuracyPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingAccuracyPluginMetric.after_tracking_step": [[187, 189], ["None"], "methods", ["None"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.__init__": [[194, 201], ["avalanche.evaluation.metrics.accuracy.Accuracy", "super().__init__", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "window_size", "=", "10", ")", ":", "\n", "        ", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "_current_acc", "=", "Accuracy", "(", ")", "# Per-task acc", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "f\"F{self.window_size}\"", ",", "metric", "=", "self", ".", "_current_acc", ",", "reset_at", "=", "'iteration'", ")", "\n", "\n", "self", ".", "acc_window", ":", "Dict", "[", "int", ",", "deque", "]", "=", "defaultdict", "(", "deque", ")", "\n", "self", ".", "max_forgetting", ":", "Dict", "[", "int", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.reset": [[202, 205], ["continual_eval_metrics.WindowedForgettingPluginMetric._current_acc.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "\"\"\"Only current acc is reset (each iteration), not the window\"\"\"", "\n", "self", ".", "_current_acc", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.result": [[206, 208], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "return", "self", ".", "max_forgetting", "# Always return all task results", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.update_current_task_acc": [[209, 212], ["continual_eval_metrics.WindowedForgettingPluginMetric._current_acc.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update_current_task_acc", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "self", ".", "_current_acc", ".", "update", "(", "col", ".", "preds_batch", ",", "col", ".", "y", ",", "task_labels", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.update_task_window": [[213, 228], ["continual_eval_metrics.WindowedForgettingPluginMetric._current_acc.result", "task_acc_window.append", "max", "len", "task_acc_window.popleft", "continual_eval_metrics.WindowedForgettingPluginMetric.max_consec_delta_from_window", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.max_consec_delta_from_window"], ["", "def", "update_task_window", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "new_acc_dict", ":", "Dict", "[", "int", ",", "float", "]", "=", "self", ".", "_current_acc", ".", "result", "(", "task_label", "=", "col", ".", "current_tracking_task", ")", "\n", "new_acc", "=", "new_acc_dict", "[", "col", ".", "current_tracking_task", "]", "\n", "\n", "# Add to window", "\n", "task_acc_window", "=", "self", ".", "acc_window", "[", "col", ".", "current_tracking_task", "]", "\n", "task_acc_window", ".", "append", "(", "new_acc", ")", "\n", "if", "len", "(", "task_acc_window", ")", ">", "self", ".", "window_size", ":", "\n", "            ", "task_acc_window", ".", "popleft", "(", ")", "\n", "\n", "# Update forgetting", "\n", "", "self", ".", "max_forgetting", "[", "col", ".", "current_tracking_task", "]", "=", "max", "(", "self", ".", "max_forgetting", "[", "col", ".", "current_tracking_task", "]", ",", "\n", "self", ".", "max_consec_delta_from_window", "(", "task_acc_window", ")", ")", "\n", "assert", "len", "(", "task_acc_window", ")", "<=", "self", ".", "window_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.max_consec_delta_from_window": [[229, 246], ["float", "float", "enumerate", "len", "range", "len", "continual_eval_metrics.WindowedForgettingPluginMetric.delta"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedPlasticityPluginMetric.delta"], ["", "def", "max_consec_delta_from_window", "(", "self", ",", "window", ")", "->", "float", ":", "\n", "        ", "\"\"\"Return max A_i - A_j for i<j in the window.\"\"\"", "\n", "if", "len", "(", "window", ")", "<=", "1", ":", "\n", "            ", "return", "0", "\n", "", "max_delta", "=", "float", "(", "'-inf'", ")", "\n", "max_found_acc", "=", "float", "(", "'-inf'", ")", "\n", "for", "idx", ",", "val", "in", "enumerate", "(", "window", ")", ":", "\n", "            ", "if", "val", "<", "max_found_acc", ":", "# Delta can only increase if higher", "\n", "                ", "continue", "\n", "", "max_found_acc", "=", "val", "\n", "for", "other_idx", "in", "range", "(", "idx", "+", "1", ",", "len", "(", "window", ")", ")", ":", "# Deltas with next ones", "\n", "                ", "other_val", "=", "window", "[", "other_idx", "]", "\n", "delta", "=", "self", ".", "delta", "(", "val", ",", "other_val", ")", "\n", "\n", "if", "delta", ">", "max_delta", ":", "\n", "                    ", "max_delta", "=", "delta", "\n", "", "", "", "return", "max_delta", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.delta": [[247, 252], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "delta", "(", "first_val", ",", "next_val", ")", ":", "\n", "        ", "\"\"\" May overwrite to define increase/decrease.\n        For forgetting we look for the largest decrease.\"\"\"", "\n", "return", "first_val", "-", "next_val", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.before_tracking_step": [[253, 255], ["None"], "methods", ["None"], ["", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.before_tracking_batch": [[256, 258], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.after_tracking_batch": [[259, 262], ["continual_eval_metrics.WindowedForgettingPluginMetric.update_current_task_acc"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.update_current_task_acc"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "\"\"\" Update over batches.\"\"\"", "\n", "self", ".", "update_current_task_acc", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.after_tracking_step": [[263, 266], ["continual_eval_metrics.WindowedForgettingPluginMetric.update_task_window"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedForgettingPluginMetric.update_task_window"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "\"\"\" Use the final accuracy (over batches), add to the window and calculate the forgetting.\"\"\"", "\n", "self", ".", "update_task_window", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedPlasticityPluginMetric.__init__": [[271, 274], ["continual_eval_metrics.WindowedForgettingPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "window_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "window_size", ")", "\n", "self", ".", "name", "=", "f\"P{self.window_size}\"", "# overwrite name", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WindowedPlasticityPluginMetric.delta": [[275, 279], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "delta", "(", "first_val", ",", "next_val", ")", ":", "\n", "        ", "\"\"\" Largest increase. \"\"\"", "\n", "return", "next_val", "-", "first_val", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.__init__": [[289, 293], ["avalanche.evaluation.metrics.accuracy.Accuracy", "collections.defaultdict", "super().__init__", "float"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_current_acc", "=", "Accuracy", "(", ")", "\n", "self", ".", "min_acc_tasks", ":", "dict", "=", "defaultdict", "(", "lambda", ":", "float", "(", "'inf'", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"acc_MIN\"", ",", "metric", "=", "self", ".", "_current_acc", ",", "reset_at", "=", "'iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.result": [[294, 296], ["continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.min_acc_tasks.items"], "methods", ["None"], ["", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "return", "{", "task", ":", "min_acc", "for", "task", ",", "min_acc", "in", "self", ".", "min_acc_tasks", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.update": [[297, 301], ["continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric._current_acc.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Loss is updated externally from common stat collector.\"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "self", ".", "_current_acc", ".", "update", "(", "col", ".", "preds_batch", ",", "col", ".", "y", ",", "task_labels", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.update_acc_minimum": [[302, 309], ["continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric._current_acc.result", "current_acc_results.items", "min"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "update_acc_minimum", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\"Update minimum.\"\"\"", "\n", "current_learning_task", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "current_acc_results", ":", "Dict", "[", "int", ",", "float", "]", "=", "self", ".", "_current_acc", ".", "result", "(", ")", "\n", "for", "task", ",", "task_result", "in", "current_acc_results", ".", "items", "(", ")", ":", "\n", "            ", "if", "task", "!=", "current_learning_task", ":", "# Not for current learning task", "\n", "                ", "self", ".", "min_acc_tasks", "[", "task", "]", "=", "min", "(", "self", ".", "min_acc_tasks", "[", "task", "]", ",", "task_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.before_tracking_step": [[310, 312], ["None"], "methods", ["None"], ["", "", "", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.before_tracking_batch": [[313, 315], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.after_tracking_batch": [[316, 318], ["continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.after_tracking_step": [[319, 321], ["continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.update_acc_minimum"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingMINAccuracyPluginMetric.update_acc_minimum"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "self", ".", "update_acc_minimum", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.__init__": [[326, 331], ["avalanche.evaluation.metrics.accuracy.Accuracy", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "min_acc_plugin", ":", "TaskTrackingMINAccuracyPluginMetric", ")", ":", "\n", "        ", "self", ".", "_current_acc", "=", "Accuracy", "(", ")", "\n", "self", ".", "min_acc_plugin", "=", "min_acc_plugin", "\n", "self", ".", "WCACC", "=", "None", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"WCACC\"", ",", "metric", "=", "self", ".", "_current_acc", ",", "reset_at", "=", "'iteration'", ")", "# Reset current_acc at iteration", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.result": [[332, 334], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "dict", ":", "\n", "        ", "return", "{", "0", ":", "self", ".", "WCACC", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.update": [[335, 341], ["continual_eval_metrics.WCACCPluginMetric._current_acc.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Update current acc\"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "current_learning_task", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "if", "current_learning_task", "==", "col", ".", "current_tracking_task", ":", "\n", "            ", "self", ".", "_current_acc", ".", "update", "(", "col", ".", "preds_batch", ",", "col", ".", "y", ",", "task_labels", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.before_tracking_step": [[342, 344], ["None"], "methods", ["None"], ["", "", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.before_tracking_batch": [[345, 347], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.after_tracking_batch": [[348, 351], ["continual_eval_metrics.WCACCPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "\"\"\" Update current task acc\"\"\"", "\n", "self", ".", "update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.after_tracking_step": [[352, 355], ["continual_eval_metrics.WCACCPluginMetric.update_WCACC"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.update_WCACC"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "\"\"\" Update final metric. \"\"\"", "\n", "self", ".", "update_WCACC", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.WCACCPluginMetric.update_WCACC": [[356, 376], ["avg_list.append", "continual_eval_metrics.WCACCPluginMetric.min_acc_plugin.result", "torch.mean().item", "continual_eval_metrics.WCACCPluginMetric._current_acc.result", "len", "avg_list.extend", "torch.mean", "torch.tensor", "min_acc_results.items"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "update_WCACC", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "avg_list", "=", "[", "]", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "current_learning_task", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "\n", "if", "current_learning_task", "!=", "col", ".", "current_tracking_task", ":", "# Only update once on current task step", "\n", "            ", "return", "\n", "\n", "# Current task", "\n", "", "current_learning_task", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "current_learning_task_acc", ":", "float", "=", "self", ".", "_current_acc", ".", "result", "(", ")", "[", "current_learning_task", "]", "\n", "avg_list", ".", "append", "(", "current_learning_task_acc", ")", "\n", "\n", "# Min-ACC results of OTHER tasks", "\n", "min_acc_results", ":", "Dict", "[", "int", ",", "float", "]", "=", "self", ".", "min_acc_plugin", ".", "result", "(", ")", "\n", "if", "len", "(", "min_acc_results", ")", ">", "0", ":", "\n", "            ", "avg_list", ".", "extend", "(", "[", "min_acc", "for", "task_id", ",", "min_acc", "in", "min_acc_results", ".", "items", "(", ")", "\n", "if", "task_id", "!=", "current_learning_task", "]", ")", "\n", "\n", "", "self", ".", "WCACC", "=", "torch", ".", "mean", "(", "torch", ".", "tensor", "(", "avg_list", ")", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.__init__": [[386, 396], ["avalanche.evaluation.metrics.accuracy.Accuracy", "collections.defaultdict", "collections.defaultdict", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "beta", "=", "10", ")", ":", "\n", "        ", "\"\"\"beta is window size of the 'beta' first accuracies.\"\"\"", "\n", "assert", "beta", ">", "0", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "_current_acc", "=", "Accuracy", "(", ")", "\n", "\n", "self", ".", "acc_window_tasks", ":", "Dict", "[", "int", ",", "list", "]", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "lca_task_counts", ":", "Dict", "[", "int", ",", "int", "]", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "lca_tasks", ":", "Dict", "[", "int", ",", "float", "]", "=", "{", "}", "# Avged over beta subsequent minibatch values (range of b-shot values)", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"LCA\"", ",", "metric", "=", "self", ".", "_current_acc", ",", "reset_at", "=", "'iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.result": [[397, 401], ["len", "torch.mean().item", "torch.mean", "torch.tensor", "continual_eval_metrics.TrackingLCAPluginMetric.lca_tasks.items"], "methods", ["None"], ["", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "\"\"\"Should always return average, avg over b-shot values and tasks.\"\"\"", "\n", "if", "len", "(", "self", ".", "lca_tasks", ")", ">", "0", ":", "\n", "            ", "return", "{", "0", ":", "torch", ".", "mean", "(", "torch", ".", "tensor", "(", "[", "lca_task", "for", "t", ",", "lca_task", "in", "self", ".", "lca_tasks", ".", "items", "(", ")", "]", ")", ")", ".", "item", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.update": [[402, 408], ["continual_eval_metrics.TrackingLCAPluginMetric._current_acc.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Update running accuracy. \"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "current_learning_task", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "if", "col", ".", "current_tracking_task", "==", "current_learning_task", ":", "# Only for current learning task", "\n", "            ", "self", ".", "_current_acc", ".", "update", "(", "col", ".", "preds_batch", ",", "col", ".", "y", ",", "task_labels", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.update_LCA": [[409, 430], ["continual_eval_metrics.TrackingLCAPluginMetric._current_acc.result", "continual_eval_metrics.TrackingLCAPluginMetric.acc_window_tasks[].append", "torch.mean().item", "torch.mean", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "", "def", "update_LCA", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\"Add accuracy to fixed window if window not full, and calculate LCA if window is filled completely.\n        Only proceed if not current learning task.\"\"\"", "\n", "current_learning_task", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "if", "col", ".", "current_tracking_task", "!=", "current_learning_task", ":", "# Only for current learning task", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "lca_task_counts", "[", "current_learning_task", "]", ">=", "self", ".", "beta", ":", "# Window is full", "\n", "            ", "return", "\n", "\n", "", "current_acc_results", ":", "Dict", "[", "int", ",", "float", "]", "=", "self", ".", "_current_acc", ".", "result", "(", ")", "\n", "current_acc_task", "=", "current_acc_results", "[", "current_learning_task", "]", "\n", "\n", "# Update windows/counts", "\n", "self", ".", "acc_window_tasks", "[", "current_learning_task", "]", ".", "append", "(", "current_acc_task", ")", "\n", "self", ".", "lca_task_counts", "[", "current_learning_task", "]", "+=", "1", "\n", "\n", "if", "self", ".", "lca_task_counts", "[", "current_learning_task", "]", "==", "self", ".", "beta", ":", "# Can calculate LCA", "\n", "            ", "self", ".", "lca_tasks", "[", "current_learning_task", "]", "=", "torch", ".", "mean", "(", "\n", "torch", ".", "tensor", "(", "self", ".", "acc_window_tasks", "[", "current_learning_task", "]", ")", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.before_tracking_step": [[431, 433], ["None"], "methods", ["None"], ["", "", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.before_tracking_batch": [[434, 436], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.after_tracking_batch": [[437, 439], ["continual_eval_metrics.TrackingLCAPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.after_tracking_step": [[440, 442], ["continual_eval_metrics.TrackingLCAPluginMetric.update_LCA"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TrackingLCAPluginMetric.update_LCA"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "self", ".", "update_LCA", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric.__init__": [[445, 454], ["avalanche.evaluation.metrics.loss.Loss", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        General instantiation of the GradNorm Metric.\n\n        :param classes: List of classes for which the deltas are averaged over.\n        Only 1 class will simply give the deltas for this one class' prototypes.\n        \"\"\"", "\n", "self", ".", "_gradnorm_mean", "=", "Loss", "(", ")", "# Also returns for multiple tasks!", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"gradnorm\"", ",", "metric", "=", "self", ".", "_gradnorm_mean", ",", "reset_at", "=", "'iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric.update": [[455, 460], ["src.utils.get_grad_normL2", "continual_eval_metrics.TaskTrackingGradnormPluginMetric._gradnorm_mean.update", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_grad_normL2", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Grad is already avg, so nb patterns should be 1, not len(strategy.mb_y).\"\"\"", "\n", "col", "=", "strategy", ".", "tracking_collector", "\n", "gradnorm", "=", "get_grad_normL2", "(", "strategy", ".", "model", ")", "\n", "self", ".", "_gradnorm_mean", ".", "update", "(", "torch", ".", "tensor", "(", "gradnorm", ")", ",", "patterns", "=", "1", ",", "task_label", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric.init_tracking": [[461, 464], ["None"], "methods", ["None"], ["", "def", "init_tracking", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "col", "=", "strategy", ".", "tracking_collector", "\n", "col", ".", "forward_with_grad", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric.before_tracking_step": [[465, 467], ["None"], "methods", ["None"], ["", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric.before_tracking_batch": [[468, 470], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric.after_tracking_batch": [[471, 473], ["None"], "methods", ["None"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingGradnormPluginMetric.after_tracking_step": [[474, 476], ["continual_eval_metrics.TaskTrackingGradnormPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "self", ".", "update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.__init__": [[481, 487], ["avalanche.evaluation.metrics.loss.Loss", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_featdrift", "=", "Loss", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"featdrift\"", ",", "metric", "=", "self", ".", "_featdrift", ",", "reset_at", "=", "'iteration'", ")", "\n", "\n", "# State vars", "\n", "self", ".", "_pre_update_feats", "=", "{", "}", "# Per task", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.update": [[488, 497], ["continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.get_feat_delta", "continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric._featdrift.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.get_feat_delta", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Loss is updated externally from common stat collector.\"\"\"", "\n", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "if", "col", ".", "is_first_preupdate_step", ":", "# Pre-update step = 0 feature drift", "\n", "            ", "return", "\n", "", "assert", "col", ".", "pre_update_features", "is", "not", "None", "\n", "assert", "col", ".", "post_update_features", "is", "not", "None", "\n", "featdrift", "=", "self", ".", "get_feat_delta", "(", "col", ".", "pre_update_features", "[", "col", ".", "current_tracking_task", "]", ",", "col", ".", "post_update_features", ")", "\n", "self", ".", "_featdrift", ".", "update", "(", "featdrift", ",", "patterns", "=", "1", ",", "task_label", "=", "col", ".", "current_tracking_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.init_tracking": [[498, 501], ["None"], "methods", ["None"], ["", "def", "init_tracking", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "col", ":", "TrackingCollector", "=", "strategy", ".", "tracking_collector", "\n", "col", ".", "collect_features", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.before_tracking_step": [[502, 504], ["None"], "methods", ["None"], ["", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.before_tracking_batch": [[505, 507], ["None"], "methods", ["None"], ["", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.after_tracking_batch": [[508, 510], ["None"], "methods", ["None"], ["", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.after_tracking_step": [[511, 514], ["continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "self", ".", "update", "(", "strategy", ")", "\n", "self", ".", "_pre_update_feats", "=", "{", "}", "# Reset", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.get_feat_delta": [[515, 519], ["torch.mean", "torch.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_feat_delta", "(", "f1_batch", ",", "f2_batch", ")", ":", "\n", "        ", "\"\"\" Sum MSE values over featdims, avg over samples\"\"\"", "\n", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "(", "f1_batch", "-", "f2_batch", ")", "**", "2", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskAveragingPluginMetric.__init__": [[524, 527], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "task_metric_plugin", ")", ":", "\n", "        ", "self", ".", "task_metric_plugin", "=", "task_metric_plugin", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "self", ".", "task_metric_plugin", ".", "name", ",", "metric", "=", "self", ".", "task_metric_plugin", ",", "reset_at", "=", "'never'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskAveragingPluginMetric.reset": [[528, 531], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "\"\"\" Never reset the original metric plugin.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskAveragingPluginMetric.update": [[532, 535], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Never update the original metric plugin.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskAveragingPluginMetric.result": [[536, 540], ["continual_eval_metrics.TaskAveragingPluginMetric.task_metric_plugin.result", "len", "torch.mean().item", "torch.mean", "torch.tensor", "continual_eval_metrics.TaskAveragingPluginMetric.items"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "dict", ":", "\n", "        ", "task_dict", "=", "self", ".", "task_metric_plugin", ".", "result", "(", ")", "# Always return all task results", "\n", "if", "len", "(", "task_dict", ")", ">", "0", ":", "\n", "            ", "return", "{", "0", ":", "torch", ".", "mean", "(", "torch", ".", "tensor", "(", "[", "t_acc", "for", "t", ",", "t_acc", "in", "task_dict", ".", "items", "(", ")", "]", ")", ")", ".", "item", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskAveragingPluginMetric.__str__": [[541, 543], ["str"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{str(self.task_metric_plugin)}_AVG\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.__init__": [[25, 79], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "src.eval.continual_eval_metrics.TrackingCollector", "print", "isinstance", "list", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tracking_plugins", ":", "List", "[", "TrackerPluginMetric", "]", ",", "\n", "max_task_subset_size", "=", "None", ",", "# Max nb of iterations on task-datasets", "\n", "eval_stream", "=", "None", ",", "eval_stream_task_labels", "=", "None", ",", "\n", "mb_update_freq", "=", "100", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ",", "skip_unseen_tasks", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Introduces Continual Evaluation tracking flow after training iterations.\n        As this plugin collects additional information in the training phases, depending on the plugins,\n        the plugins can add and set 'tracking_dict' attributes, that will enable/disable the collecting of this\n        information in this Plugin. e.g. the FeatureDriftPlugin could set 'collect_features' to True.\n\n        New flow:\n        ...\n        - before_training_iteration\n        - after_training_iteration\n            - before_tracking_step\n            - before_tracking_batch\n            - after_tracking_batch\n            - after_tracking_step\n        - after_training_epoch\n        ...\n\n        It assumes this Plugin is called first, hence updating all connected TrackerPluginMetrics.\n        The TrackerPluginMetric is only called after this ContinualEvaluationPhasePlugin, hence the\n        after_training_iteration will enable emitting the results obtained during collection with this\n        ContinualEvaluationPhasePlugin.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tracking_collector", "=", "TrackingCollector", "(", ")", "\n", "\n", "# Checks", "\n", "for", "p", "in", "tracking_plugins", ":", "\n", "            ", "assert", "isinstance", "(", "p", ",", "TrackerPluginMetric", ")", "\n", "", "self", ".", "plugins", "=", "tracking_plugins", "\n", "\n", "# Hyperparams", "\n", "self", ".", "max_task_subset_size", "=", "max_task_subset_size", "if", "max_task_subset_size", ">", "0", "else", "None", "\n", "self", ".", "eval_stream", "=", "eval_stream", "\n", "self", ".", "eval_stream_task_labels", "=", "eval_stream_task_labels", "\n", "if", "self", ".", "eval_stream", "and", "self", ".", "eval_stream_task_labels", "is", "None", ":", "\n", "            ", "self", ".", "eval_stream_task_labels", "=", "list", "(", "range", "(", "len", "(", "self", ".", "eval_stream", ")", ")", ")", "\n", "\n", "", "self", ".", "mb_update_freq", "=", "mb_update_freq", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "pin_memory", "=", "pin_memory", "\n", "self", ".", "skip_unseen_tasks", "=", "skip_unseen_tasks", "\n", "\n", "# State vars", "\n", "self", ".", "seen_tasks", "=", "[", "]", "\n", "self", ".", "subset_idxs", "=", "[", "None", "]", "*", "len", "(", "self", ".", "eval_stream", ")", "\n", "self", ".", "initial_step", "=", "False", "\n", "print", "(", "f\"TRACKING: subsetsize={self.max_task_subset_size},freq={self.mb_update_freq},stream={self.eval_stream}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.set_subset_idxs": [[80, 88], ["zip", "continual_eval.ContinualEvaluationPhasePlugin.subset_idxs.append", "torch.randperm", "len"], "methods", ["None"], ["", "def", "set_subset_idxs", "(", "self", ")", ":", "\n", "        ", "\"\"\" If only using subset of tracking stream, fix idxs beforehand. \"\"\"", "\n", "if", "self", ".", "max_task_subset_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "subset_idxs", "=", "[", "]", "\n", "for", "exp", ",", "task_label", "in", "zip", "(", "self", ".", "eval_stream", ",", "self", ".", "eval_stream_task_labels", ")", ":", "\n", "                ", "dataset", "=", "exp", ".", "dataset", "\n", "task_subset_idxs", "=", "torch", ".", "randperm", "(", "len", "(", "dataset", ")", ")", "[", ":", "self", ".", "max_task_subset_size", "]", "\n", "self", ".", "subset_idxs", ".", "append", "(", "task_subset_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_training": [[92, 98], ["p.init_tracking"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval_metrics.TaskTrackingFeatureDriftPluginMetric.init_tracking"], ["", "", "", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Initialize configs.\"\"\"", "\n", "strategy", ".", "tracking_collector", "=", "self", ".", "tracking_collector", "# For params to set in metrics", "\n", "\n", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "init_tracking", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_training_exp": [[99, 103], ["continual_eval.ContinualEvaluationPhasePlugin.seen_tasks.append"], "methods", ["None"], ["", "", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "\"\"\" Update seen experiences.\"\"\"", "\n", "exp_counter", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "self", ".", "seen_tasks", ".", "append", "(", "exp_counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_training_iteration": [[104, 123], ["continual_eval.ContinualEvaluationPhasePlugin.set_subset_idxs", "continual_eval.ContinualEvaluationPhasePlugin.continual_eval_phase", "continual_eval.ContinualEvaluationPhasePlugin._collect_exps_feats", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.set_subset_idxs", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.continual_eval_phase", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin._collect_exps_feats"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "\"\"\" Phase called from main flow.\n        Retrieve feats for delta metric. Can't reuse feats because otherwise delta depends on the logging freq.\n        We only want a one-step delta.\"\"\"", "\n", "# Subsetting of tracking stream", "\n", "self", ".", "set_subset_idxs", "(", ")", "\n", "\n", "# Track only based on frequency or last in experience.", "\n", "strategy", ".", "tracking_collector", ".", "is_tracking_iteration", "=", "(", "\n", "strategy", ".", "clock", ".", "train_epoch_iterations", "%", "self", ".", "mb_update_freq", "==", "0", "\n", "or", "strategy", ".", "clock", ".", "train_epoch_iterations", "==", "len", "(", "strategy", ".", "dataloader", ")", ")", "\n", "\n", "# Pass the very first step where no updates were performed yet", "\n", "if", "self", ".", "tracking_collector", ".", "is_first_preupdate_step", ":", "\n", "            ", "self", ".", "continual_eval_phase", "(", "strategy", ")", "\n", "\n", "# Collect features before update", "\n", "", "if", "self", ".", "tracking_collector", ".", "collect_features", "and", "strategy", ".", "tracking_collector", ".", "is_tracking_iteration", ":", "\n", "            ", "self", ".", "_collect_exps_feats", "(", "strategy", ",", "self", ".", "eval_stream", ")", "# Collect pre-update feats", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_training_iteration": [[124, 133], ["continual_eval.ContinualEvaluationPhasePlugin.continual_eval_phase"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.continual_eval_phase"], ["", "", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "\"\"\" Add ContinualEval phase after iteration in main Avalanche flow.\"\"\"", "\n", "\n", "# After first update is never the preupdate step anymore", "\n", "self", ".", "tracking_collector", ".", "is_first_preupdate_step", "=", "False", "\n", "\n", "# Get stats for all the evalstream experiences.", "\n", "if", "strategy", ".", "tracking_collector", ".", "is_tracking_iteration", ":", "\n", "            ", "self", ".", "continual_eval_phase", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.continual_eval_phase": [[134, 138], ["continual_eval.ContinualEvaluationPhasePlugin.before_tracking", "continual_eval.ContinualEvaluationPhasePlugin.track", "continual_eval.ContinualEvaluationPhasePlugin.after_tracking"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.track", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking"], ["", "", "def", "continual_eval_phase", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "before_tracking", "(", "strategy", ")", "\n", "self", ".", "track", "(", "strategy", ",", "self", ".", "eval_stream", ")", "\n", "self", ".", "after_tracking", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking": [[142, 145], ["p.before_tracking"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking"], ["", "def", "before_tracking", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_tracking", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking_step": [[146, 149], ["p.before_tracking_step"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking_step"], ["", "", "def", "before_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_tracking_step", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking_batch": [[150, 153], ["p.before_tracking_batch"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking_batch"], ["", "", "def", "before_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_tracking_batch", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking_batch": [[154, 157], ["p.after_tracking_batch"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking_batch"], ["", "", "def", "after_tracking_batch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_tracking_batch", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking_step": [[158, 161], ["p.after_tracking_step"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking_step"], ["", "", "def", "after_tracking_step", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_tracking_step", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking": [[162, 165], ["p.after_tracking"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking"], ["", "", "def", "after_tracking", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_tracking", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.forward_data": [[169, 226], ["torch.utils.data.DataLoader", "torch.nn.CrossEntropyLoss", "enumerate", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheSubset", "continual_eval.ContinualEvaluationPhasePlugin.before_tracking_batch", "range", "strategy.model.forward_feats", "strategy.model.forward_classifier", "torch.nn.CrossEntropyLoss.", "continual_eval.ContinualEvaluationPhasePlugin.after_tracking_batch", "len", "mbatch[].to", "strategy.model.forward_feats.detach().clone", "torch.zeros", "strategy.model.forward_feats.detach", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking_batch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.forward_feats", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.model.FeatClassifierModel.forward_classifier", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking_batch"], ["", "", "def", "forward_data", "(", "self", ",", "dataset", ",", "strategy", ",", "tracking_task", ",", "collect_feats", "=", "False", ",", "subset_idxs", ":", "list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Both task-incremental and class-incremental are supported.\n        Task-incremental will automatically return outputs and metrics from the specific Task-Head.\n        Class-incremental metrics are always calculated on the entire output space.\n\n        Batch-wise iterating data to calculate grad-norm allows to remove the inputs/activations that are irrelevant,\n        but the computatinoal graph for the parameters with requries_grad = True remains. Therefore, memory is saved,\n        but for large tasks the computational graph can become very large leading to memory-exceptions.\n\n        :param collect_feats: Return features of entire experience.\n        :param track_acc_task: From which task to track accuracy for in the acc_plugin.\n        :return:\n        \"\"\"", "\n", "# Subset if possible", "\n", "if", "subset_idxs", "is", "not", "None", ":", "\n", "            ", "dataset", "=", "AvalancheSubset", "(", "dataset", ",", "indices", "=", "subset_idxs", ")", "\n", "\n", "", "bs", "=", "strategy", ".", "eval_mb_size", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "batch_size", "=", "bs", ",", "\n", "pin_memory", "=", "self", ".", "pin_memory", ")", "\n", "\n", "col", "=", "self", ".", "tracking_collector", "\n", "col", ".", "current_tracking_task", "=", "tracking_task", "\n", "\n", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", "# Sum and keep cnt", "\n", "\n", "# Collected over batches", "\n", "loss_batch", "=", "0", "\n", "feats_all", "=", "None", "\n", "sample_cnt", "=", "0", "\n", "for", "it", ",", "mbatch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "self", ".", "before_tracking_batch", "(", "strategy", ")", "\n", "\n", "# Unpack", "\n", "for", "i", "in", "range", "(", "len", "(", "mbatch", ")", ")", ":", "\n", "                ", "mbatch", "[", "i", "]", "=", "mbatch", "[", "i", "]", ".", "to", "(", "strategy", ".", "device", ")", "# unpack", "\n", "", "col", ".", "x", ",", "col", ".", "y", ",", "col", ".", "task_id", "=", "mbatch", "\n", "samples_in_batch", "=", "col", ".", "x", ".", "shape", "[", "0", "]", "\n", "\n", "feats_batch", "=", "strategy", ".", "model", ".", "forward_feats", "(", "col", ".", "x", ")", "# Forward", "\n", "col", ".", "preds_batch", "=", "strategy", ".", "model", ".", "forward_classifier", "(", "feats_batch", ",", "task_labels", "=", "col", ".", "task_id", ")", "\n", "loss_batch", "+=", "criterion", "(", "col", ".", "preds_batch", ",", "col", ".", "y", ")", "# Criterion avgs over batch dim", "\n", "\n", "# Collect features", "\n", "if", "collect_feats", ":", "\n", "                ", "if", "feats_all", "is", "None", ":", "\n", "                    ", "feats_all", "=", "torch", ".", "zeros", "(", "(", "len", "(", "dataset", ")", ",", ")", "+", "feats_batch", ".", "shape", "[", "1", ":", "]", ")", "\n", "", "feats_all", "[", "sample_cnt", ":", "sample_cnt", "+", "samples_in_batch", "]", "=", "feats_batch", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "", "sample_cnt", "+=", "samples_in_batch", "# Update cnt", "\n", "self", ".", "after_tracking_batch", "(", "strategy", ")", "# Set collector", "\n", "\n", "", "loss_batch_avg", "=", "loss_batch", "/", "sample_cnt", "# Avg over task", "\n", "return", "loss_batch_avg", ",", "feats_all", "# Feats is None if not tracking", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.track": [[227, 262], ["continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "zip", "continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_", "strategy.optimizer.zero_grad", "strategy.optimizer.zero_grad", "strategy.model.eval", "exp.dataset.eval", "continual_eval.ContinualEvaluationPhasePlugin.before_tracking_step", "continual_eval.ContinualEvaluationPhasePlugin.after_tracking_step", "continual_eval.ContinualEvaluationPhasePlugin.forward_data", "col.loss.backward", "torch.no_grad", "continual_eval.ContinualEvaluationPhasePlugin.forward_data"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.before_tracking_step", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.after_tracking_step", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.forward_data", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.forward_data"], ["", "def", "track", "(", "self", ",", "strategy", ",", "eval_stream", ")", ":", "\n", "        ", "\"\"\" During training, eval on arbitrary stream of experiences on the current model.\n        We collect stats such as avg gradnorm/loss per experience.\n\n        In task-incremental setting, only forward seen tasks as they have no head yet available.\n        \"\"\"", "\n", "col", "=", "self", ".", "tracking_collector", "\n", "_prev_state", ",", "_prev_training_modes", "=", "self", ".", "get_strategy_state", "(", "strategy", ")", "\n", "for", "exp", ",", "task_label", ",", "subset_idxs", "in", "zip", "(", "eval_stream", ",", "self", ".", "eval_stream_task_labels", ",", "self", ".", "subset_idxs", ")", ":", "\n", "            ", "if", "self", ".", "skip_unseen_tasks", "and", "task_label", "not", "in", "self", ".", "seen_tasks", ":", "\n", "                ", "continue", "\n", "\n", "", "strategy", ".", "optimizer", ".", "zero_grad", "(", ")", "# Zero grad to ensure no interference", "\n", "strategy", ".", "is_training", "=", "True", "\n", "strategy", ".", "model", ".", "eval", "(", ")", "# Set to eval mode for BN/Dropout", "\n", "dataset", "=", "exp", ".", "dataset", ".", "eval", "(", ")", "# Set transforms", "\n", "\n", "# Forward and get grads", "\n", "self", ".", "before_tracking_step", "(", "strategy", ")", "\n", "\n", "# With or without grads forward", "\n", "if", "col", ".", "forward_with_grad", ":", "\n", "                ", "col", ".", "loss", ",", "col", ".", "post_update_features", "=", "self", ".", "forward_data", "(", "\n", "dataset", ",", "strategy", ",", "task_label", ",", "collect_feats", "=", "col", ".", "collect_features", ",", "subset_idxs", "=", "subset_idxs", ")", "\n", "col", ".", "loss", ".", "backward", "(", ")", "\n", "", "else", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "col", ".", "loss", ",", "col", ".", "post_update_features", "=", "self", ".", "forward_data", "(", "\n", "dataset", ",", "strategy", ",", "task_label", ",", "collect_feats", "=", "col", ".", "collect_features", ",", "subset_idxs", "=", "subset_idxs", ")", "\n", "\n", "", "", "self", ".", "after_tracking_step", "(", "strategy", ")", "\n", "\n", "# Reset grads for safety", "\n", "", "self", ".", "restore_strategy_", "(", "strategy", ",", "_prev_state", ",", "_prev_training_modes", ")", "\n", "strategy", ".", "optimizer", ".", "zero_grad", "(", ")", "# Zero grad to ensure no interference", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin._collect_exps_feats": [[263, 281], ["torch.no_grad", "continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "zip", "continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_", "strategy.model.eval", "exp.dataset.eval", "torch.no_grad", "continual_eval.ContinualEvaluationPhasePlugin.forward_data"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.forward_data"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_collect_exps_feats", "(", "self", ",", "strategy", ",", "eval_streams", ")", ":", "\n", "        ", "\"\"\"Collect features only for all in eval_streams.\"\"\"", "\n", "_prev_state", ",", "_prev_training_modes", "=", "self", ".", "get_strategy_state", "(", "strategy", ")", "\n", "col", "=", "strategy", ".", "tracking_collector", "\n", "for", "exp", ",", "task_label", ",", "subset_idxs", "in", "zip", "(", "eval_streams", ",", "self", ".", "eval_stream_task_labels", ",", "self", ".", "subset_idxs", ")", ":", "\n", "            ", "if", "self", ".", "skip_unseen_tasks", "and", "task_label", "not", "in", "self", ".", "seen_tasks", ":", "\n", "                ", "continue", "\n", "\n", "# Forward (no grads)", "\n", "", "strategy", ".", "is_training", "=", "True", "\n", "strategy", ".", "model", ".", "eval", "(", ")", "# Set to eval mode for BN/Dropout", "\n", "dataset", "=", "exp", ".", "dataset", ".", "eval", "(", ")", "# Set transforms", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", ",", "feats", "=", "self", ".", "forward_data", "(", "dataset", ",", "strategy", ",", "task_label", ",", "collect_feats", "=", "True", ",", "subset_idxs", "=", "subset_idxs", ")", "\n", "", "col", ".", "pre_update_features", "[", "task_label", "]", "=", "feats", "\n", "\n", "", "self", ".", "restore_strategy_", "(", "strategy", ",", "_prev_state", ",", "_prev_training_modes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state": [[282, 298], ["strategy.model.named_modules"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_strategy_state", "(", "strategy", ")", ":", "\n", "# Since we are switching from train to eval model inside the training", "\n", "# loop, we need to save the training state, and restore it after the", "\n", "# eval is done.", "\n", "        ", "_prev_state", "=", "(", "\n", "strategy", ".", "experience", ",", "\n", "strategy", ".", "adapted_dataset", ",", "\n", "strategy", ".", "dataloader", ",", "\n", "strategy", ".", "is_training", ")", "\n", "\n", "# save each layer's training mode, to restore it later", "\n", "_prev_training_modes", "=", "{", "}", "\n", "for", "name", ",", "layer", "in", "strategy", ".", "model", ".", "named_modules", "(", ")", ":", "\n", "            ", "_prev_training_modes", "[", "name", "]", "=", "layer", ".", "training", "\n", "", "return", "_prev_state", ",", "_prev_training_modes", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_": [[299, 310], ["strategy.model.named_modules", "layer.train"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train"], ["", "@", "staticmethod", "\n", "def", "restore_strategy_", "(", "strategy", ",", "prev_state", ",", "prev_training_modes", ")", ":", "\n", "# restore train-state variables and training mode.", "\n", "        ", "strategy", ".", "experience", ",", "strategy", ".", "adapted_dataset", "=", "prev_state", "[", ":", "2", "]", "\n", "strategy", ".", "dataloader", "=", "prev_state", "[", "2", "]", "\n", "strategy", ".", "is_training", "=", "prev_state", "[", "3", "]", "\n", "\n", "# restore each layer's training mode to original", "\n", "for", "name", ",", "layer", "in", "strategy", ".", "model", ".", "named_modules", "(", ")", ":", "\n", "            ", "prev_mode", "=", "prev_training_modes", "[", "name", "]", "\n", "layer", ".", "train", "(", "mode", "=", "prev_mode", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeAdderPlugin.__init__": [[34, 40], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "classes", ":", "list", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "classes", "=", "classes", "\n", "\n", "# State", "\n", "self", ".", "protos_weight", ",", "self", ".", "protos_bias", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeAdderPlugin.before_training_iteration": [[41, 44], ["src.utils.get_prototypes_from_classifier"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_prototypes_from_classifier"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Gather prototypes.\"\"\"", "\n", "self", ".", "protos_weight", ",", "self", ".", "protos_bias", "=", "get_prototypes_from_classifier", "(", "strategy", ".", "model", ".", "classifier", ",", "get_clone", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeAdderPlugin.after_backward": [[45, 49], ["torch.no_grad", "minibatch_logging.StrategyAttributeAdderPlugin._track_loss_components"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeAdderPlugin._track_loss_components"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "after_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Calculate different stats of the loss etc of current minibatch.\"\"\"", "\n", "self", ".", "_track_loss_components", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeAdderPlugin.after_update": [[50, 62], ["torch.no_grad", "src.utils.get_prototypes_from_classifier", "new_protos_weight.items", "new_protos_bias.items", "setattr", "setattr", "setattr", "setattr", "torch.linalg.norm", "torch.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_prototypes_from_classifier"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "after_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "# Deltas", "\n", "        ", "new_protos_weight", ",", "new_protos_bias", "=", "get_prototypes_from_classifier", "(", "strategy", ".", "model", ".", "classifier", ",", "get_clone", "=", "True", ")", "\n", "for", "y", ",", "new_param", "in", "new_protos_weight", ".", "items", "(", ")", ":", "\n", "            ", "p_delta", "=", "(", "new_param", "-", "self", ".", "protos_weight", "[", "y", "]", ")", "**", "2", "\n", "setattr", "(", "strategy", ",", "f'protodelta_weight_c{y}'", ",", "p_delta", ")", "\n", "setattr", "(", "strategy", ",", "f'protonorm_weight_c{y}'", ",", "torch", ".", "linalg", ".", "norm", "(", "new_param", ")", ")", "\n", "", "for", "y", ",", "new_param", "in", "new_protos_bias", ".", "items", "(", ")", ":", "\n", "            ", "p_delta_b", "=", "(", "new_param", "-", "self", ".", "protos_bias", "[", "y", "]", ")", "**", "2", "\n", "setattr", "(", "strategy", ",", "f'protodelta_bias_c{y}'", ",", "p_delta_b", ")", "\n", "setattr", "(", "strategy", ",", "f'protonorm_bias_c{y}'", ",", "torch", ".", "linalg", ".", "norm", "(", "new_param", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeAdderPlugin._track_loss_components": [[63, 88], ["torch.unique", "torch.nonzero", "torch.mean", "setattr", "setattr", "setattr", "torch.mean", "torch.log", "delattr", "delattr", "delattr", "y_outputs.exp().sum", "y.item", "y.item", "y.item", "y_outputs.exp", "y.item"], "methods", ["None"], ["", "", "def", "_track_loss_components", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "unique_y", ":", "Tensor", "=", "torch", ".", "unique", "(", "strategy", ".", "mb_y", ")", "\n", "for", "y", "in", "unique_y", ":", "# Per class", "\n", "            ", "y_mb_idxs", "=", "torch", ".", "nonzero", "(", "y", "==", "strategy", ".", "mb_y", ",", "as_tuple", "=", "True", ")", "\n", "y_outputs", "=", "strategy", ".", "mb_output", "[", "y_mb_idxs", "]", "\n", "\n", "# Per class", "\n", "Lce_numerator_y", "=", "-", "torch", ".", "mean", "(", "y_outputs", "[", ":", ",", "y", ".", "item", "(", ")", "]", ")", "# Logits of final layer", "\n", "Lce_denominator_y", "=", "torch", ".", "mean", "(", "torch", ".", "log", "(", "y_outputs", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ")", ")", "\n", "Lce_y", "=", "Lce_numerator_y", "+", "Lce_denominator_y", "\n", "\n", "setattr", "(", "strategy", ",", "f'Lce_numerator_c{y.item()}'", ",", "Lce_numerator_y", ")", "\n", "setattr", "(", "strategy", ",", "f'Lce_denominator_c{y.item()}'", ",", "Lce_denominator_y", ")", "\n", "setattr", "(", "strategy", ",", "f'Lce_c{y.item()}'", ",", "Lce_y", ")", "\n", "\n", "# Reset others", "\n", "", "for", "y_other", "in", "self", ".", "classes", ":", "\n", "            ", "if", "y_other", "in", "unique_y", ":", "\n", "                ", "continue", "\n", "", "try", ":", "\n", "                ", "delattr", "(", "strategy", ",", "f'Lce_numerator_c{y_other}'", ")", "\n", "delattr", "(", "strategy", ",", "f'Lce_denominator_c{y_other}'", ")", "\n", "delattr", "(", "strategy", ",", "f'Lce_c{y_other}'", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeTrackerPlugin.__init__": [[91, 101], ["avalanche.evaluation.metrics.loss.MinibatchLoss.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", ",", "strategy_attr", ":", "List", "[", "str", "]", ",", "metric_label", "=", "None", ",", ")", ":", "\n", "        ", "\"\"\"\n        Metric that tracks the values of an attribute of the Strategy each mini-batch in training.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "strategy_attr", ",", "str", ")", ":", "\n", "            ", "strategy_attr", "=", "[", "strategy_attr", "]", "\n", "", "self", ".", "strategy_attr", "=", "strategy_attr", "# First retrieve the object from the strategy to retrieve the loss from", "\n", "self", ".", "metric_label", "=", "self", ".", "strategy_attr", "[", "-", "1", "]", "if", "metric_label", "is", "None", "else", "metric_label", "\n", "self", ".", "except_cnt", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeTrackerPlugin.update": [[102, 133], ["isinstance", "minibatch_logging.StrategyAttributeTrackerPlugin._loss.update", "len", "getattr.detach().clone", "torch.tensor", "getattr", "len", "print", "print", "getattr.detach"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "# task labels defined for each experience", "\n", "        ", "task_labels", "=", "strategy", ".", "experience", ".", "task_labels", "\n", "if", "len", "(", "task_labels", ")", ">", "1", ":", "\n", "# task labels defined for each pattern", "\n", "# fall back to single task case", "\n", "            ", "task_label", "=", "0", "\n", "", "else", ":", "\n", "            ", "task_label", "=", "task_labels", "[", "0", "]", "\n", "\n", "", "try", ":", "\n", "            ", "ref_obj", "=", "strategy", "\n", "# import pdb;pdb.set_trace()", "\n", "for", "attr", "in", "self", ".", "strategy_attr", ":", "\n", "                ", "ref_obj", "=", "getattr", "(", "ref_obj", ",", "attr", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "if", "self", ".", "except_cnt", "==", "0", ":", "\n", "                ", "self", ".", "except_cnt", "+=", "1", "\n", "print", "(", "e", ")", "\n", "print", "(", "f\"strategy_attr not valid for strategy: '{self.strategy_attr}'\"", ")", "\n", "", "return", "\n", "\n", "", "if", "ref_obj", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "if", "isinstance", "(", "ref_obj", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "ret_obj", "=", "ref_obj", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "ret_obj", "=", "torch", ".", "tensor", "(", "ref_obj", ")", "\n", "", "self", ".", "_loss", ".", "update", "(", "ret_obj", ",", "\n", "patterns", "=", "len", "(", "strategy", ".", "mb_y", ")", ",", "task_label", "=", "task_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.minibatch_logging.StrategyAttributeTrackerPlugin.__str__": [[134, 136], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"CURRENT_MB_{self.metric_label}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.gem_standard.GEMStandardPlugin.__init__": [[37, 54], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "int"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "patterns_per_experience", ":", "int", ",", "memory_strength", ":", "float", ")", ":", "\n", "        ", "\"\"\"\n        :param patterns_per_experience: number of patterns per experience in the\n            memory.\n        :param memory_strength: offset to add to the projection direction\n            in order to favour backward transfer (gamma in original paper).\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "patterns_per_experience", "=", "int", "(", "patterns_per_experience", ")", "\n", "self", ".", "memory_strength", "=", "memory_strength", "\n", "\n", "self", ".", "memory_x", ",", "self", ".", "memory_y", ",", "self", ".", "memory_tid", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "\n", "self", ".", "G", "=", "None", "\n", "self", ".", "gradnorm_stab", "=", "None", "# Tracked by default (only limited additional operations)", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.gem_standard.GEMStandardPlugin.before_training_iteration": [[55, 90], ["strategy.model.train", "range", "torch.stack", "torch.tensor().mean", "strategy.model.train", "strategy.optimizer.zero_grad", "gem_standard.GEMStandardPlugin.memory_x[].to", "gem_standard.GEMStandardPlugin.memory_y[].to", "avalanche.models.avalanche_forward", "strategy._criterion", "strategy._criterion.backward", "G.append", "src.utils.get_grad_normL2", "G_norms.append", "torch.cat", "torch.tensor", "p.grad.flatten", "torch.zeros", "strategy.model.parameters", "p.numel"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_grad_normL2"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute gradient constraints on previous memory samples from all\n        experiences.\n        \"\"\"", "\n", "\n", "if", "strategy", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "            ", "G", "=", "[", "]", "\n", "G_norms", "=", "[", "]", "\n", "strategy", ".", "model", ".", "train", "(", ")", "\n", "for", "t", "in", "range", "(", "strategy", ".", "clock", ".", "train_exp_counter", ")", ":", "\n", "                ", "strategy", ".", "model", ".", "train", "(", ")", "\n", "strategy", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "xref", "=", "self", ".", "memory_x", "[", "t", "]", ".", "to", "(", "strategy", ".", "device", ")", "\n", "yref", "=", "self", ".", "memory_y", "[", "t", "]", ".", "to", "(", "strategy", ".", "device", ")", "\n", "out", "=", "avalanche_forward", "(", "strategy", ".", "model", ",", "xref", ",", "\n", "self", ".", "memory_tid", "[", "t", "]", ")", "\n", "loss", "=", "strategy", ".", "_criterion", "(", "out", ",", "yref", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "G", ".", "append", "(", "torch", ".", "cat", "(", "[", "p", ".", "grad", ".", "flatten", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "torch", ".", "zeros", "(", "p", ".", "numel", "(", ")", ",", "\n", "device", "=", "strategy", ".", "device", ")", "\n", "for", "p", "in", "strategy", ".", "model", ".", "parameters", "(", ")", "]", ",", "\n", "dim", "=", "0", ")", ")", "\n", "\n", "# TRACK GRADNORM", "\n", "g_norm", "=", "get_grad_normL2", "(", "strategy", ".", "model", ")", "\n", "G_norms", ".", "append", "(", "g_norm", ")", "\n", "\n", "", "self", ".", "G", "=", "torch", ".", "stack", "(", "G", ")", "# (experiences, parameters)", "\n", "\n", "# AVG over L2-norms of grads in memory", "\n", "self", ".", "avg_gradnorm_G", "=", "torch", ".", "tensor", "(", "G_norms", ")", ".", "mean", "(", ")", "\n", "strategy", ".", "avg_gradnorm_G", "=", "self", ".", "avg_gradnorm_G", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.gem_standard.GEMStandardPlugin.after_backward": [[91, 126], ["torch.no_grad", "float", "torch.cat", "gem_standard.GEMStandardPlugin.solve_quadprog().to", "strategy.model.parameters", "torch.norm().item", "p.numel", "gem_standard.GEMStandardPlugin.numel", "gem_standard.GEMStandardPlugin.solve_quadprog", "p.grad.copy_", "torch.norm", "p.grad.flatten", "torch.zeros", "strategy.model.parameters", "torch.mv", "g_tilde[].view", "p.numel", "p.size"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.solve_quadprog"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "after_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Project gradient based on reference gradients\n        \"\"\"", "\n", "\n", "if", "strategy", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "            ", "g", "=", "torch", ".", "cat", "(", "[", "p", ".", "grad", ".", "flatten", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "torch", ".", "zeros", "(", "p", ".", "numel", "(", ")", ",", "device", "=", "strategy", ".", "device", ")", "\n", "for", "p", "in", "strategy", ".", "model", ".", "parameters", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "to_project", "=", "(", "torch", ".", "mv", "(", "self", ".", "G", ",", "g", ")", "<", "0", ")", ".", "any", "(", ")", "\n", "", "else", ":", "\n", "            ", "to_project", "=", "False", "\n", "\n", "", "self", ".", "gradnorm_stab", "=", "0", "\n", "if", "to_project", ":", "\n", "            ", "g_tilde", "=", "self", ".", "solve_quadprog", "(", "g", ")", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "num_pars", "=", "0", "# reshape v_star into the parameter matrices", "\n", "for", "p", "in", "strategy", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "curr_pars", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p", ".", "grad", ".", "copy_", "(", "\n", "g_tilde", "[", "num_pars", ":", "num_pars", "+", "curr_pars", "]", ".", "view", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "", "num_pars", "+=", "curr_pars", "\n", "\n", "", "assert", "num_pars", "==", "g_tilde", ".", "numel", "(", ")", ",", "\"Error in projecting gradient\"", "\n", "\n", "# RECORD STABILITY GRAD", "\n", "g_stab", "=", "g_tilde", "-", "g", "\n", "self", ".", "gradnorm_stab", "=", "torch", ".", "norm", "(", "g_stab", ")", ".", "item", "(", ")", "\n", "\n", "# Update strategy element for tracking", "\n", "", "strategy", ".", "gradnorm_stab", "=", "float", "(", "self", ".", "gradnorm_stab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.gem_standard.GEMStandardPlugin.after_training_exp": [[127, 134], ["gem_standard.GEMStandardPlugin.update_memory"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.update_memory"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Save a copy of the model after each experience\n        \"\"\"", "\n", "self", ".", "update_memory", "(", "strategy", ".", "experience", ".", "dataset", ",", "\n", "strategy", ".", "clock", ".", "train_exp_counter", ",", "\n", "strategy", ".", "train_mb_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.gem_standard.GEMStandardPlugin.update_memory": [[135, 170], ["torch.no_grad", "torch.utils.data.DataLoader", "x.size", "x.size", "x.clone", "y.clone", "tid.clone", "torch.cat", "torch.cat", "torch.cat", "x[].clone", "y[].clone", "tid[].clone", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_memory", "(", "self", ",", "dataset", ",", "t", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Update replay memory with patterns from current experience.\n        \"\"\"", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ")", "\n", "tot", "=", "0", "\n", "for", "mbatch", "in", "dataloader", ":", "\n", "            ", "x", ",", "y", ",", "tid", "=", "mbatch", "[", "0", "]", ",", "mbatch", "[", "1", "]", ",", "mbatch", "[", "-", "1", "]", "\n", "if", "tot", "+", "x", ".", "size", "(", "0", ")", "<=", "self", ".", "patterns_per_experience", ":", "\n", "                ", "if", "t", "not", "in", "self", ".", "memory_x", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "x", ".", "clone", "(", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "y", ".", "clone", "(", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "tid", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_x", "[", "t", "]", ",", "x", ")", ",", "dim", "=", "0", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_y", "[", "t", "]", ",", "y", ")", ",", "dim", "=", "0", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_tid", "[", "t", "]", ",", "tid", ")", ",", "\n", "dim", "=", "0", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "diff", "=", "self", ".", "patterns_per_experience", "-", "tot", "\n", "if", "t", "not", "in", "self", ".", "memory_x", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "x", "[", ":", "diff", "]", ".", "clone", "(", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "y", "[", ":", "diff", "]", ".", "clone", "(", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "tid", "[", ":", "diff", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_x", "[", "t", "]", ",", "x", "[", ":", "diff", "]", ")", ",", "\n", "dim", "=", "0", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_y", "[", "t", "]", ",", "y", "[", ":", "diff", "]", ")", ",", "\n", "dim", "=", "0", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_tid", "[", "t", "]", ",", "\n", "tid", "[", ":", "diff", "]", ")", ",", "dim", "=", "0", ")", "\n", "", "break", "\n", "", "tot", "+=", "x", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.gem_standard.GEMStandardPlugin.solve_quadprog": [[171, 191], ["gem_standard.GEMStandardPlugin.G.cpu().double().numpy", "g.cpu().contiguous().view().double().numpy", "numpy.dot", "numpy.eye", "torch.from_numpy().float", "gem_standard.GEMStandardPlugin.transpose", "numpy.dot", "numpy.zeros", "quadprog.solve_qp", "numpy.dot", "gem_standard.GEMStandardPlugin.G.cpu().double", "g.cpu().contiguous().view().double", "numpy.eye", "torch.from_numpy", "numpy.dot.transpose", "gem_standard.GEMStandardPlugin.G.cpu", "g.cpu().contiguous().view", "g.cpu().contiguous", "g.cpu"], "methods", ["None"], ["", "", "def", "solve_quadprog", "(", "self", ",", "g", ")", ":", "\n", "        ", "\"\"\"\n        Solve quadratic programming with current gradient g and\n        gradients matrix on previous tasks G.\n        Taken from original code:\n        https://github.com/facebookresearch/GradientEpisodicMemory/blob/master/model/gem.py\n        \"\"\"", "\n", "\n", "memories_np", "=", "self", ".", "G", ".", "cpu", "(", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "gradient_np", "=", "g", ".", "cpu", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "t", "=", "memories_np", ".", "shape", "[", "0", "]", "\n", "P", "=", "np", ".", "dot", "(", "memories_np", ",", "memories_np", ".", "transpose", "(", ")", ")", "\n", "P", "=", "0.5", "*", "(", "P", "+", "P", ".", "transpose", "(", ")", ")", "+", "np", ".", "eye", "(", "t", ")", "*", "1e-3", "\n", "q", "=", "np", ".", "dot", "(", "memories_np", ",", "gradient_np", ")", "*", "-", "1", "\n", "G", "=", "np", ".", "eye", "(", "t", ")", "\n", "h", "=", "np", ".", "zeros", "(", "t", ")", "+", "self", ".", "memory_strength", "\n", "v", "=", "quadprog", ".", "solve_qp", "(", "P", ",", "q", ",", "G", ",", "h", ")", "[", "0", "]", "# This is v_star", "\n", "g_tilde", "=", "np", ".", "dot", "(", "v", ",", "memories_np", ")", "+", "gradient_np", "# This is g_tilde: G^T . v_star + original grad", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "g_tilde", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.gem_standard.GEMStandard.__init__": [[200, 240], ["gem_standard.GEMStandardPlugin", "avalanche.training.strategies.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "optimizer", ",", "criterion", ",", "\n", "patterns_per_exp", ":", "int", ",", "memory_strength", ":", "float", "=", "0.5", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "record_stability_gradnorm", ":", "bool", "=", "False", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param patterns_per_exp: number of patterns per experience in the memory\n        :param memory_strength: offset to add to the projection direction\n            in order to favour backward transfer (gamma in original paper).\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that\n            `eval` is called every `eval_every` epochs and at the end of the\n            learning experience.\n        \"\"\"", "\n", "\n", "gem", "=", "GEMStandardPlugin", "(", "patterns_per_exp", ",", "memory_strength", ",", "record_stability_gradnorm", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "gem", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "gem", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERPlugin.__init__": [[35, 59], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "avalanche.training.storage_policy.ClassBalancedBuffer", "print", "print", "pprint.pprint.pprint"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "n_total_memories", ",", "num_tasks", ")", ":", "\n", "        ", "\"\"\"\n        Standard samples the same batch-size of new samples.\n\n        :param n_total_memories: The maximal number of input samples to store in total.\n        :param num_tasks:        The number of tasks being seen in the scenario.\n        :param mode:             'ER'=regular replay, 'ERaverse'=Replay with Ridge Aversion.\n        :param init_epochs:      Number of epochs for the first experience/task.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Memory", "\n", "self", ".", "n_total_memories", "=", "n_total_memories", "# Used dynamically", "\n", "self", ".", "num_tasks", "=", "num_tasks", "\n", "\n", "# a Dict<task_id, Dataset>", "\n", "self", ".", "storage_policy", "=", "ClassBalancedBuffer", "(", "# Samples to store in memory", "\n", "max_size", "=", "self", ".", "n_total_memories", ",", "\n", "adaptive_size", "=", "True", ",", "\n", ")", "\n", "\n", "print", "(", "f\"[METHOD CONFIG] n_total_mems={self.n_total_memories} \"", ")", "\n", "print", "(", "f\"[METHOD CONFIG] SUMMARY: \"", ",", "end", "=", "''", ")", "\n", "pprint", "(", "self", ".", "__dict__", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERPlugin.before_forward": [[60, 76], ["replay.ERPlugin.load_buffer_batch", "torch.cat", "torch.cat", "torch.cat", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERPlugin.load_buffer_batch"], ["", "def", "before_forward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Add samples from rehearsal memory to current batch and\n        calculate perturbation to be applied in next forward.\"\"\"", "\n", "# Sample memory batch", "\n", "x_s", ",", "y_s", ",", "t_s", "=", "None", ",", "None", ",", "None", "\n", "if", "self", ".", "n_total_memories", ">", "0", "and", "len", "(", "self", ".", "storage_policy", ".", "buffer", ")", ">", "0", ":", "# Only sample if there are stored", "\n", "            ", "x_s", ",", "y_s", ",", "t_s", "=", "self", ".", "load_buffer_batch", "(", "self", ".", "storage_policy", ",", "strategy", ",", "nb", "=", "strategy", ".", "train_mb_size", ")", "\n", "\n", "# Append to current new-data batch", "\n", "", "if", "x_s", "is", "not", "None", ":", "# Add", "\n", "            ", "assert", "y_s", "is", "not", "None", "\n", "assert", "t_s", "is", "not", "None", "\n", "# Assemble minibatch", "\n", "strategy", ".", "mbatch", "[", "0", "]", "=", "torch", ".", "cat", "(", "[", "strategy", ".", "mbatch", "[", "0", "]", ",", "x_s", "]", ")", "\n", "strategy", ".", "mbatch", "[", "1", "]", "=", "torch", ".", "cat", "(", "[", "strategy", ".", "mbatch", "[", "1", "]", ",", "y_s", "]", ")", "\n", "strategy", ".", "mbatch", "[", "-", "1", "]", "=", "torch", ".", "cat", "(", "[", "strategy", ".", "mbatch", "[", "-", "1", "]", ",", "t_s", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERPlugin.after_training_exp": [[77, 80], ["replay.ERPlugin.storage_policy.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Update memories.\"\"\"", "\n", "self", ".", "storage_policy", ".", "update", "(", "strategy", ",", "**", "kwargs", ")", "# Storage policy: Store the new exemplars in this experience", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERPlugin.load_buffer_batch": [[81, 101], ["replay.ERPlugin.retrieve_random_buffer_batch", "torch.utils.data.DataLoader", "sample[].to", "len", "sample[].to", "sample[].to", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERPlugin.retrieve_random_buffer_batch"], ["", "@", "staticmethod", "\n", "def", "load_buffer_batch", "(", "storage_policy", ",", "strategy", ",", "nb", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Wrapper to retrieve a batch of exemplars from the rehearsal memory\n        :param nb: Number of memories to return\n        :return: input-space tensor, label tensor\n        \"\"\"", "\n", "ret_x", ",", "ret_y", ",", "ret_t", "=", "None", ",", "None", ",", "None", "\n", "# Equal amount as batch: Last batch can contain fewer!", "\n", "n_exemplars", "=", "strategy", ".", "train_mb_size", "if", "nb", "is", "None", "else", "nb", "\n", "new_dset", "=", "ERPlugin", ".", "retrieve_random_buffer_batch", "(", "storage_policy", ",", "n_exemplars", ")", "# Dataset object", "\n", "\n", "# Load the actual data", "\n", "for", "sample", "in", "DataLoader", "(", "new_dset", ",", "batch_size", "=", "len", "(", "new_dset", ")", ",", "pin_memory", "=", "True", ",", "shuffle", "=", "False", ")", ":", "\n", "            ", "x_s", ",", "y_s", "=", "sample", "[", "0", "]", ".", "to", "(", "strategy", ".", "device", ")", ",", "sample", "[", "1", "]", ".", "to", "(", "strategy", ".", "device", ")", "\n", "t_s", "=", "sample", "[", "-", "1", "]", ".", "to", "(", "strategy", ".", "device", ")", "# Task label (for multi-head)", "\n", "ret_x", "=", "x_s", "if", "ret_x", "is", "None", "else", "torch", ".", "cat", "(", "[", "ret_x", ",", "x_s", "]", ")", "\n", "ret_y", "=", "y_s", "if", "ret_y", "is", "None", "else", "torch", ".", "cat", "(", "[", "ret_y", ",", "y_s", "]", ")", "\n", "ret_t", "=", "y_s", "if", "ret_t", "is", "None", "else", "torch", ".", "cat", "(", "[", "ret_t", ",", "t_s", "]", ")", "\n", "", "return", "ret_x", ",", "ret_y", ",", "ret_t", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERPlugin.retrieve_random_buffer_batch": [[102, 157], ["storage_policy.buffer_groups.items", "copy.deepcopy", "sample_cnt.items", "torch.utils.data.ConcatDataset", "len", "list", "len", "tasks.append", "random.randrange", "range", "len", "len", "copy.deepcopy.remove", "cnt_idxs.unsqueeze().expand", "sample_idxs.view.view.view", "torch.utils.data.Subset", "subsets.append", "storage_policy.buffer_group", "torch.randperm", "storage_policy.buffer_group", "sample_idxs.view.view.tolist", "len", "cnt_idxs.unsqueeze", "storage_policy.buffer_group"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.buffer_group", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.buffer_group", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.buffer_group"], ["", "@", "staticmethod", "\n", "def", "retrieve_random_buffer_batch", "(", "storage_policy", ",", "n_samples", ")", ":", "\n", "        ", "\"\"\"\n        Retrieve a batch of exemplars from the rehearsal memory.\n        First sample indices for the available tasks at random, then actually extract from rehearsal memory.\n        There is no resampling of exemplars.\n\n        :param n_samples: Number of memories to return\n        :return: input-space tensor, label tensor\n        \"\"\"", "\n", "assert", "n_samples", ">", "0", ",", "\"Need positive nb of samples to retrieve!\"", "\n", "\n", "# Determine how many mem-samples available", "\n", "q_total_cnt", "=", "0", "# Total samples", "\n", "free_q", "=", "{", "}", "# idxs of which ones are free in mem queue", "\n", "tasks", "=", "[", "]", "\n", "for", "t", ",", "ex_buffer", "in", "storage_policy", ".", "buffer_groups", ".", "items", "(", ")", ":", "\n", "            ", "mem_cnt", "=", "len", "(", "ex_buffer", ".", "buffer", ")", "# Mem cnt", "\n", "free_q", "[", "t", "]", "=", "list", "(", "range", "(", "0", ",", "mem_cnt", ")", ")", "# Free samples", "\n", "q_total_cnt", "+=", "len", "(", "free_q", "[", "t", "]", ")", "# Total free samples", "\n", "tasks", ".", "append", "(", "t", ")", "\n", "\n", "# Randomly sample how many samples to idx per class", "\n", "", "free_tasks", "=", "copy", ".", "deepcopy", "(", "tasks", ")", "\n", "tot_sample_cnt", "=", "0", "\n", "sample_cnt", "=", "{", "c", ":", "0", "for", "c", "in", "tasks", "}", "# How many sampled already", "\n", "max_samples", "=", "n_samples", "if", "q_total_cnt", ">", "n_samples", "else", "q_total_cnt", "# How many to sample (equally divided)", "\n", "while", "tot_sample_cnt", "<", "max_samples", ":", "\n", "            ", "t_idx", "=", "random", ".", "randrange", "(", "len", "(", "free_tasks", ")", ")", "\n", "t", "=", "free_tasks", "[", "t_idx", "]", "# Sample a task", "\n", "\n", "if", "sample_cnt", "[", "t", "]", ">=", "len", "(", "storage_policy", ".", "buffer_group", "(", "t", ")", ")", ":", "# No more memories to sample", "\n", "                ", "free_tasks", ".", "remove", "(", "t", ")", "\n", "continue", "\n", "", "sample_cnt", "[", "t", "]", "+=", "1", "\n", "tot_sample_cnt", "+=", "1", "\n", "\n", "# Actually sample", "\n", "", "s_cnt", "=", "0", "\n", "subsets", "=", "[", "]", "\n", "for", "t", ",", "t_cnt", "in", "sample_cnt", ".", "items", "(", ")", ":", "\n", "            ", "if", "t_cnt", ">", "0", ":", "\n", "# Set of idxs", "\n", "                ", "cnt_idxs", "=", "torch", ".", "randperm", "(", "len", "(", "storage_policy", ".", "buffer_group", "(", "t", ")", ")", ")", "[", ":", "t_cnt", "]", "\n", "sample_idxs", "=", "cnt_idxs", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "1", ")", "\n", "sample_idxs", "=", "sample_idxs", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Actual subset", "\n", "s", "=", "Subset", "(", "storage_policy", ".", "buffer_group", "(", "t", ")", ",", "sample_idxs", ".", "tolist", "(", ")", ")", "\n", "subsets", ".", "append", "(", "s", ")", "\n", "s_cnt", "+=", "t_cnt", "\n", "", "", "assert", "s_cnt", "==", "tot_sample_cnt", "==", "max_samples", "\n", "new_dset", "=", "ConcatDataset", "(", "subsets", ")", "\n", "\n", "return", "new_dset", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERStrategy.__init__": [[162, 205], ["torch.nn.CrossEntropyLoss", "replay.ERPlugin", "isinstance", "avalanche.training.strategies.BaseStrategy.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "n_total_memories", ",", "\n", "num_tasks", ",", "\n", "model", ",", "optimizer", ",", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", ",", "\n", "record_stability_gradnorm", ":", "bool", "=", "False", ",", "\n", "Lw_new", "=", "0.5", ",", "# Weighing of the new loss w.r.t. old loss", "\n", "new_data_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "criterion", ".", "reduction", "=", "'none'", "# Overwrite", "\n", "\n", "# Checks", "\n", "assert", "criterion", ".", "reduction", "==", "'none'", ",", "\"Must have per-sample losses available for ER.\"", "\n", "assert", "0", "<=", "Lw_new", "<=", "1", "\n", "\n", "self", ".", "Lw_new", "=", "Lw_new", "\n", "self", ".", "record_stability_gradnorm", "=", "record_stability_gradnorm", "\n", "\n", "# Store/retrieve samples", "\n", "plug", "=", "ERPlugin", "(", "\n", "n_total_memories", "=", "n_total_memories", ",", "\n", "num_tasks", "=", "num_tasks", ",", "\n", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "plug", "]", "\n", "", "else", ":", "\n", "            ", "plugins", "=", "[", "plug", "]", "+", "plugins", "\n", "\n", "", "if", "isinstance", "(", "criterion", ",", "StrategyPlugin", ")", ":", "\n", "            ", "plugins", "+=", "[", "criterion", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", "=", "criterion", ",", "\n", "train_mb_size", "=", "new_data_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n", "# State vars", "\n", "self", ".", "loss_reg", "=", "None", "\n", "self", ".", "loss_new", "=", "None", "\n", "self", ".", "gradnorm_stab", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERStrategy.training_epoch": [[206, 253], ["replay.ERStrategy._unpack_minibatch", "replay.ERStrategy._before_training_iteration", "replay.ERStrategy.optimizer.zero_grad", "replay.ERStrategy._before_forward", "replay.ERStrategy.forward", "replay.ERStrategy._after_forward", "replay.ERStrategy.criterion", "replay.ERStrategy._before_backward", "replay.ERStrategy.loss.backward", "replay.ERStrategy._after_backward", "replay.ERStrategy._before_update", "replay.ERStrategy.optimizer.step", "replay.ERStrategy._after_update", "replay.ERStrategy._after_training_iteration", "replay.ERStrategy.loss_batch[].mean", "replay.ERStrategy.loss_batch[].mean", "replay.ERStrategy.get_stability_gradnorm"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._unpack_minibatch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_backward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_backward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin.get_stability_gradnorm"], ["", "def", "training_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "for", "self", ".", "mbatch", "in", "self", ".", "dataloader", ":", "\n", "            ", "if", "self", ".", "_stop_training", ":", "\n", "                ", "break", "\n", "\n", "", "self", ".", "_unpack_minibatch", "(", ")", "\n", "nb_new_samples", "=", "self", ".", "mb_x", ".", "shape", "[", "0", "]", "\n", "self", ".", "_before_training_iteration", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "loss", "=", "0", "\n", "\n", "# Forward", "\n", "self", ".", "_before_forward", "(", "**", "kwargs", ")", "# Loads memory samples", "\n", "self", ".", "mb_output", "=", "self", ".", "forward", "(", ")", "\n", "self", ".", "_after_forward", "(", "**", "kwargs", ")", "\n", "\n", "# Loss & Backward", "\n", "self", ".", "loss_batch", "=", "self", ".", "criterion", "(", ")", "# HERE UPDATED: NO PLUS, BUT NO-REDUCTION OPTION", "\n", "\n", "# Disentangle losses", "\n", "nb_samples", "=", "self", ".", "loss_batch", ".", "shape", "[", "0", "]", "\n", "\n", "# New loss", "\n", "mb_with_replay", "=", "False", "\n", "self", ".", "loss_new", "=", "self", ".", "Lw_new", "*", "self", ".", "loss_batch", "[", ":", "nb_new_samples", "]", ".", "mean", "(", ")", "\n", "self", ".", "loss", "=", "self", ".", "loss_new", "\n", "\n", "# Mem loss", "\n", "if", "nb_samples", ">", "nb_new_samples", ":", "\n", "                ", "mb_with_replay", "=", "True", "\n", "self", ".", "loss_reg", "=", "(", "1", "-", "self", ".", "Lw_new", ")", "*", "self", ".", "loss_batch", "[", "nb_new_samples", ":", "]", ".", "mean", "(", ")", "\n", "if", "self", ".", "record_stability_gradnorm", ":", "\n", "                    ", "self", ".", "get_stability_gradnorm", "(", "self", ".", "loss_reg", ")", "\n", "", "self", ".", "loss", "=", "self", ".", "loss_new", "+", "self", ".", "loss_reg", "\n", "\n", "", "self", ".", "_before_backward", "(", "**", "kwargs", ")", "\n", "self", ".", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_after_backward", "(", "**", "kwargs", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "_before_update", "(", "**", "kwargs", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "_after_update", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_after_training_iteration", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.replay.ERStrategy.get_stability_gradnorm": [[254, 267], ["src.eval.continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "replay.ERStrategy.model.eval", "loss_stab.backward", "src.utils.get_grad_normL2", "src.eval.continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_", "replay.ERStrategy.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_grad_normL2", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_"], ["", "", "def", "get_stability_gradnorm", "(", "self", ",", "loss_stab", ")", ":", "\n", "        ", "\"\"\" Given the partial stability loss, return the gradient norm for this loss only. \"\"\"", "\n", "_prev_state", ",", "_prev_training_modes", "=", "ContinualEvaluationPhasePlugin", ".", "get_strategy_state", "(", "self", ")", "\n", "\n", "# Set eval mode", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "loss_stab", ".", "backward", "(", "retain_graph", "=", "True", ")", "# (Might have to reuse intermediate results, use retain_graph)", "\n", "self", ".", "gradnorm_stab", "=", "get_grad_normL2", "(", "self", ".", "model", ")", "# Tracking", "\n", "\n", "# Restore training mode(s)", "\n", "ContinualEvaluationPhasePlugin", ".", "restore_strategy_", "(", "self", ",", "_prev_state", ",", "_prev_training_modes", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "# Zero grad to ensure no interference", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin.__init__": [[42, 61], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "set"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "alpha", "=", "1", ",", "temperature", "=", "2", ")", ":", "\n", "        ", "\"\"\"\n        :param alpha: distillation hyperparameter. It can be either a float\n                number or a list containing alpha for each experience.\n        :param temperature: softmax temperature for distillation\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "prev_model", "=", "None", "\n", "\n", "self", ".", "prev_classes", "=", "{", "'0'", ":", "set", "(", ")", "}", "\n", "\"\"\" In Avalanche, targets of different experiences are not ordered. \n        As a result, some units may be allocated even though their \n        corresponding class has never been seen by the model.\n        Knowledge distillation uses only units corresponding to old classes. \n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin._distillation_loss": [[62, 73], ["list", "torch.nn.functional.kl_div", "torch.log_softmax", "torch.softmax"], "methods", ["None"], ["", "def", "_distillation_loss", "(", "self", ",", "out", ",", "prev_out", ",", "active_units", ")", ":", "\n", "        ", "\"\"\"\n        Compute distillation loss between output of the current model\n        and output of the previous (saved) model.\n        \"\"\"", "\n", "# we compute the loss only on the previously active units.", "\n", "au", "=", "list", "(", "active_units", ")", "\n", "log_p", "=", "torch", ".", "log_softmax", "(", "out", "/", "self", ".", "temperature", ",", "dim", "=", "1", ")", "[", ":", ",", "au", "]", "\n", "q", "=", "torch", ".", "softmax", "(", "prev_out", "/", "self", ".", "temperature", ",", "dim", "=", "1", ")", "[", ":", ",", "au", "]", "\n", "res", "=", "torch", ".", "nn", ".", "functional", ".", "kl_div", "(", "log_p", ",", "q", ",", "reduction", "=", "'batchmean'", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin.penalty": [[74, 102], ["avalanche.models.utils.avalanche_forward.keys", "torch.no_grad", "isinstance", "avalanche.models.utils.avalanche_forward", "avalanche.models.utils.avalanche_forward", "lwf_standard.LwFStandardPlugin._distillation_loss", "lwf_standard.LwFStandardPlugin.prev_model"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lwf.LwFPlugin._distillation_loss"], ["", "def", "penalty", "(", "self", ",", "out", ",", "x", ",", "alpha", ",", "curr_model", ")", ":", "\n", "        ", "\"\"\"\n        Compute weighted distillation loss.\n        \"\"\"", "\n", "\n", "if", "self", ".", "prev_model", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "self", ".", "prev_model", ",", "MultiTaskModule", ")", ":", "\n", "# output from previous output heads.", "\n", "                    ", "y_prev", "=", "avalanche_forward", "(", "self", ".", "prev_model", ",", "x", ",", "None", ")", "\n", "# in a multitask scenario we need to compute the output", "\n", "# from all the heads, so we need to call forward again.", "\n", "y_curr", "=", "avalanche_forward", "(", "curr_model", ",", "x", ",", "None", ")", "\n", "", "else", ":", "# no task labels", "\n", "                    ", "y_prev", "=", "{", "'0'", ":", "self", ".", "prev_model", "(", "x", ")", "}", "\n", "y_curr", "=", "{", "'0'", ":", "out", "}", "\n", "\n", "", "", "dist_loss", "=", "0", "\n", "for", "task_id", "in", "y_prev", ".", "keys", "(", ")", ":", "\n", "# compute kd only for previous heads.", "\n", "                ", "if", "task_id", "in", "self", ".", "prev_classes", ":", "\n", "                    ", "yp", "=", "y_prev", "[", "task_id", "]", "\n", "yc", "=", "y_curr", "[", "task_id", "]", "\n", "au", "=", "self", ".", "prev_classes", "[", "task_id", "]", "\n", "dist_loss", "+=", "self", ".", "_distillation_loss", "(", "yc", ",", "yp", ",", "au", ")", "\n", "", "", "return", "alpha", "*", "dist_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin.before_backward": [[103, 123], ["lwf_standard.LwFStandardPlugin.get_stability_gradnorm", "float", "lwf_standard.LwFStandardPlugin.penalty", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin.get_stability_gradnorm", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.penalty"], ["", "", "def", "before_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Add distillation loss\n        \"\"\"", "\n", "if", "strategy", ".", "clock", ".", "train_exp_iterations", "==", "0", ":", "\n", "# First iteration = same model = zero loss (Otherwise noise in log/exp calculations)", "\n", "            ", "penalty", "=", "0", "\n", "", "else", ":", "\n", "            ", "alpha", "=", "self", ".", "alpha", "[", "strategy", ".", "clock", ".", "train_exp_counter", "]", "if", "isinstance", "(", "self", ".", "alpha", ",", "(", "list", ",", "tuple", ")", ")", "else", "self", ".", "alpha", "\n", "penalty", "=", "self", ".", "penalty", "(", "strategy", ".", "mb_output", ",", "strategy", ".", "mb_x", ",", "alpha", ",", "\n", "strategy", ".", "model", ")", "\n", "\n", "# track gradient of penalty", "\n", "", "self", ".", "get_stability_gradnorm", "(", "strategy", ",", "penalty", ")", "\n", "\n", "# Tracking", "\n", "strategy", ".", "loss_new", "=", "strategy", ".", "loss", "\n", "strategy", ".", "loss_reg", "=", "float", "(", "penalty", ")", "\n", "strategy", ".", "loss", "+=", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin.get_stability_gradnorm": [[124, 139], ["src.eval.continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "strategy.model.eval", "loss_stab.backward", "src.utils.get_grad_normL2", "src.eval.continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_", "strategy.optimizer.zero_grad", "torch.is_tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.get_strategy_state", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.src.utils.get_grad_normL2", "home.repos.pwc.inspect_result.mattdl_continualevaluation.eval.continual_eval.ContinualEvaluationPhasePlugin.restore_strategy_"], ["", "def", "get_stability_gradnorm", "(", "self", ",", "strategy", ",", "loss_stab", ")", ":", "\n", "        ", "if", "not", "torch", ".", "is_tensor", "(", "loss_stab", ")", ":", "\n", "            ", "strategy", ".", "gradnorm_stab", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "return", "\n", "", "_prev_state", ",", "_prev_training_modes", "=", "ContinualEvaluationPhasePlugin", ".", "get_strategy_state", "(", "strategy", ")", "\n", "\n", "# Set eval mode", "\n", "strategy", ".", "model", ".", "eval", "(", ")", "\n", "\n", "loss_stab", ".", "backward", "(", "retain_graph", "=", "True", ")", "# (Might have to reuse intermediate results, use retain_graph)", "\n", "strategy", ".", "gradnorm_stab", "=", "get_grad_normL2", "(", "strategy", ".", "model", ")", "# Tracking", "\n", "\n", "# Restore training mode(s)", "\n", "ContinualEvaluationPhasePlugin", ".", "restore_strategy_", "(", "strategy", ",", "_prev_state", ",", "_prev_training_modes", ")", "\n", "strategy", ".", "optimizer", ".", "zero_grad", "(", ")", "# Zero grad to ensure no interference", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandardPlugin.after_training_exp": [[140, 156], ["copy.deepcopy", "set", "lwf_standard.LwFStandardPlugin.prev_classes[].union", "str", "str"], "methods", ["None"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Save a copy of the model after each experience and\n        update self.prev_classes to include the newly learned classes.\n        \"\"\"", "\n", "self", ".", "prev_model", "=", "copy", ".", "deepcopy", "(", "strategy", ".", "model", ")", "\n", "task_ids", "=", "strategy", ".", "experience", ".", "dataset", ".", "task_set", "\n", "for", "task_id", "in", "task_ids", ":", "\n", "            ", "task_data", "=", "strategy", ".", "experience", ".", "dataset", ".", "task_set", "[", "task_id", "]", "\n", "pc", "=", "set", "(", "task_data", ".", "targets", ")", "\n", "\n", "if", "task_id", "not", "in", "self", ".", "prev_classes", ":", "\n", "                ", "self", ".", "prev_classes", "[", "str", "(", "task_id", ")", "]", "=", "pc", "\n", "", "else", ":", "\n", "                ", "self", ".", "prev_classes", "[", "str", "(", "task_id", ")", "]", "=", "self", ".", "prev_classes", "[", "task_id", "]", ".", "union", "(", "pc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.lwf_standard.LwFStandard.__init__": [[165, 204], ["lwf_standard.LwFStandardPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "alpha", ":", "Union", "[", "float", ",", "Sequence", "[", "float", "]", "]", ",", "temperature", ":", "float", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param alpha: distillation hyperparameter. It can be either a float\n                number or a list containing alpha for each experience.\n        :param temperature: softmax temperature for distillation\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that\n            `eval` is called every `eval_every` epochs and at the end of the\n            learning experience.\n        \"\"\"", "\n", "\n", "lwf", "=", "LwFStandardPlugin", "(", "alpha", ",", "temperature", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "lwf", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "lwf", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.ewc_standard.EWCStandardPlugin.__init__": [[31, 62], ["avalanche.training.plugins.StrategyPlugin.__init__", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "iw_strength", ":", "float", ",", "mode", "=", "'online'", ",", "keep_importance_data", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param iw_strength: hyperparameter to weigh the penalty inside the total\n               loss. The larger the lambda, the larger the regularization.\n        :param mode: `separate` to keep a separate penalty for each previous\n               experience.\n               `online` to keep a single penalty summed with a decay factor\n               over all previous tasks.\n        :param keep_importance_data: if True, keep in memory both parameter\n                values and importances for all previous task, for all modes.\n                If False, keep only last parameter values and importances.\n                If mode is `separate`, the value of `keep_importance_data` is\n                set to be True.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "mode", "==", "'separate'", "or", "mode", "==", "'online'", ",", "'Mode must be separate or online.'", "\n", "\n", "self", ".", "iw_strength", "=", "iw_strength", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "if", "self", ".", "mode", "==", "'separate'", ":", "\n", "            ", "self", ".", "keep_importance_data", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "keep_importance_data", "=", "keep_importance_data", "\n", "\n", "# Running", "\n", "", "self", ".", "saved_params", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "importances", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "iw_cnt", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.ewc_standard.EWCStandardPlugin.before_backward": [[63, 92], ["torch.tensor().float().to", "range", "torch.tensor().float", "zip", "zip", "ValueError", "strategy.model.named_parameters", "strategy.model.named_parameters", "torch.tensor"], "methods", ["None"], ["", "def", "before_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute Importance-weight penalty and add it to the loss.\n        \"\"\"", "\n", "exp_counter", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "if", "exp_counter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "penalty", "=", "torch", ".", "tensor", "(", "0", ")", ".", "float", "(", ")", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'separate'", ":", "\n", "            ", "for", "experience", "in", "range", "(", "exp_counter", ")", ":", "\n", "                ", "for", "(", "_", ",", "cur_param", ")", ",", "(", "_", ",", "saved_param", ")", ",", "(", "_", ",", "imp", ")", "in", "zip", "(", "\n", "strategy", ".", "model", ".", "named_parameters", "(", ")", ",", "\n", "self", ".", "saved_params", "[", "experience", "]", ",", "\n", "self", ".", "importances", "[", "experience", "]", ")", ":", "\n", "                    ", "penalty", "+=", "(", "imp", "*", "(", "cur_param", "-", "saved_param", ")", ".", "pow", "(", "2", ")", ")", ".", "sum", "(", ")", "\n", "", "", "", "elif", "self", ".", "mode", "==", "'online'", ":", "\n", "            ", "prev_exp", "=", "exp_counter", "-", "1", "\n", "for", "(", "_", ",", "cur_param", ")", ",", "(", "_", ",", "saved_param", ")", ",", "(", "_", ",", "imp", ")", "in", "zip", "(", "\n", "strategy", ".", "model", ".", "named_parameters", "(", ")", ",", "\n", "self", ".", "saved_params", "[", "prev_exp", "]", ",", "\n", "self", ".", "importances", "[", "prev_exp", "]", ")", ":", "\n", "                ", "penalty", "+=", "(", "imp", "*", "(", "cur_param", "-", "saved_param", ")", ".", "pow", "(", "2", ")", ")", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Wrong EWC mode.'", ")", "\n", "\n", "", "strategy", ".", "loss_reg", "=", "self", ".", "iw_strength", "*", "penalty", "# Already weigh", "\n", "strategy", ".", "loss", "+=", "strategy", ".", "loss_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.ewc_standard.EWCStandardPlugin.after_training_exp": [[93, 114], ["ewc_standard.EWCStandardPlugin.compute_importances", "ewc_standard.EWCStandardPlugin.update_importances", "avalanche.training.utils.copy_params_dict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.compute_importances", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.update_importances", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.copy_params_dict"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute importances of parameters after each experience.\n        \"\"\"", "\n", "exp_counter", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "importances", "=", "self", ".", "compute_importances", "(", "strategy", ".", "model", ",", "\n", "strategy", ".", "_criterion", ",", "\n", "strategy", ".", "optimizer", ",", "\n", "strategy", ".", "experience", ".", "dataset", ",", "\n", "strategy", ".", "device", ",", "\n", "strategy", ".", "train_mb_size", ")", "\n", "self", ".", "update_importances", "(", "importances", ",", "exp_counter", ",", "self", ".", "iw_cnt", ",", "1", ")", "\n", "self", ".", "iw_cnt", "+=", "1", "\n", "\n", "# Save model params", "\n", "self", ".", "saved_params", "[", "exp_counter", "]", "=", "copy_params_dict", "(", "strategy", ".", "model", ")", "\n", "# clear previous parameter values", "\n", "if", "exp_counter", ">", "0", "and", "(", "not", "self", ".", "keep_importance_data", ")", ":", "\n", "            ", "del", "self", ".", "saved_params", "[", "exp_counter", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.ewc_standard.EWCStandardPlugin.compute_importances": [[115, 160], ["model.eval", "avalanche.training.utils.zerolike_params_dict", "torch.utils.data.DataLoader", "enumerate", "model.modules", "optimizer.zero_grad", "avalanche.models.utils.avalanche_forward", "criterion", "criterion.backward", "zip", "float", "isinstance", "x.to", "y.to", "model.named_parameters", "len", "warnings.warn", "module.train", "param.grad.data.clone().pow", "param.grad.data.clone"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.zerolike_params_dict", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train"], ["", "", "def", "compute_importances", "(", "self", ",", "model", ",", "criterion", ",", "optimizer", ",", "\n", "dataset", ",", "device", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Compute EWC importance matrix for each parameter\n        \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Set RNN-like modules on GPU to training mode to avoid CUDA error", "\n", "if", "device", "==", "'cuda'", ":", "\n", "            ", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "RNNBase", ")", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "'RNN-like modules do not support '", "\n", "'backward calls while in `eval` mode on CUDA '", "\n", "'devices. Setting all `RNNBase` modules to '", "\n", "'`train` mode. May produce inconsistent '", "\n", "'output if such modules have `dropout` > 0.'", "\n", ")", "\n", "module", ".", "train", "(", ")", "\n", "\n", "# list of list", "\n", "", "", "", "importances", "=", "zerolike_params_dict", "(", "model", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# get only input, target and task_id from the batch", "\n", "            ", "x", ",", "y", ",", "task_labels", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", "]", ",", "batch", "[", "-", "1", "]", "\n", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "out", "=", "avalanche_forward", "(", "model", ",", "x", ",", "task_labels", ")", "\n", "loss", "=", "criterion", "(", "out", ",", "y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "(", "k1", ",", "param", ")", ",", "(", "k2", ",", "imp", ")", "in", "zip", "(", "model", ".", "named_parameters", "(", ")", ",", "\n", "importances", ")", ":", "\n", "                ", "assert", "(", "k1", "==", "k2", ")", "\n", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "imp", "+=", "param", ".", "grad", ".", "data", ".", "clone", "(", ")", ".", "pow", "(", "2", ")", "\n", "\n", "# average over mini batches", "\n", "", "", "", "for", "_", ",", "imp", "in", "importances", ":", "\n", "            ", "imp", "/=", "float", "(", "len", "(", "dataloader", ")", ")", "\n", "\n", "", "return", "importances", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.ewc_standard.EWCStandardPlugin.update_importances": [[161, 186], ["torch.no_grad", "zip", "ValueError", "ewc_standard.EWCStandardPlugin.importances[].append"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_importances", "(", "self", ",", "importances", ",", "t", ",", "w_old", ",", "w_new", ")", ":", "\n", "        ", "\"\"\"\n        Update importance for each parameter based on the currently computed\n        importances.\n        \"\"\"", "\n", "\n", "if", "self", ".", "mode", "==", "'separate'", "or", "t", "==", "0", ":", "\n", "            ", "self", ".", "importances", "[", "t", "]", "=", "importances", "\n", "", "elif", "self", ".", "mode", "==", "'online'", ":", "\n", "            ", "for", "(", "k1", ",", "old_imp", ")", ",", "(", "k2", ",", "curr_imp", ")", "in", "zip", "(", "self", ".", "importances", "[", "t", "-", "1", "]", ",", "importances", ")", ":", "\n", "                ", "assert", "k1", "==", "k2", ",", "'Error in importance computation.'", "\n", "# Unnormalize prev one and add new weighted", "\n", "self", ".", "importances", "[", "t", "]", ".", "append", "(", "\n", "(", "k1", ",", "\n", "(", "w_old", "*", "old_imp", "+", "curr_imp", "*", "w_new", ")", "/", "(", "w_old", "+", "w_new", ")", "\n", ")", ")", "\n", "\n", "# clear previous parameter importances", "\n", "", "if", "t", ">", "0", "and", "(", "not", "self", ".", "keep_importance_data", ")", ":", "\n", "                ", "del", "self", ".", "importances", "[", "t", "-", "1", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Wrong IW update mode.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.methods.ewc_standard.EWCStandard.__init__": [[195, 242], ["ewc_standard.EWCStandardPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "ewc_lambda", ":", "float", ",", "mode", ":", "str", "=", "'separate'", ",", "\n", "keep_importance_data", ":", "bool", "=", "False", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param ewc_lambda: hyperparameter to weigh the penalty inside the total\n               loss. The larger the lambda, the larger the regularization.\n        :param mode: `separate` to keep a separate penalty for each previous\n               experience. `onlinesum` to keep a single penalty summed over all\n               previous tasks. `onlineweightedsum` to keep a single penalty\n               summed with a decay factor over all previous tasks.\n        :param keep_importance_data: if True, keep in memory both parameter\n                values and importances for all previous task, for all modes.\n                If False, keep only last parameter values and importances.\n                If mode is `separate`, the value of `keep_importance_data` is\n                set to be True.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that\n            `eval` is called every `eval_every` epochs and at the end of the\n            learning experience.\n        \"\"\"", "\n", "ewc", "=", "EWCStandardPlugin", "(", "ewc_lambda", ",", "mode", ",", "keep_importance_data", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "ewc", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "ewc", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.__init__": [[65, 67], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_training": [[68, 71], ["None"], "methods", ["None"], ["", "def", "before_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `train` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_training_exp": [[72, 75], ["None"], "methods", ["None"], ["", "def", "before_training_exp", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `train_exp` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_train_dataset_adaptation": [[76, 80], ["None"], "methods", ["None"], ["", "def", "before_train_dataset_adaptation", "(", "self", ",", "*", "args", ",", "\n", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `train_dataset_adapatation` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_train_dataset_adaptation": [[81, 84], ["None"], "methods", ["None"], ["", "def", "after_train_dataset_adaptation", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `train_dataset_adapatation` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_training_epoch": [[85, 88], ["None"], "methods", ["None"], ["", "def", "before_training_epoch", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `train_epoch` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_training_iteration": [[89, 93], ["None"], "methods", ["None"], ["", "def", "before_training_iteration", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before the start of a training iteration by the\n        `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_forward": [[94, 97], ["None"], "methods", ["None"], ["", "def", "before_forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `model.forward()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_forward": [[98, 101], ["None"], "methods", ["None"], ["", "def", "after_forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `model.forward()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_backward": [[102, 105], ["None"], "methods", ["None"], ["", "def", "before_backward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `criterion.backward()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_backward": [[106, 109], ["None"], "methods", ["None"], ["", "def", "after_backward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `criterion.backward()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_training_iteration": [[110, 114], ["None"], "methods", ["None"], ["", "def", "after_training_iteration", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after the end of a training iteration by the\n        `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_update": [[115, 118], ["None"], "methods", ["None"], ["", "def", "before_update", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `optimizer.update()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_update": [[119, 122], ["None"], "methods", ["None"], ["", "def", "after_update", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `optimizer.update()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_training_epoch": [[123, 126], ["None"], "methods", ["None"], ["", "def", "after_training_epoch", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `train_epoch` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_training_exp": [[127, 130], ["None"], "methods", ["None"], ["", "def", "after_training_exp", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `train_exp` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_training": [[131, 134], ["None"], "methods", ["None"], ["", "def", "after_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `train` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_eval": [[135, 138], ["None"], "methods", ["None"], ["", "def", "before_eval", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `eval` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_eval_dataset_adaptation": [[139, 142], ["None"], "methods", ["None"], ["", "def", "before_eval_dataset_adaptation", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `eval_dataset_adaptation` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_eval_dataset_adaptation": [[143, 146], ["None"], "methods", ["None"], ["", "def", "after_eval_dataset_adaptation", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `eval_dataset_adaptation` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_eval_exp": [[147, 150], ["None"], "methods", ["None"], ["", "def", "before_eval_exp", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `eval_exp` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_eval_exp": [[151, 154], ["None"], "methods", ["None"], ["", "def", "after_eval_exp", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `eval_exp` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_eval": [[155, 158], ["None"], "methods", ["None"], ["", "def", "after_eval", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `eval` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_eval_iteration": [[159, 163], ["None"], "methods", ["None"], ["", "def", "before_eval_iteration", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before the start of a training iteration by the\n        `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.before_eval_forward": [[164, 167], ["None"], "methods", ["None"], ["", "def", "before_eval_forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called before `model.forward()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_eval_forward": [[168, 171], ["None"], "methods", ["None"], ["", "def", "after_eval_forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after `model.forward()` by the `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.core.StrategyCallbacks.after_eval_iteration": [[172, 176], ["None"], "methods", ["None"], ["", "def", "after_eval_iteration", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "CallbackResult", ":", "\n", "        ", "\"\"\" Called after the end of an iteration by the\n        `BaseStrategy`. \"\"\"", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.__init__._avdataset_radd": [[13, 20], ["isinstance", "_dataset_add"], "function", ["None"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.avalanche.__init__._avalanche_monkey_patches": [[22, 27], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SubSequence.__init__": [[34, 42], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "targets", ":", "Sequence", "[", "TTargetType", "]", ",", "\n", "*", ",", "\n", "indices", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "None", "]", "=", "None", ",", "\n", "converter", ":", "Optional", "[", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "_targets", "=", "targets", "\n", "self", ".", "_indices", "=", "indices", "\n", "self", ".", "converter", "=", "converter", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SubSequence.__len__": [[43, 47], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_indices", "is", "None", ":", "\n", "            ", "return", "len", "(", "self", ".", "_targets", ")", "\n", "", "return", "len", "(", "self", ".", "_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SubSequence.__getitem__": [[48, 60], ["dataset_utils.SubSequence.converter"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item_idx", ")", "->", "TTargetType", ":", "\n", "        ", "if", "self", ".", "_indices", "is", "not", "None", ":", "\n", "            ", "subset_idx", "=", "self", ".", "_indices", "[", "item_idx", "]", "\n", "", "else", ":", "\n", "            ", "subset_idx", "=", "item_idx", "\n", "\n", "", "element", "=", "self", ".", "_targets", "[", "subset_idx", "]", "\n", "\n", "if", "self", ".", "converter", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "converter", "(", "element", ")", "\n", "\n", "", "return", "element", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SubSequence.__str__": [[61, 65], ["str", "range", "len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'['", "+", "', '", ".", "join", "(", "[", "str", "(", "self", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", "]", ")", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyClassMapping.__init__": [[77, 83], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "targets", ":", "Sequence", "[", "SupportsInt", "]", ",", "\n", "indices", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "None", "]", ",", "\n", "mapping", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "targets", ",", "indices", "=", "indices", ",", "converter", "=", "int", ")", "\n", "self", ".", "_mapping", "=", "mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyClassMapping.__getitem__": [[84, 91], ["super().__getitem__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "item_idx", ")", "->", "int", ":", "\n", "        ", "target_value", "=", "super", "(", ")", ".", "__getitem__", "(", "item_idx", ")", "\n", "\n", "if", "self", ".", "_mapping", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_mapping", "[", "target_value", "]", "\n", "\n", "", "return", "target_value", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyConcatTargets.__init__": [[102, 109], ["sum", "torch.utils.data.ConcatDataset.cumsum", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "targets_list", ":", "Sequence", "[", "Sequence", "[", "TTargetType", "]", "]", ",", "\n", "converter", ":", "Optional", "[", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "_targets_list", "=", "targets_list", "\n", "self", ".", "_targets_lengths", "=", "[", "len", "(", "targets", ")", "for", "targets", "in", "targets_list", "]", "\n", "self", ".", "_overall_length", "=", "sum", "(", "self", ".", "_targets_lengths", ")", "\n", "self", ".", "_targets_cumulative_lengths", "=", "ConcatDataset", ".", "cumsum", "(", "targets_list", ")", "\n", "self", ".", "converter", "=", "converter", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyConcatTargets.__len__": [[110, 112], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_overall_length", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyConcatTargets.__getitem__": [[113, 123], ["dataset_utils.find_list_from_index", "dataset_utils.LazyConcatTargets.converter"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.find_list_from_index"], ["", "def", "__getitem__", "(", "self", ",", "item_idx", ")", "->", "TTargetType", ":", "\n", "        ", "targets_idx", ",", "internal_idx", "=", "find_list_from_index", "(", "\n", "item_idx", ",", "self", ".", "_targets_lengths", ",", "self", ".", "_overall_length", ",", "\n", "self", ".", "_targets_cumulative_lengths", ")", "\n", "\n", "target", "=", "self", ".", "_targets_list", "[", "targets_idx", "]", "[", "internal_idx", "]", "\n", "\n", "if", "self", ".", "converter", "is", "None", ":", "\n", "            ", "return", "target", "\n", "", "return", "self", ".", "converter", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyConcatTargets.__iter__": [[124, 133], ["dataset_utils.LazyConcatTargets.converter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "converter", "is", "None", ":", "\n", "            ", "for", "x", "in", "self", ".", "_targets_list", ":", "\n", "                ", "for", "y", "in", "x", ":", "\n", "                    ", "yield", "y", "\n", "", "", "", "else", ":", "\n", "            ", "for", "x", "in", "self", ".", "_targets_list", ":", "\n", "                ", "for", "y", "in", "x", ":", "\n", "                    ", "yield", "self", ".", "converter", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyConcatTargets.__str__": [[134, 138], ["str", "range", "len"], "methods", ["None"], ["", "", "", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'['", "+", "', '", ".", "join", "(", "[", "str", "(", "self", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", "]", ")", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazyConcatIntTargets.__init__": [[151, 153], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "targets_list", ":", "Sequence", "[", "Sequence", "[", "SupportsInt", "]", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "targets_list", ",", "converter", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.ConstantSequence.__init__": [[159, 162], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "constant_value", ":", "int", ",", "size", ":", "int", ")", ":", "\n", "        ", "self", ".", "_constant_value", "=", "constant_value", "\n", "self", ".", "_size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.ConstantSequence.__len__": [[163, 165], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.ConstantSequence.__getitem__": [[166, 171], ["len", "IndexError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item_idx", ")", "->", "int", ":", "\n", "        ", "if", "item_idx", ">=", "len", "(", "self", ")", ":", "\n", "            ", "raise", "IndexError", "(", ")", "\n", "\n", "", "return", "self", ".", "_constant_value", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.ConstantSequence.__str__": [[172, 176], ["str", "range", "len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'['", "+", "', '", ".", "join", "(", "[", "str", "(", "self", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", "]", ")", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SubsetWithTargets.__init__": [[183, 191], ["super().__init__", "dataset_utils.SubSequence", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ":", "IDatasetWithTargets", "[", "T_co", ",", "TTargetType", "]", ",", "\n", "indices", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "None", "]", ")", ":", "\n", "        ", "if", "indices", "is", "None", ":", "\n", "            ", "indices", "=", "range", "(", "len", "(", "dataset", ")", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "indices", ")", "\n", "self", ".", "targets", ":", "Sequence", "[", "TTargetType", "]", "=", "SubSequence", "(", "dataset", ".", "targets", ",", "indices", "=", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SubsetWithTargets.__getitem__": [[192, 194], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "self", ".", "indices", "[", "idx", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SubsetWithTargets.__len__": [[195, 197], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.ClassificationSubset.__init__": [[206, 214], ["super().__init__", "dataset_utils.LazyClassMapping"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ":", "ISupportedClassificationDataset", "[", "T_co", "]", ",", "\n", "indices", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "None", "]", ",", "\n", "class_mapping", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "indices", ")", "\n", "self", ".", "class_mapping", "=", "class_mapping", "\n", "self", ".", "targets", "=", "LazyClassMapping", "(", "dataset", ".", "targets", ",", "indices", ",", "\n", "mapping", "=", "class_mapping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.ClassificationSubset.__getitem__": [[215, 224], ["super().__getitem__", "dataset_utils.make_tuple"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__getitem__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.make_tuple"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "result", "=", "super", "(", ")", ".", "__getitem__", "(", "idx", ")", "\n", "\n", "if", "self", ".", "class_mapping", "is", "not", "None", ":", "\n", "            ", "return", "make_tuple", "(", "\n", "(", "result", "[", "0", "]", ",", "self", ".", "class_mapping", "[", "result", "[", "1", "]", "]", ",", "*", "result", "[", "2", ":", "]", ")", ",", "\n", "result", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SequenceDataset.__init__": [[231, 263], ["len", "isinstance", "len", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "*", "sequences", ":", "Sequence", ",", "\n", "targets", ":", "Union", "[", "int", ",", "Sequence", "[", "TTargetType", "]", "]", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``SequenceDataset`` instance.\n\n        Beware that the second sequence, will be used to fill the targets\n        field without running any kind of type conversion.\n\n        :param sequences: A sequence of sequences, Tensors or ndarrays\n            representing the patterns.\n        :param targets: A sequence representing the targets field of the\n            dataset. Can either be 1) a sequence of values containing as many\n            elements as the number of contained patterns, or 2) the index\n            of the sequence to use as the targets field. Defaults to 1, which\n            means that the second sequence (usually containing the \"y\" values)\n            will be used for the targets field.\n        \"\"\"", "\n", "if", "len", "(", "sequences", ")", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'At least one sequence must be passed'", ")", "\n", "\n", "", "common_size", "=", "len", "(", "sequences", "[", "0", "]", ")", "\n", "for", "seq", "in", "sequences", ":", "\n", "            ", "if", "len", "(", "seq", ")", "!=", "common_size", ":", "\n", "                ", "raise", "ValueError", "(", "'Sequences must contain the same '", "\n", "'amount of elements'", ")", "\n", "\n", "", "", "self", ".", "_sequences", "=", "sequences", "\n", "if", "isinstance", "(", "targets", ",", "int", ")", ":", "\n", "            ", "targets", "=", "sequences", "[", "targets", "]", "\n", "\n", "", "self", ".", "targets", ":", "Sequence", "[", "TTargetType", "]", "=", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SequenceDataset.__getitem__": [[264, 266], ["tuple"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "tuple", "(", "seq", "[", "idx", "]", "for", "seq", "in", "self", ".", "_sequences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.SequenceDataset.__len__": [[267, 269], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "_sequences", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazySubsequence.__init__": [[341, 348], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "sequence", ":", "Sequence", "[", "int", "]", ",", "\n", "start_idx", ":", "int", ",", "\n", "end_idx", ":", "int", ")", ":", "\n", "        ", "self", ".", "_sequence", "=", "sequence", "\n", "self", ".", "_start_idx", "=", "start_idx", "\n", "self", ".", "_end_idx", "=", "end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazySubsequence.__len__": [[349, 351], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_end_idx", "-", "self", ".", "_start_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazySubsequence.__getitem__": [[352, 357], ["len", "IndexError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item_idx", ")", "->", "int", ":", "\n", "        ", "if", "item_idx", ">=", "len", "(", "self", ")", ":", "\n", "            ", "raise", "IndexError", "(", ")", "\n", "\n", "", "return", "self", ".", "_sequence", "[", "self", ".", "_start_idx", "+", "item_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.LazySubsequence.__str__": [[358, 362], ["str", "range", "len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'['", "+", "', '", ".", "join", "(", "[", "str", "(", "self", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", "]", ")", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.TupleTLabel.__new__": [[382, 384], ["tuple.__new__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.TupleTLabel.__new__"], ["def", "__new__", "(", "cls", ",", "*", "data", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", "TupleTLabel", ",", "cls", ")", ".", "__new__", "(", "cls", ",", "*", "data", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.find_list_from_index": [[271, 292], ["bisect.bisect_right", "IndexError", "ValueError", "r.append"], "function", ["None"], ["", "", "def", "find_list_from_index", "(", "pattern_idx", ":", "int", ",", "\n", "list_sizes", ":", "Sequence", "[", "int", "]", ",", "\n", "max_size", ":", "int", ",", "\n", "cumulative_sizes", "=", "None", ")", ":", "\n", "    ", "if", "pattern_idx", ">=", "max_size", ":", "\n", "        ", "raise", "IndexError", "(", ")", "\n", "\n", "", "if", "cumulative_sizes", "is", "None", ":", "\n", "        ", "r", ",", "s", "=", "[", "]", ",", "0", "\n", "for", "list_len", "in", "list_sizes", ":", "\n", "            ", "r", ".", "append", "(", "list_len", "+", "s", ")", "\n", "s", "+=", "list_len", "\n", "", "cumulative_sizes", "=", "r", "\n", "\n", "", "list_idx", "=", "bisect", ".", "bisect_right", "(", "cumulative_sizes", ",", "pattern_idx", ")", "\n", "if", "list_idx", "!=", "0", ":", "\n", "        ", "pattern_idx", "=", "pattern_idx", "-", "cumulative_sizes", "[", "list_idx", "-", "1", "]", "\n", "\n", "", "if", "pattern_idx", ">=", "list_sizes", "[", "list_idx", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Index out of bounds, wrong max_size parameter'", ")", "\n", "", "return", "list_idx", ",", "pattern_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.manage_advanced_indexing": [[294, 334], ["isinstance", "collate_fn", "range", "isinstance", "single_element_getter", "elements.append", "len", "int", "idx.indices", "hasattr", "len", "int", "getattr"], "function", ["None"], ["", "def", "manage_advanced_indexing", "(", "idx", ",", "single_element_getter", ",", "max_length", ",", "\n", "collate_fn", ")", ":", "\n", "    ", "\"\"\"\n    Utility function used to manage the advanced indexing and slicing.\n\n    If more than a pattern is selected, the X and Y values will be merged\n    in two separate torch Tensor objects using the stack operation.\n\n    :param idx: Either an in, a slice object or a list (including ndarrays and\n        torch Tensors) of indexes.\n    :param single_element_getter: A callable used to obtain a single element\n        given its int index.\n    :param max_length: The maximum sequence length.\n    :param collate_fn: The function to use to create a batch of data from\n        single elements.\n    :return: A tuple consisting of two tensors containing the X and Y values\n        of the patterns addressed by the idx parameter.\n    \"\"\"", "\n", "indexes_iterator", ":", "Iterable", "[", "int", "]", "\n", "\n", "# Makes dataset sliceable", "\n", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "        ", "indexes_iterator", "=", "range", "(", "*", "idx", ".", "indices", "(", "max_length", ")", ")", "\n", "", "elif", "isinstance", "(", "idx", ",", "int", ")", ":", "\n", "        ", "indexes_iterator", "=", "[", "idx", "]", "\n", "", "elif", "hasattr", "(", "idx", ",", "'shape'", ")", "and", "len", "(", "getattr", "(", "idx", ",", "'shape'", ")", ")", "==", "0", ":", "\n", "# Manages 0-d ndarray / Tensor", "\n", "        ", "indexes_iterator", "=", "[", "int", "(", "idx", ")", "]", "\n", "", "else", ":", "\n", "        ", "indexes_iterator", "=", "idx", "\n", "\n", "", "elements", "=", "[", "]", "\n", "for", "single_idx", "in", "indexes_iterator", ":", "\n", "        ", "single_element", "=", "single_element_getter", "(", "int", "(", "single_idx", ")", ")", "\n", "elements", ".", "append", "(", "single_element", ")", "\n", "\n", "", "if", "len", "(", "elements", ")", "==", "1", ":", "\n", "        ", "return", "elements", "[", "0", "]", "\n", "\n", "", "return", "collate_fn", "(", "elements", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.optimize_sequence": [[364, 372], ["isinstance", "list", "isinstance", "len"], "function", ["None"], ["", "", "def", "optimize_sequence", "(", "sequence", ":", "Sequence", "[", "TTargetType", "]", ")", "->", "Sequence", "[", "TTargetType", "]", ":", "\n", "    ", "if", "len", "(", "sequence", ")", "==", "0", "or", "isinstance", "(", "sequence", ",", "ConstantSequence", ")", ":", "\n", "        ", "return", "sequence", "\n", "\n", "", "if", "isinstance", "(", "sequence", ",", "list", ")", ":", "\n", "        ", "return", "sequence", "\n", "\n", "", "return", "list", "(", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.make_tuple": [[386, 391], ["isinstance", "dataset_utils.TupleTLabel"], "function", ["None"], ["", "", "def", "make_tuple", "(", "new_tuple", ":", "Iterable", "[", "T_co", "]", ",", "prev_tuple", ":", "tuple", ")", ":", "\n", "    ", "if", "isinstance", "(", "prev_tuple", ",", "TupleTLabel", ")", ":", "\n", "        ", "return", "TupleTLabel", "(", "new_tuple", ")", "\n", "\n", "", "return", "new_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_definitions.IDataset.__getitem__": [[30, 32], ["None"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", "->", "T_co", ":", "\n", "        ", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_definitions.IDataset.__len__": [[33, 35], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_definitions.ClassificationDataset.__init__": [[114, 120], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "targets", "=", "[", "]", "\n", "\"\"\"\n        A sequence of ints describing the label of each pattern contained in the\n        dataset.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.TaskBalancedDataLoader.__init__": [[46, 90], ["data_loader.GroupBalancedDataLoader", "task_datasets.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ":", "AvalancheDataset", ",", "\n", "oversample_small_tasks", ":", "bool", "=", "False", ",", "\n", "collate_mbatches", "=", "_default_collate_mbatches_fn", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Task-balanced data loader for Avalanche's datasets.\n\n        The iterator returns a mini-batch balanced across each task, which\n        makes it useful when training in multi-task scenarios whenever data is\n        highly unbalanced.\n\n        If `oversample_small_tasks == True` smaller tasks are\n        oversampled to match the largest task. Otherwise, once the data for a\n        specific task is terminated, that task will not be present in the\n        subsequent mini-batches.\n\n        :param data: an instance of `AvalancheDataset`.\n        :param oversample_small_tasks: whether smaller tasks should be\n            oversampled to match the largest one.\n        :param collate_mbatches: function that given a sequence of mini-batches\n            (one for each task) combines them into a single mini-batch. Used to\n            combine the mini-batches obtained separately from each task.\n        :param kwargs: data loader arguments used to instantiate the loader for\n            each task separately. See pytorch :class:`DataLoader`.\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "dataloaders", ":", "Dict", "[", "int", ",", "DataLoader", "]", "=", "{", "}", "\n", "self", ".", "oversample_small_tasks", "=", "oversample_small_tasks", "\n", "self", ".", "collate_mbatches", "=", "collate_mbatches", "\n", "\n", "# split data by task.", "\n", "task_datasets", "=", "[", "]", "\n", "for", "task_label", "in", "self", ".", "data", ".", "task_set", ":", "\n", "            ", "tdata", "=", "self", ".", "data", ".", "task_set", "[", "task_label", "]", "\n", "task_datasets", ".", "append", "(", "tdata", ")", "\n", "\n", "# the iteration logic is implemented by GroupBalancedDataLoader.", "\n", "# we use kwargs to pass the arguments to avoid passing the same", "\n", "# arguments multiple times.", "\n", "", "if", "'data'", "in", "kwargs", ":", "\n", "            ", "del", "kwargs", "[", "'data'", "]", "\n", "# needed if they are passed as positional arguments", "\n", "", "kwargs", "[", "'oversample_small_groups'", "]", "=", "oversample_small_tasks", "\n", "kwargs", "[", "'collate_mbatches'", "]", "=", "collate_mbatches", "\n", "self", ".", "_dl", "=", "GroupBalancedDataLoader", "(", "datasets", "=", "task_datasets", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.TaskBalancedDataLoader.__iter__": [[91, 94], ["data_loader.TaskBalancedDataLoader._dl.__iter__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyStreamClassesInExps.__iter__"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "el", "in", "self", ".", "_dl", ".", "__iter__", "(", ")", ":", "\n", "            ", "yield", "el", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.TaskBalancedDataLoader.__len__": [[95, 97], ["data_loader.TaskBalancedDataLoader._dl.__len__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__len__"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dl", ".", "__len__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.GroupBalancedDataLoader.__init__": [[102, 133], ["max", "data_loader.GroupBalancedDataLoader.dataloaders.append", "torch.utils.data.dataloader.DataLoader", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "datasets", ":", "Sequence", "[", "AvalancheDataset", "]", ",", "\n", "oversample_small_groups", ":", "bool", "=", "False", ",", "\n", "collate_mbatches", "=", "_default_collate_mbatches_fn", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Data loader that balances data from multiple datasets.\n\n        Mini-batches emitted by this dataloader are created by collating\n        together mini-batches from each group. It may be used to balance data\n        among classes, experiences, tasks, and so on.\n\n        If `oversample_small_groups == True` smaller groups are oversampled to\n        match the largest group. Otherwise, once data from a group is\n        completely iterated, the group will be skipped.\n\n        :param datasets: an instance of `AvalancheDataset`.\n        :param oversample_small_groups: whether smaller groups should be\n            oversampled to match the largest one.\n        :param collate_mbatches: function that given a sequence of mini-batches\n            (one for each task) combines them into a single mini-batch. Used to\n            combine the mini-batches obtained separately from each task.\n        :param kwargs: data loader arguments used to instantiate the loader for\n            each group separately. See pytorch :class:`DataLoader`.\n        \"\"\"", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "dataloaders", "=", "[", "]", "\n", "self", ".", "oversample_small_groups", "=", "oversample_small_groups", "\n", "self", ".", "collate_mbatches", "=", "collate_mbatches", "\n", "\n", "for", "data", "in", "self", ".", "datasets", ":", "\n", "            ", "self", ".", "dataloaders", ".", "append", "(", "DataLoader", "(", "data", ",", "**", "kwargs", ")", ")", "\n", "", "self", ".", "max_len", "=", "max", "(", "[", "len", "(", "d", ")", "for", "d", "in", "self", ".", "dataloaders", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.GroupBalancedDataLoader.__iter__": [[134, 167], ["max", "range", "iter_dataloaders.append", "enumerate", "iter", "len", "mb_curr.append", "data_loader.GroupBalancedDataLoader.collate_mbatches", "next", "iter_dataloaders.remove", "iter", "next"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "iter_dataloaders", "=", "[", "]", "\n", "for", "dl", "in", "self", ".", "dataloaders", ":", "\n", "            ", "iter_dataloaders", ".", "append", "(", "iter", "(", "dl", ")", ")", "\n", "\n", "", "max_num_mbatches", "=", "max", "(", "[", "len", "(", "d", ")", "for", "d", "in", "iter_dataloaders", "]", ")", "\n", "for", "it", "in", "range", "(", "max_num_mbatches", ")", ":", "\n", "            ", "mb_curr", "=", "[", "]", "\n", "is_removed_dataloader", "=", "False", "\n", "# copy() is necessary because we may remove keys from the", "\n", "# dictionary. This would break the generator.", "\n", "for", "tid", ",", "t_loader", "in", "enumerate", "(", "iter_dataloaders", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "batch", "=", "next", "(", "t_loader", ")", "\n", "", "except", "StopIteration", ":", "\n", "# StopIteration is thrown if dataset ends.", "\n", "                    ", "if", "self", ".", "oversample_small_groups", ":", "\n", "# reinitialize data loader", "\n", "                        ", "iter_dataloaders", "[", "tid", "]", "=", "iter", "(", "self", ".", "dataloaders", "[", "tid", "]", ")", "\n", "batch", "=", "next", "(", "iter_dataloaders", "[", "tid", "]", ")", "\n", "", "else", ":", "\n", "# We iteratated over all the data from this group", "\n", "# and we don't need the iterator anymore.", "\n", "                        ", "iter_dataloaders", "[", "tid", "]", "=", "None", "\n", "is_removed_dataloader", "=", "True", "\n", "continue", "\n", "", "", "mb_curr", ".", "append", "(", "batch", ")", "\n", "", "yield", "self", ".", "collate_mbatches", "(", "mb_curr", ")", "\n", "\n", "# clear empty data-loaders", "\n", "if", "is_removed_dataloader", ":", "\n", "                ", "while", "None", "in", "iter_dataloaders", ":", "\n", "                    ", "iter_dataloaders", ".", "remove", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.GroupBalancedDataLoader.__len__": [[168, 170], ["None"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.GroupBalancedInfiniteDataLoader.__init__": [[176, 206], ["torch.utils.data.RandomSampler", "torch.utils.data.dataloader.DataLoader", "data_loader.GroupBalancedInfiniteDataLoader.dataloaders.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "datasets", ":", "Sequence", "[", "AvalancheDataset", "]", ",", "\n", "collate_mbatches", "=", "_default_collate_mbatches_fn", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Data loader that balances data from multiple datasets emitting an\n        infinite stream.\n\n        Mini-batches emitted by this dataloader are created by collating\n        together mini-batches from each group. It may be used to balance data\n        among classes, experiences, tasks, and so on.\n\n        :param datasets: an instance of `AvalancheDataset`.\n        :param collate_mbatches: function that given a sequence of mini-batches\n            (one for each task) combines them into a single mini-batch. Used to\n            combine the mini-batches obtained separately from each task.\n        :param kwargs: data loader arguments used to instantiate the loader for\n            each group separately. See pytorch :class:`DataLoader`.\n        \"\"\"", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "dataloaders", "=", "[", "]", "\n", "self", ".", "collate_mbatches", "=", "collate_mbatches", "\n", "\n", "for", "data", "in", "self", ".", "datasets", ":", "\n", "            ", "infinite_sampler", "=", "RandomSampler", "(", "data", ",", "replacement", "=", "True", ",", "\n", "num_samples", "=", "10", "**", "10", ")", "\n", "dl", "=", "DataLoader", "(", "\n", "data", ",", "\n", "sampler", "=", "infinite_sampler", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "dataloaders", ".", "append", "(", "dl", ")", "\n", "", "self", ".", "max_len", "=", "10", "**", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.GroupBalancedInfiniteDataLoader.__iter__": [[207, 218], ["iter_dataloaders.append", "enumerate", "iter", "next", "mb_curr.append", "data_loader.GroupBalancedInfiniteDataLoader.collate_mbatches"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "iter_dataloaders", "=", "[", "]", "\n", "for", "dl", "in", "self", ".", "dataloaders", ":", "\n", "            ", "iter_dataloaders", ".", "append", "(", "iter", "(", "dl", ")", ")", "\n", "\n", "", "while", "True", ":", "\n", "            ", "mb_curr", "=", "[", "]", "\n", "for", "tid", ",", "t_loader", "in", "enumerate", "(", "iter_dataloaders", ")", ":", "\n", "                ", "batch", "=", "next", "(", "t_loader", ")", "\n", "mb_curr", ".", "append", "(", "batch", ")", "\n", "", "yield", "self", ".", "collate_mbatches", "(", "mb_curr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.GroupBalancedInfiniteDataLoader.__len__": [[219, 221], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader.__init__": [[226, 300], ["max", "len", "data_loader.ReplayDataLoader._create_dataloaders", "data_loader.ReplayDataLoader._create_dataloaders", "data_loader.ReplayDataLoader._create_dataloaders", "data_loader.ReplayDataLoader._create_dataloaders", "len", "len", "len", "itertools.chain", "data_loader.ReplayDataLoader.loader_data.values", "data_loader.ReplayDataLoader.loader_memory.values"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._create_dataloaders", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._create_dataloaders", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._create_dataloaders", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._create_dataloaders"], ["def", "__init__", "(", "self", ",", "data", ":", "AvalancheDataset", ",", "memory", ":", "AvalancheDataset", "=", "None", ",", "\n", "oversample_small_tasks", ":", "bool", "=", "False", ",", "\n", "collate_mbatches", "=", "_default_collate_mbatches_fn", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "force_data_batch_size", ":", "int", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Custom data loader for rehearsal strategies.\n\n        The iterates in parallel two datasets, the current `data` and the\n        rehearsal `memory`, which are used to create mini-batches by\n        concatenating their data together. Mini-batches from both of them are\n        balanced using the task label (i.e. each mini-batch contains a balanced\n        number of examples from all the tasks in the `data` and `memory`).\n        \n        If `oversample_small_tasks == True` smaller tasks are oversampled to\n        match the largest task.\n\n        :param data: AvalancheDataset.\n        :param memory: AvalancheDataset.\n        :param oversample_small_tasks: whether smaller tasks should be\n            oversampled to match the largest one.\n        :param collate_mbatches: function that given a sequence of mini-batches\n            (one for each task) combines them into a single mini-batch. Used to\n            combine the mini-batches obtained separately from each task.\n        :param batch_size: the size of the batch. It must be greater than or\n            equal to the number of tasks.\n        :param ratio_data_mem: How many of the samples should be from\n        :param kwargs: data loader arguments used to instantiate the loader for\n            each task separately. See pytorch :class:`DataLoader`.\n        \"\"\"", "\n", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "memory", "=", "memory", "\n", "self", ".", "loader_data", ":", "Sequence", "[", "DataLoader", "]", "=", "{", "}", "\n", "self", ".", "loader_memory", ":", "Sequence", "[", "DataLoader", "]", "=", "{", "}", "\n", "self", ".", "oversample_small_tasks", "=", "oversample_small_tasks", "\n", "self", ".", "collate_mbatches", "=", "collate_mbatches", "\n", "\n", "if", "force_data_batch_size", "is", "not", "None", ":", "\n", "            ", "assert", "force_data_batch_size", "<=", "batch_size", ",", "\"Forced batch size of data must be <= entire batch size\"", "\n", "\n", "mem_batch_size", "=", "batch_size", "-", "force_data_batch_size", "\n", "remaining_example", "=", "0", "\n", "mem_keys", "=", "len", "(", "self", ".", "memory", ".", "task_set", ")", "\n", "assert", "mem_batch_size", ">=", "mem_keys", ",", "\"Batch size must be greator or equal \"", "\"to the number of tasks in the memory.\"", "\n", "\n", "self", ".", "loader_data", ",", "_", "=", "self", ".", "_create_dataloaders", "(", "\n", "data", ",", "force_data_batch_size", ",", "\n", "remaining_example", ",", "**", "kwargs", ")", "\n", "self", ".", "loader_memory", ",", "_", "=", "self", ".", "_create_dataloaders", "(", "\n", "memory", ",", "mem_batch_size", ",", "\n", "remaining_example", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "num_keys", "=", "len", "(", "self", ".", "data", ".", "task_set", ")", "+", "len", "(", "self", ".", "memory", ".", "task_set", ")", "\n", "assert", "batch_size", ">=", "num_keys", ",", "\"Batch size must be greator or equal \"", "\"to the number of tasks in the memory \"", "\"and current data.\"", "\n", "\n", "single_group_batch_size", "=", "batch_size", "//", "num_keys", "\n", "remaining_example", "=", "batch_size", "%", "num_keys", "\n", "\n", "self", ".", "loader_data", ",", "remaining_example", "=", "self", ".", "_create_dataloaders", "(", "\n", "data", ",", "single_group_batch_size", ",", "\n", "remaining_example", ",", "**", "kwargs", ")", "\n", "self", ".", "loader_memory", ",", "remaining_example", "=", "self", ".", "_create_dataloaders", "(", "\n", "memory", ",", "single_group_batch_size", ",", "\n", "remaining_example", ",", "**", "kwargs", ")", "\n", "\n", "", "self", ".", "max_len", "=", "max", "(", "[", "len", "(", "d", ")", "for", "d", "in", "chain", "(", "\n", "self", ".", "loader_data", ".", "values", "(", ")", ",", "self", ".", "loader_memory", ".", "values", "(", ")", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader.__iter__": [[302, 329], ["data_loader.ReplayDataLoader.loader_data.keys", "data_loader.ReplayDataLoader.loader_memory.keys", "max", "iter", "iter", "range", "len", "data_loader.ReplayDataLoader._get_mini_batch_from_data_dict", "data_loader.ReplayDataLoader._get_mini_batch_from_data_dict", "itertools.chain", "data_loader.ReplayDataLoader.collate_mbatches", "iter_data_dataloaders.values", "iter_buffer_dataloaders.values"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._get_mini_batch_from_data_dict", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._get_mini_batch_from_data_dict"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "iter_data_dataloaders", "=", "{", "}", "\n", "iter_buffer_dataloaders", "=", "{", "}", "\n", "\n", "for", "t", "in", "self", ".", "loader_data", ".", "keys", "(", ")", ":", "\n", "            ", "iter_data_dataloaders", "[", "t", "]", "=", "iter", "(", "self", ".", "loader_data", "[", "t", "]", ")", "\n", "", "for", "t", "in", "self", ".", "loader_memory", ".", "keys", "(", ")", ":", "\n", "            ", "iter_buffer_dataloaders", "[", "t", "]", "=", "iter", "(", "self", ".", "loader_memory", "[", "t", "]", ")", "\n", "\n", "", "max_len", "=", "max", "(", "[", "len", "(", "d", ")", "for", "d", "in", "chain", "(", "iter_data_dataloaders", ".", "values", "(", ")", ",", "\n", "iter_buffer_dataloaders", ".", "values", "(", ")", ")", "]", ")", "\n", "try", ":", "\n", "            ", "for", "it", "in", "range", "(", "max_len", ")", ":", "\n", "                ", "mb_curr", "=", "[", "]", "\n", "self", ".", "_get_mini_batch_from_data_dict", "(", "\n", "self", ".", "data", ",", "iter_data_dataloaders", ",", "\n", "self", ".", "loader_data", ",", "self", ".", "oversample_small_tasks", ",", "\n", "mb_curr", ")", "\n", "\n", "self", ".", "_get_mini_batch_from_data_dict", "(", "\n", "self", ".", "memory", ",", "iter_buffer_dataloaders", ",", "\n", "self", ".", "loader_memory", ",", "self", ".", "oversample_small_tasks", ",", "\n", "mb_curr", ")", "\n", "\n", "yield", "self", ".", "collate_mbatches", "(", "mb_curr", ")", "\n", "", "", "except", "StopIteration", ":", "\n", "            ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader.__len__": [[330, 332], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._get_mini_batch_from_data_dict": [[333, 353], ["list", "iter_dataloaders.keys", "mb_curr.append", "next", "iter", "next"], "methods", ["None"], ["", "def", "_get_mini_batch_from_data_dict", "(", "self", ",", "data", ",", "iter_dataloaders", ",", "\n", "loaders_dict", ",", "oversample_small_tasks", ",", "\n", "mb_curr", ")", ":", "\n", "# list() is necessary because we may remove keys from the", "\n", "# dictionary. This would break the generator.", "\n", "        ", "for", "t", "in", "list", "(", "iter_dataloaders", ".", "keys", "(", ")", ")", ":", "\n", "            ", "t_loader", "=", "iter_dataloaders", "[", "t", "]", "\n", "try", ":", "\n", "                ", "tbatch", "=", "next", "(", "t_loader", ")", "\n", "", "except", "StopIteration", ":", "\n", "# StopIteration is thrown if dataset ends.", "\n", "# reinitialize data loader", "\n", "                ", "if", "oversample_small_tasks", ":", "\n", "# reinitialize data loader", "\n", "                    ", "iter_dataloaders", "[", "t", "]", "=", "iter", "(", "loaders_dict", "[", "t", "]", ")", "\n", "tbatch", "=", "next", "(", "iter_dataloaders", "[", "t", "]", ")", "\n", "", "else", ":", "\n", "                    ", "del", "iter_dataloaders", "[", "t", "]", "\n", "continue", "\n", "", "", "mb_curr", ".", "append", "(", "tbatch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader.ReplayDataLoader._create_dataloaders": [[354, 366], ["torch.utils.data.dataloader.DataLoader"], "methods", ["None"], ["", "", "def", "_create_dataloaders", "(", "self", ",", "data_dict", ",", "single_exp_batch_size", ",", "\n", "remaining_example", ",", "**", "kwargs", ")", ":", "\n", "        ", "loaders_dict", ":", "Dict", "[", "int", ",", "DataLoader", "]", "=", "{", "}", "\n", "for", "task_id", "in", "data_dict", ".", "task_set", ":", "\n", "            ", "data", "=", "data_dict", ".", "task_set", "[", "task_id", "]", "\n", "current_batch_size", "=", "single_exp_batch_size", "\n", "if", "remaining_example", ">", "0", ":", "\n", "                ", "current_batch_size", "+=", "1", "\n", "remaining_example", "-=", "1", "\n", "", "loaders_dict", "[", "task_id", "]", "=", "DataLoader", "(", "\n", "data", ",", "batch_size", "=", "current_batch_size", ",", "**", "kwargs", ")", "\n", "", "return", "loaders_dict", ",", "remaining_example", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.data_loader._default_collate_mbatches_fn": [[27, 41], ["range", "len", "torch.cat", "batch.append"], "function", ["None"], ["def", "_default_collate_mbatches_fn", "(", "mbatches", ")", ":", "\n", "    ", "\"\"\" Combines multiple mini-batches together.\n\n    Concatenates each tensor in the mini-batches along dimension 0 (usually this\n    is the batch size).\n\n    :param mbatches: sequence of mini-batches.\n    :return: a single mini-batch\n    \"\"\"", "\n", "batch", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "mbatches", "[", "0", "]", ")", ")", ":", "\n", "        ", "t", "=", "torch", ".", "cat", "(", "[", "el", "[", "i", "]", "for", "el", "in", "mbatches", "]", ",", "dim", "=", "0", ")", "\n", "batch", ".", "append", "(", "t", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.__init__": [[94, 306], ["avalanche_dataset.AvalancheDataset._initialize_targets_sequence", "avalanche_dataset.AvalancheDataset._initialize_task_labels_sequence", "avalanche_dataset.AvalancheDataset._initialize_tasks_dict", "avalanche_dataset.AvalancheDataset._initialize_collate_fn", "avalanche_dataset.AvalancheDataset._optimize_targets", "avalanche_dataset.AvalancheDataset._optimize_task_labels", "avalanche_dataset.AvalancheDataset._optimize_task_dict", "avalanche_dataset._TaskSubsetDict", "avalanche_dataset.AvalancheDataset._initialize_groups_dict", "dict", "avalanche_dataset.AvalancheDataset.transform_groups.keys", "avalanche_dataset.AvalancheDataset._set_original_dataset_transform_group", "avalanche_dataset.AvalancheDataset._flatten_dataset", "ValueError", "isinstance", "avalanche_dataset.AvalancheDataset._check_groups_dict_format", "isinstance", "ValueError", "isinstance", "ValueError", "ValueError", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_targets_sequence", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_task_labels_sequence", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._initialize_tasks_dict", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_collate_fn", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._optimize_targets", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._optimize_task_labels", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._optimize_task_dict", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._initialize_groups_dict", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._set_original_dataset_transform_group", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._flatten_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._check_groups_dict_format"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ":", "SupportedDataset", ",", "\n", "*", ",", "\n", "transform", ":", "XTransform", "=", "None", ",", "\n", "target_transform", ":", "YTransform", "=", "None", ",", "\n", "transform_groups", ":", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "\n", "YTransform", "]", "]", "=", "None", ",", "\n", "initial_transform_group", ":", "str", "=", "None", ",", "\n", "task_labels", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "targets", ":", "Sequence", "[", "TTargetType", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ",", "\n", "collate_fn", ":", "Callable", "[", "[", "List", "]", ",", "Any", "]", "=", "None", ",", "\n", "targets_adapter", ":", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``AvalancheDataset`` instance.\n\n        :param dataset: The dataset to decorate. Beware that\n            AvalancheDataset will not overwrite transformations already\n            applied by this dataset.\n        :param transform: A function/transform that takes the X value of a\n            pattern from the original dataset and returns a transformed version.\n        :param target_transform: A function/transform that takes in the target\n            and transforms it.\n        :param transform_groups: A dictionary containing the transform groups.\n            Transform groups are used to quickly switch between training and\n            eval (test) transformations. This becomes useful when in need to\n            test on the training dataset as test transformations usually don't\n            contain random augmentations. ``AvalancheDataset`` natively supports\n            the 'train' and 'eval' groups by calling the ``train()`` and\n            ``eval()`` methods. When using custom groups one can use the\n            ``with_transforms(group_name)`` method instead. Defaults to None,\n            which means that the current transforms will be used to\n            handle both 'train' and 'eval' groups (just like in standard\n            ``torchvision`` datasets).\n        :param initial_transform_group: The name of the initial transform group\n            to be used. Defaults to None, which means that the current group of\n            the input dataset will be used (if an AvalancheDataset). If the\n            input dataset is not an AvalancheDataset, then 'train' will be\n            used.\n        :param task_labels: The task label of each instance. Must be a sequence\n            of ints, one for each instance in the dataset. Alternatively can be\n            a single int value, in which case that value will be used as the\n            task label for all the instances. Defaults to None, which means that\n            the dataset will try to obtain the task labels from the original\n            dataset. If no task labels could be found, a default task label\n            \"0\" will be applied to all instances.\n        :param targets: The label of each pattern. Defaults to None, which\n            means that the targets will be retrieved from the dataset (if\n            possible).\n        :param dataset_type: The type of the dataset. Defaults to None,\n            which means that the type will be inferred from the input dataset.\n            When the `dataset_type` is different than UNDEFINED, a\n            proper value for `collate_fn` and `targets_adapter` will be set.\n            If the `dataset_type` is different than UNDEFINED, then\n            `collate_fn` and `targets_adapter` must not be set.\n        :param collate_fn: The function to use when slicing to merge single\n            patterns. In the future this function may become the function\n            used in the data loading process, too. If None and the\n            `dataset_type` is UNDEFINED, the constructor will check if a\n            `collate_fn` field exists in the dataset. If no such field exists,\n            the default collate function will be used.\n        :param targets_adapter: A function used to convert the values of the\n            targets field. Defaults to None. Note: the adapter will not change\n            the value of the second element returned by `__getitem__`.\n            The adapter is used to adapt the values of the targets field only.\n        \"\"\"", "\n", "if", "transform_groups", "is", "not", "None", "and", "(", "\n", "transform", "is", "not", "None", "or", "target_transform", "is", "not", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'transform_groups can\\'t be used with transform'", "\n", "'and target_transform values'", ")", "\n", "\n", "", "detected_type", "=", "False", "\n", "if", "dataset_type", "is", "None", ":", "\n", "            ", "detected_type", "=", "True", "\n", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "dataset_type", "=", "dataset", ".", "dataset_type", "\n", "", "else", ":", "\n", "                ", "dataset_type", "=", "AvalancheDatasetType", ".", "UNDEFINED", "\n", "\n", "", "", "if", "dataset_type", "!=", "AvalancheDatasetType", ".", "UNDEFINED", "and", "(", "collate_fn", "is", "not", "None", "or", "targets_adapter", "is", "not", "None", ")", ":", "\n", "            ", "if", "detected_type", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'dataset_type {} was inferred from the input dataset. '", "\n", "'This dataset type can\\'t be used '", "\n", "'with custom collate_fn or targets_adapter '", "\n", "'parameters. Only the UNDEFINED type supports '", "\n", "'custom collate_fn or targets_adapter '", "\n", "'parameters'", ".", "format", "(", "dataset_type", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'dataset_type {} can\\'t be used with custom collate_fn '", "\n", "'or targets_adapter. Only the UNDEFINED type supports '", "\n", "'custom collate_fn or targets_adapter '", "\n", "'parameters.'", ".", "format", "(", "dataset_type", ")", ")", "\n", "\n", "", "", "if", "transform_groups", "is", "not", "None", ":", "\n", "            ", "AvalancheDataset", ".", "_check_groups_dict_format", "(", "transform_groups", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "dataset_type", ",", "AvalancheDatasetType", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'dataset_type must be a value of type '", "\n", "'AvalancheDatasetType'", ")", "\n", "\n", "", "self", ".", "_dataset", ":", "SupportedDataset", "=", "dataset", "\n", "\"\"\"\n        The original dataset.\n        \"\"\"", "\n", "\n", "self", ".", "dataset_type", "=", "dataset_type", "\n", "\"\"\"\n        The type of this dataset (UNDEFINED, CLASSIFICATION, ...).\n        \"\"\"", "\n", "\n", "self", ".", "targets", ":", "Sequence", "[", "TTargetType", "]", "=", "self", ".", "_initialize_targets_sequence", "(", "\n", "dataset", ",", "targets", ",", "dataset_type", ",", "targets_adapter", ")", "\n", "\"\"\"\n        A sequence of values describing the label of each pattern contained in\n        the dataset.\n        \"\"\"", "\n", "\n", "self", ".", "targets_task_labels", ":", "Sequence", "[", "int", "]", "=", "self", ".", "_initialize_task_labels_sequence", "(", "dataset", ",", "task_labels", ")", "\n", "\"\"\"\n        A sequence of ints describing the task label of each pattern contained \n        in the dataset.\n        \"\"\"", "\n", "\n", "self", ".", "tasks_pattern_indices", ":", "Dict", "[", "int", ",", "Sequence", "[", "int", "]", "]", "=", "self", ".", "_initialize_tasks_dict", "(", "dataset", ",", "self", ".", "targets_task_labels", ")", "\n", "\"\"\"\n        A dictionary mapping task labels to the indices of the patterns with \n        that task label. If you need to obtain the subset of patterns labeled\n        with a certain task label, consider using the `task_set` field.\n        \"\"\"", "\n", "\n", "self", ".", "collate_fn", "=", "self", ".", "_initialize_collate_fn", "(", "\n", "dataset", ",", "dataset_type", ",", "collate_fn", ")", "\n", "\"\"\"\n        The collate function to use when creating mini-batches from this\n        dataset.\n        \"\"\"", "\n", "\n", "# Compress targets and task labels to save some memory", "\n", "self", ".", "_optimize_targets", "(", ")", "\n", "self", ".", "_optimize_task_labels", "(", ")", "\n", "self", ".", "_optimize_task_dict", "(", ")", "\n", "\n", "self", ".", "task_set", "=", "_TaskSubsetDict", "(", "self", ")", "\n", "\"\"\"\n        A dictionary that can be used to obtain the subset of patterns given\n        a specific task label.\n        \"\"\"", "\n", "\n", "if", "initial_transform_group", "is", "None", ":", "\n", "# Detect from the input dataset. If not an AvalancheDataset then", "\n", "# use 'train' as the initial transform group", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "initial_transform_group", "=", "dataset", ".", "current_transform_group", "\n", "", "else", ":", "\n", "                ", "initial_transform_group", "=", "'train'", "\n", "\n", "", "", "self", ".", "current_transform_group", "=", "initial_transform_group", "\n", "\"\"\"\n        The name of the transform group currently in use.\n        \"\"\"", "\n", "\n", "self", ".", "transform_groups", ":", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "YTransform", "]", "]", "=", "self", ".", "_initialize_groups_dict", "(", "transform_groups", ",", "dataset", ",", "\n", "transform", ",", "target_transform", ")", "\n", "\"\"\"\n        A dictionary containing the transform groups. Transform groups are\n        used to quickly switch between training and test (eval) transformations.\n        This becomes useful when in need to test on the training dataset as test\n        transformations usually don't contain random augmentations.\n\n        AvalancheDataset natively supports switching between the 'train' and\n        'eval' groups by calling the ``train()`` and ``eval()`` methods. When\n        using custom groups one can use the ``with_transforms(group_name)``\n        method instead.\n\n        May be null, which means that the current transforms will be used to\n        handle both 'train' and 'eval' groups.\n        \"\"\"", "\n", "\n", "if", "self", ".", "current_transform_group", "not", "in", "self", ".", "transform_groups", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid transformations group '", "+", "\n", "str", "(", "self", ".", "current_transform_group", ")", ")", "\n", "", "t_group", "=", "self", ".", "transform_groups", "[", "self", ".", "current_transform_group", "]", "\n", "\n", "self", ".", "transform", ":", "XTransform", "=", "t_group", "[", "0", "]", "\n", "\"\"\"\n        A function/transform that takes in an PIL image and returns a \n        transformed version.\n        \"\"\"", "\n", "\n", "self", ".", "target_transform", ":", "YTransform", "=", "t_group", "[", "1", "]", "\n", "\"\"\"\n        A function/transform that takes in the target and transforms it.\n        \"\"\"", "\n", "\n", "self", ".", "_frozen_transforms", ":", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "YTransform", "]", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        A dictionary containing frozen transformations.\n        \"\"\"", "\n", "\n", "for", "group_name", "in", "self", ".", "transform_groups", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_frozen_transforms", "[", "group_name", "]", "=", "(", "None", ",", "None", ")", "\n", "\n", "", "self", ".", "_set_original_dataset_transform_group", "(", "self", ".", "current_transform_group", ")", "\n", "\n", "self", ".", "_flatten_dataset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.__add__": [[307, 309], ["avalanche_dataset.AvalancheConcatDataset"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "other", ":", "Dataset", ")", "->", "'AvalancheDataset'", ":", "\n", "        ", "return", "AvalancheConcatDataset", "(", "[", "self", ",", "other", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.__radd__": [[310, 312], ["avalanche_dataset.AvalancheConcatDataset"], "methods", ["None"], ["", "def", "__radd__", "(", "self", ",", "other", ":", "Dataset", ")", "->", "'AvalancheDataset'", ":", "\n", "        ", "return", "AvalancheConcatDataset", "(", "[", "other", ",", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.__getitem__": [[313, 316], ["dataset_utils.TupleTLabel", "dataset_utils.manage_advanced_indexing", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.manage_advanced_indexing"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", "->", "Union", "[", "T_co", ",", "Sequence", "[", "T_co", "]", "]", ":", "\n", "        ", "return", "TupleTLabel", "(", "manage_advanced_indexing", "(", "\n", "idx", ",", "self", ".", "_get_single_item", ",", "len", "(", "self", ")", ",", "self", ".", "collate_fn", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.__len__": [[317, 319], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.train": [[320, 330], ["avalanche_dataset.AvalancheDataset.with_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset with the transformations of the 'train' group\n        loaded.\n\n        The current dataset will not be affected.\n\n        :return: A new dataset with the training transformations loaded.\n        \"\"\"", "\n", "return", "self", ".", "with_transforms", "(", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.eval": [[331, 345], ["avalanche_dataset.AvalancheDataset.with_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset with the transformations of the 'eval' group\n        loaded.\n\n        Eval transformations usually don't contain augmentation procedures.\n        This function may be useful when in need to test on training data\n        (for instance, in order to run a validation pass).\n\n        The current dataset will not be affected.\n\n        :return: A new dataset with the eval transformations loaded.\n        \"\"\"", "\n", "return", "self", ".", "with_transforms", "(", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms": [[346, 373], ["avalanche_dataset.AvalancheDataset._fork_dataset", "avalanche_dataset.AvalancheDataset.transform_groups.keys", "avalanche_dataset.AvalancheDataset._freeze_dataset_group"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._freeze_dataset_group"], ["", "def", "freeze_transforms", "(", "self", ":", "TAvalancheDataset", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset where the current transformations are frozen.\n\n        Frozen transformations will be permanently glued to the original\n        dataset so that they can't be changed anymore. This is usually done\n        when using transformations to create derived datasets: in this way\n        freezing the transformations will ensure that the user won't be able\n        to inadvertently change them by directly setting the transformations\n        field or by using the other transformations utility methods like\n        ``replace_transforms``. Please note that transformations of all groups\n        will be frozen. If you want to freeze a specific group, please use\n        ``freeze_group_transforms``.\n\n        The current dataset will not be affected.\n\n        :return: A new dataset with the current transformations frozen.\n        \"\"\"", "\n", "\n", "dataset_copy", "=", "self", ".", "_fork_dataset", "(", ")", "\n", "\n", "for", "group_name", "in", "dataset_copy", ".", "transform_groups", ".", "keys", "(", ")", ":", "\n", "            ", "AvalancheDataset", ".", "_freeze_dataset_group", "(", "dataset_copy", ",", "\n", "group_name", ")", "\n", "\n", "", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_group_transforms": [[374, 399], ["avalanche_dataset.AvalancheDataset._fork_dataset", "avalanche_dataset.AvalancheDataset._freeze_dataset_group"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._freeze_dataset_group"], ["", "def", "freeze_group_transforms", "(", "self", ":", "TAvalancheDataset", ",", "\n", "group_name", ":", "str", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset where the transformations for a specific group\n        are frozen.\n\n        Frozen transformations will be permanently glued to the original\n        dataset so that they can't be changed anymore. This is usually done\n        when using transformations to create derived datasets: in this way\n        freezing the transformations will ensure that the user won't be able\n        to inadvertently change them by directly setting the transformations\n        field or by using the other transformations utility methods like\n        ``replace_transforms``. To freeze transformations of all groups\n        please use ``freeze_transforms``.\n\n        The current dataset will not be affected.\n\n        :return: A new dataset with the transformations frozen for the given\n            group.\n        \"\"\"", "\n", "dataset_copy", "=", "self", ".", "_fork_dataset", "(", ")", "\n", "\n", "AvalancheDataset", ".", "_freeze_dataset_group", "(", "dataset_copy", ",", "group_name", ")", "\n", "\n", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.get_transforms": [[400, 422], ["None"], "methods", ["None"], ["", "def", "get_transforms", "(", "\n", "self", ":", "TAvalancheDataset", ",", "\n", "transforms_group", ":", "str", "=", "None", ")", "->", "Tuple", "[", "Any", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Returns the transformations given a group.\n\n        Beware that this will not return the frozen transformations, nor the\n        ones included in the wrapped dataset. Only transformations directly\n        attached to this dataset will be returned.\n\n        :param transforms_group: The transformations group. Defaults to None,\n            which means that the current group is returned.\n        :return: The transformation group, as a tuple\n            (transform, target_transform).\n        \"\"\"", "\n", "if", "transforms_group", "is", "None", ":", "\n", "            ", "transforms_group", "=", "self", ".", "current_transform_group", "\n", "\n", "", "if", "transforms_group", "==", "self", ".", "current_transform_group", ":", "\n", "            ", "return", "self", ".", "transform", ",", "self", ".", "target_transform", "\n", "\n", "", "return", "self", ".", "transform_groups", "[", "transforms_group", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms": [[423, 465], ["avalanche_dataset.AvalancheDataset._fork_dataset", "torchvision.transforms.Compose", "torchvision.transforms.Compose"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset"], ["", "def", "add_transforms", "(", "\n", "self", ":", "TAvalancheDataset", ",", "\n", "transform", ":", "Callable", "[", "[", "Any", "]", ",", "Any", "]", "=", "None", ",", "\n", "target_transform", ":", "Callable", "[", "[", "int", "]", ",", "int", "]", "=", "None", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset with the given transformations added to\n        the existing ones.\n\n        The transformations will be added to the current transformations group.\n        Other transformation groups will not be affected.\n\n        The given transformations will be added \"at the end\" of previous\n        transformations of the current transformations group. This means\n        that existing transformations will be applied to the patterns first.\n\n        The current dataset will not be affected.\n\n        :param transform: A function/transform that takes the X value of a\n            pattern from the original dataset and returns a transformed version.\n        :param target_transform: A function/transform that takes in the target\n            and transforms it.\n        :return: A new dataset with the added transformations.\n        \"\"\"", "\n", "\n", "dataset_copy", "=", "self", ".", "_fork_dataset", "(", ")", "\n", "\n", "if", "transform", "is", "not", "None", ":", "\n", "            ", "if", "dataset_copy", ".", "transform", "is", "not", "None", ":", "\n", "                ", "dataset_copy", ".", "transform", "=", "Compose", "(", "[", "\n", "dataset_copy", ".", "transform", ",", "transform", "]", ")", "\n", "", "else", ":", "\n", "                ", "dataset_copy", ".", "transform", "=", "transform", "\n", "\n", "", "", "if", "target_transform", "is", "not", "None", ":", "\n", "            ", "if", "dataset_copy", ".", "target_transform", "is", "not", "None", ":", "\n", "                ", "dataset_copy", ".", "target_transform", "=", "Compose", "(", "[", "\n", "dataset_copy", ".", "target_transform", ",", "target_transform", "]", ")", "\n", "", "else", ":", "\n", "                ", "dataset_copy", ".", "target_transform", "=", "transform", "\n", "\n", "", "", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms_to_group": [[466, 522], ["avalanche_dataset.AvalancheDataset._fork_dataset", "list", "tuple", "avalanche_dataset.AvalancheDataset.add_transforms", "ValueError", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms"], ["", "def", "add_transforms_to_group", "(", "\n", "self", ":", "TAvalancheDataset", ",", "\n", "group_name", ":", "str", ",", "\n", "transform", ":", "Callable", "[", "[", "Any", "]", ",", "Any", "]", "=", "None", ",", "\n", "target_transform", ":", "Callable", "[", "[", "int", "]", ",", "int", "]", "=", "None", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset with the given transformations added to\n        the existing ones for a certain group.\n\n        The transformations will be added to the given transformations group.\n        Other transformation groups will not be affected. The group must\n        already exist.\n\n        The given transformations will be added \"at the end\" of previous\n        transformations of that group. This means that existing transformations\n        will be applied to the patterns first.\n\n        The current dataset will not be affected.\n\n        :param group_name: The name of the group.\n        :param transform: A function/transform that takes the X value of a\n            pattern from the original dataset and returns a transformed version.\n        :param target_transform: A function/transform that takes in the target\n            and transforms it.\n        :return: A new dataset with the added transformations.\n        \"\"\"", "\n", "\n", "if", "self", ".", "current_transform_group", "==", "group_name", ":", "\n", "            ", "return", "self", ".", "add_transforms", "(", "transform", ",", "target_transform", ")", "\n", "\n", "", "if", "group_name", "not", "in", "self", ".", "transform_groups", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid group name '", "+", "str", "(", "group_name", ")", ")", "\n", "\n", "", "dataset_copy", "=", "self", ".", "_fork_dataset", "(", ")", "\n", "\n", "t_group", ":", "List", "[", "XTransform", ",", "YTransform", "]", "=", "list", "(", "dataset_copy", ".", "transform_groups", "[", "group_name", "]", ")", "\n", "if", "transform", "is", "not", "None", ":", "\n", "            ", "if", "t_group", "[", "0", "]", "is", "not", "None", ":", "\n", "                ", "t_group", "[", "0", "]", "=", "Compose", "(", "[", "t_group", "[", "0", "]", ",", "transform", "]", ")", "\n", "", "else", ":", "\n", "                ", "t_group", "[", "0", "]", "=", "transform", "\n", "\n", "", "", "if", "target_transform", "is", "not", "None", ":", "\n", "            ", "if", "t_group", "[", "1", "]", "is", "not", "None", ":", "\n", "                ", "t_group", "[", "1", "]", "=", "Compose", "(", "[", "t_group", "[", "1", "]", ",", "target_transform", "]", ")", "\n", "", "else", ":", "\n", "                ", "t_group", "[", "1", "]", "=", "transform", "\n", "\n", "# tuple(t_group) works too, but it triggers a type warning", "\n", "", "", "tuple_t_group", ":", "Tuple", "[", "XTransform", ",", "YTransform", "]", "=", "tuple", "(", "\n", "(", "t_group", "[", "0", "]", ",", "t_group", "[", "1", "]", ")", ")", "\n", "dataset_copy", ".", "transform_groups", "[", "group_name", "]", "=", "tuple_t_group", "\n", "\n", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.replace_transforms": [[523, 564], ["avalanche_dataset.AvalancheDataset._fork_dataset().with_transforms", "avalanche_dataset.AvalancheDataset._replace_original_dataset_group", "avalanche_dataset.AvalancheDataset.with_transforms", "avalanche_dataset.AvalancheDataset._fork_dataset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._replace_original_dataset_group", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset"], ["", "def", "replace_transforms", "(", "\n", "self", ":", "TAvalancheDataset", ",", "\n", "transform", ":", "XTransform", ",", "\n", "target_transform", ":", "YTransform", ",", "\n", "group", ":", "str", "=", "None", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset with the existing transformations replaced with\n        the given ones.\n\n        The given transformations will replace the ones of the current\n        transformations group. Other transformation groups will not be affected.\n\n        If the original dataset is an instance of :class:`AvalancheDataset`,\n        then transformations of the original set will be considered as well\n        (the original dataset will be left untouched).\n\n        The current dataset will not be affected.\n\n        Note that this function will not override frozen transformations. This\n        will also not affect transformations found in datasets that are not\n        instances of :class:`AvalancheDataset`.\n\n        :param transform: A function/transform that takes the X value of a\n            pattern from the original dataset and returns a transformed version.\n        :param target_transform: A function/transform that takes in the target\n            and transforms it.\n        :param group: The transforms group to replace. Defaults to None, which\n            means that the current group will be replaced.\n        :return: A new dataset with the new transformations.\n        \"\"\"", "\n", "\n", "if", "group", "is", "None", ":", "\n", "            ", "group", "=", "self", ".", "current_transform_group", "\n", "\n", "", "dataset_copy", "=", "self", ".", "_fork_dataset", "(", ")", ".", "with_transforms", "(", "group", ")", "\n", "dataset_copy", ".", "_replace_original_dataset_group", "(", "None", ",", "None", ")", "\n", "\n", "dataset_copy", ".", "transform", "=", "transform", "\n", "dataset_copy", ".", "target_transform", "=", "target_transform", "\n", "\n", "return", "dataset_copy", ".", "with_transforms", "(", "self", ".", "current_transform_group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms": [[565, 595], ["avalanche_dataset.AvalancheDataset._fork_dataset", "avalanche_dataset.AvalancheDataset._set_original_dataset_transform_group", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._set_original_dataset_transform_group"], ["", "def", "with_transforms", "(", "self", ":", "TAvalancheDataset", ",", "group_name", ":", "str", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset with the transformations of a different group\n        loaded.\n\n        The current dataset will not be affected.\n\n        :param group_name: The name of the transformations group to use.\n        :return: A new dataset with the new transformations.\n        \"\"\"", "\n", "dataset_copy", "=", "self", ".", "_fork_dataset", "(", ")", "\n", "\n", "if", "group_name", "not", "in", "dataset_copy", ".", "transform_groups", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid group name '", "+", "str", "(", "group_name", ")", ")", "\n", "\n", "# Store current group (loaded in transform and target_transform fields)", "\n", "", "dataset_copy", ".", "transform_groups", "[", "dataset_copy", ".", "current_transform_group", "]", "=", "(", "dataset_copy", ".", "transform", ",", "dataset_copy", ".", "target_transform", ")", "\n", "\n", "# Load new group in transform and target_transform fields", "\n", "switch_group", "=", "dataset_copy", ".", "transform_groups", "[", "group_name", "]", "\n", "dataset_copy", ".", "transform", "=", "switch_group", "[", "0", "]", "\n", "dataset_copy", ".", "target_transform", "=", "switch_group", "[", "1", "]", "\n", "dataset_copy", ".", "current_transform_group", "=", "group_name", "\n", "\n", "# Finally, align the underlying dataset", "\n", "dataset_copy", ".", "_set_original_dataset_transform_group", "(", "group_name", ")", "\n", "\n", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms_group": [[596, 633], ["avalanche_dataset.AvalancheDataset._fork_dataset", "avalanche_dataset.AvalancheDataset._check_groups_dict_format", "avalanche_dataset.AvalancheDataset._add_original_dataset_group", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._check_groups_dict_format", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._add_original_dataset_group"], ["", "def", "add_transforms_group", "(", "self", ":", "TAvalancheDataset", ",", "\n", "group_name", ":", "str", ",", "\n", "transform", ":", "XTransform", ",", "\n", "target_transform", ":", "YTransform", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Returns a new dataset with a new transformations group.\n\n        The current dataset will not be affected.\n\n        This method raises an exception if a group with the same name already\n        exists.\n\n        :param group_name: The name of the new transformations group.\n        :param transform: A function/transform that takes the X value of a\n            pattern from the original dataset and returns a transformed version.\n        :param target_transform: A function/transform that takes in the target\n            and transforms it.\n        :return: A new dataset with the new transformations.\n        \"\"\"", "\n", "dataset_copy", "=", "self", ".", "_fork_dataset", "(", ")", "\n", "\n", "if", "group_name", "in", "dataset_copy", ".", "transform_groups", ":", "\n", "            ", "raise", "ValueError", "(", "'A group with the same name already exists'", ")", "\n", "\n", "", "dataset_copy", ".", "transform_groups", "[", "group_name", "]", "=", "(", "transform", ",", "target_transform", ")", "\n", "\n", "AvalancheDataset", ".", "_check_groups_dict_format", "(", "\n", "dataset_copy", ".", "transform_groups", ")", "\n", "\n", "dataset_copy", ".", "_frozen_transforms", "[", "group_name", "]", "=", "(", "None", ",", "None", ")", "\n", "\n", "# Finally, align the underlying dataset", "\n", "dataset_copy", ".", "_add_original_dataset_group", "(", "group_name", ")", "\n", "\n", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._fork_dataset": [[634, 640], ["copy.copy", "dict", "dict"], "methods", ["None"], ["", "def", "_fork_dataset", "(", "self", ":", "TAvalancheDataset", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "dataset_copy", "=", "copy", ".", "copy", "(", "self", ")", "\n", "dataset_copy", ".", "_frozen_transforms", "=", "dict", "(", "dataset_copy", ".", "_frozen_transforms", ")", "\n", "dataset_copy", ".", "transform_groups", "=", "dict", "(", "dataset_copy", ".", "transform_groups", ")", "\n", "\n", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._freeze_dataset_group": [[641, 696], ["dataset_copy._freeze_original_dataset", "torchvision.transforms.Compose", "torchvision.transforms.Compose"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._freeze_original_dataset"], ["", "@", "staticmethod", "\n", "def", "_freeze_dataset_group", "(", "dataset_copy", ":", "TAvalancheDataset", ",", "\n", "group_name", ":", "str", ")", ":", "\n", "# Freeze the current transformations. Frozen transformations are saved", "\n", "# in a separate dict.", "\n", "\n", "# This may rise an error if no group with the given name exists!", "\n", "        ", "frozen_group", "=", "dataset_copy", ".", "_frozen_transforms", "[", "group_name", "]", "\n", "\n", "final_frozen_transform", "=", "frozen_group", "[", "0", "]", "\n", "final_frozen_target_transform", "=", "frozen_group", "[", "1", "]", "\n", "\n", "is_current_group", "=", "dataset_copy", ".", "current_transform_group", "==", "group_name", "\n", "\n", "# If the required group is not the current one, just freeze the ones", "\n", "# found in dataset_copy.transform_groups).", "\n", "to_be_glued", "=", "dataset_copy", ".", "transform_groups", "[", "group_name", "]", "\n", "\n", "# Now that transformations are stored in to_be_glued,", "\n", "# we can safely reset them in the transform_groups dictionary.", "\n", "dataset_copy", ".", "transform_groups", "[", "group_name", "]", "=", "(", "None", ",", "None", ")", "\n", "\n", "if", "is_current_group", ":", "\n", "# If the required group is the current one, use the transformations", "\n", "# already found in transform and target_transform fields (because", "\n", "# the ones stored in dataset_copy.transform_groups may be not", "\n", "# up-to-date).", "\n", "\n", "            ", "to_be_glued", "=", "(", "dataset_copy", ".", "transform", ",", "\n", "dataset_copy", ".", "target_transform", ")", "\n", "\n", "# And of course, once frozen, set transformations to None", "\n", "dataset_copy", ".", "transform", "=", "None", "\n", "dataset_copy", ".", "target_transform", "=", "None", "\n", "\n", "", "if", "to_be_glued", "[", "0", "]", "is", "not", "None", ":", "\n", "            ", "if", "frozen_group", "[", "0", "]", "is", "None", ":", "\n", "                ", "final_frozen_transform", "=", "to_be_glued", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "final_frozen_transform", "=", "Compose", "(", "[", "\n", "frozen_group", "[", "0", "]", ",", "to_be_glued", "[", "0", "]", "]", ")", "\n", "\n", "", "", "if", "to_be_glued", "[", "1", "]", "is", "not", "None", ":", "\n", "            ", "if", "frozen_group", "[", "1", "]", "is", "None", ":", "\n", "                ", "final_frozen_target_transform", "=", "to_be_glued", "[", "1", "]", "\n", "", "else", ":", "\n", "                ", "final_frozen_target_transform", "=", "Compose", "(", "[", "\n", "frozen_group", "[", "1", "]", ",", "to_be_glued", "[", "1", "]", "]", ")", "\n", "\n", "# Set the frozen transformations", "\n", "", "", "dataset_copy", ".", "_frozen_transforms", "[", "group_name", "]", "=", "(", "\n", "final_frozen_transform", ",", "final_frozen_target_transform", ")", "\n", "\n", "# Finally, apply the freeze procedure to the original dataset", "\n", "dataset_copy", ".", "_freeze_original_dataset", "(", "group_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._get_single_item": [[697, 699], ["avalanche_dataset.AvalancheDataset._process_pattern"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._process_pattern"], ["", "def", "_get_single_item", "(", "self", ",", "idx", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "_process_pattern", "(", "self", ".", "_dataset", "[", "idx", "]", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._process_pattern": [[700, 712], ["isinstance", "avalanche_dataset.AvalancheDataset._apply_transforms", "dataset_utils.TupleTLabel"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._apply_transforms"], ["", "def", "_process_pattern", "(", "self", ",", "element", ":", "Tuple", ",", "idx", ":", "int", ")", ":", "\n", "        ", "has_task_label", "=", "isinstance", "(", "element", ",", "TupleTLabel", ")", "\n", "if", "has_task_label", ":", "\n", "            ", "element", "=", "element", "[", ":", "-", "1", "]", "\n", "\n", "", "pattern", "=", "element", "[", "0", "]", "\n", "label", "=", "element", "[", "1", "]", "\n", "\n", "pattern", ",", "label", "=", "self", ".", "_apply_transforms", "(", "pattern", ",", "label", ")", "\n", "\n", "return", "TupleTLabel", "(", "(", "pattern", ",", "label", ",", "*", "element", "[", "2", ":", "]", ",", "\n", "self", ".", "targets_task_labels", "[", "idx", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._apply_transforms": [[713, 728], ["avalanche_dataset.AvalancheDataset.transform", "avalanche_dataset.AvalancheDataset.target_transform"], "methods", ["None"], ["", "def", "_apply_transforms", "(", "self", ",", "pattern", ":", "Any", ",", "label", ":", "int", ")", ":", "\n", "        ", "frozen_group", "=", "self", ".", "_frozen_transforms", "[", "self", ".", "current_transform_group", "]", "\n", "if", "frozen_group", "[", "0", "]", "is", "not", "None", ":", "\n", "            ", "pattern", "=", "frozen_group", "[", "0", "]", "(", "pattern", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "pattern", "=", "self", ".", "transform", "(", "pattern", ")", "\n", "\n", "", "if", "frozen_group", "[", "1", "]", "is", "not", "None", ":", "\n", "            ", "label", "=", "frozen_group", "[", "1", "]", "(", "label", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "label", "=", "self", ".", "target_transform", "(", "label", ")", "\n", "\n", "", "return", "pattern", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._check_groups_dict_format": [[729, 754], ["dict", "warnings.warn", "isinstance", "ValueError", "isinstance", "ValueError", "ValueError", "len", "str", "str", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_check_groups_dict_format", "(", "groups_dict", ")", ":", "\n", "# The original groups_dict must be convertible to native Python dict", "\n", "        ", "groups_dict", "=", "dict", "(", "groups_dict", ")", "\n", "\n", "# Check if the format of the groups is correct", "\n", "for", "map_key", "in", "groups_dict", ":", "\n", "            ", "if", "not", "isinstance", "(", "map_key", ",", "str", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Every group must be identified by a string.'", "\n", "'Wrong key was: \"'", "+", "str", "(", "map_key", ")", "+", "'\"'", ")", "\n", "\n", "", "map_value", "=", "groups_dict", "[", "map_key", "]", "\n", "if", "not", "isinstance", "(", "map_value", ",", "tuple", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Transformations for group \"'", "+", "str", "(", "map_key", ")", "+", "\n", "'\" must be contained in a tuple'", ")", "\n", "\n", "", "if", "not", "len", "(", "map_value", ")", "==", "2", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Transformations for group \"'", "+", "str", "(", "map_key", ")", "+", "'\" must be '", "\n", "'a tuple containing 2 elements: a transformation for the X '", "\n", "'values and a transformation for the Y values'", ")", "\n", "\n", "", "", "if", "'test'", "in", "groups_dict", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'A transformation group named \"test\" has been found. Beware '", "\n", "'that by default AvalancheDataset supports test transformations'", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._initialize_groups_dict": [[757, 803], ["avalanche_dataset.AvalancheDataset._add_groups_from_original_dataset", "dict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._add_groups_from_original_dataset"], ["", "", "def", "_initialize_groups_dict", "(", "\n", "self", ",", "\n", "transform_groups", ":", "Optional", "[", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "\n", "YTransform", "]", "]", "]", ",", "\n", "dataset", ":", "Any", ",", "\n", "transform", ":", "XTransform", ",", "\n", "target_transform", ":", "YTransform", ")", "->", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "\n", "YTransform", "]", "]", ":", "\n", "        ", "\"\"\"\n        A simple helper method that tries to fill the 'train' and 'eval'\n        groups as those two groups must always exist.\n\n        If no transform_groups are passed to the class constructor, then\n        the transform and target_transform parameters are used for both groups.\n\n        If train transformations are set and eval transformations are not, then\n        train transformations will be used for the eval group.\n\n        :param dataset: The original dataset. Will be used to detect existing\n            groups.\n        :param transform: The transformation passed as a parameter to the\n            class constructor.\n        :param target_transform: The target transformation passed as a parameter\n            to the class constructor.\n        \"\"\"", "\n", "if", "transform_groups", "is", "None", ":", "\n", "            ", "transform_groups", "=", "{", "\n", "'train'", ":", "(", "transform", ",", "target_transform", ")", ",", "\n", "'eval'", ":", "(", "transform", ",", "target_transform", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "transform_groups", "=", "dict", "(", "transform_groups", ")", "\n", "\n", "", "if", "'train'", "in", "transform_groups", ":", "\n", "            ", "if", "'eval'", "not", "in", "transform_groups", ":", "\n", "                ", "transform_groups", "[", "'eval'", "]", "=", "transform_groups", "[", "'train'", "]", "\n", "\n", "", "", "if", "'train'", "not", "in", "transform_groups", ":", "\n", "            ", "transform_groups", "[", "'train'", "]", "=", "(", "None", ",", "None", ")", "\n", "\n", "", "if", "'eval'", "not", "in", "transform_groups", ":", "\n", "            ", "transform_groups", "[", "'eval'", "]", "=", "(", "None", ",", "None", ")", "\n", "\n", "", "self", ".", "_add_groups_from_original_dataset", "(", "dataset", ",", "transform_groups", ")", "\n", "\n", "return", "transform_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._initialize_targets_sequence": [[804, 823], ["avalanche_dataset._make_target_from_supported_dataset", "len", "len", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._make_target_from_supported_dataset"], ["", "def", "_initialize_targets_sequence", "(", "self", ",", "dataset", ",", "targets", ",", "\n", "dataset_type", ",", "targets_adapter", ")", "->", "Sequence", "[", "TTargetType", "]", ":", "\n", "        ", "if", "targets", "is", "not", "None", ":", "\n", "# User defined targets always take precedence", "\n", "# Note: no adapter is applied!", "\n", "            ", "if", "len", "(", "targets", ")", "!=", "len", "(", "dataset", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Invalid amount of target labels. It must be equal to the '", "\n", "'number of patterns in the dataset. Got {}, expected '", "\n", "'{}!'", ".", "format", "(", "len", "(", "targets", ")", ",", "len", "(", "dataset", ")", ")", ")", "\n", "", "return", "targets", "\n", "\n", "", "if", "targets_adapter", "is", "None", ":", "\n", "            ", "if", "dataset_type", "==", "AvalancheDatasetType", ".", "CLASSIFICATION", ":", "\n", "                ", "targets_adapter", "=", "int", "\n", "", "else", ":", "\n", "                ", "targets_adapter", "=", "None", "\n", "", "", "return", "_make_target_from_supported_dataset", "(", "dataset", ",", "targets_adapter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._initialize_task_labels_sequence": [[824, 840], ["avalanche_dataset._make_task_labels_from_supported_dataset", "isinstance", "dataset_utils.SubSequence", "dataset_utils.ConstantSequence", "len", "len", "len", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._make_task_labels_from_supported_dataset"], ["", "def", "_initialize_task_labels_sequence", "(", "\n", "self", ",", "dataset", ",", "task_labels", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", ")", "->", "Sequence", "[", "int", "]", ":", "\n", "        ", "if", "task_labels", "is", "not", "None", ":", "\n", "# task_labels has priority over the dataset fields", "\n", "            ", "if", "isinstance", "(", "task_labels", ",", "int", ")", ":", "\n", "                ", "task_labels", "=", "ConstantSequence", "(", "task_labels", ",", "len", "(", "dataset", ")", ")", "\n", "", "elif", "len", "(", "task_labels", ")", "!=", "len", "(", "dataset", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Invalid amount of task labels. It must be equal to the '", "\n", "'number of patterns in the dataset. Got {}, expected '", "\n", "'{}!'", ".", "format", "(", "len", "(", "task_labels", ")", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "", "return", "SubSequence", "(", "task_labels", ",", "converter", "=", "int", ")", "\n", "\n", "", "return", "_make_task_labels_from_supported_dataset", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._initialize_collate_fn": [[841, 850], ["hasattr", "getattr"], "methods", ["None"], ["", "def", "_initialize_collate_fn", "(", "self", ",", "dataset", ",", "dataset_type", ",", "collate_fn", ")", ":", "\n", "        ", "if", "collate_fn", "is", "not", "None", ":", "\n", "            ", "return", "collate_fn", "\n", "\n", "", "if", "dataset_type", "==", "AvalancheDatasetType", ".", "UNDEFINED", ":", "\n", "            ", "if", "hasattr", "(", "dataset", ",", "'collate_fn'", ")", ":", "\n", "                ", "return", "getattr", "(", "dataset", ",", "'collate_fn'", ")", "\n", "\n", "", "", "return", "default_collate", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._initialize_tasks_dict": [[851, 867], ["dict", "enumerate", "isinstance", "result[].append", "len", "range", "len", "range", "len", "len", "next", "iter", "dict.keys"], "methods", ["None"], ["", "def", "_initialize_tasks_dict", "(", "self", ",", "dataset", ",", "task_labels", ":", "Sequence", "[", "int", "]", ")", "->", "Dict", "[", "int", ",", "Sequence", "[", "int", "]", "]", ":", "\n", "        ", "if", "isinstance", "(", "task_labels", ",", "ConstantSequence", ")", "and", "len", "(", "task_labels", ")", ">", "0", ":", "\n", "# Shortcut :)", "\n", "            ", "return", "{", "task_labels", "[", "0", "]", ":", "range", "(", "len", "(", "task_labels", ")", ")", "}", "\n", "\n", "", "result", "=", "dict", "(", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "task_labels", ")", ":", "\n", "            ", "if", "x", "not", "in", "result", ":", "\n", "                ", "result", "[", "x", "]", "=", "[", "]", "\n", "", "result", "[", "x", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "if", "len", "(", "result", ")", "==", "1", ":", "\n", "            ", "result", "[", "next", "(", "iter", "(", "result", ".", "keys", "(", ")", ")", ")", "]", "=", "range", "(", "len", "(", "task_labels", ")", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._set_original_dataset_transform_group": [[868, 877], ["isinstance", "avalanche_dataset.AvalancheDataset._dataset.with_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms"], ["", "def", "_set_original_dataset_transform_group", "(", "\n", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "if", "self", ".", "_dataset", ".", "current_transform_group", "==", "group_name", ":", "\n", "# Prevents a huge slowdown in some corner cases", "\n", "# (apart from being actually more performant)", "\n", "                ", "return", "\n", "\n", "", "self", ".", "_dataset", "=", "self", ".", "_dataset", ".", "with_transforms", "(", "group_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._freeze_original_dataset": [[878, 882], ["isinstance", "avalanche_dataset.AvalancheDataset._dataset.freeze_group_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_group_transforms"], ["", "", "def", "_freeze_original_dataset", "(", "\n", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "self", ".", "_dataset", "=", "self", ".", "_dataset", ".", "freeze_group_transforms", "(", "group_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._replace_original_dataset_group": [[883, 888], ["isinstance", "avalanche_dataset.AvalancheDataset._dataset.replace_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.replace_transforms"], ["", "", "def", "_replace_original_dataset_group", "(", "\n", "self", ",", "transform", ":", "XTransform", ",", "target_transform", ":", "YTransform", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "self", ".", "_dataset", "=", "self", ".", "_dataset", ".", "replace_transforms", "(", "\n", "transform", ",", "target_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._add_original_dataset_group": [[889, 894], ["isinstance", "avalanche_dataset.AvalancheDataset._dataset.add_transforms_group"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms_group"], ["", "", "def", "_add_original_dataset_group", "(", "\n", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "self", ".", "_dataset", "=", "self", ".", "_dataset", ".", "add_transforms_group", "(", "\n", "group_name", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._add_groups_from_original_dataset": [[895, 901], ["isinstance", "dataset.transform_groups.keys"], "methods", ["None"], ["", "", "def", "_add_groups_from_original_dataset", "(", "\n", "self", ",", "dataset", ",", "transform_groups", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "for", "original_dataset_group", "in", "dataset", ".", "transform_groups", ".", "keys", "(", ")", ":", "\n", "                ", "if", "original_dataset_group", "not", "in", "transform_groups", ":", "\n", "                    ", "transform_groups", "[", "original_dataset_group", "]", "=", "(", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._has_own_transformations": [[902, 924], ["avalanche_dataset.AvalancheDataset.transform_groups.values", "avalanche_dataset.AvalancheDataset._frozen_transforms.values"], "methods", ["None"], ["", "", "", "", "def", "_has_own_transformations", "(", "self", ")", ":", "\n", "# Used to check if the current dataset has its own transformations", "\n", "# This method returns False if transformations are applied", "\n", "# by the wrapped dataset only.", "\n", "\n", "        ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "return", "True", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "return", "True", "\n", "\n", "", "for", "transform_group", "in", "self", ".", "transform_groups", ".", "values", "(", ")", ":", "\n", "            ", "for", "transform", "in", "transform_group", ":", "\n", "                ", "if", "transform", "is", "not", "None", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "for", "transform_group", "in", "self", ".", "_frozen_transforms", ".", "values", "(", ")", ":", "\n", "            ", "for", "transform", "in", "transform_group", ":", "\n", "                ", "if", "transform", "is", "not", "None", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._borrow_transformations": [[925, 961], ["dataset.transform_groups.keys", "dataset._frozen_transforms.keys", "dataset.transform_groups.keys", "dataset._frozen_transforms.keys", "isinstance", "avalanche_dataset.AvalancheDataset._prepend_transforms", "avalanche_dataset.AvalancheDataset._prepend_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._prepend_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._prepend_transforms"], ["", "@", "staticmethod", "\n", "def", "_borrow_transformations", "(", "dataset", ",", "transform_groups", ",", "\n", "frozen_transform_groups", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "return", "\n", "\n", "", "for", "original_dataset_group", "in", "dataset", ".", "transform_groups", ".", "keys", "(", ")", ":", "\n", "            ", "if", "original_dataset_group", "not", "in", "transform_groups", ":", "\n", "                ", "transform_groups", "[", "original_dataset_group", "]", "=", "(", "None", ",", "None", ")", "\n", "\n", "", "", "for", "original_dataset_group", "in", "dataset", ".", "_frozen_transforms", ".", "keys", "(", ")", ":", "\n", "            ", "if", "original_dataset_group", "not", "in", "frozen_transform_groups", ":", "\n", "                ", "frozen_transform_groups", "[", "original_dataset_group", "]", "=", "(", "None", ",", "None", ")", "\n", "\n", "# Standard transforms", "\n", "", "", "for", "original_dataset_group", "in", "dataset", ".", "transform_groups", ".", "keys", "(", ")", ":", "\n", "            ", "other_dataset_transforms", "=", "dataset", ".", "transform_groups", "[", "original_dataset_group", "]", "\n", "if", "dataset", ".", "current_transform_group", "==", "original_dataset_group", ":", "\n", "                ", "other_dataset_transforms", "=", "(", "dataset", ".", "transform", ",", "\n", "dataset", ".", "target_transform", ")", "\n", "\n", "", "transform_groups", "[", "original_dataset_group", "]", "=", "AvalancheDataset", ".", "_prepend_transforms", "(", "\n", "transform_groups", "[", "original_dataset_group", "]", ",", "\n", "other_dataset_transforms", ")", "\n", "\n", "# Frozen transforms", "\n", "", "for", "original_dataset_group", "in", "dataset", ".", "_frozen_transforms", ".", "keys", "(", ")", ":", "\n", "            ", "other_dataset_transforms", "=", "dataset", ".", "_frozen_transforms", "[", "original_dataset_group", "]", "\n", "\n", "frozen_transform_groups", "[", "original_dataset_group", "]", "=", "AvalancheDataset", ".", "_prepend_transforms", "(", "\n", "frozen_transform_groups", "[", "original_dataset_group", "]", ",", "\n", "other_dataset_transforms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._prepend_transforms": [[962, 987], ["range", "tuple", "len", "ValueError", "len", "len", "ValueError", "len", "result.append", "len", "len", "result.append", "result.append", "torchvision.transforms.Compose"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_prepend_transforms", "(", "transforms", ",", "to_be_prepended", ")", ":", "\n", "        ", "if", "len", "(", "transforms", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Transformation groups must contain exactly 2 transformations'", ")", "\n", "\n", "", "if", "len", "(", "transforms", ")", "!=", "len", "(", "to_be_prepended", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Transformation group size mismatch: {} vs {}'", ".", "format", "(", "\n", "len", "(", "transforms", ")", ",", "len", "(", "to_be_prepended", ")", "\n", ")", ")", "\n", "\n", "", "result", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "transforms", ")", ")", ":", "\n", "            ", "if", "to_be_prepended", "[", "i", "]", "is", "None", ":", "\n", "# Nothing to prepend", "\n", "                ", "result", ".", "append", "(", "transforms", "[", "i", "]", ")", "\n", "", "elif", "transforms", "[", "i", "]", "is", "None", ":", "\n", "                ", "result", ".", "append", "(", "to_be_prepended", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "result", ".", "append", "(", "Compose", "(", "[", "\n", "to_be_prepended", "[", "i", "]", ",", "transforms", "[", "i", "]", "]", ")", ")", "\n", "\n", "", "", "return", "tuple", "(", "result", ")", "# Transform to tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._optimize_targets": [[988, 990], ["dataset_utils.optimize_sequence"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.optimize_sequence"], ["", "def", "_optimize_targets", "(", "self", ")", ":", "\n", "        ", "self", ".", "targets", "=", "optimize_sequence", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._optimize_task_labels": [[991, 993], ["dataset_utils.optimize_sequence"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.optimize_sequence"], ["", "def", "_optimize_task_labels", "(", "self", ")", ":", "\n", "        ", "self", ".", "targets_task_labels", "=", "optimize_sequence", "(", "self", ".", "targets_task_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._optimize_task_dict": [[994, 998], ["dataset_utils.optimize_sequence"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.optimize_sequence"], ["", "def", "_optimize_task_dict", "(", "self", ")", ":", "\n", "        ", "for", "task_label", "in", "self", ".", "tasks_pattern_indices", ":", "\n", "            ", "self", ".", "tasks_pattern_indices", "[", "task_label", "]", "=", "optimize_sequence", "(", "\n", "self", ".", "tasks_pattern_indices", "[", "task_label", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._flatten_dataset": [[999, 1001], ["None"], "methods", ["None"], ["", "", "def", "_flatten_dataset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._TaskSubsetDict.__init__": [[1005, 1013], ["avalanche_dataset._TaskSubsetDict._full_dataset.tasks_pattern_indices.keys", "sorted", "collections.OrderedDict", "collections.OrderedDict.__init__", "list"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "avalanche_dataset", ":", "AvalancheDataset", ")", ":", "\n", "        ", "self", ".", "_full_dataset", "=", "avalanche_dataset", "\n", "task_ids", "=", "self", ".", "_full_dataset", ".", "tasks_pattern_indices", ".", "keys", "(", ")", "\n", "task_ids", "=", "sorted", "(", "list", "(", "task_ids", ")", ")", "\n", "base_dict", "=", "OrderedDict", "(", ")", "\n", "for", "x", "in", "task_ids", ":", "\n", "            ", "base_dict", "[", "x", "]", "=", "x", "\n", "", "super", "(", ")", ".", "__init__", "(", "base_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._TaskSubsetDict.__getitem__": [[1014, 1019], ["avalanche_dataset._TaskSubsetDict._make_subset", "KeyError", "str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._TaskSubsetDict._make_subset"], ["", "def", "__getitem__", "(", "self", ",", "task_id", ":", "int", ")", ":", "\n", "        ", "if", "task_id", "not", "in", "self", ".", "_full_dataset", ".", "tasks_pattern_indices", ":", "\n", "            ", "raise", "KeyError", "(", "'No pattern with '", "+", "str", "(", "task_id", ")", "+", "' found'", ")", "\n", "", "pattern_indices", "=", "self", ".", "_full_dataset", ".", "tasks_pattern_indices", "[", "task_id", "]", "\n", "return", "self", ".", "_make_subset", "(", "pattern_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._TaskSubsetDict.or_empty": [[1020, 1025], ["avalanche_dataset._TaskSubsetDict._make_subset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._TaskSubsetDict._make_subset"], ["", "def", "or_empty", "(", "self", ",", "task_id", ":", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", "[", "task_id", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "self", ".", "_make_subset", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._TaskSubsetDict._make_subset": [[1026, 1028], ["avalanche_dataset.AvalancheSubset"], "methods", ["None"], ["", "", "def", "_make_subset", "(", "self", ",", "indices", ":", "Sequence", "[", "int", "]", ")", ":", "\n", "        ", "return", "AvalancheSubset", "(", "self", ".", "_full_dataset", ",", "indices", "=", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset.__init__": [[1037, 1189], ["super().__init__", "isinstance", "dataset_utils.ClassificationSubset", "isinstance", "ValueError", "ValueError", "ValueError", "torch.utils.data.dataset.Subset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ":", "SupportedDataset", ",", "\n", "indices", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "*", ",", "\n", "class_mapping", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "transform", ":", "Callable", "[", "[", "Any", "]", ",", "Any", "]", "=", "None", ",", "\n", "target_transform", ":", "Callable", "[", "[", "int", "]", ",", "int", "]", "=", "None", ",", "\n", "transform_groups", ":", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "\n", "YTransform", "]", "]", "=", "None", ",", "\n", "initial_transform_group", ":", "str", "=", "None", ",", "\n", "task_labels", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "targets", ":", "Sequence", "[", "TTargetType", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ",", "\n", "collate_fn", ":", "Callable", "[", "[", "List", "]", ",", "Any", "]", "=", "None", ",", "\n", "targets_adapter", ":", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates an ``AvalancheSubset`` instance.\n\n        :param dataset: The whole dataset.\n        :param indices: Indices in the whole set selected for subset. Can\n            be None, which means that the whole dataset will be returned.\n        :param class_mapping: A list that, for each possible target (Y) value,\n            contains its corresponding remapped value. Can be None.\n            Beware that setting this parameter will force the final\n            dataset type to be CLASSIFICATION or UNDEFINED.\n        :param transform: A function/transform that takes the X value of a\n            pattern from the original dataset and returns a transformed version.\n        :param target_transform: A function/transform that takes in the target\n            and transforms it.\n        :param transform_groups: A dictionary containing the transform groups.\n            Transform groups are used to quickly switch between training and\n            eval (test) transformations. This becomes useful when in need to\n            test on the training dataset as test transformations usually don't\n            contain random augmentations. ``AvalancheDataset`` natively supports\n            the 'train' and 'eval' groups by calling the ``train()`` and\n            ``eval()`` methods. When using custom groups one can use the\n            ``with_transforms(group_name)`` method instead. Defaults to None,\n            which means that the current transforms will be used to\n            handle both 'train' and 'eval' groups (just like in standard\n            ``torchvision`` datasets).\n        :param initial_transform_group: The name of the initial transform group\n            to be used. Defaults to None, which means that the current group of\n            the input dataset will be used (if an AvalancheDataset). If the\n            input dataset is not an AvalancheDataset, then 'train' will be\n            used.\n        :param task_labels: The task label for each instance. Must be a sequence\n            of ints, one for each instance in the dataset. This can either be a\n            list of task labels for the original dataset or the list of task\n            labels for the instances of the subset (an automatic detection will\n            be made). In the unfortunate case in which the original dataset and\n            the subset contain the same amount of instances, then this parameter\n            is considered to contain the task labels of the subset.\n            Alternatively can be a single int value, in which case\n            that value will be used as the task label for all the instances.\n            Defaults to None, which means that the dataset will try to\n            obtain the task labels from the original dataset. If no task labels\n            could be found, a default task label \"0\" will be applied to all\n            instances.\n        :param targets: The label of each pattern. Defaults to None, which\n            means that the targets will be retrieved from the dataset (if\n            possible). This can either be a list of target labels for the\n            original dataset or the list of target labels for the instances of\n            the subset (an automatic detection will be made). In the unfortunate\n            case in which the original dataset and the subset contain the same\n            amount of instances, then this parameter is considered to contain\n            the target labels of the subset.\n        :param dataset_type: The type of the dataset. Defaults to None,\n            which means that the type will be inferred from the input dataset.\n            When the `dataset_type` is different than UNDEFINED, a\n            proper value for `collate_fn` and `targets_adapter` will be set.\n            If the `dataset_type` is different than UNDEFINED, then\n            `collate_fn` and `targets_adapter` must not be set.\n            The only exception to this rule regards `class_mapping`.\n            If `class_mapping` is set, the final dataset_type\n            (as set by this parameter or detected from the subset) must be\n            CLASSIFICATION or UNDEFINED.\n        :param collate_fn: The function to use when slicing to merge single\n            patterns. In the future this function may become the function\n            used in the data loading process, too. If None and the\n            `dataset_type` is UNDEFINED, the constructor will check if a\n            `collate_fn` field exists in the dataset. If no such field exists,\n            the default collate function will be used.\n        :param targets_adapter: A function used to convert the values of the\n            targets field. Defaults to None. Note: the adapter will not change\n            the value of the second element returned by `__getitem__`.\n            The adapter is used to adapt the values of the targets field only.\n        \"\"\"", "\n", "\n", "detected_type", "=", "False", "\n", "if", "dataset_type", "is", "None", ":", "\n", "            ", "detected_type", "=", "True", "\n", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "dataset_type", "=", "dataset", ".", "dataset_type", "\n", "if", "dataset_type", "==", "AvalancheDatasetType", ".", "UNDEFINED", ":", "\n", "                    ", "if", "collate_fn", "is", "None", ":", "\n", "                        ", "collate_fn", "=", "dataset", ".", "collate_fn", "\n", "", "", "", "else", ":", "\n", "                ", "dataset_type", "=", "AvalancheDatasetType", ".", "UNDEFINED", "\n", "\n", "", "", "if", "dataset_type", "!=", "AvalancheDatasetType", ".", "UNDEFINED", "and", "(", "collate_fn", "is", "not", "None", "or", "targets_adapter", "is", "not", "None", ")", ":", "\n", "            ", "if", "detected_type", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'dataset_type {} was inferred from the input dataset. '", "\n", "'This dataset type can\\'t be used '", "\n", "'with custom collate_fn or targets_adapter '", "\n", "'parameters. Only the UNDEFINED type supports '", "\n", "'custom collate_fn or targets_adapter '", "\n", "'parameters'", ".", "format", "(", "dataset_type", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'dataset_type {} can\\'t be used with custom collate_fn '", "\n", "'or targets_adapter. Only the UNDEFINED type supports '", "\n", "'custom collate_fn or targets_adapter '", "\n", "'parameters.'", ".", "format", "(", "dataset_type", ")", ")", "\n", "\n", "", "", "if", "class_mapping", "is", "not", "None", ":", "\n", "            ", "if", "dataset_type", "not", "in", "[", "AvalancheDatasetType", ".", "CLASSIFICATION", ",", "\n", "AvalancheDatasetType", ".", "UNDEFINED", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'class_mapping is defined but the dataset type'", "\n", "' is neither CLASSIFICATION or UNDEFINED.'", ")", "\n", "\n", "", "", "if", "class_mapping", "is", "not", "None", ":", "\n", "            ", "subset", "=", "ClassificationSubset", "(", "dataset", ",", "indices", "=", "indices", ",", "\n", "class_mapping", "=", "class_mapping", ")", "\n", "", "elif", "indices", "is", "not", "None", ":", "\n", "            ", "subset", "=", "Subset", "(", "dataset", ",", "indices", "=", "indices", ")", "\n", "", "else", ":", "\n", "            ", "subset", "=", "dataset", "# Exactly like a plain AvalancheDataset", "\n", "\n", "", "self", ".", "_original_dataset", "=", "dataset", "\n", "# self._indices and self._class_mapping currently not used apart from", "\n", "# initialization procedures", "\n", "self", ".", "_class_mapping", "=", "class_mapping", "\n", "self", ".", "_indices", "=", "indices", "\n", "\n", "if", "initial_transform_group", "is", "None", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "initial_transform_group", "=", "dataset", ".", "current_transform_group", "\n", "", "else", ":", "\n", "                ", "initial_transform_group", "=", "'train'", "\n", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "subset", ",", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "initial_transform_group", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "targets", "=", "targets", ",", "\n", "dataset_type", "=", "dataset_type", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "targets_adapter", "=", "targets_adapter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._initialize_targets_sequence": [[1190, 1211], ["super()._initialize_targets_sequence", "dataset_utils.SubSequence", "len", "len", "len", "len", "ValueError", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_targets_sequence"], ["", "def", "_initialize_targets_sequence", "(", "\n", "self", ",", "dataset", ",", "targets", ",", "dataset_type", ",", "targets_adapter", ")", "->", "Sequence", "[", "TTargetType", "]", ":", "\n", "        ", "if", "targets", "is", "not", "None", ":", "\n", "# For the reasoning behind this, have a look at", "\n", "# _initialize_task_labels_sequence (it's basically the same).", "\n", "\n", "            ", "if", "len", "(", "targets", ")", "==", "len", "(", "self", ".", "_original_dataset", ")", "and", "not", "len", "(", "targets", ")", "==", "len", "(", "dataset", ")", ":", "\n", "                ", "return", "SubSequence", "(", "targets", ",", "indices", "=", "self", ".", "_indices", ")", "\n", "", "elif", "len", "(", "targets", ")", "==", "len", "(", "dataset", ")", ":", "\n", "                ", "return", "targets", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Invalid amount of targets. It must be equal to the '", "\n", "'number of patterns in the subset. '", "\n", "'Got {}, expected {}!'", ".", "format", "(", "\n", "len", "(", "targets", ")", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "", "", "return", "super", "(", ")", ".", "_initialize_targets_sequence", "(", "\n", "dataset", ",", "None", ",", "dataset_type", ",", "targets_adapter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._initialize_task_labels_sequence": [[1212, 1244], ["super()._initialize_task_labels_sequence", "isinstance", "dataset_utils.ConstantSequence", "len", "dataset_utils.SubSequence", "len", "len", "len", "len", "dataset_utils.SubSequence", "ValueError", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_task_labels_sequence"], ["", "def", "_initialize_task_labels_sequence", "(", "\n", "self", ",", "dataset", ",", "\n", "task_labels", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", ")", "->", "Sequence", "[", "int", "]", ":", "\n", "\n", "        ", "if", "task_labels", "is", "not", "None", ":", "\n", "# The task_labels parameter is kind of ambiguous...", "\n", "# it may either be the list of task labels of the required subset", "\n", "# or it may be the list of task labels of the original dataset.", "\n", "# Simple solution: check the length of task_labels!", "\n", "# However, if task_labels, the original dataset and this subset have", "\n", "# the same size, then task_labels is considered to contain the task", "\n", "# labels for the subset!", "\n", "\n", "            ", "if", "isinstance", "(", "task_labels", ",", "int", ")", ":", "\n", "# Simplest case: constant task label", "\n", "                ", "return", "ConstantSequence", "(", "task_labels", ",", "len", "(", "dataset", ")", ")", "\n", "", "elif", "len", "(", "task_labels", ")", "==", "len", "(", "self", ".", "_original_dataset", ")", "and", "not", "len", "(", "task_labels", ")", "==", "len", "(", "dataset", ")", ":", "\n", "# task_labels refers to the original dataset ...", "\n", "                ", "return", "SubSequence", "(", "task_labels", ",", "indices", "=", "self", ".", "_indices", ",", "\n", "converter", "=", "int", ")", "\n", "", "elif", "len", "(", "task_labels", ")", "==", "len", "(", "dataset", ")", ":", "\n", "# One label for each instance", "\n", "                ", "return", "SubSequence", "(", "task_labels", ",", "converter", "=", "int", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Invalid amount of task labels. It must be equal to the '", "\n", "'number of patterns in the subset. '", "\n", "'Got {}, expected {}!'", ".", "format", "(", "\n", "len", "(", "task_labels", ")", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "", "", "return", "super", "(", ")", ".", "_initialize_task_labels_sequence", "(", "dataset", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._set_original_dataset_transform_group": [[1245, 1256], ["isinstance", "avalanche_dataset.AvalancheSubset._original_dataset.with_transforms", "avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], ["", "def", "_set_original_dataset_transform_group", "(", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_original_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "if", "self", ".", "_original_dataset", ".", "current_transform_group", "==", "group_name", ":", "\n", "# Prevents a huge slowdown in some corner cases", "\n", "# (apart from being actually more performant)", "\n", "                ", "return", "\n", "\n", "", "self", ".", "_original_dataset", "=", "self", ".", "_original_dataset", ".", "with_transforms", "(", "group_name", ")", "\n", "\n", "self", ".", "_replace_original_dataset_reference", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._freeze_original_dataset": [[1257, 1263], ["isinstance", "avalanche_dataset.AvalancheSubset._original_dataset.freeze_group_transforms", "avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_group_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], ["", "", "def", "_freeze_original_dataset", "(", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_original_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "self", ".", "_original_dataset", "=", "self", ".", "_original_dataset", ".", "freeze_group_transforms", "(", "group_name", ")", "\n", "\n", "self", ".", "_replace_original_dataset_reference", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._replace_original_dataset_group": [[1264, 1272], ["isinstance", "avalanche_dataset.AvalancheSubset._original_dataset.replace_transforms", "avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.replace_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], ["", "", "def", "_replace_original_dataset_group", "(", "\n", "self", ",", "transform", ":", "XTransform", ",", "target_transform", ":", "YTransform", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_original_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "self", ".", "_original_dataset", "=", "self", ".", "_original_dataset", ".", "replace_transforms", "(", "\n", "transform", ",", "target_transform", ")", "\n", "\n", "self", ".", "_replace_original_dataset_reference", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._add_original_dataset_group": [[1273, 1280], ["isinstance", "avalanche_dataset.AvalancheSubset._original_dataset.add_transforms_group", "avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms_group", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._replace_original_dataset_reference"], ["", "", "def", "_add_original_dataset_group", "(", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_original_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "self", ".", "_original_dataset", "=", "self", ".", "_original_dataset", ".", "add_transforms_group", "(", "\n", "group_name", ",", "None", ",", "None", ")", "\n", "\n", "self", ".", "_replace_original_dataset_reference", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._add_groups_from_original_dataset": [[1281, 1288], ["isinstance", "avalanche_dataset.AvalancheSubset._original_dataset.transform_groups.keys"], "methods", ["None"], ["", "", "def", "_add_groups_from_original_dataset", "(", "\n", "self", ",", "dataset", ",", "transform_groups", ")", "->", "None", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_original_dataset", ",", "AvalancheDataset", ")", ":", "\n", "            ", "for", "original_dataset_group", "in", "self", ".", "_original_dataset", ".", "transform_groups", ".", "keys", "(", ")", ":", "\n", "                ", "if", "original_dataset_group", "not", "in", "transform_groups", ":", "\n", "                    ", "transform_groups", "[", "original_dataset_group", "]", "=", "(", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._flatten_dataset": [[1289, 1349], ["isinstance", "avalanche_dataset.AvalancheDataset._borrow_transformations", "torch.utils.data.dataset.Subset", "dataset_utils.ClassificationSubset", "new_class_mapping.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._borrow_transformations"], ["", "", "", "", "def", "_flatten_dataset", "(", "self", ")", ":", "\n", "# Flattens this subset by borrowing indices and class mappings from", "\n", "# the original dataset (if it's an AvalancheSubset or PyTorch Subset)", "\n", "\n", "        ", "if", "isinstance", "(", "self", ".", "_original_dataset", ",", "AvalancheSubset", ")", ":", "\n", "# In order to flatten the subset, we have to integrate the", "\n", "# transformations (also frozen ones!)", "\n", "            ", "AvalancheDataset", ".", "_borrow_transformations", "(", "\n", "self", ".", "_original_dataset", ",", "self", ".", "transform_groups", ",", "\n", "self", ".", "_frozen_transforms", ")", "\n", "\n", "# We need to reload transformations after borrowing from the subset", "\n", "# This assumes that _flatten_dataset is called by __init__!", "\n", "self", ".", "transform", ",", "self", ".", "target_transform", "=", "self", ".", "transform_groups", "[", "self", ".", "current_transform_group", "]", "\n", "\n", "forward_dataset", "=", "self", ".", "_original_dataset", ".", "_original_dataset", "\n", "forward_indices", "=", "self", ".", "_original_dataset", ".", "_indices", "\n", "forward_class_mapping", "=", "self", ".", "_original_dataset", ".", "_class_mapping", "\n", "\n", "if", "self", ".", "_class_mapping", "is", "not", "None", ":", "\n", "\n", "                ", "if", "forward_class_mapping", "is", "not", "None", ":", "\n", "\n", "                    ", "new_class_mapping", "=", "[", "]", "\n", "for", "mapped_class", "in", "forward_class_mapping", ":", "\n", "# -1 is sometimes used to mark unused classes", "\n", "# shouldn't be a problem (if it is, is not our fault)", "\n", "                        ", "if", "mapped_class", "==", "-", "1", ":", "\n", "                            ", "forward_mapped", "=", "-", "1", "\n", "", "else", ":", "\n", "# forward_mapped may be -1", "\n", "                            ", "forward_mapped", "=", "self", ".", "_class_mapping", "[", "mapped_class", "]", "\n", "\n", "", "new_class_mapping", ".", "append", "(", "forward_mapped", ")", "\n", "", "", "else", ":", "\n", "                    ", "new_class_mapping", "=", "self", ".", "_class_mapping", "\n", "", "", "else", ":", "\n", "                ", "new_class_mapping", "=", "forward_class_mapping", "# May be None", "\n", "\n", "", "if", "self", ".", "_indices", "is", "not", "None", ":", "\n", "                ", "if", "forward_indices", "is", "not", "None", ":", "\n", "                    ", "new_indices", "=", "[", "forward_indices", "[", "x", "]", "for", "x", "in", "self", ".", "_indices", "]", "\n", "", "else", ":", "\n", "                    ", "new_indices", "=", "self", ".", "_indices", "\n", "", "", "else", ":", "\n", "                ", "new_indices", "=", "forward_indices", "# May be None", "\n", "\n", "", "self", ".", "_original_dataset", "=", "forward_dataset", "\n", "self", ".", "_indices", "=", "new_indices", "\n", "self", ".", "_class_mapping", "=", "new_class_mapping", "\n", "if", "new_class_mapping", "is", "None", ":", "\n", "# Subset", "\n", "                ", "self", ".", "_dataset", "=", "Subset", "(", "forward_dataset", ",", "\n", "indices", "=", "new_indices", ")", "\n", "", "else", ":", "\n", "# ClassificationSubset", "\n", "                ", "self", ".", "_dataset", "=", "ClassificationSubset", "(", "\n", "forward_dataset", ",", "indices", "=", "new_indices", ",", "\n", "class_mapping", "=", "new_class_mapping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheSubset._replace_original_dataset_reference": [[1380, 1390], ["isinstance", "dataset_utils.ClassificationSubset", "isinstance", "torch.utils.data.dataset.Subset"], "methods", ["None"], ["", "", "", "def", "_replace_original_dataset_reference", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "_dataset", ",", "ClassificationSubset", ")", ":", "\n", "            ", "self", ".", "_dataset", "=", "ClassificationSubset", "(", "\n", "self", ".", "_original_dataset", ",", "indices", "=", "self", ".", "_indices", ",", "\n", "class_mapping", "=", "self", ".", "_class_mapping", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "_dataset", ",", "Subset", ")", ":", "\n", "            ", "self", ".", "_dataset", "=", "Subset", "(", "self", ".", "_original_dataset", ",", "\n", "indices", "=", "self", ".", "_indices", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dataset", "=", "self", ".", "_original_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheTensorDataset.__init__": [[1400, 1493], ["isinstance", "super().__init__", "ValueError", "len", "ValueError", "min", "dataset_utils.SequenceDataset", "dataset_utils.SequenceDataset", "len", "min", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "*", "dataset_tensors", ":", "Sequence", ",", "\n", "transform", ":", "Callable", "[", "[", "Any", "]", ",", "Any", "]", "=", "None", ",", "\n", "target_transform", ":", "Callable", "[", "[", "int", "]", ",", "int", "]", "=", "None", ",", "\n", "transform_groups", ":", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "\n", "YTransform", "]", "]", "=", "None", ",", "\n", "initial_transform_group", ":", "str", "=", "'train'", ",", "\n", "task_labels", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "targets", ":", "Union", "[", "Sequence", "[", "TTargetType", "]", ",", "int", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "\n", "AvalancheDatasetType", ".", "UNDEFINED", ",", "\n", "collate_fn", ":", "Callable", "[", "[", "List", "]", ",", "Any", "]", "=", "None", ",", "\n", "targets_adapter", ":", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``AvalancheTensorDataset`` instance.\n\n        :param dataset_tensors: Sequences, Tensors or ndarrays representing the\n            content of the dataset.\n        :param transform: A function/transform that takes in a single element\n            from the first tensor and returns a transformed version.\n        :param target_transform: A function/transform that takes a single\n            element of the second tensor and transforms it.\n        :param transform_groups: A dictionary containing the transform groups.\n            Transform groups are used to quickly switch between training and\n            eval (test) transformations. This becomes useful when in need to\n            test on the training dataset as test transformations usually don't\n            contain random augmentations. ``AvalancheDataset`` natively supports\n            the 'train' and 'eval' groups by calling the ``train()`` and\n            ``eval()`` methods. When using custom groups one can use the\n            ``with_transforms(group_name)`` method instead. Defaults to None,\n            which means that the current transforms will be used to\n            handle both 'train' and 'eval' groups (just like in standard\n            ``torchvision`` datasets).\n        :param initial_transform_group: The name of the transform group\n            to be used. Defaults to 'train'.\n        :param task_labels: The task labels for each pattern. Must be a sequence\n            of ints, one for each pattern in the dataset. Alternatively can be a\n            single int value, in which case that value will be used as the task\n            label for all the instances. Defaults to None, which means that a\n            default task label \"0\" will be applied to all patterns.\n        :param targets: The label of each pattern. Defaults to None, which\n            means that the targets will be retrieved from the dataset.\n            Otherwise, can be 1) a sequence of values containing as many\n            elements as the number of patterns, or 2) the index of the sequence\n            to use as the targets field. When using the default value of None,\n            the targets field will be populated using the second\n            tensor. If dataset is made of only one tensor, then that tensor will\n            be used for the targets field, too.\n        :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n            Setting this parameter will automatically set a proper value for\n            `collate_fn` and `targets_adapter`. If this parameter is set to a\n            value different from UNDEFINED then `collate_fn` and\n            `targets_adapter` must not be set.\n        :param collate_fn: The function to use when slicing to merge single\n            patterns. In the future this function may become the function\n            used in the data loading process, too.\n        :param targets_adapter: A function used to convert the values of the\n            targets field. Defaults to None. Note: the adapter will not change\n            the value of the second element returned by `__getitem__`.\n            The adapter is used to adapt the values of the targets field only.\n        \"\"\"", "\n", "\n", "if", "dataset_type", "!=", "AvalancheDatasetType", ".", "UNDEFINED", "and", "(", "collate_fn", "is", "not", "None", "or", "targets_adapter", "is", "not", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'dataset_type {} can\\'t be used with custom collate_fn '", "\n", "'or targets_adapter. Only the UNDEFINED type supports '", "\n", "'custom collate_fn or targets_adapter '", "\n", "'parameters.'", ".", "format", "(", "dataset_type", ")", ")", "\n", "\n", "", "if", "len", "(", "dataset_tensors", ")", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'At least one sequence must be passed'", ")", "\n", "\n", "", "if", "targets", "is", "None", ":", "\n", "            ", "targets", "=", "min", "(", "1", ",", "len", "(", "dataset_tensors", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "targets", ",", "int", ")", ":", "\n", "            ", "base_dataset", "=", "SequenceDataset", "(", "*", "dataset_tensors", ",", "targets", "=", "targets", ")", "\n", "targets", "=", "None", "\n", "", "else", ":", "\n", "            ", "base_dataset", "=", "SequenceDataset", "(", "*", "dataset_tensors", ",", "\n", "targets", "=", "min", "(", "1", ",", "len", "(", "dataset_tensors", ")", ")", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "base_dataset", ",", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "initial_transform_group", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "targets", "=", "targets", ",", "\n", "dataset_type", "=", "dataset_type", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "targets_adapter", "=", "targets_adapter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset.__init__": [[1506, 1631], ["list", "avalanche_dataset.AvalancheConcatDataset._get_dataset_type_collate_and_adapter", "torch.utils.data.dataset.ConcatDataset.cumsum", "sum", "avalanche_dataset.AvalancheConcatDataset._adapt_concat_datasets", "super().__init__", "len", "avalanche_dataset.AvalancheConcatDataset._concat_task_labels", "avalanche_dataset.AvalancheConcatDataset._concat_targets", "dataset_definitions.ClassificationDataset", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._get_dataset_type_collate_and_adapter", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._adapt_concat_datasets", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._concat_task_labels", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._concat_targets"], ["def", "__init__", "(", "self", ",", "\n", "datasets", ":", "Collection", "[", "SupportedDataset", "]", ",", "\n", "*", ",", "\n", "transform", ":", "Callable", "[", "[", "Any", "]", ",", "Any", "]", "=", "None", ",", "\n", "target_transform", ":", "Callable", "[", "[", "int", "]", ",", "int", "]", "=", "None", ",", "\n", "transform_groups", ":", "Dict", "[", "str", ",", "Tuple", "[", "XTransform", ",", "\n", "YTransform", "]", "]", "=", "None", ",", "\n", "initial_transform_group", ":", "str", "=", "None", ",", "\n", "task_labels", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", ",", "\n", "Sequence", "[", "Sequence", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "targets", ":", "Union", "[", "Sequence", "[", "TTargetType", "]", ",", "\n", "Sequence", "[", "Sequence", "[", "TTargetType", "]", "]", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ",", "\n", "collate_fn", ":", "Callable", "[", "[", "List", "]", ",", "Any", "]", "=", "None", ",", "\n", "targets_adapter", ":", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``AvalancheConcatDataset`` instance.\n\n        :param datasets: A collection of datasets.\n        :param transform: A function/transform that takes the X value of a\n            pattern from the original dataset and returns a transformed version.\n        :param target_transform: A function/transform that takes in the target\n            and transforms it.\n        :param transform_groups: A dictionary containing the transform groups.\n            Transform groups are used to quickly switch between training and\n            eval (test) transformations. This becomes useful when in need to\n            test on the training dataset as test transformations usually don't\n            contain random augmentations. ``AvalancheDataset`` natively supports\n            the 'train' and 'eval' groups by calling the ``train()`` and\n            ``eval()`` methods. When using custom groups one can use the\n            ``with_transforms(group_name)`` method instead. Defaults to None,\n            which means that the current transforms will be used to\n            handle both 'train' and 'eval' groups (just like in standard\n            ``torchvision`` datasets).\n        :param initial_transform_group: The name of the initial transform group\n            to be used. Defaults to None, which means that if all\n            AvalancheDatasets in the input datasets list agree on a common\n            group (the \"current group\" is the same for all datasets), then that\n            group will be used as the initial one. If the list of input datasets\n            does not contain an AvalancheDataset or if the AvalancheDatasets\n            do not agree on a common group, then 'train' will be used.\n        :param targets: The label of each pattern. Can either be a sequence of\n            labels or, alternatively, a sequence containing sequences of labels\n            (one for each dataset to be concatenated). Defaults to None, which\n            means that the targets will be retrieved from the datasets (if\n            possible).\n        :param task_labels: The task labels for each pattern. Must be a sequence\n            of ints, one for each pattern in the dataset. Alternatively, task\n            labels can be expressed as a sequence containing sequences of ints\n            (one for each dataset to be concatenated) or even a single int,\n            in which case that value will be used as the task label for all\n            instances. Defaults to None, which means that the dataset will try\n            to obtain the task labels from the original datasets. If no task\n            labels could be found for a dataset, a default task label \"0\" will\n            be applied to all patterns of that dataset.\n        :param dataset_type: The type of the dataset. Defaults to None,\n            which means that the type will be inferred from the list of\n            input datasets. When `dataset_type` is None and the list of datasets\n            contains incompatible types, an error will be raised.\n            A list of datasets is compatible if they all have\n            the same type. Datasets that are not instances of `AvalancheDataset`\n            and instances of `AvalancheDataset` with type `UNDEFINED`\n            are always compatible with other types.\n            When the `dataset_type` is different than UNDEFINED, a\n            proper value for `collate_fn` and `targets_adapter` will be set.\n            If the `dataset_type` is different than UNDEFINED, then\n            `collate_fn` and `targets_adapter` must not be set.\n        :param collate_fn: The function to use when slicing to merge single\n            patterns. In the future this function may become the function\n            used in the data loading process, too. If None, the constructor\n            will check if a `collate_fn` field exists in the first dataset. If\n            no such field exists, the default collate function will be used.\n            Beware that the chosen collate function will be applied to all\n            the concatenated datasets even if a different collate is defined\n            in different datasets.\n        :param targets_adapter: A function used to convert the values of the\n            targets field. Defaults to None. Note: the adapter will not change\n            the value of the second element returned by `__getitem__`.\n            The adapter is used to adapt the values of the targets field only.\n        \"\"\"", "\n", "dataset_list", "=", "list", "(", "datasets", ")", "\n", "\n", "dataset_type", ",", "collate_fn", ",", "targets_adapter", "=", "self", ".", "_get_dataset_type_collate_and_adapter", "(", "\n", "dataset_list", ",", "dataset_type", ",", "collate_fn", ",", "targets_adapter", ")", "\n", "\n", "self", ".", "_dataset_list", "=", "dataset_list", "\n", "self", ".", "_datasets_lengths", "=", "[", "len", "(", "dataset", ")", "for", "dataset", "in", "dataset_list", "]", "\n", "self", ".", "_datasets_cumulative_lengths", "=", "ConcatDataset", ".", "cumsum", "(", "dataset_list", ")", "\n", "self", ".", "_overall_length", "=", "sum", "(", "self", ".", "_datasets_lengths", ")", "\n", "\n", "if", "initial_transform_group", "is", "None", ":", "\n", "            ", "uniform_group", "=", "None", "\n", "for", "d_set", "in", "self", ".", "_dataset_list", ":", "\n", "                ", "if", "isinstance", "(", "d_set", ",", "AvalancheDataset", ")", ":", "\n", "                    ", "if", "uniform_group", "is", "None", ":", "\n", "                        ", "uniform_group", "=", "d_set", ".", "current_transform_group", "\n", "", "else", ":", "\n", "                        ", "if", "uniform_group", "!=", "d_set", ".", "current_transform_group", ":", "\n", "                            ", "uniform_group", "=", "None", "\n", "break", "\n", "\n", "", "", "", "", "if", "uniform_group", "is", "None", ":", "\n", "                ", "initial_transform_group", "=", "'train'", "\n", "", "else", ":", "\n", "                ", "initial_transform_group", "=", "uniform_group", "\n", "\n", "", "", "if", "task_labels", "is", "not", "None", ":", "\n", "            ", "task_labels", "=", "self", ".", "_concat_task_labels", "(", "task_labels", ")", "\n", "\n", "", "if", "targets", "is", "not", "None", ":", "\n", "            ", "targets", "=", "self", ".", "_concat_targets", "(", "targets", ")", "\n", "\n", "", "self", ".", "_adapt_concat_datasets", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "ClassificationDataset", "(", ")", ",", "# not used", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "initial_transform_group", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "targets", "=", "targets", ",", "\n", "dataset_type", "=", "dataset_type", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "targets_adapter", "=", "targets_adapter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._get_dataset_type_collate_and_adapter": [[1632, 1675], ["set", "isinstance", "len", "ValueError", "ValueError", "getattr", "len", "next", "set.add", "list", "iter"], "methods", ["None"], ["", "def", "_get_dataset_type_collate_and_adapter", "(", "\n", "self", ",", "datasets", ",", "dataset_type", ",", "collate_fn", ",", "targets_adapter", ")", ":", "\n", "\n", "        ", "if", "dataset_type", "is", "not", "None", ":", "\n", "            ", "return", "dataset_type", ",", "collate_fn", ",", "targets_adapter", "\n", "\n", "", "identified_types", "=", "set", "(", ")", "\n", "first_collate_fn", "=", "None", "\n", "\n", "for", "dataset", "in", "datasets", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "if", "dataset", ".", "dataset_type", "!=", "AvalancheDatasetType", ".", "UNDEFINED", ":", "\n", "                    ", "identified_types", ".", "add", "(", "dataset", ".", "dataset_type", ")", "\n", "\n", "", "", "if", "first_collate_fn", "is", "None", ":", "\n", "                ", "first_collate_fn", "=", "getattr", "(", "dataset", ",", "'collate_fn'", ",", "None", ")", "\n", "\n", "", "", "if", "len", "(", "identified_types", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Error trying to infer a common dataset type while '", "\n", "'concatenating different datasets. '", "\n", "'Incompatible types: {}'", ".", "format", "(", "list", "(", "identified_types", ")", ")", ")", "\n", "", "elif", "len", "(", "identified_types", ")", "==", "0", ":", "\n", "            ", "dataset_type", "=", "AvalancheDatasetType", ".", "UNDEFINED", "\n", "", "else", ":", "\n", "# len(identified_types) == 1", "\n", "            ", "dataset_type", "=", "next", "(", "iter", "(", "identified_types", ")", ")", "\n", "\n", "", "if", "dataset_type", "!=", "AvalancheDatasetType", ".", "UNDEFINED", "and", "(", "collate_fn", "is", "not", "None", "or", "targets_adapter", "is", "not", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'dataset_type {} was inferred from the list of '", "\n", "'concatenated dataset. This dataset type can\\'t be used '", "\n", "'with custom collate_fn or targets_adapter '", "\n", "'parameters. Only the UNDEFINED type supports '", "\n", "'custom collate_fn or targets_adapter '", "\n", "'parameters.'", ".", "format", "(", "dataset_type", ")", ")", "\n", "\n", "", "if", "collate_fn", "is", "None", "and", "dataset_type", "==", "AvalancheDatasetType", ".", "UNDEFINED", ":", "\n", "            ", "collate_fn", "=", "first_collate_fn", "\n", "\n", "", "return", "dataset_type", ",", "collate_fn", ",", "targets_adapter", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset.__len__": [[1676, 1678], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_overall_length", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._get_single_item": [[1679, 1687], ["dataset_utils.find_list_from_index", "avalanche_dataset.AvalancheConcatDataset._process_pattern"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.find_list_from_index", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._process_pattern"], ["", "def", "_get_single_item", "(", "self", ",", "idx", ":", "int", ")", ":", "\n", "        ", "dataset_idx", ",", "internal_idx", "=", "find_list_from_index", "(", "\n", "idx", ",", "self", ".", "_datasets_lengths", ",", "self", ".", "_overall_length", ",", "\n", "cumulative_sizes", "=", "self", ".", "_datasets_cumulative_lengths", ")", "\n", "\n", "single_element", "=", "self", ".", "_dataset_list", "[", "dataset_idx", "]", "[", "internal_idx", "]", "\n", "\n", "return", "self", ".", "_process_pattern", "(", "single_element", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset": [[1688, 1695], ["super()._fork_dataset", "list"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._fork_dataset"], ["", "def", "_fork_dataset", "(", "self", ":", "TAvalancheDataset", ")", "->", "TAvalancheDataset", ":", "\n", "        ", "dataset_copy", "=", "super", "(", ")", ".", "_fork_dataset", "(", ")", "\n", "\n", "dataset_copy", ".", "_dataset_list", "=", "list", "(", "dataset_copy", ".", "_dataset_list", ")", "\n", "# Note: there is no need to duplicate _datasets_lengths", "\n", "\n", "return", "dataset_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_targets_sequence": [[1696, 1718], ["enumerate", "dataset_utils.LazyConcatTargets", "targets_list.append", "len", "ValueError", "super()._initialize_targets_sequence", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_targets_sequence"], ["", "def", "_initialize_targets_sequence", "(", "\n", "self", ",", "dataset", ",", "targets", ",", "dataset_type", ",", "targets_adapter", ")", "->", "Sequence", "[", "TTargetType", "]", ":", "\n", "        ", "if", "targets", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "targets", ")", "!=", "self", ".", "_overall_length", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Invalid amount of target labels. It must be equal to the '", "\n", "'number of patterns in the dataset. Got {}, expected '", "\n", "'{}!'", ".", "format", "(", "len", "(", "targets", ")", ",", "self", ".", "_overall_length", ")", ")", "\n", "\n", "", "return", "targets", "\n", "\n", "", "targets_list", "=", "[", "]", "\n", "# Could be easily done with a single line of code", "\n", "# This however, allows the user to better check which was the", "\n", "# problematic dataset by using a debugger.", "\n", "for", "dataset_idx", ",", "single_dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "targets_list", ".", "append", "(", "super", "(", ")", ".", "_initialize_targets_sequence", "(", "\n", "single_dataset", ",", "None", ",", "dataset_type", ",", "targets_adapter", "\n", ")", ")", "\n", "\n", "", "return", "LazyConcatTargets", "(", "targets_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_task_labels_sequence": [[1719, 1740], ["enumerate", "dataset_utils.LazyConcatTargets", "isinstance", "dataset_utils.SubSequence", "concat_t_labels.append", "dataset_utils.ConstantSequence", "super()._initialize_task_labels_sequence", "len", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_task_labels_sequence"], ["", "def", "_initialize_task_labels_sequence", "(", "\n", "self", ",", "dataset", ",", "task_labels", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", ")", "->", "Sequence", "[", "int", "]", ":", "\n", "        ", "if", "task_labels", "is", "not", "None", ":", "\n", "# task_labels has priority over the dataset fields", "\n", "\n", "            ", "if", "isinstance", "(", "task_labels", ",", "int", ")", ":", "\n", "                ", "return", "ConstantSequence", "(", "task_labels", ",", "self", ".", "_overall_length", ")", "\n", "", "elif", "len", "(", "task_labels", ")", "!=", "self", ".", "_overall_length", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Invalid amount of task labels. It must be equal to the '", "\n", "'number of patterns in the dataset. Got {}, expected '", "\n", "'{}!'", ".", "format", "(", "len", "(", "task_labels", ")", ",", "self", ".", "_overall_length", ")", ")", "\n", "", "return", "SubSequence", "(", "task_labels", ",", "converter", "=", "int", ")", "\n", "\n", "", "concat_t_labels", "=", "[", "]", "\n", "for", "dataset_idx", ",", "single_dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "concat_t_labels", ".", "append", "(", "super", "(", ")", ".", "_initialize_task_labels_sequence", "(", "\n", "single_dataset", ",", "None", ")", ")", "\n", "\n", "", "return", "LazyConcatTargets", "(", "concat_t_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._initialize_collate_fn": [[1741, 1749], ["hasattr", "getattr", "len"], "methods", ["None"], ["", "def", "_initialize_collate_fn", "(", "self", ",", "dataset", ",", "dataset_type", ",", "collate_fn", ")", ":", "\n", "        ", "if", "collate_fn", "is", "not", "None", ":", "\n", "            ", "return", "collate_fn", "\n", "\n", "", "if", "len", "(", "self", ".", "_dataset_list", ")", ">", "0", "and", "hasattr", "(", "self", ".", "_dataset_list", "[", "0", "]", ",", "'collate_fn'", ")", ":", "\n", "            ", "return", "getattr", "(", "self", ".", "_dataset_list", "[", "0", "]", ",", "'collate_fn'", ")", "\n", "", "return", "default_collate", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._set_original_dataset_transform_group": [[1750, 1761], ["enumerate", "isinstance", "dataset.with_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.with_transforms"], ["", "def", "_set_original_dataset_transform_group", "(", "\n", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "for", "dataset_idx", ",", "dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "if", "dataset", ".", "current_transform_group", "==", "group_name", ":", "\n", "# Prevents a huge slowdown in some corner cases", "\n", "# (apart from being actually more performant)", "\n", "                    ", "continue", "\n", "\n", "", "self", ".", "_dataset_list", "[", "dataset_idx", "]", "=", "dataset", ".", "with_transforms", "(", "group_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._freeze_original_dataset": [[1762, 1768], ["enumerate", "isinstance", "dataset.freeze_group_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_group_transforms"], ["", "", "", "def", "_freeze_original_dataset", "(", "\n", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "for", "dataset_idx", ",", "dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "self", ".", "_dataset_list", "[", "dataset_idx", "]", "=", "dataset", ".", "freeze_group_transforms", "(", "group_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._replace_original_dataset_group": [[1769, 1775], ["enumerate", "isinstance", "dataset.replace_transforms"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.replace_transforms"], ["", "", "", "def", "_replace_original_dataset_group", "(", "\n", "self", ",", "transform", ":", "XTransform", ",", "target_transform", ":", "YTransform", ")", "->", "None", ":", "\n", "        ", "for", "dataset_idx", ",", "dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "self", ".", "_dataset_list", "[", "dataset_idx", "]", "=", "dataset", ".", "replace_transforms", "(", "transform", ",", "target_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._add_original_dataset_group": [[1776, 1782], ["enumerate", "isinstance", "dataset.add_transforms_group"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms_group"], ["", "", "", "def", "_add_original_dataset_group", "(", "\n", "self", ",", "group_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "for", "dataset_idx", ",", "dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "self", ".", "_dataset_list", "[", "dataset_idx", "]", "=", "dataset", ".", "add_transforms_group", "(", "group_name", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._add_groups_from_original_dataset": [[1783, 1790], ["enumerate", "isinstance", "dataset.transform_groups.keys"], "methods", ["None"], ["", "", "", "def", "_add_groups_from_original_dataset", "(", "\n", "self", ",", "dataset", ",", "transform_groups", ")", "->", "None", ":", "\n", "        ", "for", "dataset_idx", ",", "dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "for", "original_dataset_group", "in", "dataset", ".", "transform_groups", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "original_dataset_group", "not", "in", "transform_groups", ":", "\n", "                        ", "transform_groups", "[", "original_dataset_group", "]", "=", "(", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._adapt_concat_datasets": [[1791, 1804], ["set", "enumerate", "isinstance", "isinstance", "set.update", "dataset.transform_groups.keys", "dataset.add_transforms_group"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.add_transforms_group"], ["", "", "", "", "", "def", "_adapt_concat_datasets", "(", "self", ")", ":", "\n", "        ", "all_groups", "=", "set", "(", ")", "\n", "\n", "for", "dataset", "in", "self", ".", "_dataset_list", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "all_groups", ".", "update", "(", "dataset", ".", "transform_groups", ".", "keys", "(", ")", ")", "\n", "\n", "", "", "for", "dataset_idx", ",", "dataset", "in", "enumerate", "(", "self", ".", "_dataset_list", ")", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                ", "for", "group_name", "in", "all_groups", ":", "\n", "                    ", "if", "group_name", "not", "in", "dataset", ".", "transform_groups", ":", "\n", "                        ", "self", ".", "_dataset_list", "[", "dataset_idx", "]", "=", "dataset", ".", "add_transforms_group", "(", "group_name", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._concat_task_labels": [[1805, 1820], ["isinstance", "isinstance", "dataset_utils.LazyConcatIntTargets"], "methods", ["None"], ["", "", "", "", "", "@", "staticmethod", "\n", "def", "_concat_task_labels", "(", "task_labels", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", ",", "\n", "Sequence", "[", "Sequence", "[", "int", "]", "]", "]", ")", ":", "\n", "        ", "if", "isinstance", "(", "task_labels", ",", "int", ")", ":", "\n", "# A single value has been passed -> use it for all instances", "\n", "# The value is returned as is because it's already managed when in", "\n", "# this form (in _initialize_task_labels_sequence).", "\n", "            ", "return", "task_labels", "\n", "", "elif", "isinstance", "(", "task_labels", "[", "0", "]", ",", "int", ")", ":", "\n", "# Flat list of task labels -> just return it.", "\n", "# The constructor will check if it has the correct size.", "\n", "            ", "return", "task_labels", "\n", "", "else", ":", "\n", "# One list for each dataset, concat them.", "\n", "            ", "return", "LazyConcatIntTargets", "(", "task_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._concat_targets": [[1821, 1828], ["isinstance", "dataset_utils.LazyConcatTargets"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_concat_targets", "(", "targets", ":", "Union", "[", "Sequence", "[", "TTargetType", "]", ",", "\n", "Sequence", "[", "Sequence", "[", "TTargetType", "]", "]", "]", ")", ":", "\n", "        ", "if", "isinstance", "(", "targets", "[", "0", "]", ",", "Sequence", ")", ":", "\n", "            ", "return", "LazyConcatTargets", "(", "targets", ")", "\n", "", "else", ":", "\n", "            ", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._flatten_dataset": [[1829, 1862], ["torch.utils.data.dataset.ConcatDataset.cumsum", "sum", "isinstance", "len", "dataset._has_own_transformations", "isinstance", "flattened_list.append", "flattened_list.extend", "avalanche_dataset.AvalancheConcatDataset._flatten_subset_concat_branch", "flattened_list.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._has_own_transformations", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._flatten_subset_concat_branch"], ["", "", "def", "_flatten_dataset", "(", "self", ")", ":", "\n", "# Flattens this subset by borrowing the list of concatenated datasets", "\n", "# from the original datasets (if they're 'AvalancheConcatSubset's or", "\n", "# PyTorch 'ConcatDataset's)", "\n", "\n", "        ", "flattened_list", "=", "[", "]", "\n", "for", "dataset", "in", "self", ".", "_dataset_list", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "AvalancheConcatDataset", ")", ":", "\n", "                ", "if", "dataset", ".", "_has_own_transformations", "(", ")", ":", "\n", "# Can't flatten as the dataset has custom transformations", "\n", "                    ", "flattened_list", ".", "append", "(", "dataset", ")", "\n", "", "else", ":", "\n", "                    ", "flattened_list", ".", "extend", "(", "dataset", ".", "_dataset_list", ")", "\n", "\n", "# PyTorch ConcatDataset doesn't have custom transformations", "\n", "# --------", "\n", "# Flattening PyTorch ConcatDatasets has been temporarily", "\n", "# disabled as the semantic of transformation groups collide", "\n", "# with the flattening process: PyTorch ConcatDataset doesn't have", "\n", "# transform groups and flattening it will expose the underlying", "\n", "# concatenated datasets list, which may contain 'AvalancheDataset's.", "\n", "# --------", "\n", "# elif isinstance(dataset, ConcatDataset):", "\n", "#    flattened_list.extend(dataset.datasets)", "\n", "", "", "elif", "isinstance", "(", "dataset", ",", "AvalancheSubset", ")", ":", "\n", "                ", "flattened_list", "+=", "self", ".", "_flatten_subset_concat_branch", "(", "dataset", ")", "\n", "", "else", ":", "\n", "                ", "flattened_list", ".", "append", "(", "dataset", ")", "\n", "\n", "", "", "self", ".", "_dataset_list", "=", "flattened_list", "\n", "self", ".", "_datasets_lengths", "=", "[", "len", "(", "dataset", ")", "for", "dataset", "in", "flattened_list", "]", "\n", "self", ".", "_datasets_cumulative_lengths", "=", "ConcatDataset", ".", "cumsum", "(", "flattened_list", ")", "\n", "self", ".", "_overall_length", "=", "sum", "(", "self", ".", "_datasets_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._flatten_subset_concat_branch": [[1863, 1918], ["concat_dataset._has_own_transformations", "enumerate", "isinstance", "dataset_utils.find_list_from_index", "last_c_idxs.append", "last_c_targets.append", "last_c_tasks.append", "result.append", "avalanche_dataset.AvalancheConcatDataset._make_similar_subset", "result.append", "avalanche_dataset.AvalancheConcatDataset._make_similar_subset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._has_own_transformations", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.find_list_from_index", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._make_similar_subset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._make_similar_subset"], ["", "def", "_flatten_subset_concat_branch", "(", "self", ",", "dataset", ":", "AvalancheSubset", ")", "->", "List", "[", "Dataset", "]", ":", "\n", "        ", "\"\"\"\n        Optimizes the dataset hierarchy in the corner case:\n\n        self -> [Subset, Subset, ] -> ConcatDataset -> [Dataset]\n\n        :param dataset: The dataset. This function returns [dataset] if the\n            dataset is not a subset containing a concat dataset (or if other\n            corner cases are encountered).\n        :return: The flattened list of datasets to be concatenated.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "dataset", ".", "_original_dataset", ",", "AvalancheConcatDataset", ")", ":", "\n", "            ", "return", "[", "dataset", "]", "\n", "\n", "", "concat_dataset", ":", "AvalancheConcatDataset", "=", "dataset", ".", "_original_dataset", "\n", "if", "concat_dataset", ".", "_has_own_transformations", "(", ")", ":", "\n", "# The dataset has custom transforms -> do nothing", "\n", "            ", "return", "[", "dataset", "]", "\n", "\n", "", "result", ":", "List", "[", "AvalancheSubset", "]", "=", "[", "]", "\n", "last_c_dataset", "=", "None", "\n", "last_c_idxs", "=", "[", "]", "\n", "last_c_targets", "=", "[", "]", "\n", "last_c_tasks", "=", "[", "]", "\n", "for", "subset_idx", ",", "idx", "in", "enumerate", "(", "dataset", ".", "_indices", ")", ":", "\n", "            ", "dataset_idx", ",", "internal_idx", "=", "find_list_from_index", "(", "\n", "idx", ",", "concat_dataset", ".", "_datasets_lengths", ",", "\n", "concat_dataset", ".", "_overall_length", ",", "\n", "cumulative_sizes", "=", "concat_dataset", ".", "_datasets_cumulative_lengths", ")", "\n", "\n", "if", "last_c_dataset", "is", "None", ":", "\n", "                ", "last_c_dataset", "=", "dataset_idx", "\n", "", "elif", "last_c_dataset", "!=", "dataset_idx", ":", "\n", "# Consolidate current subset", "\n", "                ", "result", ".", "append", "(", "AvalancheConcatDataset", ".", "_make_similar_subset", "(", "\n", "dataset", ",", "concat_dataset", ".", "_dataset_list", "[", "last_c_dataset", "]", ",", "\n", "last_c_idxs", ",", "last_c_targets", ",", "last_c_tasks", ")", ")", "\n", "\n", "# Switch to next dataset", "\n", "last_c_dataset", "=", "dataset_idx", "\n", "last_c_idxs", "=", "[", "]", "\n", "last_c_targets", "=", "[", "]", "\n", "last_c_tasks", "=", "[", "]", "\n", "\n", "", "last_c_idxs", ".", "append", "(", "internal_idx", ")", "\n", "last_c_targets", ".", "append", "(", "dataset", ".", "targets", "[", "subset_idx", "]", ")", "\n", "last_c_tasks", ".", "append", "(", "dataset", ".", "targets_task_labels", "[", "subset_idx", "]", ")", "\n", "\n", "", "if", "last_c_dataset", "is", "not", "None", ":", "\n", "            ", "result", ".", "append", "(", "AvalancheConcatDataset", ".", "_make_similar_subset", "(", "\n", "dataset", ",", "concat_dataset", ".", "_dataset_list", "[", "last_c_dataset", "]", ",", "\n", "last_c_idxs", ",", "last_c_targets", ",", "last_c_tasks", ")", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheConcatDataset._make_similar_subset": [[1919, 1944], ["dict", "dict", "avalanche_dataset.AvalancheDataset._borrow_transformations", "avalanche_dataset.AvalancheSubset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset._borrow_transformations"], ["", "@", "staticmethod", "\n", "def", "_make_similar_subset", "(", "subset", ",", "ref_dataset", ",", "indices", ",", "targets", ",", "tasks", ")", ":", "\n", "        ", "t_groups", "=", "dict", "(", ")", "\n", "f_groups", "=", "dict", "(", ")", "\n", "AvalancheDataset", ".", "_borrow_transformations", "(", "\n", "subset", ",", "t_groups", ",", "f_groups", ")", "\n", "\n", "collate_fn", "=", "None", "\n", "if", "subset", ".", "dataset_type", "==", "AvalancheDatasetType", ".", "UNDEFINED", ":", "\n", "            ", "collate_fn", "=", "subset", ".", "collate_fn", "\n", "\n", "", "result", "=", "AvalancheSubset", "(", "\n", "ref_dataset", ",", "\n", "indices", "=", "indices", ",", "\n", "class_mapping", "=", "subset", ".", "_class_mapping", ",", "\n", "transform_groups", "=", "t_groups", ",", "\n", "initial_transform_group", "=", "subset", ".", "current_transform_group", ",", "\n", "task_labels", "=", "tasks", ",", "\n", "targets", "=", "targets", ",", "\n", "dataset_type", "=", "subset", ".", "dataset_type", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", ")", "\n", "\n", "result", ".", "_frozen_transforms", "=", "f_groups", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.concat_datasets_sequentially": [[1946, 2030], ["range", "avalanche_dataset._count_unique", "len", "list", "new_class_ids_per_dataset.append", "remapped_train_datasets.append", "remapped_test_datasets.append", "avalanche_dataset.AvalancheConcatDataset", "avalanche_dataset.AvalancheConcatDataset", "range", "range", "avalanche_dataset.AvalancheSubset", "avalanche_dataset.AvalancheSubset", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._count_unique"], ["", "", "def", "concat_datasets_sequentially", "(", "\n", "train_dataset_list", ":", "Sequence", "[", "ISupportedClassificationDataset", "]", ",", "\n", "test_dataset_list", ":", "Sequence", "[", "ISupportedClassificationDataset", "]", ")", "->", "Tuple", "[", "AvalancheConcatDataset", ",", "\n", "AvalancheConcatDataset", ",", "\n", "List", "[", "list", "]", "]", ":", "\n", "    ", "\"\"\"\n    Concatenates a list of datasets. This is completely different from\n    :class:`ConcatDataset`, in which datasets are merged together without\n    other processing. Instead, this function re-maps the datasets class IDs.\n    For instance:\n    let the dataset[0] contain patterns of 3 different classes,\n    let the dataset[1] contain patterns of 2 different classes, then class IDs\n    will be mapped as follows:\n\n    dataset[0] class \"0\" -> new class ID is \"0\"\n\n    dataset[0] class \"1\" -> new class ID is \"1\"\n\n    dataset[0] class \"2\" -> new class ID is \"2\"\n\n    dataset[1] class \"0\" -> new class ID is \"3\"\n\n    dataset[1] class \"1\" -> new class ID is \"4\"\n\n    ... -> ...\n\n    dataset[-1] class \"C-1\" -> new class ID is \"overall_n_classes-1\"\n\n    In contrast, using PyTorch ConcatDataset:\n\n    dataset[0] class \"0\" -> ID is \"0\"\n\n    dataset[0] class \"1\" -> ID is \"1\"\n\n    dataset[0] class \"2\" -> ID is \"2\"\n\n    dataset[1] class \"0\" -> ID is \"0\"\n\n    dataset[1] class \"1\" -> ID is \"1\"\n\n    Note: ``train_dataset_list`` and ``test_dataset_list`` must have the same\n    number of datasets.\n\n    :param train_dataset_list: A list of training datasets\n    :param test_dataset_list: A list of test datasets\n\n    :returns: A concatenated dataset.\n    \"\"\"", "\n", "remapped_train_datasets", "=", "[", "]", "\n", "remapped_test_datasets", "=", "[", "]", "\n", "next_remapped_idx", "=", "0", "\n", "\n", "# Obtain the number of classes of each dataset", "\n", "classes_per_dataset", "=", "[", "\n", "_count_unique", "(", "train_dataset_list", "[", "dataset_idx", "]", ".", "targets", ",", "\n", "test_dataset_list", "[", "dataset_idx", "]", ".", "targets", ")", "\n", "for", "dataset_idx", "in", "range", "(", "len", "(", "train_dataset_list", ")", ")", "]", "\n", "\n", "new_class_ids_per_dataset", "=", "[", "]", "\n", "for", "dataset_idx", "in", "range", "(", "len", "(", "train_dataset_list", ")", ")", ":", "\n", "# The class IDs for this dataset will be in range", "\n", "# [n_classes_in_previous_datasets,", "\n", "#       n_classes_in_previous_datasets + classes_in_this_dataset)", "\n", "        ", "class_mapping", "=", "list", "(", "\n", "range", "(", "next_remapped_idx", ",", "\n", "next_remapped_idx", "+", "classes_per_dataset", "[", "dataset_idx", "]", ")", ")", "\n", "new_class_ids_per_dataset", ".", "append", "(", "class_mapping", ")", "\n", "\n", "train_set", "=", "train_dataset_list", "[", "dataset_idx", "]", "\n", "test_set", "=", "test_dataset_list", "[", "dataset_idx", "]", "\n", "\n", "# AvalancheSubset is used to apply the class IDs transformation.", "\n", "# Remember, the class_mapping parameter must be a list in which:", "\n", "# new_class_id = class_mapping[original_class_id]", "\n", "remapped_train_datasets", ".", "append", "(", "\n", "AvalancheSubset", "(", "train_set", ",", "class_mapping", "=", "class_mapping", ")", ")", "\n", "remapped_test_datasets", ".", "append", "(", "\n", "AvalancheSubset", "(", "test_set", ",", "class_mapping", "=", "class_mapping", ")", ")", "\n", "next_remapped_idx", "+=", "classes_per_dataset", "[", "dataset_idx", "]", "\n", "\n", "", "return", "(", "AvalancheConcatDataset", "(", "remapped_train_datasets", ")", ",", "\n", "AvalancheConcatDataset", "(", "remapped_test_datasets", ")", ",", "\n", "new_class_ids_per_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_avalanche_dataset": [[2032, 2053], ["avalanche_dataset.AvalancheDataset", "isinstance", "warnings.warn", "isinstance"], "function", ["None"], ["", "def", "as_avalanche_dataset", "(", "\n", "dataset", ":", "ISupportedClassificationDataset", "[", "T_co", "]", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ")", "->", "AvalancheDataset", "[", "T_co", ",", "TTargetType", "]", ":", "\n", "    ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", "and", "dataset_type", "is", "None", ":", "\n", "# There is no need to show the warning", "\n", "        ", "return", "dataset", "\n", "\n", "", "if", "dataset_type", "is", "None", ":", "\n", "        ", "warnings", ".", "warn", "(", "'\"as_avalanche_dataset\" was called without setting '", "\n", "'\"dataset_type\": this behaviour is deprecated. Consider '", "\n", "'setting this value or calling the specific functions '", "\n", "'\"as_classification_dataset\", \"as_regression_dataset\", '", "\n", "'\"as_segmentation_dataset\" or \"as_undefined_dataset\"'", ")", "\n", "dataset_type", "=", "AvalancheDatasetType", ".", "UNDEFINED", "\n", "\n", "", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", "and", "dataset", ".", "dataset_type", "==", "dataset_type", ":", "\n", "        ", "return", "dataset", "\n", "\n", "", "return", "AvalancheDataset", "(", "dataset", ",", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_classification_dataset": [[2055, 2059], ["avalanche_dataset.as_avalanche_dataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_avalanche_dataset"], ["", "def", "as_classification_dataset", "(", "dataset", ":", "ISupportedClassificationDataset", "[", "T_co", "]", ")", "->", "AvalancheDataset", "[", "T_co", ",", "int", "]", ":", "\n", "    ", "return", "as_avalanche_dataset", "(", "\n", "dataset", ",", "dataset_type", "=", "AvalancheDatasetType", ".", "CLASSIFICATION", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_regression_dataset": [[2061, 2065], ["avalanche_dataset.as_avalanche_dataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_avalanche_dataset"], ["", "def", "as_regression_dataset", "(", "dataset", ":", "ISupportedClassificationDataset", "[", "T_co", "]", ")", "->", "AvalancheDataset", "[", "T_co", ",", "Any", "]", ":", "\n", "    ", "return", "as_avalanche_dataset", "(", "\n", "dataset", ",", "dataset_type", "=", "AvalancheDatasetType", ".", "REGRESSION", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_segmentation_dataset": [[2067, 2071], ["avalanche_dataset.as_avalanche_dataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_avalanche_dataset"], ["", "def", "as_segmentation_dataset", "(", "dataset", ":", "ISupportedClassificationDataset", "[", "T_co", "]", ")", "->", "AvalancheDataset", "[", "T_co", ",", "Any", "]", ":", "\n", "    ", "return", "as_avalanche_dataset", "(", "\n", "dataset", ",", "dataset_type", "=", "AvalancheDatasetType", ".", "SEGMENTATION", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_undefined_dataset": [[2073, 2077], ["avalanche_dataset.as_avalanche_dataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_avalanche_dataset"], ["", "def", "as_undefined_dataset", "(", "dataset", ":", "ISupportedClassificationDataset", "[", "T_co", "]", ")", "->", "AvalancheDataset", "[", "T_co", ",", "Any", "]", ":", "\n", "    ", "return", "as_avalanche_dataset", "(", "\n", "dataset", ",", "dataset_type", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.train_eval_avalanche_datasets": [[2079, 2098], ["avalanche_dataset.AvalancheDataset", "avalanche_dataset.AvalancheDataset", "dict", "dict"], "function", ["None"], ["", "def", "train_eval_avalanche_datasets", "(", "\n", "train_dataset", ":", "ISupportedClassificationDataset", ",", "\n", "test_dataset", ":", "ISupportedClassificationDataset", ",", "\n", "train_transformation", ",", "eval_transformation", ",", "\n", "dataset_type", "=", "None", ")", ":", "\n", "    ", "train", "=", "AvalancheDataset", "(", "\n", "train_dataset", ",", "\n", "transform_groups", "=", "dict", "(", "train", "=", "(", "train_transformation", ",", "None", ")", ",", "\n", "eval", "=", "(", "eval_transformation", ",", "None", ")", ")", ",", "\n", "initial_transform_group", "=", "'train'", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n", "test", "=", "AvalancheDataset", "(", "\n", "test_dataset", ",", "\n", "transform_groups", "=", "dict", "(", "train", "=", "(", "train_transformation", ",", "None", ")", ",", "\n", "eval", "=", "(", "eval_transformation", ",", "None", ")", ")", ",", "\n", "initial_transform_group", "=", "'eval'", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "return", "train", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._traverse_supported_dataset": [[2100, 2158], ["isinstance", "isinstance", "ValueError", "list", "collections.defaultdict", "enumerate", "range", "range", "avalanche_dataset._traverse_supported_dataset", "len", "datasets_len.append", "dataset_utils.find_list_from_index", "datasets_to_indexes[].append", "indexes_to_dataset.append", "recursion_result.append", "len", "values_selector.append", "len", "list", "collections.deque", "recursion_result[].popleft", "avalanche_dataset._traverse_supported_dataset", "avalanche_dataset._traverse_supported_dataset", "avalanche_dataset._select_targets", "avalanche_dataset._select_task_labels"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._traverse_supported_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.find_list_from_index", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._traverse_supported_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._traverse_supported_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._select_targets", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._select_task_labels"], ["", "def", "_traverse_supported_dataset", "(", "\n", "dataset", ",", "values_selector", ":", "Callable", "[", "[", "Dataset", ",", "List", "[", "int", "]", "]", ",", "List", "]", ",", "\n", "indices", "=", "None", ")", "->", "List", ":", "\n", "    ", "initial_error", "=", "None", "\n", "try", ":", "\n", "        ", "result", "=", "values_selector", "(", "dataset", ",", "indices", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "return", "result", "\n", "", "", "except", "BaseException", "as", "e", ":", "\n", "        ", "initial_error", "=", "e", "\n", "\n", "", "if", "isinstance", "(", "dataset", ",", "Subset", ")", ":", "\n", "        ", "if", "indices", "is", "None", ":", "\n", "            ", "indices", "=", "range", "(", "len", "(", "dataset", ")", ")", "\n", "", "indices", "=", "[", "dataset", ".", "indices", "[", "x", "]", "for", "x", "in", "indices", "]", "\n", "return", "list", "(", "_traverse_supported_dataset", "(", "\n", "dataset", ".", "dataset", ",", "values_selector", ",", "indices", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "dataset", ",", "ConcatDataset", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "if", "indices", "is", "None", ":", "\n", "            ", "for", "c_dataset", "in", "dataset", ".", "datasets", ":", "\n", "                ", "result", "+=", "list", "(", "_traverse_supported_dataset", "(", "\n", "c_dataset", ",", "values_selector", ",", "indices", ")", ")", "\n", "", "return", "result", "\n", "\n", "", "datasets_to_indexes", "=", "defaultdict", "(", "list", ")", "\n", "indexes_to_dataset", "=", "[", "]", "\n", "datasets_len", "=", "[", "]", "\n", "recursion_result", "=", "[", "]", "\n", "\n", "all_size", "=", "0", "\n", "for", "c_dataset", "in", "dataset", ".", "datasets", ":", "\n", "            ", "len_dataset", "=", "len", "(", "c_dataset", ")", "\n", "datasets_len", ".", "append", "(", "len_dataset", ")", "\n", "all_size", "+=", "len_dataset", "\n", "\n", "", "for", "subset_idx", "in", "indices", ":", "\n", "            ", "dataset_idx", ",", "pattern_idx", "=", "find_list_from_index", "(", "subset_idx", ",", "datasets_len", ",", "all_size", ")", "\n", "datasets_to_indexes", "[", "dataset_idx", "]", ".", "append", "(", "pattern_idx", ")", "\n", "indexes_to_dataset", ".", "append", "(", "dataset_idx", ")", "\n", "\n", "", "for", "dataset_idx", ",", "c_dataset", "in", "enumerate", "(", "dataset", ".", "datasets", ")", ":", "\n", "            ", "recursion_result", ".", "append", "(", "deque", "(", "_traverse_supported_dataset", "(", "\n", "c_dataset", ",", "values_selector", ",", "datasets_to_indexes", "[", "dataset_idx", "]", ")", ")", ")", "\n", "\n", "", "result", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "indices", ")", ")", ":", "\n", "            ", "dataset_idx", "=", "indexes_to_dataset", "[", "idx", "]", "\n", "result", ".", "append", "(", "recursion_result", "[", "dataset_idx", "]", ".", "popleft", "(", ")", ")", "\n", "\n", "", "return", "result", "\n", "\n", "", "if", "initial_error", "is", "not", "None", ":", "\n", "        ", "raise", "initial_error", "\n", "\n", "", "raise", "ValueError", "(", "'Error: can\\'t find the needed data in the given dataset'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._count_unique": [[2160, 2168], ["set", "len", "set.add", "int"], "function", ["None"], ["", "def", "_count_unique", "(", "*", "sequences", ":", "Sequence", "[", "SupportsInt", "]", ")", ":", "\n", "    ", "uniques", "=", "set", "(", ")", "\n", "\n", "for", "seq", "in", "sequences", ":", "\n", "        ", "for", "x", "in", "seq", ":", "\n", "            ", "uniques", ".", "add", "(", "int", "(", "x", ")", ")", "\n", "\n", "", "", "return", "len", "(", "uniques", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._select_targets": [[2170, 2193], ["hasattr", "hasattr", "dataset_utils.SubSequence", "hasattr", "ValueError", "len", "ValueError"], "function", ["None"], ["", "def", "_select_targets", "(", "dataset", ",", "indices", ")", ":", "\n", "    ", "if", "hasattr", "(", "dataset", ",", "'targets'", ")", ":", "\n", "# Standard supported dataset", "\n", "        ", "found_targets", "=", "dataset", ".", "targets", "\n", "", "elif", "hasattr", "(", "dataset", ",", "'labels'", ")", ":", "\n", "# Standard supported dataset", "\n", "        ", "found_targets", "=", "dataset", ".", "labels", "\n", "", "elif", "hasattr", "(", "dataset", ",", "'tensors'", ")", ":", "\n", "# Support for PyTorch TensorDataset", "\n", "        ", "if", "len", "(", "dataset", ".", "tensors", ")", "<", "2", ":", "\n", "            ", "raise", "ValueError", "(", "'Tensor dataset has not enough tensors: '", "\n", "'at least 2 are required.'", ")", "\n", "", "found_targets", "=", "dataset", ".", "tensors", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'Unsupported dataset: must have a valid targets field '", "\n", "'or has to be a Tensor Dataset with at least 2 '", "\n", "'Tensors'", ")", "\n", "\n", "", "if", "indices", "is", "not", "None", ":", "\n", "        ", "found_targets", "=", "SubSequence", "(", "found_targets", ",", "indices", "=", "indices", ")", "\n", "\n", "", "return", "found_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._select_task_labels": [[2195, 2213], ["hasattr", "isinstance", "dataset_utils.ConstantSequence", "dataset_utils.SubSequence", "dataset_utils.ConstantSequence", "len", "len"], "function", ["None"], ["", "def", "_select_task_labels", "(", "dataset", ",", "indices", ")", ":", "\n", "    ", "found_task_labels", "=", "None", "\n", "if", "hasattr", "(", "dataset", ",", "'targets_task_labels'", ")", ":", "\n", "        ", "found_task_labels", "=", "dataset", ".", "targets_task_labels", "\n", "\n", "", "if", "found_task_labels", "is", "None", ":", "\n", "        ", "if", "isinstance", "(", "dataset", ",", "(", "Subset", ",", "ConcatDataset", ")", ")", ":", "\n", "            ", "return", "None", "# Continue traversing", "\n", "\n", "", "", "if", "found_task_labels", "is", "None", ":", "\n", "        ", "if", "indices", "is", "None", ":", "\n", "            ", "return", "ConstantSequence", "(", "0", ",", "len", "(", "dataset", ")", ")", "\n", "", "return", "ConstantSequence", "(", "0", ",", "len", "(", "indices", ")", ")", "\n", "\n", "", "if", "indices", "is", "not", "None", ":", "\n", "        ", "found_task_labels", "=", "SubSequence", "(", "found_task_labels", ",", "indices", "=", "indices", ")", "\n", "\n", "", "return", "found_task_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._make_target_from_supported_dataset": [[2215, 2233], ["isinstance", "avalanche_dataset._traverse_supported_dataset", "dataset_utils.SubSequence", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._traverse_supported_dataset"], ["", "def", "_make_target_from_supported_dataset", "(", "\n", "dataset", ":", "SupportedDataset", ",", "\n", "converter", ":", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "=", "None", ")", "->", "Sequence", "[", "TTargetType", "]", ":", "\n", "    ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "        ", "if", "converter", "is", "None", ":", "\n", "            ", "return", "dataset", ".", "targets", "\n", "", "elif", "isinstance", "(", "dataset", ".", "targets", ",", "\n", "(", "SubSequence", ",", "LazyConcatTargets", ")", ")", "and", "dataset", ".", "targets", ".", "converter", "==", "converter", ":", "\n", "            ", "return", "dataset", ".", "targets", "\n", "", "elif", "isinstance", "(", "dataset", ".", "targets", ",", "LazyClassMapping", ")", "and", "converter", "==", "int", ":", "\n", "# LazyClassMapping already outputs int targets", "\n", "            ", "return", "dataset", ".", "targets", "\n", "\n", "", "", "targets", "=", "_traverse_supported_dataset", "(", "dataset", ",", "_select_targets", ")", "\n", "\n", "return", "SubSequence", "(", "targets", ",", "converter", "=", "converter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._make_task_labels_from_supported_dataset": [[2235, 2243], ["isinstance", "avalanche_dataset._traverse_supported_dataset", "dataset_utils.SubSequence"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset._traverse_supported_dataset"], ["", "def", "_make_task_labels_from_supported_dataset", "(", "dataset", ":", "SupportedDataset", ")", "->", "Sequence", "[", "int", "]", ":", "\n", "    ", "if", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "        ", "return", "dataset", ".", "targets_task_labels", "\n", "\n", "", "task_labels", "=", "_traverse_supported_dataset", "(", "dataset", ",", "_select_task_labels", ")", "\n", "\n", "return", "SubSequence", "(", "task_labels", ",", "converter", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.PathsDataset.__init__": [[66, 92], ["pathlib.Path"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "root", ",", "files", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_image_loader", ")", ":", "\n", "        ", "\"\"\"\n        Creates a File Dataset from a list of files and labels.\n\n        :param root: root path where the data to load are stored. May be None.\n        :param files: list of tuples. Each tuple must contain two elements: the\n            full path to the pattern and its class label. Optionally, the tuple\n            may contain a third element describing the bounding box to use for\n            cropping (top, left, height, width).\n        :param transform: eventual transformation to add to the input data (x)\n        :param target_transform: eventual transformation to add to the targets\n            (y)\n        :param loader: loader function to use (for the real data) given path.\n        \"\"\"", "\n", "\n", "if", "root", "is", "not", "None", ":", "\n", "            ", "root", "=", "Path", "(", "root", ")", "\n", "\n", "", "self", ".", "root", ":", "Optional", "[", "Path", "]", "=", "root", "\n", "self", ".", "imgs", "=", "files", "\n", "self", ".", "targets", "=", "[", "img_data", "[", "1", "]", "for", "img_data", "in", "self", ".", "imgs", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.PathsDataset.__getitem__": [[93, 125], ["datasets_from_filelists.PathsDataset.loader", "len", "isinstance", "torchvision.transforms.functional.crop", "datasets_from_filelists.PathsDataset.transform", "datasets_from_filelists.PathsDataset.target_transform", "bbox.tolist.tolist.tolist"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Returns next element in the dataset given the current index.\n\n        :param index: index of the data to get.\n        :return: loaded item.\n        \"\"\"", "\n", "\n", "img_description", "=", "self", ".", "imgs", "[", "index", "]", "\n", "impath", "=", "img_description", "[", "0", "]", "\n", "target", "=", "img_description", "[", "1", "]", "\n", "bbox", "=", "None", "\n", "if", "len", "(", "img_description", ")", ">", "2", ":", "\n", "            ", "bbox", "=", "img_description", "[", "2", "]", "\n", "\n", "", "if", "self", ".", "root", "is", "not", "None", ":", "\n", "            ", "impath", "=", "self", ".", "root", "/", "impath", "\n", "", "img", "=", "self", ".", "loader", "(", "impath", ")", "\n", "\n", "# If a bounding box is provided, crop the image before passing it to", "\n", "# any user-defined transformation.", "\n", "if", "bbox", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "bbox", ",", "Tensor", ")", ":", "\n", "                ", "bbox", "=", "bbox", ".", "tolist", "(", ")", "\n", "", "img", "=", "crop", "(", "img", ",", "*", "bbox", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.PathsDataset.__len__": [[126, 134], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the total number of elements in the dataset.\n\n        :return: Total number of dataset items.\n        \"\"\"", "\n", "\n", "return", "len", "(", "self", ".", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.FilelistDataset.__init__": [[142, 163], ["str", "flist_reader", "datasets_from_filelists.PathsDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "\n", "self", ",", "root", ",", "flist", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "flist_reader", "=", "default_flist_reader", ",", "loader", "=", "default_image_loader", ")", ":", "\n", "        ", "\"\"\"\n        This reader reads a filelist and return a list of paths.\n\n        :param root: root path where the data to load are stored. May be None.\n        :param flist: path of the flislist to read. The flist format should be:\n            impath label\\nimpath label\\n ...(same to caffe's filelist).\n        :param transform: eventual transformation to add to the input data (x).\n        :param target_transform: eventual transformation to add to the targets\n            (y).\n        :param flist_reader: loader function to use (for the filelists) given\n            path.\n        :param loader: loader function to use (for the real data) given path.\n        \"\"\"", "\n", "\n", "flist", "=", "str", "(", "flist", ")", "# Manages Path objects", "\n", "files_and_labels", "=", "flist_reader", "(", "flist", ")", "\n", "super", "(", ")", ".", "__init__", "(", "root", ",", "files_and_labels", ",", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ",", "loader", "=", "loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.default_image_loader": [[30, 39], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["def", "default_image_loader", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    Sets the default image loader for the Pytorch Dataset.\n\n    :param path: relative or absolute path of the file to load.\n\n    :returns: Returns the image as a RGB PIL image.\n    \"\"\"", "\n", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.default_flist_reader": [[41, 58], ["open", "rf.readlines", "line.strip().split", "imlist.append", "line.strip", "int"], "function", ["None"], ["", "def", "default_flist_reader", "(", "flist", ")", ":", "\n", "    ", "\"\"\"\n    This reader reads a filelist and return a list of paths.\n\n    :param flist: path of the flislist to read. The flist format should be:\n        impath label, impath label,  ...(same to caffe's filelist)\n\n    :returns: Returns a list of paths (the examples to be loaded).\n    \"\"\"", "\n", "\n", "imlist", "=", "[", "]", "\n", "with", "open", "(", "flist", ",", "'r'", ")", "as", "rf", ":", "\n", "        ", "for", "line", "in", "rf", ".", "readlines", "(", ")", ":", "\n", "            ", "impath", ",", "imlabel", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "imlist", ".", "append", "(", "(", "impath", ",", "int", "(", "imlabel", ")", ")", ")", "\n", "\n", "", "", "return", "imlist", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.datasets_from_filelists": [[165, 240], ["dict", "avalanche.benchmarks.utils.AvalancheDataset", "avalanche.benchmarks.utils.AvalancheDataset", "len", "len", "ValueError", "datasets_from_filelists.FilelistDataset", "datasets_from_filelists.FilelistDataset", "isinstance", "isinstance", "len", "ValueError"], "function", ["None"], ["", "", "def", "datasets_from_filelists", "(", "root", ",", "train_filelists", ",", "test_filelists", ",", "\n", "complete_test_set_only", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "test_transform", "=", "None", ",", "test_target_transform", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This reader reads a list of Caffe-style filelists and returns the proper\n    Dataset objects.\n\n    A Caffe-style list is just a text file where, for each line, two elements\n    are described: the path to the pattern (relative to the root parameter)\n    and its class label. Those two elements are separated by a single white\n    space.\n\n    This method reads each file list and returns a separate\n    dataset for each of them.\n\n    Beware that the parameters must be **list of paths to Caffe-style\n    filelists**. If you need to create a dataset given a list of\n    **pattern paths**, use `datasets_from_paths` instead.\n\n    :param root: root path where the data to load are stored. May be None.\n    :param train_filelists: list of paths to train filelists. The flist format\n        should be: impath label\\\\nimpath label\\\\n ...(same to Caffe's filelist).\n    :param test_filelists: list of paths to test filelists. It can be also a\n        single path when the datasets is the same for each batch.\n    :param complete_test_set_only: if True, test_filelists must contain\n        the path to a single filelist that will serve as the complete test set.\n        Alternatively, test_filelists can be the path (str) to the complete test\n        set filelist. If False, train_filelists and test_filelists must contain\n        the same amount of filelists paths. Defaults to False.\n    :param train_transform: The transformation to apply to training patterns.\n        Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param test_transform: The transformation to apply to test patterns.\n        Defaults to None.\n    :param test_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n\n    :return: list of tuples (train dataset, test dataset) for each train\n        filelist in the list.\n    \"\"\"", "\n", "\n", "if", "complete_test_set_only", ":", "\n", "        ", "if", "not", "(", "isinstance", "(", "test_filelists", ",", "str", ")", "or", "\n", "isinstance", "(", "test_filelists", ",", "Path", ")", ")", ":", "\n", "            ", "if", "len", "(", "test_filelists", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'When complete_test_set_only is True, test_filelists must '", "\n", "'be a str, Path or a list with a single element describing '", "\n", "'the path to the complete test set.'", ")", "\n", "", "else", ":", "\n", "                ", "test_filelists", "=", "test_filelists", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "test_filelists", "=", "[", "test_filelists", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "len", "(", "test_filelists", ")", "!=", "len", "(", "train_filelists", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'When complete_test_set_only is False, test_filelists and '", "\n", "'train_filelists must contain the same number of elements.'", ")", "\n", "\n", "", "", "transform_groups", "=", "dict", "(", "train", "=", "(", "train_transform", ",", "train_target_transform", ")", ",", "\n", "eval", "=", "(", "test_transform", ",", "test_target_transform", ")", ")", "\n", "train_inc_datasets", "=", "[", "AvalancheDataset", "(", "FilelistDataset", "(", "root", ",", "tr_flist", ")", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'train'", ")", "\n", "for", "tr_flist", "in", "train_filelists", "]", "\n", "test_inc_datasets", "=", "[", "AvalancheDataset", "(", "FilelistDataset", "(", "root", ",", "te_flist", ")", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'eval'", ")", "\n", "for", "te_flist", "in", "test_filelists", "]", "\n", "\n", "return", "train_inc_datasets", ",", "test_inc_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.datasets_from_paths": [[242, 382], ["dict", "os.path.commonpath", "os.path.commonpath", "str", "list", "list", "range", "range", "avalanche.benchmarks.utils.AvalancheDataset", "avalanche.benchmarks.utils.AvalancheDataset", "isinstance", "len", "len", "ValueError", "len", "len", "list", "list.append", "len", "list", "list.append", "datasets_from_filelists.PathsDataset", "datasets_from_filelists.PathsDataset", "len", "ValueError", "os.path.relpath", "os.path.relpath", "list.append", "os.path.relpath", "os.path.relpath", "list.append", "len", "len"], "function", ["None"], ["", "def", "datasets_from_paths", "(", "\n", "train_list", ",", "test_list", ",", "complete_test_set_only", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "test_transform", "=", "None", ",", "test_target_transform", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This utility takes, for each dataset to generate, a list of tuples each\n    containing two elements: the full path to the pattern and its class label.\n    Optionally, the tuple may contain a third element describing the bounding\n    box to use for cropping.\n\n    This is equivalent to `datasets_from_filelists`, which description\n    contains more details on the behaviour of this utility. The two utilities\n    differ in which `datasets_from_filelists` accepts paths to Caffe-style\n    filelists while this one is able to create the datasets from an in-memory\n    list.\n\n    Note: this utility may try to detect (and strip) the common root path of\n    all patterns in order to save some RAM memory.\n\n    :param train_list: list of lists. Each list must contain tuples of two\n        elements: the full path to the pattern and its class label. Optionally,\n        the tuple may contain a third element describing the bounding box to use\n        for cropping (top, left, height, width).\n    :param test_list: list of lists. Each list must contain tuples of two\n        elements: the full path to the pattern and its class label. Optionally,\n        the tuple may contain a third element describing the bounding box to use\n        for cropping (top, left, height, width). It can be also a single list\n        when the test dataset is the same for each experience.\n    :param complete_test_set_only: if True, test_list must contain a single list\n        that will serve as the complete test set. If False, train_list and\n        test_list must describe the same amount of datasets. Defaults to False.\n    :param train_transform: The transformation to apply to training patterns.\n        Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param test_transform: The transformation to apply to test patterns.\n        Defaults to None.\n    :param test_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n\n    :return: A list of tuples (train dataset, test dataset).\n    \"\"\"", "\n", "\n", "if", "complete_test_set_only", ":", "\n", "# Check if the single dataset was passed as [Tuple1, Tuple2, ...]", "\n", "# or as [[Tuple1, Tuple2, ...]]", "\n", "        ", "if", "not", "isinstance", "(", "test_list", "[", "0", "]", ",", "Tuple", ")", ":", "\n", "            ", "if", "len", "(", "test_list", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'When complete_test_set_only is True, test_list must '", "\n", "'be a single list of tuples or a nested list containing '", "\n", "'a single lis of tuples'", ")", "\n", "", "else", ":", "\n", "                ", "test_list", "=", "test_list", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "test_list", "=", "[", "test_list", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "len", "(", "test_list", ")", "!=", "len", "(", "train_list", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'When complete_test_set_only is False, test_list and '", "\n", "'train_list must contain the same number of elements.'", ")", "\n", "\n", "", "", "transform_groups", "=", "dict", "(", "train", "=", "(", "train_transform", ",", "train_target_transform", ")", ",", "\n", "eval", "=", "(", "test_transform", ",", "test_target_transform", ")", ")", "\n", "\n", "common_root", "=", "None", "\n", "\n", "# Detect common root", "\n", "try", ":", "\n", "        ", "all_paths", "=", "[", "pattern_tuple", "[", "0", "]", "for", "exp_list", "in", "train_list", "\n", "for", "pattern_tuple", "in", "exp_list", "]", "+", "[", "pattern_tuple", "[", "0", "]", "for", "exp_list", "in", "test_list", "\n", "for", "pattern_tuple", "in", "exp_list", "]", "\n", "\n", "common_root", "=", "os", ".", "path", ".", "commonpath", "(", "all_paths", ")", "\n", "", "except", "ValueError", ":", "\n", "# commonpath may throw a ValueError in different situations!", "\n", "# See the official documentation for more details", "\n", "        ", "pass", "\n", "\n", "", "if", "common_root", "is", "not", "None", "and", "len", "(", "common_root", ")", ">", "0", "and", "common_root", "!=", "'/'", ":", "\n", "        ", "has_common_root", "=", "True", "\n", "common_root", "=", "str", "(", "common_root", ")", "\n", "", "else", ":", "\n", "        ", "has_common_root", "=", "False", "\n", "common_root", "=", "None", "\n", "\n", "", "if", "has_common_root", ":", "\n", "# print(f'Common root found: {common_root}!')", "\n", "# All paths have a common filesystem root", "\n", "# Remove it from all paths!", "\n", "        ", "single_path_case", "=", "False", "\n", "tr_list", "=", "list", "(", ")", "\n", "te_list", "=", "list", "(", ")", "\n", "\n", "for", "idx_exp_list", "in", "range", "(", "len", "(", "train_list", ")", ")", ":", "\n", "            ", "if", "single_path_case", ":", "\n", "                ", "break", "\n", "", "st_list", "=", "list", "(", ")", "\n", "for", "x", "in", "train_list", "[", "idx_exp_list", "]", ":", "\n", "                ", "rel", "=", "os", ".", "path", ".", "relpath", "(", "x", "[", "0", "]", ",", "common_root", ")", "\n", "if", "len", "(", "rel", ")", "==", "0", "or", "rel", "==", "'.'", ":", "\n", "# May happen if the dataset has a single path", "\n", "                    ", "single_path_case", "=", "True", "\n", "break", "\n", "", "st_list", ".", "append", "(", "(", "rel", ",", "*", "x", "[", "1", ":", "]", ")", ")", "\n", "", "tr_list", ".", "append", "(", "st_list", ")", "\n", "\n", "", "for", "idx_exp_list", "in", "range", "(", "len", "(", "test_list", ")", ")", ":", "\n", "            ", "if", "single_path_case", ":", "\n", "                ", "break", "\n", "", "st_list", "=", "list", "(", ")", "\n", "for", "x", "in", "test_list", "[", "idx_exp_list", "]", ":", "\n", "                ", "rel", "=", "os", ".", "path", ".", "relpath", "(", "x", "[", "0", "]", ",", "common_root", ")", "\n", "if", "len", "(", "rel", ")", "==", "0", "or", "rel", "==", "'.'", ":", "\n", "# May happen if the dataset has a single path", "\n", "                    ", "single_path_case", "=", "True", "\n", "break", "\n", "", "st_list", ".", "append", "(", "(", "rel", ",", "*", "x", "[", "1", ":", "]", ")", ")", "\n", "", "te_list", ".", "append", "(", "st_list", ")", "\n", "", "if", "not", "single_path_case", ":", "\n", "            ", "train_list", "=", "tr_list", "\n", "test_list", "=", "te_list", "\n", "", "else", ":", "\n", "            ", "has_common_root", "=", "False", "\n", "common_root", "=", "None", "\n", "\n", "", "", "train_inc_datasets", "=", "[", "AvalancheDataset", "(", "PathsDataset", "(", "common_root", ",", "tr_flist", ")", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'train'", ")", "\n", "for", "tr_flist", "in", "train_list", "]", "\n", "test_inc_datasets", "=", "[", "AvalancheDataset", "(", "PathsDataset", "(", "common_root", ",", "te_flist", ")", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'eval'", ")", "\n", "for", "te_flist", "in", "test_list", "]", "\n", "\n", "return", "train_inc_datasets", ",", "test_inc_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.common_paths_root": [[384, 429], ["os.path.commonpath", "os.path.commonpath", "str", "list", "len", "os.path.relpath", "os.path.relpath", "list.append", "len"], "function", ["None"], ["", "def", "common_paths_root", "(", "exp_list", ")", ":", "\n", "    ", "common_root", "=", "None", "\n", "\n", "# Detect common root", "\n", "try", ":", "\n", "        ", "all_paths", "=", "[", "pattern_tuple", "[", "0", "]", "for", "pattern_tuple", "in", "exp_list", "]", "\n", "\n", "common_root", "=", "os", ".", "path", ".", "commonpath", "(", "all_paths", ")", "\n", "", "except", "ValueError", ":", "\n", "# commonpath may throw a ValueError in different situations!", "\n", "# See the official documentation for more details", "\n", "        ", "pass", "\n", "\n", "", "if", "common_root", "is", "not", "None", "and", "len", "(", "common_root", ")", ">", "0", "and", "common_root", "!=", "'/'", ":", "\n", "        ", "has_common_root", "=", "True", "\n", "common_root", "=", "str", "(", "common_root", ")", "\n", "", "else", ":", "\n", "        ", "has_common_root", "=", "False", "\n", "common_root", "=", "None", "\n", "\n", "", "if", "has_common_root", ":", "\n", "# print(f'Common root found: {common_root}!')", "\n", "# All paths have a common filesystem root", "\n", "# Remove it from all paths!", "\n", "        ", "single_path_case", "=", "False", "\n", "exp_tuples", "=", "list", "(", ")", "\n", "\n", "for", "x", "in", "exp_list", ":", "\n", "            ", "if", "single_path_case", ":", "\n", "                ", "break", "\n", "\n", "", "rel", "=", "os", ".", "path", ".", "relpath", "(", "x", "[", "0", "]", ",", "common_root", ")", "\n", "if", "len", "(", "rel", ")", "==", "0", "or", "rel", "==", "'.'", ":", "\n", "# May happen if the dataset has a single path", "\n", "                ", "single_path_case", "=", "True", "\n", "break", "\n", "", "exp_tuples", ".", "append", "(", "(", "rel", ",", "*", "x", "[", "1", ":", "]", ")", ")", "\n", "\n", "", "if", "not", "single_path_case", ":", "\n", "            ", "exp_list", "=", "exp_tuples", "\n", "", "else", ":", "\n", "            ", "common_root", "=", "None", "\n", "\n", "", "", "return", "common_root", ",", "exp_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.torchvision_wrapper.ImageFolder": [[19, 21], ["torchvision.datasets.ImageFolder"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.ImageFolder"], ["def", "ImageFolder", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "torchImageFolder", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.torchvision_wrapper.DatasetFolder": [[23, 25], ["torchvision.datasets.DatasetFolder"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.DatasetFolder"], ["", "def", "DatasetFolder", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "torchDatasetFolder", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list": [[21, 34], ["isinstance", "isinstance", "list", "isinstance", "sequence.tolist"], "function", ["None"], ["def", "__init__", "(", "self", ",", "max_iterations", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "max_iterations", ",", "int", ")", "and", "max_iterations", ">", "0", "\n", "self", ".", "max_iterations", "=", "max_iterations", "\n", "\n", "", "def", "after_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "strategy", ".", "clock", ".", "train_exp_iterations", "==", "self", ".", "max_iterations", ":", "\n", "            ", "print", "(", "f\"Stopping training, reached max iterations: {self.max_iterations}\"", ")", "\n", "strategy", ".", "stop_training", "(", ")", "\n", "\n", "\n", "", "", "", "class", "MetricOverSeed", ":", "\n", "    ", "logging_token", "=", "\"[SEED-AVGED-RESULTS]=\"", "\n", "logging_result_format", "=", "\"{:.5f}\\pm{:.5f}\"", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils._indexes_grouped_by_classes": [[36, 84], ["collections.OrderedDict", "utils.tensor_as_list", "torch.unique().tolist", "utils.tensor_as_list", "list", "result_per_class[].append", "result.extend", "range", "torch.unique", "result_per_class[].sort", "len", "torch.as_tensor"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list"], ["\n", "def", "__init__", "(", "self", ",", "name", ",", "extract_name", ",", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        :param name: Name to give in logging\n        :param extract_name: Dict name in all_metrics dict after end of training seed.\n        :param extract_idx: Which idx to extract, -1 for final one.\n        :param mul_factor: Multiplication factor before return result.\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "extract_name", "=", "extract_name", "\n", "self", ".", "extract_idx", "=", "extract_idx", "\n", "self", ".", "mul_factor", "=", "mul_factor", "\n", "\n", "# Results appended sequentially", "\n", "self", ".", "seeds", "=", "[", "]", "\n", "self", ".", "seed_results", "=", "[", "]", "\n", "\n", "", "def", "extract_metric_fn", "(", "self", ",", "all_metrics", ":", "dict", ")", ":", "\n", "        ", "\"\"\" Extract dict of all eval results on end of seed.\n        Name-idx returns tuple of (list(<STEPS>),list(<METRIC-VALS>))\n        Select latter with [1], and apply the extraction idx.\n        \"\"\"", "\n", "return", "all_metrics", "[", "self", ".", "extract_name", "]", "[", "1", "]", "[", "self", ".", "extract_idx", "]", "*", "self", ".", "mul_factor", "\n", "\n", "", "def", "add_result", "(", "self", ",", "all_metrics", ":", "dict", ",", "seed", ":", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "result", "=", "self", ".", "extract_metric_fn", "(", "all_metrics", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "f\"[WARNING] No SEED result for metric {self.name}, because of error: {e}\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "seeds", ".", "append", "(", "seed", ")", "\n", "self", ".", "seed_results", ".", "append", "(", "result", ")", "\n", "\n", "", "def", "get_mean_std_results", "(", "self", ")", ":", "\n", "        ", "result_t", "=", "torch", ".", "tensor", "(", "self", ".", "seed_results", ")", "# list to tensor", "\n", "mean", ",", "std", "=", "result_t", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "result_t", ".", "std", "(", ")", ".", "item", "(", ")", "\n", "return", "mean", ",", "std", "\n", "\n", "\n", "", "", "def", "get_grad_normL2", "(", "model", ",", "norm_type", ":", "float", "=", "2", ")", ":", "\n", "    ", "\"\"\"Returns the gradient norm of the model.\n    Calculated the same way as torch.clip_grad_norm_\"\"\"", "\n", "\n", "# Params with grad", "\n", "parameters", "=", "model", ".", "parameters", "(", ")", "\n", "if", "isinstance", "(", "model", ".", "parameters", "(", ")", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "parameters", "=", "[", "parameters", "]", "\n", "", "parameters", "=", "[", "p", "for", "p", "in", "parameters", "if", "p", ".", "grad", "is", "not", "None", "]", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.grouped_and_ordered_indexes": [[86, 129], ["utils.tensor_as_list", "list", "list.sort", "utils._indexes_grouped_by_classes", "utils.tensor_as_list"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list", "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils._indexes_grouped_by_classes", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list"], ["        ", "return", "None", "\n", "", "device", "=", "parameters", "[", "0", "]", ".", "grad", ".", "device", "\n", "\n", "# calc norm", "\n", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "norm", "(", "p", ".", "grad", ".", "detach", "(", ")", ",", "norm_type", ")", ".", "to", "(", "device", ")", "for", "p", "in", "parameters", "]", ")", ",", "norm_type", ")", "\n", "return", "total_norm", ".", "item", "(", ")", "\n", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "get_prototypes_from_classifier", "(", "classifier", ":", "Union", "[", "torch", ".", "nn", ".", "Linear", ",", "MultiHeadClassifier", "]", ",", "get_clone", ":", "bool", ")", ":", "\n", "    ", "\"\"\"\n    Returns individual prototypes for given classifier.\n    :param classifier:\n    :param get_clone: Get a clone of the original parameter references instead of the original ones.\n    :return:\n    \"\"\"", "\n", "protos_weight", "=", "{", "}", "\n", "protos_bias", "=", "{", "}", "\n", "\n", "if", "isinstance", "(", "classifier", ",", "MultiHeadClassifier", ")", ":", "# Multi-head", "\n", "        ", "y_offset", "=", "0", "\n", "for", "taskid", ",", "taskhead", "in", "classifier", ".", "classifiers", ".", "items", "(", ")", ":", "# Iterate heads", "\n", "            ", "nb_task_protos", "=", "0", "\n", "for", "param_name", ",", "param", "in", "taskhead", ".", "named_parameters", "(", ")", ":", "# Weight/bias of Linear layer heads", "\n", "                ", "nb_task_protos", "=", "param", ".", "shape", "[", "0", "]", "\n", "if", "'weight'", "in", "param_name", ":", "\n", "                    ", "for", "y", "in", "range", "(", "nb_task_protos", ")", ":", "# Per head params restart from 0, but total protos has offset", "\n", "                        ", "protos_weight", "[", "y", "+", "y_offset", "]", "=", "param", "[", "y", "]", "\n", "", "", "elif", "'bias'", "in", "param_name", ":", "\n", "                    ", "for", "y", "in", "range", "(", "nb_task_protos", ")", ":", "\n", "                        ", "protos_bias", "[", "y", "+", "y_offset", "]", "=", "param", "[", "y", "]", "\n", "", "", "", "y_offset", "+=", "nb_task_protos", "\n", "\n", "", "", "elif", "isinstance", "(", "classifier", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "# Single head", "\n", "        ", "for", "param_name", ",", "param", "in", "classifier", ".", "named_parameters", "(", ")", ":", "\n", "            ", "nb_protos", "=", "param", ".", "shape", "[", "0", "]", "\n", "if", "'weight'", "in", "param_name", ":", "\n", "                ", "for", "y", "in", "range", "(", "nb_protos", ")", ":", "\n", "                    ", "protos_weight", "[", "y", "]", "=", "param", "[", "y", "]", "\n", "", "", "elif", "'bias'", "in", "param_name", ":", "\n", "                ", "for", "y", "in", "range", "(", "nb_protos", ")", ":", "\n", "                    ", "protos_bias", "[", "y", "]", "=", "param", "[", "y", "]", "\n", "", "", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location": [[22, 35], ["os.path.expanduser", "pathlib.Path"], "function", ["None"], ["    ", "from", "typing", "import", "Sequence", ",", "List", ",", "Any", ",", "Iterable", ",", "Union", ",", "Optional", ",", "SupportsInt", ",", "TypeVar", ",", "Tuple", ",", "Callable", ",", "Generic", "\n", "from", "typing_extensions", "import", "Protocol", "\n", "\n", "", "T_co", "=", "TypeVar", "(", "'T_co'", ",", "covariant", "=", "True", ")", "\n", "TTargetType", "=", "TypeVar", "(", "'TTargetType'", ")", "\n", "\n", "\n", "class", "SubSequence", "(", "Sequence", "[", "TTargetType", "]", ")", ":", "\n", "    ", "\"\"\"\n    A utility class used to define a lazily evaluated sub-sequence.\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "\n", "targets", ":", "Sequence", "[", "TTargetType", "]", ",", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.load_config_file": [[37, 40], ["open", "json.load"], "function", ["None"], ["indices", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "None", "]", "=", "None", ",", "\n", "converter", ":", "Optional", "[", "Callable", "[", "[", "Any", "]", ",", "TTargetType", "]", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "_targets", "=", "targets", "\n", "self", ".", "_indices", "=", "indices", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.maybe_init_config_file": [[42, 56], ["os.path.exists", "os.makedirs", "os.path.expanduser", "open", "json.dump"], "function", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_indices", "is", "None", ":", "\n", "            ", "return", "len", "(", "self", ".", "_targets", ")", "\n", "", "return", "len", "(", "self", ".", "_indices", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "item_idx", ")", "->", "TTargetType", ":", "\n", "        ", "if", "self", ".", "_indices", "is", "not", "None", ":", "\n", "            ", "subset_idx", "=", "self", ".", "_indices", "[", "item_idx", "]", "\n", "", "else", ":", "\n", "            ", "subset_idx", "=", "item_idx", "\n", "\n", "", "element", "=", "self", ".", "_targets", "[", "subset_idx", "]", "\n", "\n", "if", "self", ".", "converter", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.omniglot.Omniglot.__init__": [[22, 36], ["torchvision.datasets.Omniglot.__init__", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "str", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "target_transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "download", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "join", "(", "root", ",", "self", ".", "folder", ")", ",", "download", "=", "download", ",", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ",", "\n", "background", "=", "train", ")", "\n", "\n", "self", ".", "targets", "=", "[", "x", "[", "1", "]", "for", "x", "in", "self", ".", "_flat_character_images", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.omniglot.Omniglot.data": [[37, 40], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data", "(", "self", ")", ":", "\n", "        ", "return", "[", "x", "for", "x", ",", "_", "in", "self", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.MNIST": [[46, 48], ["torchvision.datasets.MNIST"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.MNIST"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.FashionMNIST": [[50, 52], ["torchvision.datasets.FashionMNIST"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.FashionMNIST"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.KMNIST": [[54, 56], ["torchvision.datasets.KMNIST"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.KMNIST"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.EMNIST": [[58, 60], ["torchvision.datasets.EMNIST"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.EMNIST"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.QMNIST": [[62, 64], ["torchvision.datasets.QMNIST"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.QMNIST"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.FakeData": [[66, 68], ["torchvision.datasets.FakeData"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.FakeData"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CocoCaptions": [[70, 72], ["torchvision.datasets.CocoCaptions"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CocoCaptions"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CocoDetection": [[74, 76], ["torchvision.datasets.CocoDetection"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CocoDetection"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.LSUN": [[82, 84], ["torchvision.datasets.LSUN"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.LSUN"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.ImageFolder": [[86, 88], ["torchvision.datasets.ImageFolder"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.ImageFolder"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.DatasetFolder": [[90, 92], ["torchvision.datasets.DatasetFolder"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.DatasetFolder"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.ImageNet": [[94, 96], ["torchvision.datasets.ImageNet"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.ImageNet"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR10": [[98, 100], ["torchvision.datasets.CIFAR10"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR10"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR100": [[102, 104], ["torchvision.datasets.CIFAR100"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR100"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.STL10": [[106, 108], ["torchvision.datasets.STL10"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.STL10"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SVHN": [[110, 112], ["torchvision.datasets.SVHN"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SVHN"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.PhotoTour": [[114, 116], ["torchvision.datasets.PhotoTour"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.PhotoTour"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SBU": [[118, 120], ["torchvision.datasets.SBU"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SBU"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Flickr8k": [[122, 124], ["torchvision.datasets.Flickr8k"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Flickr8k"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Flickr30k": [[126, 128], ["torchvision.datasets.Flickr30k"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Flickr30k"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.VOCDetection": [[130, 132], ["torchvision.datasets.VOCDetection"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.VOCDetection"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.VOCSegmentation": [[134, 136], ["torchvision.datasets.VOCSegmentation"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.VOCSegmentation"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Cityscapes": [[138, 140], ["torchvision.datasets.Cityscapes"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Cityscapes"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SBDataset": [[142, 144], ["torchvision.datasets.SBDataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.SBDataset"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.USPS": [[146, 148], ["torchvision.datasets.USPS"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.USPS"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Kinetics400": [[150, 152], ["torchvision.datasets.Kinetics400"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.Kinetics400"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.HMDB51": [[154, 156], ["torchvision.datasets.HMDB51"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.HMDB51"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.UCF101": [[158, 160], ["torchvision.datasets.UCF101"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.UCF101"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CelebA": [[162, 164], ["torchvision.datasets.CelebA"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CelebA"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset.__init__": [[65, 106], ["super().__init__", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "download", ":", "bool", "=", "True", ",", "\n", "verbose", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of a downloadable dataset.\n\n        Consider looking at the class documentation for the precise details on\n        how to extend this class.\n\n        Beware that calling this constructor only fills the `root` field. The\n        download and metadata loading procedures are triggered only by\n        calling `_load_dataset`.\n\n        :param root: The root path where the dataset will be downloaded.\n            Consider passing a path obtained by calling\n            `default_dataset_location` with the name of the dataset.\n        :param download: If True, the dataset will be downloaded if needed.\n            If False and the dataset can't be loaded from the provided root\n            path, an error will be raised when calling the `_load_dataset`\n            method. Defaults to True.\n        :param verbose: If True, some info about the download process will be\n            printed. Defaults to False.\n        \"\"\"", "\n", "\n", "super", "(", "DownloadableDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", ":", "Path", "=", "Path", "(", "root", ")", "\n", "\"\"\"\n        The path to the dataset.\n        \"\"\"", "\n", "\n", "self", ".", "download", ":", "bool", "=", "download", "\n", "\"\"\"\n        If True, the dataset will be downloaded (only if needed).\n        \"\"\"", "\n", "\n", "self", ".", "verbose", ":", "bool", "=", "verbose", "\n", "\"\"\"\n        If True, some info about the download process will be printed.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset": [[107, 153], ["downloadable_dataset.DownloadableDataset._load_metadata", "downloadable_dataset.DownloadableDataset._download_dataset", "downloadable_dataset.DownloadableDataset._load_metadata", "downloadable_dataset.DownloadableDataset._download_error_message", "print", "RuntimeError", "print", "RuntimeError", "print", "downloadable_dataset.DownloadableDataset._download_error_message", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._load_metadata", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._download_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._load_metadata", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._download_error_message", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._download_error_message"], ["", "def", "_load_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        The standardized dataset download and load procedure.\n\n        For more details on the coded procedure see the class documentation.\n\n        This method shouldn't be overridden.\n\n        This method will raise and error if the dataset couldn't be loaded\n        or downloaded.\n\n        :return: None\n        \"\"\"", "\n", "metadata_loaded", "=", "False", "\n", "metadata_load_error", "=", "None", "\n", "try", ":", "\n", "            ", "metadata_loaded", "=", "self", ".", "_load_metadata", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "metadata_load_error", "=", "e", "\n", "\n", "", "if", "metadata_loaded", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'Files already downloaded and verified'", ")", "\n", "", "return", "\n", "\n", "", "if", "not", "self", ".", "download", ":", "\n", "            ", "msg", "=", "'Error loading dataset metadata (dataset download was '", "'not attempted as \"download\" is set to False)'", "\n", "if", "metadata_load_error", "is", "None", ":", "\n", "                ", "raise", "RuntimeError", "(", "msg", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "msg", ")", "\n", "raise", "metadata_load_error", "\n", "\n", "", "", "try", ":", "\n", "            ", "self", ".", "_download_dataset", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "err_msg", "=", "self", ".", "_download_error_message", "(", ")", "\n", "print", "(", "err_msg", ",", "flush", "=", "True", ")", "\n", "raise", "e", "\n", "\n", "", "if", "not", "self", ".", "_load_metadata", "(", ")", ":", "\n", "            ", "err_msg", "=", "self", ".", "_download_error_message", "(", ")", "\n", "print", "(", "err_msg", ")", "\n", "raise", "RuntimeError", "(", "\n", "'Error loading dataset metadata (... but the download '", "\n", "'procedure completed successfully)'", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_dataset": [[155, 171], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        The download procedure.\n\n        This procedure is called only if `_load_metadata` fails.\n\n        This method must raise an error if the dataset can't be downloaded.\n\n        Hints: don't re-invent the wheel! There are ready-to-use helper methods\n        like `_download_and_extract_archive`, `_download_file` and\n        `_extract_archive` that can be used.\n\n        :return: None\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_metadata": [[172, 186], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        The dataset metadata loading procedure.\n\n        This procedure is called at least once to load the dataset metadata.\n\n        This procedure should return False if the dataset is corrupted or if it\n        can't be loaded.\n\n        :return: True if the dataset is not corrupted and could be successfully\n        loaded.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_error_message": [[187, 196], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Returns the error message hinting the user on how to download the\n        dataset manually.\n\n        :return: A string representing the message to show to the user.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._cleanup_dataset_root": [[197, 210], ["shutil.rmtree", "downloadable_dataset.DownloadableDataset.root.mkdir"], "methods", ["None"], ["", "def", "_cleanup_dataset_root", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Utility method that can be used to remove the dataset root directory.\n\n        Can be useful if a cleanup is needed when downloading and extracting the\n        dataset.\n\n        This method will also re-create the root directory.\n\n        :return: None\n        \"\"\"", "\n", "shutil", ".", "rmtree", "(", "self", ".", "root", ")", "\n", "self", ".", "root", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_file": [[211, 231], ["downloadable_dataset.DownloadableDataset.root.mkdir", "torchvision.datasets.utils.download_url", "str"], "methods", ["None"], ["", "def", "_download_file", "(", "self", ",", "\n", "url", ":", "str", ",", "\n", "file_name", ":", "str", ",", "\n", "checksum", ":", "Optional", "[", "str", "]", ")", "->", "Path", ":", "\n", "        ", "\"\"\"\n        Utility method that can be used to download and verify a file.\n\n        :param url: The download url.\n        :param file_name: The name of the file to save. The file will be saved\n            in the `root` with this name. Always fill this parameter.\n            Don't pass a path! Pass a file name only!\n        :param checksum: The MD5 hash to use when verifying the downloaded\n            file. Can be None, in which case the check will be skipped.\n            It is recommended to always fill this parameter.\n        :return: The path to the downloaded file.\n        \"\"\"", "\n", "self", ".", "root", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "download_url", "(", "url", ",", "str", "(", "self", ".", "root", ")", ",", "filename", "=", "file_name", ",", "\n", "md5", "=", "checksum", ")", "\n", "return", "self", ".", "root", "/", "file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._extract_archive": [[232, 260], ["torchvision.datasets.utils.extract_archive", "str", "str"], "methods", ["None"], ["", "def", "_extract_archive", "(", "self", ",", "\n", "path", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "sub_directory", ":", "str", "=", "None", ",", "\n", "remove_archive", ":", "bool", "=", "False", ")", "->", "Path", ":", "\n", "        ", "\"\"\"\n        Utility method that can be used to extract an archive.\n\n        :param path: The complete path to the archive (for instance obtained\n            by calling `_download_file`).\n        :param sub_directory: The name of the sub directory where to extract the\n            archive. Can be None, which means that the archive will be extracted\n            in the root. Beware that some archives already have a root directory\n            inside of them, in which case it's probably better to use None here.\n            Defaults to None.\n        :param remove_archive: If True, the archive will be deleted after a\n            successful extraction. Defaults to False.\n        :return:\n        \"\"\"", "\n", "\n", "if", "sub_directory", "is", "None", ":", "\n", "            ", "extract_root", "=", "self", ".", "root", "\n", "", "else", ":", "\n", "            ", "extract_root", "=", "self", ".", "root", "/", "sub_directory", "\n", "\n", "", "extract_archive", "(", "str", "(", "path", ")", ",", "to_path", "=", "str", "(", "extract_root", ")", ",", "\n", "remove_finished", "=", "remove_archive", ")", "\n", "\n", "return", "extract_root", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_and_extract_archive": [[261, 295], ["downloadable_dataset.DownloadableDataset.root.mkdir", "torchvision.datasets.utils.download_and_extract_archive", "str", "str"], "methods", ["None"], ["", "def", "_download_and_extract_archive", "(", "\n", "self", ",", "url", ":", "str", ",", "file_name", ":", "str", ",", "checksum", ":", "Optional", "[", "str", "]", ",", "\n", "sub_directory", ":", "str", "=", "None", ",", "remove_archive", ":", "bool", "=", "False", ")", "->", "Path", ":", "\n", "        ", "\"\"\"\n        Utility that downloads and extracts an archive.\n\n        :param url: The download url.\n        :param file_name: The name of the archive. The file will be saved\n            in the `root` with this name. Always fill this parameter.\n            Don't pass a path! Pass a file name only!\n        :param checksum: The MD5 hash to use when verifying the downloaded\n            archive. Can be None, in which case the check will be skipped.\n            It is recommended to always fill this parameter.\n        :param sub_directory: The name of the sub directory where to extract the\n            archive. Can be None, which means that the archive will be extracted\n            in the root. Beware that some archives already have a root directory\n            inside of them, in which case it's probably better to use None here.\n            Defaults to None.\n        :param remove_archive: If True, the archive will be deleted after a\n            successful extraction. Defaults to False.\n        :return: The path to the extracted archive. If `sub_directory` is None,\n            then this will be the `root` path.\n        \"\"\"", "\n", "if", "sub_directory", "is", "None", ":", "\n", "            ", "extract_root", "=", "self", ".", "root", "\n", "", "else", ":", "\n", "            ", "extract_root", "=", "self", ".", "root", "/", "sub_directory", "\n", "\n", "", "self", ".", "root", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "download_and_extract_archive", "(", "\n", "url", ",", "str", "(", "self", ".", "root", ")", ",", "extract_root", "=", "str", "(", "extract_root", ")", ",", "\n", "filename", "=", "file_name", ",", "md5", "=", "checksum", ",", "remove_finished", "=", "remove_archive", ")", "\n", "\n", "return", "extract_root", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._check_file": [[296, 305], ["torchvision.datasets.utils.check_integrity", "str"], "methods", ["None"], ["", "def", "_check_file", "(", "self", ",", "path", ":", "Union", "[", "str", ",", "Path", "]", ",", "checksum", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Utility method to check a file.\n\n        :param path: The path to the file.\n        :param checksum: The MD5 hash to use.\n        :return: True if the MD5 hash of the file matched the given one.\n        \"\"\"", "\n", "return", "check_integrity", "(", "str", "(", "path", ")", ",", "md5", "=", "checksum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.SimpleDownloadableDataset.__init__": [[329, 376], ["super().__init__", "isinstance", "pathlib.Path", "avalanche.benchmarks.datasets.dataset_utils.default_dataset_location"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root_or_dataset_name", ":", "str", ",", "\n", "url", ":", "str", ",", "\n", "checksum", ":", "Optional", "[", "str", "]", ",", "\n", "download", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of a simple downloadable dataset.\n\n        Consider looking at the class documentation for the precise details on\n        how to extend this class.\n\n        Beware that calling this constructor only fills the `root` field. The\n        download and metadata loading procedures are triggered only by\n        calling `_load_dataset`.\n\n        :param root_or_dataset_name: The root path where the dataset will be\n            downloaded. If a directory name is passed, then the root obtained by\n            calling `default_dataset_location` will be used (recommended).\n            To check if this parameter is a path, the constructor will check if\n            it contains the '\\' or '/' characters or if it is a Path instance.\n        :param url: The url of the archive.\n        :param checksum: The MD5 hash to use when verifying the downloaded\n            archive. Can be None, in which case the check will be skipped.\n            It is recommended to always fill this parameter.\n        :param download: If True, the dataset will be downloaded if needed.\n            If False and the dataset can't be loaded from the provided root\n            path, an error will be raised when calling the `_load_dataset`\n            method. Defaults to False.\n        :param verbose: If True, some info about the download process will be\n            printed. Defaults to False.\n        \"\"\"", "\n", "\n", "self", ".", "url", "=", "url", "\n", "self", ".", "checksum", "=", "checksum", "\n", "\n", "is_path", "=", "(", "isinstance", "(", "root_or_dataset_name", ",", "Path", ")", "or", "\n", "'/'", "in", "root_or_dataset_name", "or", "'\\\\'", "in", "root_or_dataset_name", ")", "\n", "\n", "if", "is_path", ":", "\n", "            ", "root", "=", "Path", "(", "root_or_dataset_name", ")", "\n", "", "else", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "root_or_dataset_name", ")", "\n", "\n", "", "super", "(", "SimpleDownloadableDataset", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "download", "=", "download", ",", "verbose", "=", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.SimpleDownloadableDataset._download_dataset": [[377, 382], ["os.path.basename", "downloadable_dataset.SimpleDownloadableDataset._download_and_extract_archive"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_and_extract_archive"], ["", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", "\n", "self", ".", "_download_and_extract_archive", "(", "\n", "self", ".", "url", ",", "filename", ",", "self", ".", "checksum", ",", "sub_directory", "=", "None", ",", "\n", "remove_archive", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.SimpleDownloadableDataset._download_error_message": [[383, 387], ["str"], "methods", ["None"], ["", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "'Error downloading the dataset. Consider downloading '", "'it manually at: '", "+", "self", ".", "url", "+", "' and placing it '", "'in: '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS.__init__": [[29, 57], ["avalanche.benchmarks.datasets.DownloadableDataset.__init__", "openloris.OpenLORIS._load_dataset", "avalanche.benchmarks.datasets.default_dataset_location"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["def", "__init__", "(", "self", ",", "root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "*", ",", "\n", "train", "=", "True", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ",", "download", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the OpenLORIS dataset.\n\n        :param root: The directory where the dataset can be found or downloaded.\n            Defaults to None, which means that the default location for\n            'openloris' will be used.\n        :param train: If True, the training set will be returned. If False,\n            the test set will be returned.\n        :param transform: The transformations to apply to the X values.\n        :param target_transform: The transformations to apply to the Y values.\n        :param loader: The image loader to use.\n        :param download: If True, the dataset will be downloaded if needed.\n        \"\"\"", "\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'openloris'", ")", "\n", "\n", "", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "\n", "super", "(", "OpenLORIS", ",", "self", ")", ".", "__init__", "(", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS._download_dataset": [[58, 71], ["openloris.OpenLORIS._download_file", "name[].endswith", "print", "openloris.OpenLORIS._extract_archive", "print", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_file", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._extract_archive"], ["", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "data2download", "=", "openloris_data", ".", "avl_vps_data", "\n", "\n", "for", "name", "in", "data2download", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Downloading \"", "+", "name", "[", "1", "]", "+", "\"...\"", ")", "\n", "", "file", "=", "self", ".", "_download_file", "(", "name", "[", "1", "]", ",", "name", "[", "0", "]", ",", "name", "[", "2", "]", ")", "\n", "if", "name", "[", "1", "]", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "                ", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "f'Extracting {name[0]}...'", ")", "\n", "", "self", ".", "_extract_archive", "(", "file", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "'Extraction completed!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS._load_metadata": [[72, 112], ["print", "print", "print", "openloris.OpenLORIS._check_integrity", "open", "pickle.load", "open", "pickle.load", "range", "open", "pickle.load", "range", "openloris.OpenLORIS.paths.append", "openloris.OpenLORIS.targets.append", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS._check_integrity"], ["", "", "", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "# any scenario and factor is good here since we want just to load the", "\n", "# train images and targets with no particular order", "\n", "", "scen", "=", "'domain'", "\n", "factor", "=", "0", "\n", "ntask", "=", "9", "\n", "\n", "print", "(", "\"Loading paths...\"", ")", "\n", "with", "open", "(", "str", "(", "self", ".", "root", "/", "'Paths.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "train_test_paths", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "print", "(", "\"Loading labels...\"", ")", "\n", "with", "open", "(", "str", "(", "self", ".", "root", "/", "'Labels.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "all_targets", "=", "pkl", ".", "load", "(", "f", ")", "\n", "self", ".", "train_test_targets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ntask", "+", "1", ")", ":", "\n", "                ", "self", ".", "train_test_targets", "+=", "self", ".", "all_targets", "[", "scen", "]", "[", "factor", "]", "[", "i", "]", "\n", "\n", "", "", "print", "(", "\"Loading LUP...\"", ")", "\n", "with", "open", "(", "str", "(", "self", ".", "root", "/", "'LUP.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "LUP", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "idx_list", "=", "[", "]", "\n", "if", "self", ".", "train", ":", "\n", "            ", "for", "i", "in", "range", "(", "ntask", "+", "1", ")", ":", "\n", "                ", "self", ".", "idx_list", "+=", "self", ".", "LUP", "[", "scen", "]", "[", "factor", "]", "[", "i", "]", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "idx_list", "=", "self", ".", "LUP", "[", "scen", "]", "[", "factor", "]", "[", "-", "1", "]", "\n", "\n", "", "self", ".", "paths", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n", "for", "idx", "in", "self", ".", "idx_list", ":", "\n", "            ", "self", ".", "paths", ".", "append", "(", "self", ".", "train_test_paths", "[", "idx", "]", ")", "\n", "self", ".", "targets", ".", "append", "(", "self", ".", "train_test_targets", "[", "idx", "]", ")", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS._download_error_message": [[113, 130], ["str"], "methods", ["None"], ["", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "base_url", "=", "openloris_data", ".", "base_gdrive_url", "\n", "all_urls", "=", "[", "\n", "base_url", "+", "name_url", "[", "1", "]", "for", "name_url", "in", "openloris_data", ".", "avl_vps_data", "\n", "]", "\n", "\n", "base_msg", "=", "'[OpenLoris] Direct download may no longer be supported!\\n'", "'You should download data manually using the following links:\\n'", "\n", "\n", "for", "url", "in", "all_urls", ":", "\n", "            ", "base_msg", "+=", "url", "\n", "base_msg", "+=", "'\\n'", "\n", "\n", "", "base_msg", "+=", "'and place these files in '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n", "return", "base_msg", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS._check_integrity": [[131, 142], ["filepath.is_file", "print", "str"], "methods", ["None"], ["", "def", "_check_integrity", "(", "self", ")", ":", "\n", "        ", "\"\"\" Checks if the data is already available and intact \"\"\"", "\n", "\n", "for", "name", ",", "url", ",", "md5", "in", "openloris_data", ".", "avl_vps_data", ":", "\n", "            ", "filepath", "=", "self", ".", "root", "/", "name", "\n", "if", "not", "filepath", ".", "is_file", "(", ")", ":", "\n", "                ", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "'[OpenLORIS] Error checking integrity of:'", ",", "\n", "str", "(", "filepath", ")", ")", "\n", "", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS.__getitem__": [[143, 153], ["openloris.OpenLORIS.loader", "str", "openloris.OpenLORIS.transform", "openloris.OpenLORIS.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "str", "(", "self", ".", "root", "/", "self", ".", "paths", "[", "index", "]", ")", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.openloris.openloris.OpenLORIS.__len__": [[154, 156], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.__init__": [[32, 67], ["avalanche.benchmarks.datasets.SimpleDownloadableDataset.__init__", "tiny_imagenet.TinyImagenet._load_dataset", "avalanche.benchmarks.datasets.default_dataset_location"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "*", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ",", "\n", "download", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Tiny Imagenet dataset.\n\n        :param root: folder in which to download dataset. Defaults to None,\n            which means that the default location for 'tinyimagenet' will be\n            used.\n        :param train: True for training set, False for test set.\n        :param transform: Pytorch transformation function for x.\n        :param target_transform: Pytorch transformation function for y.\n        :param loader: the procedure to load the instance from the storage.\n        :param bool download: If True, the dataset will be  downloaded if\n            needed.\n        \"\"\"", "\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'tinyimagenet'", ")", "\n", "\n", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "loader", "=", "loader", "\n", "\n", "super", "(", "TinyImagenet", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "self", ".", "filename", "[", "1", "]", ",", "self", ".", "md5", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet._load_metadata": [[68, 75], ["tiny_imagenet.TinyImagenet.labels2dict", "tiny_imagenet.TinyImagenet.load_data"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.labels2dict", "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.load_data"], ["", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "self", ".", "data_folder", "=", "self", ".", "root", "/", "'tiny-imagenet-200'", "\n", "\n", "self", ".", "label2id", ",", "self", ".", "id2label", "=", "TinyImagenet", ".", "labels2dict", "(", "\n", "self", ".", "data_folder", ")", "\n", "self", ".", "data", ",", "self", ".", "targets", "=", "self", ".", "load_data", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.labels2dict": [[76, 100], ["open", "csv.reader", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "labels2dict", "(", "data_folder", ":", "Path", ")", ":", "\n", "        ", "\"\"\"\n        Returns dictionaries to convert class names into progressive ids\n        and viceversa.\n\n        :param data_folder: The root path of tiny imagenet\n        :returns: label2id, id2label: two Python dictionaries.\n        \"\"\"", "\n", "\n", "label2id", "=", "{", "}", "\n", "id2label", "=", "{", "}", "\n", "\n", "with", "open", "(", "str", "(", "data_folder", "/", "'wnids.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ")", "\n", "curr_idx", "=", "0", "\n", "for", "ll", "in", "reader", ":", "\n", "                ", "if", "ll", "[", "0", "]", "not", "in", "label2id", ":", "\n", "                    ", "label2id", "[", "ll", "[", "0", "]", "]", "=", "curr_idx", "\n", "id2label", "[", "curr_idx", "]", "=", "ll", "[", "0", "]", "\n", "curr_idx", "+=", "1", "\n", "\n", "", "", "", "return", "label2id", ",", "id2label", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.load_data": [[101, 126], ["list", "range", "tiny_imagenet.TinyImagenet.get_train_images_paths", "tiny_imagenet.TinyImagenet.get_test_images_paths", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.get_train_images_paths", "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.get_test_images_paths"], ["", "def", "load_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load all images paths and targets.\n\n        :return: train_set, test_set: (train_X_paths, train_y).\n        \"\"\"", "\n", "\n", "data", "=", "[", "[", "]", ",", "[", "]", "]", "\n", "\n", "classes", "=", "list", "(", "range", "(", "200", ")", ")", "\n", "for", "class_id", "in", "classes", ":", "\n", "            ", "class_name", "=", "self", ".", "id2label", "[", "class_id", "]", "\n", "\n", "if", "self", ".", "train", ":", "\n", "                ", "X", "=", "self", ".", "get_train_images_paths", "(", "class_name", ")", "\n", "Y", "=", "[", "class_id", "]", "*", "len", "(", "X", ")", "\n", "", "else", ":", "\n", "# test set", "\n", "                ", "X", "=", "self", ".", "get_test_images_paths", "(", "class_name", ")", "\n", "Y", "=", "[", "class_id", "]", "*", "len", "(", "X", ")", "\n", "\n", "", "data", "[", "0", "]", "+=", "X", "\n", "data", "[", "1", "]", "+=", "Y", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.get_train_images_paths": [[127, 140], ["train_img_folder.iterdir", "f.is_file"], "methods", ["None"], ["", "def", "get_train_images_paths", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "\"\"\"\n        Gets the training set image paths.\n\n        :param class_name: names of the classes of the images to be\n            collected.\n        :returns img_paths: list of strings (paths)\n        \"\"\"", "\n", "train_img_folder", "=", "self", ".", "data_folder", "/", "'train'", "/", "class_name", "/", "'images'", "\n", "\n", "img_paths", "=", "[", "f", "for", "f", "in", "train_img_folder", ".", "iterdir", "(", ")", "if", "f", ".", "is_file", "(", ")", "]", "\n", "\n", "return", "img_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.get_test_images_paths": [[141, 166], ["open", "csv.reader", "str", "valid_names.append"], "methods", ["None"], ["", "def", "get_test_images_paths", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "\"\"\"\n        Gets the test set image paths\n\n        :param class_name: names of the classes of the images to be\n            collected.\n        :returns img_paths: list of strings (paths)\n        \"\"\"", "\n", "\n", "val_img_folder", "=", "self", ".", "data_folder", "/", "'val'", "/", "'images'", "\n", "annotations_file", "=", "self", ".", "data_folder", "/", "'val'", "/", "'val_annotations.txt'", "\n", "\n", "valid_names", "=", "[", "]", "\n", "\n", "# filter validation images by class using appropriate file", "\n", "with", "open", "(", "str", "(", "annotations_file", ")", ",", "'r'", ")", "as", "f", ":", "\n", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "dialect", "=", "'excel-tab'", ")", "\n", "for", "ll", "in", "reader", ":", "\n", "                ", "if", "ll", "[", "1", "]", "==", "class_name", ":", "\n", "                    ", "valid_names", ".", "append", "(", "ll", "[", "0", "]", ")", "\n", "\n", "", "", "", "img_paths", "=", "[", "val_img_folder", "/", "f", "for", "f", "in", "valid_names", "]", "\n", "\n", "return", "img_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.__len__": [[167, 170], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the length of the set \"\"\"", "\n", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.tiny_imagenet.tiny_imagenet.TinyImagenet.__getitem__": [[171, 187], ["tiny_imagenet.TinyImagenet.loader", "int", "tiny_imagenet.TinyImagenet.transform", "tiny_imagenet.TinyImagenet.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Returns the index-th x, y pattern of the set \"\"\"", "\n", "\n", "path", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "self", ".", "loader", "(", "path", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.cub200.cub200.CUB200.__init__": [[48, 84], ["avalanche.benchmarks.datasets.DownloadableDataset.__init__", "cub200.CUB200._load_dataset", "avalanche.benchmarks.utils.PathsDataset.__init__", "avalanche.benchmarks.datasets.default_dataset_location", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "*", ",", "\n", "train", "=", "True", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ",", "download", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n\n        :param root: root dir where the dataset can be found or downloaded.\n            Defaults to None, which means that the default location for\n            'CUB_200_2011' will be used.\n        :param train: train or test subset of the original dataset. Default\n            to True.\n        :param transform: eventual input data transformations to apply.\n            Default to None.\n        :param target_transform: eventual target data transformations to apply.\n            Default to None.\n        :param loader: method to load the data from disk. Default to\n            torchvision default_loader.\n        :param download: default set to True. If the data is already\n            downloaded it will skip the download.\n        \"\"\"", "\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'CUB_200_2011'", ")", "\n", "\n", "", "self", ".", "train", "=", "train", "\n", "\n", "DownloadableDataset", ".", "__init__", "(", "\n", "self", ",", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n", "PathsDataset", ".", "__init__", "(", "\n", "self", ",", "os", ".", "path", ".", "join", "(", "root", ",", "CUB200", ".", "images_folder", ")", ",", "self", ".", "_images", ",", "\n", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", ",", "\n", "loader", "=", "loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.cub200.cub200.CUB200._download_dataset": [[85, 102], ["gdown.download", "gdown.cached_download", "cub200.CUB200._extract_archive", "cub200.CUB200._download_and_extract_archive", "str", "str", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._extract_archive", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_and_extract_archive"], ["", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "_download_and_extract_archive", "(", "\n", "CUB200", ".", "official_url", ",", "CUB200", ".", "filename", ",", "\n", "checksum", "=", "CUB200", ".", "tgz_md5", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'[CUB200] Direct download may no longer be possible, '", "\n", "'will try GDrive.'", ")", "\n", "\n", "", "", "filepath", "=", "self", ".", "root", "/", "self", ".", "filename", "\n", "gdown", ".", "download", "(", "self", ".", "gdrive_url", ",", "str", "(", "filepath", ")", ",", "quiet", "=", "False", ")", "\n", "gdown", ".", "cached_download", "(", "\n", "self", ".", "gdrive_url", ",", "str", "(", "filepath", ")", ",", "md5", "=", "self", ".", "tgz_md5", "\n", ")", "\n", "\n", "self", ".", "_extract_archive", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.cub200.cub200.CUB200._download_error_message": [[103, 107], ["str"], "methods", ["None"], ["", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "'[CUB200] Error downloading the dataset. Consider downloading '", "'it manually at: '", "+", "CUB200", ".", "official_url", "+", "' and placing it '", "'in: '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.cub200.cub200.CUB200._load_metadata": [[108, 161], ["collections.OrderedDict", "cub200.CUB200._images.items", "open", "csv.reader", "open", "csv.reader", "open", "csv.reader", "open", "csv.reader", "images_tuples.append", "str", "int", "str", "int", "str", "int", "str", "int", "tuple", "filepath.is_file", "int", "cub200.CUB200._images[].append", "cub200.CUB200._images[].append", "cub200.CUB200._images[].append", "print", "int", "int", "float"], "methods", ["None"], ["", "def", "_load_metadata", "(", "self", ")", ":", "\n", "        ", "\"\"\" Main method to load the CUB200 metadata \"\"\"", "\n", "\n", "cub_dir", "=", "self", ".", "root", "/", "'CUB_200_2011'", "\n", "self", ".", "_images", "=", "OrderedDict", "(", ")", "\n", "\n", "with", "open", "(", "str", "(", "cub_dir", "/", "'train_test_split.txt'", ")", ")", "as", "csv_file", ":", "\n", "            ", "csv_reader", "=", "csv", ".", "reader", "(", "csv_file", ",", "delimiter", "=", "' '", ")", "\n", "for", "row", "in", "csv_reader", ":", "\n", "                ", "img_id", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "is_train_instance", "=", "int", "(", "row", "[", "1", "]", ")", "==", "1", "\n", "if", "is_train_instance", "==", "self", ".", "train", ":", "\n", "                    ", "self", ".", "_images", "[", "img_id", "]", "=", "[", "]", "\n", "\n", "", "", "", "with", "open", "(", "str", "(", "cub_dir", "/", "'images.txt'", ")", ")", "as", "csv_file", ":", "\n", "            ", "csv_reader", "=", "csv", ".", "reader", "(", "csv_file", ",", "delimiter", "=", "' '", ")", "\n", "for", "row", "in", "csv_reader", ":", "\n", "                ", "img_id", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "if", "img_id", "in", "self", ".", "_images", ":", "\n", "                    ", "self", ".", "_images", "[", "img_id", "]", ".", "append", "(", "row", "[", "1", "]", ")", "\n", "\n", "", "", "", "with", "open", "(", "str", "(", "cub_dir", "/", "'image_class_labels.txt'", ")", ")", "as", "csv_file", ":", "\n", "            ", "csv_reader", "=", "csv", ".", "reader", "(", "csv_file", ",", "delimiter", "=", "' '", ")", "\n", "for", "row", "in", "csv_reader", ":", "\n", "                ", "img_id", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "if", "img_id", "in", "self", ".", "_images", ":", "\n", "# CUB starts counting classes from 1 ...", "\n", "                    ", "self", ".", "_images", "[", "img_id", "]", ".", "append", "(", "int", "(", "row", "[", "1", "]", ")", "-", "1", ")", "\n", "\n", "", "", "", "with", "open", "(", "str", "(", "cub_dir", "/", "'bounding_boxes.txt'", ")", ")", "as", "csv_file", ":", "\n", "            ", "csv_reader", "=", "csv", ".", "reader", "(", "csv_file", ",", "delimiter", "=", "' '", ")", "\n", "for", "row", "in", "csv_reader", ":", "\n", "                ", "img_id", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "if", "img_id", "in", "self", ".", "_images", ":", "\n", "                    ", "box_cub", "=", "[", "int", "(", "float", "(", "x", ")", ")", "for", "x", "in", "row", "[", "1", ":", "]", "]", "\n", "box_avl", "=", "[", "box_cub", "[", "1", "]", ",", "box_cub", "[", "0", "]", ",", "box_cub", "[", "3", "]", ",", "box_cub", "[", "2", "]", "]", "\n", "# PathsDataset accepts (top, left, height, width)", "\n", "self", ".", "_images", "[", "img_id", "]", ".", "append", "(", "box_avl", ")", "\n", "\n", "", "", "", "images_tuples", "=", "[", "]", "\n", "for", "_", ",", "img_tuple", "in", "self", ".", "_images", ".", "items", "(", ")", ":", "\n", "            ", "images_tuples", ".", "append", "(", "tuple", "(", "img_tuple", ")", ")", "\n", "", "self", ".", "_images", "=", "images_tuples", "\n", "\n", "# Integrity check", "\n", "for", "row", "in", "self", ".", "_images", ":", "\n", "            ", "filepath", "=", "self", ".", "root", "/", "CUB200", ".", "images_folder", "/", "row", "[", "0", "]", "\n", "if", "not", "filepath", ".", "is_file", "(", ")", ":", "\n", "                ", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "'[CUB200] Error checking integrity of:'", ",", "filepath", ")", "\n", "", "return", "False", "\n", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.mini_imagenet.mini_imagenet.MiniImageNetDataset.__init__": [[105, 202], ["mini_imagenet.MiniImageNetDataset.get_train_path", "isinstance", "torchvision.transforms.Resize", "dict", "dict", "mini_imagenet.MiniImageNetDataset.prepare_dataset", "torch.utils.data.dataset.Dataset.__init__", "mini_imagenet.MiniImageNetDataset.imagenet_path.exists", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.mini_imagenet.mini_imagenet.MiniImageNetDataset.get_train_path", "home.repos.pwc.inspect_result.mattdl_continualevaluation.mini_imagenet.mini_imagenet.MiniImageNetDataset.prepare_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "imagenet_path", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "split", ":", "Literal", "[", "'all'", ",", "'train'", ",", "'val'", ",", "'test'", "]", "=", "'all'", ",", "\n", "resize_to", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "84", ",", "\n", "loader", "=", "default_loader", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Mini ImageNet dataset.\n\n        This dataset allows to obtain the whole dataset or even only specific\n        splits. Beware that, when using a split different that \"all\", the\n        returned dataset will contain patterns of a subset of the 100 classes.\n        This happens because MiniImagenet was created with the idea of training,\n        validating and testing on a disjoint set of classes.\n\n        This implementation uses the filelists provided by\n        https://github.com/yaoyao-liu/mini-imagenet-tools, which are the ones\n        generated by Ravi and Larochelle (see the linked repo for more details).\n\n        :param imagenet_path: The path to the imagenet folder. This has to be\n            the path to the full imagenet 2012 folder (plain, not resized).\n            Only the \"train\" folder will be used. Because of this, passing the\n            path to the imagenet 2012 \"train\" folder is also allowed.\n        :param split: The split to obtain. Defaults to \"all\". Valid values are\n            \"all\", \"train\", \"val\" and \"test\".\n        :param resize_to: The size of the output images. Can be an `int` value\n            or a tuple of two ints. When passing a single `int` value, images\n            will be resized by forcing as 1:1 aspect ratio. Defaults to 84,\n            which means that images will have size 84x84.\n        \"\"\"", "\n", "self", ".", "imagenet_path", "=", "MiniImageNetDataset", ".", "get_train_path", "(", "imagenet_path", ")", "\n", "\"\"\"\n        The path to the \"train\" folder of full imagenet 2012 directory.\n        \"\"\"", "\n", "\n", "self", ".", "split", ":", "Literal", "[", "'all'", ",", "'train'", ",", "'val'", ",", "'test'", "]", "=", "split", "\n", "\"\"\"\n        The required split.\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "resize_to", ",", "int", ")", ":", "\n", "            ", "resize_to", "=", "(", "resize_to", ",", "resize_to", ")", "\n", "\n", "", "self", ".", "resize_to", ":", "Tuple", "[", "int", ",", "int", "]", "=", "resize_to", "\n", "\"\"\"\n        The size of the output images, as a two ints tuple.\n        \"\"\"", "\n", "\n", "# TODO: the original loader from yaoyao-liu uses cv2.INTER_AREA", "\n", "self", ".", "_transform", "=", "Resize", "(", "self", ".", "resize_to", ",", "\n", "interpolation", "=", "PIL", ".", "Image", ".", "BILINEAR", ")", "\n", "\n", "# The following fields are filled by self.prepare_dataset()", "\n", "self", ".", "image_paths", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\"\"\"\n        The paths to images.\n        \"\"\"", "\n", "\n", "self", ".", "targets", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\"\"\"\n        The class labels for the patterns. Aligned with the image_paths field.\n        \"\"\"", "\n", "\n", "self", ".", "wnids", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "\"\"\"\n        The list of wnids (the textual class labels, such as \"n02119789\").\n        \"\"\"", "\n", "\n", "self", ".", "wnid_to_idx", ":", "Dict", "[", "str", ",", "int", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        A dictionary mapping wnids to numerical labels in range [0, 100).\n        \"\"\"", "\n", "\n", "self", ".", "classes", ":", "List", "[", "Tuple", "[", "str", ",", "...", "]", "]", "=", "[", "]", "\n", "\"\"\"\n        A list mapping numerical labels (the element index) to a tuple of human\n        readable categories. For instance:\n        ('great grey owl', 'great gray owl', 'Strix nebulosa').\n        \"\"\"", "\n", "\n", "self", ".", "class_to_idx", ":", "Dict", "[", "str", ",", "int", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        A dictionary mapping each string of the tuples found in the classes \n        field to their numerical label. That is, this dictionary contains the \n        inverse mapping of classes field.\n        \"\"\"", "\n", "\n", "self", ".", "loader", "=", "loader", "\n", "\n", "if", "not", "self", ".", "imagenet_path", ".", "exists", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'The provided directory does not exist.'", ")", "\n", "\n", "", "if", "self", ".", "split", "not", "in", "[", "'all'", ",", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid split. Valid values are: \"train\", \"val\", '", "\n", "'\"test\"'", ")", "\n", "\n", "", "self", ".", "prepare_dataset", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.mini_imagenet.mini_imagenet.MiniImageNetDataset.get_train_path": [[203, 209], ["pathlib.Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_train_path", "(", "root_path", ":", "Union", "[", "str", ",", "Path", "]", ")", ":", "\n", "        ", "root_path", "=", "Path", "(", "root_path", ")", "\n", "if", "(", "root_path", "/", "'train'", ")", ".", "exists", "(", ")", ":", "\n", "            ", "return", "root_path", "/", "'train'", "\n", "", "return", "root_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.mini_imagenet.mini_imagenet.MiniImageNetDataset.prepare_dataset": [[210, 274], ["dict", "dict.keys", "str", "glob.glob", "sorted", "numpy.arange", "pathlib.Path().resolve", "open", "csv.reader", "next", "str", "lst_files.append", "int", "range", "int", "numpy.array", "len", "mini_imagenet.MiniImageNetDataset.image_paths.append", "mini_imagenet.MiniImageNetDataset.targets.append", "len", "pathlib.Path", "dict.keys", "images[].append", "numpy.array", "i.rfind", "i.index", "i.rfind", "i.index"], "methods", ["None"], ["", "def", "prepare_dataset", "(", "self", ")", ":", "\n", "# Read the CSV containing the file list for this split", "\n", "        ", "images", "=", "dict", "(", ")", "\n", "\n", "csv_dir", "=", "Path", "(", "__file__", ")", ".", "resolve", "(", ")", ".", "parent", "/", "'csv_files'", "\n", "if", "self", ".", "split", "==", "'all'", ":", "\n", "            ", "considered_csvs", "=", "[", "'train.csv'", ",", "'val.csv'", ",", "'test.csv'", "]", "\n", "", "else", ":", "\n", "            ", "considered_csvs", "=", "[", "self", ".", "split", "+", "'.csv'", "]", "\n", "\n", "", "for", "csv_name", "in", "considered_csvs", ":", "\n", "            ", "csv_path", "=", "str", "(", "csv_dir", "/", "csv_name", ")", "\n", "\n", "with", "open", "(", "csv_path", ")", "as", "csvfile", ":", "\n", "                ", "csv_reader", "=", "csv", ".", "reader", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "next", "(", "csv_reader", ",", "None", ")", "# Skip header", "\n", "\n", "for", "row", "in", "csv_reader", ":", "\n", "                    ", "if", "row", "[", "1", "]", "in", "images", ".", "keys", "(", ")", ":", "\n", "                        ", "images", "[", "row", "[", "1", "]", "]", ".", "append", "(", "row", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                        ", "images", "[", "row", "[", "1", "]", "]", "=", "[", "row", "[", "0", "]", "]", "\n", "\n", "# Fill fields like wnids, wnid_to_idx, etc.", "\n", "# Those fields have the same meaning of the ones found in the", "\n", "# torchvision implementation of the ImageNet dataset. Of course some", "\n", "# work had to be done to keep this fields aligned for mini imagenet,", "\n", "# which only contains 100 classes of the original 1000.", "\n", "#", "\n", "# wnids are 'n01440764', 'n01443537', 'n01484850', etc.", "\n", "#", "\n", "# self.wnid_to_idx is a dict mapping wnids to numerical labels", "\n", "#", "\n", "# self.classes is a list mapping numerical labels (the element", "\n", "# index) to a tuple of human readable categories. For instance:", "\n", "# ('great grey owl', 'great gray owl', 'Strix nebulosa').", "\n", "#", "\n", "# self.class_to_idx is a dict mapping each string of the", "\n", "# aforementioned tuples to its numerical label. That is, it contains", "\n", "# the inverse mapping of self.classes.", "\n", "", "", "", "", "self", ".", "wnids", "=", "MINI_IMAGENET_WNIDS", "\n", "self", ".", "wnid_to_idx", "=", "MINI_IMAGENET_WNID_TO_IDX", "\n", "self", ".", "classes", "=", "MINI_IMAGENET_CLASSES", "\n", "self", ".", "class_to_idx", "=", "MINI_IMAGENET_CLASS_TO_IDX", "\n", "\n", "for", "cls", "in", "images", ".", "keys", "(", ")", ":", "\n", "            ", "cls_numerical_label", "=", "self", ".", "wnid_to_idx", "[", "cls", "]", "\n", "lst_files", "=", "[", "]", "\n", "for", "file", "in", "glob", ".", "glob", "(", "str", "(", "self", ".", "imagenet_path", "/", "cls", "/", "\n", "(", "\"*\"", "+", "cls", "+", "\"*\"", ")", ")", ")", ":", "\n", "                ", "lst_files", ".", "append", "(", "file", ")", "\n", "\n", "", "lst_index", "=", "[", "int", "(", "i", "[", "i", ".", "rfind", "(", "'_'", ")", "+", "1", ":", "i", ".", "rfind", "(", "'.'", ")", "]", ")", "for", "i", "in", "\n", "lst_files", "]", "\n", "index_sorted", "=", "sorted", "(", "range", "(", "len", "(", "lst_index", ")", ")", ",", "\n", "key", "=", "lst_index", ".", "__getitem__", ")", "\n", "\n", "index_selected", "=", "[", "int", "(", "i", "[", "i", ".", "index", "(", "'.'", ")", "-", "4", ":", "i", ".", "index", "(", "'.'", ")", "]", ")", "for", "\n", "i", "in", "images", "[", "cls", "]", "]", "\n", "selected_images", "=", "np", ".", "array", "(", "index_sorted", ")", "[", "\n", "np", ".", "array", "(", "index_selected", ")", "-", "1", "]", "\n", "for", "i", "in", "np", ".", "arange", "(", "len", "(", "selected_images", ")", ")", ":", "\n", "                ", "self", ".", "image_paths", ".", "append", "(", "lst_files", "[", "selected_images", "[", "i", "]", "]", ")", "\n", "self", ".", "targets", ".", "append", "(", "cls_numerical_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.mini_imagenet.mini_imagenet.MiniImageNetDataset.__len__": [[275, 277], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.mini_imagenet.mini_imagenet.MiniImageNetDataset.__getitem__": [[278, 282], ["mini_imagenet.MiniImageNetDataset.loader", "mini_imagenet.MiniImageNetDataset._transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "img", "=", "self", ".", "loader", "(", "self", ".", "image_paths", "[", "item", "]", ")", "\n", "img", "=", "self", ".", "_transform", "(", "img", ")", "\n", "return", "img", ",", "self", ".", "targets", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.ClassificationSubSequence.__init__": [[37, 66], ["endless_cl_sim.ClassificationSubSequence._load_labelmap"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._load_labelmap"], ["def", "__init__", "(", "self", ",", "file_paths", ",", "targets", ",", "patch_size", "=", "64", ",", "\n", "labelmap_path", "=", "None", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Dataset containing image-patches and targets for one subsequence of\n        an endless continual learning simulator's sequence, that has been\n        converted for image-patch classification.\n\n        :param file_paths: List that contains the paths to all images files\n            that are part of this subsequence.\n        :param targets: List that contains the targets (`object category \n            names` (str)) for each respective image.\n        :param patch_size: Int defining the quadratic patch-size the \n            image-patches are resized to.\n        :param labelmap_path: Path to a `labelmap.json` file that specifies\n            a mapping from `object category names` to labels. \n        :param transform: Eventual transformations to be applied to the image \n            data.\n        :param target_transform: Eventual transformations to be applied to the \n            target data.\n        \"\"\"", "\n", "self", ".", "file_paths", "=", "file_paths", "\n", "self", ".", "targets", "=", "targets", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "self", ".", "labelmap", "=", "self", ".", "_load_labelmap", "(", "labelmap_path", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.ClassificationSubSequence._pil_loader": [[67, 72], ["open", "PIL.Image.open().convert().resize", "PIL.Image.open().convert", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize"], ["", "def", "_pil_loader", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "\"RGB\"", ")", ".", "resize", "(", "\n", "(", "self", ".", "patch_size", ",", "self", ".", "patch_size", ")", ",", "Image", ".", "NEAREST", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.ClassificationSubSequence._load_labelmap": [[73, 87], ["ValueError", "pathlib.Path().exists", "pathlib.Path", "open", "json.load"], "methods", ["None"], ["", "def", "_load_labelmap", "(", "self", ",", "path", ")", ":", "\n", "# If path is None, load default labelmap", "\n", "        ", "if", "path", "is", "None", ":", "\n", "            ", "return", "endless_cl_sim_data", ".", "default_classification_labelmap", "\n", "\n", "# If path is valid, load labelmap from json file", "\n", "", "elif", "Path", "(", "path", ")", ".", "exists", "(", ")", ":", "\n", "            ", "with", "open", "(", "path", ")", "as", "file", ":", "\n", "                ", "json_array", "=", "json", ".", "load", "(", "file", ")", "\n", "labelmap", "=", "json_array", "[", "\"SegmentationClasses\"", "]", "\n", "return", "labelmap", "\n", "\n", "# Finally, raise value error", "\n", "", "", "raise", "ValueError", "(", "f\"path: {path} does not exist!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.ClassificationSubSequence._convert_target": [[88, 90], ["None"], "methods", ["None"], ["", "def", "_convert_target", "(", "self", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "labelmap", "[", "target", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.ClassificationSubSequence.__getitem__": [[91, 102], ["endless_cl_sim.ClassificationSubSequence._convert_target", "endless_cl_sim.ClassificationSubSequence._pil_loader", "endless_cl_sim.ClassificationSubSequence.transform", "endless_cl_sim.ClassificationSubSequence.target_transform"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._convert_target", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._pil_loader"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "img_path", "=", "self", ".", "file_paths", "[", "index", "]", "\n", "target", "=", "self", ".", "_convert_target", "(", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n", "img", "=", "self", ".", "_pil_loader", "(", "img_path", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.ClassificationSubSequence.__len__": [[103, 105], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "file_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence.__init__": [[110, 151], ["endless_cl_sim.VideoSubSequence._load_classmap", "endless_cl_sim.VideoSubSequence._load_labelmap"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._load_classmap", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._load_labelmap"], ["def", "__init__", "(", "self", ",", "file_paths", ",", "target_paths", ",", "\n", "segmentation_file", ",", "classmap_file", "=", "None", ",", "patch_size", "=", "(", "240", ",", "135", ")", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Dataset that contains the (image) data and semantic segmentation targets \n        for one subsequence of a video sequence. \n\n        :param file_paths: List containing the paths to all images files that \n            are part of this subsequence.\n        :param target_paths: List containing the paths to all target files \n            corresponding to the `file_paths`. \n        :param segmentation_file: Path to a `segmentation.json` file that \n            specifies a mapping from label indices to object  \n            (or object category) names. Defaults to None, which loads a \n            predefined default mapping.\n        :param classmap_file: Path to a `classmap.json' file that specifies\n            the mapping from object (or object category) names to a \n            respective label. Defaults to None, which loads a predefined\n            default mapping.\n        :param patch_size: Size of the images and target data to be resized to.\n            Defaults to (240, 135).\n        :param transform: Eventual transformations to be applied to the image \n            data.\n        :param target_transform: Eventual transformations to be applied to the \n            target data.\n        \"\"\"", "\n", "self", ".", "file_paths", "=", "file_paths", "\n", "self", ".", "targets", "=", "target_paths", "\n", "self", ".", "segmentation_file", "=", "segmentation_file", "\n", "self", ".", "classmap_file", "=", "classmap_file", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "transform", "\n", "\n", "# Init classmap", "\n", "self", ".", "classmap", "=", "self", ".", "_load_classmap", "(", "classmap_file", "=", "self", ".", "classmap_file", ")", "\n", "\n", "# Init labelmap", "\n", "self", ".", "labelmap", "=", "self", ".", "_load_labelmap", "(", "\n", "labelmap_file", "=", "self", ".", "segmentation_file", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._pil_loader": [[152, 160], ["open", "PIL.Image.open().convert().resize", "PIL.Image.open().convert", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize"], ["", "def", "_pil_loader", "(", "self", ",", "file_path", ",", "is_target", "=", "False", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "convert_identifier", "=", "\"RGB\"", "\n", "if", "is_target", ":", "\n", "                ", "convert_identifier", "=", "\"L\"", "\n", "", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "convert_identifier", ")", ".", "resize", "(", "\n", "(", "self", ".", "patch_size", "[", "0", "]", ",", "self", ".", "patch_size", "[", "1", "]", ")", ",", "Image", ".", "NEAREST", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._load_classmap": [[161, 172], ["pathlib.Path().exists", "ValueError", "pathlib.Path", "open", "json.load"], "methods", ["None"], ["", "def", "_load_classmap", "(", "self", ",", "classmap_file", ")", ":", "\n", "        ", "classmap", "=", "{", "}", "\n", "if", "classmap_file", "is", "None", ":", "\n", "            ", "classmap", "=", "endless_cl_sim_data", ".", "default_semseg_classmap_obj", "\n", "", "elif", "Path", "(", "classmap_file", ")", ".", "exists", "(", ")", ":", "\n", "            ", "with", "open", "(", "classmap_file", ")", "as", "file", ":", "\n", "                ", "json_array", "=", "json", ".", "load", "(", "file", ")", "\n", "classmap", "=", "json_array", "[", "\"ClassMapping\"", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"classmap_file: {classmap_file} does not exist!\"", ")", "\n", "", "return", "classmap", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._load_labelmap": [[173, 187], ["pathlib.Path().exists", "ValueError", "pathlib.Path", "open", "json.load"], "methods", ["None"], ["", "def", "_load_labelmap", "(", "self", ",", "labelmap_file", ")", ":", "\n", "        ", "labelmap", "=", "{", "}", "\n", "if", "Path", "(", "labelmap_file", ")", ".", "exists", "(", ")", ":", "\n", "            ", "with", "open", "(", "labelmap_file", ")", "as", "file", ":", "\n", "                ", "json_array", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "segMin", "=", "json_array", "[", "0", "]", "[", "\"ObjectClassMapping\"", "]", "\n", "segMax", "=", "json_array", "[", "1", "]", "[", "\"ObjectClassMapping\"", "]", "\n", "\n", "for", "key", "in", "segMin", ":", "\n", "                    ", "labelmap", "[", "key", "]", "=", "[", "segMin", "[", "key", "]", ",", "segMax", "[", "key", "]", "]", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"labelmap_file: {labelmap_file} does not exist!\"", ")", "\n", "", "return", "labelmap", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._get_label_name": [[188, 198], ["ValueError"], "methods", ["None"], ["", "def", "_get_label_name", "(", "self", ",", "label", ")", ":", "\n", "        ", "for", "key", "in", "self", ".", "labelmap", ":", "\n", "            ", "min_val", ",", "max_val", "=", "self", ".", "labelmap", "[", "key", "]", "\n", "if", "min_val", "==", "max_val", ":", "\n", "                ", "if", "label", "==", "min_val", ":", "\n", "                    ", "return", "key", "\n", "", "", "else", ":", "\n", "                ", "if", "label", ">=", "min_val", "and", "label", "<=", "max_val", ":", "\n", "                    ", "return", "key", "\n", "", "", "", "raise", "ValueError", "(", "f\"label: {label} could not be converted!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._convert_target": [[199, 214], ["target.copy.copy.copy", "torch.unique().numpy", "endless_cl_sim.VideoSubSequence._get_label_name", "torch.unique", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._get_label_name"], ["", "def", "_convert_target", "(", "self", ",", "target", ")", ":", "\n", "        ", "\"\"\" \n        Converts segmentation target (instance-segmented) according to classmap\n        \"\"\"", "\n", "# Get all unique labels in target", "\n", "target", "=", "target", ".", "copy", "(", ")", "\n", "unique_labels", "=", "torch", ".", "unique", "(", "torch", ".", "tensor", "(", "target", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "unique_label", "in", "unique_labels", ":", "\n", "# Get respective obj class label", "\n", "            ", "label_name", "=", "self", ".", "_get_label_name", "(", "unique_label", ")", "\n", "class_label", "=", "self", ".", "classmap", "[", "label_name", "]", "\n", "# Convert instance label to object class label", "\n", "target", "[", "target", "==", "unique_label", "]", "=", "class_label", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence.__getitem__": [[215, 228], ["endless_cl_sim.VideoSubSequence._pil_loader", "endless_cl_sim.VideoSubSequence.transform", "endless_cl_sim.VideoSubSequence._pil_loader", "endless_cl_sim.VideoSubSequence._convert_target", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._pil_loader", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._pil_loader", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence._convert_target"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "img_path", "=", "self", ".", "file_paths", "[", "index", "]", "\n", "target_path", "=", "self", ".", "targets", "[", "index", "]", "\n", "\n", "# Load image", "\n", "img", "=", "self", ".", "_pil_loader", "(", "img_path", ",", "is_target", "=", "False", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "# Load target", "\n", "target", "=", "self", ".", "_pil_loader", "(", "target_path", ",", "is_target", "=", "True", ")", "\n", "target", "=", "self", ".", "_convert_target", "(", "np", ".", "asarray", "(", "target", ")", ")", "\n", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.VideoSubSequence.__len__": [[229, 231], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "file_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset.__init__": [[236, 323], ["avalanche.benchmarks.datasets.downloadable_dataset.DownloadableDataset.__init__", "endless_cl_sim.EndlessCLSimDataset._load_dataset", "avalanche.benchmarks.datasets.default_dataset_location", "ValueError", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "*", ",", "\n", "scenario", "=", "None", ",", "patch_size", "=", "64", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "download", "=", "True", ",", "semseg", "=", "False", ",", "\n", "labelmap_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Endless-Continual-Leanring-Simulator Dataset.\n        This dataset is able to download and prepare datasets derived from the \n        Endless-Continual-Learning Simulator, including settings of incremental \n        classes, decrasing illumination, and shifting weather conditions, as \n        described in the paper `A Procedural World Generation Framework for \n        Systematic Evaluation of Continual Learning' \n        (https://arxiv.org/abs/2106.02585). Also custom datasets are supported \n        when following the same structure. Such can be obtained from the \n        Endless-CL-Simulator standalone application \n        (https://zenodo.org/record/4899294).\n\n        Please note:\n        1) The EndlessCLSimDataset does not provide examples directly, but \n        SubsequenceDatasets (ClassificationSubSequence, VideoSubSequence). Each \n        SubSequenceDataset will contain the samples for one respective sub \n        sequence. \n\n        2) For video sequences currently only one sequence per dataset is \n        supported!\n\n        :param root: root for the datasets data. Defaults to None, which means\n        that the default location for 'endless-cl-sim' will be used.\n        :param scenario: identifier for the dataset to be used. \n        Predefined options are 'Classes', for incremental classes scenario, \n            'Illumination', for the decreasing lighting scenario, \n            and 'Weather', for the scenario of shifting weather conditions.\n            To load a custom (non-predefined/downloadable) dataset, the \n            identifier needs to be set to None. Defaults to None.\n        :param patch_size: optional size of image data to be loaded. \n            For classification the patch_size is of type `int`, because we only\n            consider quadratic input sizes. If the `semseg` flag is set, \n            the patch_size type is `tuple`, with `(width, height)`.\n        :param transform: optional transformations to be applied to the image \n            data.\n        :param target_transform: optional transformations to be applied to the \n            targets.\n        :param download: boolean to automatically download data. \n            Defaults to True.\n        :param semseg: boolean to indicate the use of targets for a \n            semantic segmentation task. Defaults to False.\n        :param labelmap_path: path (str) to a labelmap.json file,\n            that provides a dictionary mapping 'class-names'(str) to \n            class-labels(int). The 'class-names' are derived from the \n            sub-directory names for each subsequence.\n        \"\"\"", "\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'endless-cl-sim'", ")", "\n", "\n", "", "if", "scenario", "is", "None", "and", "download", ":", "\n", "            ", "raise", "ValueError", "(", "\"No scenario defined to download!\"", ")", "\n", "\n", "", "super", "(", "EndlessCLSimDataset", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "\n", "self", ".", "scenario", "=", "scenario", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "semseg", "=", "semseg", "\n", "self", ".", "labelmap_path", "=", "labelmap_path", "\n", "\n", "self", ".", "train_sub_sequence_datasets", "=", "[", "]", "\n", "self", ".", "test_sub_sequence_datasets", "=", "[", "]", "\n", "\n", "if", "self", ".", "semseg", "and", "self", ".", "patch_size", "==", "64", ":", "\n", "            ", "self", ".", "patch_size", "=", "(", "240", ",", "135", ")", "\n", "\n", "", "if", "self", ".", "semseg", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "patch_size", ",", "tuple", ")", ",", "\"If semseg is False, patch_size needs to be of type `int`\"", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "patch_size", ",", "int", ")", ",", "\"If semseg is True, patch_size needs to be of type `tuple`\"", "\n", "\n", "# Download the dataset and initialize metadata", "\n", "", "self", ".", "_load_dataset", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._get_scenario_data": [[324, 348], ["ValueError"], "methods", ["None"], ["", "def", "_get_scenario_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            tuple: (\"DataName.zip\", \"download-url\", \"MD5-checksum\") of a \n            derived data to be used, as defined in endless_cl_sim_data.py\n        \"\"\"", "\n", "data", "=", "endless_cl_sim_data", ".", "data", "\n", "# Video data", "\n", "if", "self", ".", "semseg", ":", "\n", "            ", "if", "self", ".", "scenario", "==", "\"Classes\"", ":", "\n", "                ", "return", "data", "[", "3", "]", "\n", "", "if", "self", ".", "scenario", "==", "\"Illumination\"", ":", "\n", "                ", "return", "data", "[", "4", "]", "\n", "", "if", "self", ".", "scenario", "==", "\"Weather\"", ":", "\n", "                ", "return", "data", "[", "5", "]", "\n", "# Image-patch (classification) data", "\n", "", "", "if", "self", ".", "scenario", "==", "\"Classes\"", ":", "\n", "            ", "return", "data", "[", "0", "]", "\n", "", "if", "self", ".", "scenario", "==", "\"Illumination\"", ":", "\n", "            ", "return", "data", "[", "1", "]", "\n", "", "if", "self", ".", "scenario", "==", "\"Weather\"", ":", "\n", "            ", "return", "data", "[", "2", "]", "\n", "\n", "", "raise", "ValueError", "(", "\"Provided 'scenario' parameter is not valid!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._prepare_classification_subsequence_datasets": [[349, 410], ["glob.glob", "glob.glob", "print", "len", "len", "print", "endless_cl_sim.ClassificationSubSequence", "len", "len", "os.listdir", "sequence_path.lower", "endless_cl_sim.EndlessCLSimDataset.train_sub_sequence_datasets.append", "os.scandir", "f.is_dir", "image_paths.append", "targets.append", "sequence_path.lower", "endless_cl_sim.EndlessCLSimDataset.test_sub_sequence_datasets.append", "ValueError"], "methods", ["None"], ["", "def", "_prepare_classification_subsequence_datasets", "(", "self", ",", "path", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): Path to the root of the data to be loaded.\n\n        Returns:\n            success (bool): Boolean wether the preparation was successfull.\n        \"\"\"", "\n", "# Get sequence dirs", "\n", "sequence_paths", "=", "glob", ".", "glob", "(", "path", "+", "os", ".", "path", ".", "sep", "+", "\"*\"", "+", "os", ".", "path", ".", "sep", ")", "\n", "\n", "# For every sequence (train, test)", "\n", "for", "sequence_path", "in", "sequence_paths", ":", "\n", "            ", "sub_sequence_paths", "=", "glob", ".", "glob", "(", "\n", "sequence_path", "+", "os", ".", "path", ".", "sep", "+", "\"*\"", "+", "os", ".", "path", ".", "sep", ")", "\n", "# Get sub-sequence dirs (0,1,....,n)       ", "\n", "for", "sub_sequence_path", "in", "sub_sequence_paths", ":", "\n", "                ", "image_paths", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "# Get class dirs", "\n", "class_name_dirs", "=", "[", "f", ".", "name", "for", "f", "\n", "in", "os", ".", "scandir", "(", "\n", "sub_sequence_path", "+", "os", ".", "path", ".", "sep", ")", "\n", "if", "f", ".", "is_dir", "(", ")", "]", "\n", "\n", "# Load file_paths and targets", "\n", "for", "class_name", "in", "class_name_dirs", ":", "\n", "                    ", "class_path", "=", "sub_sequence_path", "+", "class_name", "+", "os", ".", "path", ".", "sep", "\n", "for", "file_name", "in", "os", ".", "listdir", "(", "class_path", ")", ":", "\n", "                        ", "image_paths", ".", "append", "(", "class_path", "+", "file_name", ")", "\n", "targets", ".", "append", "(", "class_name", ")", "\n", "\n", "# Create sub-sequence dataset", "\n", "", "", "subsequence_dataset", "=", "ClassificationSubSequence", "(", "\n", "image_paths", ",", "targets", ",", "patch_size", "=", "self", ".", "patch_size", ",", "\n", "labelmap_path", "=", "self", ".", "labelmap_path", ",", "\n", "transform", "=", "self", ".", "transform", ",", "\n", "target_transform", "=", "self", ".", "target_transform", ")", "\n", "if", "\"train\"", "in", "(", "sequence_path", ".", "lower", "(", ")", ")", ":", "\n", "                    ", "self", ".", "train_sub_sequence_datasets", ".", "append", "(", "subsequence_dataset", ")", "\n", "", "elif", "\"test\"", "in", "(", "sequence_path", ".", "lower", "(", ")", ")", ":", "\n", "                    ", "self", ".", "test_sub_sequence_datasets", ".", "append", "(", "subsequence_dataset", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Sequence path contains neighter 'train' nor \\\n                            'test' identifier!\"", ")", "\n", "\n", "# Check number of train and test subsequence datasets are equal", "\n", "", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Num train subsequences:\"", ",", "\n", "len", "(", "self", ".", "train_sub_sequence_datasets", ")", ",", "\n", "\"Num test subsequences:\"", ",", "\n", "len", "(", "self", ".", "test_sub_sequence_datasets", ")", ")", "\n", "", "assert", "(", "len", "(", "self", ".", "train_sub_sequence_datasets", ")", "\n", "==", "len", "(", "self", ".", "test_sub_sequence_datasets", ")", ")", "\n", "\n", "# Has run without errors", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Successfully created subsequence datasets..\"", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._load_sequence_indices": [[411, 419], ["open", "json.load", "range", "len"], "methods", ["None"], ["", "def", "_load_sequence_indices", "(", "self", ",", "sequence_file", ")", ":", "\n", "        ", "sequence_indices", "=", "{", "}", "\n", "with", "open", "(", "sequence_file", ")", "as", "file", ":", "\n", "            ", "json_array", "=", "json", ".", "load", "(", "file", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "json_array", ")", ")", ":", "\n", "                ", "sequence_indices", "[", "i", "]", "=", "json_array", "[", "i", "]", "[", "\"Sequence\"", "]", "[", "\"ImageCounter\"", "]", "\n", "", "", "return", "sequence_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._prepare_video_subsequence_datasets": [[420, 518], ["glob.glob", "glob.glob", "endless_cl_sim.EndlessCLSimDataset._load_sequence_indices", "range", "pathlib.Path().is_dir", "pathlib.Path().is_file", "print", "print", "print", "print", "print", "len", "endless_cl_sim.VideoSubSequence", "len", "len", "len", "len", "len", "len", "sequence_path.lower", "endless_cl_sim.EndlessCLSimDataset.train_sub_sequence_datasets.append", "pathlib.Path", "data_content.split", "sorted", "pathlib.Path", "sequence_path.lower", "endless_cl_sim.EndlessCLSimDataset.test_sub_sequence_datasets.append", "ValueError", "os.listdir", "image_paths.append", "sorted", "os.listdir", "target_paths.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._load_sequence_indices"], ["", "def", "_prepare_video_subsequence_datasets", "(", "self", ",", "path", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): Path to the root of the data to be loaded.\n\n        Returns:\n            success (bool): Boolean wether the preparation was successfull.\n        \"\"\"", "\n", "# Get sequence dirs", "\n", "sequence_paths", "=", "glob", ".", "glob", "(", "path", "+", "os", ".", "path", ".", "sep", "+", "\"*\"", "+", "os", ".", "path", ".", "sep", ")", "\n", "\n", "# For every sequence (train, test)", "\n", "for", "sequence_path", "in", "sequence_paths", ":", "\n", "# Get dir contents (data + files)", "\n", "            ", "data_contents", "=", "glob", ".", "glob", "(", "sequence_path", "+", "os", ".", "path", ".", "sep", "+", "\"*\"", ")", "\n", "\n", "image_paths", "=", "[", "]", "\n", "target_paths", "=", "[", "]", "\n", "sequence_file", "=", "None", "\n", "segmentation_file", "=", "None", "\n", "\n", "# Get Color, Seg dirs", "\n", "for", "data_content", "in", "data_contents", ":", "\n", "# If directory", "\n", "                ", "if", "Path", "(", "data_content", ")", ".", "is_dir", "(", ")", ":", "\n", "                    ", "dir_name", "=", "data_content", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "-", "1", "]", "\n", "if", "\"Color\"", "==", "dir_name", ":", "\n", "# Extend color path", "\n", "                        ", "color_path", "=", "data_content", "+", "os", ".", "path", ".", "sep", "+", "\"0\"", "+", "os", ".", "path", ".", "sep", "\n", "# Get all files", "\n", "for", "file_name", "in", "sorted", "(", "os", ".", "listdir", "(", "color_path", ")", ")", ":", "\n", "                            ", "image_paths", ".", "append", "(", "color_path", "+", "file_name", ")", "\n", "", "", "elif", "\"Seg\"", "==", "dir_name", ":", "\n", "# Extend seg path", "\n", "                        ", "seg_path", "=", "data_content", "+", "os", ".", "path", ".", "sep", "+", "\"0\"", "+", "os", ".", "path", ".", "sep", "\n", "# Get all files", "\n", "for", "file_name", "in", "sorted", "(", "os", ".", "listdir", "(", "seg_path", ")", ")", ":", "\n", "                            ", "target_paths", ".", "append", "(", "seg_path", "+", "file_name", ")", "\n", "\n", "# If file", "\n", "", "", "", "if", "Path", "(", "data_content", ")", ".", "is_file", "(", ")", ":", "\n", "                    ", "if", "\"Sequence.json\"", "in", "data_content", ":", "\n", "                        ", "sequence_file", "=", "data_content", "\n", "", "elif", "\"Segmentation.json\"", "in", "data_content", ":", "\n", "                        ", "segmentation_file", "=", "data_content", "\n", "\n", "# Final checks", "\n", "", "", "", "if", "not", "len", "(", "image_paths", ")", "==", "len", "(", "target_paths", ")", ":", "\n", "                ", "print", "(", "\"Not equal number of images and targets!\"", ")", "\n", "return", "False", "\n", "", "if", "sequence_file", "is", "None", ":", "\n", "                ", "print", "(", "\"No Sequence.json found!\"", ")", "\n", "return", "False", "\n", "", "if", "segmentation_file", "is", "None", ":", "\n", "                ", "print", "(", "\"No Segmentation.json found!\"", ")", "\n", "return", "False", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"All metadata checks complete!\"", ")", "\n", "\n", "", "sequence_indices", "=", "self", ".", "_load_sequence_indices", "(", "\n", "sequence_file", "=", "sequence_file", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Sequence file loaded..\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "sequence_indices", ")", ")", ":", "\n", "                ", "last_index", "=", "sequence_indices", "[", "i", "]", "\n", "if", "(", "i", "+", "1", ")", "==", "len", "(", "sequence_indices", ")", ":", "\n", "                    ", "next_index", "=", "len", "(", "image_paths", ")", "\n", "", "else", ":", "\n", "                    ", "next_index", "=", "sequence_indices", "[", "i", "+", "1", "]", "\n", "\n", "", "image_subsequence_paths", "=", "image_paths", "[", "last_index", ":", "next_index", "]", "\n", "target_subsequence_paths", "=", "target_paths", "[", "last_index", ":", "next_index", "]", "\n", "\n", "assert", "(", "len", "(", "image_subsequence_paths", ")", "==", "\n", "len", "(", "target_subsequence_paths", ")", ")", "\n", "\n", "# Create subsequence dataset", "\n", "subsequence_dataset", "=", "VideoSubSequence", "(", "image_subsequence_paths", ",", "\n", "target_subsequence_paths", ",", "\n", "segmentation_file", ",", "\n", "patch_size", "=", "self", ".", "patch_size", ",", "\n", "transform", "=", "self", ".", "transform", ",", "\n", "target_transform", "=", "self", ".", "target_transform", ")", "\n", "if", "\"train\"", "in", "(", "sequence_path", ".", "lower", "(", ")", ")", ":", "\n", "                    ", "self", ".", "train_sub_sequence_datasets", ".", "append", "(", "subsequence_dataset", ")", "\n", "", "elif", "\"test\"", "in", "(", "sequence_path", ".", "lower", "(", ")", ")", ":", "\n", "                    ", "self", ".", "test_sub_sequence_datasets", ".", "append", "(", "subsequence_dataset", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Sequence path contains neighter 'train' nor \\\n                             'test' identifiers!\"", ")", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset.__getitem__": [[519, 530], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (TrainSubSeqquenceDataset, TestSubSequenceDataset), \n            the i-th subsequence data, as requested by the provided index.\n        \"\"\"", "\n", "return", "self", ".", "train_sub_sequence_datasets", "[", "index", "]", ",", "self", ".", "test_sub_sequence_datasets", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset.__len__": [[531, 533], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "train_sub_sequence_datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._download_dataset": [[534, 561], ["endless_cl_sim.EndlessCLSimDataset._get_scenario_data", "endless_cl_sim.EndlessCLSimDataset._download_file", "data_name[].endswith", "print", "endless_cl_sim.EndlessCLSimDataset._extract_archive", "glob.glob", "print", "data_name[].split", "endless_cl_sim.EndlessCLSimDataset._extract_archive", "print", "str", "file_name.split", "print", "print", "sub_file_name.split"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._get_scenario_data", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_file", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._extract_archive", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._extract_archive"], ["", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "data_name", "=", "self", ".", "_get_scenario_data", "(", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Downloading \"", "+", "data_name", "[", "1", "]", "+", "\"...\"", ")", "\n", "", "file", "=", "self", ".", "_download_file", "(", "data_name", "[", "1", "]", ",", "data_name", "[", "0", "]", ",", "data_name", "[", "2", "]", ")", "\n", "if", "data_name", "[", "1", "]", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "f'Extracting {data_name[0]}...'", ")", "\n", "", "extract_subdir", "=", "data_name", "[", "0", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "extract_root", "=", "self", ".", "_extract_archive", "(", "file", ",", "extract_subdir", ")", "\n", "\n", "# see all extracted files and extract all .zip again", "\n", "extract_root_file_list", "=", "glob", ".", "glob", "(", "str", "(", "extract_root", ")", "+", "\"/*\"", ")", "\n", "for", "file_name", "in", "extract_root_file_list", ":", "\n", "                ", "sub_file_name", "=", "file_name", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "extract_subsubdir", "=", "extract_subdir", "+", "\"/\"", "+", "sub_file_name", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "f\"Extracting: {sub_file_name} to {extract_subdir}\"", ")", "\n", "", "self", ".", "_extract_archive", "(", "\n", "file_name", ",", "extract_subdir", ",", "remove_archive", "=", "True", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "\"Extraction complete!\"", ")", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"All extractions complete!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._load_metadata": [[562, 615], ["endless_cl_sim.EndlessCLSimDataset._get_scenario_data", "endless_cl_sim.EndlessCLSimDataset._prepare_classification_subsequence_datasets", "endless_cl_sim.EndlessCLSimDataset._prepare_video_subsequence_datasets", "print", "scenario_data_name[].split", "endless_cl_sim.EndlessCLSimDataset._prepare_classification_subsequence_datasets", "endless_cl_sim.EndlessCLSimDataset._prepare_video_subsequence_datasets", "print", "str", "str", "data_name[].split", "str", "str", "str", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._get_scenario_data", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._prepare_classification_subsequence_datasets", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._prepare_video_subsequence_datasets", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._prepare_classification_subsequence_datasets", "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._prepare_video_subsequence_datasets"], ["", "", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "# If a 'named'-scenario has been selected", "\n", "        ", "if", "self", ".", "scenario", "is", "not", "None", ":", "\n", "# Get data name", "\n", "            ", "scenario_data_name", "=", "self", ".", "_get_scenario_data", "(", ")", "\n", "scenario_data_name", "=", "scenario_data_name", "[", "0", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "# Check matching directory exists in endless_cl_sim_data", "\n", "match_path", "=", "None", "\n", "for", "data_name", "in", "endless_cl_sim_data", ".", "data", ":", "\n", "                ", "name", "=", "data_name", "[", "0", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "# Omit non selected directories", "\n", "if", "str", "(", "scenario_data_name", ")", "==", "str", "(", "name", ")", ":", "\n", "# Check there is such a directory", "\n", "                    ", "if", "(", "self", ".", "root", "/", "name", ")", ".", "exists", "(", ")", ":", "\n", "                        ", "if", "match_path", "is", "not", "None", ":", "\n", "                            ", "raise", "ValueError", "(", "\n", "\"Two directories match the selected scenario!\"", ")", "\n", "", "match_path", "=", "str", "(", "self", ".", "root", "/", "name", ")", "\n", "\n", "", "", "", "if", "match_path", "is", "None", ":", "\n", "                ", "return", "False", "\n", "\n", "", "if", "not", "self", ".", "semseg", ":", "\n", "                ", "is_subsequence_preparation_done", "=", "self", ".", "_prepare_classification_subsequence_datasets", "(", "\n", "match_path", ")", "\n", "", "else", ":", "\n", "                ", "is_subsequence_preparation_done", "=", "self", ".", "_prepare_video_subsequence_datasets", "(", "match_path", ")", "\n", "\n", "", "if", "is_subsequence_preparation_done", "and", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Data is loaded..\"", ")", "\n", "", "else", ":", "\n", "                ", "return", "False", "\n", "", "return", "True", "\n", "\n", "# If a 'generic'-endless-cl-sim-scenario has been selected", "\n", "", "if", "not", "self", ".", "semseg", ":", "\n", "            ", "is_subsequence_preparation_done", "=", "self", ".", "_prepare_classification_subsequence_datasets", "(", "\n", "str", "(", "self", ".", "root", ")", ")", "\n", "", "else", ":", "\n", "            ", "is_subsequence_preparation_done", "=", "self", ".", "_prepare_video_subsequence_datasets", "(", "\n", "str", "(", "self", ".", "root", ")", ")", "\n", "\n", "", "if", "is_subsequence_preparation_done", "and", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Data is loaded...\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n", "# Finally", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._download_error_message": [[616, 633], ["endless_cl_sim.EndlessCLSimDataset._get_scenario_data", "str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset._get_scenario_data"], ["", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "scenario_data_name", "=", "self", ".", "_get_scenario_data", "(", ")", "\n", "all_urls", "=", "[", "\n", "name_url", "[", "1", "]", "for", "name_url", "in", "scenario_data_name", "\n", "]", "\n", "\n", "base_msg", "=", "'[Endless-CL-Sim] Error downloading the dataset!\\n'", "'You should download data manually using the following links:\\n'", "\n", "\n", "for", "url", "in", "all_urls", ":", "\n", "            ", "base_msg", "+=", "url", "\n", "base_msg", "+=", "'\\n'", "\n", "\n", "", "base_msg", "+=", "'and place these files in '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n", "return", "base_msg", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist.INATURALIST2018.__init__": [[77, 135], ["torchvision.transforms.ToTensor", "torch.utils.data.dataset.Dataset.__init__", "logging.getLogger", "inaturalist.INATURALIST2018.log.info", "jsonparser", "inaturalist.INATURALIST2018.ds.anns.values", "inaturalist.INATURALIST2018.log.info", "inaturalist.INATURALIST2018.log.info", "inaturalist.INATURALIST2018.log.info", "os.path.expanduser", "inaturalist_data.INATURALIST_DATA", "len", "pprint.pformat", "os.path.join", "inaturalist.INATURALIST2018.ds.loadCats", "inaturalist.INATURALIST2018.cats_per_supcat[].add", "inaturalist.INATURALIST2018.img_ids.append", "inaturalist.INATURALIST2018.targets.append", "inaturalist.INATURALIST2018.cats_per_supcat.items", "set", "int", "inaturalist.INATURALIST2018.__len__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__len__"], ["def", "__init__", "(", "self", ",", "\n", "root", "=", "expanduser", "(", "\"~\"", ")", "+", "\"/.avalanche/data/inaturalist2018/\"", ",", "\n", "split", "=", "'train'", ",", "transform", "=", "ToTensor", "(", ")", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "pil_loader", ",", "download", "=", "True", ",", "supcats", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# conda install -c conda-forge pycocotools", "\n", "from", "pycocotools", ".", "coco", "import", "COCO", "as", "jsonparser", "\n", "\n", "assert", "split", "in", "self", ".", "splits", "\n", "self", ".", "split", "=", "split", "# training set or test set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "log", "=", "logging", ".", "getLogger", "(", "\"avalanche\"", ")", "\n", "\n", "# Supercategories to include (None = all)", "\n", "self", ".", "supcats", "=", "supcats", "if", "supcats", "is", "not", "None", "else", "self", ".", "def_supcats", "\n", "\n", "if", "download", ":", "\n", "            ", "download_trainval", "=", "self", ".", "split", "in", "[", "'train'", ",", "'val'", "]", "\n", "self", ".", "inat_data", "=", "INATURALIST_DATA", "(", "data_folder", "=", "root", ",", "\n", "trainval", "=", "download_trainval", ")", "\n", "\n", "# load annotations", "\n", "", "ann_file", "=", "f'{split}2018.json'", "\n", "self", ".", "log", ".", "info", "(", "f'Loading annotations from: {ann_file}'", ")", "\n", "self", ".", "ds", "=", "jsonparser", "(", "annotation_file", "=", "os", ".", "path", ".", "join", "(", "root", ",", "ann_file", ")", ")", "\n", "\n", "self", ".", "img_ids", ",", "self", ".", "targets", "=", "[", "]", ",", "[", "]", "# targets field is required!", "\n", "self", ".", "cats_per_supcat", "=", "{", "}", "\n", "\n", "# Filter full dataset parsed", "\n", "for", "ann", "in", "self", ".", "ds", ".", "anns", ".", "values", "(", ")", ":", "\n", "            ", "img_id", "=", "ann", "[", "\"image_id\"", "]", "\n", "cat_id", "=", "ann", "[", "\"category_id\"", "]", "\n", "\n", "# img = self.ds.loadImgs(img_id)[0][\"file_name\"]  # Img Path", "\n", "cat", "=", "self", ".", "ds", ".", "loadCats", "(", "cat_id", ")", "[", "0", "]", "# Get category", "\n", "target", "=", "cat", "[", "\"name\"", "]", "# Is subdirectory", "\n", "supcat", "=", "cat", "[", "\"supercategory\"", "]", "# Is parent directory", "\n", "\n", "if", "self", ".", "supcats", "is", "None", "or", "supcat", "in", "self", ".", "supcats", ":", "# Made selection", "\n", "\n", "# Add category to supercategory", "\n", "                ", "if", "supcat", "not", "in", "self", ".", "cats_per_supcat", ":", "\n", "                    ", "self", ".", "cats_per_supcat", "[", "supcat", "]", "=", "set", "(", ")", "\n", "", "self", ".", "cats_per_supcat", "[", "supcat", "]", ".", "add", "(", "int", "(", "target", ")", ")", "# Need int", "\n", "\n", "# Add to list", "\n", "self", ".", "img_ids", ".", "append", "(", "img_id", ")", "\n", "self", ".", "targets", ".", "append", "(", "target", ")", "\n", "# self.suptargets.append(supcat)", "\n", "\n", "", "", "cnt_per_supcat", "=", "{", "k", ":", "len", "(", "v", ")", "for", "k", ",", "v", "in", "self", ".", "cats_per_supcat", ".", "items", "(", ")", "}", "\n", "self", ".", "log", ".", "info", "(", "\"Classes per supercategories:\"", ")", "\n", "self", ".", "log", ".", "info", "(", "pprint", ".", "pformat", "(", "cnt_per_supcat", ",", "indent", "=", "2", ")", ")", "\n", "self", ".", "log", ".", "info", "(", "f\"Images in total: {self.__len__()}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist.INATURALIST2018._load_image": [[136, 139], ["PIL.Image.open().convert", "inaturalist.INATURALIST2018.ds.loadImgs", "PIL.Image.open", "os.path.join"], "methods", ["None"], ["", "def", "_load_image", "(", "self", ",", "img_id", ":", "int", ")", "->", "Image", ".", "Image", ":", "\n", "        ", "path", "=", "self", ".", "ds", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "return", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "path", ")", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist.INATURALIST2018._load_target": [[140, 142], ["inaturalist.INATURALIST2018.ds.loadAnns", "inaturalist.INATURALIST2018.ds.getAnnIds"], "methods", ["None"], ["", "def", "_load_target", "(", "self", ",", "img_id", ")", "->", "List", "[", "Any", "]", ":", "\n", "        ", "return", "self", ".", "ds", ".", "loadAnns", "(", "self", ".", "ds", ".", "getAnnIds", "(", "img_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist.INATURALIST2018.__getitem__": [[143, 164], ["inaturalist.INATURALIST2018._load_image", "inaturalist.INATURALIST2018.transform", "inaturalist.INATURALIST2018.target_transform"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist.INATURALIST2018._load_image"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target\n                class.\n        \"\"\"", "\n", "\n", "id", "=", "self", ".", "img_ids", "[", "index", "]", "\n", "img", "=", "self", ".", "_load_image", "(", "id", ")", "\n", "# target = self._load_target(id)", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist.INATURALIST2018.__len__": [[165, 167], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist.pil_loader": [[40, 47], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "    ", "\"\"\" Load an Image with PIL \"\"\"", "\n", "# open path as file to avoid ResourceWarning", "\n", "# (https://github.com/python-pillow/Pillow/issues/835)", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist._isArrayLike": [[49, 51], ["hasattr", "hasattr"], "function", ["None"], ["", "", "def", "_isArrayLike", "(", "obj", ")", ":", "\n", "    ", "return", "hasattr", "(", "obj", ",", "'__iter__'", ")", "and", "hasattr", "(", "obj", ",", "'__len__'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist_data.INATURALIST_DATA.__init__": [[117, 145], ["logging.getLogger", "os.path.isabs", "os.path.join", "os.makedirs", "inaturalist_data.INATURALIST_DATA.log.info", "inaturalist_data.INATURALIST_DATA.download_inaturalist", "os.path.dirname", "traceback.print_exc", "inaturalist_data.INATURALIST_DATA.log.error"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist_data.INATURALIST_DATA.download_inaturalist"], ["def", "__init__", "(", "self", ",", "data_folder", "=", "'data/'", ",", "trainval", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data_folder (string): folder in which to download\n            inaturalist dataset.\n        \"\"\"", "\n", "# Get train data (incl val data) or test data", "\n", "self", ".", "trainval", "=", "trainval", "\n", "self", ".", "log", "=", "logging", ".", "getLogger", "(", "\"avalanche\"", ")", "\n", "\n", "if", "os", ".", "path", ".", "isabs", "(", "data_folder", ")", ":", "\n", "            ", "self", ".", "data_folder", "=", "data_folder", "\n", "", "else", ":", "\n", "            ", "self", ".", "data_folder", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\n", "data_folder", ")", "\n", "\n", "", "try", ":", "\n", "# Create target Directory for INATURALIST data", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "data_folder", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "log", ".", "info", "(", "\"Directory %s created\"", ",", "self", ".", "data_folder", ")", "\n", "self", ".", "download", "=", "True", "\n", "self", ".", "download_inaturalist", "(", ")", "\n", "\n", "", "except", "OSError", ":", "\n", "            ", "import", "traceback", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "self", ".", "download", "=", "False", "\n", "self", ".", "log", ".", "error", "(", "\"Directory %s already exists\"", ",", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.inaturalist.inaturalist_data.INATURALIST_DATA.download_inaturalist": [[146, 176], ["inaturalist_data.INATURALIST_DATA.log.info", "inaturalist_data.INATURALIST_DATA.log.info", "os.path.join", "name[].endswith", "os.path.exists", "urlretrieve", "inaturalist_data.INATURALIST_DATA.log.info", "os.path.join", "os.path.exists", "inaturalist_data.INATURALIST_DATA.log.info", "tarfile.open", "inaturalist_data.INATURALIST_DATA.log.info", "tar.extractall", "inaturalist_data.INATURALIST_DATA.log.info", "name[].split", "os.path.join"], "methods", ["None"], ["", "", "def", "download_inaturalist", "(", "self", ")", ":", "\n", "        ", "\"\"\" Download and extract inaturalist data\n\n            :param extra: download also additional INATURALIST data not strictly\n                required by the data loader.\n        \"\"\"", "\n", "\n", "data2download", "=", "train_data", "if", "self", ".", "trainval", "else", "test_data", "\n", "\n", "for", "name", "in", "data2download", ":", "\n", "            ", "self", ".", "log", ".", "info", "(", "\"Downloading \"", "+", "name", "[", "1", "]", "+", "\"...\"", ")", "\n", "save_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "name", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_name", ")", ":", "\n", "                ", "urlretrieve", "(", "name", "[", "1", "]", ",", "save_name", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "log", ".", "info", "(", "\"Skipping download, exists: \"", ",", "save_name", ")", "\n", "\n", "", "if", "name", "[", "0", "]", ".", "endswith", "(", "\"tar.gz\"", ")", ":", "\n", "                ", "untar_save_name", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "data_folder", ",", "'.'", ".", "join", "(", "name", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", ":", "-", "2", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "untar_save_name", ")", ":", "\n", "                    ", "with", "tarfile", ".", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "name", "[", "0", "]", ")", ",", "\n", "\"r:gz\"", ")", "as", "tar", ":", "\n", "                        ", "self", ".", "log", ".", "info", "(", "'Extracting INATURALIST images...'", ")", "\n", "tar", ".", "extractall", "(", "self", ".", "data_folder", ")", "\n", "self", ".", "log", ".", "info", "(", "'Done!'", ")", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "log", ".", "info", "(", "\"Skipping untarring, exists: \"", ",", "save_name", ")", "\n", "", "", "", "self", ".", "log", ".", "info", "(", "\"Download complete.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset.__init__": [[34, 82], ["avalanche.benchmarks.datasets.downloadable_dataset.DownloadableDataset.__init__", "core50.CORe50Dataset._load_dataset", "avalanche.benchmarks.datasets.default_dataset_location"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "*", ",", "\n", "train", "=", "True", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ",", "download", "=", "True", ",", "mini", "=", "False", ",", "\n", "object_level", "=", "True", ")", ":", "\n", "\n", "        ", "\"\"\"\n        Creates an instance of the CORe50 dataset.\n\n        :param root: root for the datasets data. Defaults to None, which means\n        that the default location for 'core50' will be used.\n        :param train: train or test split.\n        :param transform: eventual transformations to be applied.\n        :param target_transform: eventual transformation to be applied to the\n            targets.\n        :param loader: the procedure to load the instance from the storage.\n        :param download: boolean to automatically download data. Default to\n            True.\n        :param mini: boolean to use the 32x32 version instead of the 128x128.\n            Default to False.\n        :param object_level: if the classification is objects based or\n            category based: 50 or 10 way classification problem. Default to True\n            (50-way object classification problem)\n        \"\"\"", "\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'core50'", ")", "\n", "\n", "", "super", "(", "CORe50Dataset", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "object_level", "=", "object_level", "\n", "self", ".", "mini", "=", "mini", "\n", "\n", "# any scenario and run is good here since we want just to load the", "\n", "# train images and targets with no particular order", "\n", "self", ".", "_scen", "=", "'ni'", "\n", "self", ".", "_run", "=", "0", "\n", "self", ".", "_nbatch", "=", "8", "\n", "\n", "# Download the dataset and initialize metadata", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset.__getitem__": [[83, 108], ["core50.CORe50Dataset.loader", "str", "core50.CORe50Dataset.transform", "core50.CORe50Dataset.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target\n                class.\n        \"\"\"", "\n", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "if", "self", ".", "mini", ":", "\n", "            ", "bp", "=", "\"core50_32x32\"", "\n", "", "else", ":", "\n", "            ", "bp", "=", "\"core50_128x128\"", "\n", "\n", "", "img", "=", "self", ".", "loader", "(", "\n", "str", "(", "self", ".", "root", "/", "bp", "/", "self", ".", "paths", "[", "index", "]", ")", "\n", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset.__len__": [[109, 111], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset._download_dataset": [[112, 129], ["list", "core50.CORe50Dataset._download_file", "name[].endswith", "print", "core50.CORe50Dataset._extract_archive", "print", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_file", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._extract_archive"], ["", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "data2download", "=", "core50_data", ".", "data", "\n", "\n", "if", "self", ".", "mini", ":", "\n", "            ", "data2download", "=", "list", "(", "data2download", ")", "\n", "data2download", "[", "0", "]", "=", "core50_data", ".", "extra_data", "[", "1", "]", "\n", "\n", "", "for", "name", "in", "data2download", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Downloading \"", "+", "name", "[", "1", "]", "+", "\"...\"", ")", "\n", "", "file", "=", "self", ".", "_download_file", "(", "name", "[", "1", "]", ",", "name", "[", "0", "]", ",", "name", "[", "2", "]", ")", "\n", "if", "name", "[", "1", "]", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "                ", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "f'Extracting {name[0]}...'", ")", "\n", "", "extract_root", "=", "self", ".", "_extract_archive", "(", "file", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "'Extraction completed!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset._load_metadata": [[130, 188], ["open", "pickle.load", "print", "open", "pickle.load", "range", "print", "open", "pickle.load", "print", "open", "pickle.load", "range", "core50.CORe50Dataset.paths.append", "core50.CORe50Dataset.targets.append", "open", "pickle.load", "core50.CORe50Dataset._create_cat_filelists"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset._create_cat_filelists"], ["", "", "", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "mini", ":", "\n", "            ", "bp", "=", "\"core50_32x32\"", "\n", "", "else", ":", "\n", "            ", "bp", "=", "\"core50_128x128\"", "\n", "\n", "", "if", "not", "(", "self", ".", "root", "/", "bp", ")", ".", "exists", "(", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "if", "not", "(", "self", ".", "root", "/", "'batches_filelists'", ")", ".", "exists", "(", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "with", "open", "(", "self", ".", "root", "/", "'paths.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "train_test_paths", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Loading labels...\"", ")", "\n", "", "with", "open", "(", "self", ".", "root", "/", "'labels.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "all_targets", "=", "pkl", ".", "load", "(", "f", ")", "\n", "self", ".", "train_test_targets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_nbatch", "+", "1", ")", ":", "\n", "                ", "self", ".", "train_test_targets", "+=", "self", ".", "all_targets", "[", "self", ".", "_scen", "]", "[", "self", ".", "_run", "]", "[", "i", "]", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Loading LUP...\"", ")", "\n", "", "with", "open", "(", "self", ".", "root", "/", "'LUP.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "LUP", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Loading labels names...\"", ")", "\n", "", "with", "open", "(", "self", ".", "root", "/", "'labels2names.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "labels2names", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "idx_list", "=", "[", "]", "\n", "if", "self", ".", "train", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "_nbatch", "+", "1", ")", ":", "\n", "                ", "self", ".", "idx_list", "+=", "self", ".", "LUP", "[", "self", ".", "_scen", "]", "[", "self", ".", "_run", "]", "[", "i", "]", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "idx_list", "=", "self", ".", "LUP", "[", "self", ".", "_scen", "]", "[", "self", ".", "_run", "]", "[", "-", "1", "]", "\n", "\n", "", "self", ".", "paths", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n", "for", "idx", "in", "self", ".", "idx_list", ":", "\n", "            ", "self", ".", "paths", ".", "append", "(", "self", ".", "train_test_paths", "[", "idx", "]", ")", "\n", "div", "=", "1", "\n", "if", "not", "self", ".", "object_level", ":", "\n", "                ", "div", "=", "5", "\n", "", "self", ".", "targets", ".", "append", "(", "self", ".", "train_test_targets", "[", "idx", "]", "//", "div", ")", "\n", "\n", "", "with", "open", "(", "self", ".", "root", "/", "'labels2names.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "labels2names", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "not", "(", "self", ".", "root", "/", "'NIC_v2_79_cat'", ")", ".", "exists", "(", ")", ":", "\n", "            ", "self", ".", "_create_cat_filelists", "(", ")", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset._download_error_message": [[189, 205], ["str"], "methods", ["None"], ["", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "all_urls", "=", "[", "\n", "name_url", "[", "1", "]", "for", "name_url", "in", "core50_data", ".", "data", "\n", "]", "\n", "\n", "base_msg", "=", "'[CORe50] Error downloading the dataset!\\n'", "'You should download data manually using the following links:\\n'", "\n", "\n", "for", "url", "in", "all_urls", ":", "\n", "            ", "base_msg", "+=", "url", "\n", "base_msg", "+=", "'\\n'", "\n", "\n", "", "base_msg", "+=", "'and place these files in '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n", "return", "base_msg", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset._create_cat_filelists": [[206, 231], ["avalanche.benchmarks.datasets.core50.core50_data.scen2dirs.items", "os.path.join", "os.path.join", "range", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "glob.glob", "os.path.exists", "os.makedirs", "os.path.join", "os.path.split", "open", "open", "open.close", "open.close", "str", "str", "os.path.join", "line.split", "core50.CORe50Dataset._objlab2cat", "open.write", "int", "str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close", "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset._objlab2cat"], ["", "def", "_create_cat_filelists", "(", "self", ")", ":", "\n", "        ", "\"\"\" Generates corresponding filelists with category-wise labels. The\n        default one are based on the object-level labels from 0 to 49.\"\"\"", "\n", "\n", "for", "k", ",", "v", "in", "core50_data", ".", "scen2dirs", ".", "items", "(", ")", ":", "\n", "            ", "orig_root_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "v", ")", "\n", "root_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "v", "[", ":", "-", "1", "]", "+", "\"_cat\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "root_path", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "root_path", ")", "\n", "", "for", "run", "in", "range", "(", "10", ")", ":", "\n", "                ", "cur_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"run\"", "+", "str", "(", "run", ")", ")", "\n", "orig_cur_path", "=", "os", ".", "path", ".", "join", "(", "orig_root_path", ",", "\"run\"", "+", "str", "(", "run", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cur_path", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "cur_path", ")", "\n", "", "for", "file", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "orig_cur_path", ",", "\"*.txt\"", ")", ")", ":", "\n", "                    ", "o_filename", "=", "file", "\n", "_", ",", "d_filename", "=", "os", ".", "path", ".", "split", "(", "o_filename", ")", "\n", "orig_f", "=", "open", "(", "o_filename", ",", "\"r\"", ")", "\n", "dst_f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "cur_path", ",", "d_filename", ")", ",", "\"w\"", ")", "\n", "for", "line", "in", "orig_f", ":", "\n", "                        ", "path", ",", "label", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "new_label", "=", "self", ".", "_objlab2cat", "(", "int", "(", "label", ")", ",", "k", ",", "run", ")", "\n", "dst_f", ".", "write", "(", "path", "+", "\" \"", "+", "str", "(", "new_label", ")", "+", "\"\\n\"", ")", "\n", "", "orig_f", ".", "close", "(", ")", "\n", "dst_f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50Dataset._objlab2cat": [[232, 241], ["int"], "methods", ["None"], ["", "", "", "", "def", "_objlab2cat", "(", "self", ",", "label", ",", "scen", ",", "run", ")", ":", "\n", "        ", "\"\"\" Mapping an object label into its corresponding category label\n        based on the scenario. \"\"\"", "\n", "\n", "if", "scen", "==", "\"nc\"", ":", "\n", "            ", "return", "core50_data", ".", "name2cat", "[", "\n", "self", ".", "labels2names", "[", "'nc'", "]", "[", "run", "]", "[", "label", "]", "[", ":", "-", "1", "]", "]", "\n", "", "else", ":", "\n", "            ", "return", "int", "(", "label", ")", "//", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.core50.core50.CORe50": [[243, 247], ["warnings.warn", "core50.CORe50Dataset"], "function", ["None"], ["", "", "", "def", "CORe50", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "warn", "(", "\"Dataset CORe50 has been renamed CORe50Dataset to prevent confusion \"", "\n", "\"with the CORe50 classic benchmark\"", ",", "DeprecationWarning", ",", "2", ")", "\n", "return", "CORe50Dataset", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__init__": [[35, 68], ["avalanche.benchmarks.datasets.DownloadableDataset.__init__", "stream51.Stream51._load_dataset", "avalanche.benchmarks.datasets.default_dataset_location"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._load_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["def", "__init__", "(", "self", ",", "root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "*", ",", "\n", "train", "=", "True", ",", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "loader", "=", "default_loader", ",", "download", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Stream-51 dataset.\n\n        :param root: The directory where the dataset can be found or downloaded.\n            Defaults to None, which means that the default location for\n            'stream51' will be used.\n        :param train: If True, the training set will be returned. If False,\n            the test set will be returned.\n        :param transform: The transformations to apply to the X values.\n        :param target_transform: The transformations to apply to the Y values.\n        :param loader: The image loader to use.\n        :param download: If True, the dataset will be downloaded if needed.\n        \"\"\"", "\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'stream51'", ")", "\n", "\n", "", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "bbox_crop", "=", "True", "\n", "self", ".", "ratio", "=", "1.1", "\n", "\n", "super", "(", "Stream51", ",", "self", ")", ".", "__init__", "(", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._download_dataset": [[69, 98], ["stream51.Stream51._download_file", "avalanche.benchmarks.datasets.stream51.stream51_data.name[].endswith", "print", "zipfile.ZipFile", "zipf.namelist", "str", "os.path.basename", "zipf.open", "open", "os.path.join", "os.path.join.mkdir", "open", "shutil.copyfileobj", "str", "str", "member.split"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.downloadable_dataset.DownloadableDataset._download_file"], ["", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_download_file", "(", "stream51_data", ".", "name", "[", "1", "]", ",", "stream51_data", ".", "name", "[", "0", "]", ",", "\n", "stream51_data", ".", "name", "[", "2", "]", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'[Stream-51] Extracting dataset...'", ")", "\n", "\n", "", "if", "stream51_data", ".", "name", "[", "1", "]", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "            ", "lfilename", "=", "self", ".", "root", "/", "stream51_data", ".", "name", "[", "0", "]", "\n", "with", "ZipFile", "(", "str", "(", "lfilename", ")", ",", "'r'", ")", "as", "zipf", ":", "\n", "                ", "for", "member", "in", "zipf", ".", "namelist", "(", ")", ":", "\n", "                    ", "filename", "=", "os", ".", "path", ".", "basename", "(", "member", ")", "\n", "# skip directories", "\n", "if", "not", "filename", ":", "\n", "                        ", "continue", "\n", "\n", "# copy file (taken from zipfile's extract)", "\n", "", "source", "=", "zipf", ".", "open", "(", "member", ")", "\n", "if", "'json'", "in", "filename", ":", "\n", "                        ", "target", "=", "open", "(", "str", "(", "self", ".", "root", "/", "filename", ")", ",", "\"wb\"", ")", "\n", "", "else", ":", "\n", "                        ", "dest_folder", "=", "os", ".", "path", ".", "join", "(", "\n", "*", "(", "member", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "1", ":", "-", "1", "]", ")", ")", "\n", "dest_folder", "=", "self", ".", "root", "/", "dest_folder", "\n", "dest_folder", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "target", "=", "open", "(", "str", "(", "dest_folder", "/", "filename", ")", ",", "\"wb\"", ")", "\n", "", "with", "source", ",", "target", ":", "\n", "                        ", "shutil", ".", "copyfileobj", "(", "source", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._load_metadata": [[101, 116], ["json.load", "json.load", "open", "open", "str", "str"], "methods", ["None"], ["", "", "", "", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "data_list", "=", "json", ".", "load", "(", "\n", "open", "(", "str", "(", "self", ".", "root", "/", "'Stream-51_meta_train.json'", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "data_list", "=", "json", ".", "load", "(", "\n", "open", "(", "str", "(", "self", ".", "root", "/", "'Stream-51_meta_test.json'", ")", ")", ")", "\n", "\n", "", "self", ".", "samples", "=", "data_list", "\n", "self", ".", "targets", "=", "[", "s", "[", "0", "]", "for", "s", "in", "data_list", "]", "\n", "\n", "self", ".", "bbox_crop", "=", "True", "\n", "self", ".", "ratio", "=", "1.1", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._download_error_message": [[117, 121], ["str"], "methods", ["None"], ["", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "'[Stream-51] Error downloading the dataset. Consider '", "'downloading it manually at: '", "+", "stream51_data", ".", "name", "[", "1", "]", "+", "' and placing it in: '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._instance_ordering": [[122, 146], ["new_data_list.append", "random.seed", "random.shuffle", "new_data_list.append", "temp_video.append", "data_list.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_instance_ordering", "(", "data_list", ",", "seed", ")", ":", "\n", "# organize data by video", "\n", "        ", "total_videos", "=", "0", "\n", "new_data_list", "=", "[", "]", "\n", "temp_video", "=", "[", "]", "\n", "for", "x", "in", "data_list", ":", "\n", "            ", "if", "x", "[", "3", "]", "==", "0", ":", "\n", "                ", "new_data_list", ".", "append", "(", "temp_video", ")", "\n", "total_videos", "+=", "1", "\n", "temp_video", "=", "[", "x", "]", "\n", "", "else", ":", "\n", "                ", "temp_video", ".", "append", "(", "x", ")", "\n", "", "", "new_data_list", ".", "append", "(", "temp_video", ")", "\n", "new_data_list", "=", "new_data_list", "[", "1", ":", "]", "\n", "# shuffle videos", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "new_data_list", ")", "\n", "# reorganize by clip", "\n", "data_list", "=", "[", "]", "\n", "for", "v", "in", "new_data_list", ":", "\n", "            ", "for", "x", "in", "v", ":", "\n", "                ", "data_list", ".", "append", "(", "x", ")", "\n", "", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._class_ordering": [[147, 171], ["range", "random.seed", "random.shuffle", "new_data_list.append", "random.seed", "random.shuffle", "stream51.Stream51._instance_ordering", "data_list.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._instance_ordering"], ["", "@", "staticmethod", "\n", "def", "_class_ordering", "(", "data_list", ",", "class_type", ",", "seed", ")", ":", "\n", "# organize data by class", "\n", "        ", "new_data_list", "=", "[", "]", "\n", "for", "class_id", "in", "range", "(", "data_list", "[", "-", "1", "]", "[", "0", "]", "+", "1", ")", ":", "\n", "            ", "class_data_list", "=", "[", "x", "for", "x", "in", "data_list", "if", "x", "[", "0", "]", "==", "class_id", "]", "\n", "if", "class_type", "==", "'class_iid'", ":", "\n", "# shuffle all class data", "\n", "                ", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "class_data_list", ")", "\n", "", "else", ":", "\n", "# shuffle clips within class", "\n", "                ", "class_data_list", "=", "Stream51", ".", "_instance_ordering", "(", "\n", "class_data_list", ",", "seed", ")", "\n", "", "new_data_list", ".", "append", "(", "class_data_list", ")", "\n", "# shuffle classes", "\n", "", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "new_data_list", ")", "\n", "# reorganize by class", "\n", "data_list", "=", "[", "]", "\n", "for", "v", "in", "new_data_list", ":", "\n", "            ", "for", "x", "in", "v", ":", "\n", "                ", "data_list", ".", "append", "(", "x", ")", "\n", "", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.make_dataset": [[172, 194], ["ValueError", "random.seed", "random.shuffle", "len", "stream51.Stream51._instance_ordering", "stream51.Stream51._class_ordering"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._instance_ordering", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51._class_ordering"], ["", "@", "staticmethod", "\n", "def", "make_dataset", "(", "data_list", ",", "ordering", "=", "'class_instance'", ",", "seed", "=", "666", ")", ":", "\n", "        ", "\"\"\"\n        data_list\n        for train: [class_id, clip_num, video_num, frame_num, bbox, file_loc]\n        for test: [class_id, bbox, file_loc]\n        \"\"\"", "\n", "if", "not", "ordering", "or", "len", "(", "data_list", "[", "0", "]", ")", "==", "3", ":", "# cannot order the test set", "\n", "            ", "return", "data_list", "\n", "", "if", "ordering", "not", "in", "[", "'iid'", ",", "'class_iid'", ",", "'instance'", ",", "'class_instance'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'dataset ordering must be one of: \"iid\", \"class_iid\", '", "\n", "'\"instance\", or \"class_instance\"'", ")", "\n", "", "if", "ordering", "==", "'iid'", ":", "\n", "# shuffle all data", "\n", "            ", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "data_list", ")", "\n", "return", "data_list", "\n", "", "elif", "ordering", "==", "'instance'", ":", "\n", "            ", "return", "Stream51", ".", "_instance_ordering", "(", "data_list", ",", "seed", ")", "\n", "", "elif", "'class'", "in", "ordering", ":", "\n", "            ", "return", "Stream51", ".", "_class_ordering", "(", "data_list", ",", "ordering", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__getitem__": [[195, 227], ["stream51.Stream51.loader", "str", "stream51.Stream51.crop", "stream51.Stream51.transform", "stream51.Stream51.target_transform", "int", "int", "min", "max", "min", "max", "int", "int", "int", "int"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target\n            class.\n        \"\"\"", "\n", "fpath", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "[", "-", "1", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "str", "(", "self", ".", "root", "/", "fpath", ")", ")", "\n", "if", "self", ".", "bbox_crop", ":", "\n", "            ", "bbox", "=", "self", ".", "samples", "[", "index", "]", "[", "-", "2", "]", "\n", "cw", "=", "bbox", "[", "0", "]", "-", "bbox", "[", "1", "]", "\n", "ch", "=", "bbox", "[", "2", "]", "-", "bbox", "[", "3", "]", "\n", "center", "=", "[", "int", "(", "bbox", "[", "1", "]", "+", "cw", "/", "2", ")", ",", "int", "(", "bbox", "[", "3", "]", "+", "ch", "/", "2", ")", "]", "\n", "bbox", "=", "[", "\n", "min", "(", "[", "int", "(", "center", "[", "0", "]", "+", "(", "cw", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "sample", ".", "size", "[", "0", "]", "]", ")", ",", "\n", "max", "(", "[", "int", "(", "center", "[", "0", "]", "-", "(", "cw", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "0", "]", ")", ",", "\n", "min", "(", "[", "int", "(", "center", "[", "1", "]", "+", "(", "ch", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "sample", ".", "size", "[", "1", "]", "]", ")", ",", "\n", "max", "(", "[", "int", "(", "center", "[", "1", "]", "-", "(", "ch", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "0", "]", ")", "]", "\n", "sample", "=", "sample", ".", "crop", "(", "(", "bbox", "[", "1", "]", ",", "\n", "bbox", "[", "3", "]", ",", "\n", "bbox", "[", "0", "]", ",", "\n", "bbox", "[", "2", "]", ")", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__len__": [[228, 230], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__repr__": [[231, 245], ["stream51.Stream51.__len__", "stream51.Stream51.transform.__repr__().replace", "stream51.Stream51.target_transform.__repr__().replace", "stream51.Stream51.transform.__repr__", "stream51.Stream51.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__len__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__repr__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "\n", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "\n", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.__init__": [[89, 205], ["generic_cl_scenario.GenericCLScenario._check_stream_definitions", "generic_cl_scenario.GenericScenarioStream", "generic_cl_scenario.GenericScenarioStream", "bool", "generic_cl_scenario.GenericCLScenario._make_original_dataset_fields", "generic_cl_scenario.GenericCLScenario._make_stream_fields", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._check_stream_definitions", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._make_original_dataset_fields", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._make_stream_fields"], ["def", "__init__", "(", "self", ":", "TGenericCLScenario", ",", "\n", "*", ",", "\n", "stream_definitions", ":", "TStreamsUserDict", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "experience_factory", ":", "Callable", "[", "[", "'GenericScenarioStream'", ",", "int", "]", ",", "\n", "TExperience", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of a Continual Learning benchmark instance.\n\n        The benchmark instance is defined by a stream definition dictionary,\n        which describes the content of each stream. The \"train\" and \"test\"\n        stream are mandatory. Any other custom stream can be added.\n\n        There is no constraint on the amount of experiences in each stream\n        (excluding the case in which `complete_test_set_only` is set).\n\n        :param stream_definitions: The stream definitions dictionary. Must\n            be a dictionary where the key is the stream name and the value\n            is the definition of that stream. \"train\" and \"test\" streams are\n            mandatory. This class supports custom streams as well. The name of\n            custom streams can only contain letters, numbers and the \"_\"\n            character and must not start with a number. Streams can be defined\n            is two ways: static and lazy. In the static case, the\n            stream must be a tuple containing 1, 2 or 3 elements:\n            - The first element must be a list containing the datasets\n            describing each experience. Datasets must be instances of\n            :class:`AvalancheDataset`.\n            - The second element is optional and must be a list containing the\n            task labels of each experience (as an int or a set of ints).\n            If the stream definition tuple contains only one element (the list\n            of datasets), then the task labels for each experience will be\n            obtained by inspecting the content of the datasets.\n            - The third element is optional and must be a reference to the\n            originating dataset (if applicable). For instance, for SplitMNIST\n            this may be a reference to the whole MNIST dataset. If the stream\n            definition tuple contains less than 3 elements, then the reference\n            to the original dataset will be set to None.\n            In the lazy case, the stream must be defined as a tuple with 2\n            elements:\n            - The first element must be a tuple containing the dataset generator\n            (one for each experience) and the number of experiences in that\n            stream.\n            - The second element must be a list containing the task labels of\n            each experience (as an int or a set of ints).\n        :param complete_test_set_only: If True, the test stream will contain\n            a single experience containing the complete test set. This also\n            means that the definition for the test stream must contain the\n            definition for a single experience.\n        :param experience_factory: If not None, a callable that, given the\n            benchmark instance and the experience ID, returns a experience\n            instance. This parameter is usually used in subclasses (when\n            invoking the super constructor) to specialize the experience class.\n            Defaults to None, which means that the :class:`GenericExperience`\n            constructor will be used.\n        \"\"\"", "\n", "\n", "self", ".", "stream_definitions", "=", "GenericCLScenario", ".", "_check_stream_definitions", "(", "stream_definitions", ")", "\n", "\"\"\"\n        A structure containing the definition of the streams.\n        \"\"\"", "\n", "\n", "self", ".", "original_train_dataset", ":", "Optional", "[", "Dataset", "]", "=", "self", ".", "stream_definitions", "[", "'train'", "]", ".", "origin_dataset", "\n", "\"\"\" The original training set. May be None. \"\"\"", "\n", "\n", "self", ".", "original_test_dataset", ":", "Optional", "[", "Dataset", "]", "=", "self", ".", "stream_definitions", "[", "'test'", "]", ".", "origin_dataset", "\n", "\"\"\" The original test set. May be None. \"\"\"", "\n", "\n", "self", ".", "train_stream", ":", "GenericScenarioStream", "[", "\n", "TExperience", ",", "TGenericCLScenario", "]", "=", "GenericScenarioStream", "(", "'train'", ",", "\n", "self", ")", "\n", "\"\"\"\n        The stream used to obtain the training experiences. \n        This stream can be sliced in order to obtain a subset of this stream.\n        \"\"\"", "\n", "\n", "self", ".", "test_stream", ":", "GenericScenarioStream", "[", "\n", "TExperience", ",", "TGenericCLScenario", "]", "=", "GenericScenarioStream", "(", "'test'", ",", "\n", "self", ")", "\n", "\"\"\"\n        The stream used to obtain the test experiences. This stream can be \n        sliced in order to obtain a subset of this stream.\n\n        Beware that, in certain scenarios, this stream may contain a single\n        element. Check the ``complete_test_set_only`` field for more details.\n        \"\"\"", "\n", "\n", "self", ".", "complete_test_set_only", ":", "bool", "=", "bool", "(", "complete_test_set_only", ")", "\n", "\"\"\"\n        If True, only the complete test set will be returned from experience\n        instances.\n\n        This flag is usually set to True in scenarios where having one separate\n        test set aligned to each training experience is impossible or doesn't\n        make sense from a semantic point of view.\n        \"\"\"", "\n", "\n", "if", "self", ".", "complete_test_set_only", ":", "\n", "            ", "if", "len", "(", "self", ".", "stream_definitions", "[", "'test'", "]", ".", "exps_data", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'complete_test_set_only is True, but the test stream'", "\n", "' contains more than one experience'", ")", "\n", "\n", "", "", "if", "experience_factory", "is", "None", ":", "\n", "            ", "experience_factory", "=", "GenericExperience", "\n", "\n", "", "self", ".", "experience_factory", ":", "Callable", "[", "[", "TGenericScenarioStream", ",", "int", "]", ",", "\n", "TExperience", "]", "=", "experience_factory", "\n", "\n", "# Create the original_<stream_name>_dataset fields for other streams", "\n", "self", ".", "_make_original_dataset_fields", "(", ")", "\n", "\n", "# Create the <stream_name>_stream fields for other streams", "\n", "self", ".", "_make_stream_fields", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.streams": [[206, 214], ["dict", "generic_cl_scenario.GenericCLScenario.stream_definitions.keys", "getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "streams", "(", "self", ")", "->", "Dict", "[", "str", ",", "'GenericScenarioStream['", "\n", "'TExperience, TGenericCLScenario]'", "]", ":", "\n", "        ", "streams_dict", "=", "dict", "(", ")", "\n", "for", "stream_name", "in", "self", ".", "stream_definitions", ".", "keys", "(", ")", ":", "\n", "            ", "streams_dict", "[", "stream_name", "]", "=", "getattr", "(", "self", ",", "f'{stream_name}_stream'", ")", "\n", "\n", "", "return", "streams_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.n_experiences": [[215, 220], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_experiences", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"  The number of incremental training experiences contained\n        in the train stream. \"\"\"", "\n", "return", "len", "(", "self", ".", "stream_definitions", "[", "'train'", "]", ".", "exps_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.task_labels": [[221, 230], ["t_labels.append", "list"], "methods", ["None"], ["", "@", "property", "\n", "def", "task_labels", "(", "self", ")", "->", "Sequence", "[", "List", "[", "int", "]", "]", ":", "\n", "        ", "\"\"\" The task label of each training experience. \"\"\"", "\n", "t_labels", "=", "[", "]", "\n", "\n", "for", "exp_t_labels", "in", "self", ".", "stream_definitions", "[", "'train'", "]", ".", "exps_task_labels", ":", "\n", "            ", "t_labels", ".", "append", "(", "list", "(", "exp_t_labels", ")", ")", "\n", "\n", "", "return", "t_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.get_reproducibility_data": [[231, 252], ["dict"], "methods", ["None"], ["", "def", "get_reproducibility_data", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Gets the data needed to reproduce this experiment.\n\n        This data can be stored using the pickle module or some other mechanism.\n        It can then be loaded by passing it as the ``reproducibility_data``\n        parameter in the constructor.\n\n        Child classes should create their own reproducibility dictionary.\n        This means that the implementation found in :class:`GenericCLScenario`\n        will return an empty dictionary, which is meaningless.\n\n        In order to obtain the same benchmark instance, the reproducibility\n        data must be passed to the constructor along with the exact same\n        input datasets.\n\n        :return: A dictionary containing the data needed to reproduce the\n            experiment.\n        \"\"\"", "\n", "\n", "return", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.classes_in_experience": [[253, 269], ["generic_cl_scenario.LazyStreamClassesInExps"], "methods", ["None"], ["", "@", "property", "\n", "def", "classes_in_experience", "(", "self", ")", "->", "Mapping", "[", "str", ",", "\n", "Sequence", "[", "Optional", "[", "Set", "[", "int", "]", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        A dictionary mapping each stream (by name) to a list.\n\n        Each element of the list is a set describing the classes included in\n        that experience (identified by its index).\n\n        In previous releases this field contained the list of sets for the\n        training stream (that is, there was no way to obtain the list for other\n        streams). That behavior is deprecated and support for that usage way\n        will be removed in the future.\n        \"\"\"", "\n", "\n", "return", "LazyStreamClassesInExps", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.get_classes_timeline": [[270, 341], ["set", "range", "set", "len", "range", "list", "set.update", "list", "list", "set.update", "list", "class_set_current_exp.union"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "get_classes_timeline", "(", "self", ",", "current_experience", ":", "int", ",", "\n", "stream", ":", "str", "=", "'train'", ")", ":", "\n", "        ", "\"\"\"\n        Returns the classes timeline given the ID of a experience.\n\n        Given a experience ID, this method returns the classes in that\n        experience, previously seen classes, the cumulative class list and a\n        list of classes that will be encountered in next experiences of the\n        same stream.\n\n        Beware that by default this will obtain the timeline of an experience\n        of the **training** stream. Use the stream parameter to select another\n        stream.\n\n        :param current_experience: The reference experience ID.\n        :param stream: The stream name.\n        :return: A tuple composed of four lists: the first list contains the\n            IDs of classes in this experience, the second contains IDs of\n            classes seen in previous experiences, the third returns a cumulative\n            list of classes (that is, the union of the first two list) while the\n            last one returns a list of classes that will be encountered in next\n            experiences. Beware that each of these elements can be None when\n            the benchmark is initialized by using a lazy generator.\n        \"\"\"", "\n", "\n", "class_set_current_exp", "=", "self", ".", "classes_in_experience", "[", "stream", "]", "[", "current_experience", "]", "\n", "\n", "if", "class_set_current_exp", "is", "not", "None", ":", "\n", "# May be None in lazy benchmarks", "\n", "            ", "classes_in_this_exp", "=", "list", "(", "class_set_current_exp", ")", "\n", "", "else", ":", "\n", "            ", "classes_in_this_exp", "=", "None", "\n", "\n", "", "class_set_prev_exps", "=", "set", "(", ")", "\n", "for", "exp_id", "in", "range", "(", "0", ",", "current_experience", ")", ":", "\n", "            ", "prev_exp_classes", "=", "self", ".", "classes_in_experience", "[", "stream", "]", "[", "exp_id", "]", "\n", "if", "prev_exp_classes", "is", "None", ":", "\n", "# May be None in lazy benchmarks", "\n", "                ", "class_set_prev_exps", "=", "None", "\n", "break", "\n", "", "class_set_prev_exps", ".", "update", "(", "prev_exp_classes", ")", "\n", "\n", "", "if", "class_set_prev_exps", "is", "not", "None", ":", "\n", "            ", "previous_classes", "=", "list", "(", "class_set_prev_exps", ")", "\n", "", "else", ":", "\n", "            ", "previous_classes", "=", "None", "\n", "\n", "", "if", "class_set_current_exp", "is", "not", "None", "and", "class_set_prev_exps", "is", "not", "None", ":", "\n", "            ", "classes_seen_so_far", "=", "list", "(", "class_set_current_exp", ".", "union", "(", "class_set_prev_exps", ")", ")", "\n", "", "else", ":", "\n", "            ", "classes_seen_so_far", "=", "None", "\n", "\n", "", "class_set_future_exps", "=", "set", "(", ")", "\n", "stream_n_exps", "=", "len", "(", "self", ".", "classes_in_experience", "[", "stream", "]", ")", "\n", "for", "exp_id", "in", "range", "(", "current_experience", "+", "1", ",", "stream_n_exps", ")", ":", "\n", "            ", "future_exp_classes", "=", "self", ".", "classes_in_experience", "[", "stream", "]", "[", "exp_id", "]", "\n", "if", "future_exp_classes", "is", "None", ":", "\n", "                ", "class_set_future_exps", "=", "None", "\n", "break", "\n", "", "class_set_future_exps", ".", "update", "(", "future_exp_classes", ")", "\n", "\n", "", "if", "class_set_future_exps", "is", "not", "None", ":", "\n", "            ", "future_classes", "=", "list", "(", "class_set_future_exps", ")", "\n", "", "else", ":", "\n", "            ", "future_classes", "=", "None", "\n", "\n", "", "return", "(", "classes_in_this_exp", ",", "previous_classes", ",", "classes_seen_so_far", ",", "\n", "future_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._make_original_dataset_fields": [[342, 349], ["generic_cl_scenario.GenericCLScenario.stream_definitions.items", "setattr"], "methods", ["None"], ["", "def", "_make_original_dataset_fields", "(", "self", ")", ":", "\n", "        ", "for", "stream_name", ",", "stream_def", "in", "self", ".", "stream_definitions", ".", "items", "(", ")", ":", "\n", "            ", "if", "stream_name", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "orig_dataset", "=", "stream_def", ".", "origin_dataset", "\n", "setattr", "(", "self", ",", "f'original_{stream_name}_dataset'", ",", "orig_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._make_stream_fields": [[350, 357], ["generic_cl_scenario.GenericCLScenario.stream_definitions.items", "generic_cl_scenario.GenericScenarioStream", "setattr"], "methods", ["None"], ["", "", "def", "_make_stream_fields", "(", "self", ")", ":", "\n", "        ", "for", "stream_name", ",", "stream_def", "in", "self", ".", "stream_definitions", ".", "items", "(", ")", ":", "\n", "            ", "if", "stream_name", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "stream_obj", "=", "GenericScenarioStream", "(", "stream_name", ",", "self", ")", "\n", "setattr", "(", "self", ",", "f'{stream_name}_stream'", ",", "stream_obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._check_stream_definitions": [[358, 386], ["dict", "stream_definitions.items", "ValueError", "ValueError", "generic_cl_scenario.GenericCLScenario._check_stream_name", "generic_cl_scenario.GenericCLScenario._check_and_adapt_user_stream_def"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._check_stream_name", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._check_and_adapt_user_stream_def"], ["", "", "@", "staticmethod", "\n", "def", "_check_stream_definitions", "(", "\n", "stream_definitions", ":", "TStreamsUserDict", ")", "->", "TStreamsDict", ":", "\n", "        ", "\"\"\"\n        A function used to check the input stream definitions.\n\n        This function should returns the adapted definition in which the\n        missing optional fields are filled. If the input definition doesn't\n        follow the expected structure, a `ValueError` will be raised.\n\n        :param stream_definitions: The input stream definitions.\n        :return: The checked and adapted stream definitions.\n        \"\"\"", "\n", "streams_defs", "=", "dict", "(", ")", "\n", "\n", "if", "'train'", "not", "in", "stream_definitions", ":", "\n", "            ", "raise", "ValueError", "(", "'No train stream found!'", ")", "\n", "\n", "", "if", "'test'", "not", "in", "stream_definitions", ":", "\n", "            ", "raise", "ValueError", "(", "'No test stream found!'", ")", "\n", "\n", "", "for", "stream_name", ",", "stream_def", "in", "stream_definitions", ".", "items", "(", ")", ":", "\n", "            ", "GenericCLScenario", ".", "_check_stream_name", "(", "stream_name", ")", "\n", "stream_def", "=", "GenericCLScenario", ".", "_check_and_adapt_user_stream_def", "(", "\n", "stream_def", ",", "stream_name", ")", "\n", "streams_defs", "[", "stream_name", "]", "=", "stream_def", "\n", "\n", "", "return", "streams_defs", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._check_stream_name": [[387, 394], ["isinstance", "ValueError", "STREAM_NAME_REGEX.fullmatch", "ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_check_stream_name", "(", "stream_name", ":", "Any", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "stream_name", ",", "str", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid type for stream name. Must be a \"str\"'", ")", "\n", "\n", "", "if", "STREAM_NAME_REGEX", ".", "fullmatch", "(", "stream_name", ")", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid name for stream {stream_name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario._check_and_adapt_user_stream_def": [[395, 501], ["generic_cl_scenario.StreamDef", "len", "len", "len", "isinstance", "isinstance", "enumerate", "range", "list", "range", "len", "ValueError", "isinstance", "avalanche.benchmarks.scenarios.lazy_dataset_sequence.LazyDatasetSequence", "avalanche.benchmarks.scenarios.lazy_dataset_sequence.LazyDatasetSequence.load_all_experiences", "isinstance", "len", "ValueError", "len", "list.append", "len", "isinstance", "avalanche.benchmarks.scenarios.lazy_dataset_sequence.LazyDatasetSequence", "isinstance", "ValueError", "isinstance", "all", "generic_cl_scenario.StreamDef", "len", "isinstance", "ValueError", "set", "ValueError", "isinstance", "isinstance", "set", "len", "len", "isinstance", "len", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.load_all_experiences"], ["", "", "@", "staticmethod", "\n", "def", "_check_and_adapt_user_stream_def", "(", "\n", "stream_def", ":", "TStreamUserDef", ",", "stream_name", ":", "str", ")", "->", "StreamDef", ":", "\n", "        ", "exp_data", "=", "stream_def", "[", "0", "]", "\n", "task_labels", "=", "None", "\n", "origin_dataset", "=", "None", "\n", "is_lazy", "=", "None", "\n", "\n", "if", "len", "(", "stream_def", ")", ">", "1", ":", "\n", "            ", "task_labels", "=", "stream_def", "[", "1", "]", "\n", "\n", "", "if", "len", "(", "stream_def", ")", ">", "2", ":", "\n", "            ", "origin_dataset", "=", "stream_def", "[", "2", "]", "\n", "\n", "", "if", "len", "(", "stream_def", ")", ">", "3", ":", "\n", "            ", "is_lazy", "=", "stream_def", "[", "3", "]", "\n", "\n", "", "if", "is_lazy", "or", "(", "isinstance", "(", "exp_data", ",", "tuple", ")", "and", "(", "is_lazy", "is", "None", ")", ")", ":", "\n", "# Creation based on a generator", "\n", "            ", "if", "is_lazy", ":", "\n", "# We also check for LazyDatasetSequence, which is sufficient", "\n", "# per se (only if is_lazy==True, otherwise is treated as a", "\n", "# standard Sequence)", "\n", "                ", "if", "not", "isinstance", "(", "exp_data", ",", "LazyDatasetSequence", ")", ":", "\n", "                    ", "if", "(", "not", "isinstance", "(", "exp_data", ",", "tuple", ")", ")", "or", "(", "not", "len", "(", "exp_data", ")", "==", "2", ")", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "f'The stream {stream_name} was flagged as '", "\n", "f'lazy-generated but its definition is not a '", "\n", "f'2-elements tuple (generator and stream length).'", ")", "\n", "", "", "", "else", ":", "\n", "                ", "if", "(", "not", "len", "(", "exp_data", ")", "==", "2", ")", "or", "(", "not", "isinstance", "(", "exp_data", "[", "1", "]", ",", "int", ")", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "f'The stream {stream_name} was detected '", "\n", "f'as lazy-generated but its definition is not a '", "\n", "f'2-elements tuple. If you\\'re trying to define a '", "\n", "f'non-lazily generated stream, don\\'t use a tuple '", "\n", "f'when passing the list of datasets, use a list '", "\n", "f'instead.'", ")", "\n", "\n", "", "", "if", "isinstance", "(", "exp_data", ",", "LazyDatasetSequence", ")", ":", "\n", "                ", "stream_length", "=", "len", "(", "exp_data", ")", "\n", "", "else", ":", "\n", "# exp_data[0] must contain the generator", "\n", "                ", "stream_length", "=", "exp_data", "[", "1", "]", "\n", "", "is_lazy", "=", "True", "\n", "", "elif", "isinstance", "(", "exp_data", ",", "AvalancheDataset", ")", ":", "\n", "# Single element", "\n", "            ", "exp_data", "=", "[", "exp_data", "]", "\n", "is_lazy", "=", "False", "\n", "stream_length", "=", "1", "\n", "", "elif", "isinstance", "(", "exp_data", ",", "Env", ")", "or", "all", "(", "[", "isinstance", "(", "e", ",", "Env", ")", "for", "e", "in", "exp_data", "]", ")", ":", "\n", "            ", "return", "StreamDef", "(", "exp_data", ",", "None", ",", "None", ",", "False", ")", "\n", "", "else", ":", "\n", "# Standard def", "\n", "            ", "stream_length", "=", "len", "(", "exp_data", ")", "\n", "is_lazy", "=", "False", "\n", "\n", "", "if", "not", "is_lazy", ":", "\n", "            ", "for", "i", ",", "dataset", "in", "enumerate", "(", "exp_data", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "dataset", ",", "AvalancheDataset", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'All experience datasets must be subclasses of'", "\n", "' AvalancheDataset'", ")", "\n", "\n", "", "", "", "if", "task_labels", "is", "None", ":", "\n", "            ", "if", "is_lazy", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Task labels must be defined for each experience when '", "\n", "'creating the stream using a generator.'", ")", "\n", "\n", "# Extract task labels from the dataset", "\n", "", "task_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "exp_data", ")", ")", ":", "\n", "                ", "exp_dataset", ":", "AvalancheDataset", "=", "exp_data", "[", "i", "]", "\n", "task_labels", ".", "append", "(", "set", "(", "exp_dataset", ".", "targets_task_labels", ")", ")", "\n", "", "", "else", ":", "\n", "# Standardize task labels structure", "\n", "            ", "task_labels", "=", "list", "(", "task_labels", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "task_labels", ")", ")", ":", "\n", "                ", "if", "isinstance", "(", "task_labels", "[", "i", "]", ",", "int", ")", ":", "\n", "                    ", "task_labels", "[", "i", "]", "=", "{", "task_labels", "[", "i", "]", "}", "\n", "", "elif", "not", "isinstance", "(", "task_labels", "[", "i", "]", ",", "set", ")", ":", "\n", "                    ", "task_labels", "[", "i", "]", "=", "set", "(", "task_labels", "[", "i", "]", ")", "\n", "\n", "", "", "", "if", "stream_length", "!=", "len", "(", "task_labels", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'{len(exp_data)} experiences have been defined, but task '", "\n", "f'labels for {len(task_labels)} experiences are given.'", ")", "\n", "\n", "", "if", "is_lazy", ":", "\n", "            ", "if", "isinstance", "(", "exp_data", ",", "LazyDatasetSequence", ")", ":", "\n", "                ", "lazy_sequence", "=", "exp_data", "\n", "", "else", ":", "\n", "                ", "lazy_sequence", "=", "LazyDatasetSequence", "(", "exp_data", "[", "0", "]", ",", "stream_length", ")", "\n", "", "", "else", ":", "\n", "            ", "lazy_sequence", "=", "LazyDatasetSequence", "(", "exp_data", ",", "stream_length", ")", "\n", "lazy_sequence", ".", "load_all_experiences", "(", ")", "\n", "\n", "", "return", "StreamDef", "(", "\n", "lazy_sequence", ",", "\n", "task_labels", ",", "\n", "origin_dataset", ",", "\n", "is_lazy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericScenarioStream.__init__": [[507, 526], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ":", "TGenericScenarioStream", ",", "\n", "name", ":", "str", ",", "\n", "benchmark", ":", "TGenericCLScenario", ",", "\n", "*", ",", "\n", "slice_ids", ":", "List", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "slice_ids", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "slice_ids", "\n", "\"\"\"\n        Describes which experiences are contained in the current stream slice. \n        Can be None, which means that this object is the original stream. \"\"\"", "\n", "\n", "self", ".", "name", ":", "str", "=", "name", "\n", "\"\"\"\n        The name of the stream (for instance: \"train\", \"test\", \"valid\", ...).\n        \"\"\"", "\n", "\n", "self", ".", "benchmark", "=", "benchmark", "\n", "\"\"\"\n        A reference to the benchmark.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericScenarioStream.__len__": [[527, 537], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Gets the number of experiences this stream it's made of.\n\n        :return: The number of experiences in this stream.\n        \"\"\"", "\n", "if", "self", ".", "slice_ids", "is", "None", ":", "\n", "            ", "return", "len", "(", "self", ".", "benchmark", ".", "stream_definitions", "[", "self", ".", "name", "]", ".", "exps_data", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "slice_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericScenarioStream.__getitem__": [[538, 561], ["isinstance", "IndexError", "generic_cl_scenario.GenericScenarioStream._create_slice", "len", "generic_cl_scenario.GenericScenarioStream.benchmark.experience_factory", "generic_cl_scenario.GenericScenarioStream.benchmark.experience_factory", "str", "int"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericScenarioStream._create_slice"], ["", "", "def", "__getitem__", "(", "self", ",", "exp_idx", ":", "Union", "[", "int", ",", "slice", ",", "Iterable", "[", "int", "]", "]", ")", "->", "Union", "[", "TExperience", ",", "TScenarioStream", "]", ":", "\n", "        ", "\"\"\"\n        Gets a experience given its experience index (or a stream slice given\n        the experience order).\n\n        :param exp_idx: An int describing the experience index or an\n            iterable/slice object describing a slice of this stream.\n\n        :return: The experience instance associated to the given experience\n            index or a sliced stream instance.\n        \"\"\"", "\n", "if", "isinstance", "(", "exp_idx", ",", "int", ")", ":", "\n", "            ", "if", "exp_idx", "<", "len", "(", "self", ")", ":", "\n", "                ", "if", "self", ".", "slice_ids", "is", "None", ":", "\n", "                    ", "return", "self", ".", "benchmark", ".", "experience_factory", "(", "self", ",", "exp_idx", ")", "\n", "", "else", ":", "\n", "                    ", "return", "self", ".", "benchmark", ".", "experience_factory", "(", "\n", "self", ",", "self", ".", "slice_ids", "[", "exp_idx", "]", ")", "\n", "", "", "raise", "IndexError", "(", "'Experience index out of bounds'", "+", "\n", "str", "(", "int", "(", "exp_idx", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_create_slice", "(", "exp_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericScenarioStream._create_slice": [[562, 582], ["copy.copy", "generic_cl_scenario._get_slice_ids", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario._get_slice_ids"], ["", "", "def", "_create_slice", "(", "self", ":", "TGenericScenarioStream", ",", "\n", "exps_slice", ":", "Union", "[", "int", ",", "slice", ",", "Iterable", "[", "int", "]", "]", ")", "->", "TScenarioStream", ":", "\n", "        ", "\"\"\"\n        Creates a sliced version of this stream.\n\n        In its base version, a shallow copy of this stream is created and\n        then its ``slice_ids`` field is adapted.\n\n        :param exps_slice: The slice to use.\n        :return: A sliced version of this stream.\n        \"\"\"", "\n", "stream_copy", "=", "copy", ".", "copy", "(", "self", ")", "\n", "slice_exps", "=", "_get_slice_ids", "(", "exps_slice", ",", "len", "(", "self", ")", ")", "\n", "\n", "if", "self", ".", "slice_ids", "is", "None", ":", "\n", "            ", "stream_copy", ".", "slice_ids", "=", "slice_exps", "\n", "", "else", ":", "\n", "            ", "stream_copy", ".", "slice_ids", "=", "[", "self", ".", "slice_ids", "[", "x", "]", "for", "x", "in", "slice_exps", "]", "\n", "", "return", "stream_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericScenarioStream.drop_previous_experiences": [[583, 614], ["generic_cl_scenario.GenericScenarioStream.benchmark.stream_definitions[].exps_data.drop_previous_experiences"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.drop_previous_experiences"], ["", "def", "drop_previous_experiences", "(", "self", ",", "to_exp", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Drop the reference to experiences up to a certain experience ID\n        (inclusive).\n\n        This means that any reference to experiences with ID [0, from_exp] will\n        be released. By dropping the reference to previous experiences, the\n        memory associated with them can be freed, especially the one occupied by\n        the dataset. However, if external references to the experience or the\n        dataset still exist, dropping previous experiences at the stream level\n        will have little to no impact on the memory usage.\n\n        To make sure that the underlying dataset can be freed, make sure that:\n        - No reference to previous datasets or experiences are kept in you code;\n        - The replay implementation doesn't keep a reference to previous\n            datasets (in which case, is better to store a copy of the raw\n            tensors instead);\n        - The benchmark is being generated using a lazy initializer.\n\n        By dropping previous experiences, those experiences will no longer be\n        available in the stream. Trying to access them will result in an\n        exception.\n\n        :param to_exp: The ID of the last exp to drop (inclusive). Can be a\n            negative number, in which case this method doesn't have any effect.\n            Can be greater or equal to the stream length, in which case all\n            currently loaded experiences will be dropped.\n        :return: None\n        \"\"\"", "\n", "self", ".", "benchmark", ".", "stream_definitions", "[", "\n", "self", ".", "name", "]", ".", "exps_data", ".", "drop_previous_experiences", "(", "to_exp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyStreamClassesInExps.__init__": [[617, 620], ["generic_cl_scenario.LazyClassesInExps"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "benchmark", ":", "GenericCLScenario", ")", ":", "\n", "        ", "self", ".", "_benchmark", "=", "benchmark", "\n", "self", ".", "_default_lcie", "=", "LazyClassesInExps", "(", "benchmark", ",", "stream", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyStreamClassesInExps.__len__": [[621, 623], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_benchmark", ".", "stream_definitions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyStreamClassesInExps.__getitem__": [[624, 634], ["isinstance", "warnings.warn", "generic_cl_scenario.LazyClassesInExps"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "stream_name_or_exp_id", ")", ":", "\n", "        ", "if", "isinstance", "(", "stream_name_or_exp_id", ",", "str", ")", ":", "\n", "            ", "return", "LazyClassesInExps", "(", "self", ".", "_benchmark", ",", "\n", "stream", "=", "stream_name_or_exp_id", ")", "\n", "\n", "", "warnings", ".", "warn", "(", "\n", "'Using classes_in_experience[exp_id] is deprecated. '", "\n", "'Consider using classes_in_experience[stream_name][exp_id]'", "\n", "'instead.'", ",", "stacklevel", "=", "2", ")", "\n", "return", "self", ".", "_default_lcie", "[", "stream_name_or_exp_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyStreamClassesInExps.__iter__": [[635, 637], ["generic_cl_scenario.LazyStreamClassesInExps._benchmark.stream_definitions.keys"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "yield", "from", "self", ".", "_benchmark", ".", "stream_definitions", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyClassesInExps.__init__": [[640, 643], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "benchmark", ":", "GenericCLScenario", ",", "stream", ":", "str", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "_benchmark", "=", "benchmark", "\n", "self", ".", "_stream", "=", "stream", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyClassesInExps.__len__": [[644, 646], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_benchmark", ".", "streams", "[", "self", ".", "_stream", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyClassesInExps.__getitem__": [[647, 651], ["avalanche.benchmarks.utils.dataset_utils.manage_advanced_indexing", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.dataset_utils.manage_advanced_indexing"], ["", "def", "__getitem__", "(", "self", ",", "exp_id", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "return", "manage_advanced_indexing", "(", "\n", "exp_id", ",", "self", ".", "_get_single_exp_classes", ",", "\n", "len", "(", "self", ")", ",", "LazyClassesInExps", ".", "_slice_collate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyClassesInExps.__str__": [[652, 656], ["str", "range", "len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'['", "+", "', '", ".", "join", "(", "[", "str", "(", "self", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", "]", ")", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyClassesInExps._get_single_exp_classes": [[657, 665], ["set"], "methods", ["None"], ["", "def", "_get_single_exp_classes", "(", "self", ",", "exp_id", ")", ":", "\n", "        ", "b", "=", "self", ".", "_benchmark", ".", "stream_definitions", "[", "self", ".", "_stream", "]", "\n", "if", "not", "b", ".", "is_lazy", "and", "exp_id", "not", "in", "b", ".", "exps_data", ".", "targets_field_sequence", ":", "\n", "            ", "raise", "IndexError", "\n", "", "targets", "=", "b", ".", "exps_data", ".", "targets_field_sequence", "[", "exp_id", "]", "\n", "if", "targets", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "return", "set", "(", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.LazyClassesInExps._slice_collate": [[666, 673], ["any", "list"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_slice_collate", "(", "*", "classes_in_exps", ":", "Optional", "[", "Set", "[", "int", "]", "]", ")", ":", "\n", "        ", "if", "any", "(", "x", "is", "None", "for", "x", "in", "classes_in_exps", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "[", "\n", "list", "(", "x", ")", "for", "x", "in", "classes_in_exps", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.AbstractExperience.__init__": [[716, 758], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ":", "TExperience", ",", "\n", "origin_stream", ":", "TScenarioStream", ",", "\n", "current_experience", ":", "int", ",", "\n", "classes_in_this_exp", ":", "Sequence", "[", "int", "]", ",", "\n", "previous_classes", ":", "Sequence", "[", "int", "]", ",", "\n", "classes_seen_so_far", ":", "Sequence", "[", "int", "]", ",", "\n", "future_classes", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the abstract experience given the benchmark\n        stream, the current experience ID and data about the classes timeline.\n\n        :param origin_stream: The stream from which this experience was\n            obtained.\n        :param current_experience: The current experience ID, as an integer.\n        :param classes_in_this_exp: The list of classes in this experience.\n        :param previous_classes: The list of classes in previous experiences.\n        :param classes_seen_so_far: List of classes of current and previous\n            experiences.\n        :param future_classes: The list of classes of next experiences.\n        \"\"\"", "\n", "\n", "self", ".", "origin_stream", ":", "TScenarioStream", "=", "origin_stream", "\n", "\n", "# benchmark keeps a reference to the base benchmark", "\n", "self", ".", "benchmark", ":", "TScenario", "=", "origin_stream", ".", "benchmark", "\n", "\n", "# current_experience is usually an incremental, 0-indexed, value used to", "\n", "# keep track of the current batch/task.", "\n", "self", ".", "current_experience", ":", "int", "=", "current_experience", "\n", "\n", "self", ".", "classes_in_this_experience", ":", "Sequence", "[", "int", "]", "=", "classes_in_this_exp", "\n", "\"\"\" The list of classes in this experience \"\"\"", "\n", "\n", "self", ".", "previous_classes", ":", "Sequence", "[", "int", "]", "=", "previous_classes", "\n", "\"\"\" The list of classes in previous experiences \"\"\"", "\n", "\n", "self", ".", "classes_seen_so_far", ":", "Sequence", "[", "int", "]", "=", "classes_seen_so_far", "\n", "\"\"\" List of classes of current and previous experiences \"\"\"", "\n", "\n", "self", ".", "future_classes", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "future_classes", "\n", "\"\"\" The list of classes of next experiences \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.AbstractExperience.task_label": [[759, 774], ["len", "ValueError"], "methods", ["None"], ["", "@", "property", "\n", "def", "task_label", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        The task label. This value will never have value \"None\". However,\n        for scenarios that don't produce task labels a placeholder value like 0\n        is usually set. Beware that this field is meant as a shortcut to obtain\n        a unique task label: it assumes that only patterns labeled with a\n        single task label are present. If this experience contains patterns from\n        multiple tasks, accessing this property will result in an exception.\n        \"\"\"", "\n", "if", "len", "(", "self", ".", "task_labels", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'The task_label property can only be accessed '", "\n", "'when the experience contains a single task label'", ")", "\n", "\n", "", "return", "self", ".", "task_labels", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericExperience.__init__": [[789, 812], ["origin_stream.benchmark.get_classes_timeline", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericCLScenario.get_classes_timeline", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ":", "TGenericExperience", ",", "\n", "origin_stream", ":", "GenericScenarioStream", "[", "TGenericExperience", ",", "\n", "TGenericCLScenario", "]", ",", "\n", "current_experience", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of a generic experience given the stream from this\n        experience was taken and and the current experience ID.\n\n        :param origin_stream: The stream from which this experience was\n            obtained.\n        :param current_experience: The current experience ID, as an integer.\n        \"\"\"", "\n", "self", ".", "dataset", ":", "AvalancheDataset", "=", "origin_stream", ".", "benchmark", ".", "stream_definitions", "[", "\n", "origin_stream", ".", "name", "]", ".", "exps_data", "[", "current_experience", "]", "\n", "\n", "(", "classes_in_this_exp", ",", "previous_classes", ",", "classes_seen_so_far", ",", "\n", "future_classes", ")", "=", "origin_stream", ".", "benchmark", ".", "get_classes_timeline", "(", "\n", "current_experience", ",", "stream", "=", "origin_stream", ".", "name", ")", "\n", "\n", "super", "(", "GenericExperience", ",", "self", ")", ".", "__init__", "(", "\n", "origin_stream", ",", "current_experience", ",", "classes_in_this_exp", ",", "\n", "previous_classes", ",", "classes_seen_so_far", ",", "future_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericExperience._get_stream_def": [[813, 815], ["None"], "methods", ["None"], ["", "def", "_get_stream_def", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "benchmark", ".", "stream_definitions", "[", "self", ".", "origin_stream", ".", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericExperience.task_labels": [[816, 820], ["generic_cl_scenario.GenericExperience._get_stream_def", "list"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario.GenericExperience._get_stream_def"], ["", "@", "property", "\n", "def", "task_labels", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "stream_def", "=", "self", ".", "_get_stream_def", "(", ")", "\n", "return", "list", "(", "stream_def", ".", "exps_task_labels", "[", "self", ".", "current_experience", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_cl_scenario._get_slice_ids": [[676, 701], ["isinstance", "list", "isinstance", "max", "IndexError", "min", "IndexError", "range", "hasattr", "list", "str", "str", "slice_definition.indices", "len", "int", "max", "min", "getattr"], "function", ["None"], ["", "", "def", "_get_slice_ids", "(", "slice_definition", ":", "Union", "[", "int", ",", "slice", ",", "Iterable", "[", "int", "]", "]", ",", "\n", "sliceable_len", ":", "int", ")", "->", "List", "[", "int", "]", ":", "\n", "# Obtain experiences list from slice object (or any iterable)", "\n", "    ", "exps_list", ":", "List", "[", "int", "]", "\n", "if", "isinstance", "(", "slice_definition", ",", "slice", ")", ":", "\n", "        ", "exps_list", "=", "list", "(", "\n", "range", "(", "*", "slice_definition", ".", "indices", "(", "sliceable_len", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "slice_definition", ",", "int", ")", ":", "\n", "        ", "exps_list", "=", "[", "slice_definition", "]", "\n", "", "elif", "hasattr", "(", "slice_definition", ",", "'shape'", ")", "and", "len", "(", "getattr", "(", "slice_definition", ",", "'shape'", ")", ")", "==", "0", ":", "\n", "        ", "exps_list", "=", "[", "int", "(", "slice_definition", ")", "]", "\n", "", "else", ":", "\n", "        ", "exps_list", "=", "list", "(", "slice_definition", ")", "\n", "\n", "# Check experience id(s) boundaries", "\n", "", "if", "max", "(", "exps_list", ")", ">=", "sliceable_len", ":", "\n", "        ", "raise", "IndexError", "(", "\n", "'Experience index out of range: '", "+", "str", "(", "max", "(", "exps_list", ")", ")", ")", "\n", "\n", "", "if", "min", "(", "exps_list", ")", "<", "0", ":", "\n", "        ", "raise", "IndexError", "(", "\n", "'Experience index out of range: '", "+", "str", "(", "min", "(", "exps_list", ")", ")", ")", "\n", "\n", "", "return", "exps_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_definitions.Experience.task_labels": [[75, 86], ["None"], "methods", ["None"], ["@", "property", "\n", "@", "abstractmethod", "\n", "def", "task_labels", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        This list will contain the unique task labels of the patterns contained\n        in this experience. In the most common scenarios this will be a list\n        with a single value. Note: for scenarios that don't produce task labels,\n        a placeholder task label value like 0 is usually set to each pattern\n        (see the description of the originating scenario for details).\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_definitions.Experience.task_label": [[87, 99], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abstractmethod", "\n", "def", "task_label", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        The task label. This value will never have value \"None\". However,\n        for scenarios that don't produce task labels a placeholder value like 0\n        is usually set. Beware that this field is meant as a shortcut to obtain\n        a unique task label: it assumes that only patterns labeled with a\n        single task label are present. If this experience contains patterns from\n        multiple tasks, accessing this property will result in an exception.\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_definitions.Experience.scenario": [[100, 107], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "scenario", "(", "self", ")", "->", "TScenario", ":", "\n", "        ", "\"\"\" This property is DEPRECATED, use self.benchmark instead.\"\"\"", "\n", "warnings", ".", "warn", "(", "\n", "'Using self.scenario is deprecated in Experience. '", "\n", "'Consider using self.benchmark instead.'", ",", "stacklevel", "=", "2", ")", "\n", "return", "self", ".", "benchmark", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_definitions.ScenarioStream.scenario": [[130, 137], ["warnings.warn"], "methods", ["None"], ["@", "property", "\n", "def", "scenario", "(", "self", ")", "->", "TScenario", ":", "\n", "        ", "\"\"\" This property is DEPRECATED, use self.benchmark instead.\"\"\"", "\n", "warnings", ".", "warn", "(", "\n", "'Using self.scenario is deprecated ScenarioStream. '", "\n", "'Consider using self.benchmark instead.'", ",", "stacklevel", "=", "2", ")", "\n", "return", "self", ".", "benchmark", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_definitions.ScenarioStream.__getitem__": [[138, 151], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ":", "TScenarioStream", ",", "\n", "experience_idx", ":", "Union", "[", "int", ",", "slice", ",", "Iterable", "[", "int", "]", "]", ")", "->", "Union", "[", "TExperience", ",", "TScenarioStream", "]", ":", "\n", "        ", "\"\"\"\n        Gets an experience given its experience index (or a stream slice given\n        the experience order).\n\n        :param experience_idx: An int describing the experience index or an\n            iterable/slice object describing a slice of this stream.\n        :return: The Experience instance associated to the given experience\n            index or a sliced stream instance.\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_definitions.ScenarioStream.__len__": [[152, 159], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Used to get the length of this stream (the amount of experiences).\n\n        :return: The amount of experiences in this stream.\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__init__": [[31, 98], ["dict", "collections.defaultdict", "collections.defaultdict", "iter", "callable", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "experience_generator", ":", "Iterable", "[", "AvalancheDataset", "]", ",", "\n", "stream_length", ":", "int", ")", ":", "\n", "        ", "self", ".", "_exp_source", ":", "Optional", "[", "Iterable", "[", "AvalancheDataset", "]", "]", "=", "experience_generator", "\n", "\"\"\"\n        The source of the experiences stream, as an Iterable.\n        \n        Can be a simple Sequence or a Generator.\n        \n        This field is kept for reference and debugging. The actual generator\n        is kept in the `_exp_generator` field, which stores the iterator.\n        \n        This field is None when if all the experiences have been loaded.\n        \"\"\"", "\n", "\n", "self", ".", "_next_exp_id", ":", "int", "=", "0", "\n", "\"\"\"\n        The ID of the next experience that will be generated.\n        \"\"\"", "\n", "\n", "self", ".", "_loaded_experiences", ":", "Dict", "[", "int", ",", "AvalancheDataset", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        The sequence of experiences obtained from the generator.\n        \"\"\"", "\n", "\n", "self", ".", "_stream_length", ":", "int", "=", "stream_length", "\n", "\"\"\"\n        The length of the stream.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "_exp_generator", ":", "Optional", "[", "Iterator", "[", "AvalancheDataset", "]", "]", "=", "iter", "(", "\n", "self", ".", "_exp_source", "\n", ")", "\n", "", "except", "TypeError", "as", "e", ":", "\n", "            ", "if", "callable", "(", "self", ".", "_exp_source", ")", ":", "\n", "# https://stackoverflow.com/a/17092033", "\n", "                ", "raise", "ValueError", "(", "\n", "'The provided generator is not iterable. When using a '", "\n", "'generator function based on \"yield\", remember to pass the'", "\n", "' result of that function, not the '", "\n", "'function itself!'", ")", "from", "None", "\n", "", "raise", "e", "\n", "", "\"\"\"\n        The experience generator, as an Iterator.\n        \n        This field is None when if all the experiences have been loaded.\n        \"\"\"", "\n", "\n", "self", ".", "targets_field_sequence", ":", "Dict", "[", "int", ",", "Optional", "[", "Sequence", "]", "]", "=", "defaultdict", "(", "lambda", ":", "None", ")", "\n", "\"\"\"\n        A dictionary mapping each experience to its `targets` field.\n        \n        This dictionary contains the targets field of datasets generated up to\n        now, including the ones of dropped experiences.\n        \"\"\"", "\n", "\n", "self", ".", "task_labels_field_sequence", ":", "Dict", "[", "int", ",", "Optional", "[", "Sequence", "[", "int", "]", "]", "]", "=", "defaultdict", "(", "lambda", ":", "None", ")", "\n", "\"\"\"\n        A dictionary mapping each experience to its `targets_task_labels` field.\n\n        This dictionary contains the task labels of datasets generated up to\n        now, including the ones of dropped experiences.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__len__": [[99, 106], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Gets the length of the stream (number of experiences).\n\n        :return: The length of the stream.\n        \"\"\"", "\n", "return", "self", ".", "_stream_length", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.__getitem__": [[107, 120], ["int", "lazy_dataset_sequence.LazyDatasetSequence.load_all_experiences", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.load_all_experiences"], ["", "def", "__getitem__", "(", "self", ",", "exp_idx", ":", "int", ")", "->", "AvalancheDataset", ":", "\n", "        ", "\"\"\"\n        Gets the dataset associated to an experience.\n\n        :param exp_idx: The ID of the experience.\n        :return: The dataset associated to the experience.\n        \"\"\"", "\n", "exp_idx", "=", "int", "(", "exp_idx", ")", "# Handle single element tensors", "\n", "self", ".", "load_all_experiences", "(", "exp_idx", ")", "\n", "if", "exp_idx", "not", "in", "self", ".", "_loaded_experiences", ":", "\n", "            ", "raise", "RuntimeError", "(", "f'Experience {exp_idx} has been dropped'", ")", "\n", "\n", "", "return", "self", ".", "_loaded_experiences", "[", "exp_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.get_experience_if_loaded": [[121, 139], ["int", "lazy_dataset_sequence.LazyDatasetSequence._loaded_experiences.get", "len", "IndexError"], "methods", ["None"], ["", "def", "get_experience_if_loaded", "(", "self", ",", "exp_idx", ":", "int", ")", "->", "Optional", "[", "AvalancheDataset", "]", ":", "\n", "        ", "\"\"\"\n        Gets the dataset associated to an experience.\n\n        Differently from `__getitem__`, this will return None if the experience\n        has not been (lazily) loaded yet.\n\n        :param exp_idx: The ID of the experience.\n        :return: The dataset associated to the experience or None if the\n            experience has not been loaded yet or if it has been dropped.\n        \"\"\"", "\n", "exp_idx", "=", "int", "(", "exp_idx", ")", "# Handle single element tensors", "\n", "if", "exp_idx", ">=", "len", "(", "self", ")", ":", "\n", "            ", "raise", "IndexError", "(", "f'The stream doesn\\'t contain {exp_idx+1}'", "\n", "f'experiences'", ")", "\n", "\n", "", "return", "self", ".", "_loaded_experiences", ".", "get", "(", "exp_idx", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.drop_previous_experiences": [[140, 166], ["int", "min", "range", "len"], "methods", ["None"], ["", "def", "drop_previous_experiences", "(", "self", ",", "to_exp", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Drop the reference to experiences up to a certain experience ID\n        (inclusive).\n\n        This means that experiences with ID [0, from_exp] will be released.\n        Beware that the associated object will be valid until all the references\n        to it are dropped.\n\n        :param to_exp: The ID of the last exp to drop (inclusive). If None,\n            the whole stream will be loaded. Can be a negative number, in\n            which case this method doesn't have any effect. Can be greater\n            or equal to the stream length, in which case all currently loaded\n            experiences will be dropped.\n        :return: None\n        \"\"\"", "\n", "\n", "to_exp", "=", "int", "(", "to_exp", ")", "# Handle single element tensors", "\n", "if", "to_exp", "<", "0", ":", "\n", "            ", "return", "\n", "\n", "", "to_exp", "=", "min", "(", "to_exp", ",", "len", "(", "self", ")", "-", "1", ")", "\n", "\n", "for", "exp_id", "in", "range", "(", "0", ",", "to_exp", "+", "1", ")", ":", "\n", "            ", "if", "exp_id", "in", "self", ".", "_loaded_experiences", ":", "\n", "                ", "del", "self", ".", "_loaded_experiences", "[", "exp_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.lazy_dataset_sequence.LazyDatasetSequence.load_all_experiences": [[167, 214], ["range", "int", "len", "IndexError", "len", "len", "next", "isinstance", "ValueError", "RuntimeError", "len"], "methods", ["None"], ["", "", "", "def", "load_all_experiences", "(", "self", ",", "to_exp", ":", "int", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Load all experiences up to a certain experience ID (inclusive).\n\n        Beware that this won't re-load any already dropped experience.\n\n        :param to_exp: The ID of the last exp to load (inclusive). If None,\n            the whole stream will be loaded.\n        :return: None\n        \"\"\"", "\n", "if", "to_exp", "is", "None", ":", "\n", "            ", "to_exp", "=", "len", "(", "self", ")", "-", "1", "\n", "", "else", ":", "\n", "            ", "to_exp", "=", "int", "(", "to_exp", ")", "# Handle single element tensors", "\n", "\n", "", "if", "to_exp", ">=", "len", "(", "self", ")", ":", "\n", "            ", "raise", "IndexError", "(", "f'The stream doesn\\'t contain {to_exp+1}'", "\n", "f'experiences'", ")", "\n", "\n", "", "if", "self", ".", "_next_exp_id", ">", "to_exp", ":", "\n", "# Nothing to do", "\n", "            ", "return", "\n", "\n", "", "for", "exp_id", "in", "range", "(", "self", ".", "_next_exp_id", ",", "to_exp", "+", "1", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "generated_exp", ":", "AvalancheDataset", "=", "next", "(", "self", ".", "_exp_generator", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "f'Unexpected end of stream. The generator was supposed to '", "\n", "f'generate {len(self)} experiences, but an error occurred '", "\n", "f'while generating experience {exp_id}.'", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "generated_exp", ",", "AvalancheDataset", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'All experience datasets must be subclasses of'", "\n", "' AvalancheDataset'", ")", "\n", "\n", "", "self", ".", "_loaded_experiences", "[", "exp_id", "]", "=", "generated_exp", "\n", "self", ".", "targets_field_sequence", "[", "exp_id", "]", "=", "generated_exp", ".", "targets", "\n", "self", ".", "task_labels_field_sequence", "[", "exp_id", "]", "=", "generated_exp", ".", "targets_task_labels", "\n", "self", ".", "_next_exp_id", "+=", "1", "\n", "\n", "", "if", "self", ".", "_next_exp_id", "==", "len", "(", "self", ")", ":", "\n", "# Release all references to the generator", "\n", "            ", "self", ".", "_exp_generator", "=", "None", "\n", "self", ".", "_exp_source", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.scenario_utils.train_eval_transforms": [[18, 47], ["isinstance", "isinstance", "dict", "dataset_train.get_transforms", "dataset_test.get_transforms", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.get_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.get_transforms"], ["def", "train_eval_transforms", "(", "dataset_train", ",", "dataset_test", ")", ":", "\n", "    ", "\"\"\"\n    Internal utility used to create the transform groups from a couple of\n    train and test datasets.\n\n    :param dataset_train: The training dataset.\n    :param dataset_test: The test dataset.\n    :return: The transformations groups.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "dataset_train", ",", "AvalancheDataset", ")", ":", "\n", "        ", "train_group", "=", "dataset_train", ".", "get_transforms", "(", "'train'", ")", "\n", "", "else", ":", "\n", "        ", "train_group", "=", "(", "\n", "getattr", "(", "dataset_train", ",", "'transform'", ",", "None", ")", ",", "\n", "getattr", "(", "dataset_train", ",", "'target_transform'", ",", "None", ")", "\n", ")", "\n", "\n", "", "if", "isinstance", "(", "dataset_test", ",", "AvalancheDataset", ")", ":", "\n", "        ", "eval_group", "=", "dataset_test", ".", "get_transforms", "(", "'eval'", ")", "\n", "", "else", ":", "\n", "        ", "eval_group", "=", "(", "\n", "getattr", "(", "dataset_test", ",", "'transform'", ",", "None", ")", ",", "\n", "getattr", "(", "dataset_test", ",", "'target_transform'", ",", "None", ")", "\n", ")", "\n", "\n", "", "return", "dict", "(", "\n", "train", "=", "train_group", ",", "\n", "eval", "=", "eval_group", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_multi_dataset_generic_scenario": [[30, 149], ["warnings.warn", "dict", "list", "range", "list", "range", "generic_cl_scenario.GenericCLScenario", "len", "train_t_labels.append", "avalanche.benchmarks.utils.AvalancheDataset", "len", "test_t_labels.append", "avalanche.benchmarks.utils.AvalancheDataset", "len", "ValueError", "len", "len", "ValueError", "avalanche.benchmarks.utils.dataset_utils.ConstantSequence", "avalanche.benchmarks.utils.dataset_utils.ConstantSequence", "len", "len"], "function", ["None"], ["def", "create_multi_dataset_generic_scenario", "(", "\n", "train_dataset_list", ":", "Sequence", "[", "SupportedDataset", "]", ",", "\n", "test_dataset_list", ":", "Sequence", "[", "SupportedDataset", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of\n    `create_multi_dataset_generic_benchmark`.\n\n    Creates a generic scenario given a list of datasets and the respective task\n    labels. Each training dataset will be considered as a separate training\n    experience. Contents of the datasets will not be changed, including the\n    targets.\n\n    When loading the datasets from a set of fixed filelist, consider using\n    the :func:`create_generic_scenario_from_filelists` helper method instead.\n\n    In its base form, this function accepts a list of test datsets that must\n    contain the same amount of datasets of the training list.\n    Those pairs are then used to create the \"past\", \"cumulative\"\n    (a.k.a. growing) and \"future\" test sets. However, in certain Continual\n    Learning scenarios only the concept of \"complete\" test set makes sense. In\n    that case, the ``complete_test_set_only`` should be set to True (see the\n    parameter description for more info).\n\n    Beware that pattern transformations must already be included in the\n    datasets (when needed).\n\n    :param train_dataset_list: A list of training datasets.\n    :param test_dataset_list: A list of test datasets.\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_dataset_list`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that the ``test_dataset_list``\n        parameter must be list with a single element (the complete test set).\n        Defaults to False, which means that ``train_dataset_list`` and\n        ``test_dataset_list`` must contain the same amount of datasets.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param dataset_type: The type of the dataset. Defaults to None, which\n        means that the type will be obtained from the input datasets. If input\n        datasets are not instances of :class:`AvalancheDataset`, the type\n        UNDEFINED will be used.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'create_multi_dataset_generic_scenario is deprecated in favor'", "\n", "' of create_multi_dataset_generic_benchmark.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "transform_groups", "=", "dict", "(", "\n", "train", "=", "(", "train_transform", ",", "train_target_transform", ")", ",", "\n", "eval", "=", "(", "eval_transform", ",", "eval_target_transform", ")", ")", "\n", "\n", "if", "complete_test_set_only", ":", "\n", "        ", "if", "len", "(", "test_dataset_list", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Test must contain 1 element when'", "\n", "'complete_test_set_only is True'", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "len", "(", "test_dataset_list", ")", "!=", "len", "(", "train_dataset_list", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Train and test lists must define the same '", "\n", "' amount of experiences'", ")", "\n", "\n", "", "", "train_t_labels", "=", "[", "]", "\n", "train_dataset_list", "=", "list", "(", "train_dataset_list", ")", "\n", "for", "dataset_idx", "in", "range", "(", "len", "(", "train_dataset_list", ")", ")", ":", "\n", "        ", "dataset", "=", "train_dataset_list", "[", "dataset_idx", "]", "\n", "train_t_labels", ".", "append", "(", "task_labels", "[", "dataset_idx", "]", ")", "\n", "train_dataset_list", "[", "dataset_idx", "]", "=", "AvalancheDataset", "(", "\n", "dataset", ",", "\n", "task_labels", "=", "ConstantSequence", "(", "task_labels", "[", "dataset_idx", "]", ",", "\n", "len", "(", "dataset", ")", ")", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'train'", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n", "", "test_t_labels", "=", "[", "]", "\n", "test_dataset_list", "=", "list", "(", "test_dataset_list", ")", "\n", "for", "dataset_idx", "in", "range", "(", "len", "(", "test_dataset_list", ")", ")", ":", "\n", "        ", "dataset", "=", "test_dataset_list", "[", "dataset_idx", "]", "\n", "\n", "test_t_label", "=", "task_labels", "[", "dataset_idx", "]", "\n", "if", "complete_test_set_only", ":", "\n", "            ", "test_t_label", "=", "0", "\n", "\n", "", "test_t_labels", ".", "append", "(", "test_t_label", ")", "\n", "\n", "test_dataset_list", "[", "dataset_idx", "]", "=", "AvalancheDataset", "(", "\n", "dataset", ",", "\n", "task_labels", "=", "ConstantSequence", "(", "test_t_label", ",", "\n", "len", "(", "dataset", ")", ")", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'eval'", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n", "", "return", "GenericCLScenario", "(", "\n", "stream_definitions", "=", "{", "\n", "'train'", ":", "(", "train_dataset_list", ",", "train_t_labels", ")", ",", "\n", "'test'", ":", "(", "test_dataset_list", ",", "test_t_labels", ")", "\n", "}", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_filelists": [[151, 229], ["warnings.warn", "avalanche.benchmarks.utils.datasets_from_filelists", "generic_scenario_creation.create_multi_dataset_generic_scenario"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.datasets_from_filelists", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_multi_dataset_generic_scenario"], ["", "def", "create_generic_scenario_from_filelists", "(", "\n", "root", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "train_file_lists", ":", "Sequence", "[", "Union", "[", "str", ",", "Path", "]", "]", ",", "\n", "test_file_lists", ":", "Union", "[", "Union", "[", "str", ",", "Path", "]", ",", "Sequence", "[", "Union", "[", "str", ",", "Path", "]", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of\n    `create_generic_benchmark_from_filelists`.\n\n    Creates a generic scenario given a list of filelists and the respective task\n    labels. A separate dataset will be created for each filelist and each of\n    those training datasets will be considered a separate training experience.\n\n    In its base form, this function accepts a list of filelists for the test\n    datsets that must contain the same amount of elements of the training list.\n    Those pairs of datasets are then used to create the \"past\", \"cumulative\"\n    (a.k.a. growing) and \"future\" test sets. However, in certain Continual\n    Learning scenarios only the concept of \"complete\" test set makes sense. In\n    that case, the ``complete_test_set_only`` should be set to True (see the\n    parameter description for more info).\n\n    This helper functions is the best shot when loading Caffe-style dataset\n    based on filelists.\n\n    The resulting benchmark instance and the intermediate datasets used to\n    populate it will be of type CLASSIFICATION.\n\n    :param root: The root path of the dataset.\n    :param train_file_lists: A list of filelists describing the\n        paths of the training patterns for each experience.\n    :param test_file_lists: A list of filelists describing the\n        paths of the test patterns for each experience.\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_file_lists`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that the ``test_file_lists``\n        parameter must be list with a single element (the complete test set).\n        Alternatively, can be a plain string or :class:`Path` object.\n        Defaults to False, which means that ``train_file_lists`` and\n        ``test_file_lists`` must contain the same amount of filelists paths.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'create_generic_scenario_from_filelists is deprecated in '", "\n", "'favor of create_generic_benchmark_from_filelists.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "train_datasets", ",", "test_dataset", "=", "datasets_from_filelists", "(", "\n", "root", ",", "train_file_lists", ",", "test_file_lists", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ")", "\n", "\n", "return", "create_multi_dataset_generic_scenario", "(", "\n", "train_datasets", ",", "test_dataset", ",", "task_labels", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "dataset_type", "=", "AvalancheDatasetType", ".", "CLASSIFICATION", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_paths": [[234, 326], ["warnings.warn", "avalanche.benchmarks.utils.datasets_from_paths", "generic_scenario_creation.create_multi_dataset_generic_scenario"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.datasets_from_paths", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_multi_dataset_generic_scenario"], ["def", "create_generic_scenario_from_paths", "(", "\n", "train_list_of_files", ":", "Sequence", "[", "Sequence", "[", "FileAndLabel", "]", "]", ",", "\n", "test_list_of_files", ":", "Union", "[", "Sequence", "[", "FileAndLabel", "]", ",", "\n", "Sequence", "[", "Sequence", "[", "FileAndLabel", "]", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of\n    `create_generic_benchmark_from_paths`.\n\n    Creates a generic scenario given a sequence of lists of files. A separate\n    dataset will be created for each list. Each of those training datasets\n    will be considered a separate training experience.\n\n    This is very similar to `create_generic_scenario_from_filelists`, with the\n    main difference being that `create_generic_scenario_from_filelists`\n    accepts, for each experience, a file list formatted in Caffe-style.\n    On the contrary, this accepts a list of tuples where each tuple contains\n    two elements: the full path to the pattern and its label.\n    Optionally, the tuple may contain a third element describing the bounding\n    box of the element to crop. This last bounding box may be useful when trying\n    to extract the part of the image depicting the desired element.\n\n    In its base form, this function accepts a list for the test datasets that\n    must contain the same amount of elements of the training list.\n    Those pairs of datasets are then used to create the \"past\", \"cumulative\"\n    (a.k.a. growing) and \"future\" test sets. However, in certain Continual\n    Learning scenarios only the concept of \"complete\" test set makes sense. In\n    that case, the ``complete_test_set_only`` should be set to True (see the\n    parameter description for more info).\n\n    The label of each pattern doesn't have to be an int.\n\n    :param train_list_of_files: A list of lists. Each list describes the paths\n        and labels of patterns to include in that training experience, as\n        tuples. Each tuple must contain two elements: the full path to the\n        pattern and its class label. Optionally, the tuple may contain a\n        third element describing the bounding box to use for cropping (top,\n        left, height, width).\n    :param test_list_of_files: A list of lists. Each list describes the paths\n        and labels of patterns to include in that test experience, as tuples.\n        Each tuple must contain two elements: the full path to the pattern\n        and its class label. Optionally, the tuple may contain a third element\n        describing the bounding box to use for cropping (top, left, height,\n        width).\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_file_lists`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that the ``test_list_of_files``\n        parameter must define a single experience (the complete test set).\n        Defaults to False, which means that ``train_list_of_files`` and\n        ``test_list_of_files`` must contain the same amount of paths.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'create_generic_scenario_from_paths is deprecated in favor'", "\n", "' of create_generic_benchmark_from_paths.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "train_datasets", ",", "test_dataset", "=", "datasets_from_paths", "(", "\n", "train_list_of_files", ",", "test_list_of_files", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ")", "\n", "\n", "return", "create_multi_dataset_generic_scenario", "(", "\n", "train_datasets", ",", "test_dataset", ",", "task_labels", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_tensor_lists": [[328, 422], ["warnings.warn", "generic_scenario_creation.create_multi_dataset_generic_scenario", "avalanche.benchmarks.utils.AvalancheTensorDataset", "avalanche.benchmarks.utils.AvalancheTensorDataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_multi_dataset_generic_scenario"], ["", "def", "create_generic_scenario_from_tensor_lists", "(", "\n", "train_tensors", ":", "Sequence", "[", "Sequence", "[", "Any", "]", "]", ",", "\n", "test_tensors", ":", "Sequence", "[", "Sequence", "[", "Any", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "*", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of\n    `create_generic_benchmark_from_tensor_lists`.\n\n    Creates a generic scenario given lists of Tensors. A separate dataset will\n    be created from each Tensor tuple (x, y, z, ...) and each of those training\n    datasets will be considered a separate training experience. Using this\n    helper function is the lowest-level way to create a Continual Learning\n    scenario. When possible, consider using higher level helpers.\n\n    Experiences are defined by passing lists of tensors as the `train_tensors`\n    and `test_tensors` parameter. Those parameters must be lists containing\n    sub-lists of tensors, one for each experience. Each tensor defines the value\n    of a feature (\"x\", \"y\", \"z\", ...) for all patterns of that experience.\n\n    By default the second tensor of each experience will be used to fill the\n    `targets` value (label of each pattern).\n\n    In its base form, the test lists must contain the same amount of elements of\n    the training lists. Those pairs of datasets are then used to create the\n    \"past\", \"cumulative\" (a.k.a. growing) and \"future\" test sets.\n    However, in certain Continual Learning scenarios only the concept of\n    \"complete\" test set makes sense. In that case, the\n    ``complete_test_set_only`` should be set to True (see the parameter\n    description for more info).\n\n    :param train_tensors: A list of lists. The first list must contain the\n        tensors for the first training experience (one tensor per feature), the\n        second list must contain the tensors for the second training experience,\n        and so on.\n    :param test_tensors: A list of lists. The first list must contain the\n        tensors for the first test experience (one tensor per feature), the\n        second list must contain the tensors for the second test experience,\n        and so on. When using `complete_test_set_only`, this parameter\n        must be a list containing a single sub-list for the single test\n        experience.\n    :param task_labels: A list of task labels. Must contain a task label for\n        each experience. For Single-Incremental-Task (a.k.a. Task-Free)\n        scenarios, this is usually a list of zeros. For Multi Task scenario,\n        this is usually a list of ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that ``test_tensors`` must\n        define a single experience. Defaults to False, which means that\n        ``train_tensors`` and ``test_tensors`` must define the same\n        amount of experiences.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param dataset_type: The type of the dataset. Defaults to None, which\n        means that the type will be obtained from the input datasets. If input\n        datasets are not instances of :class:`AvalancheDataset`, the type\n        UNDEFINED will be used.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'create_generic_scenario_from_tensor_lists is deprecated in '", "\n", "'favor of create_generic_benchmark_from_tensor_lists.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "train_datasets", "=", "[", "\n", "AvalancheTensorDataset", "(", "*", "exp_tensors", ",", "dataset_type", "=", "dataset_type", ")", "\n", "for", "exp_tensors", "in", "train_tensors", "]", "\n", "\n", "test_datasets", "=", "[", "\n", "AvalancheTensorDataset", "(", "*", "exp_tensors", ",", "dataset_type", "=", "dataset_type", ")", "\n", "for", "exp_tensors", "in", "test_tensors", "]", "\n", "\n", "return", "create_multi_dataset_generic_scenario", "(", "\n", "train_datasets", ",", "test_datasets", ",", "task_labels", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_tensors": [[424, 543], ["warnings.warn", "isinstance", "range", "range", "generic_scenario_creation.create_generic_scenario_from_tensor_lists", "len", "len", "ValueError", "type", "type", "ValueError", "len", "exp_train_first_structure.append", "len", "exp_test_first_structure.append", "len", "len", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_tensor_lists"], ["", "def", "create_generic_scenario_from_tensors", "(", "\n", "train_data_x", ":", "Sequence", "[", "Any", "]", ",", "\n", "train_data_y", ":", "Sequence", "[", "Sequence", "[", "SupportsInt", "]", "]", ",", "\n", "test_data_x", ":", "Union", "[", "Any", ",", "Sequence", "[", "Any", "]", "]", ",", "\n", "test_data_y", ":", "Union", "[", "Any", ",", "Sequence", "[", "Sequence", "[", "SupportsInt", "]", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of\n    `create_generic_benchmark_from_tensor_lists`.\n\n    Please consider using :func:`create_generic_scenario_from_tensor_lists`\n    instead. When switching to the new function, please keep in mind that the\n    format of the parameters is completely different!\n\n    Creates a generic scenario given lists of Tensors and the respective task\n    labels. A separate dataset will be created from each Tensor pair (x + y)\n    and each of those training datasets will be considered a separate\n    training experience. Contents of the datasets will not be changed, including\n    the targets. Using this helper function is the lower level way to create a\n    Continual Learning scenario. When possible, consider using higher level\n    helpers.\n\n    By default the second tensor of each experience will be used to fill the\n    `targets` value (label of each pattern).\n\n    In its base form, the test lists must contain the same amount of elements of\n    the training lists. Those pairs of datasets are then used to create the\n    \"past\", \"cumulative\" (a.k.a. growing) and \"future\" test sets.\n    However, in certain Continual Learning scenarios only the concept of\n    \"complete\" test set makes sense. In that case, the\n    ``complete_test_set_only`` should be set to True (see the parameter\n    description for more info).\n\n    :param train_data_x: A list of Tensors (one per experience) containing the\n        patterns of the training sets.\n    :param train_data_y: A list of Tensors or int lists containing the\n        labels of the patterns of the training sets. Must contain the same\n        number of elements of ``train_datasets_x``.\n    :param test_data_x: A Tensor or a list of Tensors (one per experience)\n        containing the patterns of the test sets.\n    :param test_data_y: A Tensor or a list of Tensors or int lists containing\n        the labels of the patterns of the test sets. Must contain the same\n        number of elements of ``test_datasets_x``.\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_datasets_x`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that ``test_data_x`` and\n        ``test_data_y`` must define a single experience. Defaults to False,\n        which means that ``train_data_*`` and ``test_data_*`` must define the\n        same amount of experiences.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'create_generic_scenario_from_tensors is deprecated in favor '", "\n", "'of create_generic_benchmark_from_tensor_lists.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "if", "len", "(", "train_data_x", ")", "!=", "len", "(", "train_data_y", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'train_data_x and train_data_y must contain'", "\n", "' the same amount of elements'", ")", "\n", "\n", "", "if", "type", "(", "test_data_x", ")", "!=", "type", "(", "test_data_y", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'test_data_x and test_data_y must be of'", "\n", "' the same type'", ")", "\n", "\n", "", "if", "isinstance", "(", "test_data_x", ",", "Tensor", ")", ":", "\n", "        ", "test_data_x", "=", "[", "test_data_x", "]", "\n", "test_data_y", "=", "[", "test_data_y", "]", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "test_data_x", ")", "!=", "len", "(", "test_data_y", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'test_data_x and test_data_y must contain'", "\n", "' the same amount of elements'", ")", "\n", "\n", "", "", "exp_train_first_structure", "=", "[", "]", "\n", "exp_test_first_structure", "=", "[", "]", "\n", "for", "exp_idx", "in", "range", "(", "len", "(", "train_data_x", ")", ")", ":", "\n", "        ", "exp_x", "=", "train_data_x", "[", "exp_idx", "]", "\n", "exp_y", "=", "train_data_y", "[", "exp_idx", "]", "\n", "\n", "exp_train_first_structure", ".", "append", "(", "[", "exp_x", ",", "exp_y", "]", ")", "\n", "\n", "", "for", "exp_idx", "in", "range", "(", "len", "(", "test_data_x", ")", ")", ":", "\n", "        ", "exp_x", "=", "test_data_x", "[", "exp_idx", "]", "\n", "exp_y", "=", "test_data_y", "[", "exp_idx", "]", "\n", "\n", "exp_test_first_structure", ".", "append", "(", "[", "exp_x", ",", "exp_y", "]", ")", "\n", "\n", "", "return", "create_generic_scenario_from_tensor_lists", "(", "\n", "train_tensors", "=", "exp_train_first_structure", ",", "\n", "test_tensors", "=", "exp_test_first_structure", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_multi_dataset_generic_benchmark": [[28, 143], ["dict", "dict", "dict", "dict.items", "generic_cl_scenario.GenericCLScenario", "other_streams_transforms.items", "range", "isinstance", "len", "ValueError", "len", "stream_datasets.append", "avalanche.benchmarks.utils.AvalancheDataset", "len"], "function", ["None"], ["def", "create_multi_dataset_generic_benchmark", "(", "\n", "train_datasets", ":", "Sequence", "[", "SupportedDataset", "]", ",", "\n", "test_datasets", ":", "Sequence", "[", "SupportedDataset", "]", ",", "\n", "*", ",", "\n", "other_streams_datasets", ":", "Dict", "[", "str", ",", "Sequence", "[", "SupportedDataset", "]", "]", "=", "None", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "other_streams_transforms", ":", "Dict", "[", "str", ",", "Tuple", "[", "Any", ",", "Any", "]", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    Creates a benchmark instance given a list of datasets. Each dataset will be\n    considered as a separate experience.\n\n    Contents of the datasets must already be set, including task labels.\n    Transformations will be applied if defined.\n\n    This function allows for the creation of custom streams as well.\n    While \"train\" and \"test\" datasets must always be set, the experience list\n    for other streams can be defined by using the `other_streams_datasets`\n    parameter.\n\n    If transformations are defined, they will be applied to the datasets\n    of the related stream.\n\n    :param train_datasets: A list of training datasets.\n    :param test_datasets: A list of test datasets.\n    :param other_streams_datasets: A dictionary describing the content of custom\n        streams. Keys must be valid stream names (letters and numbers,\n        not starting with a number) while the value must be a list of dataset.\n        If this dictionary contains the definition for \"train\" or \"test\"\n        streams then those definition will override the `train_datasets` and\n        `test_datasets` parameters.\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the benchmark. This means that the ``test_dataset_list``\n        parameter must be list with a single element (the complete test set).\n        Defaults to False.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param other_streams_transforms: Transformations to apply to custom\n        streams. If no transformations are defined for a custom stream,\n        then \"train\" transformations will be used. This parameter must be a\n        dictionary mapping stream names to transformations. The transformations\n        must be a two elements tuple where the first element defines the\n        X transformation while the second element is the Y transformation.\n        Those elements can be None. If this dictionary contains the\n        transformations for \"train\" or \"test\" streams then those transformations\n        will override the `train_transform`, `train_target_transform`,\n        `eval_transform` and `eval_target_transform` parameters.\n    :param dataset_type: The type of the dataset. Defaults to None, which\n        means that the type will be obtained from the input datasets. If input\n        datasets are not instances of :class:`AvalancheDataset`, the type\n        UNDEFINED will be used.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "transform_groups", "=", "dict", "(", "\n", "train", "=", "(", "train_transform", ",", "train_target_transform", ")", ",", "\n", "eval", "=", "(", "eval_transform", ",", "eval_target_transform", ")", ")", "\n", "\n", "if", "other_streams_transforms", "is", "not", "None", ":", "\n", "        ", "for", "stream_name", ",", "stream_transforms", "in", "other_streams_transforms", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "stream_transforms", ",", "Sequence", ")", ":", "\n", "                ", "if", "len", "(", "stream_transforms", ")", "==", "1", ":", "\n", "# Suppose we got only the transformation for X values", "\n", "                    ", "stream_transforms", "=", "(", "stream_transforms", "[", "0", "]", ",", "None", ")", "\n", "", "", "else", ":", "\n", "# Suppose it's the transformation for X values", "\n", "                ", "stream_transforms", "=", "(", "stream_transforms", ",", "None", ")", "\n", "\n", "", "transform_groups", "[", "stream_name", "]", "=", "stream_transforms", "\n", "\n", "", "", "input_streams", "=", "dict", "(", "\n", "train", "=", "train_datasets", ",", "\n", "test", "=", "test_datasets", ")", "\n", "\n", "if", "other_streams_datasets", "is", "not", "None", ":", "\n", "        ", "input_streams", "=", "{", "**", "input_streams", ",", "**", "other_streams_datasets", "}", "\n", "\n", "", "if", "complete_test_set_only", ":", "\n", "        ", "if", "len", "(", "input_streams", "[", "'test'", "]", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Test stream must contain one experience when'", "\n", "'complete_test_set_only is True'", ")", "\n", "\n", "", "", "stream_definitions", "=", "dict", "(", ")", "\n", "\n", "for", "stream_name", ",", "dataset_list", "in", "input_streams", ".", "items", "(", ")", ":", "\n", "        ", "initial_transform_group", "=", "'train'", "\n", "if", "stream_name", "in", "transform_groups", ":", "\n", "            ", "initial_transform_group", "=", "stream_name", "\n", "\n", "", "stream_datasets", "=", "[", "]", "\n", "for", "dataset_idx", "in", "range", "(", "len", "(", "dataset_list", ")", ")", ":", "\n", "            ", "dataset", "=", "dataset_list", "[", "dataset_idx", "]", "\n", "stream_datasets", ".", "append", "(", "AvalancheDataset", "(", "\n", "dataset", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "initial_transform_group", ",", "\n", "dataset_type", "=", "dataset_type", ")", ")", "\n", "", "stream_definitions", "[", "stream_name", "]", "=", "(", "stream_datasets", ",", ")", "\n", "\n", "", "return", "GenericCLScenario", "(", "\n", "stream_definitions", "=", "stream_definitions", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation._adapt_lazy_stream": [[145, 162], ["avalanche.benchmarks.utils.AvalancheDataset"], "function", ["None"], ["", "def", "_adapt_lazy_stream", "(", "\n", "generator", ",", "transform_groups", ",", "initial_transform_group", ",", "dataset_type", ")", ":", "\n", "    ", "\"\"\"\n    A simple internal utility to apply transforms and dataset type to all lazily\n    generated datasets. Used in the :func:`create_lazy_generic_benchmark`\n    benchmark creation helper.\n\n    :return: A datasets in which the proper transformation groups and dataset\n        type are applied.\n    \"\"\"", "\n", "\n", "for", "dataset", "in", "generator", ":", "\n", "        ", "dataset", "=", "AvalancheDataset", "(", "\n", "dataset", ",", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "initial_transform_group", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "yield", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_lazy_generic_benchmark": [[205, 330], ["dict", "dict", "dict", "dict.items", "generic_cl_scenario.GenericCLScenario", "other_streams_transforms.items", "generic_benchmark_creation._adapt_lazy_stream", "isinstance", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation._adapt_lazy_stream"], ["", "def", "create_lazy_generic_benchmark", "(", "\n", "train_generator", ":", "LazyStreamDefinition", ",", "\n", "test_generator", ":", "LazyStreamDefinition", ",", "\n", "*", ",", "\n", "other_streams_generators", ":", "Dict", "[", "str", ",", "LazyStreamDefinition", "]", "=", "None", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "other_streams_transforms", ":", "Dict", "[", "str", ",", "Tuple", "[", "Any", ",", "Any", "]", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    Creates a lazily-defined benchmark instance given a dataset generator for\n    each stream.\n\n    Generators must return properly initialized instances of\n    :class:`AvalancheDataset` which will be used to create experiences.\n\n    The created datasets can have transformations already set.\n    However, if transformations are shared across all datasets of the same\n    stream, it is recommended to use the `train_transform`, `eval_transform`\n    and `other_streams_transforms` parameters, so that transformations groups\n    can be correctly applied (transformations are lazily added atop the datasets\n    returned by the generators). The same reasoning applies to the\n    `dataset_type` parameter.\n\n    This function allows for the creation of custom streams as well.\n    While \"train\" and \"test\" streams must be always set, the generators\n    for other streams can be defined by using the `other_streams_generators`\n    parameter.\n\n    :param train_generator: A proper lazy-generation definition for the training\n        stream. It is recommended to pass an instance\n        of :class:`LazyStreamDefinition`. See its description for more details.\n    :param test_generator: A proper lazy-generation definition for the test\n        stream. It is recommended to pass an instance\n        of :class:`LazyStreamDefinition`. See its description for more details.\n    :param other_streams_generators: A dictionary describing the content of\n        custom streams. Keys must be valid stream names (letters and numbers,\n        not starting with a number) while the value must be a\n        lazy-generation definition (like the ones of the training and\n        test streams). If this dictionary contains the definition for\n        \"train\" or \"test\" streams then those definition will override the\n        `train_generator` and `test_generator` parameters.\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the benchmark. This means that the ``test_generator``\n        parameter must define a stream with a single experience (the complete\n        test set). Defaults to False.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param other_streams_transforms: Transformations to apply to custom\n        streams. If no transformations are defined for a custom stream,\n        then \"train\" transformations will be used. This parameter must be a\n        dictionary mapping stream names to transformations. The transformations\n        must be a two elements tuple where the first element defines the\n        X transformation while the second element is the Y transformation.\n        Those elements can be None. If this dictionary contains the\n        transformations for \"train\" or \"test\" streams then those transformations\n        will override the `train_transform`, `train_target_transform`,\n        `eval_transform` and `eval_target_transform` parameters.\n    :param dataset_type: The type of the datasets. Defaults to None, which\n        means that the type will be obtained from the input datasets. This\n        type will be applied to all the datasets returned by the generators.\n\n    :returns: A lazily-initialized :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "transform_groups", "=", "dict", "(", "\n", "train", "=", "(", "train_transform", ",", "train_target_transform", ")", ",", "\n", "eval", "=", "(", "eval_transform", ",", "eval_target_transform", ")", ")", "\n", "\n", "if", "other_streams_transforms", "is", "not", "None", ":", "\n", "        ", "for", "stream_name", ",", "stream_transforms", "in", "other_streams_transforms", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "stream_transforms", ",", "Sequence", ")", ":", "\n", "                ", "if", "len", "(", "stream_transforms", ")", "==", "1", ":", "\n", "# Suppose we got only the transformation for X values", "\n", "                    ", "stream_transforms", "=", "(", "stream_transforms", "[", "0", "]", ",", "None", ")", "\n", "", "", "else", ":", "\n", "# Suppose it's the transformation for X values", "\n", "                ", "stream_transforms", "=", "(", "stream_transforms", ",", "None", ")", "\n", "\n", "", "transform_groups", "[", "stream_name", "]", "=", "stream_transforms", "\n", "\n", "", "", "input_streams", "=", "dict", "(", "\n", "train", "=", "train_generator", ",", "\n", "test", "=", "test_generator", ")", "\n", "\n", "if", "other_streams_generators", "is", "not", "None", ":", "\n", "        ", "input_streams", "=", "{", "**", "input_streams", ",", "**", "other_streams_generators", "}", "\n", "\n", "", "if", "complete_test_set_only", ":", "\n", "        ", "if", "input_streams", "[", "'test'", "]", "[", "1", "]", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Test stream must contain one experience when'", "\n", "'complete_test_set_only is True'", ")", "\n", "\n", "", "", "stream_definitions", "=", "dict", "(", ")", "\n", "\n", "for", "stream_name", ",", "(", "generator", ",", "stream_length", ",", "task_labels", ")", "in", "input_streams", ".", "items", "(", ")", ":", "\n", "        ", "initial_transform_group", "=", "'train'", "\n", "if", "stream_name", "in", "transform_groups", ":", "\n", "            ", "initial_transform_group", "=", "stream_name", "\n", "\n", "", "adapted_stream_generator", "=", "_adapt_lazy_stream", "(", "\n", "generator", ",", "transform_groups", ",", "\n", "initial_transform_group", "=", "initial_transform_group", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n", "stream_definitions", "[", "stream_name", "]", "=", "(", "\n", "(", "adapted_stream_generator", ",", "stream_length", ")", ",", "task_labels", "\n", ")", "\n", "\n", "", "return", "GenericCLScenario", "(", "\n", "stream_definitions", "=", "stream_definitions", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_generic_benchmark_from_filelists": [[332, 450], ["dict", "dict", "dict.items", "generic_benchmark_creation.create_multi_dataset_generic_benchmark", "enumerate", "avalanche.benchmarks.utils.FilelistDataset", "stream_datasets.append", "avalanche.benchmarks.utils.AvalancheDataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_multi_dataset_generic_benchmark"], ["", "def", "create_generic_benchmark_from_filelists", "(", "\n", "root", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", ",", "\n", "train_file_lists", ":", "Sequence", "[", "Union", "[", "str", ",", "Path", "]", "]", ",", "\n", "test_file_lists", ":", "Sequence", "[", "Union", "[", "str", ",", "Path", "]", "]", ",", "\n", "*", ",", "\n", "other_streams_file_lists", ":", "Dict", "[", "str", ",", "Sequence", "[", "Union", "[", "str", ",", "Path", "]", "]", "]", "=", "None", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "other_streams_transforms", ":", "Dict", "[", "str", ",", "Tuple", "[", "Any", ",", "Any", "]", "]", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    Creates a benchmark instance given a list of filelists and the respective\n    task labels. A separate dataset will be created for each filelist and each\n    of those datasets will be considered a separate experience.\n\n    This helper functions is the best shot when loading Caffe-style dataset\n    based on filelists.\n\n    Beware that this helper function is limited is the following two aspects:\n\n    - The resulting benchmark instance and the intermediate datasets used to\n      populate it will be of type CLASSIFICATION. There is no way to change\n      this.\n    - Task labels can only be defined by choosing a single task label for\n      each experience (the same task label is applied to all patterns of\n      experiences sharing the same position in different streams).\n\n    Despite those constraints, this helper function is usually sufficiently\n    powerful to cover most continual learning benchmarks based on file lists.\n\n    When in need to create a similar benchmark instance starting from an\n    in-memory list of paths, then the similar helper function\n    :func:`create_generic_benchmark_from_paths` can be used.\n\n    When in need to create a benchmark instance in which task labels are defined\n    in a more fine-grained way, then consider using\n    :func:`create_multi_dataset_generic_benchmark` by passing properly\n    initialized :class:`AvalancheDataset` instances.\n\n    :param root: The root path of the dataset. Can be None.\n    :param train_file_lists: A list of filelists describing the\n        paths of the training patterns for each experience.\n    :param test_file_lists: A list of filelists describing the\n        paths of the test patterns for each experience.\n    :param other_streams_file_lists: A dictionary describing the content of\n        custom streams. Keys must be valid stream names (letters and numbers,\n        not starting with a number) while the value must be a list of filelists\n        (same as `train_file_lists` and `test_file_lists` parameters). If this\n        dictionary contains the definition for \"train\" or \"test\" streams then\n        those definition will  override the `train_file_lists` and\n        `test_file_lists` parameters.\n    :param task_labels: A list of task labels. Must contain at least a value\n        for each experience. Each value describes the task label that will be\n        applied to all patterns of a certain experience. For more info on that,\n        see the function description.\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the benchmark. This means that the ``test_file_lists``\n        parameter must be list with a single element (the complete test set).\n        Alternatively, can be a plain string or :class:`Path` object.\n        Defaults to False.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param other_streams_transforms: Transformations to apply to custom\n        streams. If no transformations are defined for a custom stream,\n        then \"train\" transformations will be used. This parameter must be a\n        dictionary mapping stream names to transformations. The transformations\n        must be a two elements tuple where the first element defines the\n        X transformation while the second element is the Y transformation.\n        Those elements can be None. If this dictionary contains the\n        transformations for \"train\" or \"test\" streams then those transformations\n        will override the `train_transform`, `train_target_transform`,\n        `eval_transform` and `eval_target_transform` parameters.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "input_streams", "=", "dict", "(", "\n", "train", "=", "train_file_lists", ",", "\n", "test", "=", "test_file_lists", ")", "\n", "\n", "if", "other_streams_file_lists", "is", "not", "None", ":", "\n", "        ", "input_streams", "=", "{", "**", "input_streams", ",", "**", "other_streams_file_lists", "}", "\n", "\n", "", "stream_definitions", "=", "dict", "(", ")", "\n", "\n", "for", "stream_name", ",", "file_lists", "in", "input_streams", ".", "items", "(", ")", ":", "\n", "        ", "stream_datasets", "=", "[", "]", "\n", "for", "exp_id", ",", "f_list", "in", "enumerate", "(", "file_lists", ")", ":", "\n", "\n", "            ", "f_list_dataset", "=", "FilelistDataset", "(", "root", ",", "f_list", ")", "\n", "stream_datasets", ".", "append", "(", "AvalancheDataset", "(", "\n", "f_list_dataset", ",", "\n", "task_labels", "=", "task_labels", "[", "exp_id", "]", ")", ")", "\n", "\n", "", "stream_definitions", "[", "stream_name", "]", "=", "stream_datasets", "\n", "\n", "", "return", "create_multi_dataset_generic_benchmark", "(", "\n", "[", "]", ",", "[", "]", ",", "\n", "other_streams_datasets", "=", "stream_definitions", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "other_streams_transforms", "=", "other_streams_transforms", ",", "\n", "dataset_type", "=", "AvalancheDatasetType", ".", "CLASSIFICATION", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_generic_benchmark_from_paths": [[456, 575], ["dict", "dict", "dict.items", "generic_benchmark_creation.create_multi_dataset_generic_benchmark", "enumerate", "avalanche.benchmarks.utils.common_paths_root", "avalanche.benchmarks.utils.PathsDataset", "stream_datasets.append", "avalanche.benchmarks.utils.AvalancheDataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_multi_dataset_generic_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.datasets_from_filelists.common_paths_root"], ["def", "create_generic_benchmark_from_paths", "(", "\n", "train_lists_of_files", ":", "Sequence", "[", "Sequence", "[", "FileAndLabel", "]", "]", ",", "\n", "test_lists_of_files", ":", "Union", "[", "Sequence", "[", "FileAndLabel", "]", ",", "\n", "Sequence", "[", "Sequence", "[", "FileAndLabel", "]", "]", "]", ",", "\n", "*", ",", "\n", "other_streams_lists_of_files", ":", "Dict", "[", "str", ",", "Sequence", "[", "\n", "Sequence", "[", "FileAndLabel", "]", "]", "]", "=", "None", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "other_streams_transforms", ":", "Dict", "[", "str", ",", "Tuple", "[", "Any", ",", "Any", "]", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    Creates a benchmark instance given a sequence of lists of files. A separate\n    dataset will be created for each list. Each of those datasets\n    will be considered a separate experience.\n\n    This is very similar to :func:`create_generic_benchmark_from_filelists`,\n    with the main difference being that\n    :func:`create_generic_benchmark_from_filelists` accepts, for each\n    experience, a file list formatted in Caffe-style. On the contrary, this\n    accepts a list of tuples where each tuple contains two elements: the full\n    path to the pattern and its label. Optionally, the tuple may contain a third\n    element describing the bounding box of the element to crop. This last\n    bounding box may be useful when trying to extract the part of the image\n    depicting the desired element.\n\n    Apart from that, the same limitations of\n    :func:`create_generic_benchmark_from_filelists` regarding task labels apply.\n\n    The label of each pattern doesn't have to be an int. Also, a dataset type\n    can be defined.\n\n    :param train_lists_of_files: A list of lists. Each list describes the paths\n        and labels of patterns to include in that training experience, as\n        tuples. Each tuple must contain two elements: the full path to the\n        pattern and its class label. Optionally, the tuple may contain a\n        third element describing the bounding box to use for cropping (top,\n        left, height, width).\n    :param test_lists_of_files: A list of lists. Each list describes the paths\n        and labels of patterns to include in that test experience, as tuples.\n        Each tuple must contain two elements: the full path to the pattern\n        and its class label. Optionally, the tuple may contain a third element\n        describing the bounding box to use for cropping (top, left, height,\n        width).\n    :param other_streams_lists_of_files: A dictionary describing the content of\n        custom streams. Keys must be valid stream names (letters and numbers,\n        not starting with a number) while the value follow the same structure\n        of `train_lists_of_files` and `test_lists_of_files` parameters. If this\n        dictionary contains the definition for \"train\" or \"test\" streams then\n        those definition will  override the `train_lists_of_files` and\n        `test_lists_of_files` parameters.\n    :param task_labels: A list of task labels. Must contain at least a value\n        for each experience. Each value describes the task label that will be\n        applied to all patterns of a certain experience. For more info on that,\n        see the function description.\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the benchmark. This means that the ``test_list_of_files``\n        parameter must define a single experience (the complete test set).\n        Defaults to False.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param other_streams_transforms: Transformations to apply to custom\n        streams. If no transformations are defined for a custom stream,\n        then \"train\" transformations will be used. This parameter must be a\n        dictionary mapping stream names to transformations. The transformations\n        must be a two elements tuple where the first element defines the\n        X transformation while the second element is the Y transformation.\n        Those elements can be None. If this dictionary contains the\n        transformations for \"train\" or \"test\" streams then those transformations\n        will override the `train_transform`, `train_target_transform`,\n        `eval_transform` and `eval_target_transform` parameters.\n    :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "input_streams", "=", "dict", "(", "\n", "train", "=", "train_lists_of_files", ",", "\n", "test", "=", "test_lists_of_files", ")", "\n", "\n", "if", "other_streams_lists_of_files", "is", "not", "None", ":", "\n", "        ", "input_streams", "=", "{", "**", "input_streams", ",", "**", "other_streams_lists_of_files", "}", "\n", "\n", "", "stream_definitions", "=", "dict", "(", ")", "\n", "\n", "for", "stream_name", ",", "lists_of_files", "in", "input_streams", ".", "items", "(", ")", ":", "\n", "        ", "stream_datasets", "=", "[", "]", "\n", "for", "exp_id", ",", "list_of_files", "in", "enumerate", "(", "lists_of_files", ")", ":", "\n", "            ", "common_root", ",", "exp_paths_list", "=", "common_paths_root", "(", "list_of_files", ")", "\n", "paths_dataset", "=", "PathsDataset", "(", "common_root", ",", "exp_paths_list", ")", "\n", "stream_datasets", ".", "append", "(", "AvalancheDataset", "(", "\n", "paths_dataset", ",", "\n", "task_labels", "=", "task_labels", "[", "exp_id", "]", ")", ")", "\n", "\n", "", "stream_definitions", "[", "stream_name", "]", "=", "stream_datasets", "\n", "\n", "", "return", "create_multi_dataset_generic_benchmark", "(", "\n", "[", "]", ",", "[", "]", ",", "\n", "other_streams_datasets", "=", "stream_definitions", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "other_streams_transforms", "=", "other_streams_transforms", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_generic_benchmark_from_tensor_lists": [[577, 692], ["dict", "dict", "dict.items", "generic_benchmark_creation.create_multi_dataset_generic_benchmark", "enumerate", "stream_datasets.append", "avalanche.benchmarks.utils.AvalancheTensorDataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_multi_dataset_generic_benchmark"], ["", "def", "create_generic_benchmark_from_tensor_lists", "(", "\n", "train_tensors", ":", "Sequence", "[", "Sequence", "[", "Any", "]", "]", ",", "\n", "test_tensors", ":", "Sequence", "[", "Sequence", "[", "Any", "]", "]", ",", "\n", "*", ",", "\n", "other_streams_tensors", ":", "Dict", "[", "str", ",", "Sequence", "[", "Sequence", "[", "Any", "]", "]", "]", "=", "None", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "other_streams_transforms", ":", "Dict", "[", "str", ",", "Tuple", "[", "Any", ",", "Any", "]", "]", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    Creates a benchmark instance given lists of Tensors. A separate dataset will\n    be created from each Tensor tuple (x, y, z, ...) and each of those training\n    datasets will be considered a separate training experience. Using this\n    helper function is the lowest-level way to create a Continual Learning\n    benchmark. When possible, consider using higher level helpers.\n\n    Experiences are defined by passing lists of tensors as the `train_tensors`,\n    `test_tensors` (and `other_streams_tensors`) parameters. Those parameters\n    must be lists containing lists of tensors, one list for each experience.\n    Each tensor defines the value of a feature (\"x\", \"y\", \"z\", ...) for all\n    patterns of that experience.\n\n    By default the second tensor of each experience will be used to fill the\n    `targets` value (label of each pattern).\n\n    Beware that task labels can only be defined by choosing a single task label\n    for each experience (the same task label is applied to all patterns of\n    experiences sharing the same position in different streams).\n\n    When in need to create a benchmark instance in which task labels are defined\n    in a more fine-grained way, then consider using\n    :func:`create_multi_dataset_generic_benchmark` by passing properly\n    initialized :class:`AvalancheDataset` instances.\n\n    :param train_tensors: A list of lists. The first list must contain the\n        tensors for the first training experience (one tensor per feature), the\n        second list must contain the tensors for the second training experience,\n        and so on.\n    :param test_tensors: A list of lists. The first list must contain the\n        tensors for the first test experience (one tensor per feature), the\n        second list must contain the tensors for the second test experience,\n        and so on. When using `complete_test_set_only`, this parameter\n        must be a list containing a single sub-list for the single test\n        experience.\n    :param other_streams_tensors: A dictionary describing the content of\n        custom streams. Keys must be valid stream names (letters and numbers,\n        not starting with a number) while the value follow the same structure\n        of `train_tensors` and `test_tensors` parameters. If this\n        dictionary contains the definition for \"train\" or \"test\" streams then\n        those definition will  override the `train_tensors` and `test_tensors`\n        parameters.\n    :param task_labels: A list of task labels. Must contain at least a value\n        for each experience. Each value describes the task label that will be\n        applied to all patterns of a certain experience. For more info on that,\n        see the function description.\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the benchmark. This means that ``test_tensors`` must\n        define a single experience. Defaults to False.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param other_streams_transforms: Transformations to apply to custom\n        streams. If no transformations are defined for a custom stream,\n        then \"train\" transformations will be used. This parameter must be a\n        dictionary mapping stream names to transformations. The transformations\n        must be a two elements tuple where the first element defines the\n        X transformation while the second element is the Y transformation.\n        Those elements can be None. If this dictionary contains the\n        transformations for \"train\" or \"test\" streams then those transformations\n        will override the `train_transform`, `train_target_transform`,\n        `eval_transform` and `eval_target_transform` parameters.\n    :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n\n    :returns: A :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "input_streams", "=", "dict", "(", "\n", "train", "=", "train_tensors", ",", "\n", "test", "=", "test_tensors", ")", "\n", "\n", "if", "other_streams_tensors", "is", "not", "None", ":", "\n", "        ", "input_streams", "=", "{", "**", "input_streams", ",", "**", "other_streams_tensors", "}", "\n", "\n", "", "stream_definitions", "=", "dict", "(", ")", "\n", "\n", "for", "stream_name", ",", "list_of_exps_tensors", "in", "input_streams", ".", "items", "(", ")", ":", "\n", "        ", "stream_datasets", "=", "[", "]", "\n", "for", "exp_id", ",", "exp_tensors", "in", "enumerate", "(", "list_of_exps_tensors", ")", ":", "\n", "            ", "stream_datasets", ".", "append", "(", "AvalancheTensorDataset", "(", "\n", "*", "exp_tensors", ",", "dataset_type", "=", "dataset_type", ",", "\n", "task_labels", "=", "task_labels", "[", "exp_id", "]", ")", ")", "\n", "\n", "", "stream_definitions", "[", "stream_name", "]", "=", "stream_datasets", "\n", "\n", "", "return", "create_multi_dataset_generic_benchmark", "(", "\n", "[", "]", ",", "[", "]", ",", "\n", "other_streams_datasets", "=", "stream_definitions", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "other_streams_transforms", "=", "other_streams_transforms", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_scenario.NCScenario.__init__": [[32, 429], ["torch.unique().tolist", "len", "range", "range", "avalanche.benchmarks.utils.AvalancheSubset", "avalanche.benchmarks.utils.AvalancheSubset", "enumerate", "enumerate", "super().__init__", "ValueError", "ValueError", "max", "sum", "nc_scenario.NCScenario._classes_in_exp.append", "nc_scenario.NCScenario.original_classes_in_exp.append", "bool", "avalanche.benchmarks.utils.dataset_utils.ConstantSequence", "avalanche.benchmarks.utils.dataset_utils.ConstantSequence", "enumerate", "enumerate", "train_exps_patterns_assignment.append", "test_exps_patterns_assignment.append", "avalanche.benchmarks.utils.dataset_utils.ConstantSequence", "train_experiences.append", "avalanche.benchmarks.utils.dataset_utils.ConstantSequence", "test_experiences.append", "torch.unique", "list", "list", "range", "set", "set", "len", "len", "len", "len", "train_task_labels.append", "train_task_labels.append", "len", "avalanche.benchmarks.utils.AvalancheSubset", "test_task_labels.append", "test_task_labels.append", "len", "avalanche.benchmarks.utils.AvalancheSubset", "torch.as_tensor", "len", "len", "ValueError", "[].tolist", "ValueError", "min", "ValueError", "sum", "ValueError", "len", "ValueError", "ValueError", "range", "enumerate", "list", "selected_indexes_train.append", "selected_indexes_test.append", "set().union", "torch.random.manual_seed", "max", "min", "per_experience_classes.values", "per_experience_classes.values", "nc_scenario.NCScenario.classes_order_original_ids.index", "list", "range", "range", "set", "per_experience_classes.keys", "per_experience_classes.keys", "sum", "range", "set", "torch.as_tensor", "sum", "per_experience_classes.values", "torch.randperm", "per_experience_classes.values", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "train_dataset", ":", "AvalancheDataset", ",", "\n", "test_dataset", ":", "AvalancheDataset", ",", "\n", "n_experiences", ":", "int", ",", "\n", "task_labels", ":", "bool", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "per_experience_classes", ":", "Optional", "[", "Dict", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "class_ids_from_zero_from_first_exp", ":", "bool", "=", "False", ",", "\n", "class_ids_from_zero_in_each_exp", ":", "bool", "=", "False", ",", "\n", "reproducibility_data", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``NCGenericScenario`` instance given the training and test\n        Datasets and the number of experiences.\n\n        By default, the number of classes will be automatically detected by\n        looking at the training Dataset ``targets`` field. Classes will be\n        uniformly distributed across ``n_experiences`` unless a\n        ``per_experience_classes`` argument is specified.\n\n        The number of classes must be divisible without remainder by the number\n        of experiences. This also applies when the ``per_experience_classes``\n        argument is not None.\n\n        :param train_dataset: The training dataset. The dataset must be a\n            subclass of :class:`AvalancheDataset`. For instance, one can\n            use the datasets from the torchvision package like that:\n            ``train_dataset=AvalancheDataset(torchvision_dataset)``.\n        :param test_dataset: The test dataset. The dataset must be a\n            subclass of :class:`AvalancheDataset`. For instance, one can\n            use the datasets from the torchvision package like that:\n            ``test_dataset=AvalancheDataset(torchvision_dataset)``.\n        :param n_experiences: The number of experiences.\n        :param task_labels: If True, each experience will have an ascending task\n            label. If False, the task label will be 0 for all the experiences.\n        :param shuffle: If True, the class order will be shuffled. Defaults to\n            True.\n        :param seed: If shuffle is True and seed is not None, the class order\n            will be shuffled according to the seed. When None, the current\n            PyTorch random number generator state will be used.\n            Defaults to None.\n        :param fixed_class_order: If not None, the class order to use (overrides\n            the shuffle argument). Very useful for enhancing\n            reproducibility. Defaults to None.\n        :param per_experience_classes: Is not None, a dictionary whose keys are\n            (0-indexed) experience IDs and their values are the number of\n            classes to include in the respective experiences. The dictionary\n            doesn't have to contain a key for each experience! All the remaining\n            experiences will contain an equal amount of the remaining classes.\n            The remaining number of classes must be divisible without remainder\n            by the remaining number of experiences. For instance,\n            if you want to include 50 classes in the first experience\n            while equally distributing remaining classes across remaining\n            experiences, just pass the \"{0: 50}\" dictionary as the\n            per_experience_classes parameter. Defaults to None.\n        :param class_ids_from_zero_from_first_exp: If True, original class IDs\n            will be remapped so that they will appear as having an ascending\n            order. For instance, if the resulting class order after shuffling\n            (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and\n            class_ids_from_zero_from_first_exp is True, then all the patterns\n            belonging to class 23 will appear as belonging to class \"0\",\n            class \"34\" will be mapped to \"1\", class \"11\" to \"2\" and so on.\n            This is very useful when drawing confusion matrices and when dealing\n            with algorithms with dynamic head expansion. Defaults to False.\n            Mutually exclusive with the ``class_ids_from_zero_in_each_exp``\n            parameter.\n        :param class_ids_from_zero_in_each_exp: If True, original class IDs\n            will be mapped to range [0, n_classes_in_exp) for each experience.\n            Defaults to False. Mutually exclusive with the\n            ``class_ids_from_zero_from_first_exp parameter``.\n        :param reproducibility_data: If not None, overrides all the other\n            scenario definition options. This is usually a dictionary containing\n            data used to reproduce a specific experiment. One can use the\n            ``get_reproducibility_data`` method to get (and even distribute)\n            the experiment setup so that it can be loaded by passing it as this\n            parameter. In this way one can be sure that the same specific\n            experimental setup is being used (for reproducibility purposes).\n            Beware that, in order to reproduce an experiment, the same train and\n            test datasets must be used. Defaults to None.\n        \"\"\"", "\n", "if", "class_ids_from_zero_from_first_exp", "and", "class_ids_from_zero_in_each_exp", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid mutually exclusive options '", "\n", "'class_ids_from_zero_from_first_exp and '", "\n", "'class_ids_from_zero_in_each_exp set at the '", "\n", "'same time'", ")", "\n", "", "if", "reproducibility_data", ":", "\n", "            ", "n_experiences", "=", "reproducibility_data", "[", "'n_experiences'", "]", "\n", "\n", "", "if", "n_experiences", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid number of experiences (n_experiences '", "\n", "'parameter): must be greater than 0'", ")", "\n", "\n", "", "self", ".", "classes_order", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\"\"\" Stores the class order (remapped class IDs). \"\"\"", "\n", "\n", "self", ".", "classes_order_original_ids", ":", "List", "[", "int", "]", "=", "torch", ".", "unique", "(", "\n", "torch", ".", "as_tensor", "(", "train_dataset", ".", "targets", ")", ",", "\n", "sorted", "=", "True", ")", ".", "tolist", "(", ")", "\n", "\"\"\" Stores the class order (original class IDs) \"\"\"", "\n", "\n", "n_original_classes", "=", "max", "(", "self", ".", "classes_order_original_ids", ")", "+", "1", "\n", "\n", "self", ".", "class_mapping", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\"\"\"\n        class_mapping stores the class mapping so that \n        `mapped_class_id = class_mapping[original_class_id]`. \n        \n        If the benchmark is created with an amount of classes which is less than\n        the amount of all classes in the dataset, then class_mapping will \n        contain some -1 values corresponding to ignored classes. This can\n        happen when passing a fixed class order to the constructor.\n        \"\"\"", "\n", "\n", "self", ".", "n_classes_per_exp", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\"\"\" A list that, for each experience (identified by its index/ID),\n            stores the number of classes assigned to that experience. \"\"\"", "\n", "\n", "self", ".", "_classes_in_exp", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "\n", "self", ".", "original_classes_in_exp", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "\"\"\"\n        A list that, for each experience (identified by its index/ID), stores a \n        set of the original IDs of classes assigned to that experience. \n        This field applies to both train and test streams.\n        \"\"\"", "\n", "\n", "self", ".", "class_ids_from_zero_from_first_exp", ":", "bool", "=", "class_ids_from_zero_from_first_exp", "\n", "\"\"\" If True the class IDs have been remapped to start from zero. \"\"\"", "\n", "\n", "self", ".", "class_ids_from_zero_in_each_exp", ":", "bool", "=", "class_ids_from_zero_in_each_exp", "\n", "\"\"\" If True the class IDs have been remapped to start from zero in \n        each experience \"\"\"", "\n", "\n", "# Note: if fixed_class_order is None and shuffle is False,", "\n", "# the class order will be the one encountered", "\n", "# By looking at the train_dataset targets field", "\n", "if", "reproducibility_data", ":", "\n", "            ", "self", ".", "classes_order_original_ids", "=", "reproducibility_data", "[", "'classes_order_original_ids'", "]", "\n", "self", ".", "class_ids_from_zero_from_first_exp", "=", "reproducibility_data", "[", "'class_ids_from_zero_from_first_exp'", "]", "\n", "self", ".", "class_ids_from_zero_in_each_exp", "=", "reproducibility_data", "[", "'class_ids_from_zero_in_each_exp'", "]", "\n", "", "elif", "fixed_class_order", "is", "not", "None", ":", "\n", "# User defined class order -> just use it", "\n", "            ", "if", "len", "(", "set", "(", "self", ".", "classes_order_original_ids", ")", ".", "union", "(", "\n", "set", "(", "fixed_class_order", ")", ")", ")", "!=", "len", "(", "self", ".", "classes_order_original_ids", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Invalid classes defined in fixed_class_order'", ")", "\n", "\n", "", "self", ".", "classes_order_original_ids", "=", "list", "(", "fixed_class_order", ")", "\n", "", "elif", "shuffle", ":", "\n", "# No user defined class order.", "\n", "# If a seed is defined, set the random number generator seed.", "\n", "# If no seed has been defined, use the actual", "\n", "# random number generator state.", "\n", "# Finally, shuffle the class list to obtain a random classes", "\n", "# order", "\n", "            ", "if", "seed", "is", "not", "None", ":", "\n", "                ", "torch", ".", "random", ".", "manual_seed", "(", "seed", ")", "\n", "", "self", ".", "classes_order_original_ids", "=", "torch", ".", "as_tensor", "(", "self", ".", "classes_order_original_ids", ")", "[", "\n", "torch", ".", "randperm", "(", "len", "(", "self", ".", "classes_order_original_ids", ")", ")", "\n", "]", ".", "tolist", "(", ")", "\n", "\n", "", "self", ".", "n_classes", ":", "int", "=", "len", "(", "self", ".", "classes_order_original_ids", ")", "\n", "\"\"\" The number of classes \"\"\"", "\n", "\n", "if", "reproducibility_data", ":", "\n", "            ", "self", ".", "n_classes_per_exp", "=", "reproducibility_data", "[", "'n_classes_per_exp'", "]", "\n", "", "elif", "per_experience_classes", "is", "not", "None", ":", "\n", "# per_experience_classes is a user-defined dictionary that defines", "\n", "# the number of classes to include in some (or all) experiences.", "\n", "# Remaining classes are equally distributed across the other", "\n", "# experiences.", "\n", "#", "\n", "# Format of per_experience_classes dictionary:", "\n", "#   - key = experience id", "\n", "#   - value = number of classes for this experience", "\n", "\n", "            ", "if", "max", "(", "per_experience_classes", ".", "keys", "(", ")", ")", ">=", "n_experiences", "or", "min", "(", "\n", "per_experience_classes", ".", "keys", "(", ")", ")", "<", "0", ":", "\n", "# The dictionary contains a key (that is, a experience id) >=", "\n", "# the number of requested experiences... or < 0", "\n", "                ", "raise", "ValueError", "(", "\n", "'Invalid experience id in per_experience_classes parameter:'", "\n", "' experience ids must be in range [0, n_experiences)'", ")", "\n", "", "if", "min", "(", "per_experience_classes", ".", "values", "(", ")", ")", "<", "0", ":", "\n", "# One or more values (number of classes for each experience) < 0", "\n", "                ", "raise", "ValueError", "(", "'Wrong number of classes defined for one or '", "\n", "'more experiences: must be a non-negative '", "\n", "'value'", ")", "\n", "\n", "", "if", "sum", "(", "per_experience_classes", ".", "values", "(", ")", ")", ">", "self", ".", "n_classes", ":", "\n", "# The sum of dictionary values (n. of classes for each", "\n", "# experience) >= the number of classes", "\n", "                ", "raise", "ValueError", "(", "'Insufficient number of classes: '", "\n", "'per_experience_classes parameter can\\'t '", "\n", "'be satisfied'", ")", "\n", "\n", "# Remaining classes are equally distributed across remaining", "\n", "# experiences. This amount of classes must be be divisible without", "\n", "# remainder by the number of remaining experiences", "\n", "", "remaining_exps", "=", "n_experiences", "-", "len", "(", "per_experience_classes", ")", "\n", "if", "remaining_exps", ">", "0", "and", "(", "self", ".", "n_classes", "-", "sum", "(", "\n", "per_experience_classes", ".", "values", "(", ")", ")", ")", "%", "remaining_exps", ">", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'Invalid number of experiences: remaining '", "\n", "'classes cannot be divided by n_experiences'", ")", "\n", "\n", "# default_per_exp_classes is the default amount of classes", "\n", "# for the remaining experiences", "\n", "", "if", "remaining_exps", ">", "0", ":", "\n", "                ", "default_per_exp_classes", "=", "(", "self", ".", "n_classes", "-", "sum", "(", "\n", "per_experience_classes", ".", "values", "(", ")", ")", ")", "//", "remaining_exps", "\n", "", "else", ":", "\n", "                ", "default_per_exp_classes", "=", "0", "\n", "\n", "# Initialize the self.n_classes_per_exp list using", "\n", "# \"default_per_exp_classes\" as the default", "\n", "# amount of classes per experience. Then, loop through the", "\n", "# per_experience_classes dictionary to set the customized,", "\n", "# user defined, classes for the required experiences.", "\n", "", "self", ".", "n_classes_per_exp", "=", "[", "default_per_exp_classes", "]", "*", "n_experiences", "\n", "for", "exp_id", "in", "per_experience_classes", ":", "\n", "                ", "self", ".", "n_classes_per_exp", "[", "exp_id", "]", "=", "per_experience_classes", "[", "\n", "exp_id", "]", "\n", "", "", "else", ":", "\n", "# Classes will be equally distributed across the experiences", "\n", "# The amount of classes must be be divisible without remainder", "\n", "# by the number of experiences", "\n", "            ", "if", "self", ".", "n_classes", "%", "n_experiences", ">", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f'Invalid number of experiences: classes contained in '", "\n", "f'dataset ({self.n_classes}) cannot be divided by '", "\n", "f'n_experiences ({n_experiences})'", ")", "\n", "", "self", ".", "n_classes_per_exp", "=", "[", "self", ".", "n_classes", "//", "n_experiences", "]", "*", "n_experiences", "\n", "\n", "# Before populating the classes_in_experience list,", "\n", "# define the remapped class IDs.", "\n", "", "if", "reproducibility_data", ":", "\n", "# Method 0: use reproducibility data", "\n", "            ", "self", ".", "classes_order", "=", "reproducibility_data", "[", "'classes_order'", "]", "\n", "self", ".", "class_mapping", "=", "reproducibility_data", "[", "'class_mapping'", "]", "\n", "", "elif", "self", ".", "class_ids_from_zero_from_first_exp", ":", "\n", "# Method 1: remap class IDs so that they appear in ascending order", "\n", "# over all experiences", "\n", "            ", "self", ".", "classes_order", "=", "list", "(", "range", "(", "0", ",", "self", ".", "n_classes", ")", ")", "\n", "self", ".", "class_mapping", "=", "[", "-", "1", "]", "*", "n_original_classes", "\n", "for", "class_id", "in", "range", "(", "n_original_classes", ")", ":", "\n", "# This check is needed because, when a fixed class order is", "\n", "# used, the user may have defined an amount of classes less than", "\n", "# the overall amount of classes in the dataset.", "\n", "                ", "if", "class_id", "in", "self", ".", "classes_order_original_ids", ":", "\n", "                    ", "self", ".", "class_mapping", "[", "class_id", "]", "=", "self", ".", "classes_order_original_ids", ".", "index", "(", "class_id", ")", "\n", "", "", "", "elif", "self", ".", "class_ids_from_zero_in_each_exp", ":", "\n", "# Method 2: remap class IDs so that they appear in range [0, N] in", "\n", "# each experience", "\n", "            ", "self", ".", "classes_order", "=", "[", "]", "\n", "self", ".", "class_mapping", "=", "[", "-", "1", "]", "*", "n_original_classes", "\n", "next_class_idx", "=", "0", "\n", "for", "exp_id", ",", "exp_n_classes", "in", "enumerate", "(", "self", ".", "n_classes_per_exp", ")", ":", "\n", "                ", "self", ".", "classes_order", "+=", "list", "(", "range", "(", "exp_n_classes", ")", ")", "\n", "for", "exp_class_idx", "in", "range", "(", "exp_n_classes", ")", ":", "\n", "                    ", "original_class_position", "=", "next_class_idx", "+", "exp_class_idx", "\n", "original_class_id", "=", "self", ".", "classes_order_original_ids", "[", "\n", "original_class_position", "]", "\n", "self", ".", "class_mapping", "[", "original_class_id", "]", "=", "exp_class_idx", "\n", "", "next_class_idx", "+=", "exp_n_classes", "\n", "", "", "else", ":", "\n", "# Method 3: no remapping of any kind", "\n", "# remapped_id = class_mapping[class_id] -> class_id == remapped_id", "\n", "            ", "self", ".", "classes_order", "=", "self", ".", "classes_order_original_ids", "\n", "self", ".", "class_mapping", "=", "list", "(", "range", "(", "0", ",", "n_original_classes", ")", ")", "\n", "\n", "", "original_training_dataset", "=", "train_dataset", "\n", "original_test_dataset", "=", "test_dataset", "\n", "\n", "# Populate the _classes_in_exp and original_classes_in_exp lists", "\n", "# \"_classes_in_exp[exp_id]\": list of (remapped) class IDs assigned", "\n", "# to experience \"exp_id\"", "\n", "# \"original_classes_in_exp[exp_id]\": list of original class IDs", "\n", "# assigned to experience \"exp_id\"", "\n", "for", "exp_id", "in", "range", "(", "n_experiences", ")", ":", "\n", "            ", "classes_start_idx", "=", "sum", "(", "self", ".", "n_classes_per_exp", "[", ":", "exp_id", "]", ")", "\n", "classes_end_idx", "=", "classes_start_idx", "+", "self", ".", "n_classes_per_exp", "[", "\n", "exp_id", "]", "\n", "\n", "self", ".", "_classes_in_exp", ".", "append", "(", "\n", "set", "(", "self", ".", "classes_order", "[", "classes_start_idx", ":", "classes_end_idx", "]", ")", ")", "\n", "self", ".", "original_classes_in_exp", ".", "append", "(", "\n", "set", "(", "self", ".", "classes_order_original_ids", "[", "classes_start_idx", ":", "\n", "classes_end_idx", "]", ")", ")", "\n", "\n", "# Finally, create the experience -> patterns assignment.", "\n", "# In order to do this, we don't load all the patterns", "\n", "# instead we use the targets field.", "\n", "", "train_exps_patterns_assignment", "=", "[", "]", "\n", "test_exps_patterns_assignment", "=", "[", "]", "\n", "\n", "self", ".", "_has_task_labels", "=", "task_labels", "\n", "if", "reproducibility_data", "is", "not", "None", ":", "\n", "            ", "self", ".", "_has_task_labels", "=", "bool", "(", "\n", "reproducibility_data", "[", "'has_task_labels'", "]", ")", "\n", "\n", "", "if", "self", ".", "_has_task_labels", ":", "\n", "            ", "pattern_train_task_labels", "=", "[", "-", "1", "]", "*", "len", "(", "train_dataset", ")", "\n", "pattern_test_task_labels", "=", "[", "-", "1", "]", "*", "len", "(", "test_dataset", ")", "\n", "", "else", ":", "\n", "            ", "pattern_train_task_labels", "=", "ConstantSequence", "(", "0", ",", "len", "(", "train_dataset", ")", ")", "\n", "pattern_test_task_labels", "=", "ConstantSequence", "(", "0", ",", "len", "(", "test_dataset", ")", ")", "\n", "\n", "", "for", "exp_id", "in", "range", "(", "n_experiences", ")", ":", "\n", "            ", "selected_classes", "=", "self", ".", "original_classes_in_exp", "[", "exp_id", "]", "\n", "selected_indexes_train", "=", "[", "]", "\n", "for", "idx", ",", "element", "in", "enumerate", "(", "original_training_dataset", ".", "targets", ")", ":", "\n", "                ", "if", "element", "in", "selected_classes", ":", "\n", "                    ", "selected_indexes_train", ".", "append", "(", "idx", ")", "\n", "if", "self", ".", "_has_task_labels", ":", "\n", "                        ", "pattern_train_task_labels", "[", "idx", "]", "=", "exp_id", "\n", "\n", "", "", "", "selected_indexes_test", "=", "[", "]", "\n", "for", "idx", ",", "element", "in", "enumerate", "(", "original_test_dataset", ".", "targets", ")", ":", "\n", "                ", "if", "element", "in", "selected_classes", ":", "\n", "                    ", "selected_indexes_test", ".", "append", "(", "idx", ")", "\n", "if", "self", ".", "_has_task_labels", ":", "\n", "                        ", "pattern_test_task_labels", "[", "idx", "]", "=", "exp_id", "\n", "\n", "", "", "", "train_exps_patterns_assignment", ".", "append", "(", "selected_indexes_train", ")", "\n", "test_exps_patterns_assignment", ".", "append", "(", "selected_indexes_test", ")", "\n", "\n", "# Good idea, but doesn't work", "\n", "# transform_groups = train_eval_transforms(train_dataset, test_dataset)", "\n", "#", "\n", "# train_dataset = train_dataset\\", "\n", "#     .replace_transforms(*transform_groups['train'], group='train') \\", "\n", "#     .replace_transforms(*transform_groups['eval'], group='eval')", "\n", "#", "\n", "# test_dataset = test_dataset \\", "\n", "#     .replace_transforms(*transform_groups['train'], group='train') \\", "\n", "#     .replace_transforms(*transform_groups['eval'], group='eval')", "\n", "\n", "", "train_dataset", "=", "AvalancheSubset", "(", "\n", "train_dataset", ",", "class_mapping", "=", "self", ".", "class_mapping", ",", "\n", "initial_transform_group", "=", "'train'", ")", "\n", "test_dataset", "=", "AvalancheSubset", "(", "\n", "test_dataset", ",", "class_mapping", "=", "self", ".", "class_mapping", ",", "\n", "initial_transform_group", "=", "'eval'", ")", "\n", "\n", "self", ".", "train_exps_patterns_assignment", "=", "train_exps_patterns_assignment", "\n", "\"\"\" A list containing which training instances are assigned to each\n        experience in the train stream. Instances are identified by their id \n        w.r.t. the dataset found in the original_train_dataset field. \"\"\"", "\n", "\n", "self", ".", "test_exps_patterns_assignment", "=", "test_exps_patterns_assignment", "\n", "\"\"\" A list containing which test instances are assigned to each\n        experience in the test stream. Instances are identified by their id \n        w.r.t. the dataset found in the original_test_dataset field. \"\"\"", "\n", "\n", "train_experiences", "=", "[", "]", "\n", "train_task_labels", "=", "[", "]", "\n", "for", "t_id", ",", "exp_def", "in", "enumerate", "(", "train_exps_patterns_assignment", ")", ":", "\n", "            ", "if", "self", ".", "_has_task_labels", ":", "\n", "                ", "train_task_labels", ".", "append", "(", "t_id", ")", "\n", "", "else", ":", "\n", "                ", "train_task_labels", ".", "append", "(", "0", ")", "\n", "", "task_labels", "=", "ConstantSequence", "(", "train_task_labels", "[", "-", "1", "]", ",", "\n", "len", "(", "train_dataset", ")", ")", "\n", "train_experiences", ".", "append", "(", "\n", "AvalancheSubset", "(", "train_dataset", ",", "indices", "=", "exp_def", ",", "\n", "task_labels", "=", "task_labels", ")", ")", "\n", "\n", "", "test_experiences", "=", "[", "]", "\n", "test_task_labels", "=", "[", "]", "\n", "for", "t_id", ",", "exp_def", "in", "enumerate", "(", "test_exps_patterns_assignment", ")", ":", "\n", "            ", "if", "self", ".", "_has_task_labels", ":", "\n", "                ", "test_task_labels", ".", "append", "(", "t_id", ")", "\n", "", "else", ":", "\n", "                ", "test_task_labels", ".", "append", "(", "0", ")", "\n", "", "task_labels", "=", "ConstantSequence", "(", "test_task_labels", "[", "-", "1", "]", ",", "\n", "len", "(", "test_dataset", ")", ")", "\n", "test_experiences", ".", "append", "(", "\n", "AvalancheSubset", "(", "test_dataset", ",", "indices", "=", "exp_def", ",", "\n", "task_labels", "=", "task_labels", ")", ")", "\n", "\n", "", "super", "(", "NCScenario", ",", "self", ")", ".", "__init__", "(", "\n", "stream_definitions", "=", "{", "\n", "'train'", ":", "(", "train_experiences", ",", "train_task_labels", ",", "train_dataset", ")", ",", "\n", "'test'", ":", "(", "test_experiences", ",", "test_task_labels", ",", "test_dataset", ")", "\n", "}", ",", "\n", "experience_factory", "=", "NCExperience", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_scenario.NCScenario.get_reproducibility_data": [[430, 443], ["bool", "bool", "int"], "methods", ["None"], ["", "def", "get_reproducibility_data", "(", "self", ")", ":", "\n", "        ", "reproducibility_data", "=", "{", "\n", "'class_ids_from_zero_from_first_exp'", ":", "bool", "(", "\n", "self", ".", "class_ids_from_zero_from_first_exp", ")", ",", "\n", "'class_ids_from_zero_in_each_exp'", ":", "bool", "(", "\n", "self", ".", "class_ids_from_zero_in_each_exp", ")", ",", "\n", "'class_mapping'", ":", "self", ".", "class_mapping", ",", "\n", "'classes_order'", ":", "self", ".", "classes_order", ",", "\n", "'classes_order_original_ids'", ":", "self", ".", "classes_order_original_ids", ",", "\n", "'n_classes_per_exp'", ":", "self", ".", "n_classes_per_exp", ",", "\n", "'n_experiences'", ":", "int", "(", "self", ".", "n_experiences", ")", ",", "\n", "'has_task_labels'", ":", "self", ".", "_has_task_labels", "}", "\n", "return", "reproducibility_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_scenario.NCScenario.classes_in_exp_range": [[444, 468], ["None"], "methods", ["None"], ["", "def", "classes_in_exp_range", "(", "self", ",", "exp_start", ":", "int", ",", "\n", "exp_end", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        Gets a list of classes contained in the given experiences. The\n        experiences are defined by range. This means that only the classes in\n        range [exp_start, exp_end) will be included.\n\n        :param exp_start: The starting experience ID.\n        :param exp_end: The final experience ID. Can be None, which means that\n            all the remaining experiences will be taken.\n\n        :returns: The classes contained in the required experience range.\n        \"\"\"", "\n", "# Ref: https://stackoverflow.com/a/952952", "\n", "if", "exp_end", "is", "None", ":", "\n", "            ", "return", "[", "\n", "item", "for", "sublist", "in", "\n", "self", ".", "classes_in_experience", "[", "'train'", "]", "[", "exp_start", ":", "]", "\n", "for", "item", "in", "sublist", "]", "\n", "\n", "", "return", "[", "\n", "item", "for", "sublist", "in", "\n", "self", ".", "classes_in_experience", "[", "'train'", "]", "[", "exp_start", ":", "exp_end", "]", "\n", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_scenario.NCExperience.__init__": [[478, 491], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "origin_stream", ":", "GenericScenarioStream", "[", "\n", "'NCExperience'", ",", "NCScenario", "]", ",", "\n", "current_experience", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``NCExperience`` instance given the stream from this\n        experience was taken and and the current experience ID.\n\n        :param origin_stream: The stream from which this experience was\n            obtained.\n        :param current_experience: The current experience ID, as an integer.\n        \"\"\"", "\n", "super", "(", "NCExperience", ",", "self", ")", ".", "__init__", "(", "origin_stream", ",", "current_experience", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils._indexes_grouped_by_classes": [[22, 76], ["collections.OrderedDict", "avalanche.benchmarks.utils.tensor_as_list", "set", "enumerate", "avalanche.benchmarks.utils.tensor_as_list", "sorted", "set", "result.extend", "torch.unique().tolist", "result_per_class[].append", "result_per_class[].sort", "torch.unique", "torch.as_tensor"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list"], ["def", "_indexes_grouped_by_classes", "(", "sequence", ":", "Sequence", "[", "SupportsInt", "]", ",", "\n", "search_elements", ":", "Union", "[", "None", ",", "Sequence", "[", "int", "]", "]", ",", "\n", "sort_indexes", ":", "bool", "=", "True", ",", "\n", "sort_classes", ":", "bool", "=", "True", ")", "->", "Union", "[", "List", "[", "int", "]", ",", "None", "]", ":", "\n", "    ", "result_per_class", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", "=", "OrderedDict", "(", ")", "\n", "result", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\n", "# tensor_as_list() handles the situation in which sequence and", "\n", "# search_elements are a torch.Tensor", "\n", "#", "\n", "# Without the tensor_as_list conversion:", "\n", "# result_per_class[element].append(idx) -> error", "\n", "# because result_per_class[0] won't exist (result_per_class[tensor(0)] will)", "\n", "if", "search_elements", "is", "not", "None", ":", "\n", "        ", "search_elements", "=", "tensor_as_list", "(", "search_elements", ")", "\n", "", "sequence", "=", "tensor_as_list", "(", "sequence", ")", "\n", "\n", "if", "sort_classes", ":", "\n", "        ", "if", "search_elements", "is", "None", ":", "\n", "            ", "search_elements", "=", "torch", ".", "unique", "(", "torch", ".", "as_tensor", "(", "sequence", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "# Consider that result_per_class is an OrderedDict", "\n", "# This means that, if sort_classes is True, the next for statement", "\n", "# will initialize the \"result_per_class\" in sorted order ->", "\n", "# -> patterns will be ordered by ascending class ID", "\n", "", "search_elements", "=", "sorted", "(", "search_elements", ")", "\n", "\n", "", "for", "search_element", "in", "search_elements", ":", "\n", "        ", "result_per_class", "[", "search_element", "]", "=", "[", "]", "\n", "\n", "# Set based \"in\" operator is **much** faster that its list counterpart!", "\n", "", "search_elements_set", "=", "set", "(", ")", "\n", "if", "search_elements", "is", "not", "None", ":", "\n", "        ", "search_elements_set", "=", "set", "(", "search_elements", ")", "\n", "\n", "# Stores each pattern index in the appropriate class list", "\n", "", "for", "idx", ",", "element", "in", "enumerate", "(", "sequence", ")", ":", "\n", "        ", "if", "search_elements", "is", "None", "or", "element", "in", "search_elements_set", ":", "\n", "            ", "result_per_class", "[", "element", "]", ".", "append", "(", "idx", ")", "\n", "\n", "# Concatenate all the pattern indexes", "\n", "", "", "for", "search_element", "in", "search_elements", ":", "\n", "        ", "if", "sort_indexes", ":", "\n", "            ", "result_per_class", "[", "search_element", "]", ".", "sort", "(", ")", "\n", "", "result", ".", "extend", "(", "result_per_class", "[", "search_element", "]", ")", "\n", "\n", "", "if", "result", "==", "sequence", ":", "\n", "# The resulting index order is the same as the input one", "\n", "# Return None to flag that the whole sequence can be", "\n", "# taken as it already is", "\n", "        ", "return", "None", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils._indexes_without_grouping": [[78, 110], ["avalanche.benchmarks.utils.tensor_as_list", "avalanche.benchmarks.utils.tensor_as_list", "list", "set", "enumerate", "list.sort", "list.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.utils.tensor_as_list"], ["", "def", "_indexes_without_grouping", "(", "sequence", ":", "Sequence", "[", "SupportsInt", "]", ",", "\n", "search_elements", ":", "Union", "[", "None", ",", "Sequence", "[", "int", "]", "]", ",", "\n", "sort_indexes", ":", "bool", "=", "False", ")", "->", "Union", "[", "List", "[", "int", "]", ",", "None", "]", ":", "\n", "    ", "sequence", "=", "tensor_as_list", "(", "sequence", ")", "\n", "\n", "if", "search_elements", "is", "None", "and", "not", "sort_indexes", ":", "\n", "# No-op", "\n", "        ", "return", "sequence", "\n", "\n", "", "if", "search_elements", "is", "not", "None", ":", "\n", "        ", "search_elements", "=", "tensor_as_list", "(", "search_elements", ")", "\n", "\n", "", "result", ":", "List", "[", "int", "]", "\n", "if", "search_elements", "is", "None", ":", "\n", "        ", "result", "=", "list", "(", "sequence", ")", "\n", "", "else", ":", "\n", "# Set based \"in\" operator is **much** faster that its list counterpart!", "\n", "        ", "search_elements", "=", "set", "(", "search_elements", ")", "\n", "result", "=", "[", "]", "\n", "for", "idx", ",", "element", "in", "enumerate", "(", "sequence", ")", ":", "\n", "            ", "if", "element", "in", "search_elements", ":", "\n", "                ", "result", ".", "append", "(", "idx", ")", "\n", "\n", "", "", "", "if", "sort_indexes", ":", "\n", "        ", "result", ".", "sort", "(", ")", "\n", "", "elif", "not", "sort_indexes", "and", "len", "(", "result", ")", "==", "len", "(", "sequence", ")", ":", "\n", "# All patterns selected. Also, no sorting is required", "\n", "# Return None to flag that the whole sequence can be", "\n", "# taken as it already is", "\n", "        ", "return", "None", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils._indexes_from_set": [[112, 145], ["nc_utils._indexes_without_grouping", "nc_utils._indexes_grouped_by_classes"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils._indexes_without_grouping", "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils._indexes_grouped_by_classes"], ["", "def", "_indexes_from_set", "(", "sequence", ":", "Sequence", "[", "SupportsInt", "]", ",", "\n", "search_elements", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "None", "]", ",", "\n", "bucket_classes", ":", "bool", "=", "True", ",", "\n", "sort_classes", ":", "bool", "=", "False", ",", "sort_indexes", ":", "bool", "=", "False", ")", "->", "Union", "[", "List", "[", "int", "]", ",", "None", "]", ":", "\n", "    ", "\"\"\"\n    Given the target list of a dataset, returns the indexes of patterns\n    belonging to classes listed in the search_elements parameter.\n\n    :param sequence: The list of pattern targets, as a list.\n    :param search_elements: A list of classes used to filter the dataset\n        patterns. Patterns belonging to one of those classes will be included.\n        If None, all patterns will be included.\n    :param bucket_classes: If True, pattern indexes will be returned so that\n        patterns will be grouped by class. Defaults to True.\n    :param sort_classes: If both ``bucket_classes`` and ``sort_classes`` are\n        True, class groups will be sorted by class index. Ignored if\n        ``bucket_classes`` is False. Defaults to False.\n    :param sort_indexes: If True, patterns indexes will be sorted. When\n        bucketing by class, patterns will be sorted inside their buckets.\n        Defaults to False.\n\n    :returns: The indexes of patterns belonging to the required classes,\n        as a list. Can return None, which means that the original pattern\n        sequence already satisfies all the constraints.\n    \"\"\"", "\n", "if", "bucket_classes", ":", "\n", "        ", "return", "_indexes_grouped_by_classes", "(", "sequence", ",", "search_elements", ",", "\n", "sort_indexes", "=", "sort_indexes", ",", "\n", "sort_classes", "=", "sort_classes", ")", "\n", "\n", "", "return", "_indexes_without_grouping", "(", "sequence", ",", "search_elements", ",", "\n", "sort_indexes", "=", "sort_indexes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils.make_nc_transformation_subset": [[147, 185], ["avalanche.benchmarks.utils.AvalancheSubset", "nc_utils._indexes_from_set"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.new_classes.nc_utils._indexes_from_set"], ["", "def", "make_nc_transformation_subset", "(", "dataset", ":", "SupportedDataset", ",", "\n", "transform", ":", "Any", ",", "target_transform", ":", "Any", ",", "\n", "classes", ":", "Union", "[", "None", ",", "Sequence", "[", "int", "]", "]", ",", "\n", "bucket_classes", ":", "bool", "=", "False", ",", "\n", "sort_classes", ":", "bool", "=", "False", ",", "\n", "sort_indexes", ":", "bool", "=", "False", ")", "->", "AvalancheSubset", ":", "\n", "    ", "\"\"\"\n    Creates a subset given the list of classes the patterns should belong to.\n\n    :param dataset: The original dataset\n    :param transform: The transform function for patterns. Can be None.\n    :param target_transform: The transform function for targets. Can be None.\n    :param classes: A list of classes used to filter the dataset patterns.\n        Patterns belonging to one of those classes will be included. If None,\n        all patterns will be included.\n    :param bucket_classes: If True, the final Dataset will output patterns by\n        grouping them by class. Defaults to True.\n    :param sort_classes: If ``bucket_classes`` and ``sort_classes`` are both\n        True, the final Dataset will output patterns by grouping them by class\n        and the class groups will be ordered by class ID (ascending). Ignored\n        if ``bucket_classes`` is False. Defaults to False.\n    :param sort_indexes: If True, pattern indexes will be sorted (ascending).\n        When grouping by class, patterns will be sorted inside their respective\n        class buckets. Defaults to False.\n\n    :returns: A :class:`TransformationSubset` that includes only patterns\n        belonging to the given classes, in the order controlled by the\n        ``bucket_classes``, ``sort_classes`` and ``sort_indexes`` parameters.\n    \"\"\"", "\n", "return", "AvalancheSubset", "(", "\n", "dataset", ",", "\n", "indices", "=", "_indexes_from_set", "(", "dataset", ".", "targets", ",", "classes", ",", "\n", "bucket_classes", "=", "bucket_classes", ",", "\n", "sort_classes", "=", "sort_classes", ",", "\n", "sort_indexes", "=", "sort_indexes", ")", ",", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_instances.ni_utils._exp_structure_from_assignment": [[18, 37], ["len", "range", "torch.unique", "range", "range", "int", "torch.as_tensor", "len", "int", "range", "int"], "function", ["None"], ["def", "_exp_structure_from_assignment", "(", "\n", "dataset", ":", "ISupportedClassificationDataset", "[", "Any", "]", ",", "\n", "assignment", ":", "Sequence", "[", "Sequence", "[", "int", "]", "]", ",", "\n", "n_classes", ":", "int", ")", ":", "\n", "    ", "n_experiences", "=", "len", "(", "assignment", ")", "\n", "exp_structure", "=", "[", "[", "0", "for", "_", "in", "range", "(", "n_classes", ")", "]", "\n", "for", "_", "in", "range", "(", "n_experiences", ")", "]", "\n", "\n", "for", "exp_id", "in", "range", "(", "n_experiences", ")", ":", "\n", "        ", "exp_targets", "=", "[", "int", "(", "dataset", ".", "targets", "[", "pattern_idx", "]", ")", "\n", "for", "pattern_idx", "in", "assignment", "[", "exp_id", "]", "]", "\n", "cls_ids", ",", "cls_counts", "=", "torch", ".", "unique", "(", "torch", ".", "as_tensor", "(", "\n", "exp_targets", ")", ",", "return_counts", "=", "True", ")", "\n", "\n", "for", "unique_idx", "in", "range", "(", "len", "(", "cls_ids", ")", ")", ":", "\n", "            ", "exp_structure", "[", "exp_id", "]", "[", "int", "(", "cls_ids", "[", "unique_idx", "]", ")", "]", "+=", "int", "(", "cls_counts", "[", "unique_idx", "]", ")", "\n", "\n", "", "", "return", "exp_structure", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_instances.ni_scenario.NIScenario.__init__": [[41, 405], ["torch.unique", "len", "range", "enumerate", "super().__init__", "len", "ValueError", "ValueError", "torch.as_tensor", "list", "avalanche.benchmarks.utils.AvalancheSubset", "torch.unique", "len", "int", "int", "avalanche.benchmarks.scenarios.new_instances.ni_utils._exp_structure_from_assignment", "min", "torch.as_tensor", "len", "avalanche.benchmarks.utils.dataset_utils.ConstantSequence", "train_experiences.append", "range", "list.extend", "torch.as_tensor", "ValueError", "torch.random.manual_seed", "torch.nonzero().view().tolist", "range", "range", "set", "range", "list", "range", "range", "train_task_labels.append", "train_task_labels.append", "len", "avalanche.benchmarks.utils.AvalancheSubset", "range", "[].tolist", "range", "range", "range", "[].tolist", "list.sort", "len", "len", "exp_patterns[].extend", "torch.unique", "cls_ids.tolist.tolist.tolist", "cls_counts.tolist.tolist.tolist", "range", "torch.nonzero().view", "range", "range", "range", "range", "exp_patterns[].extend", "range", "range", "range", "len", "exp_patterns[].extend", "list.difference_update", "torch.as_tensor", "len", "range", "exp_patterns[].append", "torch.randperm().tolist", "range", "torch.randperm().tolist", "torch.nonzero", "torch.as_tensor", "torch.as_tensor", "torch.eq", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_instances.ni_utils._exp_structure_from_assignment"], ["def", "__init__", "(", "\n", "self", ",", "\n", "train_dataset", ":", "AvalancheDataset", ",", "\n", "test_dataset", ":", "AvalancheDataset", ",", "\n", "n_experiences", ":", "int", ",", "\n", "task_labels", ":", "bool", "=", "False", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "balance_experiences", ":", "bool", "=", "False", ",", "\n", "min_class_patterns_in_exp", ":", "int", "=", "0", ",", "\n", "fixed_exp_assignment", ":", "Optional", "[", "Sequence", "[", "Sequence", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "reproducibility_data", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a NIScenario instance given the training and test Datasets and\n        the number of experiences.\n\n        :param train_dataset: The training dataset. The dataset must be an\n            instance of :class:`AvalancheDataset`. For instance, one can\n            use the datasets from the torchvision package like that:\n            ``train_dataset=AvalancheDataset(torchvision_dataset)``.\n        :param test_dataset: The test dataset. The dataset must be a\n            subclass of :class:`AvalancheDataset`. For instance, one can\n            use the datasets from the torchvision package like that:\n            ``test_dataset=AvalancheDataset(torchvision_dataset)``.\n        :param n_experiences: The number of experiences.\n        :param task_labels: If True, each experience will have an ascending task\n            label. If False, the task label will be 0 for all the experiences.\n            Defaults to False.\n        :param shuffle: If True, the patterns order will be shuffled. Defaults\n            to True.\n        :param seed: If shuffle is True and seed is not None, the class order\n            will be shuffled according to the seed. When None, the current\n            PyTorch random number generator state will be used.\n            Defaults to None.\n        :param balance_experiences: If True, pattern of each class will be\n            equally spread across all experiences. If False, patterns will be\n            assigned to experiences in a complete random way. Defaults to False.\n        :param min_class_patterns_in_exp: The minimum amount of patterns of\n            every class that must be assigned to every experience. Compatible\n            with the ``balance_experiences`` parameter. An exception will be\n            raised if this constraint can't be satisfied. Defaults to 0.\n        :param fixed_exp_assignment: If not None, the pattern assignment\n            to use. It must be a list with an entry for each experience. Each\n            entry is a list that contains the indexes of patterns belonging to\n            that experience. Overrides the ``shuffle``, ``balance_experiences``\n            and ``min_class_patterns_in_exp`` parameters.\n        :param reproducibility_data: If not None, overrides all the other\n            scenario definition options, including ``fixed_exp_assignment``.\n            This is usually a dictionary containing data used to\n            reproduce a specific experiment. One can use the\n            ``get_reproducibility_data`` method to get (and even distribute)\n            the experiment setup so that it can be loaded by passing it as this\n            parameter. In this way one can be sure that the same specific\n            experimental setup is being used (for reproducibility purposes).\n            Beware that, in order to reproduce an experiment, the same train and\n            test datasets must be used. Defaults to None.\n        \"\"\"", "\n", "\n", "self", ".", "_has_task_labels", "=", "task_labels", "\n", "\n", "self", ".", "train_exps_patterns_assignment", "=", "[", "]", "\n", "\n", "if", "reproducibility_data", "is", "not", "None", ":", "\n", "            ", "self", ".", "train_exps_patterns_assignment", "=", "reproducibility_data", "[", "\n", "'exps_patterns_assignment'", "]", "\n", "self", ".", "_has_task_labels", "=", "reproducibility_data", "[", "'has_task_labels'", "]", "\n", "n_experiences", "=", "len", "(", "self", ".", "train_exps_patterns_assignment", ")", "\n", "\n", "", "if", "n_experiences", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid number of experiences (n_experiences '", "\n", "'parameter): must be greater than 0'", ")", "\n", "\n", "", "if", "min_class_patterns_in_exp", "<", "0", "and", "reproducibility_data", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid min_class_patterns_in_exp parameter: '", "\n", "'must be greater than or equal to 0'", ")", "\n", "\n", "# # Good idea, but doesn't work", "\n", "# transform_groups = train_eval_transforms(train_dataset, test_dataset)", "\n", "#", "\n", "# train_dataset = train_dataset \\", "\n", "#     .replace_transforms(*transform_groups['train'], group='train') \\", "\n", "#     .replace_transforms(*transform_groups['eval'], group='eval')", "\n", "#", "\n", "# test_dataset = test_dataset \\", "\n", "#     .replace_transforms(*transform_groups['train'], group='train') \\", "\n", "#     .replace_transforms(*transform_groups['eval'], group='eval')", "\n", "\n", "", "unique_targets", ",", "unique_count", "=", "torch", ".", "unique", "(", "\n", "torch", ".", "as_tensor", "(", "train_dataset", ".", "targets", ")", ",", "return_counts", "=", "True", ")", "\n", "\n", "self", ".", "n_classes", ":", "int", "=", "len", "(", "unique_targets", ")", "\n", "\"\"\"\n        The amount of classes in the original training set.\n        \"\"\"", "\n", "\n", "self", ".", "n_patterns_per_class", ":", "List", "[", "int", "]", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "n_classes", ")", "]", "\n", "\"\"\"\n        The amount of patterns for each class in the original training set.\n        \"\"\"", "\n", "\n", "if", "fixed_exp_assignment", ":", "\n", "            ", "included_patterns", "=", "list", "(", ")", "\n", "for", "exp_def", "in", "fixed_exp_assignment", ":", "\n", "                ", "included_patterns", ".", "extend", "(", "exp_def", ")", "\n", "", "subset", "=", "AvalancheSubset", "(", "train_dataset", ",", "\n", "indices", "=", "included_patterns", ")", "\n", "unique_targets", ",", "unique_count", "=", "torch", ".", "unique", "(", "\n", "torch", ".", "as_tensor", "(", "subset", ".", "targets", ")", ",", "return_counts", "=", "True", ")", "\n", "\n", "", "for", "unique_idx", "in", "range", "(", "len", "(", "unique_targets", ")", ")", ":", "\n", "            ", "class_id", "=", "int", "(", "unique_targets", "[", "unique_idx", "]", ")", "\n", "class_count", "=", "int", "(", "unique_count", "[", "unique_idx", "]", ")", "\n", "self", ".", "n_patterns_per_class", "[", "class_id", "]", "=", "class_count", "\n", "\n", "", "self", ".", "n_patterns_per_experience", ":", "List", "[", "int", "]", "=", "[", "]", "\n", "\"\"\"\n        The number of patterns in each experience.\n        \"\"\"", "\n", "\n", "self", ".", "exp_structure", ":", "List", "[", "List", "[", "int", "]", "]", "=", "[", "]", "\n", "\"\"\" This field contains, for each training experience, the number of\n        instances of each class assigned to that experience. \"\"\"", "\n", "\n", "if", "reproducibility_data", "or", "fixed_exp_assignment", ":", "\n", "# fixed_patterns_assignment/reproducibility_data is the user", "\n", "# provided pattern assignment. All we have to do is populate", "\n", "# remaining fields of the class!", "\n", "# n_patterns_per_experience is filled later based on exp_structure", "\n", "# so we only need to fill exp_structure.", "\n", "\n", "            ", "if", "reproducibility_data", ":", "\n", "                ", "exp_patterns", "=", "self", ".", "train_exps_patterns_assignment", "\n", "", "else", ":", "\n", "                ", "exp_patterns", "=", "fixed_exp_assignment", "\n", "", "self", ".", "exp_structure", "=", "_exp_structure_from_assignment", "(", "\n", "train_dataset", ",", "exp_patterns", ",", "self", ".", "n_classes", "\n", ")", "\n", "", "else", ":", "\n", "# All experiences will all contain the same amount of patterns", "\n", "# The amount of patterns doesn't need to be divisible without", "\n", "# remainder by the number of experience, so we distribute remaining", "\n", "# patterns across randomly selected experience (when shuffling) or", "\n", "# the first N experiences (when not shuffling). However, we first", "\n", "# have to check if the min_class_patterns_in_exp constraint is", "\n", "# satisfiable.", "\n", "            ", "min_class_patterns", "=", "min", "(", "self", ".", "n_patterns_per_class", ")", "\n", "if", "min_class_patterns", "<", "n_experiences", "*", "min_class_patterns_in_exp", ":", "\n", "                ", "raise", "ValueError", "(", "'min_class_patterns_in_exp constraint '", "\n", "'can\\'t be satisfied'", ")", "\n", "\n", "", "if", "seed", "is", "not", "None", ":", "\n", "                ", "torch", ".", "random", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "# First, get the patterns indexes for each class", "\n", "", "targets_as_tensor", "=", "torch", ".", "as_tensor", "(", "train_dataset", ".", "targets", ")", "\n", "classes_to_patterns_idx", "=", "[", "\n", "torch", ".", "nonzero", "(", "\n", "torch", ".", "eq", "(", "targets_as_tensor", ",", "class_id", ")", ")", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "for", "class_id", "in", "range", "(", "self", ".", "n_classes", ")", "\n", "]", "\n", "\n", "if", "shuffle", ":", "\n", "                ", "classes_to_patterns_idx", "=", "[", "\n", "torch", ".", "as_tensor", "(", "cls_patterns", ")", "[", "\n", "torch", ".", "randperm", "(", "len", "(", "cls_patterns", ")", ")", "\n", "]", ".", "tolist", "(", ")", "for", "cls_patterns", "in", "classes_to_patterns_idx", "\n", "]", "\n", "\n", "# Here we assign patterns to each experience. Two different", "\n", "# strategies are required in order to manage the", "\n", "# balance_experiences parameter.", "\n", "", "if", "balance_experiences", ":", "\n", "# If balance_experiences is True we have to make sure that", "\n", "# patterns of each class are equally distributed across", "\n", "# experiences.", "\n", "#", "\n", "# To do this, populate self.exp_structure, which will", "\n", "# describe how many patterns of each class are assigned to each", "\n", "# experience. Then, for each experience, assign the required", "\n", "# amount of patterns of each class.", "\n", "#", "\n", "# We already checked that there are enough patterns for each", "\n", "# class to satisfy the min_class_patterns_in_exp param so here", "\n", "# we don't need to explicitly enforce that constraint.", "\n", "\n", "# First, count how many patterns of each class we have to assign", "\n", "# to all the experiences (avg). We also get the number of", "\n", "# remaining patterns which we'll have to assign in a second", "\n", "# experience.", "\n", "                ", "class_patterns_per_exp", "=", "[", "\n", "(", "(", "n_class_patterns", "//", "n_experiences", ")", ",", "\n", "(", "n_class_patterns", "%", "n_experiences", ")", ")", "\n", "for", "n_class_patterns", "in", "self", ".", "n_patterns_per_class", "\n", "]", "\n", "\n", "# Remember: exp_structure[exp_id][class_id] is the amount of", "\n", "# patterns of class \"class_id\" in experience \"exp_id\"", "\n", "#", "\n", "# This is the easier experience: just assign the average amount", "\n", "# of class patterns to each experience.", "\n", "self", ".", "exp_structure", "=", "[", "\n", "[", "class_patterns_this_exp", "[", "0", "]", "\n", "for", "class_patterns_this_exp", "\n", "in", "class_patterns_per_exp", "]", "for", "_", "in", "range", "(", "n_experiences", ")", "\n", "]", "\n", "\n", "# Now we have to distribute the remaining patterns of each class", "\n", "#", "\n", "# This means that, for each class, we can (randomly) select", "\n", "# \"n_class_patterns % n_experiences\" experiences to assign a", "\n", "# single additional pattern of that class.", "\n", "for", "class_id", "in", "range", "(", "self", ".", "n_classes", ")", ":", "\n", "                    ", "n_remaining", "=", "class_patterns_per_exp", "[", "class_id", "]", "[", "1", "]", "\n", "if", "n_remaining", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "if", "shuffle", ":", "\n", "                        ", "assignment_of_remaining_patterns", "=", "torch", ".", "randperm", "(", "\n", "n_experiences", ")", ".", "tolist", "(", ")", "[", ":", "n_remaining", "]", "\n", "", "else", ":", "\n", "                        ", "assignment_of_remaining_patterns", "=", "range", "(", "n_remaining", ")", "\n", "", "for", "exp_id", "in", "assignment_of_remaining_patterns", ":", "\n", "                        ", "self", ".", "exp_structure", "[", "exp_id", "]", "[", "class_id", "]", "+=", "1", "\n", "\n", "# Following the self.exp_structure definition, assign", "\n", "# the actual patterns to each experience.", "\n", "#", "\n", "# For each experience we assign exactly", "\n", "# self.exp_structure[exp_id][class_id] patterns of", "\n", "# class \"class_id\"", "\n", "", "", "exp_patterns", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_experiences", ")", "]", "\n", "next_idx_per_class", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "n_classes", ")", "]", "\n", "for", "exp_id", "in", "range", "(", "n_experiences", ")", ":", "\n", "                    ", "for", "class_id", "in", "range", "(", "self", ".", "n_classes", ")", ":", "\n", "                        ", "start_idx", "=", "next_idx_per_class", "[", "class_id", "]", "\n", "n_patterns", "=", "self", ".", "exp_structure", "[", "exp_id", "]", "[", "class_id", "]", "\n", "end_idx", "=", "start_idx", "+", "n_patterns", "\n", "exp_patterns", "[", "exp_id", "]", ".", "extend", "(", "\n", "classes_to_patterns_idx", "[", "class_id", "]", "[", "start_idx", ":", "end_idx", "]", "\n", ")", "\n", "next_idx_per_class", "[", "class_id", "]", "=", "end_idx", "\n", "", "", "", "else", ":", "\n", "# If balance_experiences if False, we just randomly shuffle the", "\n", "# patterns indexes and pick N patterns for each experience.", "\n", "#", "\n", "# However, we have to enforce the min_class_patterns_in_exp", "\n", "# constraint, which makes things difficult.", "\n", "# In the balance_experiences scenario, that constraint is", "\n", "# implicitly enforced by equally distributing class patterns in", "\n", "# each experience (we already checked that there are enough", "\n", "# overall patterns for each class to satisfy", "\n", "# min_class_patterns_in_exp)", "\n", "\n", "# Here we have to assign the minimum required amount of class", "\n", "# patterns to each experience first, then we can move to", "\n", "# randomly assign the remaining patterns to each experience.", "\n", "\n", "# First, initialize exp_patterns and exp_structure", "\n", "                ", "exp_patterns", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_experiences", ")", "]", "\n", "self", ".", "exp_structure", "=", "[", "[", "0", "for", "_", "in", "range", "(", "self", ".", "n_classes", ")", "]", "\n", "for", "_", "in", "range", "(", "n_experiences", ")", "]", "\n", "\n", "# For each experience we assign exactly", "\n", "# min_class_patterns_in_exp patterns from each class", "\n", "#", "\n", "# Very similar to the loop found in the balance_experiences", "\n", "# branch! Remember that classes_to_patterns_idx is already", "\n", "# shuffled (if required)", "\n", "next_idx_per_class", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "n_classes", ")", "]", "\n", "remaining_patterns", "=", "set", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ")", "\n", "\n", "for", "exp_id", "in", "range", "(", "n_experiences", ")", ":", "\n", "                    ", "for", "class_id", "in", "range", "(", "self", ".", "n_classes", ")", ":", "\n", "                        ", "next_idx", "=", "next_idx_per_class", "[", "class_id", "]", "\n", "end_idx", "=", "next_idx", "+", "min_class_patterns_in_exp", "\n", "selected_patterns", "=", "classes_to_patterns_idx", "[", "next_idx", ":", "end_idx", "]", "\n", "exp_patterns", "[", "exp_id", "]", ".", "extend", "(", "selected_patterns", ")", "\n", "self", ".", "exp_structure", "[", "exp_id", "]", "[", "class_id", "]", "+=", "min_class_patterns_in_exp", "\n", "remaining_patterns", ".", "difference_update", "(", "selected_patterns", ")", "\n", "next_idx_per_class", "[", "class_id", "]", "=", "end_idx", "\n", "\n", "", "", "remaining_patterns", "=", "list", "(", "remaining_patterns", ")", "\n", "\n", "# We have assigned the required min_class_patterns_in_exp,", "\n", "# now we assign the remaining patterns", "\n", "#", "\n", "# We'll work on remaining_patterns, which contains indexes of", "\n", "# patterns not assigned in the previous experience.", "\n", "if", "shuffle", ":", "\n", "                    ", "patterns_order", "=", "torch", ".", "as_tensor", "(", "remaining_patterns", ")", "[", "\n", "torch", ".", "randperm", "(", "len", "(", "remaining_patterns", ")", ")", "\n", "]", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                    ", "remaining_patterns", ".", "sort", "(", ")", "\n", "patterns_order", "=", "remaining_patterns", "\n", "", "targets_order", "=", "[", "train_dataset", ".", "targets", "[", "pattern_idx", "]", "\n", "for", "pattern_idx", "in", "patterns_order", "]", "\n", "\n", "avg_exp_size", "=", "len", "(", "patterns_order", ")", "//", "n_experiences", "\n", "n_remaining", "=", "len", "(", "patterns_order", ")", "%", "n_experiences", "\n", "prev_idx", "=", "0", "\n", "for", "exp_id", "in", "range", "(", "n_experiences", ")", ":", "\n", "                    ", "next_idx", "=", "prev_idx", "+", "avg_exp_size", "\n", "exp_patterns", "[", "exp_id", "]", ".", "extend", "(", "\n", "patterns_order", "[", "prev_idx", ":", "next_idx", "]", ")", "\n", "cls_ids", ",", "cls_counts", "=", "torch", ".", "unique", "(", "torch", ".", "as_tensor", "(", "\n", "targets_order", "[", "prev_idx", ":", "next_idx", "]", ")", ",", "return_counts", "=", "True", ")", "\n", "\n", "cls_ids", "=", "cls_ids", ".", "tolist", "(", ")", "\n", "cls_counts", "=", "cls_counts", ".", "tolist", "(", ")", "\n", "\n", "for", "unique_idx", "in", "range", "(", "len", "(", "cls_ids", ")", ")", ":", "\n", "                        ", "self", ".", "exp_structure", "[", "exp_id", "]", "[", "cls_ids", "[", "unique_idx", "]", "]", "+=", "cls_counts", "[", "unique_idx", "]", "\n", "", "prev_idx", "=", "next_idx", "\n", "\n", "# Distribute remaining patterns", "\n", "", "if", "n_remaining", ">", "0", ":", "\n", "                    ", "if", "shuffle", ":", "\n", "                        ", "assignment_of_remaining_patterns", "=", "torch", ".", "randperm", "(", "\n", "n_experiences", ")", ".", "tolist", "(", ")", "[", ":", "n_remaining", "]", "\n", "", "else", ":", "\n", "                        ", "assignment_of_remaining_patterns", "=", "range", "(", "n_remaining", ")", "\n", "", "for", "exp_id", "in", "assignment_of_remaining_patterns", ":", "\n", "                        ", "pattern_idx", "=", "patterns_order", "[", "prev_idx", "]", "\n", "pattern_target", "=", "targets_order", "[", "prev_idx", "]", "\n", "exp_patterns", "[", "exp_id", "]", ".", "append", "(", "pattern_idx", ")", "\n", "\n", "self", ".", "exp_structure", "[", "exp_id", "]", "[", "pattern_target", "]", "+=", "1", "\n", "prev_idx", "+=", "1", "\n", "\n", "", "", "", "", "self", ".", "n_patterns_per_experience", "=", "[", "len", "(", "exp_patterns", "[", "exp_id", "]", ")", "\n", "for", "exp_id", "in", "range", "(", "n_experiences", ")", "]", "\n", "\n", "self", ".", "_classes_in_exp", "=", "None", "# Will be lazy initialized later", "\n", "\n", "train_experiences", "=", "[", "]", "\n", "train_task_labels", "=", "[", "]", "\n", "for", "t_id", ",", "exp_def", "in", "enumerate", "(", "exp_patterns", ")", ":", "\n", "            ", "if", "self", ".", "_has_task_labels", ":", "\n", "                ", "train_task_labels", ".", "append", "(", "t_id", ")", "\n", "", "else", ":", "\n", "                ", "train_task_labels", ".", "append", "(", "0", ")", "\n", "", "task_labels", "=", "ConstantSequence", "(", "train_task_labels", "[", "-", "1", "]", ",", "\n", "len", "(", "train_dataset", ")", ")", "\n", "train_experiences", ".", "append", "(", "\n", "AvalancheSubset", "(", "train_dataset", ",", "indices", "=", "exp_def", ",", "\n", "task_labels", "=", "task_labels", ")", ")", "\n", "\n", "", "self", ".", "train_exps_patterns_assignment", "=", "exp_patterns", "\n", "\"\"\" A list containing which training instances are assigned to each\n        experience in the train stream. Instances are identified by their id \n        w.r.t. the dataset found in the original_train_dataset field. \"\"\"", "\n", "\n", "super", "(", "NIScenario", ",", "self", ")", ".", "__init__", "(", "\n", "stream_definitions", "=", "{", "\n", "'train'", ":", "(", "train_experiences", ",", "train_task_labels", ",", "\n", "train_dataset", ")", ",", "\n", "'test'", ":", "(", "test_dataset", ",", "[", "0", "]", ",", "test_dataset", ")", "\n", "}", ",", "\n", "complete_test_set_only", "=", "True", ",", "\n", "experience_factory", "=", "NIExperience", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_instances.ni_scenario.NIScenario.get_reproducibility_data": [[406, 413], ["bool"], "methods", ["None"], ["", "def", "get_reproducibility_data", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "reproducibility_data", "=", "{", "\n", "'exps_patterns_assignment'", ":", "self", ".", "train_exps_patterns_assignment", ",", "\n", "'has_task_labels'", ":", "bool", "(", "self", ".", "_has_task_labels", ")", ",", "\n", "\n", "}", "\n", "return", "reproducibility_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.new_instances.ni_scenario.NIExperience.__init__": [[423, 436], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "origin_stream", ":", "GenericScenarioStream", "[", "'NIExperience'", ",", "\n", "NIScenario", "]", ",", "\n", "current_experience", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``NIExperience`` instance given the stream from this\n        experience was taken and and the current experience ID.\n\n        :param origin_stream: The stream from which this experience was\n            obtained.\n        :param current_experience: The current experience ID, as an integer.\n        \"\"\"", "\n", "super", "(", "NIExperience", ",", "self", ")", ".", "__init__", "(", "\n", "origin_stream", ",", "current_experience", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.nc_scenario": [[34, 186], ["warnings.warn", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset().train", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset().eval", "avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCScenario", "ValueError", "isinstance", "isinstance", "avalanche.benchmarks.utils.concat_datasets_sequentially", "len", "len", "ValueError", "ValueError", "ValueError", "scenario_generators._one_dataset_per_exp_class_order", "len", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.concat_datasets_sequentially", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators._one_dataset_per_exp_class_order", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_classification_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_classification_dataset"], ["def", "nc_scenario", "(", "\n", "train_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "test_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "n_experiences", ":", "int", ",", "\n", "task_labels", ":", "bool", ",", "\n", "*", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "per_exp_classes", ":", "Dict", "[", "int", ",", "int", "]", "=", "None", ",", "\n", "class_ids_from_zero_from_first_exp", ":", "bool", "=", "False", ",", "\n", "class_ids_from_zero_in_each_exp", ":", "bool", "=", "False", ",", "\n", "one_dataset_per_exp", ":", "bool", "=", "False", ",", "\n", "reproducibility_data", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of `nc_benchmark`.\n\n    This method is the high-level specific scenario generator for the\n    \"New Classes\" (NC) case. Given a sequence of train and test datasets creates\n    the continual stream of data as a series of experiences. Each experience\n    will contain all the patterns belonging to a certain set of classes and a\n    class won't be assigned to more than one experience.\n\n    The ``task_labels`` parameter determines if each incremental experience has\n    an increasing task label or if, at the contrary, a default task label \"0\"\n    has to be assigned to all experiences. This can be useful when\n    differentiating between Single-Incremental-Task and Multi-Task scenarios.\n\n    There are other important parameters that can be specified in order to tweak\n    the behaviour of the resulting scenario. Please take a few minutes to read\n    and understand them as they may save you a lot of work.\n\n    This generator features a integrated reproducibility mechanism that allows\n    the user to store and later re-load a scenario. For more info see the\n    ``reproducibility_data`` parameter.\n\n    :param train_dataset: A list of training datasets, or a single dataset.\n    :param test_dataset: A list of test datasets, or a single test dataset.\n    :param n_experiences: The number of incremental experience. This is not used\n        when using multiple train/test datasets with the ``one_dataset_per_exp``\n        parameter set to True.\n    :param task_labels: If True, each experience will have an ascending task\n            label. If False, the task label will be 0 for all the experiences.\n    :param shuffle: If True, the class (or experience) order will be shuffled.\n        Defaults to True.\n    :param seed: If ``shuffle`` is True and seed is not None, the class (or\n        experience) order will be shuffled according to the seed. When None, the\n        current PyTorch random number generator state will be used. Defaults to\n        None.\n    :param fixed_class_order: If not None, the class order to use (overrides\n        the shuffle argument). Very useful for enhancing reproducibility.\n        Defaults to None.\n    :param per_exp_classes: Is not None, a dictionary whose keys are\n        (0-indexed) experience IDs and their values are the number of classes\n        to include in the respective experiences. The dictionary doesn't\n        have to contain a key for each experience! All the remaining experiences\n        will contain an equal amount of the remaining classes. The\n        remaining number of classes must be divisible without remainder\n        by the remaining number of experiences. For instance,\n        if you want to include 50 classes in the first experience\n        while equally distributing remaining classes across remaining\n        experiences, just pass the \"{0: 50}\" dictionary as the\n        per_experience_classes parameter. Defaults to None.\n    :param class_ids_from_zero_from_first_exp: If True, original class IDs\n        will be remapped so that they will appear as having an ascending\n        order. For instance, if the resulting class order after shuffling\n        (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and\n        class_ids_from_zero_from_first_exp is True, then all the patterns\n        belonging to class 23 will appear as belonging to class \"0\",\n        class \"34\" will be mapped to \"1\", class \"11\" to \"2\" and so on.\n        This is very useful when drawing confusion matrices and when dealing\n        with algorithms with dynamic head expansion. Defaults to False.\n        Mutually exclusive with the ``class_ids_from_zero_in_each_exp``\n        parameter.\n    :param class_ids_from_zero_in_each_exp: If True, original class IDs\n        will be mapped to range [0, n_classes_in_exp) for each experience.\n        Defaults to False. Mutually exclusive with the\n        ``class_ids_from_zero_from_first_exp`` parameter.\n    :param one_dataset_per_exp: available only when multiple train-test\n        datasets are provided. If True, each dataset will be treated as a\n        experience. Mutually exclusive with the ``per_experience_classes`` and\n        ``fixed_class_order`` parameters. Overrides the ``n_experiences`` \n        parameter. Defaults to False.\n    :param reproducibility_data: If not None, overrides all the other\n        scenario definition options. This is usually a dictionary containing\n        data used to reproduce a specific experiment. One can use the\n        ``get_reproducibility_data`` method to get (and even distribute)\n        the experiment setup so that it can be loaded by passing it as this\n        parameter. In this way one can be sure that the same specific\n        experimental setup is being used (for reproducibility purposes).\n        Beware that, in order to reproduce an experiment, the same train and\n        test datasets must be used. Defaults to None.\n\n    :return: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'nc_scenario is deprecated in favor of nc_benchmark.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "if", "class_ids_from_zero_from_first_exp", "and", "class_ids_from_zero_in_each_exp", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid mutually exclusive options '", "\n", "'class_ids_from_zero_from_first_exp and '", "\n", "'classes_ids_from_zero_in_each_exp set at the '", "\n", "'same time'", ")", "\n", "\n", "", "if", "isinstance", "(", "train_dataset", ",", "list", ")", "or", "isinstance", "(", "train_dataset", ",", "tuple", ")", ":", "\n", "# Multi-dataset setting", "\n", "\n", "        ", "if", "len", "(", "train_dataset", ")", "!=", "len", "(", "test_dataset", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Train/test dataset lists must contain the '", "\n", "'exact same number of datasets'", ")", "\n", "\n", "", "if", "per_exp_classes", "and", "one_dataset_per_exp", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Both per_experience_classes and one_dataset_per_exp are'", "\n", "'used, but those options are mutually exclusive'", ")", "\n", "\n", "", "if", "fixed_class_order", "and", "one_dataset_per_exp", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Both fixed_class_order and one_dataset_per_exp are'", "\n", "'used, but those options are mutually exclusive'", ")", "\n", "\n", "", "seq_train_dataset", ",", "seq_test_dataset", ",", "mapping", "=", "concat_datasets_sequentially", "(", "train_dataset", ",", "test_dataset", ")", "\n", "\n", "if", "one_dataset_per_exp", ":", "\n", "# If one_dataset_per_exp is True, each dataset will be treated as", "\n", "# a experience. In this scenario, shuffle refers to the experience", "\n", "# order, not to the class one.", "\n", "            ", "fixed_class_order", ",", "per_exp_classes", "=", "_one_dataset_per_exp_class_order", "(", "mapping", ",", "shuffle", ",", "seed", ")", "\n", "\n", "# We pass a fixed_class_order to the NCGenericScenario", "\n", "# constructor, so we don't need shuffling.", "\n", "shuffle", "=", "False", "\n", "seed", "=", "None", "\n", "\n", "# Overrides n_experiences (and per_experience_classes, already done)", "\n", "n_experiences", "=", "len", "(", "train_dataset", ")", "\n", "", "train_dataset", ",", "test_dataset", "=", "seq_train_dataset", ",", "seq_test_dataset", "\n", "\n", "# Datasets should be instances of AvalancheDataset", "\n", "", "train_dataset", "=", "as_classification_dataset", "(", "train_dataset", ")", ".", "train", "(", ")", "\n", "test_dataset", "=", "as_classification_dataset", "(", "test_dataset", ")", ".", "eval", "(", ")", "\n", "\n", "return", "NCScenario", "(", "train_dataset", ",", "test_dataset", ",", "n_experiences", ",", "task_labels", ",", "\n", "shuffle", ",", "seed", ",", "fixed_class_order", ",", "per_exp_classes", ",", "\n", "class_ids_from_zero_from_first_exp", ",", "\n", "class_ids_from_zero_in_each_exp", ",", "\n", "reproducibility_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.ni_scenario": [[188, 283], ["warnings.warn", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset().train", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset().eval", "avalanche.benchmarks.scenarios.new_instances.ni_scenario.NIScenario", "isinstance", "isinstance", "avalanche.benchmarks.utils.concat_datasets_sequentially", "len", "len", "ValueError", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset", "avalanche.benchmarks.utils.avalanche_dataset.as_classification_dataset"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.concat_datasets_sequentially", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_classification_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.as_classification_dataset"], ["", "def", "ni_scenario", "(", "\n", "train_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "test_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "task_labels", ":", "bool", "=", "False", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "balance_experiences", ":", "bool", "=", "False", ",", "\n", "min_class_patterns_in_exp", ":", "int", "=", "0", ",", "\n", "fixed_exp_assignment", ":", "Optional", "[", "Sequence", "[", "Sequence", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "reproducibility_data", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "NIScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of `ni_benchmark`.\n\n    This method is the high-level specific scenario generator for the\n    \"New Instances\" (NI) case. Given a sequence of train and test datasets\n    creates the continual stream of data as a series of experiences. Each\n    experience will contain patterns belonging to the same classes.\n\n    The ``task_labels`` parameter determines if each incremental experience has\n    an increasing task label or if, at the contrary, a default task label \"0\"\n    has to be assigned to all experiences. This can be useful when\n    differentiating between Single-Incremental-Task and Multi-Task scenarios.\n\n    There are other important parameters that can be specified in order to tweak\n    the behaviour of the resulting scenario. Please take a few minutes to read\n    and understand them as they may save you a lot of work.\n\n    This generator features an integrated reproducibility mechanism that allows\n    the user to store and later re-load a scenario. For more info see the\n    ``reproducibility_data`` parameter.\n\n    :param train_dataset: A list of training datasets, or a single dataset.\n    :param test_dataset: A list of test datasets, or a single test dataset.\n    :param n_experiences: The number of experiences.\n    :param task_labels: If True, each experience will have an ascending task\n            label. If False, the task label will be 0 for all the experiences.\n    :param shuffle: If True, patterns order will be shuffled.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param balance_experiences: If True, pattern of each class will be equally\n        spread across all experiences. If False, patterns will be assigned to\n        experiences in a complete random way. Defaults to False.\n    :param min_class_patterns_in_exp: The minimum amount of patterns of\n        every class that must be assigned to every experience. Compatible with\n        the ``balance_experiences`` parameter. An exception will be raised if\n        this constraint can't be satisfied. Defaults to 0.\n    :param fixed_exp_assignment: If not None, the pattern assignment\n        to use. It must be a list with an entry for each experience. Each entry\n        is a list that contains the indexes of patterns belonging to that\n        experience. Overrides the ``shuffle``, ``balance_experiences`` and\n        ``min_class_patterns_in_exp`` parameters.\n    :param reproducibility_data: If not None, overrides all the other\n        scenario definition options, including ``fixed_exp_assignment``.\n        This is usually a dictionary containing data used to\n        reproduce a specific experiment. One can use the\n        ``get_reproducibility_data`` method to get (and even distribute)\n        the experiment setup so that it can be loaded by passing it as this\n        parameter. In this way one can be sure that the same specific\n        experimental setup is being used (for reproducibility purposes).\n        Beware that, in order to reproduce an experiment, the same train and\n        test datasets must be used. Defaults to None.\n\n    :return: A properly initialized :class:`NIScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'ni_scenario is deprecated in favor of ni_benchmark.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "seq_train_dataset", ",", "seq_test_dataset", "=", "train_dataset", ",", "test_dataset", "\n", "if", "isinstance", "(", "train_dataset", ",", "list", ")", "or", "isinstance", "(", "train_dataset", ",", "tuple", ")", ":", "\n", "        ", "if", "len", "(", "train_dataset", ")", "!=", "len", "(", "test_dataset", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Train/test dataset lists must contain the '", "\n", "'exact same number of datasets'", ")", "\n", "\n", "", "seq_train_dataset", ",", "seq_test_dataset", ",", "_", "=", "concat_datasets_sequentially", "(", "train_dataset", ",", "test_dataset", ")", "\n", "\n", "# Datasets should be instances of AvalancheDataset", "\n", "", "seq_train_dataset", "=", "as_classification_dataset", "(", "seq_train_dataset", ")", ".", "train", "(", ")", "\n", "seq_test_dataset", "=", "as_classification_dataset", "(", "seq_test_dataset", ")", ".", "eval", "(", ")", "\n", "\n", "return", "NIScenario", "(", "\n", "seq_train_dataset", ",", "seq_test_dataset", ",", "\n", "n_experiences", ",", "\n", "task_labels", ",", "\n", "shuffle", "=", "shuffle", ",", "seed", "=", "seed", ",", "\n", "balance_experiences", "=", "balance_experiences", ",", "\n", "min_class_patterns_in_exp", "=", "min_class_patterns_in_exp", ",", "\n", "fixed_exp_assignment", "=", "fixed_exp_assignment", ",", "\n", "reproducibility_data", "=", "reproducibility_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.dataset_scenario": [[285, 345], ["warnings.warn", "create_multi_dataset_generic_scenario"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_multi_dataset_generic_scenario"], ["", "def", "dataset_scenario", "(", "\n", "train_dataset_list", ":", "Sequence", "[", "SupportedDataset", "]", ",", "\n", "test_dataset_list", ":", "Sequence", "[", "SupportedDataset", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "*", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of `dataset_benchmark`.\n\n    Creates a generic scenario given a list of datasets and the respective task\n    labels. Each training dataset will be considered as a separate training\n    experience. Contents of the datasets will not be changed, including the\n    targets.\n\n    When loading the datasets from a set of fixed file lists, consider using\n    the :func:`filelist_scenario` helper method instead. Also, loading from\n    a list of paths is supported through the :func:`paths_scenario` helper.\n\n    In its base form, this function accepts a list of test datasets that must\n    contain the same amount of datasets of the training list.\n    Those pairs are then used to create the \"past\", \"cumulative\"\n    (a.k.a. growing) and \"future\" test sets. However, in certain Continual\n    Learning scenarios only the concept of \"complete\" test set makes sense. In\n    that case, the ``complete_test_set_only`` parameter should be set to True\n    (see the parameter description for more info).\n\n    Beware that pattern transformations must already be included in the\n    datasets (when needed).\n\n    :param train_dataset_list: A list of training datasets.\n    :param test_dataset_list: A list of test datasets.\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_dataset_list`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that the ``test_dataset_list``\n        parameter must be list with a single element (the complete test set).\n        Defaults to False, which means that ``train_dataset_list`` and\n        ``test_dataset_list`` must contain the same amount of datasets.\n    :param dataset_type: The type of the dataset. Defaults to None, which\n        means that the type will be obtained from the input datasets. If input\n        datasets are not instances of :class:`AvalancheDataset`, the type\n        UNDEFINED will be used.\n\n    :returns: A properly initialized :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'dataset_scenario is deprecated in favor of '", "\n", "'dataset_benchmark.'", ",", "DeprecationWarning", ")", "\n", "\n", "return", "create_multi_dataset_generic_scenario", "(", "\n", "train_dataset_list", "=", "train_dataset_list", ",", "\n", "test_dataset_list", "=", "test_dataset_list", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.filelist_scenario": [[347, 422], ["warnings.warn", "create_generic_scenario_from_filelists"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_filelists"], ["", "def", "filelist_scenario", "(", "\n", "root", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "train_file_lists", ":", "Sequence", "[", "Union", "[", "str", ",", "Path", "]", "]", ",", "\n", "test_file_lists", ":", "Union", "[", "Union", "[", "str", ",", "Path", "]", ",", "Sequence", "[", "Union", "[", "str", ",", "Path", "]", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "*", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of `filelist_benchmark`.\n\n    Creates a generic scenario given a list of filelists and the respective task\n    labels. A separate dataset will be created for each filelist and each of\n    those training datasets will be considered a separate training experience.\n\n    In its base form, this function accepts a list of filelists for the test\n    datsets that must contain the same amount of elements of the training list.\n    Those pairs of datasets are then used to create the \"past\", \"cumulative\"\n    (a.k.a. growing) and \"future\" test sets. However, in certain Continual\n    Learning scenarios only the concept of \"complete\" test set makes sense. In\n    that case, the ``complete_test_set_only`` should be set to True (see the\n    parameter description for more info).\n\n    This helper functions is the best shot when loading Caffe-style dataset\n    based on filelists.\n\n    The resulting benchmark instance and the intermediate datasets used to\n    populate it will be of type CLASSIFICATION.\n\n    :param root: The root path of the dataset.\n    :param train_file_lists: A list of filelists describing the\n        paths of the training patterns for each experience.\n    :param test_file_lists: A list of filelists describing the\n        paths of the test patterns for each experience.\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_file_lists`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that the ``test_file_lists``\n        parameter must be list with a single element (the complete test set).\n        Alternatively, can be a plain string or :class:`Path` object.\n        Defaults to False, which means that ``train_file_lists`` and\n        ``test_file_lists`` must contain the same amount of filelists paths.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n\n    :returns: A properly initialized :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'filelist_scenario is deprecated in favor of '", "\n", "'filelist_benchmark.'", ",", "DeprecationWarning", ")", "\n", "\n", "return", "create_generic_scenario_from_filelists", "(", "\n", "root", "=", "root", ",", "\n", "train_file_lists", "=", "train_file_lists", ",", "\n", "test_file_lists", "=", "test_file_lists", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.paths_scenario": [[427, 516], ["warnings.warn", "create_generic_scenario_from_paths"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_paths"], ["def", "paths_scenario", "(", "\n", "train_list_of_files", ":", "Sequence", "[", "Sequence", "[", "FileAndLabel", "]", "]", ",", "\n", "test_list_of_files", ":", "Union", "[", "Sequence", "[", "FileAndLabel", "]", ",", "\n", "Sequence", "[", "Sequence", "[", "FileAndLabel", "]", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "*", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of `paths_benchmark`.\n\n    Creates a generic scenario given a list of files and class labels.\n    A separate dataset will be created for each list and each of\n    those training datasets will be considered a separate training experience.\n\n    This is very similar to `filelist_scenario`, with the main difference being\n    that `filelist_scenario` accepts, for each experience, a file list formatted\n    in Caffe-style. On the contrary, this accepts a list of tuples where each\n    tuple contains two elements: the full path to the pattern and its label.\n    Optionally, the tuple may contain a third element describing the bounding\n    box of the element to crop. This last bounding box may be useful when trying\n    to extract the part of the image depicting the desired element.\n\n    In its base form, this function accepts a list of lists of tuples for the\n    test datsets that must contain the same amount of lists of the training\n    list. Those pairs of datasets are then used to create the \"past\",\n    \"cumulative\" (a.k.a. growing) and \"future\" test sets. However, in certain\n    Continual Learning scenarios only the concept of \"complete\" test set makes\n    sense. In that case, the ``complete_test_set_only`` should be set to True\n    (see the parameter description for more info).\n\n    The label of each pattern doesn't have to be an int.\n\n    :param train_list_of_files: A list of lists. Each list describes the paths\n        and labels of patterns to include in that training experience as tuples.\n        Each tuple must contain two elements: the full path to the pattern\n        and its class label. Optionally, the tuple may contain a third element\n        describing the bounding box to use for cropping (top, left, height,\n        width).\n    :param test_list_of_files: A list of lists. Each list describes the paths\n        and labels of patterns to include in that test experience as tuples.\n        Each tuple must contain two elements: the full path to the pattern\n        and its class label. Optionally, the tuple may contain a third element\n        describing the bounding box to use for cropping (top, left, height,\n        width).\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_file_lists`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that the ``test_file_lists``\n        parameter must be list with a single element (the complete test set).\n        Alternatively, can be a plain string or :class:`Path` object.\n        Defaults to False, which means that ``train_file_lists`` and\n        ``test_file_lists`` must contain the same amount of filelists paths.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n\n    :returns: A properly initialized :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'paths_scenario is deprecated in favor of paths_benchmark.'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "return", "create_generic_scenario_from_paths", "(", "\n", "train_list_of_files", "=", "train_list_of_files", ",", "\n", "test_list_of_files", "=", "test_list_of_files", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.tensors_scenario": [[518, 601], ["warnings.warn", "create_generic_scenario_from_tensor_lists"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_scenario_creation.create_generic_scenario_from_tensor_lists"], ["", "def", "tensors_scenario", "(", "\n", "train_tensors", ":", "Sequence", "[", "Sequence", "[", "Any", "]", "]", ",", "\n", "test_tensors", ":", "Sequence", "[", "Sequence", "[", "Any", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "*", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of `tensors_benchmark`.\n\n    Creates a generic scenario given lists of Tensors and the respective task\n    labels. A separate dataset will be created from each Tensor tuple\n    (x, y, ...) and each of those training datasets will be considered a\n    separate training experience. Using this helper function is the lowest-level\n    way to create a Continual Learning scenario. When possible, consider using\n    higher level helpers.\n\n    Experiences are defined by passing lists of tensors as the `train_tensors`\n    and `test_tensors` parameter. Those parameters must be lists containing\n    sub-lists of tensors, one for each experience. Each tensor defines the value\n    of a feature (\"x\", \"y\", \"z\", ...) for all patterns of that experience.\n\n    By default the second tensor of each experience will be used to fill the\n    `targets` value (label of each pattern).\n\n    In its base form, the test lists must contain the same amount of elements of\n    the training lists. Those pairs of datasets are then used to create the\n    \"past\", \"cumulative\" (a.k.a. growing) and \"future\" test sets.\n    However, in certain Continual Learning scenarios only the concept of\n    \"complete\" test set makes sense. In that case, the\n    ``complete_test_set_only`` should be set to True (see the parameter\n    description for more info).\n\n    :param train_tensors: A list of lists. The first list must contain the\n        tensors for the first training experience (one tensor per feature), the\n        second list must contain the tensors for the second training experience,\n        and so on.\n    :param test_tensors: A list of lists. The first list must contain the\n        tensors for the first test experience (one tensor per feature), the\n        second list must contain the tensors for the second test experience,\n        and so on.\n    :param task_labels: A list of task labels. Must contain a task label for\n        each experience. For Single-Incremental-Task (a.k.a. Task-Free)\n        scenarios, this is usually a list of zeros. For Multi Task scenario,\n        this is usually a list of ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that ``test_tensors`` must\n        define a single experience. Defaults to False, which means that\n        ``train_tensors`` and ``test_tensors`` must define the same\n        amount of experiences.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n\n    :returns: A properly initialized :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'tensors_scenario is deprecated in favor of '", "\n", "'tensors_benchmark.'", ",", "DeprecationWarning", ")", "\n", "\n", "return", "create_generic_scenario_from_tensor_lists", "(", "\n", "train_tensors", "=", "train_tensors", ",", "\n", "test_tensors", "=", "test_tensors", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.tensor_scenario": [[603, 721], ["warnings.warn", "isinstance", "range", "range", "scenario_generators.tensors_scenario", "len", "len", "ValueError", "len", "exp_train_first_structure.append", "len", "exp_test_first_structure.append", "len", "len", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators.tensors_scenario"], ["", "def", "tensor_scenario", "(", "\n", "train_data_x", ":", "Sequence", "[", "Any", "]", ",", "\n", "train_data_y", ":", "Sequence", "[", "Sequence", "[", "SupportsInt", "]", "]", ",", "\n", "test_data_x", ":", "Union", "[", "Any", ",", "Sequence", "[", "Any", "]", "]", ",", "\n", "test_data_y", ":", "Union", "[", "Any", ",", "Sequence", "[", "Sequence", "[", "SupportsInt", "]", "]", "]", ",", "\n", "task_labels", ":", "Sequence", "[", "int", "]", ",", "\n", "*", ",", "\n", "complete_test_set_only", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "train_target_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "eval_target_transform", "=", "None", ",", "\n", "dataset_type", ":", "AvalancheDatasetType", "=", "AvalancheDatasetType", ".", "UNDEFINED", ")", "->", "GenericCLScenario", ":", "\n", "    ", "\"\"\"\n    This helper function is DEPRECATED in favor of `tensors_benchmark`.\n\n    Please consider using :func:`tensors_benchmark` instead. When switching to\n    the new function, please keep in mind that the format of the parameters is\n    completely different!\n\n    Creates a generic scenario given lists of Tensors and the respective task\n    labels. A separate dataset will be created from each Tensor pair (x + y)\n    and each of those training datasets will be considered a separate\n    training experience. Contents of the datasets will not be changed, including\n    the targets. Using this helper function is the lower level way to create a\n    Continual Learning scenario. When possible, consider using higher level\n    helpers.\n\n    By default the second tensor of each experience will be used to fill the\n    `targets` value (label of each pattern).\n\n    In its base form, the test lists must contain the same amount of elements of\n    the training lists. Those pairs of datasets are then used to create the\n    \"past\", \"cumulative\" (a.k.a. growing) and \"future\" test sets.\n    However, in certain Continual Learning scenarios only the concept of\n    \"complete\" test set makes sense. In that case, the\n    ``complete_test_set_only`` should be set to True (see the parameter\n    description for more info).\n\n    :param train_data_x: A list of Tensors (one per experience) containing the\n        patterns of the training sets.\n    :param train_data_y: A list of Tensors or int lists containing the\n        labels of the patterns of the training sets. Must contain the same\n        number of elements of ``train_datasets_x``.\n    :param test_data_x: A Tensor or a list of Tensors (one per experience)\n        containing the patterns of the test sets.\n    :param test_data_y: A Tensor or a list of Tensors or int lists containing\n        the labels of the patterns of the test sets. Must contain the same\n        number of elements of ``test_datasets_x``.\n    :param task_labels: A list of task labels. Must contain the same amount of\n        elements of the ``train_datasets_x`` parameter. For\n        Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually\n        a list of zeros. For Multi Task scenario, this is usually a list of\n        ascending task labels (starting from 0).\n    :param complete_test_set_only: If True, only the complete test set will\n        be returned by the scenario. This means that the ``test_datasets_x`` and\n        ``test_datasets_y`` parameters must be lists with a single element\n        (the complete test set). Defaults to False, which means that\n        ``train_file_lists`` and ``test_file_lists`` must contain the same\n        amount of filelists paths.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param train_target_transform: The transformation to apply to training\n        patterns targets. Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_target_transform: The transformation to apply to test\n        patterns targets. Defaults to None.\n    :param dataset_type: The type of the dataset. Defaults to UNDEFINED.\n\n    :returns: A properly initialized :class:`GenericCLScenario` instance.\n    \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "'tensor_scenario is deprecated in favor '", "\n", "'of tensors_benchmark. When switching'", "\n", "' to the new function, please keep in mind that the format of'", "\n", "' the parameters is completely different!'", ",", "\n", "DeprecationWarning", ")", "\n", "\n", "if", "isinstance", "(", "test_data_x", ",", "Tensor", ")", ":", "\n", "        ", "test_data_x", "=", "[", "test_data_x", "]", "\n", "test_data_y", "=", "[", "test_data_y", "]", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "test_data_x", ")", "!=", "len", "(", "test_data_y", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'test_data_x and test_data_y must contain'", "\n", "' the same amount of elements'", ")", "\n", "\n", "", "", "if", "len", "(", "train_data_x", ")", "!=", "len", "(", "train_data_y", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'train_data_x and train_data_y must contain'", "\n", "' the same amount of elements'", ")", "\n", "\n", "", "exp_train_first_structure", "=", "[", "]", "\n", "exp_test_first_structure", "=", "[", "]", "\n", "for", "exp_idx", "in", "range", "(", "len", "(", "train_data_x", ")", ")", ":", "\n", "        ", "exp_x", "=", "train_data_x", "[", "exp_idx", "]", "\n", "exp_y", "=", "train_data_y", "[", "exp_idx", "]", "\n", "\n", "exp_train_first_structure", ".", "append", "(", "[", "exp_x", ",", "exp_y", "]", ")", "\n", "\n", "", "for", "exp_idx", "in", "range", "(", "len", "(", "test_data_x", ")", ")", ":", "\n", "        ", "exp_x", "=", "test_data_x", "[", "exp_idx", "]", "\n", "exp_y", "=", "test_data_y", "[", "exp_idx", "]", "\n", "\n", "exp_test_first_structure", ".", "append", "(", "[", "exp_x", ",", "exp_y", "]", ")", "\n", "\n", "", "return", "tensors_scenario", "(", "\n", "train_tensors", "=", "exp_train_first_structure", ",", "\n", "test_tensors", "=", "exp_test_first_structure", ",", "\n", "task_labels", "=", "task_labels", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "train_target_transform", "=", "train_target_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", "eval_target_transform", "=", "eval_target_transform", ",", "\n", "dataset_type", "=", "dataset_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.scenario_generators._one_dataset_per_exp_class_order": [[723, 754], ["list", "enumerate", "range", "[].tolist", "fixed_class_order.extend", "len", "len", "torch.random.manual_seed", "torch.as_tensor", "torch.randperm", "len"], "function", ["None"], ["", "def", "_one_dataset_per_exp_class_order", "(", "\n", "class_list_per_exp", ":", "Sequence", "[", "Sequence", "[", "int", "]", "]", ",", "\n", "shuffle", ":", "bool", ",", "seed", ":", "Union", "[", "int", ",", "None", "]", ")", "->", "(", "List", "[", "int", "]", ",", "Dict", "[", "int", ",", "int", "]", ")", ":", "\n", "    ", "\"\"\"\n    Utility function that shuffles the class order by keeping classes from the\n    same experience together. Each experience is defined by a different entry in\n    the class_list_per_exp parameter.\n\n    :param class_list_per_exp: A list of class lists, one for each experience\n    :param shuffle: If True, the experience order will be shuffled. If False,\n        this function will return the concatenation of lists from the\n        class_list_per_exp parameter.\n    :param seed: If not None, an integer used to initialize the random\n        number generator.\n\n    :returns: A class order that keeps class IDs from the same experience\n        together (adjacent).\n    \"\"\"", "\n", "dataset_order", "=", "list", "(", "range", "(", "len", "(", "class_list_per_exp", ")", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "if", "seed", "is", "not", "None", ":", "\n", "            ", "torch", ".", "random", ".", "manual_seed", "(", "seed", ")", "\n", "", "dataset_order", "=", "torch", ".", "as_tensor", "(", "dataset_order", ")", "[", "\n", "torch", ".", "randperm", "(", "len", "(", "dataset_order", ")", ")", "]", ".", "tolist", "(", ")", "\n", "", "fixed_class_order", "=", "[", "]", "\n", "classes_per_exp", "=", "{", "}", "\n", "for", "dataset_position", ",", "dataset_idx", "in", "enumerate", "(", "dataset_order", ")", ":", "\n", "        ", "fixed_class_order", ".", "extend", "(", "class_list_per_exp", "[", "dataset_idx", "]", ")", "\n", "classes_per_exp", "[", "dataset_position", "]", "=", "len", "(", "class_list_per_exp", "[", "dataset_idx", "]", ")", "\n", "", "return", "fixed_class_order", ",", "classes_per_exp", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark": [[38, 212], ["dict", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset", "avalanche.benchmarks.scenarios.new_classes.nc_scenario.NCScenario", "ValueError", "isinstance", "isinstance", "avalanche.benchmarks.utils.concat_datasets_sequentially", "len", "len", "ValueError", "ValueError", "ValueError", "benchmark_generators._one_dataset_per_exp_class_order", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.concat_datasets_sequentially", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators._one_dataset_per_exp_class_order"], ["def", "nc_benchmark", "(", "\n", "train_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "test_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "n_experiences", ":", "int", ",", "\n", "task_labels", ":", "bool", ",", "\n", "*", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "per_exp_classes", ":", "Dict", "[", "int", ",", "int", "]", "=", "None", ",", "\n", "class_ids_from_zero_from_first_exp", ":", "bool", "=", "False", ",", "\n", "class_ids_from_zero_in_each_exp", ":", "bool", "=", "False", ",", "\n", "one_dataset_per_exp", ":", "bool", "=", "False", ",", "\n", "train_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "\n", "reproducibility_data", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    This is the high-level benchmark instances generator for the\n    \"New Classes\" (NC) case. Given a sequence of train and test datasets creates\n    the continual stream of data as a series of experiences. Each experience\n    will contain all the instances belonging to a certain set of classes and a\n    class won't be assigned to more than one experience.\n\n    This is the reference helper function for creating instances of Class- or\n    Task-Incremental benchmarks.\n\n    The ``task_labels`` parameter determines if each incremental experience has\n    an increasing task label or if, at the contrary, a default task label \"0\"\n    has to be assigned to all experiences. This can be useful when\n    differentiating between Single-Incremental-Task and Multi-Task scenarios.\n\n    There are other important parameters that can be specified in order to tweak\n    the behaviour of the resulting benchmark. Please take a few minutes to read\n    and understand them as they may save you a lot of work.\n\n    This generator features a integrated reproducibility mechanism that allows\n    the user to store and later re-load a benchmark. For more info see the\n    ``reproducibility_data`` parameter.\n\n    :param train_dataset: A list of training datasets, or a single dataset.\n    :param test_dataset: A list of test datasets, or a single test dataset.\n    :param n_experiences: The number of incremental experience. This is not used\n        when using multiple train/test datasets with the ``one_dataset_per_exp``\n        parameter set to True.\n    :param task_labels: If True, each experience will have an ascending task\n            label. If False, the task label will be 0 for all the experiences.\n    :param shuffle: If True, the class (or experience) order will be shuffled.\n        Defaults to True.\n    :param seed: If ``shuffle`` is True and seed is not None, the class (or\n        experience) order will be shuffled according to the seed. When None, the\n        current PyTorch random number generator state will be used. Defaults to\n        None.\n    :param fixed_class_order: If not None, the class order to use (overrides\n        the shuffle argument). Very useful for enhancing reproducibility.\n        Defaults to None.\n    :param per_exp_classes: Is not None, a dictionary whose keys are\n        (0-indexed) experience IDs and their values are the number of classes\n        to include in the respective experiences. The dictionary doesn't\n        have to contain a key for each experience! All the remaining experiences\n        will contain an equal amount of the remaining classes. The\n        remaining number of classes must be divisible without remainder\n        by the remaining number of experiences. For instance,\n        if you want to include 50 classes in the first experience\n        while equally distributing remaining classes across remaining\n        experiences, just pass the \"{0: 50}\" dictionary as the\n        per_experience_classes parameter. Defaults to None.\n    :param class_ids_from_zero_from_first_exp: If True, original class IDs\n        will be remapped so that they will appear as having an ascending\n        order. For instance, if the resulting class order after shuffling\n        (or defined by fixed_class_order) is [23, 34, 11, 7, 6, ...] and\n        class_ids_from_zero_from_first_exp is True, then all the patterns\n        belonging to class 23 will appear as belonging to class \"0\",\n        class \"34\" will be mapped to \"1\", class \"11\" to \"2\" and so on.\n        This is very useful when drawing confusion matrices and when dealing\n        with algorithms with dynamic head expansion. Defaults to False.\n        Mutually exclusive with the ``class_ids_from_zero_in_each_exp``\n        parameter.\n    :param class_ids_from_zero_in_each_exp: If True, original class IDs\n        will be mapped to range [0, n_classes_in_exp) for each experience.\n        Defaults to False. Mutually exclusive with the\n        ``class_ids_from_zero_from_first_exp`` parameter.\n    :param one_dataset_per_exp: available only when multiple train-test\n        datasets are provided. If True, each dataset will be treated as a\n        experience. Mutually exclusive with the ``per_experience_classes`` and\n        ``fixed_class_order`` parameters. Overrides the ``n_experiences`` \n        parameter. Defaults to False.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param reproducibility_data: If not None, overrides all the other\n        benchmark definition options. This is usually a dictionary containing\n        data used to reproduce a specific experiment. One can use the\n        ``get_reproducibility_data`` method to get (and even distribute)\n        the experiment setup so that it can be loaded by passing it as this\n        parameter. In this way one can be sure that the same specific\n        experimental setup is being used (for reproducibility purposes).\n        Beware that, in order to reproduce an experiment, the same train and\n        test datasets must be used. Defaults to None.\n\n    :return: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "if", "class_ids_from_zero_from_first_exp", "and", "class_ids_from_zero_in_each_exp", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid mutually exclusive options '", "\n", "'class_ids_from_zero_from_first_exp and '", "\n", "'classes_ids_from_zero_in_each_exp set at the '", "\n", "'same time'", ")", "\n", "\n", "", "if", "isinstance", "(", "train_dataset", ",", "list", ")", "or", "isinstance", "(", "train_dataset", ",", "tuple", ")", ":", "\n", "# Multi-dataset setting", "\n", "\n", "        ", "if", "len", "(", "train_dataset", ")", "!=", "len", "(", "test_dataset", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Train/test dataset lists must contain the '", "\n", "'exact same number of datasets'", ")", "\n", "\n", "", "if", "per_exp_classes", "and", "one_dataset_per_exp", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Both per_experience_classes and one_dataset_per_exp are'", "\n", "'used, but those options are mutually exclusive'", ")", "\n", "\n", "", "if", "fixed_class_order", "and", "one_dataset_per_exp", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Both fixed_class_order and one_dataset_per_exp are'", "\n", "'used, but those options are mutually exclusive'", ")", "\n", "\n", "", "seq_train_dataset", ",", "seq_test_dataset", ",", "mapping", "=", "concat_datasets_sequentially", "(", "train_dataset", ",", "test_dataset", ")", "\n", "\n", "if", "one_dataset_per_exp", ":", "\n", "# If one_dataset_per_exp is True, each dataset will be treated as", "\n", "# a experience. In this benchmark, shuffle refers to the experience", "\n", "# order, not to the class one.", "\n", "            ", "fixed_class_order", ",", "per_exp_classes", "=", "_one_dataset_per_exp_class_order", "(", "mapping", ",", "shuffle", ",", "seed", ")", "\n", "\n", "# We pass a fixed_class_order to the NCGenericScenario", "\n", "# constructor, so we don't need shuffling.", "\n", "shuffle", "=", "False", "\n", "seed", "=", "None", "\n", "\n", "# Overrides n_experiences (and per_experience_classes, already done)", "\n", "n_experiences", "=", "len", "(", "train_dataset", ")", "\n", "", "train_dataset", ",", "test_dataset", "=", "seq_train_dataset", ",", "seq_test_dataset", "\n", "\n", "", "transform_groups", "=", "dict", "(", "\n", "train", "=", "(", "train_transform", ",", "None", ")", ",", "\n", "eval", "=", "(", "eval_transform", ",", "None", ")", "\n", ")", "\n", "\n", "# Datasets should be instances of AvalancheDataset", "\n", "train_dataset", "=", "AvalancheDataset", "(", "\n", "train_dataset", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'train'", ",", "\n", "dataset_type", "=", "AvalancheDatasetType", ".", "CLASSIFICATION", ")", "\n", "\n", "test_dataset", "=", "AvalancheDataset", "(", "\n", "test_dataset", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'eval'", ",", "\n", "dataset_type", "=", "AvalancheDatasetType", ".", "CLASSIFICATION", ")", "\n", "\n", "return", "NCScenario", "(", "train_dataset", ",", "test_dataset", ",", "n_experiences", ",", "task_labels", ",", "\n", "shuffle", ",", "seed", ",", "fixed_class_order", ",", "per_exp_classes", ",", "\n", "class_ids_from_zero_from_first_exp", ",", "\n", "class_ids_from_zero_in_each_exp", ",", "\n", "reproducibility_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.ni_benchmark": [[214, 330], ["dict", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset", "avalanche.benchmarks.scenarios.new_instances.ni_scenario.NIScenario", "isinstance", "isinstance", "avalanche.benchmarks.utils.concat_datasets_sequentially", "len", "len", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.concat_datasets_sequentially"], ["", "def", "ni_benchmark", "(", "\n", "train_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "test_dataset", ":", "Union", "[", "\n", "Sequence", "[", "SupportedDataset", "]", ",", "SupportedDataset", "]", ",", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "task_labels", ":", "bool", "=", "False", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "balance_experiences", ":", "bool", "=", "False", ",", "\n", "min_class_patterns_in_exp", ":", "int", "=", "0", ",", "\n", "fixed_exp_assignment", ":", "Optional", "[", "Sequence", "[", "Sequence", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "train_transform", "=", "None", ",", "\n", "eval_transform", "=", "None", ",", "\n", "reproducibility_data", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "NIScenario", ":", "\n", "    ", "\"\"\"\n    This is the high-level benchmark instances generator for the\n    \"New Instances\" (NI) case. Given a sequence of train and test datasets\n    creates the continual stream of data as a series of experiences.\n\n    This is the reference helper function for creating instances of\n    Domain-Incremental benchmarks.\n\n    The ``task_labels`` parameter determines if each incremental experience has\n    an increasing task label or if, at the contrary, a default task label \"0\"\n    has to be assigned to all experiences. This can be useful when\n    differentiating between Single-Incremental-Task and Multi-Task scenarios.\n\n    There are other important parameters that can be specified in order to tweak\n    the behaviour of the resulting benchmark. Please take a few minutes to read\n    and understand them as they may save you a lot of work.\n\n    This generator features an integrated reproducibility mechanism that allows\n    the user to store and later re-load a benchmark. For more info see the\n    ``reproducibility_data`` parameter.\n\n    :param train_dataset: A list of training datasets, or a single dataset.\n    :param test_dataset: A list of test datasets, or a single test dataset.\n    :param n_experiences: The number of experiences.\n    :param task_labels: If True, each experience will have an ascending task\n            label. If False, the task label will be 0 for all the experiences.\n    :param shuffle: If True, patterns order will be shuffled.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param balance_experiences: If True, pattern of each class will be equally\n        spread across all experiences. If False, patterns will be assigned to\n        experiences in a complete random way. Defaults to False.\n    :param min_class_patterns_in_exp: The minimum amount of patterns of\n        every class that must be assigned to every experience. Compatible with\n        the ``balance_experiences`` parameter. An exception will be raised if\n        this constraint can't be satisfied. Defaults to 0.\n    :param fixed_exp_assignment: If not None, the pattern assignment\n        to use. It must be a list with an entry for each experience. Each entry\n        is a list that contains the indexes of patterns belonging to that\n        experience. Overrides the ``shuffle``, ``balance_experiences`` and\n        ``min_class_patterns_in_exp`` parameters.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations). Defaults to None.\n    :param reproducibility_data: If not None, overrides all the other\n        benchmark definition options, including ``fixed_exp_assignment``.\n        This is usually a dictionary containing data used to\n        reproduce a specific experiment. One can use the\n        ``get_reproducibility_data`` method to get (and even distribute)\n        the experiment setup so that it can be loaded by passing it as this\n        parameter. In this way one can be sure that the same specific\n        experimental setup is being used (for reproducibility purposes).\n        Beware that, in order to reproduce an experiment, the same train and\n        test datasets must be used. Defaults to None.\n\n    :return: A properly initialized :class:`NIScenario` instance.\n    \"\"\"", "\n", "\n", "seq_train_dataset", ",", "seq_test_dataset", "=", "train_dataset", ",", "test_dataset", "\n", "if", "isinstance", "(", "train_dataset", ",", "list", ")", "or", "isinstance", "(", "train_dataset", ",", "tuple", ")", ":", "\n", "        ", "if", "len", "(", "train_dataset", ")", "!=", "len", "(", "test_dataset", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Train/test dataset lists must contain the '", "\n", "'exact same number of datasets'", ")", "\n", "\n", "", "seq_train_dataset", ",", "seq_test_dataset", ",", "_", "=", "concat_datasets_sequentially", "(", "train_dataset", ",", "test_dataset", ")", "\n", "\n", "", "transform_groups", "=", "dict", "(", "\n", "train", "=", "(", "train_transform", ",", "None", ")", ",", "\n", "eval", "=", "(", "eval_transform", ",", "None", ")", "\n", ")", "\n", "\n", "# Datasets should be instances of AvalancheDataset", "\n", "seq_train_dataset", "=", "AvalancheDataset", "(", "\n", "seq_train_dataset", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'train'", ",", "\n", "dataset_type", "=", "AvalancheDatasetType", ".", "CLASSIFICATION", ")", "\n", "\n", "seq_test_dataset", "=", "AvalancheDataset", "(", "\n", "seq_test_dataset", ",", "\n", "transform_groups", "=", "transform_groups", ",", "\n", "initial_transform_group", "=", "'eval'", ",", "\n", "dataset_type", "=", "AvalancheDatasetType", ".", "CLASSIFICATION", ")", "\n", "\n", "return", "NIScenario", "(", "\n", "seq_train_dataset", ",", "seq_test_dataset", ",", "\n", "n_experiences", ",", "\n", "task_labels", ",", "\n", "shuffle", "=", "shuffle", ",", "seed", "=", "seed", ",", "\n", "balance_experiences", "=", "balance_experiences", ",", "\n", "min_class_patterns_in_exp", "=", "min_class_patterns_in_exp", ",", "\n", "fixed_exp_assignment", "=", "fixed_exp_assignment", ",", "\n", "reproducibility_data", "=", "reproducibility_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators._one_dataset_per_exp_class_order": [[342, 373], ["list", "enumerate", "range", "[].tolist", "fixed_class_order.extend", "len", "len", "torch.random.manual_seed", "torch.as_tensor", "torch.randperm", "len"], "function", ["None"], ["def", "_one_dataset_per_exp_class_order", "(", "\n", "class_list_per_exp", ":", "Sequence", "[", "Sequence", "[", "int", "]", "]", ",", "\n", "shuffle", ":", "bool", ",", "seed", ":", "Union", "[", "int", ",", "None", "]", ")", "->", "(", "List", "[", "int", "]", ",", "Dict", "[", "int", ",", "int", "]", ")", ":", "\n", "    ", "\"\"\"\n    Utility function that shuffles the class order by keeping classes from the\n    same experience together. Each experience is defined by a different entry in\n    the class_list_per_exp parameter.\n\n    :param class_list_per_exp: A list of class lists, one for each experience\n    :param shuffle: If True, the experience order will be shuffled. If False,\n        this function will return the concatenation of lists from the\n        class_list_per_exp parameter.\n    :param seed: If not None, an integer used to initialize the random\n        number generator.\n\n    :returns: A class order that keeps class IDs from the same experience\n        together (adjacent).\n    \"\"\"", "\n", "dataset_order", "=", "list", "(", "range", "(", "len", "(", "class_list_per_exp", ")", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "if", "seed", "is", "not", "None", ":", "\n", "            ", "torch", ".", "random", ".", "manual_seed", "(", "seed", ")", "\n", "", "dataset_order", "=", "torch", ".", "as_tensor", "(", "dataset_order", ")", "[", "\n", "torch", ".", "randperm", "(", "len", "(", "dataset_order", ")", ")", "]", ".", "tolist", "(", ")", "\n", "", "fixed_class_order", "=", "[", "]", "\n", "classes_per_exp", "=", "{", "}", "\n", "for", "dataset_position", ",", "dataset_idx", "in", "enumerate", "(", "dataset_order", ")", ":", "\n", "        ", "fixed_class_order", ".", "extend", "(", "class_list_per_exp", "[", "dataset_idx", "]", ")", "\n", "classes_per_exp", "[", "dataset_position", "]", "=", "len", "(", "class_list_per_exp", "[", "dataset_idx", "]", ")", "\n", "", "return", "fixed_class_order", ",", "classes_per_exp", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.fixed_size_experience_split_strategy": [[375, 428], ["list", "range", "[].tolist", "len", "result_datasets.append", "len", "len", "len", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheSubset", "torch.as_tensor", "torch.randperm", "len"], "function", ["None"], ["", "def", "fixed_size_experience_split_strategy", "(", "\n", "experience_size", ":", "int", ",", "shuffle", ":", "bool", ",", "drop_last", ":", "bool", ",", "\n", "experience", ":", "Experience", ")", ":", "\n", "    ", "\"\"\"\n    The default splitting strategy used by :func:`data_incremental_benchmark`.\n\n    This splitting strategy simply splits the experience in smaller experiences\n    of size `experience_size`.\n\n    When taking inspiration for your custom splitting strategy, please consider\n    that all parameters preceding `experience` are filled by\n    :func:`data_incremental_benchmark` by using `partial` from the `functools`\n    standard library. A custom splitting strategy must have only a single\n    parameter: the experience. Consider wrapping your custom splitting strategy\n    with `partial` if more parameters are needed.\n\n    Also consider that the stream name of the experience can be obtained by\n    using `experience.origin_stream.name`.\n\n    :param experience_size: The experience size (number of instances).\n    :param shuffle: If True, instances will be shuffled before splitting.\n    :param drop_last: If True, the last mini-experience will be dropped if\n        not of size `experience_size`\n    :param experience: The experience to split.\n    :return: The list of datasets that will be used to create the\n        mini-experiences.\n    \"\"\"", "\n", "\n", "exp_dataset", "=", "experience", ".", "dataset", "\n", "exp_indices", "=", "list", "(", "range", "(", "len", "(", "exp_dataset", ")", ")", ")", "\n", "\n", "result_datasets", "=", "[", "]", "\n", "\n", "if", "shuffle", ":", "\n", "        ", "exp_indices", "=", "torch", ".", "as_tensor", "(", "exp_indices", ")", "[", "\n", "torch", ".", "randperm", "(", "len", "(", "exp_indices", ")", ")", "\n", "]", ".", "tolist", "(", ")", "\n", "\n", "", "init_idx", "=", "0", "\n", "while", "init_idx", "<", "len", "(", "exp_indices", ")", ":", "\n", "        ", "final_idx", "=", "init_idx", "+", "experience_size", "# Exclusive", "\n", "if", "final_idx", ">", "len", "(", "exp_indices", ")", ":", "\n", "            ", "if", "drop_last", ":", "\n", "                ", "break", "\n", "\n", "", "final_idx", "=", "len", "(", "exp_indices", ")", "\n", "\n", "", "result_datasets", ".", "append", "(", "AvalancheSubset", "(", "\n", "exp_dataset", ",", "indices", "=", "exp_indices", "[", "init_idx", ":", "final_idx", "]", ")", ")", "\n", "init_idx", "=", "final_idx", "\n", "\n", "", "return", "result_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.data_incremental_benchmark": [[430, 531], ["dict", "avalanche.benchmarks.GenericCLScenario", "functools.partial", "getattr", "avalanche.benchmarks.scenarios.generic_cl_scenario.StreamUserDef", "ValueError", "functools.partial.", "range", "len", "len", "split_task_labels.append", "set"], "function", ["None"], ["", "def", "data_incremental_benchmark", "(", "\n", "benchmark_instance", ":", "GenericCLScenario", ",", "\n", "experience_size", ":", "int", ",", "\n", "shuffle", ":", "bool", "=", "False", ",", "\n", "drop_last", ":", "bool", "=", "False", ",", "\n", "split_streams", ":", "Sequence", "[", "str", "]", "=", "(", "'train'", ",", ")", ",", "\n", "custom_split_strategy", ":", "Callable", "[", "[", "Experience", "]", ",", "\n", "Sequence", "[", "AvalancheDataset", "]", "]", "=", "None", ",", "\n", "experience_factory", ":", "Callable", "[", "[", "GenericScenarioStream", ",", "int", "]", ",", "\n", "Experience", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    High-level benchmark generator for a Data Incremental setup.\n\n    This generator accepts an existing benchmark instance and returns a version\n    of it in which experiences have been split in order to produce a\n    Data Incremental stream.\n\n    In its base form this generator will split train experiences in experiences\n    of a fixed, configurable, size. The split can be also performed on other\n    streams (like the test one) if needed.\n\n    The `custom_split_strategy` parameter can be used if a more specific\n    splitting is required.\n\n    Beware that experience splitting is NOT executed in a lazy way. This\n    means that the splitting process takes place immediately. Consider\n    optimizing the split process for speed when using a custom splitting\n    strategy.\n\n    Please note that each mini-experience will have a task labels field\n    equal to the one of the originating experience.\n\n    The `complete_test_set_only` field of the resulting benchmark instance\n    will be `True` only if the same field of original benchmark instance is\n    `True` and if the resulting test stream contains exactly one experience.\n\n    :param benchmark_instance: The benchmark to split.\n    :param experience_size: The size of the experience, as an int. Ignored\n        if `custom_split_strategy` is used.\n    :param shuffle: If True, experiences will be split by first shuffling\n        instances in each experience. This will use the default PyTorch\n        random number generator at its current state. Defaults to False.\n        Ignored if `custom_split_strategy` is used.\n    :param drop_last: If True, if the last experience doesn't contain\n        `experience_size` instances, then the last experience will be dropped.\n        Defaults to False. Ignored if `custom_split_strategy` is used.\n    :param split_streams: The list of streams to split. By default only the\n        \"train\" stream will be split.\n    :param custom_split_strategy: A function that implements a custom splitting\n        strategy. The function must accept an experience and return a list\n        of datasets each describing an experience. Defaults to None, which means\n        that the standard splitting strategy will be used (which creates\n        experiences of size `experience_size`).\n        A good starting to understand the mechanism is to look at the\n        implementation of the standard splitting function\n        :func:`fixed_size_experience_split_strategy`.\n\n    :param experience_factory: The experience factory.\n        Defaults to :class:`GenericExperience`.\n    :return: The Data Incremental benchmark instance.\n    \"\"\"", "\n", "\n", "split_strategy", "=", "custom_split_strategy", "\n", "if", "split_strategy", "is", "None", ":", "\n", "        ", "split_strategy", "=", "partial", "(", "\n", "fixed_size_experience_split_strategy", ",", "experience_size", ",", "shuffle", ",", "\n", "drop_last", ")", "\n", "\n", "", "stream_definitions", ":", "TStreamsUserDict", "=", "dict", "(", "\n", "benchmark_instance", ".", "stream_definitions", ")", "\n", "\n", "for", "stream_name", "in", "split_streams", ":", "\n", "        ", "if", "stream_name", "not", "in", "stream_definitions", ":", "\n", "            ", "raise", "ValueError", "(", "f'Stream {stream_name} could not be found in the '", "\n", "f'benchmark instance'", ")", "\n", "\n", "", "stream", "=", "getattr", "(", "benchmark_instance", ",", "f'{stream_name}_stream'", ")", "\n", "\n", "split_datasets", ":", "List", "[", "AvalancheDataset", "]", "=", "[", "]", "\n", "split_task_labels", ":", "List", "[", "Set", "[", "int", "]", "]", "=", "[", "]", "\n", "\n", "exp", ":", "Experience", "\n", "for", "exp", "in", "stream", ":", "\n", "            ", "experiences", "=", "split_strategy", "(", "exp", ")", "\n", "split_datasets", "+=", "experiences", "\n", "for", "_", "in", "range", "(", "len", "(", "experiences", ")", ")", ":", "\n", "                ", "split_task_labels", ".", "append", "(", "set", "(", "exp", ".", "task_labels", ")", ")", "\n", "\n", "", "", "stream_def", "=", "StreamUserDef", "(", "\n", "split_datasets", ",", "split_task_labels", ",", "\n", "stream_definitions", "[", "stream_name", "]", ".", "origin_dataset", ",", "\n", "False", ")", "\n", "\n", "stream_definitions", "[", "stream_name", "]", "=", "stream_def", "\n", "\n", "", "complete_test_set_only", "=", "benchmark_instance", ".", "complete_test_set_only", "and", "len", "(", "stream_definitions", "[", "'test'", "]", ".", "exps_data", ")", "==", "1", "\n", "\n", "return", "GenericCLScenario", "(", "stream_definitions", "=", "stream_definitions", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "experience_factory", "=", "experience_factory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.random_validation_split_strategy": [[533, 591], ["list", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheSubset", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheSubset", "range", "[].tolist", "int", "int", "len", "len", "len", "ValueError", "len", "torch.as_tensor", "torch.randperm", "len", "len"], "function", ["None"], ["", "def", "random_validation_split_strategy", "(", "\n", "validation_size", ":", "Union", "[", "int", ",", "float", "]", ",", "\n", "shuffle", ":", "bool", ",", "\n", "experience", ":", "Experience", ")", ":", "\n", "    ", "\"\"\"\n    The default splitting strategy used by\n    :func:`benchmark_with_validation_stream`.\n\n    This splitting strategy simply splits the experience in two experiences (\n    train and validation) of size `validation_size`.\n\n    When taking inspiration for your custom splitting strategy, please consider\n    that all parameters preceding `experience` are filled by\n    :func:`benchmark_with_validation_stream` by using `partial` from the\n    `functools` standard library. A custom splitting strategy must have only\n    a single parameter: the experience. Consider wrapping your custom\n    splitting strategy with `partial` if more parameters are needed.\n\n    Also consider that the stream name of the experience can be obtained by\n    using `experience.origin_stream.name`.\n\n    :param validation_size: The number of instances to allocate to the\n    validation experience. Can be an int value or a float between 0 and 1.\n    :param shuffle: If True, instances will be shuffled before splitting.\n        Otherwise, the first instances will be allocated to the training\n        dataset by leaving the last ones to the validation dataset.\n    :param experience: The experience to split.\n    :return: A tuple containing 2 elements: the new training and validation\n        datasets.\n    \"\"\"", "\n", "\n", "exp_dataset", "=", "experience", ".", "dataset", "\n", "exp_indices", "=", "list", "(", "range", "(", "len", "(", "exp_dataset", ")", ")", ")", "\n", "\n", "if", "shuffle", ":", "\n", "        ", "exp_indices", "=", "torch", ".", "as_tensor", "(", "exp_indices", ")", "[", "\n", "torch", ".", "randperm", "(", "len", "(", "exp_indices", ")", ")", "\n", "]", ".", "tolist", "(", ")", "\n", "\n", "", "if", "0.0", "<=", "validation_size", "<=", "1.0", ":", "\n", "        ", "valid_n_instances", "=", "int", "(", "validation_size", "*", "len", "(", "exp_dataset", ")", ")", "\n", "", "else", ":", "\n", "        ", "valid_n_instances", "=", "int", "(", "validation_size", ")", "\n", "if", "valid_n_instances", ">", "len", "(", "exp_dataset", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'Can\\'t create the validation experience: nott enough '", "\n", "f'instances. Required {valid_n_instances}, got only'", "\n", "f'{len(exp_dataset)}'", ")", "\n", "\n", "", "", "train_n_instances", "=", "len", "(", "exp_dataset", ")", "-", "valid_n_instances", "\n", "\n", "result_train_dataset", "=", "AvalancheSubset", "(", "\n", "exp_dataset", ",", "indices", "=", "exp_indices", "[", ":", "train_n_instances", "]", ")", "\n", "result_valid_dataset", "=", "AvalancheSubset", "(", "\n", "exp_dataset", ",", "indices", "=", "exp_indices", "[", "train_n_instances", ":", "]", ")", "\n", "\n", "return", "result_train_dataset", ",", "result_valid_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators._gen_split": [[593, 610], ["itertools.tee"], "function", ["None"], ["", "def", "_gen_split", "(", "split_generator", ":", "Iterable", "[", "Tuple", "[", "AvalancheDataset", ",", "\n", "AvalancheDataset", "]", "]", ")", "->", "Tuple", "[", "Generator", "[", "AvalancheDataset", ",", "None", ",", "None", "]", ",", "\n", "Generator", "[", "AvalancheDataset", ",", "None", ",", "None", "]", "]", ":", "\n", "    ", "\"\"\"\n    Internal utility function to split the train-validation generator\n    into two distinct generators (one for the train stream and another one\n    for the valid stream).\n\n    :param split_generator: The lazy stream generator returning tuples of train\n        and valid datasets.\n    :return: Two generators (one for the train, one for the valuid).\n    \"\"\"", "\n", "\n", "# For more info: https://stackoverflow.com/a/28030261", "\n", "gen_a", ",", "gen_b", "=", "tee", "(", "split_generator", ",", "2", ")", "\n", "return", "(", "a", "for", "a", ",", "b", "in", "gen_a", ")", ",", "(", "b", "for", "a", ",", "b", "in", "gen_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators._lazy_train_val_split": [[612, 629], ["split_strategy"], "function", ["None"], ["", "def", "_lazy_train_val_split", "(", "\n", "split_strategy", ":", "Callable", "[", "[", "Experience", "]", ",", "\n", "Tuple", "[", "AvalancheDataset", ",", "AvalancheDataset", "]", "]", ",", "\n", "experiences", ":", "Iterable", "[", "Experience", "]", ")", "->", "Generator", "[", "Tuple", "[", "AvalancheDataset", ",", "AvalancheDataset", "]", ",", "None", ",", "None", "]", ":", "\n", "    ", "\"\"\"\n    Creates a generator operating around the split strategy and the\n    experiences stream.\n\n    :param split_strategy: The strategy used to split each experience in train\n        and validation datasets.\n    :return: A generator returning a 2 elements tuple (the train and validation\n        datasets).\n    \"\"\"", "\n", "\n", "for", "new_experience", "in", "experiences", ":", "\n", "        ", "yield", "split_strategy", "(", "new_experience", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.benchmark_with_validation_stream": [[631, 768], ["dict", "list", "avalanche.benchmarks.scenarios.generic_cl_scenario.StreamUserDef", "avalanche.benchmarks.scenarios.generic_cl_scenario.StreamUserDef", "avalanche.benchmarks.GenericCLScenario", "functools.partial", "ValueError", "ValueError", "benchmark_generators._lazy_train_val_split", "benchmark_generators._gen_split", "functools.partial.", "train_exps_source.append", "valid_exps_source.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators._lazy_train_val_split", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators._gen_split"], ["", "", "def", "benchmark_with_validation_stream", "(", "\n", "benchmark_instance", ":", "GenericCLScenario", ",", "\n", "validation_size", ":", "Union", "[", "int", ",", "float", "]", ",", "\n", "shuffle", ":", "bool", "=", "False", ",", "\n", "input_stream", ":", "str", "=", "'train'", ",", "\n", "output_stream", ":", "str", "=", "'valid'", ",", "\n", "custom_split_strategy", ":", "Callable", "[", "[", "Experience", "]", ",", "\n", "Tuple", "[", "AvalancheDataset", ",", "\n", "AvalancheDataset", "]", "]", "=", "None", ",", "\n", "*", ",", "\n", "experience_factory", ":", "Callable", "[", "[", "GenericScenarioStream", ",", "int", "]", ",", "\n", "Experience", "]", "=", "None", ",", "\n", "lazy_splitting", ":", "bool", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Helper that can be used to obtain a benchmark with a validation stream.\n\n    This generator accepts an existing benchmark instance and returns a version\n    of it in which a validation stream has been added.\n\n    In its base form this generator will split train experiences to extract\n    validation experiences of a fixed (by number of instances or relative\n    size), configurable, size. The split can be also performed on other\n    streams if needed and the name of the resulting validation stream can\n    be configured too.\n\n    Each validation experience will be extracted directly from a single training\n    experience. Patterns selected for the validation experience will be removed\n    from the training one.\n\n    If shuffle is True, the validation stream will be created randomly.\n    Beware that no kind of class balancing is done.\n\n    The `custom_split_strategy` parameter can be used if a more specific\n    splitting is required.\n\n    Please note that the resulting experiences will have a task labels field\n    equal to the one of the originating experience.\n\n    Experience splitting can be executed in a lazy way. This behavior can be\n    controlled using the `lazy_splitting` parameter. By default, experiences\n    are split in a lazy way only when the input stream is lazily generated.\n\n    :param benchmark_instance: The benchmark to split.\n    :param validation_size: The size of the validation experience, as an int\n        or a float between 0 and 1. Ignored if `custom_split_strategy` is used.\n    :param shuffle: If True, patterns will be allocated to the validation\n        stream randomly. This will use the default PyTorch random number\n        generator at its current state. Defaults to False. Ignored if\n        `custom_split_strategy` is used. If False, the first instances will be\n        allocated to the training  dataset by leaving the last ones to the\n        validation dataset.\n    :param input_stream: The name of the input stream. Defaults to 'train'.\n    :param output_stream: The name of the output stream. Defaults to 'valid'.\n    :param custom_split_strategy: A function that implements a custom splitting\n        strategy. The function must accept an experience and return a tuple\n        containing the new train and validation dataset. Defaults to None,\n        which means that the standard splitting strategy will be used (which\n        creates experiences according to `validation_size` and `shuffle`).\n        A good starting to understand the mechanism is to look at the\n        implementation of the standard splitting function\n        :func:`random_validation_split_strategy`.\n    :param experience_factory: The experience factory. Defaults to\n        :class:`GenericExperience`.\n    :param lazy_splitting: If True, the stream will be split in a lazy way.\n        If False, the stream will be split immediately. Defaults to None, which\n        means that the stream will be split in a lazy or non-lazy way depending\n        on the laziness of the `input_stream`.\n    :return: A benchmark instance in which the validation stream has been added.\n    \"\"\"", "\n", "\n", "split_strategy", "=", "custom_split_strategy", "\n", "if", "split_strategy", "is", "None", ":", "\n", "        ", "split_strategy", "=", "partial", "(", "\n", "random_validation_split_strategy", ",", "validation_size", ",", "\n", "shuffle", ")", "\n", "\n", "", "stream_definitions", ":", "TStreamsUserDict", "=", "dict", "(", "\n", "benchmark_instance", ".", "stream_definitions", ")", "\n", "streams", "=", "benchmark_instance", ".", "streams", "\n", "\n", "if", "input_stream", "not", "in", "streams", ":", "\n", "        ", "raise", "ValueError", "(", "f'Stream {input_stream} could not be found in the '", "\n", "f'benchmark instance'", ")", "\n", "\n", "", "if", "output_stream", "in", "streams", ":", "\n", "        ", "raise", "ValueError", "(", "f'Stream {output_stream} already exists in the '", "\n", "f'benchmark instance'", ")", "\n", "\n", "", "stream", "=", "streams", "[", "input_stream", "]", "\n", "\n", "split_lazily", "=", "lazy_splitting", "\n", "if", "split_lazily", "is", "None", ":", "\n", "        ", "split_lazily", "=", "stream_definitions", "[", "input_stream", "]", ".", "is_lazy", "\n", "\n", "", "exps_tasks_labels", "=", "list", "(", "\n", "stream_definitions", "[", "input_stream", "]", ".", "exps_task_labels", "\n", ")", "\n", "\n", "if", "not", "split_lazily", ":", "\n", "# Classic static splitting", "\n", "        ", "train_exps_source", "=", "[", "]", "\n", "valid_exps_source", "=", "[", "]", "\n", "\n", "exp", ":", "Experience", "\n", "for", "exp", "in", "stream", ":", "\n", "            ", "train_exp", ",", "valid_exp", "=", "split_strategy", "(", "exp", ")", "\n", "train_exps_source", ".", "append", "(", "train_exp", ")", "\n", "valid_exps_source", ".", "append", "(", "valid_exp", ")", "\n", "", "", "else", ":", "\n", "# Lazy splitting (based on a generator)", "\n", "        ", "split_generator", "=", "_lazy_train_val_split", "(", "split_strategy", ",", "stream", ")", "\n", "train_exps_gen", ",", "valid_exps_gen", "=", "_gen_split", "(", "split_generator", ")", "\n", "train_exps_source", "=", "(", "train_exps_gen", ",", "len", "(", "stream", ")", ")", "\n", "valid_exps_source", "=", "(", "valid_exps_gen", ",", "len", "(", "stream", ")", ")", "\n", "\n", "", "train_stream_def", "=", "StreamUserDef", "(", "\n", "train_exps_source", ",", "\n", "exps_tasks_labels", ",", "\n", "stream_definitions", "[", "input_stream", "]", ".", "origin_dataset", ",", "\n", "split_lazily", ")", "\n", "\n", "valid_stream_def", "=", "StreamUserDef", "(", "\n", "valid_exps_source", ",", "\n", "exps_tasks_labels", ",", "\n", "stream_definitions", "[", "input_stream", "]", ".", "origin_dataset", ",", "\n", "split_lazily", ")", "\n", "\n", "stream_definitions", "[", "input_stream", "]", "=", "train_stream_def", "\n", "stream_definitions", "[", "output_stream", "]", "=", "valid_stream_def", "\n", "\n", "complete_test_set_only", "=", "benchmark_instance", ".", "complete_test_set_only", "\n", "\n", "return", "GenericCLScenario", "(", "stream_definitions", "=", "stream_definitions", ",", "\n", "complete_test_set_only", "=", "complete_test_set_only", ",", "\n", "experience_factory", "=", "experience_factory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cimagenet.SplitImageNet": [[39, 142], ["cimagenet._get_imagenet_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cimagenet._get_imagenet_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitImageNet", "(", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "*", ",", "\n", "n_experiences", "=", "10", ",", "\n", "per_exp_classes", "=", "None", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", "=", "0", ",", "\n", "fixed_class_order", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_eval_transform", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the ImageNet dataset.\n\n    If the dataset is not present in the computer, **this method will NOT be\n    able automatically download** and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param dataset_root: Base path where Imagenet data is stored.\n    :param n_experiences: The number of experiences in the current benchmark.\n    :param per_exp_classes: Is not None, a dictionary whose keys are\n        (0-indexed) experience IDs and their values are the number of classes\n        to include in the respective experiences. The dictionary doesn't\n        have to contain a key for each experience! All the remaining exps\n        will contain an equal amount of the remaining classes. The\n        remaining number of classes must be divisible without remainder\n        by the remaining number of experiences. For instance,\n        if you want to include 50 classes in the first experience\n        while equally distributing remaining classes across remaining\n        experiences, just pass the \"{0: 50}\" dictionary as the\n        per_experience_classes parameter. Defaults to None.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "train_set", ",", "test_set", "=", "_get_imagenet_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "per_exp_classes", "=", "per_exp_classes", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "per_exp_classes", "=", "per_exp_classes", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cimagenet._get_imagenet_dataset": [[144, 150], ["avalanche.benchmarks.datasets.ImageNet", "avalanche.benchmarks.datasets.ImageNet"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.ImageNet", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.ImageNet"], ["", "", "def", "_get_imagenet_dataset", "(", "root", ")", ":", "\n", "    ", "train_set", "=", "ImageNet", "(", "root", ",", "split", "=", "\"train\"", ")", "\n", "\n", "test_set", "=", "ImageNet", "(", "root", ",", "split", "=", "\"val\"", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cinaturalist.SplitInaturalist": [[40, 153], ["cinaturalist._get_inaturalist_dataset", "cinaturalist._get_split", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark", "len", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cinaturalist._get_inaturalist_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cinaturalist._get_split", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitInaturalist", "(", "\n", "*", ",", "\n", "super_categories", "=", "None", ",", "\n", "return_task_id", "=", "False", ",", "\n", "download", "=", "False", ",", "\n", "seed", "=", "0", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the iNaturalist2018 dataset.\n    A selection of supercategories (by default 10) define the experiences.\n    Note that the supercategories are highly imbalanced in the number of classes\n    and the amount of data available.\n\n    If the dataset is not present in the computer, **this method will\n    automatically download** and store it if `download=True`\n    (120Gtrain/val).\n\n    To parse the dataset jsons you need to install an additional dependency:\n    \"pycocotools\". You can install it like this:\n\n        \"conda install -c conda-forge pycocotools\"\n\n    Implementation is based on the CL survey\n    (https://ieeexplore.ieee.org/document/9349197) but differs slightly.\n    The survey uses only the original iNaturalist2018 training dataset split\n    into 70/10/20 for train/val/test streams. This method instead uses the full\n    iNaturalist2018 training set to make the `train_stream`, whereas the\n    `test_stream` is defined by the original iNaturalist2018 validation data.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param super_categories: The list of supercategories which define the\n    tasks, i.e. each task consists of all classes in a super-category.\n    :param download: If true and the dataset is not present in the computer,\n    this method will automatically download and store it. This will take 120G\n    for the train/val set.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset.\n        Defaults to None, which means that the default location for\n        'inatuarlist2018' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "# Categories with > 100 datapoints", "\n", "if", "super_categories", "is", "None", ":", "\n", "        ", "super_categories", "=", "[", "\n", "'Amphibia'", ",", "'Animalia'", ",", "'Arachnida'", ",", "'Aves'", ",", "'Fungi'", ",", "\n", "'Insecta'", ",", "'Mammalia'", ",", "'Mollusca'", ",", "'Plantae'", ",", "'Reptilia'", "]", "\n", "\n", "", "train_set", ",", "test_set", "=", "_get_inaturalist_dataset", "(", "\n", "dataset_root", ",", "super_categories", ",", "download", "=", "download", ")", "\n", "per_exp_classes", ",", "fixed_class_order", "=", "_get_split", "(", "super_categories", ",", "train_set", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "per_exp_classes", "=", "per_exp_classes", ",", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "len", "(", "super_categories", ")", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "per_exp_classes", "=", "per_exp_classes", ",", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "len", "(", "super_categories", ")", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cinaturalist._get_inaturalist_dataset": [[156, 168], ["avalanche.benchmarks.datasets.INATURALIST2018", "avalanche.benchmarks.datasets.INATURALIST2018", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "", "def", "_get_inaturalist_dataset", "(", "dataset_root", ",", "super_categories", ",", "download", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'inatuarlist2018'", ")", "\n", "\n", "", "train_set", "=", "INATURALIST2018", "(", "\n", "dataset_root", ",", "split", "=", "\"train\"", ",", "supcats", "=", "super_categories", ",", "\n", "download", "=", "download", ")", "\n", "test_set", "=", "INATURALIST2018", "(", "\n", "dataset_root", ",", "split", "=", "\"val\"", ",", "supcats", "=", "super_categories", ",", "\n", "download", "=", "download", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cinaturalist._get_split": [[170, 179], ["enumerate", "list", "len"], "function", ["None"], ["", "def", "_get_split", "(", "super_categories", ",", "train_set", ")", ":", "\n", "    ", "\"\"\" Get number of classes per experience, and\n    the total order of the classes.\"\"\"", "\n", "per_exp_classes", ",", "fixed_class_order", "=", "{", "}", ",", "[", "]", "\n", "for", "idx", ",", "supcat", "in", "enumerate", "(", "super_categories", ")", ":", "\n", "        ", "new_cats", "=", "list", "(", "train_set", ".", "cats_per_supcat", "[", "supcat", "]", ")", "\n", "fixed_class_order", "+=", "new_cats", "\n", "per_exp_classes", "[", "idx", "]", "=", "len", "(", "new_cats", ")", "\n", "", "return", "per_exp_classes", ",", "fixed_class_order", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.core50.CORe50": [[62, 154], ["avalanche.benchmarks.datasets.core50.core50.CORe50Dataset", "range", "avalanche.benchmarks.scenarios.generic_benchmark_creation.create_generic_benchmark_from_filelists", "nbatch.keys", "avalanche.benchmarks.datasets.default_dataset_location", "str", "train_failists_paths.append", "range", "str().zfill", "str"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_generic_benchmark_from_filelists", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["            ", "root", "=", "default_dataset_location", "(", "'core50'", ")", "\n", "\n", "", "super", "(", "CORe50Dataset", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "object_level", "=", "object_level", "\n", "self", ".", "mini", "=", "mini", "\n", "\n", "# any scenario and run is good here since we want just to load the", "\n", "# train images and targets with no particular order", "\n", "self", ".", "_scen", "=", "'ni'", "\n", "self", ".", "_run", "=", "0", "\n", "self", ".", "_nbatch", "=", "8", "\n", "\n", "# Download the dataset and initialize metadata", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target\n                class.\n        \"\"\"", "\n", "\n", "target", "=", "self", ".", "targets", "[", "index", "]", "\n", "if", "self", ".", "mini", ":", "\n", "            ", "bp", "=", "\"core50_32x32\"", "\n", "", "else", ":", "\n", "            ", "bp", "=", "\"core50_128x128\"", "\n", "\n", "", "img", "=", "self", ".", "loader", "(", "\n", "str", "(", "self", ".", "root", "/", "bp", "/", "self", ".", "paths", "[", "index", "]", ")", "\n", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "targets", ")", "\n", "\n", "", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "data2download", "=", "core50_data", ".", "data", "\n", "\n", "if", "self", ".", "mini", ":", "\n", "            ", "data2download", "=", "list", "(", "data2download", ")", "\n", "data2download", "[", "0", "]", "=", "core50_data", ".", "extra_data", "[", "1", "]", "\n", "\n", "", "for", "name", "in", "data2download", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Downloading \"", "+", "name", "[", "1", "]", "+", "\"...\"", ")", "\n", "", "file", "=", "self", ".", "_download_file", "(", "name", "[", "1", "]", ",", "name", "[", "0", "]", ",", "name", "[", "2", "]", ")", "\n", "if", "name", "[", "1", "]", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "                ", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "f'Extracting {name[0]}...'", ")", "\n", "", "extract_root", "=", "self", ".", "_extract_archive", "(", "file", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "'Extraction completed!'", ")", "\n", "\n", "", "", "", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "mini", ":", "\n", "            ", "bp", "=", "\"core50_32x32\"", "\n", "", "else", ":", "\n", "            ", "bp", "=", "\"core50_128x128\"", "\n", "\n", "", "if", "not", "(", "self", ".", "root", "/", "bp", ")", ".", "exists", "(", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "if", "not", "(", "self", ".", "root", "/", "'batches_filelists'", ")", ".", "exists", "(", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "with", "open", "(", "self", ".", "root", "/", "'paths.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "train_test_paths", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"Loading labels...\"", ")", "\n", "", "with", "open", "(", "self", ".", "root", "/", "'labels.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "all_targets", "=", "pkl", ".", "load", "(", "f", ")", "\n", "self", ".", "train_test_targets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_nbatch", "+", "1", ")", ":", "\n", "                ", "self", ".", "train_test_targets", "+=", "self", ".", "all_targets", "[", "self", ".", "_scen", "]", "[", "self", ".", "_run", "]", "[", "i", "]", "\n", "\n", "", "", "if", "self", ".", "verbose", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar100.SplitCIFAR100": [[40, 140], ["ccifar100._get_cifar100_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar100._get_cifar100_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitCIFAR100", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "first_exp_with_half_classes", ":", "bool", "=", "False", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_cifar100_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_cifar100_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the CIFAR100 dataset.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of incremental experiences in the current\n        benchmark. The value of this parameter should be a divisor of 100 if\n        first_task_with_half_classes is False, a divisor of 50 otherwise.\n    :param first_exp_with_half_classes: A boolean value that indicates if a\n        first pretraining batch containing half of the classes should be used.\n        If it's True, a pretraining experience with half of the classes (50 for\n        cifar100) is used. If this parameter is False no pretraining task\n        will be used, and the dataset is simply split into a the number of\n        experiences defined by the parameter n_experiences. Default to False.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'cifar100' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "cifar_train", ",", "cifar_test", "=", "_get_cifar100_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "cifar_train", ",", "\n", "test_dataset", "=", "cifar_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "per_exp_classes", "=", "{", "0", ":", "50", "}", "if", "first_exp_with_half_classes", "else", "None", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "cifar_train", ",", "\n", "test_dataset", "=", "cifar_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "per_exp_classes", "=", "{", "0", ":", "50", "}", "if", "first_exp_with_half_classes", "else", "None", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar100.SplitCIFAR110": [[142, 241], ["ccifar100._get_cifar10_dataset", "ccifar100._get_cifar100_dataset", "avalanche.benchmarks.utils.avalanche_dataset.concat_datasets_sequentially", "avalanche.benchmarks.nc_benchmark", "class_order.extend", "random.seed", "random.sample", "class_order.extend", "range", "range"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar10._get_cifar10_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar100._get_cifar100_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.concat_datasets_sequentially", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["", "", "def", "SplitCIFAR110", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_cifar100_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_cifar100_eval_transform", ",", "\n", "dataset_root_cifar10", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "dataset_root_cifar100", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using both the CIFAR100 and CIFAR10 datasets.\n\n    If the datasets are not present in the computer, this method will\n    automatically download and store them in the data folder.\n\n    The CIFAR10 dataset is used to create the first experience, while the\n    remaining `n_experiences-1` experiences will be created from CIFAR100.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator will apply a task label \"0\" to all experiences.\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label (always \"0\" for this specific\n    benchmark).\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences for the entire benchmark.\n        The first experience will contain the entire CIFAR10 dataset, while the\n        other n-1 experiences will be obtained from CIFAR100.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order ONLY for the incremental part, which is based on cifar100. The\n        classes must be in range 0-99.\n        If None, value of ``seed`` will be used to define the class order for\n        the incremental batches on cifar100. If non-None, ``seed`` parameter\n        will be ignored. Defaults to None.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root_cifar10: The root path of the CIFAR-10 dataset.\n        Defaults to None, which means that the default location for\n        'cifar10' will be used.\n    :param dataset_root_cifar100: The root path of the CIFAR-100 dataset.\n        Defaults to None, which means that the default location for\n        'cifar100' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "cifar10_train", ",", "cifar10_test", "=", "_get_cifar10_dataset", "(", "dataset_root_cifar10", ")", "\n", "cifar100_train", ",", "cifar100_test", "=", "_get_cifar100_dataset", "(", "dataset_root_cifar100", ")", "\n", "\n", "cifar_10_100_train", ",", "cifar_10_100_test", ",", "_", "=", "concat_datasets_sequentially", "(", "\n", "[", "cifar10_train", ",", "cifar100_train", "]", ",", "[", "cifar10_test", ",", "cifar100_test", "]", "\n", ")", "\n", "# cifar10 classes", "\n", "class_order", "=", "[", "_", "for", "_", "in", "range", "(", "10", ")", "]", "\n", "# if a class order is defined (for cifar100) the given class labels are", "\n", "# appended to the class_order list, adding 10 to them (since the classes", "\n", "# 0-9 are the classes of cifar10).", "\n", "if", "fixed_class_order", "is", "not", "None", ":", "\n", "        ", "class_order", ".", "extend", "(", "[", "c", "+", "10", "for", "c", "in", "fixed_class_order", "]", ")", "\n", "", "else", ":", "\n", "        ", "random", ".", "seed", "(", "seed", ")", "\n", "# random shuffling of the cifar100 classes (labels 10-109)", "\n", "cifar_100_class_order", "=", "random", ".", "sample", "(", "range", "(", "10", ",", "110", ")", ",", "100", ")", "\n", "class_order", ".", "extend", "(", "cifar_100_class_order", ")", "\n", "\n", "", "return", "nc_benchmark", "(", "\n", "cifar_10_100_train", ",", "cifar_10_100_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "shuffle", "=", "False", ",", "\n", "seed", "=", "None", ",", "\n", "fixed_class_order", "=", "class_order", ",", "\n", "per_exp_classes", "=", "{", "0", ":", "10", "}", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar100._get_cifar10_dataset": [[243, 251], ["avalanche.benchmarks.datasets.CIFAR10", "avalanche.benchmarks.datasets.CIFAR10", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR10", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR10", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "def", "_get_cifar10_dataset", "(", "dataset_root", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'cifar10'", ")", "\n", "\n", "", "train_set", "=", "CIFAR10", "(", "dataset_root", ",", "train", "=", "True", ",", "download", "=", "True", ")", "\n", "test_set", "=", "CIFAR10", "(", "dataset_root", ",", "train", "=", "False", ",", "download", "=", "True", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar100._get_cifar100_dataset": [[253, 261], ["torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR100", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR100", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "def", "_get_cifar100_dataset", "(", "dataset_root", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'cifar100'", ")", "\n", "\n", "", "train_set", "=", "CIFAR100", "(", "dataset_root", ",", "train", "=", "True", ",", "download", "=", "True", ")", "\n", "test_set", "=", "CIFAR100", "(", "dataset_root", ",", "train", "=", "False", ",", "download", "=", "True", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cfashion_mnist.SplitFMNIST": [[35, 138], ["cfashion_mnist._get_fmnist_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cfashion_mnist._get_fmnist_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitFMNIST", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "first_batch_with_half_classes", ":", "bool", "=", "False", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_fmnist_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_fmnist_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the Fashion MNIST dataset.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences in the current\n        benchmark. If the first experience is a \"pretraining\" step and it\n        contains half of the classes. The value of this parameter should be a\n        divisor of 10 if first_task_with_half_classes if false, a divisor of 5\n        otherwise.\n    :param first_batch_with_half_classes: A boolean value that indicates if a\n        first pretraining batch containing half of the classes should be used.\n        If it's True, a pretraining batch with half of the classes (5 for\n        cifar100) is used. If this parameter is False no pretraining task\n        will be used, and the dataset is simply split into\n        a the number of experiences defined by the parameter n_experiences.\n        Default to False.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'fashionmnist' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "fmnist_train", ",", "fmnist_test", "=", "_get_fmnist_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "fmnist_train", ",", "\n", "test_dataset", "=", "fmnist_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "per_exp_classes", "=", "{", "0", ":", "5", "}", "if", "first_batch_with_half_classes", "else", "None", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "fmnist_train", ",", "\n", "test_dataset", "=", "fmnist_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "per_exp_classes", "=", "{", "0", ":", "5", "}", "if", "first_batch_with_half_classes", "else", "None", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cfashion_mnist._get_fmnist_dataset": [[140, 149], ["torchvision.datasets.FashionMNIST", "torchvision.datasets.FashionMNIST", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.FashionMNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.FashionMNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "", "def", "_get_fmnist_dataset", "(", "dataset_root", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'fashionmnist'", ")", "\n", "\n", "", "train_set", "=", "FashionMNIST", "(", "dataset_root", ",", "\n", "train", "=", "True", ",", "download", "=", "True", ")", "\n", "test_set", "=", "FashionMNIST", "(", "dataset_root", ",", "\n", "train", "=", "False", ",", "download", "=", "True", ")", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.classic_benchmarks_utils.check_vision_benchmark": [[6, 33], ["print", "enumerate", "len", "DataLoader", "print", "dataset.replace_transforms.replace_transforms", "print", "print", "plt.title", "plt.imshow", "plt.show", "torchvision.transforms.ToTensor", "len", "print", "torchvision.transforms.ToPILImage", "str"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.replace_transforms"], ["def", "check_vision_benchmark", "(", "benchmark_instance", ",", "show_without_transforms", "=", "True", ")", ":", "\n", "    ", "from", "matplotlib", "import", "pyplot", "as", "plt", "\n", "from", "torch", ".", "utils", ".", "data", ".", "dataloader", "import", "DataLoader", "\n", "dataset", ":", "AvalancheDataset", "\n", "\n", "print", "(", "'The benchmark instance contains'", ",", "\n", "len", "(", "benchmark_instance", ".", "train_stream", ")", ",", "'training experiences.'", ")", "\n", "\n", "for", "i", ",", "exp", "in", "enumerate", "(", "benchmark_instance", ".", "train_stream", ")", ":", "\n", "        ", "dataset", ",", "t", "=", "exp", ".", "dataset", ",", "exp", ".", "task_label", "\n", "if", "show_without_transforms", ":", "\n", "            ", "dataset", "=", "dataset", ".", "replace_transforms", "(", "ToTensor", "(", ")", ",", "None", ")", "\n", "\n", "", "dl", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "300", ")", "\n", "\n", "print", "(", "'Train experience'", ",", "exp", ".", "current_experience", ")", "\n", "for", "mb", "in", "dl", ":", "\n", "            ", "x", ",", "y", ",", "*", "other", "=", "mb", "\n", "print", "(", "'X tensor:'", ",", "x", ".", "shape", ")", "\n", "print", "(", "'Y tensor:'", ",", "y", ".", "shape", ")", "\n", "if", "len", "(", "other", ")", ">", "0", ":", "\n", "                ", "print", "(", "'T tensor:'", ",", "other", "[", "0", "]", ".", "shape", ")", "\n", "", "img", "=", "ToPILImage", "(", ")", "(", "x", "[", "0", "]", ")", "\n", "plt", ".", "title", "(", "'Experience: '", "+", "str", "(", "exp", ".", "current_experience", ")", ")", "\n", "plt", ".", "imshow", "(", "img", ")", "\n", "plt", ".", "show", "(", ")", "\n", "break", "# Show only an image for each experience", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.endless_cl_sim.EndlessCLSim": [[42, 148], ["avalanche.benchmarks.datasets.endless_cl_sim.endless_cl_sim.EndlessCLSimDataset", "range", "avalanche.benchmarks.generators.dataset_benchmark", "avalanche.benchmarks.datasets.default_dataset_location", "list", "list", "len", "train_datasets.append", "eval_datasets.append", "range", "range", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset", "avalanche.benchmarks.utils.avalanche_dataset.AvalancheDataset", "len", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["\n", "self", ".", "file_paths", "=", "file_paths", "\n", "self", ".", "targets", "=", "targets", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "self", ".", "labelmap", "=", "self", ".", "_load_labelmap", "(", "labelmap_path", ")", "\n", "\n", "return", "\n", "\n", "", "def", "_pil_loader", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "\"RGB\"", ")", ".", "resize", "(", "\n", "(", "self", ".", "patch_size", ",", "self", ".", "patch_size", ")", ",", "Image", ".", "NEAREST", ")", "\n", "", "return", "img", "\n", "\n", "", "def", "_load_labelmap", "(", "self", ",", "path", ")", ":", "\n", "# If path is None, load default labelmap", "\n", "        ", "if", "path", "is", "None", ":", "\n", "            ", "return", "endless_cl_sim_data", ".", "default_classification_labelmap", "\n", "\n", "# If path is valid, load labelmap from json file", "\n", "", "elif", "Path", "(", "path", ")", ".", "exists", "(", ")", ":", "\n", "            ", "with", "open", "(", "path", ")", "as", "file", ":", "\n", "                ", "json_array", "=", "json", ".", "load", "(", "file", ")", "\n", "labelmap", "=", "json_array", "[", "\"SegmentationClasses\"", "]", "\n", "return", "labelmap", "\n", "\n", "# Finally, raise value error", "\n", "", "", "raise", "ValueError", "(", "f\"path: {path} does not exist!\"", ")", "\n", "\n", "", "def", "_convert_target", "(", "self", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "labelmap", "[", "target", "]", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "img_path", "=", "self", ".", "file_paths", "[", "index", "]", "\n", "target", "=", "self", ".", "_convert_target", "(", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n", "img", "=", "self", ".", "_pil_loader", "(", "img_path", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n", "", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "file_paths", ")", "\n", "\n", "\n", "", "", "class", "VideoSubSequence", "(", "Dataset", ")", ":", "\n", "    ", "\"\"\"Video Subsequence Dataset\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "file_paths", ",", "target_paths", ",", "\n", "segmentation_file", ",", "classmap_file", "=", "None", ",", "patch_size", "=", "(", "240", ",", "135", ")", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Dataset that contains the (image) data and semantic segmentation targets \n        for one subsequence of a video sequence. \n\n        :param file_paths: List containing the paths to all images files that \n            are part of this subsequence.\n        :param target_paths: List containing the paths to all target files \n            corresponding to the `file_paths`. \n        :param segmentation_file: Path to a `segmentation.json` file that \n            specifies a mapping from label indices to object  \n            (or object category) names. Defaults to None, which loads a \n            predefined default mapping.\n        :param classmap_file: Path to a `classmap.json' file that specifies\n            the mapping from object (or object category) names to a \n            respective label. Defaults to None, which loads a predefined\n            default mapping.\n        :param patch_size: Size of the images and target data to be resized to.\n            Defaults to (240, 135).\n        :param transform: Eventual transformations to be applied to the image \n            data.\n        :param target_transform: Eventual transformations to be applied to the \n            target data.\n        \"\"\"", "\n", "self", ".", "file_paths", "=", "file_paths", "\n", "self", ".", "targets", "=", "target_paths", "\n", "self", ".", "segmentation_file", "=", "segmentation_file", "\n", "self", ".", "classmap_file", "=", "classmap_file", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "transform", "\n", "\n", "# Init classmap", "\n", "self", ".", "classmap", "=", "self", ".", "_load_classmap", "(", "classmap_file", "=", "self", ".", "classmap_file", ")", "\n", "\n", "# Init labelmap", "\n", "self", ".", "labelmap", "=", "self", ".", "_load_labelmap", "(", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccub200.SplitCUB200": [[38, 140], ["ccub200._get_cub200_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccub200._get_cub200_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitCUB200", "(", "\n", "n_experiences", "=", "11", ",", "\n", "*", ",", "\n", "classes_first_batch", "=", "100", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", "=", "0", ",", "\n", "fixed_class_order", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the Cub-200 dataset.\n\n    If the dataset is not present in the computer, **this method will NOT be\n    able automatically download** and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences in the current benchmark.\n        Defaults to 11.\n    :param classes_first_batch: Number of classes in the first batch.\n        Usually this is set to 500. Defaults to 100.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset.\n        Defaults to None, which means that the default location for\n        'CUB_200_2011' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "train_set", ",", "test_set", "=", "_get_cub200_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "classes_first_batch", "is", "not", "None", ":", "\n", "        ", "per_exp_classes", "=", "{", "0", ":", "classes_first_batch", "}", "\n", "", "else", ":", "\n", "        ", "per_exp_classes", "=", "None", "\n", "\n", "", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "per_exp_classes", "=", "per_exp_classes", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "one_dataset_per_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "per_exp_classes", "=", "per_exp_classes", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccub200._get_cub200_dataset": [[142, 147], ["avalanche.benchmarks.datasets.CUB200", "avalanche.benchmarks.datasets.CUB200"], "function", ["None"], ["", "", "def", "_get_cub200_dataset", "(", "root", ")", ":", "\n", "    ", "train_set", "=", "CUB200", "(", "root", ",", "train", "=", "True", ")", "\n", "test_set", "=", "CUB200", "(", "root", ",", "train", "=", "False", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.PixelsPermutation.__init__": [[46, 50], ["torchvision.transforms.ToTensor", "torchvision.transforms.ToPILImage"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index_permutation", ":", "Sequence", "[", "int", "]", ")", ":", "\n", "        ", "self", ".", "permutation", "=", "index_permutation", "\n", "self", ".", "_to_tensor", "=", "ToTensor", "(", ")", "\n", "self", ".", "_to_image", "=", "ToPILImage", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.PixelsPermutation.__call__": [[51, 65], ["isinstance", "[].view", "ValueError", "cmnist.PixelsPermutation._to_tensor", "cmnist.PixelsPermutation._to_image", "isinstance", "cmnist.PixelsPermutation.view"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ":", "Union", "[", "Image", ",", "Tensor", "]", ")", ":", "\n", "        ", "is_image", "=", "isinstance", "(", "img", ",", "Image", ")", "\n", "if", "(", "not", "is_image", ")", "and", "(", "not", "isinstance", "(", "img", ",", "Tensor", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid input: must be a PIL image or a Tensor'", ")", "\n", "\n", "", "if", "is_image", ":", "\n", "            ", "img", "=", "self", ".", "_to_tensor", "(", "img", ")", "\n", "\n", "", "img", "=", "img", ".", "view", "(", "-", "1", ")", "[", "self", ".", "permutation", "]", ".", "view", "(", "*", "img", ".", "shape", ")", "\n", "\n", "if", "is_image", ":", "\n", "            ", "img", "=", "self", ".", "_to_image", "(", "img", ")", "\n", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.SplitMNIST": [[67, 159], ["cmnist._get_mnist_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist._get_mnist_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["", "", "def", "SplitMNIST", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_mnist_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_mnist_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the MNIST dataset.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of incremental experiences in the current\n        benchmark.\n        The value of this parameter should be a divisor of 10.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'mnist' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "mnist_train", ",", "mnist_test", "=", "_get_mnist_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "mnist_train", ",", "\n", "test_dataset", "=", "mnist_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "mnist_train", ",", "\n", "test_dataset", "=", "mnist_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.PermutedMNIST": [[161, 257], ["numpy.random.RandomState", "cmnist._get_mnist_dataset", "range", "avalanche.benchmarks.nc_benchmark", "torch.from_numpy().type", "cmnist.PixelsPermutation", "dict", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "list_train_dataset.append", "list_test_dataset.append", "len", "torch.from_numpy", "avalanche.benchmarks.utils.AvalancheDataset", "avalanche.benchmarks.utils.AvalancheDataset", "np.random.RandomState.permutation"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist._get_mnist_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms"], ["", "", "def", "PermutedMNIST", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_mnist_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_mnist_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    Creates a Permuted MNIST benchmark.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    Random pixel permutations are used to permute the MNIST images in\n    ``n_experiences`` different manners. This means that each experience is\n    composed of all the original 10 MNIST classes, but the pixel in the images\n    are permuted in a different way.\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    A progressive task label, starting from \"0\", is applied to each experience.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences (tasks) in the current\n        benchmark. It indicates how many different permutations of the MNIST\n        dataset have to be created.\n        The value of this parameter should be a divisor of 10.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param train_transform: The transformation to apply to the training data\n        before the random permutation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data\n        before the random permutation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'mnist' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "list_train_dataset", "=", "[", "]", "\n", "list_test_dataset", "=", "[", "]", "\n", "rng_permute", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "mnist_train", ",", "mnist_test", "=", "_get_mnist_dataset", "(", "dataset_root", ")", "\n", "\n", "# for every incremental experience", "\n", "for", "_", "in", "range", "(", "n_experiences", ")", ":", "\n", "# choose a random permutation of the pixels in the image", "\n", "        ", "idx_permute", "=", "torch", ".", "from_numpy", "(", "rng_permute", ".", "permutation", "(", "784", ")", ")", ".", "type", "(", "\n", "torch", ".", "int64", ")", "\n", "\n", "permutation", "=", "PixelsPermutation", "(", "idx_permute", ")", "\n", "\n", "permutation_transforms", "=", "dict", "(", "\n", "train", "=", "(", "permutation", ",", "None", ")", ",", "\n", "eval", "=", "(", "permutation", ",", "None", ")", "\n", ")", "\n", "\n", "# Freeze the permutation", "\n", "permuted_train", "=", "AvalancheDataset", "(", "\n", "mnist_train", ",", "\n", "transform_groups", "=", "permutation_transforms", ",", "\n", "initial_transform_group", "=", "'train'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "permuted_test", "=", "AvalancheDataset", "(", "\n", "mnist_test", ",", "\n", "transform_groups", "=", "permutation_transforms", ",", "\n", "initial_transform_group", "=", "'eval'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "list_train_dataset", ".", "append", "(", "permuted_train", ")", "\n", "list_test_dataset", ".", "append", "(", "permuted_test", ")", "\n", "\n", "", "return", "nc_benchmark", "(", "\n", "list_train_dataset", ",", "\n", "list_test_dataset", ",", "\n", "n_experiences", "=", "len", "(", "list_train_dataset", ")", ",", "\n", "task_labels", "=", "True", ",", "\n", "shuffle", "=", "False", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "one_dataset_per_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist.RotatedMNIST": [[259, 373], ["numpy.random.RandomState", "cmnist._get_mnist_dataset", "range", "avalanche.benchmarks.nc_benchmark", "ValueError", "any", "ValueError", "torchvision.transforms.RandomRotation", "dict", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "list_train_dataset.append", "list_test_dataset.append", "len", "np.random.RandomState.randint", "len", "avalanche.benchmarks.utils.AvalancheDataset", "avalanche.benchmarks.utils.AvalancheDataset", "range", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist._get_mnist_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms"], ["", "def", "RotatedMNIST", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "rotations_list", ":", "Optional", "[", "Sequence", "[", "float", "]", "]", "=", "None", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_mnist_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_mnist_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    Creates a Rotated MNIST benchmark.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    Random angles are used to rotate the MNIST images in ``n_experiences``\n    different manners. This means that each experience is composed of all the\n    original 10 MNIST classes, but each image is rotated in a different way.\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    A progressive task label, starting from \"0\", is applied to each experience.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences (tasks) in the current\n        benchmark. It indicates how many different rotations of the MNIST\n        dataset have to be created.\n        The value of this parameter should be a divisor of 10.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param rotations_list: A list of rotations values in degrees (from -180 to\n        180) used to define the rotations. The rotation specified in position\n        0 of the list will be applied to the task 0, the rotation specified in\n        position 1 will be applied to task 1 and so on.\n        If None, value of ``seed`` will be used to define the rotations.\n        If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param train_transform: The transformation to apply to the training data\n        after the random rotation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data\n        after the random rotation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'mnist' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "if", "rotations_list", "is", "not", "None", "and", "len", "(", "rotations_list", ")", "!=", "n_experiences", ":", "\n", "        ", "raise", "ValueError", "(", "\"The number of rotations should match the number\"", "\n", "\" of incremental experiences.\"", ")", "\n", "\n", "", "if", "rotations_list", "is", "not", "None", "and", "any", "(", "180", "<", "rotations_list", "[", "i", "]", "<", "-", "180", "\n", "for", "i", "in", "range", "(", "len", "(", "rotations_list", ")", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"The value of a rotation should be between -180\"", "\n", "\" and 180 degrees.\"", ")", "\n", "\n", "", "list_train_dataset", "=", "[", "]", "\n", "list_test_dataset", "=", "[", "]", "\n", "rng_rotate", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "mnist_train", ",", "mnist_test", "=", "_get_mnist_dataset", "(", "dataset_root", ")", "\n", "\n", "# for every incremental experience", "\n", "for", "exp", "in", "range", "(", "n_experiences", ")", ":", "\n", "        ", "if", "rotations_list", "is", "not", "None", ":", "\n", "            ", "rotation_angle", "=", "rotations_list", "[", "exp", "]", "\n", "", "else", ":", "\n", "# choose a random rotation of the pixels in the image", "\n", "            ", "rotation_angle", "=", "rng_rotate", ".", "randint", "(", "-", "180", ",", "181", ")", "\n", "\n", "", "rotation", "=", "RandomRotation", "(", "degrees", "=", "(", "rotation_angle", ",", "rotation_angle", ")", ")", "\n", "\n", "rotation_transforms", "=", "dict", "(", "\n", "train", "=", "(", "rotation", ",", "None", ")", ",", "\n", "eval", "=", "(", "rotation", ",", "None", ")", "\n", ")", "\n", "\n", "# Freeze the rotation", "\n", "rotated_train", "=", "AvalancheDataset", "(", "\n", "mnist_train", ",", "\n", "transform_groups", "=", "rotation_transforms", ",", "\n", "initial_transform_group", "=", "'train'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "rotated_test", "=", "AvalancheDataset", "(", "\n", "mnist_test", ",", "\n", "transform_groups", "=", "rotation_transforms", ",", "\n", "initial_transform_group", "=", "'eval'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "list_train_dataset", ".", "append", "(", "rotated_train", ")", "\n", "list_test_dataset", ".", "append", "(", "rotated_test", ")", "\n", "\n", "", "return", "nc_benchmark", "(", "\n", "list_train_dataset", ",", "\n", "list_test_dataset", ",", "\n", "n_experiences", "=", "len", "(", "list_train_dataset", ")", ",", "\n", "task_labels", "=", "True", ",", "\n", "shuffle", "=", "False", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "one_dataset_per_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.cmnist._get_mnist_dataset": [[375, 386], ["torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.MNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.MNIST", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "def", "_get_mnist_dataset", "(", "dataset_root", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'mnist'", ")", "\n", "\n", "", "train_set", "=", "MNIST", "(", "root", "=", "dataset_root", ",", "\n", "train", "=", "True", ",", "download", "=", "True", ")", "\n", "\n", "test_set", "=", "MNIST", "(", "root", "=", "dataset_root", ",", "\n", "train", "=", "False", ",", "download", "=", "True", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.stream51._adjust_bbox": [[35, 58], ["int", "int", "min", "max", "min", "max", "int", "int", "int", "int"], "function", ["None"], ["def", "__init__", "(", "self", ",", "root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "\n", "*", ",", "\n", "train", "=", "True", ",", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "loader", "=", "default_loader", ",", "download", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Stream-51 dataset.\n\n        :param root: The directory where the dataset can be found or downloaded.\n            Defaults to None, which means that the default location for\n            'stream51' will be used.\n        :param train: If True, the training set will be returned. If False,\n            the test set will be returned.\n        :param transform: The transformations to apply to the X values.\n        :param target_transform: The transformations to apply to the Y values.\n        :param loader: The image loader to use.\n        :param download: If True, the dataset will be downloaded if needed.\n        \"\"\"", "\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'stream51'", ")", "\n", "\n", "", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.stream51.CLStream51": [[60, 247], ["avalanche.benchmarks.datasets.Stream51", "avalanche.benchmarks.datasets.Stream51", "avalanche.benchmarks.datasets.Stream51.make_dataset", "avalanche.benchmarks.scenarios.generic_benchmark_creation.create_generic_benchmark_from_paths", "math.ceil", "range", "math.ceil", "min", "train_filelists_paths.append", "range", "len", "math.ceil", "math.ceil", "len", "os.path.join", "stream51._adjust_bbox", "range", "list", "enumerate", "test_filelists_paths.append", "test_ood_filelists_paths.append", "train_filelists_paths.append", "len", "range", "len", "set", "range", "len", "os.path.join", "stream51._adjust_bbox", "range", "len", "range", "test_files.append", "test_ood_files.append", "min", "os.path.join", "stream51._adjust_bbox", "os.path.join", "stream51._adjust_bbox", "os.path.join", "stream51._adjust_bbox", "range", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.stream51.stream51.Stream51.make_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_generic_benchmark_from_paths", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.stream51._adjust_bbox", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.stream51._adjust_bbox", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.stream51._adjust_bbox", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.stream51._adjust_bbox", "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.stream51._adjust_bbox"], ["self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "bbox_crop", "=", "True", "\n", "self", ".", "ratio", "=", "1.1", "\n", "\n", "super", "(", "Stream51", ",", "self", ")", ".", "__init__", "(", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n", "", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_download_file", "(", "stream51_data", ".", "name", "[", "1", "]", ",", "stream51_data", ".", "name", "[", "0", "]", ",", "\n", "stream51_data", ".", "name", "[", "2", "]", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'[Stream-51] Extracting dataset...'", ")", "\n", "\n", "", "if", "stream51_data", ".", "name", "[", "1", "]", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "            ", "lfilename", "=", "self", ".", "root", "/", "stream51_data", ".", "name", "[", "0", "]", "\n", "with", "ZipFile", "(", "str", "(", "lfilename", ")", ",", "'r'", ")", "as", "zipf", ":", "\n", "                ", "for", "member", "in", "zipf", ".", "namelist", "(", ")", ":", "\n", "                    ", "filename", "=", "os", ".", "path", ".", "basename", "(", "member", ")", "\n", "# skip directories", "\n", "if", "not", "filename", ":", "\n", "                        ", "continue", "\n", "\n", "# copy file (taken from zipfile's extract)", "\n", "", "source", "=", "zipf", ".", "open", "(", "member", ")", "\n", "if", "'json'", "in", "filename", ":", "\n", "                        ", "target", "=", "open", "(", "str", "(", "self", ".", "root", "/", "filename", ")", ",", "\"wb\"", ")", "\n", "", "else", ":", "\n", "                        ", "dest_folder", "=", "os", ".", "path", ".", "join", "(", "\n", "*", "(", "member", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "1", ":", "-", "1", "]", ")", ")", "\n", "dest_folder", "=", "self", ".", "root", "/", "dest_folder", "\n", "dest_folder", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "target", "=", "open", "(", "str", "(", "dest_folder", "/", "filename", ")", ",", "\"wb\"", ")", "\n", "", "with", "source", ",", "target", ":", "\n", "                        ", "shutil", ".", "copyfileobj", "(", "source", ",", "target", ")", "\n", "\n", "# lfilename.unlink()", "\n", "\n", "", "", "", "", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "data_list", "=", "json", ".", "load", "(", "\n", "open", "(", "str", "(", "self", ".", "root", "/", "'Stream-51_meta_train.json'", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "data_list", "=", "json", ".", "load", "(", "\n", "open", "(", "str", "(", "self", ".", "root", "/", "'Stream-51_meta_test.json'", ")", ")", ")", "\n", "\n", "", "self", ".", "samples", "=", "data_list", "\n", "self", ".", "targets", "=", "[", "s", "[", "0", "]", "for", "s", "in", "data_list", "]", "\n", "\n", "self", ".", "bbox_crop", "=", "True", "\n", "self", ".", "ratio", "=", "1.1", "\n", "\n", "return", "True", "\n", "\n", "", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "'[Stream-51] Error downloading the dataset. Consider '", "'downloading it manually at: '", "+", "stream51_data", ".", "name", "[", "1", "]", "+", "' and placing it in: '", "+", "str", "(", "self", ".", "root", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_instance_ordering", "(", "data_list", ",", "seed", ")", ":", "\n", "# organize data by video", "\n", "        ", "total_videos", "=", "0", "\n", "new_data_list", "=", "[", "]", "\n", "temp_video", "=", "[", "]", "\n", "for", "x", "in", "data_list", ":", "\n", "            ", "if", "x", "[", "3", "]", "==", "0", ":", "\n", "                ", "new_data_list", ".", "append", "(", "temp_video", ")", "\n", "total_videos", "+=", "1", "\n", "temp_video", "=", "[", "x", "]", "\n", "", "else", ":", "\n", "                ", "temp_video", ".", "append", "(", "x", ")", "\n", "", "", "new_data_list", ".", "append", "(", "temp_video", ")", "\n", "new_data_list", "=", "new_data_list", "[", "1", ":", "]", "\n", "# shuffle videos", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "new_data_list", ")", "\n", "# reorganize by clip", "\n", "data_list", "=", "[", "]", "\n", "for", "v", "in", "new_data_list", ":", "\n", "            ", "for", "x", "in", "v", ":", "\n", "                ", "data_list", ".", "append", "(", "x", ")", "\n", "", "", "return", "data_list", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_class_ordering", "(", "data_list", ",", "class_type", ",", "seed", ")", ":", "\n", "# organize data by class", "\n", "        ", "new_data_list", "=", "[", "]", "\n", "for", "class_id", "in", "range", "(", "data_list", "[", "-", "1", "]", "[", "0", "]", "+", "1", ")", ":", "\n", "            ", "class_data_list", "=", "[", "x", "for", "x", "in", "data_list", "if", "x", "[", "0", "]", "==", "class_id", "]", "\n", "if", "class_type", "==", "'class_iid'", ":", "\n", "# shuffle all class data", "\n", "                ", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "class_data_list", ")", "\n", "", "else", ":", "\n", "# shuffle clips within class", "\n", "                ", "class_data_list", "=", "Stream51", ".", "_instance_ordering", "(", "\n", "class_data_list", ",", "seed", ")", "\n", "", "new_data_list", ".", "append", "(", "class_data_list", ")", "\n", "# shuffle classes", "\n", "", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "new_data_list", ")", "\n", "# reorganize by class", "\n", "data_list", "=", "[", "]", "\n", "for", "v", "in", "new_data_list", ":", "\n", "            ", "for", "x", "in", "v", ":", "\n", "                ", "data_list", ".", "append", "(", "x", ")", "\n", "", "", "return", "data_list", "\n", "\n", "", "@", "staticmethod", "\n", "def", "make_dataset", "(", "data_list", ",", "ordering", "=", "'class_instance'", ",", "seed", "=", "666", ")", ":", "\n", "        ", "\"\"\"\n        data_list\n        for train: [class_id, clip_num, video_num, frame_num, bbox, file_loc]\n        for test: [class_id, bbox, file_loc]\n        \"\"\"", "\n", "if", "not", "ordering", "or", "len", "(", "data_list", "[", "0", "]", ")", "==", "3", ":", "# cannot order the test set", "\n", "            ", "return", "data_list", "\n", "", "if", "ordering", "not", "in", "[", "'iid'", ",", "'class_iid'", ",", "'instance'", ",", "'class_instance'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'dataset ordering must be one of: \"iid\", \"class_iid\", '", "\n", "'\"instance\", or \"class_instance\"'", ")", "\n", "", "if", "ordering", "==", "'iid'", ":", "\n", "# shuffle all data", "\n", "            ", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "shuffle", "(", "data_list", ")", "\n", "return", "data_list", "\n", "", "elif", "ordering", "==", "'instance'", ":", "\n", "            ", "return", "Stream51", ".", "_instance_ordering", "(", "data_list", ",", "seed", ")", "\n", "", "elif", "'class'", "in", "ordering", ":", "\n", "            ", "return", "Stream51", ".", "_class_ordering", "(", "data_list", ",", "ordering", ",", "seed", ")", "\n", "\n", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target\n            class.\n        \"\"\"", "\n", "fpath", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "[", "-", "1", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "str", "(", "self", ".", "root", "/", "fpath", ")", ")", "\n", "if", "self", ".", "bbox_crop", ":", "\n", "            ", "bbox", "=", "self", ".", "samples", "[", "index", "]", "[", "-", "2", "]", "\n", "cw", "=", "bbox", "[", "0", "]", "-", "bbox", "[", "1", "]", "\n", "ch", "=", "bbox", "[", "2", "]", "-", "bbox", "[", "3", "]", "\n", "center", "=", "[", "int", "(", "bbox", "[", "1", "]", "+", "cw", "/", "2", ")", ",", "int", "(", "bbox", "[", "3", "]", "+", "ch", "/", "2", ")", "]", "\n", "bbox", "=", "[", "\n", "min", "(", "[", "int", "(", "center", "[", "0", "]", "+", "(", "cw", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "sample", ".", "size", "[", "0", "]", "]", ")", ",", "\n", "max", "(", "[", "int", "(", "center", "[", "0", "]", "-", "(", "cw", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "0", "]", ")", ",", "\n", "min", "(", "[", "int", "(", "center", "[", "1", "]", "+", "(", "ch", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "sample", ".", "size", "[", "1", "]", "]", ")", ",", "\n", "max", "(", "[", "int", "(", "center", "[", "1", "]", "-", "(", "ch", "*", "self", ".", "ratio", "/", "2", ")", ")", ",", "0", "]", ")", "]", "\n", "sample", "=", "sample", ".", "crop", "(", "(", "bbox", "[", "1", "]", ",", "\n", "bbox", "[", "3", "]", ",", "\n", "bbox", "[", "0", "]", ",", "\n", "bbox", "[", "2", "]", ")", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "sample", ",", "target", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "\n", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "\n", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "\n", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar10.SplitCIFAR10": [[36, 136], ["ccifar10._get_cifar10_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar10._get_cifar10_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitCIFAR10", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "first_exp_with_half_classes", ":", "bool", "=", "False", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_cifar10_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_cifar10_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the CIFAR10 dataset.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences in the current benchmark.\n        The value of this parameter should be a divisor of 10 if\n        `first_task_with_half_classes` is False, a divisor of 5 otherwise.\n    :param first_exp_with_half_classes: A boolean value that indicates if a\n        first pretraining step containing half of the classes should be used.\n        If it's True, the first experience will use half of the classes (5 for\n        cifar10). If this parameter is False, no pretraining step will be\n        used and the dataset is simply split into a the number of experiences\n        defined by the parameter n_experiences. Defaults to False.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If not None, the ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default eval transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'cifar10' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "cifar_train", ",", "cifar_test", "=", "_get_cifar10_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "cifar_train", ",", "\n", "test_dataset", "=", "cifar_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "per_exp_classes", "=", "{", "0", ":", "5", "}", "if", "first_exp_with_half_classes", "else", "None", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "cifar_train", ",", "\n", "test_dataset", "=", "cifar_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "per_exp_classes", "=", "{", "0", ":", "5", "}", "if", "first_exp_with_half_classes", "else", "None", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ccifar10._get_cifar10_dataset": [[138, 146], ["torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR10", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.torchvision_wrapper.CIFAR10", "home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "", "def", "_get_cifar10_dataset", "(", "dataset_root", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'cifar10'", ")", "\n", "\n", "", "train_set", "=", "CIFAR10", "(", "dataset_root", ",", "train", "=", "True", ",", "download", "=", "True", ")", "\n", "test_set", "=", "CIFAR10", "(", "dataset_root", ",", "train", "=", "False", ",", "download", "=", "True", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot.PixelsPermutation.__init__": [[44, 48], ["torchvision.transforms.ToTensor", "torchvision.transforms.ToPILImage"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index_permutation", ":", "Sequence", "[", "int", "]", ")", ":", "\n", "        ", "self", ".", "permutation", "=", "index_permutation", "\n", "self", ".", "_to_tensor", "=", "ToTensor", "(", ")", "\n", "self", ".", "_to_image", "=", "ToPILImage", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot.PixelsPermutation.__call__": [[49, 63], ["isinstance", "[].view", "ValueError", "comniglot.PixelsPermutation._to_tensor", "comniglot.PixelsPermutation._to_image", "isinstance", "comniglot.PixelsPermutation.view"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ":", "Union", "[", "Image", ",", "Tensor", "]", ")", ":", "\n", "        ", "is_image", "=", "isinstance", "(", "img", ",", "Image", ")", "\n", "if", "(", "not", "is_image", ")", "and", "(", "not", "isinstance", "(", "img", ",", "Tensor", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid input: must be a PIL image or a Tensor'", ")", "\n", "\n", "", "if", "is_image", ":", "\n", "            ", "img", "=", "self", ".", "_to_tensor", "(", "img", ")", "\n", "\n", "", "img", "=", "img", ".", "view", "(", "-", "1", ")", "[", "self", ".", "permutation", "]", ".", "view", "(", "*", "img", ".", "shape", ")", "\n", "\n", "if", "is_image", ":", "\n", "            ", "img", "=", "self", ".", "_to_image", "(", "img", ")", "\n", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot.SplitOmniglot": [[65, 159], ["comniglot._get_omniglot_dataset", "avalanche.benchmarks.nc_benchmark", "avalanche.benchmarks.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot._get_omniglot_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["", "", "def", "SplitOmniglot", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "fixed_class_order", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_omniglot_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_omniglot_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the OMNIGLOT dataset.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc.\n\n    By default, an equal amount of classes will be assigned to each experience.\n    OMNIGLOT consists of 964 classes, which means that the number of\n    experiences can be 1, 2, 4, 241, 482, 964.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of incremental experiences in the current\n        benchmark. The value of this parameter should be a divisor of 10.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'omniglot' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "omniglot_train", ",", "omniglot_test", "=", "_get_omniglot_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "omniglot_train", ",", "\n", "test_dataset", "=", "omniglot_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "omniglot_train", ",", "\n", "test_dataset", "=", "omniglot_test", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot.PermutedOmniglot": [[161, 256], ["numpy.random.RandomState", "comniglot._get_omniglot_dataset", "range", "avalanche.benchmarks.nc_benchmark", "torch.from_numpy().type", "comniglot.PixelsPermutation", "dict", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "list_train_dataset.append", "list_test_dataset.append", "len", "torch.from_numpy", "avalanche.benchmarks.utils.AvalancheDataset", "avalanche.benchmarks.utils.AvalancheDataset", "np.random.RandomState.permutation"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot._get_omniglot_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms"], ["", "", "def", "PermutedOmniglot", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_omniglot_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_omniglot_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    Creates a Permuted Omniglot benchmark.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    Random pixel permutations are used to permute the Omniglot images in\n    ``n_experiences`` different manners. This means that each experience is\n    composed of all the original 964 Omniglot classes, but the pixel in the\n    images are permuted in a different way.\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    A progressive task label, starting from \"0\", is applied to each experience.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences (tasks) in the current\n        benchmark. It indicates how many different permutations of the Omniglot\n        dataset have to be created.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param train_transform: The transformation to apply to the training data\n        before the random permutation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data\n        before the random permutation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'omniglot' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "list_train_dataset", "=", "[", "]", "\n", "list_test_dataset", "=", "[", "]", "\n", "rng_permute", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "omniglot_train", ",", "omniglot_test", "=", "_get_omniglot_dataset", "(", "dataset_root", ")", "\n", "\n", "# for every incremental experience", "\n", "for", "_", "in", "range", "(", "n_experiences", ")", ":", "\n", "# choose a random permutation of the pixels in the image", "\n", "        ", "idx_permute", "=", "torch", ".", "from_numpy", "(", "rng_permute", ".", "permutation", "(", "11025", ")", ")", ".", "type", "(", "\n", "torch", ".", "int64", ")", "\n", "\n", "permutation", "=", "PixelsPermutation", "(", "idx_permute", ")", "\n", "\n", "permutation_transforms", "=", "dict", "(", "\n", "train", "=", "(", "permutation", ",", "None", ")", ",", "\n", "eval", "=", "(", "permutation", ",", "None", ")", "\n", ")", "\n", "\n", "# Freeze the permutation", "\n", "permuted_train", "=", "AvalancheDataset", "(", "\n", "omniglot_train", ",", "\n", "transform_groups", "=", "permutation_transforms", ",", "\n", "initial_transform_group", "=", "'train'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "permuted_test", "=", "AvalancheDataset", "(", "\n", "omniglot_test", ",", "\n", "transform_groups", "=", "permutation_transforms", ",", "\n", "initial_transform_group", "=", "'eval'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "list_train_dataset", ".", "append", "(", "permuted_train", ")", "\n", "list_test_dataset", ".", "append", "(", "permuted_test", ")", "\n", "\n", "", "return", "nc_benchmark", "(", "\n", "list_train_dataset", ",", "\n", "list_test_dataset", ",", "\n", "n_experiences", "=", "len", "(", "list_train_dataset", ")", ",", "\n", "task_labels", "=", "True", ",", "\n", "shuffle", "=", "False", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "one_dataset_per_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot.RotatedOmniglot": [[258, 371], ["all", "comniglot._get_omniglot_dataset", "range", "avalanche.benchmarks.nc_benchmark", "numpy.random.RandomState", "torchvision.transforms.RandomRotation", "dict", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "avalanche.benchmarks.utils.AvalancheDataset().freeze_transforms", "list_train_dataset.append", "list_test_dataset.append", "np.random.RandomState.randint", "len", "len", "range", "range", "avalanche.benchmarks.utils.AvalancheDataset", "avalanche.benchmarks.utils.AvalancheDataset", "len"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot._get_omniglot_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms", "home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.freeze_transforms"], ["", "def", "RotatedOmniglot", "(", "\n", "n_experiences", ":", "int", ",", "\n", "*", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "rotations_list", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_omniglot_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_omniglot_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "NCScenario", ":", "\n", "    ", "\"\"\"\n    Creates a Rotated Omniglot benchmark.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    Random angles are used to rotate the Omniglot images in ``n_experiences``\n    different manners. This means that each experience is\n    composed of all the original 964 Omniglot classes, but each image is\n    rotated in a different way.\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    A progressive task label, starting from \"0\", is applied to each experience.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences (tasks) in the current\n        benchmark. It indicates how many different rotations of the Omniglot\n        dataset have to be created.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param rotations_list: A list of rotations values in degrees (from -180 to\n        180) used to define the rotations. The rotation specified in position\n        0 of the list will be applied to the task 0, the rotation specified in\n        position 1 will be applied to task 1 and so on.\n        If None, value of ``seed`` will be used to define the rotations.\n        If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param train_transform: The transformation to apply to the training data\n        after the random rotation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data\n        after the random rotation, e.g. a random crop, a normalization or a\n        concatenation of different transformations (see torchvision.transform\n        documentation for a comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset. Defaults to None, which\n        means that the default location for 'omniglot' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "if", "rotations_list", "is", "None", ":", "\n", "        ", "rng_rotate", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "rotations_list", "=", "[", "rng_rotate", ".", "randint", "(", "-", "180", ",", "181", ")", "for", "_", "in", "range", "(", "\n", "n_experiences", ")", "]", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "rotations_list", ")", "==", "n_experiences", ",", "\"The number of rotations\"", "\" should match the number\"", "\" of incremental experiences.\"", "\n", "", "assert", "all", "(", "-", "180", "<=", "rotations_list", "[", "i", "]", "<=", "180", "\n", "for", "i", "in", "range", "(", "len", "(", "rotations_list", ")", ")", ")", ",", "\"The value of a rotation\"", "\" should be between -180\"", "\" and 180 degrees.\"", "\n", "\n", "list_train_dataset", "=", "[", "]", "\n", "list_test_dataset", "=", "[", "]", "\n", "\n", "omniglot_train", ",", "omniglot_test", "=", "_get_omniglot_dataset", "(", "dataset_root", ")", "\n", "\n", "# for every incremental experience", "\n", "for", "experience", "in", "range", "(", "n_experiences", ")", ":", "\n", "        ", "rotation_angle", "=", "rotations_list", "[", "experience", "]", "\n", "\n", "rotation", "=", "RandomRotation", "(", "degrees", "=", "(", "rotation_angle", ",", "rotation_angle", ")", ")", "\n", "\n", "rotation_transforms", "=", "dict", "(", "\n", "train", "=", "(", "rotation", ",", "None", ")", ",", "\n", "eval", "=", "(", "rotation", ",", "None", ")", "\n", ")", "\n", "\n", "# Freeze the rotation", "\n", "rotated_train", "=", "AvalancheDataset", "(", "\n", "omniglot_train", ",", "\n", "transform_groups", "=", "rotation_transforms", ",", "\n", "initial_transform_group", "=", "'train'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "rotated_test", "=", "AvalancheDataset", "(", "\n", "omniglot_test", ",", "\n", "transform_groups", "=", "rotation_transforms", ",", "\n", "initial_transform_group", "=", "'eval'", ")", ".", "freeze_transforms", "(", ")", "\n", "\n", "list_train_dataset", ".", "append", "(", "rotated_train", ")", "\n", "list_test_dataset", ".", "append", "(", "rotated_test", ")", "\n", "\n", "", "return", "nc_benchmark", "(", "\n", "list_train_dataset", ",", "\n", "list_test_dataset", ",", "\n", "n_experiences", "=", "len", "(", "list_train_dataset", ")", ",", "\n", "task_labels", "=", "True", ",", "\n", "shuffle", "=", "False", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "one_dataset_per_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.comniglot._get_omniglot_dataset": [[373, 381], ["avalanche.benchmarks.datasets.omniglot.Omniglot", "avalanche.benchmarks.datasets.omniglot.Omniglot", "avalanche.benchmarks.datasets.default_dataset_location"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.datasets.dataset_utils.default_dataset_location"], ["", "def", "_get_omniglot_dataset", "(", "dataset_root", ")", ":", "\n", "    ", "if", "dataset_root", "is", "None", ":", "\n", "        ", "dataset_root", "=", "default_dataset_location", "(", "'omniglot'", ")", "\n", "\n", "", "train", "=", "Omniglot", "(", "root", "=", "dataset_root", ",", "train", "=", "True", ",", "download", "=", "True", ")", "\n", "test", "=", "Omniglot", "(", "root", "=", "dataset_root", ",", "train", "=", "False", ",", "download", "=", "True", ")", "\n", "\n", "return", "train", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.openloris.OpenLORIS": [[45, 117], ["avalanche.benchmarks.datasets.openloris.OpenLORIS", "range", "avalanche.benchmarks.scenarios.generic_benchmark_creation.create_generic_benchmark_from_filelists", "nbatch.keys", "train_failists_paths.append", "range", "str().zfill", "str"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.openloris.OpenLORIS", "home.repos.pwc.inspect_result.mattdl_continualevaluation.scenarios.generic_benchmark_creation.create_generic_benchmark_from_filelists"], ["\n", "\n", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "default_dataset_location", "(", "'openloris'", ")", "\n", "\n", "", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "\n", "super", "(", "OpenLORIS", ",", "self", ")", ".", "__init__", "(", "root", ",", "download", "=", "download", ",", "verbose", "=", "True", ")", "\n", "self", ".", "_load_dataset", "(", ")", "\n", "\n", "", "def", "_download_dataset", "(", "self", ")", "->", "None", ":", "\n", "        ", "data2download", "=", "openloris_data", ".", "avl_vps_data", "\n", "\n", "for", "name", "in", "data2download", ":", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "\"Downloading \"", "+", "name", "[", "1", "]", "+", "\"...\"", ")", "\n", "", "file", "=", "self", ".", "_download_file", "(", "name", "[", "1", "]", ",", "name", "[", "0", "]", ",", "name", "[", "2", "]", ")", "\n", "if", "name", "[", "1", "]", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "                ", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "f'Extracting {name[0]}...'", ")", "\n", "", "self", ".", "_extract_archive", "(", "file", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "print", "(", "'Extraction completed!'", ")", "\n", "\n", "", "", "", "", "def", "_load_metadata", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "# any scenario and factor is good here since we want just to load the", "\n", "# train images and targets with no particular order", "\n", "", "scen", "=", "'domain'", "\n", "factor", "=", "0", "\n", "ntask", "=", "9", "\n", "\n", "print", "(", "\"Loading paths...\"", ")", "\n", "with", "open", "(", "str", "(", "self", ".", "root", "/", "'Paths.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "train_test_paths", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "print", "(", "\"Loading labels...\"", ")", "\n", "with", "open", "(", "str", "(", "self", ".", "root", "/", "'Labels.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "all_targets", "=", "pkl", ".", "load", "(", "f", ")", "\n", "self", ".", "train_test_targets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ntask", "+", "1", ")", ":", "\n", "                ", "self", ".", "train_test_targets", "+=", "self", ".", "all_targets", "[", "scen", "]", "[", "factor", "]", "[", "i", "]", "\n", "\n", "", "", "print", "(", "\"Loading LUP...\"", ")", "\n", "with", "open", "(", "str", "(", "self", ".", "root", "/", "'LUP.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "LUP", "=", "pkl", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "idx_list", "=", "[", "]", "\n", "if", "self", ".", "train", ":", "\n", "            ", "for", "i", "in", "range", "(", "ntask", "+", "1", ")", ":", "\n", "                ", "self", ".", "idx_list", "+=", "self", ".", "LUP", "[", "scen", "]", "[", "factor", "]", "[", "i", "]", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "idx_list", "=", "self", ".", "LUP", "[", "scen", "]", "[", "factor", "]", "[", "-", "1", "]", "\n", "\n", "", "self", ".", "paths", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n", "for", "idx", "in", "self", ".", "idx_list", ":", "\n", "            ", "self", ".", "paths", ".", "append", "(", "self", ".", "train_test_paths", "[", "idx", "]", ")", "\n", "self", ".", "targets", ".", "append", "(", "self", ".", "train_test_targets", "[", "idx", "]", ")", "\n", "\n", "", "return", "True", "\n", "\n", "", "def", "_download_error_message", "(", "self", ")", "->", "str", ":", "\n", "        ", "base_url", "=", "openloris_data", ".", "base_gdrive_url", "\n", "all_urls", "=", "[", "\n", "base_url", "+", "name_url", "[", "1", "]", "for", "name_url", "in", "openloris_data", ".", "avl_vps_data", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ctiny_imagenet.SplitTinyImageNet": [[36, 127], ["ctiny_imagenet._get_tiny_imagenet_dataset", "avalanche.benchmarks.generators.nc_benchmark", "avalanche.benchmarks.generators.nc_benchmark"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ctiny_imagenet._get_tiny_imagenet_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark", "home.repos.pwc.inspect_result.mattdl_continualevaluation.generators.benchmark_generators.nc_benchmark"], ["def", "SplitTinyImageNet", "(", "\n", "n_experiences", "=", "10", ",", "\n", "*", ",", "\n", "return_task_id", "=", "False", ",", "\n", "seed", "=", "0", ",", "\n", "fixed_class_order", "=", "None", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "train_transform", ":", "Optional", "[", "Any", "]", "=", "_default_train_transform", ",", "\n", "eval_transform", ":", "Optional", "[", "Any", "]", "=", "_default_eval_transform", ",", "\n", "dataset_root", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a CL benchmark using the Tiny ImageNet dataset.\n\n    If the dataset is not present in the computer, this method will\n    automatically download and store it.\n\n    The returned benchmark will return experiences containing all patterns of a\n    subset of classes, which means that each class is only seen \"once\".\n    This is one of the most common scenarios in the Continual Learning\n    literature. Common names used in literature to describe this kind of\n    scenario are \"Class Incremental\", \"New Classes\", etc. By default,\n    an equal amount of classes will be assigned to each experience.\n\n    This generator doesn't force a choice on the availability of task labels,\n    a choice that is left to the user (see the `return_task_id` parameter for\n    more info on task labels).\n\n    The benchmark instance returned by this method will have two fields,\n    `train_stream` and `test_stream`, which can be iterated to obtain\n    training and test :class:`Experience`. Each Experience contains the\n    `dataset` and the associated task label.\n\n    The benchmark API is quite simple and is uniform across all benchmark\n    generators. It is recommended to check the tutorial of the \"benchmark\" API,\n    which contains usage examples ranging from \"basic\" to \"advanced\".\n\n    :param n_experiences: The number of experiences in the current benchmark.\n    :param return_task_id: if True, a progressive task id is returned for every\n        experience. If False, all experiences will have a task ID of 0.\n    :param seed: A valid int used to initialize the random number generator.\n        Can be None.\n    :param fixed_class_order: A list of class IDs used to define the class\n        order. If None, value of ``seed`` will be used to define the class\n        order. If non-None, ``seed`` parameter will be ignored.\n        Defaults to None.\n    :param shuffle: If true, the class order in the incremental experiences is\n        randomly shuffled. Default to false.\n    :param train_transform: The transformation to apply to the training data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default train transformation\n        will be used.\n    :param eval_transform: The transformation to apply to the test data,\n        e.g. a random crop, a normalization or a concatenation of different\n        transformations (see torchvision.transform documentation for a\n        comprehensive list of possible transformations).\n        If no transformation is passed, the default test transformation\n        will be used.\n    :param dataset_root: The root path of the dataset.\n        Defaults to None, which means that the default location for\n        'tinyimagenet' will be used.\n\n    :returns: A properly initialized :class:`NCScenario` instance.\n    \"\"\"", "\n", "\n", "train_set", ",", "test_set", "=", "_get_tiny_imagenet_dataset", "(", "dataset_root", ")", "\n", "\n", "if", "return_task_id", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "True", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "class_ids_from_zero_in_each_exp", "=", "True", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "", "else", ":", "\n", "        ", "return", "nc_benchmark", "(", "\n", "train_dataset", "=", "train_set", ",", "\n", "test_dataset", "=", "test_set", ",", "\n", "n_experiences", "=", "n_experiences", ",", "\n", "task_labels", "=", "False", ",", "\n", "seed", "=", "seed", ",", "\n", "fixed_class_order", "=", "fixed_class_order", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "train_transform", "=", "train_transform", ",", "\n", "eval_transform", "=", "eval_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.classic.ctiny_imagenet._get_tiny_imagenet_dataset": [[129, 135], ["avalanche.benchmarks.datasets.TinyImagenet", "avalanche.benchmarks.datasets.TinyImagenet"], "function", ["None"], ["", "", "def", "_get_tiny_imagenet_dataset", "(", "dataset_root", ")", ":", "\n", "    ", "train_set", "=", "TinyImagenet", "(", "root", "=", "dataset_root", ",", "train", "=", "True", ")", "\n", "\n", "test_set", "=", "TinyImagenet", "(", "root", "=", "dataset_root", ",", "train", "=", "False", ")", "\n", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.tensorboard_logger.TensorboardLogger.__init__": [[48, 63], ["avalanche.logging.StrategyLogger.__init__", "tensorboard_logger._make_path_if_local", "torch.utils.tensorboard.SummaryWriter"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.tensorboard_logger._make_path_if_local"], ["def", "__init__", "(", "self", ",", "tb_log_dir", ":", "Union", "[", "str", ",", "Path", "]", "=", "\"./tb_data\"", ",", "\n", "filename_suffix", ":", "str", "=", "''", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the `TensorboardLogger`.\n\n        :param tb_log_dir: path to the directory where tensorboard log file\n            will be stored. Default to \"./tb_data\".\n        :param filename_suffix: string suffix to append at the end of\n            tensorboard log file. Default ''.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "tb_log_dir", "=", "_make_path_if_local", "(", "tb_log_dir", ")", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "tb_log_dir", ",", "\n", "filename_suffix", "=", "filename_suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.tensorboard_logger.TensorboardLogger.__del__": [[64, 66], ["tensorboard_logger.TensorboardLogger.writer.close"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.tensorboard_logger.TensorboardLogger.log_single_metric": [[67, 91], ["isinstance", "isinstance", "value.best_supported_value.best_supported_value.best_supported_value", "tensorboard_logger.TensorboardLogger.writer.add_figure", "isinstance", "tensorboard_logger.TensorboardLogger.writer.add_image", "isinstance", "torchvision.transforms.functional.to_tensor", "tensorboard_logger.TensorboardLogger.writer.add_histogram", "isinstance", "tensorboard_logger.TensorboardLogger.writer.add_scalar", "isinstance", "tensorboard_logger.TensorboardLogger.writer.add_image"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_results.AlternativeValues.best_supported_value"], ["", "def", "log_single_metric", "(", "self", ",", "name", ",", "value", ",", "x_plot", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "AlternativeValues", ")", ":", "\n", "            ", "value", "=", "value", ".", "best_supported_value", "(", "Image", ",", "Tensor", ",", "TensorImage", ",", "\n", "Figure", ",", "float", ",", "int", ")", "\n", "\n", "", "if", "isinstance", "(", "value", ",", "Figure", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_figure", "(", "name", ",", "value", ",", "\n", "global_step", "=", "x_plot", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Image", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_image", "(", "name", ",", "to_tensor", "(", "value", ")", ",", "\n", "global_step", "=", "x_plot", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Tensor", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_histogram", "(", "name", ",", "value", ",", "\n", "global_step", "=", "x_plot", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_scalar", "(", "name", ",", "value", ",", "\n", "global_step", "=", "x_plot", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "TensorImage", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_image", "(", "name", ",", "value", ".", "image", ",", "\n", "global_step", "=", "x_plot", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.tensorboard_logger._make_path_if_local": [[93, 100], ["pathlib.Path", "pathlib.Path.mkdir", "isinstance", "tensorboard_logger._is_aws_or_gcloud_path"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.tensorboard_logger._is_aws_or_gcloud_path"], ["", "", "", "def", "_make_path_if_local", "(", "tb_log_dir", ":", "Union", "[", "str", ",", "Path", "]", ")", "->", "Union", "[", "str", ",", "Path", "]", ":", "\n", "    ", "if", "isinstance", "(", "tb_log_dir", ",", "str", ")", "and", "_is_aws_or_gcloud_path", "(", "tb_log_dir", ")", ":", "\n", "        ", "return", "tb_log_dir", "\n", "\n", "", "tb_log_dir", "=", "Path", "(", "tb_log_dir", ")", "\n", "tb_log_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "return", "tb_log_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.tensorboard_logger._is_aws_or_gcloud_path": [[102, 104], ["tb_log_dir.startswith", "tb_log_dir.startswith"], "function", ["None"], ["", "def", "_is_aws_or_gcloud_path", "(", "tb_log_dir", ":", "str", ")", "->", "bool", ":", "\n", "    ", "return", "tb_log_dir", ".", "startswith", "(", "\"gs://\"", ")", "or", "tb_log_dir", ".", "startswith", "(", "\"s3://\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.__init__": [[46, 84], ["avalanche.logging.StrategyLogger.__init__", "wandb_logger.WandBLogger.import_wandb", "wandb_logger.WandBLogger.args_parse", "wandb_logger.WandBLogger.before_run"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.import_wandb", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.args_parse", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.before_run"], ["def", "__init__", "(", "self", ",", "project_name", ":", "str", "=", "\"Avalanche\"", ",", "group_name", ":", "str", "=", "\"Group_Seeds\"", ",", "\n", "run_name", ":", "str", "=", "\"Test\"", ",", "log_artifacts", ":", "bool", "=", "False", ",", "\n", "path", ":", "Union", "[", "str", ",", "Path", "]", "=", "\"Checkpoints\"", ",", "\n", "uri", ":", "str", "=", "None", ",", "sync_tfboard", ":", "bool", "=", "False", ",", "\n", "save_code", ":", "bool", "=", "True", ",", "config", ":", "object", "=", "None", ",", "\n", "dir", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ",", "params", ":", "dict", "=", "None", ",", "\n", "reinit", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the `WandBLogger`.\n        :param project_name: Name of the W&B project.\n        :param run_name: Name of the W&B run.\n        :param log_artifacts: Option to log model weights as W&B Artifacts.\n        :param path: Path to locally save the model checkpoints.\n        :param uri: URI identifier for external storage buckets (GCS, S3).\n        :param sync_tfboard: Syncs TensorBoard to the W&B dashboard UI.\n        :param save_code: Saves the main training script to W&B. \n        :param config: Syncs hyper-parameters and config values used to W&B.\n        :param dir: Path to the local log directory for W&B logs to be saved at.\n        :param params: All arguments for wandb.init() function call. \n         Visit https://docs.wandb.ai/ref/python/init to learn about all \n         wand.init() parameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "import_wandb", "(", ")", "\n", "self", ".", "project_name", "=", "project_name", "\n", "self", ".", "run_name", "=", "run_name", "\n", "self", ".", "log_artifacts", "=", "log_artifacts", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "uri", "=", "uri", "\n", "self", ".", "sync_tfboard", "=", "sync_tfboard", "\n", "self", ".", "save_code", "=", "save_code", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "dir", "=", "dir", "\n", "self", ".", "group_name", "=", "group_name", "\n", "self", ".", "reinit", "=", "reinit", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "args_parse", "(", ")", "\n", "self", ".", "before_run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.import_wandb": [[85, 92], ["ImportError"], "methods", ["None"], ["", "def", "import_wandb", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "wandb", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please run \"pip install wandb\" to install wandb'", ")", "\n", "", "self", ".", "wandb", "=", "wandb", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.args_parse": [[93, 102], ["wandb_logger.WandBLogger.init_kwargs.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "args_parse", "(", "self", ")", ":", "\n", "        ", "self", ".", "init_kwargs", "=", "{", "\"project\"", ":", "self", ".", "project_name", ",", "\"name\"", ":", "self", ".", "run_name", ",", "\n", "\"group\"", ":", "self", ".", "group_name", ",", "\n", "\"sync_tensorboard\"", ":", "self", ".", "sync_tfboard", ",", "\n", "\"dir\"", ":", "self", ".", "dir", ",", "\"save_code\"", ":", "self", ".", "save_code", ",", "\n", "\"config\"", ":", "self", ".", "config", ",", "\n", "\"reinit\"", ":", "self", ".", "reinit", "}", "\n", "if", "self", ".", "params", ":", "\n", "            ", "self", ".", "init_kwargs", ".", "update", "(", "self", ".", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.before_run": [[103, 111], ["wandb_logger.WandBLogger.wandb.run._label", "wandb_logger.WandBLogger.import_wandb", "wandb_logger.WandBLogger.wandb.init", "wandb_logger.WandBLogger.wandb.init"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.import_wandb"], ["", "", "def", "before_run", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "wandb", "is", "None", ":", "\n", "            ", "self", ".", "import_wandb", "(", ")", "\n", "", "if", "self", ".", "init_kwargs", ":", "\n", "            ", "self", ".", "wandb", ".", "init", "(", "**", "self", ".", "init_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wandb", ".", "init", "(", ")", "\n", "", "self", ".", "wandb", ".", "run", ".", "_label", "(", "repo", "=", "\"Avalanche\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.finish": [[112, 116], ["wandb_logger.WandBLogger.wandb.run.finish"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.finish"], ["", "def", "finish", "(", "self", ")", ":", "\n", "        ", "\"\"\"See: https://docs.wandb.ai/guides/track/launch#how-do-i-launch-multiple-runs-from-one-script\n        For launching multiple runs in 1 script (e.g. multiple seeds).\"\"\"", "\n", "self", ".", "wandb", ".", "run", ".", "finish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.wandb_logger.WandBLogger.log_single_metric": [[117, 162], ["isinstance", "isinstance", "numpy.histogram.best_supported_value", "isinstance", "wandb_logger.WandBLogger.wandb.log", "isinstance", "numpy.histogram", "wandb_logger.WandBLogger.wandb.log", "isinstance", "wandb_logger.WandBLogger.wandb.Image", "numpy.histogram.view().numpy", "wandb_logger.WandBLogger.wandb.log", "isinstance", "wandb_logger.WandBLogger.wandb.Histogram", "wandb_logger.WandBLogger.wandb.log", "os.path.splittext.startswith", "numpy.histogram.view", "wandb_logger.WandBLogger.wandb.Image", "os.getcwd", "os.path.join", "os.path.join", "os.path.join", "isinstance", "numpy.array", "os.makedirs", "torch.save", "os.path.splittext", "wandb_logger.WandBLogger.wandb.Artifact", "wandb_logger.WandBLogger.add_file", "wandb_logger.WandBLogger.wandb.run.log_artifact", "wandb_logger.WandBLogger.add_reference"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_results.AlternativeValues.best_supported_value"], ["", "def", "log_single_metric", "(", "self", ",", "name", ",", "value", ",", "x_plot", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "AlternativeValues", ")", ":", "\n", "            ", "value", "=", "value", ".", "best_supported_value", "(", "Image", ",", "Tensor", ",", "TensorImage", ",", "\n", "Figure", ",", "float", ",", "int", ",", "\n", "self", ".", "wandb", ".", "viz", ".", "CustomChart", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "value", ",", "(", "Image", ",", "Tensor", ",", "Figure", ",", "float", ",", "int", ",", "\n", "self", ".", "wandb", ".", "viz", ".", "CustomChart", ")", ")", ":", "\n", "# Unsupported type", "\n", "            ", "return", "\n", "\n", "", "if", "isinstance", "(", "value", ",", "Image", ")", ":", "\n", "            ", "self", ".", "wandb", ".", "log", "(", "{", "name", ":", "self", ".", "wandb", ".", "Image", "(", "value", ")", "}", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "Tensor", ")", ":", "\n", "            ", "value", "=", "np", ".", "histogram", "(", "value", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "wandb", ".", "log", "(", "{", "name", ":", "self", ".", "wandb", ".", "Histogram", "(", "np_histogram", "=", "value", ")", "}", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "(", "float", ",", "int", ",", "Figure", ",", "\n", "self", ".", "wandb", ".", "viz", ".", "CustomChart", ")", ")", ":", "\n", "            ", "self", ".", "wandb", ".", "log", "(", "{", "name", ":", "value", "}", ")", "\n", "\n", "", "elif", "isinstance", "(", "value", ",", "TensorImage", ")", ":", "\n", "            ", "self", ".", "wandb", ".", "log", "(", "{", "name", ":", "self", ".", "wandb", ".", "Image", "(", "array", "(", "value", ")", ")", "}", ")", "\n", "\n", "", "elif", "name", ".", "startswith", "(", "\"WeightCheckpoint\"", ")", ":", "\n", "            ", "if", "self", ".", "log_artifacts", ":", "\n", "                ", "cwd", "=", "os", ".", "getcwd", "(", ")", "\n", "ckpt", "=", "os", ".", "path", ".", "join", "(", "cwd", ",", "self", ".", "path", ")", "\n", "try", ":", "\n", "                    ", "os", ".", "makedirs", "(", "ckpt", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "                    ", "if", "e", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "                        ", "raise", "\n", "", "", "suffix", "=", "'.pth'", "\n", "dir_name", "=", "os", ".", "path", ".", "join", "(", "ckpt", ",", "name", "+", "suffix", ")", "\n", "artifact_name", "=", "os", ".", "path", ".", "join", "(", "'Models'", ",", "name", "+", "suffix", ")", "\n", "if", "isinstance", "(", "value", ",", "Tensor", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "value", ",", "dir_name", ")", "\n", "name", "=", "os", ".", "path", ".", "splittext", "(", "self", ".", "checkpoint", ")", "\n", "artifact", "=", "self", ".", "wandb", ".", "Artifact", "(", "name", ",", "type", "=", "'model'", ")", "\n", "artifact", ".", "add_file", "(", "dir_name", ",", "name", "=", "artifact_name", ")", "\n", "self", ".", "wandb", ".", "run", ".", "log_artifact", "(", "artifact", ")", "\n", "if", "self", ".", "uri", "is", "not", "None", ":", "\n", "                        ", "artifact", ".", "add_reference", "(", "self", ".", "uri", ",", "name", "=", "artifact_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.__init__": [[32, 34], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_single_metric": [[35, 48], ["None"], "methods", ["None"], ["", "def", "log_single_metric", "(", "self", ",", "name", ",", "value", ",", "x_plot", ")", ":", "\n", "        ", "\"\"\"\n        This abstract method will have to be implemented by each subclass.\n        This method takes a metric name, a metric value and a x value and\n        decides how to show the metric value.\n\n        :param name: str, metric name\n        :param value: the metric value, will be ignored if\n            not supported by the logger\n        :param x_plot: an integer representing the x value\n            associated to the metric value\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric": [[49, 70], ["isinstance", "value.items", "strategy_logger.StrategyLogger.log_single_metric", "strategy_logger.StrategyLogger.log_single_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.log_single_metric", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.log_single_metric"], ["", "def", "log_metric", "(", "self", ",", "metric_value", ":", "'MetricValue'", ",", "callback", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        This method will be invoked on each callback.\n        The `callback` parameter describes the callback from which the metric\n        value is coming from.\n\n        :param metric_value: The value to be logged.\n        :param callback: The name of the callback (event) from which the\n            metric value was obtained.\n        :return: None\n        \"\"\"", "\n", "name", "=", "metric_value", ".", "name", "\n", "value", "=", "metric_value", ".", "value", "\n", "x_plot", "=", "metric_value", ".", "x_plot", "\n", "\n", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "value", ".", "items", "(", ")", ":", "\n", "                ", "n", "=", "f\"{name}/{k}\"", "\n", "self", ".", "log_single_metric", "(", "n", ",", "v", ",", "x_plot", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "log_single_metric", "(", "name", ",", "value", ",", "x_plot", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_training": [[71, 75], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_training'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_training_exp": [[76, 80], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_training_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_train_dataset_adaptation": [[81, 86], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'adapt_train_dataset'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_training_epoch": [[87, 91], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_training_epoch'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_training_iteration": [[92, 97], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_training_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_forward": [[98, 102], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_forward": [[103, 107], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_backward": [[108, 112], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_backward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_backward": [[113, 117], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_backward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_training_iteration": [[118, 122], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_training_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_update": [[123, 127], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_update'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_update": [[128, 132], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_update'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_training_epoch": [[133, 137], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_training_epoch'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_training_exp": [[138, 142], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_training_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_training": [[143, 147], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_training'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_eval": [[148, 152], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_eval_dataset_adaptation": [[153, 158], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'adapt_eval_dataset'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_eval_exp": [[159, 163], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_eval_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_eval_exp": [[164, 168], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_eval_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_eval": [[169, 173], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_eval_iteration": [[174, 178], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_eval_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.before_eval_forward": [[179, 183], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "before_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'before_eval_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_eval_forward": [[184, 188], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_eval_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.after_eval_iteration": [[189, 193], ["strategy_logger.StrategyLogger.log_metric"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.strategy_logger.StrategyLogger.log_metric"], ["", "", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "val", "in", "metric_values", ":", "\n", "            ", "self", ".", "log_metric", "(", "val", ",", "'after_eval_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger.__init__": [[51, 54], ["avalanche.logging.TextLogger.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "file", "=", "sys", ".", "stdout", ")", "\n", "self", ".", "_pbar", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger.before_training_epoch": [[55, 59], ["super().before_training_epoch", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_epoch", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "self", ".", "_progress", ".", "total", "=", "len", "(", "strategy", ".", "dataloader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger.after_training_epoch": [[60, 64], ["interactive_logging.InteractiveLogger._end_progress", "super().after_training_epoch"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger._end_progress", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.after_training_epoch"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_end_progress", "(", ")", "\n", "super", "(", ")", ".", "after_training_epoch", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger.before_eval_exp": [[65, 69], ["super().before_eval_exp", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval_exp"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval_exp", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "self", ".", "_progress", ".", "total", "=", "len", "(", "strategy", ".", "dataloader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger.after_eval_exp": [[70, 74], ["interactive_logging.InteractiveLogger._end_progress", "super().after_eval_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger._end_progress", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.after_eval_exp"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_end_progress", "(", ")", "\n", "super", "(", ")", ".", "after_eval_exp", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger.after_training_iteration": [[75, 80], ["interactive_logging.InteractiveLogger._progress.update", "interactive_logging.InteractiveLogger._progress.refresh", "super().after_training_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_progress", ".", "update", "(", ")", "\n", "self", ".", "_progress", ".", "refresh", "(", ")", "\n", "super", "(", ")", ".", "after_training_iteration", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger.after_eval_iteration": [[81, 86], ["interactive_logging.InteractiveLogger._progress.update", "interactive_logging.InteractiveLogger._progress.refresh", "super().after_eval_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_progress", ".", "update", "(", ")", "\n", "self", ".", "_progress", ".", "refresh", "(", ")", "\n", "super", "(", ")", ".", "after_eval_iteration", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger._progress": [[87, 92], ["tqdm.tqdm.tqdm"], "methods", ["None"], ["", "@", "property", "\n", "def", "_progress", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_pbar", "is", "None", ":", "\n", "            ", "self", ".", "_pbar", "=", "tqdm", "(", "leave", "=", "True", ",", "position", "=", "0", ",", "file", "=", "sys", ".", "stdout", ")", "\n", "", "return", "self", ".", "_pbar", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.interactive_logging.InteractiveLogger._end_progress": [[93, 97], ["interactive_logging.InteractiveLogger._pbar.close"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close"], ["", "def", "_end_progress", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_pbar", "is", "not", "None", ":", "\n", "            ", "self", ".", "_pbar", ".", "close", "(", ")", "\n", "self", ".", "_pbar", "=", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.__init__": [[58, 93], ["avalanche.logging.StrategyLogger.__init__", "os.makedirs", "open", "open", "os.makedirs", "print", "print", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "log_folder", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of `CSVLogger` class.\n\n        :param log_folder: folder in which to create log files.\n            If None, `csvlogs` folder in the default current directory\n            will be used.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "log_folder", "=", "log_folder", "if", "log_folder", "is", "not", "None", "else", "\"csvlogs\"", "\n", "os", ".", "makedirs", "(", "self", ".", "log_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "training_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "log_folder", ",", "\n", "'training_results.csv'", ")", ",", "'w'", ")", "\n", "self", ".", "eval_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "log_folder", ",", "\n", "'eval_results.csv'", ")", ",", "'w'", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "log_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# current training experience id", "\n", "self", ".", "training_exp_id", "=", "None", "\n", "\n", "# if we are currently training or evaluating", "\n", "# evaluation within training will not change this flag", "\n", "self", ".", "in_train_phase", "=", "None", "\n", "\n", "# validation metrics computed during training", "\n", "self", ".", "val_acc", ",", "self", ".", "val_loss", "=", "0", ",", "0", "\n", "\n", "# print csv headers", "\n", "print", "(", "'training_exp'", ",", "'epoch'", ",", "'training_accuracy'", ",", "'val_accuracy'", ",", "\n", "'training_loss'", ",", "'val_loss'", ",", "sep", "=", "','", ",", "file", "=", "self", ".", "training_file", ",", "\n", "flush", "=", "True", ")", "\n", "print", "(", "'eval_exp'", ",", "'training_exp'", ",", "'eval_accuracy'", ",", "'eval_loss'", ",", "\n", "'forgetting'", ",", "sep", "=", "','", ",", "file", "=", "self", ".", "eval_file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.log_single_metric": [[94, 96], ["None"], "methods", ["None"], ["", "def", "log_single_metric", "(", "self", ",", "name", ",", "value", ",", "x_plot", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger._val_to_str": [[97, 104], ["isinstance", "isinstance", "str", "str"], "methods", ["None"], ["", "def", "_val_to_str", "(", "self", ",", "m_val", ")", ":", "\n", "        ", "if", "isinstance", "(", "m_val", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "'\\n'", "+", "str", "(", "m_val", ")", "\n", "", "elif", "isinstance", "(", "m_val", ",", "float", ")", ":", "\n", "            ", "return", "f'{m_val:.4f}'", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "m_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.print_train_metrics": [[105, 111], ["print", "csv_logger.CSVLogger._val_to_str", "csv_logger.CSVLogger._val_to_str", "csv_logger.CSVLogger._val_to_str", "csv_logger.CSVLogger._val_to_str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str"], ["", "", "def", "print_train_metrics", "(", "self", ",", "training_exp", ",", "epoch", ",", "train_acc", ",", "\n", "val_acc", ",", "train_loss", ",", "val_loss", ")", ":", "\n", "        ", "print", "(", "training_exp", ",", "epoch", ",", "self", ".", "_val_to_str", "(", "train_acc", ")", ",", "\n", "self", ".", "_val_to_str", "(", "val_acc", ")", ",", "self", ".", "_val_to_str", "(", "train_loss", ")", ",", "\n", "self", ".", "_val_to_str", "(", "val_loss", ")", ",", "sep", "=", "','", ",", "\n", "file", "=", "self", ".", "training_file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.print_eval_metrics": [[112, 117], ["print", "csv_logger.CSVLogger._val_to_str", "csv_logger.CSVLogger._val_to_str", "csv_logger.CSVLogger._val_to_str"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str"], ["", "def", "print_eval_metrics", "(", "self", ",", "eval_exp", ",", "training_exp", ",", "eval_acc", ",", "\n", "eval_loss", ",", "forgetting", ")", ":", "\n", "        ", "print", "(", "eval_exp", ",", "training_exp", ",", "self", ".", "_val_to_str", "(", "eval_acc", ")", ",", "\n", "self", ".", "_val_to_str", "(", "eval_loss", ")", ",", "self", ".", "_val_to_str", "(", "forgetting", ")", ",", "\n", "sep", "=", "','", ",", "file", "=", "self", ".", "eval_file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.after_training_epoch": [[118, 133], ["super().after_training_epoch", "csv_logger.CSVLogger.print_train_metrics", "val.name.startswith", "val.name.startswith"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.after_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.print_train_metrics"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training_epoch", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "train_acc", ",", "val_acc", ",", "train_loss", ",", "val_loss", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "for", "val", "in", "metric_values", ":", "\n", "            ", "if", "'train_stream'", "in", "val", ".", "name", ":", "\n", "                ", "if", "val", ".", "name", ".", "startswith", "(", "'Top1_Acc_Epoch'", ")", ":", "\n", "                    ", "train_acc", "=", "val", ".", "value", "\n", "", "elif", "val", ".", "name", ".", "startswith", "(", "'Loss_Epoch'", ")", ":", "\n", "                    ", "train_loss", "=", "val", ".", "value", "\n", "\n", "", "", "", "self", ".", "print_train_metrics", "(", "self", ".", "training_exp_id", ",", "\n", "strategy", ".", "clock", ".", "train_exp_epochs", ",", "\n", "train_acc", ",", "self", ".", "val_acc", ",", "train_loss", ",", "\n", "self", ".", "val_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.after_eval_exp": [[134, 157], ["super().after_eval_exp", "csv_logger.CSVLogger.print_eval_metrics", "val.name.startswith", "val.name.startswith", "val.name.startswith", "val.name.startswith", "val.name.startswith"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.after_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.print_eval_metrics"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_eval_exp", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "acc", ",", "loss", ",", "forgetting", "=", "0", ",", "0", ",", "0", "\n", "\n", "for", "val", "in", "metric_values", ":", "\n", "            ", "if", "self", ".", "in_train_phase", ":", "# validation within training", "\n", "                ", "if", "val", ".", "name", ".", "startswith", "(", "'Top1_Acc_Exp'", ")", ":", "\n", "                    ", "self", ".", "val_acc", "=", "val", ".", "value", "\n", "", "elif", "val", ".", "name", ".", "startswith", "(", "'Loss_Exp'", ")", ":", "\n", "                    ", "self", ".", "val_loss", "=", "val", ".", "value", "\n", "", "", "else", ":", "\n", "                ", "if", "val", ".", "name", ".", "startswith", "(", "'Top1_Acc_Exp'", ")", ":", "\n", "                    ", "acc", "=", "val", ".", "value", "\n", "", "elif", "val", ".", "name", ".", "startswith", "(", "'Loss_Exp'", ")", ":", "\n", "                    ", "loss", "=", "val", ".", "value", "\n", "", "elif", "val", ".", "name", ".", "startswith", "(", "'ExperienceForgetting'", ")", ":", "\n", "                    ", "forgetting", "=", "val", ".", "value", "\n", "\n", "", "", "", "if", "not", "self", ".", "in_train_phase", ":", "\n", "            ", "self", ".", "print_eval_metrics", "(", "strategy", ".", "experience", ".", "current_experience", ",", "\n", "self", ".", "training_exp_id", ",", "acc", ",", "loss", ",", "\n", "forgetting", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.before_training_exp": [[158, 162], ["super().before_training"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training"], ["", "", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "self", ".", "training_exp_id", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.before_eval": [[163, 170], ["None"], "methods", ["None"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Manage the case in which `eval` is first called before `train`\n        \"\"\"", "\n", "if", "self", ".", "in_train_phase", "is", "None", ":", "\n", "            ", "self", ".", "in_train_phase", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.before_training": [[171, 174], ["None"], "methods", ["None"], ["", "", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "in_train_phase", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.after_training": [[175, 178], ["None"], "methods", ["None"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "in_train_phase", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close": [[179, 182], ["csv_logger.CSVLogger.training_file.close", "csv_logger.CSVLogger.eval_file.close"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.csv_logger.CSVLogger.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "training_file", ".", "close", "(", ")", "\n", "self", ".", "eval_file", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.__init__": [[51, 61], ["avalanche.logging.StrategyLogger.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "file", "=", "sys", ".", "stdout", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of `TextLogger` class.\n\n        :param file: destination file to which print metrics\n            (default=sys.stdout).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "file", "=", "file", "\n", "self", ".", "metric_vals", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.log_single_metric": [[62, 64], ["None"], "methods", ["None"], ["", "def", "log_single_metric", "(", "self", ",", "name", ",", "value", ",", "x_plot", ")", "->", "None", ":", "\n", "        ", "self", ".", "metric_vals", "[", "name", "]", "=", "(", "name", ",", "x_plot", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str": [[65, 72], ["isinstance", "isinstance", "str", "str"], "methods", ["None"], ["", "def", "_val_to_str", "(", "self", ",", "m_val", ")", ":", "\n", "        ", "if", "isinstance", "(", "m_val", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "'\\n'", "+", "str", "(", "m_val", ")", "\n", "", "elif", "isinstance", "(", "m_val", ",", "float", ")", ":", "\n", "            ", "return", "f'{m_val:.4f}'", "\n", "", "else", ":", "\n", "            ", "return", "str", "(", "m_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.print_current_metrics": [[73, 81], ["sorted", "text_logging.TextLogger.metric_vals.values", "isinstance", "text_logging.TextLogger._val_to_str", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._val_to_str"], ["", "", "def", "print_current_metrics", "(", "self", ")", ":", "\n", "        ", "sorted_vals", "=", "sorted", "(", "self", ".", "metric_vals", ".", "values", "(", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "for", "name", ",", "x", ",", "val", "in", "sorted_vals", ":", "\n", "            ", "if", "isinstance", "(", "val", ",", "UNSUPPORTED_TYPES", ")", ":", "\n", "                ", "continue", "\n", "", "val", "=", "self", ".", "_val_to_str", "(", "val", ")", "\n", "print", "(", "f'\\t{name} = {val}'", ",", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.before_training_exp": [[82, 86], ["super().before_training_exp", "text_logging.TextLogger._on_exp_start"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._on_exp_start"], ["", "", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_exp", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "self", ".", "_on_exp_start", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.before_eval_exp": [[87, 91], ["super().before_eval_exp", "text_logging.TextLogger._on_exp_start"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._on_exp_start"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval_exp", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "self", ".", "_on_exp_start", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.after_training_epoch": [[92, 99], ["super().after_training_epoch", "print", "text_logging.TextLogger.print_current_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.after_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.print_current_metrics"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training_epoch", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "print", "(", "f'Epoch {strategy.clock.train_exp_epochs} ended.'", ",", "\n", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "self", ".", "print_current_metrics", "(", ")", "\n", "self", ".", "metric_vals", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.after_eval_exp": [[100, 116], ["super().after_eval_exp", "text_logging.TextLogger.print_current_metrics", "avalanche.evaluation.metric_utils.phase_and_task", "print", "print", "avalanche.evaluation.metric_utils.stream_type", "avalanche.evaluation.metric_utils.stream_type"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.after_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.print_current_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_eval_exp", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "exp_id", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "task_id", "=", "phase_and_task", "(", "strategy", ")", "[", "1", "]", "\n", "if", "task_id", "is", "None", ":", "\n", "            ", "print", "(", "f'> Eval on experience {exp_id} '", "\n", "f'from {stream_type(strategy.experience)} stream ended.'", ",", "\n", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f'> Eval on experience {exp_id} (Task '", "\n", "f'{task_id}) '", "\n", "f'from {stream_type(strategy.experience)} stream ended.'", ",", "\n", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "", "self", ".", "print_current_metrics", "(", ")", "\n", "self", ".", "metric_vals", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.before_training": [[117, 121], ["super().before_training", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "print", "(", "'-- >> Start of training phase << --'", ",", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.before_eval": [[122, 126], ["super().before_eval", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "print", "(", "'-- >> Start of eval phase << --'", ",", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.after_training": [[127, 131], ["super().after_training", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.after_training"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "print", "(", "'-- >> End of training phase << --'", ",", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.after_eval": [[132, 138], ["super().after_eval", "print", "text_logging.TextLogger.print_current_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger.print_current_metrics"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "metric_values", ":", "List", "[", "'MetricValue'", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_eval", "(", "strategy", ",", "metric_values", ",", "**", "kwargs", ")", "\n", "print", "(", "'-- >> End of eval phase << --'", ",", "file", "=", "self", ".", "file", ",", "flush", "=", "True", ")", "\n", "self", ".", "print_current_metrics", "(", ")", "\n", "self", ".", "metric_vals", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.logging.text_logging.TextLogger._on_exp_start": [[139, 154], ["avalanche.evaluation.metric_utils.stream_type", "avalanche.evaluation.metric_utils.phase_and_task", "print", "print"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task"], ["", "def", "_on_exp_start", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "action_name", "=", "'training'", "if", "strategy", ".", "is_training", "else", "'eval'", "\n", "exp_id", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "task_id", "=", "phase_and_task", "(", "strategy", ")", "[", "1", "]", "\n", "stream", "=", "stream_type", "(", "strategy", ".", "experience", ")", "\n", "if", "task_id", "is", "None", ":", "\n", "            ", "print", "(", "'-- Starting {} on experience {} from {} stream --'", "\n", ".", "format", "(", "action_name", ",", "exp_id", ",", "stream", ")", ",", "\n", "file", "=", "self", ".", "file", ",", "\n", "flush", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'-- Starting {} on experience {} (Task {}) from {} stream --'", "\n", ".", "format", "(", "action_name", ",", "exp_id", ",", "task_id", ",", "stream", ")", ",", "\n", "file", "=", "self", ".", "file", ",", "\n", "flush", "=", "True", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ExemplarsBuffer.__init__": [[26, 34], ["avalanche.benchmarks.utils.AvalancheConcatDataset"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_size", ":", "int", ")", ":", "\n", "        ", "\"\"\"Init.\n\n        :param max_size: max number of input samples in the replay memory.\n        \"\"\"", "\n", "self", ".", "max_size", "=", "max_size", "\n", "\"\"\" Maximum size of the buffer. \"\"\"", "\n", "self", ".", "_buffer", "=", "AvalancheConcatDataset", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ExemplarsBuffer.buffer": [[40, 43], ["None"], "methods", ["None"], ["", "@", "buffer", ".", "setter", "\n", "def", "buffer", "(", "self", ",", "new_buffer", ":", "AvalancheDataset", ")", ":", "\n", "        ", "self", ".", "_buffer", "=", "new_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ExemplarsBuffer.update": [[44, 53], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Update `self.buffer` using the `strategy` state.\n\n        :param strategy:\n        :param kwargs:\n        :return:\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ExemplarsBuffer.resize": [[54, 63], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "resize", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "new_size", ":", "int", ")", ":", "\n", "        ", "\"\"\" Update the maximum size of the buffer.\n\n        :param strategy:\n        :param new_size:\n        :return:\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ReservoirSamplingBuffer.__init__": [[68, 81], ["storage_policy.ExemplarsBuffer.__init__", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "max_size", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        :param max_size:\n        \"\"\"", "\n", "# The algorithm follows", "\n", "# https://en.wikipedia.org/wiki/Reservoir_sampling", "\n", "# We sample a random uniform value in [0, 1] for each sample and", "\n", "# choose the `size` samples with higher values.", "\n", "# This is equivalent to a random selection of `size_samples`", "\n", "# from the entire stream.", "\n", "super", "(", ")", ".", "__init__", "(", "max_size", ")", "\n", "# INVARIANT: _buffer_weights is always sorted.", "\n", "self", ".", "_buffer_weights", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ReservoirSamplingBuffer.update": [[82, 85], ["storage_policy.ReservoirSamplingBuffer.update_from_dataset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset"], ["", "def", "update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Update buffer. \"\"\"", "\n", "self", ".", "update_from_dataset", "(", "strategy", ".", "experience", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ReservoirSamplingBuffer.update_from_dataset": [[86, 101], ["torch.rand", "torch.cat", "avalanche.benchmarks.utils.AvalancheConcatDataset", "torch.cat.sort", "avalanche.benchmarks.utils.AvalancheSubset", "len"], "methods", ["None"], ["", "def", "update_from_dataset", "(", "self", ",", "new_data", ":", "AvalancheDataset", ")", ":", "\n", "        ", "\"\"\"Update the buffer using the given dataset.\n\n        :param new_data:\n        :return:\n        \"\"\"", "\n", "new_weights", "=", "torch", ".", "rand", "(", "len", "(", "new_data", ")", ")", "\n", "\n", "cat_weights", "=", "torch", ".", "cat", "(", "[", "new_weights", ",", "self", ".", "_buffer_weights", "]", ")", "\n", "cat_data", "=", "AvalancheConcatDataset", "(", "[", "new_data", ",", "self", ".", "buffer", "]", ")", "\n", "sorted_weights", ",", "sorted_idxs", "=", "cat_weights", ".", "sort", "(", "descending", "=", "True", ")", "\n", "\n", "buffer_idxs", "=", "sorted_idxs", "[", ":", "self", ".", "max_size", "]", "\n", "self", ".", "buffer", "=", "AvalancheSubset", "(", "cat_data", ",", "buffer_idxs", ")", "\n", "self", ".", "_buffer_weights", "=", "sorted_weights", "[", ":", "self", ".", "max_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ReservoirSamplingBuffer.resize": [[102, 109], ["avalanche.benchmarks.utils.AvalancheSubset", "len", "torch.arange"], "methods", ["None"], ["", "def", "resize", "(", "self", ",", "strategy", ",", "new_size", ")", ":", "\n", "        ", "\"\"\" Update the maximum size of the buffer. \"\"\"", "\n", "self", ".", "max_size", "=", "new_size", "\n", "if", "len", "(", "self", ".", "buffer", ")", "<=", "self", ".", "max_size", ":", "\n", "            ", "return", "\n", "", "self", ".", "buffer", "=", "AvalancheSubset", "(", "self", ".", "buffer", ",", "torch", ".", "arange", "(", "self", ".", "max_size", ")", ")", "\n", "self", ".", "_buffer_weights", "=", "self", ".", "_buffer_weights", "[", ":", "self", ".", "max_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.__init__": [[123, 146], ["storage_policy.ExemplarsBuffer.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "adaptive_size", ":", "bool", "=", "True", ",", "\n", "total_num_groups", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param max_size: max number of input samples in the replay memory.\n        :param adaptive_size: True if max_size is divided equally over all\n                              observed experiences (keys in replay_mem).\n        :param total_num_groups: If adaptive size is False, the fixed number\n                                of groups to divide capacity over.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "max_size", ")", "\n", "self", ".", "adaptive_size", "=", "adaptive_size", "\n", "self", ".", "total_num_groups", "=", "total_num_groups", "\n", "if", "not", "self", ".", "adaptive_size", ":", "\n", "            ", "assert", "self", ".", "total_num_groups", ">", "0", ",", "\"You need to specify `total_num_groups` if \"", "\"`adaptive_size=True`.\"", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "total_num_groups", "is", "None", ",", "\"`total_num_groups` is not compatible with \"", "\"`adaptive_size=False`.\"", "\n", "\n", "", "self", ".", "buffer_groups", ":", "Dict", "[", "int", ",", "ExemplarsBuffer", "]", "=", "{", "}", "\n", "\"\"\" Dictionary of buffers. \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.buffer_datasets": [[147, 151], ["storage_policy.BalancedExemplarsBuffer.buffer_groups.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "buffer_datasets", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return group buffers as a list of `AvalancheDataset`s. \"\"\"", "\n", "return", "[", "g", ".", "buffer", "for", "g", "in", "self", ".", "buffer_groups", ".", "values", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.get_group_lengths": [[152, 164], ["range", "sum", "range", "range"], "methods", ["None"], ["", "def", "get_group_lengths", "(", "self", ",", "num_groups", ")", ":", "\n", "        ", "\"\"\" Compute groups lengths given the number of groups `num_groups`. \"\"\"", "\n", "if", "self", ".", "adaptive_size", ":", "\n", "            ", "lengths", "=", "[", "self", ".", "max_size", "//", "num_groups", "for", "_", "in", "range", "(", "num_groups", ")", "]", "\n", "# distribute remaining size among experiences.", "\n", "rem", "=", "self", ".", "max_size", "-", "sum", "(", "lengths", ")", "\n", "for", "i", "in", "range", "(", "rem", ")", ":", "\n", "                ", "lengths", "[", "i", "]", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "lengths", "=", "[", "self", ".", "max_size", "//", "self", ".", "total_num_groups", "for", "_", "in", "\n", "range", "(", "num_groups", ")", "]", "\n", "", "return", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.buffer_group": [[165, 168], ["None"], "methods", ["None"], ["", "def", "buffer_group", "(", "self", ",", "buffer_id", ")", ":", "\n", "        ", "\"\"\" Getter for \"\"\"", "\n", "return", "self", ".", "buffer_groups", "[", "buffer_id", "]", ".", "buffer", "# Buffer is an AvalancheConcat set already", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.buffer": [[174, 178], ["NotImplementedError"], "methods", ["None"], ["", "@", "buffer", ".", "setter", "\n", "def", "buffer", "(", "self", ",", "new_buffer", ")", ":", "\n", "        ", "assert", "NotImplementedError", "(", "\n", "\"Cannot set `self.buffer` for this class. \"", "\n", "\"You should modify `self.buffer_groups instead.\"", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.update": [[180, 189], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Update `self.buffer_groups` using the `strategy` state.\n\n        :param strategy:\n        :param kwargs:\n        :return:\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.resize": [[190, 196], ["storage_policy.BalancedExemplarsBuffer.get_group_lengths", "zip", "len", "storage_policy.BalancedExemplarsBuffer.buffer_groups.values", "buffer.resize"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.get_group_lengths", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize"], ["", "def", "resize", "(", "self", ",", "strategy", ",", "new_size", ")", ":", "\n", "        ", "\"\"\" Update the maximum size of the buffers. \"\"\"", "\n", "self", ".", "max_size", "=", "new_size", "\n", "lens", "=", "self", ".", "get_group_lengths", "(", "len", "(", "self", ".", "buffer_groups", ")", ")", "\n", "for", "ll", ",", "buffer", "in", "zip", "(", "lens", ",", "self", ".", "buffer_groups", ".", "values", "(", ")", ")", ":", "\n", "            ", "buffer", ".", "resize", "(", "strategy", ",", "ll", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ExperienceBalancedBuffer.__init__": [[206, 217], ["storage_policy.BalancedExemplarsBuffer.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "adaptive_size", ":", "bool", "=", "True", ",", "\n", "num_experiences", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param max_size: max number of total input samples in the replay\n            memory.\n        :param adaptive_size: True if mem_size is divided equally over all\n                              observed experiences (keys in replay_mem).\n        :param num_experiences: If adaptive size is False, the fixed number\n                                of experiences to divide capacity over.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "max_size", ",", "adaptive_size", ",", "num_experiences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ExperienceBalancedBuffer.update": [[218, 229], ["storage_policy.ExperienceBalancedBuffer.get_group_lengths", "storage_policy.ReservoirSamplingBuffer", "storage_policy.ReservoirSamplingBuffer.update_from_dataset", "zip", "storage_policy.ExperienceBalancedBuffer.buffer_groups.values", "b.resize"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.get_group_lengths", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize"], ["", "def", "update", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "new_data", "=", "strategy", ".", "experience", ".", "dataset", "\n", "num_exps", "=", "strategy", ".", "clock", ".", "train_exp_counter", "+", "1", "\n", "lens", "=", "self", ".", "get_group_lengths", "(", "num_exps", ")", "\n", "\n", "new_buffer", "=", "ReservoirSamplingBuffer", "(", "lens", "[", "-", "1", "]", ")", "\n", "new_buffer", ".", "update_from_dataset", "(", "new_data", ")", "\n", "self", ".", "buffer_groups", "[", "num_exps", "-", "1", "]", "=", "new_buffer", "\n", "\n", "for", "ll", ",", "b", "in", "zip", "(", "lens", ",", "self", ".", "buffer_groups", ".", "values", "(", ")", ")", ":", "\n", "            ", "b", ".", "resize", "(", "strategy", ",", "ll", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ClassBalancedBuffer.__init__": [[243, 260], ["storage_policy.BalancedExemplarsBuffer.__init__", "set"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "adaptive_size", ":", "bool", "=", "True", ",", "\n", "total_num_classes", ":", "int", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param max_size: The max capacity of the replay memory.\n        :param adaptive_size: True if mem_size is divided equally over all\n                            observed experiences (keys in replay_mem).\n        :param total_num_classes: If adaptive size is False, the fixed number\n                                  of classes to divide capacity over.\n        \"\"\"", "\n", "if", "not", "adaptive_size", ":", "\n", "            ", "assert", "total_num_classes", ">", "0", ",", "\"\"\"When fixed exp mem size, total_num_classes should be > 0.\"\"\"", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "max_size", ",", "adaptive_size", ",", "total_num_classes", ")", "\n", "self", ".", "adaptive_size", "=", "adaptive_size", "\n", "self", ".", "total_num_classes", "=", "total_num_classes", "\n", "self", ".", "seen_classes", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ClassBalancedBuffer.update": [[261, 303], ["enumerate", "cl_idxs.items", "storage_policy.ClassBalancedBuffer.seen_classes.update", "storage_policy.ClassBalancedBuffer.get_group_lengths", "zip", "cl_datasets.items", "storage_policy.ClassBalancedBuffer.buffer_groups.items", "int", "cl_idxs[].append", "avalanche.benchmarks.utils.AvalancheSubset", "cl_datasets.keys", "len", "storage_policy.ClassBalancedBuffer.buffer_groups[].resize", "old_buffer_c.update_from_dataset", "old_buffer_c.resize", "storage_policy.ReservoirSamplingBuffer", "storage_policy.ReservoirSamplingBuffer.update_from_dataset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.get_group_lengths", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset"], ["", "def", "update", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "new_data", "=", "strategy", ".", "experience", ".", "dataset", "\n", "\n", "# Get sample idxs per class", "\n", "cl_idxs", "=", "{", "}", "\n", "for", "idx", ",", "target", "in", "enumerate", "(", "new_data", ".", "targets", ")", ":", "\n", "# FIXME FIXED BUG: Required if iterating over targets, same-class tensors have different id", "\n", "            ", "target", "=", "int", "(", "target", ")", "\n", "if", "target", "not", "in", "cl_idxs", ":", "\n", "                ", "cl_idxs", "[", "target", "]", "=", "[", "]", "\n", "", "cl_idxs", "[", "target", "]", ".", "append", "(", "idx", ")", "\n", "\n", "# Make AvalancheSubset per class", "\n", "", "cl_datasets", "=", "{", "}", "\n", "for", "c", ",", "c_idxs", "in", "cl_idxs", ".", "items", "(", ")", ":", "\n", "            ", "cl_datasets", "[", "c", "]", "=", "AvalancheSubset", "(", "new_data", ",", "indices", "=", "c_idxs", ")", "\n", "\n", "# Update seen classes", "\n", "", "self", ".", "seen_classes", ".", "update", "(", "cl_datasets", ".", "keys", "(", ")", ")", "\n", "\n", "# associate lengths to classes", "\n", "lens", "=", "self", ".", "get_group_lengths", "(", "len", "(", "self", ".", "seen_classes", ")", ")", "\n", "class_to_len", "=", "{", "}", "\n", "for", "class_id", ",", "ll", "in", "zip", "(", "self", ".", "seen_classes", ",", "lens", ")", ":", "\n", "            ", "class_to_len", "[", "class_id", "]", "=", "ll", "\n", "\n", "# update buffers with new data", "\n", "", "for", "class_id", ",", "new_data_c", "in", "cl_datasets", ".", "items", "(", ")", ":", "\n", "            ", "ll", "=", "class_to_len", "[", "class_id", "]", "\n", "if", "class_id", "in", "self", ".", "buffer_groups", ":", "\n", "                ", "old_buffer_c", "=", "self", ".", "buffer_groups", "[", "class_id", "]", "\n", "old_buffer_c", ".", "update_from_dataset", "(", "new_data_c", ")", "\n", "old_buffer_c", ".", "resize", "(", "strategy", ",", "ll", ")", "\n", "", "else", ":", "\n", "                ", "new_buffer", "=", "ReservoirSamplingBuffer", "(", "ll", ")", "\n", "new_buffer", ".", "update_from_dataset", "(", "new_data_c", ")", "\n", "self", ".", "buffer_groups", "[", "class_id", "]", "=", "new_buffer", "\n", "\n", "# resize buffers", "\n", "", "", "for", "class_id", ",", "class_buf", "in", "self", ".", "buffer_groups", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "buffer_groups", "[", "class_id", "]", ".", "resize", "(", "strategy", ",", "\n", "class_to_len", "[", "class_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer.__init__": [[309, 329], ["storage_policy.BalancedExemplarsBuffer.__init__", "set", "storage_policy.RandomExemplarsSelectionStrategy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "\n", "groupby", "=", "None", ",", "\n", "selection_strategy", ":", "Optional", "[", "\n", "\"ExemplarsSelectionStrategy\"", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param max_size: The max capacity of the replay memory.\n        :param groupby: Grouping mechanism. One of {None, 'class', 'task',\n        'experience'}.\n        :param selection_strategy: The strategy used to select exemplars to\n                                   keep in memory when cutting it off.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "max_size", ")", "\n", "assert", "groupby", "in", "{", "None", ",", "'task'", ",", "'class'", ",", "'experience'", "}", ",", "\"Unknown grouping scheme. Must be one of {None, 'task', \"", "\"'class', 'experience'}\"", "\n", "self", ".", "groupby", "=", "groupby", "\n", "ss", "=", "selection_strategy", "or", "RandomExemplarsSelectionStrategy", "(", ")", "\n", "self", ".", "selection_strategy", "=", "ss", "\n", "self", ".", "seen_groups", "=", "set", "(", ")", "\n", "self", ".", "_curr_strategy", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer.update": [[330, 358], ["storage_policy.ParametricBuffer._make_groups", "storage_policy.ParametricBuffer.seen_groups.update", "storage_policy.ParametricBuffer.get_group_lengths", "zip", "storage_policy.ParametricBuffer.items", "storage_policy.ParametricBuffer.buffer_groups.items", "storage_policy.ParametricBuffer.keys", "len", "storage_policy.ParametricBuffer.buffer_groups[].resize", "old_buffer_g.update_from_dataset", "old_buffer_g.resize", "storage_policy._ParametricSingleBuffer", "storage_policy._ParametricSingleBuffer.update_from_dataset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._make_groups", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.BalancedExemplarsBuffer.get_group_lengths", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset"], ["", "def", "update", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "new_data", "=", "strategy", ".", "experience", ".", "dataset", "\n", "new_groups", "=", "self", ".", "_make_groups", "(", "strategy", ",", "new_data", ")", "\n", "self", ".", "seen_groups", ".", "update", "(", "new_groups", ".", "keys", "(", ")", ")", "\n", "\n", "# associate lengths to classes", "\n", "lens", "=", "self", ".", "get_group_lengths", "(", "len", "(", "self", ".", "seen_groups", ")", ")", "\n", "group_to_len", "=", "{", "}", "\n", "for", "group_id", ",", "ll", "in", "zip", "(", "self", ".", "seen_groups", ",", "lens", ")", ":", "\n", "            ", "group_to_len", "[", "group_id", "]", "=", "ll", "\n", "\n", "# update buffers with new data", "\n", "", "for", "group_id", ",", "new_data_g", "in", "new_groups", ".", "items", "(", ")", ":", "\n", "            ", "ll", "=", "group_to_len", "[", "group_id", "]", "\n", "if", "group_id", "in", "self", ".", "buffer_groups", ":", "\n", "                ", "old_buffer_g", "=", "self", ".", "buffer_groups", "[", "group_id", "]", "\n", "old_buffer_g", ".", "update_from_dataset", "(", "strategy", ",", "new_data_g", ")", "\n", "old_buffer_g", ".", "resize", "(", "strategy", ",", "ll", ")", "\n", "", "else", ":", "\n", "                ", "new_buffer", "=", "_ParametricSingleBuffer", "(", "ll", ",", "\n", "self", ".", "selection_strategy", ")", "\n", "new_buffer", ".", "update_from_dataset", "(", "strategy", ",", "new_data_g", ")", "\n", "self", ".", "buffer_groups", "[", "group_id", "]", "=", "new_buffer", "\n", "\n", "# resize buffers", "\n", "", "", "for", "group_id", ",", "class_buf", "in", "self", ".", "buffer_groups", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "buffer_groups", "[", "group_id", "]", ".", "resize", "(", "strategy", ",", "\n", "group_to_len", "[", "group_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._make_groups": [[359, 371], ["storage_policy.ParametricBuffer._split_by_task", "storage_policy.ParametricBuffer._split_by_experience", "storage_policy.ParametricBuffer._split_by_class"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._split_by_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._split_by_experience", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._split_by_class"], ["", "", "def", "_make_groups", "(", "self", ",", "strategy", ",", "data", ")", ":", "\n", "        ", "\"\"\"Split the data by group according to `self.groupby`.\"\"\"", "\n", "if", "self", ".", "groupby", "is", "None", ":", "\n", "            ", "return", "{", "0", ":", "data", "}", "\n", "", "elif", "self", ".", "groupby", "==", "'task'", ":", "\n", "            ", "return", "self", ".", "_split_by_task", "(", "data", ")", "\n", "", "elif", "self", ".", "groupby", "==", "'experience'", ":", "\n", "            ", "return", "self", ".", "_split_by_experience", "(", "strategy", ",", "data", ")", "\n", "", "elif", "self", ".", "groupby", "==", "'class'", ":", "\n", "            ", "return", "self", ".", "_split_by_class", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"Invalid groupby key. Should never get here.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._split_by_class": [[372, 387], ["enumerate", "class_idxs.items", "int", "class_idxs[].append", "avalanche.benchmarks.utils.AvalancheSubset"], "methods", ["None"], ["", "", "def", "_split_by_class", "(", "self", ",", "data", ")", ":", "\n", "# Get sample idxs per class", "\n", "        ", "class_idxs", "=", "{", "}", "\n", "for", "idx", ",", "target", "in", "enumerate", "(", "data", ".", "targets", ")", ":", "\n", "# FIXME FIXED BUG: Required if iterating over targets, same-class tensors have different id", "\n", "            ", "target", "=", "int", "(", "target", ")", "\n", "if", "target", "not", "in", "class_idxs", ":", "\n", "                ", "class_idxs", "[", "target", "]", "=", "[", "]", "\n", "", "class_idxs", "[", "target", "]", ".", "append", "(", "idx", ")", "\n", "\n", "# Make AvalancheSubset per class", "\n", "", "new_groups", "=", "{", "}", "\n", "for", "c", ",", "c_idxs", "in", "class_idxs", ".", "items", "(", ")", ":", "\n", "            ", "new_groups", "[", "c", "]", "=", "AvalancheSubset", "(", "data", ",", "indices", "=", "c_idxs", ")", "\n", "", "return", "new_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._split_by_experience": [[388, 391], ["None"], "methods", ["None"], ["", "def", "_split_by_experience", "(", "self", ",", "strategy", ",", "data", ")", ":", "\n", "        ", "exp_id", "=", "strategy", ".", "clock", ".", "train_exp_counter", "+", "1", "\n", "return", "{", "exp_id", ":", "data", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ParametricBuffer._split_by_task": [[392, 397], ["None"], "methods", ["None"], ["", "def", "_split_by_task", "(", "self", ",", "data", ")", ":", "\n", "        ", "new_groups", "=", "{", "}", "\n", "for", "task_id", "in", "data", ".", "task_set", ":", "\n", "            ", "new_groups", "[", "task_id", "]", "=", "data", ".", "task_set", "[", "task_id", "]", "\n", "", "return", "new_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.__init__": [[407, 419], ["storage_policy.ExemplarsBuffer.__init__", "storage_policy.RandomExemplarsSelectionStrategy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "max_size", ":", "int", ",", "\n", "selection_strategy", ":", "Optional", "[", "\n", "\"ExemplarsSelectionStrategy\"", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param max_size: The max capacity of the replay memory.\n        :param selection_strategy: The strategy used to select exemplars to\n                                   keep in memory when cutting it off.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "max_size", ")", "\n", "ss", "=", "selection_strategy", "or", "RandomExemplarsSelectionStrategy", "(", ")", "\n", "self", ".", "selection_strategy", "=", "ss", "\n", "self", ".", "_curr_strategy", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update": [[420, 423], ["storage_policy._ParametricSingleBuffer.update_from_dataset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset"], ["", "def", "update", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "new_data", "=", "strategy", ".", "experience", ".", "dataset", "\n", "self", ".", "update_from_dataset", "(", "strategy", ",", "new_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.update_from_dataset": [[424, 427], ["avalanche.benchmarks.utils.AvalancheConcatDataset", "storage_policy._ParametricSingleBuffer.resize"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize"], ["", "def", "update_from_dataset", "(", "self", ",", "strategy", ",", "new_data", ")", ":", "\n", "        ", "self", ".", "buffer", "=", "AvalancheConcatDataset", "(", "[", "self", ".", "buffer", ",", "new_data", "]", ")", "\n", "self", ".", "resize", "(", "strategy", ",", "self", ".", "max_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy._ParametricSingleBuffer.resize": [[428, 434], ["storage_policy._ParametricSingleBuffer.selection_strategy.make_sorted_indices", "avalanche.benchmarks.utils.AvalancheSubset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.FeatureBasedExemplarsSelectionStrategy.make_sorted_indices"], ["", "def", "resize", "(", "self", ",", "strategy", ",", "new_size", ":", "int", ")", ":", "\n", "        ", "self", ".", "max_size", "=", "new_size", "\n", "idxs", "=", "self", ".", "selection_strategy", ".", "make_sorted_indices", "(", "\n", "strategy", "=", "strategy", ",", "\n", "data", "=", "self", ".", "buffer", ")", "\n", "self", ".", "buffer", "=", "AvalancheSubset", "(", "self", ".", "buffer", ",", "idxs", "[", ":", "self", ".", "max_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ExemplarsSelectionStrategy.make_sorted_indices": [[441, 450], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "make_sorted_indices", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "\n", "data", ":", "AvalancheDataset", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        Should return the sorted list of indices to keep as exemplars.\n\n        The last indices will be the first to be removed when cutoff memory.\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.RandomExemplarsSelectionStrategy.make_sorted_indices": [[455, 460], ["list", "random.shuffle", "range", "len"], "methods", ["None"], ["def", "make_sorted_indices", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "\n", "data", ":", "AvalancheDataset", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "indices", "=", "list", "(", "range", "(", "len", "(", "data", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "indices", ")", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.FeatureBasedExemplarsSelectionStrategy.__init__": [[466, 468], ["avalanche.models.FeatureExtractorBackbone"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "layer_name", ":", "str", ")", ":", "\n", "        ", "self", ".", "feature_extractor", "=", "FeatureExtractorBackbone", "(", "model", ",", "layer_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.FeatureBasedExemplarsSelectionStrategy.make_sorted_indices": [[469, 480], ["torch.no_grad", "storage_policy.FeatureBasedExemplarsSelectionStrategy.feature_extractor.eval", "torch.cat", "storage_policy.FeatureBasedExemplarsSelectionStrategy.make_sorted_indices_from_features", "storage_policy.FeatureBasedExemplarsSelectionStrategy.feature_extractor", "x.to", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ClosestToCenterSelectionStrategy.make_sorted_indices_from_features"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "make_sorted_indices", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "\n", "data", ":", "AvalancheDataset", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "self", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "features", "=", "cat", "(", "\n", "[", "\n", "self", ".", "feature_extractor", "(", "x", ".", "to", "(", "strategy", ".", "device", ")", ")", "\n", "for", "x", ",", "*", "_", "in", "DataLoader", "(", "data", ",", "batch_size", "=", "strategy", ".", "eval_mb_size", ")", "\n", "]", "\n", ")", "\n", "return", "self", ".", "make_sorted_indices_from_features", "(", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.FeatureBasedExemplarsSelectionStrategy.make_sorted_indices_from_features": [[481, 489], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "make_sorted_indices_from_features", "(", "self", ",", "features", ":", "Tensor", "\n", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        Should return the sorted list of indices to keep as exemplars.\n\n        The last indices will be the first to be removed when cutoff memory.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.HerdingSelectionStrategy.make_sorted_indices_from_features": [[499, 519], ["features.mean", "range", "len", "pow().sum", "pow().sum.argmin().tolist", "selected_indices.append", "pow", "pow().sum.argmin"], "methods", ["None"], ["def", "make_sorted_indices_from_features", "(", "self", ",", "features", ":", "Tensor", "\n", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "selected_indices", "=", "[", "]", "\n", "\n", "center", "=", "features", ".", "mean", "(", "dim", "=", "0", ")", "\n", "current_center", "=", "center", "*", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "# Compute distances with real center", "\n", "            ", "candidate_centers", "=", "current_center", "*", "i", "/", "(", "i", "+", "1", ")", "+", "features", "/", "(", "i", "\n", "+", "1", ")", "\n", "distances", "=", "pow", "(", "candidate_centers", "-", "center", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "distances", "[", "selected_indices", "]", "=", "inf", "\n", "\n", "# Select best candidate", "\n", "new_index", "=", "distances", ".", "argmin", "(", ")", ".", "tolist", "(", ")", "\n", "selected_indices", ".", "append", "(", "new_index", ")", "\n", "current_center", "=", "candidate_centers", "[", "new_index", "]", "\n", "\n", "", "return", "selected_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.storage_policy.ClosestToCenterSelectionStrategy.make_sorted_indices_from_features": [[526, 531], ["features.mean", "pow().sum", "pow().sum.argsort", "pow"], "methods", ["None"], ["def", "make_sorted_indices_from_features", "(", "self", ",", "features", ":", "Tensor", "\n", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "center", "=", "features", ".", "mean", "(", "dim", "=", "0", ")", "\n", "distances", "=", "pow", "(", "features", "-", "center", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "distances", ".", "argsort", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.load_all_dataset": [[28, 64], ["torch.utils.data.DataLoader", "max", "len", "batches_x.append", "batches_y.append", "torch.cat", "torch.cat", "torch.cat", "len", "batches_t.append", "len"], "function", ["None"], ["            ", "print", "(", "f\"Stopping training, reached max iterations: {self.max_iterations}\"", ")", "\n", "strategy", ".", "stop_training", "(", ")", "\n", "\n", "\n", "", "", "", "class", "MetricOverSeed", ":", "\n", "    ", "logging_token", "=", "\"[SEED-AVGED-RESULTS]=\"", "\n", "logging_result_format", "=", "\"{:.5f}\\pm{:.5f}\"", "\n", "loggin_result_separator", "=", "\"\\t\"", "\n", "\n", "def", "__init__", "(", "self", ",", "name", ",", "extract_name", ",", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        :param name: Name to give in logging\n        :param extract_name: Dict name in all_metrics dict after end of training seed.\n        :param extract_idx: Which idx to extract, -1 for final one.\n        :param mul_factor: Multiplication factor before return result.\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "extract_name", "=", "extract_name", "\n", "self", ".", "extract_idx", "=", "extract_idx", "\n", "self", ".", "mul_factor", "=", "mul_factor", "\n", "\n", "# Results appended sequentially", "\n", "self", ".", "seeds", "=", "[", "]", "\n", "self", ".", "seed_results", "=", "[", "]", "\n", "\n", "", "def", "extract_metric_fn", "(", "self", ",", "all_metrics", ":", "dict", ")", ":", "\n", "        ", "\"\"\" Extract dict of all eval results on end of seed.\n        Name-idx returns tuple of (list(<STEPS>),list(<METRIC-VALS>))\n        Select latter with [1], and apply the extraction idx.\n        \"\"\"", "\n", "return", "all_metrics", "[", "self", ".", "extract_name", "]", "[", "1", "]", "[", "self", ".", "extract_idx", "]", "*", "self", ".", "mul_factor", "\n", "\n", "", "def", "add_result", "(", "self", ",", "all_metrics", ":", "dict", ",", "seed", ":", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "result", "=", "self", ".", "extract_metric_fn", "(", "all_metrics", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "f\"[WARNING] No SEED result for metric {self.name}, because of error: {e}\"", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.zerolike_params_dict": [[66, 76], ["torch.zeros_like().to", "model.named_parameters", "torch.zeros_like"], "function", ["None"], ["\n", "", "self", ".", "seeds", ".", "append", "(", "seed", ")", "\n", "self", ".", "seed_results", ".", "append", "(", "result", ")", "\n", "\n", "", "def", "get_mean_std_results", "(", "self", ")", ":", "\n", "        ", "result_t", "=", "torch", ".", "tensor", "(", "self", ".", "seed_results", ")", "# list to tensor", "\n", "mean", ",", "std", "=", "result_t", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "result_t", ".", "std", "(", ")", ".", "item", "(", ")", "\n", "return", "mean", ",", "std", "\n", "\n", "\n", "", "", "def", "get_grad_normL2", "(", "model", ",", "norm_type", ":", "float", "=", "2", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.copy_params_dict": [[78, 91], ["p.grad.data.clone", "model.named_parameters", "p.data.clone", "model.named_parameters"], "function", ["None"], ["\n", "\n", "# Params with grad", "\n", "parameters", "=", "model", ".", "parameters", "(", ")", "\n", "if", "isinstance", "(", "model", ".", "parameters", "(", ")", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "parameters", "=", "[", "parameters", "]", "\n", "", "parameters", "=", "[", "p", "for", "p", "in", "parameters", "if", "p", ".", "grad", "is", "not", "None", "]", "\n", "if", "len", "(", "parameters", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "device", "=", "parameters", "[", "0", "]", ".", "grad", ".", "device", "\n", "\n", "# calc norm", "\n", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "norm", "(", "p", ".", "grad", ".", "detach", "(", ")", ",", "norm_type", ")", ".", "to", "(", "device", ")", "for", "p", "in", "parameters", "]", ")", ",", "norm_type", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layers_and_params": [[100, 117], ["model.named_parameters", "model.named_modules", "result.append", "utils.get_layers_and_params", "utils.LayerAndParameter"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layers_and_params"], ["\n", "protos_weight", "=", "{", "}", "\n", "protos_bias", "=", "{", "}", "\n", "\n", "if", "isinstance", "(", "classifier", ",", "MultiHeadClassifier", ")", ":", "# Multi-head", "\n", "        ", "y_offset", "=", "0", "\n", "for", "taskid", ",", "taskhead", "in", "classifier", ".", "classifiers", ".", "items", "(", ")", ":", "# Iterate heads", "\n", "            ", "nb_task_protos", "=", "0", "\n", "for", "param_name", ",", "param", "in", "taskhead", ".", "named_parameters", "(", ")", ":", "# Weight/bias of Linear layer heads", "\n", "                ", "nb_task_protos", "=", "param", ".", "shape", "[", "0", "]", "\n", "if", "'weight'", "in", "param_name", ":", "\n", "                    ", "for", "y", "in", "range", "(", "nb_task_protos", ")", ":", "# Per head params restart from 0, but total protos has offset", "\n", "                        ", "protos_weight", "[", "y", "+", "y_offset", "]", "=", "param", "[", "y", "]", "\n", "", "", "elif", "'bias'", "in", "param_name", ":", "\n", "                    ", "for", "y", "in", "range", "(", "nb_task_protos", ")", ":", "\n", "                        ", "protos_bias", "[", "y", "+", "y_offset", "]", "=", "param", "[", "y", "]", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layer_by_name": [[119, 124], ["utils.get_layers_and_params"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layers_and_params"], ["\n", "", "", "elif", "isinstance", "(", "classifier", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "# Single head", "\n", "        ", "for", "param_name", ",", "param", "in", "classifier", ".", "named_parameters", "(", ")", ":", "\n", "            ", "nb_protos", "=", "param", ".", "shape", "[", "0", "]", "\n", "if", "'weight'", "in", "param_name", ":", "\n", "                ", "for", "y", "in", "range", "(", "nb_protos", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_last_fc_layer": [[126, 133], ["model.named_modules", "isinstance"], "function", ["None"], ["", "", "elif", "'bias'", "in", "param_name", ":", "\n", "                ", "for", "y", "in", "range", "(", "nb_protos", ")", ":", "\n", "                    ", "protos_bias", "[", "y", "]", "=", "param", "[", "y", "]", "\n", "", "", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", ")", "\n", "\n", "", "if", "get_clone", ":", "# Make clones of original references", "\n", "        ", "protos_weight", "=", "{", "y", ":", "param", ".", "detach", "(", ")", ".", "clone", "(", ")", "for", "y", ",", "param", "in", "protos_weight", ".", "items", "(", ")", "}", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.swap_last_fc_layer": [[135, 138], ["utils.get_last_fc_layer", "setattr"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_last_fc_layer"], ["", "return", "protos_weight", ",", "protos_bias", "\n", "\n", "\n", "", "class", "ExpLRSchedulerPlugin", "(", "StrategyPlugin", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.adapt_classification_layer": [[140, 153], ["utils.get_last_fc_layer", "torch.nn.Linear", "utils.swap_last_fc_layer"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_last_fc_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.swap_last_fc_layer"], ["\n", "\n", "def", "__init__", "(", "self", ",", "scheduler", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``LRSchedulerPlugin`` instance, step per experience.\n\n        :param scheduler: a learning rate scheduler that can be updated through\n            a step() method and can be reset by setting last_epoch=0\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.replace_bn_with_brn": [[155, 180], ["dir", "m.named_children", "getattr", "utils.replace_bn_with_brn", "type", "setattr", "avalanche.models.batch_renorm.BatchRenorm2D"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.replace_bn_with_brn"], ["\n", "", "def", "print_lrs", "(", "self", ")", ":", "\n", "        ", "print", "(", "f\"[LR SCHEDULER] Current lrs: \"", "\n", "f\"{['{:.1e}'.format(group['lr']) for group in self.scheduler.optimizer.param_groups]}\"", ")", "\n", "\n", "", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "print_lrs", "(", ")", "\n", "\n", "", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "self", ".", "print_lrs", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.change_brn_pars": [[182, 195], ["dir", "m.named_children", "getattr", "utils.change_brn_pars", "type", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.change_brn_pars"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.freeze_everything": [[197, 203], ["utils.get_layers_and_params", "model.eval"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layers_and_params", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.unfreeze_everything": [[205, 211], ["utils.get_layers_and_params", "model.train"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layers_and_params", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.freeze_up_to": [[213, 268], ["set", "set", "dict", "utils.get_layers_and_params", "dict.items", "layer_filter", "set.add", "layer_result[].eval", "set.add"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layers_and_params", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.examples_per_class": [[270, 280], ["collections.defaultdict", "torch.unique", "range", "torch.as_tensor", "len", "int", "int"], "function", ["None"], []], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.losses.ICaRLLossPlugin.__init__": [[20, 27], ["avalanche.training.plugins.StrategyPlugin.__init__", "torch.nn.BCELoss"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "BCELoss", "(", ")", "\n", "\n", "self", ".", "old_classes", "=", "[", "]", "\n", "self", ".", "old_model", "=", "None", "\n", "self", ".", "old_logits", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.losses.ICaRLLossPlugin.before_forward": [[28, 32], ["torch.no_grad", "losses.ICaRLLossPlugin.old_model"], "methods", ["None"], ["", "def", "before_forward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "old_model", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "old_logits", "=", "self", ".", "old_model", "(", "strategy", ".", "mb_x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.losses.ICaRLLossPlugin.__call__": [[33, 46], ["torch.sigmoid", "torch.zeros", "losses.ICaRLLossPlugin.criterion", "torch.sigmoid", "range", "targets.long", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion"], ["", "", "", "def", "__call__", "(", "self", ",", "logits", ",", "targets", ")", ":", "\n", "        ", "predictions", "=", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "\n", "one_hot", "=", "torch", ".", "zeros", "(", "targets", ".", "shape", "[", "0", "]", ",", "logits", ".", "shape", "[", "1", "]", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "logits", ".", "device", ")", "\n", "one_hot", "[", "range", "(", "len", "(", "targets", ")", ")", ",", "targets", ".", "long", "(", ")", "]", "=", "1", "\n", "\n", "if", "self", ".", "old_logits", "is", "not", "None", ":", "\n", "            ", "old_predictions", "=", "torch", ".", "sigmoid", "(", "self", ".", "old_logits", ")", "\n", "one_hot", "[", ":", ",", "self", ".", "old_classes", "]", "=", "old_predictions", "[", ":", ",", "self", ".", "old_classes", "]", "\n", "self", ".", "old_logits", "=", "None", "\n", "\n", "", "return", "self", ".", "criterion", "(", "predictions", ",", "one_hot", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.losses.ICaRLLossPlugin.after_training_exp": [[47, 57], ["losses.ICaRLLossPlugin.old_model.load_state_dict", "numpy.unique().tolist", "copy.deepcopy", "copy.deepcopy.eval", "copy.deepcopy.to", "strategy.model.state_dict", "numpy.unique"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "old_model", "is", "None", ":", "\n", "            ", "old_model", "=", "copy", ".", "deepcopy", "(", "strategy", ".", "model", ")", "\n", "old_model", ".", "eval", "(", ")", "\n", "self", ".", "old_model", "=", "old_model", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "", "self", ".", "old_model", ".", "load_state_dict", "(", "strategy", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "\n", "self", ".", "old_classes", "+=", "np", ".", "unique", "(", "\n", "strategy", ".", "experience", ".", "dataset", ".", "targets", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.Naive.__init__": [[37, 67], ["torch.nn.CrossEntropyLoss", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "\n", "criterion", "=", "CrossEntropyLoss", "(", ")", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Naive strategy.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.PNNStrategy.__init__": [[72, 121], ["torch.nn.CrossEntropyLoss", "avalanche.models.pnn.PNN", "torch.optim.SGD", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "avalanche.models.pnn.PNN.parameters"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ":", "int", ",", "in_features", ":", "int", ",", "\n", "hidden_features_per_column", ":", "int", ",", "\n", "lr", ":", "float", ",", "momentum", "=", "0", ",", "dampening", "=", "0", ",", "\n", "weight_decay", "=", "0", ",", "nesterov", "=", "False", ",", "adapter", "=", "'mlp'", ",", "\n", "criterion", "=", "CrossEntropyLoss", "(", ")", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Progressive Neural Network strategy.\n\n        :param num_layers: Number of layers for the PNN architecture.\n        :param in_features: Number of input features.\n        :param hidden_features_per_column: Number of hidden units for\n            each column of the PNN architecture.\n        :param lr: learning rate\n        :param momentum: momentum factor (default: 0)\n        :param weight_decay: weight decay (L2 penalty) (default: 0)\n        :param dampening: dampening for momentum (default: 0)\n        :param nesterov: enables Nesterov momentum (default: False)\n        :param adapter: adapter type. One of {'linear', 'mlp'} (default='mlp')\n        :param criterion: The loss criterion to use.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "model", "=", "PNN", "(", "\n", "num_layers", "=", "num_layers", ",", "\n", "in_features", "=", "in_features", ",", "\n", "hidden_features_per_column", "=", "hidden_features_per_column", ",", "\n", "adapter", "=", "adapter", "\n", ")", "\n", "optimizer", "=", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "momentum", ",", "\n", "weight_decay", "=", "weight_decay", ",", "dampening", "=", "dampening", ",", "\n", "nesterov", "=", "nesterov", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.CWRStar.__init__": [[125, 160], ["avalanche.training.plugins.CWRStarPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "cwr_layer_name", ":", "str", ",", "train_mb_size", ":", "int", "=", "1", ",", "\n", "train_epochs", ":", "int", "=", "1", ",", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" \n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param cwr_layer_name: name of the CWR layer. Defaults to None, which\n            means that the last fully connected layer will be used.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "cwsp", "=", "CWRStarPlugin", "(", "model", ",", "cwr_layer_name", ",", "freeze_remaining_model", "=", "True", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "cwsp", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "cwsp", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.Replay.__init__": [[168, 206], ["avalanche.training.plugins.ReplayPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "mem_size", ":", "int", "=", "200", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param mem_size: replay buffer size.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "\n", "rp", "=", "ReplayPlugin", "(", "mem_size", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "rp", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "rp", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "\n", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "\n", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.GSS_greedy.__init__": [[214, 251], ["avalanche.training.plugins.GSS_greedyPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "mem_size", ":", "int", "=", "200", ",", "mem_strength", "=", "1", ",", "input_size", "=", "[", "]", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param mem_size: replay buffer size.\n        :param n: memory random set size.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "rp", "=", "GSS_greedyPlugin", "(", "mem_size", "=", "mem_size", ",", "\n", "mem_strength", "=", "mem_strength", ",", "input_size", "=", "input_size", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "rp", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "rp", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.GDumb.__init__": [[259, 296], ["avalanche.training.plugins.GDumbPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "mem_size", ":", "int", "=", "200", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param mem_size: replay buffer size.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "\n", "gdumb", "=", "GDumbPlugin", "(", "mem_size", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "gdumb", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "gdumb", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.LwF.__init__": [[305, 344], ["avalanche.training.plugins.LwFPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "alpha", ":", "Union", "[", "float", ",", "Sequence", "[", "float", "]", "]", ",", "temperature", ":", "float", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param alpha: distillation hyperparameter. It can be either a float\n                number or a list containing alpha for each experience.\n        :param temperature: softmax temperature for distillation\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "\n", "lwf", "=", "LwFPlugin", "(", "alpha", ",", "temperature", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "lwf", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "lwf", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.AGEM.__init__": [[353, 392], ["avalanche.training.plugins.AGEMPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "patterns_per_exp", ":", "int", ",", "sample_size", ":", "int", "=", "64", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param patterns_per_exp: number of patterns per experience in the memory\n        :param sample_size: number of patterns in memory sample when computing\n            reference gradient.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "\n", "agem", "=", "AGEMPlugin", "(", "patterns_per_exp", ",", "sample_size", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "agem", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "agem", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.GEM.__init__": [[401, 440], ["avalanche.training.plugins.GEMPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "patterns_per_exp", ":", "int", ",", "memory_strength", ":", "float", "=", "0.5", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param patterns_per_exp: number of patterns per experience in the memory\n        :param memory_strength: offset to add to the projection direction\n            in order to favour backward transfer (gamma in original paper).\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "\n", "gem", "=", "GEMPlugin", "(", "patterns_per_exp", ",", "memory_strength", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "gem", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "gem", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.EWC.__init__": [[449, 499], ["avalanche.training.plugins.EWCPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "ewc_lambda", ":", "float", ",", "mode", ":", "str", "=", "'separate'", ",", "\n", "decay_factor", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "keep_importance_data", ":", "bool", "=", "False", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param ewc_lambda: hyperparameter to weigh the penalty inside the total\n               loss. The larger the lambda, the larger the regularization.\n        :param mode: `separate` to keep a separate penalty for each previous\n               experience. `onlinesum` to keep a single penalty summed over all\n               previous tasks. `onlineweightedsum` to keep a single penalty\n               summed with a decay factor over all previous tasks.\n        :param decay_factor: used only if mode is `onlineweightedsum`.\n               It specify the decay term of the importance matrix.\n        :param keep_importance_data: if True, keep in memory both parameter\n                values and importances for all previous task, for all modes.\n                If False, keep only last parameter values and importances.\n                If mode is `separate`, the value of `keep_importance_data` is\n                set to be True.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "ewc", "=", "EWCPlugin", "(", "ewc_lambda", ",", "mode", ",", "decay_factor", ",", "keep_importance_data", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "ewc", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "ewc", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.SynapticIntelligence.__init__": [[517, 559], ["plugins.append", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "avalanche.training.plugins.SynapticIntelligencePlugin"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "si_lambda", ":", "Union", "[", "float", ",", "Sequence", "[", "float", "]", "]", ",", "\n", "eps", ":", "float", "=", "0.0000001", ",", "train_mb_size", ":", "int", "=", "1", ",", "\n", "train_epochs", ":", "int", "=", "1", ",", "eval_mb_size", ":", "int", "=", "1", ",", "device", "=", "'cpu'", ",", "\n", "plugins", ":", "Optional", "[", "Sequence", "[", "'StrategyPlugin'", "]", "]", "=", "None", ",", "\n", "evaluator", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        Creates an instance of the Synaptic Intelligence strategy.\n\n        :param model: PyTorch model.\n        :param optimizer: PyTorch optimizer.\n        :param criterion: loss function.\n        :param si_lambda: Synaptic Intelligence lambda term.\n            If list, one lambda for each experience. If the list has less\n            elements than the number of experiences, last lambda will be\n            used for the remaining experiences.\n        :param eps: Synaptic Intelligence damping parameter.\n        :param train_mb_size: mini-batch size for training.\n        :param train_epochs: number of training epochs.\n        :param eval_mb_size: mini-batch size for eval.\n        :param device: PyTorch device to run the model.\n        :param plugins: (optional) list of StrategyPlugins.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "]", "\n", "\n", "# This implementation relies on the S.I. Plugin, which contains the", "\n", "# entire implementation of the strategy!", "\n", "", "plugins", ".", "append", "(", "SynapticIntelligencePlugin", "(", "si_lambda", "=", "si_lambda", ",", "eps", "=", "eps", ")", ")", "\n", "\n", "super", "(", "SynapticIntelligence", ",", "self", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "train_mb_size", ",", "train_epochs", ",", "\n", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "evaluator", "=", "evaluator", ",", "\n", "eval_every", "=", "eval_every", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.CoPE.__init__": [[569, 615], ["avalanche.training.plugins.CoPEPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "mem_size", ":", "int", "=", "200", ",", "n_classes", ":", "int", "=", "10", ",", "p_size", ":", "int", "=", "100", ",", "\n", "alpha", ":", "float", "=", "0.99", ",", "T", ":", "float", "=", "0.1", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "\n", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: Loss criterion to use. Standard overwritten by\n        PPPloss (see CoPEPlugin).\n        :param mem_size: replay buffer size.\n        :param n_classes: total number of classes that will be encountered. This\n        is used to output predictions for all classes, with zero probability\n        for unseen classes.\n        :param p_size: The prototype size, which equals the feature size of the\n        last layer.\n        :param alpha: The momentum for the exponentially moving average of the\n        prototypes.\n        :param T: The softmax temperature, used as a concentration parameter.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "copep", "=", "CoPEPlugin", "(", "mem_size", ",", "n_classes", ",", "p_size", ",", "alpha", ",", "T", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "copep", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "copep", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.strategy_wrappers.LFL.__init__": [[625, 663], ["avalanche.training.plugins.LFLPlugin", "avalanche.training.strategies.base_strategy.BaseStrategy.__init__", "plugins.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "lambda_e", ":", "Union", "[", "float", ",", "Sequence", "[", "float", "]", "]", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param lambda_e: euclidean loss hyper parameter. It can be either a\n                float number or a list containing lambda_e for each experience.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "\n", "lfl", "=", "LFLPlugin", "(", "lambda_e", ")", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "lfl", "]", "\n", "", "else", ":", "\n", "            ", "plugins", ".", "append", "(", "lfl", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl.ICaRL.__init__": [[27, 80], ["avalanche.training.losses.ICaRLLossPlugin", "avalanche.models.TrainEvalModel", "_ICaRLPlugin._ICaRLPlugin", "isinstance", "avalanche.training.strategies.BaseStrategy.__init__", "avalanche.models.NCMClassifier"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "feature_extractor", ":", "Module", ",", "classifier", ":", "Module", ",", "\n", "optimizer", ":", "Optimizer", ",", "memory_size", ",", "buffer_transform", ",", "\n", "fixed_memory", ",", "criterion", "=", "ICaRLLossPlugin", "(", ")", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Init.\n\n        :param feature_extractor: The feature extractor.\n        :param classifier: The differentiable classifier that takes as input\n            the output of the feature extractor.\n        :param optimizer: The optimizer to use.\n        :param memory_size: The nuber of patterns saved in the memory.\n        :param buffer_transform: transform applied on buffer elements already\n            modified by test_transform (if specified) before being used for\n             replay\n        :param fixed_memory: If True a memory of size memory_size is\n            allocated and partitioned between samples from the observed\n            experiences. If False every time a new class is observed\n            memory_size samples of that class are added to the memory.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "model", "=", "TrainEvalModel", "(", "feature_extractor", ",", "\n", "train_classifier", "=", "classifier", ",", "\n", "eval_classifier", "=", "NCMClassifier", "(", ")", ")", "\n", "\n", "icarl", "=", "_ICaRLPlugin", "(", "memory_size", ",", "buffer_transform", ",", "fixed_memory", ")", "\n", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "icarl", "]", "\n", "", "else", ":", "\n", "            ", "plugins", "+=", "[", "icarl", "]", "\n", "\n", "", "if", "isinstance", "(", "criterion", ",", "StrategyPlugin", ")", ":", "\n", "            ", "plugins", "+=", "[", "criterion", "]", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", "=", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.__init__": [[92, 119], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "memory_size", ",", "buffer_transform", "=", "None", ",", "fixed_memory", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param memory_size: amount of patterns saved in the memory.\n        :param buffer_transform: transform applied on buffer elements already\n            modified by test_transform (if specified) before being used for\n             replay\n        :param fixed_memory: If True a memory of size memory_size is\n            allocated and partitioned between samples from the observed\n            experiences. If False every time a new class is observed\n            memory_size samples of that class are added to the memory.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "buffer_transform", "=", "buffer_transform", "\n", "self", ".", "fixed_memory", "=", "fixed_memory", "\n", "\n", "self", ".", "x_memory", "=", "[", "]", "\n", "self", ".", "y_memory", "=", "[", "]", "\n", "self", ".", "order", "=", "[", "]", "\n", "\n", "self", ".", "old_model", "=", "None", "\n", "self", ".", "observed_classes", "=", "[", "]", "\n", "self", ".", "class_means", "=", "None", "\n", "self", ".", "embedding_size", "=", "None", "\n", "self", ".", "output_size", "=", "None", "\n", "self", ".", "input_size", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.after_train_dataset_adaptation": [[120, 130], ["avalanche.benchmarks.utils.AvalancheTensorDataset", "avalanche.benchmarks.utils.AvalancheConcatDataset", "torch.cat().cpu", "list", "itertools.chain.from_iterable", "torch.cat"], "methods", ["None"], ["", "def", "after_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "if", "strategy", ".", "clock", ".", "train_exp_counter", "!=", "0", ":", "\n", "            ", "memory", "=", "AvalancheTensorDataset", "(", "\n", "torch", ".", "cat", "(", "self", ".", "x_memory", ")", ".", "cpu", "(", ")", ",", "\n", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "self", ".", "y_memory", ")", ")", ",", "\n", "transform", "=", "self", ".", "buffer_transform", ",", "target_transform", "=", "None", ")", "\n", "\n", "strategy", ".", "adapted_dataset", "=", "AvalancheConcatDataset", "(", "(", "strategy", ".", "adapted_dataset", ",", "memory", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.before_training_exp": [[131, 140], ["sum", "icarl._ICaRLPlugin.observed_classes.extend"], "methods", ["None"], ["", "", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "tid", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "benchmark", "=", "strategy", ".", "experience", ".", "benchmark", "\n", "nb_cl", "=", "benchmark", ".", "n_classes_per_exp", "[", "tid", "]", "\n", "previous_seen_classes", "=", "sum", "(", "benchmark", ".", "n_classes_per_exp", "[", ":", "tid", "]", ")", "\n", "\n", "self", ".", "observed_classes", ".", "extend", "(", "\n", "benchmark", ".", "classes_order", "[", "previous_seen_classes", ":", "\n", "previous_seen_classes", "+", "nb_cl", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.before_forward": [[141, 148], ["torch.no_grad", "strategy.model", "strategy.model.feature_extractor"], "methods", ["None"], ["", "def", "before_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "input_size", "is", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "input_size", "=", "strategy", ".", "mb_x", ".", "shape", "[", "1", ":", "]", "\n", "self", ".", "output_size", "=", "strategy", ".", "model", "(", "strategy", ".", "mb_x", ")", ".", "shape", "[", "1", "]", "\n", "self", ".", "embedding_size", "=", "strategy", ".", "model", ".", "feature_extractor", "(", "\n", "strategy", ".", "mb_x", ")", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.after_training_exp": [[149, 155], ["strategy.model.eval", "icarl._ICaRLPlugin.construct_exemplar_set", "icarl._ICaRLPlugin.reduce_exemplar_set", "icarl._ICaRLPlugin.compute_class_means"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.construct_exemplar_set", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.reduce_exemplar_set", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.compute_class_means"], ["", "", "", "def", "after_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "strategy", ".", "model", ".", "eval", "(", ")", "\n", "\n", "self", ".", "construct_exemplar_set", "(", "strategy", ")", "\n", "self", ".", "reduce_exemplar_set", "(", "strategy", ")", "\n", "self", ".", "compute_class_means", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.compute_class_means": [[156, 191], ["enumerate", "sum", "torch.zeros().to", "torch.flip.to", "torch.ones", "torch.mm().squeeze", "torch.mm().squeeze", "torch.norm", "torch.no_grad", "strategy.model.feature_extractor().detach", "torch.norm", "len", "torch.flip", "torch.no_grad", "strategy.model.feature_extractor().detach", "torch.norm", "torch.zeros", "torch.mm", "torch.mm", "strategy.model.feature_extractor", "strategy.model.feature_extractor", "torch.ones.unsqueeze", "torch.ones.unsqueeze"], "methods", ["None"], ["", "def", "compute_class_means", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "if", "self", ".", "class_means", "is", "None", ":", "\n", "            ", "n_classes", "=", "sum", "(", "strategy", ".", "experience", ".", "benchmark", ".", "n_classes_per_exp", ")", "\n", "self", ".", "class_means", "=", "torch", ".", "zeros", "(", "\n", "(", "self", ".", "embedding_size", ",", "n_classes", ")", ")", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "", "for", "i", ",", "class_samples", "in", "enumerate", "(", "self", ".", "x_memory", ")", ":", "\n", "            ", "label", "=", "self", ".", "y_memory", "[", "i", "]", "[", "0", "]", "\n", "class_samples", "=", "class_samples", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "mapped_prototypes", "=", "strategy", ".", "model", ".", "feature_extractor", "(", "\n", "class_samples", ")", ".", "detach", "(", ")", "\n", "", "D", "=", "mapped_prototypes", ".", "T", "\n", "D", "=", "D", "/", "torch", ".", "norm", "(", "D", ",", "dim", "=", "0", ")", "\n", "\n", "if", "len", "(", "class_samples", ".", "shape", ")", "==", "4", ":", "\n", "                ", "class_samples", "=", "torch", ".", "flip", "(", "class_samples", ",", "[", "3", "]", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "mapped_prototypes2", "=", "strategy", ".", "model", ".", "feature_extractor", "(", "\n", "class_samples", ")", ".", "detach", "(", ")", "\n", "\n", "", "D2", "=", "mapped_prototypes2", ".", "T", "\n", "D2", "=", "D2", "/", "torch", ".", "norm", "(", "D2", ",", "dim", "=", "0", ")", "\n", "\n", "div", "=", "torch", ".", "ones", "(", "class_samples", ".", "shape", "[", "0", "]", ",", "device", "=", "strategy", ".", "device", ")", "\n", "div", "=", "div", "/", "class_samples", ".", "shape", "[", "0", "]", "\n", "\n", "m1", "=", "torch", ".", "mm", "(", "D", ",", "div", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "m2", "=", "torch", ".", "mm", "(", "D2", ",", "div", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "self", ".", "class_means", "[", ":", ",", "label", "]", "=", "(", "m1", "+", "m2", ")", "/", "2", "\n", "self", ".", "class_means", "[", ":", ",", "label", "]", "/=", "torch", ".", "norm", "(", "self", ".", "class_means", "[", ":", ",", "label", "]", ")", "\n", "\n", "strategy", ".", "model", ".", "eval_classifier", ".", "class_means", "=", "self", ".", "class_means", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.construct_exemplar_set": [[192, 245], ["sum", "torch.tensor", "range", "int", "avalanche.benchmarks.utils.AvalancheSubset", "next", "class_patterns.to.to.to", "torch.mean", "torch.zeros", "icarl._ICaRLPlugin.x_memory.append", "icarl._ICaRLPlugin.y_memory.append", "icarl._ICaRLPlugin.order.append", "math.ceil", "iter", "torch.no_grad", "strategy.model.feature_extractor().detach", "torch.norm", "torch.mm", "torch.argmax", "torch.where", "torch.utils.data.DataLoader", "w_t.unsqueeze", "selected.append", "len", "len", "avalanche.benchmarks.utils.AvalancheSubset.eval", "strategy.model.feature_extractor", "torch.argmax.item", "len", "torch.where", "torch.where", "torch.where"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], ["", "", "def", "construct_exemplar_set", "(", "self", ",", "strategy", ":", "BaseStrategy", ")", ":", "\n", "        ", "tid", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "benchmark", "=", "strategy", ".", "experience", ".", "benchmark", "\n", "nb_cl", "=", "benchmark", ".", "n_classes_per_exp", "[", "tid", "]", "\n", "previous_seen_classes", "=", "sum", "(", "benchmark", ".", "n_classes_per_exp", "[", ":", "tid", "]", ")", "\n", "\n", "if", "self", ".", "fixed_memory", ":", "\n", "            ", "nb_protos_cl", "=", "int", "(", "ceil", "(", "\n", "self", ".", "memory_size", "/", "len", "(", "self", ".", "observed_classes", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "nb_protos_cl", "=", "self", ".", "memory_size", "\n", "", "new_classes", "=", "self", ".", "observed_classes", "[", "previous_seen_classes", ":", "\n", "previous_seen_classes", "+", "nb_cl", "]", "\n", "\n", "dataset", "=", "strategy", ".", "experience", ".", "dataset", "\n", "targets", "=", "torch", ".", "tensor", "(", "dataset", ".", "targets", ")", "\n", "for", "iter_dico", "in", "range", "(", "nb_cl", ")", ":", "\n", "            ", "cd", "=", "AvalancheSubset", "(", "dataset", ",", "\n", "torch", ".", "where", "(", "targets", "==", "new_classes", "[", "iter_dico", "]", ")", "\n", "[", "0", "]", ")", "\n", "\n", "class_patterns", ",", "_", ",", "_", "=", "next", "(", "iter", "(", "\n", "DataLoader", "(", "cd", ".", "eval", "(", ")", ",", "batch_size", "=", "len", "(", "cd", ")", ")", ")", ")", "\n", "class_patterns", "=", "class_patterns", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "mapped_prototypes", "=", "strategy", ".", "model", ".", "feature_extractor", "(", "\n", "class_patterns", ")", ".", "detach", "(", ")", "\n", "", "D", "=", "mapped_prototypes", ".", "T", "\n", "D", "=", "D", "/", "torch", ".", "norm", "(", "D", ",", "dim", "=", "0", ")", "\n", "\n", "mu", "=", "torch", ".", "mean", "(", "D", ",", "dim", "=", "1", ")", "\n", "order", "=", "torch", ".", "zeros", "(", "class_patterns", ".", "shape", "[", "0", "]", ")", "\n", "w_t", "=", "mu", "\n", "\n", "i", ",", "added", ",", "selected", "=", "0", ",", "0", ",", "[", "]", "\n", "while", "not", "added", "==", "nb_protos_cl", "and", "i", "<", "1000", ":", "\n", "                ", "tmp_t", "=", "torch", ".", "mm", "(", "w_t", ".", "unsqueeze", "(", "0", ")", ",", "D", ")", "\n", "ind_max", "=", "torch", ".", "argmax", "(", "tmp_t", ")", "\n", "\n", "if", "ind_max", "not", "in", "selected", ":", "\n", "                    ", "order", "[", "ind_max", "]", "=", "1", "+", "added", "\n", "added", "+=", "1", "\n", "selected", ".", "append", "(", "ind_max", ".", "item", "(", ")", ")", "\n", "\n", "", "w_t", "=", "w_t", "+", "mu", "-", "D", "[", ":", ",", "ind_max", "]", "\n", "i", "+=", "1", "\n", "\n", "", "pick", "=", "(", "order", ">", "0", ")", "*", "(", "order", "<", "nb_protos_cl", "+", "1", ")", "*", "1.", "\n", "self", ".", "x_memory", ".", "append", "(", "class_patterns", "[", "torch", ".", "where", "(", "pick", "==", "1", ")", "[", "0", "]", "]", ")", "\n", "self", ".", "y_memory", ".", "append", "(", "\n", "[", "new_classes", "[", "iter_dico", "]", "]", "*", "len", "(", "torch", ".", "where", "(", "pick", "==", "1", ")", "[", "0", "]", ")", ")", "\n", "self", ".", "order", ".", "append", "(", "order", "[", "torch", ".", "where", "(", "pick", "==", "1", ")", "[", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.icarl._ICaRLPlugin.reduce_exemplar_set": [[246, 261], ["range", "int", "math.ceil", "len", "len", "len", "torch.where", "torch.where", "torch.where"], "methods", ["None"], ["", "", "def", "reduce_exemplar_set", "(", "self", ",", "strategy", ":", "BaseStrategy", ")", ":", "\n", "        ", "tid", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "nb_cl", "=", "strategy", ".", "experience", ".", "benchmark", ".", "n_classes_per_exp", "\n", "\n", "if", "self", ".", "fixed_memory", ":", "\n", "            ", "nb_protos_cl", "=", "int", "(", "ceil", "(", "\n", "self", ".", "memory_size", "/", "len", "(", "self", ".", "observed_classes", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "nb_protos_cl", "=", "self", ".", "memory_size", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "x_memory", ")", "-", "nb_cl", "[", "tid", "]", ")", ":", "\n", "            ", "pick", "=", "(", "self", ".", "order", "[", "i", "]", "<", "nb_protos_cl", "+", "1", ")", "*", "1.", "\n", "self", ".", "x_memory", "[", "i", "]", "=", "self", ".", "x_memory", "[", "i", "]", "[", "torch", ".", "where", "(", "pick", "==", "1", ")", "[", "0", "]", "]", "\n", "self", ".", "y_memory", "[", "i", "]", "=", "self", ".", "y_memory", "[", "i", "]", "[", ":", "len", "(", "torch", ".", "where", "(", "pick", "==", "1", ")", "[", "0", "]", ")", "]", "\n", "self", ".", "order", "[", "i", "]", "=", "self", ".", "order", "[", "i", "]", "[", "torch", ".", "where", "(", "pick", "==", "1", ")", "[", "0", "]", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.ar1.AR1.__init__": [[33, 134], ["warnings.warn", "avalanche.models.MobilenetV1", "avalanche.training.utils.replace_bn_with_brn", "avalanche.training.utils.get_last_fc_layer", "avalanche.training.plugins.CWRStarPlugin", "plugins.append", "torch.optim.SGD", "avalanche.training.strategies.BaseStrategy.__init__", "plugins.append", "avalanche.models.MobilenetV1.parameters", "torch.nn.CrossEntropyLoss", "avalanche.training.plugins.SynapticIntelligencePlugin"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.replace_bn_with_brn", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_last_fc_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "criterion", "=", "None", ",", "lr", ":", "float", "=", "0.001", ",", "momentum", "=", "0.9", ",", "\n", "l2", "=", "0.0005", ",", "train_epochs", ":", "int", "=", "4", ",", "\n", "init_update_rate", ":", "float", "=", "0.01", ",", "\n", "inc_update_rate", "=", "0.00005", ",", "\n", "max_r_max", "=", "1.25", ",", "max_d_max", "=", "0.5", ",", "inc_step", "=", "4.1e-05", ",", "\n", "rm_sz", ":", "int", "=", "1500", ",", "\n", "freeze_below_layer", ":", "str", "=", "\"lat_features.19.bn.beta\"", ",", "\n", "latent_layer_num", ":", "int", "=", "19", ",", "ewc_lambda", ":", "float", "=", "0", ",", "\n", "train_mb_size", ":", "int", "=", "128", ",", "eval_mb_size", ":", "int", "=", "128", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "Sequence", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the AR1 strategy.\n\n        :param criterion: The loss criterion to use. Defaults to None, in which\n            case the cross entropy loss is used.\n        :param lr: The learning rate (SGD optimizer).\n        :param momentum: The momentum (SGD optimizer).\n        :param l2: The L2 penalty used for weight decay.\n        :param train_epochs: The number of training epochs. Defaults to 4.\n        :param init_update_rate: The initial update rate of BatchReNorm layers.\n        :param inc_update_rate: The incremental update rate of BatchReNorm\n            layers.\n        :param max_r_max: The maximum r value of BatchReNorm layers.\n        :param max_d_max: The maximum d value of BatchReNorm layers.\n        :param inc_step: The incremental step of r and d values of BatchReNorm\n            layers.\n        :param rm_sz: The size of the replay buffer. The replay buffer is shared\n            across classes. Defaults to 1500.\n        :param freeze_below_layer: A string describing the name of the layer\n            to use while freezing the lower (nearest to the input) part of the\n            model. The given layer is not frozen (exclusive).\n        :param latent_layer_num: The number of the layer to use as the Latent\n            Replay Layer. Usually this is the same of `freeze_below_layer`.\n        :param ewc_lambda: The Synaptic Intelligence lambda term. Defaults to\n            0, which means that the Synaptic Intelligence regularization\n            will not be applied.\n        :param train_mb_size: The train minibatch size. Defaults to 128.\n        :param eval_mb_size: The eval minibatch size. Defaults to 128.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: (optional) list of StrategyPlugins.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop.\n                if -1: no evaluation during training.\n                if  0: calls `eval` after the final epoch of each training\n                    experience.\n                if >0: calls `eval` every `eval_every` epochs and at the end\n                    of all the epochs for a single experience.\n        \"\"\"", "\n", "\n", "warnings", ".", "warn", "(", "\"The AR1 strategy implementation is in an alpha stage \"", "\n", "\"and is not perfectly aligned with the paper \"", "\n", "\"implementation. Please use at your own risk!\"", ")", "\n", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "]", "\n", "\n", "# Model setup", "\n", "", "model", "=", "MobilenetV1", "(", "pretrained", "=", "True", ",", "latent_layer_num", "=", "latent_layer_num", ")", "\n", "replace_bn_with_brn", "(", "\n", "model", ",", "momentum", "=", "init_update_rate", ",", "r_d_max_inc_step", "=", "inc_step", ",", "\n", "max_r_max", "=", "max_r_max", ",", "max_d_max", "=", "max_d_max", ")", "\n", "\n", "fc_name", ",", "fc_layer", "=", "get_last_fc_layer", "(", "model", ")", "\n", "\n", "if", "ewc_lambda", "!=", "0", ":", "\n", "# Synaptic Intelligence is not applied to the last fully", "\n", "# connected layer (and implicitly to \"freeze below\" ones.", "\n", "            ", "plugins", ".", "append", "(", "SynapticIntelligencePlugin", "(", "\n", "ewc_lambda", ",", "excluded_parameters", "=", "[", "fc_name", "]", ")", ")", "\n", "\n", "", "self", ".", "cwr_plugin", "=", "CWRStarPlugin", "(", "model", ",", "cwr_layer_name", "=", "fc_name", ",", "\n", "freeze_remaining_model", "=", "False", ")", "\n", "plugins", ".", "append", "(", "self", ".", "cwr_plugin", ")", "\n", "\n", "optimizer", "=", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "momentum", ",", "\n", "weight_decay", "=", "l2", ")", "\n", "\n", "if", "criterion", "is", "None", ":", "\n", "            ", "criterion", "=", "CrossEntropyLoss", "(", ")", "\n", "\n", "", "self", ".", "ewc_lambda", "=", "ewc_lambda", "\n", "self", ".", "freeze_below_layer", "=", "freeze_below_layer", "\n", "self", ".", "rm_sz", "=", "rm_sz", "\n", "self", ".", "inc_update_rate", "=", "inc_update_rate", "\n", "self", ".", "max_r_max", "=", "max_r_max", "\n", "self", ".", "max_d_max", "=", "max_d_max", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "l2", "=", "l2", "\n", "self", ".", "rm", "=", "None", "\n", "self", ".", "cur_acts", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "self", ".", "replay_mb_size", "=", "0", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.ar1.AR1._before_training_exp": [[135, 175], ["ar1.AR1.model.eval", "ar1.AR1.model.end_features.train", "ar1.AR1.model.output.train", "super()._before_training_exp", "avalanche.training.utils.freeze_up_to", "avalanche.training.utils.change_brn_pars", "ar1.AR1.model.to", "torch.optim.SGD", "avalanche.training.utils.examples_per_class().items", "ar1.AR1.cwr_plugin.reset_weights", "ar1.AR1.model.parameters", "avalanche.training.utils.examples_per_class", "set", "ar1.AR1.model.cur_j.keys"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.freeze_up_to", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.change_brn_pars", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.reset_weights", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.examples_per_class"], ["", "def", "_before_training_exp", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "model", ".", "end_features", ".", "train", "(", ")", "\n", "self", ".", "model", ".", "output", ".", "train", "(", ")", "\n", "\n", "if", "self", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "# In AR1 batch 0 is treated differently as the feature extractor is", "\n", "# left more free to learn.", "\n", "# This if is executed for batch > 0, in which we freeze layers", "\n", "# below \"self.freeze_below_layer\" (which usually is the latent", "\n", "# replay layer!) and we also change the parameters of BatchReNorm", "\n", "# layers to a more conservative configuration.", "\n", "\n", "# \"freeze_up_to\" will freeze layers below \"freeze_below_layer\"", "\n", "# Beware that Batch ReNorm layers are not frozen!", "\n", "            ", "freeze_up_to", "(", "self", ".", "model", ",", "freeze_until_layer", "=", "self", ".", "freeze_below_layer", ",", "\n", "layer_filter", "=", "AR1", ".", "filter_bn_and_brn", ")", "\n", "\n", "# Adapt the parameters of BatchReNorm layers", "\n", "change_brn_pars", "(", "self", ".", "model", ",", "momentum", "=", "self", ".", "inc_update_rate", ",", "\n", "r_d_max_inc_step", "=", "0", ",", "r_max", "=", "self", ".", "max_r_max", ",", "\n", "d_max", "=", "self", ".", "max_d_max", ")", "\n", "\n", "# Adapt the model and optimizer", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "optimizer", "=", "SGD", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "momentum", "=", "self", ".", "momentum", ",", "\n", "weight_decay", "=", "self", ".", "l2", ")", "\n", "\n", "# super()... will run S.I. and CWR* plugin callbacks", "\n", "", "super", "(", ")", ".", "_before_training_exp", "(", "**", "kwargs", ")", "\n", "\n", "# Update cur_j of CWR* to consider latent patterns", "\n", "if", "self", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "            ", "for", "class_id", ",", "count", "in", "examples_per_class", "(", "self", ".", "rm", "[", "1", "]", ")", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "model", ".", "cur_j", "[", "class_id", "]", "+=", "count", "\n", "", "self", ".", "cwr_plugin", ".", "cur_class", "=", "[", "\n", "cls", "for", "cls", "in", "set", "(", "self", ".", "model", ".", "cur_j", ".", "keys", "(", ")", ")", "\n", "if", "self", ".", "model", ".", "cur_j", "[", "cls", "]", ">", "0", "]", "\n", "self", ".", "cwr_plugin", ".", "reset_weights", "(", "self", ".", "cwr_plugin", ".", "cur_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.ar1.AR1.make_train_dataloader": [[176, 212], ["max", "max", "torch.utils.data.DataLoader", "len"], "methods", ["None"], ["", "", "def", "make_train_dataloader", "(", "self", ",", "num_workers", "=", "0", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Called after the dataset instantiation. Initialize the data loader.\n\n        For AR1 a \"custom\" dataloader is used: instead of using\n        `self.train_mb_size` as the batch size, the data loader batch size will\n        be computed ad `self.train_mb_size - latent_mb_size`. `latent_mb_size`\n        is in turn computed as:\n\n        `\n        len(train_dataset) // ((len(train_dataset) + len(replay_buffer)\n        // self.train_mb_size)\n        `\n\n        so that the number of iterations required to run an epoch on the current\n        batch is equal to the number of iterations required to run an epoch\n        on the replay buffer.\n\n        :param num_workers: number of thread workers for the data loading.\n        :param shuffle: True if the data should be shuffled, False otherwise.\n        \"\"\"", "\n", "\n", "current_batch_mb_size", "=", "self", ".", "train_mb_size", "\n", "\n", "if", "self", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "            ", "train_patterns", "=", "len", "(", "self", ".", "adapted_dataset", ")", "\n", "current_batch_mb_size", "=", "train_patterns", "//", "(", "\n", "(", "train_patterns", "+", "self", ".", "rm_sz", ")", "//", "self", ".", "train_mb_size", ")", "\n", "\n", "", "current_batch_mb_size", "=", "max", "(", "1", ",", "current_batch_mb_size", ")", "\n", "self", ".", "replay_mb_size", "=", "max", "(", "0", ",", "self", ".", "train_mb_size", "-", "current_batch_mb_size", ")", "\n", "\n", "# AR1 only supports SIT scenarios (no task labels).", "\n", "self", ".", "dataloader", "=", "DataLoader", "(", "\n", "self", ".", "adapted_dataset", ",", "num_workers", "=", "num_workers", ",", "\n", "batch_size", "=", "current_batch_mb_size", ",", "shuffle", "=", "shuffle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.ar1.AR1.training_epoch": [[213, 261], ["enumerate", "ar1.AR1._before_training_iteration", "ar1.AR1.optimizer.zero_grad", "ar1.AR1._before_forward", "ar1.AR1.model", "ar1.AR1._after_forward", "ar1.AR1._criterion", "ar1.AR1._before_backward", "ar1.AR1.loss.backward", "ar1.AR1._after_backward", "ar1.AR1._before_update", "ar1.AR1.optimizer.step", "ar1.AR1._after_update", "ar1.AR1._after_training_iteration", "lat_mb_x.to.to.to", "lat_mb_y.to.to.to", "torch.cat", "lat_acts.detach().clone().cpu.detach().clone().cpu.detach().clone().cpu", "torch.cat", "lat_acts.detach().clone().cpu.detach().clone().cpu.detach().clone", "lat_acts.detach().clone().cpu.detach().clone().cpu.detach"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_backward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_backward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_iteration"], ["", "def", "training_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "mb_it", ",", "self", ".", "mbatch", "in", "enumerate", "(", "self", ".", "dataloader", ")", ":", "\n", "            ", "self", ".", "_before_training_iteration", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "                ", "lat_mb_x", "=", "self", ".", "rm", "[", "0", "]", "[", "mb_it", "*", "self", ".", "replay_mb_size", ":", "\n", "(", "mb_it", "+", "1", ")", "*", "self", ".", "replay_mb_size", "]", "\n", "lat_mb_x", "=", "lat_mb_x", ".", "to", "(", "self", ".", "device", ")", "\n", "lat_mb_y", "=", "self", ".", "rm", "[", "1", "]", "[", "mb_it", "*", "self", ".", "replay_mb_size", ":", "\n", "(", "mb_it", "+", "1", ")", "*", "self", ".", "replay_mb_size", "]", "\n", "lat_mb_y", "=", "lat_mb_y", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "mbatch", "[", "1", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "mb_y", ",", "lat_mb_y", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "lat_mb_x", "=", "None", "\n", "\n", "# Forward pass. Here we are injecting latent patterns lat_mb_x.", "\n", "# lat_mb_x will be None for the very first batch (batch 0), which", "\n", "# means that lat_acts.shape[0] == self.mb_x[0].", "\n", "", "self", ".", "_before_forward", "(", "**", "kwargs", ")", "\n", "self", ".", "mb_output", ",", "lat_acts", "=", "self", ".", "model", "(", "\n", "self", ".", "mb_x", ",", "latent_input", "=", "lat_mb_x", ",", "return_lat_acts", "=", "True", ")", "\n", "\n", "if", "self", ".", "epoch", "==", "0", ":", "\n", "# On the first epoch only: store latent activations. Those", "\n", "# activations will be used to update the replay buffer.", "\n", "                ", "lat_acts", "=", "lat_acts", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "cpu", "(", ")", "\n", "if", "mb_it", "==", "0", ":", "\n", "                    ", "self", ".", "cur_acts", "=", "lat_acts", "\n", "", "else", ":", "\n", "                    ", "self", ".", "cur_acts", "=", "torch", ".", "cat", "(", "(", "self", ".", "cur_acts", ",", "lat_acts", ")", ",", "0", ")", "\n", "", "", "self", ".", "_after_forward", "(", "**", "kwargs", ")", "\n", "\n", "# Loss & Backward", "\n", "# We don't need to handle latent replay, as self.mb_y already", "\n", "# contains both current and replay labels.", "\n", "self", ".", "loss", "=", "self", ".", "_criterion", "(", "self", ".", "mb_output", ",", "self", ".", "mb_y", ")", "\n", "self", ".", "_before_backward", "(", "**", "kwargs", ")", "\n", "self", ".", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_after_backward", "(", "**", "kwargs", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "_before_update", "(", "**", "kwargs", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "_after_update", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_after_training_iteration", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.ar1.AR1._after_training_exp": [[262, 287], ["min", "torch.tensor", "super()._after_training_exp", "ar1.AR1.cur_acts.size", "torch.randperm", "enumerate", "ar1.AR1.cur_acts.size", "torch.randperm", "int", "ar1.AR1.rm[].size"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_exp"], ["", "", "def", "_after_training_exp", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "h", "=", "min", "(", "self", ".", "rm_sz", "//", "(", "self", ".", "clock", ".", "train_exp_counter", "+", "1", ")", ",", "\n", "self", ".", "cur_acts", ".", "size", "(", "0", ")", ")", "\n", "\n", "curr_data", "=", "self", ".", "experience", ".", "dataset", "\n", "idxs_cur", "=", "torch", ".", "randperm", "(", "self", ".", "cur_acts", ".", "size", "(", "0", ")", ")", "[", ":", "h", "]", "\n", "rm_add_y", "=", "torch", ".", "tensor", "(", "\n", "[", "curr_data", ".", "targets", "[", "idx_cur", "]", "for", "idx_cur", "in", "idxs_cur", "]", ")", "\n", "\n", "rm_add", "=", "[", "self", ".", "cur_acts", "[", "idxs_cur", "]", ",", "rm_add_y", "]", "\n", "\n", "# replace patterns in random memory", "\n", "if", "self", ".", "clock", ".", "train_exp_counter", "==", "0", ":", "\n", "            ", "self", ".", "rm", "=", "rm_add", "\n", "", "else", ":", "\n", "            ", "idxs_2_replace", "=", "torch", ".", "randperm", "(", "self", ".", "rm", "[", "0", "]", ".", "size", "(", "0", ")", ")", "[", ":", "h", "]", "\n", "for", "j", ",", "idx", "in", "enumerate", "(", "idxs_2_replace", ")", ":", "\n", "                ", "idx", "=", "int", "(", "idx", ")", "\n", "self", ".", "rm", "[", "0", "]", "[", "idx", "]", "=", "rm_add", "[", "0", "]", "[", "j", "]", "\n", "self", ".", "rm", "[", "1", "]", "[", "idx", "]", "=", "rm_add", "[", "1", "]", "[", "j", "]", "\n", "\n", "", "", "self", ".", "cur_acts", "=", "None", "\n", "\n", "# Runs S.I. and CWR* plugin callbacks", "\n", "super", "(", ")", ".", "_after_training_exp", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.ar1.AR1.filter_bn_and_brn": [[288, 291], ["isinstance"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "filter_bn_and_brn", "(", "param_def", ":", "LayerAndParameter", ")", ":", "\n", "        ", "return", "not", "isinstance", "(", "param_def", ".", "layer", ",", "(", "_NormBase", ",", "BatchRenorm2D", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.__init__": [[28, 83], ["avalanche.models.FeatureExtractorBackbone().eval.eval", "avalanche.training.strategies.BaseStrategy.__init__", "torch.zeros().to", "torch.zeros().to", "torch.ones().to", "torch.zeros_like().to", "avalanche.models.FeatureExtractorBackbone().eval", "torch.zeros", "torch.zeros", "torch.ones", "torch.zeros_like", "avalanche.models.FeatureExtractorBackbone", "avalanche.models.FeatureExtractorBackbone().eval.to"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], ["def", "__init__", "(", "self", ",", "slda_model", ",", "criterion", ",", "\n", "input_size", ",", "num_classes", ",", "output_layer_name", "=", "None", ",", "\n", "shrinkage_param", "=", "1e-4", ",", "streaming_update_sigma", "=", "True", ",", "\n", "train_epochs", ":", "int", "=", "1", ",", "train_mb_size", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "1", ",", "device", "=", "'cpu'", ",", "\n", "plugins", ":", "Optional", "[", "Sequence", "[", "'StrategyPlugin'", "]", "]", "=", "None", ",", "\n", "evaluator", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Init function for the SLDA model.\n\n        :param slda_model: a PyTorch model\n        :param criterion: loss function\n        :param output_layer_name: if not None, wrap model to retrieve\n            only the `output_layer_name` output. If None, the strategy\n            assumes that the model already produces a valid output.\n            You can use `FeatureExtractorBackbone` class to create your custom\n            SLDA-compatible model.\n        :param input_size: feature dimension\n        :param num_classes: number of total classes in stream\n        :param train_mb_size: batch size for feature extractor during\n            training. Fit will be called on a single pattern at a time.\n        :param eval_mb_size: batch size for inference\n        :param shrinkage_param: value of the shrinkage parameter\n        :param streaming_update_sigma: True if sigma is plastic else False\n        feature extraction in `self.feature_extraction_wrapper'\n        :param plugins: list of StrategyPlugins\n        :param evaluator: Evaluation Plugin instance\n        :param eval_every: run eval every `eval_every` epochs.\n            See `BaseStrategy` for details.\n        \"\"\"", "\n", "\n", "if", "plugins", "is", "None", ":", "\n", "            ", "plugins", "=", "[", "]", "\n", "\n", "", "slda_model", "=", "slda_model", ".", "eval", "(", ")", "\n", "if", "output_layer_name", "is", "not", "None", ":", "\n", "            ", "slda_model", "=", "FeatureExtractorBackbone", "(", "slda_model", ".", "to", "(", "device", ")", ",", "\n", "output_layer_name", ")", ".", "eval", "(", ")", "\n", "\n", "", "super", "(", "StreamingLDA", ",", "self", ")", ".", "__init__", "(", "\n", "slda_model", ",", "None", ",", "criterion", ",", "train_mb_size", ",", "train_epochs", ",", "\n", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "evaluator", "=", "evaluator", ",", "\n", "eval_every", "=", "eval_every", ")", "\n", "\n", "# SLDA parameters", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "shrinkage_param", "=", "shrinkage_param", "\n", "self", ".", "streaming_update_sigma", "=", "streaming_update_sigma", "\n", "\n", "# setup weights for SLDA", "\n", "self", ".", "muK", "=", "torch", ".", "zeros", "(", "(", "num_classes", ",", "input_size", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "cK", "=", "torch", ".", "zeros", "(", "num_classes", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "Sigma", "=", "torch", ".", "ones", "(", "(", "input_size", ",", "input_size", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "num_updates", "=", "0", "\n", "self", ".", "Lambda", "=", "torch", ".", "zeros_like", "(", "self", ".", "Sigma", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "prev_num_updates", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.forward": [[84, 96], ["deep_slda.StreamingLDA.model.eval", "isinstance", "deep_slda.StreamingLDA.predict", "deep_slda.StreamingLDA.model", "deep_slda.StreamingLDA.model"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.predict"], ["", "def", "forward", "(", "self", ",", "return_features", "=", "False", ")", ":", "\n", "        ", "\"\"\"Compute the model's output given the current mini-batch.\"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "MultiTaskModule", ")", ":", "\n", "            ", "feat", "=", "self", ".", "model", "(", "self", ".", "mb_x", ",", "self", ".", "mb_task_id", ")", "\n", "", "else", ":", "# no task labels", "\n", "            ", "feat", "=", "self", ".", "model", "(", "self", ".", "mb_x", ")", "\n", "", "out", "=", "self", ".", "predict", "(", "feat", ")", "\n", "if", "return_features", ":", "\n", "            ", "return", "out", ",", "feat", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.training_epoch": [[97, 126], ["enumerate", "deep_slda.StreamingLDA._unpack_minibatch", "deep_slda.StreamingLDA._before_training_iteration", "deep_slda.StreamingLDA._before_forward", "deep_slda.StreamingLDA.forward", "deep_slda.StreamingLDA._after_forward", "deep_slda.StreamingLDA.criterion", "deep_slda.StreamingLDA._before_update", "zip", "deep_slda.StreamingLDA._after_update", "deep_slda.StreamingLDA._after_training_iteration", "deep_slda.StreamingLDA.fit", "f.unsqueeze", "y.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._unpack_minibatch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.fit"], ["", "", "def", "training_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Training epoch.\n        :param kwargs:\n        :return:\n        \"\"\"", "\n", "for", "_", ",", "self", ".", "mbatch", "in", "enumerate", "(", "self", ".", "dataloader", ")", ":", "\n", "            ", "self", ".", "_unpack_minibatch", "(", ")", "\n", "self", ".", "_before_training_iteration", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "loss", "=", "0", "\n", "\n", "# Forward", "\n", "self", ".", "_before_forward", "(", "**", "kwargs", ")", "\n", "# compute output on entire minibatch", "\n", "self", ".", "mb_output", ",", "feats", "=", "self", ".", "forward", "(", "return_features", "=", "True", ")", "\n", "self", ".", "_after_forward", "(", "**", "kwargs", ")", "\n", "\n", "# Loss & Backward", "\n", "self", ".", "loss", "+=", "self", ".", "criterion", "(", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "_before_update", "(", "**", "kwargs", ")", "\n", "# process one element at a time", "\n", "for", "f", ",", "y", "in", "zip", "(", "feats", ",", "self", ".", "mb_y", ")", ":", "\n", "                ", "self", ".", "fit", "(", "f", ".", "unsqueeze", "(", "0", ")", ",", "y", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "self", ".", "_after_update", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_after_training_iteration", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.make_optimizer": [[127, 131], ["None"], "methods", ["None"], ["", "", "def", "make_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Empty function.\n        Deep SLDA does not need a Pytorch optimizer.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.fit": [[132, 153], ["torch.no_grad", "torch.matmul", "x_minus_mu.transpose"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fit", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Fit the SLDA model to a new sample (x,y).\n        :param x: a torch tensor of the input data (must be a vector)\n        :param y: a torch tensor of the input label\n        :return: None\n        \"\"\"", "\n", "\n", "# covariance updates", "\n", "if", "self", ".", "streaming_update_sigma", ":", "\n", "            ", "x_minus_mu", "=", "(", "x", "-", "self", ".", "muK", "[", "y", "]", ")", "\n", "mult", "=", "torch", ".", "matmul", "(", "x_minus_mu", ".", "transpose", "(", "1", ",", "0", ")", ",", "x_minus_mu", ")", "\n", "delta", "=", "mult", "*", "self", ".", "num_updates", "/", "(", "self", ".", "num_updates", "+", "1", ")", "\n", "self", ".", "Sigma", "=", "(", "self", ".", "num_updates", "*", "self", ".", "Sigma", "+", "delta", ")", "/", "(", "\n", "self", ".", "num_updates", "+", "1", ")", "\n", "\n", "# update class means", "\n", "", "self", ".", "muK", "[", "y", ",", ":", "]", "+=", "(", "x", "-", "self", ".", "muK", "[", "y", ",", ":", "]", ")", "/", "(", "self", ".", "cK", "[", "y", "]", "+", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "self", ".", "cK", "[", "y", "]", "+=", "1", "\n", "self", ".", "num_updates", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.predict": [[154, 183], ["torch.no_grad", "deep_slda.StreamingLDA.muK.transpose", "torch.matmul", "torch.pinverse", "torch.sum", "torch.matmul", "torch.eye"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Make predictions on test data X.\n        :param X: a torch tensor that contains N data samples (N x d)\n        :param return_probas: True if the user would like probabilities instead\n        of predictions returned\n        :return: the test predictions or probabilities\n        \"\"\"", "\n", "\n", "# compute/load Lambda matrix", "\n", "if", "self", ".", "prev_num_updates", "!=", "self", ".", "num_updates", ":", "\n", "# there have been updates to the model, compute Lambda", "\n", "            ", "self", ".", "Lambda", "=", "torch", ".", "pinverse", "(", "\n", "(", "\n", "1", "-", "self", ".", "shrinkage_param", ")", "*", "self", ".", "Sigma", "+", "\n", "self", ".", "shrinkage_param", "*", "torch", ".", "eye", "(", "\n", "self", ".", "input_size", ",", "device", "=", "self", ".", "device", ")", ")", "\n", "self", ".", "prev_num_updates", "=", "self", ".", "num_updates", "\n", "\n", "# parameters for predictions", "\n", "", "M", "=", "self", ".", "muK", ".", "transpose", "(", "1", ",", "0", ")", "\n", "W", "=", "torch", ".", "matmul", "(", "self", ".", "Lambda", ",", "M", ")", "\n", "c", "=", "0.5", "*", "torch", ".", "sum", "(", "M", "*", "W", ",", "dim", "=", "0", ")", "\n", "\n", "scores", "=", "torch", ".", "matmul", "(", "X", ",", "W", ")", "-", "c", "\n", "\n", "# return predictions or probabilities", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.fit_base": [[184, 205], ["print", "torch.unique", "print", "OAS", "OAS.fit", "torch.from_numpy().float().to", "X[].mean", "torch.from_numpy().float", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.fit"], ["", "def", "fit_base", "(", "self", ",", "X", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Fit the SLDA model to the base data.\n        :param X: an Nxd torch tensor of base initialization data\n        :param y: an Nx1-dimensional torch tensor of the associated labels for X\n        :return: None\n        \"\"\"", "\n", "print", "(", "'\\nFitting Base...'", ")", "\n", "\n", "# update class means", "\n", "for", "k", "in", "torch", ".", "unique", "(", "y", ")", ":", "\n", "            ", "self", ".", "muK", "[", "k", "]", "=", "X", "[", "y", "==", "k", "]", ".", "mean", "(", "0", ")", "\n", "self", ".", "cK", "[", "k", "]", "=", "X", "[", "y", "==", "k", "]", ".", "shape", "[", "0", "]", "\n", "", "self", ".", "num_updates", "=", "X", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'\\nEstimating initial covariance matrix...'", ")", "\n", "from", "sklearn", ".", "covariance", "import", "OAS", "\n", "cov_estimator", "=", "OAS", "(", "assume_centered", "=", "True", ")", "\n", "cov_estimator", ".", "fit", "(", "(", "X", "-", "self", ".", "muK", "[", "y", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "Sigma", "=", "torch", ".", "from_numpy", "(", "cov_estimator", ".", "covariance_", ")", ".", "float", "(", ")", ".", "to", "(", "\n", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.save_model": [[206, 222], ["dict", "deep_slda.StreamingLDA.muK.cpu", "deep_slda.StreamingLDA.cK.cpu", "deep_slda.StreamingLDA.Sigma.cpu", "torch.save", "os.path.join"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "save_path", ",", "save_name", ")", ":", "\n", "        ", "\"\"\"\n        Save the model parameters to a torch file.\n        :param save_path: the path where the model will be saved\n        :param save_name: the name for the saved file\n        :return:\n        \"\"\"", "\n", "# grab parameters for saving", "\n", "d", "=", "dict", "(", ")", "\n", "d", "[", "'muK'", "]", "=", "self", ".", "muK", ".", "cpu", "(", ")", "\n", "d", "[", "'cK'", "]", "=", "self", ".", "cK", ".", "cpu", "(", ")", "\n", "d", "[", "'Sigma'", "]", "=", "self", ".", "Sigma", ".", "cpu", "(", ")", "\n", "d", "[", "'num_updates'", "]", "=", "self", ".", "num_updates", "\n", "\n", "# save model out", "\n", "torch", ".", "save", "(", "d", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "save_name", "+", "'.pth'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.deep_slda.StreamingLDA.load_model": [[223, 236], ["torch.load", "d[].to", "d[].to", "d[].to", "os.path.join"], "methods", ["None"], ["", "def", "load_model", "(", "self", ",", "save_path", ",", "save_name", ")", ":", "\n", "        ", "\"\"\"\n        Load the model parameters into StreamingLDA object.\n        :param save_path: the path where the model is saved\n        :param save_name: the name of the saved file\n        :return:\n        \"\"\"", "\n", "# load parameters", "\n", "d", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "save_name", "+", "'.pth'", ")", ")", "\n", "self", ".", "muK", "=", "d", "[", "'muK'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "cK", "=", "d", "[", "'cK'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "Sigma", "=", "d", "[", "'Sigma'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "num_updates", "=", "d", "[", "'num_updates'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.cumulative.Cumulative.__init__": [[20, 51], ["avalanche.training.strategies.BaseStrategy.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "None", ",", "device", "=", "None", ",", "\n", "plugins", ":", "Optional", "[", "List", "[", "StrategyPlugin", "]", "]", "=", "None", ",", "\n", "evaluator", ":", "EvaluationPlugin", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: The model.\n        :param optimizer: The optimizer to use.\n        :param criterion: The loss criterion to use.\n        :param train_mb_size: The train minibatch size. Defaults to 1.\n        :param train_epochs: The number of training epochs. Defaults to 1.\n        :param eval_mb_size: The eval minibatch size. Defaults to 1.\n        :param device: The device to use. Defaults to None (cpu).\n        :param plugins: Plugins to be added. Defaults to None.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "optimizer", ",", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "device", "=", "device", ",", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "eval_every", "=", "eval_every", ")", "\n", "\n", "self", ".", "dataset", "=", "None", "# cumulative dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.cumulative.Cumulative.train_dataset_adaptation": [[52, 62], ["avalanche.benchmarks.utils.AvalancheConcatDataset"], "methods", ["None"], ["", "def", "train_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n            Concatenates all the previous experiences.\n        \"\"\"", "\n", "if", "self", ".", "dataset", "is", "None", ":", "\n", "            ", "self", ".", "dataset", "=", "self", ".", "experience", ".", "dataset", "\n", "", "else", ":", "\n", "            ", "self", ".", "dataset", "=", "AvalancheConcatDataset", "(", "\n", "[", "self", ".", "dataset", ",", "self", ".", "experience", ".", "dataset", "]", ")", "\n", "", "self", ".", "adapted_dataset", "=", "self", ".", "dataset", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.joint_training.JointTraining.__init__": [[46, 81], ["avalanche.training.strategies.BaseStrategy.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "criterion", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "1", ",", "device", "=", "'cpu'", ",", "\n", "plugins", ":", "Optional", "[", "Sequence", "[", "'StrategyPlugin'", "]", "]", "=", "None", ",", "\n", "evaluator", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Init.\n\n        :param model: PyTorch model.\n        :param optimizer: PyTorch optimizer.\n        :param criterion: loss function.\n        :param train_mb_size: mini-batch size for training.\n        :param train_epochs: number of training epochs.\n        :param eval_mb_size: mini-batch size for eval.\n        :param device: PyTorch device to run the model.\n        :param plugins: (optional) list of StrategyPlugins.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations. None to remove logging.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "criterion", "=", "criterion", ",", "\n", "train_mb_size", "=", "train_mb_size", ",", "\n", "train_epochs", "=", "train_epochs", ",", "\n", "eval_mb_size", "=", "eval_mb_size", ",", "\n", "device", "=", "device", ",", "\n", "plugins", "=", "plugins", ",", "\n", "evaluator", "=", "evaluator", ",", "\n", "eval_every", "=", "eval_every", "\n", ")", "\n", "# JointTraining can be trained only once.", "\n", "self", ".", "_is_fitted", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.joint_training.JointTraining.train": [[82, 131], ["joint_training.JointTraining.model.train", "joint_training.JointTraining.model.to", "isinstance", "enumerate", "joint_training.JointTraining._before_training", "joint_training.JointTraining._after_training", "joint_training.JointTraining.evaluator.get_last_metrics", "joint_training.AlreadyTrainedError", "isinstance", "joint_training.JointTraining.train_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.get_last_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train_exp"], ["", "def", "train", "(", "self", ",", "experiences", ":", "Union", "[", "Experience", ",", "Sequence", "[", "Experience", "]", "]", ",", "\n", "eval_streams", ":", "Optional", "[", "Sequence", "[", "Union", "[", "Experience", ",", "\n", "Sequence", "[", "\n", "Experience", "]", "]", "]", "]", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Training loop. if experiences is a single element trains on it.\n        If it is a sequence, trains the model on each experience in order.\n        This is different from joint training on the entire stream.\n        It returns a dictionary with last recorded value for each metric.\n\n        :param experiences: single Experience or sequence.\n        :param eval_streams: list of streams for evaluation.\n            If None: use training experiences for evaluation.\n            Use [] if you do not want to evaluate during training.\n\n        :return: dictionary containing last recorded value for\n            each metric name.\n        \"\"\"", "\n", "self", ".", "is_training", "=", "True", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "_is_fitted", ":", "\n", "            ", "raise", "AlreadyTrainedError", "(", "\n", "\"JointTraining can be trained only once. \"", "\n", "\"Please call the train method once on the entire stream.\"", "\n", ")", "\n", "\n", "# Normalize training and eval data.", "\n", "", "if", "isinstance", "(", "experiences", ",", "Experience", ")", ":", "\n", "            ", "experiences", "=", "[", "experiences", "]", "\n", "", "if", "eval_streams", "is", "None", ":", "\n", "            ", "eval_streams", "=", "[", "experiences", "]", "\n", "", "for", "i", ",", "exp", "in", "enumerate", "(", "eval_streams", ")", ":", "\n", "            ", "if", "isinstance", "(", "exp", ",", "Experience", ")", ":", "\n", "                ", "eval_streams", "[", "i", "]", "=", "[", "exp", "]", "\n", "\n", "", "", "self", ".", "_experiences", "=", "experiences", "\n", "self", ".", "_before_training", "(", "**", "kwargs", ")", "\n", "for", "exp", "in", "experiences", ":", "\n", "            ", "self", ".", "train_exp", "(", "exp", ",", "eval_streams", ",", "**", "kwargs", ")", "\n", "# Joint training only needs a single step because", "\n", "# it concatenates all the data at once.", "\n", "break", "\n", "", "self", ".", "_after_training", "(", "**", "kwargs", ")", "\n", "\n", "res", "=", "self", ".", "evaluator", ".", "get_last_metrics", "(", ")", "\n", "self", ".", "_is_fitted", "=", "True", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.joint_training.JointTraining.train_dataset_adaptation": [[132, 140], ["joint_training.JointTraining.adapted_dataset.train", "avalanche.benchmarks.utils.AvalancheConcatDataset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train"], ["", "def", "train_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Concatenates all the datastream. \"\"\"", "\n", "self", ".", "adapted_dataset", "=", "self", ".", "_experiences", "[", "0", "]", ".", "dataset", "\n", "for", "exp", "in", "self", ".", "_experiences", "[", "1", ":", "]", ":", "\n", "            ", "cat_data", "=", "AvalancheConcatDataset", "(", "[", "self", ".", "adapted_dataset", ",", "\n", "exp", ".", "dataset", "]", ")", "\n", "self", ".", "adapted_dataset", "=", "cat_data", "\n", "", "self", ".", "adapted_dataset", "=", "self", ".", "adapted_dataset", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.joint_training.JointTraining.model_adaptation": [[141, 152], ["model.to.to.modules", "model.to.to.to", "isinstance", "module.adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiHeadClassifier.adaptation"], ["", "def", "model_adaptation", "(", "self", ",", "model", "=", "None", ")", ":", "\n", "        ", "\"\"\" Adapts strategy's model for all experiences. \"\"\"", "\n", "if", "model", "is", "None", ":", "\n", "            ", "model", "=", "self", ".", "model", "\n", "\n", "", "for", "experience", "in", "self", ".", "_experiences", ":", "\n", "            ", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "module", ",", "DynamicModule", ")", ":", "\n", "                    ", "module", ".", "adaptation", "(", "experience", ".", "dataset", ")", "\n", "", "", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.__init__": [[89, 194], ["torch.nn.CrossEntropyLoss", "base_strategy.BaseStrategy.plugins.append", "avalanche.training.plugins.clock.Clock", "base_strategy.BaseStrategy.plugins.append", "base_strategy.BaseStrategy._warn_for_disabled_plugins_callbacks", "base_strategy.BaseStrategy._warn_for_disabled_metrics_callbacks", "avalanche.training.plugins.EvaluationPlugin"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._warn_for_disabled_plugins_callbacks", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._warn_for_disabled_metrics_callbacks"], ["def", "__init__", "(", "self", ",", "model", ":", "Module", ",", "optimizer", ":", "Optimizer", ",", "\n", "criterion", "=", "CrossEntropyLoss", "(", ")", ",", "\n", "train_mb_size", ":", "int", "=", "1", ",", "train_epochs", ":", "int", "=", "1", ",", "\n", "eval_mb_size", ":", "int", "=", "1", ",", "device", "=", "'cpu'", ",", "\n", "plugins", ":", "Optional", "[", "Sequence", "[", "'StrategyPlugin'", "]", "]", "=", "None", ",", "\n", "evaluator", "=", "default_logger", ",", "eval_every", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\" Init.\n\n        :param model: PyTorch model.\n        :param optimizer: PyTorch optimizer.\n        :param criterion: loss function.\n        :param train_mb_size: mini-batch size for training.\n        :param train_epochs: number of training epochs.\n        :param eval_mb_size: mini-batch size for eval.\n        :param device: PyTorch device where the model will be allocated.\n        :param plugins: (optional) list of StrategyPlugins.\n        :param evaluator: (optional) instance of EvaluationPlugin for logging\n            and metric computations. None to remove logging.\n        :param eval_every: the frequency of the calls to `eval` inside the\n            training loop. -1 disables the evaluation. 0 means `eval` is called\n            only at the end of the learning experience. Values >0 mean that \n            `eval` is called every `eval_every` epochs and at the end of the \n            learning experience.\n        \"\"\"", "\n", "self", ".", "_criterion", "=", "criterion", "\n", "\n", "self", ".", "model", ":", "Module", "=", "model", "\n", "\"\"\" PyTorch model. \"\"\"", "\n", "\n", "self", ".", "optimizer", ":", "Optimizer", "=", "optimizer", "\n", "\"\"\" PyTorch optimizer. \"\"\"", "\n", "\n", "self", ".", "train_epochs", ":", "int", "=", "train_epochs", "\n", "\"\"\" Number of training epochs. \"\"\"", "\n", "\n", "self", ".", "train_mb_size", ":", "int", "=", "train_mb_size", "\n", "\"\"\" Training mini-batch size. \"\"\"", "\n", "\n", "self", ".", "eval_mb_size", ":", "int", "=", "train_mb_size", "if", "eval_mb_size", "is", "None", "else", "eval_mb_size", "\n", "\"\"\" Eval mini-batch size. \"\"\"", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\"\"\" PyTorch device where the model will be allocated. \"\"\"", "\n", "\n", "self", ".", "plugins", "=", "[", "]", "if", "plugins", "is", "None", "else", "plugins", "\n", "\"\"\" List of `StrategyPlugin`s. \"\"\"", "\n", "\n", "if", "evaluator", "is", "None", ":", "\n", "            ", "evaluator", "=", "EvaluationPlugin", "(", ")", "\n", "", "self", ".", "plugins", ".", "append", "(", "evaluator", ")", "\n", "self", ".", "evaluator", "=", "evaluator", "\n", "\"\"\" EvaluationPlugin used for logging and metric computations. \"\"\"", "\n", "\n", "self", ".", "clock", "=", "Clock", "(", ")", "\n", "\"\"\" Incremental counters for strategy events. \"\"\"", "\n", "# WARNING: Clock needs to be the last plugin, otherwise", "\n", "# counters will be wrong for plugins called after it.", "\n", "self", ".", "plugins", ".", "append", "(", "self", ".", "clock", ")", "\n", "\n", "self", ".", "eval_every", "=", "eval_every", "\n", "\"\"\" Frequency of the evaluation during training. \"\"\"", "\n", "\n", "###################################################################", "\n", "# State variables. These are updated during the train/eval loops. #", "\n", "###################################################################", "\n", "self", ".", "experience", "=", "None", "\n", "\"\"\" Current experience. \"\"\"", "\n", "\n", "self", ".", "adapted_dataset", "=", "None", "\n", "\"\"\" Data used to train. It may be modified by plugins. Plugins can \n        append data to it (e.g. for replay). \n         \n        .. note::\n\n            This dataset may contain samples from different experiences. If you \n            want the original data for the current experience  \n            use :attr:`.BaseStrategy.experience`.\n        \"\"\"", "\n", "\n", "self", ".", "dataloader", "=", "None", "\n", "\"\"\" Dataloader. \"\"\"", "\n", "\n", "self", ".", "mbatch", "=", "None", "\n", "\"\"\" Current mini-batch. \"\"\"", "\n", "\n", "self", ".", "mb_output", "=", "None", "\n", "\"\"\" Model's output computed on the current mini-batch. \"\"\"", "\n", "\n", "self", ".", "loss", "=", "None", "\n", "\"\"\" Loss of the current mini-batch. \"\"\"", "\n", "\n", "self", ".", "is_training", ":", "bool", "=", "False", "\n", "\"\"\" True if the strategy is in training mode. \"\"\"", "\n", "\n", "self", ".", "current_eval_stream", "=", "None", "\n", "\"\"\" Current evaluation stream. \"\"\"", "\n", "\n", "self", ".", "_stop_training", "=", "False", "\n", "\n", "#### CUSTOM VARS ###", "\n", "self", ".", "tracking_collector", "=", "None", "# HOlder object for tracking stats", "\n", "\n", "self", ".", "_warn_for_disabled_plugins_callbacks", "(", ")", "\n", "self", ".", "_warn_for_disabled_metrics_callbacks", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.training_exp_counter": [[195, 203], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "training_exp_counter", "(", "self", ")", ":", "\n", "        ", "\"\"\" Counts the number of training steps. +1 at the end of each\n        experience. \"\"\"", "\n", "warnings", ".", "warn", "(", "\n", "\"Deprecated attribute. You should use self.clock.train_exp_counter\"", "\n", "\" instead.\"", ",", "DeprecationWarning", ")", "\n", "return", "self", ".", "clock", ".", "train_exp_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.epoch": [[204, 211], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\" Epoch counter. \"\"\"", "\n", "warnings", ".", "warn", "(", "\n", "\"Deprecated attribute. You should use self.clock.train_exp_epochs\"", "\n", "\" instead.\"", ",", "DeprecationWarning", ")", "\n", "return", "self", ".", "clock", ".", "train_exp_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.mb_it": [[212, 220], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "mb_it", "(", "self", ")", ":", "\n", "        ", "\"\"\" Iteration counter. Reset at the start of a new epoch. \"\"\"", "\n", "warnings", ".", "warn", "(", "\n", "\"Deprecated attribute. You should use \"", "\n", "\"self.clock.train_epoch_iterations\"", "\n", "\" instead.\"", ",", "DeprecationWarning", ")", "\n", "return", "self", ".", "clock", ".", "train_epoch_iterations", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.is_eval": [[221, 225], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_eval", "(", "self", ")", ":", "\n", "        ", "\"\"\" True if the strategy is in evaluation mode. \"\"\"", "\n", "return", "not", "self", ".", "is_training", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.mb_x": [[226, 230], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mb_x", "(", "self", ")", ":", "\n", "        ", "\"\"\" Current mini-batch input. \"\"\"", "\n", "return", "self", ".", "mbatch", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.mb_y": [[231, 235], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mb_y", "(", "self", ")", ":", "\n", "        ", "\"\"\" Current mini-batch target. \"\"\"", "\n", "return", "self", ".", "mbatch", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.mb_task_id": [[236, 241], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "mb_task_id", "(", "self", ")", ":", "\n", "        ", "\"\"\"Current mini-batch task labels.\"\"\"", "\n", "assert", "len", "(", "self", ".", "mbatch", ")", ">=", "3", "\n", "return", "self", ".", "mbatch", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion": [[242, 245], ["base_strategy.BaseStrategy._criterion"], "methods", ["None"], ["", "def", "criterion", "(", "self", ")", ":", "\n", "        ", "\"\"\" Loss function. \"\"\"", "\n", "return", "self", ".", "_criterion", "(", "self", ".", "mb_output", ",", "self", ".", "mb_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train": [[246, 286], ["base_strategy.BaseStrategy.model.train", "base_strategy.BaseStrategy.model.to", "base_strategy.BaseStrategy._before_training", "base_strategy.BaseStrategy._periodic_eval", "base_strategy.BaseStrategy._after_training", "base_strategy.BaseStrategy.evaluator.get_last_metrics", "isinstance", "base_strategy.BaseStrategy.train_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._periodic_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.get_last_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train_exp"], ["", "def", "train", "(", "self", ",", "experiences", ":", "Union", "[", "Experience", ",", "Sequence", "[", "Experience", "]", "]", ",", "\n", "eval_streams", ":", "Optional", "[", "Sequence", "[", "Union", "[", "Experience", ",", "\n", "Sequence", "[", "\n", "Experience", "]", "]", "]", "]", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Training loop. if experiences is a single element trains on it.\n        If it is a sequence, trains the model on each experience in order.\n        This is different from joint training on the entire stream.\n        It returns a dictionary with last recorded value for each metric.\n\n        :param experiences: single Experience or sequence.\n        :param eval_streams: list of streams for evaluation.\n            If None: use training experiences for evaluation.\n            Use [] if you do not want to evaluate during training.\n\n        :return: dictionary containing last recorded value for\n            each metric name.\n        \"\"\"", "\n", "self", ".", "is_training", "=", "True", "\n", "self", ".", "_stop_training", "=", "False", "\n", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Normalize training and eval data.", "\n", "if", "not", "isinstance", "(", "experiences", ",", "Sequence", ")", ":", "\n", "            ", "experiences", "=", "[", "experiences", "]", "\n", "", "if", "eval_streams", "is", "None", ":", "\n", "            ", "eval_streams", "=", "[", "experiences", "]", "\n", "\n", "", "self", ".", "_before_training", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_periodic_eval", "(", "eval_streams", ",", "do_final", "=", "False", ",", "do_initial", "=", "True", ")", "\n", "\n", "for", "self", ".", "experience", "in", "experiences", ":", "\n", "            ", "self", ".", "train_exp", "(", "self", ".", "experience", ",", "eval_streams", ",", "**", "kwargs", ")", "\n", "", "self", ".", "_after_training", "(", "**", "kwargs", ")", "\n", "\n", "res", "=", "self", ".", "evaluator", ".", "get_last_metrics", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train_exp": [[287, 336], ["base_strategy.BaseStrategy.model.train", "enumerate", "base_strategy.BaseStrategy._before_train_dataset_adaptation", "base_strategy.BaseStrategy.train_dataset_adaptation", "base_strategy.BaseStrategy._after_train_dataset_adaptation", "base_strategy.BaseStrategy.make_train_dataloader", "base_strategy.BaseStrategy.model_adaptation", "base_strategy.BaseStrategy.make_optimizer", "base_strategy.BaseStrategy._before_training_exp", "range", "base_strategy.BaseStrategy._periodic_eval", "base_strategy.BaseStrategy._after_training_exp", "base_strategy.BaseStrategy._before_training_epoch", "base_strategy.BaseStrategy.training_epoch", "base_strategy.BaseStrategy._after_training_epoch", "base_strategy.BaseStrategy._periodic_eval", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_train_dataset_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train_dataset_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_train_dataset_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.make_train_dataloader", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.model_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.make_optimizer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._periodic_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._periodic_eval"], ["", "def", "train_exp", "(", "self", ",", "experience", ":", "Experience", ",", "eval_streams", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Training loop over a single Experience object.\n\n        :param experience: CL experience information.\n        :param eval_streams: list of streams for evaluation.\n            If None: use the training experience for evaluation.\n            Use [] if you do not want to evaluate during training.\n        :param kwargs: custom arguments.\n        \"\"\"", "\n", "self", ".", "experience", "=", "experience", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "if", "eval_streams", "is", "None", ":", "\n", "            ", "eval_streams", "=", "[", "experience", "]", "\n", "", "for", "i", ",", "exp", "in", "enumerate", "(", "eval_streams", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "exp", ",", "Sequence", ")", ":", "\n", "                ", "eval_streams", "[", "i", "]", "=", "[", "exp", "]", "\n", "\n", "# Data Adaptation (e.g. add new samples/data augmentation)", "\n", "", "", "self", ".", "_before_train_dataset_adaptation", "(", "**", "kwargs", ")", "\n", "self", ".", "train_dataset_adaptation", "(", "**", "kwargs", ")", "\n", "self", ".", "_after_train_dataset_adaptation", "(", "**", "kwargs", ")", "\n", "self", ".", "make_train_dataloader", "(", "**", "kwargs", ")", "\n", "\n", "# Model Adaptation (e.g. freeze/add new units)", "\n", "self", ".", "model", "=", "self", ".", "model_adaptation", "(", ")", "\n", "self", ".", "make_optimizer", "(", ")", "\n", "\n", "self", ".", "_before_training_exp", "(", "**", "kwargs", ")", "\n", "\n", "do_final", "=", "True", "\n", "if", "self", ".", "eval_every", ">", "0", "and", "(", "self", ".", "train_epochs", "-", "1", ")", "%", "self", ".", "eval_every", "==", "0", ":", "\n", "            ", "do_final", "=", "False", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "train_epochs", ")", ":", "\n", "            ", "self", ".", "_before_training_epoch", "(", "**", "kwargs", ")", "\n", "\n", "if", "self", ".", "_stop_training", ":", "# Early stopping", "\n", "                ", "self", ".", "_stop_training", "=", "False", "\n", "break", "\n", "\n", "", "self", ".", "training_epoch", "(", "**", "kwargs", ")", "\n", "self", ".", "_after_training_epoch", "(", "**", "kwargs", ")", "\n", "self", ".", "_periodic_eval", "(", "eval_streams", ",", "do_final", "=", "False", ")", "\n", "\n", "# Final evaluation", "\n", "", "self", ".", "_periodic_eval", "(", "eval_streams", ",", "do_final", "=", "do_final", ")", "\n", "self", ".", "_after_training_exp", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._periodic_eval": [[337, 371], ["base_strategy.BaseStrategy.model.named_modules", "base_strategy.BaseStrategy.model.named_modules", "layer.train", "base_strategy.BaseStrategy.eval"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], ["", "def", "_periodic_eval", "(", "self", ",", "eval_streams", ",", "do_final", ",", "do_initial", "=", "False", ")", ":", "\n", "        ", "\"\"\" Periodic eval controlled by `self.eval_every`. \"\"\"", "\n", "# Since we are switching from train to eval model inside the training", "\n", "# loop, we need to save the training state, and restore it after the", "\n", "# eval is done.", "\n", "_prev_state", "=", "(", "\n", "self", ".", "experience", ",", "\n", "self", ".", "adapted_dataset", ",", "\n", "self", ".", "dataloader", ",", "\n", "self", ".", "is_training", ")", "\n", "\n", "# save each layer's training mode, to restore it later", "\n", "_prev_model_training_modes", "=", "{", "}", "\n", "for", "name", ",", "layer", "in", "self", ".", "model", ".", "named_modules", "(", ")", ":", "\n", "            ", "_prev_model_training_modes", "[", "name", "]", "=", "layer", ".", "training", "\n", "\n", "", "curr_epoch", "=", "self", ".", "clock", ".", "train_exp_epochs", "\n", "if", "(", "self", ".", "eval_every", "==", "0", "and", "(", "do_final", "or", "do_initial", ")", ")", "or", "(", "self", ".", "eval_every", ">", "0", "and", "do_initial", ")", "or", "(", "self", ".", "eval_every", ">", "0", "and", "curr_epoch", "%", "self", ".", "eval_every", "==", "0", ")", ":", "\n", "# in the first case we are outside epoch loop", "\n", "# in the second case we are within epoch loop", "\n", "            ", "for", "exp", "in", "eval_streams", ":", "\n", "                ", "self", ".", "eval", "(", "exp", ")", "\n", "\n", "# restore train-state variables and training mode.", "\n", "", "", "self", ".", "experience", ",", "self", ".", "adapted_dataset", "=", "_prev_state", "[", ":", "2", "]", "\n", "self", ".", "dataloader", "=", "_prev_state", "[", "2", "]", "\n", "self", ".", "is_training", "=", "_prev_state", "[", "3", "]", "\n", "\n", "# restore each layer's training mode to original ", "\n", "for", "name", ",", "layer", "in", "self", ".", "model", ".", "named_modules", "(", ")", ":", "\n", "            ", "prev_mode", "=", "_prev_model_training_modes", "[", "name", "]", "\n", "layer", ".", "train", "(", "mode", "=", "prev_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.stop_training": [[372, 375], ["None"], "methods", ["None"], ["", "", "def", "stop_training", "(", "self", ")", ":", "\n", "        ", "\"\"\" Signals to stop training at the next iteration. \"\"\"", "\n", "self", ".", "_stop_training", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train_dataset_adaptation": [[376, 380], ["base_strategy.BaseStrategy.adapted_dataset.train"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train"], ["", "def", "train_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Initialize `self.adapted_dataset`. \"\"\"", "\n", "self", ".", "adapted_dataset", "=", "self", ".", "experience", ".", "dataset", "\n", "self", ".", "adapted_dataset", "=", "self", ".", "adapted_dataset", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval": [[381, 422], ["torch.no_grad", "base_strategy.BaseStrategy.model.eval", "base_strategy.BaseStrategy._before_eval", "base_strategy.BaseStrategy._after_eval", "base_strategy.BaseStrategy.evaluator.get_last_metrics", "isinstance", "base_strategy.BaseStrategy._before_eval_dataset_adaptation", "base_strategy.BaseStrategy.eval_dataset_adaptation", "base_strategy.BaseStrategy._after_eval_dataset_adaptation", "base_strategy.BaseStrategy.make_eval_dataloader", "base_strategy.BaseStrategy.model_adaptation", "base_strategy.BaseStrategy._before_eval_exp", "base_strategy.BaseStrategy.eval_epoch", "base_strategy.BaseStrategy._after_eval_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.get_last_metrics", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_dataset_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval_dataset_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_dataset_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.make_eval_dataloader", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.model_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_exp"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "eval", "(", "self", ",", "\n", "exp_list", ":", "Union", "[", "Experience", ",", "Sequence", "[", "Experience", "]", "]", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the current model on a series of experiences and\n        returns the last recorded value for each metric.\n\n        :param exp_list: CL experience information.\n        :param kwargs: custom arguments.\n\n        :return: dictionary containing last recorded value for\n            each metric name\n        \"\"\"", "\n", "self", ".", "is_training", "=", "False", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "if", "not", "isinstance", "(", "exp_list", ",", "Sequence", ")", ":", "\n", "            ", "exp_list", "=", "[", "exp_list", "]", "\n", "", "self", ".", "current_eval_stream", "=", "exp_list", "\n", "\n", "self", ".", "_before_eval", "(", "**", "kwargs", ")", "\n", "for", "self", ".", "experience", "in", "exp_list", ":", "\n", "# Data Adaptation", "\n", "            ", "self", ".", "_before_eval_dataset_adaptation", "(", "**", "kwargs", ")", "\n", "self", ".", "eval_dataset_adaptation", "(", "**", "kwargs", ")", "\n", "self", ".", "_after_eval_dataset_adaptation", "(", "**", "kwargs", ")", "\n", "self", ".", "make_eval_dataloader", "(", "**", "kwargs", ")", "\n", "\n", "# Model Adaptation (e.g. freeze/add new units)", "\n", "self", ".", "model", "=", "self", ".", "model_adaptation", "(", ")", "\n", "\n", "self", ".", "_before_eval_exp", "(", "**", "kwargs", ")", "\n", "self", ".", "eval_epoch", "(", "**", "kwargs", ")", "\n", "self", ".", "_after_eval_exp", "(", "**", "kwargs", ")", "\n", "\n", "", "self", ".", "_after_eval", "(", "**", "kwargs", ")", "\n", "\n", "res", "=", "self", ".", "evaluator", ".", "get_last_metrics", "(", ")", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_exp": [[423, 430], ["p.before_training_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_training_exp"], ["", "def", "_before_training_exp", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Called  after the dataset and data loader creation and\n        before the training loop.\n        \"\"\"", "\n", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_training_exp", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.make_train_dataloader": [[431, 450], ["avalanche.benchmarks.utils.data_loader.TaskBalancedDataLoader"], "methods", ["None"], ["", "", "def", "make_train_dataloader", "(", "self", ",", "num_workers", "=", "0", ",", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Data loader initialization.\n\n        Called at the start of each learning experience after the dataset \n        adaptation.\n\n        :param num_workers: number of thread workers for the data loading.\n        :param shuffle: True if the data should be shuffled, False otherwise.\n        :param pin_memory: If True, the data loader will copy Tensors into CUDA\n            pinned memory before returning them. Defaults to True.\n        \"\"\"", "\n", "self", ".", "dataloader", "=", "TaskBalancedDataLoader", "(", "\n", "self", ".", "adapted_dataset", ",", "\n", "oversample_small_groups", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_size", "=", "self", ".", "train_mb_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.make_eval_dataloader": [[451, 468], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "make_eval_dataloader", "(", "self", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the eval data loader.\n        :param num_workers: How many subprocesses to use for data loading.\n            0 means that the data will be loaded in the main process.\n            (default: 0).\n        :param pin_memory: If True, the data loader will copy Tensors into CUDA\n            pinned memory before returning them. Defaults to True.\n        :param kwargs:\n        :return:\n        \"\"\"", "\n", "self", ".", "dataloader", "=", "DataLoader", "(", "\n", "self", ".", "adapted_dataset", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_size", "=", "self", ".", "eval_mb_size", ",", "\n", "pin_memory", "=", "pin_memory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_train_dataset_adaptation": [[469, 478], ["p.after_train_dataset_adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.after_train_dataset_adaptation"], ["", "def", "_after_train_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Called after the dataset adaptation and before the\n        dataloader initialization. Allows to customize the dataset.\n        :param kwargs:\n        :return:\n        \"\"\"", "\n", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_train_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_epoch": [[479, 487], ["p.before_training_epoch"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch"], ["", "", "def", "_before_training_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Called at the beginning of a new training epoch.\n        :param kwargs:\n        :return:\n        \"\"\"", "\n", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_training_epoch", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.training_epoch": [[488, 522], ["base_strategy.BaseStrategy._unpack_minibatch", "base_strategy.BaseStrategy._before_training_iteration", "base_strategy.BaseStrategy.optimizer.zero_grad", "base_strategy.BaseStrategy._before_forward", "base_strategy.BaseStrategy.forward", "base_strategy.BaseStrategy._after_forward", "base_strategy.BaseStrategy.criterion", "base_strategy.BaseStrategy._before_backward", "base_strategy.BaseStrategy.loss.backward", "base_strategy.BaseStrategy._after_backward", "base_strategy.BaseStrategy._before_update", "base_strategy.BaseStrategy.optimizer.step", "base_strategy.BaseStrategy._after_update", "base_strategy.BaseStrategy._after_training_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._unpack_minibatch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_backward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_backward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_iteration"], ["", "", "def", "training_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Training epoch.\n        \n        :param kwargs:\n        :return:\n        \"\"\"", "\n", "for", "self", ".", "mbatch", "in", "self", ".", "dataloader", ":", "\n", "            ", "if", "self", ".", "_stop_training", ":", "\n", "                ", "break", "\n", "\n", "", "self", ".", "_unpack_minibatch", "(", ")", "\n", "self", ".", "_before_training_iteration", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "loss", "=", "0", "\n", "\n", "# Forward", "\n", "self", ".", "_before_forward", "(", "**", "kwargs", ")", "\n", "self", ".", "mb_output", "=", "self", ".", "forward", "(", ")", "\n", "self", ".", "_after_forward", "(", "**", "kwargs", ")", "\n", "\n", "# Loss & Backward", "\n", "self", ".", "loss", "+=", "self", ".", "criterion", "(", ")", "\n", "\n", "self", ".", "_before_backward", "(", "**", "kwargs", ")", "\n", "self", ".", "loss", ".", "backward", "(", ")", "\n", "self", ".", "_after_backward", "(", "**", "kwargs", ")", "\n", "\n", "# Optimization step", "\n", "self", ".", "_before_update", "(", "**", "kwargs", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "_after_update", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_after_training_iteration", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._unpack_minibatch": [[523, 532], ["range", "len", "len", "base_strategy.BaseStrategy.mbatch[].to"], "methods", ["None"], ["", "", "def", "_unpack_minibatch", "(", "self", ")", ":", "\n", "        ", "\"\"\" We assume mini-batches have the form <x, y, ..., t>.\n        This allows for arbitrary tensors between y and t.\n        Keep in mind that in the most general case mb_task_id is a tensor\n        which may contain different labels for each sample.\n        \"\"\"", "\n", "assert", "len", "(", "self", ".", "mbatch", ")", ">=", "3", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "mbatch", ")", ")", ":", "\n", "            ", "self", ".", "mbatch", "[", "i", "]", "=", "self", ".", "mbatch", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training": [[533, 536], ["p.before_training"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training"], ["", "", "def", "_before_training", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_training", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training": [[537, 540], ["p.after_training"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.after_training"], ["", "", "def", "_after_training", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_training", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_training_iteration": [[541, 544], ["p.before_training_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_iteration"], ["", "", "def", "_before_training_iteration", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_training_iteration", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_forward": [[545, 548], ["p.before_forward"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_forward"], ["", "", "def", "_before_forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_forward", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_forward": [[549, 552], ["p.after_forward"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_forward"], ["", "", "def", "_after_forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_forward", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_backward": [[553, 556], ["p.before_backward"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_backward"], ["", "", "def", "_before_backward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_backward", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_backward": [[557, 560], ["p.after_backward"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_backward"], ["", "", "def", "_after_backward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_backward", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_iteration": [[561, 564], ["p.after_training_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration"], ["", "", "def", "_after_training_iteration", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_training_iteration", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_update": [[565, 568], ["p.before_update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_update"], ["", "", "def", "_before_update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_update", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_update": [[569, 572], ["p.after_update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_update"], ["", "", "def", "_after_update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_update", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_epoch": [[573, 576], ["p.after_training_epoch"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.after_training_epoch"], ["", "", "def", "_after_training_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_training_epoch", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_training_exp": [[577, 580], ["p.after_training_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.after_training_exp"], ["", "", "def", "_after_training_exp", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_training_exp", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval": [[581, 584], ["p.before_eval"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval"], ["", "", "def", "_before_eval", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_eval", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_exp": [[585, 588], ["p.before_eval_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval_exp"], ["", "", "def", "_before_eval_exp", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_eval_exp", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval_dataset_adaptation": [[589, 593], ["base_strategy.BaseStrategy.adapted_dataset.eval"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], ["", "", "def", "eval_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Initialize `self.adapted_dataset`. \"\"\"", "\n", "self", ".", "adapted_dataset", "=", "self", ".", "experience", ".", "dataset", "\n", "self", ".", "adapted_dataset", "=", "self", ".", "adapted_dataset", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_dataset_adaptation": [[594, 597], ["p.before_eval_dataset_adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_eval_dataset_adaptation"], ["", "def", "_before_eval_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_eval_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_dataset_adaptation": [[598, 601], ["p.after_eval_dataset_adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.after_eval_dataset_adaptation"], ["", "", "def", "_after_eval_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_eval_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval_epoch": [[602, 614], ["base_strategy.BaseStrategy._unpack_minibatch", "base_strategy.BaseStrategy._before_eval_iteration", "base_strategy.BaseStrategy._before_eval_forward", "base_strategy.BaseStrategy.forward", "base_strategy.BaseStrategy._after_eval_forward", "base_strategy.BaseStrategy.criterion", "base_strategy.BaseStrategy._after_eval_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._unpack_minibatch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_iteration"], ["", "", "def", "eval_epoch", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Evaluation loop over the current `self.dataloader`.\"\"\"", "\n", "for", "self", ".", "mbatch", "in", "self", ".", "dataloader", ":", "\n", "            ", "self", ".", "_unpack_minibatch", "(", ")", "\n", "self", ".", "_before_eval_iteration", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "_before_eval_forward", "(", "**", "kwargs", ")", "\n", "self", ".", "mb_output", "=", "self", ".", "forward", "(", ")", "\n", "self", ".", "_after_eval_forward", "(", "**", "kwargs", ")", "\n", "self", ".", "loss", "=", "self", ".", "criterion", "(", ")", "\n", "\n", "self", ".", "_after_eval_iteration", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_exp": [[615, 618], ["p.after_eval_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.after_eval_exp"], ["", "", "def", "_after_eval_exp", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_eval_exp", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval": [[619, 622], ["p.after_eval"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval"], ["", "", "def", "_after_eval", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_eval", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_iteration": [[623, 626], ["p.before_eval_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_eval_iteration"], ["", "", "def", "_before_eval_iteration", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_eval_iteration", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_eval_forward": [[627, 630], ["p.before_eval_forward"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_eval_forward"], ["", "", "def", "_before_eval_forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_eval_forward", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_forward": [[631, 634], ["p.after_eval_forward"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_eval_forward"], ["", "", "def", "_after_eval_forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_eval_forward", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._after_eval_iteration": [[635, 638], ["p.after_eval_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration"], ["", "", "def", "_after_eval_iteration", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "after_eval_iteration", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._before_train_dataset_adaptation": [[639, 642], ["p.before_train_dataset_adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_train_dataset_adaptation"], ["", "", "def", "_before_train_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "plugins", ":", "\n", "            ", "p", ".", "before_train_dataset_adaptation", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.model_adaptation": [[643, 655], ["model.modules", "model.to", "isinstance", "module.adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiHeadClassifier.adaptation"], ["", "", "def", "model_adaptation", "(", "self", ",", "model", "=", "None", ")", ":", "\n", "        ", "\"\"\"Adapts the model to the current data.\n\n        Calls the :class:`~avalanche.models.DynamicModule`s adaptation.\n        \"\"\"", "\n", "if", "model", "is", "None", ":", "\n", "            ", "model", "=", "self", ".", "model", "\n", "\n", "", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "DynamicModule", ")", ":", "\n", "                ", "module", ".", "adaptation", "(", "self", ".", "experience", ".", "dataset", ")", "\n", "", "", "return", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.forward": [[656, 659], ["avalanche.models.utils.avalanche_forward"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Compute the model's output given the current mini-batch.\"\"\"", "\n", "return", "avalanche_forward", "(", "self", ".", "model", ",", "self", ".", "mb_x", ",", "self", ".", "mb_task_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.make_optimizer": [[660, 669], ["avalanche.models.dynamic_optimizers.reset_optimizer"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_optimizers.reset_optimizer"], ["", "def", "make_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Optimizer initialization.\n\n        Called before each training experiene to configure the optimizer.\n        \"\"\"", "\n", "# we reset the optimizer's state after each experience.", "\n", "# This allows to add new parameters (new heads) and", "\n", "# freezing old units during the model's adaptation phase.", "\n", "reset_optimizer", "(", "self", ".", "optimizer", ",", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._warn_for_disabled_plugins_callbacks": [[670, 672], ["base_strategy.BaseStrategy._warn_for_disabled_callbacks"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._warn_for_disabled_callbacks"], ["", "def", "_warn_for_disabled_plugins_callbacks", "(", "self", ")", ":", "\n", "        ", "self", ".", "_warn_for_disabled_callbacks", "(", "self", ".", "plugins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._warn_for_disabled_metrics_callbacks": [[673, 675], ["base_strategy.BaseStrategy._warn_for_disabled_callbacks"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._warn_for_disabled_callbacks"], ["", "def", "_warn_for_disabled_metrics_callbacks", "(", "self", ")", ":", "\n", "        ", "self", ".", "_warn_for_disabled_callbacks", "(", "self", ".", "evaluator", ".", "metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy._warn_for_disabled_callbacks": [[676, 696], ["getattr", "getattr.__qualname__.split", "logger.warning"], "methods", ["None"], ["", "def", "_warn_for_disabled_callbacks", "(", "\n", "self", ",", "\n", "plugins", ":", "List", "[", "\"StrategyCallbacks\"", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Will log some warnings in case some plugins appear to be using callbacks\n        that have been de-activated by the strategy class.\n        \"\"\"", "\n", "for", "disabled_callback_name", "in", "self", ".", "DISABLED_CALLBACKS", ":", "\n", "            ", "for", "plugin", "in", "plugins", ":", "\n", "                ", "callback", "=", "getattr", "(", "plugin", ",", "disabled_callback_name", ")", "\n", "callback_class", "=", "callback", ".", "__qualname__", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "callback_class", "not", "in", "(", "\n", "\"StrategyPlugin\"", ",", "\n", "\"PluginMetric\"", ",", "\n", "\"EvaluationPlugin\"", ",", "\n", "\"GenericPluginMetric\"", ",", "\n", ")", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "f\"{plugin.__class__.__name__} seems to use \"", "\n", "f\"the callback {disabled_callback_name} \"", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.replay.ReplayPlugin.__init__": [[32, 48], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "avalanche.training.storage_policy.ExperienceBalancedBuffer"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["\n", "store_criteria", "=", "[", "'rnd'", "]", "\n", "\n", "def", "__init__", "(", "self", ",", "n_total_memories", ",", "num_tasks", ")", ":", "\n", "        ", "\"\"\"\n        Standard samples the same batch-size of new samples.\n\n        :param n_total_memories: The maximal number of input samples to store in total.\n        :param num_tasks:        The number of tasks being seen in the scenario.\n        :param mode:             'ER'=regular replay, 'ERaverse'=Replay with Ridge Aversion.\n        :param init_epochs:      Number of epochs for the first experience/task.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Memory", "\n", "self", ".", "n_total_memories", "=", "n_total_memories", "# Used dynamically", "\n", "self", ".", "num_tasks", "=", "num_tasks", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.replay.ReplayPlugin.ext_mem": [[49, 52], ["None"], "methods", ["None"], ["\n", "# a Dict<task_id, Dataset>", "\n", "self", ".", "storage_policy", "=", "ClassBalancedBuffer", "(", "# Samples to store in memory", "\n", "max_size", "=", "self", ".", "n_total_memories", ",", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.replay.ReplayPlugin.before_training_exp": [[53, 71], ["avalanche.benchmarks.utils.data_loader.ReplayDataLoader", "len"], "methods", ["None"], ["adaptive_size", "=", "True", ",", "\n", ")", "\n", "\n", "print", "(", "f\"[METHOD CONFIG] n_total_mems={self.n_total_memories} \"", ")", "\n", "print", "(", "f\"[METHOD CONFIG] SUMMARY: \"", ",", "end", "=", "''", ")", "\n", "pprint", "(", "self", ".", "__dict__", ",", "indent", "=", "2", ")", "\n", "\n", "", "def", "before_forward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Add samples from rehearsal memory to current batch and\n        calculate perturbation to be applied in next forward.\"\"\"", "\n", "# Sample memory batch", "\n", "x_s", ",", "y_s", ",", "t_s", "=", "None", ",", "None", ",", "None", "\n", "if", "self", ".", "n_total_memories", ">", "0", "and", "len", "(", "self", ".", "storage_policy", ".", "buffer", ")", ">", "0", ":", "# Only sample if there are stored", "\n", "            ", "x_s", ",", "y_s", ",", "t_s", "=", "self", ".", "load_buffer_batch", "(", "self", ".", "storage_policy", ",", "strategy", ",", "nb", "=", "strategy", ".", "train_mb_size", ")", "\n", "\n", "# Append to current new-data batch", "\n", "", "if", "x_s", "is", "not", "None", ":", "# Add", "\n", "            ", "assert", "y_s", "is", "not", "None", "\n", "assert", "t_s", "is", "not", "None", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.replay.ReplayPlugin.after_training_exp": [[72, 74], ["replay.ReplayPlugin.storage_policy.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["# Assemble minibatch", "\n", "strategy", ".", "mbatch", "[", "0", "]", "=", "torch", ".", "cat", "(", "[", "strategy", ".", "mbatch", "[", "0", "]", ",", "x_s", "]", ")", "\n", "strategy", ".", "mbatch", "[", "1", "]", "=", "torch", ".", "cat", "(", "[", "strategy", ".", "mbatch", "[", "1", "]", ",", "y_s", "]", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.__init__": [[19, 42], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "logging.getLogger", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "cwr_layer_name", "=", "None", ",", "freeze_remaining_model", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param model: the model.\n        :param cwr_layer_name: name of the last fully connected layer. Defaults\n            to None, which means that the plugin will attempt an automatic\n            detection.\n        :param freeze_remaining_model: If True, the plugin will freeze (set\n            layers in eval mode and disable autograd for parameters) all the\n            model except the cwr layer. Defaults to True.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "log", "=", "logging", ".", "getLogger", "(", "\"avalanche\"", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "cwr_layer_name", "=", "cwr_layer_name", "\n", "self", ".", "freeze_remaining_model", "=", "freeze_remaining_model", "\n", "\n", "# Model setup", "\n", "self", ".", "model", ".", "saved_weights", "=", "{", "}", "\n", "self", ".", "model", ".", "past_j", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "model", ".", "cur_j", "=", "defaultdict", "(", "int", ")", "\n", "\n", "# to be updated", "\n", "self", ".", "cur_class", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.after_training_exp": [[43, 46], ["cwr_star.CWRStarPlugin.consolidate_weights", "cwr_star.CWRStarPlugin.set_consolidate_weights"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.consolidate_weights", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.set_consolidate_weights"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "consolidate_weights", "(", ")", "\n", "self", ".", "set_consolidate_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.before_training_exp": [[47, 58], ["avalanche.training.utils.examples_per_class", "cwr_star.CWRStarPlugin.reset_weights", "cwr_star.CWRStarPlugin.freeze_other_layers", "set", "cwr_star.CWRStarPlugin.model.cur_j.keys"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.examples_per_class", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.reset_weights", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.freeze_other_layers"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "freeze_remaining_model", "and", "strategy", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "            ", "self", ".", "freeze_other_layers", "(", ")", "\n", "\n", "# Count current classes and number of samples for each of them.", "\n", "", "data", "=", "strategy", ".", "experience", ".", "dataset", "\n", "self", ".", "model", ".", "cur_j", "=", "examples_per_class", "(", "data", ".", "targets", ")", "\n", "self", ".", "cur_class", "=", "[", "cls", "for", "cls", "in", "set", "(", "self", ".", "model", ".", "cur_j", ".", "keys", "(", ")", ")", "if", "\n", "self", ".", "model", ".", "cur_j", "[", "cls", "]", ">", "0", "]", "\n", "\n", "self", ".", "reset_weights", "(", "self", ".", "cur_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.consolidate_weights": [[59, 81], ["torch.no_grad", "cwr_star.CWRStarPlugin.get_cwr_layer", "numpy.average", "cwr_star.CWRStarPlugin.weight.detach().cpu().numpy", "cwr_star.CWRStarPlugin.weight.detach().cpu().numpy", "cwr_star.CWRStarPlugin.model.saved_weights.keys", "numpy.sqrt", "cwr_star.CWRStarPlugin.weight.detach().cpu", "cwr_star.CWRStarPlugin.weight.detach().cpu", "cwr_star.CWRStarPlugin.weight.detach", "cwr_star.CWRStarPlugin.weight.detach"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.get_cwr_layer"], ["", "def", "consolidate_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Mean-shift for the target layer weights\"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "cwr_layer", "=", "self", ".", "get_cwr_layer", "(", ")", "\n", "globavg", "=", "np", ".", "average", "(", "cwr_layer", ".", "weight", ".", "detach", "(", ")", "\n", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "self", ".", "cur_class", "]", ")", "\n", "for", "c", "in", "self", ".", "cur_class", ":", "\n", "                ", "w", "=", "cwr_layer", ".", "weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "c", "]", "\n", "\n", "if", "c", "in", "self", ".", "cur_class", ":", "\n", "                    ", "new_w", "=", "w", "-", "globavg", "\n", "if", "c", "in", "self", ".", "model", ".", "saved_weights", ".", "keys", "(", ")", ":", "\n", "                        ", "wpast_j", "=", "np", ".", "sqrt", "(", "self", ".", "model", ".", "past_j", "[", "c", "]", "/", "\n", "self", ".", "model", ".", "cur_j", "[", "c", "]", ")", "\n", "# wpast_j = model.past_j[c] / model.cur_j[c]", "\n", "self", ".", "model", ".", "saved_weights", "[", "c", "]", "=", "(", "self", ".", "model", ".", "saved_weights", "[", "c", "]", "*", "wpast_j", "+", "new_w", ")", "/", "(", "wpast_j", "+", "1", ")", "\n", "self", ".", "model", ".", "past_j", "[", "c", "]", "+=", "self", ".", "model", ".", "cur_j", "[", "c", "]", "\n", "", "else", ":", "\n", "                        ", "self", ".", "model", ".", "saved_weights", "[", "c", "]", "=", "new_w", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.set_consolidate_weights": [[82, 90], ["torch.no_grad", "cwr_star.CWRStarPlugin.get_cwr_layer", "cwr_star.CWRStarPlugin.model.saved_weights.items", "cwr_star.CWRStarPlugin.weight[].copy_", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.get_cwr_layer"], ["", "", "", "", "", "def", "set_consolidate_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" set trained weights \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "cwr_layer", "=", "self", ".", "get_cwr_layer", "(", ")", "\n", "for", "c", ",", "w", "in", "self", ".", "model", ".", "saved_weights", ".", "items", "(", ")", ":", "\n", "                ", "cwr_layer", ".", "weight", "[", "c", "]", ".", "copy_", "(", "\n", "torch", ".", "from_numpy", "(", "self", ".", "model", ".", "saved_weights", "[", "c", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.reset_weights": [[92, 101], ["torch.no_grad", "cwr_star.CWRStarPlugin.get_cwr_layer", "cwr_star.CWRStarPlugin.weight.fill_", "cwr_star.CWRStarPlugin.model.saved_weights.items", "cwr_star.CWRStarPlugin.weight[].copy_", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.get_cwr_layer"], ["", "", "", "def", "reset_weights", "(", "self", ",", "cur_clas", ")", ":", "\n", "        ", "\"\"\" reset weights\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "cwr_layer", "=", "self", ".", "get_cwr_layer", "(", ")", "\n", "cwr_layer", ".", "weight", ".", "fill_", "(", "0.0", ")", "\n", "for", "c", ",", "w", "in", "self", ".", "model", ".", "saved_weights", ".", "items", "(", ")", ":", "\n", "                ", "if", "c", "in", "cur_clas", ":", "\n", "                    ", "cwr_layer", ".", "weight", "[", "c", "]", ".", "copy_", "(", "\n", "torch", ".", "from_numpy", "(", "self", ".", "model", ".", "saved_weights", "[", "c", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.get_cwr_layer": [[103, 113], ["avalanche.training.utils.get_last_fc_layer", "avalanche.training.utils.get_layer_by_name"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_last_fc_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layer_by_name"], ["", "", "", "", "def", "get_cwr_layer", "(", "self", ")", "->", "Optional", "[", "Linear", "]", ":", "\n", "        ", "result", "=", "None", "\n", "if", "self", ".", "cwr_layer_name", "is", "None", ":", "\n", "            ", "last_fc", "=", "get_last_fc_layer", "(", "self", ".", "model", ")", "\n", "if", "last_fc", "is", "not", "None", ":", "\n", "                ", "result", "=", "last_fc", "[", "1", "]", "\n", "", "", "else", ":", "\n", "            ", "result", "=", "get_layer_by_name", "(", "self", ".", "model", ",", "self", ".", "cwr_layer_name", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.freeze_other_layers": [[114, 120], ["cwr_star.CWRStarPlugin.get_cwr_layer", "avalanche.training.utils.freeze_everything", "avalanche.training.utils.unfreeze_everything", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cwr_star.CWRStarPlugin.get_cwr_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.freeze_everything", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.unfreeze_everything"], ["", "def", "freeze_other_layers", "(", "self", ")", ":", "\n", "        ", "cwr_layer", "=", "self", ".", "get_cwr_layer", "(", ")", "\n", "if", "cwr_layer", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Can\\'t find a the Linear layer'", ")", "\n", "", "freeze_everything", "(", "self", ".", "model", ")", "\n", "unfreeze_everything", "(", "cwr_layer", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lwf.LwFPlugin.__init__": [[18, 37], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "set"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "alpha", "=", "1", ",", "temperature", "=", "2", ")", ":", "\n", "        ", "\"\"\"\n        :param alpha: distillation hyperparameter. It can be either a float\n                number or a list containing alpha for each experience.\n        :param temperature: softmax temperature for distillation\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "prev_model", "=", "None", "\n", "\n", "self", ".", "prev_classes", "=", "{", "'0'", ":", "set", "(", ")", "}", "\n", "\"\"\" In Avalanche, targets of different experiences are not ordered. \n        As a result, some units may be allocated even though their \n        corresponding class has never been seen by the model.\n        Knowledge distillation uses only units corresponding to old classes. \n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lwf.LwFPlugin._distillation_loss": [[38, 49], ["list", "torch.nn.functional.kl_div", "torch.log_softmax", "torch.softmax"], "methods", ["None"], ["", "def", "_distillation_loss", "(", "self", ",", "out", ",", "prev_out", ",", "active_units", ")", ":", "\n", "        ", "\"\"\"\n        Compute distillation loss between output of the current model and\n        and output of the previous (saved) model.\n        \"\"\"", "\n", "# we compute the loss only on the previously active units.", "\n", "au", "=", "list", "(", "active_units", ")", "\n", "log_p", "=", "torch", ".", "log_softmax", "(", "out", "/", "self", ".", "temperature", ",", "dim", "=", "1", ")", "[", ":", ",", "au", "]", "\n", "q", "=", "torch", ".", "softmax", "(", "prev_out", "/", "self", ".", "temperature", ",", "dim", "=", "1", ")", "[", ":", ",", "au", "]", "\n", "res", "=", "torch", ".", "nn", ".", "functional", ".", "kl_div", "(", "log_p", ",", "q", ",", "reduction", "=", "'batchmean'", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lwf.LwFPlugin.penalty": [[50, 79], ["avalanche.models.avalanche_forward.keys", "torch.no_grad", "isinstance", "avalanche.models.avalanche_forward", "avalanche.models.avalanche_forward", "lwf.LwFPlugin._distillation_loss", "lwf.LwFPlugin.prev_model"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lwf.LwFPlugin._distillation_loss"], ["", "def", "penalty", "(", "self", ",", "out", ",", "x", ",", "alpha", ",", "curr_model", ")", ":", "\n", "        ", "\"\"\"\n        Compute weighted distillation loss.\n        \"\"\"", "\n", "\n", "if", "self", ".", "prev_model", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "self", ".", "prev_model", ",", "MultiTaskModule", ")", ":", "\n", "# output from previous output heads.", "\n", "                    ", "y_prev", "=", "avalanche_forward", "(", "self", ".", "prev_model", ",", "x", ",", "None", ")", "\n", "# in a multitask scenario we need to compute the output", "\n", "# from all the heads, so we need to call forward again.", "\n", "# TODO: can we avoid this?", "\n", "y_curr", "=", "avalanche_forward", "(", "curr_model", ",", "x", ",", "None", ")", "\n", "", "else", ":", "# no task labels", "\n", "                    ", "y_prev", "=", "{", "'0'", ":", "self", ".", "prev_model", "(", "x", ")", "}", "\n", "y_curr", "=", "{", "'0'", ":", "out", "}", "\n", "\n", "", "", "dist_loss", "=", "0", "\n", "for", "task_id", "in", "y_prev", ".", "keys", "(", ")", ":", "\n", "# compute kd only for previous heads.", "\n", "                ", "if", "task_id", "in", "self", ".", "prev_classes", ":", "\n", "                    ", "yp", "=", "y_prev", "[", "task_id", "]", "\n", "yc", "=", "y_curr", "[", "task_id", "]", "\n", "au", "=", "self", ".", "prev_classes", "[", "task_id", "]", "\n", "dist_loss", "+=", "self", ".", "_distillation_loss", "(", "yc", ",", "yp", ",", "au", ")", "\n", "", "", "return", "alpha", "*", "dist_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lwf.LwFPlugin.before_backward": [[80, 89], ["lwf.LwFPlugin.penalty", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.penalty"], ["", "", "def", "before_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Add distillation loss\n        \"\"\"", "\n", "alpha", "=", "self", ".", "alpha", "[", "strategy", ".", "clock", ".", "train_exp_counter", "]", "if", "isinstance", "(", "self", ".", "alpha", ",", "(", "list", ",", "tuple", ")", ")", "else", "self", ".", "alpha", "\n", "penalty", "=", "self", ".", "penalty", "(", "strategy", ".", "mb_output", ",", "strategy", ".", "mb_x", ",", "alpha", ",", "\n", "strategy", ".", "model", ")", "\n", "strategy", ".", "loss", "+=", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lwf.LwFPlugin.after_training_exp": [[90, 106], ["copy.deepcopy", "set", "lwf.LwFPlugin.prev_classes[].union", "str", "str"], "methods", ["None"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Save a copy of the model after each experience and\n        update self.prev_classes to include the newly learned classes.\n        \"\"\"", "\n", "self", ".", "prev_model", "=", "copy", ".", "deepcopy", "(", "strategy", ".", "model", ")", "\n", "task_ids", "=", "strategy", ".", "experience", ".", "dataset", ".", "task_set", "\n", "for", "task_id", "in", "task_ids", ":", "\n", "            ", "task_data", "=", "strategy", ".", "experience", ".", "dataset", ".", "task_set", "[", "task_id", "]", "\n", "pc", "=", "set", "(", "task_data", ".", "targets", ")", "\n", "\n", "if", "task_id", "not", "in", "self", ".", "prev_classes", ":", "\n", "                ", "self", ".", "prev_classes", "[", "str", "(", "task_id", ")", "]", "=", "pc", "\n", "", "else", ":", "\n", "                ", "self", ".", "prev_classes", "[", "str", "(", "task_id", ")", "]", "=", "self", ".", "prev_classes", "[", "task_id", "]", ".", "union", "(", "pc", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gdumb.GDumbPlugin.__init__": [[25, 36], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "avalanche.training.storage_policy.ClassBalancedBuffer"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "mem_size", ":", "int", "=", "200", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mem_size", "=", "mem_size", "\n", "\n", "# model initialization", "\n", "self", ".", "buffer", "=", "{", "}", "\n", "self", ".", "storage_policy", "=", "ClassBalancedBuffer", "(", "\n", "max_size", "=", "self", ".", "mem_size", ",", "\n", "adaptive_size", "=", "True", "\n", ")", "\n", "self", ".", "init_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gdumb.GDumbPlugin.before_train_dataset_adaptation": [[37, 45], ["strategy.model_adaptation", "copy.deepcopy", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.model_adaptation"], ["", "def", "before_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Reset model. \"\"\"", "\n", "if", "self", ".", "init_model", "is", "None", ":", "\n", "            ", "self", ".", "init_model", "=", "copy", ".", "deepcopy", "(", "strategy", ".", "model", ")", "\n", "", "else", ":", "\n", "            ", "strategy", ".", "model", "=", "copy", ".", "deepcopy", "(", "self", ".", "init_model", ")", "\n", "", "strategy", ".", "model_adaptation", "(", "self", ".", "init_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gdumb.GDumbPlugin.before_eval_dataset_adaptation": [[46, 49], ["strategy.model_adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.model_adaptation"], ["", "def", "before_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "strategy", ".", "model_adaptation", "(", "self", ".", "init_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gdumb.GDumbPlugin.after_train_dataset_adaptation": [[50, 54], ["gdumb.GDumbPlugin.storage_policy.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "storage_policy", ".", "update", "(", "strategy", ",", "**", "kwargs", ")", "\n", "strategy", ".", "adapted_dataset", "=", "self", ".", "storage_policy", ".", "buffer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.__init__": [[42, 86], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "warnings.warn", "set", "isinstance", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "si_lambda", ":", "Union", "[", "float", ",", "Sequence", "[", "float", "]", "]", ",", "\n", "eps", ":", "float", "=", "0.0000001", ",", "\n", "excluded_parameters", ":", "Sequence", "[", "'str'", "]", "=", "None", ",", "\n", "device", ":", "Any", "=", "'as_strategy'", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Synaptic Intelligence plugin.\n\n        :param si_lambda: Synaptic Intelligence lambda term.\n            If list, one lambda for each experience. If the list has less\n            elements than the number of experiences, last lambda will be\n            used for the remaining experiences.\n        :param eps: Synaptic Intelligence damping parameter.\n        :param device: The device to use to run the S.I. experiences.\n            Defaults to \"as_strategy\", which means that the `device` field of\n            the strategy will be used. Using a different device may lead to a\n            performance drop due to the required data transfer.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "warnings", ".", "warn", "(", "\"The Synaptic Intelligence plugin is in an alpha stage \"", "\n", "\"and is not perfectly aligned with the paper \"", "\n", "\"implementation. Please use at your own risk!\"", ")", "\n", "\n", "if", "excluded_parameters", "is", "None", ":", "\n", "            ", "excluded_parameters", "=", "[", "]", "\n", "", "self", ".", "si_lambda", "=", "si_lambda", "if", "isinstance", "(", "si_lambda", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "si_lambda", "]", "\n", "self", ".", "eps", ":", "float", "=", "eps", "\n", "self", ".", "excluded_parameters", ":", "Set", "[", "str", "]", "=", "set", "(", "excluded_parameters", ")", "\n", "self", ".", "ewc_data", ":", "EwcDataType", "=", "(", "dict", "(", ")", ",", "dict", "(", ")", ")", "\n", "\"\"\"\n        The first dictionary contains the params at loss minimum while the \n        second one contains the parameter importance.\n        \"\"\"", "\n", "\n", "self", ".", "syn_data", ":", "SynDataType", "=", "{", "\n", "'old_theta'", ":", "dict", "(", ")", ",", "\n", "'new_theta'", ":", "dict", "(", ")", ",", "\n", "'grad'", ":", "dict", "(", ")", ",", "\n", "'trajectory'", ":", "dict", "(", ")", ",", "\n", "'cum_trajectory'", ":", "dict", "(", ")", "}", "\n", "\n", "self", ".", "_device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.before_training_exp": [[87, 96], ["super().before_training_exp", "synaptic_intelligence.SynapticIntelligencePlugin.create_syn_data", "synaptic_intelligence.SynapticIntelligencePlugin.init_batch"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.create_syn_data", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.init_batch"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_exp", "(", "strategy", ",", "**", "kwargs", ")", "\n", "SynapticIntelligencePlugin", ".", "create_syn_data", "(", "\n", "strategy", ".", "model", ",", "self", ".", "ewc_data", ",", "self", ".", "syn_data", ",", "\n", "self", ".", "excluded_parameters", ")", "\n", "\n", "SynapticIntelligencePlugin", ".", "init_batch", "(", "\n", "strategy", ".", "model", ",", "self", ".", "ewc_data", ",", "self", ".", "syn_data", ",", "\n", "self", ".", "excluded_parameters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.before_backward": [[97, 112], ["super().before_backward", "synaptic_intelligence.SynapticIntelligencePlugin.compute_ewc_loss", "synaptic_intelligence.SynapticIntelligencePlugin.compute_ewc_loss", "synaptic_intelligence.SynapticIntelligencePlugin.device"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_backward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.compute_ewc_loss", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.compute_ewc_loss", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.device"], ["", "def", "before_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_backward", "(", "strategy", ",", "**", "kwargs", ")", "\n", "\n", "exp_id", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "try", ":", "\n", "            ", "si_lamb", "=", "self", ".", "si_lambda", "[", "exp_id", "]", "\n", "", "except", "IndexError", ":", "# less than one lambda per experience, take last", "\n", "            ", "si_lamb", "=", "self", ".", "si_lambda", "[", "-", "1", "]", "\n", "\n", "", "syn_loss", "=", "SynapticIntelligencePlugin", ".", "compute_ewc_loss", "(", "\n", "strategy", ".", "model", ",", "self", ".", "ewc_data", ",", "self", ".", "excluded_parameters", ",", "\n", "lambd", "=", "si_lamb", ",", "device", "=", "self", ".", "device", "(", "strategy", ")", ")", "\n", "\n", "if", "syn_loss", "is", "not", "None", ":", "\n", "            ", "strategy", ".", "loss", "+=", "syn_loss", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.before_training_iteration": [[113, 117], ["super().before_training_iteration", "synaptic_intelligence.SynapticIntelligencePlugin.pre_update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.pre_update"], ["", "", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_iteration", "(", "strategy", ",", "**", "kwargs", ")", "\n", "SynapticIntelligencePlugin", ".", "pre_update", "(", "strategy", ".", "model", ",", "self", ".", "syn_data", ",", "\n", "self", ".", "excluded_parameters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.after_training_iteration": [[118, 122], ["super().after_training_iteration", "synaptic_intelligence.SynapticIntelligencePlugin.post_update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.post_update"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training_iteration", "(", "strategy", ",", "**", "kwargs", ")", "\n", "SynapticIntelligencePlugin", ".", "post_update", "(", "strategy", ".", "model", ",", "self", ".", "syn_data", ",", "\n", "self", ".", "excluded_parameters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.after_training_exp": [[123, 128], ["super().after_training_exp", "synaptic_intelligence.SynapticIntelligencePlugin.update_ewc_data"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.after_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.update_ewc_data"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training_exp", "(", "strategy", ",", "**", "kwargs", ")", "\n", "SynapticIntelligencePlugin", ".", "update_ewc_data", "(", "\n", "strategy", ".", "model", ",", "self", ".", "ewc_data", ",", "self", ".", "syn_data", ",", "0.001", ",", "\n", "self", ".", "excluded_parameters", ",", "1", ",", "eps", "=", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.device": [[129, 134], ["None"], "methods", ["None"], ["", "def", "device", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "if", "self", ".", "_device", "==", "'as_strategy'", ":", "\n", "            ", "return", "strategy", ".", "device", "\n", "\n", "", "return", "self", ".", "_device", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.create_syn_data": [[135, 160], ["torch.no_grad", "synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters", "synaptic_intelligence.SynapticIntelligencePlugin._zero", "synaptic_intelligence.SynapticIntelligencePlugin._zero", "synaptic_intelligence.SynapticIntelligencePlugin._zero", "synaptic_intelligence.SynapticIntelligencePlugin._zero", "synaptic_intelligence.SynapticIntelligencePlugin._zero", "synaptic_intelligence.SynapticIntelligencePlugin._zero", "synaptic_intelligence.SynapticIntelligencePlugin._zero"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero"], ["", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "create_syn_data", "(", "model", ":", "Module", ",", "ewc_data", ":", "EwcDataType", ",", "\n", "syn_data", ":", "SynDataType", ",", "excluded_parameters", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "params", "=", "SynapticIntelligencePlugin", ".", "allowed_parameters", "(", "\n", "model", ",", "excluded_parameters", ")", "\n", "\n", "for", "param_name", ",", "param", "in", "params", ":", "\n", "            ", "if", "param_name", "in", "ewc_data", "[", "0", "]", ":", "\n", "                ", "continue", "\n", "\n", "# Handles added parameters (doesn't manage parameter expansion!)", "\n", "", "ewc_data", "[", "0", "]", "[", "param_name", "]", "=", "SynapticIntelligencePlugin", ".", "_zero", "(", "param", ")", "\n", "ewc_data", "[", "1", "]", "[", "param_name", "]", "=", "SynapticIntelligencePlugin", ".", "_zero", "(", "param", ")", "\n", "\n", "syn_data", "[", "'old_theta'", "]", "[", "param_name", "]", "=", "SynapticIntelligencePlugin", ".", "_zero", "(", "param", ")", "\n", "syn_data", "[", "'new_theta'", "]", "[", "param_name", "]", "=", "SynapticIntelligencePlugin", ".", "_zero", "(", "param", ")", "\n", "syn_data", "[", "'grad'", "]", "[", "param_name", "]", "=", "SynapticIntelligencePlugin", ".", "_zero", "(", "param", ")", "\n", "syn_data", "[", "'trajectory'", "]", "[", "param_name", "]", "=", "SynapticIntelligencePlugin", ".", "_zero", "(", "param", ")", "\n", "syn_data", "[", "'cum_trajectory'", "]", "[", "param_name", "]", "=", "SynapticIntelligencePlugin", ".", "_zero", "(", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin._zero": [[161, 165], ["torch.no_grad", "torch.zeros", "param.numel"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_zero", "(", "param", ":", "Tensor", ")", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "param", ".", "numel", "(", ")", ",", "dtype", "=", "param", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.extract_weights": [[166, 175], ["torch.no_grad", "synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters", "param.detach().cpu().flatten", "param.detach().cpu", "param.detach"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters"], ["", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "extract_weights", "(", "model", ":", "Module", ",", "target", ":", "ParamDict", ",", "\n", "excluded_parameters", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "params", "=", "SynapticIntelligencePlugin", ".", "allowed_parameters", "(", "\n", "model", ",", "excluded_parameters", ")", "\n", "\n", "for", "name", ",", "param", "in", "params", ":", "\n", "            ", "target", "[", "name", "]", "[", "...", "]", "=", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.extract_grad": [[176, 185], ["torch.no_grad", "synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters", "param.grad.detach().cpu().flatten", "param.grad.detach().cpu", "param.grad.detach"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters"], ["", "", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "extract_grad", "(", "model", ",", "target", ":", "ParamDict", ",", "excluded_parameters", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "params", "=", "SynapticIntelligencePlugin", ".", "allowed_parameters", "(", "\n", "model", ",", "excluded_parameters", ")", "\n", "\n", "# Store the gradients into target", "\n", "for", "name", ",", "param", "in", "params", ":", "\n", "            ", "target", "[", "name", "]", "[", "...", "]", "=", "param", ".", "grad", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.init_batch": [[186, 195], ["torch.no_grad", "synaptic_intelligence.SynapticIntelligencePlugin.extract_weights", "syn_data[].items", "param_trajectory.fill_"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.extract_weights"], ["", "", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "init_batch", "(", "model", ",", "ewc_data", ":", "EwcDataType", ",", "syn_data", ":", "SynDataType", ",", "\n", "excluded_parameters", ":", "Set", "[", "str", "]", ")", ":", "\n", "# Keep initial weights", "\n", "        ", "SynapticIntelligencePlugin", ".", "extract_weights", "(", "model", ",", "ewc_data", "[", "0", "]", ",", "excluded_parameters", ")", "\n", "for", "param_name", ",", "param_trajectory", "in", "syn_data", "[", "'trajectory'", "]", ".", "items", "(", ")", ":", "\n", "            ", "param_trajectory", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.pre_update": [[196, 202], ["torch.no_grad", "synaptic_intelligence.SynapticIntelligencePlugin.extract_weights"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.extract_weights"], ["", "", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "pre_update", "(", "model", ",", "syn_data", ":", "SynDataType", ",", "\n", "excluded_parameters", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "SynapticIntelligencePlugin", ".", "extract_weights", "(", "model", ",", "syn_data", "[", "'old_theta'", "]", ",", "\n", "excluded_parameters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.post_update": [[203, 217], ["torch.no_grad", "synaptic_intelligence.SynapticIntelligencePlugin.extract_weights", "synaptic_intelligence.SynapticIntelligencePlugin.extract_grad"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.extract_weights", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.extract_grad"], ["", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "post_update", "(", "model", ",", "syn_data", ":", "SynDataType", ",", "\n", "excluded_parameters", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "SynapticIntelligencePlugin", ".", "extract_weights", "(", "model", ",", "syn_data", "[", "'new_theta'", "]", ",", "\n", "excluded_parameters", ")", "\n", "SynapticIntelligencePlugin", ".", "extract_grad", "(", "model", ",", "syn_data", "[", "'grad'", "]", ",", "\n", "excluded_parameters", ")", "\n", "\n", "for", "param_name", "in", "syn_data", "[", "'trajectory'", "]", ":", "\n", "            ", "syn_data", "[", "'trajectory'", "]", "[", "param_name", "]", "+=", "syn_data", "[", "'grad'", "]", "[", "param_name", "]", "*", "(", "\n", "syn_data", "[", "'new_theta'", "]", "[", "param_name", "]", "-", "\n", "syn_data", "[", "'old_theta'", "]", "[", "param_name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.compute_ewc_loss": [[218, 240], ["synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters", "param.to().flatten", "[].to", "[].to", "torch.dot", "param.to"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters"], ["", "", "@", "staticmethod", "\n", "def", "compute_ewc_loss", "(", "model", ",", "ewc_data", ":", "EwcDataType", ",", "\n", "excluded_parameters", ":", "Set", "[", "str", "]", ",", "device", ",", "lambd", "=", "0.0", ")", ":", "\n", "        ", "params", "=", "SynapticIntelligencePlugin", ".", "allowed_parameters", "(", "\n", "model", ",", "excluded_parameters", ")", "\n", "\n", "loss", "=", "None", "\n", "for", "name", ",", "param", "in", "params", ":", "\n", "            ", "weights", "=", "param", ".", "to", "(", "device", ")", ".", "flatten", "(", ")", "# Flat, not detached", "\n", "param_ewc_data_0", "=", "ewc_data", "[", "0", "]", "[", "name", "]", ".", "to", "(", "device", ")", "# Flat, detached", "\n", "param_ewc_data_1", "=", "ewc_data", "[", "1", "]", "[", "name", "]", ".", "to", "(", "device", ")", "# Flat, detached", "\n", "\n", "syn_loss", ":", "Tensor", "=", "torch", ".", "dot", "(", "\n", "param_ewc_data_1", ",", "\n", "(", "weights", "-", "param_ewc_data_0", ")", "**", "2", ")", "*", "(", "lambd", "/", "2", ")", "\n", "\n", "if", "loss", "is", "None", ":", "\n", "                ", "loss", "=", "syn_loss", "\n", "", "else", ":", "\n", "                ", "loss", "+=", "syn_loss", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.update_ewc_data": [[241, 268], ["torch.no_grad", "synaptic_intelligence.SynapticIntelligencePlugin.extract_weights", "torch.empty_like().copy_", "torch.clamp", "[].clone", "numpy.square", "torch.empty_like"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.extract_weights"], ["", "@", "staticmethod", "\n", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_ewc_data", "(", "net", ",", "ewc_data", ":", "EwcDataType", ",", "syn_data", ":", "SynDataType", ",", "\n", "clip_to", ":", "float", ",", "excluded_parameters", ":", "Set", "[", "str", "]", ",", "\n", "c", "=", "0.0015", ",", "eps", ":", "float", "=", "0.0000001", ")", ":", "\n", "        ", "SynapticIntelligencePlugin", ".", "extract_weights", "(", "net", ",", "syn_data", "[", "'new_theta'", "]", ",", "\n", "excluded_parameters", ")", "\n", "\n", "for", "param_name", "in", "syn_data", "[", "'cum_trajectory'", "]", ":", "\n", "            ", "syn_data", "[", "'cum_trajectory'", "]", "[", "param_name", "]", "+=", "c", "*", "syn_data", "[", "'trajectory'", "]", "[", "param_name", "]", "/", "(", "\n", "np", ".", "square", "(", "syn_data", "[", "'new_theta'", "]", "[", "param_name", "]", "-", "\n", "ewc_data", "[", "0", "]", "[", "param_name", "]", ")", "+", "eps", ")", "\n", "\n", "", "for", "param_name", "in", "syn_data", "[", "'cum_trajectory'", "]", ":", "\n", "            ", "ewc_data", "[", "1", "]", "[", "param_name", "]", "=", "torch", ".", "empty_like", "(", "\n", "syn_data", "[", "'cum_trajectory'", "]", "[", "param_name", "]", ")", ".", "copy_", "(", "\n", "-", "syn_data", "[", "'cum_trajectory'", "]", "[", "param_name", "]", ")", "\n", "\n", "# change sign here because the Ewc regularization", "\n", "# in Caffe (theta - thetaold) is inverted w.r.t. syn equation [4]", "\n", "# (thetaold - theta)", "\n", "", "for", "param_name", "in", "ewc_data", "[", "1", "]", ":", "\n", "            ", "ewc_data", "[", "1", "]", "[", "param_name", "]", "=", "torch", ".", "clamp", "(", "\n", "ewc_data", "[", "1", "]", "[", "param_name", "]", ",", "max", "=", "clip_to", ")", "\n", "ewc_data", "[", "0", "]", "[", "param_name", "]", "=", "syn_data", "[", "'new_theta'", "]", "[", "param_name", "]", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.explode_excluded_parameters": [[269, 286], ["set", "set.add", "x.endswith", "set.add"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "explode_excluded_parameters", "(", "excluded", ":", "Set", "[", "str", "]", ")", "->", "Set", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Explodes a list of excluded parameters by adding a generic final \".*\"\n        wildcard at its end.\n\n        :param excluded: The original set of excluded parameters.\n\n        :return: The set of excluded parameters in which \".*\" patterns have been\n            added.\n        \"\"\"", "\n", "result", "=", "set", "(", ")", "\n", "for", "x", "in", "excluded", ":", "\n", "            ", "result", ".", "add", "(", "x", ")", "\n", "if", "not", "x", ".", "endswith", "(", "'*'", ")", ":", "\n", "                ", "result", ".", "add", "(", "x", "+", "'.*'", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.not_excluded_parameters": [[287, 312], ["synaptic_intelligence.SynapticIntelligencePlugin.explode_excluded_parameters", "avalanche.training.utils.get_layers_and_params", "model.named_parameters", "isinstance", "synaptic_intelligence.SynapticIntelligencePlugin.explode_excluded_parameters", "fnmatch.fnmatch.fnmatch", "result.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.explode_excluded_parameters", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_layers_and_params", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.explode_excluded_parameters"], ["", "@", "staticmethod", "\n", "def", "not_excluded_parameters", "(", "model", ":", "Module", ",", "excluded_parameters", ":", "Set", "[", "str", "]", ")", "->", "List", "[", "Tuple", "[", "str", ",", "Tensor", "]", "]", ":", "\n", "# Add wildcards \".*\" to all excluded parameter names", "\n", "        ", "result", "=", "[", "]", "\n", "excluded_parameters", "=", "SynapticIntelligencePlugin", ".", "explode_excluded_parameters", "(", "excluded_parameters", ")", "\n", "layers_params", "=", "get_layers_and_params", "(", "model", ")", "\n", "\n", "for", "lp", "in", "layers_params", ":", "\n", "            ", "if", "isinstance", "(", "lp", ".", "layer", ",", "_NormBase", ")", ":", "\n", "# Exclude batch norm parameters", "\n", "                ", "excluded_parameters", ".", "add", "(", "lp", ".", "parameter_name", ")", "\n", "\n", "", "", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "accepted", "=", "True", "\n", "for", "exclusion_pattern", "in", "excluded_parameters", ":", "\n", "                ", "if", "fnmatch", "(", "name", ",", "exclusion_pattern", ")", ":", "\n", "                    ", "accepted", "=", "False", "\n", "break", "\n", "\n", "", "", "if", "accepted", ":", "\n", "                ", "result", ".", "append", "(", "(", "name", ",", "param", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.allowed_parameters": [[313, 326], ["synaptic_intelligence.SynapticIntelligencePlugin.not_excluded_parameters", "result.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.synaptic_intelligence.SynapticIntelligencePlugin.not_excluded_parameters"], ["", "@", "staticmethod", "\n", "def", "allowed_parameters", "(", "model", ":", "Module", ",", "excluded_parameters", ":", "Set", "[", "str", "]", ")", "->", "List", "[", "Tuple", "[", "str", ",", "Tensor", "]", "]", ":", "\n", "\n", "        ", "allow_list", "=", "SynapticIntelligencePlugin", ".", "not_excluded_parameters", "(", "\n", "model", ",", "excluded_parameters", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "allow_list", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "result", ".", "append", "(", "(", "name", ",", "param", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.agem.AGEMPlugin.__init__": [[20, 39], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "int", "int"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "patterns_per_experience", ":", "int", ",", "sample_size", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        :param patterns_per_experience: number of patterns per experience in the\n            memory.\n        :param sample_size: number of patterns in memory sample when computing\n            reference gradient.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "patterns_per_experience", "=", "int", "(", "patterns_per_experience", ")", "\n", "self", ".", "sample_size", "=", "int", "(", "sample_size", ")", "\n", "\n", "self", ".", "buffers", "=", "[", "]", "# one AvalancheDataset for each experience.", "\n", "self", ".", "buffer_dataloader", "=", "None", "\n", "self", ".", "buffer_dliter", "=", "None", "\n", "\n", "self", ".", "reference_gradients", "=", "None", "\n", "self", ".", "memory_x", ",", "self", ".", "memory_y", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.agem.AGEMPlugin.before_training_iteration": [[40, 61], ["len", "strategy.model.train", "strategy.optimizer.zero_grad", "agem.AGEMPlugin.sample_from_memory", "avalanche.models.avalanche_forward", "strategy._criterion", "strategy._criterion.backward", "torch.cat", "strategy.optimizer.zero_grad", "xref.to", "yref.to", "p.grad.view", "torch.zeros", "strategy.model.named_parameters", "p.numel"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.agem.AGEMPlugin.sample_from_memory", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute reference gradient on memory sample.\n        \"\"\"", "\n", "if", "len", "(", "self", ".", "buffers", ")", ">", "0", ":", "\n", "            ", "strategy", ".", "model", ".", "train", "(", ")", "\n", "strategy", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "mb", "=", "self", ".", "sample_from_memory", "(", ")", "\n", "xref", ",", "yref", ",", "tid", "=", "mb", "[", "0", "]", ",", "mb", "[", "1", "]", ",", "mb", "[", "-", "1", "]", "\n", "xref", ",", "yref", "=", "xref", ".", "to", "(", "strategy", ".", "device", ")", ",", "yref", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "out", "=", "avalanche_forward", "(", "strategy", ".", "model", ",", "xref", ",", "tid", ")", "\n", "loss", "=", "strategy", ".", "_criterion", "(", "out", ",", "yref", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# gradient can be None for some head on multi-headed models", "\n", "self", ".", "reference_gradients", "=", "[", "\n", "p", ".", "grad", ".", "view", "(", "-", "1", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "torch", ".", "zeros", "(", "p", ".", "numel", "(", ")", ",", "device", "=", "strategy", ".", "device", ")", "\n", "for", "n", ",", "p", "in", "strategy", ".", "model", ".", "named_parameters", "(", ")", "]", "\n", "self", ".", "reference_gradients", "=", "torch", ".", "cat", "(", "self", ".", "reference_gradients", ")", "\n", "strategy", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.agem.AGEMPlugin.after_backward": [[62, 90], ["torch.no_grad", "len", "torch.cat", "torch.dot", "strategy.model.named_parameters", "p.grad.view", "torch.zeros", "strategy.model.named_parameters", "torch.dot", "p.numel", "p.numel", "p.grad.copy_", "grad_proj[].view_as"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "after_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Project gradient based on reference gradients\n        \"\"\"", "\n", "if", "len", "(", "self", ".", "buffers", ")", ">", "0", ":", "\n", "            ", "current_gradients", "=", "[", "\n", "p", ".", "grad", ".", "view", "(", "-", "1", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "torch", ".", "zeros", "(", "p", ".", "numel", "(", ")", ",", "device", "=", "strategy", ".", "device", ")", "\n", "for", "n", ",", "p", "in", "strategy", ".", "model", ".", "named_parameters", "(", ")", "]", "\n", "current_gradients", "=", "torch", ".", "cat", "(", "current_gradients", ")", "\n", "\n", "assert", "current_gradients", ".", "shape", "==", "self", ".", "reference_gradients", ".", "shape", ",", "\"Different model parameters in AGEM projection\"", "\n", "\n", "dotg", "=", "torch", ".", "dot", "(", "current_gradients", ",", "self", ".", "reference_gradients", ")", "\n", "if", "dotg", "<", "0", ":", "\n", "                ", "alpha2", "=", "dotg", "/", "torch", ".", "dot", "(", "self", ".", "reference_gradients", ",", "\n", "self", ".", "reference_gradients", ")", "\n", "grad_proj", "=", "current_gradients", "-", "self", ".", "reference_gradients", "*", "alpha2", "\n", "\n", "count", "=", "0", "\n", "for", "n", ",", "p", "in", "strategy", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "n_param", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "p", ".", "grad", ".", "copy_", "(", "grad_proj", "[", "count", ":", "count", "+", "n_param", "]", ".", "view_as", "(", "p", ")", ")", "\n", "", "count", "+=", "n_param", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.agem.AGEMPlugin.after_training_exp": [[91, 94], ["agem.AGEMPlugin.update_memory"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.update_memory"], ["", "", "", "", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Update replay memory with patterns from current experience. \"\"\"", "\n", "self", ".", "update_memory", "(", "strategy", ".", "experience", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.agem.AGEMPlugin.sample_from_memory": [[95, 101], ["next"], "methods", ["None"], ["", "def", "sample_from_memory", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Sample a minibatch from memory.\n        Return a tuple of patterns (tensor), targets (tensor).\n        \"\"\"", "\n", "return", "next", "(", "self", ".", "buffer_dliter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.agem.AGEMPlugin.update_memory": [[102, 120], ["torch.no_grad", "agem.AGEMPlugin.buffers.append", "avalanche.benchmarks.utils.data_loader.GroupBalancedInfiniteDataLoader", "iter", "len", "torch.utils.data.random_split", "len"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_memory", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        Update replay memory with patterns from current experience.\n        \"\"\"", "\n", "removed_els", "=", "len", "(", "dataset", ")", "-", "self", ".", "patterns_per_experience", "\n", "if", "removed_els", ">", "0", ":", "\n", "            ", "dataset", ",", "_", "=", "random_split", "(", "dataset", ",", "\n", "[", "self", ".", "patterns_per_experience", ",", "\n", "removed_els", "]", ")", "\n", "", "self", ".", "buffers", ".", "append", "(", "dataset", ")", "\n", "self", ".", "buffer_dataloader", "=", "GroupBalancedInfiniteDataLoader", "(", "\n", "self", ".", "buffers", ",", "\n", "batch_size", "=", "self", ".", "sample_size", "//", "len", "(", "self", ".", "buffers", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "pin_memory", "=", "True", ",", "\n", "persistent_workers", "=", "True", ")", "\n", "self", ".", "buffer_dliter", "=", "iter", "(", "self", ".", "buffer_dataloader", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.__init__": [[23, 31], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "lambda_e", ")", ":", "\n", "        ", "\"\"\"\n        :param lambda_e: Euclidean loss hyper parameter\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lambda_e", "=", "lambda_e", "\n", "self", ".", "prev_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin._euclidean_loss": [[32, 37], ["torch.nn.functional.mse_loss"], "methods", ["None"], ["", "def", "_euclidean_loss", "(", "self", ",", "features", ",", "prev_features", ")", ":", "\n", "        ", "\"\"\"\n        Compute euclidean loss\n        \"\"\"", "\n", "return", "torch", ".", "nn", ".", "functional", ".", "mse_loss", "(", "features", ",", "prev_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.penalty": [[38, 48], ["lfl.LFLPlugin.compute_features", "lfl.LFLPlugin._euclidean_loss"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.compute_features", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin._euclidean_loss"], ["", "def", "penalty", "(", "self", ",", "x", ",", "model", ",", "lambda_e", ")", ":", "\n", "        ", "\"\"\"\n        Compute weighted euclidean loss\n        \"\"\"", "\n", "if", "self", ".", "prev_model", "is", "None", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "features", ",", "prev_features", "=", "self", ".", "compute_features", "(", "model", ",", "x", ")", "\n", "dist_loss", "=", "self", ".", "_euclidean_loss", "(", "features", ",", "prev_features", ")", "\n", "return", "lambda_e", "*", "dist_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.compute_features": [[49, 60], ["model.eval", "lfl.LFLPlugin.prev_model.eval", "model.get_features", "lfl.LFLPlugin.prev_model.get_features"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.base_model.BaseModel.get_features", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.base_model.BaseModel.get_features"], ["", "", "def", "compute_features", "(", "self", ",", "model", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute features from prev model and current model\n        \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "self", ".", "prev_model", ".", "eval", "(", ")", "\n", "\n", "features", "=", "model", ".", "get_features", "(", "x", ")", "\n", "prev_features", "=", "self", ".", "prev_model", ".", "get_features", "(", "x", ")", "\n", "\n", "return", "features", ",", "prev_features", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.before_backward": [[61, 70], ["lfl.LFLPlugin.penalty", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.penalty"], ["", "def", "before_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Add euclidean loss between prev and current features as penalty\n        \"\"\"", "\n", "lambda_e", "=", "self", ".", "lambda_e", "[", "strategy", ".", "clock", ".", "train_exp_counter", "]", "if", "isinstance", "(", "self", ".", "lambda_e", ",", "(", "list", ",", "tuple", ")", ")", "else", "self", ".", "lambda_e", "\n", "\n", "penalty", "=", "self", ".", "penalty", "(", "strategy", ".", "mb_x", ",", "strategy", ".", "model", ",", "lambda_e", ")", "\n", "strategy", ".", "loss", "+=", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.after_training_exp": [[71, 85], ["copy.deepcopy", "avalanche.training.utils.freeze_everything", "avalanche.training.utils.get_last_fc_layer", "last_fc.parameters"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.freeze_everything", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_last_fc_layer"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Save a copy of the model after each experience\n        and freeze the prev model and freeze the last layer of current model\n        \"\"\"", "\n", "\n", "self", ".", "prev_model", "=", "copy", ".", "deepcopy", "(", "strategy", ".", "model", ")", "\n", "\n", "freeze_everything", "(", "self", ".", "prev_model", ")", "\n", "\n", "last_fc_name", ",", "last_fc", "=", "get_last_fc_layer", "(", "strategy", ".", "model", ")", "\n", "\n", "for", "param", "in", "last_fc", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lfl.LFLPlugin.before_training": [[86, 93], ["isinstance", "NotImplementedError"], "methods", ["None"], ["", "", "def", "before_training", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Check if the model is an instance of base class to ensure get_features()\n        is implemented\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "strategy", ".", "model", ",", "BaseModel", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "BaseModel", ".", "__name__", "+", "'.get_features()'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.early_stopping.EarlyStoppingPlugin.__init__": [[16, 41], ["avalanche.training.plugins.StrategyPlugin.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "patience", ":", "int", ",", "val_stream_name", ":", "str", ",", "\n", "metric_name", ":", "str", "=", "'Top1_Acc_Stream'", ",", "mode", ":", "str", "=", "'max'", ")", ":", "\n", "        ", "\"\"\"\n        :param patience: Number of epochs to wait before stopping the training.\n        :param val_stream_name: Name of the validation stream to search in the\n        metrics. The corresponding stream will be used to keep track of the\n        evolution of the performance of a model.\n        :param metric_name: The name of the metric to watch as it will be\n        reported in the evaluator.\n        :param mode: Must be \"max\" or \"min\". max (resp. min) means that the\n        given metric should me maximized (resp. minimized).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "val_stream_name", "=", "val_stream_name", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "metric_name", "=", "metric_name", "\n", "self", ".", "metric_key", "=", "f'{self.metric_name}/eval_phase/'", "f'{self.val_stream_name}'", "\n", "if", "mode", "not", "in", "(", "'max'", ",", "'min'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'Mode must be \"max\" or \"min\", got {mode}.'", ")", "\n", "", "self", ".", "operator", "=", "operator", ".", "gt", "if", "mode", "==", "'max'", "else", "operator", ".", "lt", "\n", "\n", "self", ".", "best_state", "=", "None", "# Contains the best parameters", "\n", "self", ".", "best_val", "=", "None", "\n", "self", ".", "best_epoch", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.early_stopping.EarlyStoppingPlugin.before_training": [[42, 46], ["None"], "methods", ["None"], ["", "def", "before_training", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "best_state", "=", "None", "\n", "self", ".", "best_val", "=", "None", "\n", "self", ".", "best_epoch", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.early_stopping.EarlyStoppingPlugin.before_training_epoch": [[47, 52], ["early_stopping.EarlyStoppingPlugin._update_best", "strategy.model.load_state_dict", "strategy.stop_training"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.early_stopping.EarlyStoppingPlugin._update_best", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.stop_training"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_best", "(", "strategy", ")", "\n", "if", "strategy", ".", "clock", ".", "train_exp_epochs", "-", "self", ".", "best_epoch", ">=", "self", ".", "patience", ":", "\n", "            ", "strategy", ".", "model", ".", "load_state_dict", "(", "self", ".", "best_state", ")", "\n", "strategy", ".", "stop_training", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.early_stopping.EarlyStoppingPlugin._update_best": [[53, 60], ["strategy.evaluator.get_last_metrics", "strategy.evaluator.get_last_metrics.get", "early_stopping.EarlyStoppingPlugin.operator", "copy.deepcopy", "strategy.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.get_last_metrics"], ["", "", "def", "_update_best", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "res", "=", "strategy", ".", "evaluator", ".", "get_last_metrics", "(", ")", "\n", "val_acc", "=", "res", ".", "get", "(", "self", ".", "metric_key", ")", "\n", "if", "self", ".", "best_val", "is", "None", "or", "self", ".", "operator", "(", "val_acc", ",", "self", ".", "best_val", ")", ":", "\n", "            ", "self", ".", "best_state", "=", "deepcopy", "(", "strategy", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "best_val", "=", "val_acc", "\n", "self", ".", "best_epoch", "=", "strategy", ".", "clock", ".", "train_exp_epochs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.clock.Clock.__init__": [[15, 36], ["avalanche.training.plugins.StrategyPlugin.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Counter for strategy events. \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# train", "\n", "self", ".", "train_iterations", "=", "0", "\n", "\"\"\" Total number of training iterations. \"\"\"", "\n", "\n", "self", ".", "train_exp_counter", "=", "0", "\n", "\"\"\" Number of past training experiences. \"\"\"", "\n", "\n", "self", ".", "train_exp_epochs", "=", "0", "\n", "\"\"\" Number of training epochs for the current experience. \"\"\"", "\n", "\n", "self", ".", "train_exp_iterations", "=", "0", "\n", "\"\"\" Number of training iterations for the current experience. \"\"\"", "\n", "\n", "self", ".", "train_epoch_iterations", "=", "0", "\n", "\"\"\" Number of iterations for the current epoch. \"\"\"", "\n", "\n", "self", ".", "total_iterations", "=", "0", "\n", "\"\"\" Total number of iterations in training and eval mode. \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.clock.Clock.before_training_exp": [[37, 40], ["None"], "methods", ["None"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "train_exp_iterations", "=", "0", "\n", "self", ".", "train_exp_epochs", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.clock.Clock.before_training_epoch": [[41, 43], ["None"], "methods", ["None"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "train_epoch_iterations", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.clock.Clock.after_training_iteration": [[44, 49], ["None"], "methods", ["None"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "train_epoch_iterations", "+=", "1", "\n", "self", ".", "train_exp_iterations", "+=", "1", "\n", "self", ".", "train_iterations", "+=", "1", "\n", "self", ".", "total_iterations", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.clock.Clock.after_training_epoch": [[50, 52], ["None"], "methods", ["None"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "train_exp_epochs", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.clock.Clock.after_training_exp": [[53, 55], ["None"], "methods", ["None"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "train_exp_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.clock.Clock.after_eval_iteration": [[56, 58], ["None"], "methods", ["None"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "total_iterations", "+=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin.__init__": [[29, 67], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "avalanche.training.storage_policy.ClassBalancedBuffer", "cope.PPPloss"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "mem_size", "=", "200", ",", "n_classes", "=", "10", ",", "p_size", "=", "100", ",", "alpha", "=", "0.99", ",", "\n", "T", "=", "0.1", ",", "max_it_cnt", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        :param mem_size: max number of input samples in the replay memory.\n        :param n_classes: total number of classes that will be encountered. This\n        is used to output predictions for all classes, with zero probability\n        for unseen classes.\n        :param p_size: The prototype size, which equals the feature size of the\n        last layer.\n        :param alpha: The momentum for the exponentially moving average of the\n        prototypes.\n        :param T: The softmax temperature, used as a concentration parameter.\n        :param max_it_cnt: How many processing iterations per batch (experience)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "it_cnt", "=", "0", "\n", "self", ".", "max_it_cnt", "=", "max_it_cnt", "\n", "\n", "# Operational memory: replay memory", "\n", "self", ".", "replay_mem", "=", "{", "}", "\n", "self", ".", "mem_size", "=", "mem_size", "# replay memory size", "\n", "self", ".", "storage_policy", "=", "ClassBalancedBuffer", "(", "\n", "max_size", "=", "self", ".", "mem_size", ",", "\n", "adaptive_size", "=", "True", ")", "\n", "\n", "# Operational memory: Prototypical memory", "\n", "self", ".", "p_mem", "=", "{", "}", "# Scales with nb classes * feature size", "\n", "self", ".", "p_size", "=", "p_size", "# Prototype size determined on runtime", "\n", "self", ".", "tmp_p_mem", "=", "{", "}", "# Intermediate to process batch for multiple times", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "p_init_adaptive", "=", "False", "# Only create proto when class seen", "\n", "\n", "# PPP-loss", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "ppp_loss", "=", "PPPloss", "(", "self", ".", "p_mem", ",", "T", "=", "self", ".", "T", ")", "\n", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin.before_training": [[68, 88], ["print", "avalanche.training.utils.swap_last_fc_layer", "torch.nn.Sequential", "cope.CoPEPlugin._init_new_prototypes", "cope.L2Normalization", "len", "torch.arange().to", "avalanche.training.utils.get_last_fc_layer", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.swap_last_fc_layer", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._init_new_prototypes", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.get_last_fc_layer"], ["", "def", "before_training", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Enforce using the PPP-loss and add a NN-classifier.\"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "\n", "            ", "strategy", ".", "_criterion", "=", "self", ".", "ppp_loss", "\n", "print", "(", "\"Using the Pseudo-Prototypical-Proxy loss for CoPE.\"", ")", "\n", "\n", "# Normalize representation of last layer", "\n", "swap_last_fc_layer", "(", "strategy", ".", "model", ",", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "get_last_fc_layer", "(", "strategy", ".", "model", ")", "[", "1", "]", ",", "\n", "L2Normalization", "(", ")", ")", "\n", ")", "\n", "\n", "# Static prototype init", "\n", "# Create prototypes for all classes at once", "\n", "if", "not", "self", ".", "p_init_adaptive", "and", "len", "(", "self", ".", "p_mem", ")", "==", "0", ":", "\n", "                ", "self", ".", "_init_new_prototypes", "(", "\n", "torch", ".", "arange", "(", "0", ",", "self", ".", "n_classes", ")", ".", "to", "(", "strategy", ".", "device", ")", ")", "\n", "\n", "", "self", ".", "initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin.before_training_exp": [[89, 109], ["avalanche.benchmarks.utils.data_loader.ReplayDataLoader", "len", "avalanche.benchmarks.utils.AvalancheConcatDataset", "cope.CoPEPlugin.replay_mem.values"], "methods", ["None"], ["", "", "def", "before_training_exp", "(", "self", ",", "strategy", ",", "num_workers", "=", "0", ",", "shuffle", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Random retrieval from a class-balanced memory.\n        Dataloader builds batches containing examples from both memories and\n        the training dataset.\n        This implementation requires the use of early stopping, otherwise the\n        entire memory will be iterated.\n        \"\"\"", "\n", "if", "len", "(", "self", ".", "replay_mem", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "self", ".", "it_cnt", "=", "0", "\n", "strategy", ".", "dataloader", "=", "ReplayDataLoader", "(", "\n", "strategy", ".", "adapted_dataset", ",", "\n", "AvalancheConcatDataset", "(", "self", ".", "replay_mem", ".", "values", "(", ")", ")", ",", "\n", "oversample_small_tasks", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_size", "=", "strategy", ".", "train_mb_size", "*", "2", ",", "\n", "force_data_batch_size", "=", "strategy", ".", "train_mb_size", ",", "\n", "shuffle", "=", "shuffle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin.after_training_iteration": [[110, 121], ["strategy.stop_training"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.stop_training"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Implements early stopping, determining how many subsequent times a\n        batch can be used for updates. The dataloader contains only data for\n        the current experience (batch) and the entire memory.\n        Multiple iterations will hence result in the original batch with new\n        exemplars sampled from the memory for each iteration.\n        \"\"\"", "\n", "self", ".", "it_cnt", "+=", "1", "\n", "if", "self", ".", "it_cnt", "==", "self", ".", "max_it_cnt", ":", "\n", "            ", "strategy", ".", "stop_training", "(", ")", "# Stop processing the new-data batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin.after_forward": [[122, 136], ["cope.CoPEPlugin._update_running_prototypes", "cope.CoPEPlugin._init_new_prototypes"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._update_running_prototypes", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._init_new_prototypes"], ["", "", "def", "after_forward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        After the forward we can use the representations to update our running\n        avg of the prototypes. This is in case we do multiple iterations of\n        processing on the same batch.\n\n        New prototypes are initialized for previously unseen classes.\n        \"\"\"", "\n", "\n", "if", "self", ".", "p_init_adaptive", ":", "# Init prototypes for unseen classes in batch", "\n", "            ", "self", ".", "_init_new_prototypes", "(", "strategy", ".", "mb_y", ")", "\n", "\n", "# Update batch info (when multiple iterations on same batch)", "\n", "", "self", ".", "_update_running_prototypes", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._init_new_prototypes": [[137, 149], ["torch.no_grad", "torch.unique().squeeze().view", "range", "torch.unique().squeeze().view.size", "y_unique[].item", "torch.unique().squeeze", "torch.nn.functional.normalize().detach().to", "torch.unique", "torch.nn.functional.normalize().detach", "torch.nn.functional.normalize", "torch.empty().uniform_", "torch.empty"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_init_new_prototypes", "(", "self", ",", "targets", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"Initialize prototypes for previously unseen classes.\n        :param targets: The targets Tensor to make prototypes for.\n        \"\"\"", "\n", "y_unique", "=", "torch", ".", "unique", "(", "targets", ")", ".", "squeeze", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "for", "idx", "in", "range", "(", "y_unique", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "c", "=", "y_unique", "[", "idx", "]", ".", "item", "(", ")", "\n", "if", "c", "not", "in", "self", ".", "p_mem", ":", "# Init new prototype", "\n", "                ", "self", ".", "p_mem", "[", "c", "]", "=", "normalize", "(", "\n", "torch", ".", "empty", "(", "(", "1", ",", "self", ".", "p_size", ")", ")", ".", "uniform_", "(", "-", "1", ",", "1", ")", ",", "p", "=", "2", ",", "\n", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "to", "(", "targets", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._update_running_prototypes": [[150, 163], ["torch.no_grad", "torch.unique().squeeze().view", "range", "torch.unique().squeeze().view.size", "y_unique[].item", "torch.nonzero().squeeze", "strategy.mb_output[].sum().unsqueeze().to", "torch.unique().squeeze", "torch.nonzero", "strategy.mb_output[].sum().unsqueeze", "len", "torch.unique", "strategy.mb_output[].sum"], "methods", ["None"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_running_prototypes", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\" Accumulate seen outputs of the network and keep counts. \"\"\"", "\n", "y_unique", "=", "torch", ".", "unique", "(", "strategy", ".", "mb_y", ")", ".", "squeeze", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "for", "idx", "in", "range", "(", "y_unique", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "c", "=", "y_unique", "[", "idx", "]", ".", "item", "(", ")", "\n", "idxs", "=", "torch", ".", "nonzero", "(", "strategy", ".", "mb_y", "==", "c", ")", ".", "squeeze", "(", "1", ")", "\n", "p_tmp_batch", "=", "strategy", ".", "mb_output", "[", "idxs", "]", ".", "sum", "(", "dim", "=", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "\n", "strategy", ".", "device", ")", "\n", "\n", "p_init", ",", "cnt_init", "=", "self", ".", "tmp_p_mem", "[", "c", "]", "if", "c", "in", "self", ".", "tmp_p_mem", "else", "(", "0", ",", "0", ")", "\n", "self", ".", "tmp_p_mem", "[", "c", "]", "=", "(", "p_init", "+", "p_tmp_batch", ",", "cnt_init", "+", "len", "(", "idxs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin.after_training_exp": [[164, 170], ["cope.CoPEPlugin._update_prototypes", "cope.CoPEPlugin.storage_policy.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._update_prototypes", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" After the current experience (batch), update prototypes and\n        store observed samples for replay.\n        \"\"\"", "\n", "self", ".", "_update_prototypes", "(", ")", "# Update prototypes", "\n", "self", ".", "storage_policy", ".", "update", "(", "strategy", ")", "# Update memory", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._update_prototypes": [[171, 181], ["torch.no_grad", "cope.CoPEPlugin.tmp_p_mem.items", "torch.nn.functional.normalize", "cope.CoPEPlugin.p_mem[].clone", "torch.nn.functional.normalize().detach", "torch.nn.functional.normalize"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_prototypes", "(", "self", ")", ":", "\n", "        ", "\"\"\" Update the prototypes based on the running averages. \"\"\"", "\n", "for", "c", ",", "(", "p_sum", ",", "p_cnt", ")", "in", "self", ".", "tmp_p_mem", ".", "items", "(", ")", ":", "\n", "            ", "incr_p", "=", "normalize", "(", "p_sum", "/", "p_cnt", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "# L2 normalized", "\n", "old_p", "=", "self", ".", "p_mem", "[", "c", "]", ".", "clone", "(", ")", "\n", "new_p_momentum", "=", "self", ".", "alpha", "*", "old_p", "+", "(", "\n", "1", "-", "self", ".", "alpha", ")", "*", "incr_p", "# Momentum update", "\n", "self", ".", "p_mem", "[", "c", "]", "=", "normalize", "(", "new_p_momentum", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", "\n", "", "self", ".", "tmp_p_mem", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin.after_eval_iteration": [[182, 187], ["cope.CoPEPlugin._get_nearest_neigbor_distr"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._get_nearest_neigbor_distr"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Convert output scores to probabilities for other metrics like\n        accuracy and forgetting. We only do it at this point because before\n        this,we still need the embedding outputs to obtain the PPP-loss.\"\"\"", "\n", "strategy", ".", "mb_output", "=", "self", ".", "_get_nearest_neigbor_distr", "(", "strategy", ".", "mb_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.CoPEPlugin._get_nearest_neigbor_distr": [[188, 219], ["x.size", "len", "cope.CoPEPlugin.p_mem.items", "torch.LongTensor", "range", "torch.zeros().to", "range", "cope.CoPEPlugin.p_mem.keys", "torch.Tensor().fill_().to", "torch.ones().to", "float", "dist.min", "ii.squeeze.squeeze.squeeze", "ii.squeeze.squeeze.item", "x.view", "torch.mm", "torch.zeros", "torch.Tensor().fill_", "torch.ones", "x[].unsqueeze", "torch.Tensor"], "methods", ["None"], ["", "def", "_get_nearest_neigbor_distr", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "\"\"\"\n        Find closest prototype for output samples in batch x.\n        :param x: Batch of network logits.\n        :return: one-hot representation of the predicted class.\n        \"\"\"", "\n", "ns", "=", "x", ".", "size", "(", "0", ")", "\n", "nd", "=", "x", ".", "view", "(", "ns", ",", "-", "1", ")", ".", "shape", "[", "-", "1", "]", "\n", "\n", "# Get prototypes", "\n", "seen_c", "=", "len", "(", "self", ".", "p_mem", ".", "keys", "(", ")", ")", "\n", "if", "seen_c", "==", "0", ":", "# no prototypes yet, output uniform distr. all classes", "\n", "            ", "return", "torch", ".", "Tensor", "(", "ns", ",", "self", ".", "n_classes", "\n", ")", ".", "fill_", "(", "1.0", "/", "self", ".", "n_classes", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "", "means", "=", "torch", ".", "ones", "(", "seen_c", ",", "nd", ")", ".", "to", "(", "x", ".", "device", ")", "*", "float", "(", "'inf'", ")", "\n", "for", "c", ",", "c_proto", "in", "self", ".", "p_mem", ".", "items", "(", ")", ":", "\n", "            ", "means", "[", "c", "]", "=", "c_proto", "# Class idx gets allocated its prototype", "\n", "\n", "# Predict nearest mean", "\n", "", "classpred", "=", "torch", ".", "LongTensor", "(", "ns", ")", "\n", "for", "s_idx", "in", "range", "(", "ns", ")", ":", "# Per sample", "\n", "            ", "dist", "=", "-", "torch", ".", "mm", "(", "means", ",", "x", "[", "s_idx", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "# Dot product", "\n", "_", ",", "ii", "=", "dist", ".", "min", "(", "0", ")", "# Min dist (no proto = inf)", "\n", "ii", "=", "ii", ".", "squeeze", "(", ")", "\n", "classpred", "[", "s_idx", "]", "=", "ii", ".", "item", "(", ")", "# Allocate class idx", "\n", "\n", "# Convert to 1-hot", "\n", "", "out", "=", "torch", ".", "zeros", "(", "ns", ",", "self", ".", "n_classes", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "for", "s_idx", "in", "range", "(", "ns", ")", ":", "\n", "            ", "out", "[", "s_idx", ",", "classpred", "[", "s_idx", "]", "]", "=", "1", "\n", "", "return", "out", "# return 1-of-C code, ns x nc", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.L2Normalization.__init__": [[225, 227], ["torch.nn.modules.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.L2Normalization.forward": [[228, 230], ["torch.nn.functional.normalize"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.PPPloss.__init__": [[238, 247], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "p_mem", ":", "Dict", ",", "T", "=", "0.1", ")", ":", "\n", "        ", "\"\"\"\n        :param p_mem: dictionary with keys the prototype identifier and\n                      values the prototype tensors.\n        :param T: temperature of the softmax, serving as concentration\n                  density parameter.\n        \"\"\"", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "p_mem", "=", "p_mem", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.PPPloss.__call__": [[248, 284], ["x.view.view.size", "x.view.view.view", "torch.unique().squeeze().view", "torch.tensor().to().detach", "torch.cat().to().detach", "range", "len", "torch.unique().squeeze().view.size", "x.view.view.index_select", "x.view.view.index_select", "torch.nonzero().squeeze", "torch.cat().clone().detach", "cope.PPPloss.attractor", "torch.unique().squeeze", "torch.unique().squeeze().view.size", "torch.tensor().to", "torch.cat().to", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "cope.PPPloss.repellor", "torch.nonzero", "torch.cat().clone", "torch.unique", "torch.tensor", "torch.cat", "torch.nonzero", "torch.nonzero", "torch.cat", "cope.PPPloss.p_mem.keys", "c.item"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.PPPloss.attractor", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.PPPloss.repellor"], ["", "def", "__call__", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        The loss is calculated with one-vs-rest batches Bc and Bk,\n        split into the attractor and repellor loss terms.\n        We iterate over the possible batches while accumulating the losses per\n        class c vs other-classes k.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "bs", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "view", "(", "bs", ",", "-", "1", ")", "# Batch x feature size", "\n", "y_unique", "=", "torch", ".", "unique", "(", "y", ")", ".", "squeeze", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "include_repellor", "=", "len", "(", "y_unique", ".", "size", "(", ")", ")", "<=", "1", "# When at least 2 classes", "\n", "\n", "# All prototypes", "\n", "p_y", "=", "torch", ".", "tensor", "(", "\n", "[", "c", "for", "c", "in", "self", ".", "p_mem", ".", "keys", "(", ")", "]", ")", ".", "to", "(", "x", ".", "device", ")", ".", "detach", "(", ")", "\n", "p_x", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "p_mem", "[", "c", ".", "item", "(", ")", "]", "for", "c", "in", "p_y", "]", ")", ".", "to", "(", "x", ".", "device", ")", ".", "detach", "(", ")", "\n", "\n", "for", "label_idx", "in", "range", "(", "y_unique", ".", "size", "(", "0", ")", ")", ":", "# Per-class operation", "\n", "            ", "c", "=", "y_unique", "[", "label_idx", "]", "\n", "\n", "# Make all-vs-rest batches per class (Bc=attractor, Bk=repellor set)", "\n", "Bc", "=", "x", ".", "index_select", "(", "0", ",", "torch", ".", "nonzero", "(", "y", "==", "c", ")", ".", "squeeze", "(", "dim", "=", "1", ")", ")", "\n", "Bk", "=", "x", ".", "index_select", "(", "0", ",", "torch", ".", "nonzero", "(", "y", "!=", "c", ")", ".", "squeeze", "(", "dim", "=", "1", ")", ")", "\n", "\n", "p_idx", "=", "torch", ".", "nonzero", "(", "p_y", "==", "c", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "# Prototypes", "\n", "pc", "=", "p_x", "[", "p_idx", "]", "# Class proto", "\n", "pk", "=", "torch", ".", "cat", "(", "[", "p_x", "[", ":", "p_idx", "]", ",", "p_x", "[", "p_idx", "+", "1", ":", "]", "]", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "# Accumulate loss for instances of class c", "\n", "sum_logLc", "=", "self", ".", "attractor", "(", "pc", ",", "pk", ",", "Bc", ")", "\n", "sum_logLk", "=", "self", ".", "repellor", "(", "pc", ",", "pk", ",", "Bc", ",", "Bk", ")", "if", "include_repellor", "else", "0", "\n", "Loss_c", "=", "-", "sum_logLc", "-", "sum_logLk", "# attractor + repellor for class c", "\n", "loss", "=", "Loss_c", "if", "loss", "is", "None", "else", "loss", "+", "Loss_c", "# Update loss", "\n", "", "return", "loss", "/", "bs", "# Make independent batch size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.PPPloss.attractor": [[285, 305], ["torch.cat().detach", "torch.mm().div_().exp_", "torch.eye().bool().to", "torch.mm().div_().exp_.masked_fill", "E_Pc.log_().sum", "Dm[].sum", "Pci.sum", "torch.cat", "torch.mm().div_", "torch.eye().bool", "E_Pc.log_", "Bc.clone", "torch.mm", "torch.eye", "Bc.t"], "methods", ["None"], ["", "def", "attractor", "(", "self", ",", "pc", ",", "pk", ",", "Bc", ")", ":", "\n", "        ", "\"\"\"\n        Get the attractor loss terms for all instances in xc.\n        :param pc: Prototype of the same class c.\n        :param pk: Prototoypes of the other classes.\n        :param Bc: Batch of instances of the same class c.\n        :return: Sum_{i, the part of same class c} log P(c|x_i^c)\n        \"\"\"", "\n", "m", "=", "torch", ".", "cat", "(", "[", "Bc", ".", "clone", "(", ")", ",", "pc", ",", "pk", "]", ")", ".", "detach", "(", ")", "# Incl other-class proto", "\n", "pk_idx", "=", "m", ".", "shape", "[", "0", "]", "-", "pk", ".", "shape", "[", "0", "]", "# from when starts p_k", "\n", "\n", "# Resulting distance columns are per-instance loss terms", "\n", "D", "=", "torch", ".", "mm", "(", "m", ",", "Bc", ".", "t", "(", ")", ")", ".", "div_", "(", "self", ".", "T", ")", ".", "exp_", "(", ")", "# Distance matrix exp terms", "\n", "mask", "=", "torch", ".", "eye", "(", "*", "D", ".", "shape", ")", ".", "bool", "(", ")", ".", "to", "(", "Bc", ".", "device", ")", "# Exclude self-product", "\n", "Dm", "=", "D", ".", "masked_fill", "(", "mask", ",", "0", ")", "# Masked out products with self", "\n", "\n", "Lc_n", ",", "Lk_d", "=", "Dm", "[", ":", "pk_idx", "]", ",", "Dm", "[", "pk_idx", ":", "]", ".", "sum", "(", "dim", "=", "0", ")", "# Num/denominator", "\n", "Pci", "=", "Lc_n", "/", "(", "Lc_n", "+", "Lk_d", ")", "# Get probabilities per instance", "\n", "E_Pc", "=", "Pci", ".", "sum", "(", "0", ")", "/", "Bc", ".", "shape", "[", "0", "]", "# Expectation over pseudo-prototypes", "\n", "return", "E_Pc", ".", "log_", "(", ")", ".", "sum", "(", ")", "# sum over all instances (sum i)", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.cope.PPPloss.repellor": [[306, 329], ["torch.cat().detach", "torch.mm().div_().exp_", "D[].sum().unsqueeze", "E_Pk.mul_().add_().log_", "E_Pk.mul_().add_().log_.sum", "torch.cat", "torch.mm().div_", "D[].sum", "Pki[].unsqueeze", "E_Pk.mul_().add_", "Bc.clone", "torch.mm", "E_Pk.mul_", "Bk.t"], "methods", ["None"], ["", "def", "repellor", "(", "self", ",", "pc", ",", "pk", ",", "Bc", ",", "Bk", ")", ":", "\n", "        ", "\"\"\"\n        Get the repellor loss terms for all pseudo-prototype instances in Bc.\n        :param pc: Actual prototype of the same class c.\n        :param pk: Prototoypes of the other classes (k).\n        :param Bc: Batch of instances of the same class c. Acting as\n        pseudo-prototypes.\n        :param Bk: Batch of instances of other-than-c classes (k).\n        :return: Sum_{i, part of same class c} Sum_{x_j^k} log 1 - P(c|x_j^k)\n        \"\"\"", "\n", "union_ck", "=", "torch", ".", "cat", "(", "[", "Bc", ".", "clone", "(", ")", ",", "pc", ",", "pk", "]", ")", ".", "detach", "(", ")", "\n", "pk_idx", "=", "union_ck", ".", "shape", "[", "0", "]", "-", "pk", ".", "shape", "[", "0", "]", "\n", "\n", "# Distance other-class-k to prototypes (pc/pk) and pseudo-prototype (xc)", "\n", "D", "=", "torch", ".", "mm", "(", "union_ck", ",", "Bk", ".", "t", "(", ")", ")", ".", "div_", "(", "self", ".", "T", ")", ".", "exp_", "(", ")", "\n", "\n", "Lk_d", "=", "D", "[", "pk_idx", ":", "]", ".", "sum", "(", "dim", "=", "0", ")", ".", "unsqueeze", "(", "0", ")", "# Numerator/denominator terms", "\n", "Lc_n", "=", "D", "[", ":", "pk_idx", "]", "\n", "Pki", "=", "Lc_n", "/", "(", "Lc_n", "+", "Lk_d", ")", "# probability", "\n", "\n", "E_Pk", "=", "(", "Pki", "[", ":", "-", "1", "]", "+", "Pki", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", ")", "/", "2", "# Exp. pseudo/prototype", "\n", "inv_E_Pk", "=", "E_Pk", ".", "mul_", "(", "-", "1", ")", ".", "add_", "(", "1", ")", ".", "log_", "(", ")", "# log( (1 - Pk))", "\n", "return", "inv_E_Pk", ".", "sum", "(", ")", "# Sum over (pseudo-prototypes), and instances", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.__init__": [[25, 62], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "collections.defaultdict", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "ewc_lambda", ",", "mode", "=", "'separate'", ",", "decay_factor", "=", "None", ",", "\n", "keep_importance_data", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param ewc_lambda: hyperparameter to weigh the penalty inside the total\n               loss. The larger the lambda, the larger the regularization.\n        :param mode: `separate` to keep a separate penalty for each previous\n               experience.\n               `online` to keep a single penalty summed with a decay factor\n               over all previous tasks.\n        :param decay_factor: used only if mode is `online`.\n               It specifies the decay term of the importance matrix.\n        :param keep_importance_data: if True, keep in memory both parameter\n                values and importances for all previous task, for all modes.\n                If False, keep only last parameter values and importances.\n                If mode is `separate`, the value of `keep_importance_data` is\n                set to be True.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "decay_factor", "is", "None", ")", "or", "(", "mode", "==", "'online'", ")", ",", "\"You need to set `online` mode to use `decay_factor`.\"", "\n", "assert", "(", "decay_factor", "is", "not", "None", ")", "or", "(", "mode", "!=", "'online'", ")", ",", "\"You need to set `decay_factor` to use the `online` mode.\"", "\n", "assert", "mode", "==", "'separate'", "or", "mode", "==", "'online'", ",", "'Mode must be separate or online.'", "\n", "\n", "self", ".", "ewc_lambda", "=", "ewc_lambda", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "decay_factor", "=", "decay_factor", "\n", "\n", "if", "self", ".", "mode", "==", "'separate'", ":", "\n", "            ", "self", ".", "keep_importance_data", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "keep_importance_data", "=", "keep_importance_data", "\n", "\n", "", "self", ".", "saved_params", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "importances", "=", "defaultdict", "(", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.before_backward": [[63, 91], ["torch.tensor().float().to", "range", "torch.tensor().float", "zip", "zip", "ValueError", "strategy.model.named_parameters", "strategy.model.named_parameters", "torch.tensor"], "methods", ["None"], ["", "def", "before_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute EWC penalty and add it to the loss.\n        \"\"\"", "\n", "exp_counter", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "if", "exp_counter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "penalty", "=", "torch", ".", "tensor", "(", "0", ")", ".", "float", "(", ")", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'separate'", ":", "\n", "            ", "for", "experience", "in", "range", "(", "exp_counter", ")", ":", "\n", "                ", "for", "(", "_", ",", "cur_param", ")", ",", "(", "_", ",", "saved_param", ")", ",", "(", "_", ",", "imp", ")", "in", "zip", "(", "\n", "strategy", ".", "model", ".", "named_parameters", "(", ")", ",", "\n", "self", ".", "saved_params", "[", "experience", "]", ",", "\n", "self", ".", "importances", "[", "experience", "]", ")", ":", "\n", "                    ", "penalty", "+=", "(", "imp", "*", "(", "cur_param", "-", "saved_param", ")", ".", "pow", "(", "2", ")", ")", ".", "sum", "(", ")", "\n", "", "", "", "elif", "self", ".", "mode", "==", "'online'", ":", "\n", "            ", "prev_exp", "=", "exp_counter", "-", "1", "\n", "for", "(", "_", ",", "cur_param", ")", ",", "(", "_", ",", "saved_param", ")", ",", "(", "_", ",", "imp", ")", "in", "zip", "(", "\n", "strategy", ".", "model", ".", "named_parameters", "(", ")", ",", "\n", "self", ".", "saved_params", "[", "prev_exp", "]", ",", "\n", "self", ".", "importances", "[", "prev_exp", "]", ")", ":", "\n", "                ", "penalty", "+=", "(", "imp", "*", "(", "cur_param", "-", "saved_param", ")", ".", "pow", "(", "2", ")", ")", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Wrong EWC mode.'", ")", "\n", "\n", "", "strategy", ".", "loss", "+=", "self", ".", "ewc_lambda", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.after_training_exp": [[92, 110], ["ewc.EWCPlugin.compute_importances", "ewc.EWCPlugin.update_importances", "avalanche.training.utils.copy_params_dict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.compute_importances", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.update_importances", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.copy_params_dict"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute importances of parameters after each experience.\n        \"\"\"", "\n", "exp_counter", "=", "strategy", ".", "clock", ".", "train_exp_counter", "\n", "importances", "=", "self", ".", "compute_importances", "(", "strategy", ".", "model", ",", "\n", "strategy", ".", "_criterion", ",", "\n", "strategy", ".", "optimizer", ",", "\n", "strategy", ".", "experience", ".", "dataset", ",", "\n", "strategy", ".", "device", ",", "\n", "strategy", ".", "train_mb_size", ")", "\n", "self", ".", "update_importances", "(", "importances", ",", "exp_counter", ")", "\n", "self", ".", "saved_params", "[", "exp_counter", "]", "=", "copy_params_dict", "(", "strategy", ".", "model", ")", "\n", "# clear previous parameter values", "\n", "if", "exp_counter", ">", "0", "and", "(", "not", "self", ".", "keep_importance_data", ")", ":", "\n", "            ", "del", "self", ".", "saved_params", "[", "exp_counter", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.compute_importances": [[111, 156], ["model.eval", "avalanche.training.utils.zerolike_params_dict", "torch.utils.data.DataLoader", "enumerate", "model.modules", "optimizer.zero_grad", "avalanche.models.utils.avalanche_forward", "criterion", "criterion.backward", "zip", "float", "isinstance", "x.to", "y.to", "model.named_parameters", "len", "warnings.warn", "module.train", "p.grad.data.clone().pow", "p.grad.data.clone"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.training.utils.zerolike_params_dict", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.criterion", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train"], ["", "", "def", "compute_importances", "(", "self", ",", "model", ",", "criterion", ",", "optimizer", ",", "\n", "dataset", ",", "device", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Compute EWC importance matrix for each parameter\n        \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Set RNN-like modules on GPU to training mode to avoid CUDA error", "\n", "if", "device", "==", "'cuda'", ":", "\n", "            ", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "RNNBase", ")", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "'RNN-like modules do not support '", "\n", "'backward calls while in `eval` mode on CUDA '", "\n", "'devices. Setting all `RNNBase` modules to '", "\n", "'`train` mode. May produce inconsistent '", "\n", "'output if such modules have `dropout` > 0.'", "\n", ")", "\n", "module", ".", "train", "(", ")", "\n", "\n", "# list of list", "\n", "", "", "", "importances", "=", "zerolike_params_dict", "(", "model", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# get only input, target and task_id from the batch", "\n", "            ", "x", ",", "y", ",", "task_labels", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", "]", ",", "batch", "[", "-", "1", "]", "\n", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "out", "=", "avalanche_forward", "(", "model", ",", "x", ",", "task_labels", ")", "\n", "loss", "=", "criterion", "(", "out", ",", "y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "(", "k1", ",", "p", ")", ",", "(", "k2", ",", "imp", ")", "in", "zip", "(", "model", ".", "named_parameters", "(", ")", ",", "\n", "importances", ")", ":", "\n", "                ", "assert", "(", "k1", "==", "k2", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "imp", "+=", "p", ".", "grad", ".", "data", ".", "clone", "(", ")", ".", "pow", "(", "2", ")", "\n", "\n", "# average over mini batch length", "\n", "", "", "", "for", "_", ",", "imp", "in", "importances", ":", "\n", "            ", "imp", "/=", "float", "(", "len", "(", "dataloader", ")", ")", "\n", "\n", "", "return", "importances", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.ewc.EWCPlugin.update_importances": [[157, 179], ["torch.no_grad", "zip", "ValueError", "ewc.EWCPlugin.importances[].append"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_importances", "(", "self", ",", "importances", ",", "t", ")", ":", "\n", "        ", "\"\"\"\n        Update importance for each parameter based on the currently computed\n        importances.\n        \"\"\"", "\n", "\n", "if", "self", ".", "mode", "==", "'separate'", "or", "t", "==", "0", ":", "\n", "            ", "self", ".", "importances", "[", "t", "]", "=", "importances", "\n", "", "elif", "self", ".", "mode", "==", "'online'", ":", "\n", "            ", "for", "(", "k1", ",", "old_imp", ")", ",", "(", "k2", ",", "curr_imp", ")", "in", "zip", "(", "self", ".", "importances", "[", "t", "-", "1", "]", ",", "importances", ")", ":", "\n", "                ", "assert", "k1", "==", "k2", ",", "'Error in importance computation.'", "\n", "self", ".", "importances", "[", "t", "]", ".", "append", "(", "\n", "(", "k1", ",", "(", "self", ".", "decay_factor", "*", "old_imp", "+", "curr_imp", ")", ")", ")", "\n", "\n", "# clear previous parameter importances", "\n", "", "if", "t", ">", "0", "and", "(", "not", "self", ".", "keep_importance_data", ")", ":", "\n", "                ", "del", "self", ".", "importances", "[", "t", "-", "1", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Wrong EWC mode.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.__init__": [[20, 36], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "int"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "patterns_per_experience", ":", "int", ",", "memory_strength", ":", "float", ")", ":", "\n", "        ", "\"\"\"\n        :param patterns_per_experience: number of patterns per experience in the\n            memory.\n        :param memory_strength: offset to add to the projection direction\n            in order to favour backward transfer (gamma in original paper).\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "patterns_per_experience", "=", "int", "(", "patterns_per_experience", ")", "\n", "self", ".", "memory_strength", "=", "memory_strength", "\n", "\n", "self", ".", "memory_x", ",", "self", ".", "memory_y", ",", "self", ".", "memory_tid", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "\n", "self", ".", "G", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.before_training_iteration": [[37, 63], ["strategy.model.train", "range", "torch.stack", "strategy.model.train", "strategy.optimizer.zero_grad", "gem.GEMPlugin.memory_x[].to", "gem.GEMPlugin.memory_y[].to", "avalanche.models.avalanche_forward", "strategy._criterion", "strategy._criterion.backward", "G.append", "torch.cat", "p.grad.flatten", "torch.zeros", "strategy.model.parameters", "p.numel"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute gradient constraints on previous memory samples from all\n        experiences.\n        \"\"\"", "\n", "\n", "if", "strategy", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "            ", "G", "=", "[", "]", "\n", "strategy", ".", "model", ".", "train", "(", ")", "\n", "for", "t", "in", "range", "(", "strategy", ".", "clock", ".", "train_exp_counter", ")", ":", "\n", "                ", "strategy", ".", "model", ".", "train", "(", ")", "\n", "strategy", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "xref", "=", "self", ".", "memory_x", "[", "t", "]", ".", "to", "(", "strategy", ".", "device", ")", "\n", "yref", "=", "self", ".", "memory_y", "[", "t", "]", ".", "to", "(", "strategy", ".", "device", ")", "\n", "out", "=", "avalanche_forward", "(", "strategy", ".", "model", ",", "xref", ",", "\n", "self", ".", "memory_tid", "[", "t", "]", ")", "\n", "loss", "=", "strategy", ".", "_criterion", "(", "out", ",", "yref", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "G", ".", "append", "(", "torch", ".", "cat", "(", "[", "p", ".", "grad", ".", "flatten", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "torch", ".", "zeros", "(", "p", ".", "numel", "(", ")", ",", "\n", "device", "=", "strategy", ".", "device", ")", "\n", "for", "p", "in", "strategy", ".", "model", ".", "parameters", "(", ")", "]", ",", "\n", "dim", "=", "0", ")", ")", "\n", "\n", "", "self", ".", "G", "=", "torch", ".", "stack", "(", "G", ")", "# (experiences, parameters)", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.after_backward": [[64, 91], ["torch.no_grad", "torch.cat", "gem.GEMPlugin.solve_quadprog().to", "strategy.model.parameters", "p.numel", "gem.GEMPlugin.numel", "gem.GEMPlugin.solve_quadprog", "p.grad.copy_", "p.grad.flatten", "torch.zeros", "strategy.model.parameters", "torch.mv", "v_star[].view", "p.numel", "p.size"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.solve_quadprog"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "after_backward", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Project gradient based on reference gradients\n        \"\"\"", "\n", "\n", "if", "strategy", ".", "clock", ".", "train_exp_counter", ">", "0", ":", "\n", "            ", "g", "=", "torch", ".", "cat", "(", "[", "p", ".", "grad", ".", "flatten", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "else", "torch", ".", "zeros", "(", "p", ".", "numel", "(", ")", ",", "device", "=", "strategy", ".", "device", ")", "\n", "for", "p", "in", "strategy", ".", "model", ".", "parameters", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "to_project", "=", "(", "torch", ".", "mv", "(", "self", ".", "G", ",", "g", ")", "<", "0", ")", ".", "any", "(", ")", "\n", "", "else", ":", "\n", "            ", "to_project", "=", "False", "\n", "\n", "", "if", "to_project", ":", "\n", "            ", "v_star", "=", "self", ".", "solve_quadprog", "(", "g", ")", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "num_pars", "=", "0", "# reshape v_star into the parameter matrices", "\n", "for", "p", "in", "strategy", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "curr_pars", "=", "p", ".", "numel", "(", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p", ".", "grad", ".", "copy_", "(", "\n", "v_star", "[", "num_pars", ":", "num_pars", "+", "curr_pars", "]", ".", "view", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "", "num_pars", "+=", "curr_pars", "\n", "\n", "", "assert", "num_pars", "==", "v_star", ".", "numel", "(", ")", ",", "\"Error in projecting gradient\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.after_training_exp": [[92, 100], ["gem.GEMPlugin.update_memory"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.update_memory"], ["", "", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Save a copy of the model after each experience\n        \"\"\"", "\n", "\n", "self", ".", "update_memory", "(", "strategy", ".", "experience", ".", "dataset", ",", "\n", "strategy", ".", "clock", ".", "train_exp_counter", ",", "\n", "strategy", ".", "train_mb_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.update_memory": [[101, 136], ["torch.no_grad", "torch.utils.data.DataLoader", "x.size", "x.size", "x.clone", "y.clone", "tid.clone", "torch.cat", "torch.cat", "torch.cat", "x[].clone", "y[].clone", "tid[].clone", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_memory", "(", "self", ",", "dataset", ",", "t", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Update replay memory with patterns from current experience.\n        \"\"\"", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ")", "\n", "tot", "=", "0", "\n", "for", "mbatch", "in", "dataloader", ":", "\n", "            ", "x", ",", "y", ",", "tid", "=", "mbatch", "[", "0", "]", ",", "mbatch", "[", "1", "]", ",", "mbatch", "[", "-", "1", "]", "\n", "if", "tot", "+", "x", ".", "size", "(", "0", ")", "<=", "self", ".", "patterns_per_experience", ":", "\n", "                ", "if", "t", "not", "in", "self", ".", "memory_x", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "x", ".", "clone", "(", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "y", ".", "clone", "(", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "tid", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_x", "[", "t", "]", ",", "x", ")", ",", "dim", "=", "0", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_y", "[", "t", "]", ",", "y", ")", ",", "dim", "=", "0", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_tid", "[", "t", "]", ",", "tid", ")", ",", "\n", "dim", "=", "0", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "diff", "=", "self", ".", "patterns_per_experience", "-", "tot", "\n", "if", "t", "not", "in", "self", ".", "memory_x", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "x", "[", ":", "diff", "]", ".", "clone", "(", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "y", "[", ":", "diff", "]", ".", "clone", "(", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "tid", "[", ":", "diff", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "memory_x", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_x", "[", "t", "]", ",", "x", "[", ":", "diff", "]", ")", ",", "\n", "dim", "=", "0", ")", "\n", "self", ".", "memory_y", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_y", "[", "t", "]", ",", "y", "[", ":", "diff", "]", ")", ",", "\n", "dim", "=", "0", ")", "\n", "self", ".", "memory_tid", "[", "t", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "memory_tid", "[", "t", "]", ",", "\n", "tid", "[", ":", "diff", "]", ")", ",", "dim", "=", "0", ")", "\n", "", "break", "\n", "", "tot", "+=", "x", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gem.GEMPlugin.solve_quadprog": [[137, 157], ["gem.GEMPlugin.G.cpu().double().numpy", "g.cpu().contiguous().view().double().numpy", "numpy.dot", "numpy.eye", "torch.from_numpy().float", "gem.GEMPlugin.transpose", "numpy.dot", "numpy.zeros", "quadprog.solve_qp", "numpy.dot", "gem.GEMPlugin.G.cpu().double", "g.cpu().contiguous().view().double", "numpy.eye", "torch.from_numpy", "numpy.dot.transpose", "gem.GEMPlugin.G.cpu", "g.cpu().contiguous().view", "g.cpu().contiguous", "g.cpu"], "methods", ["None"], ["", "", "def", "solve_quadprog", "(", "self", ",", "g", ")", ":", "\n", "        ", "\"\"\"\n        Solve quadratic programming with current gradient g and\n        gradients matrix on previous tasks G.\n        Taken from original code:\n        https://github.com/facebookresearch/GradientEpisodicMemory/blob/master/model/gem.py\n        \"\"\"", "\n", "\n", "memories_np", "=", "self", ".", "G", ".", "cpu", "(", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "gradient_np", "=", "g", ".", "cpu", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "t", "=", "memories_np", ".", "shape", "[", "0", "]", "\n", "P", "=", "np", ".", "dot", "(", "memories_np", ",", "memories_np", ".", "transpose", "(", ")", ")", "\n", "P", "=", "0.5", "*", "(", "P", "+", "P", ".", "transpose", "(", ")", ")", "+", "np", ".", "eye", "(", "t", ")", "*", "1e-3", "\n", "q", "=", "np", ".", "dot", "(", "memories_np", ",", "gradient_np", ")", "*", "-", "1", "\n", "G", "=", "np", ".", "eye", "(", "t", ")", "\n", "h", "=", "np", ".", "zeros", "(", "t", ")", "+", "self", ".", "memory_strength", "\n", "v", "=", "quadprog", ".", "solve_qp", "(", "P", ",", "q", ",", "G", ",", "h", ")", "[", "0", "]", "\n", "v_star", "=", "np", ".", "dot", "(", "v", ",", "memories_np", ")", "+", "gradient_np", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "v_star", ")", ".", "float", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.__init__": [[16, 19], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_training": [[20, 22], ["None"], "methods", ["None"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_training_exp": [[23, 25], ["None"], "methods", ["None"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_train_dataset_adaptation": [[26, 29], ["None"], "methods", ["None"], ["", "def", "before_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_train_dataset_adaptation": [[30, 33], ["None"], "methods", ["None"], ["", "def", "after_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_training_epoch": [[34, 36], ["None"], "methods", ["None"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_training_iteration": [[37, 39], ["None"], "methods", ["None"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_forward": [[40, 42], ["None"], "methods", ["None"], ["", "def", "before_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_forward": [[43, 45], ["None"], "methods", ["None"], ["", "def", "after_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_backward": [[46, 48], ["None"], "methods", ["None"], ["", "def", "before_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_backward": [[49, 51], ["None"], "methods", ["None"], ["", "def", "after_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_training_iteration": [[52, 54], ["None"], "methods", ["None"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_update": [[55, 57], ["None"], "methods", ["None"], ["", "def", "before_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_update": [[58, 60], ["None"], "methods", ["None"], ["", "def", "after_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_training_epoch": [[61, 63], ["None"], "methods", ["None"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_training_exp": [[64, 66], ["None"], "methods", ["None"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_training": [[67, 69], ["None"], "methods", ["None"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_eval": [[70, 72], ["None"], "methods", ["None"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_eval_dataset_adaptation": [[73, 76], ["None"], "methods", ["None"], ["", "def", "before_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_eval_dataset_adaptation": [[77, 79], ["None"], "methods", ["None"], ["", "def", "after_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_eval_exp": [[80, 82], ["None"], "methods", ["None"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_eval_exp": [[83, 85], ["None"], "methods", ["None"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_eval": [[86, 88], ["None"], "methods", ["None"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_eval_iteration": [[89, 91], ["None"], "methods", ["None"], ["", "def", "before_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.before_eval_forward": [[92, 94], ["None"], "methods", ["None"], ["", "def", "before_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_eval_forward": [[95, 97], ["None"], "methods", ["None"], ["", "def", "after_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.strategy_plugin.StrategyPlugin.after_eval_iteration": [[98, 100], ["None"], "methods", ["None"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.__init__": [[23, 41], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "torch.FloatTensor().fill_", "torch.LongTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor", "torch.LongTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "mem_size", "=", "200", ",", "mem_strength", "=", "5", ",", "input_size", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n\n        :param mem_size: total number of patterns to be stored\n            in the external memory.\n        :param mem_strength:\n        :param input_size:\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mem_size", "=", "mem_size", "\n", "self", ".", "mem_strength", "=", "mem_strength", "\n", "self", ".", "device", "=", "'cpu'", "\n", "\n", "self", ".", "ext_mem_list_x", "=", "torch", ".", "FloatTensor", "(", "mem_size", ",", "*", "input_size", ")", ".", "fill_", "(", "0", ")", "\n", "self", ".", "ext_mem_list_y", "=", "torch", ".", "LongTensor", "(", "mem_size", ")", ".", "fill_", "(", "0", ")", "\n", "self", ".", "ext_mem_list_current_index", "=", "0", "\n", "\n", "self", ".", "buffer_score", "=", "torch", ".", "FloatTensor", "(", "self", ".", "mem_size", ")", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.before_training": [[42, 47], ["gss_greedy.GSS_greedyPlugin.ext_mem_list_x.to", "gss_greedy.GSS_greedyPlugin.ext_mem_list_y.to", "gss_greedy.GSS_greedyPlugin.buffer_score.to"], "methods", ["None"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "device", "=", "strategy", ".", "device", "\n", "self", ".", "ext_mem_list_x", "=", "self", ".", "ext_mem_list_x", ".", "to", "(", "strategy", ".", "device", ")", "\n", "self", ".", "ext_mem_list_y", "=", "self", ".", "ext_mem_list_y", ".", "to", "(", "strategy", ".", "device", ")", "\n", "self", ".", "buffer_score", "=", "self", ".", "buffer_score", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.cosine_similarity": [[48, 55], ["x1.norm", "x2.norm", "torch.mm", "x2.t", "w2.t"], "methods", ["None"], ["", "def", "cosine_similarity", "(", "self", ",", "x1", ",", "x2", "=", "None", ",", "eps", "=", "1e-8", ")", ":", "\n", "        ", "x2", "=", "x1", "if", "x2", "is", "None", "else", "x2", "\n", "w1", "=", "x1", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "w2", "=", "w1", "if", "x2", "is", "x1", "else", "x2", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "sim", "=", "torch", ".", "mm", "(", "x1", ",", "x2", ".", "t", "(", ")", ")", "/", "(", "w1", "*", "w2", ".", "t", "(", ")", ")", ".", "clamp", "(", "min", "=", "eps", ")", "\n", "return", "sim", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_grad_vector": [[56, 70], ["torch.zeros", "torch.zeros.fill_", "pp", "sum", "sum", "grads[].copy_", "sum", "param.grad.data.view"], "methods", ["None"], ["", "def", "get_grad_vector", "(", "self", ",", "pp", ",", "grad_dims", ")", ":", "\n", "        ", "\"\"\"\n        gather the gradients in one vector\n        \"\"\"", "\n", "grads", "=", "torch", ".", "zeros", "(", "sum", "(", "grad_dims", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "grads", ".", "fill_", "(", "0.0", ")", "\n", "cnt", "=", "0", "\n", "for", "param", "in", "pp", "(", ")", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "beg", "=", "0", "if", "cnt", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "cnt", "]", ")", "\n", "en", "=", "sum", "(", "grad_dims", "[", ":", "cnt", "+", "1", "]", ")", "\n", "grads", "[", "beg", ":", "en", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "cnt", "+=", "1", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_batch_sim": [[71, 88], ["gss_greedy.GSS_greedyPlugin.get_rand_mem_grads", "strategy.model.zero_grad", "strategy._criterion", "strategy._criterion.backward", "gss_greedy.GSS_greedyPlugin.get_grad_vector().unsqueeze", "max", "len", "strategy.model.forward", "gss_greedy.GSS_greedyPlugin.cosine_similarity", "gss_greedy.GSS_greedyPlugin.get_grad_vector"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_rand_mem_grads", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.cosine_similarity", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_grad_vector"], ["", "def", "get_batch_sim", "(", "self", ",", "strategy", ",", "grad_dims", ",", "batch_x", ",", "batch_y", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            buffer: memory buffer\n            grad_dims: gradient dimensions\n            batch_x: current batch x\n            batch_y: current batch y\n        Returns: score of current batch, gradient from memory subsets\n        \"\"\"", "\n", "mem_grads", "=", "self", ".", "get_rand_mem_grads", "(", "strategy", ",", "grad_dims", ",", "len", "(", "batch_x", ")", ")", "\n", "strategy", ".", "model", ".", "zero_grad", "(", ")", "\n", "loss", "=", "strategy", ".", "_criterion", "(", "strategy", ".", "model", ".", "forward", "(", "batch_x", ")", ",", "batch_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "batch_grad", "=", "self", ".", "get_grad_vector", "(", "\n", "strategy", ".", "model", ".", "parameters", ",", "grad_dims", ")", ".", "unsqueeze", "(", "0", ")", "\n", "batch_sim", "=", "max", "(", "self", ".", "cosine_similarity", "(", "mem_grads", ",", "batch_grad", ")", ")", "\n", "return", "batch_sim", ",", "mem_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_rand_mem_grads": [[89, 118], ["min", "min", "torch.zeros", "torch.randperm", "range", "sum", "gss_greedy.GSS_greedyPlugin.ext_mem_list_x[].to", "gss_greedy.GSS_greedyPlugin.ext_mem_list_y[].to", "strategy.model.zero_grad", "strategy._criterion", "strategy._criterion.backward", "mem_grads[].data.copy_", "strategy.model.forward", "gss_greedy.GSS_greedyPlugin.get_grad_vector"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_grad_vector"], ["", "def", "get_rand_mem_grads", "(", "self", ",", "strategy", ",", "grad_dims", ",", "gss_batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            buffer: memory buffer\n            grad_dims: gradient dimensions\n        Returns: gradient from memory subsets\n        \"\"\"", "\n", "temp_gss_batch_size", "=", "min", "(", "\n", "gss_batch_size", ",", "self", ".", "ext_mem_list_current_index", ")", "\n", "num_mem_subs", "=", "min", "(", "self", ".", "mem_strength", ",", "\n", "self", ".", "ext_mem_list_current_index", "//", "gss_batch_size", ")", "\n", "mem_grads", "=", "torch", ".", "zeros", "(", "num_mem_subs", ",", "sum", "(", "\n", "grad_dims", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "shuffeled_inds", "=", "torch", ".", "randperm", "(", "self", ".", "ext_mem_list_current_index", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "num_mem_subs", ")", ":", "\n", "            ", "random_batch_inds", "=", "shuffeled_inds", "[", "i", "*", "\n", "temp_gss_batch_size", ":", "i", "*", "\n", "temp_gss_batch_size", "+", "\n", "temp_gss_batch_size", "]", "\n", "batch_x", "=", "self", ".", "ext_mem_list_x", "[", "random_batch_inds", "]", ".", "to", "(", "strategy", ".", "device", ")", "\n", "batch_y", "=", "self", ".", "ext_mem_list_y", "[", "random_batch_inds", "]", ".", "to", "(", "strategy", ".", "device", ")", "\n", "strategy", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "loss", "=", "strategy", ".", "_criterion", "(", "strategy", ".", "model", ".", "forward", "(", "batch_x", ")", ",", "batch_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "mem_grads", "[", "i", "]", ".", "data", ".", "copy_", "(", "self", ".", "get_grad_vector", "(", "\n", "strategy", ".", "model", ".", "parameters", ",", "grad_dims", ")", ")", "\n", "", "return", "mem_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_each_batch_sample_sim": [[119, 147], ["torch.zeros", "enumerate", "batch_x.size", "zip", "strategy.model.zero_grad", "strategy._criterion", "strategy._criterion.backward", "gss_greedy.GSS_greedyPlugin.get_grad_vector().unsqueeze", "max", "strategy.model.forward", "y.unsqueeze", "gss_greedy.GSS_greedyPlugin.cosine_similarity", "x.unsqueeze", "gss_greedy.GSS_greedyPlugin.get_grad_vector"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.cosine_similarity", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_grad_vector"], ["", "def", "get_each_batch_sample_sim", "(", "\n", "self", ",", "\n", "strategy", ",", "\n", "grad_dims", ",", "\n", "mem_grads", ",", "\n", "batch_x", ",", "\n", "batch_y", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            buffer: memory buffer\n            grad_dims: gradient dimensions\n            mem_grads: gradient from memory subsets\n            batch_x: batch images\n            batch_y: batch labels\n        Returns: score of each sample from current batch\n        \"\"\"", "\n", "cosine_sim", "=", "torch", ".", "zeros", "(", "batch_x", ".", "size", "(", "0", ")", ",", "device", "=", "strategy", ".", "device", ")", "\n", "for", "i", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "zip", "(", "batch_x", ",", "batch_y", ")", ")", ":", "\n", "            ", "strategy", ".", "model", ".", "zero_grad", "(", ")", "\n", "ptloss", "=", "strategy", ".", "_criterion", "(", "\n", "strategy", ".", "model", ".", "forward", "(", "x", ".", "unsqueeze", "(", "0", ")", ")", ",", "y", ".", "unsqueeze", "(", "0", ")", ")", "\n", "ptloss", ".", "backward", "(", ")", "\n", "# add the new grad to the memory grads and add it is cosine", "\n", "# similarity", "\n", "this_grad", "=", "self", ".", "get_grad_vector", "(", "\n", "strategy", ".", "model", ".", "parameters", ",", "grad_dims", ")", ".", "unsqueeze", "(", "0", ")", "\n", "cosine_sim", "[", "i", "]", "=", "max", "(", "self", ".", "cosine_similarity", "(", "mem_grads", ",", "this_grad", ")", ")", "\n", "", "return", "cosine_sim", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.before_training_exp": [[148, 172], ["gss_greedy.GSS_greedyPlugin.ext_mem_list_y.to", "list", "avalanche.benchmarks.utils.AvalancheDataset", "avalanche.benchmarks.utils.data_loader.ReplayDataLoader", "temp_x_tensors.append", "zip", "elem.to"], "methods", ["None"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ",", "num_workers", "=", "0", ",", "shuffle", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Dataloader to build batches containing examples from both memories and\n        the training dataset\n        \"\"\"", "\n", "if", "self", ".", "ext_mem_list_current_index", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "temp_x_tensors", "=", "[", "]", "\n", "for", "elem", "in", "self", ".", "ext_mem_list_x", ":", "\n", "            ", "temp_x_tensors", ".", "append", "(", "elem", ".", "to", "(", "'cpu'", ")", ")", "\n", "", "temp_y_tensors", "=", "self", ".", "ext_mem_list_y", ".", "to", "(", "'cpu'", ")", "\n", "\n", "memory", "=", "list", "(", "zip", "(", "temp_x_tensors", ",", "temp_y_tensors", ")", ")", "\n", "memory", "=", "AvalancheDataset", "(", "memory", ",", "targets", "=", "temp_y_tensors", ")", "\n", "\n", "strategy", ".", "dataloader", "=", "ReplayDataLoader", "(", "\n", "strategy", ".", "adapted_dataset", ",", "\n", "memory", ",", "\n", "oversample_small_tasks", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_size", "=", "strategy", ".", "train_mb_size", ",", "\n", "shuffle", "=", "shuffle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.after_forward": [[173, 264], ["strategy.model.eval", "strategy.model.parameters", "strategy.model.train", "grad_dims.append", "gss_greedy.GSS_greedyPlugin.ext_mem_list_x.size", "gss_greedy.GSS_greedyPlugin.get_batch_sim", "min", "gss_greedy.GSS_greedyPlugin.ext_mem_list_x[].data.copy_", "gss_greedy.GSS_greedyPlugin.ext_mem_list_y[].data.copy_", "gss_greedy.GSS_greedyPlugin.buffer_score[].data.copy_", "param.data.numel", "gss_greedy.GSS_greedyPlugin.buffer_score[].cpu", "torch.multinomial().to", "gss_greedy.GSS_greedyPlugin.get_each_batch_sample_sim", "torch.multinomial", "torch.arange", "torch.multinomial.squeeze().bool", "strategy.mb_x[].clone", "strategy.mb_y[].clone", "batch_item_sim[].clone", "strategy.mb_x.size", "gss_greedy.GSS_greedyPlugin.get_rand_mem_grads", "gss_greedy.GSS_greedyPlugin.get_each_batch_sample_sim", "torch.cat", "torch.zeros", "torch.min", "torch.multinomial", "gss_greedy.GSS_greedyPlugin.size", "torch.multinomial.squeeze", "updated_mb_x.size", "len", "torch.max", "torch.min", "strategy.mb_x.size"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.train", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_batch_sim", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_each_batch_sample_sim", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_rand_mem_grads", "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.gss_greedy.GSS_greedyPlugin.get_each_batch_sample_sim"], ["", "def", "after_forward", "(", "self", ",", "strategy", ",", "num_workers", "=", "0", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        After every forward this function select sample to fill\n        the memory buffer based on cosine similarity\n        \"\"\"", "\n", "\n", "strategy", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# Compute the gradient dimension", "\n", "grad_dims", "=", "[", "]", "\n", "for", "param", "in", "strategy", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "grad_dims", ".", "append", "(", "param", ".", "data", ".", "numel", "(", ")", ")", "\n", "\n", "", "place_left", "=", "self", ".", "ext_mem_list_x", ".", "size", "(", "\n", "0", ")", "-", "self", ".", "ext_mem_list_current_index", "\n", "if", "(", "place_left", "<=", "0", ")", ":", "# buffer full", "\n", "\n", "            ", "batch_sim", ",", "mem_grads", "=", "self", ".", "get_batch_sim", "(", "\n", "strategy", ",", "grad_dims", ",", "batch_x", "=", "strategy", ".", "mb_x", ",", "\n", "batch_y", "=", "strategy", ".", "mb_y", ")", "\n", "\n", "if", "batch_sim", "<", "0", ":", "\n", "                ", "buffer_score", "=", "self", ".", "buffer_score", "[", "\n", ":", "self", ".", "ext_mem_list_current_index", "]", ".", "cpu", "(", ")", "\n", "\n", "buffer_sim", "=", "(", "(", "buffer_score", "-", "torch", ".", "min", "(", "buffer_score", ")", ")", "/", "\n", "(", "(", "torch", ".", "max", "(", "buffer_score", ")", "-", "\n", "torch", ".", "min", "(", "buffer_score", ")", ")", "+", "0.01", ")", ")", "\n", "\n", "# draw candidates for replacement from the buffer", "\n", "index", "=", "torch", ".", "multinomial", "(", "\n", "buffer_sim", ",", "strategy", ".", "mb_x", ".", "size", "(", "0", ")", ",", "replacement", "=", "False", ")", ".", "to", "(", "strategy", ".", "device", ")", "\n", "\n", "# estimate the similarity of each sample in the received batch", "\n", "# to the randomly drawn samples from the buffer.", "\n", "batch_item_sim", "=", "self", ".", "get_each_batch_sample_sim", "(", "\n", "strategy", ",", "grad_dims", ",", "mem_grads", ",", "strategy", ".", "mb_x", ",", "\n", "strategy", ".", "mb_y", ")", "\n", "\n", "# normalize to [0,1]", "\n", "scaled_batch_item_sim", "=", "(", "(", "batch_item_sim", "+", "1", ")", "/", "2", ")", ".", "unsqueeze", "(", "1", ")", "\n", "buffer_repl_batch_sim", "=", "(", "\n", "(", "self", ".", "buffer_score", "[", "index", "]", "+", "1", ")", "/", "2", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# draw an event to decide on replacement decision", "\n", "outcome", "=", "torch", ".", "multinomial", "(", "torch", ".", "cat", "(", "(", "scaled_batch_item_sim", ",", "\n", "buffer_repl_batch_sim", ")", ",", "\n", "dim", "=", "1", ")", ",", "\n", "1", ",", "replacement", "=", "False", ")", "\n", "# replace samples with outcome =1", "\n", "added_indx", "=", "torch", ".", "arange", "(", "end", "=", "batch_item_sim", ".", "size", "(", "0", ")", ",", "\n", "device", "=", "strategy", ".", "device", ")", "\n", "sub_index", "=", "outcome", ".", "squeeze", "(", "1", ")", ".", "bool", "(", ")", "\n", "self", ".", "ext_mem_list_x", "[", "index", "[", "sub_index", "]", "]", "=", "strategy", ".", "mb_x", "[", "\n", "added_indx", "[", "sub_index", "]", "]", ".", "clone", "(", ")", "\n", "self", ".", "ext_mem_list_y", "[", "index", "[", "sub_index", "]", "\n", "]", "=", "strategy", ".", "mb_y", "[", "added_indx", "[", "\n", "sub_index", "]", "]", ".", "clone", "(", ")", "\n", "self", ".", "buffer_score", "[", "index", "[", "sub_index", "]", "]", "=", "batch_item_sim", "[", "\n", "added_indx", "[", "sub_index", "]", "]", ".", "clone", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "offset", "=", "min", "(", "place_left", ",", "strategy", ".", "mb_x", ".", "size", "(", "0", ")", ")", "\n", "updated_mb_x", "=", "strategy", ".", "mb_x", "[", ":", "offset", "]", "\n", "updated_mb_y", "=", "strategy", ".", "mb_y", "[", ":", "offset", "]", "\n", "\n", "# first buffer insertion", "\n", "if", "self", ".", "ext_mem_list_current_index", "==", "0", ":", "\n", "                ", "batch_sample_memory_cos", "=", "torch", ".", "zeros", "(", "\n", "updated_mb_x", ".", "size", "(", "0", ")", ")", "+", "0.1", "\n", "", "else", ":", "\n", "# draw random samples from buffer", "\n", "                ", "mem_grads", "=", "self", ".", "get_rand_mem_grads", "(", "\n", "strategy", "=", "strategy", ",", "grad_dims", "=", "grad_dims", ",", "\n", "gss_batch_size", "=", "len", "(", "strategy", ".", "mb_x", ")", ")", "\n", "\n", "# estimate a score for each added sample", "\n", "batch_sample_memory_cos", "=", "self", ".", "get_each_batch_sample_sim", "(", "\n", "strategy", ",", "grad_dims", ",", "mem_grads", ",", "updated_mb_x", ",", "updated_mb_y", ")", "\n", "\n", "", "self", ".", "ext_mem_list_x", "[", "self", ".", "ext_mem_list_current_index", ":", "\n", "self", ".", "ext_mem_list_current_index", "\n", "+", "offset", "]", ".", "data", ".", "copy_", "(", "updated_mb_x", ")", "\n", "self", ".", "ext_mem_list_y", "[", "self", ".", "ext_mem_list_current_index", ":", "\n", "self", ".", "ext_mem_list_current_index", "\n", "+", "offset", "]", ".", "data", ".", "copy_", "(", "updated_mb_y", ")", "\n", "self", ".", "buffer_score", "[", "self", ".", "ext_mem_list_current_index", ":", "\n", "self", ".", "ext_mem_list_current_index", "+", "\n", "offset", "]", ".", "data", ".", "copy_", "(", "batch_sample_memory_cos", ")", "\n", "self", ".", "ext_mem_list_current_index", "+=", "offset", "\n", "\n", "", "strategy", ".", "model", ".", "train", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.__init__": [[31, 112], ["avalanche.training.plugins.strategy_plugin.StrategyPlugin.__init__", "isinstance", "len", "warnings.warn", "collections.defaultdict", "list", "flat_metrics_list.append", "isinstance", "ValueError", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "*", "metrics", ":", "Union", "[", "'PluginMetric'", ",", "Sequence", "[", "'PluginMetric'", "]", "]", ",", "\n", "loggers", ":", "Union", "[", "'StrategyLogger'", ",", "\n", "Sequence", "[", "'StrategyLogger'", "]", "]", "=", "None", ",", "\n", "collect_all", "=", "True", ",", "\n", "benchmark", "=", "None", ",", "\n", "strict_checks", "=", "False", ",", "\n", "suppress_warnings", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the evaluation plugin.\n\n        :param metrics: The metrics to compute.\n        :param loggers: The loggers to be used to log the metric values.\n        :param collect_all: if True, collect in a separate dictionary all\n            metric curves values. This dictionary is accessible with\n            `get_all_metrics` method.\n        :param benchmark: continual learning benchmark needed to check stream\n            completeness during evaluation or other kind of properties. If\n            None, no check will be conducted and the plugin will emit a\n            warning to signal this fact.\n        :param strict_checks: if True, `benchmark` has to be provided.\n            In this case, only full evaluation streams are admitted when\n            calling `eval`. An error will be raised otherwise. When False,\n            `benchmark` can be `None` and only warnings will be raised.\n        :param suppress_warnings: if True, warnings and errors will never be\n            raised from the plugin.\n            If False, warnings and errors will be raised following\n            `benchmark` and `strict_checks` behavior.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "collect_all", "=", "collect_all", "\n", "self", ".", "benchmark", "=", "benchmark", "\n", "self", ".", "strict_checks", "=", "strict_checks", "\n", "self", ".", "suppress_warnings", "=", "suppress_warnings", "\n", "flat_metrics_list", "=", "[", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "isinstance", "(", "metric", ",", "Sequence", ")", ":", "\n", "                ", "flat_metrics_list", "+=", "list", "(", "metric", ")", "\n", "", "else", ":", "\n", "                ", "flat_metrics_list", ".", "append", "(", "metric", ")", "\n", "", "", "self", ".", "metrics", "=", "flat_metrics_list", "\n", "\n", "if", "loggers", "is", "None", ":", "\n", "            ", "loggers", "=", "[", "]", "\n", "", "elif", "not", "isinstance", "(", "loggers", ",", "Sequence", ")", ":", "\n", "            ", "loggers", "=", "[", "loggers", "]", "\n", "\n", "", "if", "benchmark", "is", "None", ":", "\n", "            ", "if", "not", "suppress_warnings", ":", "\n", "                ", "if", "strict_checks", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Benchmark cannot be None \"", "\n", "\"in strict mode.\"", ")", "\n", "", "else", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "\"No benchmark provided to the evaluation plugin. \"", "\n", "\"Metrics may be computed on inconsistent portion \"", "\n", "\"of streams, use at your own risk.\"", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "complete_test_stream", "=", "benchmark", ".", "test_stream", "\n", "\n", "", "self", ".", "loggers", ":", "Sequence", "[", "'StrategyLogger'", "]", "=", "loggers", "\n", "\n", "if", "len", "(", "self", ".", "loggers", ")", "==", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "'No loggers specified, metrics will not be logged'", ")", "\n", "\n", "", "if", "self", ".", "collect_all", ":", "\n", "# for each curve collect all emitted values.", "\n", "# dictionary key is full metric name.", "\n", "# Dictionary value is a tuple of two lists.", "\n", "# first list gathers x values (indices representing", "\n", "# time steps at which the corresponding metric value", "\n", "# has been emitted)", "\n", "# second list gathers metric values", "\n", "            ", "self", ".", "all_metric_results", "=", "defaultdict", "(", "lambda", ":", "(", "[", "]", ",", "[", "]", ")", ")", "\n", "# Dictionary of last values emitted. Dictionary key", "\n", "# is the full metric name, while dictionary value is", "\n", "# metric value.", "\n", "", "self", ".", "last_metric_results", "=", "{", "}", "\n", "\n", "self", ".", "_active", "=", "True", "\n", "\"\"\"If False, no metrics will be collected.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.active": [[117, 122], ["None"], "methods", ["None"], ["", "@", "active", ".", "setter", "\n", "def", "active", "(", "self", ",", "value", ")", ":", "\n", "        ", "assert", "value", "is", "True", "or", "value", "is", "False", ",", "\"Active must be set as either True or False\"", "\n", "self", ".", "_active", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics": [[123, 148], ["isinstance", "getattr", "list", "[].append", "[].append", "getattr", "metric_values.append"], "methods", ["None"], ["", "def", "_update_metrics", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "callback", ":", "str", ")", ":", "\n", "        ", "if", "not", "self", ".", "_active", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "metric_values", "=", "[", "]", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "metric_result", "=", "getattr", "(", "metric", ",", "callback", ")", "(", "strategy", ")", "\n", "if", "isinstance", "(", "metric_result", ",", "Sequence", ")", ":", "\n", "                ", "metric_values", "+=", "list", "(", "metric_result", ")", "\n", "", "elif", "metric_result", "is", "not", "None", ":", "\n", "                ", "metric_values", ".", "append", "(", "metric_result", ")", "\n", "\n", "", "", "for", "metric_value", "in", "metric_values", ":", "\n", "            ", "name", "=", "metric_value", ".", "name", "\n", "x", "=", "metric_value", ".", "x_plot", "\n", "val", "=", "metric_value", ".", "value", "\n", "if", "self", ".", "collect_all", ":", "\n", "                ", "self", ".", "all_metric_results", "[", "name", "]", "[", "0", "]", ".", "append", "(", "x", ")", "\n", "self", ".", "all_metric_results", "[", "name", "]", "[", "1", "]", ".", "append", "(", "val", ")", "\n", "\n", "", "self", ".", "last_metric_results", "[", "name", "]", "=", "val", "\n", "\n", "", "for", "logger", "in", "self", ".", "loggers", ":", "\n", "            ", "getattr", "(", "logger", ",", "callback", ")", "(", "strategy", ",", "metric_values", ")", "\n", "", "return", "metric_values", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.get_last_metrics": [[149, 158], ["copy.copy.copy"], "methods", ["None"], ["", "def", "get_last_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a shallow copy of dictionary with metric names\n        as keys and last metrics value as values.\n\n        :return: a dictionary with full metric\n            names as keys and last metric value as value.\n        \"\"\"", "\n", "return", "copy", "(", "self", ".", "last_metric_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.get_all_metrics": [[159, 176], ["None"], "methods", ["None"], ["", "def", "get_all_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the dictionary of all collected metrics.\n        This method should be called only when `collect_all` is set to True.\n\n        :return: if `collect_all` is True, returns a dictionary\n            with full metric names as keys and a tuple of two lists\n            as value. The first list gathers x values (indices\n            representing time steps at which the corresponding\n            metric value has been emitted). The second list\n            gathers metric values. a dictionary. If `collect_all`\n            is False return an empty dictionary\n        \"\"\"", "\n", "if", "self", ".", "collect_all", ":", "\n", "            ", "return", "self", ".", "all_metric_results", "\n", "", "else", ":", "\n", "            ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.reset_last_metrics": [[177, 183], ["None"], "methods", ["None"], ["", "", "def", "reset_last_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Set the dictionary storing last value for each metric to be\n        empty dict.\n        \"\"\"", "\n", "self", ".", "last_metric_results", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_training": [[184, 186], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_training'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_training_exp": [[187, 189], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_training_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_train_dataset_adaptation": [[190, 193], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_train_dataset_adaptation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_train_dataset_adaptation": [[194, 197], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_train_dataset_adaptation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_training_epoch": [[198, 200], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_training_epoch'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_training_iteration": [[201, 203], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_training_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_forward": [[204, 206], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_forward": [[207, 209], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_backward": [[210, 212], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "update_metrics", "=", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_backward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_backward": [[213, 215], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_backward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_training_iteration": [[216, 218], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_training_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_update": [[219, 221], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_update'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_update": [[222, 224], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_update'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_training_epoch": [[225, 227], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_training_epoch'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_training_exp": [[228, 230], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_training_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_training": [[231, 233], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_training'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_eval": [[234, 255], ["evaluation.EvaluationPlugin._update_metrics", "enumerate", "ValueError", "warnings.warn", "ValueError", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_eval'", ")", "\n", "msgw", "=", "\"Evaluation stream is not equal to the complete test stream. \"", "\"This may result in inconsistent metrics. Use at your own risk.\"", "\n", "msge", "=", "\"Stream provided to `eval` must be the same of the entire \"", "\"evaluation stream.\"", "\n", "if", "self", ".", "benchmark", "is", "not", "None", ":", "\n", "            ", "for", "i", ",", "exp", "in", "enumerate", "(", "self", ".", "complete_test_stream", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "current_exp", "=", "strategy", ".", "current_eval_stream", "[", "i", "]", "\n", "if", "exp", ".", "current_experience", "!=", "current_exp", ".", "current_experience", ":", "\n", "                        ", "if", "not", "self", ".", "suppress_warnings", ":", "\n", "                            ", "if", "self", ".", "strict_checks", ":", "\n", "                                ", "raise", "ValueError", "(", "msge", ")", "\n", "", "else", ":", "\n", "                                ", "warnings", ".", "warn", "(", "msgw", ")", "\n", "", "", "", "", "except", "IndexError", ":", "\n", "                    ", "if", "self", ".", "strict_checks", ":", "\n", "                        ", "raise", "ValueError", "(", "msge", ")", "\n", "", "else", ":", "\n", "                        ", "warnings", ".", "warn", "(", "msgw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_eval_dataset_adaptation": [[256, 259], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "", "", "", "", "def", "before_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_eval_dataset_adaptation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_eval_dataset_adaptation": [[260, 262], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_eval_dataset_adaptation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_eval_exp": [[263, 265], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_eval_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_eval_exp": [[266, 268], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_eval_exp'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_eval": [[269, 271], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_eval_iteration": [[272, 274], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_eval_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.before_eval_forward": [[275, 277], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "before_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'before_eval_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_eval_forward": [[278, 280], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_eval_forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin.after_eval_iteration": [[281, 283], ["evaluation.EvaluationPlugin._update_metrics"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.evaluation.EvaluationPlugin._update_metrics"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_update_metrics", "(", "strategy", ",", "'after_eval_iteration'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lr_scheduling.LRSchedulerPlugin.__init__": [[12, 29], ["avalanche.training.plugins.StrategyPlugin.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "scheduler", ",", "reset_scheduler", "=", "True", ",", "reset_lr", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Creates a ``LRSchedulerPlugin`` instance.\n\n        :param scheduler: a learning rate scheduler that can be updated through\n            a step() method and can be reset by setting last_epoch=0\n        :param reset_scheduler: If True, the scheduler is reset at the end of\n            the experience.\n            Defaults to True.\n        :param reset_lr: If True, the optimizer learning rate is reset to its\n            original value.\n            Default to True.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "reset_scheduler", "=", "reset_scheduler", "\n", "self", ".", "reset_lr", "=", "reset_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lr_scheduling.LRSchedulerPlugin.after_training_epoch": [[30, 32], ["lr_scheduling.LRSchedulerPlugin.scheduler.step"], "methods", ["None"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.plugins.lr_scheduling.LRSchedulerPlugin.after_training_exp": [[33, 43], ["zip"], "methods", ["None"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "param_groups", "=", "strategy", ".", "optimizer", ".", "param_groups", "\n", "base_lrs", "=", "self", ".", "scheduler", ".", "base_lrs", "\n", "\n", "if", "self", ".", "reset_lr", ":", "\n", "            ", "for", "group", ",", "lr", "in", "zip", "(", "param_groups", ",", "base_lrs", ")", ":", "\n", "                ", "group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "", "", "if", "self", ".", "reset_scheduler", ":", "\n", "            ", "self", ".", "scheduler", ".", "last_epoch", "=", "0", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.vgg": [[32, 51], ["pytorchcv.model_provider.get_model", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.get_model"], ["def", "vgg", "(", "depth", ":", "int", ",", "batch_normalization", "=", "False", ",", "pretrained", "=", "False", ")", "->", "Module", ":", "\n", "    ", "\"\"\"\n    Wrapper for VGG net of verious depths availble in the pytorchcv package.\n    VGG is only availabe for imagenet.\n\n    :param depth: Depth of the model, one of (11, 13, 16, 19)\n    :param batch_normalization: include batch normalizaion layers\n    :param pretrained: loads model pretrained on imagnet\n    \"\"\"", "\n", "available_depths", "=", "[", "11", ",", "13", ",", "16", ",", "19", "]", "\n", "if", "depth", "not", "in", "available_depths", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Depth {depth} not available, \"", "\n", "f\"availble depths are {available_depths}\"", ")", "\n", "\n", "", "name", "=", "f\"vgg{depth}\"", "\n", "if", "batch_normalization", ":", "\n", "        ", "name", "=", "f\"bn_{name}\"", "\n", "\n", "", "return", "ptcv_get_model", "(", "name", ",", "pretrained", "=", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.resnet": [[53, 80], ["pytorchcv.model_provider.get_model", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.get_model"], ["", "def", "resnet", "(", "dataset", ":", "str", ",", "depth", ":", "int", ",", "pretrained", "=", "False", ")", "->", "Module", ":", "\n", "    ", "\"\"\"\n    Wrapper for (basic) renset available in the pytorchcv package. More variants\n    are availble through the general wrapper.\n\n    :param dataset: One of cifar10, cifar100, svhn, imagenet.\n    :param depth: depth of the architecture, one of (10, 12, 14, 16, 18, 26, 34,\n                  50, 101, 152, 200) for imagenet,\n                  (20, 56, 110, 1001, 1202) for the other datasets.\n    :param pretrained: loads model pretrained on `dataset`.\n    \"\"\"", "\n", "\n", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"svhn\"", "]", ":", "\n", "        ", "available_depths", "=", "[", "20", ",", "56", ",", "110", ",", "1001", ",", "1202", "]", "\n", "model_name", "=", "f\"resnet{depth}_{dataset}\"", "\n", "", "elif", "dataset", "==", "\"imagenet\"", ":", "\n", "        ", "available_depths", "=", "[", "10", ",", "12", ",", "14", ",", "16", ",", "18", ",", "26", ",", "34", ",", "50", ",", "101", ",", "152", ",", "200", "]", "\n", "model_name", "=", "f\"resnet{depth}\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unrecognized dataset {dataset}\"", ")", "\n", "\n", "", "if", "depth", "not", "in", "available_depths", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Depth {depth} not available for dataset {dataset}, \"", "\n", "f\"availble depths are {available_depths}\"", ")", "\n", "\n", "", "model", "=", "ptcv_get_model", "(", "model_name", ",", "pretrained", "=", "pretrained", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.densenet": [[82, 109], ["pytorchcv.model_provider.get_model", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.get_model"], ["", "def", "densenet", "(", "dataset", ":", "str", ",", "depth", ":", "int", ",", "pretrained", "=", "False", ")", "->", "Module", ":", "\n", "    ", "\"\"\"\n    Wrapper for densenet available in the pytorchcv package.\n\n    :param dataset: One of cifar10, cifar100, svhn, imagenet.\n    :param depth: The depth of the densnet. For imagenet depths\n                  (121, 161, 169, 201) are supported. The other datasets\n                   support dephts (40, 100).\n    :param pretrained: load model pretrained on `dataset`..\n    \"\"\"", "\n", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"svhn\"", "]", ":", "\n", "        ", "available_depths", "=", "[", "40", ",", "100", "]", "\n", "# other growth rates are available through the general method.", "\n", "growth_rate", "=", "12", "\n", "model_name", "=", "f\"densenet{depth}_k{growth_rate}_{dataset}\"", "\n", "", "elif", "dataset", "==", "\"imagenet\"", ":", "\n", "        ", "available_depths", "=", "[", "121", ",", "161", ",", "169", ",", "201", "]", "\n", "model_name", "=", "f\"densenet{depth}\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unrecognized dataset {dataset}\"", ")", "\n", "\n", "", "if", "depth", "not", "in", "available_depths", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Depth {depth} not available for dataset {dataset}, \"", "\n", "f\"availble depths are {available_depths}\"", ")", "\n", "\n", "", "model", "=", "ptcv_get_model", "(", "model_name", ",", "pretrained", "=", "pretrained", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.pyramidnet": [[111, 141], ["pytorchcv.model_provider.get_model", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.get_model"], ["", "def", "pyramidnet", "(", "dataset", ":", "str", ",", "depth", ":", "int", ",", "pretrained", "=", "False", ")", "->", "Module", ":", "\n", "    ", "\"\"\"\n    Wrapper for pyramidnet available in the pytorchcv package.\n\n    :param dataset: One of cifar10, cifar100, svhn, imagenet.\n    :param depth: The depth of the pyramidnet. For imagenet 101 is supported.\n                  The other datasets support dephts (110, 164, 200, 236, 272).\n    :param pretrained: load model pretrained on `dataset`..\n    \"\"\"", "\n", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"svhn\"", "]", ":", "\n", "        ", "available_depths", "=", "[", "110", ",", "164", ",", "200", ",", "236", ",", "272", "]", "\n", "alpha", "=", "{", "110", ":", "48", ",", "164", ":", "270", ",", "200", ":", "240", ",", "236", ":", "220", ",", "272", ":", "200", "}", ".", "get", "(", "depth", ")", "\n", "if", "depth", "<", "200", ":", "\n", "            ", "model_name", "=", "f\"pyramidnet{depth}_a{alpha}_{dataset}\"", "\n", "", "else", ":", "\n", "# These models have batch normalization", "\n", "            ", "model_name", "=", "f\"pyramidnet{depth}_a{alpha}_bn_{dataset}\"", "\n", "", "", "elif", "dataset", "==", "\"imagenet\"", ":", "\n", "        ", "available_depths", "=", "[", "101", "]", "\n", "alpha", "=", "360", "\n", "model_name", "=", "f\"pyramidnet{depth}_a{alpha}\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unrecognized dataset {dataset}\"", ")", "\n", "\n", "", "if", "depth", "not", "in", "available_depths", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Depth {depth} not available for dataset {dataset}, \"", "\n", "f\"availble depths are {available_depths}\"", ")", "\n", "\n", "", "model", "=", "ptcv_get_model", "(", "model_name", ",", "pretrained", "=", "pretrained", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.get_model": [[143, 149], ["pytorchcv.model_provider.get_model"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pytorchcv_wrapper.get_model"], ["", "def", "get_model", "(", "name", ":", "str", ",", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    This a direct wrapper to the model getter of `pytorchcv`. For available\n    models see: https://github.com/osmr/imgclsmob\n    \"\"\"", "\n", "return", "ptcv_get_model", "(", "name", ",", "pretrained", "=", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_cnn.SimpleCNN.__init__": [[22, 45], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.ReLU", "torch.Conv2d", "torch.ReLU", "torch.MaxPool2d", "torch.Dropout", "torch.Conv2d", "torch.ReLU", "torch.Conv2d", "torch.ReLU", "torch.MaxPool2d", "torch.Dropout", "torch.Conv2d", "torch.ReLU", "torch.AdaptiveMaxPool2d", "torch.Dropout", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", "SimpleCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.25", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.25", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "AdaptiveMaxPool2d", "(", "1", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.25", ")", "\n", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "64", ",", "num_classes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_cnn.SimpleCNN.forward": [[47, 52], ["simple_cnn.SimpleCNN.features", "simple_cnn.SimpleCNN.view", "simple_cnn.SimpleCNN.classifier", "simple_cnn.SimpleCNN.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_cnn.MTSimpleCNN.__init__": [[57, 60], ["simple_cnn.SimpleCNN.__init__", "avalanche.models.dynamic_modules.MultiHeadClassifier"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "classifier", "=", "MultiHeadClassifier", "(", "64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_cnn.MTSimpleCNN.forward": [[61, 66], ["simple_cnn.MTSimpleCNN.features", "simple_cnn.MTSimpleCNN.squeeze", "simple_cnn.MTSimpleCNN.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "task_labels", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "squeeze", "(", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ",", "task_labels", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.slda_resnet.SLDAResNetModel.__init__": [[14, 32], ["torch.Module.__init__", "utils.FeatureExtractorBackbone().eval", "utils.FeatureExtractorBackbone"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.strategies.base_strategy.BaseStrategy.eval"], ["def", "__init__", "(", "self", ",", "arch", "=", "'resnet18'", ",", "output_layer_name", "=", "'layer4.1'", ",", "\n", "imagenet_pretrained", "=", "True", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "\"\"\"\n        :param arch: backbone architecture (default is resnet-18, but others\n        can be used by modifying layer for\n        feature extraction in `self.feature_extraction_wrapper'\n        :param imagenet_pretrained: True if initializing backbone with imagenet\n        pre-trained weights else False\n        :param output_layer_name: name of the layer from feature extractor\n        :param device: cpu, gpu or other device\n        \"\"\"", "\n", "\n", "super", "(", "SLDAResNetModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "feat_extractor", "=", "models", ".", "__dict__", "[", "arch", "]", "(", "\n", "pretrained", "=", "imagenet_pretrained", ")", ".", "to", "(", "device", ")", ".", "eval", "(", ")", "\n", "self", ".", "feature_extraction_wrapper", "=", "FeatureExtractorBackbone", "(", "\n", "feat_extractor", ",", "output_layer_name", ")", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.slda_resnet.SLDAResNetModel.pool_feat": [[33, 44], ["features.permute", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape.mean", "torch.reshape.mean"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pool_feat", "(", "features", ")", ":", "\n", "        ", "feat_size", "=", "features", ".", "shape", "[", "-", "1", "]", "\n", "num_channels", "=", "features", ".", "shape", "[", "1", "]", "\n", "features2", "=", "features", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "\n", "1", ")", "# 1 x feat_size x feat_size x", "\n", "# num_channels", "\n", "features3", "=", "torch", ".", "reshape", "(", "features2", ",", "(", "\n", "features", ".", "shape", "[", "0", "]", ",", "feat_size", "*", "feat_size", ",", "num_channels", ")", ")", "\n", "feat", "=", "features3", ".", "mean", "(", "1", ")", "# mb x num_channels", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.slda_resnet.SLDAResNetModel.forward": [[45, 52], ["slda_resnet.SLDAResNetModel.feature_extraction_wrapper", "slda_resnet.SLDAResNetModel.pool_feat"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.slda_resnet.SLDAResNetModel.pool_feat"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        :param x: raw x data\n        \"\"\"", "\n", "feat", "=", "self", ".", "feature_extraction_wrapper", "(", "x", ")", "\n", "feat", "=", "SLDAResNetModel", ".", "pool_feat", "(", "feat", ")", "\n", "return", "feat", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_optimizers.reset_optimizer": [[20, 33], ["collections.defaultdict", "list", "len", "model.parameters"], "function", ["None"], ["def", "reset_optimizer", "(", "optimizer", ",", "model", ")", ":", "\n", "    ", "\"\"\" Reset the optimizer to update the list of learnable parameters.\n\n    .. warning::\n        This function fails if the optimizer uses multiple parameter groups.\n\n    :param optimizer:\n    :param model:\n    :return:\n    \"\"\"", "\n", "assert", "len", "(", "optimizer", ".", "param_groups", ")", "==", "1", "\n", "optimizer", ".", "state", "=", "defaultdict", "(", "dict", ")", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'params'", "]", "=", "list", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_optimizers.update_optimizer": [[35, 63], ["zip", "collections.defaultdict", "enumerate", "Exception", "hash", "hash"], "function", ["None"], ["", "def", "update_optimizer", "(", "optimizer", ",", "old_params", ",", "new_params", ",", "reset_state", "=", "True", ")", ":", "\n", "    ", "\"\"\" Update the optimizer by substituting old_params with new_params.\n\n    :param old_params: List of old trainable parameters.\n    :param new_params: List of new trainable parameters.\n    :param reset_state: Wheter to reset the optimizer's state.\n        Defaults to True.\n    :return:\n    \"\"\"", "\n", "for", "old_p", ",", "new_p", "in", "zip", "(", "old_params", ",", "new_params", ")", ":", "\n", "        ", "found", "=", "False", "\n", "# iterate over group and params for each group.", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "for", "i", ",", "curr_p", "in", "enumerate", "(", "group", "[", "'params'", "]", ")", ":", "\n", "                ", "if", "hash", "(", "curr_p", ")", "==", "hash", "(", "old_p", ")", ":", "\n", "# update parameter reference", "\n", "                    ", "group", "[", "'params'", "]", "[", "i", "]", "=", "new_p", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "found", ":", "\n", "                ", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "raise", "Exception", "(", "f\"Parameter {old_params} not found in the \"", "\n", "f\"current optimizer.\"", ")", "\n", "", "", "if", "reset_state", ":", "\n", "# State contains parameter-specific information.", "\n", "# We reset it because the model is (probably) changed.", "\n", "        ", "optimizer", ".", "state", "=", "defaultdict", "(", "dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_optimizers.add_new_params_to_optimizer": [[65, 71], ["optimizer.add_param_group"], "function", ["None"], ["", "", "def", "add_new_params_to_optimizer", "(", "optimizer", ",", "new_params", ")", ":", "\n", "    ", "\"\"\" Add new parameters to the trainable parameters.\n\n    :param new_params: list of trainable parameters\n    \"\"\"", "\n", "optimizer", ".", "add_param_group", "(", "{", "'params'", ":", "new_params", "}", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.DynamicModule.adaptation": [[34, 55], ["dynamic_modules.DynamicModule.train_adaptation", "dynamic_modules.DynamicModule.eval_adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer.train_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.TrainEvalModel.eval_adaptation"], ["def", "adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", "=", "None", ")", ":", "\n", "        ", "\"\"\" Adapt the module (freeze units, add units...) using the current\n        data. Optimizers must be updated after the model adaptation.\n\n        Avalanche strategies call this method to adapt the architecture\n        *before* processing each experience. Strategies also update the\n        optimizer automatically.\n\n        .. warning::\n            As a general rule, you should NOT use this method to train the\n            model. The dataset should be used only to check conditions which\n            require the model's adaptation, such as the discovery of new\n            classes or tasks.\n\n        :param dataset: data from the current experience.\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "train_adaptation", "(", "dataset", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eval_adaptation", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.DynamicModule.train_adaptation": [[56, 63], ["None"], "methods", ["None"], ["", "", "def", "train_adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", ")", ":", "\n", "        ", "\"\"\" Module's adaptation at training time.\n\n        Avalanche strategies automatically call this method *before* training\n        on each experience.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.DynamicModule.eval_adaptation": [[64, 78], ["None"], "methods", ["None"], ["", "def", "eval_adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", ")", ":", "\n", "        ", "\"\"\" Module's adaptation at evaluation time.\n\n        Avalanche strategies automatically call this method *before* evaluating\n        on each experience.\n\n        .. warning::\n            This method receives the experience's data at evaluation time\n            because some dynamic models need it for adaptation. For example,\n            an incremental classifier needs to be expanded even at evaluation\n            time if new classes are available. However, you should **never**\n            use this data to **train** the module's parameters.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiTaskModule.__init__": [[94, 98], ["torch.nn.Module.__init__", "set"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "known_train_tasks_labels", "=", "set", "(", ")", "\n", "\"\"\" Set of task labels encountered up to now. \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiTaskModule.train_adaptation": [[99, 107], ["isinstance", "dynamic_modules.MultiTaskModule.known_train_tasks_labels.union", "set"], "methods", ["None"], ["", "def", "train_adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", "=", "None", ")", ":", "\n", "        ", "\"\"\" Update known task labels. \"\"\"", "\n", "task_labels", "=", "dataset", ".", "targets_task_labels", "\n", "if", "isinstance", "(", "task_labels", ",", "ConstantSequence", ")", ":", "\n", "# task label is unique. Don't check duplicates.", "\n", "            ", "task_labels", "=", "[", "task_labels", "[", "0", "]", "]", "\n", "", "self", ".", "known_train_tasks_labels", "=", "self", ".", "known_train_tasks_labels", ".", "union", "(", "set", "(", "task_labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiTaskModule.forward": [[108, 139], ["isinstance", "dynamic_modules.MultiTaskModule.forward_all_tasks", "dynamic_modules.MultiTaskModule.forward_single_task", "torch.unique", "dynamic_modules.MultiTaskModule.forward_single_task", "task.item", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiTaskModule.forward_all_tasks", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.forward_single_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.forward_single_task"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "task_labels", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" compute the output given the input `x` and task labels.\n\n        :param x:\n        :param task_labels: task labels for each sample. if None, the\n            computation will return all the possible outputs as a dictionary\n            with task IDs as keys and the output of the corresponding task as\n            output.\n        :return:\n        \"\"\"", "\n", "if", "task_labels", "is", "None", ":", "\n", "            ", "return", "self", ".", "forward_all_tasks", "(", "x", ")", "\n", "\n", "", "if", "isinstance", "(", "task_labels", ",", "int", ")", ":", "\n", "# fast path. mini-batch is single task.", "\n", "            ", "return", "self", ".", "forward_single_task", "(", "x", ",", "task_labels", ")", "\n", "", "else", ":", "\n", "            ", "unique_tasks", "=", "torch", ".", "unique", "(", "task_labels", ")", "\n", "\n", "", "out", "=", "None", "\n", "for", "task", "in", "unique_tasks", ":", "\n", "            ", "task_mask", "=", "task_labels", "==", "task", "\n", "x_task", "=", "x", "[", "task_mask", "]", "\n", "out_task", "=", "self", ".", "forward_single_task", "(", "x_task", ",", "task", ".", "item", "(", ")", ")", "\n", "\n", "if", "out", "is", "None", ":", "\n", "                ", "out", "=", "torch", ".", "empty", "(", "x", ".", "shape", "[", "0", "]", ",", "*", "out_task", ".", "shape", "[", "1", ":", "]", ",", "\n", "device", "=", "out_task", ".", "device", ")", "\n", "", "out", "[", "task_mask", "]", "=", "out_task", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiTaskModule.forward_single_task": [[140, 149], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward_single_task", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "task_label", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" compute the output given the input `x` and task label.\n\n        :param x:\n        :param task_label: a single task label.\n        :return:\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiTaskModule.forward_all_tasks": [[150, 163], ["dynamic_modules.MultiTaskModule.forward_single_task"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.forward_single_task"], ["", "def", "forward_all_tasks", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\" compute the output given the input `x` and task label.\n        By default, it considers only tasks seen at training time.\n\n        :param x:\n        :return: all the possible outputs are returned as a dictionary\n            with task IDs as keys and the output of the corresponding\n            task as output.\n        \"\"\"", "\n", "res", "=", "{", "}", "\n", "for", "task_id", "in", "self", ".", "known_train_tasks_labels", ":", "\n", "            ", "res", "[", "task_id", "]", "=", "self", ".", "forward_single_task", "(", "x", ",", "task_id", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.IncrementalClassifier.__init__": [[174, 182], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "initial_out_features", "=", "2", ",", "bias", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: number of input features.\n        :param initial_out_features: initial number of classes (can be\n            dynamically expanded).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "in_features", ",", "initial_out_features", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.IncrementalClassifier.adaptation": [[183, 201], ["torch.no_grad", "max", "torch.nn.Linear", "max"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", ")", ":", "\n", "        ", "\"\"\" If `dataset` contains unseen classes the classifier is expanded.\n\n        :param dataset: data from the current experience.\n        :return:\n        \"\"\"", "\n", "in_features", "=", "self", ".", "classifier", ".", "in_features", "\n", "old_nclasses", "=", "self", ".", "classifier", ".", "out_features", "\n", "new_nclasses", "=", "max", "(", "self", ".", "classifier", ".", "out_features", ",", "\n", "max", "(", "dataset", ".", "targets", ")", "+", "1", ")", "\n", "\n", "if", "old_nclasses", "==", "new_nclasses", ":", "\n", "            ", "return", "\n", "", "old_w", ",", "old_b", "=", "self", ".", "classifier", ".", "weight", ",", "self", ".", "classifier", ".", "bias", "\n", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "in_features", ",", "new_nclasses", ")", "\n", "self", ".", "classifier", ".", "weight", "[", ":", "old_nclasses", "]", "=", "old_w", "\n", "self", ".", "classifier", ".", "bias", "[", ":", "old_nclasses", "]", "=", "old_b", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.IncrementalClassifier.forward": [[202, 210], ["dynamic_modules.IncrementalClassifier.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" compute the output given the input `x`. This module does not use\n        the task label.\n\n        :param x:\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "classifier", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiHeadClassifier.__init__": [[235, 252], ["dynamic_modules.MultiTaskModule.__init__", "torch.nn.ModuleDict", "dynamic_modules.IncrementalClassifier"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "initial_out_features", "=", "2", ",", "use_bias", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: number of input features.\n        :param initial_out_features: initial number of classes (can be\n            dynamically expanded).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "starting_out_features", "=", "initial_out_features", "\n", "self", ".", "classifiers", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "\n", "# needs to create the first head because pytorch optimizers", "\n", "# fail when model.parameters() is empty.", "\n", "first_head", "=", "IncrementalClassifier", "(", "self", ".", "in_features", ",", "\n", "self", ".", "starting_out_features", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "classifiers", "[", "'0'", "]", "=", "first_head", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiHeadClassifier.adaptation": [[253, 272], ["dynamic_modules.DynamicModule.adaptation", "isinstance", "set", "str", "dynamic_modules.IncrementalClassifier", "dynamic_modules.IncrementalClassifier.adaptation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiHeadClassifier.adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiHeadClassifier.adaptation"], ["", "def", "adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", ")", ":", "\n", "        ", "\"\"\" If `dataset` contains new tasks, a new head is initialized.\n\n        :param dataset: data from the current experience.\n        :return:\n        \"\"\"", "\n", "super", "(", ")", ".", "adaptation", "(", "dataset", ")", "\n", "task_labels", "=", "dataset", ".", "targets_task_labels", "\n", "if", "isinstance", "(", "task_labels", ",", "ConstantSequence", ")", ":", "\n", "# task label is unique. Don't check duplicates.", "\n", "            ", "task_labels", "=", "[", "task_labels", "[", "0", "]", "]", "\n", "\n", "", "for", "tid", "in", "set", "(", "task_labels", ")", ":", "\n", "            ", "tid", "=", "str", "(", "tid", ")", "# need str keys", "\n", "if", "tid", "not", "in", "self", ".", "classifiers", ":", "\n", "                ", "new_head", "=", "IncrementalClassifier", "(", "self", ".", "in_features", ",", "\n", "self", ".", "starting_out_features", ",", "bias", "=", "self", ".", "use_bias", ")", "\n", "new_head", ".", "adaptation", "(", "dataset", ")", "\n", "self", ".", "classifiers", "[", "tid", "]", "=", "new_head", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.MultiHeadClassifier.forward_single_task": [[273, 282], ["str"], "methods", ["None"], ["", "", "", "def", "forward_single_task", "(", "self", ",", "x", ",", "task_label", ")", ":", "\n", "        ", "\"\"\" compute the output given the input `x`. This module uses the task\n        label to activate the correct head.\n\n        :param x:\n        :param task_label:\n        :return:\n        \"\"\"", "\n", "return", "self", ".", "classifiers", "[", "str", "(", "task_label", ")", "]", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.TrainEvalModel.__init__": [[293, 307], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "feature_extractor", ",", "train_classifier", ",", "eval_classifier", ")", ":", "\n", "        ", "\"\"\"\n        :param feature_extractor: a differentiable feature extractor\n        :param train_classifier: a differentiable classifier used\n            during training\n        :param eval_classifier: a classifier used during testing.\n            Doesn't have to be differentiable.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "\n", "self", ".", "train_classifier", "=", "train_classifier", "\n", "self", ".", "eval_classifier", "=", "eval_classifier", "\n", "\n", "self", ".", "classifier", "=", "train_classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.TrainEvalModel.forward": [[308, 311], ["dynamic_modules.TrainEvalModel.feature_extractor", "dynamic_modules.TrainEvalModel.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "feature_extractor", "(", "x", ")", "\n", "return", "self", ".", "classifier", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.TrainEvalModel.train_adaptation": [[312, 314], ["None"], "methods", ["None"], ["", "def", "train_adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", "=", "None", ")", ":", "\n", "        ", "self", ".", "classifier", "=", "self", ".", "train_classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.dynamic_modules.TrainEvalModel.eval_adaptation": [[315, 317], ["None"], "methods", ["None"], ["", "def", "eval_adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", "=", "None", ")", ":", "\n", "        ", "self", ".", "classifier", "=", "self", ".", "eval_classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.LinearAdapter.__init__": [[15, 28], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "torch.nn.Linear", "torch.nn.Linear", "pnn.LinearAdapter.lat_layers.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features_per_column", ",", "num_prev_modules", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: size of each input sample\n        :param out_features_per_column: size of each output sample\n        :param num_prev_modules: number of previous modules\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Eq. 1 - lateral connections", "\n", "# one layer for each previous column. Empty for the first task.", "\n", "self", ".", "lat_layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "for", "_", "in", "range", "(", "num_prev_modules", ")", ":", "\n", "            ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features_per_column", ")", "\n", "self", ".", "lat_layers", ".", "append", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.LinearAdapter.forward": [[29, 35], ["enumerate", "sum", "len", "hs.append", "lat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "len", "(", "x", ")", "==", "self", ".", "num_prev_modules", "\n", "hs", "=", "[", "]", "\n", "for", "ii", ",", "lat", "in", "enumerate", "(", "self", ".", "lat_layers", ")", ":", "\n", "            ", "hs", ".", "append", "(", "lat", "(", "x", "[", "ii", "]", ")", ")", "\n", "", "return", "sum", "(", "hs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.MLPAdapter.__init__": [[41, 61], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features_per_column", ",", "num_prev_modules", ",", "\n", "activation", "=", "F", ".", "relu", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: size of each input sample\n        :param out_features_per_column: size of each output sample\n        :param num_prev_modules: number of previous modules\n        :param activation: activation function (default=ReLU)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_prev_modules", "=", "num_prev_modules", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "if", "num_prev_modules", "==", "0", ":", "\n", "            ", "return", "# first adapter is empty", "\n", "\n", "# Eq. 2 - MLP adapter. Not needed for the first task.", "\n", "", "self", ".", "V", "=", "nn", ".", "Linear", "(", "in_features", "*", "num_prev_modules", ",", "\n", "out_features_per_column", ")", "\n", "self", ".", "alphas", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "num_prev_modules", ")", ")", "\n", "self", ".", "U", "=", "nn", ".", "Linear", "(", "out_features_per_column", ",", "out_features_per_column", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.MLPAdapter.forward": [[62, 75], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pnn.MLPAdapter.U", "len", "len", "pnn.MLPAdapter.activation", "pnn.MLPAdapter.V"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "num_prev_modules", "==", "0", ":", "\n", "            ", "return", "0", "# first adapter is empty", "\n", "\n", "", "assert", "len", "(", "x", ")", "==", "self", ".", "num_prev_modules", "\n", "assert", "len", "(", "x", "[", "0", "]", ".", "shape", ")", "==", "2", ",", "\"Inputs to MLPAdapter should have two dimensions: \"", "\"<batch_size, num_features>.\"", "\n", "for", "i", ",", "el", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "x", "[", "i", "]", "=", "self", ".", "alphas", "[", "i", "]", "*", "el", "\n", "", "x", "=", "torch", ".", "cat", "(", "x", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "U", "(", "self", ".", "activation", "(", "self", ".", "V", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNColumn.__init__": [[81, 104], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "pnn.LinearAdapter", "pnn.MLPAdapter", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features_per_column", ",", "num_prev_modules", ",", "\n", "adapter", "=", "'mlp'", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: size of each input sample\n        :param out_features_per_column:\n            size of each output sample (single column)\n        :param num_prev_modules: number of previous columns\n        :param adapter: adapter type. One of {'linear', 'mlp'} (default='mlp')\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features_per_column", "=", "out_features_per_column", "\n", "self", ".", "num_prev_modules", "=", "num_prev_modules", "\n", "\n", "self", ".", "itoh", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features_per_column", ")", "\n", "if", "adapter", "==", "'linear'", ":", "\n", "            ", "self", ".", "adapter", "=", "LinearAdapter", "(", "in_features", ",", "out_features_per_column", ",", "\n", "num_prev_modules", ")", "\n", "", "elif", "adapter", "==", "'mlp'", ":", "\n", "            ", "self", ".", "adapter", "=", "MLPAdapter", "(", "in_features", ",", "out_features_per_column", ",", "\n", "num_prev_modules", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"`adapter` must be one of: {'mlp', `linear'}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNColumn.freeze": [[105, 108], ["pnn.PNNColumn.parameters"], "methods", ["None"], ["", "", "def", "freeze", "(", "self", ")", ":", "\n", "        ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNColumn.forward": [[109, 114], ["pnn.PNNColumn.adapter", "pnn.PNNColumn.itoh"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "prev_xs", ",", "last_x", "=", "x", "[", ":", "-", "1", "]", ",", "x", "[", "-", "1", "]", "\n", "hs", "=", "self", ".", "adapter", "(", "prev_xs", ")", "\n", "hs", "+=", "self", ".", "itoh", "(", "last_x", ")", "\n", "return", "hs", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer.__init__": [[123, 140], ["avalanche.models.MultiTaskModule.__init__", "pnn.PNNColumn", "torch.nn.ModuleList", "torch.nn.ModuleList"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features_per_column", ",", "adapter", "=", "'mlp'", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features: size of each input sample\n        :param out_features_per_column:\n            size of each output sample (single column)\n        :param adapter: adapter type. One of {'linear', 'mlp'} (default='mlp')\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features_per_column", "=", "out_features_per_column", "\n", "self", ".", "adapter", "=", "adapter", "\n", "\n", "# convert from task label to module list order", "\n", "self", ".", "task_to_module_idx", "=", "{", "}", "\n", "first_col", "=", "PNNColumn", "(", "in_features", ",", "out_features_per_column", ",", "\n", "0", ",", "adapter", "=", "adapter", ")", "\n", "self", ".", "columns", "=", "nn", ".", "ModuleList", "(", "[", "first_col", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer.num_columns": [[141, 144], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_columns", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer.train_adaptation": [[145, 177], ["super().train_adaptation", "isinstance", "next", "set", "len", "iter", "len", "pnn.PNNLayer._add_column"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer.train_adaptation", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer._add_column"], ["", "def", "train_adaptation", "(", "self", ",", "dataset", ":", "AvalancheDataset", ")", ":", "\n", "        ", "\"\"\" Training adaptation for PNN layer.\n\n        Adds an additional column to the layer.\n\n        :param dataset:\n        :return:\n        \"\"\"", "\n", "super", "(", ")", ".", "train_adaptation", "(", "dataset", ")", "\n", "task_labels", "=", "dataset", ".", "targets_task_labels", "\n", "if", "isinstance", "(", "task_labels", ",", "ConstantSequence", ")", ":", "\n", "# task label is unique. Don't check duplicates.", "\n", "            ", "task_labels", "=", "[", "task_labels", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "task_labels", "=", "set", "(", "task_labels", ")", "\n", "", "assert", "len", "(", "task_labels", ")", "==", "1", ",", "\"PNN assumes a single task for each experience. Please use a \"", "\"compatible benchmark.\"", "\n", "# extract task label from set", "\n", "task_label", "=", "next", "(", "iter", "(", "task_labels", ")", ")", "\n", "assert", "task_label", "not", "in", "self", ".", "task_to_module_idx", ",", "\"A new experience is using a previously seen task label. This is \"", "\"not compatible with PNN, which assumes different task labels for\"", "\" each training experience.\"", "\n", "\n", "if", "len", "(", "self", ".", "task_to_module_idx", ")", "==", "0", ":", "\n", "# we have already initialized the first column.", "\n", "# No need to call add_column here.", "\n", "            ", "self", ".", "task_to_module_idx", "[", "task_label", "]", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "task_to_module_idx", "[", "task_label", "]", "=", "self", ".", "num_columns", "\n", "self", ".", "_add_column", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer._add_column": [[178, 187], ["pnn.PNNLayer.parameters", "pnn.PNNLayer.columns.append", "pnn.PNNColumn"], "methods", ["None"], ["", "", "def", "_add_column", "(", "self", ")", ":", "\n", "        ", "\"\"\" Add a new column. \"\"\"", "\n", "# Freeze old parameters", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "columns", ".", "append", "(", "PNNColumn", "(", "self", ".", "in_features", ",", "\n", "self", ".", "out_features_per_column", ",", "\n", "self", ".", "num_columns", ",", "\n", "adapter", "=", "self", ".", "adapter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNNLayer.forward_single_task": [[188, 200], ["range", "hs.append"], "methods", ["None"], ["", "def", "forward_single_task", "(", "self", ",", "x", ",", "task_label", ")", ":", "\n", "        ", "\"\"\" Forward.\n\n        :param x: list of inputs.\n        :param task_label:\n        :return:\n        \"\"\"", "\n", "col_idx", "=", "self", ".", "task_to_module_idx", "[", "task_label", "]", "\n", "hs", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "col_idx", "+", "1", ")", ":", "\n", "            ", "hs", ".", "append", "(", "self", ".", "columns", "[", "ii", "]", "(", "x", "[", ":", "ii", "+", "1", "]", ")", ")", "\n", "", "return", "hs", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNN.__init__": [[210, 233], ["avalanche.models.MultiTaskModule.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "pnn.PNN.layers.append", "range", "avalanche.models.MultiHeadClassifier", "pnn.PNNLayer", "pnn.PNNLayer", "pnn.PNN.layers.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", "=", "1", ",", "in_features", "=", "784", ",", "\n", "hidden_features_per_column", "=", "100", ",", "adapter", "=", "'mlp'", ")", ":", "\n", "        ", "\"\"\"\n        :param num_layers: number of layers (default=1)\n        :param in_features: size of each input sample\n        :param hidden_features_per_column:\n            number of hidden units for each column\n        :param adapter: adapter type. One of {'linear', 'mlp'} (default='mlp')\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "num_layers", ">=", "1", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features_per_columns", "=", "hidden_features_per_column", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layers", ".", "append", "(", "PNNLayer", "(", "in_features", ",", "hidden_features_per_column", ")", ")", "\n", "for", "_", "in", "range", "(", "num_layers", "-", "1", ")", ":", "\n", "            ", "lay", "=", "PNNLayer", "(", "hidden_features_per_column", ",", "\n", "hidden_features_per_column", ",", "\n", "adapter", "=", "adapter", ")", "\n", "self", ".", "layers", ".", "append", "(", "lay", ")", "\n", "", "self", ".", "classifier", "=", "MultiHeadClassifier", "(", "hidden_features_per_column", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.pnn.PNN.forward_single_task": [[234, 251], ["x.view.view.contiguous", "x.view.view.view", "pnn.PNN.classifier", "x.view.view.size", "range", "torch.relu", "torch.relu", "lay"], "methods", ["None"], ["", "def", "forward_single_task", "(", "self", ",", "x", ",", "task_label", ")", ":", "\n", "        ", "\"\"\" Forward.\n\n        :param x:\n        :param task_label:\n        :return:\n        \"\"\"", "\n", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "in_features", ")", "\n", "\n", "num_columns", "=", "self", ".", "layers", "[", "0", "]", ".", "num_columns", "\n", "col_idx", "=", "self", ".", "layers", "[", "-", "1", "]", ".", "task_to_module_idx", "[", "task_label", "]", "\n", "\n", "x", "=", "[", "x", "for", "_", "in", "range", "(", "num_columns", ")", "]", "\n", "for", "lay", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "[", "F", ".", "relu", "(", "el", ")", "for", "el", "in", "lay", "(", "x", ",", "task_label", ")", "]", "\n", "", "return", "self", ".", "classifier", "(", "x", "[", "col_idx", "]", ",", "task_label", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_mlp.SimpleMLP.__init__": [[24, 48], ["super().__init__", "torch.Sequential", "range", "torch.Sequential", "torch.Linear", "torch.Sequential.add_module", "torch.Sequential", "torch.Linear", "torch.ReLU", "torch.Dropout", "torch.Linear", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "10", ",", "input_size", "=", "28", "*", "28", ",", "\n", "hidden_size", "=", "512", ",", "hidden_layers", "=", "1", ",", "drop_rate", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        :param num_classes: output size\n        :param input_size: input size\n        :param hidden_size: hidden layer size\n        :param hidden_layers: number of hidden layers\n        :param drop_rate: dropout rate. 0 to disable\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "nn", ".", "Sequential", "(", "*", "(", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", ")", ")", "\n", "for", "layer_idx", "in", "range", "(", "hidden_layers", "-", "1", ")", ":", "\n", "            ", "layers", ".", "add_module", "(", "\n", "f\"fc{layer_idx + 1}\"", ",", "nn", ".", "Sequential", "(", "\n", "*", "(", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ")", ")", ")", "\n", "\n", "", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "num_classes", ")", "\n", "self", ".", "_input_size", "=", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_mlp.SimpleMLP.forward": [[49, 55], ["simple_mlp.SimpleMLP.contiguous", "simple_mlp.SimpleMLP.view", "simple_mlp.SimpleMLP.features", "simple_mlp.SimpleMLP.classifier", "simple_mlp.SimpleMLP.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "_input_size", ")", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_mlp.SimpleMLP.get_features": [[56, 61], ["simple_mlp.SimpleMLP.contiguous", "simple_mlp.SimpleMLP.view", "simple_mlp.SimpleMLP.features", "simple_mlp.SimpleMLP.size"], "methods", ["None"], ["", "def", "get_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "_input_size", ")", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_mlp.MTSimpleMLP.__init__": [[65, 75], ["avalanche.models.dynamic_modules.MultiTaskModule.__init__", "torch.Sequential", "avalanche.models.dynamic_modules.MultiHeadClassifier", "torch.Linear", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "input_size", "=", "28", "*", "28", ",", "hidden_size", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", ")", "\n", "self", ".", "classifier", "=", "MultiHeadClassifier", "(", "hidden_size", ")", "\n", "self", ".", "_input_size", "=", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.simple_mlp.MTSimpleMLP.forward": [[76, 82], ["simple_mlp.MTSimpleMLP.contiguous", "simple_mlp.MTSimpleMLP.view", "simple_mlp.MTSimpleMLP.features", "simple_mlp.MTSimpleMLP.classifier", "simple_mlp.MTSimpleMLP.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "task_labels", ")", ":", "\n", "        ", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "_input_size", ")", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ",", "task_labels", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.batch_renorm.BatchRenorm2D.__init__": [[20, 58], ["torch.nn.Module.__init__", "torch.tensor", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.zeros", "running_mean.view", "torch.sqrt", "torch.ones", "gamma.view", "torch.zeros", "beta.view", "running_var.view"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "gamma", "=", "None", ",", "beta", "=", "None", ",", "\n", "running_mean", "=", "None", ",", "running_var", "=", "None", ",", "eps", "=", "1e-05", ",", "\n", "momentum", "=", "0.01", ",", "r_d_max_inc_step", "=", "0.0001", ",", "r_max", "=", "1.0", ",", "\n", "d_max", "=", "0.0", ",", "max_r_max", "=", "3.0", ",", "max_d_max", "=", "5.0", ")", ":", "\n", "        ", "super", "(", "BatchRenorm2D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "momentum", "=", "torch", ".", "tensor", "(", "momentum", ",", "requires_grad", "=", "False", ")", "\n", "\n", "if", "gamma", "is", "None", ":", "\n", "            ", "self", ".", "gamma", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "ones", "(", "(", "1", ",", "num_features", ",", "1", ",", "1", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma", "=", "torch", ".", "nn", ".", "Parameter", "(", "gamma", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ")", "\n", "", "if", "beta", "is", "None", ":", "\n", "            ", "self", ".", "beta", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "(", "1", ",", "num_features", ",", "1", ",", "1", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta", "=", "torch", ".", "nn", ".", "Parameter", "(", "beta", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ")", "\n", "\n", "", "if", "running_mean", "is", "None", ":", "\n", "            ", "self", ".", "running_avg_mean", "=", "torch", ".", "ones", "(", "\n", "(", "1", ",", "num_features", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "running_avg_std", "=", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "num_features", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "running_avg_mean", "=", "running_mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "running_avg_std", "=", "torch", ".", "sqrt", "(", "running_var", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ")", "\n", "\n", "", "self", ".", "max_r_max", "=", "max_r_max", "\n", "self", ".", "max_d_max", "=", "max_d_max", "\n", "\n", "self", ".", "r_max_inc_step", "=", "r_d_max_inc_step", "\n", "self", ".", "d_max_inc_step", "=", "r_d_max_inc_step", "\n", "\n", "self", ".", "r_max", "=", "r_max", "\n", "self", ".", "d_max", "=", "d_max", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.batch_renorm.BatchRenorm2D.forward": [[59, 99], ["torch.mean().to", "torch.sqrt", "batch_ch_std.to.to.to", "batch_renorm.BatchRenorm2D.running_avg_std.to", "batch_renorm.BatchRenorm2D.running_avg_mean.to", "batch_renorm.BatchRenorm2D.momentum.to", "torch.clamp().to().data.to", "torch.clamp().to().data.to", "torch.mean", "torch.var", "torch.clamp().to", "torch.clamp().to", "torch.mean().to.data.to", "batch_ch_std.to.to.data.to", "torch.clamp", "torch.clamp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "device", "=", "self", ".", "gamma", ".", "device", "\n", "\n", "batch_ch_mean", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "batch_ch_std", "=", "torch", ".", "sqrt", "(", "torch", ".", "var", "(", "\n", "x", ",", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ",", "unbiased", "=", "False", ")", "+", "self", ".", "eps", ")", "\n", "batch_ch_std", "=", "batch_ch_std", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "running_avg_std", "=", "self", ".", "running_avg_std", ".", "to", "(", "device", ")", "\n", "self", ".", "running_avg_mean", "=", "self", ".", "running_avg_mean", ".", "to", "(", "device", ")", "\n", "self", ".", "momentum", "=", "self", ".", "momentum", ".", "to", "(", "device", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "r", "=", "torch", ".", "clamp", "(", "batch_ch_std", "/", "self", ".", "running_avg_std", ",", "1.0", "/", "\n", "self", ".", "r_max", ",", "self", ".", "r_max", ")", ".", "to", "(", "device", ")", ".", "data", ".", "to", "(", "device", ")", "\n", "d", "=", "torch", ".", "clamp", "(", "(", "batch_ch_mean", "-", "self", ".", "running_avg_mean", ")", "/", "\n", "self", ".", "running_avg_std", ",", "-", "self", ".", "d_max", ",", "self", ".", "d_max", ")", ".", "to", "(", "device", ")", ".", "data", ".", "to", "(", "device", ")", "\n", "\n", "x", "=", "(", "(", "x", "-", "batch_ch_mean", ")", "*", "r", ")", "/", "batch_ch_std", "+", "d", "\n", "x", "=", "self", ".", "gamma", "*", "x", "+", "self", ".", "beta", "\n", "\n", "if", "self", ".", "r_max", "<", "self", ".", "max_r_max", ":", "\n", "                ", "self", ".", "r_max", "+=", "self", ".", "r_max_inc_step", "*", "x", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "d_max", "<", "self", ".", "max_d_max", ":", "\n", "                ", "self", ".", "d_max", "+=", "self", ".", "d_max_inc_step", "*", "x", ".", "shape", "[", "0", "]", "\n", "\n", "", "self", ".", "running_avg_mean", "=", "self", ".", "running_avg_mean", "+", "self", ".", "momentum", "*", "(", "batch_ch_mean", ".", "data", ".", "to", "(", "device", ")", "-", "self", ".", "running_avg_mean", ")", "\n", "self", ".", "running_avg_std", "=", "self", ".", "running_avg_std", "+", "self", ".", "momentum", "*", "(", "batch_ch_std", ".", "data", ".", "to", "(", "device", ")", "-", "self", ".", "running_avg_std", ")", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "x", "=", "(", "x", "-", "self", ".", "running_avg_mean", ")", "/", "self", ".", "running_avg_std", "\n", "x", "=", "self", ".", "gamma", "*", "x", "+", "self", ".", "beta", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.IdentityShortcut.__init__": [[13, 16], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "transform_function", ":", "Callable", "[", "[", "Tensor", "]", ",", "Tensor", "]", ")", ":", "\n", "        ", "super", "(", "IdentityShortcut", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform_function", "=", "transform_function", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.IdentityShortcut.forward": [[17, 19], ["icarl_resnet.IdentityShortcut.transform_function"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "return", "self", ".", "transform_function", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.ResidualBlock.__init__": [[33, 76], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "icarl_resnet.conv3x3", "icarl_resnet.batch_norm", "torch.nn.ReLU", "torch.nn.ReLU", "icarl_resnet.conv3x3", "icarl_resnet.batch_norm", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "icarl_resnet.batch_norm", "icarl_resnet.IdentityShortcut", "torch.nn.ConstantPad3d", "torch.nn.ConstantPad3d"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.conv3x3", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.batch_norm", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.conv3x3", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.batch_norm", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.batch_norm"], ["    ", "def", "__init__", "(", "self", ",", "input_num_filters", ":", "int", ",", "\n", "increase_dim", ":", "bool", "=", "False", ",", "\n", "projection", ":", "bool", "=", "False", ",", "\n", "last", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "last", ":", "bool", "=", "last", "\n", "\n", "if", "increase_dim", ":", "\n", "            ", "first_stride", "=", "(", "2", ",", "2", ")", "\n", "out_num_filters", "=", "input_num_filters", "*", "2", "\n", "", "else", ":", "\n", "            ", "first_stride", "=", "(", "1", ",", "1", ")", "\n", "out_num_filters", "=", "input_num_filters", "\n", "\n", "", "self", ".", "direct", "=", "Sequential", "(", "\n", "conv3x3", "(", "input_num_filters", ",", "out_num_filters", ",", "stride", "=", "first_stride", ")", ",", "\n", "batch_norm", "(", "out_num_filters", ")", ",", "\n", "ReLU", "(", "True", ")", ",", "\n", "conv3x3", "(", "out_num_filters", ",", "out_num_filters", ",", "stride", "=", "(", "1", ",", "1", ")", ")", ",", "\n", "batch_norm", "(", "out_num_filters", ")", ",", "\n", ")", "\n", "\n", "self", ".", "shortcut", ":", "Module", "\n", "\n", "# add shortcut connections", "\n", "if", "increase_dim", ":", "\n", "            ", "if", "projection", ":", "\n", "# projection shortcut, as option B in paper", "\n", "                ", "self", ".", "shortcut", "=", "Sequential", "(", "\n", "Conv2d", "(", "input_num_filters", ",", "out_num_filters", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "bias", "=", "False", ")", ",", "\n", "batch_norm", "(", "out_num_filters", ")", "\n", ")", "\n", "", "else", ":", "\n", "# identity shortcut, as option A in paper", "\n", "                ", "self", ".", "shortcut", "=", "Sequential", "(", "\n", "IdentityShortcut", "(", "lambda", "x", ":", "x", "[", ":", ",", ":", ",", ":", ":", "2", ",", ":", ":", "2", "]", ")", ",", "\n", "ConstantPad3d", "(", "(", "0", ",", "0", ",", "0", ",", "0", ",", "\n", "out_num_filters", "//", "4", ",", "\n", "out_num_filters", "//", "4", ")", ",", "0.0", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "shortcut", "=", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.ResidualBlock.forward": [[77, 82], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "icarl_resnet.ResidualBlock.direct", "icarl_resnet.ResidualBlock.shortcut", "icarl_resnet.ResidualBlock.direct", "icarl_resnet.ResidualBlock.shortcut"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "last", ":", "\n", "            ", "return", "self", ".", "direct", "(", "x", ")", "+", "self", ".", "shortcut", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "relu", "(", "self", ".", "direct", "(", "x", ")", "+", "self", ".", "shortcut", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.IcarlNet.__init__": [[85, 136], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "range", "torch.nn.Sequential", "torch.nn.Sequential", "range", "torch.nn.Sequential", "torch.nn.Sequential", "range", "layers_list.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "icarl_resnet.conv3x3", "icarl_resnet.batch_norm", "torch.nn.ReLU", "torch.nn.ReLU", "layers_list.append", "icarl_resnet.ResidualBlock", "layers_list.append", "icarl_resnet.ResidualBlock", "layers_list.append", "icarl_resnet.ResidualBlock", "torch.nn.modules.flatten.Flatten", "torch.nn.modules.flatten.Flatten", "icarl_resnet.ResidualBlock", "icarl_resnet.ResidualBlock", "icarl_resnet.ResidualBlock"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.conv3x3", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.batch_norm"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", ":", "int", ",", "n", "=", "5", ",", "c", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "is_train", "=", "True", "\n", "input_dims", "=", "c", "\n", "output_dims", "=", "16", "\n", "\n", "first_conv", "=", "Sequential", "(", "\n", "conv3x3", "(", "input_dims", ",", "output_dims", ",", "stride", "=", "(", "1", ",", "1", ")", ")", ",", "\n", "batch_norm", "(", "16", ")", ",", "\n", "ReLU", "(", "True", ")", "\n", ")", "\n", "\n", "input_dims", "=", "output_dims", "\n", "output_dims", "=", "16", "\n", "\n", "# first stack of residual blocks, output is 16 x 32 x 32", "\n", "layers_list", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "            ", "layers_list", ".", "append", "(", "ResidualBlock", "(", "input_dims", ")", ")", "\n", "", "first_block", "=", "Sequential", "(", "*", "layers_list", ")", "\n", "\n", "input_dims", "=", "output_dims", "\n", "output_dims", "=", "32", "\n", "\n", "# second stack of residual blocks, output is 32 x 16 x 16", "\n", "layers_list", "=", "[", "ResidualBlock", "(", "input_dims", ",", "increase_dim", "=", "True", ")", "]", "\n", "for", "_", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "            ", "layers_list", ".", "append", "(", "ResidualBlock", "(", "output_dims", ")", ")", "\n", "", "second_block", "=", "Sequential", "(", "*", "layers_list", ")", "\n", "\n", "input_dims", "=", "output_dims", "\n", "output_dims", "=", "64", "\n", "\n", "# third stack of residual blocks, output is 64 x 8 x 8", "\n", "layers_list", "=", "[", "ResidualBlock", "(", "input_dims", ",", "increase_dim", "=", "True", ")", "]", "\n", "for", "_", "in", "range", "(", "1", ",", "n", "-", "1", ")", ":", "\n", "            ", "layers_list", ".", "append", "(", "ResidualBlock", "(", "output_dims", ")", ")", "\n", "", "layers_list", ".", "append", "(", "ResidualBlock", "(", "output_dims", ",", "last", "=", "True", ")", ")", "\n", "third_block", "=", "Sequential", "(", "*", "layers_list", ")", "\n", "final_pool", "=", "AdaptiveAvgPool2d", "(", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "feature_extractor", "=", "Sequential", "(", "\n", "first_conv", ",", "first_block", ",", "\n", "second_block", ",", "third_block", ",", "\n", "final_pool", ",", "Flatten", "(", ")", ")", "\n", "\n", "input_dims", "=", "output_dims", "\n", "output_dims", "=", "num_classes", "\n", "\n", "self", ".", "classifier", "=", "Linear", "(", "input_dims", ",", "output_dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.IcarlNet.forward": [[137, 141], ["icarl_resnet.IcarlNet.feature_extractor", "icarl_resnet.IcarlNet.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "feature_extractor", "(", "x", ")", "# Already flattened", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.conv3x3": [[21, 25], ["torch.nn.Conv2d"], "function", ["None"], ["", "", "def", "conv3x3", "(", "in_planes", ":", "int", ",", "out_planes", ":", "int", ",", "\n", "stride", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", "]", "=", "1", ")", ":", "\n", "    ", "return", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.batch_norm": [[27, 29], ["torch.nn.BatchNorm2d"], "function", ["None"], ["", "def", "batch_norm", "(", "num_channels", ":", "int", ")", "->", "BatchNorm2d", ":", "\n", "    ", "return", "BatchNorm2d", "(", "num_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.make_icarl_net": [[143, 151], ["icarl_resnet.IcarlNet"], "function", ["None"], ["", "", "def", "make_icarl_net", "(", "num_classes", ":", "int", ",", "n", "=", "5", ",", "c", "=", "3", ")", "->", "IcarlNet", ":", "\n", "    ", "\"\"\"Create :py:class:`IcarlNet` network, the ResNet used in\n    ICarl.\n    :param num_classes: number of classes, network output size\n    :param n: depth of each residual blocks stack\n    :param c: number of input channels\n    \"\"\"", "\n", "return", "IcarlNet", "(", "num_classes", ",", "n", "=", "n", ",", "c", "=", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.icarl_resnet.initialize_icarl_net": [[153, 168], ["isinstance", "torch.nn.init.kaiming_normal_", "isinstance", "torch.nn.init.zeros_", "torch.nn.init.kaiming_normal_", "torch.nn.init.zeros_"], "function", ["None"], ["", "def", "initialize_icarl_net", "(", "m", ":", "Module", ")", ":", "\n", "    ", "\"\"\"Initialize the input network based on `kaiming_normal`\n    with `mode=fan_in` for `Conv2d` and `Linear` blocks.\n    Biases are initialized to zero.\n    :param m: input network (should be IcarlNet).\n    \"\"\"", "\n", "if", "isinstance", "(", "m", ",", "Conv2d", ")", ":", "\n", "        ", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "mode", "=", "'fan_in'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "zeros_", "(", "m", ".", "bias", ".", "data", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "m", ",", "Linear", ")", ":", "\n", "        ", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "mode", "=", "'fan_in'", ",", "nonlinearity", "=", "'sigmoid'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "zeros_", "(", "m", ".", "bias", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mlp_tiny_imagenet.SimpleMLP_TinyImageNet.__init__": [[20, 33], ["torch.Module.__init__", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "200", ",", "num_channels", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        :param num_classes: model output size\n        :param num_channels: number of input channels\n        \"\"\"", "\n", "super", "(", "SimpleMLP_TinyImageNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "num_channels", "*", "64", "*", "64", ",", "1024", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "1024", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mlp_tiny_imagenet.SimpleMLP_TinyImageNet.forward": [[34, 40], ["mlp_tiny_imagenet.SimpleMLP_TinyImageNet.contiguous", "mlp_tiny_imagenet.SimpleMLP_TinyImageNet.view", "mlp_tiny_imagenet.SimpleMLP_TinyImageNet.features", "mlp_tiny_imagenet.SimpleMLP_TinyImageNet.classifier", "mlp_tiny_imagenet.SimpleMLP_TinyImageNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.ncm_classifier.NCMClassifier.__init__": [[12, 19], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "class_mean", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param class_mean: tensor of dimension (num_classes x feature_size)\n            used to classify input patterns.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "class_means", "=", "class_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.ncm_classifier.NCMClassifier.forward": [[20, 24], ["torch.cdist", "torch.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "pred_inter", "=", "(", "x", ".", "T", "/", "torch", ".", "norm", "(", "x", ".", "T", ",", "dim", "=", "0", ")", ")", ".", "T", "\n", "sqd", "=", "torch", ".", "cdist", "(", "self", ".", "class_means", "[", ":", ",", ":", "]", ".", "T", ",", "pred_inter", ")", "\n", "return", "(", "-", "sqd", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mobilenetv1.MobilenetV1.__init__": [[54, 77], ["torch.Module.__init__", "pytorchcv.models.mobilenet.mobilenet_w1", "torch.AvgPool2d", "torch.AvgPool2d", "mobilenetv1.remove_sequential", "mobilenetv1.remove_DwsConvBlock", "enumerate", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "lat_list.append", "end_list.append"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mobilenetv1.remove_sequential", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mobilenetv1.remove_DwsConvBlock"], ["def", "__init__", "(", "self", ",", "pretrained", "=", "True", ",", "latent_layer_num", "=", "20", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "model", "=", "mobilenet_w1", "(", "pretrained", "=", "pretrained", ")", "\n", "model", ".", "features", ".", "final_pool", "=", "nn", ".", "AvgPool2d", "(", "4", ")", "\n", "\n", "all_layers", "=", "[", "]", "\n", "remove_sequential", "(", "model", ",", "all_layers", ")", "\n", "all_layers", "=", "remove_DwsConvBlock", "(", "all_layers", ")", "\n", "\n", "lat_list", "=", "[", "]", "\n", "end_list", "=", "[", "]", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "all_layers", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "if", "i", "<=", "latent_layer_num", ":", "\n", "                ", "lat_list", ".", "append", "(", "layer", ")", "\n", "", "else", ":", "\n", "                ", "end_list", ".", "append", "(", "layer", ")", "\n", "\n", "", "", "self", ".", "lat_features", "=", "nn", ".", "Sequential", "(", "*", "lat_list", ")", "\n", "self", ".", "end_features", "=", "nn", ".", "Sequential", "(", "*", "end_list", ")", "\n", "\n", "self", ".", "output", "=", "nn", ".", "Linear", "(", "1024", ",", "50", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mobilenetv1.MobilenetV1.forward": [[78, 97], ["mobilenetv1.MobilenetV1.end_features", "x.view.view.view", "mobilenetv1.MobilenetV1.output", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mobilenetv1.MobilenetV1.lat_features", "x.view.view.size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mobilenetv1.MobilenetV1.lat_features"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "latent_input", "=", "None", ",", "\n", "return_lat_acts", "=", "False", ")", ":", "\n", "\n", "        ", "if", "latent_input", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "orig_acts", "=", "self", ".", "lat_features", "(", "x", ")", "\n", "", "lat_acts", "=", "torch", ".", "cat", "(", "(", "orig_acts", ",", "latent_input", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "orig_acts", "=", "self", ".", "lat_features", "(", "x", ")", "\n", "lat_acts", "=", "orig_acts", "\n", "\n", "", "x", "=", "self", ".", "end_features", "(", "lat_acts", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "logits", "=", "self", ".", "output", "(", "x", ")", "\n", "\n", "if", "return_lat_acts", ":", "\n", "            ", "return", "logits", ",", "orig_acts", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mobilenetv1.remove_sequential": [[26, 36], ["network.children", "isinstance", "mobilenetv1.remove_sequential", "all_layers.append"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mobilenetv1.remove_sequential"], ["", "def", "remove_sequential", "(", "network", ",", "all_layers", ")", ":", "\n", "\n", "    ", "for", "layer", "in", "network", ".", "children", "(", ")", ":", "\n", "# if sequential layer, apply recursively to layers in sequential layer", "\n", "        ", "if", "isinstance", "(", "layer", ",", "nn", ".", "Sequential", ")", ":", "\n", "# print(layer)", "\n", "            ", "remove_sequential", "(", "layer", ",", "all_layers", ")", "\n", "", "else", ":", "# if leaf node, add it to list", "\n", "# print(layer)", "\n", "            ", "all_layers", ".", "append", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.mobilenetv1.remove_DwsConvBlock": [[38, 49], ["isinstance", "layer.children", "all_layers.append", "all_layers.append"], "function", ["None"], ["", "", "", "def", "remove_DwsConvBlock", "(", "cur_layers", ")", ":", "\n", "\n", "    ", "all_layers", "=", "[", "]", "\n", "for", "layer", "in", "cur_layers", ":", "\n", "        ", "if", "isinstance", "(", "layer", ",", "DwsConvBlock", ")", ":", "\n", "# print(\"helloooo: \", layer)", "\n", "            ", "for", "ch", "in", "layer", ".", "children", "(", ")", ":", "\n", "                ", "all_layers", ".", "append", "(", "ch", ")", "\n", "", "", "else", ":", "\n", "            ", "all_layers", ".", "append", "(", "layer", ")", "\n", "", "", "return", "all_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.base_model.BaseModel.get_features": [[9, 14], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "get_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Get features from model given input\n        \"\"\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.__init__": [[17, 23], ["torch.Module.__init__", "utils.FeatureExtractorBackbone.add_hooks"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.add_hooks"], ["\n", "", "class", "IterationsInsteadOfEpochs", "(", "StrategyPlugin", ")", ":", "\n", "    ", "\"\"\"Stop training based on number of iterations instead of epochs.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "max_iterations", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "max_iterations", ",", "int", ")", "and", "max_iterations", ">", "0", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.forward": [[24, 27], ["utils.FeatureExtractorBackbone.model"], "methods", ["None"], ["self", ".", "max_iterations", "=", "max_iterations", "\n", "\n", "", "def", "after_training_iteration", "(", "self", ",", "strategy", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "strategy", ".", "clock", ".", "train_exp_iterations", "==", "self", ".", "max_iterations", ":", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.get_name_to_module": [[28, 33], ["model.named_modules"], "methods", ["None"], ["            ", "print", "(", "f\"Stopping training, reached max iterations: {self.max_iterations}\"", ")", "\n", "strategy", ".", "stop_training", "(", ")", "\n", "\n", "\n", "", "", "", "class", "MetricOverSeed", ":", "\n", "    ", "logging_token", "=", "\"[SEED-AVGED-RESULTS]=\"", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.get_activation": [[34, 39], ["output.detach"], "methods", ["None"], ["logging_result_format", "=", "\"{:.5f}\\pm{:.5f}\"", "\n", "loggin_result_separator", "=", "\"\\t\"", "\n", "\n", "def", "__init__", "(", "self", ",", "name", ",", "extract_name", ",", "extract_idx", "=", "-", "1", ",", "mul_factor", "=", "100", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.add_hooks": [[40, 51], ["utils.FeatureExtractorBackbone.get_name_to_module", "name_to_module[].register_forward_hook", "utils.FeatureExtractorBackbone.get_activation"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.get_name_to_module", "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.FeatureExtractorBackbone.get_activation"], ["\n", "self", ".", "name", "=", "name", "\n", "self", ".", "extract_name", "=", "extract_name", "\n", "self", ".", "extract_idx", "=", "extract_idx", "\n", "self", ".", "mul_factor", "=", "mul_factor", "\n", "\n", "# Results appended sequentially", "\n", "self", ".", "seeds", "=", "[", "]", "\n", "self", ".", "seed_results", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.utils.avalanche_forward": [[4, 9], ["model", "model"], "function", ["None"], ["#", "\n", "#  Codebase of paper \"Continual evaluation for lifelong learning: Identifying the stability gap\",", "\n", "#  publicly available at https://arxiv.org/abs/2205.13452", "\n", "\n", "from", "typing", "import", "Union", ",", "TYPE_CHECKING", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.__init__": [[21, 59], ["avalanche.models.dynamic_modules.MultiTaskModule.__init__", "getattr", "isinstance", "setattr", "zip", "setattr", "isinstance", "avalanche.models.dynamic_modules.MultiHeadClassifier", "getattr().parameters", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.Sequential", "torch.Sequential", "NotImplementedError", "getattr.parameters", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "getattr", "old_classifier[].parameters", "type"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "classifier_name", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        :param model: pytorch nn.Module that does not support multitask\n        :param classifier_name: attribute name of the existing classification\n                                layer inside the module \n        \"\"\"", "\n", "self", ".", "__dict__", "[", "'_initialized'", "]", "=", "False", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "classifier_name", "=", "classifier_name", "\n", "\n", "old_classifier", "=", "getattr", "(", "model", ",", "classifier_name", ")", "\n", "\n", "if", "isinstance", "(", "old_classifier", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "in_size", "=", "old_classifier", ".", "in_features", "\n", "out_size", "=", "old_classifier", ".", "out_features", "\n", "old_params", "=", "[", "torch", ".", "clone", "(", "p", ".", "data", ")", "for", "p", "in", "\n", "old_classifier", ".", "parameters", "(", ")", "]", "\n", "# Replace old classifier by empty block", "\n", "setattr", "(", "self", ".", "model", ",", "classifier_name", ",", "nn", ".", "Sequential", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "old_classifier", ",", "nn", ".", "Sequential", ")", ":", "\n", "            ", "in_size", "=", "old_classifier", "[", "-", "1", "]", ".", "in_features", "\n", "out_size", "=", "old_classifier", "[", "-", "1", "]", ".", "out_features", "\n", "old_params", "=", "[", "torch", ".", "clone", "(", "p", ".", "data", ")", "for", "p", "in", "\n", "old_classifier", "[", "-", "1", "]", ".", "parameters", "(", ")", "]", "\n", "del", "old_classifier", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Cannot handle the following type \\\n            of classification layer {type(old_classifier)}\"", ")", "\n", "\n", "# Set new classifier and initialize to previous param values", "\n", "", "setattr", "(", "self", ",", "classifier_name", ",", "MultiHeadClassifier", "(", "in_size", ",", "out_size", ")", ")", "\n", "\n", "for", "param", ",", "param_old", "in", "zip", "(", "getattr", "(", "self", ",", "classifier_name", ")", ".", "parameters", "(", ")", ",", "old_params", ")", ":", "\n", "            ", "param", ".", "data", "=", "param_old", "\n", "\n", "", "self", ".", "_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.forward_single_task": [[60, 64], ["helper_method.MultiTaskDecorator.model", "getattr", "helper_method.MultiTaskDecorator.view", "helper_method.MultiTaskDecorator.size"], "methods", ["None"], ["", "def", "forward_single_task", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "task_label", ":", "int", ")", ":", "\n", "        ", "out", "=", "self", ".", "model", "(", "x", ")", "\n", "return", "getattr", "(", "self", ",", "self", ".", "classifier_name", ")", "(", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "\n", "task_labels", "=", "task_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.__getattr__": [[65, 79], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "# Override pytorch impl from nn.Module", "\n", "\n", "# Its a bit particular since pytorch nn.Module does not", "\n", "# keep some attributes in a classical manner in self.__dict__", "\n", "# rather it puts them into _parameters, _buffers and", "\n", "# _modules attributes. We have to add these lines to avoid recursion", "\n", "        ", "if", "name", "==", "'model'", ":", "\n", "            ", "return", "self", ".", "__dict__", "[", "'_modules'", "]", "[", "'model'", "]", "\n", "", "if", "name", "==", "self", ".", "classifier_name", ":", "\n", "            ", "return", "self", ".", "__dict__", "[", "'_modules'", "]", "[", "self", ".", "classifier_name", "]", "\n", "\n", "# If its a different attribute, return the one from the model", "\n", "", "return", "getattr", "(", "self", ".", "model", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.__setattr__": [[80, 86], ["avalanche.models.dynamic_modules.MultiTaskModule.__setattr__", "setattr"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.MultiTaskDecorator.__setattr__"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "# During initialization, use pytorch routine", "\n", "        ", "if", "not", "self", ".", "__dict__", "[", "'_initialized'", "]", "or", "name", "in", "self", ".", "__dict__", ":", "\n", "            ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "value", ")", "\n", "", "else", ":", "\n", "            ", "return", "setattr", "(", "self", ".", "model", ",", "name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.models.helper_method.as_multitask": [[88, 102], ["helper_method.MultiTaskDecorator"], "function", ["None"], ["", "", "", "def", "as_multitask", "(", "model", ":", "nn", ".", "Module", ",", "classifier_name", ":", "str", ")", "->", "MultiTaskModule", ":", "\n", "    ", "\"\"\" \n    Wraps around a model to make it a multitask model \n\n    :param model: model to be converted into MultiTaskModule\n    :param classifier_name: the name of the attribute containing \n                            the classification layer (nn.Linear). It can also \n                            be an instance of nn.Sequential containing multiple\n                            layers as long as the classification layer is the\n                            last layer.\n    :return the decorated model, now subclassing MultiTaskModule, and\n    accepting task_labels as forward() method argument\n    \"\"\"", "\n", "return", "MultiTaskDecorator", "(", "model", ",", "classifier_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.default_cm_image_creator": [[30, 116], ["matplotlib.subplots", "confusion_matrix_tensor.numpy", "ax.imshow", "fig.colorbar", "ax.set", "ax.set_ylim", "matplotlib.setp", "matplotlib.setp", "fig.tight_layout", "ax.imshow.cmap", "ax.imshow.cmap", "numpy.empty_like", "range", "numpy.arange", "ax.set_title", "ax.get_xticklabels", "ax.get_yticklabels", "range", "numpy.arange", "numpy.arange", "confusion_matrix_tensor.numpy.max", "confusion_matrix_tensor.numpy.min", "ax.text", "format", "format", "format", "len", "len"], "function", ["None"], ["def", "default_cm_image_creator", "(", "confusion_matrix_tensor", ":", "Tensor", ",", "\n", "display_labels", ":", "Sequence", "=", "None", ",", "\n", "include_values", "=", "False", ",", "\n", "xticks_rotation", "=", "0", ",", "\n", "yticks_rotation", "=", "0", ",", "\n", "values_format", "=", "None", ",", "\n", "cmap", "=", "'viridis'", ",", "\n", "image_title", "=", "''", ")", ":", "\n", "    ", "\"\"\"\n    The default Confusion Matrix image creator.\n    Code adapted from\n    `Scikit learn <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html>`_ # noqa\n\n    :param confusion_matrix_tensor: The tensor describing the confusion matrix.\n        This can be easily obtained through Scikit-learn `confusion_matrix`\n        utility.\n    :param display_labels: Target names used for plotting. By default, `labels`\n        will be used if it is defined, otherwise the values will be inferred by\n        the matrix tensor.\n    :param include_values: Includes values in confusion matrix. Defaults to\n        `False`.\n    :param xticks_rotation: Rotation of xtick labels. Valid values are\n        float point value. Defaults to 0.\n    :param yticks_rotation: Rotation of ytick labels. Valid values are\n        float point value. Defaults to 0.\n    :param values_format: Format specification for values in confusion matrix.\n        Defaults to `None`, which means that the format specification is\n        'd' or '.2g', whichever is shorter.\n    :param cmap: Must be a str or a Colormap recognized by matplotlib.\n        Defaults to 'viridis'.\n    :param image_title: The title of the image. Defaults to an empty string.\n    :return: The Confusion Matrix as a PIL Image.\n    \"\"\"", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "cm", "=", "confusion_matrix_tensor", ".", "numpy", "(", ")", "\n", "n_classes", "=", "cm", ".", "shape", "[", "0", "]", "\n", "im_", "=", "ax", ".", "imshow", "(", "cm", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cmap", ")", "\n", "cmap_min", ",", "cmap_max", "=", "im_", ".", "cmap", "(", "0", ")", ",", "im_", ".", "cmap", "(", "256", ")", "\n", "\n", "if", "include_values", ":", "\n", "        ", "text_", "=", "np", ".", "empty_like", "(", "cm", ",", "dtype", "=", "object", ")", "\n", "\n", "# print text with appropriate color depending on background", "\n", "thresh", "=", "(", "cm", ".", "max", "(", ")", "+", "cm", ".", "min", "(", ")", ")", "/", "2.0", "\n", "\n", "for", "i", "in", "range", "(", "n_classes", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "n_classes", ")", ":", "\n", "                ", "color", "=", "cmap_max", "if", "cm", "[", "i", ",", "j", "]", "<", "thresh", "else", "cmap_min", "\n", "\n", "if", "values_format", "is", "None", ":", "\n", "                    ", "text_cm", "=", "format", "(", "cm", "[", "i", ",", "j", "]", ",", "'.2g'", ")", "\n", "if", "cm", ".", "dtype", ".", "kind", "!=", "'f'", ":", "\n", "                        ", "text_d", "=", "format", "(", "cm", "[", "i", ",", "j", "]", ",", "'d'", ")", "\n", "if", "len", "(", "text_d", ")", "<", "len", "(", "text_cm", ")", ":", "\n", "                            ", "text_cm", "=", "text_d", "\n", "", "", "", "else", ":", "\n", "                    ", "text_cm", "=", "format", "(", "cm", "[", "i", ",", "j", "]", ",", "values_format", ")", "\n", "\n", "", "text_", "[", "i", ",", "j", "]", "=", "ax", ".", "text", "(", "\n", "j", ",", "i", ",", "text_cm", ",", "\n", "ha", "=", "\"center\"", ",", "va", "=", "\"center\"", ",", "\n", "color", "=", "color", ")", "\n", "\n", "", "", "", "if", "display_labels", "is", "None", ":", "\n", "        ", "display_labels", "=", "np", ".", "arange", "(", "n_classes", ")", "\n", "\n", "", "fig", ".", "colorbar", "(", "im_", ",", "ax", "=", "ax", ")", "\n", "\n", "ax", ".", "set", "(", "xticks", "=", "np", ".", "arange", "(", "n_classes", ")", ",", "\n", "yticks", "=", "np", ".", "arange", "(", "n_classes", ")", ",", "\n", "xticklabels", "=", "display_labels", ",", "\n", "yticklabels", "=", "display_labels", ",", "\n", "ylabel", "=", "\"True label\"", ",", "\n", "xlabel", "=", "\"Predicted label\"", ")", "\n", "\n", "if", "image_title", "!=", "''", ":", "\n", "        ", "ax", ".", "set_title", "(", "image_title", ")", "\n", "\n", "", "ax", ".", "set_ylim", "(", "(", "n_classes", "-", "0.5", ",", "-", "0.5", ")", ")", "\n", "plt", ".", "setp", "(", "ax", ".", "get_xticklabels", "(", ")", ",", "rotation", "=", "xticks_rotation", ")", "\n", "plt", ".", "setp", "(", "ax", ".", "get_yticklabels", "(", ")", ",", "rotation", "=", "yticks_rotation", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.repartition_pie_chart_image_creator": [[132, 157], ["matplotlib.subplots", "zip", "ax.pie", "fig.tight_layout", "label2counts.items"], "function", ["None"], ["def", "repartition_pie_chart_image_creator", "(", "\n", "label2counts", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", ",", "\n", "counters", ":", "List", "[", "int", "]", ",", "\n", "colors", ":", "Union", "[", "ndarray", ",", "Iterable", ",", "int", ",", "float", "]", "=", "SEABORN_COLORS", ",", "\n", "fmt", ":", "str", "=", "\"%1.1f%%\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Create a pie chart representing the labels repartition.\n\n    :param label2counts: A dict holding the counts for each label, of the form\n        {label: [count_at_step_0, count_at_step_1, ...]}. Only the last count of\n        each label is used here.\n    :param counters: (unused) The steps the counts were taken at.\n    :param colors: The colors to use in the chart.\n    :param fmt: Formatting used to display the text values in the chart.\n    \"\"\"", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "ax", ":", "Axes", "\n", "\n", "labels", ",", "counts", "=", "zip", "(", "*", "(", "(", "label", ",", "c", "[", "-", "1", "]", ")", "for", "label", ",", "c", "in", "label2counts", ".", "items", "(", ")", ")", ")", "\n", "\n", "ax", ".", "pie", "(", "counts", ",", "labels", "=", "labels", ",", "autopct", "=", "fmt", ",", "colors", "=", "colors", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.repartition_bar_chart_image_creator": [[159, 192], ["matplotlib.subplots", "zip", "sum", "ax.barh", "ax.set_yticks", "ax.set_yticklabels", "ax.set_xlabel", "ax.set_ylabel", "enumerate", "fig.tight_layout", "numpy.arange", "ax.text", "len", "label2counts.items"], "function", ["None"], ["", "def", "repartition_bar_chart_image_creator", "(", "\n", "label2counts", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", ",", "\n", "counters", ":", "List", "[", "int", "]", ",", "\n", "colors", ":", "Union", "[", "ndarray", ",", "Iterable", ",", "int", ",", "float", "]", "=", "SEABORN_COLORS", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Create a bar chart representing the labels repartition.\n\n    :param label2counts: A dict holding the counts for each label, of the form\n        {label: [count_at_step_0, count_at_step_1, ...]}. Only the last count of\n        each label is used here.\n    :param counters: (unused) The steps the counts were taken at.\n    :param colors: The colors to use in the chart.\n    \"\"\"", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "ax", ":", "Axes", "\n", "\n", "y", "=", "-", "arange", "(", "len", "(", "label2counts", ")", ")", "\n", "labels", ",", "counts", "=", "zip", "(", "*", "(", "(", "label", ",", "c", "[", "-", "1", "]", ")", "for", "label", ",", "c", "in", "label2counts", ".", "items", "(", ")", ")", ")", "\n", "total", "=", "sum", "(", "counts", ")", "\n", "\n", "ax", ".", "barh", "(", "y", ",", "width", "=", "counts", ",", "color", "=", "colors", ")", "\n", "ax", ".", "set_yticks", "(", "y", ")", "\n", "ax", ".", "set_yticklabels", "(", "labels", ")", "\n", "\n", "ax", ".", "set_xlabel", "(", "\"Number of exemplars\"", ")", "\n", "ax", ".", "set_ylabel", "(", "\"Class\"", ")", "\n", "\n", "for", "i", ",", "count", "in", "enumerate", "(", "counts", ")", ":", "\n", "        ", "ax", ".", "text", "(", "count", "/", "2", ",", "-", "i", ",", "f\"{count/total:.1%}\"", ",", "va", "=", "\"center\"", ",", "ha", "=", "\"center\"", ")", "\n", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.default_history_repartition_image_creator": [[194, 222], ["matplotlib.subplots", "ax.stackplot", "ax.legend", "ax.set_ylabel", "ax.set_xlabel", "fig.tight_layout", "label2counts.values", "label2counts.keys"], "function", ["None"], ["", "def", "default_history_repartition_image_creator", "(", "\n", "label2counts", ":", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", ",", "\n", "counters", ":", "List", "[", "int", "]", ",", "\n", "colors", ":", "Union", "[", "ndarray", ",", "Iterable", ",", "int", ",", "float", "]", "=", "SEABORN_COLORS", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Create a stack plot representing the labels repartition with their history.\n\n    :param label2counts: A dict holding the counts for each label, of the form\n        {label: [count_at_step_0, count_at_step_1, ...]}.\n    :param counters: The steps the counts were taken at.\n    :param colors: The colors to use in the chart.\n    \"\"\"", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "ax", ":", "Axes", "\n", "\n", "ax", ".", "stackplot", "(", "\n", "counters", ",", "\n", "label2counts", ".", "values", "(", ")", ",", "\n", "labels", "=", "label2counts", ".", "keys", "(", ")", ",", "\n", "colors", "=", "colors", ",", "\n", ")", "\n", "ax", ".", "legend", "(", "loc", "=", "'upper left'", ")", "\n", "ax", ".", "set_ylabel", "(", "\"Number of examples\"", ")", "\n", "ax", ".", "set_xlabel", "(", "\"step\"", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type": [[224, 233], ["None"], "function", ["None"], ["", "def", "stream_type", "(", "experience", ":", "'Experience'", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Returns the stream name from which the experience belongs to.\n    e.g. the experience can be part of train or test stream.\n\n    :param experience: the instance of the experience\n    \"\"\"", "\n", "\n", "return", "experience", ".", "origin_stream", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task": [[235, 259], ["len"], "function", ["None"], ["", "def", "phase_and_task", "(", "strategy", ":", "'BaseStrategy'", ")", "->", "Tuple", "[", "str", ",", "int", "]", ":", "\n", "    ", "\"\"\"\n    Returns the current phase name and the associated task label.\n\n    The current task label depends on the phase. During the training\n    phase, the task label is the one defined in the \"train_task_label\"\n    field. On the contrary, during the eval phase the task label is the one\n    defined in the \"eval_task_label\" field.\n\n    :param strategy: The strategy instance to get the task label from.\n    :return: The current phase name as either \"Train\" or \"Task\" and the\n        associated task label.\n    \"\"\"", "\n", "\n", "task", "=", "strategy", ".", "experience", ".", "task_labels", "\n", "if", "len", "(", "task", ")", ">", "1", ":", "\n", "        ", "task", "=", "None", "# task labels per patterns", "\n", "", "else", ":", "\n", "        ", "task", "=", "task", "[", "0", "]", "\n", "\n", "", "if", "strategy", ".", "is_eval", ":", "\n", "        ", "return", "EVAL", ",", "task", "\n", "", "else", ":", "\n", "        ", "return", "TRAIN", ",", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.bytes2human": [[261, 276], ["enumerate", "reversed", "float"], "function", ["None"], ["", "", "def", "bytes2human", "(", "n", ")", ":", "\n", "# http://code.activestate.com/recipes/578019", "\n", "# >>> bytes2human(10000)", "\n", "# '9.8K'", "\n", "# >>> bytes2human(100001221)", "\n", "# '95.4M'", "\n", "    ", "symbols", "=", "(", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", ",", "'E'", ",", "'Z'", ",", "'Y'", ")", "\n", "prefix", "=", "{", "}", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "symbols", ")", ":", "\n", "        ", "prefix", "[", "s", "]", "=", "1", "<<", "(", "i", "+", "1", ")", "*", "10", "\n", "", "for", "s", "in", "reversed", "(", "symbols", ")", ":", "\n", "        ", "if", "n", ">=", "prefix", "[", "s", "]", ":", "\n", "            ", "value", "=", "float", "(", "n", ")", "/", "prefix", "[", "s", "]", "\n", "return", "'%.1f%s'", "%", "(", "value", ",", "s", ")", "\n", "", "", "return", "\"%sB\"", "%", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name": [[278, 324], ["metric_utils.phase_and_task", "metric_utils.stream_type", "str", "isinstance", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type"], ["", "def", "get_metric_name", "(", "metric", ":", "'PluginMetric'", ",", "\n", "strategy", ":", "'BaseStrategy'", ",", "\n", "add_experience", "=", "False", ",", "\n", "add_task", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Return the complete metric name used to report its current value.\n    The name is composed by:\n    metric string representation /phase type/stream type/task id\n    where metric string representation is a synthetic string\n    describing the metric, phase type describe if the user\n    is training (train) or evaluating (eval), stream type describes\n    the type of stream the current experience belongs to (e.g. train, test)\n    and task id is the current task label.\n\n    :param metric: the metric object for which return the complete name\n    :param strategy: the current strategy object\n    :param add_experience: if True, add eval_exp_id to the main metric name.\n            Default to False.\n    :param add_task: if True the main metric name will include the task\n        information. If False, no task label will be displayed.\n        If an int, that value will be used as task label for the metric name.\n    \"\"\"", "\n", "\n", "phase_name", ",", "task_label", "=", "phase_and_task", "(", "strategy", ")", "\n", "stream", "=", "stream_type", "(", "strategy", ".", "experience", ")", "\n", "base_name", "=", "'{}/{}_phase/{}_stream'", ".", "format", "(", "str", "(", "metric", ")", ",", "\n", "phase_name", ",", "stream", ")", "\n", "exp_name", "=", "'/Exp{:03}'", ".", "format", "(", "strategy", ".", "experience", ".", "current_experience", ")", "\n", "\n", "if", "task_label", "is", "None", "and", "isinstance", "(", "add_task", ",", "bool", ")", ":", "\n", "        ", "add_task", "=", "False", "\n", "", "else", ":", "\n", "        ", "if", "isinstance", "(", "add_task", ",", "bool", ")", "and", "add_task", ":", "\n", "            ", "task_name", "=", "'/Task{:03}'", ".", "format", "(", "task_label", ")", "\n", "", "elif", "isinstance", "(", "add_task", ",", "int", ")", ":", "\n", "            ", "task_name", "=", "'/Task{:03}'", ".", "format", "(", "add_task", ")", "\n", "add_task", "=", "True", "\n", "\n", "", "", "if", "add_experience", "and", "not", "add_task", ":", "\n", "        ", "return", "base_name", "+", "exp_name", "\n", "", "elif", "add_experience", "and", "add_task", ":", "\n", "        ", "return", "base_name", "+", "task_name", "+", "exp_name", "\n", "", "elif", "not", "add_experience", "and", "not", "add_task", ":", "\n", "        ", "return", "base_name", "\n", "", "elif", "not", "add_experience", "and", "add_task", ":", "\n", "        ", "return", "base_name", "+", "task_name", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.plot_utils.learning_curves_plot": [[14, 31], ["list", "matplotlib.subplots", "ax.legend", "ax.set_xlabel", "ax.set_ylabel", "filter", "matplotlib.plot", "all_metrics.keys", "ak.split"], "function", ["None"], ["def", "learning_curves_plot", "(", "all_metrics", ")", ":", "\n", "    ", "\"\"\" Creates a plot with separate learning curves for each experience.\n\n    :param all_metrics: Dictionary of metrics as returned by\n        EvaluationPlugin.get_all_metrics\n    :return: matplotlib figure\n    \"\"\"", "\n", "accs_keys", "=", "list", "(", "filter", "(", "lambda", "x", ":", "'Top1_Acc_Exp'", "in", "x", ",", "all_metrics", ".", "keys", "(", ")", ")", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "for", "ak", "in", "accs_keys", ":", "\n", "        ", "k", "=", "ak", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "x", ",", "y", "=", "all_metrics", "[", "ak", "]", "\n", "plt", ".", "plot", "(", "x", ",", "y", ",", "label", "=", "k", ")", "\n", "", "ax", ".", "legend", "(", ")", "\n", "ax", ".", "set_xlabel", "(", "\"Iterations\"", ")", "\n", "ax", ".", "set_ylabel", "(", "\"Experience Accuracy\"", ")", "\n", "return", "fig", "\n", "", ""]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_results.TensorImage.__array__": [[28, 30], ["metric_results.TensorImage.image.numpy"], "methods", ["None"], ["def", "__array__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "image", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_results.AlternativeValues.__init__": [[39, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "alternatives", ":", "MetricType", ")", ":", "\n", "        ", "self", ".", "alternatives", ":", "Tuple", "[", "MetricType", "]", "=", "alternatives", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_results.AlternativeValues.best_supported_value": [[42, 55], ["isinstance"], "methods", ["None"], ["", "def", "best_supported_value", "(", "self", ",", "*", "supported_types", ":", "type", ")", "->", "Optional", "[", "MetricType", "]", ":", "\n", "        ", "\"\"\"\n        Retrieves a supported representation for this metric value.\n\n        :param supported_types: A list of supported value types.\n        :return: The best supported representation. Returns None if no supported\n            representation is found.\n        \"\"\"", "\n", "for", "alternative", "in", "self", ".", "alternatives", ":", "\n", "            ", "if", "isinstance", "(", "alternative", ",", "supported_types", ")", ":", "\n", "                ", "return", "alternative", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_results.MetricValue.__init__": [[70, 95], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "origin", ":", "'Metric'", ",", "name", ":", "str", ",", "\n", "value", ":", "Union", "[", "MetricType", ",", "AlternativeValues", "]", ",", "x_plot", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of MetricValue.\n\n        :param origin: The originating Metric instance.\n        :param name: The display name of this value. This value roughly\n            corresponds to the name of the plot in which the value should\n            be logged.\n        :param value: The value of the metric. Can be a scalar value,\n            a PIL Image, or a Tensor. If more than a possible representation\n            of the same value exist, an instance of :class:`AlternativeValues`\n            can be passed. For instance, the Confusion Matrix can be represented\n            both as an Image and a Tensor, in which case an instance of\n            :class:`AlternativeValues` carrying both the Tensor and the Image\n            is more appropriate. The Logger instance will then select the most\n            appropriate way to log the metric according to its capabilities.\n        :param x_plot: The position of the value. This value roughly corresponds\n            to the x-axis position of the value in a plot. When logging a\n            singleton value, pass 0 as a value for this parameter.\n        \"\"\"", "\n", "self", ".", "origin", ":", "'Metric'", "=", "origin", "\n", "self", ".", "name", ":", "str", "=", "name", "\n", "self", ".", "value", ":", "Union", "[", "MetricType", ",", "AlternativeValues", "]", "=", "value", "\n", "self", ".", "x_plot", ":", "int", "=", "x_plot", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.Metric.result": [[49, 56], ["None"], "methods", ["None"], ["def", "result", "(", "self", ",", "**", "kwargs", ")", "->", "Optional", "[", "TResult", "]", ":", "\n", "        ", "\"\"\"\n        Obtains the value of the metric.\n\n        :return: The value of the metric.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.Metric.reset": [[57, 64], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric internal state.\n\n        :return: None.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.__init__": [[83, 91], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of a plugin metric.\n\n        Child classes can safely invoke this (super) constructor as the first\n        experience.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.result": [[92, 95], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "result", "(", "self", ",", "**", "kwargs", ")", "->", "Optional", "[", "TResult", "]", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.reset": [[96, 99], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_training": [[100, 102], ["None"], "methods", ["None"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_training_exp": [[103, 106], ["None"], "methods", ["None"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_train_dataset_adaptation": [[107, 110], ["None"], "methods", ["None"], ["", "def", "before_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_train_dataset_adaptation": [[111, 114], ["None"], "methods", ["None"], ["", "def", "after_train_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_training_epoch": [[115, 118], ["None"], "methods", ["None"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_training_iteration": [[119, 122], ["None"], "methods", ["None"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_forward": [[123, 125], ["None"], "methods", ["None"], ["", "def", "before_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_forward": [[126, 128], ["None"], "methods", ["None"], ["", "def", "after_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_backward": [[129, 131], ["None"], "methods", ["None"], ["", "def", "before_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_backward": [[132, 134], ["None"], "methods", ["None"], ["", "def", "after_backward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_training_iteration": [[135, 138], ["None"], "methods", ["None"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_update": [[139, 141], ["None"], "methods", ["None"], ["", "def", "before_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_update": [[142, 144], ["None"], "methods", ["None"], ["", "def", "after_update", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_training_epoch": [[145, 148], ["None"], "methods", ["None"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_training_exp": [[149, 152], ["None"], "methods", ["None"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_training": [[153, 155], ["None"], "methods", ["None"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_eval": [[156, 158], ["None"], "methods", ["None"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_eval_dataset_adaptation": [[159, 162], ["None"], "methods", ["None"], ["", "def", "before_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_eval_dataset_adaptation": [[163, 166], ["None"], "methods", ["None"], ["", "def", "after_eval_dataset_adaptation", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_eval_exp": [[167, 169], ["None"], "methods", ["None"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_eval_exp": [[170, 172], ["None"], "methods", ["None"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_eval": [[173, 175], ["None"], "methods", ["None"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_eval_iteration": [[176, 179], ["None"], "methods", ["None"], ["", "def", "before_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.before_eval_forward": [[180, 183], ["None"], "methods", ["None"], ["", "def", "before_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_eval_forward": [[184, 187], ["None"], "methods", ["None"], ["", "def", "after_eval_forward", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.PluginMetric.after_eval_iteration": [[188, 191], ["None"], "methods", ["None"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.__init__": [[199, 213], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "metric", ",", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "\n", "mode", "=", "'eval'", ")", ":", "\n", "        ", "super", "(", "GenericPluginMetric", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "mode", "in", "{", "'train'", ",", "'eval'", "}", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "assert", "reset_at", "in", "{", "'iteration'", ",", "'epoch'", ",", "'experience'", ",", "'stream'", "}", "\n", "assert", "emit_at", "in", "{", "'iteration'", ",", "'epoch'", ",", "'experience'", ",", "'stream'", "}", "\n", "", "else", ":", "\n", "            ", "assert", "reset_at", "in", "{", "'iteration'", ",", "'experience'", ",", "'stream'", "}", "\n", "assert", "emit_at", "in", "{", "'iteration'", ",", "'experience'", ",", "'stream'", "}", "\n", "", "self", ".", "_metric", "=", "metric", "\n", "self", ".", "_reset_at", "=", "reset_at", "\n", "self", ".", "_emit_at", "=", "emit_at", "\n", "self", ".", "_mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.reset": [[214, 216], ["metric_definitions.GenericPluginMetric._metric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "self", ".", "_metric", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.result": [[217, 219], ["metric_definitions.GenericPluginMetric._metric.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "return", "self", ".", "_metric", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.update": [[220, 222], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric._package_result": [[223, 242], ["metric_definitions.GenericPluginMetric.result", "isinstance", "metric_definitions.GenericPluginMetric.items", "metric_utils.get_metric_name", "metric_utils.get_metric_name", "metrics.append", "metric_results.MetricValue", "metric_results.MetricValue"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "metric_value", "=", "self", ".", "result", "(", "strategy", ")", "\n", "add_exp", "=", "self", ".", "_emit_at", "==", "'experience'", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "\n", "\n", "if", "isinstance", "(", "metric_value", ",", "dict", ")", ":", "\n", "            ", "metrics", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "metric_value", ".", "items", "(", ")", ":", "\n", "                ", "metric_name", "=", "get_metric_name", "(", "\n", "self", ",", "strategy", ",", "add_experience", "=", "add_exp", ",", "add_task", "=", "k", ")", "\n", "metrics", ".", "append", "(", "MetricValue", "(", "self", ",", "metric_name", ",", "v", ",", "\n", "plot_x_position", ")", ")", "\n", "", "return", "metrics", "\n", "", "else", ":", "\n", "            ", "metric_name", "=", "get_metric_name", "(", "self", ",", "strategy", ",", "\n", "add_experience", "=", "add_exp", ",", "\n", "add_task", "=", "True", ")", "\n", "return", "[", "MetricValue", "(", "self", ",", "metric_name", ",", "metric_value", ",", "\n", "plot_x_position", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_training": [[243, 247], ["super().before_training", "metric_definitions.GenericPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ")", "\n", "if", "self", ".", "_reset_at", "==", "'stream'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_training_exp": [[248, 252], ["super().before_training_exp", "metric_definitions.GenericPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_exp", "(", "strategy", ")", "\n", "if", "self", ".", "_reset_at", "==", "'experience'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_training_epoch": [[253, 257], ["super().before_training_epoch", "metric_definitions.GenericPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_epoch", "(", "strategy", ")", "\n", "if", "self", ".", "_reset_at", "==", "'epoch'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_training_iteration": [[258, 262], ["super().before_training_iteration", "metric_definitions.GenericPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_iteration", "(", "strategy", ")", "\n", "if", "self", ".", "_reset_at", "==", "'iteration'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.after_training_iteration": [[263, 269], ["super().after_training_iteration", "metric_definitions.GenericPluginMetric.update", "metric_definitions.GenericPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "after_training_iteration", "(", "strategy", ")", "\n", "if", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "self", ".", "update", "(", "strategy", ")", "\n", "", "if", "self", ".", "_emit_at", "==", "'iteration'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.after_training_epoch": [[270, 274], ["super().after_training_epoch", "metric_definitions.GenericPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.after_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training_epoch", "(", "strategy", ")", "\n", "if", "self", ".", "_emit_at", "==", "'epoch'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.after_training_exp": [[275, 279], ["super().after_training_exp", "metric_definitions.GenericPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.after_training_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training_exp", "(", "strategy", ")", "\n", "if", "self", ".", "_emit_at", "==", "'experience'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.after_training": [[280, 284], ["super().after_training", "metric_definitions.GenericPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.after_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training", "(", "strategy", ")", "\n", "if", "self", ".", "_emit_at", "==", "'stream'", "and", "self", ".", "_mode", "==", "'train'", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_eval": [[285, 289], ["super().before_eval", "metric_definitions.GenericPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "if", "self", ".", "_reset_at", "==", "'stream'", "and", "self", ".", "_mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_eval_exp": [[290, 294], ["super().before_eval_exp", "metric_definitions.GenericPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval_exp", "(", "strategy", ")", "\n", "if", "self", ".", "_reset_at", "==", "'experience'", "and", "self", ".", "_mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.after_eval_exp": [[295, 299], ["super().after_eval_exp", "metric_definitions.GenericPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.after_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_eval_exp", "(", "strategy", ")", "\n", "if", "self", ".", "_emit_at", "==", "'experience'", "and", "self", ".", "_mode", "==", "'eval'", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.after_eval": [[300, 304], ["super().after_eval", "metric_definitions.GenericPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_eval", "(", "strategy", ")", "\n", "if", "self", ".", "_emit_at", "==", "'stream'", "and", "self", ".", "_mode", "==", "'eval'", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.after_eval_iteration": [[305, 311], ["super().after_eval_iteration", "metric_definitions.GenericPluginMetric.update", "metric_definitions.GenericPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_eval_iteration", "(", "strategy", ")", "\n", "if", "self", ".", "_mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "update", "(", "strategy", ")", "\n", "", "if", "self", ".", "_emit_at", "==", "'iteration'", "and", "self", ".", "_mode", "==", "'eval'", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_eval_iteration": [[312, 316], ["super().before_eval_iteration", "metric_definitions.GenericPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_definitions.GenericPluginMetric.before_eval_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval_iteration", "(", "strategy", ")", "\n", "if", "self", ".", "_reset_at", "==", "'iteration'", "and", "self", ".", "_mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "reset", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskUsage.__init__": [[28, 49], ["isinstance", "str", "os.getcwd"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "paths_to_monitor", ":", "Union", "[", "PathAlike", ",", "Sequence", "[", "PathAlike", "]", "]", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the standalone disk usage metric.\n\n        The `result` method will return the sum of the size\n        of the directories specified as the first parameter in KiloBytes.\n\n        :param paths_to_monitor: a path or a list of paths to monitor. If None,\n            the current working directory is used. Defaults to None.\n        \"\"\"", "\n", "\n", "if", "paths_to_monitor", "is", "None", ":", "\n", "            ", "paths_to_monitor", "=", "[", "os", ".", "getcwd", "(", ")", "]", "\n", "", "if", "isinstance", "(", "paths_to_monitor", ",", "(", "str", ",", "Path", ")", ")", ":", "\n", "            ", "paths_to_monitor", "=", "[", "paths_to_monitor", "]", "\n", "\n", "", "self", ".", "_paths_to_monitor", ":", "List", "[", "str", "]", "=", "[", "str", "(", "p", ")", "for", "p", "in", "paths_to_monitor", "]", "\n", "\n", "self", ".", "total_usage", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskUsage.update": [[50, 62], ["disk_usage.DiskUsage.get_dir_size"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskUsage.get_dir_size"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Updates the disk usage statistics.\n\n        :return None.\n        \"\"\"", "\n", "\n", "dirs_size", "=", "0", "\n", "for", "directory", "in", "self", ".", "_paths_to_monitor", ":", "\n", "            ", "dirs_size", "+=", "DiskUsage", ".", "get_dir_size", "(", "directory", ")", "\n", "\n", "", "self", ".", "total_usage", "=", "dirs_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskUsage.result": [[63, 74], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "Optional", "[", "float", "]", ":", "\n", "        ", "\"\"\"\n        Retrieves the disk usage as computed during the last call to the\n        `update` method.\n\n        Calling this method will not change the internal state of the metric.\n\n        :return: The disk usage or None if `update` was not invoked yet.\n        \"\"\"", "\n", "\n", "return", "self", ".", "total_usage", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskUsage.reset": [[75, 82], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "total_usage", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskUsage.get_dir_size": [[83, 96], ["os.walk", "os.path.join", "os.path.islink", "os.path.getsize"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_dir_size", "(", "path", ":", "str", ")", ":", "\n", "        ", "total_size", "=", "0", "\n", "for", "dirpath", ",", "dirnames", ",", "filenames", "in", "os", ".", "walk", "(", "path", ")", ":", "\n", "            ", "for", "f", "in", "filenames", ":", "\n", "                ", "fp", "=", "os", ".", "path", ".", "join", "(", "dirpath", ",", "f", ")", "\n", "# skip if it is symbolic link", "\n", "if", "not", "os", ".", "path", ".", "islink", "(", "fp", ")", ":", "\n", "# in KB", "\n", "                    ", "s", "=", "os", ".", "path", ".", "getsize", "(", "fp", ")", "/", "1024", "\n", "total_size", "+=", "s", "\n", "\n", "", "", "", "return", "total_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskPluginMetric.__init__": [[99, 105], ["disk_usage.DiskUsage", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "paths", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_disk", "=", "DiskUsage", "(", "paths_to_monitor", "=", "paths", ")", "\n", "\n", "super", "(", "DiskPluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_disk", ",", "reset_at", "=", "reset_at", ",", "emit_at", "=", "emit_at", ",", "\n", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.DiskPluginMetric.update": [[106, 108], ["disk_usage.DiskPluginMetric._disk.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_disk", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.MinibatchDiskUsage.__init__": [[122, 129], ["disk_usage.DiskPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "paths_to_monitor", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the minibatch Disk usage metric.\n        \"\"\"", "\n", "super", "(", "MinibatchDiskUsage", ",", "self", ")", ".", "__init__", "(", "\n", "paths_to_monitor", ",", "\n", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.MinibatchDiskUsage.__str__": [[130, 132], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"DiskUsage_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.EpochDiskUsage.__init__": [[143, 150], ["disk_usage.DiskPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "paths_to_monitor", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the epoch Disk usage metric.\n        \"\"\"", "\n", "super", "(", "EpochDiskUsage", ",", "self", ")", ".", "__init__", "(", "\n", "paths_to_monitor", ",", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.EpochDiskUsage.__str__": [[151, 153], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"DiskUsage_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.ExperienceDiskUsage.__init__": [[164, 171], ["disk_usage.DiskPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "paths_to_monitor", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the experience Disk usage metric.\n        \"\"\"", "\n", "super", "(", "ExperienceDiskUsage", ",", "self", ")", ".", "__init__", "(", "\n", "paths_to_monitor", ",", "\n", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.ExperienceDiskUsage.__str__": [[172, 174], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"DiskUsage_Exp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.StreamDiskUsage.__init__": [[185, 192], ["disk_usage.DiskPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "paths_to_monitor", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the stream Disk usage metric.\n        \"\"\"", "\n", "super", "(", "StreamDiskUsage", ",", "self", ")", ".", "__init__", "(", "\n", "paths_to_monitor", ",", "\n", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.StreamDiskUsage.__str__": [[193, 195], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"DiskUsage_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.disk_usage.disk_usage_metrics": [[197, 230], ["metrics.append", "metrics.append", "metrics.append", "metrics.append", "disk_usage.MinibatchDiskUsage", "disk_usage.EpochDiskUsage", "disk_usage.ExperienceDiskUsage", "disk_usage.StreamDiskUsage"], "function", ["None"], ["", "", "def", "disk_usage_metrics", "(", "*", ",", "paths_to_monitor", "=", "None", ",", "minibatch", "=", "False", ",", "epoch", "=", "False", ",", "\n", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    standalone metrics.\n\n    :param minibatch: If True, will return a metric able to log the minibatch\n        Disk usage\n    :param epoch: If True, will return a metric able to log the epoch\n        Disk usage\n    :param experience: If True, will return a metric able to log the experience\n        Disk usage.\n    :param stream: If True, will return a metric able to log the evaluation\n        stream Disk usage.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchDiskUsage", "(", "paths_to_monitor", "=", "paths_to_monitor", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochDiskUsage", "(", "paths_to_monitor", "=", "paths_to_monitor", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceDiskUsage", "(", "paths_to_monitor", "=", "paths_to_monitor", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamDiskUsage", "(", "paths_to_monitor", "=", "paths_to_monitor", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ForwardTransfer.__init__": [[38, 53], ["dict", "dict"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the standalone Forward Transfer metric\n        \"\"\"", "\n", "\n", "self", ".", "initial", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        The initial value for each key. This is the accuracy at \n        random initialization.\n        \"\"\"", "\n", "\n", "self", ".", "previous", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        The previous experience value detected for each key\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ForwardTransfer.update_initial": [[54, 56], ["None"], "methods", ["None"], ["", "def", "update_initial", "(", "self", ",", "k", ",", "v", ")", ":", "\n", "        ", "self", ".", "initial", "[", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ForwardTransfer.update_previous": [[57, 59], ["None"], "methods", ["None"], ["", "def", "update_previous", "(", "self", ",", "k", ",", "v", ")", ":", "\n", "        ", "self", ".", "previous", "[", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ForwardTransfer.update": [[60, 65], ["forward_transfer.ForwardTransfer.update_initial", "forward_transfer.ForwardTransfer.update_previous"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.update_initial", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ForwardTransfer.update_previous"], ["", "def", "update", "(", "self", ",", "k", ",", "v", ",", "initial", "=", "False", ")", ":", "\n", "        ", "if", "initial", ":", "\n", "            ", "self", ".", "update_initial", "(", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "update_previous", "(", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ForwardTransfer.result": [[66, 88], ["set", "forward_transfer.ForwardTransfer.previous.keys"], "methods", ["None"], ["", "", "def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        :param k: the key for which returning forward transfer. If k is None,\n            forward transfer will be returned for all keys\n            where the previous experience has been trained on.\n\n        :return: the difference between the key value after training on the\n            previous experience, and the key at random initialization.\n        \"\"\"", "\n", "\n", "forward_transfer", "=", "{", "}", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "if", "k", "in", "self", ".", "previous", ":", "\n", "                ", "return", "self", ".", "previous", "[", "k", "]", "-", "self", ".", "initial", "[", "k", "]", "\n", "", "else", ":", "\n", "                ", "return", "None", "\n", "\n", "", "", "previous_keys", "=", "set", "(", "self", ".", "previous", ".", "keys", "(", ")", ")", "\n", "for", "k", "in", "previous_keys", ":", "\n", "            ", "forward_transfer", "[", "k", "]", "=", "self", ".", "previous", "[", "k", "]", "-", "self", ".", "initial", "[", "k", "]", "\n", "\n", "", "return", "forward_transfer", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ForwardTransfer.reset": [[89, 91], ["dict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "previous", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.__init__": [[109, 137], ["super().__init__", "forward_transfer.ForwardTransfer"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the GenericExperienceForwardTransfer metric.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "forward_transfer", "=", "ForwardTransfer", "(", ")", "\n", "\"\"\"\n        The general metric to compute forward transfer\n        \"\"\"", "\n", "\n", "self", ".", "_current_metric", "=", "None", "\n", "\"\"\"\n        The metric the user should override\n        \"\"\"", "\n", "\n", "self", ".", "eval_exp_id", "=", "None", "\n", "\"\"\"\n        The current evaluation experience id\n        \"\"\"", "\n", "\n", "self", ".", "train_exp_id", "=", "None", "\n", "\"\"\"\n        The last encountered training experience id\n        \"\"\"", "\n", "\n", "self", ".", "at_init", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.reset": [[138, 148], ["forward_transfer.GenericExperienceForwardTransfer.forward_transfer.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        Note that this will reset the previous and initial accuracy of each\n        experience.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "forward_transfer", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.update": [[149, 160], ["forward_transfer.GenericExperienceForwardTransfer.forward_transfer.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "k", ",", "v", ",", "initial", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update forward transfer metric.\n        See `ForwardTransfer` for more detailed information.\n\n        :param k: key to update\n        :param v: value associated to k\n        :param initial: update initial value. If False, update\n            previous value.\n        \"\"\"", "\n", "self", ".", "forward_transfer", ".", "update", "(", "k", ",", "v", ",", "initial", "=", "initial", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.result": [[161, 169], ["forward_transfer.GenericExperienceForwardTransfer.forward_transfer.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Result for experience defined by a key.\n        See `ForwardTransfer` documentation for more detailed information.\n\n        k: optional key from which to compute forward transfer.\n        \"\"\"", "\n", "return", "self", ".", "forward_transfer", ".", "result", "(", "k", "=", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.before_training_exp": [[170, 172], ["None"], "methods", ["None"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "train_exp_id", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.after_eval": [[173, 178], ["None"], "methods", ["None"], ["", "def", "after_eval", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "if", "self", ".", "at_init", ":", "\n", "            ", "assert", "strategy", ".", "eval_every", ">", "-", "1", ",", "\"eval every > -1 to compute forward transfer\"", "\n", "self", ".", "at_init", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.before_eval_exp": [[179, 181], ["forward_transfer.GenericExperienceForwardTransfer._current_metric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "_current_metric", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.after_eval_iteration": [[182, 186], ["super().after_eval_iteration", "forward_transfer.GenericExperienceForwardTransfer.metric_update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_update"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "after_eval_iteration", "(", "strategy", ")", "\n", "self", ".", "eval_exp_id", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "self", ".", "metric_update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.after_eval_exp": [[187, 198], ["forward_transfer.GenericExperienceForwardTransfer.update", "forward_transfer.GenericExperienceForwardTransfer.metric_result", "forward_transfer.GenericExperienceForwardTransfer.update", "forward_transfer.GenericExperienceForwardTransfer._package_result", "forward_transfer.GenericExperienceForwardTransfer.metric_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "if", "self", ".", "at_init", ":", "\n", "            ", "self", ".", "update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ",", "initial", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_exp_id", "==", "self", ".", "eval_exp_id", "-", "1", ":", "\n", "                ", "self", ".", "update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ")", "\n", "\n", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer._package_result": [[199, 211], ["forward_transfer.GenericExperienceForwardTransfer.result", "avalanche.evaluation.metric_utils.get_metric_name", "avalanche.evaluation.metric_results.MetricValue"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name"], ["", "", "", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "# Only after the previous experience was trained on can we return the", "\n", "# forward transfer metric for this experience.", "\n", "        ", "result", "=", "self", ".", "result", "(", "k", "=", "self", ".", "eval_exp_id", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "            ", "metric_name", "=", "get_metric_name", "(", "self", ",", "strategy", ",", "add_experience", "=", "True", ")", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "\n", "\n", "metric_values", "=", "[", "MetricValue", "(", "\n", "self", ",", "metric_name", ",", "result", ",", "plot_x_position", ")", "]", "\n", "return", "metric_values", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.metric_update": [[212, 214], ["None"], "methods", ["None"], ["", "", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.metric_result": [[215, 217], ["None"], "methods", ["None"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericExperienceForwardTransfer.__str__": [[218, 220], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ExperienceForwardTransfer.__init__": [[227, 234], ["forward_transfer.GenericExperienceForwardTransfer.__init__", "avalanche.evaluation.metrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_current_metric", "=", "Accuracy", "(", ")", "\n", "\"\"\"\n        The average accuracy over the current evaluation experience\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ExperienceForwardTransfer.metric_update": [[235, 238], ["forward_transfer.ExperienceForwardTransfer._current_metric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_current_metric", ".", "update", "(", "strategy", ".", "mb_y", ",", "\n", "strategy", ".", "mb_output", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ExperienceForwardTransfer.metric_result": [[239, 241], ["forward_transfer.ExperienceForwardTransfer._current_metric.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "return", "self", ".", "_current_metric", ".", "result", "(", "0", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.ExperienceForwardTransfer.__str__": [[242, 244], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"ExperienceForwardTransfer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.__init__": [[261, 272], ["forward_transfer.GenericExperienceForwardTransfer.__init__", "avalanche.evaluation.metrics.Mean"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the GenericStreamForwardTransfer metric.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "stream_forward_transfer", "=", "Mean", "(", ")", "\n", "\"\"\"\n        The average forward transfer over all experiences\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.reset": [[273, 284], ["forward_transfer.GenericExperienceForwardTransfer.reset", "forward_transfer.GenericStreamForwardTransfer.stream_forward_transfer.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the forward transfer metrics.\n\n        Note that this will reset the previous and initial accuracy of each\n        experience.\n\n        :return: None.\n        \"\"\"", "\n", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "stream_forward_transfer", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.exp_update": [[285, 296], ["forward_transfer.GenericExperienceForwardTransfer.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "exp_update", "(", "self", ",", "k", ",", "v", ",", "initial", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update forward transfer metric.\n        See `Forward Transfer` for more detailed information.\n\n        :param k: key to update\n        :param v: value associated to k\n        :param initial: update initial value. If False, update\n            previous value.\n        \"\"\"", "\n", "super", "(", ")", ".", "update", "(", "k", ",", "v", ",", "initial", "=", "initial", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.exp_result": [[297, 305], ["forward_transfer.GenericExperienceForwardTransfer.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "exp_result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Result for experience defined by a key.\n        See `ForwardTransfer` documentation for more detailed information.\n\n        k: optional key from which to compute forward transfer.\n        \"\"\"", "\n", "return", "super", "(", ")", ".", "result", "(", "k", "=", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.result": [[306, 313], ["forward_transfer.GenericStreamForwardTransfer.stream_forward_transfer.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        The average forward transfer over all experiences.\n\n        k: optional key from which to compute forward transfer.\n        \"\"\"", "\n", "return", "self", ".", "stream_forward_transfer", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.before_eval": [[314, 317], ["super().before_eval", "forward_transfer.GenericStreamForwardTransfer.stream_forward_transfer.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "stream_forward_transfer", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.after_eval_exp": [[318, 330], ["forward_transfer.GenericStreamForwardTransfer.update", "forward_transfer.GenericStreamForwardTransfer.exp_result", "forward_transfer.GenericStreamForwardTransfer.metric_result", "forward_transfer.GenericStreamForwardTransfer.update", "forward_transfer.GenericStreamForwardTransfer.stream_forward_transfer.update", "forward_transfer.GenericStreamForwardTransfer.metric_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamBWT.exp_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "at_init", ":", "\n", "            ", "self", ".", "update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ",", "initial", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_exp_id", "==", "self", ".", "eval_exp_id", "-", "1", ":", "\n", "                ", "self", ".", "update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ")", "\n", "", "exp_forward_transfer", "=", "self", ".", "exp_result", "(", "k", "=", "self", ".", "eval_exp_id", ")", "\n", "if", "exp_forward_transfer", "is", "not", "None", ":", "\n", "                ", "self", ".", "stream_forward_transfer", ".", "update", "(", "exp_forward_transfer", ",", "\n", "weight", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.after_eval": [[331, 335], ["forward_transfer.GenericExperienceForwardTransfer.after_eval", "forward_transfer.GenericStreamForwardTransfer._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "super", "(", ")", ".", "after_eval", "(", "strategy", ")", "\n", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer._package_result": [[336, 349], ["forward_transfer.GenericStreamForwardTransfer.result", "avalanche.evaluation.metric_utils.phase_and_task", "avalanche.evaluation.metric_utils.stream_type", "str", "avalanche.evaluation.metric_results.MetricValue"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "metric_value", "=", "self", ".", "result", "(", ")", "\n", "\n", "phase_name", ",", "_", "=", "phase_and_task", "(", "strategy", ")", "\n", "stream", "=", "stream_type", "(", "strategy", ".", "experience", ")", "\n", "metric_name", "=", "'{}/{}_phase/{}_stream'", ".", "format", "(", "str", "(", "self", ")", ",", "\n", "phase_name", ",", "\n", "stream", ")", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "\n", "\n", "return", "[", "MetricValue", "(", "self", ",", "metric_name", ",", "metric_value", ",", "plot_x_position", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.metric_update": [[350, 352], ["None"], "methods", ["None"], ["", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.metric_result": [[353, 355], ["None"], "methods", ["None"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.GenericStreamForwardTransfer.__str__": [[356, 358], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.StreamForwardTransfer.__init__": [[369, 375], ["forward_transfer.GenericStreamForwardTransfer.__init__", "avalanche.evaluation.metrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_current_metric", "=", "Accuracy", "(", ")", "\n", "\"\"\"\n        The average accuracy over the current evaluation experience\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.StreamForwardTransfer.metric_update": [[376, 379], ["forward_transfer.StreamForwardTransfer._current_metric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_current_metric", ".", "update", "(", "strategy", ".", "mb_y", ",", "\n", "strategy", ".", "mb_output", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.StreamForwardTransfer.metric_result": [[380, 382], ["forward_transfer.StreamForwardTransfer._current_metric.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "return", "self", ".", "_current_metric", ".", "result", "(", "0", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.StreamForwardTransfer.__str__": [[383, 385], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"StreamForwardTransfer\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forward_transfer.forward_transfer_metrics": [[387, 410], ["metrics.append", "metrics.append", "forward_transfer.ExperienceForwardTransfer", "forward_transfer.StreamForwardTransfer"], "function", ["None"], ["", "", "def", "forward_transfer_metrics", "(", "*", ",", "experience", "=", "False", ",", "stream", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param experience: If True, will return a metric able to log\n        the forward transfer on each evaluation experience.\n    :param stream: If True, will return a metric able to log\n        the forward transfer averaged over the evaluation stream experiences,\n        which have been observed during training.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "\n", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceForwardTransfer", "(", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamForwardTransfer", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.__init__": [[62, 89], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_classes", ":", "int", "=", "None", ",", "\n", "normalize", ":", "Literal", "[", "'true'", ",", "'pred'", ",", "'all'", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the standalone confusion matrix metric.\n\n        By default this metric in its initial state will return an empty Tensor.\n        The metric can be updated by using the `update` method while the running\n        confusion matrix can be retrieved using the `result` method.\n\n        :param num_classes: The number of classes. Defaults to None,\n            which means that the number of classes will be inferred from\n            ground truth and prediction Tensors (see class description for more\n            details). If not None, the confusion matrix will always be of size\n            `num_classes, num_classes` and only the first `num_classes` values\n            of output logits or target logits will be considered in the update.\n            If the output or targets are provided as numerical labels,\n            there can be no label greater than `num_classes`.\n        :param normalize: how to normalize confusion matrix.\n            None to not normalize\n        \"\"\"", "\n", "self", ".", "_cm_tensor", ":", "Optional", "[", "Tensor", "]", "=", "None", "\n", "\"\"\"\n        The Tensor where the running confusion matrix is stored.\n        \"\"\"", "\n", "self", ".", "_num_classes", ":", "Optional", "[", "int", "]", "=", "num_classes", "\n", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.update": [[90, 171], ["torch.no_grad", "torch.as_tensor", "torch.as_tensor", "range", "len", "len", "ValueError", "len", "ValueError", "len", "ValueError", "len", "torch.min().item", "len", "torch.min().item", "ValueError", "torch.zeros", "len", "len", "len", "max", "torch.max", "ValueError", "max", "max", "torch.max", "ValueError", "max", "torch.nn.functional.pad", "torch.min", "torch.max().item", "torch.max().item", "ValueError", "torch.min", "torch.max().item", "torch.max().item", "ValueError", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update", "(", "self", ",", "true_y", ":", "Tensor", ",", "predicted_y", ":", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the running confusion matrix given the true and predicted labels.\n\n        :param true_y: The ground truth. Both labels and one-hot vectors\n            are supported.\n        :param predicted_y: The ground truth. Both labels and logit vectors\n            are supported.\n        :return: None.\n        \"\"\"", "\n", "if", "len", "(", "true_y", ")", "!=", "len", "(", "predicted_y", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Size mismatch for true_y and predicted_y tensors'", ")", "\n", "\n", "", "if", "len", "(", "true_y", ".", "shape", ")", ">", "2", ":", "\n", "            ", "raise", "ValueError", "(", "'Confusion matrix supports labels with at'", "\n", "' most 2 dimensions'", ")", "\n", "", "if", "len", "(", "predicted_y", ".", "shape", ")", ">", "2", ":", "\n", "            ", "raise", "ValueError", "(", "'Confusion matrix supports predictions with at '", "\n", "'most 2 dimensions'", ")", "\n", "\n", "", "max_label", "=", "-", "1", "if", "self", ".", "_num_classes", "is", "None", "else", "self", ".", "_num_classes", "-", "1", "\n", "\n", "# SELECT VALID PORTION OF TARGET AND PREDICTIONS", "\n", "true_y", "=", "torch", ".", "as_tensor", "(", "true_y", ")", "\n", "if", "len", "(", "true_y", ".", "shape", ")", "==", "2", "and", "self", ".", "_num_classes", "is", "not", "None", ":", "\n", "            ", "true_y", "=", "true_y", "[", ":", ",", ":", "max_label", "+", "1", "]", "\n", "", "predicted_y", "=", "torch", ".", "as_tensor", "(", "predicted_y", ")", "\n", "if", "len", "(", "predicted_y", ".", "shape", ")", "==", "2", "and", "self", ".", "_num_classes", "is", "not", "None", ":", "\n", "            ", "predicted_y", "=", "predicted_y", "[", ":", ",", ":", "max_label", "+", "1", "]", "\n", "\n", "# COMPUTE MAX LABEL AND CONVERT TARGET AND PREDICTIONS IF NEEDED", "\n", "", "if", "len", "(", "predicted_y", ".", "shape", ")", ">", "1", ":", "\n", "# Logits -> transform to labels", "\n", "            ", "if", "self", ".", "_num_classes", "is", "None", ":", "\n", "                ", "max_label", "=", "max", "(", "max_label", ",", "predicted_y", ".", "shape", "[", "1", "]", "-", "1", ")", "\n", "", "predicted_y", "=", "torch", ".", "max", "(", "predicted_y", ",", "1", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "# Labels -> check non-negative", "\n", "            ", "min_label", "=", "torch", ".", "min", "(", "predicted_y", ")", ".", "item", "(", ")", "\n", "if", "min_label", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'Label values must be non-negative values'", ")", "\n", "", "if", "self", ".", "_num_classes", "is", "None", ":", "\n", "                ", "max_label", "=", "max", "(", "max_label", ",", "torch", ".", "max", "(", "predicted_y", ")", ".", "item", "(", ")", ")", "\n", "", "elif", "torch", ".", "max", "(", "predicted_y", ")", ".", "item", "(", ")", ">=", "self", ".", "_num_classes", ":", "\n", "                ", "raise", "ValueError", "(", "\"Encountered predicted label larger than\"", "\n", "\"num_classes\"", ")", "\n", "\n", "", "", "if", "len", "(", "true_y", ".", "shape", ")", ">", "1", ":", "\n", "# Logits -> transform to labels", "\n", "            ", "if", "self", ".", "_num_classes", "is", "None", ":", "\n", "                ", "max_label", "=", "max", "(", "max_label", ",", "true_y", ".", "shape", "[", "1", "]", "-", "1", ")", "\n", "", "true_y", "=", "torch", ".", "max", "(", "true_y", ",", "1", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "# Labels -> check non-negative", "\n", "            ", "min_label", "=", "torch", ".", "min", "(", "true_y", ")", ".", "item", "(", ")", "\n", "if", "min_label", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'Label values must be non-negative values'", ")", "\n", "\n", "", "if", "self", ".", "_num_classes", "is", "None", ":", "\n", "                ", "max_label", "=", "max", "(", "max_label", ",", "torch", ".", "max", "(", "true_y", ")", ".", "item", "(", ")", ")", "\n", "", "elif", "torch", ".", "max", "(", "true_y", ")", ".", "item", "(", ")", ">=", "self", ".", "_num_classes", ":", "\n", "                ", "raise", "ValueError", "(", "\"Encountered target label larger than\"", "\n", "\"num_classes\"", ")", "\n", "\n", "", "", "if", "max_label", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'The Confusion Matrix metric can only handle '", "\n", "'positive label values'", ")", "\n", "\n", "", "if", "self", ".", "_cm_tensor", "is", "None", ":", "\n", "# Create the confusion matrix", "\n", "            ", "self", ".", "_cm_tensor", "=", "torch", ".", "zeros", "(", "(", "max_label", "+", "1", ",", "max_label", "+", "1", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "max_label", ">=", "self", ".", "_cm_tensor", ".", "shape", "[", "0", "]", ":", "\n", "# Enlarge the confusion matrix", "\n", "            ", "size_diff", "=", "1", "+", "max_label", "-", "self", ".", "_cm_tensor", ".", "shape", "[", "0", "]", "\n", "self", ".", "_cm_tensor", "=", "pad", "(", "self", ".", "_cm_tensor", ",", "\n", "(", "0", ",", "size_diff", ",", "0", ",", "size_diff", ")", ")", "\n", "\n", "", "for", "pattern_idx", "in", "range", "(", "len", "(", "true_y", ")", ")", ":", "\n", "            ", "self", ".", "_cm_tensor", "[", "true_y", "[", "pattern_idx", "]", "]", "[", "predicted_y", "[", "pattern_idx", "]", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.result": [[172, 189], ["torch.zeros", "confusion_matrix.ConfusionMatrix._normalize_cm"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix._normalize_cm"], ["", "", "def", "result", "(", "self", ")", "->", "Tensor", ":", "\n", "        ", "\"\"\"\n        Retrieves the unnormalized confusion matrix.\n\n        Calling this method will not change the internal state of the metric.\n\n        :return: The running confusion matrix, as a Tensor.\n        \"\"\"", "\n", "if", "self", ".", "_cm_tensor", "is", "None", ":", "\n", "            ", "matrix_shape", "=", "(", "0", ",", "0", ")", "\n", "if", "self", ".", "_num_classes", "is", "not", "None", ":", "\n", "                ", "matrix_shape", "=", "(", "self", ".", "_num_classes", ",", "self", ".", "_num_classes", ")", "\n", "", "return", "torch", ".", "zeros", "(", "matrix_shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "self", ".", "normalize", "is", "not", "None", ":", "\n", "            ", "return", "ConfusionMatrix", ".", "_normalize_cm", "(", "self", ".", "_cm_tensor", ",", "\n", "self", ".", "normalize", ")", "\n", "", "return", "self", ".", "_cm_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.reset": [[190, 200], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        Calling this method will *not* reset the default number of classes\n        optionally defined in the constructor optional parameter.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "_cm_tensor", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix._normalize_cm": [[201, 216], ["confusion_matrix.ConfusionMatrix.nan_to_num", "ValueError", "confusion_matrix.ConfusionMatrix.nan_to_num", "confusion_matrix.ConfusionMatrix.nan_to_num", "confusion_matrix.ConfusionMatrix.nan_to_num"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.nan_to_num", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.nan_to_num", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.nan_to_num", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.nan_to_num"], ["", "@", "staticmethod", "\n", "def", "_normalize_cm", "(", "cm", ":", "Tensor", ",", "\n", "normalization", ":", "Literal", "[", "'true'", ",", "'pred'", ",", "'all'", "]", ")", ":", "\n", "        ", "if", "normalization", "not", "in", "(", "'true'", ",", "'pred'", ",", "'all'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid normalization parameter. Can be \\'true\\','", "\n", "' \\'pred\\' or \\'all\\''", ")", "\n", "\n", "", "if", "normalization", "==", "'true'", ":", "\n", "            ", "cm", "=", "cm", "/", "cm", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "", "elif", "normalization", "==", "'pred'", ":", "\n", "            ", "cm", "=", "cm", "/", "cm", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "", "elif", "normalization", "==", "'all'", ":", "\n", "            ", "cm", "=", "cm", "/", "cm", ".", "sum", "(", "dtype", "=", "torch", ".", "float64", ")", "\n", "", "cm", "=", "ConfusionMatrix", ".", "nan_to_num", "(", "cm", ")", "\n", "return", "cm", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.nan_to_num": [[217, 226], ["matrix.numpy", "numpy.nan_to_num", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.ConfusionMatrix.nan_to_num"], ["", "@", "staticmethod", "\n", "def", "nan_to_num", "(", "matrix", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "# if version.parse(torch.__version__) >= version.parse(\"1.8.0\"):", "\n", "#    # noinspection PyUnresolvedReferences", "\n", "#    return torch.nan_to_num(matrix)", "\n", "\n", "        ", "numpy_ndarray", "=", "matrix", ".", "numpy", "(", ")", "\n", "numpy_ndarray", "=", "np", ".", "nan_to_num", "(", "numpy_ndarray", ")", "\n", "return", "torch", ".", "tensor", "(", "numpy_ndarray", ",", "dtype", "=", "matrix", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.__init__": [[244, 291], ["super().__init__", "confusion_matrix.ConfusionMatrix"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ":", "Union", "[", "int", ",", "Mapping", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "normalize", ":", "Literal", "[", "'true'", ",", "'pred'", ",", "'all'", "]", "=", "None", ",", "\n", "save_image", ":", "bool", "=", "True", ",", "\n", "image_creator", ":", "Callable", "[", "[", "Tensor", ",", "Sequence", "]", ",", "Image", "]", "=", "\n", "default_cm_image_creator", ",", "\n", "absolute_class_order", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Stream Confusion Matrix metric.\n\n        We recommend to set `save_image=False` if the runtime is too large.\n        In fact, a large number of classes may increase the computation time\n        of this metric.\n\n        :param num_classes: The number of classes. Defaults to None,\n            which means that the number of classes will be inferred from\n            ground truth and prediction Tensors (see class description for more\n            details). If not None, the confusion matrix will always be of size\n            `num_classes, num_classes` and only the first `num_classes` values\n            of output logits or target logits will be considered in the update.\n            If the output or targets are provided as numerical labels,\n            there can be no label greater than `num_classes`.\n        :param normalize: Normalizes confusion matrix over the true (rows),\n            predicted (columns) conditions or all the population. If None,\n            confusion matrix will not be normalized. Valid values are: 'true',\n            'pred' and 'all' or None.\n        :param save_image: If True, a graphical representation of the confusion\n            matrix will be logged, too. If False, only the Tensor representation\n            will be logged. Defaults to True.\n        :param image_creator: A callable that, given the tensor representation\n            of the confusion matrix and the corresponding labels, returns a\n            graphical representation of the matrix as a PIL Image. Defaults to\n            `default_cm_image_creator`.\n        :param absolute_class_order: If true, the labels in the created image\n            will be sorted by id, otherwise they will be sorted by order of\n            encounter at training time. This parameter is ignored if\n            `save_image` is False, or the scenario is not a NCScenario.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_save_image", ":", "bool", "=", "save_image", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "absolute_class_order", "=", "absolute_class_order", "\n", "self", ".", "_matrix", ":", "ConfusionMatrix", "=", "ConfusionMatrix", "(", "num_classes", "=", "num_classes", ",", "\n", "normalize", "=", "normalize", ")", "\n", "self", ".", "_image_creator", "=", "image_creator", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.reset": [[292, 295], ["confusion_matrix.ConfusionMatrix"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_matrix", "=", "ConfusionMatrix", "(", "num_classes", "=", "self", ".", "num_classes", ",", "\n", "normalize", "=", "self", ".", "normalize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.result": [[296, 299], ["confusion_matrix.StreamConfusionMatrix._matrix.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ")", "->", "Tensor", ":", "\n", "        ", "exp_cm", "=", "self", ".", "_matrix", ".", "result", "(", ")", "\n", "return", "exp_cm", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.update": [[300, 302], ["confusion_matrix.StreamConfusionMatrix._matrix.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "true_y", ":", "Tensor", ",", "predicted_y", ":", "Tensor", ")", "->", "None", ":", "\n", "        ", "self", ".", "_matrix", ".", "update", "(", "true_y", ",", "predicted_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.before_eval": [[303, 305], ["confusion_matrix.StreamConfusionMatrix.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.after_eval_iteration": [[306, 310], ["super().after_eval_iteration", "confusion_matrix.StreamConfusionMatrix.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "after_eval_iteration", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ".", "mb_y", ",", "\n", "strategy", ".", "mb_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.after_eval": [[311, 313], ["confusion_matrix.StreamConfusionMatrix._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix._package_result": [[314, 339], ["confusion_matrix.StreamConfusionMatrix.result", "avalanche.evaluation.metric_utils.phase_and_task", "avalanche.evaluation.metric_utils.stream_type", "str", "confusion_matrix.StreamConfusionMatrix._get_display_class_order", "confusion_matrix.StreamConfusionMatrix._image_creator", "avalanche.evaluation.metric_results.MetricValue", "avalanche.evaluation.metric_results.MetricValue", "avalanche.evaluation.metric_results.AlternativeValues"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix._get_display_class_order"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "exp_cm", "=", "self", ".", "result", "(", ")", "\n", "phase_name", ",", "_", "=", "phase_and_task", "(", "strategy", ")", "\n", "stream", "=", "stream_type", "(", "strategy", ".", "experience", ")", "\n", "metric_name", "=", "'{}/{}_phase/{}_stream'", ".", "format", "(", "str", "(", "self", ")", ",", "\n", "phase_name", ",", "\n", "stream", ")", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "\n", "\n", "if", "self", ".", "_save_image", ":", "\n", "            ", "class_order", "=", "self", ".", "_get_display_class_order", "(", "exp_cm", ",", "strategy", ")", "\n", "\n", "cm_image", "=", "self", ".", "_image_creator", "(", "\n", "exp_cm", "[", "class_order", "]", "[", ":", ",", "class_order", "]", ",", "\n", "class_order", "\n", ")", "\n", "metric_representation", "=", "MetricValue", "(", "\n", "self", ",", "metric_name", ",", "AlternativeValues", "(", "cm_image", ",", "exp_cm", ")", ",", "\n", "plot_x_position", ")", "\n", "", "else", ":", "\n", "            ", "metric_representation", "=", "MetricValue", "(", "\n", "self", ",", "metric_name", ",", "exp_cm", ",", "plot_x_position", ")", "\n", "\n", "", "return", "[", "metric_representation", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix._get_display_class_order": [[340, 348], ["numpy.arange", "isinstance", "len"], "methods", ["None"], ["", "def", "_get_display_class_order", "(", "self", ",", "exp_cm", ":", "Tensor", ",", "strategy", ":", "'BaseStrategy'", "\n", ")", "->", "ndarray", ":", "\n", "        ", "benchmark", "=", "strategy", ".", "experience", ".", "benchmark", "\n", "\n", "if", "self", ".", "absolute_class_order", "or", "not", "isinstance", "(", "benchmark", ",", "NCScenario", ")", ":", "\n", "            ", "return", "arange", "(", "len", "(", "exp_cm", ")", ")", "\n", "\n", "", "return", "benchmark", ".", "classes_order", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.StreamConfusionMatrix.__str__": [[349, 351], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"ConfusionMatrix_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.__init__": [[364, 376], ["avalanche.evaluation.PluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "class_names", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param class_names: list of names for the classes.\n            E.g. [\"cat\", \"dog\"] if class 0 == \"cat\" and class 1 == \"dog\"\n            If None, no class names will be used. Default None.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "outputs", "=", "[", "]", "# softmax-ed or logits outputs", "\n", "self", ".", "targets", "=", "[", "]", "# target classes", "\n", "self", ".", "class_names", "=", "class_names", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.reset": [[377, 380], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "outputs", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.before_eval": [[381, 383], ["confusion_matrix.WandBStreamConfusionMatrix.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.result": [[384, 388], ["torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "result", "(", "self", ")", ":", "\n", "        ", "outputs", "=", "torch", ".", "cat", "(", "self", ".", "outputs", ",", "dim", "=", "0", ")", "\n", "targets", "=", "torch", ".", "cat", "(", "self", ".", "targets", ",", "dim", "=", "0", ")", "\n", "return", "outputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.update": [[389, 392], ["confusion_matrix.WandBStreamConfusionMatrix.outputs.append", "confusion_matrix.WandBStreamConfusionMatrix.targets.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "self", ".", "outputs", ".", "append", "(", "output", ")", "\n", "self", ".", "targets", ".", "append", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.after_eval_iteration": [[393, 396], ["super().after_eval_iteration", "confusion_matrix.WandBStreamConfusionMatrix.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", "WandBStreamConfusionMatrix", ",", "self", ")", ".", "after_eval_iteration", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ".", "mb_output", ",", "strategy", ".", "mb_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.after_eval": [[397, 399], ["confusion_matrix.WandBStreamConfusionMatrix._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix._package_result": [[400, 421], ["confusion_matrix.WandBStreamConfusionMatrix.result", "avalanche.evaluation.metric_utils.phase_and_task", "avalanche.evaluation.metric_utils.stream_type", "torch.argmax().cpu().numpy", "wandb.plot.confusion_matrix", "avalanche.evaluation.metric_results.MetricValue", "str", "avalanche.evaluation.metric_results.AlternativeValues", "torch.argmax().cpu", "targets.cpu().numpy", "torch.argmax", "targets.cpu"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "outputs", ",", "targets", "=", "self", ".", "result", "(", ")", "\n", "phase_name", ",", "_", "=", "phase_and_task", "(", "strategy", ")", "\n", "stream", "=", "stream_type", "(", "strategy", ".", "experience", ")", "\n", "metric_name", "=", "'{}/{}_phase/{}_stream'", ".", "format", "(", "str", "(", "self", ")", ",", "\n", "phase_name", ",", "\n", "stream", ")", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "\n", "\n", "# compute predicted classes", "\n", "preds", "=", "torch", ".", "argmax", "(", "outputs", ",", "dim", "=", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "result", "=", "wandb", ".", "plot", ".", "confusion_matrix", "(", "preds", "=", "preds", ",", "\n", "y_true", "=", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "class_names", "=", "self", ".", "class_names", ")", "\n", "\n", "metric_representation", "=", "MetricValue", "(", "\n", "self", ",", "metric_name", ",", "AlternativeValues", "(", "result", ")", ",", "\n", "plot_x_position", ")", "\n", "\n", "return", "[", "metric_representation", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.WandBStreamConfusionMatrix.__str__": [[422, 424], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"W&BConfusionMatrix_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.confusion_matrix.confusion_matrix_metrics": [[426, 488], ["metrics.append", "confusion_matrix.StreamConfusionMatrix", "metrics.append", "confusion_matrix.WandBStreamConfusionMatrix"], "function", ["None"], ["", "", "def", "confusion_matrix_metrics", "(", "\n", "num_classes", "=", "None", ",", "\n", "normalize", "=", "None", ",", "\n", "save_image", "=", "True", ",", "\n", "image_creator", "=", "default_cm_image_creator", ",", "\n", "class_names", "=", "None", ",", "\n", "stream", "=", "False", ",", "\n", "wandb", "=", "False", ",", "\n", "absolute_class_order", ":", "bool", "=", "False", ",", "\n", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param num_classes: The number of classes. Defaults to None,\n        which means that the number of classes will be inferred from\n        ground truth and prediction Tensors (see class description for more\n        details). If not None, the confusion matrix will always be of size\n        `num_classes, num_classes` and only the first `num_classes` values\n        of output logits or target logits will be considered in the update.\n        If the output or targets are provided as numerical labels,\n        there can be no label greater than `num_classes`.\n    :param normalize: Normalizes confusion matrix over the true (rows),\n        predicted (columns) conditions or all the population. If None,\n        confusion matrix will not be normalized. Valid values are: 'true',\n        'pred' and 'all' or None.\n    :param save_image: If True, a graphical representation of the confusion\n        matrix will be logged, too. If False, only the Tensor representation\n        will be logged. Defaults to True.\n    :param image_creator: A callable that, given the tensor representation\n        of the confusion matrix, returns a graphical representation of the\n        matrix as a PIL Image. Defaults to `default_cm_image_creator`.\n    :param class_names: W&B only. List of names for the classes.\n        E.g. [\"cat\", \"dog\"] if class 0 == \"cat\" and class 1 == \"dog\"\n        If None, no class names will be used. Default None.\n    :param stream: If True, will return a metric able to log\n        the confusion matrix averaged over the entire evaluation stream\n        of experiences.\n    :param wandb: if True, will return a Weights and Biases confusion matrix\n        together with all the other confusion matrixes requested.\n    :param absolute_class_order: Not W&B. If true, the labels in the created\n        image will be sorted by id, otherwise they will be sorted by order of\n        encounter at training time. This parameter is ignored if `save_image` is\n         False, or the scenario is not a NCScenario.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "\n", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "\n", "StreamConfusionMatrix", "(", "num_classes", "=", "num_classes", ",", "\n", "normalize", "=", "normalize", ",", "\n", "save_image", "=", "save_image", ",", "\n", "image_creator", "=", "image_creator", ",", "\n", "absolute_class_order", "=", "absolute_class_order", ",", "\n", ")", ")", "\n", "if", "wandb", ":", "\n", "            ", "metrics", ".", "append", "(", "WandBStreamConfusionMatrix", "(", "class_names", "=", "class_names", ")", ")", "\n", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.__init__": [[44, 62], ["avalanche.evaluation.metric_definitions.PluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "mode", ":", "Literal", "[", "\"train\"", ",", "\"eval\"", ",", "\"both\"", "]", ",", "\n", "n_cols", ":", "int", ",", "\n", "n_rows", ":", "int", ",", "\n", "group", ":", "bool", "=", "True", ",", "\n", "disable_augmentations", ":", "bool", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "group", "=", "group", "\n", "self", ".", "n_rows", "=", "n_rows", "\n", "self", ".", "n_cols", "=", "n_cols", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "disable_augmentations", "=", "disable_augmentations", "\n", "\n", "self", ".", "images", ":", "List", "[", "Tensor", "]", "=", "[", "]", "\n", "self", ".", "n_wanted_images", "=", "self", ".", "n_cols", "*", "self", ".", "n_rows", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.after_train_dataset_adaptation": [[63, 68], ["images_samples.ImagesSamplePlugin._make_grid_sample"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._make_grid_sample"], ["", "def", "after_train_dataset_adaptation", "(", "\n", "self", ",", "strategy", ":", "\"BaseStrategy\"", "\n", ")", "->", "\"MetricResult\"", ":", "\n", "        ", "if", "self", ".", "mode", "==", "\"train\"", "or", "self", ".", "mode", "==", "\"both\"", ":", "\n", "            ", "return", "self", ".", "_make_grid_sample", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.after_eval_dataset_adaptation": [[69, 74], ["images_samples.ImagesSamplePlugin._make_grid_sample"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._make_grid_sample"], ["", "", "def", "after_eval_dataset_adaptation", "(", "\n", "self", ",", "strategy", ":", "\"BaseStrategy\"", "\n", ")", "->", "\"MetricResult\"", ":", "\n", "        ", "if", "self", ".", "mode", "==", "\"eval\"", "or", "self", ".", "mode", "==", "\"both\"", ":", "\n", "            ", "return", "self", ".", "_make_grid_sample", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.reset": [[75, 77], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "images", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.result": [[78, 80], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "        ", "return", "self", ".", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin.__str__": [[81, 83], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"images\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._make_grid_sample": [[84, 102], ["images_samples.ImagesSamplePlugin._load_sorted_images", "avalanche.evaluation.metric_results.MetricValue", "avalanche.evaluation.metric_utils.get_metric_name", "avalanche.evaluation.metric_results.TensorImage", "torchvision.utils.make_grid", "list"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._load_sorted_images", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name"], ["", "def", "_make_grid_sample", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "\"MetricResult\"", ":", "\n", "        ", "self", ".", "_load_sorted_images", "(", "strategy", ")", "\n", "\n", "return", "[", "\n", "MetricValue", "(", "\n", "self", ",", "\n", "name", "=", "get_metric_name", "(", "\n", "self", ",", "\n", "strategy", ",", "\n", "add_experience", "=", "self", ".", "mode", "==", "\"eval\"", ",", "\n", "add_task", "=", "True", ",", "\n", ")", ",", "\n", "value", "=", "TensorImage", "(", "\n", "make_grid", "(", "\n", "list", "(", "self", ".", "images", ")", ",", "normalize", "=", "False", ",", "nrow", "=", "self", ".", "n_cols", "\n", ")", "\n", ")", ",", "\n", "x_plot", "=", "strategy", ".", "clock", ".", "train_iterations", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._load_sorted_images": [[105, 110], ["images_samples.ImagesSamplePlugin.reset", "images_samples.ImagesSamplePlugin._load_data", "images_samples.ImagesSamplePlugin._sort_images"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._load_data", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._sort_images"], ["", "def", "_load_sorted_images", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "self", ".", "images", ",", "labels", ",", "tasks", "=", "self", ".", "_load_data", "(", "strategy", ")", "\n", "if", "self", ".", "group", ":", "\n", "            ", "self", ".", "_sort_images", "(", "labels", ",", "tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._load_data": [[111, 126], ["images_samples.ImagesSamplePlugin._make_dataloader", "labels.extend", "tasks.extend", "images.extend", "len", "batch_labels[].tolist", "batch_tasks[].tolist", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._make_dataloader"], ["", "", "def", "_load_data", "(", "\n", "self", ",", "strategy", ":", "\"BaseStrategy\"", "\n", ")", "->", "Tuple", "[", "List", "[", "Tensor", "]", ",", "List", "[", "int", "]", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "dataloader", "=", "self", ".", "_make_dataloader", "(", "strategy", ".", "adapted_dataset", ",", "\n", "strategy", ".", "eval_mb_size", ")", "\n", "\n", "images", ",", "labels", ",", "tasks", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "batch_images", ",", "batch_labels", ",", "batch_tasks", "in", "dataloader", ":", "\n", "            ", "n_missing_images", "=", "self", ".", "n_wanted_images", "-", "len", "(", "images", ")", "\n", "labels", ".", "extend", "(", "batch_labels", "[", ":", "n_missing_images", "]", ".", "tolist", "(", ")", ")", "\n", "tasks", ".", "extend", "(", "batch_tasks", "[", ":", "n_missing_images", "]", ".", "tolist", "(", ")", ")", "\n", "images", ".", "extend", "(", "batch_images", "[", ":", "n_missing_images", "]", ")", "\n", "if", "len", "(", "images", ")", "==", "self", ".", "n_wanted_images", ":", "\n", "                ", "return", "images", ",", "labels", ",", "tasks", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._sort_images": [[127, 132], ["sorted", "zip"], "methods", ["None"], ["", "", "", "def", "_sort_images", "(", "self", ",", "labels", ":", "List", "[", "int", "]", ",", "tasks", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "self", ".", "images", "=", "[", "\n", "image", "\n", "for", "task", ",", "label", ",", "image", "in", "sorted", "(", "\n", "zip", "(", "tasks", ",", "labels", ",", "self", ".", "images", ")", ",", "key", "=", "lambda", "t", ":", "(", "t", "[", "0", "]", ",", "t", "[", "1", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.ImagesSamplePlugin._make_dataloader": [[135, 145], ["torch.utils.data.DataLoader", "data.replace_transforms.replace_transforms.replace_transforms", "min", "images_samples.MaybeToTensor"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.utils.avalanche_dataset.AvalancheDataset.replace_transforms"], ["", "def", "_make_dataloader", "(", "self", ",", "data", ":", "\"AvalancheDataset\"", ",", "mb_size", ":", "int", ")", "->", "DataLoader", ":", "\n", "        ", "if", "self", ".", "disable_augmentations", ":", "\n", "            ", "data", "=", "data", ".", "replace_transforms", "(", "\n", "transform", "=", "MaybeToTensor", "(", ")", ",", "target_transform", "=", "None", ",", "\n", ")", "\n", "", "return", "DataLoader", "(", "\n", "dataset", "=", "data", ",", "\n", "batch_size", "=", "min", "(", "mb_size", ",", "self", ".", "n_wanted_images", ")", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.MaybeToTensor.__call__": [[153, 164], ["isinstance", "super().__call__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.MaybeToTensor.__call__"], ["def", "__call__", "(", "self", ",", "pic", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n\n        Returns:\n            Tensor: Converted image.\n        \"\"\"", "\n", "if", "isinstance", "(", "pic", ",", "Tensor", ")", ":", "\n", "            ", "return", "pic", "\n", "", "return", "super", "(", ")", ".", "__call__", "(", "pic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.images_samples.images_samples_metrics": [[166, 201], ["plugins.append", "plugins.append", "images_samples.ImagesSamplePlugin", "images_samples.ImagesSamplePlugin"], "function", ["None"], ["", "", "def", "images_samples_metrics", "(", "\n", "*", ",", "\n", "n_rows", ":", "int", "=", "8", ",", "\n", "n_cols", ":", "int", "=", "8", ",", "\n", "group", ":", "bool", "=", "True", ",", "\n", "on_train", ":", "bool", "=", "True", ",", "\n", "on_eval", ":", "bool", "=", "False", ",", "\n", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Create the plugins to log some images samples in grids.\n    No data augmentation is shown.\n    Only images in strategy.adapted dataset are used. Images added in the\n    dataloader (like the replay plugins do) are missed.\n\n    :param n_rows: The numbers of raws to use in the grid of images.\n    :param n_cols: The numbers of columns to use in the grid of images.\n    :param group: If True, images will be grouped by (task, label)\n    :param on_train: If True, will emit some images samples during training.\n    :param on_eval: If True, will emit some images samples during evaluation.\n    :return: The corresponding plugins.\n    \"\"\"", "\n", "plugins", "=", "[", "]", "\n", "if", "on_eval", ":", "\n", "        ", "plugins", ".", "append", "(", "\n", "ImagesSamplePlugin", "(", "\n", "mode", "=", "\"eval\"", ",", "n_rows", "=", "n_rows", ",", "n_cols", "=", "n_cols", ",", "group", "=", "group", "\n", ")", "\n", ")", "\n", "", "if", "on_train", ":", "\n", "        ", "plugins", ".", "append", "(", "\n", "ImagesSamplePlugin", "(", "\n", "mode", "=", "\"train\"", ",", "n_rows", "=", "n_rows", ",", "n_cols", "=", "n_cols", ",", "group", "=", "group", "\n", ")", "\n", ")", "\n", "", "return", "plugins", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScores.__init__": [[47, 50], ["collections.defaultdict", "mean_scores.MeanScores.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "label2mean", ":", "Dict", "[", "int", ",", "Mean", "]", "=", "defaultdict", "(", "Mean", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScores.reset": [[51, 53], ["collections.defaultdict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "label2mean", "=", "defaultdict", "(", "Mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScores.update": [[54, 67], ["torch.no_grad", "zip", "len", "len", "true_y.argmax.argmax.argmax", "scores.tolist", "true_y.argmax.argmax.tolist", "mean_scores.MeanScores.label2mean[].update", "predicted_y.size", "true_y.argmax.argmax.size", "torch.arange", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update", "(", "self", ",", "predicted_y", ":", "Tensor", ",", "true_y", ":", "Tensor", ")", ":", "\n", "        ", "assert", "(", "\n", "len", "(", "predicted_y", ".", "size", "(", ")", ")", "==", "2", "\n", ")", ",", "\"Predictions need to be logits or scores, not labels\"", "\n", "\n", "if", "len", "(", "true_y", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "            ", "true_y", "=", "true_y", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n", "", "scores", "=", "predicted_y", "[", "arange", "(", "len", "(", "true_y", ")", ")", ",", "true_y", "]", "\n", "\n", "for", "score", ",", "label", "in", "zip", "(", "scores", ".", "tolist", "(", ")", ",", "true_y", ".", "tolist", "(", ")", ")", ":", "\n", "            ", "self", ".", "label2mean", "[", "label", "]", ".", "update", "(", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScores.result": [[68, 70], ["m.result", "mean_scores.MeanScores.label2mean.items"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "", "def", "result", "(", "self", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "return", "{", "label", ":", "m", ".", "result", "(", ")", "for", "label", ",", "m", "in", "self", ".", "label2mean", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanNewOldScores.__init__": [[77, 80], ["mean_scores.MeanScores.__init__", "set"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "new_classes", ":", "Set", "[", "int", "]", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanNewOldScores.reset": [[81, 84], ["mean_scores.MeanScores.reset", "set"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "new_classes", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanNewOldScores.update_new_classes": [[85, 87], ["mean_scores.MeanNewOldScores.new_classes.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update_new_classes", "(", "self", ",", "new_classes", ":", "Set", "[", "int", "]", ")", ":", "\n", "        ", "self", ".", "new_classes", ".", "update", "(", "new_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanNewOldScores.old_classes": [[88, 91], ["set"], "methods", ["None"], ["", "@", "property", "\n", "def", "old_classes", "(", "self", ")", "->", "Set", "[", "int", "]", ":", "\n", "        ", "return", "set", "(", "self", ".", "label2mean", ")", "-", "self", ".", "new_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanNewOldScores.result": [[92, 109], ["sum().result", "sum().result", "sum", "sum", "avalanche.evaluation.metrics.Mean", "avalanche.evaluation.metrics.Mean"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ")", "->", "Dict", "[", "LabelCat", ",", "float", "]", ":", "\n", "# print(self.new_classes, self.label2mean)", "\n", "        ", "rv", "=", "{", "\n", "\"new\"", ":", "sum", "(", "\n", "(", "self", ".", "label2mean", "[", "label", "]", "for", "label", "in", "self", ".", "new_classes", ")", ",", "\n", "start", "=", "Mean", "(", ")", ",", "\n", ")", ".", "result", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "old_classes", ":", "\n", "            ", "return", "rv", "\n", "\n", "", "rv", "[", "\"old\"", "]", "=", "sum", "(", "\n", "(", "self", ".", "label2mean", "[", "label", "]", "for", "label", "in", "self", ".", "old_classes", ")", ",", "\n", "start", "=", "Mean", "(", ")", ",", "\n", ")", ".", "result", "(", ")", "\n", "\n", "return", "rv", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.__init__": [[158, 170], ["avalanche.evaluation.PluginMetric.__init__", "mean_scores.MeanNewOldScores", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_creator", ":", "Optional", "[", "\n", "MeanScoresImageCreator", "\n", "]", "=", "default_mean_scores_image_creator", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mean_scores", "=", "MeanNewOldScores", "(", ")", "\n", "self", ".", "image_creator", "=", "image_creator", "\n", "self", ".", "label_cat2step2mean", ":", "Dict", "[", "\n", "LabelCat", ",", "Dict", "[", "int", ",", "float", "]", "\n", "]", "=", "defaultdict", "(", "dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.reset": [[171, 173], ["mean_scores.MeanScoresPluginMetricABC.mean_scores.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "mean_scores", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.update_new_classes": [[174, 177], ["mean_scores.MeanScoresPluginMetricABC.mean_scores.update_new_classes"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.update_new_classes"], ["", "def", "update_new_classes", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", ":", "\n", "        ", "self", ".", "mean_scores", ".", "update_new_classes", "(", "\n", "strategy", ".", "experience", ".", "classes_in_this_experience", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.update": [[179, 182], ["mean_scores.MeanScoresPluginMetricABC.mean_scores.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", ":", "\n", "        ", "self", ".", "mean_scores", ".", "update", "(", "\n", "predicted_y", "=", "strategy", ".", "mb_output", ",", "true_y", "=", "strategy", ".", "mb_y", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.result": [[184, 186], ["mean_scores.MeanScoresPluginMetricABC.mean_scores.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ")", "->", "Dict", "[", "LabelCat", ",", "float", "]", ":", "\n", "        ", "return", "self", ".", "mean_scores", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC._package_result": [[187, 230], ["mean_scores.MeanScoresPluginMetricABC.result", "label_cat2mean_score.items", "avalanche.evaluation.metric_utils.get_metric_name", "avalanche.evaluation.metric_results.MetricValue", "rv.append", "rv.append", "label_cat2mean_score.items", "avalanche.evaluation.metric_results.MetricValue", "avalanche.evaluation.metric_results.MetricValue", "avalanche.evaluation.metric_results.AlternativeValues", "mean_scores.MeanScoresPluginMetricABC.image_creator"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "\"MetricResult\"", ":", "\n", "        ", "label_cat2mean_score", ":", "Dict", "[", "LabelCat", ",", "float", "]", "=", "self", ".", "result", "(", ")", "\n", "\n", "for", "label_cat", ",", "m", "in", "label_cat2mean_score", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "label_cat2step2mean", "[", "label_cat", "]", "[", "self", ".", "global_it_counter", "]", "=", "m", "\n", "\n", "", "base_metric_name", "=", "get_metric_name", "(", "\n", "self", ",", "strategy", ",", "add_experience", "=", "False", ",", "add_task", "=", "False", "\n", ")", "\n", "\n", "rv", "=", "[", "\n", "MetricValue", "(", "\n", "self", ",", "\n", "name", "=", "base_metric_name", "+", "f\"/{label_cat}_classes\"", ",", "\n", "value", "=", "m", ",", "\n", "x_plot", "=", "self", ".", "global_it_counter", ",", "\n", ")", "\n", "for", "label_cat", ",", "m", "in", "label_cat2mean_score", ".", "items", "(", ")", "\n", "]", "\n", "if", "\"old\"", "in", "label_cat2mean_score", "and", "\"new\"", "in", "label_cat2mean_score", ":", "\n", "            ", "rv", ".", "append", "(", "\n", "MetricValue", "(", "\n", "self", ",", "\n", "name", "=", "base_metric_name", "+", "f\"/new_old_diff\"", ",", "\n", "value", "=", "label_cat2mean_score", "[", "\"new\"", "]", "\n", "-", "label_cat2mean_score", "[", "\"old\"", "]", ",", "\n", "x_plot", "=", "self", ".", "global_it_counter", ",", "\n", ")", "\n", ")", "\n", "", "if", "self", ".", "image_creator", "is", "not", "None", ":", "\n", "            ", "rv", ".", "append", "(", "\n", "MetricValue", "(", "\n", "self", ",", "\n", "name", "=", "base_metric_name", ",", "\n", "value", "=", "AlternativeValues", "(", "\n", "self", ".", "image_creator", "(", "self", ".", "label_cat2step2mean", ")", ",", "\n", "self", ".", "label_cat2step2mean", ",", "\n", ")", ",", "\n", "x_plot", "=", "self", ".", "global_it_counter", ",", "\n", ")", "\n", ")", "\n", "\n", "", "return", "rv", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.__str__": [[231, 233], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MeanScores\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.before_training_epoch": [[241, 244], ["mean_scores.MeanScoresTrainPluginMetric.reset", "mean_scores.MeanScoresTrainPluginMetric.update_new_classes"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.update_new_classes"], ["def", "before_training_epoch", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "None", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "self", ".", "update_new_classes", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.after_training_iteration": [[245, 249], ["super().after_training_iteration", "mean_scores.MeanScoresTrainPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "None", ":", "\n", "        ", "if", "strategy", ".", "clock", ".", "train_exp_epochs", "==", "strategy", ".", "train_epochs", "-", "1", ":", "\n", "            ", "self", ".", "update", "(", "strategy", ")", "\n", "", "super", "(", ")", ".", "after_training_iteration", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresTrainPluginMetric.after_training_epoch": [[250, 253], ["mean_scores.MeanScoresTrainPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "def", "after_training_epoch", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "\"MetricResult\"", ":", "\n", "        ", "if", "strategy", ".", "clock", ".", "train_exp_epochs", "==", "strategy", ".", "train_epochs", "-", "1", ":", "\n", "            ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresEvalPluginMetric.before_training": [[261, 263], ["mean_scores.MeanScoresEvalPluginMetric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["def", "before_training", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "None", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresEvalPluginMetric.before_training_exp": [[264, 266], ["mean_scores.MeanScoresEvalPluginMetric.update_new_classes"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresPluginMetricABC.update_new_classes"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "None", ":", "\n", "        ", "self", ".", "update_new_classes", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresEvalPluginMetric.after_eval_iteration": [[267, 270], ["mean_scores.MeanScoresEvalPluginMetric.update", "super().after_eval_iteration"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "None", ":", "\n", "        ", "self", ".", "update", "(", "strategy", ")", "\n", "super", "(", ")", ".", "after_eval_iteration", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.MeanScoresEvalPluginMetric.after_eval": [[271, 273], ["mean_scores.MeanScoresEvalPluginMetric._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "\"MetricResult\"", ":", "\n", "        ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.default_mean_scores_image_creator": [[111, 144], ["matplotlib.pyplot.subplots", "zip", "ax.legend", "ax.set_xlabel", "ax.set_ylabel", "fig.tight_layout", "label2step2mean_scores.items", "ax.plot", "step2mean_scores.keys", "step2mean_scores.values"], "function", ["None"], ["", "", "def", "default_mean_scores_image_creator", "(", "\n", "label2step2mean_scores", ":", "Dict", "[", "LabelCat", ",", "Dict", "[", "int", ",", "float", "]", "]", "\n", ")", "->", "Figure", ":", "\n", "    ", "\"\"\"\n    Default function to create an image of the evolution of the scores of the\n        true class, averaged by new and old classes.\n\n    :param label2step2mean_scores: A dictionary that, for each label category\n        (\"old\" and \"new\") contains a dictionary of mean scores indexed by the\n        step of the observation.\n    :return: The figure containing the graphs.\n    \"\"\"", "\n", "fig", ",", "ax", "=", "subplots", "(", ")", "\n", "ax", ":", "Axes", "\n", "\n", "markers", "=", "\"*o\"", "\n", "\n", "for", "marker", ",", "(", "label", ",", "step2mean_scores", ")", "in", "zip", "(", "\n", "markers", ",", "label2step2mean_scores", ".", "items", "(", ")", "\n", ")", ":", "\n", "        ", "ax", ".", "plot", "(", "\n", "step2mean_scores", ".", "keys", "(", ")", ",", "\n", "step2mean_scores", ".", "values", "(", ")", ",", "\n", "marker", ",", "\n", "label", "=", "label", ",", "\n", ")", "\n", "\n", "", "ax", ".", "legend", "(", "loc", "=", "\"lower left\"", ")", "\n", "ax", ".", "set_xlabel", "(", "\"step\"", ")", "\n", "ax", ".", "set_ylabel", "(", "\"mean score\"", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean_scores.mean_scores_metrics": [[275, 302], ["plugins.append", "plugins.append", "mean_scores.MeanScoresEvalPluginMetric", "mean_scores.MeanScoresTrainPluginMetric"], "function", ["None"], ["", "", "def", "mean_scores_metrics", "(", "\n", "*", ",", "\n", "on_train", ":", "bool", "=", "True", ",", "\n", "on_eval", ":", "bool", "=", "True", ",", "\n", "image_creator", ":", "Optional", "[", "\n", "MeanScoresImageCreator", "\n", "]", "=", "default_mean_scores_image_creator", ",", "\n", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper to create plugins to show the scores of the true class, averaged by\n        new and old classes. The plugins are available during training (for the\n        last epoch of each experience) and evaluation.\n\n    :param on_train: If True the train plugin is created\n    :param on_eval: If True the eval plugin is created\n    :param image_creator: The function to use to create an image of the history\n        of the mean scores grouped by old and new classes\n    :return: The list of plugins that were specified\n    \"\"\"", "\n", "plugins", "=", "[", "]", "\n", "\n", "if", "on_eval", ":", "\n", "        ", "plugins", ".", "append", "(", "MeanScoresEvalPluginMetric", "(", "image_creator", "=", "image_creator", ")", ")", "\n", "", "if", "on_train", ":", "\n", "        ", "plugins", ".", "append", "(", "MeanScoresTrainPluginMetric", "(", "image_creator", "=", "image_creator", ")", ")", "\n", "\n", "", "return", "plugins", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.ElapsedTime.__init__": [[42, 53], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the ElapsedTime metric.\n\n        This metric in its initial state (or if the `update` method was invoked\n        only once) will return an elapsed time of 0. The metric can be updated\n        by using the `update` method while the running accuracy can be retrieved\n        using the `result` method.\n        \"\"\"", "\n", "self", ".", "_init_time", "=", "None", "\n", "self", ".", "_prev_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.ElapsedTime.update": [[54, 66], ["time.perf_counter"], "methods", ["None"], ["", "def", "update", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the elapsed time.\n\n        For more info on how to set the initial time see the class description.\n\n        :return: None.\n        \"\"\"", "\n", "now", "=", "time", ".", "perf_counter", "(", ")", "\n", "if", "self", ".", "_init_time", "is", "None", ":", "\n", "            ", "self", ".", "_init_time", "=", "now", "\n", "", "self", ".", "_prev_time", "=", "now", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.ElapsedTime.result": [[67, 78], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Retrieves the elapsed time.\n\n        Calling this method will not change the internal state of the metric.\n\n        :return: The elapsed time, in seconds, as a float value.\n        \"\"\"", "\n", "if", "self", ".", "_init_time", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "_prev_time", "-", "self", ".", "_init_time", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.ElapsedTime.reset": [[79, 87], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric, including the initial time.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "_prev_time", "=", "None", "\n", "self", ".", "_init_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.TimePluginMetric.__init__": [[90, 95], ["timing.ElapsedTime", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_time", "=", "ElapsedTime", "(", ")", "\n", "\n", "super", "(", "TimePluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_time", ",", "reset_at", ",", "emit_at", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.TimePluginMetric.update": [[96, 98], ["timing.TimePluginMetric._time.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_time", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.MinibatchTime.__init__": [[111, 117], ["timing.TimePluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the minibatch time metric.\n        \"\"\"", "\n", "super", "(", "MinibatchTime", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.MinibatchTime.before_training_iteration": [[118, 121], ["super().before_training_iteration", "timing.MinibatchTime._time.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ")", "->", "MetricResult", ":", "\n", "        ", "super", "(", ")", ".", "before_training_iteration", "(", "strategy", ")", "\n", "self", ".", "_time", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.MinibatchTime.__str__": [[122, 124], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Time_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.EpochTime.__init__": [[134, 141], ["timing.TimePluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the epoch time metric.\n        \"\"\"", "\n", "\n", "super", "(", "EpochTime", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.EpochTime.before_training_epoch": [[142, 145], ["super().before_training_epoch", "timing.EpochTime._time.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_epoch", "(", "strategy", ")", "\n", "self", ".", "_time", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.EpochTime.__str__": [[146, 148], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Time_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.RunningEpochTime.__init__": [[160, 168], ["avalanche.evaluation.metrics.mean.Mean", "timing.TimePluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the running epoch time metric..\n        \"\"\"", "\n", "self", ".", "_time_mean", "=", "Mean", "(", ")", "\n", "\n", "super", "(", "RunningEpochTime", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.RunningEpochTime.before_training_epoch": [[169, 173], ["super().before_training_epoch", "timing.RunningEpochTime._time_mean.reset", "timing.RunningEpochTime._time.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_epoch", "(", "strategy", ")", "\n", "self", ".", "_time_mean", ".", "reset", "(", ")", "\n", "self", ".", "_time", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.RunningEpochTime.after_training_iteration": [[174, 180], ["super().after_training_iteration", "timing.RunningEpochTime._time_mean.update", "timing.RunningEpochTime._time.reset", "timing.RunningEpochTime._package_result", "timing.RunningEpochTime._time.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "super", "(", ")", ".", "after_training_iteration", "(", "strategy", ")", "\n", "self", ".", "_time_mean", ".", "update", "(", "self", ".", "_time", ".", "result", "(", ")", ")", "\n", "self", ".", "_time", ".", "reset", "(", ")", "\n", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.RunningEpochTime.result": [[181, 183], ["timing.RunningEpochTime._time_mean.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "strategy", ")", "->", "float", ":", "\n", "        ", "return", "self", ".", "_time_mean", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.RunningEpochTime.__str__": [[184, 186], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"RunningTime_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.ExperienceTime.__init__": [[197, 203], ["timing.TimePluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the experience time metric.\n        \"\"\"", "\n", "super", "(", "ExperienceTime", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.ExperienceTime.before_eval_exp": [[204, 207], ["super().before_eval_exp", "timing.ExperienceTime._time.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval_exp", "(", "strategy", ")", "\n", "self", ".", "_time", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.ExperienceTime.__str__": [[208, 210], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Time_Exp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.StreamTime.__init__": [[221, 227], ["timing.TimePluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the stream time metric.\n        \"\"\"", "\n", "super", "(", "StreamTime", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.StreamTime.before_eval": [[228, 231], ["super().before_eval", "timing.StreamTime._time.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "_time", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.StreamTime.__str__": [[232, 234], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Time_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.timing.timing_metrics": [[236, 273], ["metrics.append", "metrics.append", "metrics.append", "metrics.append", "metrics.append", "timing.MinibatchTime", "timing.EpochTime", "timing.RunningEpochTime", "timing.ExperienceTime", "timing.StreamTime"], "function", ["None"], ["", "", "def", "timing_metrics", "(", "*", ",", "minibatch", "=", "False", ",", "epoch", "=", "False", ",", "epoch_running", "=", "False", ",", "\n", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param minibatch: If True, will return a metric able to log the train\n        minibatch elapsed time.\n    :param epoch: If True, will return a metric able to log the train epoch\n        elapsed time.\n    :param epoch_running: If True, will return a metric able to log the running\n        train epoch elapsed time.\n    :param experience: If True, will return a metric able to log the eval\n        experience elapsed time.\n    :param stream: If True, will return a metric able to log the eval stream\n        elapsed time.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchTime", "(", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochTime", "(", ")", ")", "\n", "\n", "", "if", "epoch_running", ":", "\n", "        ", "metrics", ".", "append", "(", "RunningEpochTime", "(", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceTime", "(", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamTime", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.CPUUsage.__init__": [[41, 64], ["avalanche.evaluation.metrics.Mean"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the standalone CPU usage metric.\n\n        By default this metric in its initial state will return a CPU usage\n        value of 0. The metric can be updated by using the `update` method\n        while the average CPU usage can be retrieved using the `result` method.\n        \"\"\"", "\n", "\n", "self", ".", "_mean_usage", "=", "Mean", "(", ")", "\n", "\"\"\"\n        The mean utility that will be used to store the average usage.\n        \"\"\"", "\n", "\n", "self", ".", "_process_handle", ":", "Optional", "[", "Process", "]", "=", "None", "\n", "\"\"\"\n        The process handle, lazily initialized.\n        \"\"\"", "\n", "\n", "self", ".", "_first_update", "=", "True", "\n", "\"\"\"\n        An internal flag to keep track of the first call to the `update` method.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.CPUUsage.update": [[65, 94], ["getattr", "cpu_usage.CPUUsage._process_handle.cpu_percent", "getattr", "psutil.Process", "cpu_usage.CPUUsage._mean_usage.update", "os.getpid", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the running CPU usage.\n\n        For more info on how to set the starting moment see the class\n        description.\n\n        :return: None.\n        \"\"\"", "\n", "if", "self", ".", "_first_update", ":", "\n", "            ", "self", ".", "_process_handle", "=", "Process", "(", "os", ".", "getpid", "(", ")", ")", "\n", "\n", "", "last_time", "=", "getattr", "(", "\n", "self", ".", "_process_handle", ",", "'_last_sys_cpu_times'", ",", "None", ")", "\n", "utilization", "=", "self", ".", "_process_handle", ".", "cpu_percent", "(", ")", "\n", "current_time", "=", "getattr", "(", "\n", "self", ".", "_process_handle", ",", "'_last_sys_cpu_times'", ",", "None", ")", "\n", "\n", "if", "self", ".", "_first_update", ":", "\n", "            ", "self", ".", "_first_update", "=", "False", "\n", "", "else", ":", "\n", "            ", "if", "current_time", "is", "None", "or", "last_time", "is", "None", ":", "\n", "                ", "warnings", ".", "warn", "(", "'CPUUsage can\\'t detect the elapsed time. It is '", "\n", "'recommended to update avalanche to the latest '", "\n", "'version.'", ")", "\n", "# Fallback, shouldn't happen", "\n", "current_time", "=", "1.0", "\n", "last_time", "=", "0.0", "\n", "", "self", ".", "_mean_usage", ".", "update", "(", "utilization", ",", "current_time", "-", "last_time", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.CPUUsage.result": [[95, 104], ["cpu_usage.CPUUsage._mean_usage.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "", "def", "result", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Retrieves the average CPU usage.\n\n        Calling this method will not change the internal state of the metric.\n\n        :return: The average CPU usage, as a float value.\n        \"\"\"", "\n", "return", "self", ".", "_mean_usage", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.CPUUsage.reset": [[105, 114], ["cpu_usage.CPUUsage._mean_usage.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "_mean_usage", ".", "reset", "(", ")", "\n", "self", ".", "_process_handle", "=", "None", "\n", "self", ".", "_first_update", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.CPUPluginMetric.__init__": [[117, 123], ["cpu_usage.CPUUsage", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_cpu", "=", "CPUUsage", "(", ")", "\n", "\n", "super", "(", "CPUPluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_cpu", ",", "reset_at", "=", "reset_at", ",", "emit_at", "=", "emit_at", ",", "\n", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.CPUPluginMetric.update": [[124, 126], ["cpu_usage.CPUPluginMetric._cpu.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_cpu", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.MinibatchCPUUsage.__init__": [[139, 145], ["cpu_usage.CPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the minibatch CPU usage metric.\n        \"\"\"", "\n", "super", "(", "MinibatchCPUUsage", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.MinibatchCPUUsage.before_training_iteration": [[146, 149], ["super().before_training_iteration", "cpu_usage.MinibatchCPUUsage.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_iteration", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ")", "# start monitoring thread", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.MinibatchCPUUsage.__str__": [[150, 152], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"CPUUsage_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.EpochCPUUsage.__init__": [[162, 168], ["cpu_usage.CPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the epoch CPU usage metric.\n        \"\"\"", "\n", "super", "(", "EpochCPUUsage", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.EpochCPUUsage.before_training_epoch": [[169, 172], ["super().before_training_epoch", "cpu_usage.EpochCPUUsage.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_epoch", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ")", "# start monitoring thread", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.EpochCPUUsage.__str__": [[173, 175], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"CPUUsage_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.__init__": [[186, 193], ["avalanche.evaluation.metrics.Mean", "cpu_usage.CPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the average epoch cpu usage metric.\n        \"\"\"", "\n", "self", ".", "_mean", "=", "Mean", "(", ")", "\n", "super", "(", "RunningEpochCPUUsage", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.result": [[194, 196], ["cpu_usage.RunningEpochCPUUsage._mean.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "strategy", ")", "->", "float", ":", "\n", "        ", "return", "self", ".", "_mean", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch": [[197, 200], ["super().before_training_epoch", "cpu_usage.RunningEpochCPUUsage._mean.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_epoch", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "before_training_epoch", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_epoch", "(", "strategy", ")", "\n", "self", ".", "_mean", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_iteration": [[201, 204], ["super().before_training_iteration", "cpu_usage.RunningEpochCPUUsage.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.before_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_training_iteration", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training_iteration", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ")", "# start monitoring thread", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration": [[205, 211], ["super().after_training_iteration", "cpu_usage.RunningEpochCPUUsage.update", "cpu_usage.RunningEpochCPUUsage._mean.update", "cpu_usage.RunningEpochCPUUsage._cpu.reset", "cpu_usage.RunningEpochCPUUsage._package_result", "cpu_usage.RunningEpochCPUUsage._cpu.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.after_training_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "after_training_iteration", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_training_iteration", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ")", "\n", "self", ".", "_mean", ".", "update", "(", "self", ".", "_cpu", ".", "result", "(", ")", ")", "\n", "self", ".", "_cpu", ".", "reset", "(", ")", "\n", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.RunningEpochCPUUsage.__str__": [[212, 214], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"RunningCPUUsage_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.ExperienceCPUUsage.__init__": [[225, 231], ["cpu_usage.CPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the experience CPU usage metric.\n        \"\"\"", "\n", "super", "(", "ExperienceCPUUsage", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.ExperienceCPUUsage.before_eval_exp": [[232, 235], ["super().before_eval_exp", "cpu_usage.ExperienceCPUUsage.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval_exp", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval_exp", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ")", "# start monitoring thread", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.ExperienceCPUUsage.__str__": [[236, 238], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"CPUUsage_Exp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.StreamCPUUsage.__init__": [[249, 255], ["cpu_usage.CPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the stream CPU usage metric.\n        \"\"\"", "\n", "super", "(", "StreamCPUUsage", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.StreamCPUUsage.before_eval": [[256, 259], ["super().before_eval", "cpu_usage.StreamCPUUsage.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "update", "(", "strategy", ")", "# start monitoring thread", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.StreamCPUUsage.__str__": [[260, 262], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"CPUUsage_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.cpu_usage.cpu_usage_metrics": [[264, 301], ["metrics.append", "metrics.append", "metrics.append", "metrics.append", "metrics.append", "cpu_usage.MinibatchCPUUsage", "cpu_usage.EpochCPUUsage", "cpu_usage.RunningEpochCPUUsage", "cpu_usage.ExperienceCPUUsage", "cpu_usage.StreamCPUUsage"], "function", ["None"], ["", "", "def", "cpu_usage_metrics", "(", "*", ",", "minibatch", "=", "False", ",", "epoch", "=", "False", ",", "epoch_running", "=", "False", ",", "\n", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param minibatch: If True, will return a metric able to log the minibatch\n        CPU usage\n    :param epoch: If True, will return a metric able to log the epoch\n        CPU usage\n    :param epoch_running: If True, will return a metric able to log the running\n        epoch CPU usage.\n    :param experience: If True, will return a metric able to log the experience\n        CPU usage.\n    :param stream: If True, will return a metric able to log the evaluation\n        stream CPU usage.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchCPUUsage", "(", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochCPUUsage", "(", ")", ")", "\n", "\n", "", "if", "epoch_running", ":", "\n", "        ", "metrics", ".", "append", "(", "RunningEpochCPUUsage", "(", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceCPUUsage", "(", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamCPUUsage", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MaxRAM.__init__": [[41, 69], ["psutil.Process", "os.getpid"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "every", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the RAM usage metric.\n        :param every: seconds after which update the maximum RAM\n            usage\n        \"\"\"", "\n", "\n", "self", ".", "_process_handle", ":", "Optional", "[", "Process", "]", "=", "Process", "(", "os", ".", "getpid", "(", ")", ")", "\n", "\"\"\"\n        The process handle, lazily initialized.\n        \"\"\"", "\n", "\n", "self", ".", "every", "=", "every", "\n", "\n", "self", ".", "stop_f", "=", "False", "\n", "\"\"\"\n        Flag to stop the thread\n        \"\"\"", "\n", "\n", "self", ".", "max_usage", "=", "0", "\n", "\"\"\"\n        Main metric result. Max RAM usage.\n        \"\"\"", "\n", "\n", "self", ".", "thread", "=", "None", "\n", "\"\"\"\n        Thread executing RAM monitoring code\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MaxRAM._f": [[70, 84], ["time.monotonic", "time.sleep", "ram_usage.MaxRAM._process_handle.memory_info", "time.monotonic"], "methods", ["None"], ["", "def", "_f", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Until a stop signal is encountered,\n        this function monitors each `every` seconds\n        the maximum amount of RAM used by the process\n        \"\"\"", "\n", "start_time", "=", "time", ".", "monotonic", "(", ")", "\n", "while", "not", "self", ".", "stop_f", ":", "\n", "# ram usage in MB", "\n", "            ", "ram_usage", "=", "self", ".", "_process_handle", ".", "memory_info", "(", ")", ".", "rss", "/", "1024", "/", "1024", "\n", "if", "ram_usage", ">", "self", ".", "max_usage", ":", "\n", "                ", "self", ".", "max_usage", "=", "ram_usage", "\n", "", "time", ".", "sleep", "(", "self", ".", "every", "-", "(", "(", "time", ".", "monotonic", "(", ")", "-", "start_time", ")", "\n", "%", "self", ".", "every", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MaxRAM.result": [[85, 94], ["None"], "methods", ["None"], ["", "", "def", "result", "(", "self", ")", "->", "Optional", "[", "float", "]", ":", "\n", "        ", "\"\"\"\n        Retrieves the RAM usage.\n\n        Calling this method will not change the internal state of the metric.\n\n        :return: The average RAM usage in bytes, as a float value.\n        \"\"\"", "\n", "return", "self", ".", "max_usage", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MaxRAM.start_thread": [[95, 100], ["threading.Thread", "ram_usage.MaxRAM.thread.start"], "methods", ["None"], ["", "def", "start_thread", "(", "self", ")", ":", "\n", "        ", "assert", "not", "self", ".", "thread", ",", "\"Trying to start thread \"", "\"without joining the previous.\"", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "_f", ",", "daemon", "=", "True", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MaxRAM.stop_thread": [[101, 107], ["ram_usage.MaxRAM.thread.join"], "methods", ["None"], ["", "def", "stop_thread", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "thread", ":", "\n", "            ", "self", ".", "stop_f", "=", "True", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "stop_f", "=", "False", "\n", "self", ".", "thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MaxRAM.reset": [[108, 115], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "max_usage", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MaxRAM.update": [[116, 118], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.RAMPluginMetric.__init__": [[121, 126], ["ram_usage.MaxRAM", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "every", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_ram", "=", "MaxRAM", "(", "every", ")", "\n", "\n", "super", "(", "RAMPluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_ram", ",", "reset_at", ",", "emit_at", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.RAMPluginMetric.update": [[127, 129], ["ram_usage.RAMPluginMetric._ram.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_ram", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MinibatchMaxRAM.__init__": [[137, 145], ["ram_usage.RAMPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "every", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Minibatch Max RAM metric\n        :param every: seconds after which update the maximum RAM\n            usage\n        \"\"\"", "\n", "super", "(", "MinibatchMaxRAM", ",", "self", ")", ".", "__init__", "(", "\n", "every", ",", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MinibatchMaxRAM.before_training": [[146, 150], ["super().before_training", "ram_usage.MinibatchMaxRAM._ram.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MinibatchMaxRAM.after_training": [[151, 154], ["super().after_training", "ram_usage.MinibatchMaxRAM._ram.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.after_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "after_training", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "stop_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.MinibatchMaxRAM.__str__": [[155, 157], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MaxRAMUsage_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.EpochMaxRAM.__init__": [[165, 173], ["ram_usage.RAMPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "every", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the epoch Max RAM metric.\n        :param every: seconds after which update the maximum RAM\n            usage\n        \"\"\"", "\n", "super", "(", "EpochMaxRAM", ",", "self", ")", ".", "__init__", "(", "\n", "every", ",", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.EpochMaxRAM.before_training": [[174, 178], ["super().before_training", "ram_usage.EpochMaxRAM._ram.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.EpochMaxRAM.after_training": [[179, 182], ["super().before_training", "ram_usage.EpochMaxRAM._ram.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "stop_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.EpochMaxRAM.__str__": [[183, 185], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MaxRAMUsage_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.ExperienceMaxRAM.__init__": [[193, 201], ["ram_usage.RAMPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "every", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Experience CPU usage metric.\n        :param every: seconds after which update the maximum RAM\n            usage\n        \"\"\"", "\n", "super", "(", "ExperienceMaxRAM", ",", "self", ")", ".", "__init__", "(", "\n", "every", ",", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.ExperienceMaxRAM.before_eval": [[202, 206], ["super().before_eval", "ram_usage.ExperienceMaxRAM._ram.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.ExperienceMaxRAM.after_eval": [[207, 210], ["super().after_eval", "ram_usage.ExperienceMaxRAM._ram.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "after_eval", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "stop_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.ExperienceMaxRAM.__str__": [[211, 213], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MaxRAMUsage_Experience\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.StreamMaxRAM.__init__": [[221, 229], ["ram_usage.RAMPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "every", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Experience CPU usage metric.\n        :param every: seconds after which update the maximum RAM\n            usage\n        \"\"\"", "\n", "super", "(", "StreamMaxRAM", ",", "self", ")", ".", "__init__", "(", "\n", "every", ",", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.StreamMaxRAM.before_eval": [[230, 233], ["super().before_eval", "ram_usage.StreamMaxRAM._ram.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.StreamMaxRAM.after_eval": [[234, 239], ["super().after_eval", "ram_usage.StreamMaxRAM._ram.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "packed", "=", "super", "(", ")", ".", "after_eval", "(", "strategy", ")", "\n", "self", ".", "_ram", ".", "stop_thread", "(", ")", "\n", "return", "packed", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.StreamMaxRAM.__str__": [[240, 242], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MaxRAMUsage_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.ram_usage.ram_usage_metrics": [[244, 278], ["metrics.append", "metrics.append", "metrics.append", "metrics.append", "ram_usage.MinibatchMaxRAM", "ram_usage.EpochMaxRAM", "ram_usage.ExperienceMaxRAM", "ram_usage.StreamMaxRAM"], "function", ["None"], ["", "", "def", "ram_usage_metrics", "(", "*", ",", "every", "=", "1", ",", "minibatch", "=", "False", ",", "epoch", "=", "False", ",", "\n", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param every: seconds after which update the maximum RAM\n        usage\n    :param minibatch: If True, will return a metric able to log the minibatch\n        max RAM usage.\n    :param epoch: If True, will return a metric able to log the epoch\n        max RAM usage.\n    :param experience: If True, will return a metric able to log the experience\n        max RAM usage.\n    :param stream: If True, will return a metric able to log the evaluation\n        max stream RAM usage.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchMaxRAM", "(", "every", "=", "every", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochMaxRAM", "(", "every", "=", "every", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceMaxRAM", "(", "every", "=", "every", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamMaxRAM", "(", "every", "=", "every", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.Loss.__init__": [[40, 53], ["collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the loss metric.\n\n        By default this metric in its initial state will return a loss\n        value of 0. The metric can be updated by using the `update` method\n        while the running loss can be retrieved using the `result` method.\n        \"\"\"", "\n", "self", ".", "_mean_loss", "=", "defaultdict", "(", "Mean", ")", "\n", "\"\"\"\n        The mean utility that will be used to store the running accuracy\n        for each task label.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.Loss.update": [[54, 66], ["torch.no_grad", "loss.Loss._mean_loss[].update", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update", "(", "self", ",", "loss", ":", "Tensor", ",", "patterns", ":", "int", ",", "task_label", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the running loss given the loss Tensor and the minibatch size.\n\n        :param loss: The loss Tensor. Different reduction types don't affect\n            the result.\n        :param patterns: The number of patterns in the minibatch.\n        :param task_label: the task label associated to the current experience\n        :return: None.\n        \"\"\"", "\n", "self", ".", "_mean_loss", "[", "task_label", "]", ".", "update", "(", "torch", ".", "mean", "(", "loss", ")", ",", "weight", "=", "patterns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.Loss.result": [[67, 81], ["isinstance", "v.result", "loss.Loss._mean_loss[].result", "loss.Loss._mean_loss.items"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "task_label", "=", "None", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Retrieves the running average loss per pattern.\n\n        Calling this method will not change the internal state of the metric.\n        :param task_label: None to return metric values for all the task labels.\n            If an int, return value only for that task label\n        :return: The running loss, as a float.\n        \"\"\"", "\n", "assert", "(", "task_label", "is", "None", "or", "isinstance", "(", "task_label", ",", "int", ")", ")", "\n", "if", "task_label", "is", "None", ":", "\n", "            ", "return", "{", "k", ":", "v", ".", "result", "(", ")", "for", "k", ",", "v", "in", "self", ".", "_mean_loss", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "task_label", ":", "self", ".", "_mean_loss", "[", "task_label", "]", ".", "result", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.Loss.reset": [[82, 95], ["isinstance", "collections.defaultdict", "loss.Loss._mean_loss[].reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "reset", "(", "self", ",", "task_label", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :param task_label: None to reset all metric values. If an int,\n            reset metric value corresponding to that task label.\n        :return: None.\n        \"\"\"", "\n", "assert", "(", "task_label", "is", "None", "or", "isinstance", "(", "task_label", ",", "int", ")", ")", "\n", "if", "task_label", "is", "None", ":", "\n", "            ", "self", ".", "_mean_loss", "=", "defaultdict", "(", "Mean", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_mean_loss", "[", "task_label", "]", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.LossPluginMetric.__init__": [[98, 102], ["loss.Loss", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_loss", "=", "Loss", "(", ")", "\n", "super", "(", "LossPluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_loss", ",", "reset_at", ",", "emit_at", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.LossPluginMetric.reset": [[103, 108], ["loss.LossPluginMetric._metric.reset", "loss.LossPluginMetric._metric.reset", "avalanche.evaluation.metric_utils.phase_and_task"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task"], ["", "def", "reset", "(", "self", ",", "strategy", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "_reset_at", "==", "'stream'", "or", "strategy", "is", "None", ":", "\n", "            ", "self", ".", "_metric", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_metric", ".", "reset", "(", "phase_and_task", "(", "strategy", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.LossPluginMetric.result": [[109, 114], ["loss.LossPluginMetric._metric.result", "loss.LossPluginMetric._metric.result", "avalanche.evaluation.metric_utils.phase_and_task"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task"], ["", "", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "float", ":", "\n", "        ", "if", "self", ".", "_emit_at", "==", "'stream'", "or", "strategy", "is", "None", ":", "\n", "            ", "return", "self", ".", "_metric", ".", "result", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_metric", ".", "result", "(", "phase_and_task", "(", "strategy", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.LossPluginMetric.update": [[115, 126], ["loss.LossPluginMetric._loss.update", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "# task labels defined for each experience", "\n", "        ", "task_labels", "=", "strategy", ".", "experience", ".", "task_labels", "\n", "if", "len", "(", "task_labels", ")", ">", "1", ":", "\n", "# task labels defined for each pattern", "\n", "# fall back to single task case", "\n", "            ", "task_label", "=", "0", "\n", "", "else", ":", "\n", "            ", "task_label", "=", "task_labels", "[", "0", "]", "\n", "", "self", ".", "_loss", ".", "update", "(", "strategy", ".", "loss", ",", "\n", "patterns", "=", "len", "(", "strategy", ".", "mb_y", ")", ",", "task_label", "=", "task_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.MinibatchLoss.__init__": [[141, 147], ["loss.LossPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the MinibatchLoss metric.\n        \"\"\"", "\n", "super", "(", "MinibatchLoss", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.MinibatchLoss.__str__": [[148, 150], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Loss_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.EpochLoss.__init__": [[162, 169], ["loss.LossPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the EpochLoss metric.\n        \"\"\"", "\n", "\n", "super", "(", "EpochLoss", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.EpochLoss.__str__": [[170, 172], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Loss_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.RunningEpochLoss.__init__": [[185, 192], ["loss.LossPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the RunningEpochLoss metric.\n        \"\"\"", "\n", "\n", "super", "(", "RunningEpochLoss", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.RunningEpochLoss.__str__": [[193, 195], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"RunningLoss_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.ExperienceLoss.__init__": [[204, 210], ["loss.LossPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of ExperienceLoss metric\n        \"\"\"", "\n", "super", "(", "ExperienceLoss", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.ExperienceLoss.__str__": [[211, 213], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Loss_Exp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.StreamLoss.__init__": [[222, 228], ["loss.LossPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of StreamLoss metric\n        \"\"\"", "\n", "super", "(", "StreamLoss", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.StreamLoss.__str__": [[229, 231], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Loss_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.loss.loss_metrics": [[233, 270], ["metrics.append", "metrics.append", "metrics.append", "metrics.append", "metrics.append", "loss.MinibatchLoss", "loss.EpochLoss", "loss.RunningEpochLoss", "loss.ExperienceLoss", "loss.StreamLoss"], "function", ["None"], ["", "", "def", "loss_metrics", "(", "*", ",", "minibatch", "=", "False", ",", "epoch", "=", "False", ",", "epoch_running", "=", "False", ",", "\n", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param minibatch: If True, will return a metric able to log\n        the minibatch loss at training time.\n    :param epoch: If True, will return a metric able to log\n        the epoch loss at training time.\n    :param epoch_running: If True, will return a metric able to log\n        the running epoch loss at training time.\n    :param experience: If True, will return a metric able to log\n        the loss on each evaluation experience.\n    :param stream: If True, will return a metric able to log\n        the loss averaged over the entire evaluation stream of experiences.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchLoss", "(", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochLoss", "(", ")", ")", "\n", "\n", "", "if", "epoch_running", ":", "\n", "        ", "metrics", ".", "append", "(", "RunningEpochLoss", "(", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceLoss", "(", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamLoss", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Mean.__init__": [[24, 34], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the mean metric.\n\n        This metric in its initial state will return a mean value of 0.\n        The metric can be updated by using the `update` method while the mean\n        can be retrieved using the `result` method.\n        \"\"\"", "\n", "self", ".", "summed", ":", "float", "=", "0.0", "\n", "self", ".", "weight", ":", "float", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Mean.update": [[35, 50], ["float", "float"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ":", "SupportsFloat", ",", "weight", ":", "SupportsFloat", "=", "1.0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the running mean given the value.\n\n        The value can be weighted with a custom value, defined by the `weight`\n        parameter.\n\n        :param value: The value to be used to update the mean.\n        :param weight: The weight of the value. Defaults to 1.\n        :return: None.\n        \"\"\"", "\n", "value", "=", "float", "(", "value", ")", "\n", "weight", "=", "float", "(", "weight", ")", "\n", "self", ".", "summed", "+=", "value", "*", "weight", "\n", "self", ".", "weight", "+=", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Mean.result": [[51, 62], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Retrieves the mean.\n\n        Calling this method will not change the internal state of the metric.\n\n        :return: The mean, as a float.\n        \"\"\"", "\n", "if", "self", ".", "weight", "==", "0.0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "summed", "/", "self", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Mean.reset": [[63, 71], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "summed", "=", "0.0", "\n", "self", ".", "weight", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Mean.__add__": [[72, 82], ["mean.Mean"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "other", ":", "'Mean'", ")", "->", "\"Mean\"", ":", "\n", "        ", "\"\"\"\n        Return a metric representing the weighted mean of the 2 means.\n\n        :param other: the other mean\n        :return: The weighted mean\"\"\"", "\n", "res", "=", "Mean", "(", ")", "\n", "res", ".", "summed", "=", "self", ".", "summed", "+", "other", ".", "summed", "\n", "res", ".", "weight", "=", "self", ".", "weight", "+", "other", ".", "weight", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Sum.__init__": [[95, 104], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the sum metric.\n\n        This metric in its initial state will return a sum value of 0.\n        The metric can be updated by using the `update` method while the sum\n        can be retrieved using the `result` method.\n        \"\"\"", "\n", "self", ".", "summed", ":", "float", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Sum.update": [[105, 113], ["float"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ":", "SupportsFloat", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the running sum given the value.\n\n        :param value: The value to be used to update the sum.\n        :return: None.\n        \"\"\"", "\n", "self", ".", "summed", "+=", "float", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Sum.result": [[114, 123], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Retrieves the sum.\n\n        Calling this method will not change the internal state of the metric.\n\n        :return: The sum, as a float.\n        \"\"\"", "\n", "return", "self", ".", "summed", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mean.Sum.reset": [[124, 131], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "summed", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartition.__init__": [[37, 41], ["labels_repartition.LabelsRepartition.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "task2label2count", ":", "Dict", "[", "int", ",", "Dict", "[", "int", ",", "int", "]", "]", "=", "{", "}", "\n", "self", ".", "class_order", "=", "None", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartition.reset": [[42, 44], ["collections.defaultdict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "task2label2count", "=", "defaultdict", "(", "Counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartition.update": [[45, 54], ["zip"], "methods", ["None"], ["", "def", "update", "(", "\n", "self", ",", "\n", "tasks", ":", "Sequence", "[", "int", "]", ",", "\n", "labels", ":", "Sequence", "[", "Union", "[", "str", ",", "int", "]", "]", ",", "\n", "class_order", ":", "Optional", "[", "List", "[", "int", "]", "]", ",", "\n", ")", ":", "\n", "        ", "self", ".", "class_order", "=", "class_order", "\n", "for", "task", ",", "label", "in", "zip", "(", "tasks", ",", "labels", ")", ":", "\n", "            ", "self", ".", "task2label2count", "[", "task", "]", "[", "label", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartition.update_order": [[55, 57], ["None"], "methods", ["None"], ["", "", "def", "update_order", "(", "self", ",", "class_order", ":", "Optional", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "self", ".", "class_order", "=", "class_order", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartition.result": [[58, 68], ["labels_repartition.LabelsRepartition.task2label2count.items"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "Dict", "[", "int", ",", "Dict", "[", "int", ",", "int", "]", "]", ":", "\n", "        ", "if", "self", ".", "class_order", "is", "None", ":", "\n", "            ", "return", "self", ".", "task2label2count", "\n", "", "return", "{", "\n", "task", ":", "{", "\n", "label", ":", "label2count", "[", "label", "]", "\n", "for", "label", "in", "self", ".", "class_order", "\n", "if", "label", "in", "label2count", "\n", "}", "\n", "for", "task", ",", "label2count", "in", "self", ".", "task2label2count", ".", "items", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartitionPlugin.__init__": [[90, 112], ["labels_repartition.LabelsRepartition", "super().__init__", "collections.defaultdict"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "image_creator", ":", "Optional", "[", "\n", "LabelsRepartitionImageCreator", "\n", "]", "=", "default_history_repartition_image_creator", ",", "\n", "mode", ":", "Literal", "[", "\"train\"", ",", "\"eval\"", "]", "=", "\"train\"", ",", "\n", "emit_reset_at", ":", "Literal", "[", "\"stream\"", ",", "\"experience\"", ",", "\"epoch\"", "]", "=", "\"epoch\"", ",", "\n", ")", ":", "\n", "        ", "self", ".", "labels_repartition", "=", "LabelsRepartition", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "metric", "=", "self", ".", "labels_repartition", ",", "\n", "emit_at", "=", "emit_reset_at", ",", "\n", "reset_at", "=", "emit_reset_at", ",", "\n", "mode", "=", "mode", ",", "\n", ")", "\n", "self", ".", "emit_reset_at", "=", "emit_reset_at", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "image_creator", "=", "image_creator", "\n", "self", ".", "steps", "=", "[", "0", "]", "\n", "self", ".", "task2label2counts", ":", "Dict", "[", "int", ",", "Dict", "[", "int", ",", "List", "[", "int", "]", "]", "]", "=", "defaultdict", "(", "\n", "dict", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartitionPlugin.reset": [[114, 117], ["labels_repartition.LabelsRepartitionPlugin.steps.append", "super().reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "steps", ".", "append", "(", "self", ".", "global_it_counter", ")", "\n", "return", "super", "(", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartitionPlugin.update": [[118, 126], ["labels_repartition.LabelsRepartitionPlugin.labels_repartition.update", "strategy.mb_task_id.tolist", "strategy.mb_y.tolist", "getattr"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", ":", "\n", "        ", "if", "strategy", ".", "clock", ".", "train_exp_epochs", "and", "self", ".", "emit_reset_at", "!=", "\"epoch\"", ":", "\n", "            ", "return", "\n", "", "self", ".", "labels_repartition", ".", "update", "(", "\n", "strategy", ".", "mb_task_id", ".", "tolist", "(", ")", ",", "\n", "strategy", ".", "mb_y", ".", "tolist", "(", ")", ",", "\n", "class_order", "=", "getattr", "(", "\n", "strategy", ".", "experience", ".", "benchmark", ",", "\"classes_order\"", ",", "None", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartitionPlugin._package_result": [[129, 155], ["labels_repartition.LabelsRepartitionPlugin.steps.append", "labels_repartition.LabelsRepartitionPlugin.labels_repartition.result", "labels_repartition.LabelsRepartitionPlugin.items", "labels_repartition.LabelsRepartitionPlugin.task2label2counts.items", "label2count.items", "label2counts.items", "avalanche.evaluation.metric_results.MetricValue", "labels_repartition.LabelsRepartitionPlugin.task2label2counts[].setdefault().extend", "counts.extend", "labels_repartition.LabelsRepartitionPlugin.task2label2counts.items", "labels_repartition.LabelsRepartitionPlugin.task2label2counts[].setdefault", "avalanche.evaluation.metric_results.AlternativeValues", "len", "len", "avalanche.evaluation.metric_utils.stream_type", "labels_repartition.LabelsRepartitionPlugin.image_creator", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "\"BaseStrategy\"", ")", "->", "\"MetricResult\"", ":", "\n", "        ", "self", ".", "steps", ".", "append", "(", "self", ".", "global_it_counter", ")", "\n", "task2label2count", "=", "self", ".", "labels_repartition", ".", "result", "(", ")", "\n", "for", "task", ",", "label2count", "in", "task2label2count", ".", "items", "(", ")", ":", "\n", "            ", "for", "label", ",", "count", "in", "label2count", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "task2label2counts", "[", "task", "]", ".", "setdefault", "(", "\n", "label", ",", "[", "0", "]", "*", "(", "len", "(", "self", ".", "steps", ")", "-", "2", ")", "\n", ")", ".", "extend", "(", "(", "count", ",", "count", ")", ")", "\n", "", "", "for", "task", ",", "label2counts", "in", "self", ".", "task2label2counts", ".", "items", "(", ")", ":", "\n", "            ", "for", "label", ",", "counts", "in", "label2counts", ".", "items", "(", ")", ":", "\n", "                ", "counts", ".", "extend", "(", "[", "0", "]", "*", "(", "len", "(", "self", ".", "steps", ")", "-", "len", "(", "counts", ")", ")", ")", "\n", "", "", "return", "[", "\n", "MetricValue", "(", "\n", "self", ",", "\n", "name", "=", "f\"Repartition\"", "\n", "f\"/{self._mode}_phase\"", "\n", "f\"/{stream_type(strategy.experience)}_stream\"", "\n", "f\"/Task_{task:03}\"", ",", "\n", "value", "=", "AlternativeValues", "(", "\n", "self", ".", "image_creator", "(", "label2counts", ",", "self", ".", "steps", ")", ",", "label2counts", ",", "\n", ")", "\n", "if", "self", ".", "image_creator", "is", "not", "None", "\n", "else", "label2counts", ",", "\n", "x_plot", "=", "strategy", ".", "clock", ".", "train_iterations", ",", "\n", ")", "\n", "for", "task", ",", "label2counts", "in", "self", ".", "task2label2counts", ".", "items", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.LabelsRepartitionPlugin.__str__": [[157, 159], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Repartition\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.labels_repartition.labels_repartition_metrics": [[161, 206], ["plugins.append", "plugins.append", "labels_repartition.LabelsRepartitionPlugin", "labels_repartition.LabelsRepartitionPlugin"], "function", ["None"], ["", "", "def", "labels_repartition_metrics", "(", "\n", "*", ",", "\n", "on_train", ":", "bool", "=", "True", ",", "\n", "emit_train_at", ":", "Literal", "[", "\"stream\"", ",", "\"experience\"", ",", "\"epoch\"", "]", "=", "\"epoch\"", ",", "\n", "on_eval", ":", "bool", "=", "False", ",", "\n", "emit_eval_at", ":", "Literal", "[", "\"stream\"", ",", "\"experience\"", "]", "=", "\"stream\"", ",", "\n", "image_creator", ":", "Optional", "[", "\n", "LabelsRepartitionImageCreator", "\n", "]", "=", "default_history_repartition_image_creator", ",", "\n", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Create plugins to monitor the labels repartition.\n\n    :param on_train: If True, emit the metrics during training.\n    :param emit_train_at: (only if on_train is True) when to emit the training\n        metrics.\n    :param on_eval:  If True, emit the metrics during evaluation.\n    :param emit_eval_at: (only if on_eval is True) when to emit the evaluation\n        metrics.\n    :param image_creator: The function to use to create an image from the\n        history of the labels repartition. It will receive a dictionary of the\n        form {label_id: [count_at_step_0, count_at_step_1, ...], ...}\n        and the list of the corresponding steps [step_0, step_1, ...].\n        If set to None, only the raw data is emitted.\n    :return: The list of corresponding plugins.\n    \"\"\"", "\n", "plugins", "=", "[", "]", "\n", "if", "on_eval", ":", "\n", "        ", "plugins", ".", "append", "(", "\n", "LabelsRepartitionPlugin", "(", "\n", "image_creator", "=", "image_creator", ",", "\n", "mode", "=", "\"eval\"", ",", "\n", "emit_reset_at", "=", "emit_eval_at", ",", "\n", ")", "\n", ")", "\n", "", "if", "on_train", ":", "\n", "        ", "plugins", ".", "append", "(", "\n", "LabelsRepartitionPlugin", "(", "\n", "image_creator", "=", "image_creator", ",", "\n", "mode", "=", "\"train\"", ",", "\n", "emit_reset_at", "=", "emit_train_at", ",", "\n", ")", "\n", ")", "\n", "\n", "", "return", "plugins", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.__init__": [[26, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the MAC metric.\n        \"\"\"", "\n", "self", ".", "hooks", "=", "[", "]", "\n", "self", ".", "_compute_cost", ":", "Optional", "[", "int", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.update": [[33, 56], ["model.modules", "model", "mac.MAC.is_recognized_module", "mod.register_forward_hook.remove", "mod.register_forward_hook", "mac.MAC.hooks.append", "mac.MAC.update_compute_cost"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.is_recognized_module", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.update_compute_cost"], ["", "def", "update", "(", "self", ",", "model", ":", "Module", ",", "dummy_input", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Computes the MAC metric.\n\n        :param model: current model.\n        :param dummy_input: A tensor of the correct size to feed as input\n            to model. It includes batch size\n        :return: MAC metric.\n        \"\"\"", "\n", "\n", "for", "mod", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "MAC", ".", "is_recognized_module", "(", "mod", ")", ":", "\n", "                ", "def", "foo", "(", "a", ",", "b", ",", "c", ")", ":", "\n", "                    ", "return", "self", ".", "update_compute_cost", "(", "a", ",", "b", ",", "c", ")", "\n", "", "handle", "=", "mod", ".", "register_forward_hook", "(", "foo", ")", "\n", "self", ".", "hooks", ".", "append", "(", "handle", ")", "\n", "\n", "", "", "self", ".", "_compute_cost", "=", "0", "\n", "model", "(", "dummy_input", ")", "# trigger forward hooks", "\n", "\n", "for", "handle", "in", "self", ".", "hooks", ":", "\n", "            ", "handle", ".", "remove", "(", ")", "\n", "", "self", ".", "hooks", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.result": [[57, 66], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "Optional", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        Return the number of MAC operations as computed in the previous call\n        to the `update` method.\n\n        :return: The number of MAC operations or None if `update` has not been\n            called yet.\n        \"\"\"", "\n", "return", "self", ".", "_compute_cost", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.reset": [[67, 69], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.update_compute_cost": [[70, 78], ["None"], "methods", ["None"], ["", "def", "update_compute_cost", "(", "self", ",", "module", ",", "dummy_input", ",", "output", ")", ":", "\n", "        ", "modname", "=", "module", ".", "__class__", ".", "__name__", "\n", "if", "modname", "==", "'Linear'", ":", "\n", "            ", "self", ".", "_compute_cost", "+=", "dummy_input", "[", "0", "]", ".", "shape", "[", "1", "]", "*", "output", ".", "shape", "[", "1", "]", "\n", "", "elif", "modname", "==", "'Conv2d'", ":", "\n", "            ", "n", ",", "cout", ",", "hout", ",", "wout", "=", "output", ".", "shape", "# Batch, Channels, Height, Width", "\n", "ksize", "=", "module", ".", "kernel_size", "[", "0", "]", "*", "module", ".", "kernel_size", "[", "1", "]", "\n", "self", ".", "_compute_cost", "+=", "cout", "*", "hout", "*", "wout", "*", "ksize", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC.is_recognized_module": [[79, 83], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "is_recognized_module", "(", "mod", ")", ":", "\n", "        ", "modname", "=", "mod", ".", "__class__", ".", "__name__", "\n", "return", "modname", "==", "'Linear'", "or", "modname", "==", "'Conv2d'", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MACPluginMetric.__init__": [[86, 91], ["mac.MAC", "avalanche.evaluation.GenericPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_mac", "=", "MAC", "(", ")", "\n", "\n", "super", "(", "MACPluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_mac", ",", "reset_at", "=", "reset_at", ",", "emit_at", "=", "emit_at", ",", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MACPluginMetric.update": [[92, 95], ["mac.MACPluginMetric._mac.update", "strategy.mb_x[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_mac", ".", "update", "(", "strategy", ".", "model", ",", "\n", "strategy", ".", "mb_x", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MinibatchMAC.__init__": [[110, 116], ["mac.MACPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the MinibatchMAC metric.\n        \"\"\"", "\n", "super", "(", "MinibatchMAC", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MinibatchMAC.__str__": [[117, 119], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MAC_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.EpochMAC.__init__": [[130, 136], ["mac.MACPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the EpochMAC metric.\n        \"\"\"", "\n", "super", "(", "EpochMAC", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.EpochMAC.__str__": [[137, 139], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MAC_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.ExperienceMAC.__init__": [[148, 154], ["mac.MACPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of ExperienceMAC metric\n        \"\"\"", "\n", "super", "(", "ExperienceMAC", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.ExperienceMAC.__str__": [[155, 157], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"MAC_Exp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.mac.MAC_metrics": [[159, 186], ["metrics.append", "metrics.append", "metrics.append", "mac.MinibatchMAC", "mac.EpochMAC", "mac.ExperienceMAC"], "function", ["None"], ["", "", "def", "MAC_metrics", "(", "*", ",", "minibatch", "=", "False", ",", "epoch", "=", "False", ",", "experience", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param minibatch: If True, will return a metric able to log\n        the MAC after each iteration at training time.\n    :param epoch: If True, will return a metric able to log\n        the MAC after each epoch at training time.\n    :param experience: If True, will return a metric able to log\n        the MAC after each eval experience.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchMAC", "(", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochMAC", "(", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceMAC", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.Accuracy.__init__": [[39, 52], ["collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the standalone Accuracy metric.\n\n        By default this metric in its initial state will return an accuracy\n        value of 0. The metric can be updated by using the `update` method\n        while the running accuracy can be retrieved using the `result` method.\n        \"\"\"", "\n", "self", ".", "_mean_accuracy", "=", "defaultdict", "(", "Mean", ")", "\n", "\"\"\"\n        The mean utility that will be used to store the running accuracy\n        for each task label.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.Accuracy.update": [[53, 103], ["torch.no_grad", "torch.as_tensor", "torch.as_tensor", "isinstance", "len", "len", "ValueError", "isinstance", "ValueError", "len", "len", "float", "len", "accuracy.Accuracy._mean_accuracy[].update", "isinstance", "len", "len", "torch.max", "torch.max", "torch.sum", "zip", "ValueError", "torch.eq", "accuracy.Accuracy._mean_accuracy[].update", "type", "t.item"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update", "(", "self", ",", "predicted_y", ":", "Tensor", ",", "true_y", ":", "Tensor", ",", "\n", "task_labels", ":", "Union", "[", "float", ",", "Tensor", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the running accuracy given the true and predicted labels.\n        Parameter `task_labels` is used to decide how to update the inner\n        dictionary: if Float, only the dictionary value related to that task\n        is updated. If Tensor, all the dictionary elements belonging to the\n        task labels will be updated.\n\n        :param predicted_y: The model prediction. Both labels and logit vectors\n            are supported.\n        :param true_y: The ground truth. Both labels and one-hot vectors\n            are supported.\n        :param task_labels: the int task label associated to the current\n            experience or the task labels vector showing the task label\n            for each pattern.\n\n        :return: None.\n        \"\"\"", "\n", "if", "len", "(", "true_y", ")", "!=", "len", "(", "predicted_y", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Size mismatch for true_y and predicted_y tensors'", ")", "\n", "\n", "", "if", "isinstance", "(", "task_labels", ",", "Tensor", ")", "and", "len", "(", "task_labels", ")", "!=", "len", "(", "true_y", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Size mismatch for true_y and task_labels tensors'", ")", "\n", "\n", "", "true_y", "=", "torch", ".", "as_tensor", "(", "true_y", ")", "\n", "predicted_y", "=", "torch", ".", "as_tensor", "(", "predicted_y", ")", "\n", "\n", "# Check if logits or labels", "\n", "if", "len", "(", "predicted_y", ".", "shape", ")", ">", "1", ":", "\n", "# Logits -> transform to labels", "\n", "            ", "predicted_y", "=", "torch", ".", "max", "(", "predicted_y", ",", "1", ")", "[", "1", "]", "\n", "\n", "", "if", "len", "(", "true_y", ".", "shape", ")", ">", "1", ":", "\n", "# Logits -> transform to labels", "\n", "            ", "true_y", "=", "torch", ".", "max", "(", "true_y", ",", "1", ")", "[", "1", "]", "\n", "\n", "", "if", "isinstance", "(", "task_labels", ",", "int", ")", ":", "\n", "            ", "true_positives", "=", "float", "(", "torch", ".", "sum", "(", "torch", ".", "eq", "(", "predicted_y", ",", "true_y", ")", ")", ")", "\n", "total_patterns", "=", "len", "(", "true_y", ")", "\n", "self", ".", "_mean_accuracy", "[", "task_labels", "]", ".", "update", "(", "\n", "true_positives", "/", "total_patterns", ",", "total_patterns", ")", "\n", "", "elif", "isinstance", "(", "task_labels", ",", "Tensor", ")", ":", "\n", "            ", "for", "pred", ",", "true", ",", "t", "in", "zip", "(", "predicted_y", ",", "true_y", ",", "task_labels", ")", ":", "\n", "                ", "true_positives", "=", "(", "pred", "==", "true", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "_mean_accuracy", "[", "t", ".", "item", "(", ")", "]", ".", "update", "(", "\n", "true_positives", ",", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Task label type: {type(task_labels)}, \"", "\n", "f\"expected int/float or Tensor\"", ")", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.Accuracy.result": [[105, 122], ["isinstance", "v.result", "accuracy.Accuracy._mean_accuracy[].result", "accuracy.Accuracy._mean_accuracy.items"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "", "def", "result", "(", "self", ",", "task_label", "=", "None", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Retrieves the running accuracy.\n\n        Calling this method will not change the internal state of the metric.\n\n        :param task_label: if None, return the entire dictionary of accuracies\n            for each task. Otherwise return the dictionary\n            `{task_label: accuracy}`.\n        :return: A dict of running accuracies for each task label,\n            where each value is a float value between 0 and 1.\n        \"\"\"", "\n", "assert", "(", "task_label", "is", "None", "or", "isinstance", "(", "task_label", ",", "int", ")", ")", "\n", "if", "task_label", "is", "None", ":", "\n", "            ", "return", "{", "k", ":", "v", ".", "result", "(", ")", "for", "k", ",", "v", "in", "self", ".", "_mean_accuracy", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "task_label", ":", "self", ".", "_mean_accuracy", "[", "task_label", "]", ".", "result", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.Accuracy.reset": [[123, 136], ["isinstance", "collections.defaultdict", "accuracy.Accuracy._mean_accuracy[].reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "", "def", "reset", "(", "self", ",", "task_label", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n        :param task_label: if None, reset the entire dictionary.\n            Otherwise, reset the value associated to `task_label`.\n\n        :return: None.\n        \"\"\"", "\n", "assert", "(", "task_label", "is", "None", "or", "isinstance", "(", "task_label", ",", "int", ")", ")", "\n", "if", "task_label", "is", "None", ":", "\n", "            ", "self", ".", "_mean_accuracy", "=", "defaultdict", "(", "Mean", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_mean_accuracy", "[", "task_label", "]", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.AccuracyPluginMetric.__init__": [[143, 148], ["accuracy.Accuracy", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_accuracy", "=", "Accuracy", "(", ")", "\n", "super", "(", "AccuracyPluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_accuracy", ",", "reset_at", "=", "reset_at", ",", "emit_at", "=", "emit_at", ",", "\n", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.AccuracyPluginMetric.reset": [[149, 154], ["accuracy.AccuracyPluginMetric._metric.reset", "accuracy.AccuracyPluginMetric._metric.reset", "avalanche.evaluation.metric_utils.phase_and_task"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task"], ["", "def", "reset", "(", "self", ",", "strategy", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "_reset_at", "==", "'stream'", "or", "strategy", "is", "None", ":", "\n", "            ", "self", ".", "_metric", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_metric", ".", "reset", "(", "phase_and_task", "(", "strategy", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.AccuracyPluginMetric.result": [[155, 160], ["accuracy.AccuracyPluginMetric._metric.result", "accuracy.AccuracyPluginMetric._metric.result", "avalanche.evaluation.metric_utils.phase_and_task"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task"], ["", "", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "if", "self", ".", "_emit_at", "==", "'stream'", "or", "strategy", "is", "None", ":", "\n", "            ", "return", "self", ".", "_metric", ".", "result", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_metric", ".", "result", "(", "phase_and_task", "(", "strategy", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.AccuracyPluginMetric.update": [[161, 170], ["accuracy.AccuracyPluginMetric._accuracy.update", "len"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "# task labels defined for each experience", "\n", "        ", "task_labels", "=", "strategy", ".", "experience", ".", "task_labels", "\n", "if", "len", "(", "task_labels", ")", ">", "1", ":", "\n", "# task labels defined for each pattern", "\n", "            ", "task_labels", "=", "strategy", ".", "mb_task_id", "\n", "", "else", ":", "\n", "            ", "task_labels", "=", "task_labels", "[", "0", "]", "\n", "", "self", ".", "_accuracy", ".", "update", "(", "strategy", ".", "mb_output", ",", "strategy", ".", "mb_y", ",", "task_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.MinibatchAccuracy.__init__": [[185, 191], ["accuracy.AccuracyPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the MinibatchAccuracy metric.\n        \"\"\"", "\n", "super", "(", "MinibatchAccuracy", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.MinibatchAccuracy.__str__": [[192, 194], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Top1_Acc_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.EpochAccuracy.__init__": [[206, 213], ["accuracy.AccuracyPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the EpochAccuracy metric.\n        \"\"\"", "\n", "\n", "super", "(", "EpochAccuracy", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.EpochAccuracy.__str__": [[214, 216], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Top1_Acc_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.RunningEpochAccuracy.__init__": [[229, 236], ["accuracy.AccuracyPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the RunningEpochAccuracy metric.\n        \"\"\"", "\n", "\n", "super", "(", "RunningEpochAccuracy", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.RunningEpochAccuracy.__str__": [[237, 239], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Top1_RunningAcc_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.ExperienceAccuracy.__init__": [[248, 254], ["accuracy.AccuracyPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of ExperienceAccuracy metric\n        \"\"\"", "\n", "super", "(", "ExperienceAccuracy", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.ExperienceAccuracy.__str__": [[255, 257], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Top1_Acc_Exp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.StreamAccuracy.__init__": [[266, 272], ["accuracy.AccuracyPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of StreamAccuracy metric\n        \"\"\"", "\n", "super", "(", "StreamAccuracy", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.StreamAccuracy.result": [[273, 284], ["accuracy.AccuracyPluginMetric.result", "torch.mean().item", "torch.mean", "torch.tensor", "list", "super().result.values"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "strategy", "=", "None", ")", "->", "Dict", "[", "int", ",", "float", "]", ":", "\n", "        ", "task_results", "=", "super", "(", ")", ".", "result", "(", "strategy", ")", "# Dict[task_id,metric_value]", "\n", "\n", "# Postprocessing of per-task results in task-incremental", "\n", "# avg_task_key = min(task_results.keys())  # Just take minimum as task label", "\n", "avg_task_key", "=", "0", "# Take zero as default", "\n", "avg_results", "=", "torch", ".", "mean", "(", "torch", ".", "tensor", "(", "list", "(", "task_results", ".", "values", "(", ")", ")", ",", "dtype", "=", "torch", ".", "float", ")", ")", ".", "item", "(", ")", "\n", "\n", "# Avg over tasks", "\n", "avg_results", "=", "{", "avg_task_key", ":", "avg_results", "}", "\n", "return", "avg_results", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.StreamAccuracy.__str__": [[285, 287], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Top1_Acc_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.__init__": [[297, 305], ["accuracy.AccuracyPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of TrainedExperienceAccuracy metric by first \n        constructing AccuracyPluginMetric\n        \"\"\"", "\n", "super", "(", "TrainedExperienceAccuracy", ",", "self", ")", ".", "__init__", "(", "\n", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "self", ".", "_current_experience", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.after_training_exp": [[306, 311], ["accuracy.AccuracyPluginMetric.reset", "AccuracyPluginMetric.after_training_exp"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.after_training_exp"], ["", "def", "after_training_exp", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "self", ".", "_current_experience", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "# Reset average after learning from a new experience ", "\n", "AccuracyPluginMetric", ".", "reset", "(", "self", ",", "strategy", ")", "\n", "return", "AccuracyPluginMetric", ".", "after_training_exp", "(", "self", ",", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.update": [[312, 319], ["accuracy.AccuracyPluginMetric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "\"\"\"\n        Only update the accuracy with results from experiences that have been \n        trained on\n        \"\"\"", "\n", "if", "strategy", ".", "experience", ".", "current_experience", "<=", "self", ".", "_current_experience", ":", "\n", "            ", "AccuracyPluginMetric", ".", "update", "(", "self", ",", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.TrainedExperienceAccuracy.__str__": [[320, 322], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"Accuracy_On_Trained_Experiences\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.accuracy.accuracy_metrics": [[324, 372], ["metrics.append", "metrics.append", "metrics.append", "metrics.append", "metrics.append", "metrics.append", "accuracy.MinibatchAccuracy", "accuracy.EpochAccuracy", "accuracy.RunningEpochAccuracy", "accuracy.ExperienceAccuracy", "accuracy.StreamAccuracy", "accuracy.TrainedExperienceAccuracy"], "function", ["None"], ["", "", "def", "accuracy_metrics", "(", "*", ",", "\n", "minibatch", "=", "False", ",", "\n", "epoch", "=", "False", ",", "\n", "epoch_running", "=", "False", ",", "\n", "experience", "=", "False", ",", "\n", "stream", "=", "False", ",", "\n", "trained_experience", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param minibatch: If True, will return a metric able to log\n        the minibatch accuracy at training time.\n    :param epoch: If True, will return a metric able to log\n        the epoch accuracy at training time.\n    :param epoch_running: If True, will return a metric able to log\n        the running epoch accuracy at training time.\n    :param experience: If True, will return a metric able to log\n        the accuracy on each evaluation experience.\n    :param stream: If True, will return a metric able to log\n        the accuracy averaged over the entire evaluation stream of experiences.\n    :param trained_experience: If True, will return a metric able to log\n        the average evaluation accuracy only for experiences that the\n        model has been trained on         \n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchAccuracy", "(", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochAccuracy", "(", ")", ")", "\n", "\n", "", "if", "epoch_running", ":", "\n", "        ", "metrics", ".", "append", "(", "RunningEpochAccuracy", "(", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceAccuracy", "(", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamAccuracy", "(", ")", ")", "\n", "\n", "", "if", "trained_experience", ":", "\n", "        ", "metrics", ".", "append", "(", "TrainedExperienceAccuracy", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.checkpoint.WeightCheckpoint.__init__": [[38, 49], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the WeightCheckpoint Metric.\n\n        By default this metric in its initial state will return None.\n        The metric can be updated by using the `update` method\n        while the current experience's weight checkpoint tensor can be \n        retrieved using the `result` method.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.checkpoint.WeightCheckpoint.update": [[50, 58], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "weights", ")", "->", "Tensor", ":", "\n", "        ", "\"\"\"\n        Update the weight checkpoint at the current experience.\n\n        :param weights: the weight tensor at current experience\n        :return: None.\n        \"\"\"", "\n", "self", ".", "weights", "=", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.checkpoint.WeightCheckpoint.result": [[59, 66], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "Tensor", ":", "\n", "        ", "\"\"\"\n        Retrieves the weight checkpoint at the current experience.\n\n        :return: The weight checkpoint as a tensor.\n        \"\"\"", "\n", "return", "self", ".", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.checkpoint.WeightCheckpoint.reset": [[67, 74], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "weights", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.checkpoint.WeightCheckpoint._package_result": [[75, 81], ["checkpoint.WeightCheckpoint.result", "avalanche.evaluation.metric_utils.get_metric_name", "avalanche.evaluation.metric_results.MetricValue"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name"], ["", "def", "_package_result", "(", "self", ",", "strategy", ")", "->", "'MetricResult'", ":", "\n", "        ", "weights", "=", "self", ".", "result", "(", ")", "\n", "metric_name", "=", "get_metric_name", "(", "self", ",", "strategy", ",", "\n", "add_experience", "=", "True", ",", "add_task", "=", "False", ")", "\n", "return", "[", "MetricValue", "(", "self", ",", "metric_name", ",", "weights", ",", "\n", "strategy", ".", "clock", ".", "train_iterations", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.checkpoint.WeightCheckpoint.after_eval_exp": [[82, 85], ["copy.deepcopy", "checkpoint.WeightCheckpoint.update", "strategy.model.parameters"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "model_params", "=", "copy", ".", "deepcopy", "(", "strategy", ".", "model", ".", "parameters", "(", ")", ")", "\n", "self", ".", "update", "(", "model_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.checkpoint.WeightCheckpoint.__str__": [[86, 88], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"WeightCheckpoint\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.__init__": [[37, 51], ["dict", "dict"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the standalone Forgetting metric\n        \"\"\"", "\n", "\n", "self", ".", "initial", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        The initial value for each key.\n        \"\"\"", "\n", "\n", "self", ".", "last", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "\"\"\"\n        The last value detected for each key\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.update_initial": [[52, 54], ["None"], "methods", ["None"], ["", "def", "update_initial", "(", "self", ",", "k", ",", "v", ")", ":", "\n", "        ", "self", ".", "initial", "[", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.update_last": [[55, 57], ["None"], "methods", ["None"], ["", "def", "update_last", "(", "self", ",", "k", ",", "v", ")", ":", "\n", "        ", "self", ".", "last", "[", "k", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.update": [[58, 63], ["forgetting_bwt.Forgetting.update_initial", "forgetting_bwt.Forgetting.update_last"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.update_initial", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.update_last"], ["", "def", "update", "(", "self", ",", "k", ",", "v", ",", "initial", "=", "False", ")", ":", "\n", "        ", "if", "initial", ":", "\n", "            ", "self", ".", "update_initial", "(", "k", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "update_last", "(", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.result": [[64, 95], ["set", "list", "forgetting_bwt.Forgetting.initial.keys", "set.intersection", "set", "forgetting_bwt.Forgetting.last.keys"], "methods", ["None"], ["", "", "def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Forgetting is returned only for keys encountered twice.\n\n        :param k: the key for which returning forgetting. If k has not\n            updated at least twice it returns None. If k is None,\n            forgetting will be returned for all keys encountered at least\n            twice.\n\n        :return: the difference between the first and last value encountered\n            for k, if k is not None. It returns None if k has not been updated\n            at least twice. If k is None, returns a dictionary\n            containing keys whose value has been updated at least twice. The\n            associated value is the difference between the first and last\n            value recorded for that key.\n        \"\"\"", "\n", "\n", "forgetting", "=", "{", "}", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "if", "k", "in", "self", ".", "initial", "and", "k", "in", "self", ".", "last", ":", "\n", "                ", "return", "self", ".", "initial", "[", "k", "]", "-", "self", ".", "last", "[", "k", "]", "\n", "", "else", ":", "\n", "                ", "return", "None", "\n", "\n", "", "", "ik", "=", "set", "(", "self", ".", "initial", ".", "keys", "(", ")", ")", "\n", "both_keys", "=", "list", "(", "ik", ".", "intersection", "(", "set", "(", "self", ".", "last", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "for", "k", "in", "both_keys", ":", "\n", "            ", "forgetting", "[", "k", "]", "=", "self", ".", "initial", "[", "k", "]", "-", "self", ".", "last", "[", "k", "]", "\n", "\n", "", "return", "forgetting", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.reset_last": [[96, 98], ["dict"], "methods", ["None"], ["", "def", "reset_last", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "last", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.Forgetting.reset": [[99, 102], ["dict", "dict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "initial", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "self", ".", "last", ":", "Dict", "[", "int", ",", "float", "]", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.__init__": [[125, 151], ["super().__init__", "forgetting_bwt.Forgetting"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the GenericExperienceForgetting metric.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "forgetting", "=", "Forgetting", "(", ")", "\n", "\"\"\"\n        The general metric to compute forgetting\n        \"\"\"", "\n", "\n", "self", ".", "_current_metric", "=", "None", "\n", "\"\"\"\n        The metric the user should override\n        \"\"\"", "\n", "\n", "self", ".", "eval_exp_id", "=", "None", "\n", "\"\"\"\n        The current evaluation experience id\n        \"\"\"", "\n", "\n", "self", ".", "train_exp_id", "=", "None", "\n", "\"\"\"\n        The last encountered training experience id\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.reset": [[152, 162], ["forgetting_bwt.GenericExperienceForgetting.forgetting.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        Beware that this will also reset the initial metric of each\n        experience!\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "forgetting", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.reset_last": [[163, 173], ["forgetting_bwt.GenericExperienceForgetting.forgetting.reset_last"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.reset_last"], ["", "def", "reset_last", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the last metric value.\n\n        This will preserve the initial metric value of each experience.\n        To be used at the beginning of each eval experience.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "forgetting", ".", "reset_last", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.update": [[174, 185], ["forgetting_bwt.GenericExperienceForgetting.forgetting.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "k", ",", "v", ",", "initial", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update forgetting metric.\n        See `Forgetting` for more detailed information.\n\n        :param k: key to update\n        :param v: value associated to k\n        :param initial: update initial value. If False, update\n            last value.\n        \"\"\"", "\n", "self", ".", "forgetting", ".", "update", "(", "k", ",", "v", ",", "initial", "=", "initial", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.result": [[186, 193], ["forgetting_bwt.GenericExperienceForgetting.forgetting.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        See `Forgetting` documentation for more detailed information.\n\n        k: optional key from which compute forgetting.\n        \"\"\"", "\n", "return", "self", ".", "forgetting", ".", "result", "(", "k", "=", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_training_exp": [[194, 196], ["None"], "methods", ["None"], ["", "def", "before_training_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "train_exp_id", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval": [[197, 199], ["forgetting_bwt.GenericExperienceForgetting.reset_last"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.reset_last"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "self", ".", "reset_last", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.before_eval_exp": [[200, 202], ["forgetting_bwt.GenericExperienceForgetting._current_metric.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "before_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "_current_metric", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration": [[203, 207], ["super().after_eval_iteration", "forgetting_bwt.GenericExperienceForgetting.metric_update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_iteration", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_update"], ["", "def", "after_eval_iteration", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "after_eval_iteration", "(", "strategy", ")", "\n", "self", ".", "eval_exp_id", "=", "strategy", ".", "experience", ".", "current_experience", "\n", "self", ".", "metric_update", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.after_eval_exp": [[208, 223], ["forgetting_bwt.GenericExperienceForgetting._package_result", "forgetting_bwt.GenericExperienceForgetting.update", "forgetting_bwt.GenericExperienceForgetting.update", "forgetting_bwt.GenericExperienceForgetting.metric_result", "forgetting_bwt.GenericExperienceForgetting.metric_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "# update experience on which training just ended", "\n", "        ", "if", "self", ".", "train_exp_id", "==", "self", ".", "eval_exp_id", ":", "\n", "            ", "self", ".", "update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ",", "\n", "initial", "=", "True", ")", "\n", "", "else", ":", "\n", "# update other experiences", "\n", "# if experience has not been encountered in training", "\n", "# its value will not be considered in forgetting", "\n", "            ", "self", ".", "update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ")", "\n", "\n", "", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting._package_result": [[224, 238], ["forgetting_bwt.GenericExperienceForgetting.result", "avalanche.evaluation.metric_utils.get_metric_name", "avalanche.evaluation.metric_results.MetricValue"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.get_metric_name"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "# this checks if the evaluation experience has been", "\n", "# already encountered at training time", "\n", "# before the last training.", "\n", "# If not, forgetting should not be returned.", "\n", "        ", "forgetting", "=", "self", ".", "result", "(", "k", "=", "self", ".", "eval_exp_id", ")", "\n", "if", "forgetting", "is", "not", "None", ":", "\n", "            ", "metric_name", "=", "get_metric_name", "(", "self", ",", "strategy", ",", "add_experience", "=", "True", ")", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "\n", "\n", "metric_values", "=", "[", "MetricValue", "(", "\n", "self", ",", "metric_name", ",", "forgetting", ",", "plot_x_position", ")", "]", "\n", "return", "metric_values", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.metric_update": [[239, 241], ["None"], "methods", ["None"], ["", "", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.metric_result": [[242, 244], ["None"], "methods", ["None"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericExperienceForgetting.__str__": [[245, 247], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.ExperienceForgetting.__init__": [[262, 273], ["forgetting_bwt.GenericExperienceForgetting.__init__", "avalanche.evaluation.metrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the ExperienceForgetting metric.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_current_metric", "=", "Accuracy", "(", ")", "\n", "\"\"\"\n        The average accuracy over the current evaluation experience\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.ExperienceForgetting.metric_update": [[274, 277], ["forgetting_bwt.ExperienceForgetting._current_metric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_current_metric", ".", "update", "(", "strategy", ".", "mb_y", ",", "\n", "strategy", ".", "mb_output", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.ExperienceForgetting.metric_result": [[278, 280], ["forgetting_bwt.ExperienceForgetting._current_metric.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "return", "self", ".", "_current_metric", ".", "result", "(", "0", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.ExperienceForgetting.__str__": [[281, 283], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"ExperienceForgetting\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.__init__": [[306, 317], ["forgetting_bwt.GenericExperienceForgetting.__init__", "avalanche.evaluation.metrics.Mean"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the GenericStreamForgetting metric.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "stream_forgetting", "=", "Mean", "(", ")", "\n", "\"\"\"\n        The average forgetting over all experiences\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.reset": [[318, 329], ["forgetting_bwt.GenericExperienceForgetting.reset", "forgetting_bwt.GenericStreamForgetting.stream_forgetting.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the forgetting metrics.\n\n        Beware that this will also reset the initial metric value of each\n        experience!\n\n        :return: None.\n        \"\"\"", "\n", "super", "(", ")", ".", "reset", "(", ")", "\n", "self", ".", "stream_forgetting", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.exp_update": [[330, 341], ["forgetting_bwt.GenericExperienceForgetting.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "exp_update", "(", "self", ",", "k", ",", "v", ",", "initial", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update forgetting metric.\n        See `Forgetting` for more detailed information.\n\n        :param k: key to update\n        :param v: value associated to k\n        :param initial: update initial value. If False, update\n            last value.\n        \"\"\"", "\n", "super", "(", ")", ".", "update", "(", "k", ",", "v", ",", "initial", "=", "initial", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.exp_result": [[342, 350], ["forgetting_bwt.GenericExperienceForgetting.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "exp_result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Result for experience defined by a key.\n        See `Forgetting` documentation for more detailed information.\n\n        k: optional key from which compute forgetting.\n        \"\"\"", "\n", "return", "super", "(", ")", ".", "result", "(", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.result": [[351, 358], ["forgetting_bwt.GenericStreamForgetting.stream_forgetting.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        The average forgetting over all experience.\n\n        k: optional key from which compute forgetting.\n        \"\"\"", "\n", "return", "self", ".", "stream_forgetting", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.before_eval": [[359, 362], ["forgetting_bwt.GenericExperienceForgetting.before_eval", "forgetting_bwt.GenericStreamForgetting.stream_forgetting.reset"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "stream_forgetting", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.after_eval_exp": [[363, 383], ["forgetting_bwt.GenericStreamForgetting.exp_result", "forgetting_bwt.GenericStreamForgetting.exp_update", "forgetting_bwt.GenericStreamForgetting.exp_update", "forgetting_bwt.GenericStreamForgetting.stream_forgetting.update", "forgetting_bwt.GenericStreamForgetting.metric_result", "forgetting_bwt.GenericStreamForgetting.metric_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamBWT.exp_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.exp_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.exp_update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result"], ["", "def", "after_eval_exp", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "# update experience on which training just ended", "\n", "        ", "if", "self", ".", "train_exp_id", "==", "self", ".", "eval_exp_id", ":", "\n", "            ", "self", ".", "exp_update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ",", "\n", "initial", "=", "True", ")", "\n", "", "else", ":", "\n", "# update other experiences", "\n", "# if experience has not been encountered in training", "\n", "# its value will not be considered in forgetting", "\n", "            ", "self", ".", "exp_update", "(", "self", ".", "eval_exp_id", ",", "\n", "self", ".", "metric_result", "(", "strategy", ")", ")", "\n", "\n", "# this checks if the evaluation experience has been", "\n", "# already encountered at training time", "\n", "# before the last training.", "\n", "# If not, forgetting should not be returned.", "\n", "", "exp_forgetting", "=", "self", ".", "exp_result", "(", "k", "=", "self", ".", "eval_exp_id", ")", "\n", "if", "exp_forgetting", "is", "not", "None", ":", "\n", "            ", "self", ".", "stream_forgetting", ".", "update", "(", "exp_forgetting", ",", "weight", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.after_eval": [[384, 387], ["forgetting_bwt.GenericStreamForgetting._package_result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result"], ["", "", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "'MetricResult'", ":", "\n", "        ", "return", "self", ".", "_package_result", "(", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting._package_result": [[388, 401], ["forgetting_bwt.GenericStreamForgetting.result", "avalanche.evaluation.metric_utils.phase_and_task", "avalanche.evaluation.metric_utils.stream_type", "str", "avalanche.evaluation.metric_results.MetricValue"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.phase_and_task", "home.repos.pwc.inspect_result.mattdl_continualevaluation.evaluation.metric_utils.stream_type"], ["", "def", "_package_result", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "metric_value", "=", "self", ".", "result", "(", ")", "\n", "\n", "phase_name", ",", "_", "=", "phase_and_task", "(", "strategy", ")", "\n", "stream", "=", "stream_type", "(", "strategy", ".", "experience", ")", "\n", "metric_name", "=", "'{}/{}_phase/{}_stream'", ".", "format", "(", "str", "(", "self", ")", ",", "\n", "phase_name", ",", "\n", "stream", ")", "\n", "plot_x_position", "=", "strategy", ".", "clock", ".", "train_iterations", "\n", "\n", "return", "[", "MetricValue", "(", "self", ",", "metric_name", ",", "metric_value", ",", "plot_x_position", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.metric_update": [[402, 404], ["None"], "methods", ["None"], ["", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.metric_result": [[405, 407], ["None"], "methods", ["None"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.GenericStreamForgetting.__str__": [[408, 410], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.__init__": [[425, 436], ["forgetting_bwt.GenericStreamForgetting.__init__", "avalanche.evaluation.metrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the StreamForgetting metric.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_current_metric", "=", "Accuracy", "(", ")", "\n", "\"\"\"\n        The average accuracy over the current evaluation experience\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_update": [[437, 440], ["forgetting_bwt.StreamForgetting._current_metric.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "metric_update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_current_metric", ".", "update", "(", "strategy", ".", "mb_y", ",", "\n", "strategy", ".", "mb_output", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.metric_result": [[441, 443], ["forgetting_bwt.StreamForgetting._current_metric.result"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result"], ["", "def", "metric_result", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "return", "self", ".", "_current_metric", ".", "result", "(", "0", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamForgetting.__str__": [[444, 446], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"StreamForgetting\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.BWT.result": [[504, 526], ["forgetting_bwt.Forgetting.result", "forgetting_bwt.forgetting_to_bwt"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.forgetting_to_bwt"], ["def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Backward Transfer is returned only for keys encountered twice.\n        Backward Transfer is the negative forgetting.\n\n        :param k: the key for which returning backward transfer. If k has not\n            updated at least twice it returns None. If k is None,\n            backward transfer will be returned for all keys encountered at\n            least twice.\n\n        :return: the difference between the last value encountered for k\n            and its first value, if k is not None.\n            It returns None if k has not been updated\n            at least twice. If k is None, returns a dictionary\n            containing keys whose value has been updated at least twice. The\n            associated value is the difference between the last and first\n            value recorded for that key.\n        \"\"\"", "\n", "\n", "forgetting", "=", "super", "(", ")", ".", "result", "(", "k", ")", "\n", "bwt", "=", "forgetting_to_bwt", "(", "forgetting", ")", "\n", "return", "bwt", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.ExperienceBWT.result": [[540, 548], ["forgetting_bwt.GenericExperienceForgetting.result", "forgetting_bwt.forgetting_to_bwt"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.forgetting_to_bwt"], ["def", "result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        See `Forgetting` documentation for more detailed information.\n\n        k: optional key from which compute forgetting.\n        \"\"\"", "\n", "forgetting", "=", "super", "(", ")", ".", "result", "(", "k", ")", "\n", "return", "forgetting_to_bwt", "(", "forgetting", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.ExperienceBWT.__str__": [[549, 551], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"ExperienceBWT\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamBWT.exp_result": [[566, 575], ["forgetting_bwt.GenericStreamForgetting.exp_result", "forgetting_bwt.forgetting_to_bwt"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamBWT.exp_result", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.forgetting_to_bwt"], ["def", "exp_result", "(", "self", ",", "k", "=", "None", ")", "->", "Union", "[", "float", ",", "None", ",", "Dict", "[", "int", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Result for experience defined by a key.\n        See `BWT` documentation for more detailed information.\n\n        k: optional key from which compute backward transfer.\n        \"\"\"", "\n", "forgetting", "=", "super", "(", ")", ".", "exp_result", "(", "k", ")", "\n", "return", "forgetting_to_bwt", "(", "forgetting", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.StreamBWT.__str__": [[576, 578], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"StreamBWT\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.forgetting_metrics": [[448, 472], ["metrics.append", "metrics.append", "forgetting_bwt.ExperienceForgetting", "forgetting_bwt.StreamForgetting"], "function", ["None"], ["", "", "def", "forgetting_metrics", "(", "*", ",", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param experience: If True, will return a metric able to log\n        the forgetting on each evaluation experience.\n    :param stream: If True, will return a metric able to log\n        the forgetting averaged over the evaluation stream experiences,\n        which have been observed during training.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "\n", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceForgetting", "(", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamForgetting", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.forgetting_to_bwt": [[474, 489], ["isinstance", "isinstance", "ValueError", "f.items"], "function", ["None"], ["", "def", "forgetting_to_bwt", "(", "f", ")", ":", "\n", "    ", "\"\"\"\n    Convert forgetting to backward transfer.\n    BWT = -1 * forgetting\n    \"\"\"", "\n", "if", "f", "is", "None", ":", "\n", "        ", "return", "f", "\n", "", "if", "isinstance", "(", "f", ",", "dict", ")", ":", "\n", "        ", "bwt", "=", "{", "k", ":", "-", "1", "*", "v", "for", "k", ",", "v", "in", "f", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "f", ",", "float", ")", ":", "\n", "        ", "bwt", "=", "-", "1", "*", "f", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Forgetting data type not recognized when converting\"", "\n", "\"to backward transfer.\"", ")", "\n", "", "return", "bwt", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.forgetting_bwt.bwt_metrics": [[580, 603], ["metrics.append", "metrics.append", "forgetting_bwt.ExperienceBWT", "forgetting_bwt.StreamBWT"], "function", ["None"], ["", "", "def", "bwt_metrics", "(", "*", ",", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param experience: If True, will return a metric able to log\n        the backward transfer on each evaluation experience.\n    :param stream: If True, will return a metric able to log\n        the backward transfer averaged over the evaluation stream experiences\n        which have been observed during training.\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "\n", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceBWT", "(", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamBWT", "(", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.__init__": [[41, 80], ["len", "GPUtil.getGPUs", "warnings.warn", "warnings.warn", "warnings.warn"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gpu_id", ",", "every", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the GPU usage metric.\n\n        :param gpu_id: GPU device ID.\n        :param every: seconds after which update the maximum GPU\n            usage\n        \"\"\"", "\n", "\n", "self", ".", "every", "=", "every", "\n", "self", ".", "gpu_id", "=", "gpu_id", "\n", "\n", "n_gpus", "=", "len", "(", "GPUtil", ".", "getGPUs", "(", ")", ")", "\n", "if", "n_gpus", "==", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"Your system has no GPU!\"", ")", "\n", "self", ".", "gpu_id", "=", "None", "\n", "", "elif", "gpu_id", "<", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"GPU metric called with negative GPU id.\"", "\n", "\"GPU logging disabled\"", ")", "\n", "self", ".", "gpu_id", "=", "None", "\n", "", "else", ":", "\n", "            ", "if", "gpu_id", ">=", "n_gpus", ":", "\n", "                ", "warnings", ".", "warn", "(", "f\"GPU {gpu_id} not found. Using GPU 0.\"", ")", "\n", "self", ".", "gpu_id", "=", "0", "\n", "\n", "", "", "self", ".", "thread", "=", "None", "\n", "\"\"\"\n        Thread executing GPU monitoring code\n        \"\"\"", "\n", "\n", "self", ".", "stop_f", "=", "False", "\n", "\"\"\"\n        Flag to stop the thread\n        \"\"\"", "\n", "\n", "self", ".", "max_usage", "=", "0", "\n", "\"\"\"\n        Main metric result. Max GPU usage.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU._f": [[81, 95], ["time.monotonic", "time.sleep", "GPUtil.getGPUs", "time.monotonic"], "methods", ["None"], ["", "def", "_f", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Until a stop signal is encountered,\n        this function monitors each `every` seconds\n        the maximum amount of GPU used by the process\n        \"\"\"", "\n", "start_time", "=", "time", ".", "monotonic", "(", ")", "\n", "while", "not", "self", ".", "stop_f", ":", "\n", "# GPU percentage", "\n", "            ", "gpu_perc", "=", "GPUtil", ".", "getGPUs", "(", ")", "[", "self", ".", "gpu_id", "]", ".", "load", "*", "100", "\n", "if", "gpu_perc", ">", "self", ".", "max_usage", ":", "\n", "                ", "self", ".", "max_usage", "=", "gpu_perc", "\n", "", "time", ".", "sleep", "(", "self", ".", "every", "-", "(", "(", "time", ".", "monotonic", "(", ")", "-", "start_time", ")", "\n", "%", "self", ".", "every", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread": [[96, 102], ["threading.Thread", "gpu_usage.MaxGPU.thread.start"], "methods", ["None"], ["", "", "def", "start_thread", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "gpu_id", "is", "not", "None", ":", "\n", "            ", "assert", "not", "self", ".", "thread", ",", "\"Trying to start thread \"", "\"without joining the previous.\"", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "_f", ",", "daemon", "=", "True", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread": [[103, 109], ["gpu_usage.MaxGPU.thread.join"], "methods", ["None"], ["", "", "def", "stop_thread", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "thread", ":", "\n", "            ", "self", ".", "stop_f", "=", "True", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "stop_f", "=", "False", "\n", "self", ".", "thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.reset": [[110, 117], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the metric.\n\n        :return: None.\n        \"\"\"", "\n", "self", ".", "max_usage", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.result": [[118, 125], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", "->", "Optional", "[", "float", "]", ":", "\n", "        ", "\"\"\"\n        Returns the max GPU percentage value.\n\n        :return: The percentage GPU usage as a float value in range [0, 1].\n        \"\"\"", "\n", "return", "self", ".", "max_usage", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.update": [[126, 128], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.__init__": [[131, 138], ["gpu_usage.MaxGPU", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gpu_id", ",", "every", ",", "reset_at", ",", "emit_at", ",", "mode", ")", ":", "\n", "        ", "self", ".", "gpu_id", "=", "gpu_id", "\n", "self", ".", "_gpu", "=", "MaxGPU", "(", "gpu_id", ",", "every", ")", "\n", "\n", "super", "(", "GPUPluginMetric", ",", "self", ")", ".", "__init__", "(", "\n", "self", ".", "_gpu", ",", "reset_at", "=", "reset_at", ",", "emit_at", "=", "emit_at", ",", "\n", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update": [[139, 141], ["gpu_usage.GPUPluginMetric._gpu.update"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.GPUPluginMetric.update"], ["", "def", "update", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "self", ".", "_gpu", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MinibatchMaxGPU.__init__": [[149, 160], ["gpu_usage.GPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "gpu_id", ",", "every", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Minibatch Max GPU metric\n\n        :param gpu_id: GPU device ID.\n        :param every: seconds after which update the maximum GPU\n            usage\n        \"\"\"", "\n", "super", "(", "MinibatchMaxGPU", ",", "self", ")", ".", "__init__", "(", "\n", "gpu_id", ",", "every", ",", "\n", "reset_at", "=", "'iteration'", ",", "emit_at", "=", "'iteration'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MinibatchMaxGPU.before_training": [[161, 165], ["super().before_training", "gpu_usage.MinibatchMaxGPU._gpu.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ")", "\n", "self", ".", "_gpu", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MinibatchMaxGPU.after_training": [[166, 169], ["super().before_training", "gpu_usage.MinibatchMaxGPU._gpu.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ")", "\n", "self", ".", "_gpu", ".", "stop_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MinibatchMaxGPU.__str__": [[170, 172], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"MaxGPU{self.gpu_id}Usage_MB\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.__init__": [[180, 191], ["gpu_usage.GPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "gpu_id", ",", "every", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the epoch Max GPU metric.\n\n        :param gpu_id: GPU device ID.\n        :param every: seconds after which update the maximum GPU\n            usage\n        \"\"\"", "\n", "super", "(", "EpochMaxGPU", ",", "self", ")", ".", "__init__", "(", "\n", "gpu_id", ",", "every", ",", "\n", "reset_at", "=", "'epoch'", ",", "emit_at", "=", "'epoch'", ",", "mode", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training": [[192, 195], ["super().before_training", "gpu_usage.EpochMaxGPU._gpu.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.before_training", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_training", "(", "strategy", ")", "\n", "self", ".", "_gpu", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.after_training": [[196, 198], ["gpu_usage.EpochMaxGPU._gpu.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_training", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "None", ":", "\n", "        ", "self", ".", "_gpu", ".", "stop_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.EpochMaxGPU.__str__": [[199, 201], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"MaxGPU{self.gpu_id}Usage_Epoch\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.ExperienceMaxGPU.__init__": [[209, 220], ["gpu_usage.GPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "gpu_id", ",", "every", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Experience CPU usage metric.\n\n        :param gpu_id: GPU device ID.\n        :param every: seconds after which update the maximum GPU\n            usage\n        \"\"\"", "\n", "super", "(", "ExperienceMaxGPU", ",", "self", ")", ".", "__init__", "(", "\n", "gpu_id", ",", "every", ",", "\n", "reset_at", "=", "'experience'", ",", "emit_at", "=", "'experience'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.ExperienceMaxGPU.before_eval": [[221, 224], ["super().before_eval", "gpu_usage.ExperienceMaxGPU._gpu.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "_gpu", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.ExperienceMaxGPU.after_eval": [[225, 228], ["super().after_eval", "gpu_usage.ExperienceMaxGPU._gpu.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", ":", "\n", "        ", "super", "(", ")", ".", "after_eval", "(", "strategy", ")", "\n", "self", ".", "_gpu", ".", "stop_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.ExperienceMaxGPU.__str__": [[229, 231], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"MaxGPU{self.gpu_id}Usage_Experience\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__": [[239, 250], ["gpu_usage.GPUPluginMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__init__"], ["def", "__init__", "(", "self", ",", "gpu_id", ",", "every", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Creates an instance of the Experience CPU usage metric.\n\n        :param gpu_id: GPU device ID.\n        :param every: seconds after which update the maximum GPU\n            usage\n        \"\"\"", "\n", "super", "(", "StreamMaxGPU", ",", "self", ")", ".", "__init__", "(", "\n", "gpu_id", ",", "every", ",", "\n", "reset_at", "=", "'stream'", ",", "emit_at", "=", "'stream'", ",", "mode", "=", "'eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval": [[251, 254], ["super().before_eval", "gpu_usage.StreamMaxGPU._gpu.start_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.before_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.start_thread"], ["", "def", "before_eval", "(", "self", ",", "strategy", ")", ":", "\n", "        ", "super", "(", ")", ".", "before_eval", "(", "strategy", ")", "\n", "self", ".", "_gpu", ".", "start_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval": [[255, 260], ["super().after_eval", "gpu_usage.StreamMaxGPU._gpu.stop_thread"], "methods", ["home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.after_eval", "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.MaxGPU.stop_thread"], ["", "def", "after_eval", "(", "self", ",", "strategy", ":", "'BaseStrategy'", ")", "->", "MetricResult", ":", "\n", "        ", "packed", "=", "super", "(", ")", ".", "after_eval", "(", "strategy", ")", "\n", "self", ".", "_gpu", ".", "stop_thread", "(", ")", "\n", "return", "packed", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.StreamMaxGPU.__str__": [[261, 263], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"MaxGPU{self.gpu_id}Usage_Stream\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mattdl_continualevaluation.metrics.gpu_usage.gpu_usage_metrics": [[265, 300], ["metrics.append", "metrics.append", "metrics.append", "metrics.append", "gpu_usage.MinibatchMaxGPU", "gpu_usage.EpochMaxGPU", "gpu_usage.ExperienceMaxGPU", "gpu_usage.StreamMaxGPU"], "function", ["None"], ["", "", "def", "gpu_usage_metrics", "(", "gpu_id", ",", "every", "=", "0.5", ",", "minibatch", "=", "False", ",", "epoch", "=", "False", ",", "\n", "experience", "=", "False", ",", "stream", "=", "False", ")", "->", "List", "[", "PluginMetric", "]", ":", "\n", "    ", "\"\"\"\n    Helper method that can be used to obtain the desired set of\n    plugin metrics.\n\n    :param gpu_id: GPU device ID.\n    :param every: seconds after which update the maximum GPU\n        usage\n    :param minibatch: If True, will return a metric able to log the minibatch\n        max GPU usage.\n    :param epoch: If True, will return a metric able to log the epoch\n        max GPU usage.\n    :param experience: If True, will return a metric able to log the experience\n        max GPU usage.\n    :param stream: If True, will return a metric able to log the evaluation\n        max stream GPU usage.\n\n    :return: A list of plugin metrics.\n    \"\"\"", "\n", "\n", "metrics", "=", "[", "]", "\n", "if", "minibatch", ":", "\n", "        ", "metrics", ".", "append", "(", "MinibatchMaxGPU", "(", "gpu_id", ",", "every", ")", ")", "\n", "\n", "", "if", "epoch", ":", "\n", "        ", "metrics", ".", "append", "(", "EpochMaxGPU", "(", "gpu_id", ",", "every", ")", ")", "\n", "\n", "", "if", "experience", ":", "\n", "        ", "metrics", ".", "append", "(", "ExperienceMaxGPU", "(", "gpu_id", ",", "every", ")", ")", "\n", "\n", "", "if", "stream", ":", "\n", "        ", "metrics", ".", "append", "(", "StreamMaxGPU", "(", "gpu_id", ",", "every", ")", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]]}