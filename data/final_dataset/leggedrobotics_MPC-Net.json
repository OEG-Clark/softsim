{"home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.replay_memory.ReplayMemory.__init__": [[8, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "        ", "self", ".", "capacity", "=", "capacity", "\n", "self", ".", "memory", "=", "[", "None", "]", "*", "capacity", "# pre-allocate memory", "\n", "self", ".", "position", "=", "0", "\n", "self", ".", "size", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.replay_memory.ReplayMemory.push": [[14, 26], ["sample.Sample.Sample", "min", "numpy.any", "numpy.isnan", "print"], "methods", ["None"], ["", "def", "push", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"Saves a sample.\"\"\"", "\n", "sample", "=", "Sample", "(", "*", "args", ")", "\n", "for", "elem", "in", "sample", ":", "\n", "            ", "if", "elem", "is", "not", "None", ":", "\n", "                ", "if", "np", ".", "any", "(", "np", ".", "isnan", "(", "elem", ")", ")", ":", "\n", "                    ", "print", "(", "\"Avoided pushing NaN into memory\"", ",", "elem", ")", "\n", "return", "\n", "\n", "", "", "", "self", ".", "size", "=", "min", "(", "self", ".", "size", "+", "1", ",", "self", ".", "capacity", ")", "\n", "self", ".", "memory", "[", "self", ".", "position", "]", "=", "sample", "\n", "self", ".", "position", "=", "(", "self", ".", "position", "+", "1", ")", "%", "self", ".", "capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.replay_memory.ReplayMemory.sample": [[27, 29], ["random.sample"], "methods", ["home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.replay_memory.ReplayMemory.sample"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "random", ".", "sample", "(", "self", ".", "memory", "[", "0", ":", "self", ".", "size", "]", ",", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.replay_memory.ReplayMemory.__len__": [[30, 32], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_evaluation.plot": [[14, 51], ["torch.load", "numpy.zeros", "numpy.zeros", "int", "range", "numpy.transpose", "matplotlib.figure", "matplotlib.plot", "matplotlib.legend", "numpy.transpose", "torch.tensor", "torch.load.", "torch.mm.t().detach().numpy().astype", "mpc.computeFlowMap", "iter", "numpy.transpose", "len", "torch.mm", "numpy.transpose", "int", "p.t", "torch.mm.t().detach().numpy", "torch.mm.t().detach", "torch.mm.t"], "function", ["home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_evaluation.plot"], ["def", "plot", "(", "save_path", ",", "t_end", "=", "10.0", ")", ":", "\n", "    ", "policy", "=", "torch", ".", "load", "(", "save_path", ")", "\n", "\n", "dt", "=", "1.", "/", "400.", "\n", "tx0", "=", "np", ".", "zeros", "(", "(", "mpc", ".", "STATE_DIM", "+", "1", ",", "1", ")", ")", "\n", "tx0", "[", "1", ",", "0", "]", "=", "-", "0.5", "\n", "tx0", "[", "2", ",", "0", "]", "=", "0.5", "\n", "\n", "tx_history", "=", "np", ".", "zeros", "(", "(", "int", "(", "t_end", "/", "dt", ")", "+", "1", ",", "mpc", ".", "STATE_DIM", "+", "1", ")", ")", "\n", "\n", "tx", "=", "tx0", "\n", "average_constraint_violation", "=", "0", "\n", "steps", "=", "int", "(", "t_end", "/", "dt", ")", "\n", "\n", "for", "it", "in", "range", "(", "steps", ")", ":", "\n", "        ", "tx_history", "[", "it", ",", ":", "]", "=", "np", ".", "transpose", "(", "tx", ")", "\n", "tx_torch", "=", "torch", ".", "tensor", "(", "np", ".", "transpose", "(", "tx", ")", ",", "dtype", "=", "torch", ".", "float", ",", "requires_grad", "=", "False", ")", "\n", "tx_torch", "[", "0", "]", "[", "0", "]", "=", "0.0", "#optionally run it in MPC style", "\n", "\n", "p", ",", "u_pred", "=", "policy", "(", "tx_torch", ")", "\n", "if", "len", "(", "p", ")", ">", "1", ":", "\n", "            ", "u", "=", "torch", ".", "mm", "(", "p", ".", "t", "(", ")", ",", "u_pred", ")", "\n", "", "else", ":", "\n", "            ", "u", "=", "u_pred", "[", "0", "]", "\n", "\n", "", "u_np", "=", "u", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "\n", "dx", "=", "mpc", ".", "computeFlowMap", "(", "tx", "[", "0", "]", ",", "tx", "[", "1", ":", "]", ",", "u_np", ")", "\n", "\n", "np", ".", "transpose", "(", "tx", "[", "1", ":", "]", ")", "[", "0", "]", "+=", "dx", "*", "dt", "\n", "tx", "[", "0", "]", "+=", "dt", "\n", "\n", "", "tx_history", "[", "it", "+", "1", ",", ":", "]", "=", "np", ".", "transpose", "(", "tx", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "lineObjects", "=", "plt", ".", "plot", "(", "tx_history", "[", ":", ",", "0", "]", ",", "tx_history", "[", ":", ",", "1", ":", "6", "]", ")", "\n", "plt", ".", "legend", "(", "iter", "(", "lineObjects", ")", ",", "(", "'px'", ",", "'py'", ",", "'thetaz'", ",", "'thetay'", ",", "'thetax'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.FlowMap.forward": [[50, 65], ["x.cpu", "u.cpu", "ctx.save_for_backward", "x.cpu.t().detach().numpy().astype", "u.cpu.t().detach().numpy().astype", "torch.tensor", "mpc.computeFlowMap", "x.cpu.t().detach().numpy", "u.cpu.t().detach().numpy", "x.cpu.t().detach", "u.cpu.t().detach", "x.cpu.t", "u.cpu.t"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "t", ",", "x", ",", "u", ")", ":", "\n", "        ", "\"\"\"\n        In the forward pass we receive a Tensor containing the input and return\n        a Tensor containing the output. ctx is a context object that can be used\n        to stash information for backward computation. You can cache arbitrary\n        objects for use in the backward pass using the ctx.save_for_backward method.\n        \"\"\"", "\n", "x_cpu", "=", "x", ".", "cpu", "(", ")", "\n", "u_cpu", "=", "u", ".", "cpu", "(", ")", "\n", "ctx", ".", "save_for_backward", "(", "t", ",", "x_cpu", ",", "u_cpu", ")", "\n", "x_np", "=", "x_cpu", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "u_np", "=", "u_cpu", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "xDot", "=", "torch", ".", "tensor", "(", "mpc", ".", "computeFlowMap", "(", "t", ",", "x_np", ",", "u_np", ")", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "return", "xDot", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.FlowMap.backward": [[66, 89], ["x.t().detach().numpy().astype", "u.t().detach().numpy().astype", "NotImplementedError", "mpc.setFlowMapDerivativeStateAndControl", "torch.tensor", "torch.matmul().reshape", "mpc.setFlowMapDerivativeStateAndControl", "torch.tensor", "torch.matmul().reshape", "x.t().detach().numpy", "u.t().detach().numpy", "mpc.computeFlowMapDerivativeState", "mpc.computeFlowMapDerivativeInput", "torch.matmul", "torch.matmul", "x.t().detach", "u.t().detach", "x.t", "u.t"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "\"\"\"\n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n        \"\"\"", "\n", "grad_t", "=", "grad_x", "=", "grad_u", "=", "None", "\n", "t", ",", "x", ",", "u", "=", "ctx", ".", "saved_tensors", "\n", "x_np", "=", "x", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "u_np", "=", "u", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Derivative of dynamics w.r.t. time not available\"", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "            ", "mpc", ".", "setFlowMapDerivativeStateAndControl", "(", "t", ",", "x_np", ",", "u_np", ")", "\n", "dfdx", "=", "torch", ".", "tensor", "(", "mpc", ".", "computeFlowMapDerivativeState", "(", ")", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "grad_x", "=", "torch", ".", "matmul", "(", "grad_output", ",", "dfdx", ")", ".", "reshape", "(", "(", "-", "1", ",", "x_np", ".", "size", ")", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "2", "]", ":", "\n", "            ", "mpc", ".", "setFlowMapDerivativeStateAndControl", "(", "t", ",", "x_np", ",", "u_np", ")", "\n", "dfdu", "=", "torch", ".", "tensor", "(", "mpc", ".", "computeFlowMapDerivativeInput", "(", ")", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "grad_u", "=", "torch", ".", "matmul", "(", "grad_output", ",", "dfdu", ")", ".", "reshape", "(", "(", "-", "1", ",", "u_np", ".", "size", ")", ")", "\n", "", "return", "grad_t", ",", "grad_x", ",", "grad_u", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.IntermediateCost.forward": [[92, 107], ["x.cpu", "u.cpu", "ctx.save_for_backward", "x.cpu.t().detach().numpy().astype", "u.cpu.t().detach().numpy().astype", "torch.tensor", "mpc.getIntermediateCost", "x.cpu.t().detach().numpy", "u.cpu.t().detach().numpy", "x.cpu.t().detach", "u.cpu.t().detach", "x.cpu.t", "u.cpu.t"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "t", ",", "x", ",", "u", ")", ":", "\n", "        ", "\"\"\"\n        In the forward pass we receive a Tensor containing the input and return\n        a Tensor containing the output. ctx is a context object that can be used\n        to stash information for backward computation. You can cache arbitrary\n        objects for use in the backward pass using the ctx.save_for_backward method.\n        \"\"\"", "\n", "x_cpu", "=", "x", ".", "cpu", "(", ")", "\n", "u_cpu", "=", "u", ".", "cpu", "(", ")", "\n", "ctx", ".", "save_for_backward", "(", "t", ",", "x_cpu", ",", "u_cpu", ")", "\n", "x_np", "=", "x_cpu", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "u_np", "=", "u_cpu", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "L", "=", "torch", ".", "tensor", "(", "mpc", ".", "getIntermediateCost", "(", "t", ",", "x_np", ",", "u_np", ")", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "return", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.IntermediateCost.backward": [[108, 129], ["x.t().detach().numpy().astype", "u.t().detach().numpy().astype", "NotImplementedError", "torch.tensor", "torch.tensor", "x.t().detach().numpy", "u.t().detach().numpy", "x.t().detach", "u.t().detach", "mpc.getIntermediateCostDerivativeState", "mpc.getIntermediateCostDerivativeInput", "x.t", "u.t"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "\"\"\"\n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n        \"\"\"", "\n", "grad_t", "=", "grad_x", "=", "grad_u", "=", "None", "\n", "t", ",", "x", ",", "u", "=", "ctx", ".", "saved_tensors", "\n", "x_np", "=", "x", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "u_np", "=", "u", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Derivative of RunningCost w.r.t. time not available\"", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "            ", "dLdx", "=", "torch", ".", "tensor", "(", "[", "[", "mpc", ".", "getIntermediateCostDerivativeState", "(", "t", ",", "x_np", ",", "u_np", ")", "]", "]", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "grad_x", "=", "grad_output", "*", "dLdx", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "2", "]", ":", "\n", "            ", "dLdu", "=", "torch", ".", "tensor", "(", "[", "[", "mpc", ".", "getIntermediateCostDerivativeInput", "(", "t", ",", "x_np", ",", "u_np", ")", "]", "]", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "grad_u", "=", "grad_output", "*", "dLdu", "\n", "", "return", "grad_t", ",", "grad_x", ",", "grad_u", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.StateInputConstraint.forward": [[132, 147], ["x.cpu", "u.cpu", "ctx.save_for_backward", "x.cpu.t().detach().numpy().astype", "u.cpu.t().detach().numpy().astype", "torch.tensor", "mpc.getStateInputConstraint", "x.cpu.t().detach().numpy", "u.cpu.t().detach().numpy", "x.cpu.t().detach", "u.cpu.t().detach", "x.cpu.t", "u.cpu.t"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "t", ",", "x", ",", "u", ")", ":", "\n", "        ", "\"\"\"\n        In the forward pass we receive a Tensor containing the input and return\n        a Tensor containing the output. ctx is a context object that can be used\n        to stash information for backward computation. You can cache arbitrary\n        objects for use in the backward pass using the ctx.save_for_backward method.\n        \"\"\"", "\n", "x_cpu", "=", "x", ".", "cpu", "(", ")", "\n", "u_cpu", "=", "u", ".", "cpu", "(", ")", "\n", "ctx", ".", "save_for_backward", "(", "t", ",", "x_cpu", ",", "u_cpu", ")", "\n", "x_np", "=", "x_cpu", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "u_np", "=", "u_cpu", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "g1", "=", "torch", ".", "tensor", "(", "mpc", ".", "getStateInputConstraint", "(", "t", ",", "x_np", ",", "u_np", ")", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "return", "g1", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.StateInputConstraint.backward": [[148, 168], ["x.t().detach().numpy().astype", "u.t().detach().numpy().astype", "NotImplementedError", "NotImplementedError", "torch.tensor", "torch.matmul().reshape", "x.t().detach().numpy", "u.t().detach().numpy", "mpc.getStateInputConstraintDerivativeControl", "torch.matmul", "x.t().detach", "u.t().detach", "x.t", "u.t"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "\"\"\"\n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n        \"\"\"", "\n", "grad_t", "=", "grad_x", "=", "grad_u", "=", "None", "\n", "t", ",", "x", ",", "u", "=", "ctx", ".", "saved_tensors", "\n", "x_np", "=", "x", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "u_np", "=", "u", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Derivative of StateInputConstraint w.r.t. time not available\"", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "1", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Derivative of StateInputConstraint w.r.t. state not available\"", ")", "\n", "", "if", "ctx", ".", "needs_input_grad", "[", "2", "]", ":", "\n", "            ", "dg1du", "=", "torch", ".", "tensor", "(", "mpc", ".", "getStateInputConstraintDerivativeControl", "(", "t", ",", "x_np", ",", "u_np", ")", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "grad_u", "=", "torch", ".", "matmul", "(", "grad_output", ",", "dg1du", ")", ".", "reshape", "(", "(", "-", "1", ",", "u_np", ".", "size", ")", ")", "\n", "", "return", "grad_t", ",", "grad_x", ",", "grad_u", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.getTargetTrajectories": [[21, 35], ["BallbotPyBindings.scalar_array", "BallbotPyBindings.scalar_array.resize", "BallbotPyBindings.dynamic_vector_array", "BallbotPyBindings.dynamic_vector_array.resize", "numpy.zeros", "BallbotPyBindings.dynamic_vector_array", "BallbotPyBindings.dynamic_vector_array.resize", "numpy.zeros", "BallbotPyBindings.cost_desired_trajectories"], "function", ["None"], ["def", "getTargetTrajectories", "(", ")", ":", "\n", "    ", "desiredTimeTraj", "=", "scalar_array", "(", ")", "\n", "desiredTimeTraj", ".", "resize", "(", "1", ")", "\n", "desiredTimeTraj", "[", "0", "]", "=", "2.0", "\n", "\n", "desiredInputTraj", "=", "dynamic_vector_array", "(", ")", "\n", "desiredInputTraj", ".", "resize", "(", "1", ")", "\n", "desiredInputTraj", "[", "0", "]", "=", "np", ".", "zeros", "(", "(", "mpc", ".", "INPUT_DIM", ",", "1", ")", ")", "\n", "\n", "desiredStateTraj", "=", "dynamic_vector_array", "(", ")", "\n", "desiredStateTraj", ".", "resize", "(", "1", ")", "\n", "desiredStateTraj", "[", "0", "]", "=", "np", ".", "zeros", "(", "(", "mpc", ".", "STATE_DIM", ",", "1", ")", ")", "\n", "\n", "return", "cost_desired_trajectories", "(", "desiredTimeTraj", ",", "desiredStateTraj", ",", "desiredInputTraj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.loss_function": [[170, 178], ["FlowMap.apply", "IntermediateCost.apply", "dVdx.dot", "StateInputConstraint.apply", "StateInputConstraint.apply.dot"], "function", ["None"], ["", "", "def", "loss_function", "(", "tx", ",", "u_pred", ",", "dVdx", ",", "nu", ")", ":", "\n", "    ", "f", "=", "FlowMap", ".", "apply", "(", "tx", "[", "0", "]", ",", "tx", "[", "1", ":", "]", ",", "u_pred", ")", "\n", "L", "=", "IntermediateCost", ".", "apply", "(", "tx", "[", "0", "]", ",", "tx", "[", "1", ":", "]", ",", "u_pred", ")", "\n", "loss", "=", "L", "+", "dVdx", ".", "dot", "(", "f", ")", "\n", "if", "systemHasConstraints", ":", "\n", "        ", "g1", "=", "StateInputConstraint", ".", "apply", "(", "tx", "[", "0", "]", ",", "tx", "[", "1", ":", "]", ",", "u_pred", ")", "\n", "loss", "+=", "g1", ".", "dot", "(", "nu", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.num_samples_per_trajectory_point": [[180, 189], ["numpy.exp", "numpy.log"], "function", ["None"], ["", "def", "num_samples_per_trajectory_point", "(", "t", ",", "max_num_points", ",", "half_value_decay_t", ")", ":", "\n", "    ", "\"\"\"\n    Calculates number of samples drawn for each nominal state point in trajectory\n    :param t: Query time along trajectory\n    :param max_num_points:\n    :param half_value_decay_t: time into trajectory after which number of sampled point is halfed\n    :return: Number of samples to be drawn\n    \"\"\"", "\n", "return", "max_num_points", "*", "np", ".", "exp", "(", "-", "np", ".", "log", "(", "2", ")", "*", "t", "/", "half_value_decay_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.ballbot_learner.trajectoryCost": [[191, 215], ["range", "numpy.zeros", "numpy.concatenate", "range", "int", "torch.tensor", "policy", "torch.matmul.t().detach().numpy().astype", "torch.tensor", "numpy.isnan", "mpc.computeFlowMap", "numpy.concatenate", "len", "torch.matmul", "mpc.getIntermediateCost", "mpc.computeFlowMap.reshape", "torch.matmul.t().detach().numpy", "torch.matmul.t().detach", "torch.matmul.t"], "function", ["None"], ["", "def", "trajectoryCost", "(", "policy", ",", "duration", ",", "dt_control", ")", ":", "\n", "    ", "cost", "=", "0.0", "# running sum", "\n", "numStartingPoints", "=", "1", "\n", "for", "_", "in", "range", "(", "numStartingPoints", ")", ":", "\n", "        ", "startPos", "=", "np", ".", "zeros", "(", "[", "mpc", ".", "STATE_DIM", ",", "1", "]", ")", "\n", "tx", "=", "np", ".", "concatenate", "(", "(", "[", "[", "0.0", "]", "]", ",", "startPos", ")", ")", "\n", "for", "it", "in", "range", "(", "int", "(", "duration", "/", "dt_control", ")", ")", ":", "\n", "            ", "ttx_torch", "=", "torch", ".", "tensor", "(", "np", ".", "concatenate", "(", "(", "tx", "[", "0", ",", "0", "]", ",", "tx", "[", "1", ":", "]", ")", ",", "axis", "=", "None", ")", ",", "dtype", "=", "dtype", ",", "\n", "device", "=", "device", ",", "requires_grad", "=", "False", ")", "\n", "p", ",", "u_pred", "=", "policy", "(", "ttx_torch", ")", "\n", "if", "len", "(", "p", ")", ">", "1", ":", "\n", "                ", "u", "=", "torch", ".", "matmul", "(", "p", ",", "u_pred", ")", "\n", "", "else", ":", "\n", "                ", "u", "=", "u_pred", "[", "0", "]", "\n", "\n", "", "u_np", "=", "u", ".", "t", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "'float64'", ")", "\n", "cost", "+=", "torch", ".", "tensor", "(", "mpc", ".", "getIntermediateCost", "(", "tx", "[", "0", "]", ",", "tx", "[", "1", ":", "]", ",", "u_np", ")", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "if", "np", ".", "isnan", "(", "cost", ")", ":", "\n", "                ", "return", "np", ".", "nan", ",", "tx", "[", "0", "]", "\n", "", "dx", "=", "mpc", ".", "computeFlowMap", "(", "tx", "[", "0", "]", ",", "tx", "[", "1", ":", "]", ",", "u_np", ")", "\n", "\n", "tx", "[", "1", ":", "]", "+=", "dx", ".", "reshape", "(", "mpc", ".", "STATE_DIM", ",", "1", ")", "*", "dt_control", "\n", "tx", "[", "0", ",", "0", "]", "+=", "dt_control", "\n", "", "", "return", "cost", ",", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.LinearPolicy.__init__": [[5, 9], ["super().__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.ExpertMixturePolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_in", ",", "d_out", ")", ":", "\n", "        ", "super", "(", "LinearPolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "d_in", ",", "d_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.LinearPolicy.forward": [[11, 14], ["PolicyNet.LinearPolicy.linear().reshape", "torch.ones", "PolicyNet.LinearPolicy.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tx", ")", ":", "\n", "        ", "u", "=", "self", ".", "linear", "(", "tx", ")", ".", "reshape", "(", "(", "1", ",", "self", ".", "d_out", ")", ")", "\n", "return", "torch", ".", "ones", "(", "(", "1", ",", "1", ")", ")", ",", "u", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.LinearPolicy.logParameters": [[15, 19], ["list", "PolicyNet.LinearPolicy.named_parameters", "range", "len", "writer.add_scalar", "param[].data.view", "[].item", "str", "param[].data.view"], "methods", ["None"], ["", "def", "logParameters", "(", "self", ",", "writer", ",", "it", ")", ":", "\n", "        ", "for", "param", "in", "list", "(", "self", ".", "named_parameters", "(", "prefix", "=", "'LinearPolicy'", ",", "recurse", "=", "True", ")", ")", ":", "\n", "            ", "for", "scalar_it", "in", "range", "(", "len", "(", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", ")", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "param", "[", "0", "]", "+", "\"/\"", "+", "str", "(", "scalar_it", ")", ",", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", "[", "scalar_it", "]", ".", "item", "(", ")", ",", "it", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.NonlinearPolicy.__init__": [[22, 33], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.ExpertMixturePolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_in", ",", "d_out", ")", ":", "\n", "        ", "super", "(", "NonlinearPolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "n_hidden", "=", "d_in", "*", "2", "*", "2", "\n", "\n", "self", ".", "linear1", "=", "torch", ".", "nn", ".", "Linear", "(", "d_in", ",", "self", ".", "n_hidden", ")", "\n", "self", ".", "activation1", "=", "torch", ".", "tanh", "\n", "self", ".", "linear2", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "n_hidden", ",", "self", ".", "n_hidden", ")", "\n", "self", ".", "activation2", "=", "torch", ".", "tanh", "\n", "self", ".", "linear3", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "n_hidden", ",", "self", ".", "d_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.NonlinearPolicy.forward": [[34, 38], ["PolicyNet.NonlinearPolicy.activation1", "PolicyNet.NonlinearPolicy.linear3().reshape", "PolicyNet.NonlinearPolicy.linear1", "torch.ones", "PolicyNet.NonlinearPolicy.linear3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tx", ")", ":", "\n", "        ", "z_h1", "=", "self", ".", "activation1", "(", "self", ".", "linear1", "(", "tx", ")", ")", "\n", "u", "=", "self", ".", "linear3", "(", "z_h1", ")", ".", "reshape", "(", "(", "1", ",", "self", ".", "d_out", ")", ")", "\n", "return", "torch", ".", "ones", "(", "(", "1", ",", "1", ")", ")", ",", "u", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.NonlinearPolicy.logParameters": [[39, 43], ["list", "PolicyNet.NonlinearPolicy.named_parameters", "range", "len", "writer.add_scalar", "param[].data.view", "[].item", "str", "param[].data.view"], "methods", ["None"], ["", "def", "logParameters", "(", "self", ",", "writer", ",", "it", ")", ":", "\n", "        ", "for", "param", "in", "list", "(", "self", ".", "named_parameters", "(", "prefix", "=", "'NonlinearPolicy'", ",", "recurse", "=", "True", ")", ")", ":", "\n", "            ", "for", "scalar_it", "in", "range", "(", "len", "(", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", ")", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "param", "[", "0", "]", "+", "\"/\"", "+", "str", "(", "scalar_it", ")", ",", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", "[", "scalar_it", "]", ".", "item", "(", ")", ",", "it", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.TwoLayerNLP.__init__": [[46, 57], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.ExpertMixturePolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_in", ",", "d_out", ")", ":", "\n", "        ", "super", "(", "TwoLayerNLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "n_hidden", "=", "128", "\n", "\n", "self", ".", "linear1", "=", "torch", ".", "nn", ".", "Linear", "(", "d_in", ",", "self", ".", "n_hidden", ")", "\n", "self", ".", "activation1", "=", "torch", ".", "tanh", "\n", "self", ".", "linear2", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "n_hidden", ",", "self", ".", "n_hidden", ")", "\n", "self", ".", "activation2", "=", "torch", ".", "tanh", "\n", "self", ".", "linear3", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "n_hidden", ",", "self", ".", "d_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.TwoLayerNLP.forward": [[58, 63], ["PolicyNet.TwoLayerNLP.activation1", "PolicyNet.TwoLayerNLP.activation2", "PolicyNet.TwoLayerNLP.linear3().reshape", "PolicyNet.TwoLayerNLP.linear1", "PolicyNet.TwoLayerNLP.linear2", "torch.ones", "PolicyNet.TwoLayerNLP.linear3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tx", ")", ":", "\n", "        ", "z_h1", "=", "self", ".", "activation1", "(", "self", ".", "linear1", "(", "tx", ")", ")", "\n", "z_h2", "=", "self", ".", "activation2", "(", "self", ".", "linear2", "(", "z_h1", ")", ")", "\n", "u", "=", "self", ".", "linear3", "(", "z_h2", ")", ".", "reshape", "(", "(", "1", ",", "self", ".", "d_out", ")", ")", "\n", "return", "torch", ".", "ones", "(", "(", "1", ",", "1", ")", ")", ",", "u", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.TwoLayerNLP.logParameters": [[64, 68], ["list", "PolicyNet.TwoLayerNLP.named_parameters", "range", "len", "writer.add_scalar", "param[].data.view", "[].item", "str", "param[].data.view"], "methods", ["None"], ["", "def", "logParameters", "(", "self", ",", "writer", ",", "it", ")", ":", "\n", "        ", "for", "param", "in", "list", "(", "self", ".", "named_parameters", "(", "prefix", "=", "'TwoLayerNLP'", ",", "recurse", "=", "True", ")", ")", ":", "\n", "            ", "for", "scalar_it", "in", "range", "(", "len", "(", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", ")", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "param", "[", "0", "]", "+", "\"/\"", "+", "str", "(", "scalar_it", ")", ",", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", "[", "scalar_it", "]", ".", "item", "(", ")", ",", "it", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.ExpertMixturePolicy.__init__": [[71, 89], ["super().__init__", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.ExpertMixturePolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_in", ",", "d_out", ")", ":", "\n", "        ", "super", "(", "ExpertMixturePolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_experts", "=", "8", "\n", "self", ".", "n_hidden", "=", "d_in", "*", "4", "\n", "self", ".", "d_out", "=", "d_out", "\n", "\n", "self", ".", "linear1", "=", "torch", ".", "nn", ".", "Linear", "(", "d_in", ",", "self", ".", "n_hidden", ")", "\n", "self", ".", "activation1", "=", "torch", ".", "tanh", "\n", "\n", "self", ".", "selector_net", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "n_hidden", ",", "self", ".", "num_experts", ")", ",", "\n", "# torch.nn.Softmax(dim=-1)", "\n", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "\n", "self", ".", "expert_net", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "n_hidden", ",", "d_out", "*", "self", ".", "num_experts", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.ExpertMixturePolicy.forward": [[91, 99], ["PolicyNet.ExpertMixturePolicy.activation1", "PolicyNet.ExpertMixturePolicy.selector_net", "PolicyNet.ExpertMixturePolicy.expert_net().reshape", "PolicyNet.ExpertMixturePolicy.linear1", "PolicyNet.ExpertMixturePolicy.sum", "PolicyNet.ExpertMixturePolicy.expert_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tx", ")", ":", "\n", "        ", "z_h", "=", "self", ".", "activation1", "(", "self", ".", "linear1", "(", "tx", ")", ")", "\n", "pi_nonNormalized", "=", "self", ".", "selector_net", "(", "z_h", ")", "\n", "pi", "=", "pi_nonNormalized", "/", "pi_nonNormalized", ".", "sum", "(", ")", "\n", "\n", "u_experts", "=", "self", ".", "expert_net", "(", "z_h", ")", ".", "reshape", "(", "(", "self", ".", "num_experts", ",", "self", ".", "d_out", ")", ")", "\n", "\n", "return", "pi", ",", "u_experts", "\n", "\n"]], "home.repos.pwc.inspect_result.leggedrobotics_MPC-Net.None.PolicyNet.ExpertMixturePolicy.logParameters": [[100, 104], ["list", "PolicyNet.ExpertMixturePolicy.named_parameters", "range", "len", "writer.add_scalar", "param[].data.view", "[].item", "str", "param[].data.view"], "methods", ["None"], ["", "def", "logParameters", "(", "self", ",", "writer", ",", "it", ")", ":", "\n", "        ", "for", "param", "in", "list", "(", "self", ".", "named_parameters", "(", "prefix", "=", "'ExpertMixPolicy'", ",", "recurse", "=", "True", ")", ")", ":", "\n", "            ", "for", "scalar_it", "in", "range", "(", "len", "(", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", ")", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "param", "[", "0", "]", "+", "\"/\"", "+", "str", "(", "scalar_it", ")", ",", "param", "[", "1", "]", ".", "data", ".", "view", "(", "-", "1", ")", "[", "scalar_it", "]", ".", "item", "(", ")", ",", "it", ")", "\n", "", "", "", "", ""]]}