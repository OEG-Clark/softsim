{"home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupRandomCrop.__init__": [[12, 17], ["isinstance", "int", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupRandomCrop.__call__": [[18, 37], ["list", "random.randint", "random.randint", "list.append", "list.append", "img.crop"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "img_tuple", ")", ":", "\n", "        ", "img_group", ",", "label", "=", "img_tuple", "\n", "\n", "w", ",", "h", "=", "img_group", "[", "0", "]", ".", "size", "\n", "th", ",", "tw", "=", "self", ".", "size", "\n", "\n", "out_images", "=", "list", "(", ")", "\n", "\n", "x1", "=", "random", ".", "randint", "(", "0", ",", "w", "-", "tw", ")", "\n", "y1", "=", "random", ".", "randint", "(", "0", ",", "h", "-", "th", ")", "\n", "\n", "for", "img", "in", "img_group", ":", "\n", "            ", "assert", "(", "img", ".", "size", "[", "0", "]", "==", "w", "and", "img", ".", "size", "[", "1", "]", "==", "h", ")", "\n", "if", "w", "==", "tw", "and", "h", "==", "th", ":", "\n", "                ", "out_images", ".", "append", "(", "img", ")", "\n", "", "else", ":", "\n", "                ", "out_images", ".", "append", "(", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x1", "+", "tw", ",", "y1", "+", "th", ")", ")", ")", "\n", "\n", "", "", "return", "(", "out_images", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupCenterCrop.__init__": [[40, 42], ["torchvision.transforms.CenterCrop", "torchvision.transforms.CenterCrop", "torchvision.transforms.CenterCrop", "torchvision.transforms.CenterCrop"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "worker", "=", "torchvision", ".", "transforms", ".", "CenterCrop", "(", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupCenterCrop.__call__": [[43, 46], ["transforms.GroupCenterCrop.worker"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_tuple", ")", ":", "\n", "        ", "img_group", ",", "label", "=", "img_tuple", "\n", "return", "(", "[", "self", ".", "worker", "(", "img", ")", "for", "img", "in", "img_group", "]", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupNormalize.__init__": [[49, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupNormalize.__call__": [[53, 63], ["zip", "t.sub_().div_", "len", "len", "tensor.size", "tensor.size", "t.sub_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor_tuple", ")", ":", "\n", "        ", "tensor", ",", "label", "=", "tensor_tuple", "\n", "rep_mean", "=", "self", ".", "mean", "*", "(", "tensor", ".", "size", "(", ")", "[", "0", "]", "//", "len", "(", "self", ".", "mean", ")", ")", "\n", "rep_std", "=", "self", ".", "std", "*", "(", "tensor", ".", "size", "(", ")", "[", "0", "]", "//", "len", "(", "self", ".", "std", ")", ")", "\n", "\n", "# TODO: make efficient", "\n", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "rep_mean", ",", "rep_std", ")", ":", "\n", "            ", "t", ".", "sub_", "(", "m", ")", ".", "div_", "(", "s", ")", "\n", "\n", "", "return", "(", "tensor", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupGrayScale.__init__": [[66, 68], ["torchvision.transforms.Grayscale", "torchvision.transforms.Grayscale", "torchvision.transforms.Grayscale", "torchvision.transforms.Grayscale"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "worker", "=", "torchvision", ".", "transforms", ".", "Grayscale", "(", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupGrayScale.__call__": [[69, 72], ["transforms.GroupGrayScale.worker"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_tuple", ")", ":", "\n", "        ", "img_group", ",", "label", "=", "img_tuple", "\n", "return", "(", "[", "self", ".", "worker", "(", "img", ")", "for", "img", "in", "img_group", "]", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupScale.__init__": [[83, 85], ["torchvision.transforms.Resize", "torchvision.transforms.Resize", "torchvision.transforms.Resize", "torchvision.transforms.Resize"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "self", ".", "worker", "=", "torchvision", ".", "transforms", ".", "Resize", "(", "size", ",", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupScale.__call__": [[86, 89], ["transforms.GroupScale.worker"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_tuple", ")", ":", "\n", "        ", "img_group", ",", "label", "=", "img_tuple", "\n", "return", "(", "[", "self", ".", "worker", "(", "img", ")", "for", "img", "in", "img_group", "]", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop.__init__": [[93, 100], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "scales", "=", "None", ",", "max_distort", "=", "1", ",", "fix_crop", "=", "True", ",", "more_fix_crop", "=", "True", ")", ":", "\n", "        ", "self", ".", "scales", "=", "scales", "if", "scales", "is", "not", "None", "else", "[", "1", ",", "875", ",", ".75", ",", ".66", "]", "\n", "self", ".", "max_distort", "=", "max_distort", "\n", "self", ".", "fix_crop", "=", "fix_crop", "\n", "self", ".", "more_fix_crop", "=", "more_fix_crop", "\n", "self", ".", "input_size", "=", "input_size", "if", "not", "isinstance", "(", "input_size", ",", "int", ")", "else", "[", "input_size", ",", "input_size", "]", "\n", "self", ".", "interpolation", "=", "Image", ".", "BILINEAR", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop.__call__": [[101, 110], ["transforms.GroupMultiScaleCrop._sample_crop_size", "img.crop", "img.resize"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop._sample_crop_size"], ["", "def", "__call__", "(", "self", ",", "img_tuple", ")", ":", "\n", "        ", "img_group", ",", "label", "=", "img_tuple", "\n", "\n", "im_size", "=", "img_group", "[", "0", "]", ".", "size", "\n", "\n", "crop_w", ",", "crop_h", ",", "offset_w", ",", "offset_h", "=", "self", ".", "_sample_crop_size", "(", "im_size", ")", "\n", "crop_img_group", "=", "[", "img", ".", "crop", "(", "(", "offset_w", ",", "offset_h", ",", "offset_w", "+", "crop_w", ",", "offset_h", "+", "crop_h", ")", ")", "for", "img", "in", "img_group", "]", "\n", "ret_img_group", "=", "[", "img", ".", "resize", "(", "(", "self", ".", "input_size", "[", "0", "]", ",", "self", ".", "input_size", "[", "1", "]", ")", ",", "self", ".", "interpolation", ")", "for", "img", "in", "crop_img_group", "]", "\n", "return", "(", "ret_img_group", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop._sample_crop_size": [[111, 134], ["min", "enumerate", "random.choice", "int", "enumerate", "random.randint", "random.randint", "transforms.GroupMultiScaleCrop._sample_fix_offset", "abs", "abs", "abs", "pairs.append"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop._sample_fix_offset"], ["", "def", "_sample_crop_size", "(", "self", ",", "im_size", ")", ":", "\n", "        ", "image_w", ",", "image_h", "=", "im_size", "[", "0", "]", ",", "im_size", "[", "1", "]", "\n", "\n", "# find a crop size", "\n", "base_size", "=", "min", "(", "image_w", ",", "image_h", ")", "\n", "crop_sizes", "=", "[", "int", "(", "base_size", "*", "x", ")", "for", "x", "in", "self", ".", "scales", "]", "\n", "crop_h", "=", "[", "self", ".", "input_size", "[", "1", "]", "if", "abs", "(", "x", "-", "self", ".", "input_size", "[", "1", "]", ")", "<", "3", "else", "x", "for", "x", "in", "crop_sizes", "]", "\n", "crop_w", "=", "[", "self", ".", "input_size", "[", "0", "]", "if", "abs", "(", "x", "-", "self", ".", "input_size", "[", "0", "]", ")", "<", "3", "else", "x", "for", "x", "in", "crop_sizes", "]", "\n", "\n", "pairs", "=", "[", "]", "\n", "for", "i", ",", "h", "in", "enumerate", "(", "crop_h", ")", ":", "\n", "            ", "for", "j", ",", "w", "in", "enumerate", "(", "crop_w", ")", ":", "\n", "                ", "if", "abs", "(", "i", "-", "j", ")", "<=", "self", ".", "max_distort", ":", "\n", "                    ", "pairs", ".", "append", "(", "(", "w", ",", "h", ")", ")", "\n", "\n", "", "", "", "crop_pair", "=", "random", ".", "choice", "(", "pairs", ")", "\n", "if", "not", "self", ".", "fix_crop", ":", "\n", "            ", "w_offset", "=", "random", ".", "randint", "(", "0", ",", "image_w", "-", "crop_pair", "[", "0", "]", ")", "\n", "h_offset", "=", "random", ".", "randint", "(", "0", ",", "image_h", "-", "crop_pair", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "w_offset", ",", "h_offset", "=", "self", ".", "_sample_fix_offset", "(", "image_w", ",", "image_h", ",", "crop_pair", "[", "0", "]", ",", "crop_pair", "[", "1", "]", ")", "\n", "\n", "", "return", "crop_pair", "[", "0", "]", ",", "crop_pair", "[", "1", "]", ",", "w_offset", ",", "h_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop._sample_fix_offset": [[135, 138], ["transforms.GroupMultiScaleCrop.fill_fix_offset", "random.choice"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop.fill_fix_offset"], ["", "def", "_sample_fix_offset", "(", "self", ",", "image_w", ",", "image_h", ",", "crop_w", ",", "crop_h", ")", ":", "\n", "        ", "offsets", "=", "self", ".", "fill_fix_offset", "(", "self", ".", "more_fix_crop", ",", "image_w", ",", "image_h", ",", "crop_w", ",", "crop_h", ")", "\n", "return", "random", ".", "choice", "(", "offsets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.GroupMultiScaleCrop.fill_fix_offset": [[139, 162], ["list", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "fill_fix_offset", "(", "more_fix_crop", ",", "image_w", ",", "image_h", ",", "crop_w", ",", "crop_h", ")", ":", "\n", "        ", "w_step", "=", "(", "image_w", "-", "crop_w", ")", "//", "4", "\n", "h_step", "=", "(", "image_h", "-", "crop_h", ")", "//", "4", "\n", "\n", "ret", "=", "list", "(", ")", "\n", "ret", ".", "append", "(", "(", "0", ",", "0", ")", ")", "# upper left", "\n", "ret", ".", "append", "(", "(", "4", "*", "w_step", ",", "0", ")", ")", "# upper right", "\n", "ret", ".", "append", "(", "(", "0", ",", "4", "*", "h_step", ")", ")", "# lower left", "\n", "ret", ".", "append", "(", "(", "4", "*", "w_step", ",", "4", "*", "h_step", ")", ")", "# lower right", "\n", "ret", ".", "append", "(", "(", "2", "*", "w_step", ",", "2", "*", "h_step", ")", ")", "# center", "\n", "\n", "if", "more_fix_crop", ":", "\n", "            ", "ret", ".", "append", "(", "(", "0", ",", "2", "*", "h_step", ")", ")", "# center left", "\n", "ret", ".", "append", "(", "(", "4", "*", "w_step", ",", "2", "*", "h_step", ")", ")", "# center right", "\n", "ret", ".", "append", "(", "(", "2", "*", "w_step", ",", "4", "*", "h_step", ")", ")", "# lower center", "\n", "ret", ".", "append", "(", "(", "2", "*", "w_step", ",", "0", "*", "h_step", ")", ")", "# upper center", "\n", "\n", "ret", ".", "append", "(", "(", "1", "*", "w_step", ",", "1", "*", "h_step", ")", ")", "# upper left quarter", "\n", "ret", ".", "append", "(", "(", "3", "*", "w_step", ",", "1", "*", "h_step", ")", ")", "# upper right quarter", "\n", "ret", ".", "append", "(", "(", "1", "*", "w_step", ",", "3", "*", "h_step", ")", ")", "# lower left quarter", "\n", "ret", ".", "append", "(", "(", "3", "*", "w_step", ",", "3", "*", "h_step", ")", ")", "# lower righ quarter", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.Stack.__init__": [[166, 168], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "roll", "=", "False", ")", ":", "\n", "        ", "self", ".", "roll", "=", "roll", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.Stack.__call__": [[169, 179], ["numpy.concatenate", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "numpy.array"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_tuple", ")", ":", "\n", "        ", "img_group", ",", "label", "=", "img_tuple", "\n", "\n", "if", "img_group", "[", "0", "]", ".", "mode", "==", "'L'", ":", "\n", "            ", "return", "(", "np", ".", "concatenate", "(", "[", "np", ".", "expand_dims", "(", "x", ",", "2", ")", "for", "x", "in", "img_group", "]", ",", "axis", "=", "2", ")", ",", "label", ")", "\n", "", "elif", "img_group", "[", "0", "]", ".", "mode", "==", "'RGB'", ":", "\n", "            ", "if", "self", ".", "roll", ":", "\n", "                ", "return", "(", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "x", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "for", "x", "in", "img_group", "]", ",", "axis", "=", "2", ")", ",", "label", ")", "\n", "", "else", ":", "\n", "                ", "return", "(", "np", ".", "concatenate", "(", "img_group", ",", "axis", "=", "2", ")", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.ToTorchFormatTensor.__init__": [[184, 186], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "div", "=", "True", ")", ":", "\n", "        ", "self", ".", "div", "=", "div", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.ToTorchFormatTensor.__call__": [[187, 201], ["isinstance", "torch.from_numpy().permute().contiguous", "torch.ByteTensor", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.view", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose().transpose().contiguous", "torch.ByteStorage.from_buffer", "len", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.float().div", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.float", "torch.from_numpy().permute", "pic.tobytes", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose().transpose", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.float", "torch.from_numpy", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "pic_tuple", ")", ":", "\n", "        ", "pic", ",", "label", "=", "pic_tuple", "\n", "\n", "if", "isinstance", "(", "pic", ",", "np", ".", "ndarray", ")", ":", "\n", "# handle numpy array", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "pic", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# handle PIL Image", "\n", "            ", "img", "=", "torch", ".", "ByteTensor", "(", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "pic", ".", "tobytes", "(", ")", ")", ")", "\n", "img", "=", "img", ".", "view", "(", "pic", ".", "size", "[", "1", "]", ",", "pic", ".", "size", "[", "0", "]", ",", "len", "(", "pic", ".", "mode", ")", ")", "\n", "# put it from HWC to CHW format", "\n", "# yikes, this transpose takes 80% of the loading time/CPU", "\n", "img", "=", "img", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", "return", "(", "img", ".", "float", "(", ")", ".", "div", "(", "255.", ")", "if", "self", ".", "div", "else", "img", ".", "float", "(", ")", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.transforms.IdentityTransform.__call__": [[205, 207], ["None"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.AugmentOp.__init__": [[342, 363], ["hparams.copy", "rand_augment.AugmentOp.hparams.get"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "prob", "=", "0.5", ",", "magnitude", "=", "10", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "hparams", "=", "hparams", "or", "_HPARAMS_DEFAULT", "\n", "self", ".", "aug_fn", "=", "NAME_TO_OP", "[", "name", "]", "\n", "self", ".", "level_fn", "=", "LEVEL_TO_ARG", "[", "name", "]", "\n", "self", ".", "prob", "=", "prob", "\n", "self", ".", "magnitude", "=", "magnitude", "\n", "self", ".", "hparams", "=", "hparams", ".", "copy", "(", ")", "\n", "self", ".", "kwargs", "=", "{", "\n", "\"fillcolor\"", ":", "hparams", "[", "\"img_mean\"", "]", "\n", "if", "\"img_mean\"", "in", "hparams", "\n", "else", "_FILL", ",", "\n", "\"resample\"", ":", "hparams", "[", "\"interpolation\"", "]", "\n", "if", "\"interpolation\"", "in", "hparams", "\n", "else", "_RANDOM_INTERPOLATION", ",", "\n", "}", "\n", "\n", "# If magnitude_std is > 0, we introduce some randomness", "\n", "# in the usually fixed policy and sample magnitude from a normal distribution", "\n", "# with mean `magnitude` and std-dev of `magnitude_std`.", "\n", "# NOTE This is my own hack, being tested, not in papers or reference impls.", "\n", "self", ".", "magnitude_std", "=", "self", ".", "hparams", ".", "get", "(", "\"magnitude_std\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.AugmentOp.__call__": [[364, 383], ["min", "isinstance", "random.gauss", "max", "rand_augment.AugmentOp.level_fn", "rand_augment.AugmentOp.aug_fn", "random.random", "rand_augment.AugmentOp.aug_fn"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "def", "__call__", "(", "self", ",", "img_list", ")", ":", "\n", "        ", "if", "self", ".", "prob", "<", "1.0", "and", "random", ".", "random", "(", ")", ">", "self", ".", "prob", ":", "\n", "            ", "return", "img_list", "\n", "", "magnitude", "=", "self", ".", "magnitude", "\n", "if", "self", ".", "magnitude_std", "and", "self", ".", "magnitude_std", ">", "0", ":", "\n", "            ", "magnitude", "=", "random", ".", "gauss", "(", "magnitude", ",", "self", ".", "magnitude_std", ")", "\n", "", "magnitude", "=", "min", "(", "_MAX_LEVEL", ",", "max", "(", "0", ",", "magnitude", ")", ")", "# clip to valid range", "\n", "level_args", "=", "(", "\n", "self", ".", "level_fn", "(", "magnitude", ",", "self", ".", "hparams", ")", "\n", "if", "self", ".", "level_fn", "is", "not", "None", "\n", "else", "(", ")", "\n", ")", "\n", "\n", "if", "isinstance", "(", "img_list", ",", "list", ")", ":", "\n", "            ", "return", "[", "\n", "self", ".", "aug_fn", "(", "img", ",", "*", "level_args", ",", "**", "self", ".", "kwargs", ")", "for", "img", "in", "img_list", "\n", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "aug_fn", "(", "img_list", ",", "*", "level_args", ",", "**", "self", ".", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.RandAugment.__init__": [[463, 467], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ops", ",", "num_layers", "=", "2", ",", "choice_weights", "=", "None", ")", ":", "\n", "        ", "self", ".", "ops", "=", "ops", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "choice_weights", "=", "choice_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.RandAugment.__call__": [[468, 479], ["numpy.random.choice", "op"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "# no replacement when using weighted choice", "\n", "        ", "ops", "=", "np", ".", "random", ".", "choice", "(", "\n", "self", ".", "ops", ",", "\n", "self", ".", "num_layers", ",", "\n", "replace", "=", "self", ".", "choice_weights", "is", "None", ",", "\n", "p", "=", "self", ".", "choice_weights", ",", "\n", ")", "\n", "for", "op", "in", "ops", ":", "\n", "            ", "img", "=", "op", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._interpolation": [[50, 56], ["kwargs.pop", "isinstance", "random.choice"], "function", ["None"], ["def", "_interpolation", "(", "kwargs", ")", ":", "\n", "    ", "interpolation", "=", "kwargs", ".", "pop", "(", "\"resample\"", ",", "Image", ".", "BILINEAR", ")", "\n", "if", "isinstance", "(", "interpolation", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "random", ".", "choice", "(", "interpolation", ")", "\n", "", "else", ":", "\n", "        ", "return", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf": [[58, 62], ["rand_augment._interpolation", "kwargs.pop"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._interpolation"], ["", "", "def", "_check_args_tf", "(", "kwargs", ")", ":", "\n", "    ", "if", "\"fillcolor\"", "in", "kwargs", "and", "_PIL_VER", "<", "(", "5", ",", "0", ")", ":", "\n", "        ", "kwargs", ".", "pop", "(", "\"fillcolor\"", ")", "\n", "", "kwargs", "[", "\"resample\"", "]", "=", "_interpolation", "(", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.shear_x": [[64, 68], ["rand_augment._check_args_tf", "img.transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf"], ["", "def", "shear_x", "(", "img", ",", "factor", ",", "**", "kwargs", ")", ":", "\n", "    ", "_check_args_tf", "(", "kwargs", ")", "\n", "return", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "factor", ",", "0", ",", "0", ",", "1", ",", "0", ")", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.shear_y": [[71, 75], ["rand_augment._check_args_tf", "img.transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf"], ["", "def", "shear_y", "(", "img", ",", "factor", ",", "**", "kwargs", ")", ":", "\n", "    ", "_check_args_tf", "(", "kwargs", ")", "\n", "return", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "factor", ",", "1", ",", "0", ")", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.translate_x_rel": [[78, 83], ["rand_augment._check_args_tf", "img.transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf"], ["", "def", "translate_x_rel", "(", "img", ",", "pct", ",", "**", "kwargs", ")", ":", "\n", "    ", "pixels", "=", "pct", "*", "img", ".", "size", "[", "0", "]", "\n", "_check_args_tf", "(", "kwargs", ")", "\n", "return", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "pixels", ",", "0", ",", "1", ",", "0", ")", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.translate_y_rel": [[86, 91], ["rand_augment._check_args_tf", "img.transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf"], ["", "def", "translate_y_rel", "(", "img", ",", "pct", ",", "**", "kwargs", ")", ":", "\n", "    ", "pixels", "=", "pct", "*", "img", ".", "size", "[", "1", "]", "\n", "_check_args_tf", "(", "kwargs", ")", "\n", "return", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "pixels", ")", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.translate_x_abs": [[94, 98], ["rand_augment._check_args_tf", "img.transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf"], ["", "def", "translate_x_abs", "(", "img", ",", "pixels", ",", "**", "kwargs", ")", ":", "\n", "    ", "_check_args_tf", "(", "kwargs", ")", "\n", "return", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "pixels", ",", "0", ",", "1", ",", "0", ")", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.translate_y_abs": [[101, 105], ["rand_augment._check_args_tf", "img.transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf"], ["", "def", "translate_y_abs", "(", "img", ",", "pixels", ",", "**", "kwargs", ")", ":", "\n", "    ", "_check_args_tf", "(", "kwargs", ")", "\n", "return", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "pixels", ")", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rotate": [[108, 140], ["rand_augment._check_args_tf", "img.rotate", "rand_augment.rotate.transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._check_args_tf", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rotate"], ["", "def", "rotate", "(", "img", ",", "degrees", ",", "**", "kwargs", ")", ":", "\n", "    ", "_check_args_tf", "(", "kwargs", ")", "\n", "if", "_PIL_VER", ">=", "(", "5", ",", "2", ")", ":", "\n", "        ", "return", "img", ".", "rotate", "(", "degrees", ",", "**", "kwargs", ")", "\n", "", "elif", "_PIL_VER", ">=", "(", "5", ",", "0", ")", ":", "\n", "        ", "w", ",", "h", "=", "img", ".", "size", "\n", "post_trans", "=", "(", "0", ",", "0", ")", "\n", "rotn_center", "=", "(", "w", "/", "2.0", ",", "h", "/", "2.0", ")", "\n", "angle", "=", "-", "math", ".", "radians", "(", "degrees", ")", "\n", "matrix", "=", "[", "\n", "round", "(", "math", ".", "cos", "(", "angle", ")", ",", "15", ")", ",", "\n", "round", "(", "math", ".", "sin", "(", "angle", ")", ",", "15", ")", ",", "\n", "0.0", ",", "\n", "round", "(", "-", "math", ".", "sin", "(", "angle", ")", ",", "15", ")", ",", "\n", "round", "(", "math", ".", "cos", "(", "angle", ")", ",", "15", ")", ",", "\n", "0.0", ",", "\n", "]", "\n", "\n", "def", "transform", "(", "x", ",", "y", ",", "matrix", ")", ":", "\n", "            ", "(", "a", ",", "b", ",", "c", ",", "d", ",", "e", ",", "f", ")", "=", "matrix", "\n", "return", "a", "*", "x", "+", "b", "*", "y", "+", "c", ",", "d", "*", "x", "+", "e", "*", "y", "+", "f", "\n", "\n", "", "matrix", "[", "2", "]", ",", "matrix", "[", "5", "]", "=", "transform", "(", "\n", "-", "rotn_center", "[", "0", "]", "-", "post_trans", "[", "0", "]", ",", "\n", "-", "rotn_center", "[", "1", "]", "-", "post_trans", "[", "1", "]", ",", "\n", "matrix", ",", "\n", ")", "\n", "matrix", "[", "2", "]", "+=", "rotn_center", "[", "0", "]", "\n", "matrix", "[", "5", "]", "+=", "rotn_center", "[", "1", "]", "\n", "return", "img", ".", "transform", "(", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "matrix", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "return", "img", ".", "rotate", "(", "degrees", ",", "resample", "=", "kwargs", "[", "\"resample\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.auto_contrast": [[142, 144], ["PIL.ImageOps.autocontrast"], "function", ["None"], ["", "", "def", "auto_contrast", "(", "img", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageOps", ".", "autocontrast", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.invert": [[146, 148], ["PIL.ImageOps.invert"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.invert"], ["", "def", "invert", "(", "img", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageOps", ".", "invert", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.equalize": [[150, 152], ["PIL.ImageOps.equalize"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.equalize"], ["", "def", "equalize", "(", "img", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageOps", ".", "equalize", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.solarize": [[154, 156], ["PIL.ImageOps.solarize"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.solarize"], ["", "def", "solarize", "(", "img", ",", "thresh", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageOps", ".", "solarize", "(", "img", ",", "thresh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.solarize_add": [[158, 171], ["range", "img.point", "lut.append", "lut.append", "min", "len"], "function", ["None"], ["", "def", "solarize_add", "(", "img", ",", "add", ",", "thresh", "=", "128", ",", "**", "__", ")", ":", "\n", "    ", "lut", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "256", ")", ":", "\n", "        ", "if", "i", "<", "thresh", ":", "\n", "            ", "lut", ".", "append", "(", "min", "(", "255", ",", "i", "+", "add", ")", ")", "\n", "", "else", ":", "\n", "            ", "lut", ".", "append", "(", "i", ")", "\n", "", "", "if", "img", ".", "mode", "in", "(", "\"L\"", ",", "\"RGB\"", ")", ":", "\n", "        ", "if", "img", ".", "mode", "==", "\"RGB\"", "and", "len", "(", "lut", ")", "==", "256", ":", "\n", "            ", "lut", "=", "lut", "+", "lut", "+", "lut", "\n", "", "return", "img", ".", "point", "(", "lut", ")", "\n", "", "else", ":", "\n", "        ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.posterize": [[173, 177], ["PIL.ImageOps.posterize"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.posterize"], ["", "", "def", "posterize", "(", "img", ",", "bits_to_keep", ",", "**", "__", ")", ":", "\n", "    ", "if", "bits_to_keep", ">=", "8", ":", "\n", "        ", "return", "img", "\n", "", "return", "ImageOps", ".", "posterize", "(", "img", ",", "bits_to_keep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.contrast": [[179, 181], ["PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast"], "function", ["None"], ["", "def", "contrast", "(", "img", ",", "factor", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageEnhance", ".", "Contrast", "(", "img", ")", ".", "enhance", "(", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.color": [[183, 185], ["PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color"], "function", ["None"], ["", "def", "color", "(", "img", ",", "factor", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageEnhance", ".", "Color", "(", "img", ")", ".", "enhance", "(", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.brightness": [[187, 189], ["PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness"], "function", ["None"], ["", "def", "brightness", "(", "img", ",", "factor", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageEnhance", ".", "Brightness", "(", "img", ")", ".", "enhance", "(", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.sharpness": [[191, 193], ["PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness"], "function", ["None"], ["", "def", "sharpness", "(", "img", ",", "factor", ",", "**", "__", ")", ":", "\n", "    ", "return", "ImageEnhance", ".", "Sharpness", "(", "img", ")", ".", "enhance", "(", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._randomly_negate": [[195, 198], ["random.random"], "function", ["None"], ["", "def", "_randomly_negate", "(", "v", ")", ":", "\n", "    ", "\"\"\"With 50% prob, negate the value\"\"\"", "\n", "return", "-", "v", "if", "random", ".", "random", "(", ")", ">", "0.5", "else", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._rotate_level_to_arg": [[200, 205], ["rand_augment._randomly_negate"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._randomly_negate"], ["", "def", "_rotate_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# range [-30, 30]", "\n", "    ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "30.0", "\n", "level", "=", "_randomly_negate", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._enhance_level_to_arg": [[207, 210], ["None"], "function", ["None"], ["", "def", "_enhance_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# range [0.1, 1.9]", "\n", "    ", "return", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "1.8", "+", "0.1", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._enhance_increasing_level_to_arg": [[212, 218], ["rand_augment._randomly_negate"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._randomly_negate"], ["", "def", "_enhance_increasing_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# the 'no change' level is 1.0, moving away from that towards 0. or 2.0 increases the enhancement blend", "\n", "# range [0.1, 1.9]", "\n", "    ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "0.9", "\n", "level", "=", "1.0", "+", "_randomly_negate", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._shear_level_to_arg": [[220, 225], ["rand_augment._randomly_negate"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._randomly_negate"], ["", "def", "_shear_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# range [-0.3, 0.3]", "\n", "    ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "0.3", "\n", "level", "=", "_randomly_negate", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._translate_abs_level_to_arg": [[227, 232], ["rand_augment._randomly_negate", "float"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._randomly_negate"], ["", "def", "_translate_abs_level_to_arg", "(", "level", ",", "hparams", ")", ":", "\n", "    ", "translate_const", "=", "hparams", "[", "\"translate_const\"", "]", "\n", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "float", "(", "translate_const", ")", "\n", "level", "=", "_randomly_negate", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._translate_rel_level_to_arg": [[234, 240], ["hparams.get", "rand_augment._randomly_negate"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._randomly_negate"], ["", "def", "_translate_rel_level_to_arg", "(", "level", ",", "hparams", ")", ":", "\n", "# default range [-0.45, 0.45]", "\n", "    ", "translate_pct", "=", "hparams", ".", "get", "(", "\"translate_pct\"", ",", "0.45", ")", "\n", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "translate_pct", "\n", "level", "=", "_randomly_negate", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._posterize_level_to_arg": [[242, 247], ["int"], "function", ["None"], ["", "def", "_posterize_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# As per Tensorflow TPU EfficientNet impl", "\n", "# range [0, 4], 'keep 0 up to 4 MSB of original image'", "\n", "# intensity/severity of augmentation decreases with level", "\n", "    ", "return", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "4", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._posterize_increasing_level_to_arg": [[249, 254], ["rand_augment._posterize_level_to_arg"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._posterize_level_to_arg"], ["", "def", "_posterize_increasing_level_to_arg", "(", "level", ",", "hparams", ")", ":", "\n", "# As per Tensorflow models research and UDA impl", "\n", "# range [4, 0], 'keep 4 down to 0 MSB of original image',", "\n", "# intensity/severity of augmentation increases with level", "\n", "    ", "return", "(", "4", "-", "_posterize_level_to_arg", "(", "level", ",", "hparams", ")", "[", "0", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._posterize_original_level_to_arg": [[256, 261], ["int"], "function", ["None"], ["", "def", "_posterize_original_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# As per original AutoAugment paper description", "\n", "# range [4, 8], 'keep 4 up to 8 MSB of image'", "\n", "# intensity/severity of augmentation decreases with level", "\n", "    ", "return", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "4", ")", "+", "4", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._solarize_level_to_arg": [[263, 267], ["int"], "function", ["None"], ["", "def", "_solarize_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# range [0, 256]", "\n", "# intensity/severity of augmentation decreases with level", "\n", "    ", "return", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "256", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._solarize_increasing_level_to_arg": [[269, 273], ["rand_augment._solarize_level_to_arg"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._solarize_level_to_arg"], ["", "def", "_solarize_increasing_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# range [0, 256]", "\n", "# intensity/severity of augmentation increases with level", "\n", "    ", "return", "(", "256", "-", "_solarize_level_to_arg", "(", "level", ",", "_hparams", ")", "[", "0", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._solarize_add_level_to_arg": [[275, 278], ["int"], "function", ["None"], ["", "def", "_solarize_add_level_to_arg", "(", "level", ",", "_hparams", ")", ":", "\n", "# range [0, 110]", "\n", "    ", "return", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "110", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._select_rand_weights": [[444, 451], ["numpy.sum"], "function", ["None"], ["def", "_select_rand_weights", "(", "weight_idx", "=", "0", ",", "transforms", "=", "None", ")", ":", "\n", "    ", "transforms", "=", "transforms", "or", "_RAND_TRANSFORMS", "\n", "assert", "weight_idx", "==", "0", "# only one set of weights currently", "\n", "rand_weights", "=", "_RAND_CHOICE_WEIGHTS_0", "\n", "probs", "=", "[", "rand_weights", "[", "k", "]", "for", "k", "in", "transforms", "]", "\n", "probs", "/=", "np", ".", "sum", "(", "probs", ")", "\n", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rand_augment_ops": [[453, 459], ["rand_augment.AugmentOp"], "function", ["None"], ["", "def", "rand_augment_ops", "(", "magnitude", "=", "10", ",", "hparams", "=", "None", ",", "transforms", "=", "None", ")", ":", "\n", "    ", "hparams", "=", "hparams", "or", "_HPARAMS_DEFAULT", "\n", "transforms", "=", "transforms", "or", "_RAND_TRANSFORMS", "\n", "return", "[", "\n", "AugmentOp", "(", "name", ",", "prob", "=", "0.5", ",", "magnitude", "=", "magnitude", ",", "hparams", "=", "hparams", ")", "\n", "for", "name", "in", "transforms", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rand_augment_transform": [[481, 532], ["config_str.split", "rand_augment.rand_augment_ops", "rand_augment.RandAugment", "re.split", "rand_augment._select_rand_weights", "len", "hparams.setdefault", "float", "bool", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rand_augment_ops", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment._select_rand_weights"], ["", "", "def", "rand_augment_transform", "(", "config_str", ",", "hparams", ")", ":", "\n", "    ", "\"\"\"\n    RandAugment: Practical automated data augmentation... - https://arxiv.org/abs/1909.13719\n\n    Create a RandAugment transform\n    :param config_str: String defining configuration of random augmentation. Consists of multiple sections separated by\n    dashes ('-'). The first section defines the specific variant of rand augment (currently only 'rand'). The remaining\n    sections, not order sepecific determine\n        'm' - integer magnitude of rand augment\n        'n' - integer num layers (number of transform ops selected per image)\n        'w' - integer probabiliy weight index (index of a set of weights to influence choice of op)\n        'mstd' -  float std deviation of magnitude noise applied\n        'inc' - integer (bool), use augmentations that increase in severity with magnitude (default: 0)\n    Ex 'rand-m9-n3-mstd0.5' results in RandAugment with magnitude 9, num_layers 3, magnitude_std 0.5\n    'rand-mstd1-w0' results in magnitude_std 1.0, weights 0, default magnitude of 10 and num_layers 2\n    :param hparams: Other hparams (kwargs) for the RandAugmentation scheme\n    :return: A PyTorch compatible Transform\n    \"\"\"", "\n", "magnitude", "=", "_MAX_LEVEL", "# default to _MAX_LEVEL for magnitude (currently 10)", "\n", "num_layers", "=", "2", "# default to 2 ops per image", "\n", "weight_idx", "=", "None", "# default to no probability weights for op choice", "\n", "transforms", "=", "_RAND_TRANSFORMS", "\n", "config", "=", "config_str", ".", "split", "(", "\"-\"", ")", "\n", "assert", "config", "[", "0", "]", "==", "\"rand\"", "\n", "config", "=", "config", "[", "1", ":", "]", "\n", "for", "c", "in", "config", ":", "\n", "        ", "cs", "=", "re", ".", "split", "(", "r\"(\\d.*)\"", ",", "c", ")", "\n", "if", "len", "(", "cs", ")", "<", "2", ":", "\n", "            ", "continue", "\n", "", "key", ",", "val", "=", "cs", "[", ":", "2", "]", "\n", "if", "key", "==", "\"mstd\"", ":", "\n", "# noise param injected via hparams for now", "\n", "            ", "hparams", ".", "setdefault", "(", "\"magnitude_std\"", ",", "float", "(", "val", ")", ")", "\n", "", "elif", "key", "==", "\"inc\"", ":", "\n", "            ", "if", "bool", "(", "val", ")", ":", "\n", "                ", "transforms", "=", "_RAND_INCREASING_TRANSFORMS", "\n", "", "", "elif", "key", "==", "\"m\"", ":", "\n", "            ", "magnitude", "=", "int", "(", "val", ")", "\n", "", "elif", "key", "==", "\"n\"", ":", "\n", "            ", "num_layers", "=", "int", "(", "val", ")", "\n", "", "elif", "key", "==", "\"w\"", ":", "\n", "            ", "weight_idx", "=", "int", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "assert", "NotImplementedError", "\n", "", "", "ra_ops", "=", "rand_augment_ops", "(", "\n", "magnitude", "=", "magnitude", ",", "hparams", "=", "hparams", ",", "transforms", "=", "transforms", "\n", ")", "\n", "choice_weights", "=", "(", "\n", "None", "if", "weight_idx", "is", "None", "else", "_select_rand_weights", "(", "weight_idx", ")", "\n", ")", "\n", "return", "RandAugment", "(", "ra_ops", ",", "num_layers", ",", "choice_weights", "=", "choice_weights", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_mae_pretraining.get_args": [[19, 117], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'VideoMAE pre-training script'", ",", "add_help", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "64", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "800", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--save_ckpt_freq'", ",", "default", "=", "50", ",", "type", "=", "int", ")", "\n", "\n", "# Model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'pretrain_videomae_base_patch16_224'", ",", "type", "=", "str", ",", "metavar", "=", "'MODEL'", ",", "\n", "help", "=", "'Name of model to train'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--decoder_depth'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "'depth of decoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--mask_type'", ",", "default", "=", "'tube'", ",", "choices", "=", "[", "'random'", ",", "'tube'", "]", ",", "\n", "type", "=", "str", ",", "help", "=", "'masked strategy of video tokens/patches'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--mask_ratio'", ",", "default", "=", "0.75", ",", "type", "=", "float", ",", "\n", "help", "=", "'ratio of the visual tokens/patches need be masked'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--input_size'", ",", "default", "=", "224", ",", "type", "=", "int", ",", "\n", "help", "=", "'videos input size for backbone'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--drop_path'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Drop path rate (default: 0.1)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--normlize_target'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "\n", "help", "=", "'normalized the target patch pixels'", ")", "\n", "\n", "# Optimizer parameters", "\n", "parser", ".", "add_argument", "(", "'--opt'", ",", "default", "=", "'adamw'", ",", "type", "=", "str", ",", "metavar", "=", "'OPTIMIZER'", ",", "\n", "help", "=", "'Optimizer (default: \"adamw\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--opt_eps'", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "metavar", "=", "'EPSILON'", ",", "\n", "help", "=", "'Optimizer Epsilon (default: 1e-8)'", ")", "\n", "parser", ".", "add_argument", "(", "'--opt_betas'", ",", "default", "=", "None", ",", "type", "=", "float", ",", "nargs", "=", "'+'", ",", "metavar", "=", "'BETA'", ",", "\n", "help", "=", "'Optimizer Betas (default: None, use opt default)'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_grad'", ",", "type", "=", "float", ",", "default", "=", "None", ",", "metavar", "=", "'NORM'", ",", "\n", "help", "=", "'Clip gradient norm (default: None, no clipping)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'SGD momentum (default: 0.9)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0.05", ",", "\n", "help", "=", "'weight decay (default: 0.05)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay_end'", ",", "type", "=", "float", ",", "default", "=", "None", ",", "help", "=", "\"\"\"Final value of the\n        weight decay. We use a cosine schedule for WD. \n        (Set the same value with args.weight_decay to keep weight decay no change)\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1.5e-4", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'learning rate (default: 1.5e-4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-6", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'warmup learning rate (default: 1e-6)'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'lower lr bound for cyclic schedulers that hit 0 (1e-5)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--warmup_epochs'", ",", "type", "=", "int", ",", "default", "=", "40", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'epochs to warmup LR, if scheduler supports'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'epochs to warmup LR, if scheduler supports'", ")", "\n", "\n", "# Augmentation parameters", "\n", "parser", ".", "add_argument", "(", "'--color_jitter'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Color jitter factor (default: 0.4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_interpolation'", ",", "type", "=", "str", ",", "default", "=", "'bicubic'", ",", "\n", "help", "=", "'Training interpolation (random, bilinear, bicubic default: \"bicubic\")'", ")", "\n", "\n", "# Dataset parameters", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "default", "=", "'/path/to/list_kinetics-400'", ",", "type", "=", "str", ",", "\n", "help", "=", "'dataset path'", ")", "\n", "parser", ".", "add_argument", "(", "'--imagenet_default_mean_and_std'", ",", "default", "=", "True", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_frames'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "parser", ".", "add_argument", "(", "'--sampling_rate'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "default", "=", "''", ",", "\n", "help", "=", "'path where to save, empty for no saving'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "default", "=", "None", ",", "\n", "help", "=", "'path where to tensorboard log'", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "default", "=", "'cuda'", ",", "\n", "help", "=", "'device to use for training / testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "default", "=", "''", ",", "help", "=", "'resume from checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--auto_resume'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_auto_resume'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'auto_resume'", ")", "\n", "parser", ".", "set_defaults", "(", "auto_resume", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--start_epoch'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'start epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_workers'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--pin_mem'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_pin_mem'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'pin_mem'", ",", "\n", "help", "=", "''", ")", "\n", "parser", ".", "set_defaults", "(", "pin_mem", "=", "True", ")", "\n", "\n", "# distributed training parameters", "\n", "parser", ".", "add_argument", "(", "'--world_size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of distributed processes'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dist_on_itp'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--dist_url'", ",", "default", "=", "'env://'", ",", "help", "=", "'url used to set up distributed training'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_mae_pretraining.get_model": [[119, 129], ["print", "timm.models.create_model"], "function", ["None"], ["", "def", "get_model", "(", "args", ")", ":", "\n", "    ", "print", "(", "f\"Creating model: {args.model}\"", ")", "\n", "model", "=", "create_model", "(", "\n", "args", ".", "model", ",", "\n", "pretrained", "=", "False", ",", "\n", "drop_path_rate", "=", "args", ".", "drop_path", ",", "\n", "drop_block_rate", "=", "None", ",", "\n", "decoder_depth", "=", "args", ".", "decoder_depth", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_mae_pretraining.main": [[131, 255], ["utils.init_distributed_mode", "print", "torch.device", "torch.device", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "run_mae_pretraining.get_model", "print", "datasets.build_pretraining_dataset", "utils.get_world_size", "utils.get_rank", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.nn.parallel.DistributedDataParallel.to", "sum", "print", "print", "print", "print", "print", "print", "optim_factory.create_optimizer", "utils.NativeScalerWithGradNormCount", "print", "utils.cosine_scheduler", "utils.cosine_scheduler", "print", "utils.auto_load_model", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "print", "time.time", "range", "str", "print", "utils.get_rank", "os.makedirs", "utils.TensorboardLogger", "utils.get_world_size", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "engine_for_pretraining.train_one_epoch", "time.time", "datetime.timedelta", "str", "len", "str", "p.numel", "str", "torch.utils.data.DataLoader.sampler.set_epoch", "utils.TensorboardLogger.set_step", "utils.is_main_process", "torch.nn.parallel.DistributedDataParallel.parameters", "max", "min", "utils.save_model", "utils.TensorboardLogger.flush", "open", "f.write", "int", "engine_for_pretraining.train_one_epoch.items", "os.path.join", "json.dumps"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.init_distributed_mode", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.get_model", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.build_pretraining_dataset", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_world_size", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_rank", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.create_optimizer", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.cosine_scheduler", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.cosine_scheduler", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.auto_load_model", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_rank", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_world_size", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_pretraining.train_one_epoch", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.set_step", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_main_process", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.save_model", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.flush"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "utils", ".", "init_distributed_mode", "(", "args", ")", "\n", "\n", "print", "(", "args", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "\n", "# fix the seed for reproducibility", "\n", "seed", "=", "args", ".", "seed", "+", "utils", ".", "get_rank", "(", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "model", "=", "get_model", "(", "args", ")", "\n", "patch_size", "=", "model", ".", "encoder", ".", "patch_embed", ".", "patch_size", "\n", "print", "(", "\"Patch size = %s\"", "%", "str", "(", "patch_size", ")", ")", "\n", "args", ".", "window_size", "=", "(", "args", ".", "num_frames", "//", "2", ",", "args", ".", "input_size", "//", "patch_size", "[", "0", "]", ",", "args", ".", "input_size", "//", "patch_size", "[", "1", "]", ")", "\n", "args", ".", "patch_size", "=", "patch_size", "\n", "\n", "# get dataset", "\n", "dataset_train", "=", "build_pretraining_dataset", "(", "args", ")", "\n", "\n", "\n", "num_tasks", "=", "utils", ".", "get_world_size", "(", ")", "\n", "global_rank", "=", "utils", ".", "get_rank", "(", ")", "\n", "sampler_rank", "=", "global_rank", "\n", "num_training_steps_per_epoch", "=", "len", "(", "dataset_train", ")", "//", "args", ".", "batch_size", "//", "num_tasks", "\n", "\n", "sampler_train", "=", "torch", ".", "utils", ".", "data", ".", "DistributedSampler", "(", "\n", "dataset_train", ",", "num_replicas", "=", "num_tasks", ",", "rank", "=", "sampler_rank", ",", "shuffle", "=", "True", "\n", ")", "\n", "print", "(", "\"Sampler_train = %s\"", "%", "str", "(", "sampler_train", ")", ")", "\n", "\n", "\n", "if", "global_rank", "==", "0", "and", "args", ".", "log_dir", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "log_writer", "=", "utils", ".", "TensorboardLogger", "(", "log_dir", "=", "args", ".", "log_dir", ")", "\n", "", "else", ":", "\n", "        ", "log_writer", "=", "None", "\n", "\n", "", "data_loader_train", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_train", ",", "sampler", "=", "sampler_train", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "args", ".", "pin_mem", ",", "\n", "drop_last", "=", "True", ",", "\n", "worker_init_fn", "=", "utils", ".", "seed_worker", "\n", ")", "\n", "\n", "model", ".", "to", "(", "device", ")", "\n", "model_without_ddp", "=", "model", "\n", "n_parameters", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n", "print", "(", "\"Model = %s\"", "%", "str", "(", "model_without_ddp", ")", ")", "\n", "print", "(", "'number of params: {} M'", ".", "format", "(", "n_parameters", "/", "1e6", ")", ")", "\n", "\n", "total_batch_size", "=", "args", ".", "batch_size", "*", "utils", ".", "get_world_size", "(", ")", "\n", "\n", "args", ".", "lr", "=", "args", ".", "lr", "*", "total_batch_size", "/", "256", "\n", "args", ".", "min_lr", "=", "args", ".", "min_lr", "*", "total_batch_size", "/", "256", "\n", "args", ".", "warmup_lr", "=", "args", ".", "warmup_lr", "*", "total_batch_size", "/", "256", "\n", "print", "(", "\"LR = %.8f\"", "%", "args", ".", "lr", ")", "\n", "print", "(", "\"Batch size = %d\"", "%", "total_batch_size", ")", "\n", "print", "(", "\"Number of training steps = %d\"", "%", "num_training_steps_per_epoch", ")", "\n", "print", "(", "\"Number of training examples per epoch = %d\"", "%", "(", "total_batch_size", "*", "num_training_steps_per_epoch", ")", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "find_unused_parameters", "=", "True", ")", "\n", "model_without_ddp", "=", "model", ".", "module", "\n", "\n", "", "optimizer", "=", "create_optimizer", "(", "\n", "args", ",", "model_without_ddp", ")", "\n", "loss_scaler", "=", "NativeScaler", "(", ")", "\n", "\n", "print", "(", "\"Use step level LR & WD scheduler!\"", ")", "\n", "lr_schedule_values", "=", "utils", ".", "cosine_scheduler", "(", "\n", "args", ".", "lr", ",", "args", ".", "min_lr", ",", "args", ".", "epochs", ",", "num_training_steps_per_epoch", ",", "\n", "warmup_epochs", "=", "args", ".", "warmup_epochs", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "\n", ")", "\n", "if", "args", ".", "weight_decay_end", "is", "None", ":", "\n", "        ", "args", ".", "weight_decay_end", "=", "args", ".", "weight_decay", "\n", "", "wd_schedule_values", "=", "utils", ".", "cosine_scheduler", "(", "\n", "args", ".", "weight_decay", ",", "args", ".", "weight_decay_end", ",", "args", ".", "epochs", ",", "num_training_steps_per_epoch", ")", "\n", "print", "(", "\"Max WD = %.7f, Min WD = %.7f\"", "%", "(", "max", "(", "wd_schedule_values", ")", ",", "min", "(", "wd_schedule_values", ")", ")", ")", "\n", "\n", "utils", ".", "auto_load_model", "(", "\n", "args", "=", "args", ",", "model", "=", "model", ",", "model_without_ddp", "=", "model_without_ddp", ",", "optimizer", "=", "optimizer", ",", "loss_scaler", "=", "loss_scaler", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "print", "(", "f\"Start training for {args.epochs} epochs\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "args", ".", "distributed", ":", "\n", "            ", "data_loader_train", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "log_writer", "is", "not", "None", ":", "\n", "            ", "log_writer", ".", "set_step", "(", "epoch", "*", "num_training_steps_per_epoch", ")", "\n", "", "train_stats", "=", "train_one_epoch", "(", "\n", "model", ",", "data_loader_train", ",", "\n", "optimizer", ",", "device", ",", "epoch", ",", "loss_scaler", ",", "\n", "args", ".", "clip_grad", ",", "log_writer", "=", "log_writer", ",", "\n", "start_steps", "=", "epoch", "*", "num_training_steps_per_epoch", ",", "\n", "lr_schedule_values", "=", "lr_schedule_values", ",", "\n", "wd_schedule_values", "=", "wd_schedule_values", ",", "\n", "patch_size", "=", "patch_size", "[", "0", "]", ",", "\n", "normlize_target", "=", "args", ".", "normlize_target", ",", "\n", ")", "\n", "if", "args", ".", "output_dir", ":", "\n", "            ", "if", "(", "epoch", "+", "1", ")", "%", "args", ".", "save_ckpt_freq", "==", "0", "or", "epoch", "+", "1", "==", "args", ".", "epochs", ":", "\n", "                ", "utils", ".", "save_model", "(", "\n", "args", "=", "args", ",", "model", "=", "model", ",", "model_without_ddp", "=", "model_without_ddp", ",", "optimizer", "=", "optimizer", ",", "\n", "loss_scaler", "=", "loss_scaler", ",", "epoch", "=", "epoch", ")", "\n", "\n", "", "", "log_stats", "=", "{", "**", "{", "f'train_{k}'", ":", "v", "for", "k", ",", "v", "in", "train_stats", ".", "items", "(", ")", "}", ",", "\n", "'epoch'", ":", "epoch", ",", "'n_parameters'", ":", "n_parameters", "}", "\n", "\n", "if", "args", ".", "output_dir", "and", "utils", ".", "is_main_process", "(", ")", ":", "\n", "            ", "if", "log_writer", "is", "not", "None", ":", "\n", "                ", "log_writer", ".", "flush", "(", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"log.txt\"", ")", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "log_stats", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "print", "(", "'Training time {}'", ".", "format", "(", "total_time_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.ClipToTensor.__init__": [[21, 25], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "channel_nb", "=", "3", ",", "div_255", "=", "True", ",", "numpy", "=", "False", ")", ":", "\n", "        ", "self", ".", "channel_nb", "=", "channel_nb", "\n", "self", ".", "div_255", "=", "div_255", "\n", "self", ".", "numpy", "=", "numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.ClipToTensor.__call__": [[26, 68], ["isinstance", "numpy.zeros", "enumerate", "isinstance", "isinstance", "volume_transforms.convert_img", "torch.from_numpy", "TypeError", "len", "int", "int", "isinstance", "isinstance", "torch.div.float", "torch.div", "numpy.array", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.convert_img"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args: clip (list of numpy.ndarray): clip (list of images)\n        to be converted to tensor.\n        \"\"\"", "\n", "# Retrieve shape", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "h", ",", "w", ",", "ch", "=", "clip", "[", "0", "]", ".", "shape", "\n", "assert", "ch", "==", "self", ".", "channel_nb", ",", "'Got {0} instead of 3 channels'", ".", "format", "(", "\n", "ch", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "Image", ".", "Image", ")", ":", "\n", "            ", "w", ",", "h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n            but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "np_clip", "=", "np", ".", "zeros", "(", "[", "self", ".", "channel_nb", ",", "len", "(", "clip", ")", ",", "int", "(", "h", ")", ",", "int", "(", "w", ")", "]", ")", "\n", "\n", "# Convert", "\n", "for", "img_idx", ",", "img", "in", "enumerate", "(", "clip", ")", ":", "\n", "            ", "if", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "pass", "\n", "", "elif", "isinstance", "(", "img", ",", "Image", ".", "Image", ")", ":", "\n", "                ", "img", "=", "np", ".", "array", "(", "img", ",", "copy", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n                but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "img", "=", "convert_img", "(", "img", ")", "\n", "np_clip", "[", ":", ",", "img_idx", ",", ":", ",", ":", "]", "=", "img", "\n", "", "if", "self", ".", "numpy", ":", "\n", "            ", "if", "self", ".", "div_255", ":", "\n", "                ", "np_clip", "=", "np_clip", "/", "255.0", "\n", "", "return", "np_clip", "\n", "\n", "", "else", ":", "\n", "            ", "tensor_clip", "=", "torch", ".", "from_numpy", "(", "np_clip", ")", "\n", "\n", "if", "not", "isinstance", "(", "tensor_clip", ",", "torch", ".", "FloatTensor", ")", ":", "\n", "                ", "tensor_clip", "=", "tensor_clip", ".", "float", "(", ")", "\n", "", "if", "self", ".", "div_255", ":", "\n", "                ", "tensor_clip", "=", "torch", ".", "div", "(", "tensor_clip", ",", "255", ")", "\n", "", "return", "tensor_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.ClipToTensor_K.__init__": [[76, 80], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "channel_nb", "=", "3", ",", "div_255", "=", "True", ",", "numpy", "=", "False", ")", ":", "\n", "        ", "self", ".", "channel_nb", "=", "channel_nb", "\n", "self", ".", "div_255", "=", "div_255", "\n", "self", ".", "numpy", "=", "numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.ClipToTensor_K.__call__": [[81, 123], ["isinstance", "numpy.zeros", "enumerate", "isinstance", "isinstance", "volume_transforms.convert_img", "torch.from_numpy", "TypeError", "len", "int", "int", "isinstance", "isinstance", "torch.div.float", "torch.div", "numpy.array", "TypeError", "torch.sub", "type", "type"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.convert_img"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args: clip (list of numpy.ndarray): clip (list of images)\n        to be converted to tensor.\n        \"\"\"", "\n", "# Retrieve shape", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "h", ",", "w", ",", "ch", "=", "clip", "[", "0", "]", ".", "shape", "\n", "assert", "ch", "==", "self", ".", "channel_nb", ",", "'Got {0} instead of 3 channels'", ".", "format", "(", "\n", "ch", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "Image", ".", "Image", ")", ":", "\n", "            ", "w", ",", "h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n            but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "np_clip", "=", "np", ".", "zeros", "(", "[", "self", ".", "channel_nb", ",", "len", "(", "clip", ")", ",", "int", "(", "h", ")", ",", "int", "(", "w", ")", "]", ")", "\n", "\n", "# Convert", "\n", "for", "img_idx", ",", "img", "in", "enumerate", "(", "clip", ")", ":", "\n", "            ", "if", "isinstance", "(", "img", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "pass", "\n", "", "elif", "isinstance", "(", "img", ",", "Image", ".", "Image", ")", ":", "\n", "                ", "img", "=", "np", ".", "array", "(", "img", ",", "copy", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image\\\n                but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "img", "=", "convert_img", "(", "img", ")", "\n", "np_clip", "[", ":", ",", "img_idx", ",", ":", ",", ":", "]", "=", "img", "\n", "", "if", "self", ".", "numpy", ":", "\n", "            ", "if", "self", ".", "div_255", ":", "\n", "                ", "np_clip", "=", "(", "np_clip", "-", "127.5", ")", "/", "127.5", "\n", "", "return", "np_clip", "\n", "\n", "", "else", ":", "\n", "            ", "tensor_clip", "=", "torch", ".", "from_numpy", "(", "np_clip", ")", "\n", "\n", "if", "not", "isinstance", "(", "tensor_clip", ",", "torch", ".", "FloatTensor", ")", ":", "\n", "                ", "tensor_clip", "=", "tensor_clip", ".", "float", "(", ")", "\n", "", "if", "self", ".", "div_255", ":", "\n", "                ", "tensor_clip", "=", "torch", ".", "div", "(", "torch", ".", "sub", "(", "tensor_clip", ",", "127.5", ")", ",", "127.5", ")", "\n", "", "return", "tensor_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.ToTensor.__call__": [[129, 132], ["torch.from_numpy"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "array", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "return", "tensor", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.volume_transforms.convert_img": [[6, 14], ["len", "np.expand_dims.transpose", "len", "numpy.expand_dims"], "function", ["None"], ["def", "convert_img", "(", "img", ")", ":", "\n", "    ", "\"\"\"Converts (H, W, C) numpy.ndarray to (C, W, H) format\n    \"\"\"", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "        ", "img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "", "if", "len", "(", "img", ".", "shape", ")", "==", "2", ":", "\n", "        ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "0", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing.RandomErasing.__init__": [[46, 79], ["mode.lower.lower.lower", "math.log", "math.log"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "probability", "=", "0.5", ",", "\n", "min_area", "=", "0.02", ",", "\n", "max_area", "=", "1", "/", "3", ",", "\n", "min_aspect", "=", "0.3", ",", "\n", "max_aspect", "=", "None", ",", "\n", "mode", "=", "\"const\"", ",", "\n", "min_count", "=", "1", ",", "\n", "max_count", "=", "None", ",", "\n", "num_splits", "=", "0", ",", "\n", "device", "=", "\"cuda\"", ",", "\n", "cube", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "probability", "=", "probability", "\n", "self", ".", "min_area", "=", "min_area", "\n", "self", ".", "max_area", "=", "max_area", "\n", "max_aspect", "=", "max_aspect", "or", "1", "/", "min_aspect", "\n", "self", ".", "log_aspect_ratio", "=", "(", "math", ".", "log", "(", "min_aspect", ")", ",", "math", ".", "log", "(", "max_aspect", ")", ")", "\n", "self", ".", "min_count", "=", "min_count", "\n", "self", ".", "max_count", "=", "max_count", "or", "min_count", "\n", "self", ".", "num_splits", "=", "num_splits", "\n", "mode", "=", "mode", ".", "lower", "(", ")", "\n", "self", ".", "rand_color", "=", "False", "\n", "self", ".", "per_pixel", "=", "False", "\n", "self", ".", "cube", "=", "cube", "\n", "if", "mode", "==", "\"rand\"", ":", "\n", "            ", "self", ".", "rand_color", "=", "True", "# per block random normal", "\n", "", "elif", "mode", "==", "\"pixel\"", ":", "\n", "            ", "self", ".", "per_pixel", "=", "True", "# per pixel random normal", "\n", "", "else", ":", "\n", "            ", "assert", "not", "mode", "or", "mode", "==", "\"const\"", "\n", "", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing.RandomErasing._erase": [[80, 108], ["range", "random.random", "random.randint", "range", "math.exp", "int", "int", "random.uniform", "round", "round", "random.randint", "random.randint", "random_erasing._get_pixels", "random.uniform", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing._get_pixels"], ["", "def", "_erase", "(", "self", ",", "img", ",", "chan", ",", "img_h", ",", "img_w", ",", "dtype", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", ">", "self", ".", "probability", ":", "\n", "            ", "return", "\n", "", "area", "=", "img_h", "*", "img_w", "\n", "count", "=", "(", "\n", "self", ".", "min_count", "\n", "if", "self", ".", "min_count", "==", "self", ".", "max_count", "\n", "else", "random", ".", "randint", "(", "self", ".", "min_count", ",", "self", ".", "max_count", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "count", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "target_area", "=", "(", "\n", "random", ".", "uniform", "(", "self", ".", "min_area", ",", "self", ".", "max_area", ")", "*", "area", "/", "count", "\n", ")", "\n", "aspect_ratio", "=", "math", ".", "exp", "(", "random", ".", "uniform", "(", "*", "self", ".", "log_aspect_ratio", ")", ")", "\n", "h", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "*", "aspect_ratio", ")", ")", ")", "\n", "w", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "/", "aspect_ratio", ")", ")", ")", "\n", "if", "w", "<", "img_w", "and", "h", "<", "img_h", ":", "\n", "                    ", "top", "=", "random", ".", "randint", "(", "0", ",", "img_h", "-", "h", ")", "\n", "left", "=", "random", ".", "randint", "(", "0", ",", "img_w", "-", "w", ")", "\n", "img", "[", ":", ",", "top", ":", "top", "+", "h", ",", "left", ":", "left", "+", "w", "]", "=", "_get_pixels", "(", "\n", "self", ".", "per_pixel", ",", "\n", "self", ".", "rand_color", ",", "\n", "(", "chan", ",", "h", ",", "w", ")", ",", "\n", "dtype", "=", "dtype", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing.RandomErasing._erase_cube": [[109, 150], ["range", "random.random", "random.randint", "range", "math.exp", "int", "int", "random.uniform", "round", "round", "random.randint", "random.randint", "range", "random.uniform", "math.sqrt", "math.sqrt", "random_erasing._get_pixels"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing._get_pixels"], ["", "", "", "", "def", "_erase_cube", "(", "\n", "self", ",", "\n", "img", ",", "\n", "batch_start", ",", "\n", "batch_size", ",", "\n", "chan", ",", "\n", "img_h", ",", "\n", "img_w", ",", "\n", "dtype", ",", "\n", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", ">", "self", ".", "probability", ":", "\n", "            ", "return", "\n", "", "area", "=", "img_h", "*", "img_w", "\n", "count", "=", "(", "\n", "self", ".", "min_count", "\n", "if", "self", ".", "min_count", "==", "self", ".", "max_count", "\n", "else", "random", ".", "randint", "(", "self", ".", "min_count", ",", "self", ".", "max_count", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "count", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "                ", "target_area", "=", "(", "\n", "random", ".", "uniform", "(", "self", ".", "min_area", ",", "self", ".", "max_area", ")", "*", "area", "/", "count", "\n", ")", "\n", "aspect_ratio", "=", "math", ".", "exp", "(", "random", ".", "uniform", "(", "*", "self", ".", "log_aspect_ratio", ")", ")", "\n", "h", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "*", "aspect_ratio", ")", ")", ")", "\n", "w", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "/", "aspect_ratio", ")", ")", ")", "\n", "if", "w", "<", "img_w", "and", "h", "<", "img_h", ":", "\n", "                    ", "top", "=", "random", ".", "randint", "(", "0", ",", "img_h", "-", "h", ")", "\n", "left", "=", "random", ".", "randint", "(", "0", ",", "img_w", "-", "w", ")", "\n", "for", "i", "in", "range", "(", "batch_start", ",", "batch_size", ")", ":", "\n", "                        ", "img_instance", "=", "img", "[", "i", "]", "\n", "img_instance", "[", "\n", ":", ",", "top", ":", "top", "+", "h", ",", "left", ":", "left", "+", "w", "\n", "]", "=", "_get_pixels", "(", "\n", "self", ".", "per_pixel", ",", "\n", "self", ".", "rand_color", ",", "\n", "(", "chan", ",", "h", ",", "w", ")", ",", "\n", "dtype", "=", "dtype", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", ")", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing.RandomErasing.__call__": [[151, 174], ["len", "random_erasing.RandomErasing._erase", "input.size", "input.size", "random_erasing.RandomErasing._erase_cube", "range", "input.size", "random_erasing.RandomErasing._erase"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing.RandomErasing._erase", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing.RandomErasing._erase_cube", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing.RandomErasing._erase"], ["", "", "", "", "def", "__call__", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "len", "(", "input", ".", "size", "(", ")", ")", "==", "3", ":", "\n", "            ", "self", ".", "_erase", "(", "input", ",", "*", "input", ".", "size", "(", ")", ",", "input", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "batch_size", ",", "chan", ",", "img_h", ",", "img_w", "=", "input", ".", "size", "(", ")", "\n", "# skip first slice of batch if num_splits is set (for clean portion of samples)", "\n", "batch_start", "=", "(", "\n", "batch_size", "//", "self", ".", "num_splits", "if", "self", ".", "num_splits", ">", "1", "else", "0", "\n", ")", "\n", "if", "self", ".", "cube", ":", "\n", "                ", "self", ".", "_erase_cube", "(", "\n", "input", ",", "\n", "batch_start", ",", "\n", "batch_size", ",", "\n", "chan", ",", "\n", "img_h", ",", "\n", "img_w", ",", "\n", "input", ".", "dtype", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_start", ",", "batch_size", ")", ":", "\n", "                    ", "self", ".", "_erase", "(", "input", "[", "i", "]", ",", "chan", ",", "img_h", ",", "img_w", ",", "input", ".", "dtype", ")", "\n", "", "", "", "return", "input", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.random_erasing._get_pixels": [[11, 25], ["torch.empty().normal_", "torch.empty().normal_", "torch.zeros", "torch.empty", "torch.empty"], "function", ["None"], ["def", "_get_pixels", "(", "\n", "per_pixel", ",", "rand_color", ",", "patch_size", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "\"cuda\"", "\n", ")", ":", "\n", "# NOTE I've seen CUDA illegal memory access errors being caused by the normal_()", "\n", "# paths, flip the order so normal is run on CPU if this becomes a problem", "\n", "# Issue has been fixed in master https://github.com/pytorch/pytorch/issues/19508", "\n", "    ", "if", "per_pixel", ":", "\n", "        ", "return", "torch", ".", "empty", "(", "patch_size", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", ".", "normal_", "(", ")", "\n", "", "elif", "rand_color", ":", "\n", "        ", "return", "torch", ".", "empty", "(", "\n", "(", "patch_size", "[", "0", "]", ",", "1", ",", "1", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "device", "\n", ")", ".", "normal_", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "(", "patch_size", "[", "0", "]", ",", "1", ",", "1", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder.__init__": [[26, 58], ["torch.Module.__init__", "modeling_finetune.PatchEmbed", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "modeling_pretrain.PretrainVisionTransformerEncoder.apply", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_finetune.get_sinusoid_encoding_table", "x.item", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "timm.models.layers.trunc_normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "modeling_finetune.Block", "range"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.get_sinusoid_encoding_table", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.trunc_normal_"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "num_classes", "=", "0", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "init_values", "=", "None", ",", "tubelet_size", "=", "2", ",", "\n", "use_learnable_pos_emb", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ",", "tubelet_size", "=", "tubelet_size", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "\n", "# TODO: Add the cls token", "\n", "if", "use_learnable_pos_emb", ":", "\n", "            ", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", "+", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "# sine-cosine positional embeddings ", "\n", "            ", "self", ".", "pos_embed", "=", "get_sinusoid_encoding_table", "(", "num_patches", ",", "embed_dim", ")", "\n", "\n", "", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "# stochastic depth decay rule", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "init_values", "=", "init_values", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "if", "use_learnable_pos_emb", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder._init_weights": [[60, 68], ["isinstance", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder.get_num_layers": [[69, 71], ["len"], "methods", ["None"], ["", "", "def", "get_num_layers", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder.no_weight_decay": [[72, 75], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder.get_classifier": [[76, 78], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder.reset_classifier": [[79, 82], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "''", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder.forward_features": [[83, 97], ["modeling_pretrain.PretrainVisionTransformerEncoder.patch_embed", "x[].reshape", "modeling_pretrain.PretrainVisionTransformerEncoder.norm", "modeling_pretrain.PretrainVisionTransformerEncoder.pos_embed.type_as().to().clone().detach", "blk", "modeling_pretrain.PretrainVisionTransformerEncoder.pos_embed.type_as().to().clone", "modeling_pretrain.PretrainVisionTransformerEncoder.pos_embed.type_as().to", "modeling_pretrain.PretrainVisionTransformerEncoder.pos_embed.type_as"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "_", ",", "_", ",", "T", ",", "_", ",", "_", "=", "x", ".", "shape", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", ".", "type_as", "(", "x", ")", ".", "to", "(", "x", ".", "device", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "B", ",", "_", ",", "C", "=", "x", ".", "shape", "\n", "x_vis", "=", "x", "[", "~", "mask", "]", ".", "reshape", "(", "B", ",", "-", "1", ",", "C", ")", "# ~mask means visible", "\n", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "x_vis", "=", "blk", "(", "x_vis", ")", "\n", "\n", "", "x_vis", "=", "self", ".", "norm", "(", "x_vis", ")", "\n", "return", "x_vis", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerEncoder.forward": [[98, 102], ["modeling_pretrain.PretrainVisionTransformerEncoder.forward_features", "modeling_pretrain.PretrainVisionTransformerEncoder.head"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ",", "mask", ")", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerDecoder.__init__": [[106, 127], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "norm_layer", "modeling_pretrain.PretrainVisionTransformerDecoder.apply", "x.item", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "modeling_finetune.Block", "range"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__"], ["def", "__init__", "(", "self", ",", "patch_size", "=", "16", ",", "num_classes", "=", "768", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop_rate", "=", "0.", ",", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "init_values", "=", "None", ",", "num_patches", "=", "196", ",", "tubelet_size", "=", "2", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "assert", "num_classes", "==", "3", "*", "tubelet_size", "*", "patch_size", "**", "2", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "# stochastic depth decay rule", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "init_values", "=", "init_values", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerDecoder._init_weights": [[129, 137], ["isinstance", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerDecoder.get_num_layers": [[138, 140], ["len"], "methods", ["None"], ["", "", "def", "get_num_layers", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerDecoder.no_weight_decay": [[141, 144], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerDecoder.get_classifier": [[145, 147], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerDecoder.reset_classifier": [[148, 151], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "''", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformerDecoder.forward": [[152, 162], ["blk", "modeling_pretrain.PretrainVisionTransformerDecoder.head", "modeling_pretrain.PretrainVisionTransformerDecoder.head", "modeling_pretrain.PretrainVisionTransformerDecoder.norm", "modeling_pretrain.PretrainVisionTransformerDecoder.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "return_token_num", ")", ":", "\n", "        ", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "\n", "", "if", "return_token_num", ">", "0", ":", "\n", "            ", "x", "=", "self", ".", "head", "(", "self", ".", "norm", "(", "x", "[", ":", ",", "-", "return_token_num", ":", "]", ")", ")", "# only return the mask tokens predict pixels", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "head", "(", "self", ".", "norm", "(", "x", ")", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformer.__init__": [[166, 235], ["torch.Module.__init__", "modeling_pretrain.PretrainVisionTransformerEncoder", "modeling_pretrain.PretrainVisionTransformerDecoder", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_finetune.get_sinusoid_encoding_table", "timm.models.layers.trunc_normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.get_sinusoid_encoding_table", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.trunc_normal_"], ["def", "__init__", "(", "self", ",", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "encoder_in_chans", "=", "3", ",", "\n", "encoder_num_classes", "=", "0", ",", "\n", "encoder_embed_dim", "=", "768", ",", "\n", "encoder_depth", "=", "12", ",", "\n", "encoder_num_heads", "=", "12", ",", "\n", "decoder_num_classes", "=", "1536", ",", "#  decoder_num_classes=768, ", "\n", "decoder_embed_dim", "=", "512", ",", "\n", "decoder_depth", "=", "8", ",", "\n", "decoder_num_heads", "=", "8", ",", "\n", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "init_values", "=", "0.", ",", "\n", "use_learnable_pos_emb", "=", "False", ",", "\n", "tubelet_size", "=", "2", ",", "\n", "num_classes", "=", "0", ",", "# avoid the error from create_fn in timm", "\n", "in_chans", "=", "0", ",", "# avoid the error from create_fn in timm", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "PretrainVisionTransformerEncoder", "(", "\n", "img_size", "=", "img_size", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "in_chans", "=", "encoder_in_chans", ",", "\n", "num_classes", "=", "encoder_num_classes", ",", "\n", "embed_dim", "=", "encoder_embed_dim", ",", "\n", "depth", "=", "encoder_depth", ",", "\n", "num_heads", "=", "encoder_num_heads", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "init_values", "=", "init_values", ",", "\n", "tubelet_size", "=", "tubelet_size", ",", "\n", "use_learnable_pos_emb", "=", "use_learnable_pos_emb", ")", "\n", "\n", "self", ".", "decoder", "=", "PretrainVisionTransformerDecoder", "(", "\n", "patch_size", "=", "patch_size", ",", "\n", "num_patches", "=", "self", ".", "encoder", ".", "patch_embed", ".", "num_patches", ",", "\n", "num_classes", "=", "decoder_num_classes", ",", "\n", "embed_dim", "=", "decoder_embed_dim", ",", "\n", "depth", "=", "decoder_depth", ",", "\n", "num_heads", "=", "decoder_num_heads", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "init_values", "=", "init_values", ",", "\n", "tubelet_size", "=", "tubelet_size", ")", "\n", "\n", "self", ".", "encoder_to_decoder", "=", "nn", ".", "Linear", "(", "encoder_embed_dim", ",", "decoder_embed_dim", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "mask_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "decoder_embed_dim", ")", ")", "\n", "\n", "self", ".", "pos_embed", "=", "get_sinusoid_encoding_table", "(", "self", ".", "encoder", ".", "patch_embed", ".", "num_patches", ",", "decoder_embed_dim", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "mask_token", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformer._init_weights": [[237, 245], ["isinstance", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformer.get_num_layers": [[246, 248], ["len"], "methods", ["None"], ["", "", "def", "get_num_layers", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformer.no_weight_decay": [[249, 252], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", ",", "'mask_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.PretrainVisionTransformer.forward": [[253, 267], ["modeling_pretrain.PretrainVisionTransformer.encoder", "modeling_pretrain.PretrainVisionTransformer.encoder_to_decoder", "modeling_pretrain.PretrainVisionTransformer.pos_embed.expand().type_as().to().clone().detach", "expand_pos_embed[].reshape", "expand_pos_embed[].reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_pretrain.PretrainVisionTransformer.decoder", "modeling_pretrain.PretrainVisionTransformer.pos_embed.expand().type_as().to().clone", "modeling_pretrain.PretrainVisionTransformer.pos_embed.expand().type_as().to", "modeling_pretrain.PretrainVisionTransformer.pos_embed.expand().type_as", "modeling_pretrain.PretrainVisionTransformer.pos_embed.expand"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "_", ",", "_", ",", "T", ",", "_", ",", "_", "=", "x", ".", "shape", "\n", "x_vis", "=", "self", ".", "encoder", "(", "x", ",", "mask", ")", "# [B, N_vis, C_e]", "\n", "x_vis", "=", "self", ".", "encoder_to_decoder", "(", "x_vis", ")", "# [B, N_vis, C_d]", "\n", "B", ",", "N", ",", "C", "=", "x_vis", ".", "shape", "\n", "# we don't unshuffle the correct visible token order, ", "\n", "# but shuffle the pos embedding accorddingly.", "\n", "expand_pos_embed", "=", "self", ".", "pos_embed", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", ".", "type_as", "(", "x", ")", ".", "to", "(", "x", ".", "device", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "pos_emd_vis", "=", "expand_pos_embed", "[", "~", "mask", "]", ".", "reshape", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "pos_emd_mask", "=", "expand_pos_embed", "[", "mask", "]", ".", "reshape", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "x_full", "=", "torch", ".", "cat", "(", "[", "x_vis", "+", "pos_emd_vis", ",", "self", ".", "mask_token", "+", "pos_emd_mask", "]", ",", "dim", "=", "1", ")", "# [B, N, C_d]", "\n", "x", "=", "self", ".", "decoder", "(", "x_full", ",", "pos_emd_mask", ".", "shape", "[", "1", "]", ")", "# [B, N_mask, 3 * 16 * 16]", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.trunc_normal_": [[13, 15], ["timm.models.layers.trunc_normal_"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.trunc_normal_"], ["def", "trunc_normal_", "(", "tensor", ",", "mean", "=", "0.", ",", "std", "=", "1.", ")", ":", "\n", "    ", "__call_trunc_normal_", "(", "tensor", ",", "mean", "=", "mean", ",", "std", "=", "std", ",", "a", "=", "-", "std", ",", "b", "=", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.pretrain_mae_small_patch16_224": [[268, 291], ["modeling_pretrain.PretrainVisionTransformer", "modeling_finetune._cfg", "torch.load", "torch.load", "torch.load", "PretrainVisionTransformer.load_state_dict", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict"], ["", "", "@", "register_model", "\n", "def", "pretrain_mae_small_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "PretrainVisionTransformer", "(", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "encoder_embed_dim", "=", "384", ",", "\n", "encoder_depth", "=", "12", ",", "\n", "encoder_num_heads", "=", "6", ",", "\n", "encoder_num_classes", "=", "0", ",", "\n", "decoder_num_classes", "=", "1536", ",", "\n", "decoder_embed_dim", "=", "192", ",", "\n", "decoder_num_heads", "=", "3", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "\n", "kwargs", "[", "\"init_ckpt\"", "]", ",", "map_location", "=", "\"cpu\"", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.pretrain_videomae_base_patch16_224": [[292, 315], ["modeling_pretrain.PretrainVisionTransformer", "modeling_finetune._cfg", "torch.load", "torch.load", "torch.load", "PretrainVisionTransformer.load_state_dict", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict"], ["", "@", "register_model", "\n", "def", "pretrain_videomae_base_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "PretrainVisionTransformer", "(", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "encoder_embed_dim", "=", "768", ",", "\n", "encoder_depth", "=", "12", ",", "\n", "encoder_num_heads", "=", "12", ",", "\n", "encoder_num_classes", "=", "0", ",", "\n", "decoder_num_classes", "=", "1536", ",", "\n", "decoder_embed_dim", "=", "384", ",", "\n", "decoder_num_heads", "=", "6", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "\n", "kwargs", "[", "\"init_ckpt\"", "]", ",", "map_location", "=", "\"cpu\"", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.pretrain_videomae_large_patch16_224": [[316, 339], ["modeling_pretrain.PretrainVisionTransformer", "modeling_finetune._cfg", "torch.load", "torch.load", "torch.load", "PretrainVisionTransformer.load_state_dict", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict"], ["", "@", "register_model", "\n", "def", "pretrain_videomae_large_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "PretrainVisionTransformer", "(", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "encoder_embed_dim", "=", "1024", ",", "\n", "encoder_depth", "=", "24", ",", "\n", "encoder_num_heads", "=", "16", ",", "\n", "encoder_num_classes", "=", "0", ",", "\n", "decoder_num_classes", "=", "1536", ",", "\n", "decoder_embed_dim", "=", "512", ",", "\n", "decoder_num_heads", "=", "8", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "\n", "kwargs", "[", "\"init_ckpt\"", "]", ",", "map_location", "=", "\"cpu\"", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.LayerDecayValueAssigner.__init__": [[39, 41], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "values", ")", ":", "\n", "        ", "self", ".", "values", "=", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.LayerDecayValueAssigner.get_scale": [[42, 44], ["None"], "methods", ["None"], ["", "def", "get_scale", "(", "self", ",", "layer_id", ")", ":", "\n", "        ", "return", "self", ".", "values", "[", "layer_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.LayerDecayValueAssigner.get_layer_id": [[45, 47], ["optim_factory.get_num_layer_for_vit", "len"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.get_num_layer_for_vit"], ["", "def", "get_layer_id", "(", "self", ",", "var_name", ")", ":", "\n", "        ", "return", "get_num_layer_for_vit", "(", "var_name", ",", "len", "(", "self", ".", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.get_num_layer_for_vit": [[24, 36], ["var_name.startswith", "var_name.startswith", "var_name.startswith", "int", "var_name.split"], "function", ["None"], ["", "def", "get_num_layer_for_vit", "(", "var_name", ",", "num_max_layer", ")", ":", "\n", "    ", "if", "var_name", "in", "(", "\"cls_token\"", ",", "\"mask_token\"", ",", "\"pos_embed\"", ")", ":", "\n", "        ", "return", "0", "\n", "", "elif", "var_name", ".", "startswith", "(", "\"patch_embed\"", ")", ":", "\n", "        ", "return", "0", "\n", "", "elif", "var_name", ".", "startswith", "(", "\"rel_pos_bias\"", ")", ":", "\n", "        ", "return", "num_max_layer", "-", "1", "\n", "", "elif", "var_name", ".", "startswith", "(", "\"blocks\"", ")", ":", "\n", "        ", "layer_id", "=", "int", "(", "var_name", ".", "split", "(", "'.'", ")", "[", "1", "]", ")", "\n", "return", "layer_id", "+", "1", "\n", "", "else", ":", "\n", "        ", "return", "num_max_layer", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.get_parameter_groups": [[49, 89], ["model.named_parameters", "print", "list", "[].append", "[].append", "parameter_group_vars.values", "name.endswith", "get_num_layer", "json.dumps", "len", "get_layer_scale"], "function", ["None"], ["", "", "def", "get_parameter_groups", "(", "model", ",", "weight_decay", "=", "1e-5", ",", "skip_list", "=", "(", ")", ",", "get_num_layer", "=", "None", ",", "get_layer_scale", "=", "None", ")", ":", "\n", "    ", "parameter_group_names", "=", "{", "}", "\n", "parameter_group_vars", "=", "{", "}", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "param", ".", "requires_grad", ":", "\n", "            ", "continue", "# frozen weights", "\n", "", "if", "len", "(", "param", ".", "shape", ")", "==", "1", "or", "name", ".", "endswith", "(", "\".bias\"", ")", "or", "name", "in", "skip_list", ":", "\n", "            ", "group_name", "=", "\"no_decay\"", "\n", "this_weight_decay", "=", "0.", "\n", "", "else", ":", "\n", "            ", "group_name", "=", "\"decay\"", "\n", "this_weight_decay", "=", "weight_decay", "\n", "", "if", "get_num_layer", "is", "not", "None", ":", "\n", "            ", "layer_id", "=", "get_num_layer", "(", "name", ")", "\n", "group_name", "=", "\"layer_%d_%s\"", "%", "(", "layer_id", ",", "group_name", ")", "\n", "", "else", ":", "\n", "            ", "layer_id", "=", "None", "\n", "\n", "", "if", "group_name", "not", "in", "parameter_group_names", ":", "\n", "            ", "if", "get_layer_scale", "is", "not", "None", ":", "\n", "                ", "scale", "=", "get_layer_scale", "(", "layer_id", ")", "\n", "", "else", ":", "\n", "                ", "scale", "=", "1.", "\n", "\n", "", "parameter_group_names", "[", "group_name", "]", "=", "{", "\n", "\"weight_decay\"", ":", "this_weight_decay", ",", "\n", "\"params\"", ":", "[", "]", ",", "\n", "\"lr_scale\"", ":", "scale", "\n", "}", "\n", "parameter_group_vars", "[", "group_name", "]", "=", "{", "\n", "\"weight_decay\"", ":", "this_weight_decay", ",", "\n", "\"params\"", ":", "[", "]", ",", "\n", "\"lr_scale\"", ":", "scale", "\n", "}", "\n", "\n", "", "parameter_group_vars", "[", "group_name", "]", "[", "\"params\"", "]", ".", "append", "(", "param", ")", "\n", "parameter_group_names", "[", "group_name", "]", "[", "\"params\"", "]", ".", "append", "(", "name", ")", "\n", "", "print", "(", "\"Param groups = %s\"", "%", "json", ".", "dumps", "(", "parameter_group_names", ",", "indent", "=", "2", ")", ")", "\n", "return", "list", "(", "parameter_group_vars", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.create_optimizer": [[91, 176], ["args.opt.lower", "dict", "print", "args.opt.lower.split", "optim_factory.get_parameter_groups", "model.parameters", "hasattr", "hasattr", "dict.pop", "torch.optim.SGD", "len", "hasattr", "torch.cuda.is_available", "dict.pop", "torch.optim.SGD", "timm.optim.lookahead.Lookahead", "model.no_weight_decay", "torch.optim.Adam", "torch.optim.AdamW", "timm.optim.nadam.Nadam", "timm.optim.radam.RAdam", "timm.optim.adamp.AdamP", "timm.optim.sgdp.SGDP", "torch.optim.Adadelta", "timm.optim.adafactor.Adafactor", "timm.optim.adahessian.Adahessian", "torch.optim.RMSprop", "timm.optim.rmsprop_tf.RMSpropTF", "timm.optim.novograd.NovoGrad", "timm.optim.nvnovograd.NvNovoGrad", "dict.pop", "FusedSGD", "dict.pop", "FusedSGD", "FusedAdam", "FusedAdam", "FusedLAMB", "dict.setdefault", "FusedNovoGrad"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.get_parameter_groups", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.no_weight_decay"], ["", "def", "create_optimizer", "(", "args", ",", "model", ",", "get_num_layer", "=", "None", ",", "get_layer_scale", "=", "None", ",", "filter_bias_and_bn", "=", "True", ",", "skip_list", "=", "None", ")", ":", "\n", "    ", "opt_lower", "=", "args", ".", "opt", ".", "lower", "(", ")", "\n", "weight_decay", "=", "args", ".", "weight_decay", "\n", "if", "weight_decay", "and", "filter_bias_and_bn", ":", "\n", "        ", "skip", "=", "{", "}", "\n", "if", "skip_list", "is", "not", "None", ":", "\n", "            ", "skip", "=", "skip_list", "\n", "", "elif", "hasattr", "(", "model", ",", "'no_weight_decay'", ")", ":", "\n", "            ", "skip", "=", "model", ".", "no_weight_decay", "(", ")", "\n", "", "parameters", "=", "get_parameter_groups", "(", "model", ",", "weight_decay", ",", "skip", ",", "get_num_layer", ",", "get_layer_scale", ")", "\n", "weight_decay", "=", "0.", "\n", "", "else", ":", "\n", "        ", "parameters", "=", "model", ".", "parameters", "(", ")", "\n", "\n", "", "if", "'fused'", "in", "opt_lower", ":", "\n", "        ", "assert", "has_apex", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "'APEX and CUDA required for fused optimizers'", "\n", "\n", "", "opt_args", "=", "dict", "(", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "if", "hasattr", "(", "args", ",", "'opt_eps'", ")", "and", "args", ".", "opt_eps", "is", "not", "None", ":", "\n", "        ", "opt_args", "[", "'eps'", "]", "=", "args", ".", "opt_eps", "\n", "", "if", "hasattr", "(", "args", ",", "'opt_betas'", ")", "and", "args", ".", "opt_betas", "is", "not", "None", ":", "\n", "        ", "opt_args", "[", "'betas'", "]", "=", "args", ".", "opt_betas", "\n", "\n", "", "print", "(", "\"optimizer settings:\"", ",", "opt_args", ")", "\n", "\n", "opt_split", "=", "opt_lower", ".", "split", "(", "'_'", ")", "\n", "opt_lower", "=", "opt_split", "[", "-", "1", "]", "\n", "if", "opt_lower", "==", "'sgd'", "or", "opt_lower", "==", "'nesterov'", ":", "\n", "        ", "opt_args", ".", "pop", "(", "'eps'", ",", "None", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "parameters", ",", "momentum", "=", "args", ".", "momentum", ",", "nesterov", "=", "True", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'momentum'", ":", "\n", "        ", "opt_args", ".", "pop", "(", "'eps'", ",", "None", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "parameters", ",", "momentum", "=", "args", ".", "momentum", ",", "nesterov", "=", "False", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'adamw'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "AdamW", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'nadam'", ":", "\n", "        ", "optimizer", "=", "Nadam", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'radam'", ":", "\n", "        ", "optimizer", "=", "RAdam", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'adamp'", ":", "\n", "        ", "optimizer", "=", "AdamP", "(", "parameters", ",", "wd_ratio", "=", "0.01", ",", "nesterov", "=", "True", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'sgdp'", ":", "\n", "        ", "optimizer", "=", "SGDP", "(", "parameters", ",", "momentum", "=", "args", ".", "momentum", ",", "nesterov", "=", "True", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'adadelta'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adadelta", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'adafactor'", ":", "\n", "        ", "if", "not", "args", ".", "lr", ":", "\n", "            ", "opt_args", "[", "'lr'", "]", "=", "None", "\n", "", "optimizer", "=", "Adafactor", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'adahessian'", ":", "\n", "        ", "optimizer", "=", "Adahessian", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'rmsprop'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "RMSprop", "(", "parameters", ",", "alpha", "=", "0.9", ",", "momentum", "=", "args", ".", "momentum", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'rmsproptf'", ":", "\n", "        ", "optimizer", "=", "RMSpropTF", "(", "parameters", ",", "alpha", "=", "0.9", ",", "momentum", "=", "args", ".", "momentum", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'novograd'", ":", "\n", "        ", "optimizer", "=", "NovoGrad", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'nvnovograd'", ":", "\n", "        ", "optimizer", "=", "NvNovoGrad", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'fusedsgd'", ":", "\n", "        ", "opt_args", ".", "pop", "(", "'eps'", ",", "None", ")", "\n", "optimizer", "=", "FusedSGD", "(", "parameters", ",", "momentum", "=", "args", ".", "momentum", ",", "nesterov", "=", "True", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'fusedmomentum'", ":", "\n", "        ", "opt_args", ".", "pop", "(", "'eps'", ",", "None", ")", "\n", "optimizer", "=", "FusedSGD", "(", "parameters", ",", "momentum", "=", "args", ".", "momentum", ",", "nesterov", "=", "False", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'fusedadam'", ":", "\n", "        ", "optimizer", "=", "FusedAdam", "(", "parameters", ",", "adam_w_mode", "=", "False", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'fusedadamw'", ":", "\n", "        ", "optimizer", "=", "FusedAdam", "(", "parameters", ",", "adam_w_mode", "=", "True", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'fusedlamb'", ":", "\n", "        ", "optimizer", "=", "FusedLAMB", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "elif", "opt_lower", "==", "'fusednovograd'", ":", "\n", "        ", "opt_args", ".", "setdefault", "(", "'betas'", ",", "(", "0.95", ",", "0.98", ")", ")", "\n", "optimizer", "=", "FusedNovoGrad", "(", "parameters", ",", "**", "opt_args", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", "and", "\"Invalid optimizer\"", "\n", "raise", "ValueError", "\n", "\n", "", "if", "len", "(", "opt_split", ")", ">", "1", ":", "\n", "        ", "if", "opt_split", "[", "0", "]", "==", "'lookahead'", ":", "\n", "            ", "optimizer", "=", "Lookahead", "(", "optimizer", ")", "\n", "\n", "", "", "return", "optimizer", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomResizedCropAndInterpolation.__init__": [[705, 725], ["isinstance", "print", "video_transforms._pil_interp"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._pil_interp"], ["def", "__init__", "(", "\n", "self", ",", "\n", "size", ",", "\n", "scale", "=", "(", "0.08", ",", "1.0", ")", ",", "\n", "ratio", "=", "(", "3.0", "/", "4.0", ",", "4.0", "/", "3.0", ")", ",", "\n", "interpolation", "=", "\"bilinear\"", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "(", "size", ",", "size", ")", "\n", "", "if", "(", "scale", "[", "0", "]", ">", "scale", "[", "1", "]", ")", "or", "(", "ratio", "[", "0", "]", ">", "ratio", "[", "1", "]", ")", ":", "\n", "            ", "print", "(", "\"range should be of kind (min, max)\"", ")", "\n", "\n", "", "if", "interpolation", "==", "\"random\"", ":", "\n", "            ", "self", ".", "interpolation", "=", "_RANDOM_INTERPOLATION", "\n", "", "else", ":", "\n", "            ", "self", ".", "interpolation", "=", "_pil_interp", "(", "interpolation", ")", "\n", "", "self", ".", "scale", "=", "scale", "\n", "self", ".", "ratio", "=", "ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomResizedCropAndInterpolation.get_params": [[726, 766], ["range", "math.exp", "int", "int", "min", "int", "random.uniform", "math.log", "math.log", "random.uniform", "round", "round", "random.randint", "random.randint", "round", "max", "int", "math.sqrt", "math.sqrt", "round", "min", "max"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "@", "staticmethod", "\n", "def", "get_params", "(", "img", ",", "scale", ",", "ratio", ")", ":", "\n", "        ", "\"\"\"Get parameters for ``crop`` for a random sized crop.\n        Args:\n            img (PIL Image): Image to be cropped.\n            scale (tuple): range of size of the origin size cropped\n            ratio (tuple): range of aspect ratio of the origin aspect ratio cropped\n        Returns:\n            tuple: params (i, j, h, w) to be passed to ``crop`` for a random\n                sized crop.\n        \"\"\"", "\n", "area", "=", "img", ".", "size", "[", "0", "]", "*", "img", ".", "size", "[", "1", "]", "\n", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "            ", "target_area", "=", "random", ".", "uniform", "(", "*", "scale", ")", "*", "area", "\n", "log_ratio", "=", "(", "math", ".", "log", "(", "ratio", "[", "0", "]", ")", ",", "math", ".", "log", "(", "ratio", "[", "1", "]", ")", ")", "\n", "aspect_ratio", "=", "math", ".", "exp", "(", "random", ".", "uniform", "(", "*", "log_ratio", ")", ")", "\n", "\n", "w", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "*", "aspect_ratio", ")", ")", ")", "\n", "h", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "/", "aspect_ratio", ")", ")", ")", "\n", "\n", "if", "w", "<=", "img", ".", "size", "[", "0", "]", "and", "h", "<=", "img", ".", "size", "[", "1", "]", ":", "\n", "                ", "i", "=", "random", ".", "randint", "(", "0", ",", "img", ".", "size", "[", "1", "]", "-", "h", ")", "\n", "j", "=", "random", ".", "randint", "(", "0", ",", "img", ".", "size", "[", "0", "]", "-", "w", ")", "\n", "return", "i", ",", "j", ",", "h", ",", "w", "\n", "\n", "# Fallback to central crop", "\n", "", "", "in_ratio", "=", "img", ".", "size", "[", "0", "]", "/", "img", ".", "size", "[", "1", "]", "\n", "if", "in_ratio", "<", "min", "(", "ratio", ")", ":", "\n", "            ", "w", "=", "img", ".", "size", "[", "0", "]", "\n", "h", "=", "int", "(", "round", "(", "w", "/", "min", "(", "ratio", ")", ")", ")", "\n", "", "elif", "in_ratio", ">", "max", "(", "ratio", ")", ":", "\n", "            ", "h", "=", "img", ".", "size", "[", "1", "]", "\n", "w", "=", "int", "(", "round", "(", "h", "*", "max", "(", "ratio", ")", ")", ")", "\n", "", "else", ":", "# whole image", "\n", "            ", "w", "=", "img", ".", "size", "[", "0", "]", "\n", "h", "=", "img", ".", "size", "[", "1", "]", "\n", "", "i", "=", "(", "img", ".", "size", "[", "1", "]", "-", "h", ")", "//", "2", "\n", "j", "=", "(", "img", ".", "size", "[", "0", "]", "-", "w", ")", "//", "2", "\n", "return", "i", ",", "j", ",", "h", ",", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomResizedCropAndInterpolation.__call__": [[767, 780], ["video_transforms.RandomResizedCropAndInterpolation.get_params", "isinstance", "torchvision.resized_crop", "torchvision.resized_crop", "random.choice"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.ColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL Image): Image to be cropped and resized.\n        Returns:\n            PIL Image: Randomly cropped and resized image.\n        \"\"\"", "\n", "i", ",", "j", ",", "h", ",", "w", "=", "self", ".", "get_params", "(", "img", ",", "self", ".", "scale", ",", "self", ".", "ratio", ")", "\n", "if", "isinstance", "(", "self", ".", "interpolation", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "interpolation", "=", "random", ".", "choice", "(", "self", ".", "interpolation", ")", "\n", "", "else", ":", "\n", "            ", "interpolation", "=", "self", ".", "interpolation", "\n", "", "return", "F", ".", "resized_crop", "(", "img", ",", "i", ",", "j", ",", "h", ",", "w", ",", "self", ".", "size", ",", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomResizedCropAndInterpolation.__repr__": [[781, 797], ["isinstance", "tuple", "tuple", "round", "round"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "interpolation", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "interpolate_str", "=", "\" \"", ".", "join", "(", "\n", "[", "_pil_interpolation_to_str", "[", "x", "]", "for", "x", "in", "self", ".", "interpolation", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "interpolate_str", "=", "_pil_interpolation_to_str", "[", "self", ".", "interpolation", "]", "\n", "", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(size={0}\"", ".", "format", "(", "self", ".", "size", ")", "\n", "format_string", "+=", "\", scale={0}\"", ".", "format", "(", "\n", "tuple", "(", "round", "(", "s", ",", "4", ")", "for", "s", "in", "self", ".", "scale", ")", "\n", ")", "\n", "format_string", "+=", "\", ratio={0}\"", ".", "format", "(", "\n", "tuple", "(", "round", "(", "r", ",", "4", ")", "for", "r", "in", "self", ".", "ratio", ")", "\n", ")", "\n", "format_string", "+=", "\", interpolation={0})\"", ".", "format", "(", "interpolate_str", ")", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.Compose.__init__": [[909, 911], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.Compose.__call__": [[912, 916], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "clip", "=", "t", "(", "clip", ")", "\n", "", "return", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomHorizontalFlip.__call__": [[923, 942], ["random.random", "isinstance", "isinstance", "numpy.fliplr", "TypeError", "img.transpose", "type"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Randomly flipped clip\n        \"\"\"", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "return", "[", "np", ".", "fliplr", "(", "img", ")", "for", "img", "in", "clip", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "                ", "return", "[", "\n", "img", ".", "transpose", "(", "PIL", ".", "Image", ".", "FLIP_LEFT_RIGHT", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "' but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "", "return", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomResize.__init__": [[954, 957], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ratio", "=", "(", "3.", "/", "4.", ",", "4.", "/", "3.", ")", ",", "interpolation", "=", "'nearest'", ")", ":", "\n", "        ", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomResize.__call__": [[958, 972], ["random.uniform", "isinstance", "int", "int", "functional.resize_clip", "isinstance"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.resize_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "scaling_factor", "=", "random", ".", "uniform", "(", "self", ".", "ratio", "[", "0", "]", ",", "self", ".", "ratio", "[", "1", "]", ")", "\n", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "\n", "", "new_w", "=", "int", "(", "im_w", "*", "scaling_factor", ")", "\n", "new_h", "=", "int", "(", "im_h", "*", "scaling_factor", ")", "\n", "new_size", "=", "(", "new_w", ",", "new_h", ")", "\n", "resized", "=", "FF", ".", "resize_clip", "(", "\n", "clip", ",", "new_size", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.Resize.__init__": [[984, 987], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "'nearest'", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.Resize.__call__": [[988, 992], ["functional.resize_clip"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.resize_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "resized", "=", "FF", ".", "resize_clip", "(", "\n", "clip", ",", "self", ".", "size", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomCrop.__init__": [[1001, 1006], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "size", "=", "(", "size", ",", "size", ")", "\n", "\n", "", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomCrop.__call__": [[1007, 1036], ["isinstance", "random.randint", "random.randint", "functional.crop_clip", "isinstance", "ValueError", "TypeError", "type"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.crop_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "if", "w", ">", "im_w", "or", "h", ">", "im_h", ":", "\n", "            ", "error_msg", "=", "(", "\n", "'Initial image size should be larger then '", "\n", "'cropped size but got cropped sizes : ({w}, {h}) while '", "\n", "'initial image is ({im_w}, {im_h})'", ".", "format", "(", "\n", "im_w", "=", "im_w", ",", "im_h", "=", "im_h", ",", "w", "=", "w", ",", "h", "=", "h", ")", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "x1", "=", "random", ".", "randint", "(", "0", ",", "im_w", "-", "w", ")", "\n", "y1", "=", "random", ".", "randint", "(", "0", ",", "im_h", "-", "h", ")", "\n", "cropped", "=", "FF", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", "\n", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.ThreeCrop.__init__": [[1045, 1050], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "size", "=", "(", "size", ",", "size", ")", "\n", "\n", "", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.ThreeCrop.__call__": [[1051, 1083], ["isinstance", "numpy.max", "range", "isinstance", "functional.resize_clip", "TypeError", "cropped.extend", "cropped.extend", "numpy.max", "functional.crop_clip", "functional.crop_clip", "type"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.resize_clip", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.crop_clip", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.crop_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "if", "w", "!=", "im_w", "and", "h", "!=", "im_h", ":", "\n", "            ", "clip", "=", "FF", ".", "resize_clip", "(", "clip", ",", "self", ".", "size", ",", "interpolation", "=", "\"bilinear\"", ")", "\n", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "\n", "", "step", "=", "np", ".", "max", "(", "(", "np", ".", "max", "(", "(", "im_w", ",", "im_h", ")", ")", "-", "self", ".", "size", "[", "0", "]", ")", "//", "2", ",", "0", ")", "\n", "cropped", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "if", "(", "im_h", ">", "self", ".", "size", "[", "0", "]", ")", ":", "\n", "                ", "x1", "=", "0", "\n", "y1", "=", "i", "*", "step", "\n", "cropped", ".", "extend", "(", "FF", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "x1", "=", "i", "*", "step", "\n", "y1", "=", "0", "\n", "cropped", ".", "extend", "(", "FF", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", ")", "\n", "", "", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomRotation.__init__": [[1094, 1106], ["isinstance", "ValueError", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "degrees", ")", ":", "\n", "        ", "if", "isinstance", "(", "degrees", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "if", "degrees", "<", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a single number,'", "\n", "'must be positive'", ")", "\n", "", "degrees", "=", "(", "-", "degrees", ",", "degrees", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "degrees", ")", "!=", "2", ":", "\n", "                ", "raise", "ValueError", "(", "'If degrees is a sequence,'", "\n", "'it must be of len 2.'", ")", "\n", "\n", "", "", "self", ".", "degrees", "=", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.RandomRotation.__call__": [[1107, 1126], ["random.uniform", "isinstance", "isinstance", "skimage.transform.rotate", "TypeError", "img.rotate", "type"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rotate", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rotate"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "import", "skimage", "\n", "angle", "=", "random", ".", "uniform", "(", "self", ".", "degrees", "[", "0", "]", ",", "self", ".", "degrees", "[", "1", "]", ")", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "rotated", "=", "[", "skimage", ".", "transform", ".", "rotate", "(", "img", ",", "angle", ")", "for", "img", "in", "clip", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "rotated", "=", "[", "img", ".", "rotate", "(", "angle", ")", "for", "img", "in", "clip", "]", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "rotated", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.CenterCrop.__init__": [[1135, 1140], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "size", "=", "(", "size", ",", "size", ")", "\n", "\n", "", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.CenterCrop.__call__": [[1141, 1170], ["isinstance", "int", "int", "functional.crop_clip", "isinstance", "ValueError", "round", "round", "TypeError", "type"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.crop_clip"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        img (PIL.Image or numpy.ndarray): List of images to be cropped\n        in format (h, w, c) in numpy.ndarray\n        Returns:\n        PIL.Image or numpy.ndarray: Cropped list of images\n        \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "size", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "if", "w", ">", "im_w", "or", "h", ">", "im_h", ":", "\n", "            ", "error_msg", "=", "(", "\n", "'Initial image size should be larger then '", "\n", "'cropped size but got cropped sizes : ({w}, {h}) while '", "\n", "'initial image is ({im_w}, {im_h})'", ".", "format", "(", "\n", "im_w", "=", "im_w", ",", "im_h", "=", "im_h", ",", "w", "=", "w", ",", "h", "=", "h", ")", ")", "\n", "raise", "ValueError", "(", "error_msg", ")", "\n", "\n", "", "x1", "=", "int", "(", "round", "(", "(", "im_w", "-", "w", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "im_h", "-", "h", ")", "/", "2.", ")", ")", "\n", "cropped", "=", "FF", ".", "crop_clip", "(", "clip", ",", "y1", ",", "x1", ",", "h", ",", "w", ")", "\n", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.ColorJitter.__init__": [[1185, 1190], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "self", ".", "brightness", "=", "brightness", "\n", "self", ".", "contrast", "=", "contrast", "\n", "self", ".", "saturation", "=", "saturation", "\n", "self", ".", "hue", "=", "hue", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.ColorJitter.get_params": [[1191, 1215], ["random.uniform", "random.uniform", "random.uniform", "random.uniform", "max", "max", "max"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "def", "get_params", "(", "self", ",", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", ":", "\n", "        ", "if", "brightness", ">", "0", ":", "\n", "            ", "brightness_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", ")", "\n", "", "else", ":", "\n", "            ", "brightness_factor", "=", "None", "\n", "\n", "", "if", "contrast", ">", "0", ":", "\n", "            ", "contrast_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", ")", "\n", "", "else", ":", "\n", "            ", "contrast_factor", "=", "None", "\n", "\n", "", "if", "saturation", ">", "0", ":", "\n", "            ", "saturation_factor", "=", "random", ".", "uniform", "(", "\n", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", ")", "\n", "", "else", ":", "\n", "            ", "saturation_factor", "=", "None", "\n", "\n", "", "if", "hue", ">", "0", ":", "\n", "            ", "hue_factor", "=", "random", ".", "uniform", "(", "-", "hue", ",", "hue", ")", "\n", "", "else", ":", "\n", "            ", "hue_factor", "=", "None", "\n", "", "return", "brightness_factor", ",", "contrast_factor", ",", "saturation_factor", ",", "hue_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.ColorJitter.__call__": [[1216, 1253], ["isinstance", "TypeError", "isinstance", "video_transforms.ColorJitter.get_params", "random.shuffle", "TypeError", "img_transforms.append", "img_transforms.append", "img_transforms.append", "img_transforms.append", "jittered_clip.append", "func", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_brightness", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_saturation", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_hue", "torchvision.transforms.functional.adjust_contrast", "torchvision.transforms.functional.adjust_contrast", "torchvision.transforms.functional.adjust_contrast", "torchvision.transforms.functional.adjust_contrast", "type"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.ColorJitter.get_params"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n        clip (list): list of PIL.Image\n        Returns:\n        list PIL.Image : list of transformed PIL.Image\n        \"\"\"", "\n", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "'Color jitter not yet implemented for numpy arrays'", ")", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "            ", "brightness", ",", "contrast", ",", "saturation", ",", "hue", "=", "self", ".", "get_params", "(", "\n", "self", ".", "brightness", ",", "self", ".", "contrast", ",", "self", ".", "saturation", ",", "self", ".", "hue", ")", "\n", "\n", "# Create img transform function sequence", "\n", "img_transforms", "=", "[", "]", "\n", "if", "brightness", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_brightness", "(", "img", ",", "brightness", ")", ")", "\n", "", "if", "saturation", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_saturation", "(", "img", ",", "saturation", ")", ")", "\n", "", "if", "hue", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_hue", "(", "img", ",", "hue", ")", ")", "\n", "", "if", "contrast", "is", "not", "None", ":", "\n", "                ", "img_transforms", ".", "append", "(", "lambda", "img", ":", "torchvision", ".", "transforms", ".", "functional", ".", "adjust_contrast", "(", "img", ",", "contrast", ")", ")", "\n", "", "random", ".", "shuffle", "(", "img_transforms", ")", "\n", "\n", "# Apply to all images", "\n", "jittered_clip", "=", "[", "]", "\n", "for", "img", "in", "clip", ":", "\n", "                ", "for", "func", "in", "img_transforms", ":", "\n", "                    ", "jittered_img", "=", "func", "(", "img", ")", "\n", "", "jittered_clip", ".", "append", "(", "jittered_img", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "jittered_clip", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.Normalize.__init__": [[1267, 1270], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.Normalize.__call__": [[1271, 1279], ["functional.normalize"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.normalize"], ["", "def", "__call__", "(", "self", ",", "clip", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            clip (Tensor): Tensor clip of size (T, C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized Tensor clip.\n        \"\"\"", "\n", "return", "FF", ".", "normalize", "(", "clip", ",", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.Normalize.__repr__": [[1280, 1282], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'(mean={0}, std={1})'", ".", "format", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._pil_interp": [[33, 42], ["None"], "function", ["None"], ["def", "_pil_interp", "(", "method", ")", ":", "\n", "    ", "if", "method", "==", "\"bicubic\"", ":", "\n", "        ", "return", "Image", ".", "BICUBIC", "\n", "", "elif", "method", "==", "\"lanczos\"", ":", "\n", "        ", "return", "Image", ".", "LANCZOS", "\n", "", "elif", "method", "==", "\"hamming\"", ":", "\n", "        ", "return", "Image", ".", "HAMMING", "\n", "", "else", ":", "\n", "        ", "return", "Image", ".", "BILINEAR", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_short_side_scale_jitter": [[44, 98], ["int", "int", "int", "int", "torch.nn.functional.interpolate", "round", "round", "math.floor", "math.floor", "numpy.random.uniform", "numpy.random.uniform", "float", "float", "float", "float"], "function", ["None"], ["", "", "def", "random_short_side_scale_jitter", "(", "\n", "images", ",", "min_size", ",", "max_size", ",", "boxes", "=", "None", ",", "inverse_uniform_sampling", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Perform a spatial short scale jittering on the given images and\n    corresponding boxes.\n    Args:\n        images (tensor): images to perform scale jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        min_size (int): the minimal size to scale the frames.\n        max_size (int): the maximal size to scale the frames.\n        boxes (ndarray): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n        inverse_uniform_sampling (bool): if True, sample uniformly in\n            [1 / max_scale, 1 / min_scale] and take a reciprocal to get the\n            scale. If False, take a uniform sample from [min_scale, max_scale].\n    Returns:\n        (tensor): the scaled images with dimension of\n            `num frames` x `channel` x `new height` x `new width`.\n        (ndarray or None): the scaled boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "if", "inverse_uniform_sampling", ":", "\n", "        ", "size", "=", "int", "(", "\n", "round", "(", "1.0", "/", "np", ".", "random", ".", "uniform", "(", "1.0", "/", "max_size", ",", "1.0", "/", "min_size", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "size", "=", "int", "(", "round", "(", "np", ".", "random", ".", "uniform", "(", "min_size", ",", "max_size", ")", ")", ")", "\n", "\n", "", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "if", "(", "width", "<=", "height", "and", "width", "==", "size", ")", "or", "(", "\n", "height", "<=", "width", "and", "height", "==", "size", "\n", ")", ":", "\n", "        ", "return", "images", ",", "boxes", "\n", "", "new_width", "=", "size", "\n", "new_height", "=", "size", "\n", "if", "width", "<", "height", ":", "\n", "        ", "new_height", "=", "int", "(", "math", ".", "floor", "(", "(", "float", "(", "height", ")", "/", "width", ")", "*", "size", ")", ")", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "=", "boxes", "*", "float", "(", "new_height", ")", "/", "height", "\n", "", "", "else", ":", "\n", "        ", "new_width", "=", "int", "(", "math", ".", "floor", "(", "(", "float", "(", "width", ")", "/", "height", ")", "*", "size", ")", ")", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "=", "boxes", "*", "float", "(", "new_width", ")", "/", "width", "\n", "\n", "", "", "return", "(", "\n", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "images", ",", "\n", "size", "=", "(", "new_height", ",", "new_width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", ",", "\n", "boxes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.crop_boxes": [[101, 118], ["boxes.copy"], "function", ["None"], ["", "def", "crop_boxes", "(", "boxes", ",", "x_offset", ",", "y_offset", ")", ":", "\n", "    ", "\"\"\"\n    Peform crop on the bounding boxes given the offsets.\n    Args:\n        boxes (ndarray or None): bounding boxes to peform crop. The dimension\n            is `num boxes` x 4.\n        x_offset (int): cropping offset in the x axis.\n        y_offset (int): cropping offset in the y axis.\n    Returns:\n        cropped_boxes (ndarray or None): the cropped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "cropped_boxes", "=", "boxes", ".", "copy", "(", ")", "\n", "cropped_boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "-", "x_offset", "\n", "cropped_boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "-", "y_offset", "\n", "\n", "return", "cropped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_crop": [[120, 154], ["int", "int", "video_transforms.crop_boxes", "numpy.random.randint", "numpy.random.randint"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.crop_boxes"], ["", "def", "random_crop", "(", "images", ",", "size", ",", "boxes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform random spatial crop on the given images and corresponding boxes.\n    Args:\n        images (tensor): images to perform random crop. The dimension is\n            `num frames` x `channel` x `height` x `width`.\n        size (int): the size of height and width to crop on the image.\n        boxes (ndarray or None): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n    Returns:\n        cropped (tensor): cropped images with dimension of\n            `num frames` x `channel` x `size` x `size`.\n        cropped_boxes (ndarray or None): the cropped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "if", "images", ".", "shape", "[", "2", "]", "==", "size", "and", "images", ".", "shape", "[", "3", "]", "==", "size", ":", "\n", "        ", "return", "images", "\n", "", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "y_offset", "=", "0", "\n", "if", "height", ">", "size", ":", "\n", "        ", "y_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "height", "-", "size", ")", ")", "\n", "", "x_offset", "=", "0", "\n", "if", "width", ">", "size", ":", "\n", "        ", "x_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "width", "-", "size", ")", ")", "\n", "", "cropped", "=", "images", "[", "\n", ":", ",", ":", ",", "y_offset", ":", "y_offset", "+", "size", ",", "x_offset", ":", "x_offset", "+", "size", "\n", "]", "\n", "\n", "cropped_boxes", "=", "(", "\n", "crop_boxes", "(", "boxes", ",", "x_offset", ",", "y_offset", ")", "if", "boxes", "is", "not", "None", "else", "None", "\n", ")", "\n", "\n", "return", "cropped", ",", "cropped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.horizontal_flip": [[156, 189], ["boxes.copy", "numpy.random.uniform", "images.flip.flip", "len", "len", "NotImplementedError"], "function", ["None"], ["", "def", "horizontal_flip", "(", "prob", ",", "images", ",", "boxes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform horizontal flip on the given images and corresponding boxes.\n    Args:\n        prob (float): probility to flip the images.\n        images (tensor): images to perform horizontal flip, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n        boxes (ndarray or None): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n    Returns:\n        images (tensor): images with dimension of\n            `num frames` x `channel` x `height` x `width`.\n        flipped_boxes (ndarray or None): the flipped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "if", "boxes", "is", "None", ":", "\n", "        ", "flipped_boxes", "=", "None", "\n", "", "else", ":", "\n", "        ", "flipped_boxes", "=", "boxes", ".", "copy", "(", ")", "\n", "\n", "", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "prob", ":", "\n", "        ", "images", "=", "images", ".", "flip", "(", "(", "-", "1", ")", ")", "\n", "\n", "if", "len", "(", "images", ".", "shape", ")", "==", "3", ":", "\n", "            ", "width", "=", "images", ".", "shape", "[", "2", "]", "\n", "", "elif", "len", "(", "images", ".", "shape", ")", "==", "4", ":", "\n", "            ", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Dimension does not supported\"", ")", "\n", "", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "flipped_boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "width", "-", "boxes", "[", ":", ",", "[", "2", ",", "0", "]", "]", "-", "1", "\n", "\n", "", "", "return", "images", ",", "flipped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.uniform_crop": [[191, 252], ["len", "int", "int", "torch.nn.functional.interpolate.unsqueeze", "torch.nn.functional.interpolate", "math.ceil", "math.ceil", "video_transforms.crop_boxes", "cropped.squeeze.squeeze", "int", "int"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.crop_boxes"], ["", "def", "uniform_crop", "(", "images", ",", "size", ",", "spatial_idx", ",", "boxes", "=", "None", ",", "scale_size", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Perform uniform spatial sampling on the images and corresponding boxes.\n    Args:\n        images (tensor): images to perform uniform crop. The dimension is\n            `num frames` x `channel` x `height` x `width`.\n        size (int): size of height and weight to crop the images.\n        spatial_idx (int): 0, 1, or 2 for left, center, and right crop if width\n            is larger than height. Or 0, 1, or 2 for top, center, and bottom\n            crop if height is larger than width.\n        boxes (ndarray or None): optional. Corresponding boxes to images.\n            Dimension is `num boxes` x 4.\n        scale_size (int): optinal. If not None, resize the images to scale_size before\n            performing any crop.\n    Returns:\n        cropped (tensor): images with dimension of\n            `num frames` x `channel` x `size` x `size`.\n        cropped_boxes (ndarray or None): the cropped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "0", ",", "1", ",", "2", "]", "\n", "ndim", "=", "len", "(", "images", ".", "shape", ")", "\n", "if", "ndim", "==", "3", ":", "\n", "        ", "images", "=", "images", ".", "unsqueeze", "(", "0", ")", "\n", "", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "\n", "if", "scale_size", "is", "not", "None", ":", "\n", "        ", "if", "width", "<=", "height", ":", "\n", "            ", "width", ",", "height", "=", "scale_size", ",", "int", "(", "height", "/", "width", "*", "scale_size", ")", "\n", "", "else", ":", "\n", "            ", "width", ",", "height", "=", "int", "(", "width", "/", "height", "*", "scale_size", ")", ",", "scale_size", "\n", "", "images", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "images", ",", "\n", "size", "=", "(", "height", ",", "width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n", "\n", "", "y_offset", "=", "int", "(", "math", ".", "ceil", "(", "(", "height", "-", "size", ")", "/", "2", ")", ")", "\n", "x_offset", "=", "int", "(", "math", ".", "ceil", "(", "(", "width", "-", "size", ")", "/", "2", ")", ")", "\n", "\n", "if", "height", ">", "width", ":", "\n", "        ", "if", "spatial_idx", "==", "0", ":", "\n", "            ", "y_offset", "=", "0", "\n", "", "elif", "spatial_idx", "==", "2", ":", "\n", "            ", "y_offset", "=", "height", "-", "size", "\n", "", "", "else", ":", "\n", "        ", "if", "spatial_idx", "==", "0", ":", "\n", "            ", "x_offset", "=", "0", "\n", "", "elif", "spatial_idx", "==", "2", ":", "\n", "            ", "x_offset", "=", "width", "-", "size", "\n", "", "", "cropped", "=", "images", "[", "\n", ":", ",", ":", ",", "y_offset", ":", "y_offset", "+", "size", ",", "x_offset", ":", "x_offset", "+", "size", "\n", "]", "\n", "cropped_boxes", "=", "(", "\n", "crop_boxes", "(", "boxes", ",", "x_offset", ",", "y_offset", ")", "if", "boxes", "is", "not", "None", "else", "None", "\n", ")", "\n", "if", "ndim", "==", "3", ":", "\n", "        ", "cropped", "=", "cropped", ".", "squeeze", "(", "0", ")", "\n", "", "return", "cropped", ",", "cropped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.clip_boxes_to_image": [[254, 274], ["boxes.copy", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum"], "function", ["None"], ["", "def", "clip_boxes_to_image", "(", "boxes", ",", "height", ",", "width", ")", ":", "\n", "    ", "\"\"\"\n    Clip an array of boxes to an image with the given height and width.\n    Args:\n        boxes (ndarray): bounding boxes to perform clipping.\n            Dimension is `num boxes` x 4.\n        height (int): given image height.\n        width (int): given image width.\n    Returns:\n        clipped_boxes (ndarray): the clipped boxes with dimension of\n            `num boxes` x 4.\n    \"\"\"", "\n", "clipped_boxes", "=", "boxes", ".", "copy", "(", ")", "\n", "clipped_boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "np", ".", "minimum", "(", "\n", "width", "-", "1.0", ",", "np", ".", "maximum", "(", "0.0", ",", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", ")", "\n", ")", "\n", "clipped_boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "np", ".", "minimum", "(", "\n", "height", "-", "1.0", ",", "np", ".", "maximum", "(", "0.0", ",", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", ")", "\n", ")", "\n", "return", "clipped_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.blend": [[276, 290], ["None"], "function", ["None"], ["", "def", "blend", "(", "images1", ",", "images2", ",", "alpha", ")", ":", "\n", "    ", "\"\"\"\n    Blend two images with a given weight alpha.\n    Args:\n        images1 (tensor): the first images to be blended, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n        images2 (tensor): the second images to be blended, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n        alpha (float): the blending weight.\n    Returns:\n        (tensor): blended images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "return", "images1", "*", "alpha", "+", "images2", "*", "(", "1", "-", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.grayscale": [[292, 312], ["torch.tensor"], "function", ["None"], ["", "def", "grayscale", "(", "images", ")", ":", "\n", "    ", "\"\"\"\n    Get the grayscale for the input images. The channels of images should be\n    in order BGR.\n    Args:\n        images (tensor): the input images for getting grayscale. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        img_gray (tensor): blended images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "# R -> 0.299, G -> 0.587, B -> 0.114.", "\n", "img_gray", "=", "torch", ".", "tensor", "(", "images", ")", "\n", "gray_channel", "=", "(", "\n", "0.299", "*", "images", "[", ":", ",", "2", "]", "+", "0.587", "*", "images", "[", ":", ",", "1", "]", "+", "0.114", "*", "images", "[", ":", ",", "0", "]", "\n", ")", "\n", "img_gray", "[", ":", ",", "0", "]", "=", "gray_channel", "\n", "img_gray", "[", ":", ",", "1", "]", "=", "gray_channel", "\n", "img_gray", "[", ":", ",", "2", "]", "=", "gray_channel", "\n", "return", "img_gray", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.color_jitter": [[314, 347], ["jitter.append", "jitter.append", "jitter.append", "len", "numpy.random.permutation", "range", "numpy.arange", "len", "len", "video_transforms.brightness_jitter", "video_transforms.contrast_jitter", "video_transforms.saturation_jitter"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.brightness_jitter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.contrast_jitter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.saturation_jitter"], ["", "def", "color_jitter", "(", "images", ",", "img_brightness", "=", "0", ",", "img_contrast", "=", "0", ",", "img_saturation", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom a color jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        img_brightness (float): jitter ratio for brightness.\n        img_contrast (float): jitter ratio for contrast.\n        img_saturation (float): jitter ratio for saturation.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "\n", "jitter", "=", "[", "]", "\n", "if", "img_brightness", "!=", "0", ":", "\n", "        ", "jitter", ".", "append", "(", "\"brightness\"", ")", "\n", "", "if", "img_contrast", "!=", "0", ":", "\n", "        ", "jitter", ".", "append", "(", "\"contrast\"", ")", "\n", "", "if", "img_saturation", "!=", "0", ":", "\n", "        ", "jitter", ".", "append", "(", "\"saturation\"", ")", "\n", "\n", "", "if", "len", "(", "jitter", ")", ">", "0", ":", "\n", "        ", "order", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "jitter", ")", ")", ")", "\n", "for", "idx", "in", "range", "(", "0", ",", "len", "(", "jitter", ")", ")", ":", "\n", "            ", "if", "jitter", "[", "order", "[", "idx", "]", "]", "==", "\"brightness\"", ":", "\n", "                ", "images", "=", "brightness_jitter", "(", "img_brightness", ",", "images", ")", "\n", "", "elif", "jitter", "[", "order", "[", "idx", "]", "]", "==", "\"contrast\"", ":", "\n", "                ", "images", "=", "contrast_jitter", "(", "img_contrast", ",", "images", ")", "\n", "", "elif", "jitter", "[", "order", "[", "idx", "]", "]", "==", "\"saturation\"", ":", "\n", "                ", "images", "=", "saturation_jitter", "(", "img_saturation", ",", "images", ")", "\n", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.brightness_jitter": [[349, 366], ["torch.zeros", "video_transforms.blend", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.blend"], ["", "def", "brightness_jitter", "(", "var", ",", "images", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom brightness jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        var (float): jitter ratio for brightness.\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "alpha", "=", "1.0", "+", "np", ".", "random", ".", "uniform", "(", "-", "var", ",", "var", ")", "\n", "\n", "img_bright", "=", "torch", ".", "zeros", "(", "images", ".", "shape", ")", "\n", "images", "=", "blend", "(", "images", ",", "img_bright", ",", "alpha", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.contrast_jitter": [[368, 386], ["video_transforms.grayscale", "torch.mean", "video_transforms.blend", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.grayscale", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.blend"], ["", "def", "contrast_jitter", "(", "var", ",", "images", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom contrast jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        var (float): jitter ratio for contrast.\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "alpha", "=", "1.0", "+", "np", ".", "random", ".", "uniform", "(", "-", "var", ",", "var", ")", "\n", "\n", "img_gray", "=", "grayscale", "(", "images", ")", "\n", "img_gray", "[", ":", "]", "=", "torch", ".", "mean", "(", "img_gray", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "images", "=", "blend", "(", "images", ",", "img_gray", ",", "alpha", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.saturation_jitter": [[388, 405], ["video_transforms.grayscale", "video_transforms.blend", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.grayscale", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.blend"], ["", "def", "saturation_jitter", "(", "var", ",", "images", ")", ":", "\n", "    ", "\"\"\"\n    Perfrom saturation jittering on the input images. The channels of images\n    should be in order BGR.\n    Args:\n        var (float): jitter ratio for saturation.\n        images (tensor): images to perform color jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "alpha", "=", "1.0", "+", "np", ".", "random", ".", "uniform", "(", "-", "var", ",", "var", ")", "\n", "img_gray", "=", "grayscale", "(", "images", ")", "\n", "images", "=", "blend", "(", "images", ",", "img_gray", ",", "alpha", ")", "\n", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.lighting_jitter": [[407, 453], ["numpy.random.normal", "numpy.array", "numpy.reshape", "numpy.sum", "torch.zeros_like", "range", "len", "numpy.repeat", "len", "NotImplementedError", "len", "numpy.repeat", "len", "NotImplementedError", "len", "len"], "function", ["None"], ["", "def", "lighting_jitter", "(", "images", ",", "alphastd", ",", "eigval", ",", "eigvec", ")", ":", "\n", "    ", "\"\"\"\n    Perform AlexNet-style PCA jitter on the given images.\n    Args:\n        images (tensor): images to perform lighting jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        alphastd (float): jitter ratio for PCA jitter.\n        eigval (list): eigenvalues for PCA jitter.\n        eigvec (list[list]): eigenvectors for PCA jitter.\n    Returns:\n        out_images (tensor): the jittered images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "if", "alphastd", "==", "0", ":", "\n", "        ", "return", "images", "\n", "# generate alpha1, alpha2, alpha3.", "\n", "", "alpha", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "alphastd", ",", "size", "=", "(", "1", ",", "3", ")", ")", "\n", "eig_vec", "=", "np", ".", "array", "(", "eigvec", ")", "\n", "eig_val", "=", "np", ".", "reshape", "(", "eigval", ",", "(", "1", ",", "3", ")", ")", "\n", "rgb", "=", "np", ".", "sum", "(", "\n", "eig_vec", "*", "np", ".", "repeat", "(", "alpha", ",", "3", ",", "axis", "=", "0", ")", "*", "np", ".", "repeat", "(", "eig_val", ",", "3", ",", "axis", "=", "0", ")", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "out_images", "=", "torch", ".", "zeros_like", "(", "images", ")", "\n", "if", "len", "(", "images", ".", "shape", ")", "==", "3", ":", "\n", "# C H W", "\n", "        ", "channel_dim", "=", "0", "\n", "", "elif", "len", "(", "images", ".", "shape", ")", "==", "4", ":", "\n", "# T C H W", "\n", "        ", "channel_dim", "=", "1", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Unsupported dimension {len(images.shape)}\"", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "images", ".", "shape", "[", "channel_dim", "]", ")", ":", "\n", "# C H W", "\n", "        ", "if", "len", "(", "images", ".", "shape", ")", "==", "3", ":", "\n", "            ", "out_images", "[", "idx", "]", "=", "images", "[", "idx", "]", "+", "rgb", "[", "2", "-", "idx", "]", "\n", "# T C H W", "\n", "", "elif", "len", "(", "images", ".", "shape", ")", "==", "4", ":", "\n", "            ", "out_images", "[", ":", ",", "idx", "]", "=", "images", "[", ":", ",", "idx", "]", "+", "rgb", "[", "2", "-", "idx", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"Unsupported dimension {len(images.shape)}\"", "\n", ")", "\n", "\n", "", "", "return", "out_images", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.color_normalization": [[455, 497], ["torch.zeros_like", "range", "len", "len", "len", "len", "len", "NotImplementedError", "len", "len", "len", "len", "NotImplementedError", "len", "len"], "function", ["None"], ["", "def", "color_normalization", "(", "images", ",", "mean", ",", "stddev", ")", ":", "\n", "    ", "\"\"\"\n    Perform color nomration on the given images.\n    Args:\n        images (tensor): images to perform color normalization. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        mean (list): mean values for normalization.\n        stddev (list): standard deviations for normalization.\n\n    Returns:\n        out_images (tensor): the noramlized images, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "if", "len", "(", "images", ".", "shape", ")", "==", "3", ":", "\n", "        ", "assert", "(", "\n", "len", "(", "mean", ")", "==", "images", ".", "shape", "[", "0", "]", "\n", ")", ",", "\"channel mean not computed properly\"", "\n", "assert", "(", "\n", "len", "(", "stddev", ")", "==", "images", ".", "shape", "[", "0", "]", "\n", ")", ",", "\"channel stddev not computed properly\"", "\n", "", "elif", "len", "(", "images", ".", "shape", ")", "==", "4", ":", "\n", "        ", "assert", "(", "\n", "len", "(", "mean", ")", "==", "images", ".", "shape", "[", "1", "]", "\n", ")", ",", "\"channel mean not computed properly\"", "\n", "assert", "(", "\n", "len", "(", "stddev", ")", "==", "images", ".", "shape", "[", "1", "]", "\n", ")", ",", "\"channel stddev not computed properly\"", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Unsupported dimension {len(images.shape)}\"", ")", "\n", "\n", "", "out_images", "=", "torch", ".", "zeros_like", "(", "images", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "mean", ")", ")", ":", "\n", "# C H W", "\n", "        ", "if", "len", "(", "images", ".", "shape", ")", "==", "3", ":", "\n", "            ", "out_images", "[", "idx", "]", "=", "(", "images", "[", "idx", "]", "-", "mean", "[", "idx", "]", ")", "/", "stddev", "[", "idx", "]", "\n", "", "elif", "len", "(", "images", ".", "shape", ")", "==", "4", ":", "\n", "            ", "out_images", "[", ":", ",", "idx", "]", "=", "(", "images", "[", ":", ",", "idx", "]", "-", "mean", "[", "idx", "]", ")", "/", "stddev", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"Unsupported dimension {len(images.shape)}\"", "\n", ")", "\n", "", "", "return", "out_images", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._get_param_spatial_crop": [[499, 539], ["range", "int", "int", "float", "float", "min", "int", "random.uniform", "math.exp", "random.uniform", "round", "round", "random.randint", "random.randint", "round", "max", "int", "math.log", "math.log", "random.uniform", "math.sqrt", "math.sqrt", "numpy.random.uniform", "round", "min", "max"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "def", "_get_param_spatial_crop", "(", "\n", "scale", ",", "ratio", ",", "height", ",", "width", ",", "num_repeat", "=", "10", ",", "log_scale", "=", "True", ",", "switch_hw", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Given scale, ratio, height and width, return sampled coordinates of the videos.\n    \"\"\"", "\n", "for", "_", "in", "range", "(", "num_repeat", ")", ":", "\n", "        ", "area", "=", "height", "*", "width", "\n", "target_area", "=", "random", ".", "uniform", "(", "*", "scale", ")", "*", "area", "\n", "if", "log_scale", ":", "\n", "            ", "log_ratio", "=", "(", "math", ".", "log", "(", "ratio", "[", "0", "]", ")", ",", "math", ".", "log", "(", "ratio", "[", "1", "]", ")", ")", "\n", "aspect_ratio", "=", "math", ".", "exp", "(", "random", ".", "uniform", "(", "*", "log_ratio", ")", ")", "\n", "", "else", ":", "\n", "            ", "aspect_ratio", "=", "random", ".", "uniform", "(", "*", "ratio", ")", "\n", "\n", "", "w", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "*", "aspect_ratio", ")", ")", ")", "\n", "h", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "/", "aspect_ratio", ")", ")", ")", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "0.5", "and", "switch_hw", ":", "\n", "            ", "w", ",", "h", "=", "h", ",", "w", "\n", "\n", "", "if", "0", "<", "w", "<=", "width", "and", "0", "<", "h", "<=", "height", ":", "\n", "            ", "i", "=", "random", ".", "randint", "(", "0", ",", "height", "-", "h", ")", "\n", "j", "=", "random", ".", "randint", "(", "0", ",", "width", "-", "w", ")", "\n", "return", "i", ",", "j", ",", "h", ",", "w", "\n", "\n", "# Fallback to central crop", "\n", "", "", "in_ratio", "=", "float", "(", "width", ")", "/", "float", "(", "height", ")", "\n", "if", "in_ratio", "<", "min", "(", "ratio", ")", ":", "\n", "        ", "w", "=", "width", "\n", "h", "=", "int", "(", "round", "(", "w", "/", "min", "(", "ratio", ")", ")", ")", "\n", "", "elif", "in_ratio", ">", "max", "(", "ratio", ")", ":", "\n", "        ", "h", "=", "height", "\n", "w", "=", "int", "(", "round", "(", "h", "*", "max", "(", "ratio", ")", ")", ")", "\n", "", "else", ":", "# whole image", "\n", "        ", "w", "=", "width", "\n", "h", "=", "height", "\n", "", "i", "=", "(", "height", "-", "h", ")", "//", "2", "\n", "j", "=", "(", "width", "-", "w", ")", "//", "2", "\n", "return", "i", ",", "j", ",", "h", ",", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_resized_crop": [[541, 573], ["video_transforms._get_param_spatial_crop", "torch.nn.functional.interpolate"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._get_param_spatial_crop"], ["", "def", "random_resized_crop", "(", "\n", "images", ",", "\n", "target_height", ",", "\n", "target_width", ",", "\n", "scale", "=", "(", "0.8", ",", "1.0", ")", ",", "\n", "ratio", "=", "(", "3.0", "/", "4.0", ",", "4.0", "/", "3.0", ")", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Crop the given images to random size and aspect ratio. A crop of random\n    size (default: of 0.08 to 1.0) of the original size and a random aspect\n    ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. This\n    crop is finally resized to given size. This is popularly used to train the\n    Inception networks.\n\n    Args:\n        images: Images to perform resizing and cropping.\n        target_height: Desired height after cropping.\n        target_width: Desired width after cropping.\n        scale: Scale range of Inception-style area based random resizing.\n        ratio: Aspect ratio range of Inception-style area based random resizing.\n    \"\"\"", "\n", "\n", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "\n", "i", ",", "j", ",", "h", ",", "w", "=", "_get_param_spatial_crop", "(", "scale", ",", "ratio", ",", "height", ",", "width", ")", "\n", "cropped", "=", "images", "[", ":", ",", ":", ",", "i", ":", "i", "+", "h", ",", "j", ":", "j", "+", "w", "]", "\n", "return", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "cropped", ",", "\n", "size", "=", "(", "target_height", ",", "target_width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_resized_crop_with_shift": [[576, 619], ["video_transforms._get_param_spatial_crop", "video_transforms._get_param_spatial_crop", "torch.zeros", "range", "int", "int", "int", "int", "torch.nn.functional.interpolate", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace().tolist", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._get_param_spatial_crop", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._get_param_spatial_crop"], ["", "def", "random_resized_crop_with_shift", "(", "\n", "images", ",", "\n", "target_height", ",", "\n", "target_width", ",", "\n", "scale", "=", "(", "0.8", ",", "1.0", ")", ",", "\n", "ratio", "=", "(", "3.0", "/", "4.0", ",", "4.0", "/", "3.0", ")", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    This is similar to random_resized_crop. However, it samples two different\n    boxes (for cropping) for the first and last frame. It then linearly\n    interpolates the two boxes for other frames.\n\n    Args:\n        images: Images to perform resizing and cropping.\n        target_height: Desired height after cropping.\n        target_width: Desired width after cropping.\n        scale: Scale range of Inception-style area based random resizing.\n        ratio: Aspect ratio range of Inception-style area based random resizing.\n    \"\"\"", "\n", "t", "=", "images", ".", "shape", "[", "1", "]", "\n", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "\n", "i", ",", "j", ",", "h", ",", "w", "=", "_get_param_spatial_crop", "(", "scale", ",", "ratio", ",", "height", ",", "width", ")", "\n", "i_", ",", "j_", ",", "h_", ",", "w_", "=", "_get_param_spatial_crop", "(", "scale", ",", "ratio", ",", "height", ",", "width", ")", "\n", "i_s", "=", "[", "int", "(", "i", ")", "for", "i", "in", "torch", ".", "linspace", "(", "i", ",", "i_", ",", "steps", "=", "t", ")", ".", "tolist", "(", ")", "]", "\n", "j_s", "=", "[", "int", "(", "i", ")", "for", "i", "in", "torch", ".", "linspace", "(", "j", ",", "j_", ",", "steps", "=", "t", ")", ".", "tolist", "(", ")", "]", "\n", "h_s", "=", "[", "int", "(", "i", ")", "for", "i", "in", "torch", ".", "linspace", "(", "h", ",", "h_", ",", "steps", "=", "t", ")", ".", "tolist", "(", ")", "]", "\n", "w_s", "=", "[", "int", "(", "i", ")", "for", "i", "in", "torch", ".", "linspace", "(", "w", ",", "w_", ",", "steps", "=", "t", ")", ".", "tolist", "(", ")", "]", "\n", "out", "=", "torch", ".", "zeros", "(", "(", "3", ",", "t", ",", "target_height", ",", "target_width", ")", ")", "\n", "for", "ind", "in", "range", "(", "t", ")", ":", "\n", "        ", "out", "[", ":", ",", "ind", ":", "ind", "+", "1", ",", ":", ",", ":", "]", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "images", "[", "\n", ":", ",", "\n", "ind", ":", "ind", "+", "1", ",", "\n", "i_s", "[", "ind", "]", ":", "i_s", "[", "ind", "]", "+", "h_s", "[", "ind", "]", ",", "\n", "j_s", "[", "ind", "]", ":", "j_s", "[", "ind", "]", "+", "w_s", "[", "ind", "]", ",", "\n", "]", ",", "\n", "size", "=", "(", "target_height", ",", "target_width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.create_random_augment": [[621, 655], ["isinstance", "isinstance", "isinstance", "auto_augment.startswith", "min", "int", "video_transforms._pil_interp", "torchvision.transforms.Compose", "rand_augment.rand_augment_transform"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._pil_interp", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rand_augment_transform"], ["", "def", "create_random_augment", "(", "\n", "input_size", ",", "\n", "auto_augment", "=", "None", ",", "\n", "interpolation", "=", "\"bilinear\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Get video randaug transform.\n\n    Args:\n        input_size: The size of the input video in tuple.\n        auto_augment: Parameters for randaug. An example:\n            \"rand-m7-n4-mstd0.5-inc1\" (m is the magnitude and n is the number\n            of operations to apply).\n        interpolation: Interpolation method.\n    \"\"\"", "\n", "if", "isinstance", "(", "input_size", ",", "tuple", ")", ":", "\n", "        ", "img_size", "=", "input_size", "[", "-", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "img_size", "=", "input_size", "\n", "\n", "", "if", "auto_augment", ":", "\n", "        ", "assert", "isinstance", "(", "auto_augment", ",", "str", ")", "\n", "if", "isinstance", "(", "img_size", ",", "tuple", ")", ":", "\n", "            ", "img_size_min", "=", "min", "(", "img_size", ")", "\n", "", "else", ":", "\n", "            ", "img_size_min", "=", "img_size", "\n", "", "aa_params", "=", "{", "\"translate_const\"", ":", "int", "(", "img_size_min", "*", "0.45", ")", "}", "\n", "if", "interpolation", "and", "interpolation", "!=", "\"random\"", ":", "\n", "            ", "aa_params", "[", "\"interpolation\"", "]", "=", "_pil_interp", "(", "interpolation", ")", "\n", "", "if", "auto_augment", ".", "startswith", "(", "\"rand\"", ")", ":", "\n", "            ", "return", "transforms", ".", "Compose", "(", "\n", "[", "rand_augment_transform", "(", "auto_augment", ",", "aa_params", ")", "]", "\n", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_sized_crop_img": [[657, 687], ["video_transforms._get_param_spatial_crop", "torch.nn.functional.interpolate().squeeze", "len", "torch.nn.functional.interpolate", "cropped.unsqueeze"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._get_param_spatial_crop"], ["", "def", "random_sized_crop_img", "(", "\n", "im", ",", "\n", "size", ",", "\n", "jitter_scale", "=", "(", "0.08", ",", "1.0", ")", ",", "\n", "jitter_aspect", "=", "(", "3.0", "/", "4.0", ",", "4.0", "/", "3.0", ")", ",", "\n", "max_iter", "=", "10", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Performs Inception-style cropping (used for training).\n    \"\"\"", "\n", "assert", "(", "\n", "len", "(", "im", ".", "shape", ")", "==", "3", "\n", ")", ",", "\"Currently only support image for random_sized_crop\"", "\n", "h", ",", "w", "=", "im", ".", "shape", "[", "1", ":", "3", "]", "\n", "i", ",", "j", ",", "h", ",", "w", "=", "_get_param_spatial_crop", "(", "\n", "scale", "=", "jitter_scale", ",", "\n", "ratio", "=", "jitter_aspect", ",", "\n", "height", "=", "h", ",", "\n", "width", "=", "w", ",", "\n", "num_repeat", "=", "max_iter", ",", "\n", "log_scale", "=", "False", ",", "\n", "switch_hw", "=", "True", ",", "\n", ")", "\n", "cropped", "=", "im", "[", ":", ",", "i", ":", "i", "+", "h", ",", "j", ":", "j", "+", "w", "]", "\n", "return", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "cropped", ".", "unsqueeze", "(", "0", ")", ",", "\n", "size", "=", "(", "size", ",", "size", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.transforms_imagenet_train": [[799, 898], ["isinstance", "tuple", "tuple", "video_transforms.RandomResizedCropAndInterpolation", "isinstance", "isinstance", "dict", "auto_augment.startswith", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "final_tfl.append", "torchvision.transforms.Compose", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.RandomVerticalFlip", "min", "video_transforms._pil_interp", "auto_augment.startswith", "isinstance", "random_erasing.RandomErasing", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "int", "tuple", "rand_augment.rand_augment_transform", "NotImplementedError", "NotImplementedError", "torchvision.transforms.ColorJitter", "torch.tensor", "torch.tensor", "len", "min", "float", "round"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms._pil_interp", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.rand_augment.rand_augment_transform"], ["", "", "def", "transforms_imagenet_train", "(", "\n", "img_size", "=", "224", ",", "\n", "scale", "=", "None", ",", "\n", "ratio", "=", "None", ",", "\n", "hflip", "=", "0.5", ",", "\n", "vflip", "=", "0.0", ",", "\n", "color_jitter", "=", "0.4", ",", "\n", "auto_augment", "=", "None", ",", "\n", "interpolation", "=", "\"random\"", ",", "\n", "use_prefetcher", "=", "False", ",", "\n", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "\n", "std", "=", "(", "0.229", ",", "0.224", ",", "0.225", ")", ",", "\n", "re_prob", "=", "0.0", ",", "\n", "re_mode", "=", "\"const\"", ",", "\n", "re_count", "=", "1", ",", "\n", "re_num_splits", "=", "0", ",", "\n", "separate", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    If separate==True, the transforms are returned as a tuple of 3 separate transforms\n    for use in a mixing dataset that passes\n     * all data through the first (primary) transform, called the 'clean' data\n     * a portion of the data through the secondary transform\n     * normalizes and converts the branches above with the third, final transform\n    \"\"\"", "\n", "if", "isinstance", "(", "img_size", ",", "tuple", ")", ":", "\n", "        ", "img_size", "=", "img_size", "[", "-", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "img_size", "=", "img_size", "\n", "\n", "", "scale", "=", "tuple", "(", "scale", "or", "(", "0.08", ",", "1.0", ")", ")", "# default imagenet scale range", "\n", "ratio", "=", "tuple", "(", "\n", "ratio", "or", "(", "3.0", "/", "4.0", ",", "4.0", "/", "3.0", ")", "\n", ")", "# default imagenet ratio range", "\n", "primary_tfl", "=", "[", "\n", "RandomResizedCropAndInterpolation", "(", "\n", "img_size", ",", "scale", "=", "scale", ",", "ratio", "=", "ratio", ",", "interpolation", "=", "interpolation", "\n", ")", "\n", "]", "\n", "if", "hflip", ">", "0.0", ":", "\n", "        ", "primary_tfl", "+=", "[", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "hflip", ")", "]", "\n", "", "if", "vflip", ">", "0.0", ":", "\n", "        ", "primary_tfl", "+=", "[", "transforms", ".", "RandomVerticalFlip", "(", "p", "=", "vflip", ")", "]", "\n", "\n", "", "secondary_tfl", "=", "[", "]", "\n", "if", "auto_augment", ":", "\n", "        ", "assert", "isinstance", "(", "auto_augment", ",", "str", ")", "\n", "if", "isinstance", "(", "img_size", ",", "tuple", ")", ":", "\n", "            ", "img_size_min", "=", "min", "(", "img_size", ")", "\n", "", "else", ":", "\n", "            ", "img_size_min", "=", "img_size", "\n", "", "aa_params", "=", "dict", "(", "\n", "translate_const", "=", "int", "(", "img_size_min", "*", "0.45", ")", ",", "\n", "img_mean", "=", "tuple", "(", "[", "min", "(", "255", ",", "round", "(", "255", "*", "x", ")", ")", "for", "x", "in", "mean", "]", ")", ",", "\n", ")", "\n", "if", "interpolation", "and", "interpolation", "!=", "\"random\"", ":", "\n", "            ", "aa_params", "[", "\"interpolation\"", "]", "=", "_pil_interp", "(", "interpolation", ")", "\n", "", "if", "auto_augment", ".", "startswith", "(", "\"rand\"", ")", ":", "\n", "            ", "secondary_tfl", "+=", "[", "rand_augment_transform", "(", "auto_augment", ",", "aa_params", ")", "]", "\n", "", "elif", "auto_augment", ".", "startswith", "(", "\"augmix\"", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Augmix not implemented\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Auto aug not implemented\"", ")", "\n", "", "", "elif", "color_jitter", "is", "not", "None", ":", "\n", "# color jitter is enabled when not using AA", "\n", "        ", "if", "isinstance", "(", "color_jitter", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "# color jitter should be a 3-tuple/list if spec brightness/contrast/saturation", "\n", "# or 4 if also augmenting hue", "\n", "            ", "assert", "len", "(", "color_jitter", ")", "in", "(", "3", ",", "4", ")", "\n", "", "else", ":", "\n", "# if it's a scalar, duplicate for brightness, contrast, and saturation, no hue", "\n", "            ", "color_jitter", "=", "(", "float", "(", "color_jitter", ")", ",", ")", "*", "3", "\n", "", "secondary_tfl", "+=", "[", "transforms", ".", "ColorJitter", "(", "*", "color_jitter", ")", "]", "\n", "\n", "", "final_tfl", "=", "[", "]", "\n", "final_tfl", "+=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "torch", ".", "tensor", "(", "mean", ")", ",", "std", "=", "torch", ".", "tensor", "(", "std", ")", ")", ",", "\n", "]", "\n", "if", "re_prob", ">", "0.0", ":", "\n", "        ", "final_tfl", ".", "append", "(", "\n", "RandomErasing", "(", "\n", "re_prob", ",", "\n", "mode", "=", "re_mode", ",", "\n", "max_count", "=", "re_count", ",", "\n", "num_splits", "=", "re_num_splits", ",", "\n", "device", "=", "\"cpu\"", ",", "\n", "cube", "=", "False", ",", "\n", ")", "\n", ")", "\n", "\n", "", "if", "separate", ":", "\n", "        ", "return", "(", "\n", "transforms", ".", "Compose", "(", "primary_tfl", ")", ",", "\n", "transforms", ".", "Compose", "(", "secondary_tfl", ")", ",", "\n", "transforms", ".", "Compose", "(", "final_tfl", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "transforms", ".", "Compose", "(", "primary_tfl", "+", "secondary_tfl", "+", "final_tfl", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.DataAugmentationForVideoMAE.__init__": [[21, 35], ["torchvision.transforms.GroupNormalize", "torchvision.transforms.GroupCenterCrop", "torchvision.transforms.Compose", "masking_generator.TubeMaskingGenerator", "torchvision.transforms.Stack", "torchvision.transforms.ToTorchFormatTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "input_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "# IMAGENET_DEFAULT_MEAN", "\n", "self", ".", "input_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "# IMAGENET_DEFAULT_STD", "\n", "normalize", "=", "GroupNormalize", "(", "self", ".", "input_mean", ",", "self", ".", "input_std", ")", "\n", "self", ".", "train_augmentation", "=", "GroupCenterCrop", "(", "args", ".", "input_size", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "self", ".", "train_augmentation", ",", "\n", "Stack", "(", "roll", "=", "False", ")", ",", "\n", "ToTorchFormatTensor", "(", "div", "=", "True", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "if", "args", ".", "mask_type", "==", "'tube'", ":", "\n", "            ", "self", ".", "masked_position_generator", "=", "TubeMaskingGenerator", "(", "\n", "args", ".", "window_size", ",", "args", ".", "mask_ratio", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.DataAugmentationForVideoMAE.__call__": [[37, 40], ["run_videomae_vis.DataAugmentationForVideoMAE.transform", "run_videomae_vis.DataAugmentationForVideoMAE.masked_position_generator"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "process_data", ",", "_", "=", "self", ".", "transform", "(", "images", ")", "\n", "return", "process_data", ",", "self", ".", "masked_position_generator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.DataAugmentationForVideoMAE.__repr__": [[41, 47], ["str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr", "=", "\"(DataAugmentationForVideoMAE,\\n\"", "\n", "repr", "+=", "\"  transform = %s,\\n\"", "%", "str", "(", "self", ".", "transform", ")", "\n", "repr", "+=", "\"  Masked position generator = %s,\\n\"", "%", "str", "(", "self", ".", "masked_position_generator", ")", "\n", "repr", "+=", "\")\"", "\n", "return", "repr", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.get_args": [[48, 73], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'VideoMAE visualization reconstruction script'", ",", "add_help", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'img_path'", ",", "type", "=", "str", ",", "help", "=", "'input video path'", ")", "\n", "parser", ".", "add_argument", "(", "'save_path'", ",", "type", "=", "str", ",", "help", "=", "'save video path'", ")", "\n", "parser", ".", "add_argument", "(", "'model_path'", ",", "type", "=", "str", ",", "help", "=", "'checkpoint path of model'", ")", "\n", "parser", ".", "add_argument", "(", "'--mask_type'", ",", "default", "=", "'random'", ",", "choices", "=", "[", "'random'", ",", "'tube'", "]", ",", "\n", "type", "=", "str", ",", "help", "=", "'masked strategy of video tokens/patches'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_frames'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "parser", ".", "add_argument", "(", "'--sampling_rate'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder_depth'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "'depth of decoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_size'", ",", "default", "=", "224", ",", "type", "=", "int", ",", "\n", "help", "=", "'videos input size for backbone'", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "default", "=", "'cuda:0'", ",", "\n", "help", "=", "'device to use for training / testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--imagenet_default_mean_and_std'", ",", "default", "=", "True", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--mask_ratio'", ",", "default", "=", "0.75", ",", "type", "=", "float", ",", "\n", "help", "=", "'ratio of the visual tokens/patches need be masked'", ")", "\n", "# Model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'pretrain_videomae_base_patch16_224'", ",", "type", "=", "str", ",", "metavar", "=", "'MODEL'", ",", "\n", "help", "=", "'Name of model to vis'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_path'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Drop path rate (default: 0.1)'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.get_model": [[75, 86], ["print", "timm.models.create_model"], "function", ["None"], ["", "def", "get_model", "(", "args", ")", ":", "\n", "    ", "print", "(", "f\"Creating model: {args.model}\"", ")", "\n", "model", "=", "create_model", "(", "\n", "args", ".", "model", ",", "\n", "pretrained", "=", "False", ",", "\n", "drop_path_rate", "=", "args", ".", "drop_path", ",", "\n", "drop_block_rate", "=", "None", ",", "\n", "decoder_depth", "=", "args", ".", "decoder_depth", "\n", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.main": [[88, 182], ["print", "torch.device", "torch.device", "run_videomae_vis.get_model", "print", "get_model.to", "torch.load", "torch.load", "get_model.load_state_dict", "get_model.eval", "len", "tmp.tolist", "decord.VideoReader.get_batch().asnumpy", "print", "run_videomae_vis.DataAugmentationForVideoMAE", "datasets.DataAugmentationForVideoMAE.", "img.to.view().transpose", "torch.from_numpy", "torch.from_numpy", "pathlib.Path().mkdir", "open", "decord.VideoReader", "numpy.arange", "PIL.Image.fromarray().convert", "torch.no_grad", "torch.no_grad", "img.to.unsqueeze", "print", "bool_masked_pos.to().flatten().to.unsqueeze", "img.to.to", "bool_masked_pos.to().flatten().to.to().flatten().to", "get_model.", "enumerate", "einops.rearrange", "einops.rearrange", "torch.ones_like", "torch.ones_like", "einops.rearrange", "einops.rearrange", "einops.rearrange", "einops.rearrange", "enumerate", "enumerate", "str", "decord.VideoReader.get_batch", "enumerate", "img.to.view", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "im.save", "einops.rearrange.mean", "im.save", "im.save", "pathlib.Path", "decord.cpu", "PIL.Image.fromarray", "bool_masked_pos.to().flatten().to.to().flatten", "torchvision.transforms.ToPILImage", "ori_img[].cpu", "enumerate", "einops.rearrange.mean", "einops.rearrange.var().sqrt", "torchvision.transforms.ToPILImage", "rec_img[].cpu().clamp", "enumerate", "torchvision.transforms.ToPILImage", "img_mask[].cpu", "enumerate", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "einops.rearrange.var().sqrt", "img.to.size", "bool_masked_pos.to().flatten().to.to", "einops.rearrange.var", "rec_img[].cpu", "einops.rearrange.var"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_videomae_vis.get_model", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "args", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "model", "=", "get_model", "(", "args", ")", "\n", "patch_size", "=", "model", ".", "encoder", ".", "patch_embed", ".", "patch_size", "\n", "print", "(", "\"Patch size = %s\"", "%", "str", "(", "patch_size", ")", ")", "\n", "args", ".", "window_size", "=", "(", "args", ".", "num_frames", "//", "2", ",", "args", ".", "input_size", "//", "patch_size", "[", "0", "]", ",", "args", ".", "input_size", "//", "patch_size", "[", "1", "]", ")", "\n", "args", ".", "patch_size", "=", "patch_size", "\n", "\n", "model", ".", "to", "(", "device", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "model_path", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "args", ".", "save_path", ":", "\n", "        ", "Path", "(", "args", ".", "save_path", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "img_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "vr", "=", "VideoReader", "(", "f", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "", "duration", "=", "len", "(", "vr", ")", "\n", "new_length", "=", "1", "\n", "new_step", "=", "1", "\n", "skip_length", "=", "new_length", "*", "new_step", "\n", "# frame_id_list = [1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61]", "\n", "\n", "\n", "tmp", "=", "np", ".", "arange", "(", "0", ",", "32", ",", "2", ")", "+", "60", "\n", "frame_id_list", "=", "tmp", ".", "tolist", "(", ")", "\n", "# average_duration = (duration - skip_length + 1) // args.num_frames", "\n", "# if average_duration > 0:", "\n", "#     frame_id_list = np.multiply(list(range(args.num_frames)),", "\n", "#                             average_duration)", "\n", "#     frame_id_list = frame_id_list + np.random.randint(average_duration,", "\n", "#                                             size=args.num_frames)", "\n", "\n", "video_data", "=", "vr", ".", "get_batch", "(", "frame_id_list", ")", ".", "asnumpy", "(", ")", "\n", "print", "(", "video_data", ".", "shape", ")", "\n", "img", "=", "[", "Image", ".", "fromarray", "(", "video_data", "[", "vid", ",", ":", ",", ":", ",", ":", "]", ")", ".", "convert", "(", "'RGB'", ")", "for", "vid", ",", "_", "in", "enumerate", "(", "frame_id_list", ")", "]", "\n", "\n", "transforms", "=", "DataAugmentationForVideoMAE", "(", "args", ")", "\n", "img", ",", "bool_masked_pos", "=", "transforms", "(", "(", "img", ",", "None", ")", ")", "# T*C,H,W", "\n", "# print(img.shape)", "\n", "img", "=", "img", ".", "view", "(", "(", "args", ".", "num_frames", ",", "3", ")", "+", "img", ".", "size", "(", ")", "[", "-", "2", ":", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "# T*C,H,W -> T,C,H,W -> C,T,H,W", "\n", "# img = img.view(( -1 , args.num_frames) + img.size()[-2:]) ", "\n", "bool_masked_pos", "=", "torch", ".", "from_numpy", "(", "bool_masked_pos", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# img = img[None, :]", "\n", "# bool_masked_pos = bool_masked_pos[None, :]", "\n", "        ", "img", "=", "img", ".", "unsqueeze", "(", "0", ")", "\n", "print", "(", "img", ".", "shape", ")", "\n", "bool_masked_pos", "=", "bool_masked_pos", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "img", "=", "img", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "bool_masked_pos", "=", "bool_masked_pos", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", ".", "flatten", "(", "1", ")", ".", "to", "(", "torch", ".", "bool", ")", "\n", "outputs", "=", "model", "(", "img", ",", "bool_masked_pos", ")", "\n", "\n", "#save original video", "\n", "mean", "=", "torch", ".", "as_tensor", "(", "IMAGENET_DEFAULT_MEAN", ")", ".", "to", "(", "device", ")", "[", "None", ",", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "std", "=", "torch", ".", "as_tensor", "(", "IMAGENET_DEFAULT_STD", ")", ".", "to", "(", "device", ")", "[", "None", ",", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "ori_img", "=", "img", "*", "std", "+", "mean", "# in [0, 1]", "\n", "imgs", "=", "[", "ToPILImage", "(", ")", "(", "ori_img", "[", "0", ",", ":", ",", "vid", ",", ":", ",", ":", "]", ".", "cpu", "(", ")", ")", "for", "vid", ",", "_", "in", "enumerate", "(", "frame_id_list", ")", "]", "\n", "for", "id", ",", "im", "in", "enumerate", "(", "imgs", ")", ":", "\n", "            ", "im", ".", "save", "(", "f\"{args.save_path}/ori_img{id}.jpg\"", ")", "\n", "\n", "", "img_squeeze", "=", "rearrange", "(", "ori_img", ",", "'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2) c'", ",", "p0", "=", "2", ",", "p1", "=", "patch_size", "[", "0", "]", ",", "p2", "=", "patch_size", "[", "0", "]", ")", "\n", "img_norm", "=", "(", "img_squeeze", "-", "img_squeeze", ".", "mean", "(", "dim", "=", "-", "2", ",", "keepdim", "=", "True", ")", ")", "/", "(", "img_squeeze", ".", "var", "(", "dim", "=", "-", "2", ",", "unbiased", "=", "True", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "1e-6", ")", "\n", "img_patch", "=", "rearrange", "(", "img_norm", ",", "'b n p c -> b n (p c)'", ")", "\n", "img_patch", "[", "bool_masked_pos", "]", "=", "outputs", "\n", "\n", "#make mask", "\n", "mask", "=", "torch", ".", "ones_like", "(", "img_patch", ")", "\n", "mask", "[", "bool_masked_pos", "]", "=", "0", "\n", "mask", "=", "rearrange", "(", "mask", ",", "'b n (p c) -> b n p c'", ",", "c", "=", "3", ")", "\n", "mask", "=", "rearrange", "(", "mask", ",", "'b (t h w) (p0 p1 p2) c -> b c (t p0) (h p1) (w p2) '", ",", "p0", "=", "2", ",", "p1", "=", "patch_size", "[", "0", "]", ",", "p2", "=", "patch_size", "[", "1", "]", ",", "h", "=", "14", ",", "w", "=", "14", ")", "\n", "\n", "#save reconstruction video", "\n", "rec_img", "=", "rearrange", "(", "img_patch", ",", "'b n (p c) -> b n p c'", ",", "c", "=", "3", ")", "\n", "# Notice: To visualize the reconstruction video, we add the predict and the original mean and var of each patch.", "\n", "rec_img", "=", "rec_img", "*", "(", "img_squeeze", ".", "var", "(", "dim", "=", "-", "2", ",", "unbiased", "=", "True", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "1e-6", ")", "+", "img_squeeze", ".", "mean", "(", "dim", "=", "-", "2", ",", "keepdim", "=", "True", ")", "\n", "rec_img", "=", "rearrange", "(", "rec_img", ",", "'b (t h w) (p0 p1 p2) c -> b c (t p0) (h p1) (w p2)'", ",", "p0", "=", "2", ",", "p1", "=", "patch_size", "[", "0", "]", ",", "p2", "=", "patch_size", "[", "1", "]", ",", "h", "=", "14", ",", "w", "=", "14", ")", "\n", "imgs", "=", "[", "ToPILImage", "(", ")", "(", "rec_img", "[", "0", ",", ":", ",", "vid", ",", ":", ",", ":", "]", ".", "cpu", "(", ")", ".", "clamp", "(", "0", ",", "0.996", ")", ")", "for", "vid", ",", "_", "in", "enumerate", "(", "frame_id_list", ")", "]", "\n", "\n", "for", "id", ",", "im", "in", "enumerate", "(", "imgs", ")", ":", "\n", "            ", "im", ".", "save", "(", "f\"{args.save_path}/rec_img{id}.jpg\"", ")", "\n", "\n", "#save masked video ", "\n", "", "img_mask", "=", "rec_img", "*", "mask", "\n", "imgs", "=", "[", "ToPILImage", "(", ")", "(", "img_mask", "[", "0", ",", ":", ",", "vid", ",", ":", ",", ":", "]", ".", "cpu", "(", ")", ")", "for", "vid", ",", "_", "in", "enumerate", "(", "frame_id_list", ")", "]", "\n", "for", "id", ",", "im", "in", "enumerate", "(", "imgs", ")", ":", "\n", "            ", "im", ".", "save", "(", "f\"{args.save_path}/mask_img{id}.jpg\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.DropPath.__init__": [[23, 26], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__"], ["def", "__init__", "(", "self", ",", "drop_prob", "=", "None", ")", ":", "\n", "        ", "super", "(", "DropPath", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob", "=", "drop_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.DropPath.forward": [[27, 29], ["timm.models.layers.drop_path"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "drop_path", "(", "x", ",", "self", ".", "drop_prob", ",", "self", ".", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.DropPath.extra_repr": [[30, 32], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "'p={}'", ".", "format", "(", "self", ".", "drop_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.Mlp.__init__": [[35, 43], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "act_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", ",", "out_features", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.Mlp.forward": [[44, 52], ["modeling_finetune.Mlp.fc1", "modeling_finetune.Mlp.act", "modeling_finetune.Mlp.fc2", "modeling_finetune.Mlp.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "# x = self.drop(x)", "\n", "# commit this for the orignal BERT implement ", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.Attention.__init__": [[55, 77], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "dim", ",", "num_heads", "=", "8", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "\n", "proj_drop", "=", "0.", ",", "attn_head_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "if", "attn_head_dim", "is", "not", "None", ":", "\n", "            ", "head_dim", "=", "attn_head_dim", "\n", "", "all_head_dim", "=", "head_dim", "*", "self", ".", "num_heads", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "all_head_dim", "*", "3", ",", "bias", "=", "False", ")", "\n", "if", "qkv_bias", ":", "\n", "            ", "self", ".", "q_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "all_head_dim", ")", ")", "\n", "self", ".", "v_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "all_head_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "q_bias", "=", "None", "\n", "self", ".", "v_bias", "=", "None", "\n", "\n", "", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "all_head_dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.Attention.forward": [[78, 99], ["torch.linear", "torch.linear", "torch.linear", "qkv.reshape().permute.reshape().permute.reshape().permute", "modeling_finetune.Attention.softmax", "modeling_finetune.Attention.attn_drop", "modeling_finetune.Attention.proj", "modeling_finetune.Attention.proj_drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "k.transpose", "qkv.reshape().permute.reshape().permute.reshape", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv_bias", "=", "None", "\n", "if", "self", ".", "q_bias", "is", "not", "None", ":", "\n", "            ", "qkv_bias", "=", "torch", ".", "cat", "(", "(", "self", ".", "q_bias", ",", "torch", ".", "zeros_like", "(", "self", ".", "v_bias", ",", "requires_grad", "=", "False", ")", ",", "self", ".", "v_bias", ")", ")", "\n", "# qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)", "\n", "", "qkv", "=", "F", ".", "linear", "(", "input", "=", "x", ",", "weight", "=", "self", ".", "qkv", ".", "weight", ",", "bias", "=", "qkv_bias", ")", "\n", "qkv", "=", "qkv", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "-", "1", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.Block.__init__": [[103, 122], ["torch.Module.__init__", "norm_layer", "modeling_finetune.Attention", "norm_layer", "int", "modeling_finetune.Mlp", "modeling_finetune.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "init_values", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "attn_head_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "\n", "dim", ",", "num_heads", "=", "num_heads", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ",", "attn_head_dim", "=", "attn_head_dim", ")", "\n", "# NOTE: drop path for stochastic depth, we shall see if this is better than dropout here", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n", "if", "init_values", ">", "0", ":", "\n", "            ", "self", ".", "gamma_1", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "gamma_2", "=", "nn", ".", "Parameter", "(", "init_values", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma_1", ",", "self", ".", "gamma_2", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.Block.forward": [[123, 131], ["modeling_finetune.Block.drop_path", "modeling_finetune.Block.drop_path", "modeling_finetune.Block.drop_path", "modeling_finetune.Block.drop_path", "modeling_finetune.Block.attn", "modeling_finetune.Block.mlp", "modeling_finetune.Block.norm1", "modeling_finetune.Block.norm2", "modeling_finetune.Block.attn", "modeling_finetune.Block.mlp", "modeling_finetune.Block.norm1", "modeling_finetune.Block.norm2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "gamma_1", "is", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_1", "*", "self", ".", "attn", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "gamma_2", "*", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.PatchEmbed.__init__": [[136, 148], ["torch.Module.__init__", "timm.models.layers.to_2tuple", "timm.models.layers.to_2tuple", "int", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__"], ["def", "__init__", "(", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "num_frames", "=", "16", ",", "tubelet_size", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "img_size", "=", "to_2tuple", "(", "img_size", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "self", ".", "tubelet_size", "=", "int", "(", "tubelet_size", ")", "\n", "num_patches", "=", "(", "img_size", "[", "1", "]", "//", "patch_size", "[", "1", "]", ")", "*", "(", "img_size", "[", "0", "]", "//", "patch_size", "[", "0", "]", ")", "*", "(", "num_frames", "//", "self", ".", "tubelet_size", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "self", ".", "num_patches", "=", "num_patches", "\n", "self", ".", "proj", "=", "nn", ".", "Conv3d", "(", "in_channels", "=", "in_chans", ",", "out_channels", "=", "embed_dim", ",", "\n", "kernel_size", "=", "(", "self", ".", "tubelet_size", ",", "patch_size", "[", "0", "]", ",", "patch_size", "[", "1", "]", ")", ",", "\n", "stride", "=", "(", "self", ".", "tubelet_size", ",", "patch_size", "[", "0", "]", ",", "patch_size", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.PatchEmbed.forward": [[149, 156], ["modeling_finetune.PatchEmbed.proj().flatten().transpose", "modeling_finetune.PatchEmbed.proj().flatten", "modeling_finetune.PatchEmbed.proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "B", ",", "C", ",", "T", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "# FIXME look at relaxing size constraints", "\n", "assert", "H", "==", "self", ".", "img_size", "[", "0", "]", "and", "W", "==", "self", ".", "img_size", "[", "1", "]", ",", "f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.__init__": [[175, 232], ["torch.Module.__init__", "modeling_finetune.PatchEmbed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "timm.models.layers.trunc_normal_", "modeling_finetune.VisionTransformer.apply", "modeling_finetune.VisionTransformer.head.weight.data.mul_", "modeling_finetune.VisionTransformer.head.bias.data.mul_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_finetune.get_sinusoid_encoding_table", "x.item", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer", "norm_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "timm.models.layers.trunc_normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "modeling_finetune.Block", "range"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.trunc_normal_", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.get_sinusoid_encoding_table", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.trunc_normal_"], ["def", "__init__", "(", "self", ",", "\n", "img_size", "=", "224", ",", "\n", "patch_size", "=", "16", ",", "\n", "in_chans", "=", "3", ",", "\n", "num_classes", "=", "1000", ",", "\n", "embed_dim", "=", "768", ",", "\n", "depth", "=", "12", ",", "\n", "num_heads", "=", "12", ",", "\n", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "init_values", "=", "0.", ",", "\n", "use_learnable_pos_emb", "=", "False", ",", "\n", "init_scale", "=", "0.", ",", "\n", "all_frames", "=", "16", ",", "\n", "tubelet_size", "=", "2", ",", "\n", "use_mean_pooling", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_features", "=", "self", ".", "embed_dim", "=", "embed_dim", "# num_features for consistency with other models", "\n", "self", ".", "tubelet_size", "=", "tubelet_size", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "img_size", "=", "img_size", ",", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ",", "num_frames", "=", "all_frames", ",", "tubelet_size", "=", "self", ".", "tubelet_size", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "\n", "if", "use_learnable_pos_emb", ":", "\n", "            ", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "# sine-cosine positional embeddings is on the way", "\n", "            ", "self", ".", "pos_embed", "=", "get_sinusoid_encoding_table", "(", "num_patches", ",", "embed_dim", ")", "\n", "\n", "", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "depth", ")", "]", "# stochastic depth decay rule", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "Block", "(", "\n", "dim", "=", "embed_dim", ",", "num_heads", "=", "num_heads", ",", "mlp_ratio", "=", "mlp_ratio", ",", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop_rate", ",", "attn_drop", "=", "attn_drop_rate", ",", "drop_path", "=", "dpr", "[", "i", "]", ",", "norm_layer", "=", "norm_layer", ",", "\n", "init_values", "=", "init_values", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "self", ".", "norm", "=", "nn", ".", "Identity", "(", ")", "if", "use_mean_pooling", "else", "norm_layer", "(", "embed_dim", ")", "\n", "self", ".", "fc_norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "use_mean_pooling", "else", "None", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "if", "use_learnable_pos_emb", ":", "\n", "            ", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "\n", "", "trunc_normal_", "(", "self", ".", "head", ".", "weight", ",", "std", "=", ".02", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n", "self", ".", "head", ".", "weight", ".", "data", ".", "mul_", "(", "init_scale", ")", "\n", "self", ".", "head", ".", "bias", ".", "data", ".", "mul_", "(", "init_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer._init_weights": [[233, 241], ["isinstance", "timm.models.layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_pretrain.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.get_num_layers": [[242, 244], ["len"], "methods", ["None"], ["", "", "def", "get_num_layers", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.no_weight_decay": [[245, 248], ["None"], "methods", ["None"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "no_weight_decay", "(", "self", ")", ":", "\n", "        ", "return", "{", "'pos_embed'", ",", "'cls_token'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.get_classifier": [[249, 251], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.reset_classifier": [[252, 255], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ",", "global_pool", "=", "''", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.forward_features": [[256, 272], ["modeling_finetune.VisionTransformer.patch_embed", "blk.size", "modeling_finetune.VisionTransformer.pos_drop", "modeling_finetune.VisionTransformer.norm", "blk", "modeling_finetune.VisionTransformer.fc_norm", "modeling_finetune.VisionTransformer.pos_embed.expand().type_as().to().clone().detach", "blk.mean", "modeling_finetune.VisionTransformer.pos_embed.expand().type_as().to().clone", "modeling_finetune.VisionTransformer.pos_embed.expand().type_as().to", "modeling_finetune.VisionTransformer.pos_embed.expand().type_as", "modeling_finetune.VisionTransformer.pos_embed.expand"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "B", ",", "_", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "\n", "if", "self", ".", "pos_embed", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "pos_embed", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", ".", "type_as", "(", "x", ")", ".", "to", "(", "x", ".", "device", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "if", "self", ".", "fc_norm", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "fc_norm", "(", "x", ".", "mean", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.forward": [[273, 277], ["modeling_finetune.VisionTransformer.forward_features", "modeling_finetune.VisionTransformer.head"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.forward_features"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg": [[10, 17], ["None"], "function", ["None"], ["def", "_cfg", "(", "url", "=", "''", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "'url'", ":", "url", ",", "\n", "'num_classes'", ":", "400", ",", "'input_size'", ":", "(", "3", ",", "224", ",", "224", ")", ",", "'pool_size'", ":", "None", ",", "\n", "'crop_pct'", ":", ".9", ",", "'interpolation'", ":", "'bicubic'", ",", "\n", "'mean'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "'std'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "**", "kwargs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.get_sinusoid_encoding_table": [[159, 170], ["numpy.array", "numpy.sin", "numpy.cos", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "modeling_finetune.get_sinusoid_encoding_table.get_position_angle_vec"], "function", ["None"], ["", "", "def", "get_sinusoid_encoding_table", "(", "n_position", ",", "d_hid", ")", ":", "\n", "    ", "''' Sinusoid position encoding table '''", "\n", "# TODO: make it with torch instead of numpy ", "\n", "def", "get_position_angle_vec", "(", "position", ")", ":", "\n", "        ", "return", "[", "position", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "hid_j", "//", "2", ")", "/", "d_hid", ")", "for", "hid_j", "in", "range", "(", "d_hid", ")", "]", "\n", "\n", "", "sinusoid_table", "=", "np", ".", "array", "(", "[", "get_position_angle_vec", "(", "pos_i", ")", "for", "pos_i", "in", "range", "(", "n_position", ")", "]", ")", "\n", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i ", "\n", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1 ", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "sinusoid_table", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.vit_small_patch16_224": [[278, 285], ["modeling_finetune.VisionTransformer", "modeling_finetune._cfg", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg"], ["", "", "@", "register_model", "\n", "def", "vit_small_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "VisionTransformer", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.vit_base_patch16_224": [[286, 293], ["modeling_finetune.VisionTransformer", "modeling_finetune._cfg", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "VisionTransformer", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.vit_base_patch16_384": [[295, 302], ["modeling_finetune.VisionTransformer", "modeling_finetune._cfg", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg"], ["", "@", "register_model", "\n", "def", "vit_base_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "VisionTransformer", "(", "\n", "img_size", "=", "384", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.vit_large_patch16_224": [[304, 311], ["modeling_finetune.VisionTransformer", "modeling_finetune._cfg", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg"], ["", "@", "register_model", "\n", "def", "vit_large_patch16_224", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "VisionTransformer", "(", "\n", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.vit_large_patch16_384": [[313, 320], ["modeling_finetune.VisionTransformer", "modeling_finetune._cfg", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg"], ["", "@", "register_model", "\n", "def", "vit_large_patch16_384", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "VisionTransformer", "(", "\n", "img_size", "=", "384", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.vit_large_patch16_512": [[322, 329], ["modeling_finetune.VisionTransformer", "modeling_finetune._cfg", "functools.partial"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune._cfg"], ["", "@", "register_model", "\n", "def", "vit_large_patch16_512", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "VisionTransformer", "(", "\n", "img_size", "=", "512", ",", "patch_size", "=", "16", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "mlp_ratio", "=", "4", ",", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "**", "kwargs", ")", "\n", "model", ".", "default_cfg", "=", "_cfg", "(", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.train_class_batch": [[12, 16], ["model", "criterion"], "function", ["None"], ["def", "train_class_batch", "(", "model", ",", "samples", ",", "target", ",", "criterion", ")", ":", "\n", "    ", "outputs", "=", "model", "(", "samples", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "target", ")", "\n", "return", "loss", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.get_loss_scale_for_deepspeed": [[18, 21], ["hasattr"], "function", ["None"], ["", "def", "get_loss_scale_for_deepspeed", "(", "model", ")", ":", "\n", "    ", "optimizer", "=", "model", ".", "optimizer", "\n", "return", "optimizer", ".", "loss_scale", "if", "hasattr", "(", "optimizer", ",", "\"loss_scale\"", ")", "else", "optimizer", ".", "cur_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.train_one_epoch": [[23, 140], ["model.train", "utils.MetricLogger", "utils.MetricLogger.add_meter", "utils.MetricLogger.add_meter", "enumerate", "utils.MetricLogger.synchronize_between_processes", "print", "utils.SmoothedValue", "utils.SmoothedValue", "model.zero_grad", "optimizer.zero_grad", "utils.MetricLogger.log_every", "samples.half.to", "targets.to.to", "loss.item", "torch.cuda.synchronize", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "enumerate", "mixup_fn", "samples.half.half", "engine_for_finetuning.train_class_batch", "math.isfinite", "print", "sys.exit", "model.backward", "model.step", "engine_for_finetuning.get_loss_scale_for_deepspeed", "loss_scaler", "min", "max", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.set_step", "utils.MetricLogger.meters.items", "torch.cuda.amp.autocast", "engine_for_finetuning.train_class_batch", "hasattr", "optimizer.zero_grad", "loss_scaler.state_dict", "model_ema.update", "model.parameters", "model_ema.update", "output.max"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.add_meter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.add_meter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.synchronize_between_processes", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.log_every", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.train_class_batch", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.get_loss_scale_for_deepspeed", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.set_step", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.train_class_batch", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "def", "train_one_epoch", "(", "model", ":", "torch", ".", "nn", ".", "Module", ",", "criterion", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "data_loader", ":", "Iterable", ",", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "device", ":", "torch", ".", "device", ",", "epoch", ":", "int", ",", "loss_scaler", ",", "max_norm", ":", "float", "=", "0", ",", "\n", "model_ema", ":", "Optional", "[", "ModelEma", "]", "=", "None", ",", "mixup_fn", ":", "Optional", "[", "Mixup", "]", "=", "None", ",", "log_writer", "=", "None", ",", "\n", "start_steps", "=", "None", ",", "lr_schedule_values", "=", "None", ",", "wd_schedule_values", "=", "None", ",", "\n", "num_training_steps_per_epoch", "=", "None", ",", "update_freq", "=", "None", ")", ":", "\n", "    ", "model", ".", "train", "(", "True", ")", "\n", "metric_logger", "=", "utils", ".", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "metric_logger", ".", "add_meter", "(", "'lr'", ",", "utils", ".", "SmoothedValue", "(", "window_size", "=", "1", ",", "fmt", "=", "'{value:.6f}'", ")", ")", "\n", "metric_logger", ".", "add_meter", "(", "'min_lr'", ",", "utils", ".", "SmoothedValue", "(", "window_size", "=", "1", ",", "fmt", "=", "'{value:.6f}'", ")", ")", "\n", "header", "=", "'Epoch: [{}]'", ".", "format", "(", "epoch", ")", "\n", "print_freq", "=", "10", "\n", "\n", "if", "loss_scaler", "is", "None", ":", "\n", "        ", "model", ".", "zero_grad", "(", ")", "\n", "model", ".", "micro_steps", "=", "0", "\n", "", "else", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "data_iter_step", ",", "(", "samples", ",", "targets", ",", "_", ",", "_", ")", "in", "enumerate", "(", "metric_logger", ".", "log_every", "(", "data_loader", ",", "print_freq", ",", "header", ")", ")", ":", "\n", "        ", "step", "=", "data_iter_step", "//", "update_freq", "\n", "if", "step", ">=", "num_training_steps_per_epoch", ":", "\n", "            ", "continue", "\n", "", "it", "=", "start_steps", "+", "step", "# global training iteration", "\n", "# Update LR & WD for the first acc", "\n", "if", "lr_schedule_values", "is", "not", "None", "or", "wd_schedule_values", "is", "not", "None", "and", "data_iter_step", "%", "update_freq", "==", "0", ":", "\n", "            ", "for", "i", ",", "param_group", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "                ", "if", "lr_schedule_values", "is", "not", "None", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "lr_schedule_values", "[", "it", "]", "*", "param_group", "[", "\"lr_scale\"", "]", "\n", "", "if", "wd_schedule_values", "is", "not", "None", "and", "param_group", "[", "\"weight_decay\"", "]", ">", "0", ":", "\n", "                    ", "param_group", "[", "\"weight_decay\"", "]", "=", "wd_schedule_values", "[", "it", "]", "\n", "\n", "", "", "", "samples", "=", "samples", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "targets", "=", "targets", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "if", "mixup_fn", "is", "not", "None", ":", "\n", "            ", "samples", ",", "targets", "=", "mixup_fn", "(", "samples", ",", "targets", ")", "\n", "\n", "", "if", "loss_scaler", "is", "None", ":", "\n", "            ", "samples", "=", "samples", ".", "half", "(", ")", "\n", "loss", ",", "output", "=", "train_class_batch", "(", "\n", "model", ",", "samples", ",", "targets", ",", "criterion", ")", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", ")", ":", "\n", "                ", "loss", ",", "output", "=", "train_class_batch", "(", "\n", "model", ",", "samples", ",", "targets", ",", "criterion", ")", "\n", "\n", "", "", "loss_value", "=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "not", "math", ".", "isfinite", "(", "loss_value", ")", ":", "\n", "            ", "print", "(", "\"Loss is {}, stopping training\"", ".", "format", "(", "loss_value", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "if", "loss_scaler", "is", "None", ":", "\n", "            ", "loss", "/=", "update_freq", "\n", "model", ".", "backward", "(", "loss", ")", "\n", "model", ".", "step", "(", ")", "\n", "\n", "if", "(", "data_iter_step", "+", "1", ")", "%", "update_freq", "==", "0", ":", "\n", "# model.zero_grad()", "\n", "# Deepspeed will call step() & model.zero_grad() automatic", "\n", "                ", "if", "model_ema", "is", "not", "None", ":", "\n", "                    ", "model_ema", ".", "update", "(", "model", ")", "\n", "", "", "grad_norm", "=", "None", "\n", "loss_scale_value", "=", "get_loss_scale_for_deepspeed", "(", "model", ")", "\n", "", "else", ":", "\n", "# this attribute is added by timm on one optimizer (adahessian)", "\n", "            ", "is_second_order", "=", "hasattr", "(", "optimizer", ",", "'is_second_order'", ")", "and", "optimizer", ".", "is_second_order", "\n", "loss", "/=", "update_freq", "\n", "grad_norm", "=", "loss_scaler", "(", "loss", ",", "optimizer", ",", "clip_grad", "=", "max_norm", ",", "\n", "parameters", "=", "model", ".", "parameters", "(", ")", ",", "create_graph", "=", "is_second_order", ",", "\n", "update_grad", "=", "(", "data_iter_step", "+", "1", ")", "%", "update_freq", "==", "0", ")", "\n", "if", "(", "data_iter_step", "+", "1", ")", "%", "update_freq", "==", "0", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "model_ema", "is", "not", "None", ":", "\n", "                    ", "model_ema", ".", "update", "(", "model", ")", "\n", "", "", "loss_scale_value", "=", "loss_scaler", ".", "state_dict", "(", ")", "[", "\"scale\"", "]", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "if", "mixup_fn", "is", "None", ":", "\n", "            ", "class_acc", "=", "(", "output", ".", "max", "(", "-", "1", ")", "[", "-", "1", "]", "==", "targets", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "            ", "class_acc", "=", "None", "\n", "", "metric_logger", ".", "update", "(", "loss", "=", "loss_value", ")", "\n", "metric_logger", ".", "update", "(", "class_acc", "=", "class_acc", ")", "\n", "metric_logger", ".", "update", "(", "loss_scale", "=", "loss_scale_value", ")", "\n", "min_lr", "=", "10.", "\n", "max_lr", "=", "0.", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "min_lr", "=", "min", "(", "min_lr", ",", "group", "[", "\"lr\"", "]", ")", "\n", "max_lr", "=", "max", "(", "max_lr", ",", "group", "[", "\"lr\"", "]", ")", "\n", "\n", "", "metric_logger", ".", "update", "(", "lr", "=", "max_lr", ")", "\n", "metric_logger", ".", "update", "(", "min_lr", "=", "min_lr", ")", "\n", "weight_decay_value", "=", "None", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "if", "group", "[", "\"weight_decay\"", "]", ">", "0", ":", "\n", "                ", "weight_decay_value", "=", "group", "[", "\"weight_decay\"", "]", "\n", "", "", "metric_logger", ".", "update", "(", "weight_decay", "=", "weight_decay_value", ")", "\n", "metric_logger", ".", "update", "(", "grad_norm", "=", "grad_norm", ")", "\n", "\n", "if", "log_writer", "is", "not", "None", ":", "\n", "            ", "log_writer", ".", "update", "(", "loss", "=", "loss_value", ",", "head", "=", "\"loss\"", ")", "\n", "log_writer", ".", "update", "(", "class_acc", "=", "class_acc", ",", "head", "=", "\"loss\"", ")", "\n", "log_writer", ".", "update", "(", "loss_scale", "=", "loss_scale_value", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "lr", "=", "max_lr", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "min_lr", "=", "min_lr", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "weight_decay", "=", "weight_decay_value", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "grad_norm", "=", "grad_norm", ",", "head", "=", "\"opt\"", ")", "\n", "\n", "log_writer", ".", "set_step", "(", ")", "\n", "\n", "# gather the stats from all processes", "\n", "", "", "metric_logger", ".", "synchronize_between_processes", "(", ")", "\n", "print", "(", "\"Averaged stats:\"", ",", "metric_logger", ")", "\n", "return", "{", "k", ":", "meter", ".", "global_avg", "for", "k", ",", "meter", "in", "metric_logger", ".", "meters", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.validation_one_epoch": [[142, 175], ["torch.no_grad", "torch.nn.CrossEntropyLoss", "utils.MetricLogger", "model.eval", "utils.MetricLogger.log_every", "utils.MetricLogger.synchronize_between_processes", "print", "videos.to.to", "target.to.to", "timm.utils.accuracy", "utils.MetricLogger.update", "utils.MetricLogger.meters[].update", "utils.MetricLogger.meters[].update", "torch.cuda.amp.autocast", "model", "torch.nn.CrossEntropyLoss.", "acc1.item", "acc5.item", "utils.MetricLogger.meters.items", "criterion.item"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.log_every", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.synchronize_between_processes", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validation_one_epoch", "(", "data_loader", ",", "model", ",", "device", ")", ":", "\n", "    ", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "metric_logger", "=", "utils", ".", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "header", "=", "'Val:'", "\n", "\n", "# switch to evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "metric_logger", ".", "log_every", "(", "data_loader", ",", "10", ",", "header", ")", ":", "\n", "        ", "videos", "=", "batch", "[", "0", "]", "\n", "target", "=", "batch", "[", "1", "]", "\n", "videos", "=", "videos", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "target", "=", "target", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "# compute output", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", ")", ":", "\n", "            ", "output", "=", "model", "(", "videos", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "\n", "", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "batch_size", "=", "videos", ".", "shape", "[", "0", "]", "\n", "metric_logger", ".", "update", "(", "loss", "=", "loss", ".", "item", "(", ")", ")", "\n", "metric_logger", ".", "meters", "[", "'acc1'", "]", ".", "update", "(", "acc1", ".", "item", "(", ")", ",", "n", "=", "batch_size", ")", "\n", "metric_logger", ".", "meters", "[", "'acc5'", "]", ".", "update", "(", "acc5", ".", "item", "(", ")", ",", "n", "=", "batch_size", ")", "\n", "# gather the stats from all processes", "\n", "", "metric_logger", ".", "synchronize_between_processes", "(", ")", "\n", "print", "(", "'* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}'", "\n", ".", "format", "(", "top1", "=", "metric_logger", ".", "acc1", ",", "top5", "=", "metric_logger", ".", "acc5", ",", "losses", "=", "metric_logger", ".", "loss", ")", ")", "\n", "\n", "return", "{", "k", ":", "meter", ".", "global_avg", "for", "k", ",", "meter", "in", "metric_logger", ".", "meters", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.final_test": [[178, 230], ["torch.no_grad", "torch.nn.CrossEntropyLoss", "utils.MetricLogger", "model.eval", "utils.MetricLogger.log_every", "utils.MetricLogger.synchronize_between_processes", "print", "videos.to.to", "target.to.to", "range", "timm.utils.accuracy", "utils.MetricLogger.update", "utils.MetricLogger.meters[].update", "utils.MetricLogger.meters[].update", "os.path.exists", "os.mknod", "open", "f.write", "torch.cuda.amp.autocast", "model", "torch.nn.CrossEntropyLoss.", "model.size", "final_result.append", "acc1.item", "acc5.item", "f.write", "utils.MetricLogger.meters.items", "str", "str", "str", "str", "criterion.item", "model.data[].cpu().numpy().tolist", "int", "int", "int", "target[].cpu().numpy", "chunk_nb[].cpu().numpy", "split_nb[].cpu().numpy", "model.data[].cpu().numpy", "target[].cpu", "chunk_nb[].cpu", "split_nb[].cpu", "model.data[].cpu"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.log_every", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.synchronize_between_processes", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "final_test", "(", "data_loader", ",", "model", ",", "device", ",", "file", ")", ":", "\n", "    ", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "metric_logger", "=", "utils", ".", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "header", "=", "'Test:'", "\n", "\n", "# switch to evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "final_result", "=", "[", "]", "\n", "\n", "for", "batch", "in", "metric_logger", ".", "log_every", "(", "data_loader", ",", "10", ",", "header", ")", ":", "\n", "        ", "videos", "=", "batch", "[", "0", "]", "\n", "target", "=", "batch", "[", "1", "]", "\n", "ids", "=", "batch", "[", "2", "]", "\n", "chunk_nb", "=", "batch", "[", "3", "]", "\n", "split_nb", "=", "batch", "[", "4", "]", "\n", "videos", "=", "videos", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "target", "=", "target", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "# compute output", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", ")", ":", "\n", "            ", "output", "=", "model", "(", "videos", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "output", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "string", "=", "\"{} {} {} {} {}\\n\"", ".", "format", "(", "ids", "[", "i", "]", ",", "str", "(", "output", ".", "data", "[", "i", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", ",", "str", "(", "int", "(", "target", "[", "i", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ",", "str", "(", "int", "(", "chunk_nb", "[", "i", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ",", "str", "(", "int", "(", "split_nb", "[", "i", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", "\n", "final_result", ".", "append", "(", "string", ")", "\n", "\n", "", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "batch_size", "=", "videos", ".", "shape", "[", "0", "]", "\n", "metric_logger", ".", "update", "(", "loss", "=", "loss", ".", "item", "(", ")", ")", "\n", "metric_logger", ".", "meters", "[", "'acc1'", "]", ".", "update", "(", "acc1", ".", "item", "(", ")", ",", "n", "=", "batch_size", ")", "\n", "metric_logger", ".", "meters", "[", "'acc5'", "]", ".", "update", "(", "acc5", ".", "item", "(", ")", ",", "n", "=", "batch_size", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "file", ")", ":", "\n", "        ", "os", ".", "mknod", "(", "file", ")", "\n", "", "with", "open", "(", "file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"{}, {}\\n\"", ".", "format", "(", "acc1", ",", "acc5", ")", ")", "\n", "for", "line", "in", "final_result", ":", "\n", "            ", "f", ".", "write", "(", "line", ")", "\n", "# gather the stats from all processes", "\n", "", "", "metric_logger", ".", "synchronize_between_processes", "(", ")", "\n", "print", "(", "'* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}'", "\n", ".", "format", "(", "top1", "=", "metric_logger", ".", "acc1", ",", "top5", "=", "metric_logger", ".", "acc5", ",", "losses", "=", "metric_logger", ".", "loss", ")", ")", "\n", "\n", "return", "{", "k", ":", "meter", ".", "global_avg", "for", "k", ",", "meter", "in", "metric_logger", ".", "meters", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.merge": [[232, 272], ["print", "range", "print", "print", "enumerate", "Pool", "Pool.map", "os.path.join", "len", "input_lst.append", "numpy.mean", "numpy.mean", "open().readlines", "line.strip.strip", "numpy.fromstring", "dict_feats[].append", "dict_pos[].append", "str", "line.strip.split", "[].split", "[].split", "[].split", "open", "[].split", "line.strip.split", "line.strip.split", "line.strip.split", "line.strip.split"], "function", ["None"], ["", "def", "merge", "(", "eval_path", ",", "num_tasks", ")", ":", "\n", "    ", "dict_feats", "=", "{", "}", "\n", "dict_label", "=", "{", "}", "\n", "dict_pos", "=", "{", "}", "\n", "print", "(", "\"Reading individual output files\"", ")", "\n", "\n", "for", "x", "in", "range", "(", "num_tasks", ")", ":", "\n", "        ", "file", "=", "os", ".", "path", ".", "join", "(", "eval_path", ",", "str", "(", "x", ")", "+", "'.txt'", ")", "\n", "lines", "=", "open", "(", "file", ",", "'r'", ")", ".", "readlines", "(", ")", "[", "1", ":", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "name", "=", "line", ".", "split", "(", "'['", ")", "[", "0", "]", "\n", "label", "=", "line", ".", "split", "(", "']'", ")", "[", "1", "]", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "chunk_nb", "=", "line", ".", "split", "(", "']'", ")", "[", "1", "]", ".", "split", "(", "' '", ")", "[", "2", "]", "\n", "split_nb", "=", "line", ".", "split", "(", "']'", ")", "[", "1", "]", ".", "split", "(", "' '", ")", "[", "3", "]", "\n", "data", "=", "np", ".", "fromstring", "(", "line", ".", "split", "(", "'['", ")", "[", "1", "]", ".", "split", "(", "']'", ")", "[", "0", "]", ",", "dtype", "=", "np", ".", "float", ",", "sep", "=", "','", ")", "\n", "if", "not", "name", "in", "dict_feats", ":", "\n", "                ", "dict_feats", "[", "name", "]", "=", "[", "]", "\n", "dict_label", "[", "name", "]", "=", "0", "\n", "dict_pos", "[", "name", "]", "=", "[", "]", "\n", "", "if", "chunk_nb", "+", "split_nb", "in", "dict_pos", "[", "name", "]", ":", "\n", "                ", "continue", "\n", "", "dict_feats", "[", "name", "]", ".", "append", "(", "data", ")", "\n", "dict_pos", "[", "name", "]", ".", "append", "(", "chunk_nb", "+", "split_nb", ")", "\n", "dict_label", "[", "name", "]", "=", "label", "\n", "", "", "print", "(", "\"Computing final results\"", ")", "\n", "\n", "input_lst", "=", "[", "]", "\n", "print", "(", "len", "(", "dict_feats", ")", ")", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "dict_feats", ")", ":", "\n", "        ", "input_lst", ".", "append", "(", "[", "i", ",", "item", ",", "dict_feats", "[", "item", "]", ",", "dict_label", "[", "item", "]", "]", ")", "\n", "", "from", "multiprocessing", "import", "Pool", "\n", "p", "=", "Pool", "(", "64", ")", "\n", "ans", "=", "p", ".", "map", "(", "compute_video", ",", "input_lst", ")", "\n", "top1", "=", "[", "x", "[", "1", "]", "for", "x", "in", "ans", "]", "\n", "top5", "=", "[", "x", "[", "2", "]", "for", "x", "in", "ans", "]", "\n", "pred", "=", "[", "x", "[", "0", "]", "for", "x", "in", "ans", "]", "\n", "label", "=", "[", "x", "[", "3", "]", "for", "x", "in", "ans", "]", "\n", "final_top1", ",", "final_top5", "=", "np", ".", "mean", "(", "top1", ")", ",", "np", ".", "mean", "(", "top5", ")", "\n", "return", "final_top1", "*", "100", ",", "final_top5", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.compute_video": [[273, 281], ["numpy.mean", "numpy.argmax", "int", "int", "int", "int", "numpy.argsort"], "function", ["None"], ["", "def", "compute_video", "(", "lst", ")", ":", "\n", "    ", "i", ",", "video_id", ",", "data", ",", "label", "=", "lst", "\n", "feat", "=", "[", "x", "for", "x", "in", "data", "]", "\n", "feat", "=", "np", ".", "mean", "(", "feat", ",", "axis", "=", "0", ")", "\n", "pred", "=", "np", ".", "argmax", "(", "feat", ")", "\n", "top1", "=", "(", "int", "(", "pred", ")", "==", "int", "(", "label", ")", ")", "*", "1.0", "\n", "top5", "=", "(", "int", "(", "label", ")", "in", "np", ".", "argsort", "(", "-", "feat", ")", "[", ":", "5", "]", ")", "*", "1.0", "\n", "return", "[", "pred", ",", "top1", ",", "top5", ",", "int", "(", "label", ")", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.ssv2.SSVideoClsDataset.__init__": [[16, 78], ["pd.read_csv", "list", "list", "ImportError", "video_transforms.Compose", "video_transforms.Compose", "video_transforms.Compose", "range", "video_transforms.Resize", "video_transforms.CenterCrop", "volume_transforms.ClipToTensor", "video_transforms.Normalize", "range", "video_transforms.Resize", "volume_transforms.ClipToTensor", "video_transforms.Normalize", "range", "len", "ssv2.SSVideoClsDataset.test_label_array.append", "ssv2.SSVideoClsDataset.test_dataset.append", "ssv2.SSVideoClsDataset.test_seg.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "anno_path", ",", "data_path", ",", "mode", "=", "'train'", ",", "clip_len", "=", "8", ",", "\n", "crop_size", "=", "224", ",", "short_side_size", "=", "256", ",", "new_height", "=", "256", ",", "\n", "new_width", "=", "340", ",", "keep_aspect_ratio", "=", "True", ",", "num_segment", "=", "1", ",", "\n", "num_crop", "=", "1", ",", "test_num_segment", "=", "10", ",", "test_num_crop", "=", "3", ",", "args", "=", "None", ")", ":", "\n", "        ", "self", ".", "anno_path", "=", "anno_path", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "clip_len", "=", "clip_len", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "short_side_size", "=", "short_side_size", "\n", "self", ".", "new_height", "=", "new_height", "\n", "self", ".", "new_width", "=", "new_width", "\n", "self", ".", "keep_aspect_ratio", "=", "keep_aspect_ratio", "\n", "self", ".", "num_segment", "=", "num_segment", "\n", "self", ".", "test_num_segment", "=", "test_num_segment", "\n", "self", ".", "num_crop", "=", "num_crop", "\n", "self", ".", "test_num_crop", "=", "test_num_crop", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "aug", "=", "False", "\n", "self", ".", "rand_erase", "=", "False", "\n", "if", "self", ".", "mode", "in", "[", "'train'", "]", ":", "\n", "            ", "self", ".", "aug", "=", "True", "\n", "if", "self", ".", "args", ".", "reprob", ">", "0", ":", "\n", "                ", "self", ".", "rand_erase", "=", "True", "\n", "", "", "if", "VideoReader", "is", "None", ":", "\n", "            ", "raise", "ImportError", "(", "\"Unable to import `decord` which is required to read videos.\"", ")", "\n", "\n", "", "import", "pandas", "as", "pd", "\n", "cleaned", "=", "pd", ".", "read_csv", "(", "self", ".", "anno_path", ",", "header", "=", "None", ",", "delimiter", "=", "' '", ")", "\n", "self", ".", "dataset_samples", "=", "list", "(", "cleaned", ".", "values", "[", ":", ",", "0", "]", ")", "\n", "self", ".", "label_array", "=", "list", "(", "cleaned", ".", "values", "[", ":", ",", "1", "]", ")", "\n", "\n", "if", "(", "mode", "==", "'train'", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "elif", "(", "mode", "==", "'validation'", ")", ":", "\n", "            ", "self", ".", "data_transform", "=", "video_transforms", ".", "Compose", "(", "[", "\n", "video_transforms", ".", "Resize", "(", "self", ".", "short_side_size", ",", "interpolation", "=", "'bilinear'", ")", ",", "\n", "video_transforms", ".", "CenterCrop", "(", "size", "=", "(", "self", ".", "crop_size", ",", "self", ".", "crop_size", ")", ")", ",", "\n", "volume_transforms", ".", "ClipToTensor", "(", ")", ",", "\n", "video_transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "self", ".", "data_resize", "=", "video_transforms", ".", "Compose", "(", "[", "\n", "video_transforms", ".", "Resize", "(", "size", "=", "(", "short_side_size", ")", ",", "interpolation", "=", "'bilinear'", ")", "\n", "]", ")", "\n", "self", ".", "data_transform", "=", "video_transforms", ".", "Compose", "(", "[", "\n", "volume_transforms", ".", "ClipToTensor", "(", ")", ",", "\n", "video_transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "self", ".", "test_seg", "=", "[", "]", "\n", "self", ".", "test_dataset", "=", "[", "]", "\n", "self", ".", "test_label_array", "=", "[", "]", "\n", "for", "ck", "in", "range", "(", "self", ".", "test_num_segment", ")", ":", "\n", "                ", "for", "cp", "in", "range", "(", "self", ".", "test_num_crop", ")", ":", "\n", "                    ", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "label_array", ")", ")", ":", "\n", "                        ", "sample_label", "=", "self", ".", "label_array", "[", "idx", "]", "\n", "self", ".", "test_label_array", ".", "append", "(", "sample_label", ")", "\n", "self", ".", "test_dataset", ".", "append", "(", "self", ".", "dataset_samples", "[", "idx", "]", ")", "\n", "self", ".", "test_seg", ".", "append", "(", "(", "ck", ",", "cp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.ssv2.SSVideoClsDataset.__getitem__": [[79, 154], ["ssv2.SSVideoClsDataset.loadvideo_decord", "len", "range", "ssv2.SSVideoClsDataset._aug_frame", "ssv2.SSVideoClsDataset.loadvideo_decord", "ssv2.SSVideoClsDataset.data_transform", "len", "warnings.warn", "numpy.random.randint", "ssv2.SSVideoClsDataset.loadvideo_decord", "ssv2.SSVideoClsDataset._aug_frame", "frame_list.append", "label_list.append", "index_list.append", "len", "ssv2.SSVideoClsDataset.loadvideo_decord", "ssv2.SSVideoClsDataset.data_resize", "isinstance", "int", "ssv2.SSVideoClsDataset.data_transform", "NameError", "ssv2.SSVideoClsDataset.__len__", "len", "warnings.warn", "numpy.random.randint", "ssv2.SSVideoClsDataset.loadvideo_decord", "[].split", "len", "warnings.warn", "numpy.random.randint", "ssv2.SSVideoClsDataset.loadvideo_decord", "numpy.stack", "ssv2.SSVideoClsDataset.__len__", "ssv2.SSVideoClsDataset.__len__", "[].split", "str", "max", "sample.split", "sample.split"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset._aug_frame", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset._aug_frame", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__len__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__len__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__len__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "", "", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "args", "=", "self", ".", "args", "\n", "scale_t", "=", "1", "\n", "\n", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ",", "sample_rate_scale", "=", "scale_t", ")", "# T H W C", "\n", "if", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                ", "while", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\"video {} not correctly loaded during training\"", ".", "format", "(", "sample", ")", ")", "\n", "index", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "__len__", "(", ")", ")", "\n", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ",", "sample_rate_scale", "=", "scale_t", ")", "\n", "\n", "", "", "if", "args", ".", "num_sample", ">", "1", ":", "\n", "                ", "frame_list", "=", "[", "]", "\n", "label_list", "=", "[", "]", "\n", "index_list", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "args", ".", "num_sample", ")", ":", "\n", "                    ", "new_frames", "=", "self", ".", "_aug_frame", "(", "buffer", ",", "args", ")", "\n", "label", "=", "self", ".", "label_array", "[", "index", "]", "\n", "frame_list", ".", "append", "(", "new_frames", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "index_list", ".", "append", "(", "index", ")", "\n", "", "return", "frame_list", ",", "label_list", ",", "index_list", ",", "{", "}", "\n", "", "else", ":", "\n", "                ", "buffer", "=", "self", ".", "_aug_frame", "(", "buffer", ",", "args", ")", "\n", "\n", "", "return", "buffer", ",", "self", ".", "label_array", "[", "index", "]", ",", "index", ",", "{", "}", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'validation'", ":", "\n", "            ", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "if", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                ", "while", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\"video {} not correctly loaded during validation\"", ".", "format", "(", "sample", ")", ")", "\n", "index", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "__len__", "(", ")", ")", "\n", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "", "", "buffer", "=", "self", ".", "data_transform", "(", "buffer", ")", "\n", "return", "buffer", ",", "self", ".", "label_array", "[", "index", "]", ",", "sample", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "sample", "=", "self", ".", "test_dataset", "[", "index", "]", "\n", "chunk_nb", ",", "split_nb", "=", "self", ".", "test_seg", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "\n", "while", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"video {}, temporal {}, spatial {} not found during testing\"", ".", "format", "(", "str", "(", "self", ".", "test_dataset", "[", "index", "]", ")", ",", "chunk_nb", ",", "split_nb", ")", ")", "\n", "index", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "__len__", "(", ")", ")", "\n", "sample", "=", "self", ".", "test_dataset", "[", "index", "]", "\n", "chunk_nb", ",", "split_nb", "=", "self", ".", "test_seg", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "\n", "", "buffer", "=", "self", ".", "data_resize", "(", "buffer", ")", "\n", "if", "isinstance", "(", "buffer", ",", "list", ")", ":", "\n", "                ", "buffer", "=", "np", ".", "stack", "(", "buffer", ",", "0", ")", "\n", "\n", "", "spatial_step", "=", "1.0", "*", "(", "max", "(", "buffer", ".", "shape", "[", "1", "]", ",", "buffer", ".", "shape", "[", "2", "]", ")", "-", "self", ".", "short_side_size", ")", "/", "(", "self", ".", "test_num_crop", "-", "1", ")", "\n", "temporal_start", "=", "chunk_nb", "# 0/1", "\n", "spatial_start", "=", "int", "(", "split_nb", "*", "spatial_step", ")", "\n", "if", "buffer", ".", "shape", "[", "1", "]", ">=", "buffer", ".", "shape", "[", "2", "]", ":", "\n", "                ", "buffer", "=", "buffer", "[", "temporal_start", ":", ":", "2", ",", "spatial_start", ":", "spatial_start", "+", "self", ".", "short_side_size", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "buffer", "=", "buffer", "[", "temporal_start", ":", ":", "2", ",", ":", ",", "spatial_start", ":", "spatial_start", "+", "self", ".", "short_side_size", ",", ":", "]", "\n", "\n", "", "buffer", "=", "self", ".", "data_transform", "(", "buffer", ")", "\n", "return", "buffer", ",", "self", ".", "test_label_array", "[", "index", "]", ",", "sample", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "chunk_nb", ",", "split_nb", "\n", "", "else", ":", "\n", "            ", "raise", "NameError", "(", "'mode {} unkown'", ".", "format", "(", "self", ".", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.ssv2.SSVideoClsDataset._aug_frame": [[155, 215], ["video_transforms.create_random_augment", "video_transforms.create_random_augment.", "torch.stack", "buffer.permute.permute.permute", "ssv2.tensor_normalize", "buffer.permute.permute.permute", "ssv2.spatial_sampling", "random_erasing.RandomErasing", "buffer.permute.permute.permute", "random_erasing.RandomErasing.", "buffer.permute.permute.permute", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToTensor"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.create_random_augment", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.tensor_normalize", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.spatial_sampling"], ["", "", "def", "_aug_frame", "(", "\n", "self", ",", "\n", "buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "\n", "        ", "aug_transform", "=", "video_transforms", ".", "create_random_augment", "(", "\n", "input_size", "=", "(", "self", ".", "crop_size", ",", "self", ".", "crop_size", ")", ",", "\n", "auto_augment", "=", "args", ".", "aa", ",", "\n", "interpolation", "=", "args", ".", "train_interpolation", ",", "\n", ")", "\n", "\n", "buffer", "=", "[", "\n", "transforms", ".", "ToPILImage", "(", ")", "(", "frame", ")", "for", "frame", "in", "buffer", "\n", "]", "\n", "\n", "buffer", "=", "aug_transform", "(", "buffer", ")", "\n", "\n", "buffer", "=", "[", "transforms", ".", "ToTensor", "(", ")", "(", "img", ")", "for", "img", "in", "buffer", "]", "\n", "buffer", "=", "torch", ".", "stack", "(", "buffer", ")", "# T C H W", "\n", "buffer", "=", "buffer", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# T H W C ", "\n", "\n", "# T H W C ", "\n", "buffer", "=", "tensor_normalize", "(", "\n", "buffer", ",", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "# T H W C -> C T H W.", "\n", "buffer", "=", "buffer", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "# Perform data augmentation.", "\n", "scl", ",", "asp", "=", "(", "\n", "[", "0.08", ",", "1.0", "]", ",", "\n", "[", "0.75", ",", "1.3333", "]", ",", "\n", ")", "\n", "\n", "buffer", "=", "spatial_sampling", "(", "\n", "buffer", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "self", ".", "crop_size", ",", "\n", "random_horizontal_flip", "=", "False", "if", "args", ".", "data_set", "==", "'SSV2'", "else", "True", ",", "\n", "inverse_uniform_sampling", "=", "False", ",", "\n", "aspect_ratio", "=", "asp", ",", "\n", "scale", "=", "scl", ",", "\n", "motion_shift", "=", "False", "\n", ")", "\n", "\n", "if", "self", ".", "rand_erase", ":", "\n", "            ", "erase_transform", "=", "RandomErasing", "(", "\n", "args", ".", "reprob", ",", "\n", "mode", "=", "args", ".", "remode", ",", "\n", "max_count", "=", "args", ".", "recount", ",", "\n", "num_splits", "=", "args", ".", "recount", ",", "\n", "device", "=", "\"cpu\"", ",", "\n", ")", "\n", "buffer", "=", "buffer", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "buffer", "=", "erase_transform", "(", "buffer", ")", "\n", "buffer", "=", "buffer", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "", "return", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.ssv2.SSVideoClsDataset.loadvideo_decord": [[217, 264], ["list", "decord.VideoReader.seek", "decord.VideoReader.get_batch().asnumpy", "os.path.exists", "os.path.getsize", "print", "list", "list", "decord.VideoReader.seek", "decord.VideoReader.get_batch().asnumpy", "len", "list", "numpy.array", "os.path.getsize", "decord.VideoReader", "decord.VideoReader", "print", "len", "float", "numpy.array", "len", "list.append", "numpy.sort", "len", "list", "list", "decord.VideoReader.get_batch", "numpy.array", "decord.VideoReader.get_batch", "numpy.multiply", "numpy.random.randint", "numpy.sort", "numpy.zeros", "decord.cpu", "decord.cpu", "list", "numpy.random.randint", "int", "int", "range", "len", "range", "range"], "methods", ["None"], ["", "def", "loadvideo_decord", "(", "self", ",", "sample", ",", "sample_rate_scale", "=", "1", ")", ":", "\n", "        ", "\"\"\"Load video content using Decord\"\"\"", "\n", "fname", "=", "sample", "\n", "\n", "if", "not", "(", "os", ".", "path", ".", "exists", "(", "fname", ")", ")", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "# avoid hanging issue", "\n", "", "if", "os", ".", "path", ".", "getsize", "(", "fname", ")", "<", "1", "*", "1024", ":", "\n", "            ", "print", "(", "'SKIP: '", ",", "fname", ",", "\" - \"", ",", "os", ".", "path", ".", "getsize", "(", "fname", ")", ")", "\n", "return", "[", "]", "\n", "", "try", ":", "\n", "            ", "if", "self", ".", "keep_aspect_ratio", ":", "\n", "                ", "vr", "=", "VideoReader", "(", "fname", ",", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "vr", "=", "VideoReader", "(", "fname", ",", "width", "=", "self", ".", "new_width", ",", "height", "=", "self", ".", "new_height", ",", "\n", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "", "", "except", ":", "\n", "            ", "print", "(", "\"video cannot be loaded by decord: \"", ",", "fname", ")", "\n", "return", "[", "]", "\n", "\n", "", "if", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "all_index", "=", "[", "]", "\n", "tick", "=", "len", "(", "vr", ")", "/", "float", "(", "self", ".", "num_segment", ")", "\n", "all_index", "=", "list", "(", "np", ".", "array", "(", "[", "int", "(", "tick", "/", "2.0", "+", "tick", "*", "x", ")", "for", "x", "in", "range", "(", "self", ".", "num_segment", ")", "]", "+", "\n", "[", "int", "(", "tick", "*", "x", ")", "for", "x", "in", "range", "(", "self", ".", "num_segment", ")", "]", ")", ")", "\n", "while", "len", "(", "all_index", ")", "<", "(", "self", ".", "num_segment", "*", "self", ".", "test_num_segment", ")", ":", "\n", "                ", "all_index", ".", "append", "(", "all_index", "[", "-", "1", "]", ")", "\n", "", "all_index", "=", "list", "(", "np", ".", "sort", "(", "np", ".", "array", "(", "all_index", ")", ")", ")", "\n", "vr", ".", "seek", "(", "0", ")", "\n", "buffer", "=", "vr", ".", "get_batch", "(", "all_index", ")", ".", "asnumpy", "(", ")", "\n", "return", "buffer", "\n", "\n", "# handle temporal segments", "\n", "", "average_duration", "=", "len", "(", "vr", ")", "//", "self", ".", "num_segment", "\n", "all_index", "=", "[", "]", "\n", "if", "average_duration", ">", "0", ":", "\n", "            ", "all_index", "+=", "list", "(", "np", ".", "multiply", "(", "list", "(", "range", "(", "self", ".", "num_segment", ")", ")", ",", "average_duration", ")", "+", "np", ".", "random", ".", "randint", "(", "average_duration", ",", "\n", "size", "=", "self", ".", "num_segment", ")", ")", "\n", "", "elif", "len", "(", "vr", ")", ">", "self", ".", "num_segment", ":", "\n", "            ", "all_index", "+=", "list", "(", "np", ".", "sort", "(", "np", ".", "random", ".", "randint", "(", "len", "(", "vr", ")", ",", "size", "=", "self", ".", "num_segment", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "all_index", "+=", "list", "(", "np", ".", "zeros", "(", "(", "self", ".", "num_segment", ",", ")", ")", ")", "\n", "", "all_index", "=", "list", "(", "np", ".", "array", "(", "all_index", ")", ")", "\n", "vr", ".", "seek", "(", "0", ")", "\n", "buffer", "=", "vr", ".", "get_batch", "(", "all_index", ")", ".", "asnumpy", "(", ")", "\n", "return", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.ssv2.SSVideoClsDataset.__len__": [[265, 270], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mode", "!=", "'test'", ":", "\n", "            ", "return", "len", "(", "self", ".", "dataset_samples", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "test_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.ssv2.spatial_sampling": [[272, 344], ["video_transforms.random_short_side_scale_jitter", "video_transforms.uniform_crop", "video_transforms.random_short_side_scale_jitter", "video_transforms.random_crop", "transform_func", "video_transforms.horizontal_flip", "len"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.uniform_crop", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_crop", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.horizontal_flip"], ["", "", "", "def", "spatial_sampling", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "224", ",", "\n", "random_horizontal_flip", "=", "True", ",", "\n", "inverse_uniform_sampling", "=", "False", ",", "\n", "aspect_ratio", "=", "None", ",", "\n", "scale", "=", "None", ",", "\n", "motion_shift", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Perform spatial sampling on the given video frames. If spatial_idx is\n    -1, perform random scale, random crop, and random flip on the given\n    frames. If spatial_idx is 0, 1, or 2, perform spatial uniform sampling\n    with the given spatial_idx.\n    Args:\n        frames (tensor): frames of images sampled from the video. The\n            dimension is `num frames` x `height` x `width` x `channel`.\n        spatial_idx (int): if -1, perform random spatial sampling. If 0, 1,\n            or 2, perform left, center, right crop if width is larger than\n            height, and perform top, center, buttom crop if height is larger\n            than width.\n        min_scale (int): the minimal size of scaling.\n        max_scale (int): the maximal size of scaling.\n        crop_size (int): the size of height and width used to crop the\n            frames.\n        inverse_uniform_sampling (bool): if True, sample uniformly in\n            [1 / max_scale, 1 / min_scale] and take a reciprocal to get the\n            scale. If False, take a uniform sample from [min_scale,\n            max_scale].\n        aspect_ratio (list): Aspect ratio range for resizing.\n        scale (list): Scale range for resizing.\n        motion_shift (bool): Whether to apply motion shift for resizing.\n    Returns:\n        frames (tensor): spatially sampled frames.\n    \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "-", "1", ",", "0", ",", "1", ",", "2", "]", "\n", "if", "spatial_idx", "==", "-", "1", ":", "\n", "        ", "if", "aspect_ratio", "is", "None", "and", "scale", "is", "None", ":", "\n", "            ", "frames", ",", "_", "=", "video_transforms", ".", "random_short_side_scale_jitter", "(", "\n", "images", "=", "frames", ",", "\n", "min_size", "=", "min_scale", ",", "\n", "max_size", "=", "max_scale", ",", "\n", "inverse_uniform_sampling", "=", "inverse_uniform_sampling", ",", "\n", ")", "\n", "frames", ",", "_", "=", "video_transforms", ".", "random_crop", "(", "frames", ",", "crop_size", ")", "\n", "", "else", ":", "\n", "            ", "transform_func", "=", "(", "\n", "video_transforms", ".", "random_resized_crop_with_shift", "\n", "if", "motion_shift", "\n", "else", "video_transforms", ".", "random_resized_crop", "\n", ")", "\n", "frames", "=", "transform_func", "(", "\n", "images", "=", "frames", ",", "\n", "target_height", "=", "crop_size", ",", "\n", "target_width", "=", "crop_size", ",", "\n", "scale", "=", "scale", ",", "\n", "ratio", "=", "aspect_ratio", ",", "\n", ")", "\n", "", "if", "random_horizontal_flip", ":", "\n", "            ", "frames", ",", "_", "=", "video_transforms", ".", "horizontal_flip", "(", "0.5", ",", "frames", ")", "\n", "", "", "else", ":", "\n", "# The testing is deterministic and no jitter should be performed.", "\n", "# min_scale, max_scale, and crop_size are expect to be the same.", "\n", "        ", "assert", "len", "(", "{", "min_scale", ",", "max_scale", ",", "crop_size", "}", ")", "==", "1", "\n", "frames", ",", "_", "=", "video_transforms", ".", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", ",", "_", "=", "video_transforms", ".", "uniform_crop", "(", "frames", ",", "crop_size", ",", "spatial_idx", ")", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.ssv2.tensor_normalize": [[346, 364], ["tensor.float.float", "type", "torch.tensor", "type", "torch.tensor"], "function", ["None"], ["", "def", "tensor_normalize", "(", "tensor", ",", "mean", ",", "std", ")", ":", "\n", "    ", "\"\"\"\n    Normalize a given tensor by subtracting the mean and dividing the std.\n    Args:\n        tensor (tensor): tensor to normalize.\n        mean (tensor or list): mean value to subtract.\n        std (tensor or list): std to divide.\n    \"\"\"", "\n", "if", "tensor", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "        ", "tensor", "=", "tensor", ".", "float", "(", ")", "\n", "tensor", "=", "tensor", "/", "255.0", "\n", "", "if", "type", "(", "mean", ")", "==", "list", ":", "\n", "        ", "mean", "=", "torch", ".", "tensor", "(", "mean", ")", "\n", "", "if", "type", "(", "std", ")", "==", "list", ":", "\n", "        ", "std", "=", "torch", ".", "tensor", "(", "std", ")", "\n", "", "tensor", "=", "tensor", "-", "mean", "\n", "tensor", "=", "tensor", "/", "std", "\n", "return", "tensor", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.__init__": [[18, 81], ["pd.read_csv", "list", "list", "ImportError", "video_transforms.Compose", "video_transforms.Compose", "video_transforms.Compose", "range", "video_transforms.Resize", "video_transforms.CenterCrop", "volume_transforms.ClipToTensor", "video_transforms.Normalize", "range", "video_transforms.Resize", "volume_transforms.ClipToTensor", "video_transforms.Normalize", "range", "len", "kinetics.VideoClsDataset.test_label_array.append", "kinetics.VideoClsDataset.test_dataset.append", "kinetics.VideoClsDataset.test_seg.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "anno_path", ",", "data_path", ",", "mode", "=", "'train'", ",", "clip_len", "=", "8", ",", "\n", "frame_sample_rate", "=", "2", ",", "crop_size", "=", "224", ",", "short_side_size", "=", "256", ",", "\n", "new_height", "=", "256", ",", "new_width", "=", "340", ",", "keep_aspect_ratio", "=", "True", ",", "\n", "num_segment", "=", "1", ",", "num_crop", "=", "1", ",", "test_num_segment", "=", "10", ",", "test_num_crop", "=", "3", ",", "args", "=", "None", ")", ":", "\n", "        ", "self", ".", "anno_path", "=", "anno_path", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "clip_len", "=", "clip_len", "\n", "self", ".", "frame_sample_rate", "=", "frame_sample_rate", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "short_side_size", "=", "short_side_size", "\n", "self", ".", "new_height", "=", "new_height", "\n", "self", ".", "new_width", "=", "new_width", "\n", "self", ".", "keep_aspect_ratio", "=", "keep_aspect_ratio", "\n", "self", ".", "num_segment", "=", "num_segment", "\n", "self", ".", "test_num_segment", "=", "test_num_segment", "\n", "self", ".", "num_crop", "=", "num_crop", "\n", "self", ".", "test_num_crop", "=", "test_num_crop", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "aug", "=", "False", "\n", "self", ".", "rand_erase", "=", "False", "\n", "if", "self", ".", "mode", "in", "[", "'train'", "]", ":", "\n", "            ", "self", ".", "aug", "=", "True", "\n", "if", "self", ".", "args", ".", "reprob", ">", "0", ":", "\n", "                ", "self", ".", "rand_erase", "=", "True", "\n", "", "", "if", "VideoReader", "is", "None", ":", "\n", "            ", "raise", "ImportError", "(", "\"Unable to import `decord` which is required to read videos.\"", ")", "\n", "\n", "", "import", "pandas", "as", "pd", "\n", "cleaned", "=", "pd", ".", "read_csv", "(", "self", ".", "anno_path", ",", "header", "=", "None", ",", "delimiter", "=", "' '", ")", "\n", "self", ".", "dataset_samples", "=", "list", "(", "cleaned", ".", "values", "[", ":", ",", "0", "]", ")", "\n", "self", ".", "label_array", "=", "list", "(", "cleaned", ".", "values", "[", ":", ",", "1", "]", ")", "\n", "\n", "if", "(", "mode", "==", "'train'", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "elif", "(", "mode", "==", "'validation'", ")", ":", "\n", "            ", "self", ".", "data_transform", "=", "video_transforms", ".", "Compose", "(", "[", "\n", "video_transforms", ".", "Resize", "(", "self", ".", "short_side_size", ",", "interpolation", "=", "'bilinear'", ")", ",", "\n", "video_transforms", ".", "CenterCrop", "(", "size", "=", "(", "self", ".", "crop_size", ",", "self", ".", "crop_size", ")", ")", ",", "\n", "volume_transforms", ".", "ClipToTensor", "(", ")", ",", "\n", "video_transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "self", ".", "data_resize", "=", "video_transforms", ".", "Compose", "(", "[", "\n", "video_transforms", ".", "Resize", "(", "size", "=", "(", "short_side_size", ")", ",", "interpolation", "=", "'bilinear'", ")", "\n", "]", ")", "\n", "self", ".", "data_transform", "=", "video_transforms", ".", "Compose", "(", "[", "\n", "volume_transforms", ".", "ClipToTensor", "(", ")", ",", "\n", "video_transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "self", ".", "test_seg", "=", "[", "]", "\n", "self", ".", "test_dataset", "=", "[", "]", "\n", "self", ".", "test_label_array", "=", "[", "]", "\n", "for", "ck", "in", "range", "(", "self", ".", "test_num_segment", ")", ":", "\n", "                ", "for", "cp", "in", "range", "(", "self", ".", "test_num_crop", ")", ":", "\n", "                    ", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "label_array", ")", ")", ":", "\n", "                        ", "sample_label", "=", "self", ".", "label_array", "[", "idx", "]", "\n", "self", ".", "test_label_array", ".", "append", "(", "sample_label", ")", "\n", "self", ".", "test_dataset", ".", "append", "(", "self", ".", "dataset_samples", "[", "idx", "]", ")", "\n", "self", ".", "test_seg", ".", "append", "(", "(", "ck", ",", "cp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.__getitem__": [[82, 159], ["kinetics.VideoClsDataset.loadvideo_decord", "len", "range", "kinetics.VideoClsDataset._aug_frame", "kinetics.VideoClsDataset.loadvideo_decord", "kinetics.VideoClsDataset.data_transform", "len", "warnings.warn", "numpy.random.randint", "kinetics.VideoClsDataset.loadvideo_decord", "kinetics.VideoClsDataset._aug_frame", "frame_list.append", "label_list.append", "index_list.append", "len", "kinetics.VideoClsDataset.loadvideo_decord", "kinetics.VideoClsDataset.data_resize", "isinstance", "max", "int", "int", "kinetics.VideoClsDataset.data_transform", "NameError", "kinetics.VideoClsDataset.__len__", "len", "warnings.warn", "numpy.random.randint", "kinetics.VideoClsDataset.loadvideo_decord", "[].split", "len", "warnings.warn", "numpy.random.randint", "kinetics.VideoClsDataset.loadvideo_decord", "numpy.stack", "kinetics.VideoClsDataset.__len__", "kinetics.VideoClsDataset.__len__", "[].split", "str", "max", "sample.split", "sample.split"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset._aug_frame", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset._aug_frame", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__len__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__len__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__len__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "", "", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "args", "=", "self", ".", "args", "\n", "scale_t", "=", "1", "\n", "\n", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ",", "sample_rate_scale", "=", "scale_t", ")", "# T H W C", "\n", "if", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                ", "while", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\"video {} not correctly loaded during training\"", ".", "format", "(", "sample", ")", ")", "\n", "index", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "__len__", "(", ")", ")", "\n", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ",", "sample_rate_scale", "=", "scale_t", ")", "\n", "\n", "", "", "if", "args", ".", "num_sample", ">", "1", ":", "\n", "                ", "frame_list", "=", "[", "]", "\n", "label_list", "=", "[", "]", "\n", "index_list", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "args", ".", "num_sample", ")", ":", "\n", "                    ", "new_frames", "=", "self", ".", "_aug_frame", "(", "buffer", ",", "args", ")", "\n", "label", "=", "self", ".", "label_array", "[", "index", "]", "\n", "frame_list", ".", "append", "(", "new_frames", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "index_list", ".", "append", "(", "index", ")", "\n", "", "return", "frame_list", ",", "label_list", ",", "index_list", ",", "{", "}", "\n", "", "else", ":", "\n", "                ", "buffer", "=", "self", ".", "_aug_frame", "(", "buffer", ",", "args", ")", "\n", "\n", "", "return", "buffer", ",", "self", ".", "label_array", "[", "index", "]", ",", "index", ",", "{", "}", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'validation'", ":", "\n", "            ", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "if", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                ", "while", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\"video {} not correctly loaded during validation\"", ".", "format", "(", "sample", ")", ")", "\n", "index", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "__len__", "(", ")", ")", "\n", "sample", "=", "self", ".", "dataset_samples", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "", "", "buffer", "=", "self", ".", "data_transform", "(", "buffer", ")", "\n", "return", "buffer", ",", "self", ".", "label_array", "[", "index", "]", ",", "sample", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "sample", "=", "self", ".", "test_dataset", "[", "index", "]", "\n", "chunk_nb", ",", "split_nb", "=", "self", ".", "test_seg", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "\n", "while", "len", "(", "buffer", ")", "==", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"video {}, temporal {}, spatial {} not found during testing\"", ".", "format", "(", "str", "(", "self", ".", "test_dataset", "[", "index", "]", ")", ",", "chunk_nb", ",", "split_nb", ")", ")", "\n", "index", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "__len__", "(", ")", ")", "\n", "sample", "=", "self", ".", "test_dataset", "[", "index", "]", "\n", "chunk_nb", ",", "split_nb", "=", "self", ".", "test_seg", "[", "index", "]", "\n", "buffer", "=", "self", ".", "loadvideo_decord", "(", "sample", ")", "\n", "\n", "", "buffer", "=", "self", ".", "data_resize", "(", "buffer", ")", "\n", "if", "isinstance", "(", "buffer", ",", "list", ")", ":", "\n", "                ", "buffer", "=", "np", ".", "stack", "(", "buffer", ",", "0", ")", "\n", "\n", "", "spatial_step", "=", "1.0", "*", "(", "max", "(", "buffer", ".", "shape", "[", "1", "]", ",", "buffer", ".", "shape", "[", "2", "]", ")", "-", "self", ".", "short_side_size", ")", "/", "(", "self", ".", "test_num_crop", "-", "1", ")", "\n", "temporal_step", "=", "max", "(", "1.0", "*", "(", "buffer", ".", "shape", "[", "0", "]", "-", "self", ".", "clip_len", ")", "/", "(", "self", ".", "test_num_segment", "-", "1", ")", ",", "0", ")", "\n", "temporal_start", "=", "int", "(", "chunk_nb", "*", "temporal_step", ")", "\n", "spatial_start", "=", "int", "(", "split_nb", "*", "spatial_step", ")", "\n", "if", "buffer", ".", "shape", "[", "1", "]", ">=", "buffer", ".", "shape", "[", "2", "]", ":", "\n", "                ", "buffer", "=", "buffer", "[", "temporal_start", ":", "temporal_start", "+", "self", ".", "clip_len", ",", "spatial_start", ":", "spatial_start", "+", "self", ".", "short_side_size", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "buffer", "=", "buffer", "[", "temporal_start", ":", "temporal_start", "+", "self", ".", "clip_len", ",", ":", ",", "spatial_start", ":", "spatial_start", "+", "self", ".", "short_side_size", ",", ":", "]", "\n", "\n", "", "buffer", "=", "self", ".", "data_transform", "(", "buffer", ")", "\n", "return", "buffer", ",", "self", ".", "test_label_array", "[", "index", "]", ",", "sample", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "chunk_nb", ",", "split_nb", "\n", "", "else", ":", "\n", "            ", "raise", "NameError", "(", "'mode {} unkown'", ".", "format", "(", "self", ".", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset._aug_frame": [[160, 220], ["video_transforms.create_random_augment", "video_transforms.create_random_augment.", "torch.stack", "buffer.permute.permute.permute", "kinetics.tensor_normalize", "buffer.permute.permute.permute", "kinetics.spatial_sampling", "random_erasing.RandomErasing", "buffer.permute.permute.permute", "random_erasing.RandomErasing.", "buffer.permute.permute.permute", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToTensor"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.create_random_augment", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.tensor_normalize", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.spatial_sampling"], ["", "", "def", "_aug_frame", "(", "\n", "self", ",", "\n", "buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "\n", "        ", "aug_transform", "=", "video_transforms", ".", "create_random_augment", "(", "\n", "input_size", "=", "(", "self", ".", "crop_size", ",", "self", ".", "crop_size", ")", ",", "\n", "auto_augment", "=", "args", ".", "aa", ",", "\n", "interpolation", "=", "args", ".", "train_interpolation", ",", "\n", ")", "\n", "\n", "buffer", "=", "[", "\n", "transforms", ".", "ToPILImage", "(", ")", "(", "frame", ")", "for", "frame", "in", "buffer", "\n", "]", "\n", "\n", "buffer", "=", "aug_transform", "(", "buffer", ")", "\n", "\n", "buffer", "=", "[", "transforms", ".", "ToTensor", "(", ")", "(", "img", ")", "for", "img", "in", "buffer", "]", "\n", "buffer", "=", "torch", ".", "stack", "(", "buffer", ")", "# T C H W", "\n", "buffer", "=", "buffer", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# T H W C ", "\n", "\n", "# T H W C ", "\n", "buffer", "=", "tensor_normalize", "(", "\n", "buffer", ",", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "# T H W C -> C T H W.", "\n", "buffer", "=", "buffer", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "# Perform data augmentation.", "\n", "scl", ",", "asp", "=", "(", "\n", "[", "0.08", ",", "1.0", "]", ",", "\n", "[", "0.75", ",", "1.3333", "]", ",", "\n", ")", "\n", "\n", "buffer", "=", "spatial_sampling", "(", "\n", "buffer", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "self", ".", "crop_size", ",", "\n", "random_horizontal_flip", "=", "False", "if", "args", ".", "data_set", "==", "'SSV2'", "else", "True", ",", "\n", "inverse_uniform_sampling", "=", "False", ",", "\n", "aspect_ratio", "=", "asp", ",", "\n", "scale", "=", "scl", ",", "\n", "motion_shift", "=", "False", "\n", ")", "\n", "\n", "if", "self", ".", "rand_erase", ":", "\n", "            ", "erase_transform", "=", "RandomErasing", "(", "\n", "args", ".", "reprob", ",", "\n", "mode", "=", "args", ".", "remode", ",", "\n", "max_count", "=", "args", ".", "recount", ",", "\n", "num_splits", "=", "args", ".", "recount", ",", "\n", "device", "=", "\"cpu\"", ",", "\n", ")", "\n", "buffer", "=", "buffer", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "buffer", "=", "erase_transform", "(", "buffer", ")", "\n", "buffer", "=", "buffer", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "", "return", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.loadvideo_decord": [[222, 273], ["int", "range", "decord.VideoReader.seek", "decord.VideoReader.get_batch().asnumpy", "os.path.exists", "os.path.getsize", "print", "decord.VideoReader.seek", "decord.VideoReader.get_batch().asnumpy", "len", "all_index.extend", "os.path.getsize", "decord.VideoReader", "decord.VideoReader", "print", "len", "all_index.append", "numpy.linspace", "numpy.concatenate", "numpy.clip().astype", "numpy.random.randint", "numpy.linspace", "numpy.clip().astype", "list", "int", "decord.VideoReader.get_batch", "range", "decord.VideoReader.get_batch", "decord.cpu", "decord.cpu", "len", "numpy.clip", "numpy.clip", "numpy.ones"], "methods", ["None"], ["", "def", "loadvideo_decord", "(", "self", ",", "sample", ",", "sample_rate_scale", "=", "1", ")", ":", "\n", "        ", "\"\"\"Load video content using Decord\"\"\"", "\n", "fname", "=", "sample", "\n", "\n", "if", "not", "(", "os", ".", "path", ".", "exists", "(", "fname", ")", ")", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "# avoid hanging issue", "\n", "", "if", "os", ".", "path", ".", "getsize", "(", "fname", ")", "<", "1", "*", "1024", ":", "\n", "            ", "print", "(", "'SKIP: '", ",", "fname", ",", "\" - \"", ",", "os", ".", "path", ".", "getsize", "(", "fname", ")", ")", "\n", "return", "[", "]", "\n", "", "try", ":", "\n", "            ", "if", "self", ".", "keep_aspect_ratio", ":", "\n", "                ", "vr", "=", "VideoReader", "(", "fname", ",", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "vr", "=", "VideoReader", "(", "fname", ",", "width", "=", "self", ".", "new_width", ",", "height", "=", "self", ".", "new_height", ",", "\n", "num_threads", "=", "1", ",", "ctx", "=", "cpu", "(", "0", ")", ")", "\n", "", "", "except", ":", "\n", "            ", "print", "(", "\"video cannot be loaded by decord: \"", ",", "fname", ")", "\n", "return", "[", "]", "\n", "\n", "", "if", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "all_index", "=", "[", "x", "for", "x", "in", "range", "(", "0", ",", "len", "(", "vr", ")", ",", "self", ".", "frame_sample_rate", ")", "]", "\n", "while", "len", "(", "all_index", ")", "<", "self", ".", "clip_len", ":", "\n", "                ", "all_index", ".", "append", "(", "all_index", "[", "-", "1", "]", ")", "\n", "", "vr", ".", "seek", "(", "0", ")", "\n", "buffer", "=", "vr", ".", "get_batch", "(", "all_index", ")", ".", "asnumpy", "(", ")", "\n", "return", "buffer", "\n", "\n", "# handle temporal segments", "\n", "", "converted_len", "=", "int", "(", "self", ".", "clip_len", "*", "self", ".", "frame_sample_rate", ")", "\n", "seg_len", "=", "len", "(", "vr", ")", "//", "self", ".", "num_segment", "\n", "\n", "all_index", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_segment", ")", ":", "\n", "            ", "if", "seg_len", "<=", "converted_len", ":", "\n", "                ", "index", "=", "np", ".", "linspace", "(", "0", ",", "seg_len", ",", "num", "=", "seg_len", "//", "self", ".", "frame_sample_rate", ")", "\n", "index", "=", "np", ".", "concatenate", "(", "(", "index", ",", "np", ".", "ones", "(", "self", ".", "clip_len", "-", "seg_len", "//", "self", ".", "frame_sample_rate", ")", "*", "seg_len", ")", ")", "\n", "index", "=", "np", ".", "clip", "(", "index", ",", "0", ",", "seg_len", "-", "1", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "", "else", ":", "\n", "                ", "end_idx", "=", "np", ".", "random", ".", "randint", "(", "converted_len", ",", "seg_len", ")", "\n", "str_idx", "=", "end_idx", "-", "converted_len", "\n", "index", "=", "np", ".", "linspace", "(", "str_idx", ",", "end_idx", ",", "num", "=", "self", ".", "clip_len", ")", "\n", "index", "=", "np", ".", "clip", "(", "index", ",", "str_idx", ",", "end_idx", "-", "1", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "", "index", "=", "index", "+", "i", "*", "seg_len", "\n", "all_index", ".", "extend", "(", "list", "(", "index", ")", ")", "\n", "\n", "", "all_index", "=", "all_index", "[", ":", ":", "int", "(", "sample_rate_scale", ")", "]", "\n", "vr", ".", "seek", "(", "0", ")", "\n", "buffer", "=", "vr", ".", "get_batch", "(", "all_index", ")", ".", "asnumpy", "(", ")", "\n", "return", "buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoClsDataset.__len__": [[274, 279], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mode", "!=", "'test'", ":", "\n", "            ", "return", "len", "(", "self", ".", "dataset_samples", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "test_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__init__": [[425, 469], ["super().__init__", "kinetics.VideoMAE._make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE._make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "root", ",", "\n", "setting", ",", "\n", "train", "=", "True", ",", "\n", "test_mode", "=", "False", ",", "\n", "name_pattern", "=", "'img_%05d.jpg'", ",", "\n", "video_ext", "=", "'mp4'", ",", "\n", "is_color", "=", "True", ",", "\n", "modality", "=", "'rgb'", ",", "\n", "num_segments", "=", "1", ",", "\n", "num_crop", "=", "1", ",", "\n", "new_length", "=", "1", ",", "\n", "new_step", "=", "1", ",", "\n", "transform", "=", "None", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "video_loader", "=", "False", ",", "\n", "use_decord", "=", "False", ",", "\n", "lazy_init", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", "VideoMAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "setting", "=", "setting", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "is_color", "=", "is_color", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "num_crop", "=", "num_crop", "\n", "self", ".", "new_length", "=", "new_length", "\n", "self", ".", "new_step", "=", "new_step", "\n", "self", ".", "skip_length", "=", "self", ".", "new_length", "*", "self", ".", "new_step", "\n", "self", ".", "temporal_jitter", "=", "temporal_jitter", "\n", "self", ".", "name_pattern", "=", "name_pattern", "\n", "self", ".", "video_loader", "=", "video_loader", "\n", "self", ".", "video_ext", "=", "video_ext", "\n", "self", ".", "use_decord", "=", "use_decord", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "lazy_init", "=", "lazy_init", "\n", "\n", "\n", "if", "not", "self", ".", "lazy_init", ":", "\n", "            ", "self", ".", "clips", "=", "self", ".", "_make_dataset", "(", "root", ",", "setting", ")", "\n", "if", "len", "(", "self", ".", "clips", ")", "==", "0", ":", "\n", "                ", "raise", "(", "RuntimeError", "(", "\"Found 0 video clips in subfolders of: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Check your data directory (opt.data-dir).\"", ")", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__getitem__": [[471, 494], ["kinetics.VideoMAE._sample_train_indices", "kinetics.VideoMAE._video_TSN_decord_batch_loader", "kinetics.VideoMAE.transform", "process_data.view().transpose.view().transpose.view().transpose", "decord.VideoReader", "len", "process_data.view().transpose.view().transpose.view", "directory.split", "process_data.view().transpose.view().transpose.size"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE._sample_train_indices", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE._video_TSN_decord_batch_loader"], ["", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "directory", ",", "target", "=", "self", ".", "clips", "[", "index", "]", "\n", "if", "self", ".", "video_loader", ":", "\n", "            ", "if", "'.'", "in", "directory", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ":", "\n", "# data in the \"setting\" file already have extension, e.g., demo.mp4", "\n", "                ", "video_name", "=", "directory", "\n", "", "else", ":", "\n", "# data in the \"setting\" file do not have extension, e.g., demo", "\n", "# So we need to provide extension (i.e., .mp4) to complete the file name.", "\n", "                ", "video_name", "=", "'{}.{}'", ".", "format", "(", "directory", ",", "self", ".", "video_ext", ")", "\n", "\n", "", "decord_vr", "=", "decord", ".", "VideoReader", "(", "video_name", ",", "num_threads", "=", "1", ")", "\n", "duration", "=", "len", "(", "decord_vr", ")", "\n", "\n", "", "segment_indices", ",", "skip_offsets", "=", "self", ".", "_sample_train_indices", "(", "duration", ")", "\n", "\n", "images", "=", "self", ".", "_video_TSN_decord_batch_loader", "(", "directory", ",", "decord_vr", ",", "duration", ",", "segment_indices", ",", "skip_offsets", ")", "\n", "\n", "process_data", ",", "mask", "=", "self", ".", "transform", "(", "(", "images", ",", "None", ")", ")", "# T*C,H,W", "\n", "process_data", "=", "process_data", ".", "view", "(", "(", "self", ".", "new_length", ",", "3", ")", "+", "process_data", ".", "size", "(", ")", "[", "-", "2", ":", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "# T*C,H,W -> T,C,H,W -> C,T,H,W", "\n", "\n", "return", "(", "process_data", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE.__len__": [[495, 497], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "clips", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE._make_dataset": [[498, 514], ["os.path.exists", "RuntimeError", "open", "split_f.readlines", "line.split", "os.path.join", "int", "clips.append", "len", "RuntimeError"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ",", "directory", ",", "setting", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "setting", ")", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Setting file %s doesn't exist. Check opt.train-list and opt.val-list. \"", "%", "(", "setting", ")", ")", ")", "\n", "", "clips", "=", "[", "]", "\n", "with", "open", "(", "setting", ")", "as", "split_f", ":", "\n", "            ", "data", "=", "split_f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "data", ":", "\n", "                ", "line_info", "=", "line", ".", "split", "(", "' '", ")", "\n", "# line format: video_path, video_duration, video_label", "\n", "if", "len", "(", "line_info", ")", "<", "2", ":", "\n", "                    ", "raise", "(", "RuntimeError", "(", "'Video input format is not correct, missing one or more element. %s'", "%", "line", ")", ")", "\n", "", "clip_path", "=", "os", ".", "path", ".", "join", "(", "line_info", "[", "0", "]", ")", "\n", "target", "=", "int", "(", "line_info", "[", "1", "]", ")", "\n", "item", "=", "(", "clip_path", ",", "target", ")", "\n", "clips", ".", "append", "(", "item", ")", "\n", "", "", "return", "clips", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE._sample_train_indices": [[515, 536], ["numpy.multiply", "numpy.random.randint", "numpy.zeros", "list", "numpy.random.randint", "max", "numpy.sort", "numpy.zeros", "range", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "def", "_sample_train_indices", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "average_duration", "=", "(", "num_frames", "-", "self", ".", "skip_length", "+", "1", ")", "//", "self", ".", "num_segments", "\n", "if", "average_duration", ">", "0", ":", "\n", "            ", "offsets", "=", "np", ".", "multiply", "(", "list", "(", "range", "(", "self", ".", "num_segments", ")", ")", ",", "\n", "average_duration", ")", "\n", "offsets", "=", "offsets", "+", "np", ".", "random", ".", "randint", "(", "average_duration", ",", "\n", "size", "=", "self", ".", "num_segments", ")", "\n", "", "elif", "num_frames", ">", "max", "(", "self", ".", "num_segments", ",", "self", ".", "skip_length", ")", ":", "\n", "            ", "offsets", "=", "np", ".", "sort", "(", "np", ".", "random", ".", "randint", "(", "\n", "num_frames", "-", "self", ".", "skip_length", "+", "1", ",", "\n", "size", "=", "self", ".", "num_segments", ")", ")", "\n", "", "else", ":", "\n", "            ", "offsets", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_segments", ",", ")", ")", "\n", "\n", "", "if", "self", ".", "temporal_jitter", ":", "\n", "            ", "skip_offsets", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "new_step", ",", "size", "=", "self", ".", "skip_length", "//", "self", ".", "new_step", ")", "\n", "", "else", ":", "\n", "            ", "skip_offsets", "=", "np", ".", "zeros", "(", "\n", "self", ".", "skip_length", "//", "self", ".", "new_step", ",", "dtype", "=", "int", ")", "\n", "", "return", "offsets", "+", "1", ",", "skip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.VideoMAE._video_TSN_decord_batch_loader": [[538, 557], ["int", "enumerate", "video_reader.get_batch().asnumpy", "range", "frame_id_list.append", "PIL.Image.fromarray().convert", "RuntimeError", "video_reader.get_batch", "enumerate", "PIL.Image.fromarray"], "methods", ["None"], ["", "def", "_video_TSN_decord_batch_loader", "(", "self", ",", "directory", ",", "video_reader", ",", "duration", ",", "indices", ",", "skip_offsets", ")", ":", "\n", "        ", "sampled_list", "=", "[", "]", "\n", "frame_id_list", "=", "[", "]", "\n", "for", "seg_ind", "in", "indices", ":", "\n", "            ", "offset", "=", "int", "(", "seg_ind", ")", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "range", "(", "0", ",", "self", ".", "skip_length", ",", "self", ".", "new_step", ")", ")", ":", "\n", "                ", "if", "offset", "+", "skip_offsets", "[", "i", "]", "<=", "duration", ":", "\n", "                    ", "frame_id", "=", "offset", "+", "skip_offsets", "[", "i", "]", "-", "1", "\n", "", "else", ":", "\n", "                    ", "frame_id", "=", "offset", "-", "1", "\n", "", "frame_id_list", ".", "append", "(", "frame_id", ")", "\n", "if", "offset", "+", "self", ".", "new_step", "<", "duration", ":", "\n", "                    ", "offset", "+=", "self", ".", "new_step", "\n", "", "", "", "try", ":", "\n", "            ", "video_data", "=", "video_reader", ".", "get_batch", "(", "frame_id_list", ")", ".", "asnumpy", "(", ")", "\n", "sampled_list", "=", "[", "Image", ".", "fromarray", "(", "video_data", "[", "vid", ",", ":", ",", ":", ",", ":", "]", ")", ".", "convert", "(", "'RGB'", ")", "for", "vid", ",", "_", "in", "enumerate", "(", "frame_id_list", ")", "]", "\n", "", "except", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error occured in reading frames {} from video {} of duration {}.'", ".", "format", "(", "frame_id_list", ",", "directory", ",", "duration", ")", ")", "\n", "", "return", "sampled_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.spatial_sampling": [[281, 353], ["video_transforms.random_short_side_scale_jitter", "video_transforms.uniform_crop", "video_transforms.random_short_side_scale_jitter", "video_transforms.random_crop", "transform_func", "video_transforms.horizontal_flip", "len"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.uniform_crop", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.random_crop", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.video_transforms.horizontal_flip"], ["", "", "", "def", "spatial_sampling", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "224", ",", "\n", "random_horizontal_flip", "=", "True", ",", "\n", "inverse_uniform_sampling", "=", "False", ",", "\n", "aspect_ratio", "=", "None", ",", "\n", "scale", "=", "None", ",", "\n", "motion_shift", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Perform spatial sampling on the given video frames. If spatial_idx is\n    -1, perform random scale, random crop, and random flip on the given\n    frames. If spatial_idx is 0, 1, or 2, perform spatial uniform sampling\n    with the given spatial_idx.\n    Args:\n        frames (tensor): frames of images sampled from the video. The\n            dimension is `num frames` x `height` x `width` x `channel`.\n        spatial_idx (int): if -1, perform random spatial sampling. If 0, 1,\n            or 2, perform left, center, right crop if width is larger than\n            height, and perform top, center, buttom crop if height is larger\n            than width.\n        min_scale (int): the minimal size of scaling.\n        max_scale (int): the maximal size of scaling.\n        crop_size (int): the size of height and width used to crop the\n            frames.\n        inverse_uniform_sampling (bool): if True, sample uniformly in\n            [1 / max_scale, 1 / min_scale] and take a reciprocal to get the\n            scale. If False, take a uniform sample from [min_scale,\n            max_scale].\n        aspect_ratio (list): Aspect ratio range for resizing.\n        scale (list): Scale range for resizing.\n        motion_shift (bool): Whether to apply motion shift for resizing.\n    Returns:\n        frames (tensor): spatially sampled frames.\n    \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "-", "1", ",", "0", ",", "1", ",", "2", "]", "\n", "if", "spatial_idx", "==", "-", "1", ":", "\n", "        ", "if", "aspect_ratio", "is", "None", "and", "scale", "is", "None", ":", "\n", "            ", "frames", ",", "_", "=", "video_transforms", ".", "random_short_side_scale_jitter", "(", "\n", "images", "=", "frames", ",", "\n", "min_size", "=", "min_scale", ",", "\n", "max_size", "=", "max_scale", ",", "\n", "inverse_uniform_sampling", "=", "inverse_uniform_sampling", ",", "\n", ")", "\n", "frames", ",", "_", "=", "video_transforms", ".", "random_crop", "(", "frames", ",", "crop_size", ")", "\n", "", "else", ":", "\n", "            ", "transform_func", "=", "(", "\n", "video_transforms", ".", "random_resized_crop_with_shift", "\n", "if", "motion_shift", "\n", "else", "video_transforms", ".", "random_resized_crop", "\n", ")", "\n", "frames", "=", "transform_func", "(", "\n", "images", "=", "frames", ",", "\n", "target_height", "=", "crop_size", ",", "\n", "target_width", "=", "crop_size", ",", "\n", "scale", "=", "scale", ",", "\n", "ratio", "=", "aspect_ratio", ",", "\n", ")", "\n", "", "if", "random_horizontal_flip", ":", "\n", "            ", "frames", ",", "_", "=", "video_transforms", ".", "horizontal_flip", "(", "0.5", ",", "frames", ")", "\n", "", "", "else", ":", "\n", "# The testing is deterministic and no jitter should be performed.", "\n", "# min_scale, max_scale, and crop_size are expect to be the same.", "\n", "        ", "assert", "len", "(", "{", "min_scale", ",", "max_scale", ",", "crop_size", "}", ")", "==", "1", "\n", "frames", ",", "_", "=", "video_transforms", ".", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", ",", "_", "=", "video_transforms", ".", "uniform_crop", "(", "frames", ",", "crop_size", ",", "spatial_idx", ")", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.kinetics.tensor_normalize": [[355, 373], ["tensor.float.float", "type", "torch.tensor", "type", "torch.tensor"], "function", ["None"], ["", "def", "tensor_normalize", "(", "tensor", ",", "mean", ",", "std", ")", ":", "\n", "    ", "\"\"\"\n    Normalize a given tensor by subtracting the mean and dividing the std.\n    Args:\n        tensor (tensor): tensor to normalize.\n        mean (tensor or list): mean value to subtract.\n        std (tensor or list): std to divide.\n    \"\"\"", "\n", "if", "tensor", ".", "dtype", "==", "torch", ".", "uint8", ":", "\n", "        ", "tensor", "=", "tensor", ".", "float", "(", ")", "\n", "tensor", "=", "tensor", "/", "255.0", "\n", "", "if", "type", "(", "mean", ")", "==", "list", ":", "\n", "        ", "mean", "=", "torch", ".", "tensor", "(", "mean", ")", "\n", "", "if", "type", "(", "std", ")", "==", "list", ":", "\n", "        ", "std", "=", "torch", ".", "tensor", "(", "std", ")", "\n", "", "tensor", "=", "tensor", "-", "mean", "\n", "tensor", "=", "tensor", "/", "std", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_pretraining.train_one_epoch": [[10, 106], ["model.train", "utils.MetricLogger", "utils.MetricLogger.add_meter", "utils.MetricLogger.add_meter", "torch.MSELoss", "enumerate", "utils.MetricLogger.synchronize_between_processes", "print", "utils.SmoothedValue", "utils.SmoothedValue", "utils.MetricLogger.log_every", "videos.to.to", "bool_masked_pos.to().flatten().to.to().flatten().to", "loss_func.item", "optimizer.zero_grad", "loss_scaler", "torch.cuda.synchronize", "torch.cuda.synchronize", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "utils.MetricLogger.update", "enumerate", "torch.no_grad", "torch.no_grad", "videos_patch[].reshape", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "model", "nn.MSELoss.", "math.isfinite", "print", "sys.exit", "hasattr", "loss_scaler.state_dict", "min", "max", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.update", "log_writer.set_step", "lr_scheduler.step_update", "utils.MetricLogger.meters.items", "bool_masked_pos.to().flatten().to.to().flatten", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "einops.rearrange", "einops.rearrange", "einops.rearrange", "model.parameters", "bool_masked_pos.to().flatten().to.to", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "einops.rearrange.mean", "einops.rearrange.var().sqrt", "einops.rearrange.var"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.add_meter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.add_meter", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.synchronize_between_processes", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.log_every", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.set_step"], ["def", "train_one_epoch", "(", "model", ":", "torch", ".", "nn", ".", "Module", ",", "data_loader", ":", "Iterable", ",", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "device", ":", "torch", ".", "device", ",", "epoch", ":", "int", ",", "loss_scaler", ",", "max_norm", ":", "float", "=", "0", ",", "patch_size", ":", "int", "=", "16", ",", "\n", "normlize_target", ":", "bool", "=", "True", ",", "log_writer", "=", "None", ",", "lr_scheduler", "=", "None", ",", "start_steps", "=", "None", ",", "\n", "lr_schedule_values", "=", "None", ",", "wd_schedule_values", "=", "None", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "metric_logger", "=", "utils", ".", "MetricLogger", "(", "delimiter", "=", "\"  \"", ")", "\n", "metric_logger", ".", "add_meter", "(", "'lr'", ",", "utils", ".", "SmoothedValue", "(", "window_size", "=", "1", ",", "fmt", "=", "'{value:.6f}'", ")", ")", "\n", "metric_logger", ".", "add_meter", "(", "'min_lr'", ",", "utils", ".", "SmoothedValue", "(", "window_size", "=", "1", ",", "fmt", "=", "'{value:.6f}'", ")", ")", "\n", "header", "=", "'Epoch: [{}]'", ".", "format", "(", "epoch", ")", "\n", "print_freq", "=", "10", "\n", "\n", "loss_func", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "metric_logger", ".", "log_every", "(", "data_loader", ",", "print_freq", ",", "header", ")", ")", ":", "\n", "# assign learning rate & weight decay for each step", "\n", "        ", "it", "=", "start_steps", "+", "step", "# global training iteration", "\n", "if", "lr_schedule_values", "is", "not", "None", "or", "wd_schedule_values", "is", "not", "None", ":", "\n", "            ", "for", "i", ",", "param_group", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "                ", "if", "lr_schedule_values", "is", "not", "None", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "lr_schedule_values", "[", "it", "]", "*", "param_group", "[", "\"lr_scale\"", "]", "\n", "", "if", "wd_schedule_values", "is", "not", "None", "and", "param_group", "[", "\"weight_decay\"", "]", ">", "0", ":", "\n", "                    ", "param_group", "[", "\"weight_decay\"", "]", "=", "wd_schedule_values", "[", "it", "]", "\n", "\n", "", "", "", "videos", ",", "bool_masked_pos", "=", "batch", "\n", "videos", "=", "videos", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "bool_masked_pos", "=", "bool_masked_pos", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", ".", "flatten", "(", "1", ")", ".", "to", "(", "torch", ".", "bool", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# calculate the predict label", "\n", "            ", "mean", "=", "torch", ".", "as_tensor", "(", "IMAGENET_DEFAULT_MEAN", ")", ".", "to", "(", "device", ")", "[", "None", ",", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "std", "=", "torch", ".", "as_tensor", "(", "IMAGENET_DEFAULT_STD", ")", ".", "to", "(", "device", ")", "[", "None", ",", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "unnorm_videos", "=", "videos", "*", "std", "+", "mean", "# in [0, 1]", "\n", "\n", "if", "normlize_target", ":", "\n", "                ", "videos_squeeze", "=", "rearrange", "(", "unnorm_videos", ",", "'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2) c'", ",", "p0", "=", "2", ",", "p1", "=", "patch_size", ",", "p2", "=", "patch_size", ")", "\n", "videos_norm", "=", "(", "videos_squeeze", "-", "videos_squeeze", ".", "mean", "(", "dim", "=", "-", "2", ",", "keepdim", "=", "True", ")", "\n", ")", "/", "(", "videos_squeeze", ".", "var", "(", "dim", "=", "-", "2", ",", "unbiased", "=", "True", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "1e-6", ")", "\n", "# we find that the mean is about 0.48 and standard deviation is about 0.08.", "\n", "videos_patch", "=", "rearrange", "(", "videos_norm", ",", "'b n p c -> b n (p c)'", ")", "\n", "", "else", ":", "\n", "                ", "videos_patch", "=", "rearrange", "(", "unnorm_videos", ",", "'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)'", ",", "p0", "=", "2", ",", "p1", "=", "patch_size", ",", "p2", "=", "patch_size", ")", "\n", "\n", "", "B", ",", "_", ",", "C", "=", "videos_patch", ".", "shape", "\n", "labels", "=", "videos_patch", "[", "bool_masked_pos", "]", ".", "reshape", "(", "B", ",", "-", "1", ",", "C", ")", "\n", "\n", "", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "videos", ",", "bool_masked_pos", ")", "\n", "loss", "=", "loss_func", "(", "input", "=", "outputs", ",", "target", "=", "labels", ")", "\n", "\n", "", "loss_value", "=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "not", "math", ".", "isfinite", "(", "loss_value", ")", ":", "\n", "            ", "print", "(", "\"Loss is {}, stopping training\"", ".", "format", "(", "loss_value", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "# this attribute is added by timm on one optimizer (adahessian)", "\n", "is_second_order", "=", "hasattr", "(", "optimizer", ",", "'is_second_order'", ")", "and", "optimizer", ".", "is_second_order", "\n", "grad_norm", "=", "loss_scaler", "(", "loss", ",", "optimizer", ",", "clip_grad", "=", "max_norm", ",", "\n", "parameters", "=", "model", ".", "parameters", "(", ")", ",", "create_graph", "=", "is_second_order", ")", "\n", "loss_scale_value", "=", "loss_scaler", ".", "state_dict", "(", ")", "[", "\"scale\"", "]", "\n", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "metric_logger", ".", "update", "(", "loss", "=", "loss_value", ")", "\n", "metric_logger", ".", "update", "(", "loss_scale", "=", "loss_scale_value", ")", "\n", "min_lr", "=", "10.", "\n", "max_lr", "=", "0.", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "min_lr", "=", "min", "(", "min_lr", ",", "group", "[", "\"lr\"", "]", ")", "\n", "max_lr", "=", "max", "(", "max_lr", ",", "group", "[", "\"lr\"", "]", ")", "\n", "\n", "", "metric_logger", ".", "update", "(", "lr", "=", "max_lr", ")", "\n", "metric_logger", ".", "update", "(", "min_lr", "=", "min_lr", ")", "\n", "weight_decay_value", "=", "None", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "if", "group", "[", "\"weight_decay\"", "]", ">", "0", ":", "\n", "                ", "weight_decay_value", "=", "group", "[", "\"weight_decay\"", "]", "\n", "", "", "metric_logger", ".", "update", "(", "weight_decay", "=", "weight_decay_value", ")", "\n", "metric_logger", ".", "update", "(", "grad_norm", "=", "grad_norm", ")", "\n", "\n", "if", "log_writer", "is", "not", "None", ":", "\n", "            ", "log_writer", ".", "update", "(", "loss", "=", "loss_value", ",", "head", "=", "\"loss\"", ")", "\n", "log_writer", ".", "update", "(", "loss_scale", "=", "loss_scale_value", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "lr", "=", "max_lr", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "min_lr", "=", "min_lr", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "weight_decay", "=", "weight_decay_value", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "update", "(", "grad_norm", "=", "grad_norm", ",", "head", "=", "\"opt\"", ")", "\n", "log_writer", ".", "set_step", "(", ")", "\n", "\n", "", "if", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "lr_scheduler", ".", "step_update", "(", "start_steps", "+", "step", ")", "\n", "# gather the stats from all processes", "\n", "", "", "metric_logger", ".", "synchronize_between_processes", "(", ")", "\n", "print", "(", "\"Averaged stats:\"", ",", "metric_logger", ")", "\n", "return", "{", "k", ":", "meter", ".", "global_avg", "for", "k", ",", "meter", "in", "metric_logger", ".", "meters", ".", "items", "(", ")", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.masking_generator.TubeMaskingGenerator.__init__": [[4, 10], ["int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "mask_ratio", ")", ":", "\n", "        ", "self", ".", "frames", ",", "self", ".", "height", ",", "self", ".", "width", "=", "input_size", "\n", "self", ".", "num_patches_per_frame", "=", "self", ".", "height", "*", "self", ".", "width", "\n", "self", ".", "total_patches", "=", "self", ".", "frames", "*", "self", ".", "num_patches_per_frame", "\n", "self", ".", "num_masks_per_frame", "=", "int", "(", "mask_ratio", "*", "self", ".", "num_patches_per_frame", ")", "\n", "self", ".", "total_masks", "=", "self", ".", "frames", "*", "self", ".", "num_masks_per_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.masking_generator.TubeMaskingGenerator.__repr__": [[11, 16], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "\"Maks: total patches {}, mask patches {}\"", ".", "format", "(", "\n", "self", ".", "total_patches", ",", "self", ".", "total_masks", "\n", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.masking_generator.TubeMaskingGenerator.__call__": [[17, 25], ["numpy.hstack", "numpy.random.shuffle", "numpy.tile().flatten", "numpy.zeros", "numpy.ones", "numpy.tile"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "mask_per_frame", "=", "np", ".", "hstack", "(", "[", "\n", "np", ".", "zeros", "(", "self", ".", "num_patches_per_frame", "-", "self", ".", "num_masks_per_frame", ")", ",", "\n", "np", ".", "ones", "(", "self", ".", "num_masks_per_frame", ")", ",", "\n", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "mask_per_frame", ")", "\n", "mask", "=", "np", ".", "tile", "(", "mask_per_frame", ",", "(", "self", ".", "frames", ",", "1", ")", ")", ".", "flatten", "(", ")", "\n", "return", "mask", "", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional._is_tensor_clip": [[8, 10], ["torch.is_tensor", "clip.ndimension"], "function", ["None"], ["def", "_is_tensor_clip", "(", "clip", ")", ":", "\n", "    ", "return", "torch", ".", "is_tensor", "(", "clip", ")", "and", "clip", ".", "ndimension", "(", ")", "==", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.crop_clip": [[12, 24], ["isinstance", "isinstance", "TypeError", "img.crop", "type"], "function", ["None"], ["", "def", "crop_clip", "(", "clip", ",", "min_h", ",", "min_w", ",", "h", ",", "w", ")", ":", "\n", "    ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "cropped", "=", "[", "img", "[", "min_h", ":", "min_h", "+", "h", ",", "min_w", ":", "min_w", "+", "w", ",", ":", "]", "for", "img", "in", "clip", "]", "\n", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "        ", "cropped", "=", "[", "\n", "img", ".", "crop", "(", "(", "min_w", ",", "min_h", ",", "min_w", "+", "w", ",", "min_h", "+", "h", ")", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.resize_clip": [[26, 65], ["isinstance", "isinstance", "isinstance", "functional.get_resize_sizes", "cv2.resize", "isinstance", "TypeError", "functional.get_resize_sizes", "img.resize", "type"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.get_resize_sizes", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.get_resize_sizes"], ["", "def", "resize_clip", "(", "clip", ",", "size", ",", "interpolation", "=", "'bilinear'", ")", ":", "\n", "    ", "if", "isinstance", "(", "clip", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "im_h", ",", "im_w", ",", "im_c", "=", "clip", "[", "0", "]", ".", "shape", "\n", "# Min spatial dim already matches minimal size", "\n", "if", "(", "im_w", "<=", "im_h", "and", "im_w", "==", "size", ")", "or", "(", "im_h", "<=", "im_w", "\n", "and", "im_h", "==", "size", ")", ":", "\n", "                ", "return", "clip", "\n", "", "new_h", ",", "new_w", "=", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", "\n", "size", "=", "(", "new_w", ",", "new_h", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "size", "[", "0", "]", ",", "size", "[", "1", "]", "\n", "", "if", "interpolation", "==", "'bilinear'", ":", "\n", "            ", "np_inter", "=", "cv2", ".", "INTER_LINEAR", "\n", "", "else", ":", "\n", "            ", "np_inter", "=", "cv2", ".", "INTER_NEAREST", "\n", "", "scaled", "=", "[", "\n", "cv2", ".", "resize", "(", "img", ",", "size", ",", "interpolation", "=", "np_inter", ")", "for", "img", "in", "clip", "\n", "]", "\n", "", "elif", "isinstance", "(", "clip", "[", "0", "]", ",", "PIL", ".", "Image", ".", "Image", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "im_w", ",", "im_h", "=", "clip", "[", "0", "]", ".", "size", "\n", "# Min spatial dim already matches minimal size", "\n", "if", "(", "im_w", "<=", "im_h", "and", "im_w", "==", "size", ")", "or", "(", "im_h", "<=", "im_w", "\n", "and", "im_h", "==", "size", ")", ":", "\n", "                ", "return", "clip", "\n", "", "new_h", ",", "new_w", "=", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", "\n", "size", "=", "(", "new_w", ",", "new_h", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "size", "[", "1", "]", ",", "size", "[", "0", "]", "\n", "", "if", "interpolation", "==", "'bilinear'", ":", "\n", "            ", "pil_inter", "=", "PIL", ".", "Image", ".", "BILINEAR", "\n", "", "else", ":", "\n", "            ", "pil_inter", "=", "PIL", ".", "Image", ".", "NEAREST", "\n", "", "scaled", "=", "[", "img", ".", "resize", "(", "size", ",", "pil_inter", ")", "for", "img", "in", "clip", "]", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'Expected numpy.ndarray or PIL.Image'", "+", "\n", "'but got list of {0}'", ".", "format", "(", "type", "(", "clip", "[", "0", "]", ")", ")", ")", "\n", "", "return", "scaled", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.get_resize_sizes": [[67, 75], ["int", "int"], "function", ["None"], ["", "def", "get_resize_sizes", "(", "im_h", ",", "im_w", ",", "size", ")", ":", "\n", "    ", "if", "im_w", "<", "im_h", ":", "\n", "        ", "ow", "=", "size", "\n", "oh", "=", "int", "(", "size", "*", "im_h", "/", "im_w", ")", "\n", "", "else", ":", "\n", "        ", "oh", "=", "size", "\n", "ow", "=", "int", "(", "size", "*", "im_w", "/", "im_h", ")", "\n", "", "return", "oh", ",", "ow", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional.normalize": [[77, 90], ["torch.as_tensor", "torch.as_tensor", "clip.clone.sub_().div_", "functional._is_tensor_clip", "TypeError", "clip.clone.clone", "clip.clone.sub_"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.functional._is_tensor_clip"], ["", "def", "normalize", "(", "clip", ",", "mean", ",", "std", ",", "inplace", "=", "False", ")", ":", "\n", "    ", "if", "not", "_is_tensor_clip", "(", "clip", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'tensor is not a torch clip.'", ")", "\n", "\n", "", "if", "not", "inplace", ":", "\n", "        ", "clip", "=", "clip", ".", "clone", "(", ")", "\n", "\n", "", "dtype", "=", "clip", ".", "dtype", "\n", "mean", "=", "torch", ".", "as_tensor", "(", "mean", ",", "dtype", "=", "dtype", ",", "device", "=", "clip", ".", "device", ")", "\n", "std", "=", "torch", ".", "as_tensor", "(", "std", ",", "dtype", "=", "dtype", ",", "device", "=", "clip", ".", "device", ")", "\n", "clip", ".", "sub_", "(", "mean", "[", ":", ",", "None", ",", "None", ",", "None", "]", ")", ".", "div_", "(", "std", "[", ":", ",", "None", ",", "None", ",", "None", "]", ")", "\n", "\n", "return", "clip", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.__init__": [[26, 33], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "window_size", "=", "20", ",", "fmt", "=", "None", ")", ":", "\n", "        ", "if", "fmt", "is", "None", ":", "\n", "            ", "fmt", "=", "\"{median:.4f} ({global_avg:.4f})\"", "\n", "", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "window_size", ")", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "fmt", "=", "fmt", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.update": [[34, 38], ["utils.SmoothedValue.deque.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "value", ")", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "total", "+=", "value", "*", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.synchronize_between_processes": [[39, 51], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.barrier", "torch.barrier", "torch.all_reduce", "torch.all_reduce", "t.tolist.tolist.tolist", "int", "utils.is_dist_avail_and_initialized"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_dist_avail_and_initialized"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Warning: does not synchronize the deque!\n        \"\"\"", "\n", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "            ", "return", "\n", "", "t", "=", "torch", ".", "tensor", "(", "[", "self", ".", "count", ",", "self", ".", "total", "]", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "\n", "dist", ".", "barrier", "(", ")", "\n", "dist", ".", "all_reduce", "(", "t", ")", "\n", "t", "=", "t", ".", "tolist", "(", ")", "\n", "self", ".", "count", "=", "int", "(", "t", "[", "0", "]", ")", "\n", "self", ".", "total", "=", "t", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.median": [[52, 56], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.median().item", "torch.tensor.median().item", "list", "torch.tensor.median", "torch.tensor.median"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.median", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.median"], ["", "@", "property", "\n", "def", "median", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "median", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.avg": [[57, 61], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.mean().item", "torch.tensor.mean().item", "list", "torch.tensor.mean", "torch.tensor.mean"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "return", "d", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.global_avg": [[62, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max": [[66, 69], ["utils.SmoothedValue.max"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "@", "property", "\n", "def", "max", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "self", ".", "deque", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.value": [[70, 73], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "deque", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.__str__": [[74, 81], ["utils.SmoothedValue.fmt.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fmt", ".", "format", "(", "\n", "median", "=", "self", ".", "median", ",", "\n", "avg", "=", "self", ".", "avg", ",", "\n", "global_avg", "=", "self", ".", "global_avg", ",", "\n", "max", "=", "self", ".", "max", ",", "\n", "value", "=", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.__init__": [[84, 87], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "delimiter", "=", "\"\\t\"", ")", ":", "\n", "        ", "self", ".", "meters", "=", "defaultdict", "(", "SmoothedValue", ")", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.update": [[88, 96], ["kwargs.items", "isinstance", "isinstance", "utils.MetricLogger.meters[].update", "v.item.item.item"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update"], ["", "def", "update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "v", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.__getattr__": [[97, 104], ["AttributeError", "type"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "if", "attr", "in", "self", ".", "meters", ":", "\n", "            ", "return", "self", ".", "meters", "[", "attr", "]", "\n", "", "if", "attr", "in", "self", ".", "__dict__", ":", "\n", "            ", "return", "self", ".", "__dict__", "[", "attr", "]", "\n", "", "raise", "AttributeError", "(", "\"'{}' object has no attribute '{}'\"", ".", "format", "(", "\n", "type", "(", "self", ")", ".", "__name__", ",", "attr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.__str__": [[105, 112], ["utils.MetricLogger.meters.items", "utils.MetricLogger.delimiter.join", "loss_str.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "loss_str", "=", "[", "]", "\n", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "loss_str", ".", "append", "(", "\n", "\"{}: {}\"", ".", "format", "(", "name", ",", "str", "(", "meter", ")", ")", "\n", ")", "\n", "", "return", "self", ".", "delimiter", ".", "join", "(", "loss_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.synchronize_between_processes": [[113, 116], ["utils.MetricLogger.meters.values", "meter.synchronize_between_processes"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.synchronize_between_processes"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "for", "meter", "in", "self", ".", "meters", ".", "values", "(", ")", ":", "\n", "            ", "meter", ".", "synchronize_between_processes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.add_meter": [[117, 119], ["None"], "methods", ["None"], ["", "", "def", "add_meter", "(", "self", ",", "name", ",", "meter", ")", ":", "\n", "        ", "self", ".", "meters", "[", "name", "]", "=", "meter", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.MetricLogger.log_every": [[120, 165], ["time.time", "time.time", "utils.SmoothedValue", "utils.SmoothedValue", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "utils.MetricLogger.delimiter.join", "str", "print", "utils.MetricLogger.append", "utils.SmoothedValue.update", "utils.SmoothedValue.update", "time.time", "time.time", "datetime.timedelta", "str", "str", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "len", "time.time", "time.time", "datetime.timedelta", "print", "print", "int", "len", "str", "len", "len", "utils.MetricLogger.format", "utils.MetricLogger.format", "len", "int", "len", "len", "str", "str", "str", "str", "str", "str", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update"], ["", "def", "log_every", "(", "self", ",", "iterable", ",", "print_freq", ",", "header", "=", "None", ")", ":", "\n", "        ", "i", "=", "0", "\n", "if", "not", "header", ":", "\n", "            ", "header", "=", "''", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "iter_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "data_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "space_fmt", "=", "':'", "+", "str", "(", "len", "(", "str", "(", "len", "(", "iterable", ")", ")", ")", ")", "+", "'d'", "\n", "log_msg", "=", "[", "\n", "header", ",", "\n", "'[{0'", "+", "space_fmt", "+", "'}/{1}]'", ",", "\n", "'eta: {eta}'", ",", "\n", "'{meters}'", ",", "\n", "'time: {time}'", ",", "\n", "'data: {data}'", "\n", "]", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "log_msg", ".", "append", "(", "'max mem: {memory:.0f}'", ")", "\n", "", "log_msg", "=", "self", ".", "delimiter", ".", "join", "(", "log_msg", ")", "\n", "MB", "=", "1024.0", "*", "1024.0", "\n", "for", "obj", "in", "iterable", ":", "\n", "            ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "yield", "obj", "\n", "iter_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "if", "i", "%", "print_freq", "==", "0", "or", "i", "==", "len", "(", "iterable", ")", "-", "1", ":", "\n", "                ", "eta_seconds", "=", "iter_time", ".", "global_avg", "*", "(", "len", "(", "iterable", ")", "-", "i", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len", "(", "iterable", ")", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ",", "\n", "memory", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "MB", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len", "(", "iterable", ")", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ")", ")", "\n", "", "", "i", "+=", "1", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "print", "(", "'{} Total time: {} ({:.4f} s / it)'", ".", "format", "(", "\n", "header", ",", "total_time_str", ",", "total_time", "/", "len", "(", "iterable", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.__init__": [[168, 171], ["tensorboardX.SummaryWriter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "log_dir", ")", ":", "\n", "        ", "self", ".", "writer", "=", "SummaryWriter", "(", "logdir", "=", "log_dir", ")", "\n", "self", ".", "step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.set_step": [[172, 177], ["None"], "methods", ["None"], ["", "def", "set_step", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "if", "step", "is", "not", "None", ":", "\n", "            ", "self", ".", "step", "=", "step", "\n", "", "else", ":", "\n", "            ", "self", ".", "step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update": [[178, 186], ["kwargs.items", "isinstance", "isinstance", "utils.TensorboardLogger.writer.add_scalar", "v.item.item.item"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "head", "=", "'scalar'", ",", "step", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "v", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "head", "+", "\"/\"", "+", "k", ",", "v", ",", "self", ".", "step", "if", "step", "is", "None", "else", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.flush": [[187, 189], ["utils.TensorboardLogger.writer.flush"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.flush"], ["", "", "def", "flush", "(", "self", ")", ":", "\n", "        ", "self", ".", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.__init__": [[344, 346], ["torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.__call__": [[347, 362], ["utils.NativeScalerWithGradNormCount._scaler.scale().backward", "utils.NativeScalerWithGradNormCount._scaler.step", "utils.NativeScalerWithGradNormCount._scaler.update", "utils.NativeScalerWithGradNormCount._scaler.scale", "utils.NativeScalerWithGradNormCount._scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "utils.NativeScalerWithGradNormCount._scaler.unscale_", "utils.get_grad_norm_"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_grad_norm_"], ["", "def", "__call__", "(", "self", ",", "loss", ",", "optimizer", ",", "clip_grad", "=", "None", ",", "parameters", "=", "None", ",", "create_graph", "=", "False", ",", "update_grad", "=", "True", ")", ":", "\n", "        ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", "create_graph", "=", "create_graph", ")", "\n", "if", "update_grad", ":", "\n", "            ", "if", "clip_grad", "is", "not", "None", ":", "\n", "                ", "assert", "parameters", "is", "not", "None", "\n", "self", ".", "_scaler", ".", "unscale_", "(", "optimizer", ")", "# unscale the gradients of optimizer's assigned params in-place", "\n", "norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "parameters", ",", "clip_grad", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_scaler", ".", "unscale_", "(", "optimizer", ")", "\n", "norm", "=", "get_grad_norm_", "(", "parameters", ")", "\n", "", "self", ".", "_scaler", ".", "step", "(", "optimizer", ")", "\n", "self", ".", "_scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "            ", "norm", "=", "None", "\n", "", "return", "norm", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict": [[363, 365], ["utils.NativeScalerWithGradNormCount._scaler.state_dict"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_scaler", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.load_state_dict": [[366, 368], ["utils.NativeScalerWithGradNormCount._scaler.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "_scaler", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.seed_worker": [[190, 194], ["numpy.random.seed", "random.seed", "torch.initial_seed", "torch.initial_seed"], "function", ["None"], ["", "", "def", "seed_worker", "(", "worker_id", ")", ":", "\n", "    ", "worker_seed", "=", "torch", ".", "initial_seed", "(", ")", "%", "2", "**", "32", "\n", "np", ".", "random", ".", "seed", "(", "worker_seed", ")", "\n", "random", ".", "seed", "(", "worker_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils._load_checkpoint_for_ema": [[195, 203], ["io.BytesIO", "torch.save", "torch.save", "io.BytesIO.seek", "model_ema._load_checkpoint"], "function", ["None"], ["", "def", "_load_checkpoint_for_ema", "(", "model_ema", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\"\n    Workaround for ModelEma._load_checkpoint to accept an already-loaded object\n    \"\"\"", "\n", "mem_file", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "mem_file", ")", "\n", "mem_file", ".", "seek", "(", "0", ")", "\n", "model_ema", ".", "_load_checkpoint", "(", "mem_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.setup_for_distributed": [[205, 218], ["kwargs.pop", "builtin_print"], "function", ["None"], ["", "def", "setup_for_distributed", "(", "is_master", ")", ":", "\n", "    ", "\"\"\"\n    This function disables printing when not in master process\n    \"\"\"", "\n", "import", "builtins", "as", "__builtin__", "\n", "builtin_print", "=", "__builtin__", ".", "print", "\n", "\n", "def", "print", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "force", "=", "kwargs", ".", "pop", "(", "'force'", ",", "False", ")", "\n", "if", "is_master", "or", "force", ":", "\n", "            ", "builtin_print", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "__builtin__", ".", "print", "=", "print", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_dist_avail_and_initialized": [[220, 226], ["torch.is_available", "torch.is_initialized"], "function", ["None"], ["", "def", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_world_size": [[228, 232], ["torch.get_world_size", "utils.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_world_size", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_dist_avail_and_initialized"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_rank": [[234, 238], ["torch.get_rank", "utils.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_rank", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_dist_avail_and_initialized"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_main_process": [[240, 242], ["utils.get_rank"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.save_on_master": [[244, 247], ["utils.is_main_process", "torch.save", "torch.save"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_main_process"], ["", "def", "save_on_master", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.init_distributed_mode": [[249, 291], ["torch.cuda.set_device", "torch.cuda.set_device", "utils.setup_for_distributed.print", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.barrier", "torch.distributed.barrier", "utils.setup_for_distributed", "int", "int", "int", "str", "str", "str", "int", "int", "int", "str", "str", "str", "subprocess.getoutput", "int", "int", "int", "utils.setup_for_distributed.print"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.setup_for_distributed"], ["", "", "def", "init_distributed_mode", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "dist_on_itp", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "'OMPI_COMM_WORLD_RANK'", "]", ")", "\n", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'OMPI_COMM_WORLD_SIZE'", "]", ")", "\n", "args", ".", "gpu", "=", "int", "(", "os", ".", "environ", "[", "'OMPI_COMM_WORLD_LOCAL_RANK'", "]", ")", "\n", "args", ".", "dist_url", "=", "\"tcp://%s:%s\"", "%", "(", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", ",", "os", ".", "environ", "[", "'MASTER_PORT'", "]", ")", "\n", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "os", ".", "environ", "[", "'RANK'", "]", "=", "str", "(", "args", ".", "rank", ")", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "=", "str", "(", "args", ".", "world_size", ")", "\n", "", "elif", "'SLURM_PROCID'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "args", ".", "gpu", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_LOCALID'", "]", ")", "\n", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_NTASKS'", "]", ")", "\n", "os", ".", "environ", "[", "'RANK'", "]", "=", "str", "(", "args", ".", "rank", ")", "\n", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "gpu", ")", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "=", "str", "(", "args", ".", "world_size", ")", "\n", "\n", "node_list", "=", "os", ".", "environ", "[", "'SLURM_NODELIST'", "]", "\n", "addr", "=", "subprocess", ".", "getoutput", "(", "\n", "f'scontrol show hostname {node_list} | head -n1'", ")", "\n", "if", "'MASTER_ADDR'", "not", "in", "os", ".", "environ", ":", "\n", "            ", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "addr", "\n", "", "", "elif", "'RANK'", "in", "os", ".", "environ", "and", "'WORLD_SIZE'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", "\n", "args", ".", "gpu", "=", "int", "(", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Not using distributed mode'", ")", "\n", "args", ".", "distributed", "=", "False", "\n", "return", "\n", "\n", "", "args", ".", "distributed", "=", "True", "\n", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "args", ".", "dist_backend", "=", "'nccl'", "\n", "print", "(", "'| distributed init (rank {}): {}, gpu {}'", ".", "format", "(", "\n", "args", ".", "rank", ",", "args", ".", "dist_url", ",", "args", ".", "gpu", ")", ",", "flush", "=", "True", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "args", ".", "dist_backend", ",", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "rank", "=", "args", ".", "rank", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "# assert torch.distributed.is_initialized()", "\n", "setup_for_distributed", "(", "args", ".", "rank", "==", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict": [[293, 339], ["getattr", "state_dict.copy.copy", "utils.load_state_dict.load"], "function", ["None"], ["", "def", "load_state_dict", "(", "model", ",", "state_dict", ",", "prefix", "=", "''", ",", "ignore_missing", "=", "\"relative_position_index\"", ")", ":", "\n", "    ", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "        ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "        ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "\n", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "            ", "if", "child", "is", "not", "None", ":", "\n", "                ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "", "", "", "load", "(", "model", ",", "prefix", "=", "prefix", ")", "\n", "\n", "warn_missing_keys", "=", "[", "]", "\n", "ignore_missing_keys", "=", "[", "]", "\n", "for", "key", "in", "missing_keys", ":", "\n", "        ", "keep_flag", "=", "True", "\n", "for", "ignore_key", "in", "ignore_missing", ".", "split", "(", "'|'", ")", ":", "\n", "            ", "if", "ignore_key", "in", "key", ":", "\n", "                ", "keep_flag", "=", "False", "\n", "break", "\n", "", "", "if", "keep_flag", ":", "\n", "            ", "warn_missing_keys", ".", "append", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "ignore_missing_keys", ".", "append", "(", "key", ")", "\n", "\n", "", "", "missing_keys", "=", "warn_missing_keys", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "        ", "print", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "        ", "print", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "ignore_missing_keys", ")", ">", "0", ":", "\n", "        ", "print", "(", "\"Ignored weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "ignore_missing_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "        ", "print", "(", "'\\n'", ".", "join", "(", "error_msgs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_grad_norm_": [[370, 383], ["isinstance", "float", "len", "torch.tensor", "torch.tensor", "max", "torch.norm", "torch.norm", "torch.stack", "torch.stack", "p.grad.detach().abs().max().to", "torch.norm().to", "torch.norm().to", "p.grad.detach().abs().max", "torch.norm", "torch.norm", "p.grad.detach().abs", "p.grad.detach", "p.grad.detach"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max"], ["", "", "def", "get_grad_norm_", "(", "parameters", ",", "norm_type", ":", "float", "=", "2.0", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "isinstance", "(", "parameters", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "parameters", "=", "[", "parameters", "]", "\n", "", "parameters", "=", "[", "p", "for", "p", "in", "parameters", "if", "p", ".", "grad", "is", "not", "None", "]", "\n", "norm_type", "=", "float", "(", "norm_type", ")", "\n", "if", "len", "(", "parameters", ")", "==", "0", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "0.", ")", "\n", "", "device", "=", "parameters", "[", "0", "]", ".", "grad", ".", "device", "\n", "if", "norm_type", "==", "inf", ":", "\n", "        ", "total_norm", "=", "max", "(", "p", ".", "grad", ".", "detach", "(", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "to", "(", "device", ")", "for", "p", "in", "parameters", ")", "\n", "", "else", ":", "\n", "        ", "total_norm", "=", "torch", ".", "norm", "(", "torch", ".", "stack", "(", "[", "torch", ".", "norm", "(", "p", ".", "grad", ".", "detach", "(", ")", ",", "norm_type", ")", ".", "to", "(", "device", ")", "for", "p", "in", "parameters", "]", ")", ",", "norm_type", ")", "\n", "", "return", "total_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.cosine_scheduler": [[385, 403], ["numpy.array", "utils.setup_for_distributed.print", "numpy.arange", "numpy.array", "numpy.concatenate", "numpy.linspace", "len", "math.cos", "len"], "function", ["None"], ["", "def", "cosine_scheduler", "(", "base_value", ",", "final_value", ",", "epochs", ",", "niter_per_ep", ",", "warmup_epochs", "=", "0", ",", "\n", "start_warmup_value", "=", "0", ",", "warmup_steps", "=", "-", "1", ")", ":", "\n", "    ", "warmup_schedule", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "warmup_iters", "=", "warmup_epochs", "*", "niter_per_ep", "\n", "if", "warmup_steps", ">", "0", ":", "\n", "        ", "warmup_iters", "=", "warmup_steps", "\n", "", "print", "(", "\"Set warmup steps = %d\"", "%", "warmup_iters", ")", "\n", "if", "warmup_epochs", ">", "0", ":", "\n", "        ", "warmup_schedule", "=", "np", ".", "linspace", "(", "start_warmup_value", ",", "base_value", ",", "warmup_iters", ")", "\n", "\n", "", "iters", "=", "np", ".", "arange", "(", "epochs", "*", "niter_per_ep", "-", "warmup_iters", ")", "\n", "schedule", "=", "np", ".", "array", "(", "\n", "[", "final_value", "+", "0.5", "*", "(", "base_value", "-", "final_value", ")", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "i", "/", "(", "len", "(", "iters", ")", ")", ")", ")", "for", "i", "in", "iters", "]", ")", "\n", "\n", "schedule", "=", "np", ".", "concatenate", "(", "(", "warmup_schedule", ",", "schedule", ")", ")", "\n", "\n", "assert", "len", "(", "schedule", ")", "==", "epochs", "*", "niter_per_ep", "\n", "return", "schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.save_model": [[405, 428], ["pathlib.Path", "str", "model.save_checkpoint", "utils.save_on_master", "timm.utils.get_state_dict", "model_without_ddp.state_dict", "optimizer.state_dict", "loss_scaler.state_dict", "timm.utils.get_state_dict"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.save_on_master", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict"], ["", "def", "save_model", "(", "args", ",", "epoch", ",", "model", ",", "model_without_ddp", ",", "optimizer", ",", "loss_scaler", ",", "model_ema", "=", "None", ")", ":", "\n", "    ", "output_dir", "=", "Path", "(", "args", ".", "output_dir", ")", "\n", "epoch_name", "=", "str", "(", "epoch", ")", "\n", "if", "loss_scaler", "is", "not", "None", ":", "\n", "        ", "checkpoint_paths", "=", "[", "output_dir", "/", "(", "'checkpoint-%s.pth'", "%", "epoch_name", ")", "]", "\n", "for", "checkpoint_path", "in", "checkpoint_paths", ":", "\n", "            ", "to_save", "=", "{", "\n", "'model'", ":", "model_without_ddp", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'scaler'", ":", "loss_scaler", ".", "state_dict", "(", ")", ",", "\n", "'args'", ":", "args", ",", "\n", "}", "\n", "\n", "if", "model_ema", "is", "not", "None", ":", "\n", "                ", "to_save", "[", "'model_ema'", "]", "=", "get_state_dict", "(", "model_ema", ")", "\n", "\n", "", "save_on_master", "(", "to_save", ",", "checkpoint_path", ")", "\n", "", "", "else", ":", "\n", "        ", "client_state", "=", "{", "'epoch'", ":", "epoch", "}", "\n", "if", "model_ema", "is", "not", "None", ":", "\n", "            ", "client_state", "[", "'model_ema'", "]", "=", "get_state_dict", "(", "model_ema", ")", "\n", "", "model", ".", "save_checkpoint", "(", "save_dir", "=", "args", ".", "output_dir", ",", "tag", "=", "\"checkpoint-%s\"", "%", "epoch_name", ",", "client_state", "=", "client_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.auto_load_model": [[430, 480], ["pathlib.Path", "glob.glob", "utils.setup_for_distributed.print", "args.resume.startswith", "model_without_ddp.load_state_dict", "utils.setup_for_distributed.print", "glob.glob", "len", "os.path.join", "t.isdigit", "os.path.join", "torch.hub.load_state_dict_from_url", "torch.hub.load_state_dict_from_url", "torch.load", "torch.load", "optimizer.load_state_dict", "utils.setup_for_distributed.print", "os.path.join", "t.isdigit", "os.path.join", "utils.setup_for_distributed.print", "model.load_checkpoint", "[].split", "max", "hasattr", "utils._load_checkpoint_for_ema", "loss_scaler.load_state_dict", "[].split", "max", "int", "int", "utils._load_checkpoint_for_ema", "ckpt.split", "ckpt.split"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils._load_checkpoint_for_ema", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils._load_checkpoint_for_ema"], ["", "", "def", "auto_load_model", "(", "args", ",", "model", ",", "model_without_ddp", ",", "optimizer", ",", "loss_scaler", ",", "model_ema", "=", "None", ")", ":", "\n", "    ", "output_dir", "=", "Path", "(", "args", ".", "output_dir", ")", "\n", "if", "loss_scaler", "is", "not", "None", ":", "\n", "# torch.amp", "\n", "        ", "if", "args", ".", "auto_resume", "and", "len", "(", "args", ".", "resume", ")", "==", "0", ":", "\n", "            ", "import", "glob", "\n", "all_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'checkpoint-*.pth'", ")", ")", "\n", "latest_ckpt", "=", "-", "1", "\n", "for", "ckpt", "in", "all_checkpoints", ":", "\n", "                ", "t", "=", "ckpt", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "t", ".", "isdigit", "(", ")", ":", "\n", "                    ", "latest_ckpt", "=", "max", "(", "int", "(", "t", ")", ",", "latest_ckpt", ")", "\n", "", "", "if", "latest_ckpt", ">=", "0", ":", "\n", "                ", "args", ".", "resume", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'checkpoint-%d.pth'", "%", "latest_ckpt", ")", "\n", "", "print", "(", "\"Auto resume checkpoint: %s\"", "%", "args", ".", "resume", ")", "\n", "\n", "", "if", "args", ".", "resume", ":", "\n", "            ", "if", "args", ".", "resume", ".", "startswith", "(", "'https'", ")", ":", "\n", "                ", "checkpoint", "=", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "\n", "args", ".", "resume", ",", "map_location", "=", "'cpu'", ",", "check_hash", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ",", "map_location", "=", "'cpu'", ")", "\n", "", "model_without_ddp", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "\"Resume checkpoint %s\"", "%", "args", ".", "resume", ")", "\n", "if", "'optimizer'", "in", "checkpoint", "and", "'epoch'", "in", "checkpoint", ":", "\n", "                ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "if", "hasattr", "(", "args", ",", "'model_ema'", ")", "and", "args", ".", "model_ema", ":", "\n", "                    ", "_load_checkpoint_for_ema", "(", "model_ema", ",", "checkpoint", "[", "'model_ema'", "]", ")", "\n", "", "if", "'scaler'", "in", "checkpoint", ":", "\n", "                    ", "loss_scaler", ".", "load_state_dict", "(", "checkpoint", "[", "'scaler'", "]", ")", "\n", "", "print", "(", "\"With optim & sched!\"", ")", "\n", "", "", "", "else", ":", "\n", "# deepspeed, only support '--auto_resume'.", "\n", "        ", "if", "args", ".", "auto_resume", ":", "\n", "            ", "import", "glob", "\n", "all_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'checkpoint-*'", ")", ")", "\n", "latest_ckpt", "=", "-", "1", "\n", "for", "ckpt", "in", "all_checkpoints", ":", "\n", "                ", "t", "=", "ckpt", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "t", ".", "isdigit", "(", ")", ":", "\n", "                    ", "latest_ckpt", "=", "max", "(", "int", "(", "t", ")", ",", "latest_ckpt", ")", "\n", "", "", "if", "latest_ckpt", ">=", "0", ":", "\n", "                ", "args", ".", "resume", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'checkpoint-%d'", "%", "latest_ckpt", ")", "\n", "print", "(", "\"Auto resume checkpoint: %d\"", "%", "latest_ckpt", ")", "\n", "_", ",", "client_states", "=", "model", ".", "load_checkpoint", "(", "args", ".", "output_dir", ",", "tag", "=", "'checkpoint-%d'", "%", "latest_ckpt", ")", "\n", "args", ".", "start_epoch", "=", "client_states", "[", "'epoch'", "]", "+", "1", "\n", "if", "model_ema", "is", "not", "None", ":", "\n", "                    ", "if", "args", ".", "model_ema", ":", "\n", "                        ", "_load_checkpoint_for_ema", "(", "model_ema", ",", "client_states", "[", "'model_ema'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.create_ds_config": [[482, 512], ["os.path.join", "open", "writer.write", "json.dumps", "utils.get_world_size"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_world_size"], ["", "", "", "", "", "", "def", "create_ds_config", "(", "args", ")", ":", "\n", "    ", "args", ".", "deepspeed_config", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"deepspeed_config.json\"", ")", "\n", "with", "open", "(", "args", ".", "deepspeed_config", ",", "mode", "=", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "ds_config", "=", "{", "\n", "\"train_batch_size\"", ":", "args", ".", "batch_size", "*", "args", ".", "update_freq", "*", "get_world_size", "(", ")", ",", "\n", "\"train_micro_batch_size_per_gpu\"", ":", "args", ".", "batch_size", ",", "\n", "\"steps_per_print\"", ":", "1000", ",", "\n", "\"optimizer\"", ":", "{", "\n", "\"type\"", ":", "\"Adam\"", ",", "\n", "\"adam_w_mode\"", ":", "True", ",", "\n", "\"params\"", ":", "{", "\n", "\"lr\"", ":", "args", ".", "lr", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "\"bias_correction\"", ":", "True", ",", "\n", "\"betas\"", ":", "[", "\n", "0.9", ",", "\n", "0.999", "\n", "]", ",", "\n", "\"eps\"", ":", "1e-8", "\n", "}", "\n", "}", ",", "\n", "\"fp16\"", ":", "{", "\n", "\"enabled\"", ":", "True", ",", "\n", "\"loss_scale\"", ":", "0", ",", "\n", "\"initial_scale_power\"", ":", "7", ",", "\n", "\"loss_scale_window\"", ":", "128", "\n", "}", "\n", "}", "\n", "\n", "writer", ".", "write", "(", "json", ".", "dumps", "(", "ds_config", ",", "indent", "=", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.multiple_samples_collate": [[513, 536], ["zip", "torch.utils.data._utils.collate.default_collate", "torch.utils.data._utils.collate.default_collate", "torch.utils.data._utils.collate.default_collate", "torch.utils.data._utils.collate.default_collate"], "function", ["None"], ["", "", "def", "multiple_samples_collate", "(", "batch", ",", "fold", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Collate function for repeated augmentation. Each instance in the batch has\n    more than one sample.\n    Args:\n        batch (tuple or list): data batch to collate.\n    Returns:\n        (tuple): collated data batch.\n    \"\"\"", "\n", "inputs", ",", "labels", ",", "video_idx", ",", "extra_data", "=", "zip", "(", "*", "batch", ")", "\n", "inputs", "=", "[", "item", "for", "sublist", "in", "inputs", "for", "item", "in", "sublist", "]", "\n", "labels", "=", "[", "item", "for", "sublist", "in", "labels", "for", "item", "in", "sublist", "]", "\n", "video_idx", "=", "[", "item", "for", "sublist", "in", "video_idx", "for", "item", "in", "sublist", "]", "\n", "inputs", ",", "labels", ",", "video_idx", ",", "extra_data", "=", "(", "\n", "default_collate", "(", "inputs", ")", ",", "\n", "default_collate", "(", "labels", ")", ",", "\n", "default_collate", "(", "video_idx", ")", ",", "\n", "default_collate", "(", "extra_data", ")", ",", "\n", ")", "\n", "if", "fold", ":", "\n", "        ", "return", "[", "inputs", "]", ",", "labels", ",", "video_idx", ",", "extra_data", "\n", "", "else", ":", "\n", "        ", "return", "inputs", ",", "labels", ",", "video_idx", ",", "extra_data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_class_finetuning.get_args": [[27, 202], ["argparse.ArgumentParser", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.set_defaults", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.set_defaults", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.set_defaults", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.set_defaults", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.parse_known_args", "deepspeed.add_config_arguments.add_argument", "deepspeed.add_config_arguments.parse_args", "deepspeed.add_config_arguments", "print", "exit"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'VideoMAE fine-tuning and evaluation script for video classification'", ",", "add_help", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "64", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "30", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--update_freq'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--save_ckpt_freq'", ",", "default", "=", "100", ",", "type", "=", "int", ")", "\n", "\n", "# Model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'vit_base_patch16_224'", ",", "type", "=", "str", ",", "metavar", "=", "'MODEL'", ",", "\n", "help", "=", "'Name of model to train'", ")", "\n", "parser", ".", "add_argument", "(", "'--tubelet_size'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--input_size'", ",", "default", "=", "224", ",", "type", "=", "int", ",", "\n", "help", "=", "'videos input size'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--drop'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Dropout rate (default: 0.)'", ")", "\n", "parser", ".", "add_argument", "(", "'--attn_drop_rate'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Attention dropout rate (default: 0.)'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_path'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Drop path rate (default: 0.1)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--disable_eval_during_finetuning'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--model_ema'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--model_ema_decay'", ",", "type", "=", "float", ",", "default", "=", "0.9999", ",", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--model_ema_force_cpu'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "''", ")", "\n", "\n", "# Optimizer parameters", "\n", "parser", ".", "add_argument", "(", "'--opt'", ",", "default", "=", "'adamw'", ",", "type", "=", "str", ",", "metavar", "=", "'OPTIMIZER'", ",", "\n", "help", "=", "'Optimizer (default: \"adamw\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--opt_eps'", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "metavar", "=", "'EPSILON'", ",", "\n", "help", "=", "'Optimizer Epsilon (default: 1e-8)'", ")", "\n", "parser", ".", "add_argument", "(", "'--opt_betas'", ",", "default", "=", "None", ",", "type", "=", "float", ",", "nargs", "=", "'+'", ",", "metavar", "=", "'BETA'", ",", "\n", "help", "=", "'Optimizer Betas (default: None, use opt default)'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_grad'", ",", "type", "=", "float", ",", "default", "=", "None", ",", "metavar", "=", "'NORM'", ",", "\n", "help", "=", "'Clip gradient norm (default: None, no clipping)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'SGD momentum (default: 0.9)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0.05", ",", "\n", "help", "=", "'weight decay (default: 0.05)'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay_end'", ",", "type", "=", "float", ",", "default", "=", "None", ",", "help", "=", "\"\"\"Final value of the\n        weight decay. We use a cosine schedule for WD and using a larger decay by\n        the end of training improves performance for ViTs.\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1e-3", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'learning rate (default: 1e-3)'", ")", "\n", "parser", ".", "add_argument", "(", "'--layer_decay'", ",", "type", "=", "float", ",", "default", "=", "0.75", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--warmup_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-6", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'warmup learning rate (default: 1e-6)'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-6", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'lower lr bound for cyclic schedulers that hit 0 (1e-5)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--warmup_epochs'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'epochs to warmup LR, if scheduler supports'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'num of steps to warmup LR, will overload warmup_epochs if set > 0'", ")", "\n", "\n", "# Augmentation parameters", "\n", "parser", ".", "add_argument", "(", "'--color_jitter'", ",", "type", "=", "float", ",", "default", "=", "0.4", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Color jitter factor (default: 0.4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_sample'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Repeated_aug (default: 2)'", ")", "\n", "parser", ".", "add_argument", "(", "'--aa'", ",", "type", "=", "str", ",", "default", "=", "'rand-m7-n4-mstd0.5-inc1'", ",", "metavar", "=", "'NAME'", ",", "\n", "help", "=", "'Use AutoAugment policy. \"v0\" or \"original\". \" + \"(default: rand-m7-n4-mstd0.5-inc1)'", ")", ",", "\n", "parser", ".", "add_argument", "(", "'--smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "'Label smoothing (default: 0.1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_interpolation'", ",", "type", "=", "str", ",", "default", "=", "'bicubic'", ",", "\n", "help", "=", "'Training interpolation (random, bilinear, bicubic default: \"bicubic\")'", ")", "\n", "\n", "# Evaluation parameters", "\n", "parser", ".", "add_argument", "(", "'--crop_pct'", ",", "type", "=", "float", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--short_side_size'", ",", "type", "=", "int", ",", "default", "=", "224", ")", "\n", "parser", ".", "add_argument", "(", "'--test_num_segment'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--test_num_crop'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "\n", "# Random Erase params", "\n", "parser", ".", "add_argument", "(", "'--reprob'", ",", "type", "=", "float", ",", "default", "=", "0.25", ",", "metavar", "=", "'PCT'", ",", "\n", "help", "=", "'Random erase prob (default: 0.25)'", ")", "\n", "parser", ".", "add_argument", "(", "'--remode'", ",", "type", "=", "str", ",", "default", "=", "'pixel'", ",", "\n", "help", "=", "'Random erase mode (default: \"pixel\")'", ")", "\n", "parser", ".", "add_argument", "(", "'--recount'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Random erase count (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--resplit'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Do not random erase first (clean) augmentation split'", ")", "\n", "\n", "# Mixup params", "\n", "parser", ".", "add_argument", "(", "'--mixup'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "\n", "help", "=", "'mixup alpha, mixup enabled if > 0.'", ")", "\n", "parser", ".", "add_argument", "(", "'--cutmix'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'cutmix alpha, cutmix enabled if > 0.'", ")", "\n", "parser", ".", "add_argument", "(", "'--cutmix_minmax'", ",", "type", "=", "float", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "\n", "help", "=", "'cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)'", ")", "\n", "parser", ".", "add_argument", "(", "'--mixup_prob'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'Probability of performing mixup or cutmix when either/both is enabled'", ")", "\n", "parser", ".", "add_argument", "(", "'--mixup_switch_prob'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'Probability of switching to cutmix when both mixup and cutmix enabled'", ")", "\n", "parser", ".", "add_argument", "(", "'--mixup_mode'", ",", "type", "=", "str", ",", "default", "=", "'batch'", ",", "\n", "help", "=", "'How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"'", ")", "\n", "\n", "# Finetuning params", "\n", "parser", ".", "add_argument", "(", "'--finetune'", ",", "default", "=", "''", ",", "help", "=", "'finetune from checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_key'", ",", "default", "=", "'model|module'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--model_prefix'", ",", "default", "=", "''", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--init_scale'", ",", "default", "=", "0.001", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--use_mean_pooling'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "set_defaults", "(", "use_mean_pooling", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--use_cls'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'use_mean_pooling'", ")", "\n", "\n", "# Dataset parameters", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "default", "=", "'/path/to/list_kinetics-400'", ",", "type", "=", "str", ",", "\n", "help", "=", "'dataset path'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_data_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'dataset path for evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--nb_classes'", ",", "default", "=", "400", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of the classification types'", ")", "\n", "parser", ".", "add_argument", "(", "'--imagenet_default_mean_and_std'", ",", "default", "=", "True", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_segments'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--num_frames'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "parser", ".", "add_argument", "(", "'--sampling_rate'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--data_set'", ",", "default", "=", "'Kinetics-400'", ",", "choices", "=", "[", "'Kinetics-400'", ",", "'SSV2'", ",", "'UCF101'", ",", "'HMDB51'", ",", "'image_folder'", "]", ",", "\n", "type", "=", "str", ",", "help", "=", "'dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "default", "=", "''", ",", "\n", "help", "=", "'path where to save, empty for no saving'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "default", "=", "None", ",", "\n", "help", "=", "'path where to tensorboard log'", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "default", "=", "'cuda'", ",", "\n", "help", "=", "'device to use for training / testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "default", "=", "''", ",", "\n", "help", "=", "'resume from checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--auto_resume'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_auto_resume'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'auto_resume'", ")", "\n", "parser", ".", "set_defaults", "(", "auto_resume", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--save_ckpt'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_save_ckpt'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'save_ckpt'", ")", "\n", "parser", ".", "set_defaults", "(", "save_ckpt", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--start_epoch'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'start epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Perform evaluation only'", ")", "\n", "parser", ".", "add_argument", "(", "'--dist_eval'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Enabling distributed evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_workers'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--pin_mem'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_pin_mem'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'pin_mem'", ")", "\n", "parser", ".", "set_defaults", "(", "pin_mem", "=", "True", ")", "\n", "\n", "# distributed training parameters", "\n", "parser", ".", "add_argument", "(", "'--world_size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of distributed processes'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dist_on_itp'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--dist_url'", ",", "default", "=", "'env://'", ",", "\n", "help", "=", "'url used to set up distributed training'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--enable_deepspeed'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "known_args", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "if", "known_args", ".", "enable_deepspeed", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "deepspeed", "\n", "from", "deepspeed", "import", "DeepSpeedConfig", "\n", "parser", "=", "deepspeed", ".", "add_config_arguments", "(", "parser", ")", "\n", "ds_init", "=", "deepspeed", ".", "initialize", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"Please 'pip install deepspeed'\"", ")", "\n", "exit", "(", "0", ")", "\n", "", "", "else", ":", "\n", "        ", "ds_init", "=", "None", "\n", "\n", "", "return", "parser", ".", "parse_args", "(", ")", ",", "ds_init", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.run_class_finetuning.main": [[204, 552], ["utils.init_distributed_mode", "print", "torch.device", "torch.device", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "datasets.build_dataset", "datasets.build_dataset", "utils.get_world_size", "utils.get_rank", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "timm.models.create_model", "print", "torch.nn.parallel.DistributedDataParallel.to", "sum", "print", "print", "print", "print", "print", "print", "print", "model_without_ddp.get_num_layers", "torch.nn.parallel.DistributedDataParallel.no_weight_decay", "print", "print", "utils.cosine_scheduler", "utils.cosine_scheduler", "print", "print", "utils.auto_load_model", "print", "time.time", "range", "os.path.join", "engine_for_finetuning.final_test", "torch.distributed.barrier", "torch.distributed.barrier", "str", "print", "utils.create_ds_config", "utils.get_rank", "datasets.build_dataset", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "os.makedirs", "utils.TensorboardLogger", "functools.partial", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "timm.data.mixup.Mixup", "args.finetune.startswith", "print", "args.model_key.split", "torch.nn.parallel.DistributedDataParallel.state_dict", "list", "collections.OrderedDict", "utils.load_state_dict", "timm.utils.ModelEma", "print", "utils.get_world_size", "len", "optim_factory.LayerDecayValueAssigner", "print", "optim_factory.get_parameter_groups", "ds_init", "print", "optim_factory.create_optimizer", "utils.NativeScalerWithGradNormCount", "timm.loss.SoftTargetCrossEntropy", "os.path.join", "engine_for_finetuning.final_test", "torch.distributed.barrier", "torch.distributed.barrier", "exit", "engine_for_finetuning.train_one_epoch", "print", "engine_for_finetuning.merge", "print", "time.time", "datetime.timedelta", "str", "print", "str", "torch.hub.load_state_dict_from_url", "torch.hub.load_state_dict_from_url", "torch.load", "torch.load", "checkpoint_model.keys", "key.startswith", "int", "int", "p.numel", "str", "len", "list", "torch.nn.parallel.DistributedDataParallel.gradient_accumulation_steps", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "timm.loss.LabelSmoothingCrossEntropy", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "str", "print", "engine_for_finetuning.merge", "print", "torch.utils.data.DataLoader.sampler.set_epoch", "utils.TensorboardLogger.set_step", "engine_for_finetuning.validation_one_epoch", "print", "print", "utils.is_main_process", "str", "utils.is_main_process", "len", "int", "print", "print", "key.startswith", "print", "pos_tokens.flatten.reshape", "pos_tokens.flatten.reshape().permute", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "pos_tokens.flatten.permute().reshape", "pos_tokens.flatten.flatten", "torch.cat", "torch.cat", "torch.nn.parallel.DistributedDataParallel.parameters", "str", "torch.nn.parallel.DistributedDataParallel.gradient_accumulation_steps", "max", "min", "str", "utils.is_main_process", "utils.save_model", "utils.TensorboardLogger.update", "utils.TensorboardLogger.update", "utils.TensorboardLogger.update", "utils.TensorboardLogger.flush", "open", "f.write", "open", "f.write", "int", "open", "f.write", "utils.save_model", "os.path.join", "len", "os.path.join", "pos_tokens.flatten.reshape", "pos_tokens.flatten.permute", "range", "len", "os.path.join", "len", "engine_for_finetuning.train_one_epoch.items", "engine_for_finetuning.validation_one_epoch.items", "engine_for_finetuning.train_one_epoch.items", "json.dumps", "json.dumps", "json.dumps"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.init_distributed_mode", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.build_dataset", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.build_dataset", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_world_size", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_rank", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.get_num_layers", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.modeling_finetune.VisionTransformer.no_weight_decay", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.cosine_scheduler", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.cosine_scheduler", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.auto_load_model", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.final_test", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.create_ds_config", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_rank", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.build_dataset", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.NativeScalerWithGradNormCount.state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.load_state_dict", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.get_world_size", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.get_parameter_groups", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.optim_factory.create_optimizer", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.final_test", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_pretraining.train_one_epoch", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.merge", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.merge", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.set_step", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.engine_for_finetuning.validation_one_epoch", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_main_process", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_main_process", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.SmoothedValue.max", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.is_main_process", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.save_model", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.update", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.TensorboardLogger.flush", "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.utils.save_model"], ["", "def", "main", "(", "args", ",", "ds_init", ")", ":", "\n", "    ", "utils", ".", "init_distributed_mode", "(", "args", ")", "\n", "\n", "if", "ds_init", "is", "not", "None", ":", "\n", "        ", "utils", ".", "create_ds_config", "(", "args", ")", "\n", "\n", "", "print", "(", "args", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "\n", "# fix the seed for reproducibility", "\n", "seed", "=", "args", ".", "seed", "+", "utils", ".", "get_rank", "(", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "# random.seed(seed)", "\n", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "dataset_train", ",", "args", ".", "nb_classes", "=", "build_dataset", "(", "is_train", "=", "True", ",", "test_mode", "=", "False", ",", "args", "=", "args", ")", "\n", "if", "args", ".", "disable_eval_during_finetuning", ":", "\n", "        ", "dataset_val", "=", "None", "\n", "", "else", ":", "\n", "        ", "dataset_val", ",", "_", "=", "build_dataset", "(", "is_train", "=", "False", ",", "test_mode", "=", "False", ",", "args", "=", "args", ")", "\n", "", "dataset_test", ",", "_", "=", "build_dataset", "(", "is_train", "=", "False", ",", "test_mode", "=", "True", ",", "args", "=", "args", ")", "\n", "\n", "\n", "num_tasks", "=", "utils", ".", "get_world_size", "(", ")", "\n", "global_rank", "=", "utils", ".", "get_rank", "(", ")", "\n", "sampler_train", "=", "torch", ".", "utils", ".", "data", ".", "DistributedSampler", "(", "\n", "dataset_train", ",", "num_replicas", "=", "num_tasks", ",", "rank", "=", "global_rank", ",", "shuffle", "=", "True", "\n", ")", "\n", "print", "(", "\"Sampler_train = %s\"", "%", "str", "(", "sampler_train", ")", ")", "\n", "if", "args", ".", "dist_eval", ":", "\n", "        ", "if", "len", "(", "dataset_val", ")", "%", "num_tasks", "!=", "0", ":", "\n", "            ", "print", "(", "'Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. '", "\n", "'This will slightly alter validation results as extra duplicate entries are added to achieve '", "\n", "'equal num of samples per-process.'", ")", "\n", "", "sampler_val", "=", "torch", ".", "utils", ".", "data", ".", "DistributedSampler", "(", "\n", "dataset_val", ",", "num_replicas", "=", "num_tasks", ",", "rank", "=", "global_rank", ",", "shuffle", "=", "False", ")", "\n", "sampler_test", "=", "torch", ".", "utils", ".", "data", ".", "DistributedSampler", "(", "\n", "dataset_test", ",", "num_replicas", "=", "num_tasks", ",", "rank", "=", "global_rank", ",", "shuffle", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "sampler_val", "=", "torch", ".", "utils", ".", "data", ".", "SequentialSampler", "(", "dataset_val", ")", "\n", "\n", "", "if", "global_rank", "==", "0", "and", "args", ".", "log_dir", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "log_writer", "=", "utils", ".", "TensorboardLogger", "(", "log_dir", "=", "args", ".", "log_dir", ")", "\n", "", "else", ":", "\n", "        ", "log_writer", "=", "None", "\n", "\n", "", "if", "args", ".", "num_sample", ">", "1", ":", "\n", "        ", "collate_func", "=", "partial", "(", "multiple_samples_collate", ",", "fold", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "collate_func", "=", "None", "\n", "\n", "", "data_loader_train", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_train", ",", "sampler", "=", "sampler_train", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "args", ".", "pin_mem", ",", "\n", "drop_last", "=", "True", ",", "\n", "collate_fn", "=", "collate_func", ",", "\n", ")", "\n", "\n", "if", "dataset_val", "is", "not", "None", ":", "\n", "        ", "data_loader_val", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_val", ",", "sampler", "=", "sampler_val", ",", "\n", "batch_size", "=", "int", "(", "1.5", "*", "args", ".", "batch_size", ")", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "args", ".", "pin_mem", ",", "\n", "drop_last", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "data_loader_val", "=", "None", "\n", "\n", "", "if", "dataset_test", "is", "not", "None", ":", "\n", "        ", "data_loader_test", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_test", ",", "sampler", "=", "sampler_test", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "pin_memory", "=", "args", ".", "pin_mem", ",", "\n", "drop_last", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "data_loader_test", "=", "None", "\n", "\n", "", "mixup_fn", "=", "None", "\n", "mixup_active", "=", "args", ".", "mixup", ">", "0", "or", "args", ".", "cutmix", ">", "0.", "or", "args", ".", "cutmix_minmax", "is", "not", "None", "\n", "if", "mixup_active", ":", "\n", "        ", "print", "(", "\"Mixup is activated!\"", ")", "\n", "mixup_fn", "=", "Mixup", "(", "\n", "mixup_alpha", "=", "args", ".", "mixup", ",", "cutmix_alpha", "=", "args", ".", "cutmix", ",", "cutmix_minmax", "=", "args", ".", "cutmix_minmax", ",", "\n", "prob", "=", "args", ".", "mixup_prob", ",", "switch_prob", "=", "args", ".", "mixup_switch_prob", ",", "mode", "=", "args", ".", "mixup_mode", ",", "\n", "label_smoothing", "=", "args", ".", "smoothing", ",", "num_classes", "=", "args", ".", "nb_classes", ")", "\n", "\n", "", "model", "=", "create_model", "(", "\n", "args", ".", "model", ",", "\n", "pretrained", "=", "False", ",", "\n", "num_classes", "=", "args", ".", "nb_classes", ",", "\n", "all_frames", "=", "args", ".", "num_frames", "*", "args", ".", "num_segments", ",", "\n", "tubelet_size", "=", "args", ".", "tubelet_size", ",", "\n", "drop_rate", "=", "args", ".", "drop", ",", "\n", "drop_path_rate", "=", "args", ".", "drop_path", ",", "\n", "attn_drop_rate", "=", "args", ".", "attn_drop_rate", ",", "\n", "drop_block_rate", "=", "None", ",", "\n", "use_mean_pooling", "=", "args", ".", "use_mean_pooling", ",", "\n", "init_scale", "=", "args", ".", "init_scale", ",", "\n", ")", "\n", "\n", "patch_size", "=", "model", ".", "patch_embed", ".", "patch_size", "\n", "print", "(", "\"Patch size = %s\"", "%", "str", "(", "patch_size", ")", ")", "\n", "args", ".", "window_size", "=", "(", "args", ".", "num_frames", "//", "2", ",", "args", ".", "input_size", "//", "patch_size", "[", "0", "]", ",", "args", ".", "input_size", "//", "patch_size", "[", "1", "]", ")", "\n", "args", ".", "patch_size", "=", "patch_size", "\n", "\n", "if", "args", ".", "finetune", ":", "\n", "        ", "if", "args", ".", "finetune", ".", "startswith", "(", "'https'", ")", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "\n", "args", ".", "finetune", ",", "map_location", "=", "'cpu'", ",", "check_hash", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "finetune", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "", "print", "(", "\"Load ckpt from %s\"", "%", "args", ".", "finetune", ")", "\n", "checkpoint_model", "=", "None", "\n", "for", "model_key", "in", "args", ".", "model_key", ".", "split", "(", "'|'", ")", ":", "\n", "            ", "if", "model_key", "in", "checkpoint", ":", "\n", "                ", "checkpoint_model", "=", "checkpoint", "[", "model_key", "]", "\n", "print", "(", "\"Load state_dict by model_key = %s\"", "%", "model_key", ")", "\n", "break", "\n", "", "", "if", "checkpoint_model", "is", "None", ":", "\n", "            ", "checkpoint_model", "=", "checkpoint", "\n", "", "state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "k", "in", "[", "'head.weight'", ",", "'head.bias'", "]", ":", "\n", "            ", "if", "k", "in", "checkpoint_model", "and", "checkpoint_model", "[", "k", "]", ".", "shape", "!=", "state_dict", "[", "k", "]", ".", "shape", ":", "\n", "                ", "print", "(", "f\"Removing key {k} from pretrained checkpoint\"", ")", "\n", "del", "checkpoint_model", "[", "k", "]", "\n", "\n", "", "", "all_keys", "=", "list", "(", "checkpoint_model", ".", "keys", "(", ")", ")", "\n", "new_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "all_keys", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "'backbone.'", ")", ":", "\n", "                ", "new_dict", "[", "key", "[", "9", ":", "]", "]", "=", "checkpoint_model", "[", "key", "]", "\n", "", "elif", "key", ".", "startswith", "(", "'encoder.'", ")", ":", "\n", "                ", "new_dict", "[", "key", "[", "8", ":", "]", "]", "=", "checkpoint_model", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "new_dict", "[", "key", "]", "=", "checkpoint_model", "[", "key", "]", "\n", "", "", "checkpoint_model", "=", "new_dict", "\n", "\n", "# interpolate position embedding", "\n", "if", "'pos_embed'", "in", "checkpoint_model", ":", "\n", "            ", "pos_embed_checkpoint", "=", "checkpoint_model", "[", "'pos_embed'", "]", "\n", "embedding_size", "=", "pos_embed_checkpoint", ".", "shape", "[", "-", "1", "]", "# channel dim", "\n", "num_patches", "=", "model", ".", "patch_embed", ".", "num_patches", "# ", "\n", "num_extra_tokens", "=", "model", ".", "pos_embed", ".", "shape", "[", "-", "2", "]", "-", "num_patches", "# 0/1", "\n", "\n", "# height (== width) for the checkpoint position embedding ", "\n", "orig_size", "=", "int", "(", "(", "(", "pos_embed_checkpoint", ".", "shape", "[", "-", "2", "]", "-", "num_extra_tokens", ")", "//", "(", "args", ".", "num_frames", "//", "model", ".", "patch_embed", ".", "tubelet_size", ")", ")", "**", "0.5", ")", "\n", "# height (== width) for the new position embedding", "\n", "new_size", "=", "int", "(", "(", "num_patches", "//", "(", "args", ".", "num_frames", "//", "model", ".", "patch_embed", ".", "tubelet_size", ")", ")", "**", "0.5", ")", "\n", "# class_token and dist_token are kept unchanged", "\n", "if", "orig_size", "!=", "new_size", ":", "\n", "                ", "print", "(", "\"Position interpolate from %dx%d to %dx%d\"", "%", "(", "orig_size", ",", "orig_size", ",", "new_size", ",", "new_size", ")", ")", "\n", "extra_tokens", "=", "pos_embed_checkpoint", "[", ":", ",", ":", "num_extra_tokens", "]", "\n", "# only the position tokens are interpolated", "\n", "pos_tokens", "=", "pos_embed_checkpoint", "[", ":", ",", "num_extra_tokens", ":", "]", "\n", "# B, L, C -> BT, H, W, C -> BT, C, H, W", "\n", "pos_tokens", "=", "pos_tokens", ".", "reshape", "(", "-", "1", ",", "args", ".", "num_frames", "//", "model", ".", "patch_embed", ".", "tubelet_size", ",", "orig_size", ",", "orig_size", ",", "embedding_size", ")", "\n", "pos_tokens", "=", "pos_tokens", ".", "reshape", "(", "-", "1", ",", "orig_size", ",", "orig_size", ",", "embedding_size", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "pos_tokens", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "pos_tokens", ",", "size", "=", "(", "new_size", ",", "new_size", ")", ",", "mode", "=", "'bicubic'", ",", "align_corners", "=", "False", ")", "\n", "# BT, C, H, W -> BT, H, W, C ->  B, T, H, W, C", "\n", "pos_tokens", "=", "pos_tokens", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "args", ".", "num_frames", "//", "model", ".", "patch_embed", ".", "tubelet_size", ",", "new_size", ",", "new_size", ",", "embedding_size", ")", "\n", "pos_tokens", "=", "pos_tokens", ".", "flatten", "(", "1", ",", "3", ")", "# B, L, C", "\n", "new_pos_embed", "=", "torch", ".", "cat", "(", "(", "extra_tokens", ",", "pos_tokens", ")", ",", "dim", "=", "1", ")", "\n", "checkpoint_model", "[", "'pos_embed'", "]", "=", "new_pos_embed", "\n", "\n", "", "", "utils", ".", "load_state_dict", "(", "model", ",", "checkpoint_model", ",", "prefix", "=", "args", ".", "model_prefix", ")", "\n", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "model_ema", "=", "None", "\n", "if", "args", ".", "model_ema", ":", "\n", "        ", "model_ema", "=", "ModelEma", "(", "\n", "model", ",", "\n", "decay", "=", "args", ".", "model_ema_decay", ",", "\n", "device", "=", "'cpu'", "if", "args", ".", "model_ema_force_cpu", "else", "''", ",", "\n", "resume", "=", "''", ")", "\n", "print", "(", "\"Using EMA with decay = %.8f\"", "%", "args", ".", "model_ema_decay", ")", "\n", "\n", "", "model_without_ddp", "=", "model", "\n", "n_parameters", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n", "print", "(", "\"Model = %s\"", "%", "str", "(", "model_without_ddp", ")", ")", "\n", "print", "(", "'number of params:'", ",", "n_parameters", ")", "\n", "\n", "total_batch_size", "=", "args", ".", "batch_size", "*", "args", ".", "update_freq", "*", "utils", ".", "get_world_size", "(", ")", "\n", "num_training_steps_per_epoch", "=", "len", "(", "dataset_train", ")", "//", "total_batch_size", "\n", "args", ".", "lr", "=", "args", ".", "lr", "*", "total_batch_size", "/", "256", "\n", "args", ".", "min_lr", "=", "args", ".", "min_lr", "*", "total_batch_size", "/", "256", "\n", "args", ".", "warmup_lr", "=", "args", ".", "warmup_lr", "*", "total_batch_size", "/", "256", "\n", "print", "(", "\"LR = %.8f\"", "%", "args", ".", "lr", ")", "\n", "print", "(", "\"Batch size = %d\"", "%", "total_batch_size", ")", "\n", "print", "(", "\"Update frequent = %d\"", "%", "args", ".", "update_freq", ")", "\n", "print", "(", "\"Number of training examples = %d\"", "%", "len", "(", "dataset_train", ")", ")", "\n", "print", "(", "\"Number of training training per epoch = %d\"", "%", "num_training_steps_per_epoch", ")", "\n", "\n", "num_layers", "=", "model_without_ddp", ".", "get_num_layers", "(", ")", "\n", "if", "args", ".", "layer_decay", "<", "1.0", ":", "\n", "        ", "assigner", "=", "LayerDecayValueAssigner", "(", "list", "(", "args", ".", "layer_decay", "**", "(", "num_layers", "+", "1", "-", "i", ")", "for", "i", "in", "range", "(", "num_layers", "+", "2", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "assigner", "=", "None", "\n", "\n", "", "if", "assigner", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Assigned values = %s\"", "%", "str", "(", "assigner", ".", "values", ")", ")", "\n", "\n", "", "skip_weight_decay_list", "=", "model", ".", "no_weight_decay", "(", ")", "\n", "print", "(", "\"Skip weight decay list: \"", ",", "skip_weight_decay_list", ")", "\n", "\n", "if", "args", ".", "enable_deepspeed", ":", "\n", "        ", "loss_scaler", "=", "None", "\n", "optimizer_params", "=", "get_parameter_groups", "(", "\n", "model", ",", "args", ".", "weight_decay", ",", "skip_weight_decay_list", ",", "\n", "assigner", ".", "get_layer_id", "if", "assigner", "is", "not", "None", "else", "None", ",", "\n", "assigner", ".", "get_scale", "if", "assigner", "is", "not", "None", "else", "None", ")", "\n", "model", ",", "optimizer", ",", "_", ",", "_", "=", "ds_init", "(", "\n", "args", "=", "args", ",", "model", "=", "model", ",", "model_parameters", "=", "optimizer_params", ",", "dist_init_required", "=", "not", "args", ".", "distributed", ",", "\n", ")", "\n", "\n", "print", "(", "\"model.gradient_accumulation_steps() = %d\"", "%", "model", ".", "gradient_accumulation_steps", "(", ")", ")", "\n", "assert", "model", ".", "gradient_accumulation_steps", "(", ")", "==", "args", ".", "update_freq", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "distributed", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "find_unused_parameters", "=", "True", ")", "\n", "model_without_ddp", "=", "model", ".", "module", "\n", "\n", "", "optimizer", "=", "create_optimizer", "(", "\n", "args", ",", "model_without_ddp", ",", "skip_list", "=", "skip_weight_decay_list", ",", "\n", "get_num_layer", "=", "assigner", ".", "get_layer_id", "if", "assigner", "is", "not", "None", "else", "None", ",", "\n", "get_layer_scale", "=", "assigner", ".", "get_scale", "if", "assigner", "is", "not", "None", "else", "None", ")", "\n", "loss_scaler", "=", "NativeScaler", "(", ")", "\n", "\n", "", "print", "(", "\"Use step level LR scheduler!\"", ")", "\n", "lr_schedule_values", "=", "utils", ".", "cosine_scheduler", "(", "\n", "args", ".", "lr", ",", "args", ".", "min_lr", ",", "args", ".", "epochs", ",", "num_training_steps_per_epoch", ",", "\n", "warmup_epochs", "=", "args", ".", "warmup_epochs", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "\n", ")", "\n", "if", "args", ".", "weight_decay_end", "is", "None", ":", "\n", "        ", "args", ".", "weight_decay_end", "=", "args", ".", "weight_decay", "\n", "", "wd_schedule_values", "=", "utils", ".", "cosine_scheduler", "(", "\n", "args", ".", "weight_decay", ",", "args", ".", "weight_decay_end", ",", "args", ".", "epochs", ",", "num_training_steps_per_epoch", ")", "\n", "print", "(", "\"Max WD = %.7f, Min WD = %.7f\"", "%", "(", "max", "(", "wd_schedule_values", ")", ",", "min", "(", "wd_schedule_values", ")", ")", ")", "\n", "\n", "if", "mixup_fn", "is", "not", "None", ":", "\n", "# smoothing is handled with mixup label transform", "\n", "        ", "criterion", "=", "SoftTargetCrossEntropy", "(", ")", "\n", "", "elif", "args", ".", "smoothing", ">", "0.", ":", "\n", "        ", "criterion", "=", "LabelSmoothingCrossEntropy", "(", "smoothing", "=", "args", ".", "smoothing", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "", "print", "(", "\"criterion = %s\"", "%", "str", "(", "criterion", ")", ")", "\n", "\n", "utils", ".", "auto_load_model", "(", "\n", "args", "=", "args", ",", "model", "=", "model", ",", "model_without_ddp", "=", "model_without_ddp", ",", "\n", "optimizer", "=", "optimizer", ",", "loss_scaler", "=", "loss_scaler", ",", "model_ema", "=", "model_ema", ")", "\n", "\n", "if", "args", ".", "eval", ":", "\n", "        ", "preds_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "str", "(", "global_rank", ")", "+", "'.txt'", ")", "\n", "test_stats", "=", "final_test", "(", "data_loader_test", ",", "model", ",", "device", ",", "preds_file", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "if", "global_rank", "==", "0", ":", "\n", "            ", "print", "(", "\"Start merging results...\"", ")", "\n", "final_top1", ",", "final_top5", "=", "merge", "(", "args", ".", "output_dir", ",", "num_tasks", ")", "\n", "print", "(", "f\"Accuracy of the network on the {len(dataset_test)} test videos: Top-1: {final_top1:.2f}%, Top-5: {final_top5:.2f}%\"", ")", "\n", "log_stats", "=", "{", "'Final top-1'", ":", "final_top1", ",", "\n", "'Final Top-5'", ":", "final_top1", "}", "\n", "if", "args", ".", "output_dir", "and", "utils", ".", "is_main_process", "(", ")", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"log.txt\"", ")", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "json", ".", "dumps", "(", "log_stats", ")", "+", "\"\\n\"", ")", "\n", "", "", "", "exit", "(", "0", ")", "\n", "\n", "\n", "", "print", "(", "f\"Start training for {args.epochs} epochs\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "max_accuracy", "=", "0.0", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "args", ".", "distributed", ":", "\n", "            ", "data_loader_train", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "if", "log_writer", "is", "not", "None", ":", "\n", "            ", "log_writer", ".", "set_step", "(", "epoch", "*", "num_training_steps_per_epoch", "*", "args", ".", "update_freq", ")", "\n", "", "train_stats", "=", "train_one_epoch", "(", "\n", "model", ",", "criterion", ",", "data_loader_train", ",", "optimizer", ",", "\n", "device", ",", "epoch", ",", "loss_scaler", ",", "args", ".", "clip_grad", ",", "model_ema", ",", "mixup_fn", ",", "\n", "log_writer", "=", "log_writer", ",", "start_steps", "=", "epoch", "*", "num_training_steps_per_epoch", ",", "\n", "lr_schedule_values", "=", "lr_schedule_values", ",", "wd_schedule_values", "=", "wd_schedule_values", ",", "\n", "num_training_steps_per_epoch", "=", "num_training_steps_per_epoch", ",", "update_freq", "=", "args", ".", "update_freq", ",", "\n", ")", "\n", "if", "args", ".", "output_dir", "and", "args", ".", "save_ckpt", ":", "\n", "            ", "if", "(", "epoch", "+", "1", ")", "%", "args", ".", "save_ckpt_freq", "==", "0", "or", "epoch", "+", "1", "==", "args", ".", "epochs", ":", "\n", "                ", "utils", ".", "save_model", "(", "\n", "args", "=", "args", ",", "model", "=", "model", ",", "model_without_ddp", "=", "model_without_ddp", ",", "optimizer", "=", "optimizer", ",", "\n", "loss_scaler", "=", "loss_scaler", ",", "epoch", "=", "epoch", ",", "model_ema", "=", "model_ema", ")", "\n", "", "", "if", "data_loader_val", "is", "not", "None", ":", "\n", "            ", "test_stats", "=", "validation_one_epoch", "(", "data_loader_val", ",", "model", ",", "device", ")", "\n", "print", "(", "f\"Accuracy of the network on the {len(dataset_val)} val videos: {test_stats['acc1']:.1f}%\"", ")", "\n", "if", "max_accuracy", "<", "test_stats", "[", "\"acc1\"", "]", ":", "\n", "                ", "max_accuracy", "=", "test_stats", "[", "\"acc1\"", "]", "\n", "if", "args", ".", "output_dir", "and", "args", ".", "save_ckpt", ":", "\n", "                    ", "utils", ".", "save_model", "(", "\n", "args", "=", "args", ",", "model", "=", "model", ",", "model_without_ddp", "=", "model_without_ddp", ",", "optimizer", "=", "optimizer", ",", "\n", "loss_scaler", "=", "loss_scaler", ",", "epoch", "=", "\"best\"", ",", "model_ema", "=", "model_ema", ")", "\n", "\n", "", "", "print", "(", "f'Max accuracy: {max_accuracy:.2f}%'", ")", "\n", "if", "log_writer", "is", "not", "None", ":", "\n", "                ", "log_writer", ".", "update", "(", "val_acc1", "=", "test_stats", "[", "'acc1'", "]", ",", "head", "=", "\"perf\"", ",", "step", "=", "epoch", ")", "\n", "log_writer", ".", "update", "(", "val_acc5", "=", "test_stats", "[", "'acc5'", "]", ",", "head", "=", "\"perf\"", ",", "step", "=", "epoch", ")", "\n", "log_writer", ".", "update", "(", "val_loss", "=", "test_stats", "[", "'loss'", "]", ",", "head", "=", "\"perf\"", ",", "step", "=", "epoch", ")", "\n", "\n", "", "log_stats", "=", "{", "**", "{", "f'train_{k}'", ":", "v", "for", "k", ",", "v", "in", "train_stats", ".", "items", "(", ")", "}", ",", "\n", "**", "{", "f'val_{k}'", ":", "v", "for", "k", ",", "v", "in", "test_stats", ".", "items", "(", ")", "}", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'n_parameters'", ":", "n_parameters", "}", "\n", "", "else", ":", "\n", "            ", "log_stats", "=", "{", "**", "{", "f'train_{k}'", ":", "v", "for", "k", ",", "v", "in", "train_stats", ".", "items", "(", ")", "}", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'n_parameters'", ":", "n_parameters", "}", "\n", "", "if", "args", ".", "output_dir", "and", "utils", ".", "is_main_process", "(", ")", ":", "\n", "            ", "if", "log_writer", "is", "not", "None", ":", "\n", "                ", "log_writer", ".", "flush", "(", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"log.txt\"", ")", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "log_stats", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "preds_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "str", "(", "global_rank", ")", "+", "'.txt'", ")", "\n", "test_stats", "=", "final_test", "(", "data_loader_test", ",", "model", ",", "device", ",", "preds_file", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "if", "global_rank", "==", "0", ":", "\n", "        ", "print", "(", "\"Start merging results...\"", ")", "\n", "final_top1", ",", "final_top5", "=", "merge", "(", "args", ".", "output_dir", ",", "num_tasks", ")", "\n", "print", "(", "f\"Accuracy of the network on the {len(dataset_test)} test videos: Top-1: {final_top1:.2f}%, Top-5: {final_top5:.2f}%\"", ")", "\n", "log_stats", "=", "{", "'Final top-1'", ":", "final_top1", ",", "\n", "'Final Top-5'", ":", "final_top5", "}", "\n", "if", "args", ".", "output_dir", "and", "utils", ".", "is_main_process", "(", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"log.txt\"", ")", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "log_stats", ")", "+", "\"\\n\"", ")", "\n", "\n", "\n", "", "", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "print", "(", "'Training time {}'", ".", "format", "(", "total_time_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__init__": [[10, 24], ["torchvision.transforms.GroupNormalize", "torchvision.transforms.GroupMultiScaleCrop", "torchvision.transforms.Compose", "masking_generator.TubeMaskingGenerator", "torchvision.transforms.Stack", "torchvision.transforms.ToTorchFormatTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "input_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "# IMAGENET_DEFAULT_MEAN", "\n", "self", ".", "input_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "# IMAGENET_DEFAULT_STD", "\n", "normalize", "=", "GroupNormalize", "(", "self", ".", "input_mean", ",", "self", ".", "input_std", ")", "\n", "self", ".", "train_augmentation", "=", "GroupMultiScaleCrop", "(", "args", ".", "input_size", ",", "[", "1", ",", ".875", ",", ".75", ",", ".66", "]", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "self", ".", "train_augmentation", ",", "\n", "Stack", "(", "roll", "=", "False", ")", ",", "\n", "ToTorchFormatTensor", "(", "div", "=", "True", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "if", "args", ".", "mask_type", "==", "'tube'", ":", "\n", "            ", "self", ".", "masked_position_generator", "=", "TubeMaskingGenerator", "(", "\n", "args", ".", "window_size", ",", "args", ".", "mask_ratio", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__call__": [[26, 29], ["datasets.DataAugmentationForVideoMAE.transform", "datasets.DataAugmentationForVideoMAE.masked_position_generator"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "process_data", ",", "_", "=", "self", ".", "transform", "(", "images", ")", "\n", "return", "process_data", ",", "self", ".", "masked_position_generator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.DataAugmentationForVideoMAE.__repr__": [[30, 36], ["str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr", "=", "\"(DataAugmentationForVideoMAE,\\n\"", "\n", "repr", "+=", "\"  transform = %s,\\n\"", "%", "str", "(", "self", ".", "transform", ")", "\n", "repr", "+=", "\"  Masked position generator = %s,\\n\"", "%", "str", "(", "self", ".", "masked_position_generator", ")", "\n", "repr", "+=", "\")\"", "\n", "return", "repr", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.build_pretraining_dataset": [[38, 55], ["datasets.DataAugmentationForVideoMAE", "kinetics.VideoMAE", "print", "str"], "function", ["None"], ["", "", "def", "build_pretraining_dataset", "(", "args", ")", ":", "\n", "    ", "transform", "=", "DataAugmentationForVideoMAE", "(", "args", ")", "\n", "dataset", "=", "VideoMAE", "(", "\n", "root", "=", "None", ",", "\n", "setting", "=", "args", ".", "data_path", ",", "\n", "video_ext", "=", "'mp4'", ",", "\n", "is_color", "=", "True", ",", "\n", "modality", "=", "'rgb'", ",", "\n", "new_length", "=", "args", ".", "num_frames", ",", "\n", "new_step", "=", "args", ".", "sampling_rate", ",", "\n", "transform", "=", "transform", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "video_loader", "=", "True", ",", "\n", "use_decord", "=", "True", ",", "\n", "lazy_init", "=", "False", ")", "\n", "print", "(", "\"Data Aug = %s\"", "%", "str", "(", "transform", ")", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_VideoMAE.None.datasets.build_dataset": [[57, 186], ["print", "kinetics.VideoClsDataset", "os.path.join", "ssv2.SSVideoClsDataset", "os.path.join", "os.path.join", "os.path.join", "kinetics.VideoClsDataset", "os.path.join", "os.path.join", "os.path.join", "kinetics.VideoClsDataset", "NotImplementedError", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "build_dataset", "(", "is_train", ",", "test_mode", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "data_set", "==", "'Kinetics-400'", ":", "\n", "        ", "mode", "=", "None", "\n", "anno_path", "=", "None", "\n", "if", "is_train", "is", "True", ":", "\n", "            ", "mode", "=", "'train'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'train.csv'", ")", "\n", "", "elif", "test_mode", "is", "True", ":", "\n", "            ", "mode", "=", "'test'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'val.csv'", ")", "\n", "", "else", ":", "\n", "            ", "mode", "=", "'validation'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'test.csv'", ")", "\n", "\n", "", "dataset", "=", "VideoClsDataset", "(", "\n", "anno_path", "=", "anno_path", ",", "\n", "data_path", "=", "'/'", ",", "\n", "mode", "=", "mode", ",", "\n", "clip_len", "=", "args", ".", "num_frames", ",", "\n", "frame_sample_rate", "=", "args", ".", "sampling_rate", ",", "\n", "num_segment", "=", "1", ",", "\n", "test_num_segment", "=", "args", ".", "test_num_segment", ",", "\n", "test_num_crop", "=", "args", ".", "test_num_crop", ",", "\n", "num_crop", "=", "1", "if", "not", "test_mode", "else", "3", ",", "\n", "keep_aspect_ratio", "=", "True", ",", "\n", "crop_size", "=", "args", ".", "input_size", ",", "\n", "short_side_size", "=", "args", ".", "short_side_size", ",", "\n", "new_height", "=", "256", ",", "\n", "new_width", "=", "320", ",", "\n", "args", "=", "args", ")", "\n", "nb_classes", "=", "400", "\n", "\n", "", "elif", "args", ".", "data_set", "==", "'SSV2'", ":", "\n", "        ", "mode", "=", "None", "\n", "anno_path", "=", "None", "\n", "if", "is_train", "is", "True", ":", "\n", "            ", "mode", "=", "'train'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'train.csv'", ")", "\n", "", "elif", "test_mode", "is", "True", ":", "\n", "            ", "mode", "=", "'test'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'val.csv'", ")", "\n", "", "else", ":", "\n", "            ", "mode", "=", "'validation'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'test.csv'", ")", "\n", "\n", "", "dataset", "=", "SSVideoClsDataset", "(", "\n", "anno_path", "=", "anno_path", ",", "\n", "data_path", "=", "'/'", ",", "\n", "mode", "=", "mode", ",", "\n", "clip_len", "=", "1", ",", "\n", "num_segment", "=", "args", ".", "num_frames", ",", "\n", "test_num_segment", "=", "args", ".", "test_num_segment", ",", "\n", "test_num_crop", "=", "args", ".", "test_num_crop", ",", "\n", "num_crop", "=", "1", "if", "not", "test_mode", "else", "3", ",", "\n", "keep_aspect_ratio", "=", "True", ",", "\n", "crop_size", "=", "args", ".", "input_size", ",", "\n", "short_side_size", "=", "args", ".", "short_side_size", ",", "\n", "new_height", "=", "256", ",", "\n", "new_width", "=", "320", ",", "\n", "args", "=", "args", ")", "\n", "nb_classes", "=", "174", "\n", "\n", "", "elif", "args", ".", "data_set", "==", "'UCF101'", ":", "\n", "        ", "mode", "=", "None", "\n", "anno_path", "=", "None", "\n", "if", "is_train", "is", "True", ":", "\n", "            ", "mode", "=", "'train'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'train.csv'", ")", "\n", "", "elif", "test_mode", "is", "True", ":", "\n", "            ", "mode", "=", "'test'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'val.csv'", ")", "\n", "", "else", ":", "\n", "            ", "mode", "=", "'validation'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'test.csv'", ")", "\n", "\n", "", "dataset", "=", "VideoClsDataset", "(", "\n", "anno_path", "=", "anno_path", ",", "\n", "data_path", "=", "'/'", ",", "\n", "mode", "=", "mode", ",", "\n", "clip_len", "=", "args", ".", "num_frames", ",", "\n", "frame_sample_rate", "=", "args", ".", "sampling_rate", ",", "\n", "num_segment", "=", "1", ",", "\n", "test_num_segment", "=", "args", ".", "test_num_segment", ",", "\n", "test_num_crop", "=", "args", ".", "test_num_crop", ",", "\n", "num_crop", "=", "1", "if", "not", "test_mode", "else", "3", ",", "\n", "keep_aspect_ratio", "=", "True", ",", "\n", "crop_size", "=", "args", ".", "input_size", ",", "\n", "short_side_size", "=", "args", ".", "short_side_size", ",", "\n", "new_height", "=", "256", ",", "\n", "new_width", "=", "320", ",", "\n", "args", "=", "args", ")", "\n", "nb_classes", "=", "101", "\n", "\n", "", "elif", "args", ".", "data_set", "==", "'HMDB51'", ":", "\n", "        ", "mode", "=", "None", "\n", "anno_path", "=", "None", "\n", "if", "is_train", "is", "True", ":", "\n", "            ", "mode", "=", "'train'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'train.csv'", ")", "\n", "", "elif", "test_mode", "is", "True", ":", "\n", "            ", "mode", "=", "'test'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'val.csv'", ")", "\n", "", "else", ":", "\n", "            ", "mode", "=", "'validation'", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "'test.csv'", ")", "\n", "\n", "", "dataset", "=", "VideoClsDataset", "(", "\n", "anno_path", "=", "anno_path", ",", "\n", "data_path", "=", "'/'", ",", "\n", "mode", "=", "mode", ",", "\n", "clip_len", "=", "args", ".", "num_frames", ",", "\n", "frame_sample_rate", "=", "args", ".", "sampling_rate", ",", "\n", "num_segment", "=", "1", ",", "\n", "test_num_segment", "=", "args", ".", "test_num_segment", ",", "\n", "test_num_crop", "=", "args", ".", "test_num_crop", ",", "\n", "num_crop", "=", "1", "if", "not", "test_mode", "else", "3", ",", "\n", "keep_aspect_ratio", "=", "True", ",", "\n", "crop_size", "=", "args", ".", "input_size", ",", "\n", "short_side_size", "=", "args", ".", "short_side_size", ",", "\n", "new_height", "=", "256", ",", "\n", "new_width", "=", "320", ",", "\n", "args", "=", "args", ")", "\n", "nb_classes", "=", "51", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "assert", "nb_classes", "==", "args", ".", "nb_classes", "\n", "print", "(", "\"Number of the class = %d\"", "%", "args", ".", "nb_classes", ")", "\n", "\n", "return", "dataset", ",", "nb_classes", "\n", "", ""]]}