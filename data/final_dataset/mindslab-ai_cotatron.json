{"home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron_trainer.main": [[12, 52], ["cotatron.Cotatron", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.merge", "os.path.join", "os.makedirs", "pytorch_lightning.callbacks.ModelCheckpoint", "utils.loggers.TacotronLogger", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.fit", "os.path.join", "utils.utils.get_commit_hash"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.utils.get_commit_hash"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "model", "=", "Cotatron", "(", "args", ")", "\n", "\n", "hp_global", "=", "OmegaConf", ".", "load", "(", "args", ".", "config", "[", "0", "]", ")", "\n", "hp_cota", "=", "OmegaConf", ".", "load", "(", "args", ".", "config", "[", "1", "]", ")", "\n", "\n", "hp", "=", "OmegaConf", ".", "merge", "(", "hp_global", ",", "hp_cota", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "hp", ".", "log", ".", "chkpt_dir", ",", "args", ".", "name", ")", "\n", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "hp", ".", "log", ".", "chkpt_dir", ",", "args", ".", "name", ")", ",", "\n", "monitor", "=", "'val_loss'", ",", "\n", "verbose", "=", "True", ",", "\n", "save_top_k", "=", "args", ".", "save_top_k", ",", "# save all", "\n", "prefix", "=", "get_commit_hash", "(", ")", ",", "\n", ")", "\n", "\n", "tb_logger", "=", "TacotronLogger", "(", "\n", "save_dir", "=", "hp", ".", "log", ".", "log_dir", ",", "\n", "name", "=", "args", ".", "name", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "logger", "=", "tb_logger", ",", "\n", "early_stop_callback", "=", "None", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "default_save_path", "=", "save_path", ",", "\n", "gpus", "=", "-", "1", "if", "args", ".", "gpus", "is", "None", "else", "args", ".", "gpus", ",", "\n", "distributed_backend", "=", "'ddp'", ",", "\n", "num_sanity_val_steps", "=", "1", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "checkpoint_path", ",", "\n", "gradient_clip_val", "=", "hp", ".", "train", ".", "grad_clip", ",", "\n", "fast_dev_run", "=", "args", ".", "fast_dev_run", ",", "\n", "check_val_every_n_epoch", "=", "args", ".", "val_epoch", ",", "\n", "progress_bar_refresh_rate", "=", "1", ",", "\n", "max_epochs", "=", "10000", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.__init__": [[18, 37], ["pytorch_lightning.LightningModule.__init__", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.merge", "datasets.text.Language().get_symbols", "modules.TextEncoder", "modules.SpeakerEncoder", "modules.SpkClassifier", "modules.TTSDecoder", "modules.Audio2Mel", "len", "datasets.text.Language"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language.get_symbols"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "# used for pl", "\n", "hp_global", "=", "OmegaConf", ".", "load", "(", "hparams", ".", "config", "[", "0", "]", ")", "\n", "hp_cota", "=", "OmegaConf", ".", "load", "(", "hparams", ".", "config", "[", "1", "]", ")", "\n", "hp", "=", "OmegaConf", ".", "merge", "(", "hp_global", ",", "hp_cota", ")", "\n", "self", ".", "hp", "=", "hp", "\n", "\n", "self", ".", "symbols", "=", "Language", "(", "hp", ".", "data", ".", "lang", ",", "hp", ".", "data", ".", "text_cleaners", ")", ".", "get_symbols", "(", ")", "\n", "self", ".", "symbols", "=", "[", "'\"{}\"'", ".", "format", "(", "symbol", ")", "for", "symbol", "in", "self", ".", "symbols", "]", "\n", "self", ".", "encoder", "=", "TextEncoder", "(", "hp", ".", "chn", ".", "encoder", ",", "hp", ".", "ker", ".", "encoder", ",", "hp", ".", "depth", ".", "encoder", ",", "len", "(", "self", ".", "symbols", ")", ")", "\n", "self", ".", "speaker", "=", "SpeakerEncoder", "(", "hp", ")", "\n", "self", ".", "classifier", "=", "SpkClassifier", "(", "hp", ")", "\n", "self", ".", "decoder", "=", "TTSDecoder", "(", "hp", ")", "\n", "\n", "self", ".", "audio2mel", "=", "Audio2Mel", "(", "hp", ".", "audio", ".", "filter_length", ",", "hp", ".", "audio", ".", "hop_length", ",", "hp", ".", "audio", ".", "win_length", ",", "\n", "hp", ".", "audio", ".", "sampling_rate", ",", "hp", ".", "audio", ".", "n_mel_channels", ",", "hp", ".", "audio", ".", "mel_fmin", ",", "hp", ".", "audio", ".", "mel_fmax", ")", "\n", "\n", "self", ".", "is_val_first", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.forward": [[38, 48], ["cotatron.Cotatron.encoder", "cotatron.Cotatron.speaker", "cotatron.Cotatron.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cotatron.Cotatron.decoder", "cotatron.Cotatron.size", "cotatron.Cotatron.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "text", ",", "mel_target", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ",", "\n", "prenet_dropout", "=", "0.5", ",", "no_mask", "=", "False", ",", "tfrate", "=", "True", ")", ":", "\n", "        ", "text_encoding", "=", "self", ".", "encoder", "(", "text", ",", "input_lengths", ")", "# [B, T, chn.encoder]", "\n", "speaker_emb", "=", "self", ".", "speaker", "(", "mel_target", ",", "output_lengths", ")", "# [B, chn.speaker]", "\n", "speaker_emb_rep", "=", "speaker_emb", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "text_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "# [B, T, chn.speaker]", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "(", "text_encoding", ",", "speaker_emb_rep", ")", ",", "dim", "=", "2", ")", "# [B, T, (chn.encoder + chn.speaker)]", "\n", "mel_pred", ",", "mel_postnet", ",", "alignment", "=", "self", ".", "decoder", "(", "mel_target", ",", "decoder_input", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ",", "\n", "prenet_dropout", ",", "no_mask", ",", "tfrate", ")", "\n", "return", "speaker_emb", ",", "mel_pred", ",", "mel_postnet", ",", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.inference": [[49, 62], ["torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "cotatron.Cotatron.encoder.inference", "cotatron.Cotatron.speaker.inference", "cotatron.Cotatron.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cotatron.Cotatron.decoder", "cotatron.Cotatron.size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "cotatron.Cotatron.unsqueeze", "text.size", "mel_target.size"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.inference", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.inference"], ["", "def", "inference", "(", "self", ",", "text", ",", "mel_target", ")", ":", "\n", "        ", "device", "=", "text", ".", "device", "\n", "in_len", "=", "torch", ".", "LongTensor", "(", "[", "text", ".", "size", "(", "1", ")", "]", ")", ".", "to", "(", "device", ")", "\n", "out_len", "=", "torch", ".", "LongTensor", "(", "[", "mel_target", ".", "size", "(", "2", ")", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "text_encoding", "=", "self", ".", "encoder", ".", "inference", "(", "text", ")", "\n", "speaker_emb", "=", "self", ".", "speaker", ".", "inference", "(", "mel_target", ")", "\n", "speaker_emb_rep", "=", "speaker_emb", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "text_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "(", "text_encoding", ",", "speaker_emb_rep", ")", ",", "dim", "=", "2", ")", "\n", "_", ",", "mel_postnet", ",", "alignment", "=", "self", ".", "decoder", "(", "mel_target", ",", "decoder_input", ",", "in_len", ",", "out_len", ",", "in_len", ",", "\n", "prenet_dropout", "=", "0.0", ",", "no_mask", "=", "True", ",", "tfrate", "=", "False", ")", "\n", "return", "mel_postnet", ",", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.training_step": [[63, 75], ["cotatron.Cotatron.forward", "cotatron.Cotatron.classifier", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "cotatron.Cotatron.logger.log_loss", "cotatron.Cotatron.logger.log_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.forward", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_loss", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_loss"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "text", ",", "mel_target", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", "=", "batch", "\n", "speaker_emb", ",", "mel_pred", ",", "mel_postnet", ",", "_", "=", "self", ".", "forward", "(", "text", ",", "mel_target", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ")", "\n", "speaker_prob", "=", "self", ".", "classifier", "(", "speaker_emb", ")", "\n", "classifier_loss", "=", "F", ".", "nll_loss", "(", "speaker_prob", ",", "speakers", ")", "\n", "\n", "loss_rec", "=", "F", ".", "mse_loss", "(", "mel_pred", ",", "mel_target", ")", "+", "F", ".", "mse_loss", "(", "mel_postnet", ",", "mel_target", ")", "\n", "self", ".", "logger", ".", "log_loss", "(", "loss_rec", ",", "mode", "=", "'train'", ",", "step", "=", "self", ".", "global_step", ",", "name", "=", "'reconstruction'", ")", "\n", "self", ".", "logger", ".", "log_loss", "(", "classifier_loss", ",", "mode", "=", "'train'", ",", "step", "=", "self", ".", "global_step", ",", "name", "=", "'classifier'", ")", "\n", "\n", "return", "{", "'loss'", ":", "loss_rec", "+", "classifier_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.validation_step": [[76, 92], ["cotatron.Cotatron.forward", "cotatron.Cotatron.classifier", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "cotatron.Cotatron.logger.log_figures", "cotatron.Cotatron.logger.log_embedding"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.forward", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_figures", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.TacotronLogger.log_embedding"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "text", ",", "mel_target", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", "=", "batch", "\n", "speaker_emb", ",", "mel_pred", ",", "mel_postnet", ",", "alignment", "=", "self", ".", "forward", "(", "text", ",", "mel_target", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ",", "\n", "prenet_dropout", "=", "0.0", ",", "tfrate", "=", "False", ")", "\n", "speaker_prob", "=", "self", ".", "classifier", "(", "speaker_emb", ")", "\n", "classifier_loss", "=", "F", ".", "nll_loss", "(", "speaker_prob", ",", "speakers", ")", "\n", "\n", "loss_rec", "=", "F", ".", "mse_loss", "(", "mel_pred", ",", "mel_target", ")", "+", "F", ".", "mse_loss", "(", "mel_postnet", ",", "mel_target", ")", "\n", "\n", "if", "self", ".", "is_val_first", ":", "# plot alignment, character embedding", "\n", "            ", "self", ".", "is_val_first", "=", "False", "\n", "self", ".", "logger", ".", "log_figures", "(", "mel_pred", ",", "mel_postnet", ",", "mel_target", ",", "alignment", ",", "self", ".", "global_step", ")", "\n", "self", ".", "logger", ".", "log_embedding", "(", "self", ".", "symbols", ",", "self", ".", "encoder", ".", "embedding", ".", "weight", ",", "self", ".", "global_step", ")", "\n", "\n", "", "return", "{", "'loss_rec'", ":", "loss_rec", ",", "'classifier_loss'", ":", "classifier_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.validation_end": [[93, 101], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "cotatron.Cotatron.logger.log_loss", "cotatron.Cotatron.logger.log_loss", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_loss", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_loss"], ["", "def", "validation_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "loss_rec", "=", "torch", ".", "stack", "(", "[", "x", "[", "'loss_rec'", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "classifier_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "'classifier_loss'", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "self", ".", "logger", ".", "log_loss", "(", "loss_rec", ",", "mode", "=", "'val'", ",", "step", "=", "self", ".", "global_step", ",", "name", "=", "'reconstruction'", ")", "\n", "self", ".", "logger", ".", "log_loss", "(", "classifier_loss", ",", "mode", "=", "'val'", ",", "step", "=", "self", ".", "global_step", ",", "name", "=", "'classifier'", ")", "\n", "self", ".", "is_val_first", "=", "True", "\n", "\n", "return", "{", "'val_loss'", ":", "loss_rec", "+", "classifier_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.configure_optimizers": [[102, 107], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "cotatron.Cotatron.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "hp", ".", "train", ".", "adam", ".", "lr", ",", "\n", "weight_decay", "=", "self", ".", "hp", ".", "train", ".", "adam", ".", "weight_decay", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.lr_lambda": [[109, 112], ["numpy.clip"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "progress", "=", "(", "step", "-", "self", ".", "hp", ".", "train", ".", "decay", ".", "start", ")", "/", "(", "self", ".", "hp", ".", "train", ".", "decay", ".", "end", "-", "self", ".", "hp", ".", "train", ".", "decay", ".", "start", ")", "\n", "return", "self", ".", "hp", ".", "train", ".", "decay", ".", "rate", "**", "np", ".", "clip", "(", "progress", ",", "0.0", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.optimizer_step": [[113, 122], ["cotatron.Cotatron.lr_lambda", "optimizer.step", "optimizer.zero_grad", "cotatron.Cotatron.logger.log_learning_rate"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.lr_lambda", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.TacotronLogger.log_learning_rate"], ["", "def", "optimizer_step", "(", "self", ",", "epoch_nb", ",", "batch_nb", ",", "optimizer", ",", "optimizer_idx", ",", "second_order_closure", ")", ":", "\n", "        ", "lr_scale", "=", "self", ".", "lr_lambda", "(", "self", ".", "global_step", ")", "\n", "for", "pg", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "pg", "[", "'lr'", "]", "=", "lr_scale", "*", "self", ".", "hp", ".", "train", ".", "adam", ".", "lr", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "self", ".", "logger", ".", "log_learning_rate", "(", "lr_scale", "*", "self", ".", "hp", ".", "train", ".", "adam", ".", "lr", ",", "self", ".", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.train_dataloader": [[123, 128], ["datasets.TextMelDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "trainset", "=", "TextMelDataset", "(", "self", ".", "hp", ",", "self", ".", "hp", ".", "data", ".", "train_dir", ",", "self", ".", "hp", ".", "data", ".", "train_meta", ",", "train", "=", "True", ",", "norm", "=", "True", ")", "\n", "return", "DataLoader", "(", "trainset", ",", "batch_size", "=", "self", ".", "hp", ".", "train", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "hp", ".", "train", ".", "num_workers", ",", "\n", "collate_fn", "=", "text_mel_collate", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.cotatron.Cotatron.val_dataloader": [[129, 134], ["datasets.TextMelDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "valset", "=", "TextMelDataset", "(", "self", ".", "hp", ",", "self", ".", "hp", ".", "data", ".", "val_dir", ",", "self", ".", "hp", ".", "data", ".", "val_meta", ",", "train", "=", "False", ",", "norm", "=", "True", ")", "\n", "return", "DataLoader", "(", "valset", ",", "batch_size", "=", "self", ".", "hp", ".", "train", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "hp", ".", "train", ".", "num_workers", ",", "\n", "collate_fn", "=", "text_mel_collate", ",", "pin_memory", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer_trainer.main": [[12, 57], ["synthesizer.Synthesizer", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.merge", "os.path.join", "os.makedirs", "pytorch_lightning.callbacks.ModelCheckpoint", "utils.loggers.SynthesizerLogger", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.fit", "synthesizer.Synthesizer.load_cotatron", "os.path.join", "utils.utils.get_commit_hash"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.load_cotatron", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.utils.get_commit_hash"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "model", "=", "Synthesizer", "(", "args", ")", "\n", "\n", "hp_global", "=", "OmegaConf", ".", "load", "(", "args", ".", "config", "[", "0", "]", ")", "\n", "hp_vc", "=", "OmegaConf", ".", "load", "(", "args", ".", "config", "[", "1", "]", ")", "\n", "\n", "hp", "=", "OmegaConf", ".", "merge", "(", "hp_global", ",", "hp_vc", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "hp", ".", "log", ".", "chkpt_dir", ",", "args", ".", "name", ")", "\n", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "hp", ".", "log", ".", "chkpt_dir", ",", "args", ".", "name", ")", ",", "\n", "monitor", "=", "'val_loss'", ",", "\n", "verbose", "=", "True", ",", "\n", "save_top_k", "=", "args", ".", "save_top_k", ",", "# save all", "\n", "prefix", "=", "get_commit_hash", "(", ")", ",", "\n", ")", "\n", "\n", "tb_logger", "=", "SynthesizerLogger", "(", "\n", "save_dir", "=", "hp", ".", "log", ".", "log_dir", ",", "\n", "name", "=", "args", ".", "name", ",", "\n", ")", "\n", "\n", "if", "args", ".", "checkpoint_path", "is", "None", ":", "\n", "        ", "assert", "hp", ".", "train", ".", "cotatron_path", "is", "not", "None", ",", "\"pretrained aligner must be given as h.p. when not resuming\"", "\n", "model", ".", "load_cotatron", "(", "hp", ".", "train", ".", "cotatron_path", ")", "\n", "\n", "", "trainer", "=", "Trainer", "(", "\n", "logger", "=", "tb_logger", ",", "\n", "early_stop_callback", "=", "None", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "default_save_path", "=", "save_path", ",", "\n", "gpus", "=", "-", "1", "if", "args", ".", "gpus", "is", "None", "else", "args", ".", "gpus", ",", "\n", "distributed_backend", "=", "'ddp'", ",", "\n", "num_sanity_val_steps", "=", "1", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "checkpoint_path", ",", "\n", "gradient_clip_val", "=", "0.0", ",", "\n", "fast_dev_run", "=", "args", ".", "fast_dev_run", ",", "\n", "check_val_every_n_epoch", "=", "args", ".", "val_epoch", ",", "\n", "progress_bar_refresh_rate", "=", "1", ",", "\n", "max_epochs", "=", "10000", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.__init__": [[18, 33], ["pytorch_lightning.LightningModule.__init__", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.merge", "len", "cotatron.Cotatron", "modules.ResidualEncoder", "modules.VCDecoder", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "# used for pl", "\n", "hp_global", "=", "OmegaConf", ".", "load", "(", "hparams", ".", "config", "[", "0", "]", ")", "\n", "hp_vc", "=", "OmegaConf", ".", "load", "(", "hparams", ".", "config", "[", "1", "]", ")", "\n", "hp", "=", "OmegaConf", ".", "merge", "(", "hp_global", ",", "hp_vc", ")", "\n", "self", ".", "hp", "=", "hp", "\n", "\n", "self", ".", "num_speakers", "=", "len", "(", "self", ".", "hp", ".", "data", ".", "speakers", ")", "\n", "self", ".", "cotatron", "=", "Cotatron", "(", "hparams", ")", "\n", "self", ".", "residual_encoder", "=", "ResidualEncoder", "(", "hp", ")", "\n", "self", ".", "decoder", "=", "VCDecoder", "(", "hp", ")", "\n", "self", ".", "speaker", "=", "nn", ".", "Embedding", "(", "self", ".", "num_speakers", ",", "hp", ".", "chn", ".", "speaker", ".", "token", ")", "\n", "\n", "self", ".", "is_val_first", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.load_cotatron": [[34, 40], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "synthesizer.Synthesizer.cotatron.load_state_dict", "synthesizer.Synthesizer.cotatron.eval", "synthesizer.Synthesizer.cotatron.freeze"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.eval"], ["", "def", "load_cotatron", "(", "self", ",", "checkpoint_path", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ")", "\n", "self", ".", "cotatron", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "\n", "self", ".", "cotatron", ".", "eval", "(", ")", "\n", "self", ".", "cotatron", ".", "freeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.train": [[44, 52], ["synthesizer.Synthesizer.children", "synthesizer.Synthesizer.cotatron.eval", "synthesizer.Synthesizer.cotatron.freeze", "module.train"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.eval", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.train"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "self", ".", "training", "=", "mode", "\n", "for", "module", "in", "self", ".", "children", "(", ")", ":", "\n", "            ", "module", ".", "train", "(", "mode", ")", "\n", "\n", "", "self", ".", "cotatron", ".", "eval", "(", ")", "\n", "self", ".", "cotatron", ".", "freeze", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.forward": [[53, 67], ["synthesizer.Synthesizer.cotatron.speaker", "synthesizer.Synthesizer.cotatron.encoder", "synthesizer.Synthesizer.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "synthesizer.Synthesizer.cotatron.decoder", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "linguistic.transpose.transpose.transpose", "synthesizer.Synthesizer.size", "synthesizer.Synthesizer.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "text", ",", "mel_source", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ")", ":", "\n", "        ", "z_s_aligner", "=", "self", ".", "cotatron", ".", "speaker", "(", "mel_source", ",", "output_lengths", ")", "\n", "text_encoding", "=", "self", ".", "cotatron", ".", "encoder", "(", "text", ",", "input_lengths", ")", "\n", "z_s_repeated", "=", "z_s_aligner", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "text_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "(", "text_encoding", ",", "z_s_repeated", ")", ",", "dim", "=", "2", ")", "\n", "_", ",", "_", ",", "alignment", "=", "self", ".", "cotatron", ".", "decoder", "(", "mel_source", ",", "decoder_input", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ",", "\n", "prenet_dropout", "=", "0.0", ",", "tfrate", "=", "False", ")", "\n", "\n", "# alignment: [B, T_dec, T_enc]", "\n", "# text_encoding: [B, T_enc, chn.encoder]", "\n", "linguistic", "=", "torch", ".", "bmm", "(", "alignment", ",", "text_encoding", ")", "# [B, T_dec, chn.encoder]", "\n", "linguistic", "=", "linguistic", ".", "transpose", "(", "1", ",", "2", ")", "# [B, chn.encoder, T_dec]", "\n", "return", "linguistic", ",", "alignment", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.inference": [[68, 89], ["torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "synthesizer.Synthesizer.cotatron.speaker.inference", "synthesizer.Synthesizer.cotatron.encoder.inference", "synthesizer.Synthesizer.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "synthesizer.Synthesizer.cotatron.decoder", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "synthesizer.Synthesizer.residual_encoder.inference", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "synthesizer.Synthesizer.speaker", "synthesizer.Synthesizer.decoder", "synthesizer.Synthesizer.size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "synthesizer.Synthesizer.unsqueeze", "text.size", "mel_source.size"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.inference", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.inference", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.inference"], ["", "def", "inference", "(", "self", ",", "text", ",", "mel_source", ",", "target_speaker", ")", ":", "\n", "        ", "device", "=", "text", ".", "device", "\n", "in_len", "=", "torch", ".", "LongTensor", "(", "[", "text", ".", "size", "(", "1", ")", "]", ")", ".", "to", "(", "device", ")", "\n", "out_len", "=", "torch", ".", "LongTensor", "(", "[", "mel_source", ".", "size", "(", "2", ")", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "z_s", "=", "self", ".", "cotatron", ".", "speaker", ".", "inference", "(", "mel_source", ")", "\n", "text_encoding", "=", "self", ".", "cotatron", ".", "encoder", ".", "inference", "(", "text", ")", "\n", "z_s_repeated", "=", "z_s", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "text_encoding", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "(", "text_encoding", ",", "z_s_repeated", ")", ",", "dim", "=", "2", ")", "\n", "_", ",", "_", ",", "alignment", "=", "self", ".", "cotatron", ".", "decoder", "(", "mel_source", ",", "decoder_input", ",", "in_len", ",", "out_len", ",", "in_len", ",", "\n", "prenet_dropout", "=", "0.0", ",", "no_mask", "=", "True", ",", "tfrate", "=", "False", ")", "\n", "ling_s", "=", "torch", ".", "bmm", "(", "alignment", ",", "text_encoding", ")", "\n", "ling_s", "=", "ling_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "residual", "=", "self", ".", "residual_encoder", ".", "inference", "(", "mel_source", ")", "\n", "ling_s", "=", "torch", ".", "cat", "(", "(", "ling_s", ",", "residual", ")", ",", "dim", "=", "1", ")", "\n", "\n", "z_t", "=", "self", ".", "speaker", "(", "target_speaker", ")", "\n", "mel_s_t", "=", "self", ".", "decoder", "(", "ling_s", ",", "z_t", ")", "\n", "return", "mel_s_t", ",", "alignment", ",", "residual", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.get_cnn_mask": [[91, 97], ["torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.unsqueeze.unsqueeze.unsqueeze", "lengths.unsqueeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor"], "methods", ["None"], ["", "def", "get_cnn_mask", "(", "self", ",", "lengths", ")", ":", "\n", "        ", "max_len", "=", "torch", ".", "max", "(", "lengths", ")", ".", "item", "(", ")", "\n", "ids", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "out", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "max_len", ")", ")", "\n", "mask", "=", "(", "ids", ">=", "lengths", ".", "unsqueeze", "(", "1", ")", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "return", "mask", "# [B, 1, T], torch.bool", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.training_step": [[98, 113], ["synthesizer.Synthesizer.speaker", "synthesizer.Synthesizer.get_cnn_mask", "synthesizer.Synthesizer.residual_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "synthesizer.Synthesizer.decoder", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "synthesizer.Synthesizer.logger.log_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "synthesizer.Synthesizer.forward"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.get_cnn_mask", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_loss", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "text", ",", "mel_source", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", "=", "batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "ling_s", ",", "_", "=", "self", ".", "forward", "(", "text", ",", "mel_source", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ")", "\n", "\n", "", "z_s", "=", "self", ".", "speaker", "(", "speakers", ")", "\n", "mask", "=", "self", ".", "get_cnn_mask", "(", "output_lengths", ")", "\n", "residual", "=", "self", ".", "residual_encoder", "(", "mel_source", ",", "mask", ",", "output_lengths", ")", "\n", "ling_s", "=", "torch", ".", "cat", "(", "(", "ling_s", ",", "residual", ")", ",", "dim", "=", "1", ")", "# [B, chn.encoder+chn.residual_out, T]", "\n", "mel_s_s", "=", "self", ".", "decoder", "(", "ling_s", ",", "z_s", ",", "mask", ")", "\n", "loss_rec", "=", "F", ".", "mse_loss", "(", "mel_s_s", ",", "mel_source", ")", "\n", "self", ".", "logger", ".", "log_loss", "(", "loss_rec", ",", "mode", "=", "'train'", ",", "step", "=", "self", ".", "global_step", ",", "name", "=", "'rec'", ")", "\n", "\n", "return", "{", "'loss'", ":", "loss_rec", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.validation_step": [[114, 136], ["synthesizer.Synthesizer.forward", "synthesizer.Synthesizer.speaker", "synthesizer.Synthesizer.get_cnn_mask", "synthesizer.Synthesizer.residual_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "synthesizer.Synthesizer.decoder", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "numpy.random.choice", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "synthesizer.Synthesizer.speaker", "synthesizer.Synthesizer.decoder", "synthesizer.Synthesizer.logger.log_figures", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "synthesizer.Synthesizer.hp.data.speakers.index"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.forward", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.get_cnn_mask", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_figures"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "text", ",", "mel_source", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", "=", "batch", "\n", "\n", "ling_s", ",", "alignment", "=", "self", ".", "forward", "(", "text", ",", "mel_source", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", ")", "\n", "\n", "z_s", "=", "self", ".", "speaker", "(", "speakers", ")", "\n", "mask", "=", "self", ".", "get_cnn_mask", "(", "output_lengths", ")", "\n", "residual", "=", "self", ".", "residual_encoder", "(", "mel_source", ",", "mask", ",", "output_lengths", ")", "\n", "ling_s", "=", "torch", ".", "cat", "(", "(", "ling_s", ",", "residual", ")", ",", "dim", "=", "1", ")", "# [B, chn.encoder+chn.residual_out, T]", "\n", "mel_s_s", "=", "self", ".", "decoder", "(", "ling_s", ",", "z_s", ",", "mask", ")", "\n", "loss_rec", "=", "F", ".", "mse_loss", "(", "mel_s_s", ",", "mel_source", ")", "\n", "\n", "target_speakers", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "hp", ".", "data", ".", "speakers", ",", "size", "=", "ling_s", ".", "size", "(", "0", ")", ")", "\n", "z_t_index", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "hp", ".", "data", ".", "speakers", ".", "index", "(", "x", ")", "for", "x", "in", "target_speakers", "]", ")", ".", "cuda", "(", ")", "\n", "z_t", "=", "self", ".", "speaker", "(", "z_t_index", ")", "\n", "mel_s_t", "=", "self", ".", "decoder", "(", "ling_s", ",", "z_t", ",", "mask", ")", "\n", "\n", "if", "self", ".", "is_val_first", ":", "\n", "            ", "self", ".", "is_val_first", "=", "False", "\n", "self", ".", "logger", ".", "log_figures", "(", "mel_source", ",", "mel_s_s", ",", "mel_s_t", ",", "alignment", ",", "residual", ",", "self", ".", "global_step", ")", "\n", "\n", "", "return", "{", "'loss_rec'", ":", "loss_rec", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.validation_end": [[137, 143], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "synthesizer.Synthesizer.logger.log_loss", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_loss"], ["", "def", "validation_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "loss_rec", "=", "torch", ".", "stack", "(", "[", "x", "[", "'loss_rec'", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "self", ".", "logger", ".", "log_loss", "(", "loss_rec", ",", "mode", "=", "'val'", ",", "step", "=", "self", ".", "global_step", ",", "name", "=", "'rec'", ")", "\n", "\n", "self", ".", "is_val_first", "=", "True", "\n", "return", "{", "'val_loss'", ":", "loss_rec", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.configure_optimizers": [[144, 152], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "list", "list", "list", "synthesizer.Synthesizer.speaker.parameters", "synthesizer.Synthesizer.decoder.parameters", "synthesizer.Synthesizer.residual_encoder.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "list", "(", "self", ".", "decoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "residual_encoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "speaker", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "self", ".", "hp", ".", "train", ".", "adam", ".", "lr", ",", "\n", "weight_decay", "=", "self", ".", "hp", ".", "train", ".", "adam", ".", "weight_decay", ",", "\n", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.train_dataloader": [[153, 158], ["datasets.TextMelDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "trainset", "=", "TextMelDataset", "(", "self", ".", "hp", ",", "self", ".", "hp", ".", "data", ".", "train_dir", ",", "self", ".", "hp", ".", "data", ".", "train_meta", ",", "train", "=", "True", ",", "norm", "=", "True", ")", "\n", "return", "DataLoader", "(", "trainset", ",", "batch_size", "=", "self", ".", "hp", ".", "train", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "hp", ".", "train", ".", "num_workers", ",", "\n", "collate_fn", "=", "text_mel_collate", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.None.synthesizer.Synthesizer.val_dataloader": [[159, 164], ["datasets.TextMelDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "valset", "=", "TextMelDataset", "(", "self", ".", "hp", ",", "self", ".", "hp", ".", "data", ".", "val_dir", ",", "self", ".", "hp", ".", "data", ".", "val_meta", ",", "train", "=", "False", ",", "norm", "=", "True", ")", "\n", "return", "DataLoader", "(", "valset", ",", "batch_size", "=", "self", ".", "hp", ".", "train", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "hp", ".", "train", ".", "num_workers", ",", "\n", "collate_fn", "=", "text_mel_collate", ",", "pin_memory", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_alignments": [[7, 29], ["matplotlib.figure", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.ylabel", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.subplots_adjust", "matplotlib.axes", "matplotlib.colorbar", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize"], "function", ["None"], ["def", "plot_alignments", "(", "alignment1", ",", "alignment2", ",", "transpose", "=", "True", ")", ":", "\n", "    ", "if", "transpose", ":", "\n", "        ", "alignment1", "=", "alignment1", ".", "T", "\n", "alignment2", "=", "alignment2", ".", "T", "\n", "\n", "", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "7", ")", ")", "\n", "\n", "plt", ".", "subplot", "(", "211", ")", "\n", "plt", ".", "imshow", "(", "alignment1", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "0.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "ylabel", "(", "'Encoder timestep'", ")", "\n", "\n", "plt", ".", "subplot", "(", "212", ")", "\n", "plt", ".", "imshow", "(", "alignment2", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "0.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Decoder timestep'", ")", "\n", "plt", ".", "ylabel", "(", "'Encoder timestep'", ")", "\n", "\n", "plt", ".", "subplots_adjust", "(", "bottom", "=", "0.1", ",", "right", "=", "0.88", ",", "top", "=", "0.9", ")", "\n", "cax", "=", "plt", ".", "axes", "(", "[", "0.9", ",", "0.1", ",", "0.02", ",", "0.8", "]", ")", "\n", "plt", ".", "colorbar", "(", "cax", "=", "cax", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_spectrograms": [[30, 53], ["matplotlib.figure", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.ylabel", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.ylabel", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.subplots_adjust", "matplotlib.axes", "matplotlib.colorbar", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize"], "function", ["None"], ["", "def", "plot_spectrograms", "(", "mel_pred", ",", "mel_postnet", ",", "mel_target", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "9", ")", ")", "\n", "\n", "plt", ".", "subplot", "(", "311", ")", "\n", "plt", ".", "imshow", "(", "mel_pred", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "-", "5.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "ylabel", "(", "'before postnet'", ")", "\n", "\n", "plt", ".", "subplot", "(", "312", ")", "\n", "plt", ".", "imshow", "(", "mel_postnet", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "-", "5.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "ylabel", "(", "'after postnet'", ")", "\n", "\n", "plt", ".", "subplot", "(", "313", ")", "\n", "plt", ".", "imshow", "(", "mel_target", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "-", "5.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "ylabel", "(", "'target mel'", ")", "\n", "plt", ".", "xlabel", "(", "'time frames'", ")", "\n", "\n", "plt", ".", "subplots_adjust", "(", "bottom", "=", "0.1", ",", "right", "=", "0.88", ",", "top", "=", "0.9", ")", "\n", "cax", "=", "plt", ".", "axes", "(", "[", "0.9", ",", "0.1", ",", "0.02", ",", "0.8", "]", ")", "\n", "plt", ".", "colorbar", "(", "cax", "=", "cax", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_conversions": [[54, 77], ["matplotlib.figure", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.ylabel", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.ylabel", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.subplots_adjust", "matplotlib.axes", "matplotlib.colorbar", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize"], "function", ["None"], ["", "def", "plot_conversions", "(", "mel_source", ",", "mel_s_s", ",", "mel_s_t", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "9", ")", ")", "\n", "\n", "plt", ".", "subplot", "(", "311", ")", "\n", "plt", ".", "imshow", "(", "mel_source", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "-", "5.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "ylabel", "(", "'mel_source'", ")", "\n", "\n", "plt", ".", "subplot", "(", "312", ")", "\n", "plt", ".", "imshow", "(", "mel_s_s", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "-", "5.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "ylabel", "(", "'mel_s_s'", ")", "\n", "\n", "plt", ".", "subplot", "(", "313", ")", "\n", "plt", ".", "imshow", "(", "mel_s_t", ",", "aspect", "=", "'auto'", ",", "origin", "=", "'lower'", ",", "interpolation", "=", "'none'", ",", "\n", "norm", "=", "Normalize", "(", "vmin", "=", "-", "5.0", ",", "vmax", "=", "1.0", ")", ")", "\n", "plt", ".", "ylabel", "(", "'mel_s_t'", ")", "\n", "plt", ".", "xlabel", "(", "'time frames'", ")", "\n", "\n", "plt", ".", "subplots_adjust", "(", "bottom", "=", "0.1", ",", "right", "=", "0.88", ",", "top", "=", "0.9", ")", "\n", "cax", "=", "plt", ".", "axes", "(", "[", "0.9", ",", "0.1", ",", "0.02", ",", "0.8", "]", ")", "\n", "plt", ".", "colorbar", "(", "cax", "=", "cax", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_residual": [[78, 88], ["matplotlib.figure", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.subplots_adjust", "matplotlib.plot", "len", "range", "len"], "function", ["None"], ["", "def", "plot_residual", "(", "residual", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "3", ")", ")", "\n", "for", "feat", "in", "residual", ":", "\n", "        ", "plt", ".", "plot", "(", "range", "(", "len", "(", "feat", ")", ")", ",", "feat", ")", "\n", "", "plt", ".", "xlim", "(", "0", ",", "len", "(", "residual", "[", "0", "]", ")", ")", "\n", "plt", ".", "ylim", "(", "-", "1.0", ",", "1.0", ")", "\n", "plt", ".", "xlabel", "(", "'time frames'", ")", "\n", "plt", ".", "ylabel", "(", "'residual info'", ")", "\n", "plt", ".", "subplots_adjust", "(", "bottom", "=", "0.1", ",", "right", "=", "0.88", ",", "top", "=", "0.9", ")", "\n", "return", "fig", "\n", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.TacotronLogger.__init__": [[7, 9], ["pytorch_lightning.loggers.TensorBoardLogger.__init__"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "save_dir", ",", "name", "=", "'default'", ",", "version", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "save_dir", ",", "name", ",", "version", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.TacotronLogger.log_loss": [[10, 14], ["loggers.TacotronLogger.experiment.add_scalar"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "log_loss", "(", "self", ",", "loss", ",", "mode", ",", "step", ",", "name", "=", "''", ")", ":", "\n", "        ", "name", "=", "'.loss'", "+", "(", "''", "if", "name", "==", "''", "else", "'_'", "+", "name", ")", "\n", "self", ".", "experiment", ".", "add_scalar", "(", "mode", "+", "name", ",", "loss", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.TacotronLogger.log_figures": [[15, 29], ["mel_pred.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "mel_postnet.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "mel_target.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "alignment.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "random.randint", "utils.plotting.plot_alignments", "loggers.TacotronLogger.experiment.add_figure", "utils.plotting.plot_spectrograms", "loggers.TacotronLogger.experiment.add_figure", "mel_pred.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "mel_postnet.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "mel_target.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "alignment.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "len", "mel_pred.cpu().detach().numpy.cpu().detach().numpy.cpu", "mel_postnet.cpu().detach().numpy.cpu().detach().numpy.cpu", "mel_target.cpu().detach().numpy.cpu().detach().numpy.cpu", "alignment.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_alignments", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_spectrograms"], ["", "@", "rank_zero_only", "\n", "def", "log_figures", "(", "self", ",", "mel_pred", ",", "mel_postnet", ",", "mel_target", ",", "alignment", ",", "step", ")", ":", "\n", "        ", "mel_pred", "=", "mel_pred", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "mel_postnet", "=", "mel_postnet", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "mel_target", "=", "mel_target", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "alignment", "=", "alignment", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "rand_idx", "=", "random", ".", "randint", "(", "1", ",", "len", "(", "mel_pred", ")", "-", "1", ")", "\n", "\n", "alignment_plot", "=", "plot_alignments", "(", "alignment", "[", "0", "]", ",", "alignment", "[", "rand_idx", "]", ",", "transpose", "=", "True", ")", "\n", "self", ".", "experiment", ".", "add_figure", "(", "'alignment_fixed_random'", ",", "alignment_plot", ",", "step", ")", "\n", "\n", "spectrogram_plot", "=", "plot_spectrograms", "(", "mel_pred", "[", "rand_idx", "]", ",", "mel_postnet", "[", "rand_idx", "]", ",", "mel_target", "[", "rand_idx", "]", ")", "\n", "self", ".", "experiment", ".", "add_figure", "(", "'mel_spectrograms'", ",", "spectrogram_plot", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.TacotronLogger.log_embedding": [[30, 37], ["loggers.TacotronLogger.experiment.add_embedding"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "log_embedding", "(", "self", ",", "symbols", ",", "embedding", ",", "step", ")", ":", "\n", "        ", "self", ".", "experiment", ".", "add_embedding", "(", "\n", "mat", "=", "embedding", ",", "\n", "metadata", "=", "symbols", ",", "\n", "global_step", "=", "step", ",", "\n", "tag", "=", "'character_embedding'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.TacotronLogger.log_learning_rate": [[38, 41], ["loggers.TacotronLogger.experiment.add_scalar"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "log_learning_rate", "(", "self", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "self", ".", "experiment", ".", "add_scalar", "(", "'learning_rate'", ",", "learning_rate", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.__init__": [[44, 46], ["pytorch_lightning.loggers.TensorBoardLogger.__init__"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "save_dir", ",", "name", "=", "'default'", ",", "version", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "save_dir", ",", "name", ",", "version", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_loss": [[47, 51], ["loggers.SynthesizerLogger.experiment.add_scalar"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "log_loss", "(", "self", ",", "loss", ",", "mode", ",", "step", ",", "name", "=", "''", ")", ":", "\n", "        ", "name", "=", "'.loss'", "+", "(", "''", "if", "name", "==", "''", "else", "'_'", "+", "name", ")", "\n", "self", ".", "experiment", ".", "add_scalar", "(", "mode", "+", "name", ",", "loss", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.loggers.SynthesizerLogger.log_figures": [[52, 71], ["mel_source.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "mel_s_s.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "mel_s_t.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "alignment.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "residual.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "random.randint", "utils.plotting.plot_alignments", "loggers.SynthesizerLogger.experiment.add_figure", "utils.plotting.plot_conversions", "loggers.SynthesizerLogger.experiment.add_figure", "utils.plotting.plot_residual", "loggers.SynthesizerLogger.experiment.add_figure", "mel_source.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "mel_s_s.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "mel_s_t.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "alignment.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "residual.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "len", "mel_source.cpu().detach().numpy.cpu().detach().numpy.cpu", "mel_s_s.cpu().detach().numpy.cpu().detach().numpy.cpu", "mel_s_t.cpu().detach().numpy.cpu().detach().numpy.cpu", "alignment.cpu().detach().numpy.cpu().detach().numpy.cpu", "residual.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_alignments", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_conversions", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.plotting.plot_residual"], ["", "@", "rank_zero_only", "\n", "def", "log_figures", "(", "self", ",", "mel_source", ",", "mel_s_s", ",", "mel_s_t", ",", "alignment", ",", "residual", ",", "step", ")", ":", "\n", "        ", "mel_source", "=", "mel_source", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "mel_s_s", "=", "mel_s_s", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "mel_s_t", "=", "mel_s_t", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "alignment", "=", "alignment", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "residual", "=", "residual", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "rand_idx", "=", "random", ".", "randint", "(", "1", ",", "len", "(", "mel_source", ")", "-", "1", ")", "\n", "\n", "alignment_plot", "=", "plot_alignments", "(", "alignment", "[", "0", "]", ",", "alignment", "[", "rand_idx", "]", ",", "transpose", "=", "True", ")", "\n", "self", ".", "experiment", ".", "add_figure", "(", "'pretrained_alignment_fixed_random'", ",", "alignment_plot", ",", "step", ")", "\n", "\n", "spectrogram_plot", "=", "plot_conversions", "(", "\n", "mel_source", "[", "rand_idx", "]", ",", "mel_s_s", "[", "rand_idx", "]", ",", "mel_s_t", "[", "rand_idx", "]", ")", "\n", "self", ".", "experiment", ".", "add_figure", "(", "'conversions'", ",", "spectrogram_plot", ",", "step", ")", "\n", "\n", "residual_plot", "=", "plot_residual", "(", "residual", "[", "rand_idx", "]", ")", "\n", "self", ".", "experiment", ".", "add_figure", "(", "'residual_info'", ",", "residual_plot", ",", "step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.utils.utils.get_commit_hash": [[4, 7], ["subprocess.check_output", "subprocess.check_output.strip().decode", "subprocess.check_output.strip"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.decode"], ["def", "get_commit_hash", "(", ")", ":", "\n", "    ", "message", "=", "subprocess", ".", "check_output", "(", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"--short\"", ",", "\"HEAD\"", "]", ")", "\n", "return", "message", ".", "strip", "(", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.__init__": [[12, 44], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReflectionPad1d", "torch.ReflectionPad1d", "torch.ReflectionPad1d", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "res_stack.ResStack", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "res_stack.ResStack", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "res_stack.ResStack", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "res_stack.ResStack", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReflectionPad1d", "torch.ReflectionPad1d", "torch.ReflectionPad1d", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mel_channel", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mel_channel", "=", "mel_channel", "\n", "\n", "self", ".", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReflectionPad1d", "(", "3", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "Conv1d", "(", "mel_channel", ",", "512", ",", "kernel_size", "=", "7", ",", "stride", "=", "1", ")", ")", ",", "\n", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "ConvTranspose1d", "(", "512", ",", "256", ",", "kernel_size", "=", "16", ",", "stride", "=", "8", ",", "padding", "=", "4", ")", ")", ",", "\n", "\n", "ResStack", "(", "256", ")", ",", "\n", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "ConvTranspose1d", "(", "256", ",", "128", ",", "kernel_size", "=", "16", ",", "stride", "=", "8", ",", "padding", "=", "4", ")", ")", ",", "\n", "\n", "ResStack", "(", "128", ")", ",", "\n", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "ConvTranspose1d", "(", "128", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", ",", "\n", "\n", "ResStack", "(", "64", ")", ",", "\n", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "ConvTranspose1d", "(", "64", ",", "32", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", ",", "\n", "\n", "ResStack", "(", "32", ")", ",", "\n", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ReflectionPad1d", "(", "3", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "Conv1d", "(", "32", ",", "1", ",", "kernel_size", "=", "7", ",", "stride", "=", "1", ")", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.forward": [[46, 48], ["generator.Generator.generator"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "mel", ")", ":", "\n", "        ", "return", "self", ".", "generator", "(", "mel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.eval": [[49, 55], ["super().eval", "generator.Generator.remove_weight_norm"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.eval", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm"], ["", "def", "eval", "(", "self", ",", "inference", "=", "False", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "eval", "(", ")", "\n", "\n", "# don't remove weight norm while validation in training loop", "\n", "if", "inference", ":", "\n", "            ", "self", ".", "remove_weight_norm", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.remove_weight_norm": [[56, 63], ["enumerate", "len", "layer.state_dict", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "layer.remove_weight_norm"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm"], ["", "", "def", "remove_weight_norm", "(", "self", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "generator", ")", ":", "\n", "            ", "if", "len", "(", "layer", ".", "state_dict", "(", ")", ")", "!=", "0", ":", "\n", "                ", "try", ":", "\n", "                    ", "nn", ".", "utils", ".", "remove_weight_norm", "(", "layer", ")", "\n", "", "except", ":", "\n", "                    ", "layer", ".", "remove_weight_norm", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.generator.Generator.inference": [[64, 79], ["generator.Generator.forward", "audio.short.short.squeeze", "audio.short.short.clamp", "audio.short.short.short"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.forward"], ["", "", "", "", "def", "inference", "(", "self", ",", "mel", ")", ":", "\n", "        ", "hop_length", "=", "256", "\n", "# pad input mel with zeros to cut artifact", "\n", "# see https://github.com/seungwonpark/melgan/issues/8", "\n", "# zero = torch.full((1, self.mel_channel, 10), -11.5129).to(mel.device)", "\n", "# mel = torch.cat((mel, zero), dim=2)", "\n", "\n", "audio", "=", "self", ".", "forward", "(", "mel", ")", "\n", "audio", "=", "audio", ".", "squeeze", "(", ")", "# collapse all dimension except time axis", "\n", "# audio = audio[:-(hop_length*10)]", "\n", "audio", "=", "MAX_WAV_VALUE", "*", "audio", "\n", "audio", "=", "audio", ".", "clamp", "(", "min", "=", "-", "MAX_WAV_VALUE", ",", "max", "=", "MAX_WAV_VALUE", "-", "1", ")", "\n", "audio", "=", "audio", ".", "short", "(", ")", "\n", "\n", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.__init__": [[8, 24], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ReflectionPad1d", "torch.ReflectionPad1d", "torch.ReflectionPad1d", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "range", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "range", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ")", ":", "\n", "        ", "super", "(", "ResStack", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ReflectionPad1d", "(", "3", "**", "i", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "Conv1d", "(", "channel", ",", "channel", ",", "kernel_size", "=", "3", ",", "dilation", "=", "3", "**", "i", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "Conv1d", "(", "channel", ",", "channel", ",", "kernel_size", "=", "1", ")", ")", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "3", ")", "\n", "]", ")", "\n", "self", ".", "shortcuts", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "utils", ".", "weight_norm", "(", "nn", ".", "Conv1d", "(", "channel", ",", "channel", ",", "kernel_size", "=", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "3", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.forward": [[26, 30], ["zip", "shortcut", "block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "block", ",", "shortcut", "in", "zip", "(", "self", ".", "blocks", ",", "self", ".", "shortcuts", ")", ":", "\n", "            ", "x", "=", "shortcut", "(", "x", ")", "+", "block", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm": [[31, 36], ["zip", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm", "torch.utils.remove_weight_norm"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.melgan.res_stack.ResStack.remove_weight_norm"], ["", "def", "remove_weight_norm", "(", "self", ")", ":", "\n", "        ", "for", "block", ",", "shortcut", "in", "zip", "(", "self", ".", "blocks", ",", "self", ".", "shortcuts", ")", ":", "\n", "            ", "nn", ".", "utils", ".", "remove_weight_norm", "(", "block", "[", "2", "]", ")", "\n", "nn", ".", "utils", ".", "remove_weight_norm", "(", "block", "[", "4", "]", ")", "\n", "nn", ".", "utils", ".", "remove_weight_norm", "(", "shortcut", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.__init__": [[16, 46], ["torch.utils.data.Dataset.__init__", "text.Language", "text_mel_dataset.TextMelDataset.load_metadata", "text_mel_dataset.TextMelDataset.remove_existing_mel", "modules.mel.Audio2Mel", "collections.Counter", "torch.DoubleTensor", "text.cmudict.CMUDict", "re.compile", "enumerate"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.load_metadata", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.remove_existing_mel"], ["    ", "def", "__init__", "(", "self", ",", "hp", ",", "data_dir", ",", "metadata_path", ",", "train", "=", "True", ",", "norm", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hp", "=", "hp", "\n", "self", ".", "lang", "=", "Language", "(", "hp", ".", "data", ".", "lang", ",", "hp", ".", "data", ".", "text_cleaners", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "meta", "=", "self", ".", "load_metadata", "(", "metadata_path", ")", "\n", "self", ".", "speaker_dict", "=", "{", "speaker", ":", "idx", "for", "idx", ",", "speaker", "in", "enumerate", "(", "hp", ".", "data", ".", "speakers", ")", "}", "\n", "\n", "if", "train", ":", "\n", "# balanced sampling for each speaker", "\n", "            ", "speaker_counter", "=", "Counter", "(", "(", "spk_id", "for", "audiopath", ",", "text", ",", "spk_id", "in", "self", ".", "meta", ")", ")", "\n", "weights", "=", "[", "1.0", "/", "speaker_counter", "[", "spk_id", "]", "for", "audiopath", ",", "text", ",", "spk_id", "in", "self", ".", "meta", "]", "\n", "self", ".", "mapping_weights", "=", "torch", ".", "DoubleTensor", "(", "weights", ")", "\n", "\n", "", "self", ".", "remove_existing_mel", "(", ")", "\n", "self", ".", "audio2mel", "=", "Audio2Mel", "(", "\n", "n_fft", "=", "hp", ".", "audio", ".", "filter_length", ",", "hop_length", "=", "hp", ".", "audio", ".", "hop_length", ",", "\n", "win_length", "=", "hp", ".", "audio", ".", "win_length", ",", "sampling_rate", "=", "hp", ".", "audio", ".", "sampling_rate", ",", "\n", "n_mel_channels", "=", "hp", ".", "audio", ".", "n_mel_channels", ",", "\n", "mel_fmin", "=", "hp", ".", "audio", ".", "mel_fmin", ",", "mel_fmax", "=", "hp", ".", "audio", ".", "mel_fmax", ")", "\n", "\n", "if", "hp", ".", "data", ".", "lang", "==", "'cmu'", ":", "\n", "            ", "self", ".", "cmudict", "=", "CMUDict", "(", "hp", ".", "data", ".", "cmudict_path", ")", "\n", "self", ".", "cmu_pattern", "=", "re", ".", "compile", "(", "r'^(?P<word>[^!\\'(),-.:~?]+)(?P<punc>[!\\'(),-.:~?]+)$'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "cmudict", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.__len__": [[47, 49], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.__getitem__": [[50, 60], ["os.path.join", "text_mel_dataset.TextMelDataset.get_mel", "text_mel_dataset.TextMelDataset.get_text", "torch.multinomial().item", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.get_mel", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.get_text"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "idx", "=", "torch", ".", "multinomial", "(", "self", ".", "mapping_weights", ",", "1", ")", ".", "item", "(", ")", "\n", "\n", "", "audiopath", ",", "text", ",", "spk_id", "=", "self", ".", "meta", "[", "idx", "]", "\n", "audiopath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "audiopath", ")", "\n", "mel", "=", "self", ".", "get_mel", "(", "audiopath", ")", "\n", "text_norm", "=", "self", ".", "get_text", "(", "text", ")", "\n", "spk_id", "=", "self", ".", "speaker_dict", "[", "spk_id", "]", "\n", "return", "text_norm", ",", "mel", ",", "spk_id", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.get_mel": [[61, 81], ["os.path.join", "torch.load", "text_mel_dataset.TextMelDataset.size", "librosa.load", "torch.from_numpy().view", "text_mel_dataset.TextMelDataset.audio2mel().squeeze", "torch.save", "text_mel_dataset.TextMelDataset.size", "torch.from_numpy", "text_mel_dataset.TextMelDataset.audio2mel", "torch.max", "torch.abs"], "methods", ["None"], ["", "def", "get_mel", "(", "self", ",", "audiopath", ")", ":", "\n", "        ", "melpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'{}.pt'", ".", "format", "(", "audiopath", ")", ")", "\n", "try", ":", "\n", "            ", "mel", "=", "torch", ".", "load", "(", "melpath", ",", "map_location", "=", "'cpu'", ")", "\n", "assert", "mel", ".", "size", "(", "0", ")", "==", "self", ".", "hp", ".", "audio", ".", "n_mel_channels", ",", "'Mel dimension mismatch: expected %d, got %d'", "%", "(", "self", ".", "hp", ".", "audio", ".", "n_mel_channels", ",", "mel", ".", "size", "(", "0", ")", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "RuntimeError", ",", "TypeError", ")", ":", "\n", "            ", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "audiopath", ",", "sr", "=", "None", ",", "mono", "=", "True", ")", "\n", "assert", "sr", "==", "self", ".", "hp", ".", "audio", ".", "sampling_rate", ",", "'sample mismatch: expected %d, got %d at %s'", "%", "(", "self", ".", "hp", ".", "audio", ".", "sampling_rate", ",", "sr", ",", "audiopath", ")", "\n", "wav", "=", "torch", ".", "from_numpy", "(", "wav", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "if", "self", ".", "norm", ":", "\n", "                ", "wav", "=", "wav", "*", "(", "0.99", "/", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "wav", ")", ")", "+", "1e-7", ")", ")", "\n", "", "mel", "=", "self", ".", "audio2mel", "(", "wav", ")", ".", "squeeze", "(", "0", ")", "\n", "\n", "torch", ".", "save", "(", "mel", ",", "melpath", ")", "\n", "\n", "", "return", "mel", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.get_text": [[82, 87], ["torch.IntTensor", "text_mel_dataset.TextMelDataset.lang.text_to_sequence", "text_mel_dataset.TextMelDataset.get_arpabet", "text.split"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language.text_to_sequence", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.get_arpabet"], ["", "def", "get_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "cmudict", "is", "not", "None", ":", "\n", "            ", "text", "=", "' '", ".", "join", "(", "[", "self", ".", "get_arpabet", "(", "word", ")", "for", "word", "in", "text", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "text_norm", "=", "torch", ".", "IntTensor", "(", "self", ".", "lang", ".", "text_to_sequence", "(", "text", ",", "self", ".", "hp", ".", "data", ".", "text_cleaners", ")", ")", "\n", "return", "text_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.get_arpabet": [[88, 107], ["text_mel_dataset.TextMelDataset.cmudict.lookup", "text_mel_dataset.TextMelDataset.cmu_pattern.search", "text_mel_dataset.TextMelDataset.group", "text_mel_dataset.TextMelDataset.cmudict.lookup", "text_mel_dataset.TextMelDataset.group", "random.random"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict.CMUDict.lookup", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict.CMUDict.lookup"], ["", "def", "get_arpabet", "(", "self", ",", "word", ")", ":", "\n", "        ", "arpabet", "=", "self", ".", "cmudict", ".", "lookup", "(", "word", ")", "\n", "if", "arpabet", "is", "None", ":", "\n", "            ", "match", "=", "self", ".", "cmu_pattern", ".", "search", "(", "word", ")", "\n", "if", "match", "is", "None", ":", "\n", "                ", "return", "word", "\n", "", "subword", "=", "match", ".", "group", "(", "'word'", ")", "\n", "arpabet", "=", "self", ".", "cmudict", ".", "lookup", "(", "subword", ")", "\n", "if", "arpabet", "is", "None", ":", "\n", "                ", "return", "word", "\n", "", "punc", "=", "match", ".", "group", "(", "'punc'", ")", "\n", "arpabet", "=", "'{%s}%s'", "%", "(", "arpabet", "[", "0", "]", ",", "punc", ")", "\n", "", "else", ":", "\n", "            ", "arpabet", "=", "'{%s}'", "%", "arpabet", "[", "0", "]", "\n", "\n", "", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "return", "word", "\n", "", "else", ":", "\n", "            ", "return", "arpabet", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.load_metadata": [[108, 113], ["open", "line.strip().split", "line.strip"], "methods", ["None"], ["", "", "def", "load_metadata", "(", "self", ",", "path", ",", "split", "=", "\"|\"", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "metadata", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "split", ")", "for", "line", "in", "f", "]", "\n", "\n", "", "return", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.TextMelDataset.remove_existing_mel": [[114, 124], ["os.path.join", "os.path.exists", "os.remove"], "methods", ["None"], ["", "def", "remove_existing_mel", "(", "self", ")", ":", "\n", "        ", "for", "meta", "in", "self", ".", "meta", ":", "\n", "            ", "audiopath", "=", "meta", "[", "0", "]", "\n", "melpath", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "data_dir", ",", "'{}.pt'", ".", "format", "(", "audiopath", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "melpath", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "os", ".", "remove", "(", "melpath", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "                    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.datasets.text_mel_dataset.text_mel_collate": [[126, 150], ["torch.sort", "torch.empty", "torch.empty.fill_", "torch.zeros", "[].size", "max", "torch.zeros", "torch.empty", "torch.empty", "enumerate", "torch.LongTensor", "len", "len", "len", "len", "mel.size", "len", "x[].size", "len", "text.size", "mel.size"], "function", ["None"], ["", "", "", "", "", "def", "text_mel_collate", "(", "batch", ")", ":", "\n", "    ", "input_lengths", ",", "ids_sorted_decreasing", "=", "torch", ".", "sort", "(", "\n", "torch", ".", "LongTensor", "(", "[", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "batch", "]", ")", ",", "\n", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "max_input_len", "=", "torch", ".", "empty", "(", "len", "(", "batch", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "max_input_len", ".", "fill_", "(", "input_lengths", "[", "0", "]", ")", "\n", "\n", "text_padded", "=", "torch", ".", "zeros", "(", "(", "len", "(", "batch", ")", ",", "max_input_len", "[", "0", "]", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "n_mel_channels", "=", "batch", "[", "0", "]", "[", "1", "]", ".", "size", "(", "0", ")", "\n", "max_target_len", "=", "max", "(", "[", "x", "[", "1", "]", ".", "size", "(", "1", ")", "for", "x", "in", "batch", "]", ")", "\n", "mel_padded", "=", "torch", ".", "zeros", "(", "len", "(", "batch", ")", ",", "n_mel_channels", ",", "max_target_len", ")", "\n", "output_lengths", "=", "torch", ".", "empty", "(", "len", "(", "batch", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "speakers", "=", "torch", ".", "empty", "(", "len", "(", "batch", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "ids_sorted_decreasing", ")", ":", "\n", "        ", "text", "=", "batch", "[", "key", "]", "[", "0", "]", "\n", "text_padded", "[", "idx", ",", ":", "text", ".", "size", "(", "0", ")", "]", "=", "text", "\n", "mel", "=", "batch", "[", "key", "]", "[", "1", "]", "\n", "mel_padded", "[", "idx", ",", ":", ",", ":", "mel", ".", "size", "(", "1", ")", "]", "=", "mel", "\n", "output_lengths", "[", "idx", "]", "=", "mel", ".", "size", "(", "1", ")", "\n", "speakers", "[", "idx", "]", "=", "batch", "[", "key", "]", "[", "2", "]", "\n", "\n", "", "return", "text_padded", ",", "mel_padded", ",", "speakers", ",", "input_lengths", ",", "output_lengths", ",", "max_input_len", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.expand_abbreviations": [[47, 51], ["re.sub"], "function", ["None"], ["def", "expand_abbreviations", "(", "text", ")", ":", "\n", "  ", "for", "regex", ",", "replacement", "in", "_abbreviations", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "regex", ",", "replacement", ",", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.expand_numbers": [[53, 55], ["numbers.normalize_numbers"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.numbers.normalize_numbers"], ["", "def", "expand_numbers", "(", "text", ")", ":", "\n", "  ", "return", "normalize_numbers", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.lowercase": [[57, 59], ["text.lower"], "function", ["None"], ["", "def", "lowercase", "(", "text", ")", ":", "\n", "  ", "return", "text", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.collapse_whitespace": [[61, 63], ["re.sub"], "function", ["None"], ["", "def", "collapse_whitespace", "(", "text", ")", ":", "\n", "  ", "return", "re", ".", "sub", "(", "_whitespace_re", ",", "' '", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.convert_to_ascii": [[65, 67], ["unidecode.unidecode"], "function", ["None"], ["", "def", "convert_to_ascii", "(", "text", ")", ":", "\n", "  ", "return", "unidecode", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.basic_cleaners": [[69, 74], ["cleaners.lowercase", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.lowercase", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.collapse_whitespace"], ["", "def", "basic_cleaners", "(", "text", ")", ":", "\n", "  ", "'''Basic pipeline that lowercases and collapses whitespace without transliteration.'''", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.transliteration_cleaners": [[76, 82], ["cleaners.convert_to_ascii", "cleaners.lowercase", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.convert_to_ascii", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.lowercase", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.collapse_whitespace"], ["", "def", "transliteration_cleaners", "(", "text", ")", ":", "\n", "  ", "'''Pipeline for non-English text that transliterates to ASCII.'''", "\n", "text", "=", "convert_to_ascii", "(", "text", ")", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.english_cleaners": [[84, 92], ["cleaners.convert_to_ascii", "cleaners.lowercase", "cleaners.expand_numbers", "cleaners.expand_abbreviations", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.convert_to_ascii", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.lowercase", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.expand_numbers", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.expand_abbreviations", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cleaners.collapse_whitespace"], ["", "def", "english_cleaners", "(", "text", ")", ":", "\n", "  ", "'''Pipeline for English text, including number and abbreviation expansion.'''", "\n", "text", "=", "convert_to_ascii", "(", "text", ")", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "expand_numbers", "(", "text", ")", "\n", "text", "=", "expand_abbreviations", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.numbers._remove_commas": [[16, 18], ["m.group().replace", "m.group"], "function", ["None"], ["def", "_remove_commas", "(", "m", ")", ":", "\n", "  ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "','", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.numbers._expand_decimal_point": [[20, 22], ["m.group().replace", "m.group"], "function", ["None"], ["", "def", "_expand_decimal_point", "(", "m", ")", ":", "\n", "  ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "'.'", ",", "' point '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.numbers._expand_dollars": [[24, 43], ["m.group", "m.group.split", "len", "int", "int", "len"], "function", ["None"], ["", "def", "_expand_dollars", "(", "m", ")", ":", "\n", "  ", "match", "=", "m", ".", "group", "(", "1", ")", "\n", "parts", "=", "match", ".", "split", "(", "'.'", ")", "\n", "if", "len", "(", "parts", ")", ">", "2", ":", "\n", "    ", "return", "match", "+", "' dollars'", "# Unexpected format", "\n", "", "dollars", "=", "int", "(", "parts", "[", "0", "]", ")", "if", "parts", "[", "0", "]", "else", "0", "\n", "cents", "=", "int", "(", "parts", "[", "1", "]", ")", "if", "len", "(", "parts", ")", ">", "1", "and", "parts", "[", "1", "]", "else", "0", "\n", "if", "dollars", "and", "cents", ":", "\n", "    ", "dollar_unit", "=", "'dollar'", "if", "dollars", "==", "1", "else", "'dollars'", "\n", "cent_unit", "=", "'cent'", "if", "cents", "==", "1", "else", "'cents'", "\n", "return", "'%s %s, %s %s'", "%", "(", "dollars", ",", "dollar_unit", ",", "cents", ",", "cent_unit", ")", "\n", "", "elif", "dollars", ":", "\n", "    ", "dollar_unit", "=", "'dollar'", "if", "dollars", "==", "1", "else", "'dollars'", "\n", "return", "'%s %s'", "%", "(", "dollars", ",", "dollar_unit", ")", "\n", "", "elif", "cents", ":", "\n", "    ", "cent_unit", "=", "'cent'", "if", "cents", "==", "1", "else", "'cents'", "\n", "return", "'%s %s'", "%", "(", "cents", ",", "cent_unit", ")", "\n", "", "else", ":", "\n", "    ", "return", "'zero dollars'", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.numbers._expand_ordinal": [[45, 47], ["_inflect.number_to_words", "m.group"], "function", ["None"], ["", "", "def", "_expand_ordinal", "(", "m", ")", ":", "\n", "  ", "return", "_inflect", ".", "number_to_words", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.numbers._expand_number": [[49, 62], ["int", "m.group", "_inflect.number_to_words", "_inflect.number_to_words", "_inflect.number_to_words().replace", "_inflect.number_to_words", "_inflect.number_to_words"], "function", ["None"], ["", "def", "_expand_number", "(", "m", ")", ":", "\n", "  ", "num", "=", "int", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "if", "num", ">", "1000", "and", "num", "<", "3000", ":", "\n", "    ", "if", "num", "==", "2000", ":", "\n", "      ", "return", "'two thousand'", "\n", "", "elif", "num", ">", "2000", "and", "num", "<", "2010", ":", "\n", "      ", "return", "'two thousand '", "+", "_inflect", ".", "number_to_words", "(", "num", "%", "100", ")", "\n", "", "elif", "num", "%", "100", "==", "0", ":", "\n", "      ", "return", "_inflect", ".", "number_to_words", "(", "num", "//", "100", ")", "+", "' hundred'", "\n", "", "else", ":", "\n", "      ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "''", ",", "zero", "=", "'oh'", ",", "group", "=", "2", ")", ".", "replace", "(", "', '", ",", "' '", ")", "\n", "", "", "else", ":", "\n", "    ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.numbers.normalize_numbers": [[64, 72], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub"], "function", ["None"], ["", "", "def", "normalize_numbers", "(", "text", ")", ":", "\n", "  ", "text", "=", "re", ".", "sub", "(", "_comma_number_re", ",", "_remove_commas", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_pounds_re", ",", "r'\\1 pounds'", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_dollars_re", ",", "_expand_dollars", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_decimal_number_re", ",", "_expand_decimal_point", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_ordinal_re", ",", "_expand_ordinal", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_number_re", ",", "_expand_number", ",", "text", ")", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict.CMUDict.__init__": [[21, 30], ["isinstance", "cmudict._parse_cmudict", "open", "cmudict._parse_cmudict", "_parse_cmudict.items", "len"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict._parse_cmudict", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict._parse_cmudict"], ["def", "__init__", "(", "self", ",", "file_or_path", ",", "keep_ambiguous", "=", "True", ")", ":", "\n", "    ", "if", "isinstance", "(", "file_or_path", ",", "str", ")", ":", "\n", "      ", "with", "open", "(", "file_or_path", ",", "encoding", "=", "'latin-1'", ")", "as", "f", ":", "\n", "        ", "entries", "=", "_parse_cmudict", "(", "f", ")", "\n", "", "", "else", ":", "\n", "      ", "entries", "=", "_parse_cmudict", "(", "file_or_path", ")", "\n", "", "if", "not", "keep_ambiguous", ":", "\n", "      ", "entries", "=", "{", "word", ":", "pron", "for", "word", ",", "pron", "in", "entries", ".", "items", "(", ")", "if", "len", "(", "pron", ")", "==", "1", "}", "\n", "", "self", ".", "_entries", "=", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict.CMUDict.__len__": [[32, 34], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "_entries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict.CMUDict.lookup": [[36, 39], ["cmudict.CMUDict._entries.get", "word.upper"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "word", ")", ":", "\n", "    ", "'''Returns list of ARPAbet pronunciations of the given word.'''", "\n", "return", "self", ".", "_entries", ".", "get", "(", "word", ".", "upper", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict._parse_cmudict": [[45, 58], ["len", "line.split", "re.sub", "cmudict._get_pronunciation", "cmudict[].append"], "function", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict._get_pronunciation"], ["def", "_parse_cmudict", "(", "file", ")", ":", "\n", "  ", "cmudict", "=", "{", "}", "\n", "for", "line", "in", "file", ":", "\n", "    ", "if", "len", "(", "line", ")", "and", "(", "line", "[", "0", "]", ">=", "'A'", "and", "line", "[", "0", "]", "<=", "'Z'", "or", "line", "[", "0", "]", "==", "\"'\"", ")", ":", "\n", "      ", "parts", "=", "line", ".", "split", "(", "'  '", ")", "\n", "word", "=", "re", ".", "sub", "(", "_alt_re", ",", "''", ",", "parts", "[", "0", "]", ")", "\n", "pronunciation", "=", "_get_pronunciation", "(", "parts", "[", "1", "]", ")", "\n", "if", "pronunciation", ":", "\n", "        ", "if", "word", "in", "cmudict", ":", "\n", "          ", "cmudict", "[", "word", "]", ".", "append", "(", "pronunciation", ")", "\n", "", "else", ":", "\n", "          ", "cmudict", "[", "word", "]", "=", "[", "pronunciation", "]", "\n", "", "", "", "", "return", "cmudict", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.cmudict._get_pronunciation": [[60, 66], ["s.strip().split", "s.strip"], "function", ["None"], ["", "def", "_get_pronunciation", "(", "s", ")", ":", "\n", "  ", "parts", "=", "s", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "for", "part", "in", "parts", ":", "\n", "    ", "if", "part", "not", "in", "_valid_symbol_set", ":", "\n", "      ", "return", "None", "\n", "", "", "return", "' '", ".", "join", "(", "parts", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language.__init__": [[8, 49], ["re.compile", "RuntimeError", "enumerate", "enumerate", "RuntimeError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language.get_symbols": [[50, 52], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language.text_to_sequence": [[53, 81], ["len", "sequence.append", "__init__.Language._symbols_to_sequence", "__init__.Language._arpabet_to_sequence", "m.group", "sequence.append", "__init__.Language._curly_re.match", "__init__.Language._symbols_to_sequence", "__init__.Language._clean_text", "m.group", "__init__.Language._clean_text", "m.group"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._symbols_to_sequence", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._arpabet_to_sequence", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._symbols_to_sequence", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._clean_text", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._clean_text"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language.sequence_to_text": [[83, 94], ["result.replace", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._clean_text": [[96, 103], ["getattr", "getattr.", "Exception"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._symbols_to_sequence": [[105, 109], ["symbols.split.split.split", "__init__.Language._should_keep_symbol"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._should_keep_symbol"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._arpabet_to_sequence": [[111, 113], ["__init__.Language._symbols_to_sequence", "text.split"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._symbols_to_sequence"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.text.__init__.Language._should_keep_symbol": [[115, 117], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.cond_bn.ConditionalBatchNorm1d.__init__": [[8, 13], ["torch.Module.__init__", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "condition_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "num_features", ",", "affine", "=", "False", ")", "\n", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "condition_dim", ",", "2", "*", "num_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.cond_bn.ConditionalBatchNorm1d.forward": [[14, 21], ["cond_bn.ConditionalBatchNorm1d.bn", "cond_bn.ConditionalBatchNorm1d.projection().chunk", "beta.unsqueeze", "cond_bn.ConditionalBatchNorm1d.projection", "gamma.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "cond", ")", ":", "\n", "# x: [B, num_features, T]", "\n", "# cond: [B, condition_dim]", "\n", "        ", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "gamma", ",", "beta", "=", "self", ".", "projection", "(", "cond", ")", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "x", "=", "gamma", ".", "unsqueeze", "(", "-", "1", ")", "*", "x", "+", "beta", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.encoder.TextEncoder.__init__": [[7, 23], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "list", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LSTM", "torch.LSTM", "torch.LSTM", "encoder.TextEncoder.cnn.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "kernel_size", ",", "depth", ",", "n_symbols", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "n_symbols", ",", "channels", ")", "\n", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "self", ".", "cnn", "=", "list", "(", ")", "\n", "for", "_", "in", "range", "(", "depth", ")", ":", "\n", "            ", "self", ".", "cnn", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "channels", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.5", ")", ",", "\n", ")", ")", "\n", "", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "cnn", ")", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "channels", ",", "channels", "//", "2", ",", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.encoder.TextEncoder.forward": [[24, 40], ["encoder.TextEncoder.embedding", "torch.utils.rnn.pack_padded_sequence.transpose", "encoder.TextEncoder.cnn", "torch.utils.rnn.pack_padded_sequence.transpose", "input_lengths.cpu().numpy.cpu().numpy.cpu().numpy", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "encoder.TextEncoder.lstm.flatten_parameters", "encoder.TextEncoder.lstm", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "input_lengths.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "input_lengths", ")", ":", "\n", "        ", "x", "=", "self", ".", "embedding", "(", "x", ")", "# [B, T, emb]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# [B, emb, T]", "\n", "x", "=", "self", ".", "cnn", "(", "x", ")", "# [B, chn, T]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# [B, T, chn]", "\n", "\n", "input_lengths", "=", "input_lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "x", ",", "input_lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "x", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "\n", "x", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "x", ",", "batch_first", "=", "True", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.encoder.TextEncoder.inference": [[41, 49], ["encoder.TextEncoder.embedding", "x.transpose.transpose.transpose", "encoder.TextEncoder.cnn", "x.transpose.transpose.transpose", "encoder.TextEncoder.lstm.flatten_parameters", "encoder.TextEncoder.lstm"], "methods", ["None"], ["", "def", "inference", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "embedding", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "cnn", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "x", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.encoder.SpeakerEncoder.__init__": [[52, 66], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "zip", "list"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "stem", "=", "nn", ".", "Conv2d", "(", "\n", "1", ",", "hp", ".", "chn", ".", "speaker", ".", "cnn", "[", "0", "]", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "cnn", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "for", "in_channels", ",", "out_channels", "in", "zip", "(", "list", "(", "hp", ".", "chn", ".", "speaker", ".", "cnn", ")", "[", ":", "-", "1", "]", ",", "hp", ".", "chn", ".", "speaker", ".", "cnn", "[", "1", ":", "]", ")", "\n", "]", ")", "# 80 - 40 - 20 - 10 - 5 - 3 - 2", "\n", "self", ".", "bn", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "BatchNorm2d", "(", "channels", ")", "for", "channels", "in", "hp", ".", "chn", ".", "speaker", ".", "cnn", "\n", "]", ")", "\n", "self", ".", "gru", "=", "nn", ".", "GRU", "(", "hp", ".", "chn", ".", "speaker", ".", "cnn", "[", "-", "1", "]", "*", "2", ",", "hp", ".", "chn", ".", "speaker", ".", "token", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.encoder.SpeakerEncoder.forward": [[67, 94], ["cnn.unsqueeze", "encoder.SpeakerEncoder.stem", "zip", "cnn.view", "cnn.transpose", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "input_lengths.cpu().numpy.cpu().numpy.cpu().numpy", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "encoder.SpeakerEncoder.gru.flatten_parameters", "encoder.SpeakerEncoder.gru", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "bn", "encoder.SpeakerEncoder.relu", "cnn", "cnn.size", "cnn.size", "input_lengths.cpu().numpy.cpu().numpy.cpu", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "input_lengths", ")", ":", "\n", "# x: [B, mel, T]", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "# [B, 1, mel, T]", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "input_lengths", "=", "(", "input_lengths", "+", "1", ")", "//", "2", "\n", "\n", "for", "cnn", ",", "bn", "in", "zip", "(", "self", ".", "cnn", ",", "self", ".", "bn", ")", ":", "\n", "            ", "x", "=", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "cnn", "(", "x", ")", "\n", "input_lengths", "=", "(", "input_lengths", "+", "1", ")", "//", "2", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "# [B, chn.speaker.cnn[-1]*2, T}]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# [B, T, chn.speaker.cnn[-1]*2]", "\n", "\n", "input_lengths", ",", "indices", "=", "torch", ".", "sort", "(", "input_lengths", ",", "descending", "=", "True", ")", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "dim", "=", "0", ",", "index", "=", "indices", ")", "\n", "\n", "input_lengths", "=", "input_lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "x", ",", "input_lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "gru", ".", "flatten_parameters", "(", ")", "\n", "_", ",", "x", "=", "self", ".", "gru", "(", "x", ")", "\n", "\n", "x", "=", "torch", ".", "index_select", "(", "x", "[", "0", "]", ",", "dim", "=", "0", ",", "index", "=", "torch", ".", "sort", "(", "indices", ")", "[", "1", "]", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.encoder.SpeakerEncoder.inference": [[95, 111], ["cnn.unsqueeze", "encoder.SpeakerEncoder.stem", "zip", "cnn.view", "cnn.transpose", "encoder.SpeakerEncoder.gru.flatten_parameters", "encoder.SpeakerEncoder.gru", "cnn.squeeze", "bn", "encoder.SpeakerEncoder.relu", "cnn", "cnn.size", "cnn.size"], "methods", ["None"], ["", "def", "inference", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "\n", "for", "cnn", ",", "bn", "in", "zip", "(", "self", ".", "cnn", ",", "self", ".", "bn", ")", ":", "\n", "            ", "x", "=", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "cnn", "(", "x", ")", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "self", ".", "gru", ".", "flatten_parameters", "(", ")", "\n", "_", ",", "x", "=", "self", ".", "gru", "(", "x", ")", "\n", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.__init__": [[12, 34], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "residual.ResidualEncoder.register_buffer", "padded_instancenorm.PaddedInstanceNorm1d", "torch.InstanceNorm1d", "torch.InstanceNorm1d", "torch.InstanceNorm1d", "torch.hann_window.view", "torch.hann_window.view", "torch.hann_window.view", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "zip", "list"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hp", "=", "hp", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "stem", "=", "nn", ".", "Conv2d", "(", "\n", "1", ",", "hp", ".", "chn", ".", "residual", "[", "0", "]", ",", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "padding", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "for", "in_channels", ",", "out_channels", "in", "zip", "(", "list", "(", "hp", ".", "chn", ".", "residual", ")", "[", ":", "-", "1", "]", ",", "hp", ".", "chn", ".", "residual", "[", "1", ":", "]", ")", "\n", "]", ")", "\n", "self", ".", "bn_layers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "BatchNorm2d", "(", "channels", ")", "for", "channels", "in", "hp", ".", "chn", ".", "residual", "\n", "]", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "None", ")", ")", "# [B, C, 1, T]", "\n", "self", ".", "fc", "=", "nn", ".", "Conv1d", "(", "hp", ".", "chn", ".", "residual", "[", "-", "1", "]", ",", "hp", ".", "chn", ".", "residual_out", ",", "kernel_size", "=", "1", ")", "\n", "\n", "assert", "hp", ".", "ker", ".", "hann_window", "%", "2", "==", "1", ",", "'hp.ker.hann_window must be odd'", "\n", "hann_window", "=", "torch", ".", "hann_window", "(", "window_length", "=", "hp", ".", "ker", ".", "hann_window", ",", "periodic", "=", "False", ")", "\n", "hann_window", "=", "hann_window", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "*", "(", "2.0", "/", "(", "hp", ".", "ker", ".", "hann_window", "-", "1", ")", ")", "\n", "self", ".", "register_buffer", "(", "'hann'", ",", "hann_window", ")", "\n", "self", ".", "padded_norm", "=", "PaddedInstanceNorm1d", "(", "hp", ".", "chn", ".", "residual_out", ")", "# affine=False by default", "\n", "self", ".", "norm", "=", "nn", ".", "InstanceNorm1d", "(", "hp", ".", "chn", ".", "residual_out", ")", "# affine=False by default", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.forward": [[35, 69], ["mel.unsqueeze", "residual.ResidualEncoder.stem", "zip", "residual.ResidualEncoder.avgpool", "residual.ResidualEncoder.squeeze", "residual.ResidualEncoder.fc", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "residual.ResidualEncoder.view", "torch.conv1d", "torch.conv1d", "torch.conv1d", "residual.ResidualEncoder.view", "mask.unsqueeze.unsqueeze.unsqueeze", "bn", "residual.ResidualEncoder.relu", "cnn", "residual.ResidualEncoder.masked_fill_", "residual.ResidualEncoder.padded_norm", "residual.ResidualEncoder.masked_fill_", "residual.ResidualEncoder.norm", "residual.ResidualEncoder.size", "residual.ResidualEncoder.size", "residual.ResidualEncoder.masked_fill_", "mask.unsqueeze.unsqueeze.squeeze", "mask.unsqueeze.unsqueeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "mel", ",", "mask", ",", "lengths", ")", ":", "\n", "        ", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# [B, 1, 1, T]", "\n", "# mel: [B, mel, T]", "\n", "", "x", "=", "mel", ".", "unsqueeze", "(", "1", ")", "# [B, 1, mel, T]", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "# [B, chn.residual[0], T]", "\n", "\n", "for", "cnn", ",", "bn", "in", "zip", "(", "self", ".", "conv_layers", ",", "self", ".", "bn_layers", ")", ":", "\n", "            ", "x", "=", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "cnn", "(", "x", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "                ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "# [B, C, 1, T]", "\n", "x", "=", "x", ".", "squeeze", "(", "2", ")", "# [B, C, T]", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "# [B, chn.residual_out, T]", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ".", "squeeze", "(", "1", ")", ",", "0.0", ")", "\n", "assert", "lengths", "is", "not", "None", "\n", "x", "=", "self", ".", "padded_norm", "(", "x", ",", "lengths", ")", "\n", "x", ".", "masked_fill_", "(", "mask", ".", "squeeze", "(", "1", ")", ",", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "\n", "", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "\n", "# smoothing with hann window", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "1", ",", "x", ".", "size", "(", "2", ")", ")", "# [B*chn.residual_out, 1, T]", "\n", "x", "=", "F", ".", "conv1d", "(", "x", ",", "self", ".", "hann", ",", "padding", "=", "(", "self", ".", "hp", ".", "ker", ".", "hann_window", "-", "1", ")", "//", "2", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "hp", ".", "chn", ".", "residual_out", ",", "x", ".", "size", "(", "2", ")", ")", "# [B, chn.residual_out, T]", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.residual.ResidualEncoder.inference": [[70, 72], ["residual.ResidualEncoder.forward"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.forward"], ["", "def", "inference", "(", "self", ",", "mel", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "mel", ",", "None", ",", "None", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.padded_instancenorm.PaddedInstanceNorm1d.__init__": [[7, 17], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-05", ",", "momentum", "=", "0.1", ",", "\n", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "momentum", "=", "momentum", "# only used when track_running_stats=True", "\n", "if", "affine", "is", "True", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "track_running_stats", "is", "True", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.padded_instancenorm.PaddedInstanceNorm1d.forward": [[18, 29], ["lengths.view().float.view().float.view().float", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "lengths.view().float.view().float.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "lengths", ")", ":", "\n", "# x: [N, C, L]", "\n", "# lengths: [N] torch.LongTensor", "\n", "        ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "float", "(", ")", "# [N, 1, 1]", "\n", "sum_", "=", "torch", ".", "sum", "(", "x", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "# [N, C, 1]", "\n", "mean", "=", "sum_", "/", "lengths", "# [N, C, 1]", "\n", "sqsum", "=", "torch", ".", "sum", "(", "torch", ".", "pow", "(", "x", ",", "2.0", ")", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "# [N, C, 1]", "\n", "sqmean", "=", "sqsum", "/", "lengths", "# [N, C, 1]", "\n", "var", "=", "sqmean", "-", "torch", ".", "pow", "(", "mean", ",", "2.0", ")", "# [N, C, 1]", "\n", "\n", "return", "(", "x", "-", "mean", ")", "/", "torch", ".", "pow", "(", "var", "+", "self", ".", "eps", ",", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.mel.Audio2Mel.__init__": [[31, 46], ["torch.Module.__init__", "torch.hann_window().float", "torch.hann_window().float", "torch.hann_window().float", "torch.hann_window().float", "torch.hann_window().float", "torch.hann_window().float", "torch.hann_window().float", "torch.hann_window().float", "torch.hann_window().float", "librosa.filters.mel", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "librosa.filters.mel.Audio2Mel.register_buffer", "librosa.filters.mel.Audio2Mel.register_buffer", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_fft", ",", "hop_length", ",", "win_length", ",", "sampling_rate", ",", "\n", "n_mel_channels", ",", "mel_fmin", ",", "mel_fmax", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "window", "=", "torch", ".", "hann_window", "(", "win_length", ")", ".", "float", "(", ")", "\n", "mel_basis", "=", "librosa_mel_fn", "(", "\n", "sampling_rate", ",", "n_fft", ",", "n_mel_channels", ",", "mel_fmin", ",", "mel_fmax", "\n", ")", "\n", "mel_basis", "=", "torch", ".", "from_numpy", "(", "mel_basis", ")", ".", "float", "(", ")", "\n", "self", ".", "register_buffer", "(", "\"mel_basis\"", ",", "mel_basis", ")", "\n", "self", ".", "register_buffer", "(", "\"window\"", ",", "window", ")", "\n", "self", ".", "n_fft", "=", "n_fft", "\n", "self", ".", "hop_length", "=", "hop_length", "\n", "self", ".", "win_length", "=", "win_length", "\n", "self", ".", "sampling_rate", "=", "sampling_rate", "\n", "self", ".", "n_mel_channels", "=", "n_mel_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.mel.Audio2Mel.forward": [[47, 62], ["torch.pad().squeeze", "torch.pad().squeeze", "torch.pad().squeeze", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.log10", "torch.log10", "torch.log10", "torch.log10", "torch.log10", "torch.log10", "torch.log10", "torch.log10", "torch.log10", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.pad", "torch.pad", "torch.pad"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "audio", ")", ":", "\n", "        ", "p", "=", "(", "self", ".", "n_fft", "-", "self", ".", "hop_length", ")", "//", "2", "\n", "audio", "=", "F", ".", "pad", "(", "audio", ",", "(", "p", ",", "p", ")", ",", "\"reflect\"", ")", ".", "squeeze", "(", "1", ")", "\n", "fft", "=", "torch", ".", "stft", "(", "\n", "audio", ",", "\n", "n_fft", "=", "self", ".", "n_fft", ",", "\n", "hop_length", "=", "self", ".", "hop_length", ",", "\n", "win_length", "=", "self", ".", "win_length", ",", "\n", "window", "=", "self", ".", "window", ",", "\n", "center", "=", "False", ",", "\n", ")", "\n", "magnitude", "=", "torch", ".", "norm", "(", "fft", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "mel_output", "=", "torch", ".", "matmul", "(", "self", ".", "mel_basis", ",", "magnitude", ")", "\n", "log_mel_spec", "=", "torch", ".", "log10", "(", "torch", ".", "clamp", "(", "mel_output", ",", "min", "=", "1e-5", ")", ")", "\n", "return", "log_mel_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.vc_decoder.GBlock.__init__": [[10, 21], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "cond_bn.ConditionalBatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "range", "range"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "condition_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cond_bn", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ConditionalBatchNorm1d", "(", "in_channels", "if", "i", "==", "0", "else", "out_channels", ",", "condition_dim", ")", "\n", "for", "i", "in", "range", "(", "4", ")", "]", ")", "\n", "self", ".", "leaky_relu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ")", "\n", "self", ".", "cnn", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Conv1d", "(", "in_channels", "if", "i", "==", "0", "else", "out_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "dilation", "=", "2", "**", "i", ",", "padding", "=", "2", "**", "i", ")", "\n", "for", "i", "in", "range", "(", "4", ")", "]", ")", "\n", "self", ".", "shortcut", "=", "nn", ".", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.vc_decoder.GBlock.forward": [[22, 48], ["vc_decoder.GBlock.leaky_relu", "x.masked_fill_", "vc_decoder.GBlock.leaky_relu", "x.masked_fill_", "vc_decoder.GBlock.shortcut", "x.masked_fill_", "vc_decoder.GBlock.leaky_relu", "x.masked_fill_", "vc_decoder.GBlock.leaky_relu", "x.masked_fill_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "z", ",", "mask", "=", "None", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "x", "=", "self", ".", "cnn", "[", "0", "]", "(", "self", ".", "leaky_relu", "(", "self", ".", "cond_bn", "[", "0", "]", "(", "x", ",", "z", ")", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "x", "=", "self", ".", "cnn", "[", "1", "]", "(", "self", ".", "leaky_relu", "(", "self", ".", "cond_bn", "[", "1", "]", "(", "x", ",", "z", ")", ")", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "x", "=", "x", "+", "self", ".", "shortcut", "(", "identity", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "identity", "=", "x", "\n", "x", "=", "self", ".", "cnn", "[", "2", "]", "(", "self", ".", "leaky_relu", "(", "self", ".", "cond_bn", "[", "2", "]", "(", "x", ",", "z", ")", ")", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "x", "=", "self", ".", "cnn", "[", "3", "]", "(", "self", ".", "leaky_relu", "(", "self", ".", "cond_bn", "[", "3", "]", "(", "x", ",", "z", ")", ")", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "x", "=", "x", "+", "identity", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.vc_decoder.VCDecoder.__init__": [[51, 59], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "vc_decoder.GBlock", "zip", "list"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stem", "=", "nn", ".", "Conv1d", "(", "hp", ".", "chn", ".", "encoder", "+", "hp", ".", "chn", ".", "residual_out", ",", "hp", ".", "chn", ".", "gblock", "[", "0", "]", ",", "kernel_size", "=", "7", ",", "padding", "=", "3", ")", "\n", "self", ".", "gblock", "=", "nn", ".", "ModuleList", "(", "[", "\n", "GBlock", "(", "in_channels", ",", "out_channels", ",", "hp", ".", "chn", ".", "speaker", ".", "token", ")", "\n", "for", "in_channels", ",", "out_channels", "in", "\n", "zip", "(", "list", "(", "hp", ".", "chn", ".", "gblock", ")", "[", ":", "-", "1", "]", ",", "hp", ".", "chn", ".", "gblock", "[", "1", ":", "]", ")", "]", ")", "\n", "self", ".", "final", "=", "nn", ".", "Conv1d", "(", "hp", ".", "chn", ".", "gblock", "[", "-", "1", "]", ",", "hp", ".", "audio", ".", "n_mel_channels", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.vc_decoder.VCDecoder.forward": [[60, 75], ["vc_decoder.VCDecoder.stem", "vc_decoder.VCDecoder.final", "gblock.masked_fill_", "gblock", "gblock.masked_fill_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "speaker_emb", ",", "mask", "=", "None", ")", ":", "\n", "# x: linguistic features + pitch info.", "\n", "# [B, chn.encoder + chn.residual_out, T_dec]", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "# [B, chn.gblock[0], T]", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "for", "gblock", "in", "self", ".", "gblock", ":", "\n", "            ", "x", "=", "gblock", "(", "x", ",", "speaker_emb", ",", "mask", ")", "\n", "# x: [B, chn.gblock[-1], T]", "\n", "\n", "", "x", "=", "self", ".", "final", "(", "x", ")", "# [B, M, T]", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "x", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.StaticFilter.__init__": [[10, 18], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "kernel_size", ",", "out_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "kernel_size", "%", "2", "==", "1", ",", "'kernel size of StaticFilter must be odd, got %d'", "%", "kernel_size", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "1", ",", "channels", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "channels", ",", "out_dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.StaticFilter.forward": [[19, 26], ["prev_attn.unsqueeze", "attention.StaticFilter.conv", "attention.StaticFilter.transpose", "attention.StaticFilter.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_attn", ")", ":", "\n", "# prev_attn: [B, T]", "\n", "        ", "x", "=", "prev_attn", ".", "unsqueeze", "(", "1", ")", "# [B, 1, T]", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "# [B, channels, T]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# [B, T, out_dim]", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.DynamicFilter.__init__": [[29, 43], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "kernel_size", ",", "attn_rnn_dim", ",", "hypernet_dim", ",", "out_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "assert", "kernel_size", "%", "2", "==", "1", ",", "'kernel size of DynamicFilter must be odd, god %d'", "%", "kernel_size", "\n", "self", ".", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "\n", "self", ".", "hypernet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "attn_rnn_dim", ",", "hypernet_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hypernet_dim", ",", "channels", "*", "kernel_size", ")", ",", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "channels", ",", "out_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.DynamicFilter.forward": [[44, 57], ["attention.DynamicFilter.hypernet", "convweight.view.view.view", "convweight.view.view.view", "prev_attn.unsqueeze.unsqueeze.unsqueeze", "torch.conv1d", "torch.conv1d", "torch.conv1d", "attention.DynamicFilter.view", "attention.DynamicFilter.transpose", "attention.DynamicFilter.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "prev_attn", ")", ":", "\n", "# query: [B, attn_rnn_dim]", "\n", "# prev_attn: [B, T]", "\n", "        ", "B", ",", "T", "=", "prev_attn", ".", "shape", "\n", "convweight", "=", "self", ".", "hypernet", "(", "query", ")", "# [B, channels * kernel_size]", "\n", "convweight", "=", "convweight", ".", "view", "(", "B", ",", "self", ".", "channels", ",", "self", ".", "kernel_size", ")", "\n", "convweight", "=", "convweight", ".", "view", "(", "B", "*", "self", ".", "channels", ",", "1", ",", "self", ".", "kernel_size", ")", "\n", "prev_attn", "=", "prev_attn", ".", "unsqueeze", "(", "0", ")", "\n", "x", "=", "F", ".", "conv1d", "(", "prev_attn", ",", "convweight", ",", "padding", "=", "self", ".", "padding", ",", "groups", "=", "B", ")", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "self", ".", "channels", ",", "T", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# [B, T, channels]", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "# [B, T, out_dim]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.PriorFilter.__init__": [[60, 82], ["torch.Module.__init__", "numpy.array().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "attention.PriorFilter.prior.view", "attention.PriorFilter.register_buffer", "scipy.special.gamma", "attention.PriorFilter.__init__.beta_func"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "causal_n", ",", "alpha", ",", "beta", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "causal_n", "=", "causal_n", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "def", "beta_func", "(", "x", ",", "y", ")", ":", "\n", "            ", "return", "gamma", "(", "x", ")", "*", "gamma", "(", "y", ")", "/", "gamma", "(", "x", "+", "y", ")", "\n", "\n", "", "def", "p", "(", "n", ",", "k", ",", "alpha", ",", "beta", ")", ":", "\n", "            ", "def", "nCr", "(", "n", ",", "r", ")", ":", "\n", "                ", "f", "=", "math", ".", "factorial", "\n", "return", "f", "(", "n", ")", "/", "(", "f", "(", "r", ")", "*", "f", "(", "n", "-", "r", ")", ")", "\n", "", "return", "nCr", "(", "n", ",", "k", ")", "*", "beta_func", "(", "k", "+", "alpha", ",", "n", "-", "k", "+", "beta", ")", "/", "beta_func", "(", "alpha", ",", "beta", ")", "\n", "\n", "", "self", ".", "prior", "=", "np", ".", "array", "(", "[", "\n", "p", "(", "self", ".", "causal_n", "-", "1", ",", "i", ",", "self", ".", "alpha", ",", "self", ".", "beta", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "causal_n", ")", "[", ":", ":", "-", "1", "]", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "self", ".", "prior", "=", "torch", ".", "from_numpy", "(", "self", ".", "prior", ")", "\n", "self", ".", "prior", "=", "self", ".", "prior", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "self", ".", "register_buffer", "(", "'prior_filter'", ",", "self", ".", "prior", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.PriorFilter.forward": [[83, 89], ["prev_attn.unsqueeze.unsqueeze.unsqueeze", "torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.log.squeeze", "torch.log.squeeze", "torch.log.squeeze", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.pad", "torch.pad", "torch.pad", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_attn", ")", ":", "\n", "        ", "prev_attn", "=", "prev_attn", ".", "unsqueeze", "(", "1", ")", "\n", "energies", "=", "F", ".", "conv1d", "(", "F", ".", "pad", "(", "prev_attn", ",", "(", "self", ".", "causal_n", "-", "1", ",", "0", ")", ")", ",", "self", ".", "prior_filter", ")", "\n", "energies", "=", "energies", ".", "squeeze", "(", "1", ")", "\n", "energies", "=", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "energies", ",", "min", "=", "1e-8", ")", ")", "\n", "return", "energies", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.Attention.__init__": [[92, 100], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "attention.StaticFilter", "attention.DynamicFilter", "attention.PriorFilter", "float"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attn_rnn_dim", ",", "attn_dim", ",", "static_channels", ",", "static_kernel_size", ",", "\n", "dynamic_channels", ",", "dynamic_kernel_size", ",", "causal_n", ",", "causal_alpha", ",", "causal_beta", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "attn_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "static_filter", "=", "StaticFilter", "(", "static_channels", ",", "static_kernel_size", ",", "attn_dim", ")", "\n", "self", ".", "dynamic_filter", "=", "DynamicFilter", "(", "dynamic_channels", ",", "dynamic_kernel_size", ",", "attn_rnn_dim", ",", "attn_dim", ",", "attn_dim", ")", "\n", "self", ".", "prior_filter", "=", "PriorFilter", "(", "causal_n", ",", "causal_alpha", ",", "causal_beta", ")", "\n", "self", ".", "score_mask_value", "=", "-", "float", "(", "'inf'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.Attention.get_alignment_energies": [[101, 108], ["attention.Attention.static_filter", "attention.Attention.dynamic_filter", "attention.Attention.prior_filter", "attention.Attention.v().squeeze", "attention.Attention.v", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "get_alignment_energies", "(", "self", ",", "query", ",", "prev_attn", ")", ":", "\n", "        ", "static_result", "=", "self", ".", "static_filter", "(", "prev_attn", ")", "\n", "dynamic_result", "=", "self", ".", "dynamic_filter", "(", "query", ",", "prev_attn", ")", "\n", "prior_result", "=", "self", ".", "prior_filter", "(", "prev_attn", ")", "\n", "\n", "energies", "=", "self", ".", "v", "(", "torch", ".", "tanh", "(", "static_result", "+", "dynamic_result", ")", ")", ".", "squeeze", "(", "-", "1", ")", "+", "prior_result", "\n", "return", "energies", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.Attention.forward": [[109, 121], ["attention.Attention.get_alignment_energies", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "context.squeeze.squeeze.squeeze", "attention.Attention.data.masked_fill_", "torch.softmax.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.attention.Attention.get_alignment_energies"], ["", "def", "forward", "(", "self", ",", "attn_hidden", ",", "memory", ",", "prev_attn", ",", "mask", ")", ":", "\n", "        ", "alignment", "=", "self", ".", "get_alignment_energies", "(", "attn_hidden", ",", "prev_attn", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "alignment", ".", "data", ".", "masked_fill_", "(", "mask", ",", "self", ".", "score_mask_value", ")", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "alignment", ",", "dim", "=", "1", ")", "# [B, T]", "\n", "context", "=", "torch", ".", "bmm", "(", "attn_weights", ".", "unsqueeze", "(", "1", ")", ",", "memory", ")", "\n", "# [B, 1, T] @ [B, T, (chn.encoder + chn.speaker)] -> [B, 1, (chn.encoder + chn.speaker)]", "\n", "context", "=", "context", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "context", ",", "attn_weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.PreNet.__init__": [[12, 18], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "zip"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "in_dim", ",", "depth", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "sizes", "=", "[", "in_dim", "]", "+", "[", "channels", "]", "*", "depth", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", "\n", "for", "(", "in_size", ",", "out_size", ")", "in", "zip", "(", "sizes", "[", ":", "-", "1", "]", ",", "sizes", "[", "1", ":", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.PreNet.forward": [[21, 25], ["torch.dropout", "torch.dropout", "torch.dropout", "torch.relu", "torch.relu", "torch.relu", "linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "prenet_dropout", ")", ":", "\n", "        ", "for", "linear", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "F", ".", "relu", "(", "linear", "(", "x", ")", ")", ",", "p", "=", "prenet_dropout", ",", "training", "=", "True", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.PostNet.__init__": [[28, 52], ["torch.Module.__init__", "list", "tts_decoder.PostNet.cnn.append", "range", "tts_decoder.PostNet.cnn.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "tts_decoder.PostNet.cnn.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "kernel_size", ",", "n_mel_channels", ",", "depth", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "self", ".", "cnn", "=", "list", "(", ")", "\n", "self", ".", "cnn", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "n_mel_channels", ",", "channels", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "channels", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.5", ")", ",", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "depth", "-", "1", ")", ":", "\n", "            ", "self", ".", "cnn", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "channels", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.5", ")", ",", ")", ")", "\n", "\n", "", "self", ".", "cnn", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "channels", ",", "n_mel_channels", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ")", ",", ")", ")", "\n", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "cnn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.PostNet.forward": [[53, 55], ["tts_decoder.PostNet.cnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "cnn", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.__init__": [[58, 77], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "tts_decoder.PreNet", "tts_decoder.PostNet", "zoneout.ZoneoutLSTMCell", "attention.Attention", "zoneout.ZoneoutLSTMCell", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hp", "=", "hp", "\n", "self", ".", "go_frame", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "1", ",", "hp", ".", "audio", ".", "n_mel_channels", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "self", ".", "prenet", "=", "PreNet", "(", "\n", "hp", ".", "chn", ".", "prenet", ",", "in_dim", "=", "hp", ".", "audio", ".", "n_mel_channels", ",", "depth", "=", "hp", ".", "depth", ".", "encoder", ")", "\n", "self", ".", "postnet", "=", "PostNet", "(", "\n", "hp", ".", "chn", ".", "postnet", ",", "hp", ".", "ker", ".", "postnet", ",", "hp", ".", "audio", ".", "n_mel_channels", ",", "hp", ".", "depth", ".", "postnet", ")", "\n", "self", ".", "attention_rnn", "=", "ZoneoutLSTMCell", "(", "\n", "hp", ".", "chn", ".", "prenet", "+", "hp", ".", "chn", ".", "encoder", "+", "hp", ".", "chn", ".", "speaker", ".", "token", ",", "hp", ".", "chn", ".", "attention_rnn", ",", "zoneout_prob", "=", "0.1", ")", "\n", "self", ".", "attention_layer", "=", "Attention", "(", "\n", "hp", ".", "chn", ".", "attention_rnn", ",", "hp", ".", "chn", ".", "attention", ",", "hp", ".", "chn", ".", "static", ",", "hp", ".", "ker", ".", "static", ",", "\n", "hp", ".", "chn", ".", "dynamic", ",", "hp", ".", "ker", ".", "dynamic", ",", "hp", ".", "ker", ".", "causal", ",", "hp", ".", "ker", ".", "alpha", ",", "hp", ".", "ker", ".", "beta", ")", "\n", "self", ".", "decoder_rnn", "=", "ZoneoutLSTMCell", "(", "\n", "hp", ".", "chn", ".", "attention_rnn", "+", "hp", ".", "chn", ".", "encoder", "+", "hp", ".", "chn", ".", "speaker", ".", "token", ",", "hp", ".", "chn", ".", "decoder_rnn", ",", "zoneout_prob", "=", "0.1", ")", "\n", "self", ".", "mel_fc", "=", "nn", ".", "Linear", "(", "\n", "hp", ".", "chn", ".", "decoder_rnn", "+", "hp", ".", "chn", ".", "encoder", "+", "hp", ".", "chn", ".", "speaker", ".", "token", ",", "hp", ".", "audio", ".", "n_mel_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.get_go_frame": [[78, 80], ["tts_decoder.TTSDecoder.go_frame.expand", "memory.size"], "methods", ["None"], ["", "def", "get_go_frame", "(", "self", ",", "memory", ")", ":", "\n", "        ", "return", "self", ".", "go_frame", ".", "expand", "(", "memory", ".", "size", "(", "0", ")", ",", "self", ".", "hp", ".", "audio", ".", "n_mel_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.initialize": [[81, 97], ["memory.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "memory", ",", "mask", ")", ":", "\n", "        ", "B", ",", "T", ",", "_", "=", "memory", ".", "size", "(", ")", "\n", "self", ".", "memory", "=", "memory", "\n", "self", ".", "mask", "=", "mask", "\n", "device", "=", "memory", ".", "device", "\n", "\n", "attn_h", "=", "torch", ".", "zeros", "(", "B", ",", "self", ".", "hp", ".", "chn", ".", "attention_rnn", ")", ".", "to", "(", "device", ")", "\n", "attn_c", "=", "torch", ".", "zeros", "(", "B", ",", "self", ".", "hp", ".", "chn", ".", "attention_rnn", ")", ".", "to", "(", "device", ")", "\n", "dec_h", "=", "torch", ".", "zeros", "(", "B", ",", "self", ".", "hp", ".", "chn", ".", "decoder_rnn", ")", ".", "to", "(", "device", ")", "\n", "dec_c", "=", "torch", ".", "zeros", "(", "B", ",", "self", ".", "hp", ".", "chn", ".", "decoder_rnn", ")", ".", "to", "(", "device", ")", "\n", "\n", "prev_attn", "=", "torch", ".", "zeros", "(", "B", ",", "T", ")", ".", "to", "(", "device", ")", "\n", "prev_attn", "[", ":", ",", "0", "]", "=", "1.0", "\n", "context", "=", "torch", ".", "zeros", "(", "B", ",", "self", ".", "hp", ".", "chn", ".", "encoder", "+", "self", ".", "hp", ".", "chn", ".", "speaker", ".", "token", ")", ".", "to", "(", "device", ")", "\n", "\n", "return", "attn_h", ",", "attn_c", ",", "dec_h", ",", "dec_c", ",", "prev_attn", ",", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.decode": [[98, 118], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tts_decoder.TTSDecoder.attention_rnn", "tts_decoder.TTSDecoder.attention_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tts_decoder.TTSDecoder.decoder_rnn", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tts_decoder.TTSDecoder.mel_fc"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "x", ",", "attn_h", ",", "attn_c", ",", "dec_h", ",", "dec_c", ",", "prev_attn", ",", "context", ")", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "context", ")", ",", "dim", "=", "-", "1", ")", "\n", "# [B, chn.prenet + (chn.encoder + chn.speaker.token)]", "\n", "attn_h", ",", "attn_c", "=", "self", ".", "attention_rnn", "(", "x", ",", "(", "attn_h", ",", "attn_c", ")", ")", "\n", "# [B, chn.attention_rnn]", "\n", "\n", "context", ",", "prev_attn", "=", "self", ".", "attention_layer", "(", "attn_h", ",", "self", ".", "memory", ",", "prev_attn", ",", "self", ".", "mask", ")", "\n", "# context: [B, (chn.encoder + chn.speaker.token)], prev_attn: [B, T]", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "(", "attn_h", ",", "context", ")", ",", "dim", "=", "-", "1", ")", "\n", "# [B, chn.attention_rnn + (chn.encoder + chn.speaker.token)]", "\n", "dec_h", ",", "dec_c", "=", "self", ".", "decoder_rnn", "(", "x", ",", "(", "dec_h", ",", "dec_c", ")", ")", "\n", "# [B, chn.decoder_rnn]", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "(", "dec_h", ",", "context", ")", ",", "dim", "=", "-", "1", ")", "\n", "# [B, chn.decoder_rnn + (chn.encoder + chn.speaker.token)]", "\n", "mel_out", "=", "self", ".", "mel_fc", "(", "x", ")", "\n", "# [B, audio.n_mel_channels]", "\n", "\n", "return", "mel_out", ",", "attn_h", ",", "attn_c", ",", "dec_h", ",", "dec_c", ",", "prev_attn", ",", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.parse_decoder_outputs": [[119, 128], ["torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "mel_outputs.transpose.transpose.transpose", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "parse_decoder_outputs", "(", "self", ",", "mel_outputs", ",", "alignments", ")", ":", "\n", "# 'T' is T_dec.", "\n", "        ", "mel_outputs", "=", "torch", ".", "stack", "(", "mel_outputs", ",", "dim", "=", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "mel_outputs", "=", "mel_outputs", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# mel: [T, B, M] -> [B, T, M] -> [B, M, T]", "\n", "alignments", "=", "torch", ".", "stack", "(", "alignments", ",", "dim", "=", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# align: [T_dec, B, T_enc] -> [B, T_dec, T_enc]", "\n", "\n", "return", "mel_outputs", ",", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.forward": [[129, 166], ["tts_decoder.TTSDecoder.get_go_frame().unsqueeze", "tts_decoder.TTSDecoder.transpose().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tts_decoder.TTSDecoder.prenet", "tts_decoder.TTSDecoder.initialize", "tts_decoder.TTSDecoder.parse_decoder_outputs", "alignments.squeeze.squeeze.unsqueeze", "torch.pad", "torch.pad", "torch.pad", "alignments.squeeze.squeeze.squeeze", "tts_decoder.TTSDecoder.mask_output", "len", "tts_decoder.TTSDecoder.decode", "mel_outputs.append", "alignments.squeeze.squeeze.append", "tts_decoder.TTSDecoder.postnet", "tts_decoder.TTSDecoder.get_go_frame", "tts_decoder.TTSDecoder.transpose", "tts_decoder.TTSDecoder.size", "tts_decoder.TTSDecoder.prenet", "random.random", "alignments.squeeze.squeeze.size", "tts_decoder.TTSDecoder.get_mask_from_lengths", "len"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.initialize", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.parse_decoder_outputs", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.mask_output", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.decode", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.get_go_frame", "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.get_mask_from_lengths"], ["", "def", "forward", "(", "self", ",", "x", ",", "memory", ",", "memory_lengths", ",", "output_lengths", ",", "max_input_len", ",", "\n", "prenet_dropout", "=", "0.5", ",", "no_mask", "=", "False", ",", "tfrate", "=", "True", ")", ":", "\n", "# x: mel spectrogram for teacher-forcing. [B, M, T].", "\n", "        ", "go_frame", "=", "self", ".", "get_go_frame", "(", "memory", ")", ".", "unsqueeze", "(", "0", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "# [B, M, T] -> [B, T, M] -> [T, B, M]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "go_frame", ",", "x", ")", ",", "dim", "=", "0", ")", "# [T+1, B, M]", "\n", "x", "=", "self", ".", "prenet", "(", "x", ",", "prenet_dropout", ")", "\n", "\n", "attn_h", ",", "attn_c", ",", "dec_h", ",", "dec_c", ",", "prev_attn", ",", "context", "=", "self", ".", "initialize", "(", "memory", ",", "\n", "mask", "=", "None", "if", "no_mask", "else", "~", "self", ".", "get_mask_from_lengths", "(", "memory_lengths", ")", ")", "\n", "mel_outputs", ",", "alignments", "=", "[", "]", ",", "[", "]", "\n", "\n", "decoder_input", "=", "x", "[", "0", "]", "\n", "while", "len", "(", "mel_outputs", ")", "<", "x", ".", "size", "(", "0", ")", "-", "1", ":", "\n", "            ", "mel_out", ",", "attn_h", ",", "attn_c", ",", "dec_h", ",", "dec_c", ",", "prev_attn", ",", "context", "=", "self", ".", "decode", "(", "decoder_input", ",", "attn_h", ",", "attn_c", ",", "dec_h", ",", "dec_c", ",", "prev_attn", ",", "context", ")", "\n", "\n", "mel_outputs", ".", "append", "(", "mel_out", ")", "\n", "alignments", ".", "append", "(", "prev_attn", ")", "\n", "\n", "if", "tfrate", "and", "self", ".", "hp", ".", "train", ".", "teacher_force", ".", "rate", "<", "random", ".", "random", "(", ")", ":", "\n", "                ", "decoder_input", "=", "self", ".", "prenet", "(", "mel_out", ",", "prenet_dropout", ")", "\n", "", "else", ":", "\n", "                ", "decoder_input", "=", "x", "[", "len", "(", "mel_outputs", ")", "]", "\n", "\n", "", "", "mel_outputs", ",", "alignments", "=", "self", ".", "parse_decoder_outputs", "(", "mel_outputs", ",", "alignments", ")", "\n", "mel_postnet", "=", "mel_outputs", "+", "self", ".", "postnet", "(", "mel_outputs", ")", "\n", "\n", "# DataParallel expects equal sized inputs/outputs, hence padding", "\n", "alignments", "=", "alignments", ".", "unsqueeze", "(", "0", ")", "\n", "alignments", "=", "F", ".", "pad", "(", "alignments", ",", "(", "0", ",", "max_input_len", "[", "0", "]", "-", "alignments", ".", "size", "(", "-", "1", ")", ")", ",", "'constant'", ",", "0", ")", "\n", "alignments", "=", "alignments", ".", "squeeze", "(", "0", ")", "\n", "\n", "mel_outputs", ",", "mel_postnet", ",", "alignments", "=", "self", ".", "mask_output", "(", "mel_outputs", ",", "mel_postnet", ",", "alignments", ",", "output_lengths", ")", "\n", "return", "mel_outputs", ",", "mel_postnet", ",", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.get_mask_from_lengths": [[167, 173], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "lengths.unsqueeze", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "get_mask_from_lengths", "(", "self", ",", "lengths", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "if", "max_len", "is", "None", ":", "\n", "            ", "max_len", "=", "torch", ".", "max", "(", "lengths", ")", ".", "item", "(", ")", "\n", "", "ids", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "out", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "max_len", ")", ")", "\n", "mask", "=", "(", "ids", "<", "lengths", ".", "unsqueeze", "(", "1", ")", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.mask_output": [[174, 182], ["mask.unsqueeze.unsqueeze.unsqueeze", "mel_outputs.masked_fill_", "mel_postnet.masked_fill_", "tts_decoder.TTSDecoder.get_mask_from_lengths", "mel_outputs.size"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.tts_decoder.TTSDecoder.get_mask_from_lengths"], ["", "def", "mask_output", "(", "self", ",", "mel_outputs", ",", "mel_postnet", ",", "alignments", ",", "output_lengths", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "hp", ".", "train", ".", "mask_padding", "and", "output_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "~", "self", ".", "get_mask_from_lengths", "(", "output_lengths", ",", "max_len", "=", "mel_outputs", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# [B, 1, T] torch.bool", "\n", "mel_outputs", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "mel_postnet", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "\n", "", "return", "mel_outputs", ",", "mel_postnet", ",", "alignments", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.zoneout.ZoneoutLSTMCell.__init__": [[6, 18], ["torch.Module.__init__", "torch.LSTMCell", "torch.LSTMCell", "torch.Dropout", "torch.Dropout", "zoneout.ZoneoutLSTMCell.lstm.bias_ih[].data.fill_", "zoneout.ZoneoutLSTMCell.lstm.bias_hh[].data.fill_"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "zoneout_prob", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "zoneout_prob", "=", "zoneout_prob", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTMCell", "(", "input_size", ",", "hidden_size", ",", "bias", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "zoneout_prob", ")", "\n", "\n", "# initialize all forget gate bias of LSTM to 1.0", "\n", "# https://discuss.pytorch.org/t/set-forget-gate-bias-of-lstm/1745/4", "\n", "self", ".", "lstm", ".", "bias_ih", "[", "hidden_size", ":", "2", "*", "hidden_size", "]", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "self", ".", "lstm", ".", "bias_hh", "[", "hidden_size", ":", "2", "*", "hidden_size", "]", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.zoneout.ZoneoutLSTMCell.forward": [[19, 36], ["zoneout.ZoneoutLSTMCell.lstm", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x.size", "x.size", "zoneout.ZoneoutLSTMCell.dropout", "zoneout.ZoneoutLSTMCell.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "prev_hc", "=", "None", ")", ":", "\n", "        ", "h", ",", "c", "=", "self", ".", "lstm", "(", "x", ",", "prev_hc", ")", "\n", "\n", "if", "prev_hc", "is", "None", ":", "\n", "            ", "prev_h", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_size", ")", "\n", "prev_c", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "prev_h", ",", "prev_c", "=", "prev_hc", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "h", "=", "(", "1.", "-", "self", ".", "zoneout_prob", ")", "*", "self", ".", "dropout", "(", "h", "-", "prev_h", ")", "+", "prev_h", "\n", "c", "=", "(", "1.", "-", "self", ".", "zoneout_prob", ")", "*", "self", ".", "dropout", "(", "c", "-", "prev_c", ")", "+", "prev_c", "\n", "", "else", ":", "\n", "            ", "h", "=", "(", "1.", "-", "self", ".", "zoneout_prob", ")", "*", "h", "+", "self", ".", "zoneout_prob", "*", "prev_h", "\n", "c", "=", "(", "1.", "-", "self", ".", "zoneout_prob", ")", "*", "c", "+", "self", ".", "zoneout_prob", "*", "prev_c", "\n", "\n", "", "return", "h", ",", "c", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__": [[7, 16], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.5", ")", ",", "\n", "nn", ".", "Linear", "(", "hp", ".", "chn", ".", "speaker", ".", "token", ",", "hp", ".", "chn", ".", "speaker", ".", "token", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.5", ")", ",", "\n", "nn", ".", "Linear", "(", "hp", ".", "chn", ".", "speaker", ".", "token", ",", "len", "(", "hp", ".", "data", ".", "speakers", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mindslab-ai_cotatron.modules.classifier.SpkClassifier.forward": [[18, 22], ["classifier.SpkClassifier.mlp", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "mlp", "(", "x", ")", "\n", "x", "=", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "return", "x", "\n", "", "", ""]]}