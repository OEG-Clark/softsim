{"home.repos.pwc.inspect_result.directgroup_direct.tools.parse_metrics_log.parse_args": [[11, 23], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tools.parse_metrics_log.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\"Parse input arguments.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Find the best checkpoint for a given metric\"", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"metrics_path\"", ",", "type", "=", "pathlib", ".", "Path", ",", "help", "=", "\"Path to metrics.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"key\"", ",", "type", "=", "str", ",", "help", "=", "\"Key to use to find the best checkpoint.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max\"", ",", "dest", "=", "\"max\"", ",", "help", "=", "\"If True, this computes on maximum, else minimum value for key.\"", ",", "action", "=", "\"store_true\"", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tools.parse_metrics_log.main": [[25, 39], ["parse_metrics_log.parse_args", "numpy.asarray", "print", "open", "f.readlines", "json.loads", "int", "int", "numpy.where", "numpy.where", "x[].max", "x[].min"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tools.parse_metrics_log.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "metrics_path", "/", "\"metrics.json\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "readlines", "(", ")", "\n", "data", "=", "[", "json", ".", "loads", "(", "_", ")", "for", "_", "in", "data", "]", "\n", "", "x", "=", "np", ".", "asarray", "(", "[", "(", "int", "(", "_", "[", "\"iteration\"", "]", ")", ",", "_", "[", "args", ".", "key", "]", ")", "for", "_", "in", "data", "if", "args", ".", "key", "in", "_", "]", ")", "\n", "\n", "if", "args", ".", "max", ":", "\n", "        ", "out", "=", "x", "[", "np", ".", "where", "(", "x", "[", ":", ",", "1", "]", "==", "x", "[", ":", ",", "1", "]", ".", "max", "(", ")", ")", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "out", "=", "x", "[", "np", ".", "where", "(", "x", "[", ":", ",", "1", "]", "==", "x", "[", ":", ",", "1", "]", ".", "min", "(", ")", ")", "]", "[", "0", "]", "\n", "\n", "", "print", "(", "f\"{args.key} - {int(out[0])}: {out[1]}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.DataDimensionality.__init__": [[56, 58], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ndim", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.DataDimensionality.ndim": [[66, 72], ["ValueError", "isinstance"], "methods", ["None"], ["", "@", "ndim", ".", "setter", "\n", "def", "ndim", "(", "self", ",", "ndim", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "ndim", ",", "int", ")", "or", "ndim", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"ndim has to be an integer larger than 0. Got {ndim}.\"", ")", "\n", "\n", "", "self", ".", "_ndim", "=", "ndim", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.__init__": [[75, 125], ["logging.getLogger", "torch.cuda.amp.GradScaler", "engine.Engine.__bind_sigint_signal", "engine.DataDimensionality.__init__", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.__bind_sigint_signal", "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`Engine`.\n\n        Parameters\n        ----------\n        cfg: BaseConfig\n            Configuration file.\n        model: nn.Module\n            Model.\n        device: str\n            Device. Can be \"cuda\" or \"cpu\".\n        forward_operator: Callable, optional\n            The forward operator. Default: None.\n        backward_operator: Callable, optional\n            The backward operator. Default: None.\n        mixed_precision: bool\n            Use mixed precision. Default: False.\n        **models: nn.Module\n            Additional models.\n        \"\"\"", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Operators can be useful in some operations", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "\n", "self", ".", "mixed_precision", "=", "mixed_precision", "\n", "self", ".", "checkpointer", ":", "Union", "[", "Checkpointer", ",", "None", "]", "=", "None", "\n", "\n", "self", ".", "__optimizer", ":", "Union", "[", "torch", ".", "optim", ".", "Optimizer", ",", "None", "]", "=", "None", "\n", "self", ".", "__lr_scheduler", "=", "None", "\n", "self", ".", "_scaler", "=", "GradScaler", "(", "enabled", "=", "self", ".", "mixed_precision", ")", "\n", "self", ".", "__writers", "=", "None", "\n", "self", ".", "__bind_sigint_signal", "(", ")", "\n", "\n", "DataDimensionality", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_loss": [[126, 129], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "build_loss", "(", "self", ")", "->", "Dict", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine._build_function_class": [[130, 141], ["direct.utils.str_to_class", "curr_func.split"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["", "@", "staticmethod", "\n", "def", "_build_function_class", "(", "functions_list", ",", "root_module", ",", "postfix", ")", "->", "Dict", ":", "\n", "        ", "if", "not", "functions_list", ":", "\n", "            ", "return", "{", "}", "\n", "\n", "# _postfix is added as only keys containing loss, metric or reg are logged.", "\n", "", "functions_dict", "=", "{", "\n", "curr_func", ".", "split", "(", "\"(\"", ")", "[", "0", "]", "+", "f\"_{postfix}\"", ":", "str_to_class", "(", "root_module", ",", "curr_func", ")", "\n", "for", "curr_func", "in", "functions_list", "\n", "}", "\n", "return", "functions_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_metrics": [[142, 144], ["engine.Engine._build_function_class"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine._build_function_class"], ["", "def", "build_metrics", "(", "self", ",", "metrics_list", ")", "->", "Dict", ":", "\n", "        ", "return", "self", ".", "_build_function_class", "(", "metrics_list", ",", "\"direct.functionals\"", ",", "\"metric\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_regularizers": [[145, 147], ["engine.Engine._build_function_class"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine._build_function_class"], ["", "def", "build_regularizers", "(", "self", ",", "regularizers_list", ")", "->", "Dict", ":", "\n", "        ", "return", "self", ".", "_build_function_class", "(", "regularizers_list", ",", "\"direct.functionals\"", ",", "\"reg\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine._do_iteration": [[148, 161], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "        ", "\"\"\"This is a placeholder for the iteration function.\n\n        This needs to perform the backward pass. If using mixed-precision you need to implement `autocast` as well in\n        this function. It is recommended you raise an error if `self.mixed_precision` is true but mixed precision is not\n        available.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.predict": [[162, 200], ["torch.no_grad", "engine.Engine.logger.info", "torch.cuda.empty_cache", "engine.Engine.logger.info", "direct.checkpointer.Checkpointer", "engine.Engine.build_batch_sampler", "engine.Engine.build_loader", "list", "isinstance", "engine.Engine.checkpointer.load_models_from_file", "engine.Engine.reconstruct_volumes", "engine.Engine.checkpointer.load"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_batch_sampler", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_loader", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load_models_from_file", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.reconstruct_volumes", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "predict", "(", "\n", "self", ",", "\n", "dataset", ":", "Dataset", ",", "\n", "experiment_directory", ":", "pathlib", ".", "Path", ",", "\n", "checkpoint", ":", "Union", "[", "int", ",", "str", ",", "pathlib", ".", "Path", ",", "None", "]", "=", "-", "1", ",", "\n", "num_workers", ":", "int", "=", "6", ",", "\n", "batch_size", ":", "int", "=", "1", ",", "\n", "crop", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Predicting...\"", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "self", ".", "ndim", "=", "dataset", ".", "ndim", "# type: ignore", "\n", "self", ".", "logger", ".", "info", "(", "\"Data dimensionality: %s.\"", ",", "self", ".", "ndim", ")", "\n", "\n", "self", ".", "checkpointer", "=", "Checkpointer", "(", "\n", "save_directory", "=", "experiment_directory", ",", "save_to_disk", "=", "False", ",", "model", "=", "self", ".", "model", ",", "**", "self", ".", "models", "# type: ignore", "\n", ")", "\n", "# If integer, latest or None", "\n", "if", "isinstance", "(", "checkpoint", ",", "int", ")", "or", "checkpoint", "==", "\"latest\"", "or", "checkpoint", "is", "None", ":", "\n", "# Do not load again if we already have loaded the checkpoint.", "\n", "            ", "if", "self", ".", "checkpointer", ".", "checkpoint_loaded", "is", "not", "checkpoint", ":", "\n", "                ", "self", ".", "checkpointer", ".", "load", "(", "iteration", "=", "checkpoint", ",", "checkpointable_objects", "=", "None", ")", "\n", "# Otherwise it's a path or a url", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "checkpointer", ".", "load_models_from_file", "(", "checkpoint", ")", "\n", "\n", "", "batch_sampler", "=", "self", ".", "build_batch_sampler", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler_type", "=", "\"sequential\"", ",", "\n", "limit_number_of_volumes", "=", "None", ",", "\n", ")", "\n", "# TODO: Batch size can be much larger, perhaps have a different batch size during evaluation.", "\n", "data_loader", "=", "self", ".", "build_loader", "(", "dataset", ",", "batch_sampler", "=", "batch_sampler", ",", "num_workers", "=", "num_workers", ")", "\n", "output", "=", "list", "(", "self", ".", "reconstruct_volumes", "(", "data_loader", ",", "add_target", "=", "False", ",", "crop", "=", "crop", ")", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_loader": [[201, 221], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_loader", "(", "\n", "dataset", ":", "Dataset", ",", "\n", "batch_sampler", ":", "Optional", "[", "Sampler", "]", "=", "None", ",", "\n", "num_workers", ":", "int", "=", "6", ",", "\n", ")", "->", "DataLoader", ":", "\n", "# TODO(jt): Custom memory pinning.", "\n", "        ", "loader", "=", "DataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "sampler", "=", "None", ",", "\n", "batch_size", "=", "1", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "drop_last", "=", "False", ",", "\n", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "False", ",", "# This can do strange things, and needs a custom implementation.", "\n", "# prefetch_factor=1,", "\n", "# persistent_workers=True,", "\n", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_batch_sampler": [[222, 243], ["direct.data.samplers.ConcatDatasetBatchSampler", "any", "ValueError", "direct.data.samplers.DistributedSequentialSampler", "direct.data.samplers.BatchVolumeSampler", "ValueError", "isinstance", "isinstance"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "build_batch_sampler", "(", "\n", "dataset", ":", "Union", "[", "Dataset", ",", "List", "[", "Dataset", "]", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "sampler_type", ":", "str", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "Sampler", ":", "\n", "        ", "if", "sampler_type", "==", "\"random\"", ":", "\n", "            ", "if", "not", "isinstance", "(", "dataset", ",", "List", ")", "or", "any", "(", "not", "isinstance", "(", "_", ",", "Dataset", ")", "for", "_", "in", "dataset", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Random sampler requires a list of datasets as input.\"", ")", "\n", "", "batch_sampler", "=", "ConcatDatasetBatchSampler", "(", "datasets", "=", "dataset", ",", "batch_size", "=", "batch_size", ")", "\n", "", "elif", "sampler_type", "==", "\"sequential\"", ":", "\n", "            ", "sampler", "=", "direct", ".", "data", ".", "samplers", ".", "DistributedSequentialSampler", "(", "dataset", ",", "**", "kwargs", ")", "\n", "batch_sampler", "=", "direct", ".", "data", ".", "samplers", ".", "BatchVolumeSampler", "(", "\n", "sampler", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Sampler type {sampler_type} not supported.\"", ")", "\n", "\n", "", "return", "batch_sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.training_loop": [[244, 392], ["engine.Engine.logger.info", "engine.Engine.models_training_mode", "engine.Engine.build_loss", "engine.Engine.build_metrics", "engine.Engine.build_regularizers", "direct.utils.events.get_event_storage", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.build_batch_sampler", "engine.Engine.build_loader", "functools.partial", "zip", "direct.data.datasets.ConcatDataset", "str", "range", "engine.Engine.__lr_scheduler.step", "direct.utils.events.get_event_storage.add_scalar", "engine.Engine.__optimizer.zero_grad", "direct.utils.communication.reduce_tensor_dict", "sum", "direct.utils.evaluate_dict", "direct.utils.events.get_event_storage.add_scalars", "engine.Engine.checkpoint_model_at_interval", "engine.Engine.write_to_logs_at_interval", "engine.Engine.validate_model_at_interval", "direct.utils.events.get_event_storage.step", "len", "AssertionError", "engine.Engine.logger.info", "sys.exit", "len", "engine.Engine.log_first_training_example_and_model", "engine.Engine.logger.info", "functools.partial.", "engine.Engine._do_iteration", "engine.Engine.logger.info", "engine.Engine._scaler.step", "engine.Engine._scaler.update", "direct.utils.communication.reduce_tensor_dict.values", "direct.data.transforms.modulus_if_complex", "data[].detach().to", "direct.utils.communication.reduce_tensor_dict", "direct.utils.communication.get_local_rank", "engine.Engine.logger.exception", "engine.Engine.checkpoint_and_write_to_logs", "sys.exit", "engine.Engine.checkpoint_and_write_to_logs", "engine.Engine.logger.info", "RuntimeError", "engine.Engine.model.parameters", "engine.Engine._scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "warnings.warn", "list", "sum().sqrt", "direct.utils.events.get_event_storage.add_scalar", "output.detach", "str", "engine.Engine.logger.info", "engine.Engine.__optimizer.zero_grad", "gc.collect", "torch.cuda.empty_cache", "engine.Engine.model.parameters", "filter", "data[].detach", "engine.Engine.checkpoint_and_write_to_logs", "direct.exceptions.TrainingException", "parameter.grad.div_", "engine.Engine.model.parameters", "sum"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_training_mode", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_metrics", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_regularizers", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.get_event_storage", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_batch_sampler", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_loader", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalar", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.reduce_tensor_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.evaluate_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalars", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.checkpoint_model_at_interval", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.write_to_logs_at_interval", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.validate_model_at_interval", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.log_first_training_example_and_model", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus_if_complex", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.reduce_tensor_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_local_rank", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.checkpoint_and_write_to_logs", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.checkpoint_and_write_to_logs", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalar", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.checkpoint_and_write_to_logs"], ["", "def", "training_loop", "(", "\n", "self", ",", "\n", "training_datasets", ":", "List", ",", "# TODO(jt): Improve typing", "\n", "start_iter", ":", "int", ",", "\n", "validation_datasets", ":", "Optional", "[", "List", "]", "=", "None", ",", "\n", "experiment_directory", ":", "Optional", "[", "pathlib", ".", "Path", "]", "=", "None", ",", "\n", "num_workers", ":", "int", "=", "6", ",", "\n", "start_with_validation", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "f\"Local rank: {communication.get_local_rank()}.\"", ")", "\n", "self", ".", "models_training_mode", "(", ")", "\n", "\n", "loss_fns", "=", "self", ".", "build_loss", "(", ")", "\n", "metric_fns", "=", "self", ".", "build_metrics", "(", "self", ".", "cfg", ".", "training", ".", "metrics", ")", "# type: ignore", "\n", "regularizer_fns", "=", "self", ".", "build_regularizers", "(", "self", ".", "cfg", ".", "training", ".", "regularizers", ")", "# type: ignore", "\n", "storage", "=", "get_event_storage", "(", ")", "\n", "\n", "self", ".", "ndim", "=", "training_datasets", "[", "0", "]", ".", "ndim", "\n", "self", ".", "logger", ".", "info", "(", "\"Data dimensionality: %s.\"", ",", "self", ".", "ndim", ")", "\n", "\n", "try", ":", "\n", "            ", "training_data", "=", "ConcatDataset", "(", "training_datasets", ")", "\n", "if", "len", "(", "training_data", ")", "<=", "0", ":", "\n", "                ", "raise", "AssertionError", "(", "\"No training data available\"", ")", "\n", "", "", "except", "AssertionError", "as", "err", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"%s: Terminating training...\"", ",", "err", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Concatenated dataset length: %s.\"", ",", "str", "(", "len", "(", "training_data", ")", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"Building batch sampler for training set with batch size %s.\"", ",", "self", ".", "cfg", ".", "training", ".", "batch_size", "# type: ignore", "\n", ")", "\n", "\n", "training_sampler", "=", "self", ".", "build_batch_sampler", "(", "\n", "training_datasets", ",", "\n", "self", ".", "cfg", ".", "training", ".", "batch_size", ",", "# type: ignore", "\n", "\"random\"", ",", "\n", ")", "\n", "data_loader", "=", "self", ".", "build_loader", "(", "\n", "training_data", ",", "\n", "batch_sampler", "=", "training_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "\n", "# Convenient shorthand", "\n", "validation_func", "=", "functools", ".", "partial", "(", "\n", "self", ".", "validation_loop", ",", "\n", "validation_datasets", ",", "\n", "loss_fns", ",", "\n", "experiment_directory", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "\n", "total_iter", "=", "self", ".", "cfg", ".", "training", ".", "num_iterations", "# type: ignore", "\n", "fail_counter", "=", "0", "\n", "for", "data", ",", "iter_idx", "in", "zip", "(", "data_loader", ",", "range", "(", "start_iter", ",", "total_iter", ")", ")", ":", "\n", "            ", "if", "iter_idx", "==", "0", ":", "\n", "                ", "self", ".", "log_first_training_example_and_model", "(", "data", ")", "\n", "\n", "", "if", "start_with_validation", "and", "iter_idx", "==", "start_iter", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "f\"Starting with validation at iteration: {iter_idx}.\"", ")", "\n", "validation_func", "(", "iter_idx", ")", "\n", "", "try", ":", "\n", "                ", "iteration_output", "=", "self", ".", "_do_iteration", "(", "data", ",", "loss_fns", ",", "regularizer_fns", "=", "regularizer_fns", ")", "\n", "output", "=", "iteration_output", ".", "output_image", "\n", "loss_dict", "=", "iteration_output", ".", "data_dict", "\n", "", "except", "(", "ProcessKilledException", ",", "TrainingException", ")", "as", "e", ":", "\n", "# If the process is killed, the DoIterationOutput", "\n", "# if saved at state iter_idx, which is the current state,", "\n", "# so the computation can restart from the last iteration.", "\n", "                ", "self", ".", "logger", ".", "exception", "(", "f\"Exiting with exception: {e}.\"", ")", "\n", "self", ".", "checkpoint_and_write_to_logs", "(", "iter_idx", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "# Maybe string can change", "\n", "                ", "if", "\"out of memory\"", "in", "str", "(", "e", ")", ":", "\n", "                    ", "if", "fail_counter", "==", "3", ":", "\n", "                        ", "self", ".", "checkpoint_and_write_to_logs", "(", "iter_idx", ")", "\n", "raise", "TrainingException", "(", "f\"OOM, had three exceptions in a row tries: {e}.\"", ")", "\n", "", "fail_counter", "+=", "1", "\n", "self", ".", "logger", ".", "info", "(", "f\"OOM Error: {e}. Skipping batch. Retry {fail_counter}/3.\"", ")", "\n", "self", ".", "__optimizer", ".", "zero_grad", "(", ")", "# type: ignore", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "continue", "\n", "\n", "", "self", ".", "checkpoint_and_write_to_logs", "(", "iter_idx", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Cannot recover from exception {e}. Exiting.\"", ")", "\n", "raise", "RuntimeError", "(", "e", ")", "\n", "\n", "", "if", "fail_counter", ">", "0", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\"Recovered from OOM, skipped batch.\"", ")", "\n", "", "fail_counter", "=", "0", "\n", "# Gradient accumulation", "\n", "if", "(", "iter_idx", "+", "1", ")", "%", "self", ".", "cfg", ".", "training", ".", "gradient_steps", "==", "0", ":", "# type: ignore", "\n", "                ", "if", "self", ".", "cfg", ".", "training", ".", "gradient_steps", ">", "1", ":", "# type: ignore", "\n", "                    ", "for", "parameter", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                        ", "if", "parameter", ".", "grad", "is", "not", "None", ":", "\n", "# In-place division", "\n", "                            ", "parameter", ".", "grad", ".", "div_", "(", "self", ".", "cfg", ".", "training", ".", "gradient_steps", ")", "# type: ignore", "\n", "", "", "", "if", "self", ".", "cfg", ".", "training", ".", "gradient_clipping", ">", "0.0", ":", "# type: ignore", "\n", "                    ", "self", ".", "_scaler", ".", "unscale_", "(", "self", ".", "__optimizer", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "cfg", ".", "training", ".", "gradient_clipping", "# type: ignore", "\n", ")", "\n", "\n", "# Gradient norm", "\n", "", "if", "self", ".", "cfg", ".", "training", ".", "gradient_debug", ":", "# type: ignore", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "\"Gradient debug set. This will affect training performance. Only use for debugging.\"", "\n", "\"This message will only be displayed once.\"", "\n", ")", "\n", "parameters", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "self", ".", "model", ".", "parameters", "(", ")", ")", ")", "\n", "gradient_norm", "=", "sum", "(", "[", "parameter", ".", "grad", ".", "data", "**", "2", "for", "parameter", "in", "parameters", "]", ")", ".", "sqrt", "(", ")", "# type: ignore", "\n", "storage", ".", "add_scalar", "(", "\"train/gradient_norm\"", ",", "gradient_norm", ")", "\n", "\n", "# Same as self.__optimizer.step() for mixed precision.", "\n", "", "self", ".", "_scaler", ".", "step", "(", "self", ".", "__optimizer", ")", "\n", "# Updates the scale for next iteration.", "\n", "self", ".", "_scaler", ".", "update", "(", ")", "\n", "\n", "# TODO: Optimizer is only set in case of training, mypy inference does not seem to be correct.", "\n", "# Perhaps this has to be written differently, though. Related to #83", "\n", "", "self", ".", "__lr_scheduler", ".", "step", "(", ")", "# type: ignore # noqa", "\n", "storage", ".", "add_scalar", "(", "\"lr\"", ",", "self", ".", "__optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "smoothing_hint", "=", "False", ")", "# type: ignore", "\n", "\n", "self", ".", "__optimizer", ".", "zero_grad", "(", ")", "# type: ignore", "\n", "\n", "# Reduce the loss over all devices", "\n", "loss_dict_reduced", "=", "communication", ".", "reduce_tensor_dict", "(", "loss_dict", ")", "\n", "loss_reduced", "=", "sum", "(", "loss_dict_reduced", ".", "values", "(", ")", ")", "\n", "\n", "metrics_dict", "=", "evaluate_dict", "(", "\n", "metric_fns", ",", "\n", "T", ".", "modulus_if_complex", "(", "output", ".", "detach", "(", ")", ")", ",", "\n", "data", "[", "\"target\"", "]", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "metrics_dict_reduced", "=", "communication", ".", "reduce_tensor_dict", "(", "metrics_dict", ")", "if", "metrics_dict", "else", "{", "}", "\n", "storage", ".", "add_scalars", "(", "loss", "=", "loss_reduced", ",", "**", "loss_dict_reduced", ",", "**", "metrics_dict_reduced", ")", "\n", "# Maybe not needed.", "\n", "del", "data", "\n", "\n", "self", ".", "checkpoint_model_at_interval", "(", "iter_idx", ",", "total_iter", ")", "\n", "self", ".", "write_to_logs_at_interval", "(", "iter_idx", ",", "total_iter", ")", "\n", "self", ".", "validate_model_at_interval", "(", "validation_func", ",", "iter_idx", ",", "total_iter", ")", "\n", "\n", "storage", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.validate_model_at_interval": [[393, 397], ["func"], "methods", ["None"], ["", "", "def", "validate_model_at_interval", "(", "self", ",", "func", ",", "iter_idx", ",", "total_iter", ")", ":", "\n", "        ", "if", "iter_idx", ">=", "5", ":", "# No validation or anything needed", "\n", "            ", "if", "iter_idx", "%", "self", ".", "cfg", ".", "training", ".", "validation_steps", "==", "0", "or", "(", "iter_idx", "+", "1", ")", "==", "total_iter", ":", "\n", "                ", "func", "(", "iter_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.checkpoint_model_at_interval": [[398, 403], ["engine.Engine.logger.info", "engine.Engine.checkpointer.save"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save"], ["", "", "", "def", "checkpoint_model_at_interval", "(", "self", ",", "iter_idx", ",", "total_iter", ")", ":", "\n", "        ", "if", "iter_idx", ">=", "5", ":", "\n", "            ", "if", "iter_idx", "%", "self", ".", "cfg", ".", "training", ".", "checkpointer", ".", "checkpoint_steps", "==", "0", "or", "(", "iter_idx", "+", "1", ")", "==", "total_iter", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "f\"Checkpointing at iteration {iter_idx}.\"", ")", "\n", "self", ".", "checkpointer", ".", "save", "(", "iter_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.write_to_logs_at_interval": [[404, 413], ["engine.Engine.write_to_logs"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.write_to_logs"], ["", "", "", "def", "write_to_logs_at_interval", "(", "self", ",", "iter_idx", ",", "total_iter", ")", ":", "\n", "        ", "if", "iter_idx", ">=", "5", ":", "\n", "# Log every 20 iterations, or at a validation step or at the end of training.", "\n", "            ", "if", "(", "\n", "iter_idx", "%", "20", "==", "0", "\n", "or", "iter_idx", "%", "self", ".", "cfg", ".", "training", ".", "validation_steps", "==", "0", "\n", "or", "(", "iter_idx", "+", "1", ")", "==", "total_iter", "\n", ")", ":", "\n", "                ", "self", ".", "write_to_logs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.checkpoint_and_write_to_logs": [[414, 418], ["engine.Engine.write_to_logs", "engine.Engine.checkpointer.save"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.write_to_logs", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save"], ["", "", "", "def", "checkpoint_and_write_to_logs", "(", "self", ",", "iter_idx", ")", ":", "\n", "        ", "if", "iter_idx", ">=", "5", ":", "\n", "            ", "self", ".", "checkpointer", ".", "save", "(", "iter_idx", ")", "# Save checkpoint at kill. # noqa", "\n", "", "self", ".", "write_to_logs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.validation_loop": [[419, 490], ["direct.utils.events.get_event_storage", "engine.Engine.model.train", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.build_batch_sampler", "engine.Engine.build_loader", "engine.Engine.evaluate", "direct.utils.reduce_list_of_dicts", "sum", "direct.utils.events.get_event_storage.add_scalars", "engine.Engine.process_slices_for_visualization", "direct.utils.events.get_event_storage.add_image", "engine.Engine.logger.info", "json_output_fn.parent.mkdir", "direct.utils.communication.is_main_process", "engine.Engine.logger.info", "list", "curr_loss_dict.values", "torchvision.utils.make_grid", "direct.utils.events.get_event_storage.add_image", "str", "str", "direct.utils.io.write_json", "str", "curr_metrics_per_case.values", "direct.utils.normalize_image", "direct.data.bbox.crop_to_largest", "direct.utils.prefix_dict_keys", "direct.utils.prefix_dict_keys"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.get_event_storage", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.train", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_batch_sampler", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_loader", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.evaluate", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalars", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.process_slices_for_visualization", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_image", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.is_main_process", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_image", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.write_json", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.normalize_image", "home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_largest", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.prefix_dict_keys", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.prefix_dict_keys"], ["", "def", "validation_loop", "(", "\n", "self", ",", "\n", "validation_datasets", ",", "\n", "loss_fns", ",", "\n", "experiment_directory", ",", "\n", "iter_idx", ",", "\n", "num_workers", ":", "int", "=", "6", ",", "\n", ")", ":", "\n", "        ", "if", "not", "validation_datasets", ":", "\n", "            ", "return", "\n", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "\n", "for", "curr_validation_dataset", "in", "validation_datasets", ":", "\n", "            ", "curr_dataset_name", "=", "curr_validation_dataset", ".", "text_description", "\n", "self", ".", "logger", ".", "info", "(", "\"Evaluating: %s...\"", ",", "curr_dataset_name", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Building dataloader for dataset: %s.\"", ",", "curr_dataset_name", ")", "\n", "curr_batch_sampler", "=", "self", ".", "build_batch_sampler", "(", "\n", "curr_validation_dataset", ",", "\n", "batch_size", "=", "self", ".", "cfg", ".", "validation", ".", "batch_size", ",", "# type: ignore", "\n", "sampler_type", "=", "\"sequential\"", ",", "\n", "limit_number_of_volumes", "=", "None", ",", "\n", ")", "\n", "curr_data_loader", "=", "self", ".", "build_loader", "(", "\n", "curr_validation_dataset", ",", "\n", "batch_sampler", "=", "curr_batch_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "\n", "(", "curr_loss_dict", ",", "curr_metrics_per_case", ",", "visualize_slices", ",", "visualize_target", ",", ")", "=", "self", ".", "evaluate", "(", "\n", "curr_data_loader", ",", "\n", "loss_fns", ",", "\n", ")", "\n", "\n", "if", "experiment_directory", ":", "\n", "                ", "json_output_fn", "=", "experiment_directory", "/", "f\"metrics_val_{curr_dataset_name}_{iter_idx}.json\"", "\n", "json_output_fn", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "# A / in the filename can create a folder", "\n", "if", "communication", ".", "is_main_process", "(", ")", ":", "\n", "                    ", "write_json", "(", "\n", "json_output_fn", ",", "\n", "curr_metrics_per_case", ",", "\n", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Wrote per image logs to: %s.\"", ",", "str", "(", "json_output_fn", ")", ")", "\n", "\n", "# Metric dict still needs to be reduced as it gives values *per* data", "\n", "", "curr_metric_dict", "=", "reduce_list_of_dicts", "(", "list", "(", "curr_metrics_per_case", ".", "values", "(", ")", ")", ",", "mode", "=", "\"average\"", ")", "\n", "\n", "key_prefix", "=", "\"val/\"", "if", "not", "curr_dataset_name", "else", "f\"val/{curr_dataset_name}/\"", "\n", "loss_reduced", "=", "sum", "(", "curr_loss_dict", ".", "values", "(", ")", ")", "\n", "storage", ".", "add_scalars", "(", "\n", "**", "{", "key_prefix", "+", "\"loss\"", ":", "loss_reduced", "}", ",", "\n", "**", "{", "\n", "**", "prefix_dict_keys", "(", "curr_metric_dict", ",", "key_prefix", ")", ",", "\n", "**", "prefix_dict_keys", "(", "curr_loss_dict", ",", "key_prefix", ")", ",", "\n", "}", ",", "\n", "smoothing_hint", "=", "False", ",", "\n", ")", "\n", "visualize_slices", "=", "self", ".", "process_slices_for_visualization", "(", "visualize_slices", ",", "visualize_target", ")", "\n", "storage", ".", "add_image", "(", "f\"{key_prefix}prediction\"", ",", "visualize_slices", ")", "\n", "\n", "if", "iter_idx", "//", "self", ".", "cfg", ".", "training", ".", "validation_steps", "-", "1", "==", "0", ":", "# type: ignore", "\n", "                ", "visualize_target", "=", "[", "normalize_image", "(", "image", ")", "for", "image", "in", "visualize_target", "]", "\n", "visualize_target", "=", "make_grid", "(", "\n", "crop_to_largest", "(", "visualize_target", ",", "pad_value", "=", "0", ")", ",", "\n", "nrow", "=", "self", ".", "cfg", ".", "logging", ".", "tensorboard", ".", "num_images", ",", "# type: ignore", "\n", "scale_each", "=", "True", ",", "\n", ")", "\n", "storage", ".", "add_image", "(", "f\"{key_prefix}target\"", ",", "visualize_target", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Done evaluation of %s at iteration %s.\"", ",", "str", "(", "curr_dataset_name", ")", ",", "str", "(", "iter_idx", ")", ")", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.process_slices_for_visualization": [[491, 506], ["torchvision.utils.make_grid", "direct.utils.normalize_image", "direct.data.bbox.crop_to_largest", "zip", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.normalize_image", "home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_largest"], ["", "def", "process_slices_for_visualization", "(", "self", ",", "visualize_slices", ",", "visualize_target", ")", ":", "\n", "# Log slices.", "\n", "# Compute the difference as well, and normalize for visualization", "\n", "        ", "difference_slices", "=", "[", "a", "-", "b", "for", "a", ",", "b", "in", "zip", "(", "visualize_slices", ",", "visualize_target", ")", "]", "\n", "# Normalize slices", "\n", "difference_slices", "=", "[", "(", "d", "/", "np", ".", "abs", "(", "d", ")", ")", "*", "0.5", "+", "0.5", "for", "d", "in", "difference_slices", "]", "\n", "visualize_slices", "=", "[", "normalize_image", "(", "image", ")", "for", "image", "in", "visualize_slices", "]", "\n", "\n", "# Visualize slices, and crop to the largest volume", "\n", "visualize_slices", "=", "make_grid", "(", "\n", "crop_to_largest", "(", "visualize_slices", "+", "difference_slices", ",", "pad_value", "=", "0", ")", ",", "\n", "nrow", "=", "self", ".", "cfg", ".", "logging", ".", "tensorboard", ".", "num_images", ",", "\n", "scale_each", "=", "True", ",", "\n", ")", "\n", "return", "visualize_slices", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_training_mode": [[507, 511], ["engine.Engine.model.train", "engine.Engine.models[].train"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.train", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.train"], ["", "def", "models_training_mode", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "curr_model", "in", "self", ".", "models", ":", "\n", "            ", "self", ".", "models", "[", "curr_model", "]", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_validation_mode": [[512, 516], ["engine.Engine.model.eval", "engine.Engine.models[].eval"], "methods", ["None"], ["", "", "def", "models_validation_mode", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "for", "curr_model", "in", "self", ".", "models", ":", "\n", "            ", "self", ".", "models", "[", "curr_model", "]", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_to_device": [[517, 521], ["engine.Engine.model.to", "engine.Engine.models[].to"], "methods", ["None"], ["", "", "def", "models_to_device", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "curr_model_name", "in", "self", ".", "models", ":", "\n", "            ", "self", ".", "models", "[", "curr_model_name", "]", "=", "self", ".", "models", "[", "curr_model_name", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.train": [[522, 665], ["engine.Engine.logger.info", "engine.Engine.models_to_device", "engine.Engine.__optimizer.zero_grad", "direct.utils.git_hash", "direct.checkpointer.Checkpointer", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.checkpointer.load", "engine.Engine.logger.warning", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.logger.info", "direct.utils.communication.get_world_size", "torch.nn.parallel.DistributedDataParallel", "direct.utils.communication.is_main_process", "direct.utils.events.EventStorage", "engine.Engine.training_loop", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.logger.info", "engine.Engine.checkpointer.load_models_from_file", "engine.Engine.logger.info", "engine.Engine.logger.warning", "direct.utils.git_hash", "engine.Engine.logger.warning", "engine.Engine.logger.warning", "torch.nn.DataParallel", "direct.utils.events.JSONWriter", "direct.utils.events.CommonMetricPrinter", "direct.utils.events.TensorboardWriter", "engine.Engine.logger.warning", "direct.utils.communication.get_world_size", "torch.cuda.device_count", "torch.cuda.device_count", "direct.utils.communication.get_world_size", "direct.utils.communication.is_main_process", "direct.utils.communication.get_local_rank", "direct.utils.git_hash"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_to_device", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.git_hash", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.is_main_process", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.training_loop", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load_models_from_file", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.git_hash", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.is_main_process", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_local_rank", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.git_hash"], ["", "", "def", "train", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "lr_scheduler", ":", "torch", ".", "optim", ".", "lr_scheduler", ".", "_LRScheduler", ",", "# noqa", "\n", "training_datasets", ":", "List", "[", "Dataset", "]", ",", "\n", "experiment_directory", ":", "pathlib", ".", "Path", ",", "\n", "validation_datasets", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "resume", ":", "bool", "=", "False", ",", "\n", "start_with_validation", ":", "bool", "=", "False", ",", "\n", "initialization", ":", "Optional", "[", "PathOrString", "]", "=", "None", ",", "\n", "num_workers", ":", "int", "=", "6", ",", "\n", ")", "->", "None", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Starting training.\"", ")", "\n", "# Can consider not to make this a member of self, but that requires that optimizer is passed to", "\n", "# training_loop()", "\n", "self", ".", "__optimizer", "=", "optimizer", "\n", "self", ".", "__lr_scheduler", "=", "lr_scheduler", "\n", "\n", "self", ".", "models_to_device", "(", ")", "\n", "\n", "# Optimizer", "\n", "self", ".", "__optimizer", ".", "zero_grad", "(", ")", "# type: ignore", "\n", "\n", "# Mixed precision setup. This requires the model to be on the gpu.", "\n", "git_hash", "=", "direct", ".", "utils", ".", "git_hash", "(", ")", "\n", "checkpointing_metadata", "=", "{", "\n", "\"__author__\"", ":", "git_hash", "if", "git_hash", "else", "\"N/A\"", ",", "\n", "\"__version__\"", ":", "direct", ".", "__version__", ",", "\n", "\"__mixed_precision__\"", ":", "self", ".", "mixed_precision", ",", "\n", "}", "\n", "if", "self", ".", "mixed_precision", ":", "\n", "# TODO(jt): Check if on GPU", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Using mixed precision training.\"", ")", "\n", "\n", "", "self", ".", "checkpointer", "=", "Checkpointer", "(", "\n", "save_directory", "=", "experiment_directory", ",", "\n", "save_to_disk", "=", "False", "if", "not", "communication", ".", "is_main_process", "(", ")", "else", "True", ",", "\n", "model", "=", "self", ".", "model", ",", "# type: ignore", "\n", "optimizer", "=", "optimizer", ",", "# type: ignore", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "# type: ignore", "\n", "scaler", "=", "self", ".", "_scaler", ",", "# type: ignore", "\n", "**", "checkpointing_metadata", ",", "# type: ignore", "\n", "**", "self", ".", "models", ",", "# type: ignore", "\n", ")", "\n", "\n", "# Load checkpoint", "\n", "start_iter", "=", "0", "\n", "checkpoint", "=", "{", "}", "\n", "\n", "if", "resume", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Attempting to resume...\"", ")", "\n", "# This changes the model inplace", "\n", "checkpoint", "=", "self", ".", "checkpointer", ".", "load", "(", "iteration", "=", "\"latest\"", ")", "\n", "if", "not", "checkpoint", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\"No checkpoint found. Starting from scratch.\"", ")", "\n", "", "else", ":", "\n", "                ", "start_iter", "=", "checkpoint", "[", "\"iteration\"", "]", "+", "1", "\n", "self", ".", "logger", ".", "info", "(", "f\"Starting from iteration: {start_iter}.\"", ")", "\n", "\n", "", "", "if", "start_iter", ">", "0", "and", "initialization", ":", "\n", "            ", "self", ".", "logger", ".", "warning", "(", "\n", "f\"Initialization checkpoint set to {initialization},\"", "\n", "f\" but model will resume training from previous checkpoint. Initialization ignored.\"", "\n", ")", "\n", "", "elif", "initialization", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Initializing from {initialization}...\"", ")", "\n", "self", ".", "checkpointer", ".", "load_models_from_file", "(", "initialization", ")", "\n", "start_with_validation", "=", "True", "\n", "self", ".", "logger", ".", "info", "(", "\"Setting start_with_validation to True.\"", ")", "\n", "\n", "", "if", "\"__version__\"", "in", "checkpoint", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"DIRECT version of checkpoint: {checkpoint['__version__']}.\"", ")", "\n", "if", "checkpoint", "[", "\"__version__\"", "]", "!=", "direct", ".", "__version__", ":", "\n", "                ", "self", ".", "logger", ".", "warning", "(", "\n", "f\"Current DIRECT version {direct.__version__} is different from the one \"", "\n", "f\"this checkpoint is saved with: {checkpoint['__version__']}. This can be fine, \"", "\n", "f\"but beware that this can be a source of confusion.\"", "\n", ")", "\n", "\n", "", "", "if", "\"__author__\"", "in", "checkpoint", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Git hash of checkpoint: {checkpoint['__author__']}.\"", ")", "\n", "if", "checkpoint", "[", "\"__author__\"", "]", "!=", "direct", ".", "utils", ".", "git_hash", "(", ")", ":", "\n", "                ", "self", ".", "logger", ".", "warning", "(", "\n", "f\"Current git hash {direct.utils.git_hash()} is different from the one \"", "\n", "f\"this checkpoint is saved with: {checkpoint['__author__']}. This can be fine, \"", "\n", "f\"but beware that this can be a source of confusion.\"", "\n", ")", "\n", "\n", "", "", "if", "\"__datetime__\"", "in", "checkpoint", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Checkpoint created at: %s.\"", ",", "checkpoint", "[", "\"__datetime__\"", "]", ")", "\n", "\n", "", "if", "\"__mixed_precision__\"", "in", "checkpoint", ":", "\n", "            ", "if", "(", "not", "self", ".", "mixed_precision", ")", "and", "checkpoint", "[", "\"__mixed_precision__\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "warning", "(", "\n", "\"Mixed precision training is not enabled, yet saved checkpoint requests this. \"", "\n", "\"Will now enable mixed precision.\"", "\n", ")", "\n", "self", ".", "mixed_precision", "=", "True", "\n", "", "elif", "not", "checkpoint", "[", "\"__mixed_precision__\"", "]", "and", "self", ".", "mixed_precision", ":", "\n", "                ", "self", ".", "logger", ".", "warning", "(", "\n", "\"Mixed precision levels of training and loading checkpoint do not match. \"", "\n", "\"Requested mixed precision but checkpoint is saved without. \"", "\n", "\"This will almost surely lead to performance degradation.\"", "\n", ")", "\n", "\n", "", "", "if", "start_with_validation", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Requested to start with validation.\"", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "f\"World size: {communication.get_world_size()}.\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Device count: {torch.cuda.device_count()}.\"", ")", "\n", "if", "communication", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "model", "=", "DistributedDataParallel", "(", "\n", "self", ".", "model", ",", "\n", "device_ids", "=", "[", "communication", ".", "get_local_rank", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ",", "\n", "find_unused_parameters", "=", "False", ",", "\n", ")", "\n", "\n", "# World size > 1 if distributed mode, else allow a DataParallel fallback, can be convenient for debugging.", "\n", "", "elif", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", "and", "communication", ".", "get_world_size", "(", ")", "==", "1", ":", "\n", "            ", "self", ".", "model", "=", "DataParallel", "(", "self", ".", "model", ")", "\n", "\n", "", "self", ".", "__writers", "=", "(", "\n", "[", "\n", "JSONWriter", "(", "experiment_directory", "/", "\"metrics.json\"", ")", ",", "\n", "CommonMetricPrinter", "(", "self", ".", "cfg", ".", "training", ".", "num_iterations", ")", ",", "# type: ignore", "\n", "TensorboardWriter", "(", "experiment_directory", "/", "\"tensorboard\"", ")", ",", "\n", "]", "\n", "if", "communication", ".", "is_main_process", "(", ")", "\n", "else", "[", "]", "\n", ")", "\n", "\n", "with", "EventStorage", "(", "start_iter", ")", ":", "\n", "            ", "self", ".", "training_loop", "(", "\n", "training_datasets", ",", "\n", "start_iter", ",", "\n", "validation_datasets", ",", "\n", "experiment_directory", "=", "experiment_directory", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "start_with_validation", "=", "start_with_validation", ",", "\n", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Training completed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.reconstruct_volumes": [[666, 669], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reconstruct_volumes", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "# noqa", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.evaluate": [[670, 673], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "evaluate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "# noqa", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.log_process": [[674, 677], ["engine.Engine.logger.info"], "methods", ["None"], ["", "def", "log_process", "(", "self", ",", "idx", ",", "total", ")", ":", "\n", "        ", "if", "idx", "%", "(", "total", "//", "10", ")", "==", "0", "or", "total", "==", "(", "idx", "+", "1", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"Progress: {(idx + 1) / total * 100:.2f}%.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.log_first_training_example_and_model": [[678, 709], ["direct.utils.events.get_event_storage", "engine.Engine.logger.info", "direct.utils.events.get_event_storage.add_image", "direct.utils.events.get_event_storage.add_image", "engine.Engine.write_to_logs", "first_sampling_mask[].unsqueeze", "direct.utils.normalize_image", "direct.utils.events.get_event_storage.add_image", "first_target.unsqueeze", "direct.utils.normalize_image", "direct.data.transforms.modulus().unsqueeze", "direct.data.transforms.modulus"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.get_event_storage", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_image", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_image", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.write_to_logs", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.normalize_image", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_image", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.normalize_image", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus"], ["", "", "def", "log_first_training_example_and_model", "(", "self", ",", "data", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"First case: slice_no: {data['slice_no'][0]}, filename: {data['filename'][0]}.\"", ")", "\n", "\n", "# TODO(jt): Cleaner, loop over types of images", "\n", "first_sampling_mask", "=", "data", "[", "\"sampling_mask\"", "]", "[", "0", "]", "[", "0", "]", "\n", "first_target", "=", "data", "[", "\"target\"", "]", "[", "0", "]", "\n", "\n", "if", "self", ".", "ndim", "==", "3", ":", "\n", "            ", "first_sampling_mask", "=", "first_sampling_mask", "[", "0", "]", "\n", "slice_dim", "=", "-", "4", "\n", "num_slices", "=", "first_target", ".", "shape", "[", "slice_dim", "]", "\n", "first_target", "=", "first_target", "[", "num_slices", "//", "2", "]", "\n", "", "elif", "self", ".", "ndim", ">", "3", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "storage", ".", "add_image", "(", "\"train/mask\"", ",", "first_sampling_mask", "[", "...", ",", "0", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "storage", ".", "add_image", "(", "\n", "\"train/target\"", ",", "\n", "normalize_image", "(", "first_target", ".", "unsqueeze", "(", "0", ")", ")", ",", "\n", ")", "\n", "\n", "if", "\"initial_image\"", "in", "data", ":", "\n", "            ", "storage", ".", "add_image", "(", "\n", "\"train/initial_image\"", ",", "\n", "normalize_image", "(", "T", ".", "modulus", "(", "data", "[", "\"initial_image\"", "]", "[", "0", "]", ")", ".", "unsqueeze", "(", "0", ")", ")", ",", "\n", ")", "\n", "\n", "# TODO: Add graph", "\n", "\n", "", "self", ".", "write_to_logs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.write_to_logs": [[710, 714], ["writer.write"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "def", "write_to_logs", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "__writers", "is", "not", "None", ":", "\n", "            ", "for", "writer", "in", "self", ".", "__writers", ":", "\n", "                ", "writer", ".", "write", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.__bind_sigint_signal": [[715, 725], ["signal.signal", "engine.Engine.logger.info", "direct.exceptions.ProcessKilledException", "signal.Signals", "signal.Signals"], "methods", ["None"], ["", "", "", "def", "__bind_sigint_signal", "(", "self", ")", ":", "\n", "        ", "\"\"\"Bind SIGINT signal to handle preemption or other kill of the process.\"\"\"", "\n", "\n", "# pylint: disable = E1101", "\n", "def", "raise_process_killed_error", "(", "signal_id", ",", "_", ")", ":", "\n", "            ", "\"\"\"Raise the ProcessKilledError.\"\"\"", "\n", "self", ".", "logger", ".", "info", "(", "f\"Received {signal.Signals(signal_id).name} Shutting down...\"", ")", "\n", "raise", "ProcessKilledException", "(", "signal_id", ",", "signal", ".", "Signals", "(", "signal_id", ")", ".", "name", ")", "\n", "\n", "", "signal", ".", "signal", "(", "signalnum", "=", "signal", ".", "SIGINT", ",", "handler", "=", "raise_process_killed_error", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.direct.predict._get_transforms": [[19, 24], ["direct.common.subsample.build_masking_function", "direct.inference.build_inference_transforms"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.build_masking_function", "home.repos.pwc.inspect_result.directgroup_direct.direct.inference.build_inference_transforms"], ["def", "_get_transforms", "(", "env", ")", ":", "\n", "    ", "dataset_cfg", "=", "env", ".", "cfg", ".", "inference", ".", "dataset", "\n", "mask_func", "=", "build_masking_function", "(", "**", "dataset_cfg", ".", "transforms", ".", "masking", ")", "\n", "transforms", "=", "build_inference_transforms", "(", "env", ",", "mask_func", ",", "dataset_cfg", ")", "\n", "return", "dataset_cfg", ",", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.predict.predict_from_argparse": [[32, 63], ["torch.set_num_threads", "direct.utils.set_all_seeds", "direct.launch.launch"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.set_all_seeds", "home.repos.pwc.inspect_result.directgroup_direct.direct.launch.launch"], ["def", "predict_from_argparse", "(", "args", ":", "argparse", ".", "Namespace", ")", ":", "\n", "# This sets MKL threads to 1.", "\n", "# DataLoader can otherwise bring a lot of difficulties when computing CPU FFTs in the transforms.", "\n", "    ", "torch", ".", "set_num_threads", "(", "1", ")", "\n", "os", ".", "environ", "[", "\"OMP_NUM_THREADS\"", "]", "=", "\"1\"", "\n", "\n", "set_all_seeds", "(", "args", ".", "seed", ")", "\n", "experiment_directory", "=", "(", "\n", "args", ".", "experiment_directory", "if", "args", ".", "experiment_directory", "is", "not", "None", "else", "args", ".", "output_directory", "\n", ")", "\n", "\n", "launch", "(", "\n", "setup_inference_save_to_h5", ",", "\n", "args", ".", "num_machines", ",", "\n", "args", ".", "num_gpus", ",", "\n", "args", ".", "machine_rank", ",", "\n", "args", ".", "dist_url", ",", "\n", "args", ".", "name", ",", "\n", "args", ".", "data_root", ",", "\n", "experiment_directory", ",", "\n", "args", ".", "output_directory", ",", "\n", "args", ".", "filenames_filter", ",", "\n", "args", ".", "checkpoint", ",", "\n", "args", ".", "device", ",", "\n", "args", ".", "num_workers", ",", "\n", "args", ".", "machine_rank", ",", "\n", "args", ".", "cfg_file", ",", "\n", "None", ",", "\n", "args", ".", "mixed_precision", ",", "\n", "args", ".", "debug", ",", "\n", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.launch._find_free_port": [[31, 42], ["socket.socket", "socket.socket.bind", "socket.socket.close", "socket.socket.getsockname"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close"], ["def", "_find_free_port", "(", ")", ":", "\n", "    ", "\"\"\"Finds ans returns a free port.\"\"\"", "\n", "import", "socket", "\n", "\n", "sock", "=", "socket", ".", "socket", "(", "socket", ".", "AF_INET", ",", "socket", ".", "SOCK_STREAM", ")", "\n", "# Binding to port 0 will cause the OS to find an available port for us", "\n", "sock", ".", "bind", "(", "(", "\"\"", ",", "0", ")", ")", "\n", "port", "=", "sock", ".", "getsockname", "(", ")", "[", "1", "]", "\n", "sock", ".", "close", "(", ")", "\n", "# NOTE: there is still a chance the port could be taken by other processes.", "\n", "return", "port", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.launch.launch_distributed": [[44, 105], ["torch.spawn", "main_func", "launch._find_free_port", "dist_url.startswith", "logger.warning", "ValueError"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.launch._find_free_port"], ["", "def", "launch_distributed", "(", "\n", "main_func", ":", "Callable", ",", "\n", "num_gpus_per_machine", ":", "int", ",", "\n", "num_machines", ":", "int", "=", "1", ",", "\n", "machine_rank", ":", "int", "=", "0", ",", "\n", "dist_url", ":", "str", "=", "\"auto\"", ",", "\n", "args", ":", "Tuple", "=", "(", ")", ",", "\n", "timeout", ":", "timedelta", "=", "DEFAULT_TIMEOUT", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Launch multi-gpu or distributed training.\n\n    This function must be called on all machines involved in the training and it will spawn\n    child processes (defined by `num_gpus_per_machine`) on each machine.\n\n    Parameters\n    ----------\n    main_func: Callable\n        A function that will be called by `main_func(*args)`.\n    num_gpus_per_machine: int\n        The number of GPUs per machine.\n    num_machines : int\n        The number of machines.\n    machine_rank: int\n        The rank of this machine (one per machine).\n    dist_url: str\n        URL to connect to for distributed training, including protocol e.g. \"tcp://127.0.0.1:8686\".\n        Can be set to auto to automatically select a free port on localhost\n    args: Tuple\n        arguments passed to main_func.\n    timeout: timedelta\n        Timeout of the distributed workers.\n    \"\"\"", "\n", "world_size", "=", "num_machines", "*", "num_gpus_per_machine", "\n", "if", "world_size", ">", "1", ":", "\n", "# https://github.com/pytorch/pytorch/pull/14391", "\n", "# TODO prctl in spawned processes", "\n", "\n", "        ", "if", "dist_url", "==", "\"auto\"", ":", "\n", "            ", "if", "num_machines", "!=", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"dist_url=auto not supported in multi-machine jobs.\"", ")", "\n", "", "port", "=", "_find_free_port", "(", ")", "\n", "dist_url", "=", "f\"tcp://127.0.0.1:{port}\"", "\n", "", "if", "num_machines", ">", "1", "and", "dist_url", ".", "startswith", "(", "\"file://\"", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\"file:// is not a reliable init_method in multi-machine jobs. Prefer tcp://\"", ")", "\n", "\n", "", "mp", ".", "spawn", "(", "\n", "_distributed_worker", ",", "\n", "nprocs", "=", "num_gpus_per_machine", ",", "\n", "args", "=", "(", "\n", "main_func", ",", "\n", "world_size", ",", "\n", "num_gpus_per_machine", ",", "\n", "machine_rank", ",", "\n", "dist_url", ",", "\n", "args", ",", "\n", "timeout", ",", "\n", ")", ",", "\n", "daemon", "=", "False", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "main_func", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.launch._distributed_worker": [[107, 175], ["direct.utils.communication.synchronize", "logger.info", "logger.info", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "range", "main_func", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "RuntimeError", "torch.init_process_group", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "list", "torch.new_group", "logger.error", "range"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.synchronize"], ["", "", "def", "_distributed_worker", "(", "\n", "local_rank", ":", "int", ",", "\n", "main_func", ":", "Callable", ",", "\n", "world_size", ":", "int", ",", "\n", "num_gpus_per_machine", ":", "int", ",", "\n", "machine_rank", ":", "int", ",", "\n", "dist_url", ":", "str", ",", "\n", "args", ":", "Tuple", ",", "\n", "timeout", ":", "timedelta", "=", "DEFAULT_TIMEOUT", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Sets up `init_process_group`.\n\n    Parameters\n    ----------\n    local_rank: int\n        Local rank.\n    main_func: Callable\n        A function that will be called by `main_func(*args)`.\n    world_size: int\n        World size equal to `num_machines * num_gpus_per_machine`.\n    machine_rank: int\n        The rank of this machine (one per machine).\n    num_gpus_per_machine: int\n        The number of GPUs per machine.\n    dist_url: str\n        URL to connect to for distributed training, including protocol e.g. \"tcp://127.0.0.1:8686\".\n        Can be set to auto to automatically select a free port on localhost\n    args: Tuple\n        arguments passed to main_func.\n    timeout: timedelta\n        Timeout of the distributed workers.\n    \"\"\"", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"CUDA is not available. Please check your installation.\"", ")", "\n", "\n", "", "global_rank", "=", "machine_rank", "*", "num_gpus_per_machine", "+", "local_rank", "\n", "try", ":", "\n", "        ", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "\"NCCL\"", ",", "\n", "init_method", "=", "dist_url", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "global_rank", ",", "\n", "timeout", "=", "timeout", ",", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "f\"Process group URL: {dist_url}\"", ")", "\n", "raise", "e", "\n", "# synchronize is needed here to prevent a possible timeout after calling init_process_group", "\n", "# See: https://github.com/facebookresearch/maskrcnn-benchmark/issues/172", "\n", "", "communication", ".", "synchronize", "(", ")", "\n", "logger", ".", "info", "(", "f\"Global rank {global_rank}.\"", ")", "\n", "logger", ".", "info", "(", "\"Synchronized GPUs.\"", ")", "\n", "\n", "if", "num_gpus_per_machine", ">", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "raise", "RuntimeError", "\n", "", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "\n", "# Setup the local process group (which contains ranks within the same machine)", "\n", "if", "communication", ".", "_LOCAL_PROCESS_GROUP", "is", "not", "None", ":", "\n", "        ", "raise", "RuntimeError", "\n", "", "num_machines", "=", "world_size", "//", "num_gpus_per_machine", "\n", "for", "idx", "in", "range", "(", "num_machines", ")", ":", "\n", "        ", "ranks_on_i", "=", "list", "(", "range", "(", "idx", "*", "num_gpus_per_machine", ",", "(", "idx", "+", "1", ")", "*", "num_gpus_per_machine", ")", ")", "\n", "pg", "=", "dist", ".", "new_group", "(", "ranks_on_i", ")", "\n", "if", "idx", "==", "machine_rank", ":", "\n", "            ", "communication", ".", "_LOCAL_PROCESS_GROUP", "=", "pg", "\n", "\n", "", "", "main_func", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.launch.launch": [[177, 225], ["func", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "logger.warning", "print", "sys.exit", "launch.launch_distributed", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.launch.launch_distributed"], ["", "def", "launch", "(", "\n", "func", ":", "Callable", ",", "\n", "num_machines", ":", "int", ",", "\n", "num_gpus", ":", "int", ",", "\n", "machine_rank", ":", "int", ",", "\n", "dist_url", ":", "str", ",", "\n", "*", "args", ":", "Tuple", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Launch the training, in case there is only one GPU available the function can be called directly.\n\n    Parameters\n    ----------\n    func: Callable\n        Function to launch.\n    num_machines : int\n        The number of machines.\n    num_gpus: int\n        The number of GPUs.\n    machine_rank: int\n        The machine rank.\n    dist_url: str\n        URL to connect to for distributed training, including protocol.\n    args: Tuple\n        Arguments to pass to func.\n    \"\"\"", "\n", "# There is no need for the launch script within one node and at most one GPU.", "\n", "if", "num_machines", "==", "1", "and", "num_gpus", "<=", "1", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"Device count is {torch.cuda.device_count()}, \"", "\n", "f\"but num_machines is set to {num_machines} and num_gpus is {num_gpus}.\"", "\n", ")", "\n", "", "func", "(", "*", "args", ")", "\n", "", "elif", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", "and", "num_gpus", "<=", "1", ":", "\n", "        ", "print", "(", "\n", "f\"Device count is {torch.cuda.device_count()}, yet number of GPUs is {num_gpus}. \"", "\n", "f\"Unexpected behavior will occur. Consider exposing less GPUs (e.g. through docker). Exiting.\"", "\n", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "else", ":", "\n", "        ", "launch_distributed", "(", "\n", "func", ",", "\n", "num_gpus", ",", "\n", "num_machines", "=", "num_machines", ",", "\n", "machine_rank", "=", "machine_rank", ",", "\n", "dist_url", "=", "dist_url", ",", "\n", "args", "=", "args", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.inference.setup_inference_save_to_h5": [[23, 127], ["direct.environment.setup_inference_environment", "get_inference_settings", "logger.info", "list", "inference.inference_on_environment", "direct.utils.writers.write_output_to_h5", "direct.utils.chunks", "direct.utils.io.read_list"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_inference_environment", "home.repos.pwc.inspect_result.directgroup_direct.direct.inference.inference_on_environment", "home.repos.pwc.inspect_result.directgroup_direct.utils.writers.write_output_to_h5", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.chunks", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_list"], ["def", "setup_inference_save_to_h5", "(", "\n", "get_inference_settings", ":", "Callable", ",", "\n", "run_name", ":", "str", ",", "\n", "data_root", ":", "Union", "[", "PathOrString", ",", "None", "]", ",", "\n", "base_directory", ":", "PathOrString", ",", "\n", "output_directory", ":", "PathOrString", ",", "\n", "filenames_filter", ":", "Union", "[", "List", "[", "PathOrString", "]", ",", "None", "]", ",", "\n", "checkpoint", ":", "FileOrUrl", ",", "\n", "device", ":", "str", ",", "\n", "num_workers", ":", "int", ",", "\n", "machine_rank", ":", "int", ",", "\n", "cfg_file", ":", "Union", "[", "PathOrString", ",", "None", "]", "=", "None", ",", "\n", "process_per_chunk", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "debug", ":", "bool", "=", "False", ",", "\n", "is_validation", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"This function contains most of the logic in DIRECT required to launch a multi-gpu / multi-node inference process.\n\n    It saves predictions as `.h5` files.\n\n    Parameters\n    ----------\n    get_inference_settings: Callable\n        Callable object to create inference dataset and environment.\n    run_name: str\n        Experiment run name. Can be an empty string.\n    data_root: Union[PathOrString, None]\n        Path of the directory of the data if applicable for dataset. Can be None.\n    base_directory: PathOrString\n        Path to directory where where inference logs will be stored. If `run_name` is not an empty string,\n        `base_directory / run_name` will be used.\n    output_directory: PathOrString\n        Path to directory where output data will be saved.\n    filenames_filter: Union[List[PathOrString], None]\n        List of filenames to include in the dataset (if applicable). Can be None.\n    checkpoint: FileOrUrl\n        Checkpoint to a model. This can be a path to a local file or an URL.\n    device: str\n        Device name.\n    num_workers: int\n        Number of workers.\n    machine_rank: int\n        Machine rank.\n    cfg_file: Union[PathOrString, None]\n        Path to configuration file. If None, will search in `base_directory`.\n    process_per_chunk: int\n        Processes per chunk number.\n    mixed_precision: bool\n        If True, mixed precision will be allowed. Default: False.\n    debug: bool\n        If True, debug information will be displayed. Default: False.\n    is_validation: bool\n        If True, will use settings (e.g. `batch_size` & `crop`) of `validation` in config.\n        Otherwise it will use `inference` settings. Default: False.\n\n    Returns\n    -------\n    None\n    \"\"\"", "\n", "env", "=", "setup_inference_environment", "(", "\n", "run_name", ",", "base_directory", ",", "device", ",", "machine_rank", ",", "mixed_precision", ",", "cfg_file", ",", "debug", "=", "debug", "\n", ")", "\n", "\n", "dataset_cfg", ",", "transforms", "=", "get_inference_settings", "(", "env", ")", "\n", "\n", "# Trigger cudnn benchmark when the number of different input masks_dict is small.", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "if", "data_root", ":", "\n", "        ", "if", "filenames_filter", ":", "\n", "            ", "filenames_filter", "=", "[", "data_root", "/", "_", "for", "_", "in", "read_list", "(", "filenames_filter", ")", "]", "\n", "\n", "", "", "if", "not", "process_per_chunk", ":", "\n", "        ", "filenames_filter", "=", "[", "filenames_filter", "]", "\n", "", "else", ":", "\n", "        ", "filenames_filter", "=", "list", "(", "chunks", "(", "filenames_filter", ",", "process_per_chunk", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Predicting dataset and saving in: {output_directory}.\"", ")", "\n", "\n", "if", "is_validation", ":", "\n", "        ", "batch_size", ",", "crop", "=", "env", ".", "cfg", ".", "validation", ".", "batch_size", ",", "env", ".", "cfg", ".", "validation", ".", "crop", "# type: ignore", "\n", "", "else", ":", "\n", "        ", "batch_size", ",", "crop", "=", "env", ".", "cfg", ".", "inference", ".", "batch_size", ",", "env", ".", "cfg", ".", "inference", ".", "crop", "# type: ignore", "\n", "\n", "", "for", "curr_filenames_filter", "in", "filenames_filter", ":", "\n", "        ", "output", "=", "inference_on_environment", "(", "\n", "env", "=", "env", ",", "\n", "data_root", "=", "data_root", ",", "\n", "dataset_cfg", "=", "dataset_cfg", ",", "\n", "transforms", "=", "transforms", ",", "\n", "experiment_path", "=", "base_directory", "/", "run_name", ",", "\n", "checkpoint", "=", "checkpoint", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "filenames_filter", "=", "curr_filenames_filter", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "crop", "=", "crop", ",", "\n", ")", "\n", "\n", "# Perhaps aggregation to the main process would be most optimal here before writing.", "\n", "# The current way this write the volumes for each process.", "\n", "write_output_to_h5", "(", "\n", "output", ",", "\n", "output_directory", ",", "\n", "output_key", "=", "\"reconstruction\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.inference.build_inference_transforms": [[130, 140], ["functools.partial", "functools.partial.", "direct.utils.remove_keys"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.remove_keys"], ["", "", "def", "build_inference_transforms", "(", "env", ",", "mask_func", ":", "Callable", ",", "dataset_cfg", ":", "DictConfig", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"Builds inference transforms.\"\"\"", "\n", "partial_build_mri_transforms", "=", "partial", "(", "\n", "build_mri_transforms", ",", "\n", "forward_operator", "=", "env", ".", "engine", ".", "forward_operator", ",", "\n", "backward_operator", "=", "env", ".", "engine", ".", "backward_operator", ",", "\n", "mask_func", "=", "mask_func", ",", "\n", ")", "\n", "transforms", "=", "partial_build_mri_transforms", "(", "**", "remove_keys", "(", "dataset_cfg", ".", "transforms", ",", "\"masking\"", ")", ")", "\n", "return", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.inference.inference_on_environment": [[142, 209], ["logger.warning", "direct.data.datasets.build_dataset_from_input", "logger.info", "env.engine.predict", "kwargs.update", "len", "logger.info", "sys.exit", "kwargs.update", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets.build_dataset_from_input", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.predict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "inference_on_environment", "(", "\n", "env", ",", "\n", "data_root", ":", "Union", "[", "PathOrString", ",", "None", "]", ",", "\n", "dataset_cfg", ":", "DictConfig", ",", "\n", "transforms", ":", "Callable", ",", "\n", "experiment_path", ":", "PathOrString", ",", "\n", "checkpoint", ":", "FileOrUrl", ",", "\n", "num_workers", ":", "int", "=", "0", ",", "\n", "filenames_filter", ":", "Union", "[", "List", "[", "PathOrString", "]", ",", "None", "]", "=", "None", ",", "\n", "batch_size", ":", "int", "=", "1", ",", "\n", "crop", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "Union", "[", "Dict", ",", "DefaultDict", "]", ":", "\n", "    ", "\"\"\"Performs inference on environment.\n\n    Parameters\n    ----------\n    env: Environment.\n    data_root: Union[PathOrString, None]\n        Path of the directory of the data if applicable for dataset. Can be None.\n    dataset_cfg: DictConfig\n        Configuration containing inference dataset settings.\n    transforms: Callable\n        Dataset transformations object.\n    experiment_path: PathOrString\n        Path to directory where where inference logs will be stored.\n    checkpoint: FileOrUrl\n        Checkpoint to a model. This can be a path to a local file or an URL.\n    num_workers: int\n        Number of workers.\n    filenames_filter: Union[List[PathOrString], None]\n        List of filenames to include in the dataset (if applicable). Can be None. Default: None.\n    batch_size: int\n        Inference batch size. Default: 1.\n    crop: Optional[str]\n        Inference crop type. Can be `header` or None. Default: None.\n\n    Returns\n    -------\n    output: Union[Dict, DefaultDict]\n    \"\"\"", "\n", "\n", "logger", ".", "warning", "(", "\"pass_h5s and pass_dictionaries is not yet supported for inference.\"", ")", "\n", "\n", "kwargs", "=", "{", "}", "\n", "if", "data_root", "is", "not", "None", ":", "\n", "        ", "kwargs", ".", "update", "(", "{", "\"data_root\"", ":", "data_root", "}", ")", "\n", "if", "filenames_filter", ":", "\n", "            ", "kwargs", ".", "update", "(", "{", "\"filenames_filter\"", ":", "filenames_filter", "}", ")", "\n", "\n", "", "", "dataset", "=", "build_dataset_from_input", "(", "transforms", "=", "transforms", ",", "dataset_config", "=", "dataset_cfg", ",", "**", "kwargs", ")", "\n", "\n", "if", "len", "(", "dataset", ")", "<=", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"Inference dataset is empty. Terminating inference...\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Inference data size: {len(dataset)}.\"", ")", "\n", "\n", "# Run prediction", "\n", "output", "=", "env", ".", "engine", ".", "predict", "(", "\n", "dataset", ",", "\n", "experiment_path", ",", "\n", "checkpoint", "=", "checkpoint", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "crop", "=", "crop", ",", "\n", ")", "\n", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.direct.exceptions.DirectException.__init__": [[7, 10], ["BaseException.__init__", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.exceptions.ProcessKilledException.__init__": [[15, 28], ["exceptions.DirectException.__init__", "exceptions.ProcessKilledException.logger.exception"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "signal_id", ":", "int", ",", "signal_name", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        signal_id: str\n        signal_name: str\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", ".", "exception", "(", "\n", "f\"Received signal (signal_id = {signal_id} - signal_name = {signal_name}). \"", "\"Critical. Process will stop.\"", "\n", ")", "\n", "self", ".", "signal_id", "=", "signal_id", "\n", "self", ".", "signal_name", "=", "signal_name", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.exceptions.TrainingException.__init__": [[31, 37], ["exceptions.DirectException.__init__", "exceptions.TrainingException.logger.exception", "exceptions.TrainingException.logger.exception"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "message", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "message", ":", "\n", "            ", "self", ".", "logger", ".", "exception", "(", "\"TrainingException\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "logger", ".", "exception", "(", "f\"TrainingException: {message}\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.direct.train.parse_noise_dict": [[32, 49], ["logger.info", "collections.defaultdict", "numpy.percentile", "numpy.percentile", "numpy.clip", "int"], "function", ["None"], ["def", "parse_noise_dict", "(", "noise_dict", ":", "dict", ",", "percentile", ":", "float", "=", "1.0", ",", "multiplier", ":", "float", "=", "1.0", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Parsing noise dictionary...\"", ")", "\n", "output", ":", "Dict", "=", "defaultdict", "(", "dict", ")", "\n", "for", "filename", "in", "noise_dict", ":", "\n", "        ", "data_per_volume", "=", "noise_dict", "[", "filename", "]", "\n", "for", "slice_no", "in", "data_per_volume", ":", "\n", "            ", "curr_data", "=", "data_per_volume", "[", "slice_no", "]", "\n", "if", "percentile", "!=", "1.0", ":", "\n", "                ", "lower_clip", "=", "np", ".", "percentile", "(", "curr_data", ",", "100", "*", "(", "1", "-", "percentile", ")", ")", "\n", "upper_clip", "=", "np", ".", "percentile", "(", "curr_data", ",", "100", "*", "percentile", ")", "\n", "curr_data", "=", "np", ".", "clip", "(", "curr_data", ",", "lower_clip", ",", "upper_clip", ")", "\n", "\n", "", "output", "[", "filename", "]", "[", "int", "(", "slice_no", ")", "]", "=", "(", "\n", "curr_data", "*", "multiplier", "\n", ")", "**", "2", "# np.asarray(curr_data) * multiplier# (np.clip(curr_data, lower_clip, upper_clip) * multiplier) ** 2", "\n", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.train.get_root_of_file": [[51, 75], ["direct.utils.io.check_is_valid_url", "str", "urllib.parse.urljoin", "str", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url"], ["", "def", "get_root_of_file", "(", "filename", ":", "PathOrString", ")", ":", "\n", "    ", "\"\"\"Get the root directory of the file or URL to file.\n\n    Examples\n    --------\n    >>> get_root_of_file('/mnt/archive/data.txt')\n    >>> /mnt/archive\n    >>> get_root_of_file('https://aiforoncology.nl/people')\n    >>> https://aiforoncology.nl/\n\n    Parameters\n    ----------\n    filename: pathlib.Path or str\n\n    Returns\n    -------\n    pathlib.Path or str\n    \"\"\"", "\n", "if", "check_is_valid_url", "(", "str", "(", "filename", ")", ")", ":", "\n", "        ", "filename", "=", "urllib", ".", "parse", ".", "urljoin", "(", "str", "(", "filename", ")", ",", "\".\"", ")", "\n", "", "else", ":", "\n", "        ", "filename", "=", "pathlib", ".", "Path", "(", "filename", ")", ".", "parents", "[", "0", "]", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.train.build_transforms_from_environment": [[77, 85], ["functools.partial", "functools.partial.", "direct.common.subsample.build_masking_function", "direct.utils.remove_keys"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.build_masking_function", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.remove_keys"], ["", "def", "build_transforms_from_environment", "(", "env", ",", "dataset_config", ":", "DictConfig", ")", "->", "Callable", ":", "\n", "    ", "mri_transforms_func", "=", "functools", ".", "partial", "(", "\n", "build_mri_transforms", ",", "\n", "forward_operator", "=", "env", ".", "engine", ".", "forward_operator", ",", "\n", "backward_operator", "=", "env", ".", "engine", ".", "backward_operator", ",", "\n", "mask_func", "=", "build_masking_function", "(", "**", "dataset_config", ".", "transforms", ".", "masking", ")", ",", "\n", ")", "\n", "return", "mri_transforms_func", "(", "**", "remove_keys", "(", "dataset_config", ".", "transforms", ",", "\"masking\"", ")", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.train.build_training_datasets_from_environment": [[87, 130], ["enumerate", "train.build_transforms_from_environment", "direct.data.datasets.build_dataset_from_input", "logger.debug", "datasets.append", "logger.info", "dataset_args.update", "dataset_args.update", "dataset_args.update", "direct.utils.dataset.get_filenames_for_datasets_from_config", "dataset_args.update", "dataset_args.update", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.train.build_transforms_from_environment", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.build_dataset_from_input", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.dataset.get_filenames_for_datasets_from_config", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "build_training_datasets_from_environment", "(", "\n", "env", ",", "\n", "datasets_config", ":", "List", "[", "DictConfig", "]", ",", "\n", "lists_root", ":", "Optional", "[", "PathOrString", "]", "=", "None", ",", "\n", "data_root", ":", "Optional", "[", "PathOrString", "]", "=", "None", ",", "\n", "initial_images", ":", "Optional", "[", "Union", "[", "List", "[", "pathlib", ".", "Path", "]", ",", "None", "]", "]", "=", "None", ",", "\n", "initial_kspaces", ":", "Optional", "[", "Union", "[", "List", "[", "pathlib", ".", "Path", "]", ",", "None", "]", "]", "=", "None", ",", "\n", "pass_text_description", ":", "bool", "=", "True", ",", "\n", "pass_dictionaries", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "\n", "    ", "datasets", "=", "[", "]", "\n", "for", "idx", ",", "dataset_config", "in", "enumerate", "(", "datasets_config", ")", ":", "\n", "        ", "if", "pass_text_description", ":", "\n", "            ", "if", "not", "\"text_description\"", "in", "dataset_config", ":", "\n", "                ", "dataset_config", ".", "text_description", "=", "f\"ds{idx}\"", "if", "len", "(", "datasets_config", ")", ">", "1", "else", "None", "\n", "", "", "else", ":", "\n", "            ", "dataset_config", ".", "text_description", "=", "None", "\n", "", "transforms", "=", "build_transforms_from_environment", "(", "env", ",", "dataset_config", ")", "\n", "dataset_args", "=", "{", "\"transforms\"", ":", "transforms", ",", "\"dataset_config\"", ":", "dataset_config", "}", "\n", "if", "initial_images", "is", "not", "None", ":", "\n", "            ", "dataset_args", ".", "update", "(", "{", "\"initial_images\"", ":", "initial_images", "}", ")", "\n", "", "if", "initial_kspaces", "is", "not", "None", ":", "\n", "            ", "dataset_args", ".", "update", "(", "{", "\"initial_kspaces\"", ":", "initial_kspaces", "}", ")", "\n", "", "if", "data_root", "is", "not", "None", ":", "\n", "            ", "dataset_args", ".", "update", "(", "{", "\"data_root\"", ":", "data_root", "}", ")", "\n", "filenames_filter", "=", "get_filenames_for_datasets_from_config", "(", "dataset_config", ",", "lists_root", ",", "data_root", ")", "\n", "dataset_args", ".", "update", "(", "{", "\"filenames_filter\"", ":", "filenames_filter", "}", ")", "\n", "", "if", "pass_dictionaries", "is", "not", "None", ":", "\n", "            ", "dataset_args", ".", "update", "(", "{", "\"pass_dictionaries\"", ":", "pass_dictionaries", "}", ")", "\n", "", "dataset", "=", "build_dataset_from_input", "(", "**", "dataset_args", ")", "\n", "\n", "logger", ".", "debug", "(", "\"Transforms %s / %s :\\n%s\"", ",", "idx", "+", "1", ",", "len", "(", "datasets_config", ")", ",", "transforms", ")", "\n", "datasets", ".", "append", "(", "dataset", ")", "\n", "logger", ".", "info", "(", "\n", "\"Data size for %s (%s/%s): %s.\"", ",", "\n", "dataset_config", ".", "text_description", ",", "# type: ignore", "\n", "idx", "+", "1", ",", "\n", "len", "(", "datasets_config", ")", ",", "\n", "len", "(", "dataset", ")", ",", "\n", ")", "\n", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.train.setup_train": [[132, 283], ["direct.environment.setup_training_environment", "torch.cuda.empty_cache", "train.build_training_datasets_from_environment", "logger.info", "logger.info", "list", "direct.data.lr_scheduler.WarmupMultiStepLR", "torch.cuda.empty_cache", "direct.environment.setup_training_environment.engine.train", "ValueError", "training_dataset_args.update", "training_dataset_args.update", "train.get_root_of_file", "training_dataset_args.update", "training_dataset_args.update", "len", "sum", "train.build_training_datasets_from_environment", "logger.info", "logger.info", "optimizer_params.append", "direct.utils.str_to_class", "range", "ValueError", "direct.utils.io.read_json", "train.parse_noise_dict", "training_dataset_args.update", "validation_dataset_args.update", "train.get_root_of_file", "validation_dataset_args.update", "validation_dataset_args.update", "direct.environment.setup_training_environment.engine.model.parameters", "logger.warning", "str", "validation_dataset_args.update", "direct.environment.setup_training_environment.engine.models[].parameters"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_training_environment", "home.repos.pwc.inspect_result.directgroup_direct.direct.train.build_training_datasets_from_environment", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.train", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.direct.train.get_root_of_file", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.direct.train.build_training_datasets_from_environment", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_json", "home.repos.pwc.inspect_result.directgroup_direct.direct.train.parse_noise_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.direct.train.get_root_of_file", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "setup_train", "(", "\n", "run_name", ":", "str", ",", "\n", "training_root", ":", "Union", "[", "pathlib", ".", "Path", ",", "None", "]", ",", "\n", "validation_root", ":", "Union", "[", "pathlib", ".", "Path", ",", "None", "]", ",", "\n", "base_directory", ":", "pathlib", ".", "Path", ",", "\n", "cfg_filename", ":", "PathOrString", ",", "\n", "force_validation", ":", "bool", ",", "\n", "initialization_checkpoint", ":", "PathOrString", ",", "\n", "initial_images", ":", "Optional", "[", "Union", "[", "List", "[", "pathlib", ".", "Path", "]", ",", "None", "]", "]", ",", "\n", "initial_kspace", ":", "Optional", "[", "Union", "[", "List", "[", "pathlib", ".", "Path", "]", ",", "None", "]", "]", ",", "\n", "noise", ":", "Optional", "[", "Union", "[", "List", "[", "pathlib", ".", "Path", "]", ",", "None", "]", "]", ",", "\n", "device", ":", "str", ",", "\n", "num_workers", ":", "int", ",", "\n", "resume", ":", "bool", ",", "\n", "machine_rank", ":", "int", ",", "\n", "mixed_precision", ":", "bool", ",", "\n", "debug", ":", "bool", ",", "\n", ")", ":", "\n", "\n", "    ", "env", "=", "setup_training_environment", "(", "\n", "run_name", ",", "\n", "base_directory", ",", "\n", "cfg_filename", ",", "\n", "device", ",", "\n", "machine_rank", ",", "\n", "mixed_precision", ",", "\n", "debug", "=", "debug", ",", "\n", ")", "\n", "\n", "# Trigger cudnn benchmark and remove the associated cache", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "if", "initial_kspace", "is", "not", "None", "and", "initial_images", "is", "not", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot both provide initial kspace or initial images.\"", ")", "\n", "# Create training data", "\n", "", "training_dataset_args", "=", "{", "\"env\"", ":", "env", ",", "\"datasets_config\"", ":", "env", ".", "cfg", ".", "training", ".", "datasets", ",", "\"pass_text_description\"", ":", "True", "}", "\n", "pass_dictionaries", "=", "{", "}", "\n", "if", "noise", "is", "not", "None", ":", "\n", "        ", "if", "not", "env", ".", "cfg", ".", "physics", ".", "use_noise_matrix", ":", "\n", "            ", "raise", "ValueError", "(", "\"cfg.physics.use_noise_matrix is null, yet command line passed noise files.\"", ")", "\n", "\n", "", "noise", "=", "[", "read_json", "(", "fn", ")", "for", "fn", "in", "noise", "]", "\n", "pass_dictionaries", "[", "\"loglikelihood_scaling\"", "]", "=", "[", "\n", "parse_noise_dict", "(", "_", ",", "percentile", "=", "0.999", ",", "multiplier", "=", "env", ".", "cfg", ".", "physics", ".", "noise_matrix_scaling", ")", "for", "_", "in", "noise", "\n", "]", "\n", "training_dataset_args", ".", "update", "(", "{", "\"pass_dictionaries\"", ":", "pass_dictionaries", "}", ")", "\n", "\n", "", "if", "training_root", "is", "not", "None", ":", "\n", "        ", "training_dataset_args", ".", "update", "(", "{", "\"data_root\"", ":", "training_root", "}", ")", "\n", "# Get the lists_root. Assume now the given path is with respect to the config file.", "\n", "lists_root", "=", "get_root_of_file", "(", "cfg_filename", ")", "\n", "if", "lists_root", "is", "not", "None", ":", "\n", "            ", "training_dataset_args", ".", "update", "(", "{", "\"lists_root\"", ":", "lists_root", "}", ")", "\n", "", "", "if", "initial_images", "is", "not", "None", ":", "\n", "        ", "training_dataset_args", ".", "update", "(", "{", "\"initial_images\"", ":", "initial_images", "[", "0", "]", "}", ")", "\n", "", "if", "initial_kspace", "is", "not", "None", ":", "\n", "        ", "training_dataset_args", ".", "update", "(", "{", "\"initial_kspaces\"", ":", "initial_kspace", "[", "0", "]", "}", ")", "\n", "\n", "# Build training datasets", "\n", "", "training_datasets", "=", "build_training_datasets_from_environment", "(", "**", "training_dataset_args", ")", "\n", "training_data_sizes", "=", "[", "len", "(", "_", ")", "for", "_", "in", "training_datasets", "]", "\n", "logger", ".", "info", "(", "\"Training data sizes: %s (sum=%s).\"", ",", "training_data_sizes", ",", "sum", "(", "training_data_sizes", ")", ")", "\n", "\n", "# Create validation data", "\n", "if", "\"validation\"", "in", "env", ".", "cfg", ":", "\n", "        ", "validation_dataset_args", "=", "{", "\n", "\"env\"", ":", "env", ",", "\n", "\"datasets_config\"", ":", "env", ".", "cfg", ".", "validation", ".", "datasets", ",", "\n", "\"pass_text_description\"", ":", "True", ",", "\n", "}", "\n", "if", "validation_root", "is", "not", "None", ":", "\n", "            ", "validation_dataset_args", ".", "update", "(", "{", "\"data_root\"", ":", "validation_root", "}", ")", "\n", "lists_root", "=", "get_root_of_file", "(", "cfg_filename", ")", "\n", "if", "lists_root", "is", "not", "None", ":", "\n", "                ", "validation_dataset_args", ".", "update", "(", "{", "\"lists_root\"", ":", "lists_root", "}", ")", "\n", "", "", "if", "initial_images", "is", "not", "None", ":", "\n", "            ", "validation_dataset_args", ".", "update", "(", "{", "\"initial_images\"", ":", "initial_images", "[", "1", "]", "}", ")", "\n", "", "if", "initial_kspace", "is", "not", "None", ":", "\n", "            ", "validation_dataset_args", ".", "update", "(", "{", "\"initial_kspaces\"", ":", "initial_kspace", "[", "1", "]", "}", ")", "\n", "\n", "# Build validation datasets", "\n", "", "validation_data", "=", "build_training_datasets_from_environment", "(", "**", "validation_dataset_args", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"No validation data.\"", ")", "\n", "validation_data", "=", "None", "\n", "\n", "# Create the optimizers", "\n", "", "logger", ".", "info", "(", "\"Building optimizers.\"", ")", "\n", "optimizer_params", "=", "[", "{", "\"params\"", ":", "env", ".", "engine", ".", "model", ".", "parameters", "(", ")", "}", "]", "\n", "for", "curr_model_name", "in", "env", ".", "engine", ".", "models", ":", "\n", "# TODO(jt): Can get learning rate from the config per additional model too.", "\n", "        ", "curr_learning_rate", "=", "env", ".", "cfg", ".", "training", ".", "lr", "\n", "logger", ".", "info", "(", "\"Adding model parameters of %s with learning rate %s.\"", ",", "curr_model_name", ",", "curr_learning_rate", ")", "\n", "optimizer_params", ".", "append", "(", "\n", "{", "\n", "\"params\"", ":", "env", ".", "engine", ".", "models", "[", "curr_model_name", "]", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "curr_learning_rate", ",", "\n", "}", "\n", ")", "\n", "\n", "", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", "=", "str_to_class", "(", "\"torch.optim\"", ",", "env", ".", "cfg", ".", "training", ".", "optimizer", ")", "(", "# noqa", "\n", "optimizer_params", ",", "\n", "lr", "=", "env", ".", "cfg", ".", "training", ".", "lr", ",", "\n", "weight_decay", "=", "env", ".", "cfg", ".", "training", ".", "weight_decay", ",", "\n", ")", "# noqa", "\n", "\n", "# Build the LR scheduler, we use a fixed LR schedule step size, no adaptive training schedule.", "\n", "solver_steps", "=", "list", "(", "\n", "range", "(", "\n", "env", ".", "cfg", ".", "training", ".", "lr_step_size", ",", "\n", "env", ".", "cfg", ".", "training", ".", "num_iterations", ",", "\n", "env", ".", "cfg", ".", "training", ".", "lr_step_size", ",", "\n", ")", "\n", ")", "\n", "lr_scheduler", "=", "WarmupMultiStepLR", "(", "\n", "optimizer", ",", "\n", "solver_steps", ",", "\n", "env", ".", "cfg", ".", "training", ".", "lr_gamma", ",", "\n", "warmup_factor", "=", "1", "/", "3.0", ",", "\n", "warmup_iterations", "=", "env", ".", "cfg", ".", "training", ".", "lr_warmup_iter", ",", "\n", "warmup_method", "=", "\"linear\"", ",", "\n", ")", "\n", "\n", "# Just to make sure.", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# Check the initialization checkpoint", "\n", "if", "env", ".", "cfg", ".", "training", ".", "model_checkpoint", ":", "\n", "        ", "if", "initialization_checkpoint", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"`--initialization-checkpoint is set, and config has a set `training.model_checkpoint`: %s. \"", "\n", "\"Will overwrite config variable with the command line: %s.\"", ",", "\n", "env", ".", "cfg", ".", "training", ".", "model_checkpoint", ",", "\n", "initialization_checkpoint", ",", "\n", ")", "\n", "# Now overwrite this in the configuration, so the correct value is dumped.", "\n", "env", ".", "cfg", ".", "training", ".", "model_checkpoint", "=", "str", "(", "initialization_checkpoint", ")", "\n", "", "else", ":", "\n", "            ", "initialization_checkpoint", "=", "env", ".", "cfg", ".", "training", ".", "model_checkpoint", "\n", "\n", "", "", "env", ".", "engine", ".", "train", "(", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "training_datasets", ",", "\n", "env", ".", "experiment_dir", ",", "\n", "validation_datasets", "=", "validation_data", ",", "\n", "resume", "=", "resume", ",", "\n", "initialization", "=", "initialization_checkpoint", ",", "\n", "start_with_validation", "=", "force_validation", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.train.train_from_argparse": [[286, 327], ["torch.set_num_threads", "direct.cli.utils.check_train_val", "direct.cli.utils.check_train_val", "direct.cli.utils.check_train_val", "direct.utils.set_all_seeds", "direct.launch.launch", "sys.exit", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.cli.utils.check_train_val", "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.check_train_val", "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.check_train_val", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.set_all_seeds", "home.repos.pwc.inspect_result.directgroup_direct.direct.launch.launch"], ["", "def", "train_from_argparse", "(", "args", ":", "argparse", ".", "Namespace", ")", ":", "\n", "# This sets MKL threads to 1.", "\n", "# DataLoader can otherwise bring a lot of difficulties when computing CPU FFTs in the transforms.", "\n", "    ", "torch", ".", "set_num_threads", "(", "1", ")", "\n", "os", ".", "environ", "[", "\"OMP_NUM_THREADS\"", "]", "=", "\"1\"", "\n", "# Disable Tensorboard warnings.", "\n", "os", ".", "environ", "[", "\"TF_CPP_MIN_LOG_LEVEL\"", "]", "=", "\"2\"", "\n", "\n", "if", "args", ".", "initialization_images", "is", "not", "None", "and", "args", ".", "initialization_kspace", "is", "not", "None", ":", "\n", "        ", "sys", ".", "exit", "(", "\"--initialization-images and --initialization-kspace are mutually exclusive.\"", ")", "\n", "", "check_train_val", "(", "args", ".", "initialization_images", ",", "\"initialization-images\"", ")", "\n", "check_train_val", "(", "args", ".", "initialization_kspace", ",", "\"initialization-kspace\"", ")", "\n", "check_train_val", "(", "args", ".", "noise", ",", "\"noise\"", ")", "\n", "\n", "set_all_seeds", "(", "args", ".", "seed", ")", "\n", "\n", "run_name", "=", "args", ".", "name", "if", "args", ".", "name", "is", "not", "None", "else", "os", ".", "path", ".", "basename", "(", "args", ".", "cfg_file", ")", "[", ":", "-", "5", "]", "\n", "\n", "# TODO(jt): Duplicate params", "\n", "launch", "(", "\n", "setup_train", ",", "\n", "args", ".", "num_machines", ",", "\n", "args", ".", "num_gpus", ",", "\n", "args", ".", "machine_rank", ",", "\n", "args", ".", "dist_url", ",", "\n", "run_name", ",", "\n", "args", ".", "training_root", ",", "\n", "args", ".", "validation_root", ",", "\n", "args", ".", "experiment_dir", ",", "\n", "args", ".", "cfg_file", ",", "\n", "args", ".", "force_validation", ",", "\n", "args", ".", "initialization_checkpoint", ",", "\n", "args", ".", "initialization_images", ",", "\n", "args", ".", "initialization_kspace", ",", "\n", "args", ".", "noise", ",", "\n", "args", ".", "device", ",", "\n", "args", ".", "num_workers", ",", "\n", "args", ".", "resume", ",", "\n", "args", ".", "machine_rank", ",", "\n", "args", ".", "mixed_precision", ",", "\n", "args", ".", "debug", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.__init__": [[42, 64], ["logging.getLogger", "checkpointer.Checkpointer._remove_module_attribute", "checkpointables.copy", "re.match", "type", "checkpointer.Checkpointer._remove_module_attribute"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._remove_module_attribute", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._remove_module_attribute"], ["def", "__init__", "(", "\n", "self", ",", "\n", "save_directory", ":", "pathlib", ".", "Path", ",", "\n", "save_to_disk", ":", "bool", "=", "True", ",", "\n", "model_regex", ":", "str", "=", "\"^.*model$\"", ",", "\n", "**", "checkpointables", ":", "Mapping", "[", "str", ",", "Union", "[", "str", ",", "bool", ",", "HasStateDict", "]", "]", ",", "\n", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "self", ".", "save_directory", "=", "save_directory", "\n", "self", ".", "model_regex", "=", "model_regex", "\n", "\n", "model", "=", "checkpointables", "[", "\"model\"", "]", "\n", "del", "checkpointables", "[", "\"model\"", "]", "\n", "\n", "self", ".", "model", "=", "self", ".", "_remove_module_attribute", "(", "model", ")", "\n", "for", "key", "in", "checkpointables", ".", "copy", "(", ")", ":", "\n", "            ", "if", "re", ".", "match", "(", "model_regex", ",", "key", ")", ":", "\n", "                ", "checkpointables", "[", "key", "]", "=", "self", ".", "_remove_module_attribute", "(", "checkpointables", "[", "key", "]", ")", "\n", "\n", "", "", "self", ".", "save_to_disk", "=", "save_to_disk", "\n", "self", ".", "checkpoint_loaded", ":", "Union", "[", "int", ",", "str", ",", "None", "]", "=", "None", "\n", "self", ".", "checkpointables", "=", "checkpointables", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._remove_module_attribute": [[65, 76], ["hasattr", "isinstance", "warnings.warn"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_remove_module_attribute", "(", "model", ")", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "model", ",", "(", "DistributedDataParallel", ",", "DataParallel", ")", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "\"Model has a `.module` property and is not derived from DistributeDataParallel or DataParallel. \"", "\n", "\"This is strange, but assuming the model is in `.module`.\"", "\n", ")", "\n", "\n", "", "model", "=", "model", ".", "module", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load": [[77, 112], ["checkpointer.Checkpointer.load_from_path", "ValueError", "checkpointer.Checkpointer.logger.info", "last_model_text_path.exists", "isinstance", "checkpointer.Checkpointer.logger.info", "open", "int", "checkpointer.Checkpointer.logger.info", "pathlib.Path", "f.readline"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load_from_path"], ["", "def", "load", "(", "\n", "self", ",", "\n", "iteration", ":", "Union", "[", "int", ",", "str", ",", "None", "]", ",", "\n", "checkpointable_objects", ":", "Optional", "[", "Dict", "[", "str", ",", "nn", ".", "Module", "]", "]", "=", "None", ",", "\n", ")", "->", "Dict", ":", "\n", "        ", "if", "iteration", "is", "not", "None", "and", "not", "isinstance", "(", "iteration", ",", "int", ")", "and", "iteration", "!=", "\"latest\"", ":", "\n", "            ", "raise", "ValueError", "(", "\"Value `iteration` is expected to be either None, an integer or `latest`.\"", ")", "\n", "\n", "", "if", "iteration", "is", "None", ":", "\n", "            ", "return", "{", "}", "\n", "\n", "", "if", "iteration", "in", "(", "\"latest\"", ",", "-", "1", ")", ":", "\n", "            ", "last_model_text_path", "=", "self", ".", "save_directory", "/", "\"last_model.txt\"", "\n", "self", ".", "logger", ".", "info", "(", "\"Attempting to load latest model.\"", ")", "\n", "if", "last_model_text_path", ".", "exists", "(", ")", ":", "\n", "                ", "with", "open", "(", "pathlib", ".", "Path", "(", "last_model_text_path", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                    ", "iteration", "=", "int", "(", "f", ".", "readline", "(", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading last saved iteration: %s\"", ",", "iteration", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\n", "\"Latest model not found. Perhaps `last_model.txt` (path = %s) \"", "\n", "\"is missing? You can try to set an explicit iteration number, or create this file if \"", "\n", "\"you believe this is an error. Will not load any model.\"", ",", "\n", "last_model_text_path", ",", "\n", ")", "\n", "return", "{", "}", "\n", "\n", "", "", "checkpoint_path", "=", "self", ".", "save_directory", "/", "f\"model_{iteration}.pt\"", "\n", "checkpoint", "=", "self", ".", "load_from_path", "(", "checkpoint_path", ",", "checkpointable_objects", ")", "\n", "checkpoint", "[", "\"iteration\"", "]", "=", "iteration", "\n", "\n", "self", ".", "checkpoint_loaded", "=", "iteration", "\n", "# Return whatever is left", "\n", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load_from_path": [[113, 161], ["checkpointer.Checkpointer._load_checkpoint", "checkpointer.Checkpointer.logger.info", "checkpointer.Checkpointer._load_model", "checkpointer.Checkpointer.logger.info", "checkpointer.Checkpointer.pop", "re.match", "checkpointer.Checkpointer.logger.warning", "key.endswith", "key.startswith", "checkpointer.Checkpointer.logger.debug", "checkpointer.Checkpointer._load_model", "obj.load_state_dict", "re.match"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._load_checkpoint", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._load_model", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._load_model"], ["", "def", "load_from_path", "(", "\n", "self", ",", "\n", "checkpoint_path", ":", "PathOrString", ",", "\n", "checkpointable_objects", ":", "Optional", "[", "Dict", "[", "str", ",", "nn", ".", "Module", "]", "]", "=", "None", ",", "\n", "only_models", ":", "bool", "=", "False", ",", "\n", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Load a checkpoint from a path.\n\n        Parameters\n        ----------\n        checkpoint_path: Path or str\n            Path to checkpoint, either a path to a file or a path to a URL where the file can be downloaded\n        checkpointable_objects: dict\n            Dictionary mapping names to nn.Module's\n        only_models: bool\n            If true will only load the models and no other objects in the checkpoint\n\n        Returns\n        -------\n        Dictionary with loaded models.\n        \"\"\"", "\n", "checkpoint", "=", "self", ".", "_load_checkpoint", "(", "checkpoint_path", ")", "\n", "checkpointables", "=", "self", ".", "checkpointables", "if", "not", "checkpointable_objects", "else", "checkpointable_objects", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading model...\"", ")", "\n", "self", ".", "_load_model", "(", "self", ".", "model", ",", "checkpoint", "[", "\"model\"", "]", ")", "\n", "\n", "for", "key", "in", "checkpointables", ":", "# type: ignore", "\n", "            ", "if", "only_models", "and", "not", "re", ".", "match", "(", "self", ".", "model_regex", ",", "key", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "key", "not", "in", "checkpoint", ":", "\n", "                ", "self", ".", "logger", ".", "warning", "(", "\"Requested to load %s, but this was not stored.\"", ",", "key", ")", "\n", "continue", "\n", "\n", "", "if", "key", ".", "endswith", "(", "\"__\"", ")", "and", "key", ".", "startswith", "(", "\"__\"", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Loading %s...\"", ",", "key", ")", "\n", "obj", "=", "self", ".", "checkpointables", "[", "key", "]", "\n", "state_dict", "=", "checkpoint", ".", "pop", "(", "key", ")", "\n", "if", "re", ".", "match", "(", "self", ".", "model_regex", ",", "key", ")", ":", "\n", "                ", "self", ".", "logger", ".", "debug", "(", "\"key %s matches regex %s.\"", ",", "key", ",", "self", ".", "model_regex", ")", "\n", "self", ".", "_load_model", "(", "obj", ",", "state_dict", ")", "# type: ignore", "\n", "", "else", ":", "\n", "                ", "obj", ".", "load_state_dict", "(", "state_dict", ")", "# type: ignore", "\n", "\n", "", "", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._load_model": [[162, 170], ["obj.load_state_dict", "checkpointer.Checkpointer.logger.warning"], "methods", ["None"], ["", "def", "_load_model", "(", "self", ",", "obj", ",", "state_dict", ")", ":", "\n", "# https://github.com/facebookresearch/fvcore/blob/master/fvcore/common/checkpoint.py", "\n", "# Link has more elaborate checking for incompatibles in _log_incompatible_keys", "\n", "        ", "incompatible", "=", "obj", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "if", "incompatible", ".", "missing_keys", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "incompatible", ".", "unexpected_keys", ":", "\n", "            ", "self", ".", "logger", ".", "warning", "(", "\"Unexpected keys provided which cannot be loaded: %s.\"", ",", "incompatible", ".", "unexpected_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load_models_from_file": [[171, 173], ["checkpointer.Checkpointer.load_from_path"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load_from_path"], ["", "", "def", "load_models_from_file", "(", "self", ",", "checkpoint_path", ":", "PathOrString", ")", "->", "None", ":", "\n", "        ", "_", "=", "self", ".", "load_from_path", "(", "checkpoint_path", ",", "only_models", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save": [[174, 204], ["checkpointer.Checkpointer.checkpointables.items", "data.update", "checkpointer.Checkpointer.logger.info", "datetime.datetime.now().strftime", "checkpointer.Checkpointer.model.state_dict", "open", "torch.save", "torch.save", "torch.save", "torch.save", "open", "f.write", "key.endswith", "key.startswith", "isinstance", "datetime.datetime.now", "str", "str", "typing.get_args", "obj.state_dict", "checkpointer.Checkpointer.logger.warning"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.LRScheduler.state_dict", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.LRScheduler.state_dict"], ["", "def", "save", "(", "self", ",", "iteration", ":", "int", ",", "**", "kwargs", ":", "Dict", "[", "str", ",", "str", "]", ")", "->", "None", ":", "\n", "# For instance useful to only have the rank 0 process write to disk.", "\n", "        ", "if", "not", "self", ".", "save_to_disk", ":", "\n", "            ", "return", "\n", "\n", "", "data", ":", "Dict", "[", "str", ",", "Union", "[", "nn", ".", "Module", ",", "str", "]", "]", "=", "{", "\"model\"", ":", "self", ".", "model", ".", "state_dict", "(", ")", "}", "\n", "\n", "for", "key", ",", "obj", "in", "self", ".", "checkpointables", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", ".", "endswith", "(", "\"__\"", ")", "and", "key", ".", "startswith", "(", "\"__\"", ")", ":", "\n", "# Keys of the form __TEXT__ do should not have state", "\n", "                ", "data", "[", "key", "]", "=", "obj", "\n", "\n", "", "elif", "isinstance", "(", "obj", ",", "get_args", "(", "HasStateDict", ")", ")", ":", "\n", "                ", "data", "[", "key", "]", "=", "obj", ".", "state_dict", "(", ")", "# type: ignore", "\n", "", "else", ":", "\n", "                ", "self", ".", "logger", ".", "warning", "(", "\"Value of key %s has no state_dict.\"", ",", "key", ")", "\n", "\n", "", "", "data", ".", "update", "(", "kwargs", ")", "\n", "\n", "checkpoint_path", "=", "self", ".", "save_directory", "/", "f\"model_{iteration}.pt\"", "\n", "self", ".", "logger", ".", "info", "(", "\"Saving checkpoint to: %s.\"", ",", "checkpoint_path", ")", "\n", "\n", "data", "[", "\"__datetime__\"", "]", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "\n", "with", "open", "(", "str", "(", "checkpoint_path", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "data", ",", "f", ")", "\n", "\n", "# noinspection PyTypeChecker", "\n", "", "with", "open", "(", "self", ".", "save_directory", "/", "\"last_model.txt\"", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "# type: ignore", "\n", "            ", "f", ".", "write", "(", "str", "(", "iteration", ")", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._load_checkpoint": [[205, 236], ["direct.utils.io.check_is_valid_url", "pathlib.Path", "checkpointer.Checkpointer.logger.info", "str", "checkpointer.Checkpointer.logger.info", "checkpointer.Checkpointer._download_or_load_from_cache", "checkpointer.Checkpointer.logger.info", "checkpointer.Checkpointer.exists", "FileNotFoundError", "torch.load", "torch.load", "torch.load", "torch.load", "str", "checkpointer.Checkpointer.logger.exception", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._download_or_load_from_cache", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load"], ["", "", "def", "_load_checkpoint", "(", "self", ",", "checkpoint_path", ":", "PathOrString", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Load a checkpoint from path or string.\n\n        Parameters\n        ----------\n        checkpoint_path: Path or str\n            Path to checkpoint, either a path to a file or a path to a URL where the file can be downloaded\n        Returns\n        -------\n        Dict loaded from checkpoint.\n        \"\"\"", "\n", "# Check if the path is an URL", "\n", "if", "check_is_valid_url", "(", "str", "(", "checkpoint_path", ")", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Initializing from remote checkpoint %s...\"", ",", "checkpoint_path", ")", "\n", "checkpoint_path", "=", "self", ".", "_download_or_load_from_cache", "(", "str", "(", "checkpoint_path", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading downloaded checkpoint %s.\"", ",", "checkpoint_path", ")", "\n", "\n", "", "checkpoint_path", "=", "pathlib", ".", "Path", "(", "checkpoint_path", ")", "\n", "if", "not", "checkpoint_path", ".", "exists", "(", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Requested to load {checkpoint_path}, but does not exist.\"", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Loaded checkpoint path: %s.\"", ",", "checkpoint_path", ")", "\n", "\n", "try", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n", "", "except", "UnpicklingError", "as", "exc", ":", "\n", "            ", "self", ".", "logger", ".", "exception", "(", "\"Tried to load %s, but was unable to unpickle: %s.\"", ",", "checkpoint_path", ",", "exc", ")", "\n", "raise", "\n", "\n", "", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer._download_or_load_from_cache": [[237, 247], ["direct.utils.io.download_url", "urllib.parse.urlparse", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.download_url"], ["", "@", "staticmethod", "\n", "def", "_download_or_load_from_cache", "(", "url", ":", "str", ")", "->", "pathlib", ".", "Path", ":", "\n", "# Get final part of url.", "\n", "        ", "file_path", "=", "urllib", ".", "parse", ".", "urlparse", "(", "url", ")", ".", "path", "\n", "filename", "=", "pathlib", ".", "Path", "(", "file_path", ")", ".", "name", "\n", "\n", "cache_path", "=", "DIRECT_MODEL_DOWNLOAD_DIR", "/", "filename", "\n", "download_url", "(", "url", ",", "DIRECT_MODEL_DOWNLOAD_DIR", ",", "max_redirect_hops", "=", "3", ")", "\n", "\n", "return", "cache_path", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.Args.__init__": [[580, 652], ["argparse.ArgumentParser.__init__", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.add_argument", "environment.Args.set_defaults", "hash", "os.getuid"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "epilog", "=", "None", ",", "add_help", "=", "True", ",", "**", "overrides", ")", ":", "\n", "        ", "\"\"\"Inits Args.\n\n        Parameters\n        ----------\n        epilog: str\n            Text to display after the argument help. Default: None.\n        add_help: bool\n            Add a -h/--help option to the parser. Default: True.\n        **overrides: (dict, optional)\n            Keyword arguments used to override default argument values\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "epilog", "=", "epilog", ",", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "add_help", "=", "add_help", ")", "\n", "\n", "self", ".", "add_argument", "(", "\n", "\"--device\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"cuda\"", ",", "\n", "help", "=", "'Which device to train on. Set to \"cuda\" to use the GPU.'", ",", "\n", ")", "\n", "self", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "\"Seed for random number generators.\"", ")", "\n", "self", ".", "add_argument", "(", "\"--num-workers\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "\"Number of workers.\"", ")", "\n", "self", ".", "add_argument", "(", "\"--mixed-precision\"", ",", "help", "=", "\"Use mixed precision.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "self", ".", "add_argument", "(", "\"--debug\"", ",", "help", "=", "\"Set debug mode true.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "self", ".", "add_argument", "(", "\"--num-gpus\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"# GPUs per machine.\"", ")", "\n", "self", ".", "add_argument", "(", "\"--num-machines\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"# of machines.\"", ")", "\n", "self", ".", "add_argument", "(", "\n", "\"--machine-rank\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "\"the rank of this machine (unique per machine).\"", ",", "\n", ")", "\n", "self", ".", "add_argument", "(", "\n", "\"--initialization-images\"", ",", "\n", "help", "=", "\"Path to images which will be used as initialization to the model. \"", "\n", "\"The filenames assumed to be the same as the images themselves. If these are h5 files, \"", "\n", "\"the key to read in the h5 has to be set in the configuration in the dataset.input_image_key.\"", ",", "\n", "required", "=", "False", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "type", "=", "pathlib", ".", "Path", ",", "\n", ")", "\n", "self", ".", "add_argument", "(", "\n", "\"--initialization-kspace\"", ",", "\n", "help", "=", "\"Path to kspace which will be used as initialization to the model. \"", "\n", "\"The filenames assumed to be the same as the images themselves. If these are h5 files, \"", "\n", "\"the key to read in the h5 has to be set in the configuration in the dataset.input_image_key.\"", ",", "\n", "required", "=", "False", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "type", "=", "pathlib", ".", "Path", ",", "\n", ")", "\n", "self", ".", "add_argument", "(", "\n", "\"--noise\"", ",", "\n", "help", "=", "\"Path to json file mapping relative filename to noise estimates. \"", "\n", "\"Path to training and validation data\"", ",", "\n", "required", "=", "False", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "type", "=", "pathlib", ".", "Path", ",", "\n", ")", "\n", "\n", "# Taken from: https://github.com/facebookresearch/detectron2/blob/bd2ea475b693a88c063e05865d13954d50242857/detectron2/engine/defaults.py#L49 # noqa", "\n", "# PyTorch still may leave orphan processes in multi-gpu training. Therefore we use a deterministic way", "\n", "# to obtain port, so that users are aware of orphan processes by seeing the port occupied.", "\n", "port", "=", "2", "**", "15", "+", "2", "**", "14", "+", "hash", "(", "os", ".", "getuid", "(", ")", ")", "%", "2", "**", "14", "\n", "self", ".", "add_argument", "(", "\n", "\"--dist-url\"", ",", "\n", "default", "=", "f\"tcp://127.0.0.1:{port}\"", ",", "\n", "help", "=", "\"initialization URL for pytorch distributed backend. See \"", "\n", "\"https://pytorch.org/docs/stable/distributed.html for details.\"", ",", "\n", ")", "\n", "\n", "self", ".", "set_defaults", "(", "**", "overrides", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_model_config_from_name": [[32, 54], ["model_name.split", "direct.utils.str_to_class", "[].lower", "logger.error", "sys.exit", "model_name.split"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["def", "load_model_config_from_name", "(", "model_name", ":", "str", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"Load specific configuration module for models based on their name.\n\n    Parameters\n    ----------\n    model_name: str\n        Path to model relative to direct.nn.\n\n    Returns\n    -------\n    model_cfg: Callable\n        Model configuration.\n    \"\"\"", "\n", "module_path", "=", "f\"direct.nn.{model_name.split('.')[0].lower()}.config\"", "\n", "model_name", "+=", "\"Config\"", "\n", "config_name", "=", "model_name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "try", ":", "\n", "        ", "model_cfg", "=", "str_to_class", "(", "module_path", ",", "config_name", ")", "\n", "", "except", "(", "AttributeError", ",", "ModuleNotFoundError", ")", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "f\"Path {module_path} for config_name {config_name} does not exist (err = {e}).\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "", "return", "model_cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_model_from_name": [[56, 78], ["model_name.split", "direct.utils.str_to_class", "logger.error", "sys.exit", "_.lower", "model_name.split"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["", "def", "load_model_from_name", "(", "model_name", ":", "str", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"Load model based on `model_name`.\n\n    Parameters\n    ----------\n    model_name: str\n        Model name as in direct.nn.\n\n    Returns\n    -------\n    model: Callable\n        Model class.\n    \"\"\"", "\n", "module_path", "=", "f\"direct.nn.{'.'.join([_.lower() for _ in model_name.split('.')[:-1]])}\"", "\n", "module_name", "=", "model_name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "try", ":", "\n", "        ", "model", "=", "str_to_class", "(", "module_path", ",", "module_name", ")", "\n", "", "except", "(", "AttributeError", ",", "ModuleNotFoundError", ")", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "f\"Path {module_path} for model_name {module_name} does not exist (err = {e}).\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_dataset_config": [[80, 95], ["direct.utils.str_to_class"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["", "def", "load_dataset_config", "(", "dataset_name", ":", "str", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"Load specific dataset configuration for dataset based on `dataset_name`.\n\n    Parameters\n    ----------\n    dataset_name: str\n        Name of dataset.\n\n    Returns\n    -------\n    dataset_config: Callable\n        Dataset configuration.\n    \"\"\"", "\n", "dataset_config", "=", "str_to_class", "(", "\"direct.data.datasets_config\"", ",", "dataset_name", "+", "\"Config\"", ")", "\n", "return", "dataset_config", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.build_operators": [[97, 103], ["direct.utils.str_to_class", "direct.utils.str_to_class"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["", "def", "build_operators", "(", "cfg", ":", "PhysicsConfig", ")", "->", "Tuple", "[", "Callable", ",", "Callable", "]", ":", "\n", "    ", "\"\"\"Builds operators from configuration.\"\"\"", "\n", "# Get the operators", "\n", "forward_operator", "=", "str_to_class", "(", "\"direct.data.transforms\"", ",", "cfg", ".", "forward_operator", ")", "\n", "backward_operator", "=", "str_to_class", "(", "\"direct.data.transforms\"", ",", "cfg", ".", "backward_operator", ")", "\n", "return", "forward_operator", ",", "backward_operator", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_logging": [[105, 150], ["direct.utils.logging.setup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "direct.utils.git_hash", "logger.info", "logger.info", "direct.utils.communication.get_local_rank", "torch.backends.cudnn.version", "torch.utils.collect_env.get_pretty_env_info", "omegaconf.OmegaConf.to_yaml", "direct.utils.communication.get_local_rank", "direct.utils.communication.is_main_process"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.ext.doi_role.setup", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.git_hash", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_local_rank", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_local_rank", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.is_main_process"], ["", "def", "setup_logging", "(", "\n", "machine_rank", ":", "int", ",", "\n", "output_directory", ":", "pathlib", ".", "Path", ",", "\n", "run_name", ":", "str", ",", "\n", "cfg_filename", ":", "Union", "[", "pathlib", ".", "Path", ",", "str", "]", ",", "\n", "cfg", ":", "DefaultConfig", ",", "\n", "debug", ":", "bool", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Logs environment information.\n\n    Parameters\n    ----------\n    machine_rank: int\n        Machine rank.\n    output_directory: pathlib.Path\n        Path to output directory.\n    run_name: str\n        Name of run.\n    cfg_filename: Union[pathlib.Path, str]\n        Name of configuration file.\n    cfg: DefaultConfig\n        Configuration file.\n    debug: bool\n        Whether the debug mode is enabled.\n    \"\"\"", "\n", "# Setup logging", "\n", "log_file", "=", "output_directory", "/", "f\"log_{machine_rank}_{communication.get_local_rank()}.txt\"", "\n", "\n", "setup", "(", "\n", "use_stdout", "=", "communication", ".", "is_main_process", "(", ")", "or", "debug", ",", "\n", "filename", "=", "log_file", ",", "\n", "log_level", "=", "(", "\"INFO\"", "if", "not", "debug", "else", "\"DEBUG\"", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"Machine rank: %s\"", ",", "machine_rank", ")", "\n", "logger", ".", "info", "(", "\"Local rank: %s\"", ",", "communication", ".", "get_local_rank", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Logging: %s\"", ",", "log_file", ")", "\n", "logger", ".", "info", "(", "\"Saving to: %s\"", ",", "output_directory", ")", "\n", "logger", ".", "info", "(", "\"Run name: %s\"", ",", "run_name", ")", "\n", "logger", ".", "info", "(", "\"Config file: %s\"", ",", "cfg_filename", ")", "\n", "logger", ".", "info", "(", "\"CUDA %s - cuDNN %s\"", ",", "torch", ".", "version", ".", "cuda", ",", "torch", ".", "backends", ".", "cudnn", ".", "version", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Environment information: %s\"", ",", "collect_env", ".", "get_pretty_env_info", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"DIRECT version: %s\"", ",", "direct", ".", "__version__", ")", "\n", "git_hash", "=", "direct", ".", "utils", ".", "git_hash", "(", ")", "\n", "logger", ".", "info", "(", "\"Git hash: %s\"", ",", "git_hash", "if", "git_hash", "else", "\"N/A\"", ")", "\n", "logger", ".", "info", "(", "\"Configuration: %s\"", ",", "OmegaConf", ".", "to_yaml", "(", "cfg", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_models_into_environment_config": [[152, 185], ["environment.load_model_from_name", "omegaconf.OmegaConf.merge", "omegaconf.OmegaConf.merge", "logger.error", "sys.exit", "environment.load_model_config_from_name"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_model_from_name", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_model_config_from_name"], ["", "def", "load_models_into_environment_config", "(", "cfg_from_file", ":", "DictConfig", ")", "->", "Tuple", "[", "dict", ",", "DictConfig", "]", ":", "\n", "    ", "\"\"\"Load the configuration for the models.\n\n    Parameters\n    ----------\n    cfg_from_file: DictConfig\n        Omegaconf configuration.\n\n    Returns\n    -------\n    (models, models_config): (dict, DictConfig)\n        Models dictionary and models configuration dictionary.\n    \"\"\"", "\n", "cfg", "=", "{", "\"model\"", ":", "cfg_from_file", ".", "model", "}", "\n", "\n", "if", "\"additional_models\"", "in", "cfg_from_file", ":", "\n", "        ", "cfg", "=", "{", "**", "cfg", ",", "**", "cfg_from_file", ".", "additional_models", "}", "\n", "# Parse config of additional models", "\n", "# TODO: Merge this with the normal model config loading.", "\n", "", "models_config", "=", "{", "}", "\n", "models", "=", "{", "}", "\n", "for", "curr_model_name", "in", "cfg", ":", "\n", "        ", "if", "\"model_name\"", "not", "in", "cfg", "[", "curr_model_name", "]", ":", "\n", "            ", "logger", ".", "error", "(", "f\"Model {curr_model_name} has no model_name.\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "curr_model_cfg", "=", "cfg", "[", "curr_model_name", "]", "\n", "model_name", "=", "curr_model_cfg", ".", "model_name", "\n", "models", "[", "curr_model_name", "]", "=", "load_model_from_name", "(", "model_name", ")", "\n", "\n", "models_config", "[", "curr_model_name", "]", "=", "OmegaConf", ".", "merge", "(", "load_model_config_from_name", "(", "model_name", ")", ",", "curr_model_cfg", ")", "\n", "\n", "", "return", "models", ",", "OmegaConf", ".", "merge", "(", "models_config", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.initialize_models_from_config": [[187, 231], ["logger.info", "cfg.additional_models.items", "direct.utils.count_parameters", "curr_model", "v.items", "cfg.model.items"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.count_parameters"], ["", "def", "initialize_models_from_config", "(", "\n", "cfg", ":", "DictConfig", ",", "models", ":", "dict", ",", "forward_operator", ":", "Callable", ",", "backward_operator", ":", "Callable", ",", "device", ":", "str", "\n", ")", "->", "Tuple", "[", "torch", ".", "nn", ".", "Module", ",", "Dict", "]", ":", "\n", "    ", "\"\"\"Creates models from config.\n\n    Parameters\n    ----------\n    cfg: DictConfig\n        Configuration.\n    models: dict\n        Models dictionary including configurations.\n    forward_operator: Callable\n        Forward operator.\n    backward_operator: Callable\n        Backward operator.\n    device: str\n        Type of device.\n\n    Returns\n    -------\n    model: torch.nn.Module\n        Model.\n    additional_models: Dict\n        Additional models.\n    \"\"\"", "\n", "# Create the model", "\n", "logger", ".", "info", "(", "\"Building models.\"", ")", "\n", "# TODO(jt): Model name is not used here.", "\n", "additional_models", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "cfg", ".", "additional_models", ".", "items", "(", ")", ":", "\n", "# Remove model_name key", "\n", "        ", "curr_model", "=", "models", "[", "k", "]", "\n", "curr_model_cfg", "=", "{", "kk", ":", "vv", "for", "kk", ",", "vv", "in", "v", ".", "items", "(", ")", "if", "kk", "!=", "\"model_name\"", "}", "\n", "additional_models", "[", "k", "]", "=", "curr_model", "(", "**", "curr_model_cfg", ")", "\n", "\n", "", "model", "=", "models", "[", "\"model\"", "]", "(", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "**", "{", "k", ":", "v", "for", "(", "k", ",", "v", ")", "in", "cfg", ".", "model", ".", "items", "(", ")", "}", ",", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Log total number of parameters", "\n", "count_parameters", "(", "{", "\"model\"", ":", "model", ",", "**", "additional_models", "}", ")", "\n", "return", "model", ",", "additional_models", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_engine": [[233, 291], ["direct.utils.str_to_class.", "cfg.model.model_name.split", "direct.utils.str_to_class", "cfg.model.model_name.split", "logger.error", "sys.exit", "model_name_short.lower", "model_name_short.lower"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["", "def", "setup_engine", "(", "\n", "cfg", ":", "DictConfig", ",", "\n", "device", ":", "str", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "additional_models", ":", "dict", ",", "\n", "forward_operator", ":", "Optional", "[", "Union", "[", "Callable", ",", "object", "]", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Union", "[", "Callable", ",", "object", "]", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Setups engine.\n\n    Parameters\n    ----------\n    cfg: DictConfig\n        Configuration.\n    device: str\n        Type of device.\n    model: torch.nn.Module\n        Model.\n    additional_models: dict\n        Additional models.\n    forward_operator: Callable\n        Forward operator.\n    backward_operator: Callable\n        Backward operator.\n    mixed_precision: bool\n        Whether to enable mixed precision or not. Default: False.\n\n    Returns\n    -------\n    engine\n        Experiment Engine.\n    \"\"\"", "\n", "\n", "# There is a bit of repetition here, but the warning provided is more descriptive", "\n", "# TODO(jt): Try to find a way to combine this with the setup above.", "\n", "model_name_short", "=", "cfg", ".", "model", ".", "model_name", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "engine_name", "=", "cfg", ".", "model", ".", "model_name", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "+", "\"Engine\"", "\n", "\n", "try", ":", "\n", "        ", "engine_class", "=", "str_to_class", "(", "\n", "f\"direct.nn.{model_name_short.lower()}.{model_name_short.lower()}_engine\"", ",", "\n", "engine_name", ",", "\n", ")", "\n", "", "except", "(", "AttributeError", ",", "ModuleNotFoundError", ")", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "f\"Engine does not exist for {cfg.model.model_name} (err = {e}).\"", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "engine", "=", "engine_class", "(", "# noqa", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", "=", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "additional_models", ",", "\n", ")", "\n", "return", "engine", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.extract_names": [[293, 307], ["cfg.copy.copy", "isinstance", "isinstance", "ValueError", "ValueError", "environment.extract_names", "type"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.environment.extract_names"], ["", "def", "extract_names", "(", "cfg", ")", ":", "\n", "    ", "cfg", "=", "cfg", ".", "copy", "(", ")", "\n", "if", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "        ", "if", "\"name\"", "not", "in", "cfg", ":", "\n", "            ", "raise", "ValueError", "(", "\"`name` needs to be present in config.\"", ")", "\n", "", "curr_name", "=", "cfg", "[", "\"name\"", "]", "\n", "\n", "", "elif", "isinstance", "(", "cfg", ",", "ListConfig", ")", ":", "\n", "        ", "return", "[", "extract_names", "(", "v", ")", "for", "v", "in", "cfg", "]", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Expected DictConfig or ListConfig. Got {type(cfg)}.\"", ")", "\n", "\n", "", "return", "curr_name", ",", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_common_environment": [[309, 419], ["logging.getLogger", "direct.utils.communication.synchronize", "direct.utils.io.check_is_valid_url", "omegaconf.OmegaConf.structured", "environment.load_models_into_environment_config", "OmegaConf.load.copy", "environment.setup_logging", "environment.build_operators", "environment.initialize_models_from_config", "environment.setup_engine", "collections.namedtuple", "collections.namedtuple.", "direct.utils.communication.get_local_rank", "experiment_dir.mkdir", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.load", "omegaconf.OmegaConf.merge", "direct.utils.io.read_text_from_url", "logging.getLogger.info", "environment.extract_names", "enumerate", "environment.extract_names", "environment.load_dataset_config", "cfg[].datasets.append", "environment.load_dataset_config"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.synchronize", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_models_into_environment_config", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_logging", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.build_operators", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.initialize_models_from_config", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_engine", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_local_rank", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_text_from_url", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.extract_names", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.extract_names", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_dataset_config", "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.load_dataset_config"], ["", "def", "setup_common_environment", "(", "\n", "run_name", ":", "str", ",", "\n", "base_directory", ":", "pathlib", ".", "Path", ",", "\n", "cfg_pathname", ":", "Union", "[", "pathlib", ".", "Path", ",", "str", "]", ",", "\n", "device", ":", "str", ",", "\n", "machine_rank", ":", "int", ",", "\n", "mixed_precision", ":", "bool", ",", "\n", "debug", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Setup environment.\n\n    Parameters\n    ----------\n    run_name: str\n        Run name.\n    base_directory: pathlib.Path\n        Base directory path.\n    cfg_pathname: Union[pathlib.Path, str]\n        Path or url to configuratio file.\n    device: str\n        Device type.\n    machine_rank: int\n        Machine rank.\n    mixed_precision: bool\n        Whether to enable mixed precision or not. Default: False.\n    debug: bool\n        Whether the debug mode is enabled.\n\n    Returns\n    -------\n    environment\n        Common Environment.\n    \"\"\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "experiment_dir", "=", "base_directory", "/", "run_name", "\n", "if", "communication", ".", "get_local_rank", "(", ")", "==", "0", ":", "\n", "# Want to prevent multiple workers from trying to write a directory", "\n", "# This is required in the logging below", "\n", "        ", "experiment_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "", "communication", ".", "synchronize", "(", ")", "# Ensure folders are in place.", "\n", "\n", "# Load configs from YAML file to check which model needs to be loaded.", "\n", "# Can also be loaded from a URL", "\n", "if", "check_is_valid_url", "(", "cfg_pathname", ")", ":", "\n", "        ", "cfg_from_external_source", "=", "OmegaConf", ".", "create", "(", "read_text_from_url", "(", "cfg_pathname", ")", ")", "\n", "", "else", ":", "\n", "        ", "cfg_from_external_source", "=", "OmegaConf", ".", "load", "(", "cfg_pathname", ")", "\n", "\n", "# Load the default configs to ensure type safety", "\n", "", "cfg", "=", "OmegaConf", ".", "structured", "(", "DefaultConfig", ")", "\n", "\n", "models", ",", "models_config", "=", "load_models_into_environment_config", "(", "cfg_from_external_source", ")", "\n", "cfg", ".", "model", "=", "models_config", ".", "model", "\n", "del", "models_config", "[", "\"model\"", "]", "\n", "cfg", ".", "additional_models", "=", "models_config", "\n", "\n", "# Setup everything for training", "\n", "cfg", ".", "training", "=", "TrainingConfig", "\n", "cfg", ".", "validation", "=", "ValidationConfig", "\n", "cfg", ".", "inference", "=", "InferenceConfig", "\n", "\n", "cfg_from_file_new", "=", "cfg_from_external_source", ".", "copy", "(", ")", "\n", "for", "key", "in", "cfg_from_external_source", ":", "\n", "# TODO: This does not really do a full validation.", "\n", "# BODY: This will be handeled once Hydra is implemented.", "\n", "        ", "if", "key", "in", "[", "\"models\"", ",", "\"additional_models\"", "]", ":", "# Still handled separately", "\n", "            ", "continue", "\n", "\n", "", "if", "key", "in", "[", "\"training\"", ",", "\"validation\"", ",", "\"inference\"", "]", ":", "\n", "            ", "if", "not", "cfg_from_external_source", "[", "key", "]", ":", "\n", "                ", "logger", ".", "info", "(", "f\"key {key} missing in config.\"", ")", "\n", "continue", "\n", "\n", "", "if", "key", "in", "[", "\"training\"", ",", "\"validation\"", "]", ":", "\n", "                ", "dataset_cfg_from_file", "=", "extract_names", "(", "cfg_from_external_source", "[", "key", "]", ".", "datasets", ")", "\n", "for", "idx", ",", "(", "dataset_name", ",", "dataset_config", ")", "in", "enumerate", "(", "dataset_cfg_from_file", ")", ":", "\n", "                    ", "cfg_from_file_new", "[", "key", "]", ".", "datasets", "[", "idx", "]", "=", "dataset_config", "\n", "cfg", "[", "key", "]", ".", "datasets", ".", "append", "(", "load_dataset_config", "(", "dataset_name", ")", ")", "# pylint: disable = E1136", "\n", "", "", "else", ":", "\n", "                ", "dataset_name", ",", "dataset_config", "=", "extract_names", "(", "cfg_from_external_source", "[", "key", "]", ".", "dataset", ")", "\n", "cfg_from_file_new", "[", "key", "]", ".", "dataset", "=", "dataset_config", "\n", "cfg", "[", "key", "]", ".", "dataset", "=", "load_dataset_config", "(", "dataset_name", ")", "# pylint: disable = E1136", "\n", "\n", "", "", "cfg", "[", "key", "]", "=", "OmegaConf", ".", "merge", "(", "cfg", "[", "key", "]", ",", "cfg_from_file_new", "[", "key", "]", ")", "# pylint: disable = E1136, E1137", "\n", "\n", "# Make configuration read only.", "\n", "# TODO(jt): Does not work when indexing config lists.", "\n", "# OmegaConf.set_readonly(cfg, True)", "\n", "", "setup_logging", "(", "machine_rank", ",", "experiment_dir", ",", "run_name", ",", "cfg_pathname", ",", "cfg", ",", "debug", ")", "\n", "forward_operator", ",", "backward_operator", "=", "build_operators", "(", "cfg", ".", "physics", ")", "\n", "\n", "model", ",", "additional_models", "=", "initialize_models_from_config", "(", "cfg", ",", "models", ",", "forward_operator", ",", "backward_operator", ",", "device", ")", "\n", "\n", "engine", "=", "setup_engine", "(", "\n", "cfg", ",", "\n", "device", ",", "\n", "model", ",", "\n", "additional_models", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", ")", "\n", "\n", "environment", "=", "namedtuple", "(", "\n", "\"environment\"", ",", "\n", "[", "\"cfg\"", ",", "\"experiment_dir\"", ",", "\"engine\"", "]", ",", "\n", ")", "\n", "return", "environment", "(", "cfg", ",", "experiment_dir", ",", "engine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_training_environment": [[421, 473], ["environment.setup_common_environment", "logger.info", "direct.utils.communication.is_main_process", "direct.utils.communication.synchronize", "open", "f.write", "omegaconf.OmegaConf.to_yaml"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_common_environment", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.is_main_process", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.synchronize", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "def", "setup_training_environment", "(", "\n", "run_name", ":", "str", ",", "\n", "base_directory", ":", "pathlib", ".", "Path", ",", "\n", "cfg_filename", ":", "Union", "[", "pathlib", ".", "Path", ",", "str", "]", ",", "\n", "device", ":", "str", ",", "\n", "machine_rank", ":", "int", ",", "\n", "mixed_precision", ":", "bool", ",", "\n", "debug", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Setup training environment.\n\n    Parameters\n    ----------\n    run_name: str\n        Run name.\n    base_directory: pathlib.Path\n        Base directory path.\n    cfg_filename: Union[pathlib.Path, str]\n        Path or url to configuratio file.\n    device: str\n        Device type.\n    machine_rank: int\n        Machine rank.\n    mixed_precision: bool\n        Whether to enable mixed precision or not. Default: False.\n    debug: bool\n        Whether the debug mode is enabled.\n\n    Returns\n    -------\n    environment\n        Training Environment.\n    \"\"\"", "\n", "\n", "env", "=", "setup_common_environment", "(", "\n", "run_name", ",", "\n", "base_directory", ",", "\n", "cfg_filename", ",", "\n", "device", ",", "\n", "machine_rank", ",", "\n", "mixed_precision", ",", "\n", "debug", "=", "debug", ",", "\n", ")", "\n", "# Write config file to experiment directory.", "\n", "config_file_in_project_folder", "=", "env", ".", "experiment_dir", "/", "\"config.yaml\"", "\n", "logger", ".", "info", "(", "\"Writing configuration file to: %s\"", ",", "config_file_in_project_folder", ")", "\n", "if", "communication", ".", "is_main_process", "(", ")", ":", "\n", "        ", "with", "open", "(", "config_file_in_project_folder", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "OmegaConf", ".", "to_yaml", "(", "env", ".", "cfg", ")", ")", "\n", "", "", "communication", ".", "synchronize", "(", ")", "\n", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_testing_environment": [[475, 531], ["environment.setup_common_environment", "collections.namedtuple", "collections.namedtuple.", "direct.utils.io.check_is_valid_url", "pathlib.Path().exists", "FileNotFoundError", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_common_environment", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url"], ["", "def", "setup_testing_environment", "(", "\n", "run_name", ":", "str", ",", "\n", "base_directory", ":", "pathlib", ".", "Path", ",", "\n", "device", ":", "str", ",", "\n", "machine_rank", ":", "int", ",", "\n", "mixed_precision", ":", "bool", ",", "\n", "cfg_pathname", ":", "Optional", "[", "Union", "[", "pathlib", ".", "Path", ",", "str", "]", "]", "=", "None", ",", "\n", "debug", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Setup testing environment.\n\n    Parameters\n    ----------\n    run_name: str\n        Run name.\n    base_directory: pathlib.Path\n        Base directory path.\n    device: str\n        Device type.\n    machine_rank: int\n        Machine rank.\n    mixed_precision: bool\n        Whether to enable mixed precision or not. Default: False.\n    cfg_pathname: Union[pathlib.Path, str], optional\n        Path or url to configuration file.\n    debug: bool\n        Whether the debug mode is enabled.\n\n    Returns\n    -------\n    environment\n        Testing Environment.\n    \"\"\"", "\n", "if", "cfg_pathname", "is", "None", ":", "# If None, try to load from base experiment directory", "\n", "        ", "cfg_pathname", "=", "base_directory", "/", "run_name", "/", "\"config.yaml\"", "\n", "\n", "# If not an URL, check if it exists", "\n", "", "if", "not", "check_is_valid_url", "(", "cfg_pathname", ")", ":", "\n", "        ", "if", "not", "pathlib", ".", "Path", "(", "cfg_pathname", ")", ".", "exists", "(", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Config file {cfg_pathname} does not exist.\"", ")", "\n", "\n", "", "", "env", "=", "setup_common_environment", "(", "\n", "run_name", ",", "\n", "base_directory", ",", "\n", "cfg_pathname", ",", "\n", "device", ",", "\n", "machine_rank", ",", "\n", "mixed_precision", ",", "\n", "debug", "=", "debug", ",", "\n", ")", "\n", "\n", "environment", "=", "namedtuple", "(", "\n", "\"environment\"", ",", "\n", "[", "\"cfg\"", ",", "\"engine\"", "]", ",", "\n", ")", "\n", "return", "environment", "(", "env", ".", "cfg", ",", "env", ".", "engine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_inference_environment": [[533, 575], ["environment.setup_testing_environment", "collections.namedtuple", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.environment.setup_testing_environment"], ["", "def", "setup_inference_environment", "(", "\n", "run_name", ":", "str", ",", "\n", "base_directory", ":", "pathlib", ".", "Path", ",", "\n", "device", ":", "str", ",", "\n", "machine_rank", ":", "int", ",", "\n", "mixed_precision", ":", "bool", ",", "\n", "cfg_file", ":", "Optional", "[", "Union", "[", "pathlib", ".", "Path", ",", "str", "]", "]", "=", "None", ",", "\n", "debug", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Setup inference environment.\n\n    Parameters\n    ----------\n    run_name: str\n        Run name.\n    base_directory: pathlib.Path\n        Base directory path.\n    device: str\n        Device type.\n    machine_rank: int\n        Machine rank.\n    mixed_precision: bool\n        Whether to enable mixed precision or not. Default: False.\n    cfg_file: Union[pathlib.Path, str], optional\n        Path or url to configuration file.\n    debug: bool\n        Whether the debug mode is enabled.\n\n    Returns\n    -------\n    environment\n        Inference Environment.\n    \"\"\"", "\n", "env", "=", "setup_testing_environment", "(", "\n", "run_name", ",", "base_directory", ",", "device", ",", "machine_rank", ",", "mixed_precision", ",", "cfg_file", ",", "debug", "=", "debug", "\n", ")", "\n", "\n", "environment", "=", "namedtuple", "(", "\n", "\"environment\"", ",", "\n", "[", "\"cfg\"", ",", "\"engine\"", "]", ",", "\n", ")", "\n", "return", "environment", "(", "env", ".", "cfg", ",", "env", ".", "engine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.writers.write_output_to_h5": [[14, 59], ["enumerate", "output_directory.mkdir", "isinstance", "logger.info", "[].astype", "volume_processing_func", "h5py.File", "f.create_dataset", "len", "volume.numpy"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset"], ["def", "write_output_to_h5", "(", "\n", "output", ":", "Union", "[", "Dict", ",", "DefaultDict", "]", ",", "\n", "output_directory", ":", "pathlib", ".", "Path", ",", "\n", "volume_processing_func", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "output_key", ":", "str", "=", "\"reconstruction\"", ",", "\n", "create_dirs_if_needed", ":", "bool", "=", "True", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Write dictionary with keys filenames and values torch tensors to h5 files.\n\n    Parameters\n    ----------\n    output: dict\n        Dictionary with keys filenames and values torch.Tensor's with shape [depth, num_channels, ...]\n        where num_channels is typically 1 for MRI.\n    output_directory: pathlib.Path\n    volume_processing_func: callable\n        Function which postprocesses the volume array before saving.\n    output_key: str\n        Name of key to save the output to.\n    create_dirs_if_needed: bool\n        If true, the output directory and all its parents will be created.\n\n    Notes\n    -----\n    Currently only num_channels = 1 is supported. If you run this function with more channels the first one\n    will be used.\n    \"\"\"", "\n", "if", "create_dirs_if_needed", ":", "\n", "# Create output directory", "\n", "        ", "output_directory", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "", "for", "idx", ",", "(", "volume", ",", "_", ",", "filename", ")", "in", "enumerate", "(", "output", ")", ":", "\n", "# The output has shape (slice, 1, height, width)", "\n", "        ", "if", "isinstance", "(", "filename", ",", "pathlib", ".", "PosixPath", ")", ":", "\n", "            ", "filename", "=", "filename", ".", "name", "\n", "\n", "", "logger", ".", "info", "(", "f\"({idx + 1}/{len(output)}): Writing {output_directory / filename}...\"", ")", "\n", "\n", "reconstruction", "=", "volume", ".", "numpy", "(", ")", "[", ":", ",", "0", ",", "...", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "if", "volume_processing_func", ":", "\n", "            ", "reconstruction", "=", "volume_processing_func", "(", "reconstruction", ")", "\n", "\n", "", "with", "h5py", ".", "File", "(", "output_directory", "/", "filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "create_dataset", "(", "output_key", ",", "data", "=", "reconstruction", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.models.fix_state_dict_module_prefix": [[6, 26], ["[].startswith", "collections.OrderedDict", "enumerate", "state_dict.items", "list", "state_dict.keys"], "function", ["None"], ["def", "fix_state_dict_module_prefix", "(", "state_dict", ")", ":", "\n", "    ", "\"\"\"If models are saved after being wrapped in e.g. DataParallel, the keys of the state dict are prefixed with\n    `module.`. This function removes this prefix.\n\n    Parameters\n    ----------\n    state_dict: dict\n        state_dict of a network module\n    Returns\n    -------\n    dict\n    \"\"\"", "\n", "if", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "[", "0", "]", ".", "startswith", "(", "\"module.\"", ")", ":", "\n", "        ", "new_ordered_dict", "=", "OrderedDict", "(", ")", "\n", "for", "_", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "state_dict", ".", "items", "(", ")", ")", ":", "\n", "            ", "name", "=", "k", "[", "7", ":", "]", "\n", "new_ordered_dict", "[", "name", "]", "=", "v", "\n", "", "state_dict", "=", "new_ordered_dict", "\n", "\n", "", "return", "state_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.logging.setup": [[10, 59], ["logging.captureWarnings", "isinstance", "logging.getLogger", "logging.getLogger.setLevel", "logging.Formatter", "logging.warning", "ValueError", "getattr", "name.startswith", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger().setLevel", "logging.getLogger"], "function", ["None"], ["def", "setup", "(", "\n", "use_stdout", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "filename", ":", "Optional", "[", "PathLike", "]", "=", "None", ",", "\n", "log_level", ":", "Union", "[", "int", ",", "str", "]", "=", "\"INFO\"", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Setup logging for DIRECT.\n\n    Parameters\n    ----------\n    use_stdout: bool\n        Write output to standard out.\n    filename: PathLike\n        Filename to write log to.\n    log_level: str\n        Logging level as in the `python.logging` library.\n\n    Returns\n    -------\n    None\n    \"\"\"", "\n", "if", "log_level", "not", "in", "[", "\"DEBUG\"", ",", "\"INFO\"", ",", "\"WARNING\"", ",", "\"ERROR\"", ",", "\"EXCEPTION\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unexpected log level got {log_level}.\"", ")", "\n", "\n", "", "logging", ".", "captureWarnings", "(", "True", ")", "\n", "if", "isinstance", "(", "log_level", ",", "str", ")", ":", "\n", "        ", "log_level", "=", "getattr", "(", "logging", ",", "log_level", ")", "\n", "\n", "", "root", "=", "logging", ".", "getLogger", "(", ")", "\n", "root", ".", "setLevel", "(", "log_level", ")", "\n", "\n", "for", "name", "in", "logging", ".", "root", ".", "manager", ".", "loggerDict", ":", "# pylint: disable = E1101 # type: ignore", "\n", "        ", "if", "name", ".", "startswith", "(", "\"torch\"", ")", ":", "\n", "            ", "logging", ".", "getLogger", "(", "name", ")", ".", "setLevel", "(", "\"WARNING\"", ")", "\n", "\n", "", "", "formatter", "=", "logging", ".", "Formatter", "(", "\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\"", ")", "\n", "\n", "if", "use_stdout", ":", "\n", "        ", "handler", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "handler", ".", "setLevel", "(", "log_level", ")", "\n", "handler", ".", "setFormatter", "(", "formatter", ")", "\n", "root", ".", "addHandler", "(", "handler", ")", "\n", "\n", "", "if", "filename", "is", "not", "None", ":", "\n", "        ", "fh", "=", "logging", ".", "FileHandler", "(", "filename", ")", "\n", "fh", ".", "setLevel", "(", "log_level", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "root", ".", "addHandler", "(", "fh", ")", "\n", "\n", "", "logging", ".", "warning", "(", "\"DIRECT is not intended for clinical use.\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventWriter.write": [[44, 46], ["None"], "methods", ["None"], ["def", "write", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventWriter.close": [[47, 49], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.JSONWriter.__init__": [[95, 110], ["open"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "json_file", ":", "Union", "[", "Path", ",", "str", "]", ",", "window_size", ":", "int", "=", "2", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        json_file: Union[Path, str]\n            Path to the JSON file. Data will be appended if it exists\n        window_size: int\n            Window size of median smoothing for variables for which `smoothing_hint` is True.\n        validation: bool\n            If true, will only log keys starting with val_\n        \"\"\"", "\n", "\n", "self", ".", "_file_handle", "=", "open", "(", "json_file", ",", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.JSONWriter.write": [[111, 121], ["events.get_event_storage", "to_save.update", "events.JSONWriter._file_handle.write", "events.JSONWriter._file_handle.flush", "get_event_storage.latest_with_smoothing_hint", "os.fsync", "json.dumps", "events.JSONWriter._file_handle.fileno"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.get_event_storage", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.latest_with_smoothing_hint"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "to_save", "=", "{", "\"iteration\"", ":", "storage", ".", "iter", "}", "\n", "to_save", ".", "update", "(", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ")", "\n", "self", ".", "_file_handle", ".", "write", "(", "json", ".", "dumps", "(", "to_save", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", ")", "\n", "self", ".", "_file_handle", ".", "flush", "(", ")", "\n", "try", ":", "\n", "            ", "os", ".", "fsync", "(", "self", ".", "_file_handle", ".", "fileno", "(", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.JSONWriter.close": [[122, 124], ["events.JSONWriter._file_handle.close"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "_file_handle", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.__init__": [[129, 144], ["SummaryWriter", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "log_dir", ":", "Union", "[", "Path", ",", "str", "]", ",", "window_size", ":", "int", "=", "20", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        log_dir: Union[Path, str]\n            The directory to save the output events.\n        window_size: int\n            The scalars will be median-smoothed by this window size.\n        kwargs: dict\n            other arguments passed to `torch.utils.tensorboard.SummaryWriter(...)`\n        \"\"\"", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "from", "torch", ".", "utils", ".", "tensorboard", "import", "SummaryWriter", "\n", "\n", "self", ".", "_writer", "=", "SummaryWriter", "(", "str", "(", "log_dir", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.write": [[145, 154], ["events.get_event_storage", "get_event_storage.latest_with_smoothing_hint().items", "events.TensorboardWriter._writer.add_scalar", "len", "get_event_storage.clear_images", "get_event_storage.latest_with_smoothing_hint", "events.TensorboardWriter._writer.add_image"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.get_event_storage", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalar", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.clear_images", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.latest_with_smoothing_hint", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_image"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "for", "k", ",", "v", "in", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "_writer", ".", "add_scalar", "(", "k", ",", "v", ",", "storage", ".", "iter", ")", "\n", "\n", "", "if", "len", "(", "storage", ".", "vis_data", ")", ">=", "1", ":", "\n", "            ", "for", "img_name", ",", "img", ",", "step_num", "in", "storage", ".", "vis_data", ":", "\n", "                ", "self", ".", "_writer", ".", "add_image", "(", "img_name", ",", "img", ",", "step_num", ")", "\n", "", "storage", ".", "clear_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close": [[155, 158], ["hasattr", "events.TensorboardWriter._writer.close"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "\"_writer\"", ")", ":", "# doesn't exist when the code fails at import", "\n", "            ", "self", ".", "_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.__init__": [[167, 176], ["logging.getLogger", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_iter", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            max_iter (int): the maximum number of iterations to train.\n                Used to compute ETA.\n        \"\"\"", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "self", ".", "_max_iter", "=", "max_iter", "\n", "self", ".", "_last_write", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write": [[177, 228], ["events.get_event_storage", "torch.cuda.is_available", "events.CommonMetricPrinter.logger.info", "get_event_storage.history().avg", "get_event_storage.history().global_avg", "get_event_storage.add_scalar", "str", "get_event_storage.history().median", "datetime.timedelta", "get_event_storage.history", "get_event_storage.history", "str", "time.perf_counter", "get_event_storage.history().latest", "torch.cuda.max_memory_allocated", "get_event_storage.histories().items", "get_event_storage.history", "int", "datetime.timedelta", "v.median", "time.perf_counter", "get_event_storage.history", "get_event_storage.histories", "int"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.get_event_storage", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.avg", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.global_avg", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalar", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.median", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.latest", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.median", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.histories"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "iteration", "=", "storage", ".", "iter", "\n", "\n", "try", ":", "\n", "            ", "data_time", "=", "storage", ".", "history", "(", "\"data_time\"", ")", ".", "avg", "(", "20", ")", "\n", "", "except", "KeyError", ":", "\n", "# they may not exist in the first few iterations (due to warmup)", "\n", "# or when SimpleTrainer is not used", "\n", "            ", "data_time", "=", "None", "\n", "\n", "", "eta_string", "=", "\"N/A\"", "\n", "try", ":", "\n", "            ", "iter_time", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "global_avg", "(", ")", "\n", "eta_seconds", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "median", "(", "1000", ")", "*", "(", "self", ".", "_max_iter", "-", "iteration", ")", "\n", "storage", ".", "add_scalar", "(", "\"eta_seconds\"", ",", "eta_seconds", ",", "smoothing_hint", "=", "False", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "iter_time", "=", "None", "\n", "# estimate eta on our own - more noisy", "\n", "if", "self", ".", "_last_write", "is", "not", "None", ":", "\n", "                ", "estimate_iter_time", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "_last_write", "[", "1", "]", ")", "/", "(", "iteration", "-", "self", ".", "_last_write", "[", "0", "]", ")", "\n", "eta_seconds", "=", "estimate_iter_time", "*", "(", "self", ".", "_max_iter", "-", "iteration", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "self", ".", "_last_write", "=", "(", "iteration", ",", "time", ".", "perf_counter", "(", ")", ")", "\n", "\n", "", "try", ":", "\n", "            ", "lr", "=", "f\"{storage.history('lr').latest():.6f}\"", "\n", "", "except", "KeyError", ":", "\n", "            ", "lr", "=", "\"N/A\"", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "max_mem_mb", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "1024.0", "/", "1024.0", "\n", "", "else", ":", "\n", "            ", "max_mem_mb", "=", "None", "\n", "\n", "", "metrics_and_losses_string", "=", "\"  \"", ".", "join", "(", "\n", "[", "\n", "f\"{k}: {v.median(20):.6f}\"", "\n", "for", "k", ",", "v", "in", "storage", ".", "histories", "(", ")", ".", "items", "(", ")", "\n", "if", "(", "\"loss\"", "in", "k", "or", "\"metric\"", "in", "k", "or", "\"reg\"", "in", "k", ")", "\n", "]", "\n", ")", "\n", "\n", "time_string", "=", "f\"time: {iter_time:.4f}  \"", "if", "iter_time", "is", "not", "None", "else", "\"\"", "\n", "data_time_string", "=", "f\"data_time: {data_time:.4f}  \"", "if", "data_time", "is", "not", "None", "else", "\"\"", "\n", "memory_string", "=", "f\"max_mem: {max_mem_mb:.0f}M\"", "if", "max_mem_mb", "is", "not", "None", "else", "\"\"", "\n", "\n", "# no logger here, the code already saves the iterations to json.", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f\"eta: {eta_string}  iter: {iteration}  \"", "\n", "f\"{metrics_and_losses_string}  {time_string}{data_time_string}lr: {lr}  {memory_string}\"", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.__init__": [[238, 251], ["collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "start_iter", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        start_iter: int\n            The index to start with.\n        \"\"\"", "\n", "self", ".", "_history", "=", "defaultdict", "(", "HistoryBuffer", ")", "\n", "self", ".", "_smoothing_hints", "=", "{", "}", "\n", "self", ".", "_latest_scalars", "=", "{", "}", "\n", "self", ".", "_iter", "=", "start_iter", "\n", "self", ".", "_current_prefix", "=", "\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_image": [[252, 263], ["events.EventStorage._vis_data.append"], "methods", ["None"], ["", "def", "add_image", "(", "self", ",", "img_name", ",", "img_tensor", ")", ":", "\n", "        ", "\"\"\"Add an `img_tensor` to the `_vis_data` associated with `img_name`.\n\n        Parameters\n        ----------\n        img_name: str\n            The name of the input_image to put into tensorboard.\n        img_tensor: torch.Tensor or numpy.array\n            An `uint8` or `float` Tensor of shape `[channel, height, width]` where `channel` is 3. The input_image format should be RGB. The elements in img_tensor can either have values in [0, 1] (float32) or [0, 255] (uint8). The `img_tensor` will be visualized in tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", ".", "append", "(", "(", "img_name", ",", "img_tensor", ",", "self", ".", "_iter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.clear_images": [[264, 270], ["None"], "methods", ["None"], ["", "def", "clear_images", "(", "self", ")", ":", "\n", "        ", "\"\"\"Delete all the stored images for visualization.\n\n        This should be called after images are written to tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalar": [[271, 296], ["float", "history.update", "events.EventStorage._smoothing_hints.get", "AssertionError"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "add_scalar", "(", "self", ",", "name", ",", "value", ",", "smoothing_hint", "=", "True", ")", ":", "\n", "        ", "\"\"\"Add a scalar `value` to the `HistoryBuffer` associated with `name`.\n\n        Parameters\n        ----------\n        name: str\n        value: float\n        smoothing_hint: bool\n            A 'hint' on whether this scalar is noisy and should be smoothed when logged. The hint will be accessible through `EventStorage.smoothing_hints`. A writer may ignore the hint and apply custom smoothing rule. It defaults to True because most scalars we save need to be smoothed to provide any useful signal.\n\n        Returns\n        -------\n        \"\"\"", "\n", "name", "=", "self", ".", "_current_prefix", "+", "name", "\n", "history", "=", "self", ".", "_history", "[", "name", "]", "\n", "value", "=", "float", "(", "value", ")", "\n", "history", ".", "update", "(", "value", ",", "self", ".", "_iter", ")", "\n", "self", ".", "_latest_scalars", "[", "name", "]", "=", "value", "\n", "\n", "existing_hint", "=", "self", ".", "_smoothing_hints", ".", "get", "(", "name", ")", "\n", "if", "existing_hint", "is", "not", "None", ":", "\n", "            ", "if", "existing_hint", "!=", "smoothing_hint", ":", "\n", "                ", "raise", "AssertionError", "(", "f\"Scalar {name} was put with a different smoothing_hint!\"", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_smoothing_hints", "[", "name", "]", "=", "smoothing_hint", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalars": [[297, 306], ["kwargs.items", "events.EventStorage.add_scalar"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_scalar"], ["", "", "def", "add_scalars", "(", "self", ",", "*", ",", "smoothing_hint", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Put multiple scalars from keyword arguments.\n\n        Examples\n        --------\n            storage.add_scalars(loss=my_loss, accuracy=my_accuracy, smoothing_hint=True)\n        \"\"\"", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "add_scalar", "(", "k", ",", "v", ",", "smoothing_hint", "=", "smoothing_hint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.add_graph": [[307, 318], ["events.EventStorage._vis_data.append"], "methods", ["None"], ["", "", "def", "add_graph", "(", "self", ",", "img_name", ",", "img_tensor", ")", ":", "\n", "        ", "\"\"\"Add an `img_tensor` to the `_vis_data` associated with `img_name`.\n\n        Parameters\n        ----------\n        img_name: str\n            The name of the input_image to put into tensorboard.\n        img_tensor: torch.Tensor or numpy.array\n            An `uint8` or `float` Tensor of shape `[channel, height, width]` where `channel` is 3. The input_image format should be RGB. The elements in img_tensor can either have values in [0, 1] (float32) or [0, 255] (uint8). The `img_tensor` will be visualized in tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", ".", "append", "(", "(", "img_name", ",", "img_tensor", ",", "self", ".", "_iter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.history": [[319, 328], ["events.EventStorage._history.get", "KeyError"], "methods", ["None"], ["", "def", "history", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            HistoryBuffer: the scalar history for name\n        \"\"\"", "\n", "ret", "=", "self", ".", "_history", ".", "get", "(", "name", ",", "None", ")", "\n", "if", "ret", "is", "None", ":", "\n", "            ", "raise", "KeyError", "(", "f\"No history metric available for {name}!\"", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.histories": [[329, 335], ["None"], "methods", ["None"], ["", "def", "histories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> HistoryBuffer]: the HistoryBuffer for all scalars\n        \"\"\"", "\n", "return", "self", ".", "_history", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.latest": [[336, 342], ["None"], "methods", ["None"], ["", "def", "latest", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> number]: the scalars that's added in the current iteration.\n        \"\"\"", "\n", "return", "self", ".", "_latest_scalars", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.latest_with_smoothing_hint": [[343, 353], ["events.EventStorage._latest_scalars.items", "events.EventStorage._history[].median"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.median"], ["", "def", "latest_with_smoothing_hint", "(", "self", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "\"\"\"Similar to :meth:`latest`, but the returned values are either the un-smoothed original latest value, or a\n        median of the given window_size, depend on whether the smoothing_hint is True.\n\n        This provides a default behavior that other writers can use.\n        \"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "_latest_scalars", ".", "items", "(", ")", ":", "\n", "            ", "result", "[", "k", "]", "=", "self", ".", "_history", "[", "k", "]", ".", "median", "(", "window_size", ")", "if", "self", ".", "_smoothing_hints", "[", "k", "]", "else", "v", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.smoothing_hints": [[354, 361], ["None"], "methods", ["None"], ["", "def", "smoothing_hints", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> bool]: the user-provided hint on whether the scalar\n                is noisy and needs smoothing.\n        \"\"\"", "\n", "return", "self", ".", "_smoothing_hints", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.step": [[362, 369], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"User should call this function at the beginning of each iteration, to notify the storage of the start of a\n        new iteration.\n\n        The storage will then be able to associate the new data with the correct iteration number.\n        \"\"\"", "\n", "self", ".", "_iter", "+=", "1", "\n", "# TODO: This clears validation metrics.", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.vis_data": [[372, 375], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vis_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_vis_data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.iter": [[376, 379], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iter", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.__enter__": [[380, 383], ["_CURRENT_STORAGE_STACK.append"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "_CURRENT_STORAGE_STACK", ".", "append", "(", "self", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.__exit__": [[384, 388], ["_CURRENT_STORAGE_STACK.pop"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "if", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "!=", "self", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "_CURRENT_STORAGE_STACK", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.name_scope": [[389, 400], ["name.rstrip"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "name_scope", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Yields:\n            A context within which all the events added to this storage\n            will be prefixed by the name scope.\n        \"\"\"", "\n", "old_prefix", "=", "self", ".", "_current_prefix", "\n", "self", ".", "_current_prefix", "=", "name", ".", "rstrip", "(", "\"/\"", ")", "+", "\"/\"", "\n", "yield", "\n", "self", ".", "_current_prefix", "=", "old_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.__init__": [[406, 417], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_length", ":", "int", "=", "1000000", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Args:\n            max_length: maximal number of values that can be stored in the\n                buffer. When the capacity of the buffer is exhausted, old\n                values will be removed.\n        \"\"\"", "\n", "self", ".", "_max_length", ":", "int", "=", "max_length", "\n", "self", ".", "_data", ":", "List", "[", "Tuple", "[", "float", ",", "float", "]", "]", "=", "[", "]", "# (value, iteration) pairs", "\n", "self", ".", "_count", ":", "int", "=", "0", "\n", "self", ".", "_global_avg", ":", "float", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update": [[418, 431], ["events.HistoryBuffer._data.append", "len", "events.HistoryBuffer._data.pop"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ":", "float", ",", "iteration", ":", "Optional", "[", "float", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"Add a new scalar value produced at certain iteration.\n\n        If the length of the buffer exceeds self._max_length, the oldest element will be removed from the buffer.\n        \"\"\"", "\n", "if", "iteration", "is", "None", ":", "\n", "            ", "iteration", "=", "self", ".", "_count", "\n", "", "if", "len", "(", "self", ".", "_data", ")", "==", "self", ".", "_max_length", ":", "\n", "            ", "self", ".", "_data", ".", "pop", "(", "0", ")", "\n", "", "self", ".", "_data", ".", "append", "(", "(", "value", ",", "iteration", ")", ")", "\n", "\n", "self", ".", "_count", "+=", "1", "\n", "self", ".", "_global_avg", "+=", "(", "value", "-", "self", ".", "_global_avg", ")", "/", "self", ".", "_count", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.latest": [[432, 435], ["None"], "methods", ["None"], ["", "def", "latest", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"Return the latest scalar value added to the buffer.\"\"\"", "\n", "return", "self", ".", "_data", "[", "-", "1", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.median": [[436, 439], ["numpy.median"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.median"], ["", "def", "median", "(", "self", ",", "window_size", ":", "int", ")", "->", "float", ":", "\n", "        ", "\"\"\"Return the median of the latest `window_size` values in the buffer.\"\"\"", "\n", "return", "np", ".", "median", "(", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "_data", "[", "-", "window_size", ":", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.avg": [[440, 443], ["float", "numpy.mean"], "methods", ["None"], ["", "def", "avg", "(", "self", ",", "window_size", ":", "int", ")", "->", "float", ":", "\n", "        ", "\"\"\"Return the mean of the latest `window_size` values in the buffer.\"\"\"", "\n", "return", "float", "(", "np", ".", "mean", "(", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "_data", "[", "-", "window_size", ":", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.global_avg": [[444, 450], ["None"], "methods", ["None"], ["", "def", "global_avg", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"Return the mean of all the elements in the buffer.\n\n        Note that this includes those getting removed due to limited buffer storage.\n        \"\"\"", "\n", "return", "self", ".", "_global_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values": [[451, 457], ["None"], "methods", ["None"], ["", "def", "values", "(", "self", ")", "->", "List", "[", "Tuple", "[", "float", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns:\n            list[(number, iteration)]: content of the current buffer.\n        \"\"\"", "\n", "return", "self", ".", "_data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.events.get_event_storage": [[30, 39], ["len", "ValueError"], "function", ["None"], ["def", "get_event_storage", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The :class:`EventStorage` object that's currently being used.\n        Throws an error if no :class`EventStorage` is currently enabled.\n    \"\"\"", "\n", "if", "len", "(", "_CURRENT_STORAGE_STACK", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"get_event_storage() has to be called inside a 'with EventStorage(...)' context!\"", ")", "\n", "", "return", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.ArrayEncoder.default": [[65, 77], ["isinstance", "isinstance", "json.JSONEncoder.default", "obj.numpy.numpy.numpy", "obj.numpy.numpy.tolist", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.ArrayEncoder.default"], ["    ", "def", "default", "(", "self", ",", "obj", ")", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "obj", "=", "obj", ".", "numpy", "(", ")", "\n", "\n", "", "if", "isinstance", "(", "obj", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "if", "obj", ".", "size", ">", "10e4", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "\"Trying to JSON serialize a very large array of size {obj.size}. \"", "\n", "\"Reconsider doing this differently\"", "\n", ")", "\n", "", "return", "obj", ".", "tolist", "(", ")", "\n", "", "return", "json", ".", "JSONEncoder", ".", "default", "(", "self", ",", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_json": [[43, 61], ["isinstance", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load"], ["def", "read_json", "(", "fn", ":", "Union", "[", "Dict", ",", "str", ",", "pathlib", ".", "Path", "]", ")", "->", "Dict", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Read file and output dict, or take dict and output dict.\n\n    Parameters\n    ----------\n    fn: Union[Dict, str, pathlib.Path]\n\n\n    Returns\n    -------\n    dict\n    \"\"\"", "\n", "if", "isinstance", "(", "fn", ",", "dict", ")", ":", "\n", "        ", "return", "fn", "\n", "\n", "", "with", "open", "(", "fn", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.write_json": [[79, 94], ["open", "json.dump"], "function", ["None"], ["", "", "def", "write_json", "(", "fn", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ",", "data", ":", "Dict", ",", "indent", "=", "2", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Write dict data to fn.\n\n    Parameters\n    ----------\n    fn: Path or str\n    data: dict\n    indent: int\n\n    Returns\n    -------\n    None\n    \"\"\"", "\n", "with", "open", "(", "fn", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "data", ",", "f", ",", "indent", "=", "indent", ",", "cls", "=", "ArrayEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_list": [[96, 118], ["isinstance", "isinstance", "io.check_is_valid_url", "io.read_text_from_url", "_.strip", "open", "f.readlines", "_.strip", "f.readlines.split", "_.startswith", "_.startswith"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_text_from_url"], ["", "", "def", "read_list", "(", "fn", ":", "Union", "[", "List", ",", "str", ",", "pathlib", ".", "Path", "]", ")", "->", "List", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Read file and output list, or take list and output list. Can read data from URLs.\n\n    Parameters\n    ----------\n    fn: Union[[list, str, pathlib.Path]]\n        Input text file or list, or a URL to a text file.\n\n    Returns\n    -------\n    list\n        Text file read line by line.\n    \"\"\"", "\n", "if", "isinstance", "(", "fn", ",", "(", "pathlib", ".", "Path", ",", "str", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "fn", ",", "str", ")", "and", "check_is_valid_url", "(", "fn", ")", ":", "\n", "            ", "data", "=", "read_text_from_url", "(", "fn", ")", "\n", "return", "[", "_", ".", "strip", "(", ")", "for", "_", "in", "data", ".", "split", "(", "\"\\n\"", ")", "if", "not", "_", ".", "startswith", "(", "\"#\"", ")", "and", "_", "!=", "\"\"", "]", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "fn", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "data", "=", "f", ".", "readlines", "(", ")", "\n", "", "return", "[", "_", ".", "strip", "(", ")", "for", "_", "in", "data", "if", "not", "_", ".", "startswith", "(", "\"#\"", ")", "]", "\n", "", "", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.write_list": [[120, 135], ["open", "f.write"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "def", "write_list", "(", "fn", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ",", "data", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Write list line by line to file.\n\n    Parameters\n    ----------\n    fn: Union[[list, str, pathlib.Path]]\n        Input text file or list\n    data: list or tuple\n    Returns\n    -------\n    None\n    \"\"\"", "\n", "with", "open", "(", "fn", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "data", ":", "\n", "            ", "f", ".", "write", "(", "f\"{line}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io._urlretrieve": [[137, 146], ["open", "urllib.request.urlopen", "urllib.request.urlopen", "urllib.request.urlopen", "urllib.request.Request", "urllib.request.Request", "urllib.request.Request", "tqdm.auto.tqdm", "iter", "pbar.update", "fh.write", "response.read"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "", "", "def", "_urlretrieve", "(", "url", ":", "str", ",", "filename", ":", "str", ",", "chunk_size", ":", "int", "=", "1024", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "fh", ":", "\n", "        ", "with", "urllib", ".", "request", ".", "urlopen", "(", "urllib", ".", "request", ".", "Request", "(", "url", ",", "headers", "=", "{", "\"User-Agent\"", ":", "USER_AGENT", "}", ")", ")", "as", "response", ":", "\n", "            ", "with", "tqdm", "(", "total", "=", "response", ".", "length", ")", "as", "pbar", ":", "\n", "                ", "for", "chunk", "in", "iter", "(", "lambda", ":", "response", ".", "read", "(", "chunk_size", ")", ",", "\"\"", ")", ":", "\n", "                    ", "if", "not", "chunk", ":", "\n", "                        ", "break", "\n", "", "pbar", ".", "update", "(", "chunk_size", ")", "\n", "fh", ".", "write", "(", "chunk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.gen_bar_updater": [[148, 158], ["tqdm.auto.tqdm", "tqdm.auto.tqdm.update"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "", "", "", "", "def", "gen_bar_updater", "(", ")", "->", "Callable", "[", "[", "int", ",", "int", ",", "int", "]", ",", "None", "]", ":", "# pragma: no cover", "\n", "    ", "pbar", "=", "tqdm", "(", "total", "=", "None", ")", "\n", "\n", "def", "bar_update", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "        ", "if", "pbar", ".", "total", "is", "None", "and", "total_size", ":", "\n", "            ", "pbar", ".", "total", "=", "total_size", "\n", "", "progress_bytes", "=", "count", "*", "block_size", "\n", "pbar", ".", "update", "(", "progress_bytes", "-", "pbar", ".", "n", ")", "\n", "\n", "", "return", "bar_update", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.calculate_md5": [[160, 166], ["hashlib.md5", "hashlib.md5.hexdigest", "open", "iter", "hashlib.md5.update", "f.read"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "calculate_md5", "(", "fpath", ":", "str", ",", "chunk_size", ":", "int", "=", "1024", "*", "1024", ")", "->", "str", ":", "# pragma: no cover", "\n", "    ", "md5", "=", "hashlib", ".", "md5", "(", ")", "\n", "with", "open", "(", "fpath", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "for", "chunk", "in", "iter", "(", "lambda", ":", "f", ".", "read", "(", "chunk_size", ")", ",", "b\"\"", ")", ":", "\n", "            ", "md5", ".", "update", "(", "chunk", ")", "\n", "", "", "return", "md5", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_md5": [[168, 170], ["io.calculate_md5"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.calculate_md5"], ["", "def", "check_md5", "(", "fpath", ":", "str", ",", "md5", ":", "str", ",", "**", "kwargs", ":", "Any", ")", "->", "bool", ":", "# pragma: no cover", "\n", "    ", "return", "md5", "==", "calculate_md5", "(", "fpath", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_integrity": [[172, 178], ["io.check_md5", "os.path.isfile", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_md5"], ["", "def", "check_integrity", "(", "fpath", ":", "str", ",", "md5", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "bool", ":", "# pragma: no cover", "\n", "    ", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "md5", "is", "None", ":", "\n", "        ", "return", "True", "\n", "", "return", "check_md5", "(", "fpath", ",", "md5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io._get_redirect_url": [[180, 193], ["range", "RecursionError", "urllib.request.urlopen", "urllib.request.urlopen", "urllib.request.urlopen", "urllib.request.Request", "urllib.request.Request", "urllib.request.Request"], "function", ["None"], ["", "def", "_get_redirect_url", "(", "url", ":", "str", ",", "max_hops", ":", "int", "=", "3", ")", "->", "str", ":", "# pragma: no cover", "\n", "    ", "initial_url", "=", "url", "\n", "headers", "=", "{", "\"Method\"", ":", "\"HEAD\"", ",", "\"User-Agent\"", ":", "USER_AGENT", "}", "\n", "\n", "for", "_", "in", "range", "(", "max_hops", "+", "1", ")", ":", "\n", "        ", "with", "urllib", ".", "request", ".", "urlopen", "(", "urllib", ".", "request", ".", "Request", "(", "url", ",", "headers", "=", "headers", ")", ")", "as", "response", ":", "\n", "            ", "if", "response", ".", "url", "==", "url", "or", "response", ".", "url", "is", "None", ":", "\n", "                ", "return", "url", "\n", "\n", "", "url", "=", "response", ".", "url", "\n", "", "", "else", ":", "\n", "        ", "raise", "RecursionError", "(", "\n", "f\"Request to {initial_url} exceeded {max_hops} redirects. The last redirect points to {url}.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.download_url": [[196, 244], ["os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "io.check_integrity", "io._get_redirect_url", "os.path.basename", "os.path.basename", "logger.info", "logger.info", "io._urlretrieve", "io.check_integrity", "RuntimeError", "url.replace.replace", "logger.info", "io._urlretrieve"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_integrity", "home.repos.pwc.inspect_result.directgroup_direct.utils.io._get_redirect_url", "home.repos.pwc.inspect_result.directgroup_direct.utils.io._urlretrieve", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_integrity", "home.repos.pwc.inspect_result.directgroup_direct.utils.io._urlretrieve"], ["", "", "def", "download_url", "(", "\n", "url", ":", "str", ",", "root", ":", "PathOrString", ",", "filename", ":", "Optional", "[", "str", "]", "=", "None", ",", "md5", ":", "Optional", "[", "str", "]", "=", "None", ",", "max_redirect_hops", ":", "int", "=", "3", "\n", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Download a file from a url and place it in root.\n\n    Parameters\n    ----------\n    url: str\n        URL to download file from\n    root: PathOrString\n        Directory to place downloaded file in\n    filename: str, optional:\n        Name to save the file under. If None, use the basename of the URL\n    md5: str, optional\n        MD5 checksum of the download. If None, do not check\n    max_redirect_hops: int, optional)\n        Maximum number of redirect hops allowed\n    \"\"\"", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "if", "not", "filename", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "\n", "os", ".", "makedirs", "(", "root", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# check if file is already present locally", "\n", "if", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using downloaded and verified file: \"", "+", "fpath", ")", "\n", "return", "\n", "\n", "# expand redirect chain if needed", "\n", "", "url", "=", "_get_redirect_url", "(", "url", ",", "max_hops", "=", "max_redirect_hops", ")", "\n", "\n", "# download the file", "\n", "try", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Downloading {url} to {fpath}\"", ")", "\n", "_urlretrieve", "(", "url", ",", "fpath", ")", "\n", "", "except", "(", "urllib", ".", "error", ".", "URLError", ",", "OSError", ")", "as", "e", ":", "# type: ignore[attr-defined]", "\n", "        ", "if", "url", "[", ":", "5", "]", "==", "\"https\"", ":", "\n", "            ", "url", "=", "url", ".", "replace", "(", "\"https:\"", ",", "\"http:\"", ")", "\n", "logger", ".", "info", "(", "f\"Failed download. Trying https -> http instead. Downloading {url} to {fpath}\"", ")", "\n", "_urlretrieve", "(", "url", ",", "fpath", ")", "\n", "", "else", ":", "\n", "            ", "raise", "e", "\n", "\n", "# check integrity of downloaded file", "\n", "", "", "if", "not", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"File not found or corrupted.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io._extract_tar": [[246, 249], ["tarfile.open", "tar.extractall"], "function", ["None"], ["", "", "def", "_extract_tar", "(", "from_path", ":", "str", ",", "to_path", ":", "str", ",", "compression", ":", "Optional", "[", "str", "]", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "with", "tarfile", ".", "open", "(", "from_path", ",", "f\"r:{compression[1:]}\"", "if", "compression", "else", "\"r\"", ")", "as", "tar", ":", "\n", "        ", "tar", ".", "extractall", "(", "to_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io._extract_zip": [[257, 262], ["zipfile.ZipFile", "zip_file_handler.extractall"], "function", ["None"], ["def", "_extract_zip", "(", "from_path", ":", "str", ",", "to_path", ":", "str", ",", "compression", ":", "Optional", "[", "str", "]", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "with", "zipfile", ".", "ZipFile", "(", "\n", "from_path", ",", "\"r\"", ",", "compression", "=", "_ZIP_COMPRESSION_MAP", "[", "compression", "]", "if", "compression", "else", "zipfile", ".", "ZIP_STORED", "\n", ")", "as", "zip_file_handler", ":", "\n", "        ", "zip_file_handler", ".", "extractall", "(", "to_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io._detect_file_type": [[280, 321], ["sorted", "RuntimeError", "pathlib.Path", "RuntimeError", "len", "set", "set", "set"], "function", ["None"], ["def", "_detect_file_type", "(", "file", ":", "str", ")", "->", "Tuple", "[", "str", ",", "Optional", "[", "str", "]", ",", "Optional", "[", "str", "]", "]", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Detect the archive type and/or compression of a file.\n\n    Args:\n        file (str): the filename\n\n    Returns:\n        (tuple): tuple of suffix, archive type, and compression\n\n    Raises:\n        RuntimeError: if file has no suffix or suffix is not supported\n    \"\"\"", "\n", "suffixes", "=", "pathlib", ".", "Path", "(", "file", ")", ".", "suffixes", "\n", "if", "not", "suffixes", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"File '{file}' has no suffixes that could be used to detect the archive type and compression.\"", "\n", ")", "\n", "", "suffix", "=", "suffixes", "[", "-", "1", "]", "\n", "\n", "# check if the suffix is a known alias", "\n", "if", "suffix", "in", "_FILE_TYPE_ALIASES", ":", "\n", "        ", "return", "(", "suffix", ",", "*", "_FILE_TYPE_ALIASES", "[", "suffix", "]", ")", "\n", "\n", "# check if the suffix is an archive type", "\n", "", "if", "suffix", "in", "_ARCHIVE_EXTRACTORS", ":", "\n", "        ", "return", "suffix", ",", "suffix", ",", "None", "\n", "\n", "# check if the suffix is a compression", "\n", "", "if", "suffix", "in", "_COMPRESSED_FILE_OPENERS", ":", "\n", "# check for suffix hierarchy", "\n", "        ", "if", "len", "(", "suffixes", ")", ">", "1", ":", "\n", "            ", "suffix2", "=", "suffixes", "[", "-", "2", "]", "\n", "\n", "# check if the suffix2 is an archive type", "\n", "if", "suffix2", "in", "_ARCHIVE_EXTRACTORS", ":", "\n", "                ", "return", "suffix2", "+", "suffix", ",", "suffix2", ",", "suffix", "\n", "\n", "", "", "return", "suffix", ",", "None", ",", "suffix", "\n", "\n", "", "valid_suffixes", "=", "sorted", "(", "set", "(", "_FILE_TYPE_ALIASES", ")", "|", "set", "(", "_ARCHIVE_EXTRACTORS", ")", "|", "set", "(", "_COMPRESSED_FILE_OPENERS", ")", ")", "\n", "raise", "RuntimeError", "(", "f\"Unknown compression or archive type: '{suffix}'.\\nKnown suffixes are: '{valid_suffixes}'.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io._decompress": [[323, 359], ["io._detect_file_type", "RuntimeError", "from_path.replace", "compressed_file_opener", "open", "wfh.write", "os.remove", "os.remove", "rfh.read"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io._detect_file_type", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "def", "_decompress", "(", "\n", "from_path", ":", "str", ",", "to_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "remove_finished", ":", "bool", "=", "False", "\n", ")", "->", "str", ":", "# pragma: no cover", "\n", "    ", "r\"\"\"Decompress a file.\n\n    The compression is automatically detected from the file name.\n\n    Parameters\n    ----------\n    from_path: str\n        Path to the file to be decompressed.\n    to_path: str\n        Path to the decompressed file. If omitted, ``from_path`` without compression extension is used.\n        remove_finished (bool): If ``True``, remove the file after the extraction.\n\n    Returns\n    -------\n    str, Path to the decompressed file.\n    \"\"\"", "\n", "suffix", ",", "archive_type", ",", "compression", "=", "_detect_file_type", "(", "from_path", ")", "\n", "if", "not", "compression", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Couldn't detect a compression from suffix {suffix}.\"", ")", "\n", "\n", "", "if", "to_path", "is", "None", ":", "\n", "        ", "to_path", "=", "from_path", ".", "replace", "(", "suffix", ",", "archive_type", "if", "archive_type", "is", "not", "None", "else", "\"\"", ")", "\n", "\n", "# We don't need to check for a missing key here, since this was already done in _detect_file_type()", "\n", "", "compressed_file_opener", "=", "_COMPRESSED_FILE_OPENERS", "[", "compression", "]", "\n", "\n", "with", "compressed_file_opener", "(", "from_path", ",", "\"rb\"", ")", "as", "rfh", ",", "open", "(", "to_path", ",", "\"wb\"", ")", "as", "wfh", ":", "\n", "        ", "wfh", ".", "write", "(", "rfh", ".", "read", "(", ")", ")", "\n", "\n", "", "if", "remove_finished", ":", "\n", "        ", "os", ".", "remove", "(", "from_path", ")", "\n", "\n", "", "return", "to_path", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.extract_archive": [[361, 400], ["io._detect_file_type", "extractor", "os.path.dirname", "os.path.dirname", "io._decompress", "os.path.join", "os.path.join", "os.path.basename().replace", "os.path.basename().replace", "os.path.basename", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io._detect_file_type", "home.repos.pwc.inspect_result.directgroup_direct.utils.io._decompress"], ["", "def", "extract_archive", "(", "\n", "from_path", ":", "str", ",", "to_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "remove_finished", ":", "bool", "=", "False", "\n", ")", "->", "str", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Extract an archive.\n\n    The archive type and a possible compression is automatically detected from the file name. If the file is compressed\n    but not an archive the call is dispatched to :func:`decompress`.\n\n    Parameters\n    ----------\n    from_path: str\n        Path to the file to be extracted.\n    to_path: str\n        Path to the directory the file will be extracted to. If omitted, the directory of the file is used.\n    remove_finished: bool\n        If ``True``, remove the file after the extraction.\n\n    Returns\n    -------\n    str\n        Path to the directory the file was extracted to.\n    \"\"\"", "\n", "if", "to_path", "is", "None", ":", "\n", "        ", "to_path", "=", "os", ".", "path", ".", "dirname", "(", "from_path", ")", "\n", "\n", "", "suffix", ",", "archive_type", ",", "compression", "=", "_detect_file_type", "(", "from_path", ")", "\n", "if", "not", "archive_type", ":", "\n", "        ", "return", "_decompress", "(", "\n", "from_path", ",", "\n", "os", ".", "path", ".", "join", "(", "to_path", ",", "os", ".", "path", ".", "basename", "(", "from_path", ")", ".", "replace", "(", "suffix", ",", "\"\"", ")", ")", ",", "\n", "remove_finished", "=", "remove_finished", ",", "\n", ")", "\n", "\n", "# We don't need to check for a missing key here, since this was already done in _detect_file_type()", "\n", "", "extractor", "=", "_ARCHIVE_EXTRACTORS", "[", "archive_type", "]", "\n", "\n", "extractor", "(", "from_path", ",", "to_path", ",", "compression", ")", "\n", "\n", "return", "to_path", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.download_and_extract_archive": [[402, 421], ["os.path.expanduser", "os.path.expanduser", "io.download_url", "os.path.join", "os.path.join", "logger.info", "io.extract_archive", "os.path.basename", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.download_url", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.extract_archive"], ["", "def", "download_and_extract_archive", "(", "\n", "url", ":", "str", ",", "\n", "download_root", ":", "str", ",", "\n", "extract_root", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "filename", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "md5", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "remove_finished", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "download_root", "=", "os", ".", "path", ".", "expanduser", "(", "download_root", ")", "\n", "if", "extract_root", "is", "None", ":", "\n", "        ", "extract_root", "=", "download_root", "\n", "", "if", "not", "filename", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "\n", "", "download_url", "(", "url", ",", "download_root", ",", "filename", ",", "md5", ")", "\n", "\n", "archive", "=", "os", ".", "path", ".", "join", "(", "download_root", ",", "filename", ")", "\n", "logger", ".", "info", "(", "f\"Extracting {archive} to {extract_root}\"", ")", "\n", "extract_archive", "(", "archive", ",", "extract_root", ",", "remove_finished", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_text_from_url": [[423, 454], ["data.decode", "io.check_is_valid_url", "ValueError", "urllib.request.urlopen", "urllib.request.urlopen", "urllib.request.urlopen", "urllib.request.Request", "urllib.request.Request", "urllib.request.Request", "tqdm.auto.tqdm", "iter", "pbar.update", "response.read"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.iter", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "read_text_from_url", "(", "url", ",", "chunk_size", ":", "int", "=", "1024", ")", ":", "\n", "    ", "\"\"\"Read a text file from a URL, e.g. a config file.\n\n    Parameters\n    ----------\n    url: str\n    chunk_size: int\n\n    Returns\n    -------\n    str\n        Data from URL\n    \"\"\"", "\n", "if", "not", "check_is_valid_url", "(", "url", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{url} is not a valid URL.\"", ")", "\n", "\n", "", "data", "=", "b\"\"", "\n", "\n", "try", ":", "\n", "        ", "with", "urllib", ".", "request", ".", "urlopen", "(", "urllib", ".", "request", ".", "Request", "(", "url", ",", "headers", "=", "{", "\"User-Agent\"", ":", "USER_AGENT", "}", ")", ")", "as", "response", ":", "\n", "            ", "with", "tqdm", "(", "total", "=", "response", ".", "length", ")", "as", "pbar", ":", "\n", "                ", "for", "chunk", "in", "iter", "(", "lambda", ":", "response", ".", "read", "(", "chunk_size", ")", ",", "\"\"", ")", ":", "\n", "                    ", "if", "not", "chunk", ":", "\n", "                        ", "break", "\n", "", "pbar", ".", "update", "(", "chunk_size", ")", "\n", "data", "+=", "chunk", "\n", "", "", "", "", "except", "urllib", ".", "error", ".", "HTTPError", "as", "e", ":", "\n", "        ", "e", ".", "msg", "=", "f\"{e.msg}: {url}\"", "\n", "raise", "\n", "\n", "", "return", "data", ".", "decode", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url": [[456, 484], ["re.compile", "re.match", "str().startswith", "str().startswith", "str().startswith", "str", "str", "str"], "function", ["None"], ["", "def", "check_is_valid_url", "(", "path", ":", "PathOrString", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Check if the given path is a valid url.\n\n    Parameters\n    ----------\n    path: PathOrString\n\n    Returns\n    -------\n    Bool describing if this is an URL or not.\n    \"\"\"", "\n", "# From https://gist.github.com/dokterbob/998722/1c380cb896afa22306218f73384b79d2d4386638", "\n", "if", "not", "str", "(", "path", ")", ".", "startswith", "(", "\"http\"", ")", "and", "not", "str", "(", "path", ")", ".", "startswith", "(", "\"s3\"", ")", "and", "not", "str", "(", "path", ")", ".", "startswith", "(", "\"ftp\"", ")", ":", "\n", "        ", "return", "False", "\n", "\n", "", "regex", "=", "re", ".", "compile", "(", "\n", "r\"^((?:http|ftp)s?://\"", "# http:// or https://", "\n", "r\"(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|\"", "# domain...", "\n", "r\"localhost|\"", "# localhost...", "\n", "r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"", "# ...or ip", "\n", "r\"(?::\\d+)?)?\"", "# optional port", "\n", "r\"(?:/?|[/?]\\S+)$\"", ",", "\n", "re", ".", "IGNORECASE", ",", "\n", ")", "# host is optional, allow for relative URLs", "\n", "\n", "if", "re", ".", "match", "(", "regex", ",", "path", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.io.upload_to_s3": [[486, 540], ["boto3.client", "RuntimeError", "os.stat", "os.stat", "tqdm.auto.tqdm", "boto3.client.upload_file", "boto3.session.Config", "str", "pbar.update"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "upload_to_s3", "(", "\n", "filename", ":", "pathlib", ".", "Path", ",", "\n", "to_filename", ":", "str", ",", "\n", "aws_access_key_id", ":", "str", ",", "\n", "aws_secret_access_key", ":", "str", ",", "\n", "endpoint_url", ":", "str", "=", "\"https://s3.aiforoncology.nl\"", ",", "\n", "bucket", ":", "str", "=", "\"direct-project\"", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "None", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Upload file to an s3 bucket.\n\n    Parameters\n    ----------\n    filename : pathlib.Path\n        Filename to upload\n    to_filename : str\n        Where to store the file\n    aws_access_key_id : str\n    aws_secret_access_key : str\n    endpoint_url : str\n        AWS endpoint url\n    bucket : str\n        Bucket name\n    verbose : str\n        Show upload progress\n\n    Returns\n    -------\n    None\n    \"\"\"", "\n", "if", "not", "boto3_available", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"`boto3` is not installed, and this is required to upload files to s3 buckets.\"", ")", "\n", "\n", "", "s3_client", "=", "boto3", ".", "client", "(", "\n", "\"s3\"", ",", "\n", "endpoint_url", "=", "endpoint_url", ",", "\n", "aws_access_key_id", "=", "aws_access_key_id", ",", "\n", "aws_secret_access_key", "=", "aws_secret_access_key", ",", "\n", "config", "=", "boto3", ".", "session", ".", "Config", "(", "\"s3v4\"", ")", ",", "\n", ")", "\n", "file_size", "=", "os", ".", "stat", "(", "filename", ")", ".", "st_size", "\n", "with", "tqdm", "(", "\n", "total", "=", "file_size", ",", "\n", "unit", "=", "\"B\"", ",", "\n", "bar_format", "=", "\"{percentage:.1f}%|{bar:25} | {rate_fmt} | {desc}\"", ",", "\n", "unit_scale", "=", "True", ",", "\n", "desc", "=", "f\"to: {endpoint_url}/{bucket}/{to_filename}\"", ",", "\n", "disable", "=", "not", "verbose", ",", "\n", ")", "as", "pbar", ":", "\n", "        ", "s3_client", ".", "upload_file", "(", "\n", "Filename", "=", "str", "(", "filename", ")", ",", "\n", "Bucket", "=", "bucket", ",", "\n", "Key", "=", "to_filename", ",", "\n", "Callback", "=", "lambda", "bytes_transferred", ":", "pbar", ".", "update", "(", "bytes_transferred", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.imports._module_available": [[8, 22], ["importlib.util.find_spec"], "function", ["None"], ["def", "_module_available", "(", "module_path", ":", "str", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Check if a path is available in your environment.\n\n    >>> _module_available('os')\n    True\n    >>> _module_available('bla.bla')\n    False\n    Adapted from: https://github.com/PyTorchLightning/pytorch-lightning/blob/ef7d41692ca04bb9877da5c743f80fceecc6a100/pytorch_lightning/utilities/imports.py#L27\n    Under Apache 2.0 license.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "return", "find_spec", "(", "module_path", ")", "is", "not", "None", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "        ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.bbox.crop_to_bbox": [[9, 65], ["isinstance", "isinstance", "isinstance", "ValueError", "len", "ValueError", "numpy.asarray", "numpy.asarray", "bbox_coords.copy", "numpy.array", "slice", "data[].clone", "data[].copy", "numpy.all", "numpy.all", "slice", "len", "zip", "torch.ones", "numpy.ones", "zip", "tuple", "bbox_size.tolist", "bbox_size.tolist", "type", "tuple", "tuple"], "function", ["None"], ["def", "crop_to_bbox", "(", "\n", "data", ":", "Union", "[", "np", ".", "ndarray", ",", "torch", ".", "Tensor", "]", ",", "bbox", ":", "List", "[", "int", "]", ",", "pad_value", ":", "int", "=", "0", "\n", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Extract bbox from images, coordinates can be negative.\n\n    Parameters\n    ----------\n    data: np.ndarray or torch.tensor\n       nD array or torch tensor.\n    bbox: list or tuple\n       bbox of the form (coordinates, size),\n       for instance (4, 4, 2, 1) is a patch starting at row 4, col 4 with height 2 and width 1.\n    pad_value: number\n       if bounding box would be out of the image, this is value the patch will be padded with.\n\n    Returns\n    -------\n    ndarray\n        Numpy array of data cropped to BoundingBox\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "data", ",", "(", "np", ".", "ndarray", ",", "torch", ".", "Tensor", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Expected `data` to be ndarray or tensor. Got {type(data)}.\"", ")", "\n", "\n", "# Coordinates, size", "\n", "", "ndim", "=", "len", "(", "bbox", ")", "//", "2", "\n", "if", "len", "(", "bbox", ")", "%", "2", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Bounding box should have the form of [x_0, x_1, ..., h_0, h_1], but got length {ndim}.\"", ")", "\n", "", "bbox_coords", ",", "bbox_size", "=", "np", ".", "asarray", "(", "bbox", "[", ":", "ndim", "]", ")", ",", "np", ".", "asarray", "(", "bbox", "[", "ndim", ":", "]", ")", "\n", "# Offsets", "\n", "l_offset", "=", "-", "bbox_coords", ".", "copy", "(", ")", "\n", "l_offset", "[", "l_offset", "<", "0", "]", "=", "0", "\n", "\n", "r_offset", "=", "(", "bbox_coords", "+", "bbox_size", ")", "-", "np", ".", "array", "(", "data", ".", "shape", ")", "\n", "r_offset", "[", "r_offset", "<", "0", "]", "=", "0", "\n", "\n", "region_idx", "=", "[", "slice", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "zip", "(", "bbox_coords", "+", "l_offset", ",", "bbox_coords", "+", "bbox_size", "-", "r_offset", ")", "]", "\n", "\n", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "# TODO(jt): Investigate if clone is needed", "\n", "        ", "out", "=", "data", "[", "tuple", "(", "region_idx", ")", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "        ", "out", "=", "data", "[", "tuple", "(", "region_idx", ")", "]", ".", "copy", "(", ")", "\n", "\n", "", "if", "np", ".", "all", "(", "l_offset", "==", "0", ")", "and", "np", ".", "all", "(", "r_offset", "==", "0", ")", ":", "\n", "        ", "return", "out", "\n", "\n", "# If we have a positive offset, we need to pad the patch.", "\n", "", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "patch", "=", "pad_value", "*", "torch", ".", "ones", "(", "bbox_size", ".", "tolist", "(", ")", ",", "dtype", "=", "data", ".", "dtype", ")", "\n", "", "else", ":", "\n", "        ", "patch", "=", "pad_value", "*", "np", ".", "ones", "(", "bbox_size", ".", "tolist", "(", ")", ",", "dtype", "=", "data", ".", "dtype", ")", "\n", "\n", "", "patch_idx", "=", "[", "slice", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "zip", "(", "l_offset", ",", "bbox_size", "-", "r_offset", ")", "]", "\n", "patch", "[", "tuple", "(", "patch_idx", ")", "]", "=", "out", "\n", "\n", "return", "patch", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.bbox.crop_to_largest": [[67, 92], ["numpy.asarray", "np.asarray.max", "bbox.crop_to_bbox", "_.tolist", "shapes.max.tolist", "zip", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_bbox"], ["", "def", "crop_to_largest", "(", "\n", "data", ":", "List", "[", "Union", "[", "np", ".", "ndarray", ",", "torch", ".", "Tensor", "]", "]", ",", "pad_value", ":", "int", "=", "0", "\n", ")", "->", "List", "[", "Union", "[", "np", ".", "ndarray", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "    ", "\"\"\"Given a list of arrays or tensors, return the same list with the data padded to the largest in the set. Can be\n    convenient for e.g. logging and tiling several images as with torchvision's `make_grid'`\n\n    Parameters\n    ----------\n    data: List[Union[np.ndarray, torch.Tensor]]\n    pad_value: int\n\n    Returns\n    -------\n    List[Union[np.ndarray, torch.Tensor]]\n    \"\"\"", "\n", "if", "not", "data", ":", "\n", "        ", "return", "data", "\n", "\n", "", "shapes", "=", "np", ".", "asarray", "(", "[", "_", ".", "shape", "for", "_", "in", "data", "]", ")", "\n", "max_shape", "=", "shapes", ".", "max", "(", "axis", "=", "0", ")", "\n", "\n", "crop_start_per_shape", "=", "[", "-", "(", "max_shape", "-", "np", ".", "asarray", "(", "_", ")", ")", "//", "2", "for", "_", "in", "shapes", "]", "\n", "crop_boxes", "=", "[", "_", ".", "tolist", "(", ")", "+", "max_shape", ".", "tolist", "(", ")", "for", "_", "in", "crop_start_per_shape", "]", "\n", "\n", "return", "[", "crop_to_bbox", "(", "curr_data", ",", "bbox", ",", "pad_value", "=", "pad_value", ")", "for", "curr_data", ",", "bbox", "in", "zip", "(", "data", ",", "crop_boxes", ")", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.dataset.get_filenames_for_datasets_from_config": [[11, 29], ["dataset.get_filenames_for_datasets"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.dataset.get_filenames_for_datasets"], ["def", "get_filenames_for_datasets_from_config", "(", "cfg", ",", "files_root", ":", "PathOrString", ",", "data_root", ":", "pathlib", ".", "Path", ")", ":", "\n", "    ", "\"\"\"Given a configuration object it returns a list of filenames.\n\n    Parameters\n    ----------\n    cfg: cfg-object\n        cfg object having property lists having the relative paths compared to files root.\n    files_root: Union[str, pathlib.Path]\n    data_root: pathlib.Path\n\n    Returns\n    -------\n    list of filenames or None\n    \"\"\"", "\n", "if", "\"filenames_lists\"", "not", "in", "cfg", ":", "\n", "        ", "return", "None", "\n", "", "lists", "=", "cfg", ".", "filenames_lists", "\n", "return", "get_filenames_for_datasets", "(", "lists", ",", "files_root", ",", "data_root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.dataset.get_filenames_for_datasets": [[31, 59], ["direct.utils.io.check_is_valid_url", "urllib.parse.urljoin", "pathlib.Path", "pathlib.Path", "direct.utils.io.read_list"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.read_list"], ["", "def", "get_filenames_for_datasets", "(", "lists", ":", "List", "[", "PathOrString", "]", ",", "files_root", ":", "PathOrString", ",", "data_root", ":", "pathlib", ".", "Path", ")", ":", "\n", "    ", "\"\"\"Given lists of filenames of data points, concatenate these into a large list of full filenames.\n\n    Parameters\n    ----------\n    lists: List[PathOrString]\n    files_root: PathOrString\n    data_root: pathlib.Path\n\n    Returns\n    -------\n    list of filenames or None\n    \"\"\"", "\n", "# Build the path, know that files_root can also be a URL", "\n", "is_url", "=", "check_is_valid_url", "(", "files_root", ")", "\n", "\n", "filter_filenames", "=", "[", "]", "\n", "for", "curr_list", "in", "lists", ":", "\n", "        ", "if", "not", "is_url", ":", "\n", "            ", "path_to_list", "=", "pathlib", ".", "Path", "(", "files_root", ")", "/", "curr_list", "\n", "", "else", ":", "\n", "# The path needs to be extended / and '...' needs to be parsed. The urljoin handles this correctly", "\n", "# Note: any query arguments are dropped. So any temporary keys such as ?Q=XYZ will not be added to the URL.", "\n", "            ", "path_to_list", "=", "urllib", ".", "parse", ".", "urljoin", "(", "files_root", ",", "curr_list", ")", "\n", "\n", "", "filter_filenames", "+=", "[", "data_root", "/", "pathlib", ".", "Path", "(", "_", ")", "for", "_", "in", "read_list", "(", "path_to_list", ")", "]", "\n", "\n", "", "return", "filter_filenames", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.synchronize": [[34, 52], ["torch.distributed.barrier", "torch.distributed.is_available", "logger.info", "torch.distributed.is_initialized", "logger.info", "torch.distributed.get_world_size", "logger.info"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size"], ["def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"Synchronize processes between GPUs.\n\n    Wait until all devices are available. Does nothing in a non-distributed setting.\n    \"\"\"", "\n", "if", "not", "torch", ".", "distributed", ".", "is_available", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"torch.distributed: not available.\"", ")", "\n", "return", "\n", "\n", "", "if", "not", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"torch.distributed: not initialized.\"", ")", "\n", "return", "\n", "\n", "", "if", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"torch distributed: world size is 1\"", ")", "\n", "return", "\n", "\n", "", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank": [[54, 67], ["torch.distributed.get_rank", "torch.distributed.is_available", "torch.distributed.is_initialized"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank"], ["", "def", "get_rank", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"Get rank of the process, even when torch.distributed is not initialized.\n\n    Returns\n    -------\n    int\n    \"\"\"", "\n", "if", "not", "torch", ".", "distributed", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "\n", "", "return", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_local_rank": [[69, 84], ["torch.distributed.get_rank", "torch.distributed.is_available", "torch.distributed.is_initialized", "ValueError"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank"], ["", "def", "get_local_rank", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"Get rank of the process within the same machine, even when torch.distributed is not initialized.\n\n    Returns\n    -------\n    int: The rank of the current process within the local (per-machine) process group.\n    \"\"\"", "\n", "if", "not", "torch", ".", "distributed", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "_LOCAL_PROCESS_GROUP", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{_LOCAL_PROCESS_GROUP} needs to be set.\"", ")", "\n", "\n", "", "return", "torch", ".", "distributed", ".", "get_rank", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_local_size": [[86, 98], ["torch.distributed.get_world_size", "torch.distributed.is_available", "torch.distributed.is_initialized"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size"], ["", "def", "get_local_size", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"Number of compute units in local machine.\n\n    Returns\n    -------\n    int\n    \"\"\"", "\n", "if", "not", "torch", ".", "distributed", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.is_main_process": [[100, 108], ["communication.get_rank"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank"], ["", "def", "is_main_process", "(", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Simple wrapper around get_rank().\n\n    Returns\n    -------\n    bool\n    \"\"\"", "\n", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size": [[110, 122], ["torch.distributed.get_world_size", "torch.distributed.is_available", "torch.distributed.is_initialized"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size"], ["", "def", "get_world_size", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"Get number of compute device in the world, returns 1 in case multi device is not initialized.\n\n    Returns\n    -------\n    int\n    \"\"\"", "\n", "if", "not", "torch", ".", "distributed", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._get_global_gloo_group": [[124, 130], ["functools.lru_cache", "torch.distributed.get_backend", "torch.distributed.new_group"], "function", ["None"], ["", "@", "functools", ".", "lru_cache", "(", ")", "\n", "def", "_get_global_gloo_group", "(", ")", "->", "torch", ".", "distributed", ".", "group", ":", "\n", "    ", "\"\"\"Return a process group based on gloo backend, containing all the ranks The result is cached.\"\"\"", "\n", "if", "torch", ".", "distributed", ".", "get_backend", "(", ")", "==", "\"nccl\"", ":", "\n", "        ", "return", "torch", ".", "distributed", ".", "new_group", "(", "backend", "=", "\"gloo\"", ")", "\n", "", "return", "torch", ".", "distributed", ".", "group", ".", "WORLD", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._serialize_to_tensor": [[132, 147], ["torch.distributed.get_backend", "torch.device", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "len", "logger.warning", "torch.ByteTensor", "communication.get_rank", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank"], ["", "def", "_serialize_to_tensor", "(", "data", ":", "object", ",", "group", ":", "torch", ".", "distributed", ".", "group", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "backend", "=", "torch", ".", "distributed", ".", "get_backend", "(", "group", ")", "\n", "if", "backend", "not", "in", "[", "\"gloo\"", ",", "\"nccl\"", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cpu\"", "if", "backend", "==", "\"gloo\"", "else", "\"cuda\"", ")", "\n", "\n", "# Pickeling goes through the normal pickle interface, the current torch.save also zips data.", "\n", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "if", "len", "(", "buffer", ")", ">", "1024", "**", "3", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"Rank {get_rank()} trying to all-gather {len(buffer) / (1024 ** 3):.2f} GB of data on device {device}\"", "\n", ")", "\n", "", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "# type: ignore", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "device", "=", "device", ")", "# type: ignore", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._pad_to_largest_tensor": [[149, 181], ["torch.distributed.get_world_size", "torch.tensor", "torch.distributed.all_gather", "max", "ValueError", "torch.zeros", "int", "torch.zeros", "torch.cat", "torch.cat.numel", "range", "size.item"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.all_gather"], ["", "def", "_pad_to_largest_tensor", "(", "\n", "tensor", ":", "torch", ".", "Tensor", ",", "group", ":", "torch", ".", "distributed", ".", "group", "\n", ")", "->", "Tuple", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Parameters\n    ----------\n    tensor: torch.Tensor\n    group: torch.distributed.group\n\n    Returns\n    -------\n    list[int]: size of the tensor, on each rank\n    Tensor: padded tensor that has the max size\n    \"\"\"", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "\n", "if", "not", "world_size", ">", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"communication.gather/all_gather must be called from ranks within the given group!\"", ")", "\n", "", "local_size", "=", "torch", ".", "tensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "\n", "size_list", "=", "[", "torch", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "size_list", ",", "local_size", ",", "group", "=", "group", ")", "# type: ignore", "\n", "\n", "# Cast list to integers", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "# type: ignore", "\n", "max_size", "=", "max", "(", "size_list", ")", "# type: ignore", "\n", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "zeros", "(", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "# type: ignore", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "return", "size_list", ",", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.all_gather": [[183, 219], ["communication._serialize_to_tensor", "communication._pad_to_largest_tensor", "max", "torch.distributed.all_gather", "zip", "communication.get_world_size", "communication._get_global_gloo_group", "torch.distributed.get_world_size", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication._serialize_to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._pad_to_largest_tensor", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.all_gather", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._get_global_gloo_group", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size"], ["", "def", "all_gather", "(", "data", ":", "object", ",", "group", ":", "Optional", "[", "torch", ".", "distributed", ".", "group", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run all_gather on arbitrary picklable data (not necessarily tensors).\n\n    Parameters\n    ----------\n    data: object\n        Any pickleable object.\n    group :\n        A torch process group. By default, will use a group which contains all ranks on gloo backend.\n\n    Returns\n    -------\n    list: list of data gathered for each rank\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "torch", ".", "distributed", ".", "get_world_size", "(", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "# type: ignore", "\n", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "max_size", "=", "max", "(", "size_list", ")", "# type: ignore", "\n", "\n", "# receiving Tensor from all ranks", "\n", "tensor_list", "=", "[", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "size_list", "]", "# type: ignore", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "tensor_list", ",", "tensor", ",", "group", "=", "group", ")", "# type: ignore", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "# type: ignore", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.gather": [[221, 267], ["torch.distributed.get_rank", "communication._serialize_to_tensor", "communication._pad_to_largest_tensor", "torch.distributed.gather", "communication.get_world_size", "communication._get_global_gloo_group", "torch.distributed.get_world_size", "max", "torch.distributed.gather", "zip", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._serialize_to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._pad_to_largest_tensor", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.gather", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication._get_global_gloo_group", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.gather"], ["", "def", "gather", "(", "\n", "data", ":", "object", ",", "\n", "destination_rank", ":", "int", "=", "0", ",", "\n", "group", ":", "Optional", "[", "torch", ".", "distributed", ".", "group", "]", "=", "None", ",", "\n", ")", "->", "List", ":", "\n", "    ", "\"\"\"Run gather on arbitrary picklable data (not necessarily tensors).\n\n    Parameters\n    ----------\n    data: object\n        Any pickleable object\n    destination_rank: int\n        Destination rank\n    group :\n        A torch process group. By default, will use a group which contains all ranks on gloo backend.\n\n    Returns\n    -------\n    list[data]: on destination_rank, a list of data gathered from each rank. Otherwise, an empty list.\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "torch", ".", "distributed", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "\n", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "if", "rank", "==", "destination_rank", ":", "\n", "        ", "max_size", "=", "max", "(", "size_list", ")", "# type: ignore", "\n", "tensor_list", "=", "[", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "size_list", "]", "# type: ignore", "\n", "# Ignore type, as torch.distributed is not implemented on OS X.", "\n", "torch", ".", "distributed", ".", "gather", "(", "tensor", ",", "tensor_list", ",", "dst", "=", "destination_rank", ",", "group", "=", "group", ")", "# type: ignore", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "            ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "# type: ignore", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "", "return", "data_list", "\n", "# Ignore type, as torch.distributed is not implemented on OS X.", "\n", "", "torch", ".", "distributed", ".", "gather", "(", "tensor", ",", "[", "]", ",", "dst", "=", "destination_rank", ",", "group", "=", "group", ")", "# type: ignore", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.shared_random_seed": [[269, 280], ["numpy.random.randint", "communication.all_gather"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.all_gather"], ["", "def", "shared_random_seed", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"All workers must call this function, otherwise it will deadlock.\n\n    Returns\n    -------\n    A random number that is the same across all workers. If workers need a shared RNG, they can use this shared seed to\n    create one.\n    \"\"\"", "\n", "ints", "=", "np", ".", "random", ".", "randint", "(", "2", "**", "31", ")", "\n", "all_ints", "=", "all_gather", "(", "ints", ")", "\n", "return", "all_ints", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.reduce_tensor_dict": [[282, 313], ["communication.get_world_size", "torch.no_grad", "sorted", "torch.stack", "torch.distributed.reduce", "dict", "tensors_dict.keys", "tensor_names.append", "torch.stack.append", "torch.distributed.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank"], ["", "def", "reduce_tensor_dict", "(", "tensors_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Reduce the tensor dictionary from all processes so that process with rank 0 has the averaged results. Returns a\n    dict with the same fields as tensors_dict, after reduction.\n\n    Parameters\n    ----------\n    tensors_dict: dict\n        dictionary with str keys mapping to torch tensors.\n    Returns\n    -------\n    dict: the reduced dict.\n    \"\"\"", "\n", "if", "not", "tensors_dict", ":", "\n", "        ", "return", "tensors_dict", "\n", "\n", "", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<=", "1", ":", "\n", "        ", "return", "tensors_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "tensor_names", "=", "[", "]", "\n", "all_tensors", "=", "[", "]", "\n", "for", "k", "in", "sorted", "(", "tensors_dict", ".", "keys", "(", ")", ")", ":", "# sorted to make sure this is consistent across processes.", "\n", "            ", "tensor_names", ".", "append", "(", "k", ")", "\n", "all_tensors", ".", "append", "(", "tensors_dict", "[", "k", "]", ")", "\n", "", "all_tensors", "=", "torch", ".", "stack", "(", "all_tensors", ",", "dim", "=", "0", ")", "# type: ignore", "\n", "torch", ".", "distributed", ".", "reduce", "(", "all_tensors", ",", "dst", "=", "0", ")", "# type: ignore", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "# Only accumulate in main process", "\n", "            ", "all_tensors", "/=", "world_size", "# type: ignore", "\n", "", "reduced_tensor_dict", "=", "dict", "(", "zip", "(", "tensor_names", ",", "all_tensors", ")", ")", "\n", "", "return", "reduced_tensor_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_positive_integer": [[11, 31], ["inspect.currentframe().f_back.f_locals.items", "ValueError", "isinstance", "type", "inspect.currentframe"], "function", ["None"], ["def", "assert_positive_integer", "(", "*", "variables", ",", "strict", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "    ", "\"\"\"Assert if given variables are positive integer.\n\n    Parameters\n    ----------\n    variables: Any\n    strict: bool\n        If true, will allow zero values.\n    \"\"\"", "\n", "if", "not", "strict", ":", "\n", "        ", "type_name", "=", "\"positive integer\"", "\n", "", "else", ":", "\n", "        ", "type_name", "=", "\"positive integer larger than zero\"", "\n", "\n", "", "for", "variable", "in", "variables", ":", "\n", "        ", "if", "not", "isinstance", "(", "variable", ",", "int", ")", "or", "(", "variable", "<=", "0", "and", "strict", ")", "or", "(", "variable", "<", "0", "and", "not", "strict", ")", ":", "\n", "            ", "callers_local_vars", "=", "inspect", ".", "currentframe", "(", ")", ".", "f_back", ".", "f_locals", ".", "items", "(", ")", "# type: ignore", "\n", "variable_name", "=", "[", "var_name", "for", "var_name", ",", "var_val", "in", "callers_local_vars", "if", "var_val", "is", "variable", "]", "[", "0", "]", "\n", "\n", "raise", "ValueError", "(", "f\"{variable_name} has to be a {type_name}. \"", "f\"Got {variable} of type {type(variable)}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_same_shape": [[33, 44], ["set", "ValueError", "len"], "function", ["None"], ["", "", "", "def", "assert_same_shape", "(", "data_list", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "    ", "\"\"\"Check if all tensors in the list have the same shape.\n\n    Parameters\n    ----------\n    data_list: list\n        List of tensors\n    \"\"\"", "\n", "shape_list", "=", "set", "(", "_", ".", "shape", "for", "_", "in", "data_list", ")", "\n", "if", "not", "len", "(", "shape_list", ")", "==", "1", ":", "\n", "        ", "raise", "ValueError", "(", "f\"All inputs are expected to have the same shape. Got {shape_list}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex": [[46, 63], ["direct.utils.is_complex_data"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.is_complex_data"], ["", "", "def", "assert_complex", "(", "data", ":", "torch", ".", "Tensor", ",", "complex_axis", ":", "int", "=", "-", "1", ",", "complex_last", ":", "Optional", "[", "bool", "]", "=", "None", ")", "->", "None", ":", "\n", "    ", "\"\"\"Assert if a tensor is complex (has complex dimension of size 2 corresponding to real and imaginary channels).\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    complex_axis: int\n        Complex dimension along which the assertion will be done. Default: -1 (last).\n    complex_last: Optional[bool]\n        If true, will override complex_axis with -1 (last). Default: None.\n    \"\"\"", "\n", "# TODO: This is because ifft and fft or torch expect the last dimension to represent the complex axis.", "\n", "if", "complex_last", ":", "\n", "        ", "complex_axis", "=", "-", "1", "\n", "", "assert", "is_complex_data", "(", "\n", "data", ",", "complex_axis", "\n", ")", ",", "f\"Complex dimension assumed to be 2 (complex valued), but not found in shape {data.shape}.\"", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.DirectTransform.__init__": [[347, 350], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.DirectTransform.__repr__": [[351, 376], ["__init__.DirectTransform.__dict__.items", "callable", "hasattr", "isinstance", "isinstance", "str", "isinstance", "type", "len", "len", "str", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.DirectModule.__init__": [[379, 382], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.DirectModule.forward": [[383, 385], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.is_complex_data": [[25, 42], ["data.size"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.is_power_of_two": [[44, 56], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.ensure_list": [[58, 76], ["list", "isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.cast_as_path": [[78, 93], ["pathlib.Path"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class": [[95, 137], ["ast.parse", "importlib.import_module", "functools.partial", "hasattr", "hasattr", "getattr", "getattr", "ast.literal_eval", "ast.literal_eval"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device": [[139, 160], ["data.keys", "isinstance", "v.to", "data.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict": [[162, 178], ["data.keys", "v.detach", "data.items", "isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts": [[180, 213], ["ValueError", "torch.zeros_like", "len", "data[].items", "result_dict.items", "elem.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.merge_list_of_dicts": [[215, 230], ["functools.reduce", "dict", "dict"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.evaluate_dict": [[232, 257], ["fns_dict.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.prefix_dict_keys": [[259, 272], ["data.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.git_hash": [[274, 293], ["subprocess.check_output().decode().strip", "e.output.decode", "e.stderr.decode", "subprocess.check_output().decode", "sys.getfilesystemencoding", "sys.getfilesystemencoding", "subprocess.check_output"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.normalize_image": [[295, 318], ["image.min", "image.max"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.multiply_function": [[320, 339], ["func"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.count_parameters": [[387, 403], ["logger.info", "sum", "logger.info", "logger.debug", "p.numel", "models[].parameters"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__._select_random_seed": [[407, 423], ["random.randint"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.set_all_seeds": [[425, 445], ["random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "numpy.random.seed", "str", "str", "__init__._select_random_seed", "__init__._select_random_seed", "__init__._select_random_seed", "__init__._select_random_seed", "__init__._select_random_seed"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__._select_random_seed", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__._select_random_seed", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__._select_random_seed", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__._select_random_seed", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__._select_random_seed"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.chunks": [[447, 464], ["divmod", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.remove_keys": [[466, 486], ["dict().copy", "isinstance", "dict"], "function", ["None"], []], "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.volume_post_processing_func": [[6, 11], ["numpy.sqrt", "numpy.prod"], "function", ["None"], [""]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.__init__": [[62, 102], ["direct.engine.Engine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MRIModelEngine`.\n\n        Parameters\n        ----------\n        cfg: BaseConfig\n            Configuration file.\n        model: nn.Module\n            Model.\n        device: str\n            Device. Can be \"cuda\" or \"cpu\".\n        forward_operator: Callable, optional\n            The forward operator. Default: None.\n        backward_operator: Callable, optional\n            The backward operator. Default: None.\n        mixed_precision: bool\n            Use mixed precision. Default: False.\n        **models: nn.Module\n            Additional models.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "self", ".", "_complex_dim", "=", "-", "1", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine._do_iteration": [[103, 115], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "        ", "\"\"\"To be implemented by child class.\n\n        Should output a :meth:`DoIterationOutput` object with `output_image`, `sensitivity_map` and\n        `data_dict` attributes.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss": [[116, 226], ["mri_models._compute_resolution", "mri_models.MRIModelEngine.build_loss.get_resolution"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._compute_resolution"], ["", "def", "build_loss", "(", "self", ")", "->", "Dict", ":", "\n", "# TODO: Cropper is a processing output tool.", "\n", "        ", "def", "get_resolution", "(", "**", "data", ")", ":", "\n", "            ", "\"\"\"Be careful that this will use the cropping size of the FIRST sample in the batch.\"\"\"", "\n", "return", "_compute_resolution", "(", "self", ".", "cfg", ".", "training", ".", "loss", ".", "crop", ",", "data", ".", "get", "(", "\"reconstruction_size\"", ",", "None", ")", ")", "\n", "\n", "# TODO(jt) Ideally this is also configurable:", "\n", "# - Do in steps (use insertation order)", "\n", "# Crop -> then loss.", "\n", "\n", "", "def", "l1_loss", "(", "source", ":", "torch", ".", "Tensor", ",", "reduction", ":", "str", "=", "\"mean\"", ",", "**", "data", ")", "->", "torch", ".", "Tensor", ":", "\n", "            ", "\"\"\"Calculate L1 loss given source and target.\n\n            Parameters\n            ----------\n            source: torch.Tensor\n                Has shape (batch, [complex=2,] height, width)\n            reduction: str\n                Reduction type. Can be \"sum\" or \"mean\".\n            data: Dict[str, torch.Tensor]\n                Contains key \"target\" with value a tensor of shape (batch, height, width)\n\n            Returns\n            -------\n            l1_loss: torch.Tensor\n                L1 loss.\n            \"\"\"", "\n", "resolution", "=", "get_resolution", "(", "**", "data", ")", "\n", "l1_loss", "=", "F", ".", "l1_loss", "(", "\n", "*", "_crop_volume", "(", "\n", "T", ".", "modulus_if_complex", "(", "source", ",", "complex_axis", "=", "self", ".", "_complex_dim", ")", ",", "data", "[", "\"target\"", "]", ",", "resolution", "\n", ")", ",", "\n", "reduction", "=", "reduction", ",", "\n", ")", "\n", "\n", "return", "l1_loss", "\n", "\n", "", "def", "l2_loss", "(", "source", ":", "torch", ".", "Tensor", ",", "reduction", ":", "str", "=", "\"mean\"", ",", "**", "data", ")", "->", "torch", ".", "Tensor", ":", "\n", "            ", "\"\"\"Calculate L2 loss (MSE) given source and target.\n\n            Parameters\n            ----------\n            source: torch.Tensor\n                Has shape (batch, [complex=2,] height, width)\n            reduction: str\n                Reduction type. Can be \"sum\" or \"mean\".\n            data: Dict[str, torch.Tensor]\n                Contains key \"target\" with value a tensor of shape (batch, height, width)\n\n            Returns\n            -------\n            l2_loss: torch.Tensor\n                L2 loss.\n            \"\"\"", "\n", "resolution", "=", "get_resolution", "(", "**", "data", ")", "\n", "l2_loss", "=", "F", ".", "mse_loss", "(", "\n", "*", "_crop_volume", "(", "\n", "T", ".", "modulus_if_complex", "(", "source", ",", "complex_axis", "=", "self", ".", "_complex_dim", ")", ",", "data", "[", "\"target\"", "]", ",", "resolution", "\n", ")", ",", "\n", "reduction", "=", "reduction", ",", "\n", ")", "\n", "\n", "return", "l2_loss", "\n", "\n", "", "def", "ssim_loss", "(", "source", ":", "torch", ".", "Tensor", ",", "reduction", ":", "str", "=", "\"mean\"", ",", "**", "data", ")", "->", "torch", ".", "Tensor", ":", "\n", "            ", "\"\"\"Calculate SSIM loss given source and target.\n\n            Parameters\n            ----------\n            source: torch.Tensor\n                Has shape (batch, [complex=2,] height, width)\n            reduction: str\n                Reduction type. Can be \"sum\" or \"mean\".\n            data: Dict[str, torch.Tensor]\n                Contains key \"target\" with value a tensor of shape (batch, height, width)\n\n            Returns\n            -------\n            ssim_loss: torch.Tensor\n                SSIM loss.\n            \"\"\"", "\n", "resolution", "=", "get_resolution", "(", "**", "data", ")", "\n", "if", "reduction", "!=", "\"mean\"", ":", "\n", "                ", "raise", "AssertionError", "(", "\n", "f\"SSIM loss can only be computed with reduction == 'mean'.\"", "f\" Got reduction == {reduction}.\"", "\n", ")", "\n", "\n", "", "source_abs", ",", "target_abs", "=", "_crop_volume", "(", "\n", "T", ".", "modulus_if_complex", "(", "source", ",", "complex_axis", "=", "self", ".", "_complex_dim", ")", ",", "data", "[", "\"target\"", "]", ",", "resolution", "\n", ")", "\n", "data_range", "=", "torch", ".", "tensor", "(", "[", "target_abs", ".", "max", "(", ")", "]", ",", "device", "=", "target_abs", ".", "device", ")", "\n", "\n", "ssim_loss", "=", "SSIMLoss", "(", ")", ".", "to", "(", "source_abs", ".", "device", ")", ".", "forward", "(", "source_abs", ",", "target_abs", ",", "data_range", "=", "data_range", ")", "\n", "\n", "return", "ssim_loss", "\n", "\n", "# Build losses", "\n", "", "loss_dict", "=", "{", "}", "\n", "for", "curr_loss", "in", "self", ".", "cfg", ".", "training", ".", "loss", ".", "losses", ":", "# type: ignore", "\n", "            ", "loss_fn", "=", "curr_loss", ".", "function", "\n", "if", "loss_fn", "==", "\"l1_loss\"", ":", "\n", "                ", "loss_dict", "[", "loss_fn", "]", "=", "multiply_function", "(", "curr_loss", ".", "multiplier", ",", "l1_loss", ")", "\n", "", "elif", "loss_fn", "==", "\"l2_loss\"", ":", "\n", "                ", "loss_dict", "[", "loss_fn", "]", "=", "multiply_function", "(", "curr_loss", ".", "multiplier", ",", "l2_loss", ")", "\n", "", "elif", "loss_fn", "==", "\"ssim_loss\"", ":", "\n", "                ", "loss_dict", "[", "loss_fn", "]", "=", "multiply_function", "(", "curr_loss", ".", "multiplier", ",", "ssim_loss", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{loss_fn} not permissible.\"", ")", "\n", "\n", "", "", "return", "loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map": [[227, 265], ["torch.sqrt", "sensitivity_map_norm.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "direct.safe_divide", "mri_models.MRIModelEngine.permute", "mri_models.MRIModelEngine.compute_model_per_coil().permute", "sensitivity_map_norm.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "mri_models.MRIModelEngine.compute_model_per_coil"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.safe_divide", "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.DualNet.compute_model_per_coil"], ["", "def", "compute_sensitivity_map", "(", "self", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes sensitivity maps :math:`\\{S^k\\}_{k=1}^{n_c}` if `sensitivity_model` is available.\n\n        :math:`\\{S^k\\}_{k=1}^{n_c}` are normalized such that\n\n        .. math::\n            \\sum_{k=1}^{n_c}S^k {S^k}^* = I.\n\n        Parameters\n        ----------\n        sensitivity_map: torch.Tensor\n            Sensitivity maps of shape (batch, coil, height,  width, complex=2).\n\n        Returns\n        -------\n        sensitivity_map: torch.Tensor\n            Normalized and refined sensitivity maps of shape (batch, coil, height,  width, complex=2).\n        \"\"\"", "\n", "# Some things can be done with the sensitivity map here, e.g. apply a u-net", "\n", "if", "\"sensitivity_model\"", "in", "self", ".", "models", ":", "\n", "# Move channels to first axis", "\n", "            ", "sensitivity_map", "=", "sensitivity_map", ".", "permute", "(", "\n", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", ")", "# shape (batch, coil, complex=2, height,  width)", "\n", "\n", "sensitivity_map", "=", "self", ".", "compute_model_per_coil", "(", "\"sensitivity_model\"", ",", "sensitivity_map", ")", ".", "permute", "(", "\n", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", ")", "# has channel last: shape (batch, coil, height,  width, complex=2)", "\n", "\n", "# The sensitivity map needs to be normalized such that", "\n", "# So \\sum_{i \\in \\text{coils}} S_i S_i^* = 1", "\n", "\n", "", "sensitivity_map_norm", "=", "torch", ".", "sqrt", "(", "\n", "(", "(", "sensitivity_map", "**", "2", ")", ".", "sum", "(", "self", ".", "_complex_dim", ")", ")", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", ")", "# shape (batch, height, width)", "\n", "sensitivity_map_norm", "=", "sensitivity_map_norm", ".", "unsqueeze", "(", "self", ".", "_coil_dim", ")", ".", "unsqueeze", "(", "self", ".", "_complex_dim", ")", "\n", "\n", "return", "T", ".", "safe_divide", "(", "sensitivity_map", ",", "sensitivity_map_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.reconstruct_volumes": [[266, 390], ["torch.no_grad", "mri_models.MRIModelEngine.models_to_device", "mri_models.MRIModelEngine.models_validation_mode", "torch.cuda.empty_cache", "list", "len", "mri_models.MRIModelEngine.logger.info", "time.time", "enumerate", "data_loader.dataset.volume_indices.keys", "list", "len", "direct.utils.communication.get_world_size", "torch.cuda.empty_cache", "gc.collect", "mri_models._get_filename_from_batch", "data[].clone", "mri_models._compute_resolution", "mri_models.MRIModelEngine._do_iteration", "mri_models._process_output", "_process_output.cpu", "data_loader.batch_sampler.sampler.volume_indices.keys", "mri_models._process_output", "len", "torch.zeros", "loss_dict_list.append", "_process_output.cpu", "mri_models.MRIModelEngine.logger.info", "data.get", "torch.zeros.clone", "list", "time.time", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_to_device", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_validation_mode", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._get_filename_from_batch", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._compute_resolution", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._process_output", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._process_output", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "reconstruct_volumes", "(", "# type: ignore", "\n", "self", ",", "\n", "data_loader", ":", "DataLoader", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "add_target", ":", "bool", "=", "True", ",", "\n", "crop", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Validation process. Assumes that each batch only contains slices of the same volume *AND* that these are\n        sequentially ordered.\n\n        Parameters\n        ----------\n        data_loader: DataLoader\n        loss_fns: Dict[str, Callable], optional\n        regularizer_fns: Dict[str, Callable], optional\n        add_target: bool\n            If true, will add the target to the output\n        crop: str, optional\n            Crop type.\n\n        Yields\n        ------\n        (curr_volume, [curr_target,] loss_dict_list, filename): torch.Tensor, [torch.Tensor,], dict, pathlib.Path\n        # TODO(jt): visualization should be a namedtuple or a dict or so\n        \"\"\"", "\n", "# pylint: disable=too-many-locals, arguments-differ", "\n", "self", ".", "models_to_device", "(", ")", "\n", "self", ".", "models_validation_mode", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# Let us inspect this data", "\n", "all_filenames", "=", "list", "(", "data_loader", ".", "dataset", ".", "volume_indices", ".", "keys", "(", ")", ")", "# type: ignore", "\n", "num_for_this_process", "=", "len", "(", "list", "(", "data_loader", ".", "batch_sampler", ".", "sampler", ".", "volume_indices", ".", "keys", "(", ")", ")", ")", "# type: ignore", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"Reconstructing a total of %s volumes. This process has %s volumes (world size: %s).\"", ",", "\n", "len", "(", "all_filenames", ")", ",", "\n", "num_for_this_process", ",", "\n", "communication", ".", "get_world_size", "(", ")", ",", "\n", ")", "\n", "\n", "last_filename", "=", "None", "# At the start of evaluation, there are no filenames.", "\n", "curr_volume", "=", "None", "\n", "curr_target", "=", "None", "\n", "slice_counter", "=", "0", "\n", "filenames_seen", "=", "0", "\n", "\n", "# Loop over dataset. This requires the use of direct.data.sampler.DistributedSequentialSampler as this sampler", "\n", "# splits the data over the different processes, and outputs the slices linearly. The implicit assumption here is", "\n", "# that the slices are outputted from the Dataset *sequentially* for each volume one by one, and each batch only", "\n", "# contains data from one volume.", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "loss_dict_list", "=", "[", "]", "\n", "# TODO: Use iter_idx to keep track of volume", "\n", "for", "_", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "gc", ".", "collect", "(", ")", "\n", "filename", "=", "_get_filename_from_batch", "(", "data", ")", "\n", "if", "last_filename", "is", "None", ":", "\n", "                ", "last_filename", "=", "filename", "# First iteration last_filename is not set.", "\n", "", "if", "last_filename", "!=", "filename", ":", "\n", "                ", "curr_volume", "=", "None", "\n", "curr_target", "=", "None", "\n", "slice_counter", "=", "0", "\n", "last_filename", "=", "filename", "\n", "\n", "", "scaling_factors", "=", "data", "[", "\"scaling_factor\"", "]", ".", "clone", "(", ")", "\n", "resolution", "=", "_compute_resolution", "(", "\n", "key", "=", "crop", ",", "\n", "reconstruction_size", "=", "data", ".", "get", "(", "\"reconstruction_size\"", ",", "None", ")", ",", "\n", ")", "\n", "# Compute output", "\n", "iteration_output", "=", "self", ".", "_do_iteration", "(", "data", ",", "loss_fns", "=", "loss_fns", ",", "regularizer_fns", "=", "regularizer_fns", ")", "\n", "output", "=", "iteration_output", ".", "output_image", "\n", "loss_dict", "=", "iteration_output", ".", "data_dict", "\n", "\n", "# Output can be complex-valued, and has to be cropped. This holds for both output and target.", "\n", "output_abs", "=", "_process_output", "(", "\n", "output", ",", "\n", "scaling_factors", ",", "\n", "resolution", "=", "resolution", ",", "\n", "complex_axis", "=", "self", ".", "_complex_dim", ",", "\n", ")", "\n", "\n", "if", "add_target", ":", "\n", "                ", "target_abs", "=", "_process_output", "(", "\n", "data", "[", "\"target\"", "]", ",", "\n", "scaling_factors", ",", "\n", "resolution", "=", "resolution", ",", "\n", "complex_axis", "=", "self", ".", "_complex_dim", ",", "\n", ")", "\n", "\n", "", "if", "curr_volume", "is", "None", ":", "\n", "                ", "volume_size", "=", "len", "(", "data_loader", ".", "batch_sampler", ".", "sampler", ".", "volume_indices", "[", "filename", "]", ")", "# type: ignore", "\n", "curr_volume", "=", "torch", ".", "zeros", "(", "*", "(", "volume_size", ",", "*", "output_abs", ".", "shape", "[", "1", ":", "]", ")", ",", "dtype", "=", "output_abs", ".", "dtype", ")", "\n", "loss_dict_list", ".", "append", "(", "loss_dict", ")", "\n", "if", "add_target", ":", "\n", "                    ", "curr_target", "=", "curr_volume", ".", "clone", "(", ")", "\n", "\n", "", "", "curr_volume", "[", "slice_counter", ":", "slice_counter", "+", "output_abs", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "output_abs", ".", "cpu", "(", ")", "\n", "if", "add_target", ":", "\n", "                ", "curr_target", "[", "slice_counter", ":", "slice_counter", "+", "output_abs", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "target_abs", ".", "cpu", "(", ")", "# type: ignore", "\n", "\n", "", "slice_counter", "+=", "output_abs", ".", "shape", "[", "0", "]", "\n", "\n", "# Check if we had the last batch", "\n", "if", "slice_counter", "==", "volume_size", ":", "\n", "                ", "filenames_seen", "+=", "1", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"%i of %i volumes reconstructed: %s (shape = %s) in %.3fs.\"", ",", "\n", "filenames_seen", ",", "\n", "num_for_this_process", ",", "\n", "last_filename", ",", "\n", "list", "(", "curr_volume", ".", "shape", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "time_start", ",", "\n", ")", "\n", "# Maybe not needed.", "\n", "del", "data", "\n", "yield", "(", "curr_volume", ",", "curr_target", ",", "reduce_list_of_dicts", "(", "loss_dict_list", ")", ",", "filename", ")", "if", "add_target", "else", "(", "\n", "curr_volume", ",", "\n", "reduce_list_of_dicts", "(", "loss_dict_list", ")", ",", "\n", "filename", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.evaluate": [[392, 457], ["torch.no_grad", "mri_models.MRIModelEngine.models_to_device", "mri_models.MRIModelEngine.models_validation_mode", "torch.cuda.empty_cache", "mri_models.MRIModelEngine.build_metrics", "collections.defaultdict", "enumerate", "direct.utils.reduce_list_of_dicts", "direct.utils.communication.reduce_tensor_dict", "direct.utils.communication.synchronize", "torch.cuda.empty_cache", "direct.utils.merge_list_of_dicts", "mri_models.MRIModelEngine.reconstruct_volumes", "mri_models.MRIModelEngine.logger.info", "val_losses.append", "direct.utils.communication.all_gather", "metric_fn().clone", "len", "visualize_slices.append", "visualize_target.append", "mri_models.MRIModelEngine.items", "metric_fn", "curr_metrics.items", "float"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_to_device", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.models_validation_mode", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_metrics", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.reduce_tensor_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.synchronize", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.merge_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.reconstruct_volumes", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.all_gather"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "# type: ignore", "\n", "self", ",", "\n", "data_loader", ":", "DataLoader", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Validation process.\n\n        Assumes that each batch only contains slices of the same volume *AND* that these are sequentially ordered.\n\n        Parameters\n        ----------\n        data_loader: DataLoader\n        loss_fns: Dict[str, Callable], optional\n\n        Returns\n        -------\n        loss_dict, all_gathered_metrics, visualize_slices, visualize_target\n        \"\"\"", "\n", "# TODO(jt): visualization should be a namedtuple or a dict or so", "\n", "# TODO(gy): Implement visualization of extra keys. E.g. sensitivity_map.", "\n", "# pylint: disable=arguments-differ, too-many-locals", "\n", "\n", "self", ".", "models_to_device", "(", ")", "\n", "self", ".", "models_validation_mode", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "volume_metrics", "=", "self", ".", "build_metrics", "(", "self", ".", "cfg", ".", "validation", ".", "metrics", ")", "# type: ignore", "\n", "val_losses", "=", "[", "]", "\n", "val_volume_metrics", ":", "Dict", "[", "PathLike", ",", "Dict", "]", "=", "defaultdict", "(", "dict", ")", "\n", "\n", "# Container to for the slices which can be visualized in TensorBoard.", "\n", "visualize_slices", ":", "List", "[", "np", ".", "ndarray", "]", "=", "[", "]", "\n", "visualize_target", ":", "List", "[", "np", ".", "ndarray", "]", "=", "[", "]", "\n", "\n", "for", "_", ",", "output", "in", "enumerate", "(", "\n", "self", ".", "reconstruct_volumes", "(", "\n", "data_loader", ",", "loss_fns", "=", "loss_fns", ",", "add_target", "=", "True", ",", "crop", "=", "self", ".", "cfg", ".", "validation", ".", "crop", "# type: ignore", "\n", ")", "\n", ")", ":", "\n", "            ", "volume", ",", "target", ",", "volume_loss_dict", ",", "filename", "=", "output", "\n", "curr_metrics", "=", "{", "\n", "metric_name", ":", "metric_fn", "(", "target", ",", "volume", ")", ".", "clone", "(", ")", "for", "metric_name", ",", "metric_fn", "in", "volume_metrics", ".", "items", "(", ")", "\n", "}", "\n", "curr_metrics_string", "=", "\", \"", ".", "join", "(", "[", "f\"{x}: {float(y)}\"", "for", "x", ",", "y", "in", "curr_metrics", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Metrics for %s: %s\"", ",", "filename", ",", "curr_metrics_string", ")", "\n", "# TODO: Path can be tricky if it is not unique (e.g. image.h5)", "\n", "val_volume_metrics", "[", "filename", ".", "name", "]", "=", "curr_metrics", "\n", "val_losses", ".", "append", "(", "volume_loss_dict", ")", "\n", "\n", "# Log the center slice of the volume", "\n", "if", "len", "(", "visualize_slices", ")", "<", "self", ".", "cfg", ".", "logging", ".", "tensorboard", ".", "num_images", ":", "# type: ignore", "\n", "                ", "visualize_slices", ".", "append", "(", "volume", "[", "volume", ".", "shape", "[", "0", "]", "//", "2", "]", ")", "\n", "visualize_target", ".", "append", "(", "target", "[", "target", ".", "shape", "[", "0", "]", "//", "2", "]", ")", "\n", "\n", "# Average loss dict", "\n", "", "", "loss_dict", "=", "reduce_list_of_dicts", "(", "val_losses", ")", "\n", "reduce_tensor_dict", "(", "loss_dict", ")", "\n", "\n", "communication", ".", "synchronize", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# TODO: Does not work yet with normal gather.", "\n", "all_gathered_metrics", "=", "merge_list_of_dicts", "(", "communication", ".", "all_gather", "(", "val_volume_metrics", ")", ")", "\n", "return", "loss_dict", ",", "all_gathered_metrics", ",", "visualize_slices", ",", "visualize_target", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_model_per_coil": [[458, 479], ["range", "torch.stack", "data.size", "data.select", "output.append"], "methods", ["None"], ["", "def", "compute_model_per_coil", "(", "self", ",", "model_name", ":", "str", ",", "data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of model `model_name` in `self.models` per coil.\n\n        Parameters\n        ----------\n        model_name: str\n            Model to run.\n        data: torch.Tensor\n            Multi-coil data of shape (batch, coil, complex=2, height, width).\n\n        Returns\n        -------\n        output: torch.Tensor\n            Computed output per coil.\n        \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "self", ".", "_coil_dim", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "self", ".", "_coil_dim", ",", "idx", ")", "\n", "output", ".", "append", "(", "self", ".", "models", "[", "model_name", "]", "(", "subselected_data", ")", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "output", ",", "dim", "=", "self", ".", "_coil_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._crop_volume": [[28, 54], ["direct.center_crop().unsqueeze", "direct.center_crop().unsqueeze", "all", "source.unsqueeze", "target.unsqueeze", "direct.center_crop", "direct.center_crop"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.center_crop", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.center_crop"], ["def", "_crop_volume", "(", "\n", "source", ":", "torch", ".", "Tensor", ",", "target", ":", "torch", ".", "Tensor", ",", "resolution", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"2D source/target cropper.\n\n    Parameters\n    ----------\n    source: torch.Tensor\n        Has shape (batch, height, width)\n    target: torch.Tensor\n        Has shape (batch, height, width)\n    resolution: list of ints or tuple of ints\n        Target resolution.\n\n    Returns\n    -------\n    (torch.Tensor, torch.Tensor)\n    \"\"\"", "\n", "\n", "if", "not", "resolution", "or", "all", "(", "_", "==", "0", "for", "_", "in", "resolution", ")", ":", "\n", "        ", "return", "source", ".", "unsqueeze", "(", "1", ")", ",", "target", ".", "unsqueeze", "(", "1", ")", "# Added channel dimension.", "\n", "\n", "", "source_abs", "=", "T", ".", "center_crop", "(", "source", ",", "resolution", ")", ".", "unsqueeze", "(", "1", ")", "# Added channel dimension.", "\n", "target_abs", "=", "T", ".", "center_crop", "(", "target", ",", "resolution", ")", ".", "unsqueeze", "(", "1", ")", "# Added channel dimension.", "\n", "\n", "return", "source_abs", ",", "target_abs", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._process_output": [[481, 516], ["direct.modulus_if_complex", "len", "T.center_crop().contiguous.unsqueeze", "direct.center_crop().contiguous", "scaling_factors.view().to", "direct.center_crop", "scaling_factors.view", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus_if_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.center_crop"], ["", "", "def", "_process_output", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "scaling_factors", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "resolution", ":", "Optional", "[", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "complex_axis", ":", "Optional", "[", "int", "]", "=", "-", "1", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Crops and scales input tensor.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    scaling_factors: Optional[torch.Tensor]\n        Scaling factor. Default: None.\n    resolution: Optional[Union[List[int], Tuple[int]]]\n        Resolution. Default: None.\n    complex_axis: Optional[int]\n        Dimension along which modulus of `data` will be computed (if it's complex). Default: -1 (last).\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "# data is of shape (batch, complex=2, height, width)", "\n", "if", "scaling_factors", "is", "not", "None", ":", "\n", "        ", "data", "=", "data", "*", "scaling_factors", ".", "view", "(", "-", "1", ",", "*", "(", "(", "1", ",", ")", "*", "(", "len", "(", "data", ".", "shape", ")", "-", "1", ")", ")", ")", ".", "to", "(", "data", ".", "device", ")", "\n", "\n", "", "data", "=", "T", ".", "modulus_if_complex", "(", "data", ",", "complex_axis", "=", "complex_axis", ")", "\n", "\n", "if", "len", "(", "data", ".", "shape", ")", "==", "3", ":", "# (batch, height, width)", "\n", "        ", "data", "=", "data", ".", "unsqueeze", "(", "1", ")", "# Added channel dimension.", "\n", "\n", "", "if", "resolution", "is", "not", "None", ":", "\n", "        ", "data", "=", "T", ".", "center_crop", "(", "data", ",", "resolution", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._compute_resolution": [[518, 548], ["_.detach().cpu().numpy().tolist", "ValueError", "_.detach().cpu().numpy", "_.detach().cpu", "_.detach"], "function", ["None"], ["", "def", "_compute_resolution", "(", "\n", "key", ":", "Optional", "[", "str", "]", ",", "reconstruction_size", ":", "Optional", "[", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", "]", "]", "]", "=", "None", "\n", ")", "->", "Union", "[", "List", "[", "int", "]", ",", "None", "]", ":", "\n", "    ", "\"\"\"Computes resolution.\n\n    Parameters\n    ----------\n    key: str\n        Can be `header` or None.\n    reconstruction_size: Optional[Union[List[int], Tuple[int]]]\n        Reconstruction size. Default: None.\n\n    Returns\n    -------\n    resolution: Union[str, List[int], None]\n        Resolution of reconstruction.\n    \"\"\"", "\n", "\n", "if", "key", "==", "\"header\"", ":", "\n", "# This will be of the form [tensor(x_0, x_1, ...), tensor(y_0, y_1,...), tensor(z_0, z_1, ...)] over", "\n", "# batches.", "\n", "        ", "resolution", "=", "[", "_", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "for", "_", "in", "reconstruction_size", "]", "# type: ignore", "\n", "# The volume sampler should give validation indices belonging to the *same* volume, so it should be", "\n", "# safe taking the first element, the matrix size are in x,y,z (we work in z,x,y).", "\n", "resolution", "=", "[", "_", "[", "0", "]", "for", "_", "in", "resolution", "]", "[", ":", "-", "1", "]", "\n", "return", "resolution", "\n", "", "elif", "not", "key", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cropping should be either set to `header` to get the values from the header or None.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models._get_filename_from_batch": [[550, 558], ["data.pop", "pathlib.Path", "len", "ValueError", "set", "set"], "function", ["None"], ["", "", "def", "_get_filename_from_batch", "(", "data", ":", "dict", ")", "->", "pathlib", ".", "Path", ":", "\n", "    ", "filenames", "=", "data", ".", "pop", "(", "\"filename\"", ")", "\n", "if", "len", "(", "set", "(", "filenames", ")", ")", "!=", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Expected a batch during validation to only contain filenames of one case. \"", "f\"Got {set(filenames)}.\"", "\n", ")", "\n", "# This can be fixed when there is a custom collate_fn", "\n", "", "return", "pathlib", ".", "Path", "(", "filenames", "[", "0", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.kikinet.kikinet.KIKINet.__init__": [[26, 123], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "direct.nn.mwcnn.mwcnn.MWCNN", "direct.nn.conv.conv.Conv2d", "unet", "NotImplementedError", "direct.nn.didn.didn.DIDN", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "unet", "NotImplementedError", "direct.nn.crossdomain.multicoil.MultiCoil", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "image_model_architecture", ":", "str", "=", "\"MWCNN\"", ",", "\n", "kspace_model_architecture", ":", "str", "=", "\"DIDN\"", ",", "\n", "num_iter", ":", "int", "=", "2", ",", "\n", "normalize", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`KIKINet`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        image_model_architecture: str\n            Image model architecture. Currently only implemented for MWCNN and (NORM)UNET. Default: 'MWCNN'.\n        kspace_model_architecture: str\n            Kspace model architecture. Currently only implemented for CONV and DIDN and (NORM)UNET. Default: 'DIDN'.\n        num_iter: int\n            Number of unrolled iterations.\n        normalize: bool\n            If true, input is normalised based on input scaling_factor.\n        kwargs: dict\n            Keyword arguments for model architectures.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "image_model", ":", "nn", ".", "Module", "\n", "if", "image_model_architecture", "==", "\"MWCNN\"", ":", "\n", "            ", "image_model", "=", "MWCNN", "(", "\n", "input_channels", "=", "2", ",", "\n", "first_conv_hidden_channels", "=", "kwargs", ".", "get", "(", "\"image_mwcnn_hidden_channels\"", ",", "32", ")", ",", "\n", "num_scales", "=", "kwargs", ".", "get", "(", "\"image_mwcnn_num_scales\"", ",", "4", ")", ",", "\n", "bias", "=", "kwargs", ".", "get", "(", "\"image_mwcnn_bias\"", ",", "False", ")", ",", "\n", "batchnorm", "=", "kwargs", ".", "get", "(", "\"image_mwcnn_batchnorm\"", ",", "False", ")", ",", "\n", ")", "\n", "", "elif", "image_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "unet", "=", "UnetModel2d", "if", "image_model_architecture", "==", "\"UNET\"", "else", "NormUnetModel2d", "\n", "image_model", "=", "unet", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "kwargs", ".", "get", "(", "\"image_unet_num_filters\"", ",", "8", ")", ",", "\n", "num_pool_layers", "=", "kwargs", ".", "get", "(", "\"image_unet_num_pool_layers\"", ",", "4", ")", ",", "\n", "dropout_probability", "=", "kwargs", ".", "get", "(", "\"image_unet_dropout_probability\"", ",", "0.0", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"XPDNet is currently implemented only with image_model_architecture == 'MWCNN', 'UNET' or 'NORMUNET.\"", "\n", "f\"Got {image_model_architecture}.\"", "\n", ")", "\n", "\n", "", "kspace_model", ":", "nn", ".", "Module", "\n", "if", "kspace_model_architecture", "==", "\"CONV\"", ":", "\n", "            ", "kspace_model", "=", "Conv2d", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "kwargs", ".", "get", "(", "\"kspace_conv_hidden_channels\"", ",", "16", ")", ",", "\n", "n_convs", "=", "kwargs", ".", "get", "(", "\"kspace_conv_n_convs\"", ",", "4", ")", ",", "\n", "batchnorm", "=", "kwargs", ".", "get", "(", "\"kspace_conv_batchnorm\"", ",", "False", ")", ",", "\n", ")", "\n", "", "elif", "kspace_model_architecture", "==", "\"DIDN\"", ":", "\n", "            ", "kspace_model", "=", "DIDN", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "kwargs", ".", "get", "(", "\"kspace_didn_hidden_channels\"", ",", "16", ")", ",", "\n", "num_dubs", "=", "kwargs", ".", "get", "(", "\"kspace_didn_num_dubs\"", ",", "6", ")", ",", "\n", "num_convs_recon", "=", "kwargs", ".", "get", "(", "\"kspace_didn_num_convs_recon\"", ",", "9", ")", ",", "\n", ")", "\n", "", "elif", "kspace_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "unet", "=", "UnetModel2d", "if", "kspace_model_architecture", "==", "\"UNET\"", "else", "NormUnetModel2d", "\n", "kspace_model", "=", "unet", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "kwargs", ".", "get", "(", "\"kspace_unet_num_filters\"", ",", "8", ")", ",", "\n", "num_pool_layers", "=", "kwargs", ".", "get", "(", "\"kspace_unet_num_pool_layers\"", ",", "4", ")", ",", "\n", "dropout_probability", "=", "kwargs", ".", "get", "(", "\"kspace_unet_dropout_probability\"", ",", "0.0", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"XPDNet is currently implemented for kspace_model_architecture == 'CONV', 'DIDN',\"", "\n", "f\" 'UNET' or 'NORMUNET'. Got kspace_model_architecture == {kspace_model_architecture}.\"", "\n", ")", "\n", "\n", "", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_complex_dim", "=", "-", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n", "self", ".", "image_model_list", "=", "nn", ".", "ModuleList", "(", "[", "image_model", "]", "*", "num_iter", ")", "\n", "self", ".", "kspace_model_list", "=", "nn", ".", "ModuleList", "(", "[", "MultiCoil", "(", "kspace_model", ",", "self", ".", "_coil_dim", ")", "]", "*", "num_iter", ")", "\n", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.kikinet.kikinet.KIKINet.forward": [[124, 185], ["masked_kspace.clone", "range", "direct.reduce_operator", "kikinet.KIKINet.backward_operator", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "kikinet.KIKINet.forward_operator", "torch.where.permute", "torch.where.permute", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "direct.reduce_operator.permute", "direct.expand_operator", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "scaling_factor", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes forward pass of :class:`KIKINet`.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n        scaling_factor: Optional[torch.Tensor]\n            Scaling factor of shape (N,). If None, no scaling is applied. Default: None.\n\n        Returns\n        -------\n        image: torch.Tensor\n            Output image of shape (N, height, width, complex=2).\n        \"\"\"", "\n", "\n", "kspace", "=", "masked_kspace", ".", "clone", "(", ")", "\n", "if", "self", ".", "normalize", "and", "scaling_factor", "is", "not", "None", ":", "\n", "            ", "kspace", "=", "kspace", "/", "(", "scaling_factor", "**", "2", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "            ", "kspace", "=", "self", ".", "kspace_model_list", "[", "idx", "]", "(", "kspace", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "\n", "image", "=", "T", ".", "reduce_operator", "(", "\n", "self", ".", "backward_operator", "(", "\n", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "kspace", ".", "dtype", ")", ".", "to", "(", "kspace", ".", "device", ")", ",", "\n", "kspace", ",", "\n", ")", ",", "\n", "self", ".", "_spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_map", ",", "\n", "self", ".", "_coil_dim", ",", "\n", ")", "\n", "\n", "image", "=", "self", ".", "image_model_list", "[", "idx", "]", "(", "image", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "if", "idx", "<", "self", ".", "num_iter", "-", "1", ":", "\n", "                ", "kspace", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "image", ".", "dtype", ")", ".", "to", "(", "image", ".", "device", ")", ",", "\n", "self", ".", "forward_operator", "(", "\n", "T", ".", "expand_operator", "(", "image", ",", "sensitivity_map", ",", "self", ".", "_coil_dim", ")", ",", "dim", "=", "self", ".", "_spatial_dims", "\n", ")", ",", "\n", ")", "\n", "\n", "", "", "if", "self", ".", "normalize", "and", "scaling_factor", "is", "not", "None", ":", "\n", "            ", "image", "=", "image", "*", "(", "scaling_factor", "**", "2", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "return", "image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.kikinet.kikinet_engine.KIKINetEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`KIKINetEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.kikinet.kikinet_engine.KIKINetEngine._do_iteration": [[43, 113], ["direct.utils.dict_to_device", "data[].clone", "kikinet_engine.KIKINetEngine.compute_sensitivity_map", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "torch.cuda.amp.autocast", "kikinet_engine.KIKINetEngine.model", "direct.modulus", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "kikinet_engine.KIKINetEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "kikinet_engine.KIKINetEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_image", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sampling_mask", "=", "data", "[", "\"sampling_mask\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "scaling_factor", "=", "data", "[", "\"scaling_factor\"", "]", ",", "\n", ")", "# shape (batch, height,  width, complex=2)", "\n", "\n", "output_image", "=", "T", ".", "modulus", "(", "output_image", ")", "# shape (batch, height,  width)", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomainnet_engine.MultiDomainNetEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MultiDomainNetEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomainnet_engine.MultiDomainNetEngine._do_iteration": [[43, 113], ["direct.utils.dict_to_device", "data[].clone", "multidomainnet_engine.MultiDomainNetEngine.compute_sensitivity_map", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "torch.cuda.amp.autocast", "multidomainnet_engine.MultiDomainNetEngine.model", "direct.root_sum_of_squares", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "multidomainnet_engine.MultiDomainNetEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "multidomainnet_engine.MultiDomainNetEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_multicoil_image", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", ")", "\n", "\n", "output_image", "=", "T", ".", "root_sum_of_squares", "(", "\n", "output_multicoil_image", ",", "self", ".", "_coil_dim", ",", "self", ".", "_complex_dim", "\n", ")", "# shape (batch, height,  width)", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainConv2d.__init__": [[12, 41], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MultiDomainConv2d`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "image_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "self", ".", "kspace_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "_channels_dim", "=", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainConv2d.forward": [[42, 79], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConv2d.kspace_conv", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConv2d.image_conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multidomain.MultiDomainConv2d.forward_operator", "multidomain.MultiDomainConv2d.backward_operator", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "multidomain.MultiDomainConv2d.permute().contiguous", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "multidomain.MultiDomainConv2d.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of of :class:`MultiDomainConv2d`.\n\n        Parameters\n        ----------\n        image: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "kspace", "=", "torch", ".", "cat", "(", "\n", "tensors", "=", "[", "\n", "self", ".", "forward_operator", "(", "\n", "im", ",", "\n", "dim", "=", "self", ".", "_spatial_dims", ",", "\n", ")", "\n", "for", "im", "in", "torch", ".", "split", "(", "image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "kspace", "=", "self", ".", "kspace_conv", "(", "kspace", ")", "\n", "\n", "backward", "=", "torch", ".", "cat", "(", "\n", "tensors", "=", "[", "\n", "self", ".", "backward_operator", "(", "\n", "ks", ",", "\n", "dim", "=", "self", ".", "_spatial_dims", ",", "\n", ")", "\n", "for", "ks", "in", "torch", ".", "split", "(", "kspace", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "image", "=", "self", ".", "image_conv", "(", "image", ")", "\n", "image", "=", "torch", ".", "cat", "(", "[", "image", ",", "backward", "]", ",", "dim", "=", "self", ".", "_channels_dim", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainConvTranspose2d.__init__": [[82, 111], ["torch.Module.__init__", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MultiDomainConvTranspose2d`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "image_conv", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "self", ".", "kspace_conv", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "_channels_dim", "=", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainConvTranspose2d.forward": [[112, 148], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConvTranspose2d.kspace_conv", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConvTranspose2d.image_conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multidomain.MultiDomainConvTranspose2d.forward_operator", "multidomain.MultiDomainConvTranspose2d.backward_operator", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "multidomain.MultiDomainConvTranspose2d.permute().contiguous", "multidomain.MultiDomainConvTranspose2d.permute().contiguous", "multidomain.MultiDomainConvTranspose2d.permute", "multidomain.MultiDomainConvTranspose2d.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of of :class:`MultiDomainConvTranspose2d`.\n\n        Parameters\n        ----------\n        image: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "kspace", "=", "torch", ".", "cat", "(", "\n", "tensors", "=", "[", "\n", "self", ".", "forward_operator", "(", "\n", "im", ",", "\n", "dim", "=", "self", ".", "_spatial_dims", ",", "\n", ")", "\n", "for", "im", "in", "torch", ".", "split", "(", "image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "kspace", "=", "self", ".", "kspace_conv", "(", "kspace", ")", "\n", "\n", "backward", "=", "torch", ".", "cat", "(", "\n", "tensors", "=", "[", "\n", "self", ".", "backward_operator", "(", "\n", "ks", ",", "\n", "dim", "=", "self", ".", "_spatial_dims", ",", "\n", ")", "\n", "for", "ks", "in", "torch", ".", "split", "(", "kspace", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "image", "=", "self", ".", "image_conv", "(", "image", ")", "\n", "return", "torch", ".", "cat", "(", "[", "image", ",", "backward", "]", ",", "dim", "=", "self", ".", "_channels_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainConvBlock.__init__": [[154, 196], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "multidomain.MultiDomainConv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "multidomain.MultiDomainConv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "dropout_probability", ":", "float", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MultiDomainConvBlock`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        dropout_probability: float\n            Dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "dropout_probability", "=", "dropout_probability", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "MultiDomainConv2d", "(", "\n", "forward_operator", ",", "backward_operator", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", "\n", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "dropout_probability", ")", ",", "\n", "MultiDomainConv2d", "(", "\n", "forward_operator", ",", "backward_operator", ",", "out_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", "\n", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "dropout_probability", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainConvBlock.forward": [[198, 210], ["multidomain.MultiDomainConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "_input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of of :class:`MultiDomainConvBlock`.\n\n        Parameters\n        ----------\n        _input: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "return", "self", ".", "layers", "(", "_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainConvBlock.__repr__": [[211, 215], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Representation of :class:`MultiDomainConvBlock`.\"\"\"", "\n", "return", "(", "\n", "f\"MultiDomainConvBlock(in_channels={self.in_channels}, out_channels={self.out_channels}, \"", "\n", "f\"dropout_probability={self.dropout_probability})\"", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.TransposeMultiDomainConvBlock.__init__": [[223, 241], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "multidomain.MultiDomainConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "forward_operator", ",", "backward_operator", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "MultiDomainConvTranspose2d", "(", "\n", "forward_operator", ",", "backward_operator", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "bias", "=", "False", "\n", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.TransposeMultiDomainConvBlock.forward": [[243, 255], ["multidomain.TransposeMultiDomainConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        input_data: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "return", "self", ".", "layers", "(", "input_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.TransposeMultiDomainConvBlock.__repr__": [[256, 258], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"MultiDomainConvBlock(in_channels={self.in_channels}, out_channels={self.out_channels})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainUnet2d.__init__": [[264, 326], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "multidomain.MultiDomainConvBlock", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "multidomain.TransposeMultiDomainConvBlock", "torch.Sequential", "torch.Sequential", "torch.Sequential", "multidomain.MultiDomainConvBlock", "multidomain.MultiDomainConvBlock", "multidomain.TransposeMultiDomainConvBlock", "multidomain.MultiDomainConvBlock", "multidomain.MultiDomainConvBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "num_filters", ":", "int", ",", "\n", "num_pool_layers", ":", "int", ",", "\n", "dropout_probability", ":", "float", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        in_channels: int\n            Number of input channels to the u-net.\n        out_channels: int\n            Number of output channels to the u-net.\n        num_filters: int\n            Number of output channels of the first convolutional layer.\n        num_pool_layers: int\n            Number of down-sampling and up-sampling layers (depth).\n        dropout_probability: float\n            Dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "num_pool_layers", "=", "num_pool_layers", "\n", "self", ".", "dropout_probability", "=", "dropout_probability", "\n", "\n", "self", ".", "down_sample_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "MultiDomainConvBlock", "(", "forward_operator", ",", "backward_operator", ",", "in_channels", ",", "num_filters", ",", "dropout_probability", ")", "]", "\n", ")", "\n", "ch", "=", "num_filters", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "down_sample_layers", "+=", "[", "\n", "MultiDomainConvBlock", "(", "forward_operator", ",", "backward_operator", ",", "ch", ",", "ch", "*", "2", ",", "dropout_probability", ")", "\n", "]", "\n", "ch", "*=", "2", "\n", "", "self", ".", "conv", "=", "MultiDomainConvBlock", "(", "forward_operator", ",", "backward_operator", ",", "ch", ",", "ch", "*", "2", ",", "dropout_probability", ")", "\n", "\n", "self", ".", "up_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "up_transpose_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "up_transpose_conv", "+=", "[", "TransposeMultiDomainConvBlock", "(", "forward_operator", ",", "backward_operator", ",", "ch", "*", "2", ",", "ch", ")", "]", "\n", "self", ".", "up_conv", "+=", "[", "\n", "MultiDomainConvBlock", "(", "forward_operator", ",", "backward_operator", ",", "ch", "*", "2", ",", "ch", ",", "dropout_probability", ")", "\n", "]", "\n", "ch", "//=", "2", "\n", "\n", "", "self", ".", "up_transpose_conv", "+=", "[", "TransposeMultiDomainConvBlock", "(", "forward_operator", ",", "backward_operator", ",", "ch", "*", "2", ",", "ch", ")", "]", "\n", "self", ".", "up_conv", "+=", "[", "\n", "nn", ".", "Sequential", "(", "\n", "MultiDomainConvBlock", "(", "forward_operator", ",", "backward_operator", ",", "ch", "*", "2", ",", "ch", ",", "dropout_probability", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ch", ",", "self", ".", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomain.MultiDomainUnet2d.forward": [[329, 369], ["enumerate", "multidomain.MultiDomainUnet2d.conv", "zip", "layer", "stack.append", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "stack.pop", "transpose_conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv", "sum", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        input_data: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "stack", "=", "[", "]", "\n", "output", "=", "input_data", "\n", "\n", "# Apply down-sampling layers", "\n", "for", "_", ",", "layer", "in", "enumerate", "(", "self", ".", "down_sample_layers", ")", ":", "\n", "            ", "output", "=", "layer", "(", "output", ")", "\n", "stack", ".", "append", "(", "output", ")", "\n", "output", "=", "F", ".", "avg_pool2d", "(", "output", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "", "output", "=", "self", ".", "conv", "(", "output", ")", "\n", "\n", "# Apply up-sampling layers", "\n", "for", "transpose_conv", ",", "conv", "in", "zip", "(", "self", ".", "up_transpose_conv", ",", "self", ".", "up_conv", ")", ":", "\n", "            ", "downsample_layer", "=", "stack", ".", "pop", "(", ")", "\n", "output", "=", "transpose_conv", "(", "output", ")", "\n", "\n", "# Reflect pad on the right/bottom if needed to handle odd input dimensions.", "\n", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "if", "output", ".", "shape", "[", "-", "1", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "padding", "[", "1", "]", "=", "1", "# Padding right", "\n", "", "if", "output", ".", "shape", "[", "-", "2", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "padding", "[", "3", "]", "=", "1", "# Padding bottom", "\n", "", "if", "sum", "(", "padding", ")", "!=", "0", ":", "\n", "                ", "output", "=", "F", ".", "pad", "(", "output", ",", "padding", ",", "\"reflect\"", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "downsample_layer", "]", ",", "dim", "=", "1", ")", "\n", "output", "=", "conv", "(", "output", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomainnet.StandardizationLayer.__init__": [[23, 36], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "coil_dim", ":", "int", "=", "1", ",", "channel_dim", ":", "int", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Inits :class:`StandardizationLayer`.\n\n        Parameters\n        ----------\n        coil_dim: int\n            Coil dimension. Default: 1.\n        channel_dim: int\n            Channel dimension. Default: -1.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "self", ".", "channel_dim", "=", "channel_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomainnet.StandardizationLayer.forward": [[37, 65], ["direct.reduce_operator", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "direct.reduce_operator.unsqueeze", "direct.complex_multiplication", "direct.reduce_operator.unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "coil_images.size", "residual_image.select"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication"], ["", "def", "forward", "(", "self", ",", "coil_images", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`StandardizationLayer`.\n\n        Parameters\n        ----------\n        coil_images: torch.Tensor\n            Coil images tensor.\n        sensitivity_map: torch.Tensor\n            Sensitivity maps.\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "combined_image", "=", "T", ".", "reduce_operator", "(", "coil_images", ",", "sensitivity_map", ",", "self", ".", "coil_dim", ")", "\n", "residual_image", "=", "combined_image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "-", "T", ".", "complex_multiplication", "(", "\n", "sensitivity_map", ",", "combined_image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "\n", ")", "\n", "concat", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "torch", ".", "cat", "(", "[", "combined_image", ",", "residual_image", ".", "select", "(", "self", ".", "coil_dim", ",", "idx", ")", "]", ",", "self", ".", "channel_dim", ")", ".", "unsqueeze", "(", "\n", "self", ".", "coil_dim", "\n", ")", "\n", "for", "idx", "in", "range", "(", "coil_images", ".", "size", "(", "self", ".", "coil_dim", ")", ")", "\n", "]", ",", "\n", "self", ".", "coil_dim", ",", "\n", ")", "\n", "return", "concat", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomainnet.MultiDomainNet.__init__": [[73, 118], ["torch.Module.__init__", "direct.nn.multidomainnet.multidomain.MultiDomainUnet2d", "multidomainnet.StandardizationLayer"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "standardization", ":", "bool", "=", "True", ",", "\n", "num_filters", ":", "int", "=", "16", ",", "\n", "num_pool_layers", ":", "int", "=", "4", ",", "\n", "dropout_probability", ":", "float", "=", "0.0", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MultiDomainNet`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        standardization: bool\n            If True standardization is used. Default: True.\n        num_filters: int\n            Number of filters for the :class:`MultiDomainUnet` module. Default: 16.\n        num_pool_layers: int\n            Number of pooling layers for the :class:`MultiDomainUnet` module. Default: 4.\n        dropout_probability: float\n            Dropout probability for the :class:`MultiDomainUnet` module. Default: 0.0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_complex_dim", "=", "-", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n", "if", "standardization", ":", "\n", "            ", "self", ".", "standardization", "=", "StandardizationLayer", "(", "self", ".", "_coil_dim", ",", "self", ".", "_complex_dim", ")", "\n", "\n", "", "self", ".", "unet", "=", "MultiDomainUnet2d", "(", "\n", "forward_operator", ",", "\n", "backward_operator", ",", "\n", "in_channels", "=", "4", "if", "standardization", "else", "2", ",", "# if standardization, in_channels is 4 due to standardized input", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "num_filters", ",", "\n", "num_pool_layers", "=", "num_pool_layers", ",", "\n", "dropout_probability", "=", "dropout_probability", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomainnet.MultiDomainNet._compute_model_per_coil": [[120, 140], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "data.size", "data.select", "torch.stack.append", "torch.stack.append", "model"], "methods", ["None"], ["", "def", "_compute_model_per_coil", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes model per coil.\n\n        Parameters\n        ----------\n        model: nn.Module\n            Model to compute.\n        data: torch.Tensor\n            Data to pass in the model.\n\n        Returns\n        -------\n        output: torch.Tensor\n        \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "self", ".", "_coil_dim", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "self", ".", "_coil_dim", ",", "idx", ")", "\n", "output", ".", "append", "(", "model", "(", "subselected_data", ")", ")", "\n", "", "output", "=", "torch", ".", "stack", "(", "output", ",", "dim", "=", "self", ".", "_coil_dim", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.multidomainnet.multidomainnet.MultiDomainNet.forward": [[141, 163], ["multidomainnet.MultiDomainNet.backward_operator", "hasattr", "multidomainnet.MultiDomainNet._compute_model_per_coil().permute", "multidomainnet.MultiDomainNet.standardization", "multidomainnet.MultiDomainNet._compute_model_per_coil", "multidomainnet.MultiDomainNet.permute"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._compute_model_per_coil"], ["", "def", "forward", "(", "self", ",", "masked_kspace", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`MultiDomainNet`.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n\n        Returns\n        -------\n        output_image: torch.Tensor\n            Multi-coil output image of shape (N, coil, height, width, complex=2).\n        \"\"\"", "\n", "input_image", "=", "self", ".", "backward_operator", "(", "masked_kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", "\n", "if", "hasattr", "(", "self", ",", "\"standardization\"", ")", ":", "\n", "            ", "input_image", "=", "self", ".", "standardization", "(", "input_image", ",", "sensitivity_map", ")", "\n", "", "output_image", "=", "self", ".", "_compute_model_per_coil", "(", "self", ".", "unet", ",", "input_image", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ")", ".", "permute", "(", "\n", "0", ",", "1", ",", "3", ",", "4", ",", "2", "\n", ")", "\n", "return", "output_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.multicoil.MultiCoil.__init__": [[15, 33], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "coil_dim", ":", "int", "=", "1", ",", "coil_to_batch", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MultiCoil`.\n\n        Parameters\n        ----------\n        model: nn.Module\n            Any nn.Module that takes as input with 4D data (N, H, W, C). Typically a convolutional-like model.\n        coil_dim: int\n            Coil dimension. Default: 1.\n        coil_to_batch: bool\n            If True batch and coil dimensions are merged when forwarded by the model and unmerged when outputted.\n            Otherwise, input is forwarded to the model per coil.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "coil_to_batch", "=", "coil_to_batch", "\n", "self", ".", "_coil_dim", "=", "coil_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.multicoil.MultiCoil._compute_model_per_coil": [[34, 42], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "data.size", "data.select", "output.append", "multicoil.MultiCoil.model"], "methods", ["None"], ["", "def", "_compute_model_per_coil", "(", "self", ",", "data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "output", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "self", ".", "_coil_dim", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "self", ".", "_coil_dim", ",", "idx", ")", "\n", "output", ".", "append", "(", "self", ".", "model", "(", "subselected_data", ")", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "output", ",", "dim", "=", "self", ".", "_coil_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.multicoil.MultiCoil.forward": [[43, 67], ["multicoil.MultiCoil.clone", "multicoil.MultiCoil.size", "multicoil.MultiCoil.reshape().permute().contiguous", "multicoil.MultiCoil.model().permute", "multicoil.MultiCoil.reshape", "multicoil.MultiCoil._compute_model_per_coil().contiguous", "multicoil.MultiCoil.reshape().permute", "multicoil.MultiCoil.model", "multicoil.MultiCoil._compute_model_per_coil", "multicoil.MultiCoil.reshape"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._compute_model_per_coil"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs the forward pass of MultiCoil.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Multi-coil input of shape (N, coil, height, width, in_channels).\n\n        Returns\n        -------\n        out: torch.Tensor\n            Multi-coil output of shape (N, coil, height, width, out_channels).\n        \"\"\"", "\n", "if", "self", ".", "coil_to_batch", ":", "\n", "            ", "x", "=", "x", ".", "clone", "(", ")", "\n", "batch", ",", "coil", ",", "height", ",", "width", ",", "channels", "=", "x", ".", "size", "(", ")", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "batch", "*", "coil", ",", "height", ",", "width", ",", "channels", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "self", ".", "model", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "x", "=", "x", ".", "reshape", "(", "batch", ",", "coil", ",", "height", ",", "width", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "_compute_model_per_coil", "(", "x", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork.__init__": [[15, 77], ["torch.Module.__init__", "set().issubset", "ValueError", "len", "crossdomain.CrossDomainNetwork.domain_sequence.count", "ValueError", "domain_sequence.strip", "len", "crossdomain.CrossDomainNetwork.domain_sequence.count", "ValueError", "set"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "image_model_list", ":", "nn", ".", "ModuleList", ",", "\n", "kspace_model_list", ":", "Optional", "[", "Union", "[", "nn", ".", "ModuleList", ",", "None", "]", "]", "=", "None", ",", "\n", "domain_sequence", ":", "str", "=", "\"KIKI\"", ",", "\n", "image_buffer_size", ":", "int", "=", "1", ",", "\n", "kspace_buffer_size", ":", "int", "=", "1", ",", "\n", "normalize_image", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits CrossDomainNetwork.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        image_model_list: nn.ModuleList\n            Image domain model list.\n        kspace_model_list: Optional[nn.ModuleList]\n            K-space domain model list. If set to None, a correction step is applied. Default: None.\n        domain_sequence: str\n            Domain sequence containing only \"K\" (k-space domain) and/or \"I\" (image domain). Default: \"KIKI\".\n        image_buffer_size: int\n            Image buffer size. Default: 1.\n        kspace_buffer_size: int\n            K-space buffer size. Default: 1.\n        normalize_image: bool\n            If True, input is normalized. Default: False.\n        kwargs: dict\n            Keyword Arguments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "\n", "self", ".", "domain_sequence", "=", "[", "domain_name", "for", "domain_name", "in", "domain_sequence", ".", "strip", "(", ")", "]", "\n", "if", "not", "set", "(", "self", ".", "domain_sequence", ")", ".", "issubset", "(", "{", "\"K\"", ",", "\"I\"", "}", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid domain sequence. Got {domain_sequence}. Should only contain 'K' and 'I'.\"", ")", "\n", "\n", "", "if", "kspace_model_list", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "kspace_model_list", ")", "!=", "self", ".", "domain_sequence", ".", "count", "(", "\"K\"", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"K-space domain steps do not match k-space model list length.\"", ")", "\n", "\n", "", "", "if", "len", "(", "image_model_list", ")", "!=", "self", ".", "domain_sequence", ".", "count", "(", "\"I\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Image domain steps do not match image model list length.\"", ")", "\n", "\n", "", "self", ".", "kspace_model_list", "=", "kspace_model_list", "\n", "self", ".", "kspace_buffer_size", "=", "kspace_buffer_size", "\n", "\n", "self", ".", "image_model_list", "=", "image_model_list", "\n", "self", ".", "image_buffer_size", "=", "image_buffer_size", "\n", "\n", "self", ".", "normalize_image", "=", "normalize_image", "\n", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_complex_dim", "=", "-", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork.kspace_correction": [[78, 109], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "crossdomain.CrossDomainNetwork._forward_operator", "image.clone", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat.permute", "torch.cat.permute"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._forward_operator"], ["", "def", "kspace_correction", "(", "\n", "self", ",", "\n", "block_idx", ":", "int", ",", "\n", "image_buffer", ":", "torch", ".", "Tensor", ",", "\n", "kspace_buffer", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "forward_buffer", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_forward_operator", "(", "\n", "image", ".", "clone", "(", ")", ",", "\n", "sampling_mask", ",", "\n", "sensitivity_map", ",", "\n", ")", "\n", "for", "image", "in", "torch", ".", "split", "(", "image_buffer", ",", "2", ",", "self", ".", "_complex_dim", ")", "\n", "]", ",", "\n", "self", ".", "_complex_dim", ",", "\n", ")", "\n", "kspace_buffer", "=", "torch", ".", "cat", "(", "[", "kspace_buffer", ",", "forward_buffer", ",", "masked_kspace", "]", ",", "self", ".", "_complex_dim", ")", "\n", "\n", "if", "self", ".", "kspace_model_list", "is", "not", "None", ":", "\n", "            ", "kspace_buffer", "=", "self", ".", "kspace_model_list", "[", "block_idx", "]", "(", "kspace_buffer", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ")", ".", "permute", "(", "\n", "0", ",", "1", ",", "3", ",", "4", ",", "2", "\n", ")", "\n", "", "else", ":", "\n", "            ", "kspace_buffer", "=", "kspace_buffer", "[", "...", ",", ":", "2", "]", "-", "kspace_buffer", "[", "...", ",", "2", ":", "4", "]", "\n", "\n", "", "return", "kspace_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork.image_correction": [[110, 131], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "crossdomain.CrossDomainNetwork._backward_operator", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "kspace.clone", "torch.split", "torch.split", "torch.split", "torch.split"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._backward_operator"], ["", "def", "image_correction", "(", "\n", "self", ",", "\n", "block_idx", ":", "int", ",", "\n", "image_buffer", ":", "torch", ".", "Tensor", ",", "\n", "kspace_buffer", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "backward_buffer", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "_backward_operator", "(", "kspace", ".", "clone", "(", ")", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "for", "kspace", "in", "torch", ".", "split", "(", "kspace_buffer", ",", "2", ",", "self", ".", "_complex_dim", ")", "\n", "]", ",", "\n", "self", ".", "_complex_dim", ",", "\n", ")", "\n", "\n", "image_buffer", "=", "torch", ".", "cat", "(", "[", "image_buffer", ",", "backward_buffer", "]", ",", "self", ".", "_complex_dim", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "image_buffer", "=", "self", ".", "image_model_list", "[", "block_idx", "]", "(", "image_buffer", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "return", "image_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork._forward_operator": [[132, 141], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "crossdomain.CrossDomainNetwork.forward_operator", "direct.expand_operator", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator"], ["", "def", "_forward_operator", "(", "\n", "self", ",", "image", ":", "torch", ".", "Tensor", ",", "sampling_mask", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "forward", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "image", ".", "dtype", ")", ".", "to", "(", "image", ".", "device", ")", ",", "\n", "self", ".", "forward_operator", "(", "T", ".", "expand_operator", "(", "image", ",", "sensitivity_map", ",", "self", ".", "_coil_dim", ")", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "\n", ")", "\n", "return", "forward", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork._backward_operator": [[142, 158], ["direct.reduce_operator", "crossdomain.CrossDomainNetwork.backward_operator", "torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator"], ["", "def", "_backward_operator", "(", "\n", "self", ",", "kspace", ":", "torch", ".", "Tensor", ",", "sampling_mask", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "backward", "=", "T", ".", "reduce_operator", "(", "\n", "self", ".", "backward_operator", "(", "\n", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "kspace", ".", "dtype", ")", ".", "to", "(", "kspace", ".", "device", ")", ",", "\n", "kspace", ",", "\n", ")", ",", "\n", "self", ".", "_spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_map", ",", "\n", "self", ".", "_coil_dim", ",", "\n", ")", "\n", "return", "backward", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork.forward": [[159, 214], ["crossdomain.CrossDomainNetwork._backward_operator", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "crossdomain.CrossDomainNetwork.kspace_correction", "crossdomain.CrossDomainNetwork.image_correction"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._backward_operator", "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork.kspace_correction", "home.repos.pwc.inspect_result.directgroup_direct.crossdomain.crossdomain.CrossDomainNetwork.image_correction"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "scaling_factor", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes the forward pass of :class:`CrossDomainNetwork`.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n        scaling_factor: Optional[torch.Tensor]\n            Scaling factor of shape (N,). If None, no scaling is applied. Default: None.\n\n        Returns\n        -------\n        out_image: torch.Tensor\n            Output image of shape (N, height, width, complex=2).\n        \"\"\"", "\n", "input_image", "=", "self", ".", "_backward_operator", "(", "masked_kspace", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "\n", "if", "self", ".", "normalize_image", "and", "scaling_factor", "is", "not", "None", ":", "\n", "            ", "input_image", "=", "input_image", "/", "scaling_factor", "**", "2", "\n", "masked_kspace", "=", "masked_kspace", "/", "scaling_factor", "**", "2", "\n", "\n", "", "image_buffer", "=", "torch", ".", "cat", "(", "[", "input_image", "]", "*", "self", ".", "image_buffer_size", ",", "self", ".", "_complex_dim", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", "\n", "\n", "kspace_buffer", "=", "torch", ".", "cat", "(", "[", "masked_kspace", "]", "*", "self", ".", "kspace_buffer_size", ",", "self", ".", "_complex_dim", ")", ".", "to", "(", "\n", "masked_kspace", ".", "device", "\n", ")", "\n", "\n", "kspace_block_idx", ",", "image_block_idx", "=", "0", ",", "0", "\n", "for", "block_domain", "in", "self", ".", "domain_sequence", ":", "\n", "            ", "if", "block_domain", "==", "\"K\"", ":", "\n", "                ", "kspace_buffer", "=", "self", ".", "kspace_correction", "(", "\n", "kspace_block_idx", ",", "image_buffer", ",", "kspace_buffer", ",", "sampling_mask", ",", "sensitivity_map", ",", "masked_kspace", "\n", ")", "\n", "kspace_block_idx", "+=", "1", "\n", "", "else", ":", "\n", "                ", "image_buffer", "=", "self", ".", "image_correction", "(", "\n", "image_block_idx", ",", "image_buffer", ",", "kspace_buffer", ",", "sampling_mask", ",", "sensitivity_map", "\n", ")", "\n", "image_block_idx", "+=", "1", "\n", "\n", "", "", "if", "self", ".", "normalize_image", "and", "scaling_factor", "is", "not", "None", ":", "\n", "            ", "image_buffer", "=", "image_buffer", "*", "scaling_factor", "**", "2", "\n", "\n", "", "out_image", "=", "image_buffer", "[", "...", ",", ":", "2", "]", "\n", "return", "out_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet_engine.RecurrentVarNetEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`RecurrentVarNetEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet_engine.RecurrentVarNetEngine._do_iteration": [[43, 115], ["direct.utils.dict_to_device", "data[].clone", "recurrentvarnet_engine.RecurrentVarNetEngine.compute_sensitivity_map", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "torch.cuda.amp.autocast", "recurrentvarnet_engine.RecurrentVarNetEngine.model", "direct.root_sum_of_squares", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "recurrentvarnet_engine.RecurrentVarNetEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "recurrentvarnet_engine.RecurrentVarNetEngine.backward_operator", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "recurrentvarnet_engine.RecurrentVarNetEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_kspace", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sampling_mask", "=", "data", "[", "\"sampling_mask\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", ")", "\n", "\n", "output_image", "=", "T", ".", "root_sum_of_squares", "(", "\n", "self", ".", "backward_operator", "(", "output_kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "# type: ignore", "\n", "dim", "=", "self", ".", "_coil_dim", ",", "\n", ")", "# shape (batch, height,  width)", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet.RecurrentInit.__init__": [[26, 70], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "zip", "numpy.sum", "range", "recurrentvarnet.RecurrentInit.conv_blocks.append", "recurrentvarnet.RecurrentInit.out_blocks.append", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "channels", ":", "Tuple", "[", "int", ",", "...", "]", ",", "\n", "dilations", ":", "Tuple", "[", "int", ",", "...", "]", ",", "\n", "depth", ":", "int", "=", "2", ",", "\n", "multiscale_depth", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`RecurrentInit`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Input channels.\n        out_channels: int\n            Number of hidden channels of the recurrent unit of RecurrentVarNet Block.\n        channels: tuple\n            Channels :math:`n_d` in the convolutional layers of initializer.\n        dilations: tuple\n            Dilations :math:`p` of the convolutional layers of the initializer.\n        depth: int\n            RecurrentVarNet Block number of layers :math:`n_l`.\n        multiscale_depth: 1\n            Number of feature layers to aggregate for the output, if 1, multi-scale context aggregation is disabled.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "multiscale_depth", "=", "multiscale_depth", "\n", "tch", "=", "in_channels", "\n", "for", "(", "curr_channels", ",", "curr_dilations", ")", "in", "zip", "(", "channels", ",", "dilations", ")", ":", "\n", "            ", "block", "=", "[", "\n", "nn", ".", "ReplicationPad2d", "(", "curr_dilations", ")", ",", "\n", "nn", ".", "Conv2d", "(", "tch", ",", "curr_channels", ",", "3", ",", "padding", "=", "0", ",", "dilation", "=", "curr_dilations", ")", ",", "\n", "]", "\n", "tch", "=", "curr_channels", "\n", "self", ".", "conv_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "", "tch", "=", "np", ".", "sum", "(", "channels", "[", "-", "multiscale_depth", ":", "]", ")", "\n", "for", "_", "in", "range", "(", "depth", ")", ":", "\n", "            ", "block", "=", "[", "nn", ".", "Conv2d", "(", "tch", ",", "out_channels", ",", "1", ",", "padding", "=", "0", ")", "]", "\n", "self", ".", "out_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet.RecurrentInit.forward": [[71, 98], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "output_list.append", "block", "features.append", "block"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes initialization for recurrent unit given input `x`.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Initialization for RecurrentInit.\n\n        Returns\n        -------\n        out: torch.Tensor\n            Initial recurrent hidden state from input `x`.\n        \"\"\"", "\n", "\n", "features", "=", "[", "]", "\n", "for", "block", "in", "self", ".", "conv_blocks", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "block", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "if", "self", ".", "multiscale_depth", ">", "1", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "", "", "if", "self", ".", "multiscale_depth", ">", "1", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "features", "[", "-", "self", ".", "multiscale_depth", ":", "]", ",", "dim", "=", "1", ")", "\n", "", "output_list", "=", "[", "]", "\n", "for", "block", "in", "self", ".", "out_blocks", ":", "\n", "            ", "y", "=", "F", ".", "relu", "(", "block", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "output_list", ".", "append", "(", "y", ")", "\n", "", "out", "=", "torch", ".", "stack", "(", "output_list", ",", "dim", "=", "-", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet.RecurrentVarNet.__init__": [[109, 211], ["torch.Module.__init__", "kwargs.keys", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "recurrentvarnet.RecurrentInit", "recurrentvarnet.RecurrentVarNet.block_list.append", "ValueError", "ValueError", "recurrentvarnet.RecurrentVarNetBlock", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "in_channels", ":", "int", "=", "2", ",", "\n", "num_steps", ":", "int", "=", "15", ",", "\n", "recurrent_hidden_channels", ":", "int", "=", "64", ",", "\n", "recurrent_num_layers", ":", "int", "=", "4", ",", "\n", "no_parameter_sharing", ":", "bool", "=", "True", ",", "\n", "learned_initializer", ":", "bool", "=", "False", ",", "\n", "initializer_initialization", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "initializer_channels", ":", "Optional", "[", "Tuple", "[", "int", ",", "...", "]", "]", "=", "(", "32", ",", "32", ",", "64", ",", "64", ")", ",", "\n", "initializer_dilations", ":", "Optional", "[", "Tuple", "[", "int", ",", "...", "]", "]", "=", "(", "1", ",", "1", ",", "2", ",", "4", ")", ",", "\n", "initializer_multiscale", ":", "int", "=", "1", ",", "\n", "normalized", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`RecurrentVarNet`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        num_steps: int\n            Number of iterations :math:`T`.\n        in_channels: int\n            Input channel number. Default is 2 for complex data.\n        recurrent_hidden_channels: int\n            Hidden channels number for the recurrent unit of the RecurrentVarNet Blocks. Default: 64.\n        recurrent_num_layers: int\n            Number of layers for the recurrent unit of the RecurrentVarNet Block (:math:`n_l`). Default: 4.\n        no_parameter_sharing: bool\n            If False, the same :class:`RecurrentVarNetBlock` is used for all num_steps. Default: True.\n        learned_initializer: bool\n            If True an RSI module is used. Default: False.\n        initializer_initialization: str, Optional\n            Type of initialization for the RSI module. Can be either 'sense', 'zero-filled' or 'input-image'.\n            Default: None.\n        initializer_channels: tuple\n            Channels :math:`n_d` in the convolutional layers of the RSI module. Default: (32, 32, 64, 64).\n        initializer_dilations: tuple\n            Dilations :math:`p` of the convolutional layers of the RSI module. Default: (1, 1, 2, 4).\n        initializer_multiscale: int\n            RSI module number of feature layers to aggregate for the output, if 1, multi-scale context aggregation\n            is disabled. Default: 1.\n        normalized: bool\n            If True, :class:`NormConv2dGRU` will be used as a regularizer in the :class:`RecurrentVarNetBlocks`. Default: False.\n        \"\"\"", "\n", "super", "(", "RecurrentVarNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "extra_keys", "=", "kwargs", ".", "keys", "(", ")", "\n", "for", "extra_key", "in", "extra_keys", ":", "\n", "            ", "if", "extra_key", "not", "in", "[", "\n", "\"model_name\"", ",", "\n", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{type(self).__name__} got key `{extra_key}` which is not supported.\"", ")", "\n", "\n", "", "", "self", ".", "initializer", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", "\n", "if", "(", "\n", "learned_initializer", "\n", "and", "initializer_initialization", "is", "not", "None", "\n", "and", "initializer_channels", "is", "not", "None", "\n", "and", "initializer_dilations", "is", "not", "None", "\n", ")", ":", "\n", "            ", "if", "initializer_initialization", "not", "in", "[", "\n", "\"sense\"", ",", "\n", "\"input_image\"", ",", "\n", "\"zero_filled\"", ",", "\n", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Unknown initializer_initialization. Expected `sense`, `'input_image` or `zero_filled`.\"", "\n", "f\"Got {initializer_initialization}.\"", "\n", ")", "\n", "", "self", ".", "initializer_initialization", "=", "initializer_initialization", "\n", "self", ".", "initializer", "=", "RecurrentInit", "(", "\n", "in_channels", ",", "\n", "recurrent_hidden_channels", ",", "\n", "channels", "=", "initializer_channels", ",", "\n", "dilations", "=", "initializer_dilations", ",", "\n", "depth", "=", "recurrent_num_layers", ",", "\n", "multiscale_depth", "=", "initializer_multiscale", ",", "\n", ")", "\n", "", "self", ".", "num_steps", "=", "num_steps", "\n", "self", ".", "no_parameter_sharing", "=", "no_parameter_sharing", "\n", "self", ".", "block_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_steps", "if", "self", ".", "no_parameter_sharing", "else", "1", ")", ":", "\n", "            ", "self", ".", "block_list", ".", "append", "(", "\n", "RecurrentVarNetBlock", "(", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "in_channels", "=", "in_channels", ",", "\n", "hidden_channels", "=", "recurrent_hidden_channels", ",", "\n", "num_layers", "=", "recurrent_num_layers", ",", "\n", "normalized", "=", "normalized", ",", "\n", ")", "\n", ")", "\n", "", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet.RecurrentVarNet.compute_sense_init": [[212, 239], ["direct.data.transforms.complex_multiplication", "input_image.sum.sum.sum", "direct.data.transforms.conjugate", "recurrentvarnet.RecurrentVarNet.backward_operator"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate"], ["", "def", "compute_sense_init", "(", "self", ",", "kspace", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"Computes sense initialization :math:`x_{\\text{SENSE}}`:\n\n        .. math::\n            x_{\\text{SENSE}} = \\sum_{k=1}^{n_c} {S^{k}}^* \\times y^k\n\n        where :math:`y^k` denotes the data from coil :math:`k`.\n\n        Parameters\n        ----------\n        kspace: torch.Tensor\n            k-space of shape (N, coil, height, width, complex=2).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n\n        Returns\n        -------\n        input_image: torch.Tensor\n            Sense initialization :math:`x_{\\text{SENSE}}`.\n        \"\"\"", "\n", "input_image", "=", "complex_multiplication", "(", "\n", "conjugate", "(", "sensitivity_map", ")", ",", "\n", "self", ".", "backward_operator", "(", "kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "\n", ")", "\n", "input_image", "=", "input_image", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", "\n", "return", "input_image", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet.RecurrentVarNet.forward": [[240, 303], ["masked_kspace.clone", "range", "recurrentvarnet.RecurrentVarNet.initializer", "block", "recurrentvarnet.RecurrentVarNet.compute_sense_init().unsqueeze", "recurrentvarnet.RecurrentVarNet.forward_operator().sum().permute", "kwargs[].unsqueeze", "recurrentvarnet.RecurrentVarNet.compute_sense_init", "ValueError", "recurrentvarnet.RecurrentVarNet.backward_operator", "recurrentvarnet.RecurrentVarNet.forward_operator().sum", "recurrentvarnet.RecurrentVarNet.forward_operator"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIM.compute_sense_init"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes forward pass of :class:`RecurrentVarNet`.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        sensitivity_map: torch.Tensor\n            Coil sensitivities of shape (N, coil, height, width, complex=2).\n\n        Returns\n        -------\n        kspace_prediction: torch.Tensor\n            k-space prediction.\n        \"\"\"", "\n", "\n", "previous_state", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", "\n", "\n", "if", "self", ".", "initializer", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "initializer_initialization", "==", "\"sense\"", ":", "\n", "                ", "initializer_input_image", "=", "self", ".", "compute_sense_init", "(", "\n", "kspace", "=", "masked_kspace", ",", "\n", "sensitivity_map", "=", "sensitivity_map", ",", "\n", ")", ".", "unsqueeze", "(", "self", ".", "_coil_dim", ")", "\n", "", "elif", "self", ".", "initializer_initialization", "==", "\"input_image\"", ":", "\n", "                ", "if", "\"initial_image\"", "not", "in", "kwargs", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "f\"`'initial_image` is required as input if initializer_initialization \"", "\n", "f\"is {self.initializer_initialization}.\"", "\n", ")", "\n", "", "initializer_input_image", "=", "kwargs", "[", "\"initial_image\"", "]", ".", "unsqueeze", "(", "self", ".", "_coil_dim", ")", "\n", "", "elif", "self", ".", "initializer_initialization", "==", "\"zero_filled\"", ":", "\n", "                ", "initializer_input_image", "=", "self", ".", "backward_operator", "(", "masked_kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", "\n", "\n", "", "previous_state", "=", "self", ".", "initializer", "(", "\n", "self", ".", "forward_operator", "(", "initializer_input_image", ",", "dim", "=", "self", ".", "_spatial_dims", ")", "\n", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", ")", "\n", "\n", "", "kspace_prediction", "=", "masked_kspace", ".", "clone", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "block", "=", "self", ".", "block_list", "[", "step", "]", "if", "self", ".", "no_parameter_sharing", "else", "self", ".", "block_list", "[", "0", "]", "\n", "kspace_prediction", ",", "previous_state", "=", "block", "(", "\n", "kspace_prediction", ",", "\n", "masked_kspace", ",", "\n", "sampling_mask", ",", "\n", "sensitivity_map", ",", "\n", "previous_state", ",", "\n", "self", ".", "_coil_dim", ",", "\n", "self", ".", "_spatial_dims", ",", "\n", ")", "\n", "\n", "", "return", "kspace_prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet.RecurrentVarNetBlock.__init__": [[315, 355], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "direct.nn.recurrent.recurrent.NormConv2dGRU", "direct.nn.recurrent.recurrent.Conv2dGRU"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "in_channels", ":", "int", "=", "2", ",", "\n", "hidden_channels", ":", "int", "=", "64", ",", "\n", "num_layers", ":", "int", "=", "4", ",", "\n", "normalized", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits RecurrentVarNetBlock.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Fourier Transform.\n        backward_operator: Callable\n            Backward Fourier Transform.\n        in_channels: int,\n            Input channel number. Default is 2 for complex data.\n        hidden_channels: int,\n            Hidden channels. Default: 64.\n        num_layers: int,\n            Number of layers of :math:`n_l` recurrent unit. Default: 4.\n        normalized: bool\n            If True, :class:`NormConv2dGRU` will be used as a regularizer. Default: False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "\n", "self", ".", "learning_rate", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ")", "# :math:`\\alpha_t`", "\n", "regularizer_params", "=", "{", "\n", "\"in_channels\"", ":", "in_channels", ",", "\n", "\"hidden_channels\"", ":", "hidden_channels", ",", "\n", "\"num_layers\"", ":", "num_layers", ",", "\n", "\"replication_padding\"", ":", "True", ",", "\n", "}", "\n", "# Recurrent Unit of RecurrentVarNet Block :math:`\\mathcal{H}_{\\theta_t}`", "\n", "self", ".", "regularizer", "=", "(", "\n", "NormConv2dGRU", "(", "**", "regularizer_params", ")", "if", "normalized", "else", "Conv2dGRU", "(", "**", "regularizer_params", ")", "# type: ignore", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrentvarnet.recurrentvarnet.RecurrentVarNetBlock.forward": [[357, 417], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "direct.data.transforms.reduce_operator().permute", "recurrentvarnet.RecurrentVarNetBlock.regularizer", "recurrentvarnet.RecurrentVarNetBlock.permute", "recurrentvarnet.RecurrentVarNetBlock.forward_operator", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "direct.data.transforms.expand_operator", "direct.data.transforms.reduce_operator", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "recurrentvarnet.RecurrentVarNetBlock.backward_operator"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "current_kspace", ":", "torch", ".", "Tensor", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "Union", "[", "None", ",", "torch", ".", "Tensor", "]", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "spatial_dims", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "2", ",", "3", ")", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Computes forward pass of RecurrentVarNetBlock.\n\n        Parameters\n        ----------\n        current_kspace: torch.Tensor\n            Current k-space prediction of shape (N, coil, height, width, complex=2).\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        sensitivity_map: torch.Tensor\n            Coil sensitivities of shape (N, coil, height, width, complex=2).\n        hidden_state: torch.Tensor or None\n            Recurrent unit hidden state of shape (N, hidden_channels, height, width, num_layers) if not None. Optional.\n        coil_dim: int\n            Coil dimension. Default: 1.\n        spatial_dims: tuple of ints\n            Spatial dimensions. Default: (2, 3).\n\n        Returns\n        -------\n        new_kspace: torch.Tensor\n            New k-space prediction of shape (N, coil, height, width, complex=2).\n        hidden_state: torch.Tensor\n            Next hidden state of shape (N, hidden_channels, height, width, num_layers).\n        \"\"\"", "\n", "\n", "kspace_error", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "masked_kspace", ".", "dtype", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", ",", "\n", "current_kspace", "-", "masked_kspace", ",", "\n", ")", "\n", "\n", "recurrent_term", "=", "reduce_operator", "(", "\n", "self", ".", "backward_operator", "(", "current_kspace", ",", "dim", "=", "spatial_dims", ")", ",", "\n", "sensitivity_map", ",", "\n", "dim", "=", "coil_dim", ",", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "recurrent_term", ",", "hidden_state", "=", "self", ".", "regularizer", "(", "recurrent_term", ",", "hidden_state", ")", "# :math:`w_t`, :math:`h_{t+1}`", "\n", "recurrent_term", "=", "recurrent_term", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "recurrent_term", "=", "self", ".", "forward_operator", "(", "\n", "expand_operator", "(", "recurrent_term", ",", "sensitivity_map", ",", "dim", "=", "coil_dim", ")", ",", "\n", "dim", "=", "spatial_dims", ",", "\n", ")", "\n", "\n", "new_kspace", "=", "current_kspace", "-", "self", ".", "learning_rate", "*", "kspace_error", "+", "recurrent_term", "\n", "\n", "return", "new_kspace", ",", "hidden_state", "# type: ignore", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.InstanceNorm2dFunc.symbolic": [[12, 18], ["g.op", "g.op", "g.op"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "symbolic", "(", "g", ",", "cls", ",", "inp", ")", ":", "\n", "        ", "\"\"\"ONNX node definition for custom nodes\"\"\"", "\n", "c_scale", "=", "g", ".", "op", "(", "\"Constant\"", ",", "value_t", "=", "cls", ".", "scale_one", ")", "\n", "c_bias", "=", "g", ".", "op", "(", "\"Constant\"", ",", "value_t", "=", "cls", ".", "bias_zero", ")", "\n", "return", "g", ".", "op", "(", "\"InstanceNormalization\"", ",", "inp", ",", "c_scale", ",", "c_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.InstanceNorm2dFunc.forward": [[19, 23], ["cls.origin_forward"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "cls", ",", "inp", ")", ":", "# pylint: disable=unused-argument", "\n", "        ", "\"\"\"Fallback to origin custom function.\"\"\"", "\n", "return", "cls", ".", "origin_forward", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.InstanceNorm2dONNX.__init__": [[30, 41], ["torch.nn.InstanceNorm2d.__init__", "torch.ones", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "\"\"\"Inits InstanceNorm2dONNX\n\n        Parameters\n        ----------\n        num_features: int\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "num_features", ")", "\n", "self", ".", "origin_forward", "=", "super", "(", ")", ".", "forward", "\n", "self", ".", "scale_one", "=", "torch", ".", "ones", "(", "num_features", ")", "\n", "self", ".", "bias_zero", "=", "torch", ".", "zeros", "(", "num_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.InstanceNorm2dONNX.forward": [[42, 50], ["InstanceNorm2dFunc.apply().clone", "InstanceNorm2dFunc.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"This is a helper function that calls InstanceNorm2dFunc wrapper methods.\n\n        Parameters\n        ----------\n        inp: torch.Tensor\n        \"\"\"", "\n", "return", "InstanceNorm2dFunc", ".", "apply", "(", "self", ",", "inp", ")", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.OpenVINOModel.__init__": [[71, 84], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "\"\"\"Inits OpenVINOModel.\n\n        Parameters\n        ----------\n        model: direct.nn.rim.rim.RIM or direct.nn.unet.unet_2d.Unet2d\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inputs", ":", "tuple", "\n", "self", ".", "input_names", ":", "list", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "exec_net", "=", "None", "\n", "self", ".", "model_name", "=", "self", ".", "model", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.OpenVINOModel.create_net": [[85, 125], ["openvino.inference_engine.IECore", "openvino.inference_engine.IECore.add_extension", "openvino_model.convert_layer", "openvino_extensions.get_extensions_path", "torch.no_grad", "io.BytesIO", "torch.onnx.export", "openvino.inference_engine.IECore.read_network", "openvino.inference_engine.IECore.load_network", "ValueError", "tuple", "io.BytesIO.getvalue", "openvino_model.OpenVINOModel.input_names.append"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.convert_layer"], ["", "def", "create_net", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"This function export PyTorch model to ONNX and create OpenVINO model.\n        Parameters are the same as for the corresponding PyTorch model.\n        \"\"\"", "\n", "self", ".", "inputs", "=", "args", "\n", "\n", "if", "self", ".", "model_name", "==", "\"RIM\"", ":", "\n", "            ", "self", ".", "input_names", "=", "[", "\"input_image\"", ",", "\"masked_kspace\"", ",", "\"sampling_mask\"", ",", "\"sensitivity_map\"", "]", "\n", "output_names", "=", "[", "\"cell_outputs\"", ",", "\"previous_state\"", "]", "\n", "", "elif", "self", ".", "model_name", "==", "\"Unet2d\"", ":", "\n", "            ", "output_names", "=", "[", "\"output\"", "]", "\n", "self", ".", "input_names", "=", "[", "\"masked_kspace\"", "]", "\n", "if", "self", ".", "model", ".", "image_initialization", "==", "\"sense\"", ":", "\n", "                ", "self", ".", "input_names", ".", "append", "(", "\"sensitivity_map\"", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"The model is not supported by OpenVINO: {self.model_name}\"", ")", "\n", "\n", "", "for", "k", "in", "self", ".", "input_names", ":", "\n", "            ", "if", "k", "in", "kwargs", ":", "\n", "                ", "self", ".", "inputs", "+=", "tuple", "(", "[", "kwargs", "[", "k", "]", "]", ")", "\n", "\n", "", "", "ie", "=", "IECore", "(", ")", "\n", "ie", ".", "add_extension", "(", "get_extensions_path", "(", ")", ",", "\"CPU\"", ")", "\n", "\n", "convert_layer", "(", "self", ".", "model", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "buf", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "onnx", ".", "export", "(", "\n", "self", ".", "model", ",", "\n", "self", ".", "inputs", ",", "\n", "buf", ",", "\n", "opset_version", "=", "12", ",", "\n", "operator_export_type", "=", "torch", ".", "onnx", ".", "OperatorExportTypes", ".", "ONNX_FALLTHROUGH", ",", "\n", "input_names", "=", "self", ".", "input_names", ",", "\n", "output_names", "=", "output_names", ",", "\n", ")", "\n", "\n", "net", "=", "ie", ".", "read_network", "(", "buf", ".", "getvalue", "(", ")", ",", "b\"\"", ",", "init_from_buffer", "=", "True", ")", "\n", "self", ".", "exec_net", "=", "ie", ".", "load_network", "(", "net", ",", "\"CPU\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.OpenVINOModel.postprocess": [[126, 142], ["torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "", "def", "postprocess", "(", "self", ",", "res", ")", ":", "\n", "        ", "\"\"\"This function custom the output of an OpenVINO model to the output format of the original PyTorch model.\n\n        Parameters\n        ----------\n        res: dict\n\n        Returns\n        -------\n        Output is the same as the output of the corresponding PyTorch model.\n        \"\"\"", "\n", "if", "self", ".", "model_name", "==", "\"RIM\"", ":", "\n", "            ", "out", "=", "(", "[", "torch", ".", "Tensor", "(", "res", "[", "\"cell_outputs\"", "]", ")", "]", ",", "torch", ".", "Tensor", "(", "res", "[", "\"previous_state\"", "]", ")", ")", "\n", "", "elif", "self", ".", "model_name", "==", "\"Unet2d\"", ":", "\n", "            ", "out", "=", "torch", ".", "Tensor", "(", "res", "[", "\"output\"", "]", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.OpenVINOModel.forward": [[143, 161], ["dict", "openvino_model.OpenVINOModel.exec_net.infer", "openvino_model.OpenVINOModel.postprocess", "openvino_model.OpenVINOModel.create_net", "zip"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.OpenVINOModel.postprocess", "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.OpenVINOModel.create_net"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Creates an OpenVINO model if it doesn't exist and computes forward pass of the model.\n\n        Parameters\n        ----------\n        Parameters are the same as for the corresponding PyTorch model.\n\n        Returns\n        -------\n        Output is the same as for the corresponding PyTorch model.\n        \"\"\"", "\n", "if", "self", ".", "exec_net", "is", "None", ":", "\n", "            ", "self", ".", "create_net", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "ov_input", "=", "dict", "(", "zip", "(", "self", ".", "input_names", ",", "self", ".", "inputs", ")", ")", "\n", "res", "=", "self", ".", "exec_net", ".", "infer", "(", "ov_input", ")", "\n", "\n", "return", "self", ".", "postprocess", "(", "res", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.convert_layer": [[52, 66], ["model.named_children", "openvino_model.InstanceNorm2dONNX", "setattr", "openvino_model.convert_layer"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.openvino.openvino_model.convert_layer"], ["", "", "def", "convert_layer", "(", "model", ")", ":", "\n", "    ", "\"\"\"This function recursively replaces the InstanceNorm2d layer with the custom InstanceNorm2dONNX layer.\n\n    Parameters\n    ----------\n    model: torch.nn.Module subclass\n    \"\"\"", "\n", "for", "name", ",", "l", "in", "model", ".", "named_children", "(", ")", ":", "\n", "        ", "layer_type", "=", "l", ".", "__class__", ".", "__name__", "\n", "if", "layer_type", "==", "\"InstanceNorm2d\"", ":", "\n", "            ", "new_layer", "=", "InstanceNorm2dONNX", "(", "l", ".", "num_features", ")", "\n", "setattr", "(", "model", ",", "name", ",", "new_layer", ")", "\n", "", "else", ":", "\n", "            ", "convert_layer", "(", "l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.DWT.__init__": [[21, 25], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Inits :class:`DWT`.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.DWT.forward": [[26, 51], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes DWT(`x`) given tensor `x`.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        out: torch.Tensor\n            DWT of `x`.\n        \"\"\"", "\n", "x01", "=", "x", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", ":", "]", "/", "2", "\n", "x02", "=", "x", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", ":", "]", "/", "2", "\n", "x1", "=", "x01", "[", ":", ",", ":", ",", ":", ",", "0", ":", ":", "2", "]", "\n", "x2", "=", "x02", "[", ":", ",", ":", ",", ":", ",", "0", ":", ":", "2", "]", "\n", "x3", "=", "x01", "[", ":", ",", ":", ",", ":", ",", "1", ":", ":", "2", "]", "\n", "x4", "=", "x02", "[", ":", ",", ":", ",", ":", ",", "1", ":", ":", "2", "]", "\n", "x_LL", "=", "x1", "+", "x2", "+", "x3", "+", "x4", "\n", "x_HL", "=", "-", "x1", "-", "x2", "+", "x3", "+", "x4", "\n", "x_LH", "=", "-", "x1", "+", "x2", "-", "x3", "+", "x4", "\n", "x_HH", "=", "x1", "-", "x2", "-", "x3", "+", "x4", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "x_LL", ",", "x_HL", ",", "x_LH", ",", "x_HH", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.IWT.__init__": [[62, 67], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Inits :class:`IWT`.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "requires_grad", "=", "False", "\n", "self", ".", "_r", "=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.IWT.forward": [[68, 97], ["x.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes IWT(`x`) given tensor `x`.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        h: torch.Tensor\n            IWT of `x`.\n        \"\"\"", "\n", "batch", ",", "in_channel", ",", "in_height", ",", "in_width", "=", "x", ".", "size", "(", ")", "\n", "out_channel", ",", "out_height", ",", "out_width", "=", "int", "(", "in_channel", "/", "(", "self", ".", "_r", "**", "2", ")", ")", ",", "self", ".", "_r", "*", "in_height", ",", "self", ".", "_r", "*", "in_width", "\n", "\n", "x1", "=", "x", "[", ":", ",", "0", ":", "out_channel", ",", ":", ",", ":", "]", "/", "2", "\n", "x2", "=", "x", "[", ":", ",", "out_channel", ":", "out_channel", "*", "2", ",", ":", ",", ":", "]", "/", "2", "\n", "x3", "=", "x", "[", ":", ",", "out_channel", "*", "2", ":", "out_channel", "*", "3", ",", ":", ",", ":", "]", "/", "2", "\n", "x4", "=", "x", "[", ":", ",", "out_channel", "*", "3", ":", "out_channel", "*", "4", ",", ":", ",", ":", "]", "/", "2", "\n", "\n", "h", "=", "torch", ".", "zeros", "(", "[", "batch", ",", "out_channel", ",", "out_height", ",", "out_width", "]", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "\n", "h", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "=", "x1", "-", "x2", "-", "x3", "+", "x4", "\n", "h", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "=", "x1", "-", "x2", "+", "x3", "-", "x4", "\n", "h", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "=", "x1", "+", "x2", "-", "x3", "-", "x4", "\n", "h", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "=", "x1", "+", "x2", "+", "x3", "+", "x4", "\n", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.ConvBlock.__init__": [[108, 155], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "net.append", "net.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "net.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "kernel_size", ":", "int", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "batchnorm", ":", "bool", "=", "False", ",", "\n", "activation", ":", "nn", ".", "Module", "=", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`ConvBlock`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        kernel_size: int\n            Conv kernel size.\n        bias: bool\n            Use convolution bias. Default: True.\n        batchnorm: bool\n            Use batch normalization. Default: False.\n        activation: nn.Module\n            Activation function. Default: nn.ReLU(True).\n        scale: float, optional\n            Scale. Default: 1.0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "net", ":", "List", "[", "nn", ".", "Module", "]", "=", "[", "]", "\n", "net", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "padding", "=", "kernel_size", "//", "2", ",", "\n", ")", "\n", ")", "\n", "if", "batchnorm", ":", "\n", "            ", "net", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "num_features", "=", "out_channels", ",", "eps", "=", "1e-4", ",", "momentum", "=", "0.95", ")", ")", "\n", "", "net", ".", "append", "(", "activation", ")", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "net", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.ConvBlock.forward": [[156, 171], ["mwcnn.ConvBlock.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`ConvBlock`.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input with shape (N, C, H, W).\n\n        Returns\n        -------\n        output: torch.Tensor\n            Output with shape (N, C', H', W').\n        \"\"\"", "\n", "output", "=", "self", ".", "net", "(", "x", ")", "*", "self", ".", "scale", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.DilatedConvBlock.__init__": [[182, 247], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "net.append", "net.append", "net.append", "net.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "net.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "net.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "dilations", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "kernel_size", ":", "int", ",", "\n", "out_channels", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "batchnorm", ":", "bool", "=", "False", ",", "\n", "activation", ":", "nn", ".", "Module", "=", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`DilatedConvBlock`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        dilations: (int, int)\n            Number of dilations.\n        kernel_size: int\n            Conv kernel size.\n        out_channels: int\n            Number of output channels.\n        bias: bool\n            Use convolution bias. Default: True.\n        batchnorm: bool\n            Use batch normalization. Default: False.\n        activation: nn.Module\n            Activation function. Default: nn.ReLU(True).\n        scale: float, optional\n            Scale. Default: 1.0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "net", ":", "List", "[", "nn", ".", "Module", "]", "=", "[", "]", "\n", "net", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "in_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "dilation", "=", "dilations", "[", "0", "]", ",", "\n", "padding", "=", "kernel_size", "//", "2", "+", "dilations", "[", "0", "]", "-", "1", ",", "\n", ")", "\n", ")", "\n", "if", "batchnorm", ":", "\n", "            ", "net", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "num_features", "=", "in_channels", ",", "eps", "=", "1e-4", ",", "momentum", "=", "0.95", ")", ")", "\n", "", "net", ".", "append", "(", "activation", ")", "\n", "if", "out_channels", "is", "None", ":", "\n", "            ", "out_channels", "=", "in_channels", "\n", "", "net", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "dilation", "=", "dilations", "[", "1", "]", ",", "\n", "padding", "=", "kernel_size", "//", "2", "+", "dilations", "[", "1", "]", "-", "1", ",", "\n", ")", "\n", ")", "\n", "if", "batchnorm", ":", "\n", "            ", "net", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "num_features", "=", "in_channels", ",", "eps", "=", "1e-4", ",", "momentum", "=", "0.95", ")", ")", "\n", "", "net", ".", "append", "(", "activation", ")", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "net", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.DilatedConvBlock.forward": [[248, 263], ["mwcnn.DilatedConvBlock.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`DilatedConvBlock`.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input with shape (N, C, H, W).\n\n        Returns\n        -------\n        output: torch.Tensor\n            Output with shape (N, C', H', W').\n        \"\"\"", "\n", "output", "=", "self", ".", "net", "(", "x", ")", "*", "self", ".", "scale", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.MWCNN.__init__": [[274, 378], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "mwcnn.DWT", "mwcnn.IWT", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "mwcnn.MWCNN.down.append", "range", "mwcnn.MWCNN.up.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "collections.OrderedDict", "collections.OrderedDict", "mwcnn.ConvBlock", "mwcnn.DilatedConvBlock", "mwcnn.DilatedConvBlock", "mwcnn.ConvBlock"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_channels", ":", "int", ",", "\n", "first_conv_hidden_channels", ":", "int", ",", "\n", "num_scales", ":", "int", "=", "4", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "batchnorm", ":", "bool", "=", "False", ",", "\n", "activation", ":", "nn", ".", "Module", "=", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MWCNN`.\n\n        Parameters\n        ----------\n        input_channels: int\n            Input channels dimension.\n        first_conv_hidden_channels: int\n            First convolution output channels dimension.\n        num_scales: int\n            Number of scales. Default: 4.\n        bias: bool\n            Convolution bias. If True, adds a learnable bias to the output. Default: True.\n        batchnorm: bool\n            If True, a batchnorm layer is added after each convolution. Default: False.\n        activation: nn.Module\n            Activation function applied after each convolution. Default: nn.ReLU().\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_kernel_size", "=", "3", "\n", "self", ".", "DWT", "=", "DWT", "(", ")", "\n", "self", ".", "IWT", "=", "IWT", "(", ")", "\n", "\n", "self", ".", "down", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "idx", "in", "range", "(", "0", ",", "num_scales", ")", ":", "\n", "\n", "            ", "in_channels", "=", "input_channels", "if", "idx", "==", "0", "else", "first_conv_hidden_channels", "*", "2", "**", "(", "idx", "+", "1", ")", "\n", "out_channels", "=", "first_conv_hidden_channels", "*", "2", "**", "idx", "\n", "dilations", "=", "(", "2", ",", "1", ")", "if", "idx", "!=", "num_scales", "-", "1", "else", "(", "2", ",", "3", ")", "\n", "self", ".", "down", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "OrderedDict", "(", "\n", "[", "\n", "(", "\n", "f\"convblock{idx}\"", ",", "\n", "ConvBlock", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "(", "\n", "f\"dilconvblock{idx}\"", ",", "\n", "DilatedConvBlock", "(", "\n", "in_channels", "=", "out_channels", ",", "\n", "dilations", "=", "dilations", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "]", "\n", ")", "\n", ")", "\n", ")", "\n", "", "self", ".", "up", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "idx", "in", "range", "(", "num_scales", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "\n", "            ", "in_channels", "=", "first_conv_hidden_channels", "*", "2", "**", "idx", "\n", "out_channels", "=", "input_channels", "if", "idx", "==", "0", "else", "first_conv_hidden_channels", "*", "2", "**", "(", "idx", "+", "1", ")", "\n", "dilations", "=", "(", "2", ",", "1", ")", "if", "idx", "!=", "num_scales", "-", "1", "else", "(", "3", ",", "2", ")", "\n", "self", ".", "up", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "OrderedDict", "(", "\n", "[", "\n", "(", "\n", "f\"invdilconvblock{num_scales - 2 - idx}\"", ",", "\n", "DilatedConvBlock", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "dilations", "=", "dilations", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "(", "\n", "f\"invconvblock{num_scales - 2 - idx}\"", ",", "\n", "ConvBlock", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "]", "\n", ")", "\n", ")", "\n", ")", "\n", "", "self", ".", "num_scales", "=", "num_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.MWCNN.pad": [[379, 390], ["sum", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad"], ["", "@", "staticmethod", "\n", "def", "pad", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "\n", "if", "x", ".", "shape", "[", "-", "2", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "3", "]", "=", "1", "# Padding right - width", "\n", "", "if", "x", ".", "shape", "[", "-", "1", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "1", "]", "=", "1", "# Padding bottom - height", "\n", "", "if", "sum", "(", "padding", ")", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "padding", ",", "\"reflect\"", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.MWCNN.crop_to_shape": [[391, 400], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "crop_to_shape", "(", "x", ":", "torch", ".", "Tensor", ",", "shape", ":", "tuple", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "h", ",", "w", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "if", "h", ">", "shape", "[", "0", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "if", "w", ">", "shape", "[", "1", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", "shape", "[", "1", "]", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mwcnn.mwcnn.MWCNN.forward": [[401, 439], ["mwcnn.MWCNN.pad", "range", "range", "input_tensor.clone", "mwcnn.MWCNN.pad", "res_values.append", "mwcnn.MWCNN.crop_to_shape", "mwcnn.MWCNN.pad", "res_values.append", "mwcnn.MWCNN.crop_to_shape", "mwcnn.MWCNN.DWT", "mwcnn.MWCNN.IWT", "mwcnn.MWCNN.DWT"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.crop_to_shape", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.crop_to_shape"], ["", "def", "forward", "(", "self", ",", "input_tensor", ":", "torch", ".", "Tensor", ",", "res", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes forward pass of :class:`MWCNN`.\n\n        Parameters\n        ----------\n        input_tensor: torch.Tensor\n            Input tensor.\n        res: bool\n            If True, residual connection is applied to the output. Default: False.\n\n        Returns\n        -------\n        x: torch.Tensor\n            Output tensor.\n        \"\"\"", "\n", "res_values", "=", "[", "]", "\n", "x", "=", "self", ".", "pad", "(", "input_tensor", ".", "clone", "(", ")", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_scales", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "x", "=", "self", ".", "pad", "(", "self", ".", "down", "[", "idx", "]", "(", "x", ")", ")", "\n", "res_values", ".", "append", "(", "x", ")", "\n", "", "elif", "idx", "==", "self", ".", "num_scales", "-", "1", ":", "\n", "                ", "x", "=", "self", ".", "down", "[", "idx", "]", "(", "self", ".", "DWT", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "self", ".", "pad", "(", "self", ".", "down", "[", "idx", "]", "(", "self", ".", "DWT", "(", "x", ")", ")", ")", "\n", "res_values", ".", "append", "(", "x", ")", "\n", "\n", "", "", "for", "idx", "in", "range", "(", "self", ".", "num_scales", ")", ":", "\n", "            ", "if", "idx", "!=", "self", ".", "num_scales", "-", "1", ":", "\n", "                ", "x", "=", "(", "\n", "self", ".", "crop_to_shape", "(", "self", ".", "IWT", "(", "self", ".", "up", "[", "idx", "]", "(", "x", ")", ")", ",", "res_values", "[", "self", ".", "num_scales", "-", "2", "-", "idx", "]", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "+", "res_values", "[", "self", ".", "num_scales", "-", "2", "-", "idx", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "self", ".", "crop_to_shape", "(", "self", ".", "up", "[", "idx", "]", "(", "x", ")", ",", "input_tensor", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "if", "res", ":", "\n", "                    ", "x", "+=", "input_tensor", "\n", "", "", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.Subpixel.__init__": [[20, 48], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "upscale_factor", ":", "int", ",", "\n", "kernel_size", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "padding", ":", "int", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`Subpixel`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        upscale_factor: int\n            Subpixel upscale factor.\n        kernel_size: int or (int, int)\n            Convolution kernel size.\n        padding: int\n            Padding size. Default: 0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", "*", "upscale_factor", "**", "2", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", "\n", ")", "\n", "self", ".", "pixelshuffle", "=", "nn", ".", "PixelShuffle", "(", "upscale_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.Subpixel.forward": [[49, 58], ["didn.Subpixel.pixelshuffle", "didn.Subpixel.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes :class:`Subpixel` convolution on input torch.Tensor ``x``.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor.\n        \"\"\"", "\n", "return", "self", ".", "pixelshuffle", "(", "self", ".", "conv", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.ReconBlock.__init__": [[69, 93], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "didn.ReconBlock.convs.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "num_convs", ":", "int", ")", ":", "\n", "        ", "\"\"\"Inits :class:`ReconBlock`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        num_convs: int\n            Number of convolution blocks.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_convs", "-", "1", ")", "\n", "]", "\n", ")", "\n", "self", ".", "convs", ".", "append", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ")", "\n", "self", ".", "num_convs", "=", "num_convs", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.ReconBlock.forward": [[94, 108], ["input_data.clone", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes num_convs convolutions followed by PReLU activation on `input_data`.\n\n        Parameters\n        ----------\n        input_data: torch.Tensor\n            Input tensor.\n        \"\"\"", "\n", "\n", "output", "=", "input_data", ".", "clone", "(", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_convs", ")", ":", "\n", "            ", "output", "=", "self", ".", "convs", "[", "idx", "]", "(", "output", ")", "\n", "\n", "", "return", "input_data", "+", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DUB.__init__": [[119, 177], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "didn.Subpixel", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "didn.Subpixel", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`DUB`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "\n", "# Scale 1", "\n", "self", ".", "conv1_1", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "*", "2", ")", "\n", "self", ".", "down1", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "# Scale 2", "\n", "self", ".", "conv2_1", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "\n", ")", "\n", "self", ".", "down2", "=", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "# Scale 3", "\n", "self", ".", "conv3_1", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", "*", "4", ",", "in_channels", "*", "4", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "up1", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "# nn.Conv2d(in_channels * 4, in_channels * 8, kernel_size=1),", "\n", "Subpixel", "(", "in_channels", "*", "4", ",", "in_channels", "*", "2", ",", "2", ",", "1", ",", "0", ")", "\n", "]", "\n", ")", "\n", "# Scale 2", "\n", "self", ".", "conv_agg_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "*", "4", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv2_2", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "up2", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "# nn.Conv2d(in_channels * 2, in_channels * 4, kernel_size=1),", "\n", "Subpixel", "(", "in_channels", "*", "2", ",", "in_channels", ",", "2", ",", "1", ",", "0", ")", "\n", "]", "\n", ")", "\n", "# Scale 1", "\n", "self", ".", "conv_agg_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv1_2", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "*", "2", ")", "\n", "self", ".", "conv_out", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DUB.pad": [[178, 201], ["sum", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad"], ["", "@", "staticmethod", "\n", "def", "pad", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Pads input to height and width dimensions if odd.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input to pad.\n\n        Returns\n        -------\n        x: torch.Tensor\n            Padded tensor.\n        \"\"\"", "\n", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "\n", "if", "x", ".", "shape", "[", "-", "2", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "3", "]", "=", "1", "# Padding right - width", "\n", "", "if", "x", ".", "shape", "[", "-", "1", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "1", "]", "=", "1", "# Padding bottom - height", "\n", "", "if", "sum", "(", "padding", ")", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "padding", ",", "\"reflect\"", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DUB.crop_to_shape": [[202, 225], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "crop_to_shape", "(", "x", ":", "torch", ".", "Tensor", ",", "shape", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Crops ``x`` to specified shape.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor with shape (\\*, H, W).\n        shape: Tuple(int, int)\n            Crop shape corresponding to H, W.\n\n        Returns\n        -------\n        cropped_output: torch.Tensor\n            Cropped tensor.\n        \"\"\"", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "if", "h", ">", "shape", "[", "0", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "if", "w", ">", "shape", "[", "1", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", "shape", "[", "1", "]", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DUB.forward": [[226, 254], ["didn.DUB.pad", "didn.DUB.down1", "didn.DUB.down2", "didn.DUB.up1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "didn.DUB.conv_agg_1", "didn.DUB.up2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "didn.DUB.conv_agg_2", "x.clone", "didn.DUB.conv1_1", "didn.DUB.conv2_1", "didn.DUB.conv3_1", "didn.DUB.conv2_2", "didn.DUB.conv1_2", "didn.DUB.crop_to_shape", "didn.DUB.crop_to_shape", "didn.DUB.crop_to_shape", "didn.DUB.conv_out"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.crop_to_shape", "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.crop_to_shape", "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.crop_to_shape"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        out: torch.Tensor\n            DUB output.\n        \"\"\"", "\n", "x1", "=", "self", ".", "pad", "(", "x", ".", "clone", "(", ")", ")", "\n", "x1", "=", "x1", "+", "self", ".", "conv1_1", "(", "x1", ")", "\n", "x2", "=", "self", ".", "down1", "(", "x1", ")", "\n", "x2", "=", "x2", "+", "self", ".", "conv2_1", "(", "x2", ")", "\n", "out", "=", "self", ".", "down2", "(", "x2", ")", "\n", "out", "=", "out", "+", "self", ".", "conv3_1", "(", "out", ")", "\n", "out", "=", "self", ".", "up1", "(", "out", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "x2", ",", "self", ".", "crop_to_shape", "(", "out", ",", "(", "x2", ".", "shape", "[", "-", "2", "]", ",", "x2", ".", "shape", "[", "-", "1", "]", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "conv_agg_1", "(", "out", ")", "\n", "out", "=", "out", "+", "self", ".", "conv2_2", "(", "out", ")", "\n", "out", "=", "self", ".", "up2", "(", "out", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "x1", ",", "self", ".", "crop_to_shape", "(", "out", ",", "(", "x1", ".", "shape", "[", "-", "2", "]", ",", "x1", ".", "shape", "[", "-", "1", "]", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "conv_agg_2", "(", "out", ")", "\n", "out", "=", "out", "+", "self", ".", "conv1_2", "(", "out", ")", "\n", "out", "=", "x", "+", "self", ".", "crop_to_shape", "(", "self", ".", "conv_out", "(", "out", ")", ",", "(", "x", ".", "shape", "[", "-", "2", "]", ",", "x", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.__init__": [[265, 327], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "didn.ReconBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "didn.Subpixel", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "didn.DUB", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "hidden_channels", ":", "int", "=", "128", ",", "\n", "num_dubs", ":", "int", "=", "6", ",", "\n", "num_convs_recon", ":", "int", "=", "9", ",", "\n", "skip_connection", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`DIDN`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        hidden_channels: int\n            Number of hidden channels. First convolution out_channels. Default: 128.\n        num_dubs: int\n            Number of DUB networks. Default: 6.\n        num_convs_recon: int\n            Number of ReconBlock convolutions. Default: 9.\n        skip_connection: bool\n            Use skip connection. Default: False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_in", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "hidden_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "\n", ")", "\n", "self", ".", "down", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "hidden_channels", ",", "\n", "out_channels", "=", "hidden_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "self", ".", "dubs", "=", "nn", ".", "ModuleList", "(", "\n", "[", "DUB", "(", "in_channels", "=", "hidden_channels", ",", "out_channels", "=", "hidden_channels", ")", "for", "_", "in", "range", "(", "num_dubs", ")", "]", "\n", ")", "\n", "self", ".", "recon_block", "=", "ReconBlock", "(", "in_channels", "=", "hidden_channels", ",", "num_convs", "=", "num_convs_recon", ")", "\n", "self", ".", "recon_agg", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "hidden_channels", "*", "num_dubs", ",", "out_channels", "=", "hidden_channels", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "hidden_channels", ",", "\n", "out_channels", "=", "hidden_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "up2", "=", "Subpixel", "(", "hidden_channels", ",", "hidden_channels", ",", "2", ",", "1", ")", "\n", "self", ".", "conv_out", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "hidden_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "self", ".", "num_dubs", "=", "num_dubs", "\n", "self", ".", "skip_connection", "=", "(", "in_channels", "==", "out_channels", ")", "and", "skip_connection", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.crop_to_shape": [[328, 351], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "crop_to_shape", "(", "x", ":", "torch", ".", "Tensor", ",", "shape", ":", "Tuple", "[", "int", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Crops ``x`` to specified shape.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor with shape (\\*, H, W).\n        shape: Tuple(int, int)\n            Crop shape corresponding to H, W.\n\n        Returns\n        -------\n        cropped_output: torch.Tensor\n            Cropped tensor.\n        \"\"\"", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "if", "h", ">", "shape", "[", "0", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "if", "w", ">", "shape", "[", "1", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", "shape", "[", "1", "]", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.forward": [[352, 385], ["didn.DIDN.conv_in", "didn.DIDN.down", "didn.DIDN.recon_agg", "didn.DIDN.conv", "didn.DIDN.up2", "didn.DIDN.conv_out", "didn.DIDN.crop_to_shape", "dub", "dub_outs.append", "didn.DIDN.recon_block", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.didn.didn.DIDN.crop_to_shape"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "channel_dim", ":", "int", "=", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Takes as input a torch.Tensor `x` and computes DIDN(x).\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor.\n        channel_dim: int\n            Channel dimension. Default: 1.\n\n        Returns\n        -------\n        out: torch.Tensor\n            DIDN output tensor.\n        \"\"\"", "\n", "out", "=", "self", ".", "conv_in", "(", "x", ")", "\n", "out", "=", "self", ".", "down", "(", "out", ")", "\n", "\n", "dub_outs", "=", "[", "]", "\n", "for", "dub", "in", "self", ".", "dubs", ":", "\n", "            ", "out", "=", "dub", "(", "out", ")", "\n", "dub_outs", ".", "append", "(", "out", ")", "\n", "\n", "", "out", "=", "[", "self", ".", "recon_block", "(", "dub_out", ")", "for", "dub_out", "in", "dub_outs", "]", "\n", "out", "=", "self", ".", "recon_agg", "(", "torch", ".", "cat", "(", "out", ",", "dim", "=", "channel_dim", ")", ")", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "out", "=", "self", ".", "up2", "(", "out", ")", "\n", "out", "=", "self", ".", "conv_out", "(", "out", ")", "\n", "out", "=", "self", ".", "crop_to_shape", "(", "out", ",", "(", "x", ".", "shape", "[", "-", "2", "]", ",", "x", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "\n", "if", "self", ".", "skip_connection", ":", "\n", "            ", "out", "=", "x", "+", "out", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.xpdnet.xpdnet_engine.XPDNetEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`XPDNetEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.xpdnet.xpdnet_engine.XPDNetEngine._do_iteration": [[43, 113], ["direct.utils.dict_to_device", "data[].clone", "xpdnet_engine.XPDNetEngine.compute_sensitivity_map", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "torch.cuda.amp.autocast", "xpdnet_engine.XPDNetEngine.model", "direct.modulus", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "xpdnet_engine.XPDNetEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "xpdnet_engine.XPDNetEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_image", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sampling_mask", "=", "data", "[", "\"sampling_mask\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "scaling_factor", "=", "data", "[", "\"scaling_factor\"", "]", ",", "\n", ")", "# shape (batch, height,  width, complex=2)", "\n", "\n", "output_image", "=", "T", ".", "modulus", "(", "output_image", ")", "# shape (batch, height,  width)", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.xpdnet.xpdnet.XPDNet.__init__": [[24, 131], ["direct.nn.crossdomain.crossdomain.CrossDomainNetwork.__init__", "torch.ModuleList", "NotImplementedError", "torch.ModuleList", "torch.ModuleList", "NotImplementedError", "torch.Sequential", "direct.nn.crossdomain.multicoil.MultiCoil", "direct.nn.mwcnn.mwcnn.MWCNN", "torch.Conv2d", "range", "direct.nn.conv.conv.Conv2d", "range", "direct.nn.crossdomain.multicoil.MultiCoil", "kwargs.get", "kwargs.get", "direct.nn.didn.didn.DIDN", "range", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "num_primal", ":", "int", "=", "5", ",", "\n", "num_dual", ":", "int", "=", "1", ",", "\n", "num_iter", ":", "int", "=", "10", ",", "\n", "use_primal_only", ":", "bool", "=", "True", ",", "\n", "image_model_architecture", ":", "str", "=", "\"MWCNN\"", ",", "\n", "kspace_model_architecture", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "normalize", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`XPDNet`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        num_primal: int\n            Number of primal networks.\n        num_dual: int\n            Number of dual networks.\n        num_iter: int\n            Number of unrolled iterations.\n        use_primal_only: bool\n            If set to True no dual-kspace model is used. Default: True.\n        image_model_architecture: str\n            Primal-image model architecture. Currently only implemented for MWCNN. Default: 'MWCNN'.\n        kspace_model_architecture: str\n            Dual-kspace model architecture. Currently only implemented for CONV and DIDN.\n        normalize: bool\n            Normalize input. Default: False.\n        kwargs: dict\n            Keyword arguments for model architectures.\n        \"\"\"", "\n", "if", "use_primal_only", ":", "\n", "            ", "kspace_model_list", "=", "None", "\n", "num_dual", "=", "1", "\n", "", "elif", "kspace_model_architecture", "==", "\"CONV\"", ":", "\n", "            ", "kspace_model_list", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "MultiCoil", "(", "\n", "Conv2d", "(", "\n", "2", "*", "(", "num_dual", "+", "num_primal", "+", "1", ")", ",", "\n", "2", "*", "num_dual", ",", "\n", "kwargs", ".", "get", "(", "\"dual_conv_hidden_channels\"", ",", "16", ")", ",", "\n", "kwargs", ".", "get", "(", "\"dual_conv_n_convs\"", ",", "4", ")", ",", "\n", "batchnorm", "=", "kwargs", ".", "get", "(", "\"dual_conv_batchnorm\"", ",", "False", ")", ",", "\n", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "", "elif", "kspace_model_architecture", "==", "\"DIDN\"", ":", "\n", "            ", "kspace_model_list", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "MultiCoil", "(", "\n", "DIDN", "(", "\n", "in_channels", "=", "2", "*", "(", "num_dual", "+", "num_primal", "+", "1", ")", ",", "\n", "out_channels", "=", "2", "*", "num_dual", ",", "\n", "hidden_channels", "=", "kwargs", ".", "get", "(", "\"dual_didn_hidden_channels\"", ",", "16", ")", ",", "\n", "num_dubs", "=", "kwargs", ".", "get", "(", "\"dual_didn_num_dubs\"", ",", "6", ")", ",", "\n", "num_convs_recon", "=", "kwargs", ".", "get", "(", "\"dual_didn_num_convs_recon\"", ",", "9", ")", ",", "\n", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"XPDNet is currently implemented for kspace_model_architecture == 'CONV' or 'DIDN'.\"", "\n", "f\"Got kspace_model_architecture == {kspace_model_architecture}.\"", "\n", ")", "\n", "", "if", "image_model_architecture", "==", "\"MWCNN\"", ":", "\n", "            ", "image_model_list", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "nn", ".", "Sequential", "(", "\n", "MWCNN", "(", "\n", "input_channels", "=", "2", "*", "(", "num_primal", "+", "num_dual", ")", ",", "\n", "first_conv_hidden_channels", "=", "kwargs", ".", "get", "(", "\"mwcnn_hidden_channels\"", ",", "32", ")", ",", "\n", "num_scales", "=", "kwargs", ".", "get", "(", "\"mwcnn_num_scales\"", ",", "4", ")", ",", "\n", "bias", "=", "kwargs", ".", "get", "(", "\"mwcnn_bias\"", ",", "False", ")", ",", "\n", "batchnorm", "=", "kwargs", ".", "get", "(", "\"mwcnn_batchnorm\"", ",", "False", ")", ",", "\n", ")", ",", "\n", "nn", ".", "Conv2d", "(", "2", "*", "(", "num_primal", "+", "num_dual", ")", ",", "2", "*", "num_primal", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"XPDNet is currently implemented only with image_model_architecture == 'MWCNN'.\"", "\n", "f\"Got {image_model_architecture}.\"", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "image_model_list", "=", "image_model_list", ",", "\n", "kspace_model_list", "=", "kspace_model_list", ",", "\n", "domain_sequence", "=", "\"KI\"", "*", "num_iter", ",", "\n", "image_buffer_size", "=", "num_primal", ",", "\n", "kspace_buffer_size", "=", "num_dual", ",", "\n", "normalize_image", "=", "normalize", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_engine.Unet2dEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`Unet2dEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_engine.Unet2dEngine._do_iteration": [[43, 113], ["direct.utils.dict_to_device", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "data[].clone", "unet_engine.Unet2dEngine.compute_sensitivity_map", "torch.cuda.amp.autocast", "unet_engine.Unet2dEngine.model", "direct.modulus", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "unet_engine.Unet2dEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "unet_engine.Unet2dEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "model", ".", "image_initialization", "==", "\"sense\"", ":", "# type: ignore", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "            ", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_image", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", "\n", "if", "self", ".", "cfg", ".", "model", ".", "image_initialization", "==", "\"sense\"", "# type: ignore", "\n", "else", "None", ",", "\n", ")", "\n", "output_image", "=", "T", ".", "modulus", "(", "output_image", ")", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.ConvBlock.__init__": [[21, 48], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.InstanceNorm2d", "torch.nn.LeakyReLU", "torch.nn.Dropout2d", "torch.nn.Conv2d", "torch.nn.InstanceNorm2d", "torch.nn.LeakyReLU", "torch.nn.Dropout2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "dropout_probability", ":", "float", ")", ":", "\n", "        ", "\"\"\"Inits ConvBlock.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        dropout_probability: float\n            Dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "dropout_probability", "=", "dropout_probability", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "dropout_probability", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "dropout_probability", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.ConvBlock.forward": [[50, 62], ["unet_2d.ConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs the forward pass of :class:`ConvBlock`.\n\n        Parameters\n        ----------\n        input_data: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "return", "self", ".", "layers", "(", "input_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.ConvBlock.__repr__": [[63, 67], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Representation of :class:`ConvBlock`.\"\"\"", "\n", "return", "(", "\n", "f\"ConvBlock(in_channels={self.in_channels}, out_channels={self.out_channels}, \"", "\n", "f\"dropout_probability={self.dropout_probability})\"", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.TransposeConvBlock.__init__": [[77, 96], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.ConvTranspose2d", "torch.nn.InstanceNorm2d", "torch.nn.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ")", ":", "\n", "        ", "\"\"\"Inits :class:`TransposeConvBlock`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.TransposeConvBlock.forward": [[98, 110], ["unet_2d.TransposeConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`TransposeConvBlock`.\n\n        Parameters\n        ----------\n        input_data: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "return", "self", ".", "layers", "(", "input_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.TransposeConvBlock.__repr__": [[111, 114], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Representation of \"class:`TransposeConvBlock`.\"\"\"", "\n", "return", "f\"ConvBlock(in_channels={self.in_channels}, out_channels={self.out_channels})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.UnetModel2d.__init__": [[125, 175], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "range", "unet_2d.ConvBlock", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "unet_2d.TransposeConvBlock", "torch.nn.Sequential", "unet_2d.ConvBlock", "unet_2d.ConvBlock", "unet_2d.TransposeConvBlock", "unet_2d.ConvBlock", "unet_2d.ConvBlock", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "num_filters", ":", "int", ",", "\n", "num_pool_layers", ":", "int", ",", "\n", "dropout_probability", ":", "float", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`UnetModel2d`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels to the u-net.\n        out_channels: int\n            Number of output channels to the u-net.\n        num_filters: int\n            Number of output channels of the first convolutional layer.\n        num_pool_layers: int\n            Number of down-sampling and up-sampling layers (depth).\n        dropout_probability: float\n            Dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "num_pool_layers", "=", "num_pool_layers", "\n", "self", ".", "dropout_probability", "=", "dropout_probability", "\n", "\n", "self", ".", "down_sample_layers", "=", "nn", ".", "ModuleList", "(", "[", "ConvBlock", "(", "in_channels", ",", "num_filters", ",", "dropout_probability", ")", "]", ")", "\n", "ch", "=", "num_filters", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "down_sample_layers", "+=", "[", "ConvBlock", "(", "ch", ",", "ch", "*", "2", ",", "dropout_probability", ")", "]", "\n", "ch", "*=", "2", "\n", "", "self", ".", "conv", "=", "ConvBlock", "(", "ch", ",", "ch", "*", "2", ",", "dropout_probability", ")", "\n", "\n", "self", ".", "up_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "up_transpose_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "up_transpose_conv", "+=", "[", "TransposeConvBlock", "(", "ch", "*", "2", ",", "ch", ")", "]", "\n", "self", ".", "up_conv", "+=", "[", "ConvBlock", "(", "ch", "*", "2", ",", "ch", ",", "dropout_probability", ")", "]", "\n", "ch", "//=", "2", "\n", "\n", "", "self", ".", "up_transpose_conv", "+=", "[", "TransposeConvBlock", "(", "ch", "*", "2", ",", "ch", ")", "]", "\n", "self", ".", "up_conv", "+=", "[", "\n", "nn", ".", "Sequential", "(", "\n", "ConvBlock", "(", "ch", "*", "2", ",", "ch", ",", "dropout_probability", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ch", ",", "self", ".", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.UnetModel2d.forward": [[178, 218], ["enumerate", "unet_2d.UnetModel2d.conv", "zip", "layer", "stack.append", "torch.nn.functional.avg_pool2d", "stack.pop", "transpose_conv", "torch.cat", "conv", "sum", "torch.nn.functional.pad"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`UnetModel2d`.\n\n        Parameters\n        ----------\n        input_data: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "stack", "=", "[", "]", "\n", "output", "=", "input_data", "\n", "\n", "# Apply down-sampling layers", "\n", "for", "_", ",", "layer", "in", "enumerate", "(", "self", ".", "down_sample_layers", ")", ":", "\n", "            ", "output", "=", "layer", "(", "output", ")", "\n", "stack", ".", "append", "(", "output", ")", "\n", "output", "=", "F", ".", "avg_pool2d", "(", "output", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "", "output", "=", "self", ".", "conv", "(", "output", ")", "\n", "\n", "# Apply up-sampling layers", "\n", "for", "transpose_conv", ",", "conv", "in", "zip", "(", "self", ".", "up_transpose_conv", ",", "self", ".", "up_conv", ")", ":", "\n", "            ", "downsample_layer", "=", "stack", ".", "pop", "(", ")", "\n", "output", "=", "transpose_conv", "(", "output", ")", "\n", "\n", "# Reflect pad on the right/bottom if needed to handle odd input dimensions.", "\n", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "if", "output", ".", "shape", "[", "-", "1", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "padding", "[", "1", "]", "=", "1", "# Padding right", "\n", "", "if", "output", ".", "shape", "[", "-", "2", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "padding", "[", "3", "]", "=", "1", "# Padding bottom", "\n", "", "if", "sum", "(", "padding", ")", "!=", "0", ":", "\n", "                ", "output", "=", "F", ".", "pad", "(", "output", ",", "padding", ",", "\"reflect\"", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "downsample_layer", "]", ",", "dim", "=", "1", ")", "\n", "output", "=", "conv", "(", "output", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.__init__": [[223, 260], ["torch.nn.Module.__init__", "unet_2d.UnetModel2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "num_filters", ":", "int", ",", "\n", "num_pool_layers", ":", "int", ",", "\n", "dropout_probability", ":", "float", ",", "\n", "norm_groups", ":", "int", "=", "2", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`NormUnetModel2d`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels to the u-net.\n        out_channels: int\n            Number of output channels to the u-net.\n        num_filters: int\n            Number of output channels of the first convolutional layer.\n        num_pool_layers: int\n            Number of down-sampling and up-sampling layers (depth).\n        dropout_probability: float\n            Dropout probability.\n        norm_groups: int,\n            Number of normalization groups.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "unet2d", "=", "UnetModel2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "num_filters", "=", "num_filters", ",", "\n", "num_pool_layers", "=", "num_pool_layers", ",", "\n", "dropout_probability", "=", "dropout_probability", ",", "\n", ")", "\n", "\n", "self", ".", "norm_groups", "=", "norm_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.norm": [[261, 275], ["input_data.reshape.reshape.reshape", "input_data.reshape.reshape.mean", "input_data.reshape.reshape.std", "output.reshape.reshape.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "norm", "(", "input_data", ":", "torch", ".", "Tensor", ",", "groups", ":", "int", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Performs group normalization.\"\"\"", "\n", "# group norm", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "input_data", ".", "shape", "\n", "input_data", "=", "input_data", ".", "reshape", "(", "b", ",", "groups", ",", "-", "1", ")", "\n", "\n", "mean", "=", "input_data", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "input_data", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "output", "=", "(", "input_data", "-", "mean", ")", "/", "std", "\n", "output", "=", "output", ".", "reshape", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "return", "output", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.unnorm": [[276, 281], ["input_data.reshape.reshape.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "unnorm", "(", "input_data", ":", "torch", ".", "Tensor", ",", "mean", ":", "torch", ".", "Tensor", ",", "std", ":", "torch", ".", "Tensor", ",", "groups", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "input_data", ".", "shape", "\n", "input_data", "=", "input_data", ".", "reshape", "(", "b", ",", "groups", ",", "-", "1", ")", "\n", "return", "(", "input_data", "*", "std", "+", "mean", ")", ".", "reshape", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad": [[282, 292], ["torch.nn.functional.pad", "math.floor", "math.ceil", "math.floor", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad"], ["", "@", "staticmethod", "\n", "def", "pad", "(", "input_data", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "Tuple", "[", "List", "[", "int", "]", ",", "List", "[", "int", "]", ",", "int", ",", "int", "]", "]", ":", "\n", "        ", "_", ",", "_", ",", "h", ",", "w", "=", "input_data", ".", "shape", "\n", "w_mult", "=", "(", "(", "w", "-", "1", ")", "|", "15", ")", "+", "1", "\n", "h_mult", "=", "(", "(", "h", "-", "1", ")", "|", "15", ")", "+", "1", "\n", "w_pad", "=", "[", "math", ".", "floor", "(", "(", "w_mult", "-", "w", ")", "/", "2", ")", ",", "math", ".", "ceil", "(", "(", "w_mult", "-", "w", ")", "/", "2", ")", "]", "\n", "h_pad", "=", "[", "math", ".", "floor", "(", "(", "h_mult", "-", "h", ")", "/", "2", ")", ",", "math", ".", "ceil", "(", "(", "h_mult", "-", "h", ")", "/", "2", ")", "]", "\n", "\n", "output", "=", "F", ".", "pad", "(", "input_data", ",", "w_pad", "+", "h_pad", ")", "\n", "return", "output", ",", "(", "h_pad", ",", "w_pad", ",", "h_mult", ",", "w_mult", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.unpad": [[293, 303], ["int", "int", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "unpad", "(", "\n", "input_data", ":", "torch", ".", "Tensor", ",", "\n", "h_pad", ":", "List", "[", "int", "]", ",", "\n", "w_pad", ":", "List", "[", "int", "]", ",", "\n", "h_mult", ":", "int", ",", "\n", "w_mult", ":", "int", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "return", "input_data", "[", "...", ",", "int", "(", "h_pad", "[", "0", "]", ")", ":", "int", "(", "h_mult", "-", "h_pad", "[", "1", "]", ")", ",", "int", "(", "w_pad", "[", "0", "]", ")", ":", "int", "(", "w_mult", "-", "w_pad", "[", "1", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.forward": [[304, 324], ["unet_2d.NormUnetModel2d.norm", "unet_2d.NormUnetModel2d.pad", "unet_2d.NormUnetModel2d.unet2d", "unet_2d.NormUnetModel2d.unpad", "unet_2d.NormUnetModel2d.unnorm"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.norm", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.unpad", "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.unnorm"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`NormUnetModel2d`.\n\n        Parameters\n        ----------\n        input_data: torch.Tensor\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "\n", "output", ",", "mean", ",", "std", "=", "self", ".", "norm", "(", "input_data", ",", "self", ".", "norm_groups", ")", "\n", "output", ",", "pad_sizes", "=", "self", ".", "pad", "(", "output", ")", "\n", "output", "=", "self", ".", "unet2d", "(", "output", ")", "\n", "\n", "output", "=", "self", ".", "unpad", "(", "output", ",", "*", "pad_sizes", ")", "\n", "output", "=", "self", ".", "unnorm", "(", "output", ",", "mean", ",", "std", ",", "self", ".", "norm_groups", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.Unet2d.__init__": [[329, 394], ["torch.nn.Module.__init__", "kwargs.keys", "unet_2d.NormUnetModel2d", "unet_2d.UnetModel2d", "ValueError", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "num_filters", ":", "int", ",", "\n", "num_pool_layers", ":", "int", ",", "\n", "dropout_probability", ":", "float", ",", "\n", "skip_connection", ":", "bool", "=", "False", ",", "\n", "normalized", ":", "bool", "=", "False", ",", "\n", "image_initialization", ":", "str", "=", "\"zero_filled\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`Unet2d`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        num_filters: int\n            Number of first layer filters.\n        num_pool_layers: int\n            Number of pooling layers.\n        dropout_probability: float\n            Dropout probability.\n        skip_connection: bool\n            If True, skip connection is used for the output. Default: False.\n        normalized: bool\n            If True, Normalized Unet is used. Default: False.\n        image_initialization: str\n            Type of image initialization. Default: \"zero-filled\".\n        kwargs: dict\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "extra_keys", "=", "kwargs", ".", "keys", "(", ")", "\n", "for", "extra_key", "in", "extra_keys", ":", "\n", "            ", "if", "extra_key", "not", "in", "[", "\n", "\"sensitivity_map_model\"", ",", "\n", "\"model_name\"", ",", "\n", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{type(self).__name__} got key `{extra_key}` which is not supported.\"", ")", "\n", "", "", "self", ".", "unet", ":", "nn", ".", "Module", "\n", "if", "normalized", ":", "\n", "            ", "self", ".", "unet", "=", "NormUnetModel2d", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "num_filters", ",", "\n", "num_pool_layers", "=", "num_pool_layers", ",", "\n", "dropout_probability", "=", "dropout_probability", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "unet", "=", "UnetModel2d", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "num_filters", ",", "\n", "num_pool_layers", "=", "num_pool_layers", ",", "\n", "dropout_probability", "=", "dropout_probability", ",", "\n", ")", "\n", "", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "skip_connection", "=", "skip_connection", "\n", "self", ".", "image_initialization", "=", "image_initialization", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.Unet2d.compute_sense_init": [[395, 421], ["direct.data.transforms.complex_multiplication", "input_image.sum.sum.sum", "direct.data.transforms.conjugate", "unet_2d.Unet2d.backward_operator"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate"], ["", "def", "compute_sense_init", "(", "self", ",", "kspace", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "r\"\"\"Computes sense initialization :math:`x_{\\text{SENSE}}`:\n\n        .. math::\n            x_{\\text{SENSE}} = \\sum_{k=1}^{n_c} {S^{k}}^* \\times y^k\n\n        where :math:`y^k` denotes the data from coil :math:`k`.\n\n        Parameters\n        ----------\n        kspace: torch.Tensor\n            k-space of shape (N, coil, height, width, complex=2).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n\n        Returns\n        -------\n        input_image: torch.Tensor\n            Sense initialization :math:`x_{\\text{SENSE}}`.\n        \"\"\"", "\n", "input_image", "=", "T", ".", "complex_multiplication", "(", "\n", "T", ".", "conjugate", "(", "sensitivity_map", ")", ",", "\n", "self", ".", "backward_operator", "(", "kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "\n", ")", "\n", "input_image", "=", "input_image", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", "return", "input_image", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.Unet2d.forward": [[422, 460], ["unet_2d.Unet2d.unet().permute", "unet_2d.Unet2d.compute_sense_init", "ValueError", "unet_2d.Unet2d.backward_operator().sum", "ValueError", "unet_2d.Unet2d.unet", "unet_2d.Unet2d.permute", "unet_2d.Unet2d.backward_operator"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIM.compute_sense_init"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes forward pass of Unet2d.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2). Default: None.\n\n        Returns\n        -------\n        output: torch.Tensor\n            Output image of shape (N, height, width, complex=2).\n        \"\"\"", "\n", "if", "self", ".", "image_initialization", "==", "\"sense\"", ":", "\n", "            ", "if", "sensitivity_map", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Expected sensitivity_map not to be None with 'sense' image_initialization.\"", ")", "\n", "", "input_image", "=", "self", ".", "compute_sense_init", "(", "\n", "kspace", "=", "masked_kspace", ",", "\n", "sensitivity_map", "=", "sensitivity_map", ",", "\n", ")", "\n", "", "elif", "self", ".", "image_initialization", "==", "\"zero_filled\"", ":", "\n", "            ", "input_image", "=", "self", ".", "backward_operator", "(", "masked_kspace", ")", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Unknown image_initialization. Expected `sense` or `zero_filled`. \"", "\n", "f\"Got {self.image_initialization}.\"", "\n", ")", "\n", "\n", "", "output", "=", "self", ".", "unet", "(", "input_image", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "if", "self", ".", "skip_connection", ":", "\n", "            ", "output", "+=", "input_image", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.Conv2dGRU.__init__": [[15, 110], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "range", "block.append", "recurrent.Conv2dGRU.conv_blocks.append", "zip", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "gru_block.append", "gru_part.append", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "block.append", "block.append", "gru_block.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "min", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "hidden_channels", ":", "int", ",", "\n", "out_channels", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_layers", ":", "int", "=", "2", ",", "\n", "gru_kernel_size", "=", "1", ",", "\n", "orthogonal_initialization", ":", "bool", "=", "True", ",", "\n", "instance_norm", ":", "bool", "=", "False", ",", "\n", "dense_connect", ":", "int", "=", "0", ",", "\n", "replication_padding", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`Conv2dGRU`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        hidden_channels: int\n            Number of hidden channels.\n        out_channels: Optional[int]\n            Number of output channels. If None, same as in_channels. Default: None.\n        num_layers: int\n            Number of layers. Default: 2.\n        gru_kernel_size: int\n            Size of the GRU kernel. Default: 1.\n        orthogonal_initialization: bool\n            Orthogonal initialization is used if set to True. Default: True.\n        instance_norm: bool\n            Instance norm is used if set to True. Default: False.\n        dense_connect: int\n            Number of dense connections.\n        replication_padding: bool\n            If set to true replication padding is applied.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "out_channels", "is", "None", ":", "\n", "            ", "out_channels", "=", "in_channels", "\n", "\n", "", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_channels", "=", "hidden_channels", "\n", "self", ".", "dense_connect", "=", "dense_connect", "\n", "\n", "self", ".", "reset_gates", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "update_gates", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "out_gates", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "conv_blocks", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "\n", "# Create convolutional blocks", "\n", "for", "idx", "in", "range", "(", "num_layers", "+", "1", ")", ":", "\n", "            ", "in_ch", "=", "in_channels", "if", "idx", "==", "0", "else", "(", "1", "+", "min", "(", "idx", ",", "dense_connect", ")", ")", "*", "hidden_channels", "\n", "out_ch", "=", "hidden_channels", "if", "idx", "<", "num_layers", "else", "out_channels", "\n", "padding", "=", "0", "if", "replication_padding", "else", "(", "2", "if", "idx", "==", "0", "else", "1", ")", "\n", "block", ":", "List", "[", "nn", ".", "Module", "]", "=", "[", "]", "\n", "if", "replication_padding", ":", "\n", "                ", "if", "idx", "==", "1", ":", "\n", "                    ", "block", ".", "append", "(", "nn", ".", "ReplicationPad2d", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "block", ".", "append", "(", "nn", ".", "ReplicationPad2d", "(", "2", "if", "idx", "==", "0", "else", "1", ")", ")", "\n", "", "", "block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_ch", ",", "\n", "out_channels", "=", "out_ch", ",", "\n", "kernel_size", "=", "5", "if", "idx", "==", "0", "else", "3", ",", "\n", "dilation", "=", "(", "2", "if", "idx", "==", "1", "else", "1", ")", ",", "\n", "padding", "=", "padding", ",", "\n", ")", "\n", ")", "\n", "self", ".", "conv_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "\n", "# Create GRU blocks", "\n", "", "for", "idx", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "gru_part", "in", "[", "self", ".", "reset_gates", ",", "self", ".", "update_gates", ",", "self", ".", "out_gates", "]", ":", "\n", "                ", "gru_block", ":", "List", "[", "nn", ".", "Module", "]", "=", "[", "]", "\n", "if", "instance_norm", ":", "\n", "                    ", "gru_block", ".", "append", "(", "nn", ".", "InstanceNorm2d", "(", "2", "*", "hidden_channels", ")", ")", "\n", "", "gru_block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "2", "*", "hidden_channels", ",", "\n", "out_channels", "=", "hidden_channels", ",", "\n", "kernel_size", "=", "gru_kernel_size", ",", "\n", "padding", "=", "gru_kernel_size", "//", "2", ",", "\n", ")", "\n", ")", "\n", "gru_part", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "gru_block", ")", ")", "\n", "\n", "", "", "if", "orthogonal_initialization", ":", "\n", "            ", "for", "reset_gate", ",", "update_gate", ",", "out_gate", "in", "zip", "(", "self", ".", "reset_gates", ",", "self", ".", "update_gates", ",", "self", ".", "out_gates", ")", ":", "\n", "                ", "nn", ".", "init", ".", "orthogonal_", "(", "reset_gate", "[", "-", "1", "]", ".", "weight", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "update_gate", "[", "-", "1", "]", ".", "weight", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "out_gate", "[", "-", "1", "]", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "reset_gate", "[", "-", "1", "]", ".", "bias", ",", "-", "1.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "update_gate", "[", "-", "1", "]", ".", "bias", ",", "0.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "out_gate", "[", "-", "1", "]", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.Conv2dGRU.forward": [[111, 164], ["range", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "new_states.append", "torch.relu", "torch.relu", "torch.relu", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu.size", "len", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "conv_skip.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu.size", "torch.relu.size", "list", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "", "def", "forward", "(", "\n", "self", ",", "\n", "cell_input", ":", "torch", ".", "Tensor", ",", "\n", "previous_state", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Computes Conv2dGRU forward pass given tensors `cell_input` and `previous_state`.\n\n        Parameters\n        ----------\n        cell_input: torch.Tensor\n            Input tensor.\n        previous_state: torch.Tensor\n            Tensor of previous hidden state.\n\n        Returns\n        -------\n        out, new_states: (torch.Tensor, torch.Tensor)\n            Output and new states.\n        \"\"\"", "\n", "new_states", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "conv_skip", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "\n", "if", "previous_state", "is", "None", ":", "\n", "            ", "batch_size", ",", "spatial_size", "=", "cell_input", ".", "size", "(", "0", ")", ",", "(", "cell_input", ".", "size", "(", "2", ")", ",", "cell_input", ".", "size", "(", "3", ")", ")", "\n", "state_size", "=", "[", "batch_size", ",", "self", ".", "hidden_channels", "]", "+", "list", "(", "spatial_size", ")", "+", "[", "self", ".", "num_layers", "]", "\n", "previous_state", "=", "torch", ".", "zeros", "(", "*", "state_size", ",", "dtype", "=", "cell_input", ".", "dtype", ")", ".", "to", "(", "cell_input", ".", "device", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "if", "len", "(", "conv_skip", ")", ">", "0", ":", "\n", "                ", "cell_input", "=", "F", ".", "relu", "(", "\n", "self", ".", "conv_blocks", "[", "idx", "]", "(", "torch", ".", "cat", "(", "[", "*", "conv_skip", "[", "-", "self", ".", "dense_connect", ":", "]", ",", "cell_input", "]", ",", "dim", "=", "1", ")", ")", ",", "\n", "inplace", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "cell_input", "=", "F", ".", "relu", "(", "self", ".", "conv_blocks", "[", "idx", "]", "(", "cell_input", ")", ",", "inplace", "=", "True", ")", "\n", "", "if", "self", ".", "dense_connect", ">", "0", ":", "\n", "                ", "conv_skip", ".", "append", "(", "cell_input", ")", "\n", "\n", "", "prev_state", "=", "previous_state", "[", ":", ",", ":", ",", ":", ",", ":", ",", "idx", "]", "\n", "stacked_inputs", "=", "torch", ".", "cat", "(", "[", "cell_input", ",", "prev_state", "]", ",", "dim", "=", "1", ")", "\n", "\n", "update", "=", "torch", ".", "sigmoid", "(", "self", ".", "update_gates", "[", "idx", "]", "(", "stacked_inputs", ")", ")", "\n", "reset", "=", "torch", ".", "sigmoid", "(", "self", ".", "reset_gates", "[", "idx", "]", "(", "stacked_inputs", ")", ")", "\n", "delta", "=", "torch", ".", "tanh", "(", "self", ".", "out_gates", "[", "idx", "]", "(", "torch", ".", "cat", "(", "[", "cell_input", ",", "prev_state", "*", "reset", "]", ",", "dim", "=", "1", ")", ")", ")", "\n", "cell_input", "=", "prev_state", "*", "(", "1", "-", "update", ")", "+", "delta", "*", "update", "\n", "new_states", ".", "append", "(", "cell_input", ")", "\n", "cell_input", "=", "F", ".", "relu", "(", "cell_input", ",", "inplace", "=", "False", ")", "\n", "", "if", "len", "(", "conv_skip", ")", ">", "0", ":", "\n", "            ", "out", "=", "self", ".", "conv_blocks", "[", "self", ".", "num_layers", "]", "(", "torch", ".", "cat", "(", "[", "*", "conv_skip", "[", "-", "self", ".", "dense_connect", ":", "]", ",", "cell_input", "]", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "conv_blocks", "[", "self", ".", "num_layers", "]", "(", "cell_input", ")", "\n", "\n", "", "return", "out", ",", "torch", ".", "stack", "(", "new_states", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.__init__": [[177, 228], ["torch.Module.__init__", "recurrent.Conv2dGRU"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "hidden_channels", ":", "int", ",", "\n", "out_channels", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_layers", ":", "int", "=", "2", ",", "\n", "gru_kernel_size", "=", "1", ",", "\n", "orthogonal_initialization", ":", "bool", "=", "True", ",", "\n", "instance_norm", ":", "bool", "=", "False", ",", "\n", "dense_connect", ":", "int", "=", "0", ",", "\n", "replication_padding", ":", "bool", "=", "True", ",", "\n", "norm_groups", ":", "int", "=", "2", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`NormConv2dGRU`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        hidden_channels: int\n            Number of hidden channels.\n        out_channels: Optional[int]\n            Number of output channels. If None, same as in_channels. Default: None.\n        num_layers: int\n            Number of layers. Default: 2.\n        gru_kernel_size: int\n            Size of the GRU kernel. Default: 1.\n        orthogonal_initialization: bool\n            Orthogonal initialization is used if set to True. Default: True.\n        instance_norm: bool\n            Instance norm is used if set to True. Default: False.\n        dense_connect: int\n            Number of dense connections.\n        replication_padding: bool\n            If set to true replication padding is applied.\n        norm_groups: int,\n            Number of normalization groups.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convgru", "=", "Conv2dGRU", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "hidden_channels", "=", "hidden_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "gru_kernel_size", "=", "gru_kernel_size", ",", "\n", "orthogonal_initialization", "=", "orthogonal_initialization", ",", "\n", "instance_norm", "=", "instance_norm", ",", "\n", "dense_connect", "=", "dense_connect", ",", "\n", "replication_padding", "=", "replication_padding", ",", "\n", ")", "\n", "self", ".", "norm_groups", "=", "norm_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.norm": [[229, 242], ["input_data.reshape.reshape.reshape", "input_data.reshape.reshape.mean", "input_data.reshape.reshape.std", "output.reshape.reshape.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "norm", "(", "input_data", ":", "torch", ".", "Tensor", ",", "num_groups", ":", "int", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Performs group normalization.\"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "input_data", ".", "shape", "\n", "input_data", "=", "input_data", ".", "reshape", "(", "b", ",", "num_groups", ",", "-", "1", ")", "\n", "\n", "mean", "=", "input_data", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "input_data", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "output", "=", "(", "input_data", "-", "mean", ")", "/", "std", "\n", "output", "=", "output", ".", "reshape", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "return", "output", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.unnorm": [[243, 248], ["input_data.reshape.reshape.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "unnorm", "(", "input_data", ":", "torch", ".", "Tensor", ",", "mean", ":", "torch", ".", "Tensor", ",", "std", ":", "torch", ".", "Tensor", ",", "num_groups", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "input_data", ".", "shape", "\n", "input_data", "=", "input_data", ".", "reshape", "(", "b", ",", "num_groups", ",", "-", "1", ")", "\n", "return", "(", "input_data", "*", "std", "+", "mean", ")", ".", "reshape", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.forward": [[249, 280], ["recurrent.NormConv2dGRU.norm", "recurrent.NormConv2dGRU.convgru", "recurrent.NormConv2dGRU.unnorm"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.norm", "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.unnorm"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "cell_input", ":", "torch", ".", "Tensor", ",", "\n", "previous_state", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Computes :class:`NormConv2dGRU` forward pass given tensors `cell_input` and `previous_state`.\n\n        It performs group normalization on the input before the forward pass to the Conv2dGRU.\n        Output of Conv2dGRU is then un-normalized.\n\n        Parameters\n        ----------\n        cell_input: torch.Tensor\n            Input tensor.\n        previous_state: torch.Tensor\n            Tensor of previous hidden state.\n\n        Returns\n        -------\n        out, new_states: (torch.Tensor, torch.Tensor)\n            Output and new states.\n\n        \"\"\"", "\n", "# Normalize", "\n", "cell_input", ",", "mean", ",", "std", "=", "self", ".", "norm", "(", "cell_input", ",", "self", ".", "norm_groups", ")", "\n", "# Pass normalized input", "\n", "cell_input", ",", "previous_state", "=", "self", ".", "convgru", "(", "cell_input", ",", "previous_state", ")", "\n", "# Unnormalize output", "\n", "cell_input", "=", "self", ".", "unnorm", "(", "cell_input", ",", "mean", ",", "std", ",", "self", ".", "norm_groups", ")", "\n", "\n", "return", "cell_input", ",", "previous_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet.ConvBNReLU.__init__": [[32, 48], ["torch.nn.Sequential.__init__", "torch.nn.Conv2d", "norm_layer", "torch.nn.ReLU6"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "groups", "=", "groups", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "norm_layer", "(", "out_planes", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet.InvertedResidual.__init__": [[52, 85], ["torch.nn.Module.__init__", "int", "layers.extend", "torch.nn.Sequential", "round", "layers.append", "mobilenet.ConvBNReLU", "mobilenet.ConvBNReLU", "torch.nn.Conv2d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inp", ",", "oup", ",", "stride", ",", "expand_ratio", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "stride", "=", "stride", "\n", "if", "stride", "not", "in", "[", "1", ",", "2", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "\n", "", "hidden_dim", "=", "int", "(", "round", "(", "inp", "*", "expand_ratio", ")", ")", "\n", "self", ".", "use_res_connect", "=", "self", ".", "stride", "==", "1", "and", "inp", "==", "oup", "\n", "\n", "layers", "=", "[", "]", "\n", "if", "expand_ratio", "!=", "1", ":", "\n", "# pw", "\n", "            ", "layers", ".", "append", "(", "ConvBNReLU", "(", "inp", ",", "hidden_dim", ",", "kernel_size", "=", "1", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "", "layers", ".", "extend", "(", "\n", "[", "\n", "# dw", "\n", "ConvBNReLU", "(", "\n", "hidden_dim", ",", "\n", "hidden_dim", ",", "\n", "stride", "=", "stride", ",", "\n", "groups", "=", "hidden_dim", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", ")", ",", "\n", "# pw-linear", "\n", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "oup", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "norm_layer", "(", "oup", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet.InvertedResidual.forward": [[86, 90], ["mobilenet.InvertedResidual.conv", "mobilenet.InvertedResidual.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "use_res_connect", ":", "\n", "            ", "return", "x", "+", "self", ".", "conv", "(", "x", ")", "\n", "", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet.MobileNetV2.__init__": [[93, 198], ["torch.nn.Module.__init__", "mobilenet._make_divisible", "mobilenet._make_divisible", "features.append", "torch.nn.Sequential", "torch.nn.Sequential", "mobilenet.MobileNetV2.modules", "direct.utils.str_to_class", "ValueError", "mobilenet.ConvBNReLU", "mobilenet._make_divisible", "range", "mobilenet.ConvBNReLU", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "len", "len", "max", "features.append", "torch.nn.init.kaiming_normal_", "isinstance", "str().split", "str().split", "block", "torch.nn.init.zeros_", "torch.nn.init.ones_", "torch.nn.init.zeros_", "isinstance", "torch.nn.init.normal_", "torch.nn.init.zeros_", "str", "str"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet._make_divisible", "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet._make_divisible", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class", "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet._make_divisible"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_channels", "=", "2", ",", "\n", "num_classes", "=", "1000", ",", "\n", "width_mult", "=", "1.0", ",", "\n", "inverted_residual_setting", "=", "None", ",", "\n", "round_nearest", "=", "8", ",", "\n", "block", "=", "None", ",", "\n", "norm_layer", ":", "Callable", "[", "...", ",", "Any", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"MobileNet V2 main class.\n\n        Parameters\n        ----------\n        num_channels: int\n            Number of channels.\n        num_classes: int\n            Number of classes.\n        width_mult: float\n            Width multiplier - adjusts number of channels in each layer by this amount.\n        inverted_residual_setting: Network structure\n        round_nearest: int\n            Round the number of channels in each layer to be a multiple of this number\n            Set to 1 to turn off rounding\n        block: str\n            Module specifying inverted residual building block for mobilenet.\n        norm_layer: str\n            Module specifying the normalization layer to use.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "block", "is", "None", ":", "\n", "            ", "block", "=", "InvertedResidual", "\n", "\n", "", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "else", ":", "\n", "            ", "module_name", "=", "\".\"", ".", "join", "(", "str", "(", "norm_layer", ")", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", "\n", "norm_layer", "=", "str_to_class", "(", "f\"torch.{module_name}\"", ",", "str", "(", "norm_layer", ")", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ")", "\n", "\n", "", "input_channel", "=", "32", "\n", "last_channel", "=", "1280", "\n", "\n", "if", "inverted_residual_setting", "is", "None", ":", "\n", "            ", "inverted_residual_setting", "=", "[", "\n", "# t, c, n, s", "\n", "[", "1", ",", "16", ",", "1", ",", "1", "]", ",", "\n", "[", "6", ",", "24", ",", "2", ",", "2", "]", ",", "\n", "[", "6", ",", "32", ",", "3", ",", "2", "]", ",", "\n", "[", "6", ",", "64", ",", "4", ",", "2", "]", ",", "\n", "[", "6", ",", "96", ",", "3", ",", "1", "]", ",", "\n", "[", "6", ",", "160", ",", "3", ",", "2", "]", ",", "\n", "[", "6", ",", "320", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "\n", "# only check the first element, assuming user knows t,c,n,s are required", "\n", "", "if", "len", "(", "inverted_residual_setting", ")", "==", "0", "or", "len", "(", "inverted_residual_setting", "[", "0", "]", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"inverted_residual_setting should be non-empty \"", "\n", "f\"or a 4-element list, got {inverted_residual_setting}\"", "\n", ")", "\n", "\n", "# building first layer", "\n", "", "input_channel", "=", "_make_divisible", "(", "input_channel", "*", "width_mult", ",", "round_nearest", ")", "\n", "self", ".", "last_channel", "=", "_make_divisible", "(", "last_channel", "*", "max", "(", "1.0", ",", "width_mult", ")", ",", "round_nearest", ")", "\n", "features", "=", "[", "ConvBNReLU", "(", "num_channels", ",", "input_channel", ",", "stride", "=", "2", ",", "norm_layer", "=", "norm_layer", ")", "]", "\n", "# building inverted residual blocks", "\n", "for", "t", ",", "c", ",", "n", ",", "s", "in", "inverted_residual_setting", ":", "\n", "            ", "output_channel", "=", "_make_divisible", "(", "c", "*", "width_mult", ",", "round_nearest", ")", "\n", "for", "idx", "in", "range", "(", "n", ")", ":", "\n", "                ", "stride", "=", "s", "if", "idx", "==", "0", "else", "1", "\n", "features", ".", "append", "(", "\n", "block", "(", "\n", "input_channel", ",", "\n", "output_channel", ",", "\n", "stride", ",", "\n", "expand_ratio", "=", "t", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", ")", "\n", ")", "\n", "input_channel", "=", "output_channel", "\n", "# building last several layers", "\n", "", "", "features", ".", "append", "(", "ConvBNReLU", "(", "input_channel", ",", "self", ".", "last_channel", ",", "kernel_size", "=", "1", ",", "norm_layer", "=", "norm_layer", ")", ")", "\n", "# make it nn.Sequential", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "*", "features", ")", "\n", "\n", "# building classifier", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "0.2", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "last_channel", ",", "num_classes", ")", ",", "\n", ")", "\n", "\n", "# weight initialization", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "\"fan_out\"", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "ones_", "(", "m", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.01", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet.MobileNetV2._forward_impl": [[199, 207], ["mobilenet.MobileNetV2.features", "torch.nn.functional.adaptive_avg_pool2d().reshape", "mobilenet.MobileNetV2.classifier", "torch.nn.functional.adaptive_avg_pool2d"], "methods", ["None"], ["", "", "", "def", "_forward_impl", "(", "self", ",", "x", ")", ":", "\n", "# This exists since TorchScript doesn't support inheritance, so the superclass method", "\n", "# (this one) needs to have a name other than `forward` that can be accessed in a subclass", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "# Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]", "\n", "x", "=", "nn", ".", "functional", ".", "adaptive_avg_pool2d", "(", "x", ",", "1", ")", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet.MobileNetV2.forward": [[208, 210], ["mobilenet.MobileNetV2._forward_impl"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet.MobileNetV2._forward_impl"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_forward_impl", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.mobilenet.mobilenet._make_divisible": [[15, 29], ["max", "int"], "function", ["None"], ["def", "_make_divisible", "(", "v", ",", "divisor", ",", "min_value", "=", "None", ")", ":", "\n", "    ", "\"\"\"This function is taken from the original tf repo.\n\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    \"\"\"", "\n", "if", "min_value", "is", "None", ":", "\n", "        ", "min_value", "=", "divisor", "\n", "", "new_v", "=", "max", "(", "min_value", ",", "int", "(", "v", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "# Make sure that round down does not go down by more than 10%.", "\n", "if", "new_v", "<", "0.9", "*", "v", ":", "\n", "        ", "new_v", "+=", "divisor", "\n", "", "return", "new_v", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.varnet.varnet_engine.EndToEndVarNetEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`EndToEndVarNetEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.varnet.varnet_engine.EndToEndVarNetEngine._do_iteration": [[43, 114], ["direct.utils.dict_to_device", "data[].clone", "varnet_engine.EndToEndVarNetEngine.compute_sensitivity_map", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "torch.cuda.amp.autocast", "varnet_engine.EndToEndVarNetEngine.model", "direct.root_sum_of_squares", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "varnet_engine.EndToEndVarNetEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "varnet_engine.EndToEndVarNetEngine.backward_operator", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "varnet_engine.EndToEndVarNetEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_kspace", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sampling_mask", "=", "data", "[", "\"sampling_mask\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", ")", "\n", "\n", "output_image", "=", "T", ".", "root_sum_of_squares", "(", "\n", "self", ".", "backward_operator", "(", "output_kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "dim", "=", "self", ".", "_coil_dim", "# type: ignore", "\n", ")", "# shape (batch, height,  width)", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.varnet.varnet.EndToEndVarNet.__init__": [[22, 71], ["torch.Module.__init__", "kwargs.keys", "torch.ModuleList", "torch.ModuleList", "range", "varnet.EndToEndVarNet.layers_list.append", "ValueError", "varnet.EndToEndVarNetBlock", "direct.nn.unet.UnetModel2d", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "num_layers", ":", "int", ",", "\n", "regularizer_num_filters", ":", "int", "=", "18", ",", "\n", "regularizer_num_pull_layers", ":", "int", "=", "4", ",", "\n", "regularizer_dropout", ":", "float", "=", "0.0", ",", "\n", "in_channels", ":", "int", "=", "2", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`EndToEndVarNet`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        num_layers: int\n            Number of cascades.\n        regularizer_num_filters: int\n            Regularizer model number of filters.\n        regularizer_num_pull_layers: int\n            Regularizer model number of pulling layers.\n        regularizer_dropout: float\n            Regularizer model dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "extra_keys", "=", "kwargs", ".", "keys", "(", ")", "\n", "for", "extra_key", "in", "extra_keys", ":", "\n", "            ", "if", "extra_key", "not", "in", "[", "\n", "\"model_name\"", ",", "\n", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{type(self).__name__} got key `{extra_key}` which is not supported.\"", ")", "\n", "\n", "", "", "self", ".", "layers_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers_list", ".", "append", "(", "\n", "EndToEndVarNetBlock", "(", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "regularizer_model", "=", "UnetModel2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "in_channels", ",", "\n", "num_filters", "=", "regularizer_num_filters", ",", "\n", "num_pool_layers", "=", "regularizer_num_pull_layers", ",", "\n", "dropout_probability", "=", "regularizer_dropout", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.varnet.varnet.EndToEndVarNet.forward": [[75, 99], ["masked_kspace.clone", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "masked_kspace", ":", "torch", ".", "Tensor", ",", "sampling_mask", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs the forward pass of :class:`EndToEndVarNet`.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n\n        Returns\n        -------\n        kspace_prediction: torch.Tensor\n            K-space prediction of shape (N, coil, height, width, complex=2).\n        \"\"\"", "\n", "\n", "kspace_prediction", "=", "masked_kspace", ".", "clone", "(", ")", "\n", "for", "layer", "in", "self", ".", "layers_list", ":", "\n", "            ", "kspace_prediction", "=", "layer", "(", "kspace_prediction", ",", "masked_kspace", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "", "return", "kspace_prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.varnet.varnet.EndToEndVarNetBlock.__init__": [[104, 129], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "regularizer_model", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`EndToEndVarNetBlock`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        regularizer_model: nn.Module\n            Regularizer model.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "regularizer_model", "=", "regularizer_model", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "learning_rate", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ")", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_complex_dim", "=", "-", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.varnet.varnet.EndToEndVarNetBlock.forward": [[130, 180], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "varnet.EndToEndVarNetBlock.regularizer_model().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "varnet.EndToEndVarNetBlock.regularizer_model", "varnet.EndToEndVarNetBlock.forward_operator", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "direct.data.transforms.expand_operator", "torch.split", "torch.split", "torch.split", "torch.split", "direct.data.transforms.reduce_operator", "varnet.EndToEndVarNetBlock.backward_operator", "torch.split", "torch.split", "torch.split", "torch.split"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "current_kspace", ":", "torch", ".", "Tensor", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs the forward pass of :class:`EndToEndVarNetBlock`.\n\n        Parameters\n        ----------\n        current_kspace: torch.Tensor\n            Current k-space prediction of shape (N, coil, height, width, complex=2).\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n\n        Returns\n        -------\n        torch.Tensor\n            Next k-space prediction of shape (N, coil, height, width, complex=2).\n        \"\"\"", "\n", "kspace_error", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "masked_kspace", ".", "dtype", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", ",", "\n", "current_kspace", "-", "masked_kspace", ",", "\n", ")", "\n", "regularization_term", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "reduce_operator", "(", "\n", "self", ".", "backward_operator", "(", "kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "sensitivity_map", ",", "dim", "=", "self", ".", "_coil_dim", "\n", ")", "\n", "for", "kspace", "in", "torch", ".", "split", "(", "current_kspace", ",", "2", ",", "self", ".", "_complex_dim", ")", "\n", "]", ",", "\n", "dim", "=", "self", ".", "_complex_dim", ",", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "regularization_term", "=", "self", ".", "regularizer_model", "(", "regularization_term", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "regularization_term", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "self", ".", "forward_operator", "(", "\n", "expand_operator", "(", "image", ",", "sensitivity_map", ",", "dim", "=", "self", ".", "_coil_dim", ")", ",", "dim", "=", "self", ".", "_spatial_dims", "\n", ")", "\n", "for", "image", "in", "torch", ".", "split", "(", "regularization_term", ",", "2", ",", "self", ".", "_complex_dim", ")", "\n", "]", ",", "\n", "dim", "=", "self", ".", "_complex_dim", ",", "\n", ")", "\n", "return", "current_kspace", "-", "self", ".", "learning_rate", "*", "kspace_error", "+", "regularization_term", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet_engine.JointICNetEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`JointICNetEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet_engine.JointICNetEngine._do_iteration": [[43, 112], ["direct.utils.dict_to_device", "data[].clone", "jointicnet_engine.JointICNetEngine.compute_sensitivity_map", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "torch.cuda.amp.autocast", "jointicnet_engine.JointICNetEngine.model", "direct.modulus", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "jointicnet_engine.JointICNetEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "jointicnet_engine.JointICNetEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_image", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sampling_mask", "=", "data", "[", "\"sampling_mask\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", ")", "# shape (batch, height,  width, complex=2)", "\n", "\n", "output_image", "=", "T", ".", "modulus", "(", "output_image", ")", "# shape (batch, height,  width)", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet.__init__": [[22, 86], ["torch.Module.__init__", "unet_architecture", "unet_architecture", "unet_architecture", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "num_iter", ":", "int", "=", "10", ",", "\n", "use_norm_unet", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`JointICNet`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Transform.\n        backward_operator: Callable\n            Backward Transform.\n        num_iter: int\n            Number of unrolled iterations. Default: 10.\n        use_norm_unet: bool\n            If True, a Normalized U-Net is used. Default: False.\n        kwargs: dict\n            Image, k-space and sensitivity-map U-Net models keyword-arguments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "\n", "unet_architecture", "=", "NormUnetModel2d", "if", "use_norm_unet", "else", "UnetModel2d", "\n", "\n", "self", ".", "image_model", "=", "unet_architecture", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "kwargs", ".", "get", "(", "\"image_unet_num_filters\"", ",", "8", ")", ",", "\n", "num_pool_layers", "=", "kwargs", ".", "get", "(", "\"image_unet_num_pool_layers\"", ",", "4", ")", ",", "\n", "dropout_probability", "=", "kwargs", ".", "get", "(", "\"image_unet_dropout\"", ",", "0.0", ")", ",", "\n", ")", "\n", "self", ".", "kspace_model", "=", "unet_architecture", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "kwargs", ".", "get", "(", "\"kspace_unet_num_filters\"", ",", "8", ")", ",", "\n", "num_pool_layers", "=", "kwargs", ".", "get", "(", "\"kspace_unet_num_pool_layers\"", ",", "4", ")", ",", "\n", "dropout_probability", "=", "kwargs", ".", "get", "(", "\"kspace_unet_dropout\"", ",", "0.0", ")", ",", "\n", ")", "\n", "self", ".", "sens_model", "=", "unet_architecture", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "kwargs", ".", "get", "(", "\"sens_unet_num_filters\"", ",", "8", ")", ",", "\n", "num_pool_layers", "=", "kwargs", ".", "get", "(", "\"sens_unet_num_pool_layers\"", ",", "4", ")", ",", "\n", "dropout_probability", "=", "kwargs", ".", "get", "(", "\"sens_unet_dropout\"", ",", "0.0", ")", ",", "\n", ")", "\n", "self", ".", "conv_out", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "1", ")", "\n", "\n", "self", ".", "reg_param_I", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_iter", ")", ")", "\n", "self", ".", "reg_param_F", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_iter", ")", ")", "\n", "self", ".", "reg_param_C", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_iter", ")", ")", "\n", "\n", "self", ".", "lr_image", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_iter", ")", ")", "\n", "self", ".", "lr_sens", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_iter", ")", ")", "\n", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_complex_dim", "=", "-", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._image_model": [[87, 90], ["image.permute.permute.permute", "jointicnet.JointICNet.image_model().permute().contiguous", "jointicnet.JointICNet.image_model().permute", "jointicnet.JointICNet.image_model"], "methods", ["None"], ["", "def", "_image_model", "(", "self", ",", "image", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "image", "=", "image", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "self", ".", "image_model", "(", "image", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._kspace_model": [[91, 94], ["kspace.permute.permute.permute", "jointicnet.JointICNet.kspace_model().permute().contiguous", "jointicnet.JointICNet.kspace_model().permute", "jointicnet.JointICNet.kspace_model"], "methods", ["None"], ["", "def", "_kspace_model", "(", "self", ",", "kspace", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "kspace", "=", "kspace", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "self", ".", "kspace_model", "(", "kspace", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._sens_model": [[95, 99], ["jointicnet.JointICNet._compute_model_per_coil().permute().contiguous", "jointicnet.JointICNet._compute_model_per_coil().permute", "jointicnet.JointICNet._compute_model_per_coil", "sensitivity_map.permute"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._compute_model_per_coil"], ["", "def", "_sens_model", "(", "self", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "(", "\n", "self", ".", "_compute_model_per_coil", "(", "self", ".", "sens_model", ",", "sensitivity_map", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ")", "\n", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", ".", "contiguous", "(", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._compute_model_per_coil": [[102, 108], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "data.size", "data.select", "output.append", "model"], "methods", ["None"], ["", "def", "_compute_model_per_coil", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "output", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "self", ".", "_coil_dim", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "self", ".", "_coil_dim", ",", "idx", ")", "\n", "output", ".", "append", "(", "model", "(", "subselected_data", ")", ")", "\n", "", "return", "torch", ".", "stack", "(", "output", ",", "dim", "=", "self", ".", "_coil_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._forward_operator": [[109, 118], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "jointicnet.JointICNet.forward_operator", "direct.expand_operator", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator"], ["", "def", "_forward_operator", "(", "\n", "self", ",", "image", ":", "torch", ".", "Tensor", ",", "sampling_mask", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "forward", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "image", ".", "dtype", ")", ".", "to", "(", "image", ".", "device", ")", ",", "\n", "self", ".", "forward_operator", "(", "T", ".", "expand_operator", "(", "image", ",", "sensitivity_map", ",", "self", ".", "_coil_dim", ")", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "\n", ")", "\n", "return", "forward", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._backward_operator": [[119, 135], ["direct.reduce_operator", "jointicnet.JointICNet.backward_operator", "torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator"], ["", "def", "_backward_operator", "(", "\n", "self", ",", "kspace", ":", "torch", ".", "Tensor", ",", "sampling_mask", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "backward", "=", "T", ".", "reduce_operator", "(", "\n", "self", ".", "backward_operator", "(", "\n", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "kspace", ".", "dtype", ")", ".", "to", "(", "kspace", ".", "device", ")", ",", "\n", "kspace", ",", "\n", ")", ",", "\n", "self", ".", "_spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_map", ",", "\n", "self", ".", "_coil_dim", ",", "\n", ")", "\n", "return", "backward", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet.forward": [[136, 220], ["jointicnet.JointICNet._backward_operator", "range", "jointicnet.JointICNet.conv_out().permute", "direct.modulus().unsqueeze().amax().view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "sensitivity_map_norm.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "direct.safe_divide", "jointicnet.JointICNet.forward_operator", "direct.modulus().unsqueeze().amax().view", "jointicnet.JointICNet.conv_out", "direct.modulus().unsqueeze().amax", "direct.complex_multiplication", "sensitivity_map_norm.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "tuple", "jointicnet.JointICNet.permute", "jointicnet.JointICNet.backward_operator", "direct.conjugate().unsqueeze", "jointicnet.JointICNet._backward_operator", "direct.modulus().unsqueeze().amax", "direct.modulus().unsqueeze", "torch.where", "torch.where", "torch.where", "torch.where", "jointicnet.JointICNet._sens_model", "jointicnet.JointICNet.backward_operator", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "direct.conjugate", "jointicnet.JointICNet.backward_operator", "jointicnet.JointICNet._forward_operator", "jointicnet.JointICNet._image_model", "jointicnet.JointICNet._kspace_model", "direct.modulus().unsqueeze", "direct.modulus", "jointicnet.JointICNet._forward_operator", "tuple", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "direct.modulus"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._backward_operator", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.safe_divide", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._backward_operator", "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._sens_model", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate", "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._forward_operator", "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._image_model", "home.repos.pwc.inspect_result.directgroup_direct.jointicnet.jointicnet.JointICNet._kspace_model", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus", "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._forward_operator", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes forward pass of :class:`JointICNet`.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n\n        Returns\n        -------\n        out_image: torch.Tensor\n            Output image of shape (N, height, width, complex=2).\n        \"\"\"", "\n", "\n", "input_image", "=", "self", ".", "_backward_operator", "(", "masked_kspace", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "input_image", "=", "input_image", "/", "T", ".", "modulus", "(", "input_image", ")", ".", "unsqueeze", "(", "self", ".", "_coil_dim", ")", ".", "amax", "(", "dim", "=", "self", ".", "_spatial_dims", ")", ".", "view", "(", "\n", "-", "1", ",", "1", ",", "1", ",", "1", "\n", ")", "\n", "\n", "for", "curr_iter", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "            ", "step_sensitivity_map", "=", "(", "\n", "2", "\n", "*", "self", ".", "lr_sens", "[", "curr_iter", "]", "\n", "*", "(", "\n", "T", ".", "complex_multiplication", "(", "\n", "self", ".", "backward_operator", "(", "\n", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "masked_kspace", ".", "dtype", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", ",", "\n", "self", ".", "_forward_operator", "(", "input_image", ",", "sampling_mask", ",", "sensitivity_map", ")", "-", "masked_kspace", ",", "\n", ")", ",", "\n", "self", ".", "_spatial_dims", ",", "\n", ")", ",", "\n", "T", ".", "conjugate", "(", "input_image", ")", ".", "unsqueeze", "(", "self", ".", "_coil_dim", ")", ",", "\n", ")", "\n", "+", "self", ".", "reg_param_C", "[", "curr_iter", "]", "\n", "*", "(", "\n", "sensitivity_map", "\n", "-", "self", ".", "_sens_model", "(", "self", ".", "backward_operator", "(", "masked_kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ")", "\n", ")", "\n", ")", "\n", ")", "\n", "sensitivity_map", "=", "sensitivity_map", "-", "step_sensitivity_map", "\n", "sensitivity_map_norm", "=", "torch", ".", "sqrt", "(", "(", "(", "sensitivity_map", "**", "2", ")", ".", "sum", "(", "self", ".", "_complex_dim", ")", ")", ".", "sum", "(", "self", ".", "_coil_dim", ")", ")", "\n", "sensitivity_map_norm", "=", "sensitivity_map_norm", ".", "unsqueeze", "(", "self", ".", "_complex_dim", ")", ".", "unsqueeze", "(", "self", ".", "_coil_dim", ")", "\n", "sensitivity_map", "=", "T", ".", "safe_divide", "(", "sensitivity_map", ",", "sensitivity_map_norm", ")", "\n", "input_kspace", "=", "self", ".", "forward_operator", "(", "input_image", ",", "dim", "=", "tuple", "(", "d", "-", "1", "for", "d", "in", "self", ".", "_spatial_dims", ")", ")", "\n", "\n", "step_image", "=", "(", "\n", "2", "\n", "*", "self", ".", "lr_image", "[", "curr_iter", "]", "\n", "*", "(", "\n", "self", ".", "_backward_operator", "(", "\n", "self", ".", "_forward_operator", "(", "input_image", ",", "sampling_mask", ",", "sensitivity_map", ")", "-", "masked_kspace", ",", "\n", "sampling_mask", ",", "\n", "sensitivity_map", ",", "\n", ")", "\n", "+", "self", ".", "reg_param_I", "[", "curr_iter", "]", "*", "(", "input_image", "-", "self", ".", "_image_model", "(", "input_image", ")", ")", "\n", "+", "self", ".", "reg_param_F", "[", "curr_iter", "]", "\n", "*", "(", "\n", "input_image", "\n", "-", "self", ".", "backward_operator", "(", "\n", "self", ".", "_kspace_model", "(", "input_kspace", ")", ",", "dim", "=", "tuple", "(", "d", "-", "1", "for", "d", "in", "self", ".", "_spatial_dims", ")", "\n", ")", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "input_image", "=", "input_image", "-", "step_image", "\n", "input_image", "=", "input_image", "/", "T", ".", "modulus", "(", "input_image", ")", ".", "unsqueeze", "(", "self", ".", "_coil_dim", ")", ".", "amax", "(", "\n", "dim", "=", "self", ".", "_spatial_dims", "\n", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "out_image", "=", "self", ".", "conv_out", "(", "input_image", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "return", "out_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.conv.conv.Conv2d.__init__": [[16, 59], ["torch.PReLU", "torch.PReLU", "torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "conv.append", "torch.Conv2d", "torch.Conv2d", "conv.append", "conv.append", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "hidden_channels", ":", "int", ",", "\n", "n_convs", ":", "int", "=", "3", ",", "\n", "activation", ":", "nn", ".", "Module", "=", "nn", ".", "PReLU", "(", ")", ",", "\n", "batchnorm", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`Conv2d`.\n\n        Parameters\n        ----------\n        in_channels: int\n            Number of input channels.\n        out_channels: int\n            Number of output channels.\n        hidden_channels: int\n            Number of hidden channels.\n        n_convs: int\n            Number of convolutional layers.\n        activation: nn.Module\n            Activation function.\n        batchnorm: bool\n            If True a batch normalization layer is applied after every convolution.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "conv", ":", "List", "[", "nn", ".", "Module", "]", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "conv", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "if", "idx", "==", "0", "else", "hidden_channels", ",", "\n", "hidden_channels", "if", "idx", "!=", "n_convs", "-", "1", "else", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "if", "batchnorm", ":", "\n", "                ", "conv", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "hidden_channels", "if", "idx", "!=", "n_convs", "-", "1", "else", "out_channels", ",", "eps", "=", "1e-4", ")", ")", "\n", "", "if", "idx", "!=", "n_convs", "-", "1", ":", "\n", "                ", "conv", ".", "append", "(", "activation", ")", "\n", "", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "conv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.conv.conv.Conv2d.forward": [[60, 75], ["conv.Conv2d.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs the forward pass of :class:`Conv2d`.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        out: torch.Tensor\n            Convoluted output.\n        \"\"\"", "\n", "out", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd_engine.LPDNetEngine.__init__": [[20, 42], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`LPDNetEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd_engine.LPDNetEngine._do_iteration": [[43, 112], ["direct.utils.dict_to_device", "data[].clone", "lpd_engine.LPDNetEngine.compute_sensitivity_map", "loss_dicts.append", "regularizer_dicts.append", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "torch.cuda.amp.autocast", "lpd_engine.LPDNetEngine.model", "direct.modulus", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "lpd_engine.LPDNetEngine._scaler.scale().backward", "direct.utils.detach_dict", "direct.utils.detach_dict", "torch.tensor().to", "torch.tensor().to", "sum", "sum", "loss_fns.keys", "regularizer_fns.keys", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "lpd_engine.LPDNetEngine._scaler.scale", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "\n", "            ", "output_image", "=", "self", ".", "model", "(", "\n", "masked_kspace", "=", "data", "[", "\"masked_kspace\"", "]", ",", "\n", "sampling_mask", "=", "data", "[", "\"sampling_mask\"", "]", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", ")", "# shape (batch, height,  width, complex=2)", "\n", "\n", "output_image", "=", "T", ".", "modulus", "(", "output_image", ")", "# shape (batch, height,  width)", "\n", "\n", "loss_dict", "=", "{", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "            ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts.", "\n", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "regularizer_dicts", ",", "mode", "=", "\"sum\"", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.DualNet.__init__": [[19, 45], ["torch.Module.__init__", "kwargs.get", "kwargs.get", "torch.Sequential", "torch.Sequential", "kwargs.get", "ValueError", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "num_dual", ":", "int", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Inits :class:`DualNet`.\n\n        Parameters\n        ----------\n        num_dual: int\n            Number of dual for LPD algorithm.\n        kwargs: dict\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "kwargs", ".", "get", "(", "\"dual_architectue\"", ")", "is", "None", ":", "\n", "            ", "n_hidden", "=", "kwargs", ".", "get", "(", "\"n_hidden\"", ")", "\n", "if", "n_hidden", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Missing argument n_hidden.\"", ")", "\n", "", "self", ".", "dual_block", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "2", "*", "(", "num_dual", "+", "2", ")", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "2", "*", "num_dual", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dual_block", "=", "kwargs", ".", "get", "(", "\"dual_architectue\"", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.DualNet.compute_model_per_coil": [[46, 68], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "data.size", "data.select", "output.append", "model"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "compute_model_per_coil", "(", "model", ":", "nn", ".", "Module", ",", "data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes model per coil.\n\n        Parameters\n        ----------\n        model: nn.Module\n            Model to compute.\n        data: torch.Tensor\n            Multi-coil input.\n\n        Returns\n        -------\n        output: torch.Tensor\n            Multi-coil output.\n        \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "1", ",", "idx", ")", "\n", "output", ".", "append", "(", "model", "(", "subselected_data", ")", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "output", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.DualNet.forward": [[69, 72], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "lpd.DualNet.compute_model_per_coil().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lpd.DualNet.compute_model_per_coil"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.DualNet.compute_model_per_coil"], ["", "def", "forward", "(", "self", ",", "h", ":", "torch", ".", "Tensor", ",", "forward_f", ":", "torch", ".", "Tensor", ",", "g", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "inp", "=", "torch", ".", "cat", "(", "[", "h", ",", "forward_f", ",", "g", "]", ",", "dim", "=", "-", "1", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", "return", "self", ".", "compute_model_per_coil", "(", "self", ".", "dual_block", ",", "inp", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.PrimalNet.__init__": [[77, 102], ["torch.Module.__init__", "kwargs.get", "kwargs.get", "torch.Sequential", "torch.Sequential", "kwargs.get", "ValueError", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "num_primal", ":", "int", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Inits :class:`PrimalNet`.\n\n        Parameters\n        ----------\n        num_primal: int\n            Number of primal for LPD algorithm.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "kwargs", ".", "get", "(", "\"primal_architectue\"", ")", "is", "None", ":", "\n", "            ", "n_hidden", "=", "kwargs", ".", "get", "(", "\"n_hidden\"", ")", "\n", "if", "n_hidden", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Missing argument n_hidden.\"", ")", "\n", "", "self", ".", "primal_block", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "2", "*", "(", "num_primal", "+", "1", ")", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "2", "*", "num_primal", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "primal_block", "=", "kwargs", ".", "get", "(", "\"primal_architectue\"", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.PrimalNet.forward": [[103, 106], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "lpd.PrimalNet.primal_block().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lpd.PrimalNet.primal_block"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "f", ":", "torch", ".", "Tensor", ",", "backward_h", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "inp", "=", "torch", ".", "cat", "(", "[", "f", ",", "backward_h", "]", ",", "dim", "=", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "self", ".", "primal_block", "(", "inp", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet.__init__": [[117, 225], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "direct.nn.conv.conv.Conv2d", "unet", "NotImplementedError", "direct.nn.didn.didn.DIDN", "lpd.PrimalNet", "lpd.DualNet", "kwargs.get", "kwargs.get", "kwargs.get", "unet", "NotImplementedError", "range", "range", "direct.nn.mwcnn.mwcnn.MWCNN", "torch.Conv2d", "torch.Conv2d", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "num_iter", ":", "int", ",", "\n", "num_primal", ":", "int", ",", "\n", "num_dual", ":", "int", ",", "\n", "primal_model_architecture", ":", "str", "=", "\"MWCNN\"", ",", "\n", "dual_model_architecture", ":", "str", "=", "\"DIDN\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`LPDNet`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        num_iter: int\n            Number of unrolled iterations.\n        num_primal: int\n            Number of primal networks.\n        num_dual: int\n            Number of dual networks.\n        primal_model_architecture: str\n            Primal model architecture. Currently only implemented for MWCNN and (NORM)UNET. Default: 'MWCNN'.\n        dual_model_architecture: str\n            Dual model architecture. Currently only implemented for CONV and DIDN and (NORM)UNET. Default: 'DIDN'.\n        kwargs: dict\n            Keyword arguments for model architectures.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "num_primal", "=", "num_primal", "\n", "self", ".", "num_dual", "=", "num_dual", "\n", "\n", "primal_model", ":", "nn", ".", "Module", "\n", "if", "primal_model_architecture", "==", "\"MWCNN\"", ":", "\n", "            ", "primal_model", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "MWCNN", "(", "\n", "input_channels", "=", "2", "*", "(", "num_primal", "+", "1", ")", ",", "\n", "first_conv_hidden_channels", "=", "kwargs", ".", "get", "(", "\"primal_mwcnn_hidden_channels\"", ",", "32", ")", ",", "\n", "num_scales", "=", "kwargs", ".", "get", "(", "\"primal_mwcnn_num_scales\"", ",", "4", ")", ",", "\n", "bias", "=", "kwargs", ".", "get", "(", "\"primal_mwcnn_bias\"", ",", "False", ")", ",", "\n", "batchnorm", "=", "kwargs", ".", "get", "(", "\"primal_mwcnn_batchnorm\"", ",", "False", ")", ",", "\n", ")", ",", "\n", "nn", ".", "Conv2d", "(", "2", "*", "(", "num_primal", "+", "1", ")", ",", "2", "*", "num_primal", ",", "kernel_size", "=", "1", ")", ",", "\n", "]", "\n", ")", "\n", "", "elif", "primal_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "unet", "=", "UnetModel2d", "if", "primal_model_architecture", "==", "\"UNET\"", "else", "NormUnetModel2d", "\n", "primal_model", "=", "unet", "(", "\n", "in_channels", "=", "2", "*", "(", "num_primal", "+", "1", ")", ",", "\n", "out_channels", "=", "2", "*", "num_primal", ",", "\n", "num_filters", "=", "kwargs", ".", "get", "(", "\"primal_unet_num_filters\"", ",", "8", ")", ",", "\n", "num_pool_layers", "=", "kwargs", ".", "get", "(", "\"primal_unet_num_pool_layers\"", ",", "4", ")", ",", "\n", "dropout_probability", "=", "kwargs", ".", "get", "(", "\"primal_unet_dropout_probability\"", ",", "0.0", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"XPDNet is currently implemented only with primal_model_architecture == 'MWCNN', 'UNET' or 'NORMUNET.\"", "\n", "f\"Got {primal_model_architecture}.\"", "\n", ")", "\n", "", "dual_model", ":", "nn", ".", "Module", "\n", "if", "dual_model_architecture", "==", "\"CONV\"", ":", "\n", "            ", "dual_model", "=", "Conv2d", "(", "\n", "in_channels", "=", "2", "*", "(", "num_dual", "+", "2", ")", ",", "\n", "out_channels", "=", "2", "*", "num_dual", ",", "\n", "hidden_channels", "=", "kwargs", ".", "get", "(", "\"dual_conv_hidden_channels\"", ",", "16", ")", ",", "\n", "n_convs", "=", "kwargs", ".", "get", "(", "\"dual_conv_n_convs\"", ",", "4", ")", ",", "\n", "batchnorm", "=", "kwargs", ".", "get", "(", "\"dual_conv_batchnorm\"", ",", "False", ")", ",", "\n", ")", "\n", "", "elif", "dual_model_architecture", "==", "\"DIDN\"", ":", "\n", "            ", "dual_model", "=", "DIDN", "(", "\n", "in_channels", "=", "2", "*", "(", "num_dual", "+", "2", ")", ",", "\n", "out_channels", "=", "2", "*", "num_dual", ",", "\n", "hidden_channels", "=", "kwargs", ".", "get", "(", "\"dual_didn_hidden_channels\"", ",", "16", ")", ",", "\n", "num_dubs", "=", "kwargs", ".", "get", "(", "\"dual_didn_num_dubs\"", ",", "6", ")", ",", "\n", "num_convs_recon", "=", "kwargs", ".", "get", "(", "\"dual_didn_num_convs_recon\"", ",", "9", ")", ",", "\n", ")", "\n", "", "elif", "dual_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "unet", "=", "UnetModel2d", "if", "dual_model_architecture", "==", "\"UNET\"", "else", "NormUnetModel2d", "\n", "dual_model", "=", "unet", "(", "\n", "in_channels", "=", "2", "*", "(", "num_dual", "+", "2", ")", ",", "\n", "out_channels", "=", "2", "*", "num_dual", ",", "\n", "num_filters", "=", "kwargs", ".", "get", "(", "\"dual_unet_num_filters\"", ",", "8", ")", ",", "\n", "num_pool_layers", "=", "kwargs", ".", "get", "(", "\"dual_unet_num_pool_layers\"", ",", "4", ")", ",", "\n", "dropout_probability", "=", "kwargs", ".", "get", "(", "\"dual_unet_dropout_probability\"", ",", "0.0", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"XPDNet is currently implemented for dual_model_architecture == 'CONV', 'DIDN',\"", "\n", "f\" 'UNET' or 'NORMUNET'. Got dual_model_architecture == {dual_model_architecture}.\"", "\n", ")", "\n", "\n", "", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_complex_dim", "=", "-", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n", "self", ".", "primal_net", "=", "nn", ".", "ModuleList", "(", "\n", "[", "PrimalNet", "(", "num_primal", ",", "primal_architectue", "=", "primal_model", ")", "for", "_", "in", "range", "(", "num_iter", ")", "]", "\n", ")", "\n", "self", ".", "dual_net", "=", "nn", ".", "ModuleList", "(", "[", "DualNet", "(", "num_dual", ",", "dual_architectue", "=", "dual_model", ")", "for", "_", "in", "range", "(", "num_iter", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._forward_operator": [[226, 235], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "lpd.LPDNet.forward_operator", "direct.expand_operator", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator"], ["", "def", "_forward_operator", "(", "\n", "self", ",", "image", ":", "torch", ".", "Tensor", ",", "sampling_mask", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "forward", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "image", ".", "dtype", ")", ".", "to", "(", "image", ".", "device", ")", ",", "\n", "self", ".", "forward_operator", "(", "T", ".", "expand_operator", "(", "image", ",", "sensitivity_map", ",", "self", ".", "_coil_dim", ")", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "\n", ")", "\n", "return", "forward", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._backward_operator": [[236, 252], ["direct.reduce_operator", "lpd.LPDNet.backward_operator", "torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator"], ["", "def", "_backward_operator", "(", "\n", "self", ",", "kspace", ":", "torch", ".", "Tensor", ",", "sampling_mask", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "backward", "=", "T", ".", "reduce_operator", "(", "\n", "self", ".", "backward_operator", "(", "\n", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "kspace", ".", "dtype", ")", ".", "to", "(", "kspace", ".", "device", ")", ",", "\n", "kspace", ",", "\n", ")", ",", "\n", "self", ".", "_spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_map", ",", "\n", "self", ".", "_coil_dim", ",", "\n", ")", "\n", "return", "backward", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet.forward": [[253, 295], ["lpd.LPDNet._backward_operator", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "range", "primal_buffer[].clone", "dual_buffer[].clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lpd.LPDNet._forward_operator", "lpd.LPDNet._backward_operator"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._backward_operator", "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._forward_operator", "home.repos.pwc.inspect_result.directgroup_direct.lpd.lpd.LPDNet._backward_operator"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes forward pass of :class:`LPDNet`.\n\n        Parameters\n        ----------\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n\n        Returns\n        -------\n        output: torch.Tensor\n            Output image of shape (N, height, width, complex=2).\n        \"\"\"", "\n", "input_image", "=", "self", ".", "_backward_operator", "(", "masked_kspace", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "dual_buffer", "=", "torch", ".", "cat", "(", "[", "masked_kspace", "]", "*", "self", ".", "num_dual", ",", "self", ".", "_complex_dim", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", "\n", "primal_buffer", "=", "torch", ".", "cat", "(", "[", "input_image", "]", "*", "self", ".", "num_primal", ",", "self", ".", "_complex_dim", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", "\n", "\n", "for", "curr_iter", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "\n", "# Dual", "\n", "            ", "f_2", "=", "primal_buffer", "[", "...", ",", "2", ":", "4", "]", ".", "clone", "(", ")", "\n", "dual_buffer", "=", "self", ".", "dual_net", "[", "curr_iter", "]", "(", "\n", "dual_buffer", ",", "self", ".", "_forward_operator", "(", "f_2", ",", "sampling_mask", ",", "sensitivity_map", ")", ",", "masked_kspace", "\n", ")", "\n", "\n", "# Primal", "\n", "h_1", "=", "dual_buffer", "[", "...", ",", "0", ":", "2", "]", ".", "clone", "(", ")", "\n", "primal_buffer", "=", "self", ".", "primal_net", "[", "curr_iter", "]", "(", "\n", "primal_buffer", ",", "self", ".", "_backward_operator", "(", "h_1", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", ")", "\n", "\n", "", "output", "=", "primal_buffer", "[", "...", ",", "0", ":", "2", "]", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.MRILogLikelihood.__init__": [[26, 47], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`MRILogLikelihood`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.MRILogLikelihood.forward": [[48, 117], ["input_image.permute.permute.permute", "torch.tensor().to.reshape", "torch.tensor().to.reshape", "torch.tensor().to.reshape", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "rim.MRILogLikelihood.backward_operator", "rim.MRILogLikelihood.sum.permute", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "direct.data.transforms.complex_multiplication", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "rim.MRILogLikelihood.forward_operator", "direct.data.transforms.complex_multiplication().sum", "rim.MRILogLikelihood.sum", "torch.ones().int", "torch.ones().int", "torch.ones().int", "torch.ones().int", "torch.ones().int", "torch.ones().int", "torch.ones().int", "torch.ones().int", "torch.ones().int", "input_image.permute.permute.unsqueeze", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "direct.data.transforms.complex_multiplication", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "direct.data.transforms.conjugate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_image", ",", "\n", "masked_kspace", ",", "\n", "sensitivity_map", ",", "\n", "sampling_mask", ",", "\n", "loglikelihood_scaling", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`MRILogLikelihood`.\n\n        Parameters\n        ----------\n        input_image: torch.Tensor\n            Initial or previous iteration of image with complex first\n            of shape (N, complex, height, width).\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex).\n        sensitivity_map: torch.Tensor\n            Sensitivity Map of shape (N, coil, height, width, complex).\n        sampling_mask: torch.Tensor\n        loglikelihood_scaling: torch.Tensor\n            Multiplier for loglikelihood, for instance for the k-space noise, of shape (1,).\n\n        Returns\n        -------\n        out: torch.Tensor\n            The MRI Loglikelihood.\n        \"\"\"", "\n", "\n", "input_image", "=", "input_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# shape (N, height, width, complex)", "\n", "\n", "if", "loglikelihood_scaling", "is", "not", "None", ":", "\n", "            ", "loglikelihood_scaling", "=", "loglikelihood_scaling", "\n", "", "else", ":", "\n", "            ", "loglikelihood_scaling", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ",", "dtype", "=", "masked_kspace", ".", "dtype", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", "\n", "", "loglikelihood_scaling", "=", "loglikelihood_scaling", ".", "reshape", "(", "\n", "-", "1", ",", "*", "(", "torch", ".", "ones", "(", "len", "(", "sensitivity_map", ".", "shape", ")", "-", "1", ")", ".", "int", "(", ")", ")", "\n", ")", "# shape (1, 1, 1, 1, 1)", "\n", "\n", "# We multiply by the loglikelihood_scaling here to prevent fp16 information loss,", "\n", "# as this value is typically <<1, and the operators are linear.", "\n", "\n", "mul", "=", "loglikelihood_scaling", "*", "T", ".", "complex_multiplication", "(", "\n", "sensitivity_map", ",", "input_image", ".", "unsqueeze", "(", "1", ")", "# (N, 1, height, width, complex)", "\n", ")", "# shape (N, coil, height, width, complex)", "\n", "\n", "mr_forward", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "masked_kspace", ".", "dtype", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", ",", "\n", "self", ".", "forward_operator", "(", "mul", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "\n", ")", "# shape (N, coil, height, width, complex)", "\n", "\n", "error", "=", "mr_forward", "-", "loglikelihood_scaling", "*", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "masked_kspace", ".", "dtype", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", ",", "\n", "masked_kspace", ",", "\n", ")", "# shape (N, coil, height, width, complex)", "\n", "\n", "mr_backward", "=", "self", ".", "backward_operator", "(", "error", ",", "dim", "=", "self", ".", "_spatial_dims", ")", "# shape (N, coil, height, width, complex)", "\n", "\n", "if", "sensitivity_map", "is", "not", "None", ":", "\n", "            ", "out", "=", "T", ".", "complex_multiplication", "(", "T", ".", "conjugate", "(", "sensitivity_map", ")", ",", "mr_backward", ")", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "mr_backward", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", "# out has shape (N, complex=2, height, width)", "\n", "\n", "", "out", "=", "out", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# complex first: shape (N, height, width, complex=2)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIMInit.__init__": [[129, 173], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "zip", "numpy.sum", "range", "rim.RIMInit.conv_blocks.append", "rim.RIMInit.out_blocks.append", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "x_ch", ":", "int", ",", "\n", "out_ch", ":", "int", ",", "\n", "channels", ":", "Tuple", "[", "int", ",", "...", "]", ",", "\n", "dilations", ":", "Tuple", "[", "int", ",", "...", "]", ",", "\n", "depth", ":", "int", "=", "2", ",", "\n", "multiscale_depth", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`RIMInit`.\n\n        Parameters\n        ----------\n        x_ch: int\n            Input channels.\n        out_ch: int\n            Number of hidden channels in the RIM.\n        channels: tuple\n            Channels in the convolutional layers of initializer. Typical it could be e.g. (32, 32, 64, 64).\n        dilations: tuple\n            Dilations of the convolutional layers of the initializer. Typically it could be e.g. (1, 1, 2, 4).\n        depth: int\n            RIM depth\n        multiscale_depth: 1\n            Number of feature layers to aggregate for the output, if 1, multi-scale context aggregation is disabled.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "multiscale_depth", "=", "multiscale_depth", "\n", "tch", "=", "x_ch", "\n", "for", "(", "curr_channels", ",", "curr_dilations", ")", "in", "zip", "(", "channels", ",", "dilations", ")", ":", "\n", "            ", "block", "=", "[", "\n", "nn", ".", "ReplicationPad2d", "(", "curr_dilations", ")", ",", "\n", "nn", ".", "Conv2d", "(", "tch", ",", "curr_channels", ",", "3", ",", "padding", "=", "0", ",", "dilation", "=", "curr_dilations", ")", ",", "\n", "]", "\n", "tch", "=", "curr_channels", "\n", "self", ".", "conv_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "", "tch", "=", "np", ".", "sum", "(", "channels", "[", "-", "multiscale_depth", ":", "]", ")", "\n", "for", "_", "in", "range", "(", "depth", ")", ":", "\n", "            ", "block", "=", "[", "nn", ".", "Conv2d", "(", "tch", ",", "out_ch", ",", "1", ",", "padding", "=", "0", ")", "]", "\n", "self", ".", "out_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIMInit.forward": [[174, 189], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "output_list.append", "block", "features.append", "block"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "features", "=", "[", "]", "\n", "for", "block", "in", "self", ".", "conv_blocks", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "block", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "if", "self", ".", "multiscale_depth", ">", "1", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "", "", "if", "self", ".", "multiscale_depth", ">", "1", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "features", "[", "-", "self", ".", "multiscale_depth", ":", "]", ",", "dim", "=", "1", ")", "\n", "", "output_list", "=", "[", "]", "\n", "for", "block", "in", "self", ".", "out_blocks", ":", "\n", "            ", "y", "=", "F", ".", "relu", "(", "block", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "output_list", ".", "append", "(", "y", ")", "\n", "", "out", "=", "torch", ".", "stack", "(", "output_list", ",", "dim", "=", "-", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIM.__init__": [[200, 325], ["torch.Module.__init__", "kwargs.keys", "direct.utils.asserts.assert_positive_integer", "rim.MRILogLikelihood", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "rim.RIMInit", "rim.RIM.cell_list.append", "ValueError", "direct.nn.recurrent.recurrent.NormConv2dGRU", "direct.nn.recurrent.recurrent.Conv2dGRU", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_positive_integer"], ["def", "__init__", "(", "\n", "self", ",", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "hidden_channels", ":", "int", ",", "\n", "x_channels", ":", "int", "=", "2", ",", "\n", "length", ":", "int", "=", "8", ",", "\n", "depth", ":", "int", "=", "1", ",", "\n", "no_parameter_sharing", ":", "bool", "=", "True", ",", "\n", "instance_norm", ":", "bool", "=", "False", ",", "\n", "dense_connect", ":", "bool", "=", "False", ",", "\n", "skip_connections", ":", "bool", "=", "True", ",", "\n", "replication_padding", ":", "bool", "=", "True", ",", "\n", "image_initialization", ":", "str", "=", "\"zero_filled\"", ",", "\n", "learned_initializer", ":", "bool", "=", "False", ",", "\n", "initializer_channels", ":", "Optional", "[", "Tuple", "[", "int", ",", "...", "]", "]", "=", "(", "32", ",", "32", ",", "64", ",", "64", ")", ",", "\n", "initializer_dilations", ":", "Optional", "[", "Tuple", "[", "int", ",", "...", "]", "]", "=", "(", "1", ",", "1", ",", "2", ",", "4", ")", ",", "\n", "initializer_multiscale", ":", "int", "=", "1", ",", "\n", "normalized", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`RIM`.\n\n        Parameters\n        ----------\n        forward_operator: Callable\n            Forward Operator.\n        backward_operator: Callable\n            Backward Operator.\n        hidden_channels: int\n            Number of hidden channels in recurrent unit of RIM.\n        x_channels: int\n            Number of input channels. Default: 2 (complex data).\n        length: int\n            Number of time-steps. Default: 8.\n        depth: int\n            Number of layers of recurrent unit of RIM. Default: 1.\n        no_parameter_sharing: bool\n            If False, a single recurrent unit will be used for each time-step. Default: True.\n        instance_norm: bool\n            If True, instance normalization is applied in the recurrent unit of RIM. Default: False.\n        dense_connect: bool\n            Use dense connection in the recurrent unit of RIM. Default: False.\n        skip_connections: bool\n            If True, the previous prediction is added to the next. Default: True.\n        replication_padding: bool\n            Replication padding for the recurrent unit of RIM. Defaul: True.\n        image_initialization: str\n            Input image initialization for RIM. Can be \"sense\", \"input_kspace\", \"input_image\" or \"zero_filled\". Default: \"zero_filled\".\n        learned_initializer: bool\n            If True, an initializer is trained to learn image initialization. Default: False.\n        initializer_channels: Optional[Tuple[int, ...]]\n            Number of channels for learned_initializer. If \"learned_initializer=False\" this is ignored. Default: (32, 32, 64, 64).\n        initializer_dilations: Optional[Tuple[int, ...]]\n            Number of dilations for learned_initializer. Must have the same length as \"initialize_channels\".\n            If \"learned_initializer=False\" this is ignored. Default: (1, 1, 2, 4)\n        initializer_multiscale: int\n            Number of initializer multiscale. If \"learned_initializer=False\" this is ignored. Default: 1.\n        normalized: bool\n            If True, :class:`NormConv2dGRU` will be used instead of :class:`Conv2dGRU`. Default: False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "extra_keys", "=", "kwargs", ".", "keys", "(", ")", "\n", "for", "extra_key", "in", "extra_keys", ":", "\n", "            ", "if", "extra_key", "not", "in", "[", "\n", "\"steps\"", ",", "\n", "\"sensitivity_map_model\"", ",", "\n", "\"model_name\"", ",", "\n", "\"z_reduction_frequency\"", ",", "\n", "\"kspace_context\"", ",", "\n", "\"scale_loglikelihood\"", ",", "\n", "\"whiten_input\"", ",", "# should be passed!", "\n", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{type(self).__name__} got key `{extra_key}` which is not supported.\"", ")", "\n", "\n", "", "", "assert_positive_integer", "(", "x_channels", ",", "hidden_channels", ",", "length", ",", "depth", ")", "\n", "# assert_bool(no_parameter_sharing, instance_norm, dense_connect, skip_connections, replication_padding)", "\n", "\n", "self", ".", "initializer", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", "\n", "if", "learned_initializer", "and", "initializer_channels", "is", "not", "None", "and", "initializer_dilations", "is", "not", "None", ":", "\n", "# List is because of a omegaconf bug.", "\n", "            ", "self", ".", "initializer", "=", "RIMInit", "(", "\n", "x_channels", ",", "\n", "hidden_channels", ",", "\n", "channels", "=", "initializer_channels", ",", "\n", "dilations", "=", "initializer_dilations", ",", "\n", "depth", "=", "depth", ",", "\n", "multiscale_depth", "=", "initializer_multiscale", ",", "\n", ")", "\n", "\n", "", "self", ".", "image_initialization", "=", "image_initialization", "\n", "\n", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "\n", "self", ".", "grad_likelihood", "=", "MRILogLikelihood", "(", "forward_operator", ",", "backward_operator", ")", "\n", "\n", "self", ".", "skip_connections", "=", "skip_connections", "\n", "\n", "self", ".", "x_channels", "=", "x_channels", "\n", "self", ".", "hidden_channels", "=", "hidden_channels", "\n", "\n", "self", ".", "cell_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "no_parameter_sharing", "=", "no_parameter_sharing", "\n", "\n", "conv_unit_params", "=", "{", "\n", "\"in_channels\"", ":", "x_channels", "*", "2", ",", "# double channels as input is concatenated image and gradient", "\n", "\"out_channels\"", ":", "x_channels", ",", "\n", "\"hidden_channels\"", ":", "hidden_channels", ",", "\n", "\"num_layers\"", ":", "depth", ",", "\n", "\"instance_norm\"", ":", "instance_norm", ",", "\n", "\"dense_connect\"", ":", "dense_connect", ",", "\n", "\"replication_padding\"", ":", "replication_padding", ",", "\n", "}", "\n", "for", "_", "in", "range", "(", "length", "if", "no_parameter_sharing", "else", "1", ")", ":", "\n", "            ", "self", ".", "cell_list", ".", "append", "(", "\n", "NormConv2dGRU", "(", "**", "conv_unit_params", ")", "if", "normalized", "else", "Conv2dGRU", "(", "**", "conv_unit_params", ")", "# type: ignore", "\n", ")", "\n", "\n", "", "self", ".", "length", "=", "length", "\n", "self", ".", "depth", "=", "depth", "\n", "\n", "self", ".", "_coil_dim", "=", "1", "\n", "self", ".", "_spatial_dims", "=", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIM.compute_sense_init": [[326, 339], ["direct.data.transforms.complex_multiplication", "input_image.sum.sum.sum", "direct.data.transforms.conjugate", "rim.RIM.backward_operator"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate"], ["", "def", "compute_sense_init", "(", "self", ",", "kspace", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "# kspace is of shape: (N, coil, height, width, complex)", "\n", "# sensitivity_map is of shape (N, coil, height, width, complex)", "\n", "\n", "        ", "input_image", "=", "T", ".", "complex_multiplication", "(", "\n", "T", ".", "conjugate", "(", "sensitivity_map", ")", ",", "\n", "self", ".", "backward_operator", "(", "kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ",", "\n", ")", "# shape (N, coil, height, width, complex=2)", "\n", "\n", "input_image", "=", "input_image", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", "\n", "# shape (N, height, width, complex=2)", "\n", "return", "input_image", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIM.forward": [[340, 462], ["rim.RIM.permute().contiguous", "rim.RIM.size", "range", "rim.RIM.initializer", "rim.RIM.size", "rim.RIM.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "rim.RIM.grad_likelihood", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cell", "rim.RIM.compute_sense_init", "rim.RIM.permute", "rim.RIM.permute", "list", "rim.RIM.abs().max", "warnings.warn", "cell_output.set_", "rim.RIM.set_", "cell_outputs.append", "rim.RIM.compute_sense_init", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "ValueError", "rim.RIM.abs", "ValueError", "rim.RIM.backward_operator().sum", "ValueError", "rim.RIM.abs().max", "rim.RIM.backward_operator", "rim.RIM.abs"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIM.compute_sense_init", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim.RIM.compute_sense_init"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_image", ":", "torch", ".", "Tensor", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "previous_state", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "loglikelihood_scaling", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Performs forward pass of :class:`RIM`.\n\n        Parameters\n        ----------\n        input_image: torch.Tensor\n            Initial or intermediate guess of input. Has shape (N, height, width, complex=2).\n        masked_kspace: torch.Tensor\n            Masked k-space of shape (N, coil, height, width, complex=2).\n        sensitivity_map: torch.Tensor\n            Sensitivity map of shape (N, coil, height, width, complex=2).\n        sampling_mask: torch.Tensor\n            Sampling mask of shape (N, 1, height, width, 1).\n        previous_state: torch.Tensor\n        loglikelihood_scaling: torch.Tensor\n            Float tensor of shape (1,).\n\n        Returns\n        -------\n        torch.Tensor\n        \"\"\"", "\n", "if", "input_image", "is", "None", ":", "\n", "            ", "if", "self", ".", "image_initialization", "==", "\"sense\"", ":", "\n", "                ", "input_image", "=", "self", ".", "compute_sense_init", "(", "\n", "kspace", "=", "masked_kspace", ",", "\n", "sensitivity_map", "=", "sensitivity_map", ",", "\n", ")", "\n", "", "elif", "self", ".", "image_initialization", "==", "\"input_kspace\"", ":", "\n", "                ", "if", "\"initial_kspace\"", "not", "in", "kwargs", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "f\"`'initial_kspace` is required as input if initialization is {self.image_initialization}.\"", "\n", ")", "\n", "", "input_image", "=", "self", ".", "compute_sense_init", "(", "\n", "kspace", "=", "kwargs", "[", "\"initial_kspace\"", "]", ",", "\n", "sensitivity_map", "=", "sensitivity_map", ",", "\n", ")", "\n", "", "elif", "self", ".", "image_initialization", "==", "\"input_image\"", ":", "\n", "                ", "if", "\"initial_image\"", "not", "in", "kwargs", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "f\"`'initial_image` is required as input if initialization is {self.image_initialization}.\"", "\n", ")", "\n", "", "input_image", "=", "kwargs", "[", "\"initial_image\"", "]", "\n", "\n", "", "elif", "self", ".", "image_initialization", "==", "\"zero_filled\"", ":", "\n", "                ", "input_image", "=", "self", ".", "backward_operator", "(", "masked_kspace", ",", "dim", "=", "self", ".", "_spatial_dims", ")", ".", "sum", "(", "self", ".", "_coil_dim", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Unknown image_initialization. Expected `sense`, `input_kspace`, `input_image` or `zero_filled`. \"", "\n", "f\"Got {self.image_initialization}.\"", "\n", ")", "\n", "# Provide an initialization for the first hidden state.", "\n", "", "", "if", "(", "self", ".", "initializer", "is", "not", "None", ")", "and", "(", "previous_state", "is", "None", ")", ":", "\n", "            ", "previous_state", "=", "self", ".", "initializer", "(", "\n", "input_image", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", ")", "# shape (N, hidden_channels, height, width, depth)", "\n", "# TODO: This has to be made contiguous", "\n", "\n", "", "input_image", "=", "input_image", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "# shape (N, complex=2, height, width)", "\n", "\n", "batch_size", "=", "input_image", ".", "size", "(", "0", ")", "\n", "spatial_shape", "=", "[", "input_image", ".", "size", "(", "self", ".", "_spatial_dims", "[", "0", "]", ")", ",", "input_image", ".", "size", "(", "self", ".", "_spatial_dims", "[", "1", "]", ")", "]", "\n", "# Initialize zero state for RIM", "\n", "state_size", "=", "[", "batch_size", ",", "self", ".", "hidden_channels", "]", "+", "list", "(", "spatial_shape", ")", "+", "[", "self", ".", "depth", "]", "\n", "if", "previous_state", "is", "None", ":", "\n", "# shape (N, hidden_channels, height, width, depth)", "\n", "            ", "previous_state", "=", "torch", ".", "zeros", "(", "*", "state_size", ",", "dtype", "=", "input_image", ".", "dtype", ")", ".", "to", "(", "input_image", ".", "device", ")", "\n", "\n", "", "cell_outputs", "=", "[", "]", "\n", "intermediate_image", "=", "input_image", "# shape (N, complex=2, height, width)", "\n", "\n", "for", "cell_idx", "in", "range", "(", "self", ".", "length", ")", ":", "\n", "            ", "cell", "=", "self", ".", "cell_list", "[", "cell_idx", "]", "if", "self", ".", "no_parameter_sharing", "else", "self", ".", "cell_list", "[", "0", "]", "\n", "\n", "grad_loglikelihood", "=", "self", ".", "grad_likelihood", "(", "\n", "intermediate_image", ",", "\n", "masked_kspace", ",", "\n", "sensitivity_map", ",", "\n", "sampling_mask", ",", "\n", "loglikelihood_scaling", ",", "\n", ")", "# shape (N, complex=2, height, width)", "\n", "\n", "if", "grad_loglikelihood", ".", "abs", "(", ")", ".", "max", "(", ")", ">", "150.0", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "f\"Very large values for the gradient loglikelihood ({grad_loglikelihood.abs().max()}). \"", "\n", "f\"Might cause difficulties.\"", "\n", ")", "\n", "\n", "", "cell_input", "=", "torch", ".", "cat", "(", "\n", "[", "intermediate_image", ",", "grad_loglikelihood", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "# shape (N, complex=4, height, width)", "\n", "\n", "cell_output", ",", "previous_state", "=", "cell", "(", "cell_input", ",", "previous_state", ")", "\n", "# shapes (N, complex=2, height, width), (N, hidden_channels, height, width, depth)", "\n", "\n", "if", "self", ".", "skip_connections", ":", "\n", "# shape (N, complex=2, height, width)", "\n", "                ", "intermediate_image", "=", "intermediate_image", "+", "cell_output", "\n", "", "else", ":", "\n", "# shape (N, complex=2, height, width)", "\n", "                ", "intermediate_image", "=", "cell_output", "\n", "\n", "", "if", "not", "self", ".", "training", ":", "\n", "# If not training, memory can be significantly reduced by clearing the previous cell.", "\n", "                ", "cell_output", ".", "set_", "(", ")", "\n", "grad_loglikelihood", ".", "set_", "(", ")", "\n", "del", "cell_output", ",", "grad_loglikelihood", "\n", "\n", "# Only save intermediate reconstructions at training step", "\n", "", "if", "self", ".", "training", "or", "cell_idx", "==", "(", "self", ".", "length", "-", "1", ")", ":", "\n", "                ", "cell_outputs", ".", "append", "(", "intermediate_image", ")", "# type: ignore", "\n", "\n", "", "", "return", "cell_outputs", ",", "previous_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine.__init__": [[19, 38], ["direct.nn.mri_models.MRIModelEngine.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ":", "BaseConfig", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "device", ":", "str", ",", "\n", "forward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "backward_operator", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "mixed_precision", ":", "bool", "=", "False", ",", "\n", "**", "models", ":", "nn", ".", "Module", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits :class:`RIMEngine.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration": [[40, 155], ["direct.utils.dict_to_device", "data[].clone", "rim_engine.RIMEngine.compute_sensitivity_map", "range", "direct.utils.reduce_list_of_dicts", "direct.utils.reduce_list_of_dicts", "direct.engine.DoIterationOutput", "NotImplementedError", "torch.tensor().to.reshape", "rim_engine.RIMEngine.logger.debug", "torch.tensor().to", "hidden_state.detach.detach.detach", "reconstruction_iter[].permute.detach", "loss_dicts.append", "regularizer_dicts.append", "torch.cuda.amp.autocast", "rim_engine.RIMEngine.model", "reconstruction_iter[].permute", "direct.utils.detach_dict", "direct.utils.detach_dict", "torch.tensor", "input_image.permute.permute.permute", "torch.tensor().to", "torch.tensor().to", "output_image_iter.permute.permute.permute", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.items", "sum", "sum", "rim_engine.RIMEngine._scaler.scale().backward", "rim_engine.RIMEngine._scaler.scale().backward", "loss_fns.keys", "regularizer_fns.keys", "len", "direct.utils.reduce_list_of_dicts.items", "len", "direct.utils.reduce_list_of_dicts.items", "direct.utils.reduce_list_of_dicts.values", "direct.utils.reduce_list_of_dicts.values", "torch.tensor", "torch.tensor", "rim_engine.RIMEngine._scaler.scale", "rim_engine.RIMEngine._scaler.scale"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.dict_to_device", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.compute_sensitivity_map", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.reduce_list_of_dicts", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.detach_dict", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.values"], ["", "def", "_do_iteration", "(", "\n", "self", ",", "\n", "data", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "loss_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", "regularizer_fns", ":", "Optional", "[", "Dict", "[", "str", ",", "Callable", "]", "]", "=", "None", ",", "\n", ")", "->", "DoIterationOutput", ":", "\n", "\n", "# loss_fns can be done, e.g. during validation", "\n", "        ", "if", "loss_fns", "is", "None", ":", "\n", "            ", "loss_fns", "=", "{", "}", "\n", "\n", "", "if", "regularizer_fns", "is", "None", ":", "\n", "            ", "regularizer_fns", "=", "{", "}", "\n", "\n", "# The first input_image in the iteration is the input_image with the mask applied and no first hidden state.", "\n", "", "input_image", "=", "None", "\n", "hidden_state", "=", "None", "\n", "output_image", "=", "None", "\n", "loss_dicts", "=", "[", "]", "\n", "regularizer_dicts", "=", "[", "]", "\n", "\n", "data", "=", "dict_to_device", "(", "data", ",", "self", ".", "device", ")", "\n", "# TODO(jt): keys=['sampling_mask', 'sensitivity_map', 'target', 'masked_kspace', 'scaling_factor']", "\n", "\n", "# sensitivity_map of shape (batch, coil, height,  width, complex=2)", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ".", "clone", "(", ")", "\n", "\n", "if", "\"noise_model\"", "in", "self", ".", "models", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "data", "[", "\"sensitivity_map\"", "]", "=", "self", ".", "compute_sensitivity_map", "(", "sensitivity_map", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "model", ".", "scale_loglikelihood", ":", "# type: ignore", "\n", "            ", "scaling_factor", "=", "1.0", "*", "self", ".", "cfg", ".", "model", ".", "scale_loglikelihood", "/", "(", "data", "[", "\"scaling_factor\"", "]", "**", "2", ")", "# type: ignore", "\n", "scaling_factor", "=", "scaling_factor", ".", "reshape", "(", "-", "1", ",", "1", ")", "# shape (batch, complex=1)", "\n", "self", ".", "logger", ".", "debug", "(", "f\"Scaling factor is: {scaling_factor}\"", ")", "\n", "", "else", ":", "\n", "# Needs fixing.", "\n", "            ", "scaling_factor", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ".", "to", "(", "sensitivity_map", ".", "device", ")", "# shape (complex=1, )", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "cfg", ".", "model", ".", "steps", ")", ":", "# type: ignore", "\n", "            ", "with", "autocast", "(", "enabled", "=", "self", ".", "mixed_precision", ")", ":", "\n", "                ", "if", "input_image", "is", "not", "None", ":", "\n", "                    ", "input_image", "=", "input_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "reconstruction_iter", ",", "hidden_state", "=", "self", ".", "model", "(", "\n", "**", "data", ",", "\n", "input_image", "=", "input_image", ",", "\n", "hidden_state", "=", "hidden_state", ",", "\n", "loglikelihood_scaling", "=", "scaling_factor", ",", "\n", ")", "\n", "# reconstruction_iter: list with tensors of shape (batch, complex=2, height, width)", "\n", "# hidden_state has shape: (batch, num_hidden_channels, height, width, depth)", "\n", "\n", "output_image", "=", "reconstruction_iter", "[", "-", "1", "]", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# shape (batch, height,  width, complex=2)", "\n", "\n", "loss_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "loss_fns", ".", "keys", "(", ")", "\n", "}", "\n", "regularizer_dict", "=", "{", "\n", "k", ":", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "data", "[", "\"target\"", "]", ".", "dtype", ")", ".", "to", "(", "self", ".", "device", ")", "for", "k", "in", "regularizer_fns", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "# TODO: This seems too similar not to be able to do this, perhaps a partial can help here", "\n", "for", "output_image_iter", "in", "reconstruction_iter", ":", "\n", "                    ", "output_image_iter", "=", "output_image_iter", ".", "permute", "(", "\n", "0", ",", "2", ",", "3", ",", "1", "\n", ")", "# shape (batch, height,  width, complex=2)", "\n", "for", "key", ",", "value", "in", "loss_dict", ".", "items", "(", ")", ":", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "value", "+", "loss_fns", "[", "key", "]", "(", "\n", "output_image_iter", ",", "\n", "**", "data", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "regularizer_dict", ".", "items", "(", ")", ":", "\n", "                        ", "regularizer_dict", "[", "key", "]", "=", "value", "+", "regularizer_fns", "[", "key", "]", "(", "\n", "output_image_iter", ",", "\n", "**", "data", ",", "\n", ")", "\n", "\n", "", "", "loss_dict", "=", "{", "k", ":", "v", "/", "len", "(", "reconstruction_iter", ")", "for", "k", ",", "v", "in", "loss_dict", ".", "items", "(", ")", "}", "\n", "regularizer_dict", "=", "{", "k", ":", "v", "/", "len", "(", "reconstruction_iter", ")", "for", "k", ",", "v", "in", "regularizer_dict", ".", "items", "(", ")", "}", "\n", "\n", "loss", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "+", "sum", "(", "regularizer_dict", ".", "values", "(", ")", ")", "# type: ignore", "\n", "\n", "", "if", "self", ".", "model", ".", "training", ":", "\n", "# TODO(gy): With steps >= 1, calling .backward(retain_grad=False) caused problems.", "\n", "#  Check with Jonas if it's ok.", "\n", "\n", "                ", "if", "(", "self", ".", "cfg", ".", "model", ".", "steps", ">", "1", ")", "and", "(", "_", "<", "self", ".", "cfg", ".", "model", ".", "steps", "-", "1", ")", ":", "# type: ignore", "\n", "                    ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "# Detach hidden state from computation graph, to ensure loss is only computed per RIM block.", "\n", "", "", "hidden_state", "=", "hidden_state", ".", "detach", "(", ")", "# shape: (batch, num_hidden_channels, [slice,] height, width, depth)", "\n", "input_image", "=", "output_image", ".", "detach", "(", ")", "# shape (batch, complex=2, [slice,] height,  width)", "\n", "\n", "loss_dicts", ".", "append", "(", "detach_dict", "(", "loss_dict", ")", ")", "\n", "regularizer_dicts", ".", "append", "(", "\n", "detach_dict", "(", "regularizer_dict", ")", "\n", ")", "# Need to detach dict as this is only used for logging.", "\n", "\n", "# Add the loss dicts together over RIM steps, divide by the number of steps.", "\n", "", "loss_dict", "=", "reduce_list_of_dicts", "(", "loss_dicts", ",", "mode", "=", "\"sum\"", ",", "divisor", "=", "self", ".", "cfg", ".", "model", ".", "steps", ")", "# type: ignore", "\n", "regularizer_dict", "=", "reduce_list_of_dicts", "(", "\n", "regularizer_dicts", ",", "\n", "mode", "=", "\"sum\"", ",", "\n", "divisor", "=", "self", ".", "cfg", ".", "model", ".", "steps", ",", "# type: ignore", "\n", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "**", "loss_dict", ",", "**", "regularizer_dict", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.cli.predict.register_parser": [[12, 85], ["direct.environment.Args", "parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults"], "function", ["None"], ["from", "direct", ".", "inference", "import", "build_inference_transforms", ",", "setup_inference_save_to_h5", "\n", "from", "direct", ".", "launch", "import", "launch", "\n", "from", "direct", ".", "utils", "import", "set_all_seeds", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "def", "_get_transforms", "(", "env", ")", ":", "\n", "    ", "dataset_cfg", "=", "env", ".", "cfg", ".", "inference", ".", "dataset", "\n", "mask_func", "=", "build_masking_function", "(", "**", "dataset_cfg", ".", "transforms", ".", "masking", ")", "\n", "transforms", "=", "build_inference_transforms", "(", "env", ",", "mask_func", ",", "dataset_cfg", ")", "\n", "return", "dataset_cfg", ",", "transforms", "\n", "\n", "\n", "", "setup_inference_save_to_h5", "=", "functools", ".", "partial", "(", "\n", "setup_inference_save_to_h5", ",", "\n", "functools", ".", "partial", "(", "_get_transforms", ")", ",", "\n", ")", "\n", "\n", "\n", "def", "predict_from_argparse", "(", "args", ":", "argparse", ".", "Namespace", ")", ":", "\n", "# This sets MKL threads to 1.", "\n", "# DataLoader can otherwise bring a lot of difficulties when computing CPU FFTs in the transforms.", "\n", "    ", "torch", ".", "set_num_threads", "(", "1", ")", "\n", "os", ".", "environ", "[", "\"OMP_NUM_THREADS\"", "]", "=", "\"1\"", "\n", "\n", "set_all_seeds", "(", "args", ".", "seed", ")", "\n", "experiment_directory", "=", "(", "\n", "args", ".", "experiment_directory", "if", "args", ".", "experiment_directory", "is", "not", "None", "else", "args", ".", "output_directory", "\n", ")", "\n", "\n", "launch", "(", "\n", "setup_inference_save_to_h5", ",", "\n", "args", ".", "num_machines", ",", "\n", "args", ".", "num_gpus", ",", "\n", "args", ".", "machine_rank", ",", "\n", "args", ".", "dist_url", ",", "\n", "args", ".", "name", ",", "\n", "args", ".", "data_root", ",", "\n", "experiment_directory", ",", "\n", "args", ".", "output_directory", ",", "\n", "args", ".", "filenames_filter", ",", "\n", "args", ".", "checkpoint", ",", "\n", "args", ".", "device", ",", "\n", "args", ".", "num_workers", ",", "\n", "args", ".", "machine_rank", ",", "\n", "args", ".", "cfg_file", ",", "\n", "None", ",", "\n", "args", ".", "mixed_precision", ",", "\n", "args", ".", "debug", ",", "\n", "False", ",", "\n", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.cli.train.register_parser": [[11, 70], ["direct.environment.Args", "parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults"], "function", ["None"], ["from", "typing", "import", "Callable", ",", "Dict", ",", "List", ",", "Optional", ",", "Union", "\n", "\n", "import", "numpy", "as", "np", "\n", "import", "torch", "\n", "from", "omegaconf", "import", "DictConfig", "\n", "\n", "from", "direct", ".", "cli", ".", "utils", "import", "check_train_val", "\n", "from", "direct", ".", "common", ".", "subsample", "import", "build_masking_function", "\n", "from", "direct", ".", "data", ".", "datasets", "import", "build_dataset_from_input", "\n", "from", "direct", ".", "data", ".", "lr_scheduler", "import", "WarmupMultiStepLR", "\n", "from", "direct", ".", "data", ".", "mri_transforms", "import", "build_mri_transforms", "\n", "from", "direct", ".", "environment", "import", "setup_training_environment", "\n", "from", "direct", ".", "launch", "import", "launch", "\n", "from", "direct", ".", "types", "import", "PathOrString", "\n", "from", "direct", ".", "utils", "import", "remove_keys", ",", "set_all_seeds", ",", "str_to_class", "\n", "from", "direct", ".", "utils", ".", "dataset", "import", "get_filenames_for_datasets_from_config", "\n", "from", "direct", ".", "utils", ".", "io", "import", "check_is_valid_url", ",", "read_json", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "def", "parse_noise_dict", "(", "noise_dict", ":", "dict", ",", "percentile", ":", "float", "=", "1.0", ",", "multiplier", ":", "float", "=", "1.0", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Parsing noise dictionary...\"", ")", "\n", "output", ":", "Dict", "=", "defaultdict", "(", "dict", ")", "\n", "for", "filename", "in", "noise_dict", ":", "\n", "        ", "data_per_volume", "=", "noise_dict", "[", "filename", "]", "\n", "for", "slice_no", "in", "data_per_volume", ":", "\n", "            ", "curr_data", "=", "data_per_volume", "[", "slice_no", "]", "\n", "if", "percentile", "!=", "1.0", ":", "\n", "                ", "lower_clip", "=", "np", ".", "percentile", "(", "curr_data", ",", "100", "*", "(", "1", "-", "percentile", ")", ")", "\n", "upper_clip", "=", "np", ".", "percentile", "(", "curr_data", ",", "100", "*", "percentile", ")", "\n", "curr_data", "=", "np", ".", "clip", "(", "curr_data", ",", "lower_clip", ",", "upper_clip", ")", "\n", "\n", "", "output", "[", "filename", "]", "[", "int", "(", "slice_no", ")", "]", "=", "(", "\n", "curr_data", "*", "multiplier", "\n", ")", "**", "2", "# np.asarray(curr_data) * multiplier# (np.clip(curr_data, lower_clip, upper_clip) * multiplier) ** 2", "\n", "\n", "", "", "return", "output", "\n", "\n", "\n", "", "def", "get_root_of_file", "(", "filename", ":", "PathOrString", ")", ":", "\n", "    ", "\"\"\"Get the root directory of the file or URL to file.\n\n    Examples\n    --------\n    >>> get_root_of_file('/mnt/archive/data.txt')\n    >>> /mnt/archive\n    >>> get_root_of_file('https://aiforoncology.nl/people')\n    >>> https://aiforoncology.nl/\n\n    Parameters\n    ----------\n    filename: pathlib.Path or str\n\n    Returns\n    -------\n    pathlib.Path or str\n    \"\"\"", "\n", "if", "check_is_valid_url", "(", "str", "(", "filename", ")", ")", ":", "\n", "        ", "filename", "=", "urllib", ".", "parse", ".", "urljoin", "(", "str", "(", "filename", ")", ",", "\".\"", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.cli.upload.BaseArgs.__init__": [[25, 34], ["argparse.ArgumentParser.__init__", "upload.BaseArgs.add_argument", "upload.BaseArgs.set_defaults"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "epilog", "=", "None", ",", "add_help", "=", "True", ",", "**", "overrides", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            **overrides (dict, optional): Keyword arguments used to override default argument values\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "epilog", "=", "epilog", ",", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "add_help", "=", "add_help", ")", "\n", "\n", "self", ".", "add_argument", "(", "\"--silent\"", ",", "help", "=", "\"Do not show progress\"", ",", "action", "=", "\"store_true\"", ")", "\n", "self", ".", "set_defaults", "(", "**", "overrides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.cli.upload.upload_from_argparse": [[10, 19], ["direct.utils.io.upload_to_s3"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.upload_to_s3"], ["def", "upload_from_argparse", "(", "args", ":", "argparse", ".", "Namespace", ")", ":", "# pragma: no cover", "\n", "    ", "upload_to_s3", "(", "\n", "filename", "=", "args", ".", "data", ",", "\n", "to_filename", "=", "args", ".", "upload_path", ",", "\n", "endpoint_url", "=", "args", ".", "aws_endpoint_url", ",", "\n", "aws_access_key_id", "=", "args", ".", "aws_access_key_id", ",", "\n", "aws_secret_access_key", "=", "args", ".", "aws_secret_access_key", ",", "\n", "bucket", "=", "args", ".", "aws_bucket_name", ",", "\n", "verbose", "=", "not", "args", ".", "silent", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.cli.upload.register_parser": [[36, 85], ["upload.BaseArgs", "parser.add_parser", "os.environ.get", "os.environ.get", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults"], "function", ["None"], ["", "", "def", "register_parser", "(", "parser", ":", "argparse", ".", "_SubParsersAction", ")", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Register upload commands to a root parser.\"\"\"", "\n", "\n", "epilog", "=", "\"\"\"\n        \"\"\"", "\n", "common_parser", "=", "BaseArgs", "(", "add_help", "=", "False", ")", "\n", "upload_parser", "=", "parser", ".", "add_parser", "(", "\n", "\"upload-to-bucket\"", ",", "\n", "help", "=", "\"Upload data to S3 bucket.\"", ",", "\n", "parents", "=", "[", "common_parser", "]", ",", "\n", "epilog", "=", "epilog", ",", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", ")", "\n", "\n", "aws_access_key_id", "=", "os", ".", "environ", ".", "get", "(", "\"DIRECT_AWS_ACCESS_KEY_ID\"", ",", "\"direct\"", ")", "\n", "aws_secret_access_key", "=", "os", ".", "environ", ".", "get", "(", "\"DIRECT_AWS_SECRET_ACCESS_KEY\"", ",", "None", ")", "\n", "upload_parser", ".", "add_argument", "(", "\n", "\"--aws_endpoint_url\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"S3 endpoint url.\"", ",", "\n", "default", "=", "\"https://s3.aiforoncology.nl\"", ",", "\n", ")", "\n", "upload_parser", ".", "add_argument", "(", "\"data\"", ",", "type", "=", "is_file", ",", "help", "=", "\"File to upload.\"", ")", "\n", "upload_parser", ".", "add_argument", "(", "\"upload_path\"", ",", "type", "=", "str", ",", "help", "=", "\"Path where to upload.\"", ")", "\n", "\n", "upload_parser", ".", "add_argument", "(", "\n", "\"--aws-access-key-id\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"S3 access key id, (default='direct'). \"", "\n", "\"Can also be set with environmental variable DIRECT_AWS_ACCESS_KEY_ID\"", ",", "\n", "default", "=", "aws_access_key_id", ",", "\n", "required", "=", "aws_access_key_id", "is", "None", ",", "\n", ")", "\n", "upload_parser", ".", "add_argument", "(", "\n", "\"--aws-secret-access-key\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "aws_secret_access_key", ",", "\n", "help", "=", "\"S3 secret access key. Can also be set with environmental variable DIRECT_AWS_SECRET_ACCESS_KEY\"", ",", "\n", "required", "=", "aws_secret_access_key", "is", "None", ",", "\n", ")", "\n", "\n", "upload_parser", ".", "add_argument", "(", "\n", "\"--aws-bucket-name\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"direct-project\"", ",", "\n", "help", "=", "\"S3 bucket name\"", ",", "\n", ")", "\n", "\n", "upload_parser", ".", "set_defaults", "(", "subcommand", "=", "upload_from_argparse", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.cli.__init__.main": [[11, 34], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_subparsers", "register_train_subcommand", "register_predict_subcommand", "register_upload_subcommand", "argparse.ArgumentParser.parse_args", "root_parser.parse_args.subcommand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tools.parse_metrics_log.parse_args"], []], "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.is_file": [[12, 17], ["pathlib.Path", "pathlib.Path.is_file", "argparse.ArgumentTypeError"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.cli.utils.is_file"], ["def", "is_file", "(", "path", ")", ":", "\n", "    ", "path", "=", "pathlib", ".", "Path", "(", "path", ")", "\n", "if", "path", ".", "is_file", "(", ")", ":", "\n", "        ", "return", "path", "\n", "", "raise", "argparse", ".", "ArgumentTypeError", "(", "f\"{path} is not a valid file or url.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.file_or_url": [[19, 26], ["direct.utils.io.check_is_valid_url", "pathlib.Path", "pathlib.Path.is_file", "argparse.ArgumentTypeError", "direct.types.FileOrUrl", "direct.types.FileOrUrl"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url", "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.is_file"], ["", "def", "file_or_url", "(", "path", ":", "PathOrString", ")", "->", "FileOrUrl", ":", "\n", "    ", "if", "check_is_valid_url", "(", "path", ")", ":", "\n", "        ", "return", "FileOrUrl", "(", "path", ")", "\n", "", "path", "=", "pathlib", ".", "Path", "(", "path", ")", "\n", "if", "path", ".", "is_file", "(", ")", ":", "\n", "        ", "return", "FileOrUrl", "(", "path", ")", "\n", "", "raise", "argparse", ".", "ArgumentTypeError", "(", "f\"{path} is not a valid file or url.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.check_train_val": [[28, 31], ["sys.exit", "len"], "function", ["None"], ["", "def", "check_train_val", "(", "key", ",", "name", ")", ":", "\n", "    ", "if", "key", "is", "not", "None", "and", "len", "(", "key", ")", "!=", "2", ":", "\n", "        ", "sys", ".", "exit", "(", "f\"--{name} has to be of the form `train_folder, validation_folder` if a validation folder is set.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy": [[16, 20], ["isinstance", "tensor.cpu().numpy", "tensor.cpu"], "function", ["None"], ["def", "_to_numpy", "(", "tensor", ")", ":", "\n", "    ", "if", "isinstance", "(", "tensor", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "tensor", "\n", "", "return", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.fastmri_ssim": [[22, 35], ["structural_similarity", "torch.from_numpy().float", "challenges._to_numpy", "challenges._to_numpy", "gt.transpose", "target.transpose", "gt.max", "torch.from_numpy", "numpy.array"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy", "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy"], ["", "def", "fastmri_ssim", "(", "gt", ",", "target", ")", ":", "\n", "    ", "\"\"\"Compute Structural Similarity Index Measure (SSIM) compatible with the FastMRI challenge.\"\"\"", "\n", "from", "skimage", ".", "metrics", "import", "structural_similarity", "\n", "\n", "gt", "=", "_to_numpy", "(", "gt", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "target", "=", "_to_numpy", "(", "target", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "out", "=", "structural_similarity", "(", "\n", "gt", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ",", "\n", "target", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ",", "\n", "channel_axis", "=", "-", "1", ",", "\n", "data_range", "=", "gt", ".", "max", "(", ")", ",", "\n", ")", "\n", "return", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "out", ")", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.fastmri_psnr": [[37, 45], ["psnr", "torch.from_numpy().float", "challenges._to_numpy", "challenges._to_numpy", "gt.max", "torch.from_numpy", "numpy.array"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy", "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy"], ["", "def", "fastmri_psnr", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\"Compute Peak Signal to Noise Ratio metric (PSNR) compatible with the FastMRI challenge.\"\"\"", "\n", "gt", "=", "_to_numpy", "(", "gt", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "pred", "=", "_to_numpy", "(", "pred", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "from", "skimage", ".", "metrics", "import", "peak_signal_noise_ratio", "as", "psnr", "\n", "\n", "out", "=", "psnr", "(", "image_true", "=", "gt", ",", "image_test", "=", "pred", ",", "data_range", "=", "gt", ".", "max", "(", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "out", ")", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.fastmri_nmse": [[47, 53], ["torch.from_numpy().float", "challenges._to_numpy", "challenges._to_numpy", "numpy.linalg.norm", "numpy.linalg.norm", "torch.from_numpy", "numpy.array"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy", "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy", "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.norm", "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.norm"], ["", "def", "fastmri_nmse", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\"Compute Normalized Mean Square Error metric (NMSE) compatible with the FastMRI challenge.\"\"\"", "\n", "gt", "=", "_to_numpy", "(", "gt", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "pred", "=", "_to_numpy", "(", "pred", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "out", "=", "np", ".", "linalg", ".", "norm", "(", "gt", "-", "pred", ")", "**", "2", "/", "np", ".", "linalg", ".", "norm", "(", "gt", ")", "**", "2", "\n", "return", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "out", ")", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._calgary_campinas_metric": [[55, 70], ["gt.max", "range", "torch.from_numpy().mean", "challenges._to_numpy", "challenges._to_numpy", "output.append", "numpy.maximum", "numpy.minimum", "metric_func", "torch.from_numpy", "gt[].max", "pred[].max", "gt[].min", "pred[].min", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy", "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._to_numpy"], ["", "def", "_calgary_campinas_metric", "(", "gt", ",", "pred", ",", "metric_func", ")", ":", "\n", "    ", "\"\"\"General placeholder for the Calgary-Campinas challenge metrics.\"\"\"", "\n", "# https://github.com/rmsouza01/MC-MRRec-challenge/blob/master/JNotebooks/evaluation-system/extract_challenge_metrics_pre_submisison.ipynb", "\n", "gt", "=", "_to_numpy", "(", "gt", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "pred", "=", "_to_numpy", "(", "pred", ")", "[", ":", ",", "0", ",", "...", "]", "\n", "gt_max", "=", "gt", ".", "max", "(", "axis", "=", "(", "1", ",", "2", ")", ",", "keepdims", "=", "True", ")", "\n", "gt", "=", "gt", "/", "gt_max", "\n", "pred", "=", "pred", "/", "gt_max", "\n", "\n", "output", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "gt", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "data_range", "=", "np", ".", "maximum", "(", "gt", "[", "idx", "]", ".", "max", "(", ")", ",", "pred", "[", "idx", "]", ".", "max", "(", ")", ")", "-", "np", ".", "minimum", "(", "gt", "[", "idx", "]", ".", "min", "(", ")", ",", "pred", "[", "idx", "]", ".", "min", "(", ")", ")", "\n", "output", ".", "append", "(", "metric_func", "(", "gt", "[", "idx", "]", ",", "pred", "[", "idx", "]", ",", "data_range", "=", "data_range", ")", ")", "\n", "\n", "", "return", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "output", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_ssim": [[72, 76], ["challenges._calgary_campinas_metric"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._calgary_campinas_metric"], ["", "def", "calgary_campinas_ssim", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "from", "skimage", ".", "metrics", "import", "structural_similarity", "\n", "\n", "return", "_calgary_campinas_metric", "(", "gt", ",", "pred", ",", "structural_similarity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_psnr": [[78, 82], ["challenges._calgary_campinas_metric"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._calgary_campinas_metric"], ["", "def", "calgary_campinas_psnr", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "from", "skimage", ".", "metrics", "import", "peak_signal_noise_ratio", "\n", "\n", "return", "_calgary_campinas_metric", "(", "gt", ",", "pred", ",", "peak_signal_noise_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_vif": [[84, 100], ["challenges._calgary_campinas_metric", "_module_available", "RuntimeError", "vifp"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges._calgary_campinas_metric", "home.repos.pwc.inspect_result.directgroup_direct.utils.imports._module_available"], ["", "def", "calgary_campinas_vif", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "def", "vif_func", "(", "gt", ",", "target", ",", "data_range", ")", ":", "# noqa", "\n", "        ", "from", "direct", ".", "utils", ".", "imports", "import", "_module_available", "\n", "\n", "# Calgary Campinas VIF metric requires 'sewar' module. Check if it exists", "\n", "if", "not", "_module_available", "(", "\"sewar\"", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"'sewar' module required for calgary_campinas_vif metric, but not found. \"", "\n", "\"Please use 'pip3 install sewar' and run again.\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "from", "sewar", ".", "full_ref", "import", "vifp", "\n", "\n", "return", "vifp", "(", "gt", ",", "target", ",", "sigma_nsq", "=", "0.4", ")", "\n", "\n", "", "", "return", "_calgary_campinas_metric", "(", "gt", ",", "pred", ",", "vif_func", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.ssim.SSIMLoss.__init__": [[23, 40], ["torch.Module.__init__", "ssim.SSIMLoss.register_buffer", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "win_size", "=", "7", ",", "k1", "=", "0.01", ",", "k2", "=", "0.03", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        win_size: int\n            Window size for SSIM calculation. Default: 7.\n        k1: float\n            k1 parameter for SSIM calculation. Default: 0.1.\n        k2: float\n            k2 parameter for SSIM calculation. Default: 0.03.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "win_size", "=", "win_size", "\n", "self", ".", "k1", ",", "self", ".", "k2", "=", "k1", ",", "k2", "\n", "self", ".", "register_buffer", "(", "\"w\"", ",", "torch", ".", "ones", "(", "1", ",", "1", ",", "win_size", ",", "win_size", ")", "/", "win_size", "**", "2", ")", "\n", "NP", "=", "win_size", "**", "2", "\n", "self", ".", "cov_norm", "=", "NP", "/", "(", "NP", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.ssim.SSIMLoss.forward": [[41, 63], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "S.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ",", "Y", ",", "data_range", ")", ":", "\n", "        ", "data_range", "=", "data_range", "[", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "C1", "=", "(", "self", ".", "k1", "*", "data_range", ")", "**", "2", "\n", "C2", "=", "(", "self", ".", "k2", "*", "data_range", ")", "**", "2", "\n", "ux", "=", "F", ".", "conv2d", "(", "X", ",", "self", ".", "w", ")", "\n", "uy", "=", "F", ".", "conv2d", "(", "Y", ",", "self", ".", "w", ")", "\n", "uxx", "=", "F", ".", "conv2d", "(", "X", "*", "X", ",", "self", ".", "w", ")", "\n", "uyy", "=", "F", ".", "conv2d", "(", "Y", "*", "Y", ",", "self", ".", "w", ")", "\n", "uxy", "=", "F", ".", "conv2d", "(", "X", "*", "Y", ",", "self", ".", "w", ")", "\n", "vx", "=", "self", ".", "cov_norm", "*", "(", "uxx", "-", "ux", "*", "ux", ")", "\n", "vy", "=", "self", ".", "cov_norm", "*", "(", "uyy", "-", "uy", "*", "uy", ")", "\n", "vxy", "=", "self", ".", "cov_norm", "*", "(", "uxy", "-", "ux", "*", "uy", ")", "\n", "A1", ",", "A2", ",", "B1", ",", "B2", "=", "(", "\n", "2", "*", "ux", "*", "uy", "+", "C1", ",", "\n", "2", "*", "vxy", "+", "C2", ",", "\n", "ux", "**", "2", "+", "uy", "**", "2", "+", "C1", ",", "\n", "vx", "+", "vy", "+", "C2", ",", "\n", ")", "\n", "D", "=", "B1", "*", "B2", "\n", "S", "=", "(", "A1", "*", "A2", ")", "/", "D", "\n", "\n", "return", "1", "-", "S", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.psnr.PSNRLoss.__init__": [[42, 44], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "        ", "self", ".", "reduction", "=", "reduction", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.psnr.PSNRLoss.forward": [[45, 47], ["psnr.batch_psnr"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.psnr.batch_psnr"], ["", "def", "forward", "(", "self", ",", "input_data", ",", "target_data", ")", ":", "\n", "        ", "return", "batch_psnr", "(", "input_data", ",", "target_data", ",", "reduction", "=", "self", ".", "reduction", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.functionals.psnr.batch_psnr": [[9, 37], ["target_data.size", "input_data.view", "target_data.view", "torch.mean", "torch.mean", "ValueError", "torch.max", "torch.max", "psnrs.mean", "psnrs.sum", "torch.log10", "torch.log10", "torch.log10", "torch.log10"], "function", ["None"], ["def", "batch_psnr", "(", "input_data", ",", "target_data", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "    ", "\"\"\"This function is a torch implementation of skimage.metrics.compare_psnr.\n\n    Parameters\n    ----------\n    input_data: torch.Tensor\n    target_data: torch.Tensor\n    reduction: str\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "batch_size", "=", "target_data", ".", "size", "(", "0", ")", "\n", "input_view", "=", "input_data", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "target_view", "=", "target_data", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "maximum_value", "=", "torch", ".", "max", "(", "input_view", ",", "1", ")", "[", "0", "]", "\n", "\n", "mean_square_error", "=", "torch", ".", "mean", "(", "(", "input_view", "-", "target_view", ")", "**", "2", ",", "1", ")", "\n", "psnrs", "=", "20.0", "*", "torch", ".", "log10", "(", "maximum_value", ")", "-", "10.0", "*", "torch", ".", "log10", "(", "mean_square_error", ")", "\n", "\n", "if", "reduction", "==", "\"mean\"", ":", "\n", "        ", "return", "psnrs", ".", "mean", "(", ")", "\n", "", "if", "reduction", "==", "\"sum\"", ":", "\n", "        ", "return", "psnrs", ".", "sum", "(", ")", "\n", "", "if", "reduction", "==", "\"none\"", ":", "\n", "        ", "return", "psnrs", "\n", "", "raise", "ValueError", "(", "f\"Reduction is either `mean`, `sum` or `none`. Got {reduction}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.FFTONNX.symbolic": [[27, 34], ["g.op", "g.op", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "int", "int"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "symbolic", "(", "\n", "g", ",", "data", ",", "dim", ",", "centered", ",", "normalized", ",", "inverse", "=", "False", "\n", ")", ":", "# pylint: disable=too-many-arguments, unused-argument, useless-suppression", "\n", "        ", "\"\"\"ONNX node definition for custom nodes.\"\"\"", "\n", "dim", "=", "g", ".", "op", "(", "\"Constant\"", ",", "value_t", "=", "torch", ".", "tensor", "(", "dim", ")", ")", "\n", "return", "g", ".", "op", "(", "\"IFFT\"", "if", "inverse", "else", "\"FFT\"", ",", "data", ",", "dim", ",", "centered_i", "=", "int", "(", "centered", ")", ",", "inverse_i", "=", "int", "(", "inverse", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.FFTONNX.forward": [[35, 43], ["transforms.origin_ifft2", "transforms.origin_fft2"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_ifft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_fft2"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "data", ",", "dim", ",", "centered", ",", "normalized", ",", "inverse", "=", "False", ")", ":", "# pylint: disable=unused-argument", "\n", "        ", "\"\"\"Fallback to origin custom function.\"\"\"", "\n", "if", "inverse", ":", "\n", "            ", "custom_func", "=", "origin_ifft2", "(", "data", ",", "dim", ",", "centered", ",", "normalized", ")", "\n", "", "else", ":", "\n", "            ", "custom_func", "=", "origin_fft2", "(", "data", ",", "dim", ",", "centered", ",", "normalized", ")", "\n", "", "return", "custom_func", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ComplexMultiplicationONNX.symbolic": [[50, 54], ["g.op"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "symbolic", "(", "g", ",", "input_tensor", ",", "other_tensor", ")", ":", "\n", "        ", "\"\"\"ONNX node definition for custom nodes.\"\"\"", "\n", "return", "g", ".", "op", "(", "\"ComplexMultiplication\"", ",", "input_tensor", ",", "other_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ComplexMultiplicationONNX.forward": [[55, 59], ["transforms.origin_complex_multiplication"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_complex_multiplication"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input_tensor", ",", "other_tensor", ")", ":", "# pylint: disable=unused-argument", "\n", "        ", "\"\"\"Fallback to origin custom function.\"\"\"", "\n", "return", "origin_complex_multiplication", "(", "input_tensor", ",", "other_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor": [[61, 76], ["numpy.iscomplexobj", "torch.from_numpy", "torch.from_numpy", "numpy.stack"], "function", ["None"], ["", "", "def", "to_tensor", "(", "data", ":", "np", ".", "ndarray", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Convert numpy array to PyTorch tensor. Complex arrays will have real and imaginary parts on the last axis.\n\n    Parameters\n    ----------\n    data: np.ndarray\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "if", "np", ".", "iscomplexobj", "(", "data", ")", ":", "\n", "        ", "data", "=", "np", ".", "stack", "(", "(", "data", ".", "real", ",", "data", ".", "imag", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "return", "torch", ".", "from_numpy", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.verify_fft_dtype_possible": [[78, 97], ["all", "direct.utils.is_power_of_two", "data.size"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.is_power_of_two"], ["", "def", "verify_fft_dtype_possible", "(", "data", ":", "torch", ".", "Tensor", ",", "dims", ":", "Tuple", "[", "int", ",", "...", "]", ")", "->", "bool", ":", "\n", "    ", "\"\"\"fft and ifft can only be performed on GPU in float16 if the shapes are powers of 2. This function verifies if\n    this is the case.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    dims: tuple\n\n    Returns\n    -------\n    bool\n    \"\"\"", "\n", "is_complex64", "=", "data", ".", "dtype", "==", "torch", ".", "complex64", "\n", "is_complex32_and_power_of_two", "=", "(", "data", ".", "dtype", "==", "torch", ".", "float32", ")", "and", "all", "(", "\n", "is_power_of_two", "(", "_", ")", "for", "_", "in", "[", "data", ".", "size", "(", "idx", ")", "for", "idx", "in", "dims", "]", "\n", ")", "\n", "\n", "return", "is_complex64", "or", "is_complex32_and_power_of_two", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_complex": [[99, 117], ["torch.view_as_complex", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_complex"], ["", "def", "view_as_complex", "(", "data", ")", ":", "\n", "    ", "\"\"\"Returns a view of input as a complex tensor.\n\n    For an input tensor of size (N, ..., 2) where the last dimension of size 2 represents the real and imaginary\n    components of complex numbers, this function returns a new complex tensor of size (N, ...).\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Input data with torch.dtype torch.float64 and torch.float32 with complex axis (last) of dimension 2\n        and of shape (N, \\*, 2).\n\n    Returns\n    -------\n    complex_valued_data: torch.Tensor\n        Output complex-valued data of shape (N, \\*) with complex torch.dtype.\n    \"\"\"", "\n", "return", "torch", ".", "view_as_complex", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_real": [[119, 137], ["torch.view_as_real", "torch.view_as_real"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_real", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_real"], ["", "def", "view_as_real", "(", "data", ")", ":", "\n", "    ", "\"\"\"Returns a view of data as a real tensor.\n\n    For an input complex tensor of size (N, ...) this function returns a new real tensor of size (N, ..., 2) where the\n    last dimension of size 2 represents the real and imaginary components of complex numbers.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Input data with complex torch.dtype of shape (N, \\*).\n\n    Returns\n    -------\n    real_valued_data: torch.Tensor\n        Output real-valued data of shape (N, \\*, 2).\n    \"\"\"", "\n", "\n", "return", "torch", ".", "view_as_real", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_fft2": [[139, 194], ["direct.utils.asserts.assert_complex", "transforms.view_as_complex", "transforms.verify_fft_dtype_possible", "transforms.view_as_real", "all", "TypeError", "transforms.ifftshift", "torch.fft.fftn", "torch.fft.fftn", "ValueError", "transforms.fftshift", "isinstance"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.verify_fft_dtype_possible", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_real", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift"], ["", "def", "origin_fft2", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "1", ",", "2", ")", ",", "\n", "centered", ":", "bool", "=", "True", ",", "\n", "normalized", ":", "bool", "=", "True", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Apply centered two-dimensional Inverse Fast Fourier Transform. Can be performed in half precision when input\n    shapes are powers of two.\n\n    Version for PyTorch >= 1.7.0.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Complex-valued input tensor. Should be of shape (\\*, 2) and dim is in \\*.\n    dim: tuple, list or int\n        Dimensions over which to compute. Should be positive. Negative indexing not supported\n        Default is (1, 2), corresponding to ('height', 'width').\n    centered: bool\n        Whether to apply a centered fft (center of kspace is in the center versus in the corners).\n        For FastMRI dataset this has to be true and for the Calgary-Campinas dataset false.\n    normalized: bool\n        Whether to normalize the fft. For the FastMRI this has to be true and for the Calgary-Campinas dataset false.\n\n    Returns\n    -------\n    output_data: torch.Tensor\n        The Fast Fourier transform of the data.\n    \"\"\"", "\n", "if", "not", "all", "(", "(", "_", ">=", "0", "and", "isinstance", "(", "_", ",", "int", ")", ")", "for", "_", "in", "dim", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f\"Currently fft2 does not support negative indexing. \"", "\n", "f\"Dim should contain only positive integers. Got {dim}.\"", "\n", ")", "\n", "\n", "", "assert_complex", "(", "data", ",", "complex_last", "=", "True", ")", "\n", "\n", "data", "=", "view_as_complex", "(", "data", ")", "\n", "if", "centered", ":", "\n", "        ", "data", "=", "ifftshift", "(", "data", ",", "dim", "=", "dim", ")", "\n", "# Verify whether half precision and if fft is possible in this shape. Else do a typecast.", "\n", "", "if", "verify_fft_dtype_possible", "(", "data", ",", "dim", ")", ":", "\n", "        ", "data", "=", "torch", ".", "fft", ".", "fftn", "(", "\n", "data", ",", "\n", "dim", "=", "dim", ",", "\n", "norm", "=", "\"ortho\"", "if", "normalized", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Currently half precision FFT is not supported.\"", ")", "\n", "\n", "", "if", "centered", ":", "\n", "        ", "data", "=", "fftshift", "(", "data", ",", "dim", "=", "dim", ")", "\n", "\n", "", "data", "=", "view_as_real", "(", "data", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fft2": [[196, 213], ["transforms.origin_fft2", "FFTONNX.apply"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_fft2"], ["", "def", "fft2", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "1", ",", "2", ")", ",", "\n", "centered", ":", "bool", "=", "True", ",", "\n", "normalized", ":", "bool", "=", "True", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"This is a helper function that calls:\n    1. FFTONNX wrapper methods when torch.no_grad() is used (i.e. export to ONNX)\n    2. origin_fft2 method when running origin model.\n    \"\"\"", "\n", "\n", "if", "data", ".", "requires_grad", ":", "\n", "        ", "fft", "=", "origin_fft2", "(", "data", ",", "dim", ",", "centered", ",", "normalized", ")", "\n", "", "else", ":", "\n", "        ", "fft", "=", "FFTONNX", ".", "apply", "(", "data", ",", "dim", ",", "centered", ",", "normalized", ")", "\n", "\n", "", "return", "fft", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_ifft2": [[215, 269], ["direct.utils.asserts.assert_complex", "transforms.view_as_complex", "transforms.verify_fft_dtype_possible", "transforms.view_as_real", "all", "TypeError", "transforms.ifftshift", "torch.fft.ifftn", "torch.fft.ifftn", "ValueError", "transforms.fftshift", "isinstance"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.verify_fft_dtype_possible", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_real", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift"], ["", "def", "origin_ifft2", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "1", ",", "2", ")", ",", "\n", "centered", ":", "bool", "=", "True", ",", "\n", "normalized", ":", "bool", "=", "True", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Apply centered two-dimensional Inverse Fast Fourier Transform. Can be performed in half precision when input\n    shapes are powers of two.\n\n    Version for PyTorch >= 1.7.0.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Complex-valued input tensor. Should be of shape (\\*, 2) and dim is in \\*.\n    dim: tuple, list or int\n        Dimensions over which to compute. Should be positive. Negative indexing not supported\n        Default is (1, 2), corresponding to ( 'height', 'width').\n    centered: bool\n        Whether to apply a centered ifft (center of kspace is in the center versus in the corners).\n        For FastMRI dataset this has to be true and for the Calgary-Campinas dataset false.\n    normalized: bool\n        Whether to normalize the ifft. For the FastMRI this has to be true and for the Calgary-Campinas dataset false.\n\n    Returns\n    -------\n    output_data: torch.Tensor\n        The Inverse Fast Fourier transform of the data.\n    \"\"\"", "\n", "if", "not", "all", "(", "(", "_", ">=", "0", "and", "isinstance", "(", "_", ",", "int", ")", ")", "for", "_", "in", "dim", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f\"Currently ifft2 does not support negative indexing. \"", "\n", "f\"Dim should contain only positive integers. Got {dim}.\"", "\n", ")", "\n", "", "assert_complex", "(", "data", ",", "complex_last", "=", "True", ")", "\n", "\n", "data", "=", "view_as_complex", "(", "data", ")", "\n", "if", "centered", ":", "\n", "        ", "data", "=", "ifftshift", "(", "data", ",", "dim", "=", "dim", ")", "\n", "# Verify whether half precision and if fft is possible in this shape. Else do a typecast.", "\n", "", "if", "verify_fft_dtype_possible", "(", "data", ",", "dim", ")", ":", "\n", "        ", "data", "=", "torch", ".", "fft", ".", "ifftn", "(", "\n", "data", ",", "\n", "dim", "=", "dim", ",", "\n", "norm", "=", "\"ortho\"", "if", "normalized", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Currently half precision FFT is not supported.\"", ")", "\n", "\n", "", "if", "centered", ":", "\n", "        ", "data", "=", "fftshift", "(", "data", ",", "dim", "=", "dim", ")", "\n", "\n", "", "data", "=", "view_as_real", "(", "data", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifft2": [[271, 288], ["transforms.origin_ifft2", "FFTONNX.apply"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_ifft2"], ["", "def", "ifft2", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "Tuple", "[", "int", ",", "...", "]", "=", "(", "1", ",", "2", ")", ",", "\n", "centered", ":", "bool", "=", "True", ",", "\n", "normalized", ":", "bool", "=", "True", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"This is a helper function that calls:\n    1. FFTONNX wrapper methods when torch.no_grad() is used (i.e. export to ONNX)\n    2. origin_ifft2 method when running origin model.\n    \"\"\"", "\n", "\n", "if", "data", ".", "requires_grad", ":", "\n", "        ", "ifft", "=", "origin_ifft2", "(", "data", ",", "dim", ",", "centered", ",", "normalized", ")", "\n", "", "else", ":", "\n", "        ", "ifft", "=", "FFTONNX", ".", "apply", "(", "data", ",", "dim", ",", "centered", ",", "normalized", ",", "True", ")", "\n", "\n", "", "return", "ifft", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.safe_divide": [[290, 309], ["torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "safe_divide", "(", "input_tensor", ":", "torch", ".", "Tensor", ",", "other_tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Divide input_tensor and other_tensor safely, set the output to zero where the divisor b is zero.\n\n    Parameters\n    ----------\n    input_tensor: torch.Tensor\n    other_tensor: torch.Tensor\n\n    Returns\n    -------\n    torch.Tensor: the division.\n    \"\"\"", "\n", "\n", "data", "=", "torch", ".", "where", "(", "\n", "other_tensor", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "input_tensor", ".", "dtype", ")", ".", "to", "(", "input_tensor", ".", "device", ")", ",", "\n", "input_tensor", "/", "other_tensor", ",", "\n", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus": [[311, 328], ["direct.utils.asserts.assert_complex"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex"], ["", "def", "modulus", "(", "data", ":", "torch", ".", "Tensor", ",", "complex_axis", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Compute modulus of complex input data. Assumes there is a complex axis (of dimension 2) in the data.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    complex_axis: int\n        Complex dimension along which the modulus will be calculated. Default: -1.\n\n    Returns\n    -------\n    output_data: torch.Tensor\n        Modulus of data.\n    \"\"\"", "\n", "assert_complex", "(", "data", ",", "complex_axis", "=", "complex_axis", ")", "\n", "\n", "return", "(", "data", "**", "2", ")", ".", "sum", "(", "complex_axis", ")", ".", "sqrt", "(", ")", "# noqa", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus_if_complex": [[330, 346], ["direct.utils.is_complex_data", "transforms.modulus"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.is_complex_data", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus"], ["", "def", "modulus_if_complex", "(", "data", ":", "torch", ".", "Tensor", ",", "complex_axis", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Compute modulus if complex tensor (has complex axis).\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    complex_axis: int\n        Complex dimension along which the modulus will be calculated if that dimension is complex. Default: -1.\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "if", "is_complex_data", "(", "data", ",", "complex_axis", "=", "complex_axis", ")", ":", "\n", "        ", "return", "modulus", "(", "data", "=", "data", ",", "complex_axis", "=", "complex_axis", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll_one_dim": [[348, 369], ["data.narrow", "data.narrow", "torch.cat", "torch.cat", "data.size", "data.size", "data.size"], "function", ["None"], ["", "def", "roll_one_dim", "(", "data", ":", "torch", ".", "Tensor", ",", "shift", ":", "int", ",", "dim", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Similar to roll but only for one dim\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    shift: tuple, int\n    dim: int\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "shift", "=", "shift", "%", "data", ".", "size", "(", "dim", ")", "\n", "if", "shift", "==", "0", ":", "\n", "        ", "return", "data", "\n", "\n", "", "left", "=", "data", ".", "narrow", "(", "dim", ",", "0", ",", "data", ".", "size", "(", "dim", ")", "-", "shift", ")", "\n", "right", "=", "data", ".", "narrow", "(", "dim", ",", "data", ".", "size", "(", "dim", ")", "-", "shift", ",", "shift", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "right", ",", "left", ")", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll": [[371, 396], ["zip", "len", "len", "ValueError", "transforms.roll_one_dim"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll_one_dim"], ["", "def", "roll", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "shift", ":", "List", "[", "int", "]", ",", "\n", "dim", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Similar to numpy roll but applies to pytorch tensors.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    shift: tuple, int\n    dim: List or tuple of ints\n\n    Returns\n    -------\n    torch.Tensor\n        Rolled version of data\n    \"\"\"", "\n", "if", "len", "(", "shift", ")", "!=", "len", "(", "dim", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"len(shift) must match len(dim)\"", ")", "\n", "\n", "", "for", "(", "s", ",", "d", ")", "in", "zip", "(", "shift", ",", "dim", ")", ":", "\n", "        ", "data", "=", "roll_one_dim", "(", "data", ",", "s", ",", "d", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift": [[398, 424], ["enumerate", "transforms.roll", "range", "len", "data.dim", "data.dim"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll"], ["", "def", "fftshift", "(", "data", ":", "torch", ".", "Tensor", ",", "dim", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", ",", "None", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Similar to numpy fftshift but applies to pytorch tensors.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Input data.\n    dim: List or tuple of ints or None\n        Default: None.\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "if", "dim", "is", "None", ":", "\n", "# this weird code is necessary for torch.jit.script typing", "\n", "        ", "dim", "=", "[", "0", "]", "*", "(", "data", ".", "dim", "(", ")", ")", "\n", "for", "idx", "in", "range", "(", "1", ",", "data", ".", "dim", "(", ")", ")", ":", "\n", "            ", "dim", "[", "idx", "]", "=", "idx", "\n", "\n", "# also necessary for torch.jit.script", "\n", "", "", "shift", "=", "[", "0", "]", "*", "len", "(", "dim", ")", "\n", "for", "idx", ",", "dim_num", "in", "enumerate", "(", "dim", ")", ":", "\n", "        ", "shift", "[", "idx", "]", "=", "data", ".", "shape", "[", "dim_num", "]", "//", "2", "\n", "\n", "", "return", "roll", "(", "data", ",", "shift", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift": [[426, 452], ["enumerate", "transforms.roll", "range", "len", "data.dim", "data.dim"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll"], ["", "def", "ifftshift", "(", "data", ":", "torch", ".", "Tensor", ",", "dim", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", ",", "None", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Similar to numpy ifftshift but applies to pytorch tensors.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Input data.\n    dim: List or tuple of ints or None\n        Default: None.\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "if", "dim", "is", "None", ":", "\n", "# this weird code is necessary for torch.jit.script typing", "\n", "        ", "dim", "=", "[", "0", "]", "*", "(", "data", ".", "dim", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "data", ".", "dim", "(", ")", ")", ":", "\n", "            ", "dim", "[", "i", "]", "=", "i", "\n", "\n", "# also necessary for torch.jit.script", "\n", "", "", "shift", "=", "[", "0", "]", "*", "len", "(", "dim", ")", "\n", "for", "i", ",", "dim_num", "in", "enumerate", "(", "dim", ")", ":", "\n", "        ", "shift", "[", "i", "]", "=", "(", "data", ".", "shape", "[", "dim_num", "]", "+", "1", ")", "//", "2", "\n", "\n", "", "return", "roll", "(", "data", ",", "shift", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication": [[454, 461], ["transforms.origin_complex_multiplication", "ComplexMultiplicationONNX.apply"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_complex_multiplication"], ["", "def", "complex_multiplication", "(", "input_tensor", ":", "torch", ".", "Tensor", ",", "other_tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "input_tensor", ".", "requires_grad", ":", "\n", "        ", "complex_mul", "=", "origin_complex_multiplication", "(", "input_tensor", ",", "other_tensor", ")", "\n", "", "else", ":", "\n", "        ", "complex_mul", "=", "ComplexMultiplicationONNX", ".", "apply", "(", "input_tensor", ",", "other_tensor", ")", "\n", "\n", "", "return", "complex_mul", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.origin_complex_multiplication": [[463, 494], ["direct.utils.asserts.assert_complex", "direct.utils.asserts.assert_complex", "torch.cat", "torch.cat", "real_part.unsqueeze", "imaginary_part.unsqueeze"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex"], ["", "def", "origin_complex_multiplication", "(", "input_tensor", ":", "torch", ".", "Tensor", ",", "other_tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Multiplies two complex-valued tensors. Assumes input tensors are complex (last axis has dimension 2).\n\n    Parameters\n    ----------\n    input_tensor: torch.Tensor\n        Input data\n    other_tensor: torch.Tensor\n        Input data\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "assert_complex", "(", "input_tensor", ",", "complex_last", "=", "True", ")", "\n", "assert_complex", "(", "other_tensor", ",", "complex_last", "=", "True", ")", "\n", "\n", "complex_index", "=", "-", "1", "\n", "\n", "real_part", "=", "input_tensor", "[", "...", ",", "0", "]", "*", "other_tensor", "[", "...", ",", "0", "]", "-", "input_tensor", "[", "...", ",", "1", "]", "*", "other_tensor", "[", "...", ",", "1", "]", "\n", "imaginary_part", "=", "input_tensor", "[", "...", ",", "0", "]", "*", "other_tensor", "[", "...", ",", "1", "]", "+", "input_tensor", "[", "...", ",", "1", "]", "*", "other_tensor", "[", "...", ",", "0", "]", "\n", "\n", "multiplication", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "real_part", ".", "unsqueeze", "(", "dim", "=", "complex_index", ")", ",", "\n", "imaginary_part", ".", "unsqueeze", "(", "dim", "=", "complex_index", ")", ",", "\n", "]", ",", "\n", "dim", "=", "complex_index", ",", "\n", ")", "\n", "\n", "return", "multiplication", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms._complex_matrix_multiplication": [[496, 522], ["ValueError", "input_tensor.is_complex", "other_tensor.is_complex", "torch.mm", "torch.mm", "torch.bmm", "torch.bmm"], "function", ["None"], ["", "def", "_complex_matrix_multiplication", "(", "\n", "input_tensor", ":", "torch", ".", "Tensor", ",", "other_tensor", ":", "torch", ".", "Tensor", ",", "mult_func", ":", "Callable", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Perform a matrix multiplication, helper function for complex_bmm and complex_mm.\n\n    Parameters\n    ----------\n    input_tensor: torch.Tensor\n    other_tensor: torch.Tensor\n    mult_func: Callable\n        Multiplication function e.g. torch.bmm or torch.mm\n\n    Returns\n    -------\n    torch.Tensor\n    \"\"\"", "\n", "if", "not", "input_tensor", ".", "is_complex", "(", ")", "or", "not", "other_tensor", ".", "is_complex", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both input_tensor and other_tensor have to be complex-valued torch tensors.\"", ")", "\n", "\n", "", "output", "=", "(", "\n", "mult_func", "(", "input_tensor", ".", "real", ",", "other_tensor", ".", "real", ")", "\n", "-", "mult_func", "(", "input_tensor", ".", "imag", ",", "other_tensor", ".", "imag", ")", "\n", "+", "1j", "*", "mult_func", "(", "input_tensor", ".", "real", ",", "other_tensor", ".", "imag", ")", "\n", "+", "1j", "*", "mult_func", "(", "input_tensor", ".", "imag", ",", "other_tensor", ".", "real", ")", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_mm": [[524, 541], ["transforms._complex_matrix_multiplication"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms._complex_matrix_multiplication"], ["", "def", "complex_mm", "(", "input_tensor", ":", "torch", ".", "Tensor", ",", "other_tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Performs a matrix multiplication of the 2D complex matrices input_tensor and other_tensor. If input_tensor is a\n    (n\u00d7m) tensor, other_tensor is a (m\u00d7p) tensor, out will be a (n\u00d7p) tensor.\n\n    Parameters\n    ----------\n    input_tensor: torch.Tensor\n        Input 2D tensor.\n    other_tensor: torch.Tensor\n        Other 2D tensor.\n\n    Returns\n    -------\n    out: torch.Tensor\n        Complex-multiplied 2D output tensor.\n    \"\"\"", "\n", "return", "_complex_matrix_multiplication", "(", "input_tensor", ",", "other_tensor", ",", "torch", ".", "mm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_bmm": [[543, 559], ["transforms._complex_matrix_multiplication"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms._complex_matrix_multiplication"], ["", "def", "complex_bmm", "(", "input_tensor", ":", "torch", ".", "Tensor", ",", "other_tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Complex batch multiplication.\n\n    Parameters\n    ----------\n    input_tensor: torch.Tensor\n        Input tensor.\n    other_tensor: torch.Tensor\n        Other tensor.\n\n    Returns\n    -------\n    out: torch.Tensor\n        Batch complex-multiplied output tensor.\n    \"\"\"", "\n", "return", "_complex_matrix_multiplication", "(", "input_tensor", ",", "other_tensor", ",", "torch", ".", "bmm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate": [[561, 578], ["direct.utils.asserts.assert_complex", "data.clone.clone"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex"], ["", "def", "conjugate", "(", "data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Compute the complex conjugate of a torch tensor where the last axis denotes the real and complex part (last axis\n    has dimension 2).\n\n    Parameters\n    ----------\n    data: torch.Tensor\n\n    Returns\n    -------\n    conjugate_tensor: torch.Tensor\n    \"\"\"", "\n", "assert_complex", "(", "data", ",", "complex_last", "=", "True", ")", "\n", "data", "=", "data", ".", "clone", "(", ")", "# Clone is required as the data in the next line is changed in-place.", "\n", "data", "[", "...", ",", "1", "]", "=", "data", "[", "...", ",", "1", "]", "*", "-", "1.0", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.apply_mask": [[580, 620], ["direct.utils.asserts.assert_complex", "torch.where", "torch.where", "isinstance", "mask_func", "torch.tensor", "torch.tensor", "numpy.array"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.DictionaryMaskFunc.mask_func"], ["", "def", "apply_mask", "(", "\n", "kspace", ":", "torch", ".", "Tensor", ",", "\n", "mask_func", ":", "Union", "[", "Callable", ",", "torch", ".", "Tensor", "]", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "return_mask", ":", "bool", "=", "True", ",", "\n", ")", "->", "Union", "[", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Subsample kspace by setting kspace to zero as given by a binary mask.\n\n    Parameters\n    ----------\n    kspace: torch.Tensor\n        k-space as a complex-valued tensor.\n    mask_func: callable or torch.tensor\n        Masking function, taking a shape and returning a mask with this shape or can be broadcast as such\n        Can also be a sampling mask.\n    seed: int\n        Seed for the random number generator\n    return_mask: bool\n        If true, mask will be returned\n\n    Returns\n    -------\n    masked data, mask: (torch.Tensor, torch.Tensor)\n    \"\"\"", "\n", "# TODO: Split the function to apply_mask_func and apply_mask", "\n", "\n", "assert_complex", "(", "kspace", ",", "complex_last", "=", "True", ")", "\n", "\n", "if", "not", "isinstance", "(", "mask_func", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "shape", "=", "np", ".", "array", "(", "kspace", ".", "shape", ")", "[", "1", ":", "]", "# The first dimension is always the coil dimension.", "\n", "mask", "=", "mask_func", "(", "shape", "=", "shape", ",", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "        ", "mask", "=", "mask_func", "\n", "\n", "", "masked_kspace", "=", "torch", ".", "where", "(", "mask", "==", "0", ",", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "kspace", ".", "dtype", ")", ",", "kspace", ")", "\n", "\n", "if", "not", "return_mask", ":", "\n", "        ", "return", "masked_kspace", "\n", "\n", "", "return", "masked_kspace", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy": [[622, 639], ["direct.utils.asserts.assert_complex", "data.detach().cpu().numpy", "data.detach().cpu", "data.detach"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex"], ["", "def", "tensor_to_complex_numpy", "(", "data", ":", "torch", ".", "Tensor", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"Converts a complex pytorch tensor to a complex numpy array. The last axis denote the real and imaginary parts\n    respectively.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Input data\n\n    Returns\n    -------\n    out: np.array\n        Complex valued np.ndarray\n    \"\"\"", "\n", "assert_complex", "(", "data", ",", "complex_last", "=", "True", ")", "\n", "data_numpy", "=", "data", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "data_numpy", "[", "...", ",", "0", "]", "+", "1j", "*", "data_numpy", "[", "...", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.root_sum_of_squares": [[641, 665], ["direct.utils.is_complex_data", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.is_complex_data"], ["", "def", "root_sum_of_squares", "(", "data", ":", "torch", ".", "Tensor", ",", "dim", ":", "int", "=", "0", ",", "complex_dim", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "r\"\"\"Compute the root sum of squares (RSS) transform along a given dimension of the input tensor:\n\n    .. math::\n        x_{\\textrm{RSS}} = \\sqrt{\\sum_{i \\in \\textrm{coil}} |x_i|^2}\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Input tensor\n    dim: int\n        Coil dimension. Default is 0 as the first dimension is always the coil dimension.\n    complex_dim: int\n        Complex channel dimension. Default is -1. If data not complex this is ignored.\n\n    Returns\n    -------\n    torch.Tensor: RSS of the input tensor.\n\n    \"\"\"", "\n", "if", "is_complex_data", "(", "data", ")", ":", "\n", "        ", "return", "torch", ".", "sqrt", "(", "(", "data", "**", "2", ")", ".", "sum", "(", "complex_dim", ")", ".", "sum", "(", "dim", ")", ")", "\n", "\n", "", "return", "torch", ".", "sqrt", "(", "(", "data", "**", "2", ")", ".", "sum", "(", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.center_crop": [[667, 690], ["ValueError"], "function", ["None"], ["", "def", "center_crop", "(", "data", ":", "torch", ".", "Tensor", ",", "shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Apply a center crop along the last two dimensions.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n    shape: List or tuple of ints\n        The output shape, should be smaller than the corresponding data dimensions.\n\n    Returns\n    -------\n    torch.Tensor: The center cropped data.\n    \"\"\"", "\n", "# TODO: Make dimension independent.", "\n", "if", "not", "(", "0", "<", "shape", "[", "0", "]", "<=", "data", ".", "shape", "[", "-", "2", "]", ")", "or", "not", "(", "0", "<", "shape", "[", "1", "]", "<=", "data", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Crop shape should be smaller than data. Requested {shape}, got {data.shape}.\"", ")", "\n", "\n", "", "width_lower", "=", "(", "data", ".", "shape", "[", "-", "2", "]", "-", "shape", "[", "0", "]", ")", "//", "2", "\n", "width_upper", "=", "width_lower", "+", "shape", "[", "0", "]", "\n", "height_lower", "=", "(", "data", ".", "shape", "[", "-", "1", "]", "-", "shape", "[", "1", "]", ")", "//", "2", "\n", "height_upper", "=", "height_lower", "+", "shape", "[", "1", "]", "\n", "\n", "return", "data", "[", "...", ",", "width_lower", ":", "width_upper", ",", "height_lower", ":", "height_upper", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_center_crop": [[692, 746], ["direct.utils.ensure_list", "direct.utils.asserts.assert_same_shape", "list", "enumerate", "all", "ValueError", "direct.data.bbox.crop_to_bbox", "len", "enumerate", "_.contiguous", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.ensure_list", "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_same_shape", "home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_bbox"], ["", "def", "complex_center_crop", "(", "\n", "data_list", ":", "Union", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ",", "\n", "crop_shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", ",", "\n", "offset", ":", "int", "=", "1", ",", "\n", "contiguous", ":", "bool", "=", "False", ",", "\n", ")", "->", "Union", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Apply a center crop to the input data, or to a list of complex images.\n\n    Parameters\n    ----------\n    data_list: Union[List[torch.Tensor], torch.Tensor]\n        The complex input tensor to be center cropped. It should have at least 3 dimensions\n         and the cropping is applied along dimensions didx and didx+1 and the last dimensions should have a size of 2.\n    crop_shape: List[int] or Tuple[int, ...]\n        The output shape. The shape should be smaller than the corresponding dimensions of data.\n        If one value is None, this is filled in by the image shape.\n    offset: int\n        Starting dimension for cropping.\n    contiguous: bool\n        Return as a contiguous array. Useful for fast reshaping or viewing.\n\n    Returns\n    -------\n    Union[List[torch.Tensor], torch.Tensor]\n        The center cropped input_image(s).\n    \"\"\"", "\n", "data_list", "=", "ensure_list", "(", "data_list", ")", "\n", "assert_same_shape", "(", "data_list", ")", "\n", "\n", "image_shape", "=", "list", "(", "data_list", "[", "0", "]", ".", "shape", ")", "\n", "ndim", "=", "data_list", "[", "0", "]", ".", "ndim", "\n", "bbox", "=", "[", "0", "]", "*", "ndim", "+", "image_shape", "\n", "\n", "# Allow for False in crop directions", "\n", "shape", "=", "[", "_", "if", "_", "else", "image_shape", "[", "idx", "+", "offset", "]", "for", "idx", ",", "_", "in", "enumerate", "(", "crop_shape", ")", "]", "\n", "for", "idx", ",", "_", "in", "enumerate", "(", "shape", ")", ":", "\n", "        ", "bbox", "[", "idx", "+", "offset", "]", "=", "(", "image_shape", "[", "idx", "+", "offset", "]", "-", "shape", "[", "idx", "]", ")", "//", "2", "\n", "bbox", "[", "len", "(", "image_shape", ")", "+", "idx", "+", "offset", "]", "=", "shape", "[", "idx", "]", "\n", "\n", "", "if", "not", "all", "(", "_", ">=", "0", "for", "_", "in", "bbox", "[", ":", "ndim", "]", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Bounding box requested has negative values, \"", "\n", "f\"this is likely to data size being smaller than the crop size. Got {bbox} with image_shape {image_shape} \"", "\n", "f\"and requested shape {shape}.\"", "\n", ")", "\n", "\n", "", "output", "=", "[", "crop_to_bbox", "(", "data", ",", "bbox", ")", "for", "data", "in", "data_list", "]", "\n", "\n", "if", "contiguous", ":", "\n", "        ", "output", "=", "[", "_", ".", "contiguous", "(", ")", "for", "_", "in", "output", "]", "\n", "\n", "", "if", "len", "(", "output", ")", "==", "1", ":", "# Only one element:", "\n", "        ", "return", "output", "[", "0", "]", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_random_crop": [[748, 838], ["direct.utils.ensure_list", "direct.utils.asserts.assert_same_shape", "list", "numpy.asarray", "numpy.zeros", "enumerate", "enumerate", "ValueError", "len", "all", "ValueError", "numpy.random.seed", "numpy.random.randint().tolist", "direct.data.bbox.crop_to_bbox", "len", "enumerate", "numpy.asarray", "numpy.clip", "ValueError", "_.contiguous", "numpy.random.randint", "isinstance", "isinstance", "len", "len", "ValueError", "numpy.random.normal", "len", "len", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.ensure_list", "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_same_shape", "home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_bbox"], ["", "def", "complex_random_crop", "(", "\n", "data_list", ":", "Union", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ",", "\n", "crop_shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", ",", "\n", "offset", ":", "int", "=", "1", ",", "\n", "contiguous", ":", "bool", "=", "False", ",", "\n", "sampler", ":", "str", "=", "\"uniform\"", ",", "\n", "sigma", ":", "Union", "[", "float", ",", "List", "[", "float", "]", ",", "None", "]", "=", "None", ",", "\n", "seed", ":", "Union", "[", "None", ",", "int", ",", "ArrayLike", "]", "=", "None", ",", "\n", ")", "->", "Union", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Apply a random crop to the input data tensor or a list of complex.\n\n    Parameters\n    ----------\n    data_list: Union[List[torch.Tensor], torch.Tensor]\n        The complex input tensor to be center cropped. It should have at least 3 dimensions and the cropping is applied\n        along dimensions -3 and -2 and the last dimensions should have a size of 2.\n    crop_shape: List[int] or Tuple[int, ...]\n        The output shape. The shape should be smaller than the corresponding dimensions of data.\n    offset: int\n        Starting dimension for cropping.\n    contiguous: bool\n        Return as a contiguous array. Useful for fast reshaping or viewing.\n    sampler: str\n        Select the random indices from either a `uniform` or `gaussian` distribution (around the center)\n    sigma: float or list of float or None\n        Standard variance of the gaussian when sampler is `gaussian`. If not set will take 1/3th of image shape\n    seed: None, int or ArrayLike\n\n    Returns\n    -------\n    Union[List[torch.Tensor], torch.Tensor]\n        The center cropped input tensor or list of tensors.\n    \"\"\"", "\n", "if", "sampler", "==", "\"uniform\"", "and", "sigma", "is", "not", "None", ":", "\n", "        ", "raise", "ValueError", "(", "f\"sampler `uniform` is incompatible with sigma {sigma}, has to be None.\"", ")", "\n", "\n", "", "data_list", "=", "ensure_list", "(", "data_list", ")", "\n", "assert_same_shape", "(", "data_list", ")", "\n", "\n", "image_shape", "=", "list", "(", "data_list", "[", "0", "]", ".", "shape", ")", "\n", "\n", "ndim", "=", "data_list", "[", "0", "]", ".", "ndim", "\n", "bbox", "=", "[", "0", "]", "*", "ndim", "+", "image_shape", "\n", "\n", "crop_shape", "=", "[", "_", "if", "_", "else", "image_shape", "[", "idx", "+", "offset", "]", "for", "idx", ",", "_", "in", "enumerate", "(", "crop_shape", ")", "]", "\n", "crop_shape", "=", "np", ".", "asarray", "(", "crop_shape", ")", "\n", "\n", "limits", "=", "np", ".", "zeros", "(", "len", "(", "crop_shape", ")", ",", "dtype", "=", "int", ")", "\n", "for", "idx", ",", "_", "in", "enumerate", "(", "limits", ")", ":", "\n", "        ", "limits", "[", "idx", "]", "=", "image_shape", "[", "offset", "+", "idx", "]", "-", "crop_shape", "[", "idx", "]", "\n", "\n", "", "if", "not", "all", "(", "_", ">=", "0", "for", "_", "in", "limits", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Bounding box limits have negative values, \"", "\n", "f\"this is likely to data size being smaller than the crop size. Got {limits}\"", "\n", ")", "\n", "", "if", "seed", "is", "not", "None", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "", "if", "sampler", "==", "\"uniform\"", ":", "\n", "        ", "lower_point", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "limits", "+", "1", ")", ".", "tolist", "(", ")", "\n", "", "elif", "sampler", "==", "\"gaussian\"", ":", "\n", "        ", "data_shape", "=", "np", ".", "asarray", "(", "image_shape", "[", "offset", ":", "offset", "+", "len", "(", "crop_shape", ")", "]", ")", "\n", "if", "not", "sigma", ":", "\n", "            ", "sigma", "=", "data_shape", "/", "6", "# w, h", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "sigma", ",", "float", ")", "or", "isinstance", "(", "sigma", ",", "list", ")", "and", "len", "(", "sigma", ")", "==", "1", ":", "\n", "                ", "sigma", "=", "[", "sigma", "for", "_", "in", "range", "(", "len", "(", "crop_shape", ")", ")", "]", "\n", "", "elif", "len", "(", "sigma", ")", "!=", "len", "(", "crop_shape", ")", ":", "# type: ignore", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Either one sigma has to be set or same as the length of the bounding box. Got {sigma}.\"", "\n", ")", "\n", "", "", "lower_point", "=", "(", "\n", "np", ".", "random", ".", "normal", "(", "loc", "=", "data_shape", "/", "2", ",", "scale", "=", "sigma", ",", "size", "=", "len", "(", "data_shape", ")", ")", "-", "crop_shape", "/", "2", "\n", ")", ".", "astype", "(", "int", ")", "\n", "lower_point", "=", "np", ".", "clip", "(", "lower_point", ",", "0", ",", "limits", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Sampler is either `uniform` or `gaussian`. Got {sampler}.\"", ")", "\n", "\n", "", "for", "idx", ",", "_", "in", "enumerate", "(", "crop_shape", ")", ":", "\n", "        ", "bbox", "[", "offset", "+", "idx", "]", "=", "lower_point", "[", "idx", "]", "\n", "bbox", "[", "offset", "+", "ndim", "+", "idx", "]", "=", "crop_shape", "[", "idx", "]", "\n", "\n", "", "output", "=", "[", "crop_to_bbox", "(", "data", ",", "bbox", ")", "for", "data", "in", "data_list", "]", "\n", "\n", "if", "contiguous", ":", "\n", "        ", "output", "=", "[", "_", ".", "contiguous", "(", ")", "for", "_", "in", "output", "]", "\n", "\n", "", "if", "len", "(", "output", ")", "==", "1", ":", "\n", "        ", "return", "output", "[", "0", "]", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator": [[840, 879], ["direct.utils.asserts.assert_complex", "direct.utils.asserts.assert_complex", "complex_multiplication().sum", "transforms.complex_multiplication", "transforms.conjugate"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate"], ["", "def", "reduce_operator", "(", "\n", "coil_data", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "int", "=", "0", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "r\"\"\"\n    Given zero-filled reconstructions from multiple coils :math:`\\{x_i\\}_{i=1}^{N_c}` and\n    coil sensitivity maps :math:`\\{S_i\\}_{i=1}^{N_c}` it returns:\n\n        .. math::\n            R(x_{1}, .., x_{N_c}, S_1, .., S_{N_c}) = \\sum_{i=1}^{N_c} {S_i}^{*} \\times x_i.\n\n    Adapted from [1]_.\n\n    Parameters\n    ----------\n    coil_data: torch.Tensor\n        Zero-filled reconstructions from coils. Should be a complex tensor (with complex dim of size 2).\n    sensitivity_map: torch.Tensor\n        Coil sensitivity maps. Should be complex tensor (with complex dim of size 2).\n    dim: int\n        Coil dimension. Default: 0.\n\n    Returns\n    -------\n    torch.Tensor:\n        Combined individual coil images.\n\n    References\n    ----------\n\n    .. [1] Sriram, Anuroop, et al. \u201cEnd-to-End Variational Networks for Accelerated MRI Reconstruction.\u201d ArXiv:2004.06688 [Cs, Eess], Apr. 2020. arXiv.org, http://arxiv.org/abs/2004.06688.\n\n    \"\"\"", "\n", "\n", "assert_complex", "(", "coil_data", ",", "complex_last", "=", "True", ")", "\n", "assert_complex", "(", "sensitivity_map", ",", "complex_last", "=", "True", ")", "\n", "\n", "return", "complex_multiplication", "(", "conjugate", "(", "sensitivity_map", ")", ",", "coil_data", ")", ".", "sum", "(", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator": [[881, 919], ["direct.utils.asserts.assert_complex", "direct.utils.asserts.assert_complex", "transforms.complex_multiplication", "data.unsqueeze"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication"], ["", "def", "expand_operator", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "int", "=", "0", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "r\"\"\"\n    Given a reconstructed image :math:`x` and coil sensitivity maps :math:`\\{S_i\\}_{i=1}^{N_c}`, it returns\n\n        .. math::\n            E(x) = (S_1 \\times x, .., S_{N_c} \\times x) = (x_1, .., x_{N_c}).\n\n    Adapted from [1]_.\n\n    Parameters\n    ----------\n    data: torch.Tensor\n        Image data. Should be a complex tensor (with complex dim of size 2).\n    sensitivity_map: torch.Tensor\n        Coil sensitivity maps. Should be complex tensor (with complex dim of size 2).\n    dim: int\n        Coil dimension. Default: 0.\n\n    Returns\n    -------\n    torch.Tensor:\n        Zero-filled reconstructions from each coil.\n\n    References\n    ----------\n\n    .. [1] Sriram, Anuroop, et al. \u201cEnd-to-End Variational Networks for Accelerated MRI Reconstruction.\u201d ArXiv:2004.06688 [Cs, Eess], Apr. 2020. arXiv.org, http://arxiv.org/abs/2004.06688.\n\n    \"\"\"", "\n", "\n", "assert_complex", "(", "data", ",", "complex_last", "=", "True", ")", "\n", "assert_complex", "(", "sensitivity_map", ",", "complex_last", "=", "True", ")", "\n", "\n", "return", "complex_multiplication", "(", "sensitivity_map", ",", "data", ".", "unsqueeze", "(", "dim", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.__init__": [[19, 45], ["logging.getLogger", "NotImplementedError", "type"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ndim", ":", "int", "=", "2", ",", "\n", "blobs_n_samples", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "blobs_cluster_std", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`FakeMRIData`.\n\n        Parameters\n        ----------\n        ndim: int\n            Dimension of samples. Can be 2 or 3. Default: 2.\n        blobs_n_samples: Optional[int]\n            The total number of points equally divided among clusters. Default: None.\n        blobs_cluster_std: Optional[float]\n            Standard deviation of the clusters. Default: None.\n        \"\"\"", "\n", "\n", "if", "ndim", "not", "in", "[", "2", ",", "3", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Currently FakeMRIData is not implemented for {ndim}D data.\"", ")", "\n", "\n", "", "self", ".", "ndim", "=", "ndim", "\n", "self", ".", "blobs_n_samples", "=", "blobs_n_samples", "\n", "self", ".", "blobs_cluster_std", "=", "blobs_cluster_std", "\n", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.get_kspace": [[46, 70], ["fake.FakeMRIData.make_blobs", "fake.FakeMRIData._get_image_from_samples", "fake.fft", "direct.data.sens.simulate_sensitivity_maps", "fft.transpose"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.make_blobs", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData._get_image_from_samples", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.fft", "home.repos.pwc.inspect_result.directgroup_direct.data.sens.simulate_sensitivity_maps"], ["", "def", "get_kspace", "(", "\n", "self", ",", "\n", "spatial_shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", ",", "\n", "num_coils", ":", "int", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        spatial_shape: List of ints or tuple of ints.\n        num_coils: int\n        \"\"\"", "\n", "\n", "samples", "=", "self", ".", "make_blobs", "(", "spatial_shape", ",", "num_coils", ")", "\n", "\n", "image", "=", "self", ".", "_get_image_from_samples", "(", "samples", ",", "spatial_shape", ")", "\n", "image", "=", "image", "[", "None", "]", "\n", "if", "num_coils", ">", "1", ":", "\n", "            ", "sens_maps", "=", "simulate_sensitivity_maps", "(", "spatial_shape", "[", "-", "2", ":", "]", ",", "num_coils", ")", "\n", "\n", "image", "=", "image", "*", "(", "sens_maps", "if", "self", ".", "ndim", "==", "2", "else", "sens_maps", "[", ":", ",", "None", "]", ")", "\n", "\n", "", "kspace", "=", "fft", "(", "image", ")", "\n", "\n", "return", "kspace", "[", "np", ".", "newaxis", ",", "...", "]", "if", "self", ".", "ndim", "==", "2", "else", "kspace", ".", "transpose", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.set_attrs": [[71, 81], ["dict", "numpy.linalg.norm", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.norm"], ["", "def", "set_attrs", "(", "self", ",", "sample", ":", "Dict", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Sets metadata attributes of sample.\"\"\"", "\n", "\n", "attrs", "=", "dict", "(", ")", "\n", "attrs", "[", "\"norm\"", "]", "=", "np", ".", "linalg", ".", "norm", "(", "sample", "[", "\"reconstruction_rss\"", "]", ")", "\n", "attrs", "[", "\"max\"", "]", "=", "np", ".", "max", "(", "sample", "[", "\"reconstruction_rss\"", "]", ")", "\n", "attrs", "[", "\"encoding_size\"", "]", "=", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "-", "self", ".", "ndim", ":", "]", "\n", "attrs", "[", "\"reconstruction_size\"", "]", "=", "sample", "[", "\"reconstruction_rss\"", "]", ".", "shape", "[", "-", "self", ".", "ndim", ":", "]", "\n", "\n", "return", "attrs", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.make_blobs": [[82, 110], ["sklearn.datasets.make_blobs", "fake.scale_data", "numpy.prod", "list"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.make_blobs", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.scale_data"], ["", "def", "make_blobs", "(", "\n", "self", ",", "\n", "spatial_shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", ",", "\n", "num_coils", ":", "int", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"Generates gaussian blobs in 'num_coils' classes and scales them the interval.\n\n        [0, slice] x [0, height] x [0, width].\n        \"\"\"", "\n", "\n", "# Number of samples to be converted to an image", "\n", "n_samples", "=", "self", ".", "blobs_n_samples", "if", "self", ".", "blobs_n_samples", "else", "np", ".", "prod", "(", "list", "(", "spatial_shape", ")", ")", "//", "self", ".", "ndim", "\n", "cluster_std", "=", "self", ".", "blobs_cluster_std", "if", "self", ".", "blobs_cluster_std", "is", "not", "None", "else", "0.1", "\n", "\n", "samples", ",", "_", ",", "_", "=", "make_blobs", "(", "\n", "n_samples", "=", "n_samples", ",", "\n", "n_features", "=", "self", ".", "ndim", ",", "\n", "centers", "=", "num_coils", ",", "\n", "cluster_std", "=", "cluster_std", ",", "\n", "center_box", "=", "(", "0", ",", "1", ")", ",", "\n", "random_state", "=", "seed", ",", "\n", "return_centers", "=", "True", ",", "\n", ")", "\n", "\n", "samples", "=", "scale_data", "(", "data", "=", "samples", ",", "shape", "=", "spatial_shape", ")", "\n", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData._get_image_from_samples": [[111, 117], ["numpy.zeros", "list", "tuple", "numpy.split", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_image_from_samples", "(", "samples", ",", "spatial_shape", ")", ":", "\n", "        ", "image", "=", "np", ".", "zeros", "(", "list", "(", "spatial_shape", ")", ")", "\n", "image", "[", "tuple", "(", "np", ".", "split", "(", "samples", ",", "len", "(", "spatial_shape", ")", ",", "axis", "=", "-", "1", ")", ")", "]", "=", "1", "\n", "\n", "return", "image", "+", "0.0j", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.__call__": [[118, 169], ["isinstance", "range", "len", "ValueError", "dict", "len", "fake.FakeMRIData.get_kspace", "fake.root_sum_of_squares", "fake.FakeMRIData.set_attrs", "range", "range"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.get_kspace", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.FakeMRIData.set_attrs"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "sample_size", ":", "int", "=", "1", ",", "\n", "num_coils", ":", "int", "=", "1", ",", "\n", "spatial_shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "...", "]", "]", "=", "(", "100", ",", "100", ")", ",", "\n", "name", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", "=", "\"fake_mri_sample\"", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "root", ":", "Optional", "[", "pathlib", ".", "Path", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "Dict", "]", ":", "\n", "        ", "\"\"\"Returns fake mri samples in the form of gaussian blobs.\n\n        Parameters\n        ----------\n        sample_size: int\n            Size of the samples.\n        num_coils: int\n            Number of simulated coils.\n        spatial_shape: List of ints or Tuple of ints.\n            Must be (slice, height, width) or (height, width).\n        name: String or list of strings.\n            Name of file.\n        root: pathlib.Path, Optional\n            Root to save data. To be used with save_as_h5=True\n\n        Returns:\n        --------\n        sample: dict or list of dicts\n            Contains:\n                \"kspace\": np.array of shape (slice, num_coils, height, width)\n                \"reconstruction_rss\": np. array of shape (slice, height, width)\n                If spatial_shape is of shape 2 (height, width), slice=1.\n        \"\"\"", "\n", "\n", "if", "len", "(", "spatial_shape", ")", "!=", "self", ".", "ndim", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Spatial shape must have {self.ndim} dimensions. Got shape {spatial_shape}.\"", ")", "\n", "\n", "", "sample", ":", "List", "[", "Dict", "]", "=", "[", "dict", "(", ")", "for", "_", "in", "range", "(", "sample_size", ")", "]", "\n", "\n", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "            ", "name", "=", "[", "name", "]", "\n", "\n", "", "if", "len", "(", "name", ")", "!=", "sample_size", ":", "\n", "            ", "name", "=", "[", "name", "[", "0", "]", "+", "f\"{_:04}\"", "for", "_", "in", "range", "(", "1", ",", "sample_size", "+", "1", ")", "]", "\n", "\n", "", "for", "idx", "in", "range", "(", "sample_size", ")", ":", "\n", "            ", "sample", "[", "idx", "]", "[", "\"kspace\"", "]", "=", "self", ".", "get_kspace", "(", "spatial_shape", ",", "num_coils", ")", "\n", "sample", "[", "idx", "]", "[", "\"reconstruction_rss\"", "]", "=", "root_sum_of_squares", "(", "sample", "[", "idx", "]", "[", "\"kspace\"", "]", ",", "coil_dim", "=", "1", ")", "\n", "sample", "[", "idx", "]", "[", "\"attrs\"", "]", "=", "self", ".", "set_attrs", "(", "sample", "[", "idx", "]", ")", "\n", "sample", "[", "idx", "]", "[", "\"filename\"", "]", "=", "name", "[", "idx", "]", "\n", "\n", "", "return", "sample", "# if sample_size > 1 else sample[0]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.scale_data": [[171, 178], ["numpy.round().astype", "numpy.array", "numpy.round", "data.min", "data.max", "data.min"], "function", ["None"], ["", "", "def", "scale_data", "(", "data", ",", "shape", ")", ":", "\n", "    ", "\"\"\"Scales data to (0,1) and then to shape.\"\"\"", "\n", "\n", "scaled_data", "=", "(", "data", "-", "data", ".", "min", "(", "0", ")", ")", "/", "(", "data", ".", "max", "(", "0", ")", "-", "data", ".", "min", "(", "0", ")", ")", "*", "(", "np", ".", "array", "(", "shape", ")", "-", "1", ")", "\n", "scaled_data", "=", "np", ".", "round", "(", "scaled_data", ")", ".", "astype", "(", "int", ")", "\n", "\n", "return", "scaled_data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.fft": [[180, 187], ["numpy.fft.ifftshift", "numpy.fft.fft2", "numpy.fft.fftshift"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift"], ["", "def", "fft", "(", "data", ",", "dims", "=", "(", "-", "2", ",", "-", "1", ")", ")", ":", "\n", "    ", "\"\"\"Fast Fourier Transform.\"\"\"", "\n", "data", "=", "np", ".", "fft", ".", "ifftshift", "(", "data", ",", "dims", ")", "\n", "out", "=", "np", ".", "fft", ".", "fft2", "(", "data", ",", "norm", "=", "\"ortho\"", ")", "\n", "out", "=", "np", ".", "fft", ".", "fftshift", "(", "out", ",", "dims", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.ifft": [[189, 196], ["numpy.fft.ifftshift", "numpy.fft.ifft2", "numpy.fft.fftshift"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift"], ["", "def", "ifft", "(", "data", ",", "dims", "=", "(", "-", "2", ",", "-", "1", ")", ")", ":", "\n", "    ", "\"\"\"Inverse Fast Fourier Transform.\"\"\"", "\n", "data", "=", "np", ".", "fft", ".", "ifftshift", "(", "data", ",", "dims", ")", "\n", "out", "=", "np", ".", "fft", ".", "ifft2", "(", "data", ",", "norm", "=", "\"ortho\"", ")", "\n", "out", "=", "np", ".", "fft", ".", "fftshift", "(", "out", ",", "dims", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares": [[198, 201], ["numpy.sqrt", "numpy.abs", "fake.ifft"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_fake.ifft"], ["", "def", "root_sum_of_squares", "(", "kspace_data", ",", "coil_dim", "=", "1", ")", ":", "\n", "    ", "\"\"\"Root Sum of Squares Estimate, given kspace data.\"\"\"", "\n", "return", "np", ".", "sqrt", "(", "(", "np", ".", "abs", "(", "ifft", "(", "kspace_data", ")", ")", "**", "2", ")", ".", "sum", "(", "coil_dim", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.DistributedSampler.__init__": [[30, 57], ["torch.utils.data.sampler.Sampler.__init__", "int", "direct.utils.communication.get_rank", "direct.utils.communication.get_world_size", "direct.utils.communication.shared_random_seed"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.shared_random_seed"], ["def", "__init__", "(", "\n", "self", ",", "\n", "size", ":", "int", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        size: int\n            Size of underlying dataset.\n        shuffle: bool\n            If true, the indices will be shuffled.\n        seed: int\n            Initial seed of the shuffle, must be the same across all workers!\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "data_source", "=", "None", ")", "\n", "self", ".", "_size", "=", "size", "\n", "if", "self", ".", "_size", "<=", "0", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "self", ".", "_shuffle", "=", "shuffle", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "communication", ".", "shared_random_seed", "(", ")", "\n", "", "self", ".", "_seed", "=", "int", "(", "seed", ")", "\n", "\n", "self", ".", "_rank", "=", "communication", ".", "get_rank", "(", ")", "\n", "self", ".", "_world_size", "=", "communication", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.DistributedSampler.__iter__": [[58, 61], ["itertools.islice", "samplers.DistributedSampler._infinite_indices"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.samplers.DistributedSampler._infinite_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "start", "=", "self", ".", "_rank", "\n", "yield", "from", "itertools", ".", "islice", "(", "self", ".", "_infinite_indices", "(", ")", ",", "start", ",", "None", ",", "self", ".", "_world_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.DistributedSampler._infinite_indices": [[62, 70], ["torch.Generator", "torch.Generator.manual_seed", "torch.randperm", "torch.arange"], "methods", ["None"], ["", "def", "_infinite_indices", "(", "self", ")", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "_seed", ")", "\n", "while", "True", ":", "\n", "            ", "if", "self", ".", "_shuffle", ":", "\n", "                ", "yield", "from", "torch", ".", "randperm", "(", "self", ".", "_size", ",", "generator", "=", "g", ")", "\n", "", "else", ":", "\n", "                ", "yield", "from", "torch", ".", "arange", "(", "self", ".", "_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.DistributedSequentialSampler.__init__": [[83, 114], ["torch.utils.data.sampler.Sampler.__init__", "list", "list", "direct.utils.communication.get_world_size", "direct.utils.communication.get_rank", "samplers.DistributedSequentialSampler.dataset.volume_indices.keys", "direct.utils.chunks", "len", "samplers.DistributedSequentialSampler.indices.extend", "list"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_world_size", "home.repos.pwc.inspect_result.directgroup_direct.utils.communication.get_rank", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.chunks"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "num_replicas", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "rank", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "limit_number_of_volumes", ":", "bool", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ")", "\n", "if", "num_replicas", "is", "None", ":", "\n", "            ", "num_replicas", "=", "communication", ".", "get_world_size", "(", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "            ", "rank", "=", "communication", ".", "get_rank", "(", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_replicas", "=", "num_replicas", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "filenames", "=", "list", "(", "self", ".", "dataset", ".", "volume_indices", ".", "keys", "(", ")", ")", "# This is an OrderedDict", "\n", "if", "limit_number_of_volumes", ":", "\n", "            ", "filenames", "=", "filenames", "[", ":", "limit_number_of_volumes", "]", "\n", "\n", "", "chunked_filenames", "=", "list", "(", "chunks", "(", "filenames", ",", "self", ".", "num_replicas", ")", ")", "\n", "filenames", "=", "chunked_filenames", "[", "self", ".", "rank", "]", "\n", "\n", "# Create volume indices for this sampler.", "\n", "self", ".", "volume_indices", "=", "{", "k", ":", "self", ".", "dataset", ".", "volume_indices", "[", "k", "]", "for", "k", "in", "filenames", "}", "\n", "\n", "# Collect the indices belonging to these filenames.", "\n", "self", ".", "indices", "=", "[", "]", "\n", "if", "self", ".", "rank", "<", "len", "(", "chunked_filenames", ")", ":", "# Otherwise there is nothing to fill.", "\n", "            ", "for", "filename", "in", "filenames", ":", "\n", "                ", "self", ".", "indices", ".", "extend", "(", "list", "(", "self", ".", "dataset", ".", "volume_indices", "[", "filename", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.DistributedSequentialSampler.__iter__": [[115, 117], ["iter"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.iter"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.DistributedSequentialSampler.__len__": [[118, 120], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.BatchVolumeSampler.__init__": [[130, 151], ["torch.utils.data.sampler.Sampler.__init__", "iter", "isinstance", "ValueError", "end_of_volume.append", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.iter"], ["def", "__init__", "(", "self", ",", "sampler", ":", "Sampler", ",", "batch_size", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sampler", ")", "# type: ignore", "\n", "if", "not", "isinstance", "(", "sampler", ",", "Sampler", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Sampler should be an instance of \"", "f\"torch.utils.data.Sampler, but got sampler={sampler}.\"", "\n", ")", "\n", "\n", "", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "# Create a reverse lookup when we need to switch to a new batch", "\n", "end_of_volume", "=", "[", "]", "\n", "self", ".", "__num_batches", "=", "0", "\n", "for", "filename", "in", "self", ".", "sampler", ".", "volume_indices", ":", "# type: ignore", "\n", "            ", "curr_slice", "=", "self", ".", "sampler", ".", "volume_indices", "[", "filename", "]", "# type: ignore", "\n", "end_of_volume", ".", "append", "(", "curr_slice", ".", "stop", ")", "\n", "num_indices", "=", "curr_slice", ".", "stop", "-", "curr_slice", ".", "start", "\n", "self", ".", "__num_batches", "+=", "math", ".", "ceil", "(", "num_indices", "/", "batch_size", ")", "\n", "\n", "", "self", ".", "end_of_volume", "=", "iter", "(", "end_of_volume", "[", "1", ":", "]", ")", "\n", "self", ".", "_next_value", "=", "end_of_volume", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.BatchVolumeSampler.__iter__": [[152, 168], ["batch.append", "len", "len", "next"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "batch", "=", "[", "]", "\n", "for", "idx", "in", "self", ".", "sampler", ":", "\n", "            ", "batch", ".", "append", "(", "idx", ")", "\n", "if", "(", "len", "(", "batch", ")", "==", "self", ".", "batch_size", ")", "or", "(", "idx", "==", "self", ".", "_next_value", "-", "1", ")", ":", "\n", "                ", "yield", "batch", "\n", "batch", "=", "[", "]", "\n", "\n", "", "if", "idx", "==", "self", ".", "_next_value", "-", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "_next_value", "=", "next", "(", "self", ".", "end_of_volume", ")", "\n", "", "except", "StopIteration", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "", "if", "len", "(", "batch", ")", ">", "0", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.BatchVolumeSampler.__len__": [[169, 171], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__num_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.ConcatDatasetBatchSampler.__init__": [[181, 202], ["torch.utils.data.sampler.Sampler.__init__", "logging.getLogger", "numpy.asarray", "samplers.ConcatDatasetBatchSampler.cumsum", "samplers.ConcatDatasetBatchSampler.logger.info", "isinstance", "ValueError", "samplers.DistributedSampler", "samplers.ConcatDatasetBatchSampler.batch_sampler", "type", "isinstance", "len", "len", "enumerate"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.ConcatDatasetBatchSampler.batch_sampler"], ["def", "__init__", "(", "self", ",", "datasets", ":", "List", ",", "batch_size", ":", "int", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "datasets", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n", "if", "not", "isinstance", "(", "batch_size", ",", "int", ")", "or", "isinstance", "(", "batch_size", ",", "bool", ")", "or", "batch_size", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"batch_size should be a positive integer value, \"", "f\"but got batch_size={batch_size}\"", ")", "\n", "\n", "", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "samplers", "=", "[", "DistributedSampler", "(", "len", "(", "_", ")", ",", "shuffle", "=", "True", ",", "seed", "=", "seed", ")", "for", "_", "in", "datasets", "]", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "weights", "=", "np", ".", "asarray", "(", "[", "len", "(", "_", ")", "for", "_", "in", "datasets", "]", ")", "\n", "self", ".", "cumulative_sizes", "=", "self", ".", "cumsum", "(", "datasets", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"Sampling batches with weights %s with cumulative sizes %s.\"", ",", "self", ".", "weights", ",", "self", ".", "cumulative_sizes", "\n", ")", "\n", "self", ".", "_batch_samplers", "=", "[", "\n", "self", ".", "batch_sampler", "(", "sampler", ",", "0", "if", "idx", "==", "0", "else", "self", ".", "cumulative_sizes", "[", "idx", "-", "1", "]", ")", "\n", "for", "idx", ",", "sampler", "in", "enumerate", "(", "self", ".", "samplers", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.ConcatDatasetBatchSampler.batch_sampler": [[204, 214], ["batch.append", "len", "len"], "methods", ["None"], ["", "def", "batch_sampler", "(", "self", ",", "sampler", ",", "sampler_offset", ")", ":", "\n", "        ", "batch", "=", "[", "]", "\n", "for", "batch_idx", "in", "sampler", ":", "\n", "            ", "batch", ".", "append", "(", "batch_idx", "+", "sampler_offset", ")", "\n", "if", "len", "(", "batch", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "yield", "batch", "\n", "batch", "=", "[", "]", "\n", "\n", "", "", "if", "len", "(", "batch", ")", ">", "0", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.ConcatDatasetBatchSampler.__next__": [[215, 218], ["next", "random.choices", "range", "len", "samplers.ConcatDatasetBatchSampler.weights.sum"], "methods", ["None"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "iterator_idx", "=", "random", ".", "choices", "(", "range", "(", "len", "(", "self", ".", "weights", ")", ")", ",", "weights", "=", "self", ".", "weights", "/", "self", ".", "weights", ".", "sum", "(", ")", ")", "[", "0", "]", "\n", "return", "next", "(", "self", ".", "_batch_samplers", "[", "iterator_idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.ConcatDatasetBatchSampler.__iter__": [[219, 221], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.ConcatDatasetBatchSampler.cumsum": [[222, 231], ["len", "r.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "cumsum", "(", "sequence", ")", ":", "\n", "# From Pytorch 1.5.1: torch.utils.data.dataset.ConcatDataset", "\n", "        ", "r", ",", "s", "=", "[", "]", ",", "0", "\n", "for", "e", "in", "sequence", ":", "\n", "            ", "curr_len", "=", "len", "(", "e", ")", "\n", "r", ".", "append", "(", "curr_len", "+", "s", ")", "\n", "s", "+=", "curr_len", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.samplers.ConcatDatasetBatchSampler.__len__": [[232, 235], ["ValueError"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# This does not make sense for this sampler.", "\n", "        ", "raise", "ValueError", "(", "\"length does not make sense for ConcatDatasetBatchSampler.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.sens.simulate_sensitivity_maps": [[10, 69], ["numpy.meshgrid", "numpy.stack", "numpy.zeros", "numpy.zeros", "range", "numpy.diag", "numpy.random.uniform", "range", "len", "len", "numpy.random.seed", "scipy.stats.multivariate_normal.pdf", "numpy.sqrt", "numpy.cos().item", "numpy.sin().item", "len", "numpy.ones", "numpy.linspace", "scipy.stats.multivariate_normal", "numpy.cos", "numpy.sin", "numpy.conj"], "function", ["None"], ["def", "simulate_sensitivity_maps", "(", "\n", "shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", "]", "]", ",", "num_coils", ":", "int", ",", "var", ":", "float", "=", "1", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "r\"\"\"Simulates coil sensitivities using bi-variate or tri-variate gaussian distribution.\n\n    Parameters\n    ----------\n    shape: List[int] or Tuple[int]\n        (nx, ny) or (nx, ny, nz).\n    num_coils: int\n        Number of coils to be simulated.\n    var: float\n        Variance.\n    seed: int or None\n        If not None, a seed will be used to produce an offset for the gaussian mean :math:`\\mu`.\n\n    Returns\n    -------\n    sensitivity_map : nd.array\n        Simulated coil sensitivity maps of shape (num_coils, \\*shape).\n\n    Notes\n    -----\n    Sensitivity maps are normalized such that:\n\n        .. math::\n            \\sum_{k=1}^{n_c} {S^{k}}^{*}S^{k} = I.\n\n    \"\"\"", "\n", "if", "num_coils", "==", "1", ":", "\n", "        ", "return", "np", ".", "ones", "(", "shape", ")", "[", "None", "]", "+", "0.0j", "\n", "# X, Y are switched in np.meshgrid", "\n", "", "meshgrid", "=", "np", ".", "meshgrid", "(", "*", "[", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "n", ")", "for", "n", "in", "shape", "[", ":", "2", "]", "[", ":", ":", "-", "1", "]", "+", "shape", "[", "2", ":", "]", "]", ")", "\n", "indices", "=", "np", ".", "stack", "(", "meshgrid", ",", "axis", "=", "-", "1", ")", "\n", "\n", "sensitivity_map", "=", "np", ".", "zeros", "(", "(", "num_coils", ",", "*", "shape", ")", ")", "\n", "# Assume iid", "\n", "cov", "=", "np", ".", "zeros", "(", "len", "(", "shape", ")", ")", "\n", "for", "ii", "in", "range", "(", "len", "(", "shape", ")", ")", ":", "\n", "        ", "cov", "[", "ii", "]", "=", "var", "\n", "", "cov", "=", "np", ".", "diag", "(", "cov", ")", "\n", "if", "seed", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "", "offset", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "2", "*", "np", ".", "pi", ",", "1", ")", "\n", "for", "coil_idx", "in", "range", "(", "num_coils", ")", ":", "\n", "        ", "mu", "=", "[", "\n", "np", ".", "cos", "(", "coil_idx", "/", "num_coils", "*", "2", "*", "np", ".", "pi", "+", "offset", ")", ".", "item", "(", ")", ",", "\n", "np", ".", "sin", "(", "coil_idx", "/", "num_coils", "*", "2", "*", "np", ".", "pi", "+", "offset", ")", ".", "item", "(", ")", ",", "\n", "]", "\n", "if", "len", "(", "shape", ")", "==", "3", ":", "\n", "            ", "mu", "+=", "[", "0.0", "]", "\n", "", "sensitivity_map", "[", "coil_idx", "]", "=", "normal", "(", "mu", ",", "cov", ")", ".", "pdf", "(", "indices", ")", "\n", "\n", "", "sensitivity_map", "=", "sensitivity_map", "+", "1.0j", "*", "sensitivity_map", "# make complex", "\n", "# Normalize", "\n", "sensitivity_map_norm", "=", "np", ".", "sqrt", "(", "(", "np", ".", "conj", "(", "sensitivity_map", ")", "*", "sensitivity_map", ")", ".", "sum", "(", "0", ")", ")", "[", "None", "]", "\n", "sensitivity_map", "=", "sensitivity_map", "/", "sensitivity_map_norm", "\n", "\n", "return", "sensitivity_map", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_bbox": [[11, 70], ["isinstance", "isinstance", "isinstance", "ValueError", "len", "ValueError", "numpy.asarray", "numpy.asarray", "bbox_coords.copy", "numpy.array", "slice", "data[].clone", "isinstance", "numpy.all", "numpy.all", "isinstance", "slice", "len", "zip", "data[].copy", "torch.ones", "zip", "tuple", "bbox_size.tolist", "numpy.ones", "type", "tuple", "tuple"], "function", ["None"], [")", "->", "Union", "[", "np", ".", "ndarray", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Extract bbox from images, coordinates can be negative.\n\n    Parameters\n    ----------\n    data: np.ndarray or torch.tensor\n       nD array or torch tensor.\n    bbox: list or tuple\n       bbox of the form (coordinates, size),\n       for instance (4, 4, 2, 1) is a patch starting at row 4, col 4 with height 2 and width 1.\n    pad_value: number\n       if bounding box would be out of the image, this is value the patch will be padded with.\n\n    Returns\n    -------\n    ndarray\n        Numpy array of data cropped to BoundingBox\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "data", ",", "(", "np", ".", "ndarray", ",", "torch", ".", "Tensor", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Expected `data` to be ndarray or tensor. Got {type(data)}.\"", ")", "\n", "\n", "# Coordinates, size", "\n", "", "ndim", "=", "len", "(", "bbox", ")", "//", "2", "\n", "if", "len", "(", "bbox", ")", "%", "2", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Bounding box should have the form of [x_0, x_1, ..., h_0, h_1], but got length {ndim}.\"", ")", "\n", "", "bbox_coords", ",", "bbox_size", "=", "np", ".", "asarray", "(", "bbox", "[", ":", "ndim", "]", ")", ",", "np", ".", "asarray", "(", "bbox", "[", "ndim", ":", "]", ")", "\n", "# Offsets", "\n", "l_offset", "=", "-", "bbox_coords", ".", "copy", "(", ")", "\n", "l_offset", "[", "l_offset", "<", "0", "]", "=", "0", "\n", "\n", "r_offset", "=", "(", "bbox_coords", "+", "bbox_size", ")", "-", "np", ".", "array", "(", "data", ".", "shape", ")", "\n", "r_offset", "[", "r_offset", "<", "0", "]", "=", "0", "\n", "\n", "region_idx", "=", "[", "slice", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "zip", "(", "bbox_coords", "+", "l_offset", ",", "bbox_coords", "+", "bbox_size", "-", "r_offset", ")", "]", "\n", "\n", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "# TODO(jt): Investigate if clone is needed", "\n", "        ", "out", "=", "data", "[", "tuple", "(", "region_idx", ")", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "        ", "out", "=", "data", "[", "tuple", "(", "region_idx", ")", "]", ".", "copy", "(", ")", "\n", "\n", "", "if", "np", ".", "all", "(", "l_offset", "==", "0", ")", "and", "np", ".", "all", "(", "r_offset", "==", "0", ")", ":", "\n", "        ", "return", "out", "\n", "\n", "# If we have a positive offset, we need to pad the patch.", "\n", "", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "patch", "=", "pad_value", "*", "torch", ".", "ones", "(", "bbox_size", ".", "tolist", "(", ")", ",", "dtype", "=", "data", ".", "dtype", ")", "\n", "", "else", ":", "\n", "        ", "patch", "=", "pad_value", "*", "np", ".", "ones", "(", "bbox_size", ".", "tolist", "(", ")", ",", "dtype", "=", "data", ".", "dtype", ")", "\n", "\n", "", "patch_idx", "=", "[", "slice", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "zip", "(", "l_offset", ",", "bbox_size", "-", "r_offset", ")", "]", "\n", "patch", "[", "tuple", "(", "patch_idx", ")", "]", "=", "out", "\n", "\n", "return", "patch", "\n", "\n", "\n", "", "def", "crop_to_largest", "(", "\n", "data", ":", "List", "[", "Union", "[", "np", ".", "ndarray", ",", "torch", ".", "Tensor", "]", "]", ",", "pad_value", ":", "int", "=", "0", "\n", ")", "->", "List", "[", "Union", "[", "np", ".", "ndarray", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "    "]], "home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_largest": [[72, 97], ["numpy.asarray", "np.asarray.max", "bbox.crop_to_bbox", "_.tolist", "shapes.max.tolist", "zip", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_bbox"], ["\n", "if", "not", "data", ":", "\n", "        ", "return", "data", "\n", "\n", "", "shapes", "=", "np", ".", "asarray", "(", "[", "_", ".", "shape", "for", "_", "in", "data", "]", ")", "\n", "max_shape", "=", "shapes", ".", "max", "(", "axis", "=", "0", ")", "\n", "\n", "crop_start_per_shape", "=", "[", "-", "(", "max_shape", "-", "np", ".", "asarray", "(", "_", ")", ")", "//", "2", "for", "_", "in", "shapes", "]", "\n", "crop_boxes", "=", "[", "_", ".", "tolist", "(", ")", "+", "max_shape", ".", "tolist", "(", ")", "for", "_", "in", "crop_start_per_shape", "]", "\n", "\n", "return", "[", "crop_to_bbox", "(", "curr_data", ",", "bbox", ",", "pad_value", "=", "pad_value", ")", "for", "curr_data", ",", "bbox", "in", "zip", "(", "data", ",", "crop_boxes", ")", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.Compose.__init__": [[27, 37], ["direct.utils.DirectModule.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "transforms", ":", "Iterable", "[", "Callable", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`Compose`.\n\n        Parameters\n        ----------\n        transforms: Iterable[Callable]\n            List of transforms.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.Compose.__call__": [[38, 55], ["transform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`Compose`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Dict sample.\n\n        Returns\n        -------\n        Dict[str, Any]\n            Dict sample transformed by `transforms`.\n        \"\"\"", "\n", "for", "transform", "in", "self", ".", "transforms", ":", "\n", "            ", "sample", "=", "transform", "(", "sample", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.Compose.__repr__": [[56, 64], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Representation of :class:`Compose`.\"\"\"", "\n", "repr_string", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "for", "transform", "in", "self", ".", "transforms", ":", "\n", "            ", "repr_string", "+=", "\"\\n\"", "\n", "repr_string", "+=", "f\"    {transform}\"", "\n", "", "repr_string", "+=", "\"\\n)\"", "\n", "return", "repr_string", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.RandomFlip.__init__": [[73, 76], ["direct.utils.DirectTransform.__init__", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "raise", "NotImplementedError", "(", "\":class:`RandomFlip` is not implemented yet.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.CreateSamplingMask.__init__": [[84, 110], ["direct.utils.DirectModule.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "mask_func", ":", "Callable", ",", "\n", "shape", ":", "Optional", "[", "Tuple", "[", "int", ",", "...", "]", "]", "=", "None", ",", "\n", "use_seed", ":", "bool", "=", "True", ",", "\n", "return_acs", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`CreateSamplingMask`.\n\n        Parameters\n        ----------\n        mask_func: Callable\n            A function which creates a sampling mask of the appropriate shape.\n        shape: tuple, optional\n            Sampling mask shape. Default: None.\n        use_seed: bool\n            If true, a pseudo-random number based on the filename is computed so that every slice of the volume get\n            the same mask every time. Default: True.\n        return_acs: bool\n            If True, it will generate an ACS mask. Default: False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mask_func", "=", "mask_func", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "use_seed", "=", "use_seed", "\n", "self", ".", "return_acs", "=", "return_acs", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.CreateSamplingMask.__call__": [[111, 158], ["mri_transforms.CreateSamplingMask.mask_func", "any", "tuple", "mri_transforms.CreateSamplingMask.mask_func", "list", "map", "sample.get", "sample.get", "ValueError", "tuple", "str", "enumerate"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.DictionaryMaskFunc.mask_func", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.DictionaryMaskFunc.mask_func"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`CreateSamplingMask`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Dict sample.\n\n        Returns\n        -------\n        Dict[str, Any]\n            Sample with `sampling_mask` key.\n        \"\"\"", "\n", "if", "not", "self", ".", "shape", ":", "\n", "            ", "shape", "=", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "1", ":", "]", "\n", "", "elif", "any", "(", "_", "is", "None", "for", "_", "in", "self", ".", "shape", ")", ":", "# Allow None as values.", "\n", "            ", "kspace_shape", "=", "list", "(", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "1", ":", "-", "1", "]", ")", "\n", "shape", "=", "tuple", "(", "_", "if", "_", "else", "kspace_shape", "[", "idx", "]", "for", "idx", ",", "_", "in", "enumerate", "(", "self", ".", "shape", ")", ")", "+", "(", "2", ",", ")", "\n", "", "else", ":", "\n", "            ", "shape", "=", "self", ".", "shape", "+", "(", "2", ",", ")", "\n", "\n", "", "seed", "=", "None", "if", "not", "self", ".", "use_seed", "else", "tuple", "(", "map", "(", "ord", ",", "str", "(", "sample", "[", "\"filename\"", "]", ")", ")", ")", "\n", "\n", "sampling_mask", "=", "self", ".", "mask_func", "(", "shape", "=", "shape", ",", "seed", "=", "seed", ",", "return_acs", "=", "False", ")", "\n", "\n", "if", "sample", ".", "get", "(", "\"padding_left\"", ",", "0", ")", ">", "0", "or", "sample", ".", "get", "(", "\"padding_right\"", ",", "0", ")", ">", "0", ":", "\n", "\n", "            ", "if", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "2", "]", "!=", "shape", "[", "-", "2", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Currently only support for the `width` axis to be at the 2th position when padding. \"", "\n", "+", "\"When padding in left or right is present, you cannot crop in the phase-encoding direction!\"", "\n", ")", "\n", "\n", "", "padding_left", "=", "sample", "[", "\"padding_left\"", "]", "\n", "padding_right", "=", "sample", "[", "\"padding_right\"", "]", "\n", "\n", "sampling_mask", "[", ":", ",", ":", ",", ":", "padding_left", ",", ":", "]", "=", "0", "\n", "sampling_mask", "[", ":", ",", ":", ",", "padding_right", ":", ",", ":", "]", "=", "0", "\n", "\n", "# Shape (1, [slice], height, width, 1)", "\n", "", "sample", "[", "\"sampling_mask\"", "]", "=", "sampling_mask", "\n", "\n", "if", "self", ".", "return_acs", ":", "\n", "            ", "kspace_shape", "=", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "1", ":", "]", "\n", "sample", "[", "\"acs_mask\"", "]", "=", "self", ".", "mask_func", "(", "shape", "=", "kspace_shape", ",", "seed", "=", "seed", ",", "return_acs", "=", "True", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.ApplyMask.__init__": [[166, 170], ["direct.utils.DirectModule.__init__", "logging.getLogger", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`ApplyMask`.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.ApplyMask.__call__": [[171, 195], ["direct.data.transforms.apply_mask"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.apply_mask"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`ApplyMask`.\n\n        This assumes that a `sampling_mask` is present in the sample.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Dict sample containing key `kspace`.\n\n        Returns\n        -------\n        Dict[str, Any]\n            Sample with new key `masked_kspace`.\n        \"\"\"", "\n", "kspace", "=", "sample", "[", "\"kspace\"", "]", "\n", "\n", "assert", "\"sampling_mask\"", "in", "sample", ",", "\"Key 'sampling_mask' not found in sample.\"", "\n", "sampling_mask", "=", "sample", "[", "\"sampling_mask\"", "]", "\n", "\n", "masked_kspace", ",", "_", "=", "T", ".", "apply_mask", "(", "kspace", ",", "sampling_mask", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "masked_kspace", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.CropKspace.__init__": [[206, 262], ["direct.utils.DirectModule.__init__", "logging.getLogger", "isinstance", "ValueError", "functools.partial", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "crop", ":", "Union", "[", "str", ",", "Tuple", "[", "int", ",", "...", "]", ",", "List", "[", "int", "]", "]", ",", "\n", "forward_operator", ":", "Callable", "=", "T", ".", "fft2", ",", "\n", "backward_operator", ":", "Callable", "=", "T", ".", "ifft2", ",", "\n", "image_space_center_crop", ":", "bool", "=", "False", ",", "\n", "random_crop_sampler_type", ":", "Optional", "[", "str", "]", "=", "\"uniform\"", ",", "\n", "random_crop_sampler_use_seed", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "random_crop_sampler_gaussian_sigma", ":", "Optional", "[", "List", "[", "float", "]", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`CropKspace`.\n\n        Parameters\n        ----------\n        crop: tuple of ints or str\n            Shape to crop the input to or a string pointing to a crop key (e.g. `reconstruction_size`).\n        forward_operator: Callable\n            The forward operator, e.g. some form of FFT (centered or uncentered).\n            Default: :class:`direct.data.transforms.fft2`.\n        backward_operator: Callable\n            The backward operator, e.g. some form of inverse FFT (centered or uncentered).\n            Default: :class:`direct.data.transforms.ifft2`.\n        image_space_center_crop: bool\n            If set, the crop in the data will be taken in the center\n        random_crop_sampler_type: Optional[str]\n            If \"uniform\" the random cropping will be done by uniformly sampling `crop`, as opposed to `gaussian` which\n            will sample from a gaussian distribution. If `image_space_center_crop` is True, then this is ignored.\n            Default: \"uniform\".\n        random_crop_sampler_use_seed: bool\n            If true, a pseudo-random number based on the filename is computed so that every slice of the volume\n            is cropped the same way. Default: True.\n        random_crop_sampler_gaussian_sigma: Optional[List[float]]\n            Standard variance of the gaussian when `random_crop_sampler_type` is `gaussian`.\n            If `image_space_center_crop` is True, then this is ignored. Default: None.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n", "self", ".", "image_space_center_crop", "=", "image_space_center_crop", "\n", "\n", "if", "not", "(", "isinstance", "(", "crop", ",", "(", "Iterable", ",", "str", ")", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Invalid input for `crop`. Received {crop}. Can be a list of tuple of integers or a string.\"", "\n", ")", "\n", "", "self", ".", "crop", "=", "crop", "\n", "\n", "if", "image_space_center_crop", ":", "\n", "            ", "self", ".", "crop_func", "=", "T", ".", "complex_center_crop", "\n", "", "else", ":", "\n", "            ", "self", ".", "crop_func", "=", "functools", ".", "partial", "(", "\n", "T", ".", "complex_random_crop", ",", "sampler", "=", "random_crop_sampler_type", ",", "sigma", "=", "random_crop_sampler_gaussian_sigma", "\n", ")", "\n", "self", ".", "random_crop_sampler_use_seed", "=", "random_crop_sampler_use_seed", "\n", "\n", "", "self", ".", "forward_operator", "=", "forward_operator", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.CropKspace.__call__": [[263, 299], ["mri_transforms.CropKspace.backward_operator", "isinstance", "mri_transforms.CropKspace.crop_func", "mri_transforms.CropKspace.forward_operator", "tuple", "map", "str"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`CropKspace`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Dict sample containing key `kspace`.\n\n        Returns\n        -------\n        Dict[str, Any]\n            Cropped and masked sample.\n        \"\"\"", "\n", "\n", "kspace", "=", "sample", "[", "\"kspace\"", "]", "# shape (coil, height, width, complex=2)", "\n", "\n", "backprojected_kspace", "=", "self", ".", "backward_operator", "(", "kspace", ")", "# shape (coil, height, width, complex=2)", "\n", "\n", "if", "isinstance", "(", "self", ".", "crop", ",", "str", ")", ":", "\n", "            ", "assert", "self", ".", "crop", "in", "sample", ",", "f\"Not found {self.crop} key in sample.\"", "\n", "crop_shape", "=", "sample", "[", "self", ".", "crop", "]", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "crop_shape", "=", "self", ".", "crop", "\n", "\n", "", "cropper_args", "=", "{", "\"data_list\"", ":", "[", "backprojected_kspace", "]", ",", "\"crop_shape\"", ":", "crop_shape", ",", "\"contiguous\"", ":", "False", "}", "\n", "if", "not", "self", ".", "image_space_center_crop", ":", "\n", "            ", "cropper_args", "[", "\"seed\"", "]", "=", "(", "\n", "None", "if", "not", "self", ".", "random_crop_sampler_use_seed", "else", "tuple", "(", "map", "(", "ord", ",", "str", "(", "sample", "[", "\"filename\"", "]", ")", ")", ")", "\n", ")", "\n", "", "cropped_backprojected_kspace", "=", "self", ".", "crop_func", "(", "**", "cropper_args", ")", "\n", "\n", "# Compute new k-space for the cropped_backprojected_kspace", "\n", "# shape (coil, new_height, new_width, complex=2)", "\n", "sample", "[", "\"kspace\"", "]", "=", "self", ".", "forward_operator", "(", "cropped_backprojected_kspace", ")", "# The cropped kspace", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.ComputeImage.__init__": [[307, 333], ["direct.utils.DirectModule.__init__", "type_reconstruction.lower", "ValueError"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "kspace_key", ":", "str", ",", "target_key", ":", "str", ",", "backward_operator", ":", "Callable", ",", "type_reconstruction", ":", "str", "=", "\"complex\"", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`ComputeImage`.\n\n        Parameters\n        ----------\n        kspace_key: str\n            K-space key.\n        target_key: str\n            Target key.\n        backward_operator: callable\n            The backward operator, e.g. some form of inverse FFT (centered or uncentered).\n        type_reconstruction: str\n            Type of reconstruction. Can be 'complex', 'sense' or 'rss'. Default: 'complex'.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "kspace_key", "=", "kspace_key", "\n", "self", ".", "target_key", "=", "target_key", "\n", "\n", "self", ".", "type_reconstruction", "=", "type_reconstruction", "\n", "\n", "if", "type_reconstruction", ".", "lower", "(", ")", "not", "in", "[", "\"complex\"", ",", "\"sense\"", ",", "\"rss\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Only `complex`, `rss` and `sense` are possible choices for `reconstruction_type`. \"", "\n", "f\"Got {self.type_reconstruction}.\"", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.ComputeImage.__call__": [[336, 372], ["mri_transforms.ComputeImage.backward_operator", "mri_transforms.ComputeImage.sum", "mri_transforms.ComputeImage.type_reconstruction.lower", "direct.data.transforms.root_sum_of_squares", "direct.data.transforms.complex_multiplication().sum", "ValueError", "direct.data.transforms.complex_multiplication", "direct.data.transforms.conjugate"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate"], ["", "", "def", "__call__", "(", "\n", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ",", "coil_dim", ":", "int", "=", "0", ",", "spatial_dims", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "2", ")", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`ComputeImage`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Contains key kspace_key with value a torch.Tensor of shape (coil, *spatial_dims, complex=2).\n        coil_dim: int\n            Coil dimension. Default: 0.\n        spatial_dims: (int, int)\n            Spatial dimensions corresponding to (height, width). Default: (1, 2).\n\n        Returns\n        ----------\n        sample: dict\n            Contains key target_key with value a torch.Tensor of shape (*spatial_dims) or (*spatial_dims) if\n            type_reconstruction is 'rss'.\n        \"\"\"", "\n", "kspace_data", "=", "sample", "[", "self", ".", "kspace_key", "]", "\n", "\n", "# Get complex-valued data solution", "\n", "image", "=", "self", ".", "backward_operator", "(", "kspace_data", ",", "dim", "=", "spatial_dims", ")", "\n", "if", "self", ".", "type_reconstruction", "==", "\"complex\"", ":", "\n", "            ", "sample", "[", "self", ".", "target_key", "]", "=", "image", ".", "sum", "(", "coil_dim", ")", "\n", "", "elif", "self", ".", "type_reconstruction", ".", "lower", "(", ")", "==", "\"rss\"", ":", "\n", "            ", "sample", "[", "self", ".", "target_key", "]", "=", "T", ".", "root_sum_of_squares", "(", "image", ",", "dim", "=", "coil_dim", ")", "\n", "", "elif", "self", ".", "type_reconstruction", "==", "\"sense\"", ":", "\n", "            ", "if", "\"sensitivity_map\"", "not", "in", "sample", ":", "\n", "                ", "raise", "ValueError", "(", "\"Sensitivity map is required for SENSE reconstruction.\"", ")", "\n", "", "sample", "[", "self", ".", "target_key", "]", "=", "T", ".", "complex_multiplication", "(", "T", ".", "conjugate", "(", "sample", "[", "\"sensitivity_map\"", "]", ")", ",", "image", ")", ".", "sum", "(", "\n", "coil_dim", "\n", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.EstimateBodyCoilImage.__init__": [[377, 394], ["direct.utils.DirectModule.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "mask_func", ":", "Callable", ",", "backward_operator", ":", "Callable", ",", "use_seed", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`EstimateBodyCoilImage'.\n\n        Parameters\n        ----------\n        mask_func: Callable\n            A function which creates a sampling mask of the appropriate shape.\n        backward_operator: callable\n            The backward operator, e.g. some form of inverse FFT (centered or uncentered).\n        use_seed: bool\n            If true, a pseudo-random number based on the filename is computed so that every slice of the volume get\n            the same mask every time. Default: True.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mask_func", "=", "mask_func", "\n", "self", ".", "use_seed", "=", "use_seed", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.EstimateBodyCoilImage.__call__": [[395, 422], ["mri_transforms.EstimateBodyCoilImage.mask_func", "mri_transforms.EstimateBodyCoilImage.backward_operator", "direct.data.transforms.root_sum_of_squares", "tuple", "map", "str"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.DictionaryMaskFunc.mask_func", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ",", "coil_dim", ":", "int", "=", "0", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`EstimateBodyCoilImage`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Contains key kspace_key with value a torch.Tensor of shape (coil, ..., complex=2).\n        coil_dim: int\n            Coil dimension. Default: 0.\n\n        Returns\n        ----------\n        sample: Dict[str, Any]\n            Contains key `\"body_coil_image`.\n        \"\"\"", "\n", "kspace", "=", "sample", "[", "\"kspace\"", "]", "\n", "# We need to create an ACS mask based on the shape of this kspace, as it can be cropped.", "\n", "\n", "seed", "=", "None", "if", "not", "self", ".", "use_seed", "else", "tuple", "(", "map", "(", "ord", ",", "str", "(", "sample", "[", "\"filename\"", "]", ")", ")", ")", "\n", "kspace_shape", "=", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "1", ":", "]", "\n", "acs_mask", "=", "self", ".", "mask_func", "(", "shape", "=", "kspace_shape", ",", "seed", "=", "seed", ",", "return_acs", "=", "True", ")", "\n", "\n", "kspace", "=", "acs_mask", "*", "kspace", "+", "0.0", "\n", "acs_image", "=", "self", ".", "backward_operator", "(", "kspace", ")", "\n", "\n", "sample", "[", "\"body_coil_image\"", "]", "=", "T", ".", "root_sum_of_squares", "(", "acs_image", ",", "dim", "=", "coil_dim", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.EstimateSensitivityMap.__init__": [[430, 457], ["direct.utils.DirectModule.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "kspace_key", ":", "str", "=", "\"kspace\"", ",", "\n", "backward_operator", ":", "Callable", "=", "T", ".", "ifft2", ",", "\n", "type_of_map", ":", "Optional", "[", "str", "]", "=", "\"unit\"", ",", "\n", "gaussian_sigma", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Inits :class:`EstimateSensitivityMap`.\n\n        Parameters\n        ----------\n        kspace_key: str\n            K-space key. Default `kspace`.\n        backward_operator: callable\n            The backward operator, e.g. some form of inverse FFT (centered or uncentered).\n        type_of_map: str, optional\n            Type of map to estimate. Can be \"unit\" or \"rss_estimate\". Default: \"unit\".\n        gaussian_sigma: float, optional\n            If non-zero, acs_image well be calculated\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backward_operator", "=", "backward_operator", "\n", "self", ".", "kspace_key", "=", "kspace_key", "\n", "if", "type_of_map", "not", "in", "[", "\"unit\"", ",", "\"rss_estimate\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Expected type of map to be either `unit` or `rss_estimate`. Got {type_of_map}.\"", ")", "\n", "", "self", ".", "type_of_map", "=", "type_of_map", "\n", "self", ".", "gaussian_sigma", "=", "gaussian_sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.EstimateSensitivityMap.estimate_acs_image": [[458, 500], ["mri_transforms.EstimateSensitivityMap.backward_operator", "warnings.warn", "warnings.warn", "torch.linspace", "torch.exp", "torch.ones().int", "kspace_data.size", "gaussian_mask.reshape.reshape.reshape", "kspace_data.size", "tuple", "torch.ones", "len"], "methods", ["None"], ["", "def", "estimate_acs_image", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ",", "width_dim", ":", "int", "=", "-", "2", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Estimates the autocalibration (ACS) image by sampling the k-space using the ACS mask.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Sample dictionary,\n        width_dim: int\n            Dimension corresponding to width. Default: -2.\n\n        Returns\n        -------\n        acs_image: torch.Tensor\n            Estimate of the ACS image.\n        \"\"\"", "\n", "kspace_data", "=", "sample", "[", "self", ".", "kspace_key", "]", "# Shape (coil, [slice], height, width, complex=2)", "\n", "\n", "if", "kspace_data", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"Estimation of sensitivity map of Single-coil data. This warning will be displayed only once.\"", "\n", ")", "\n", "\n", "", "if", "\"sensitivity_map\"", "in", "sample", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"`sensitivity_map` is given, but will be overwritten. This warning will be displayed only once.\"", "\n", ")", "\n", "\n", "", "if", "self", ".", "gaussian_sigma", "==", "0", "or", "not", "self", ".", "gaussian_sigma", ":", "\n", "            ", "kspace_acs", "=", "kspace_data", "*", "sample", "[", "\"acs_mask\"", "]", "+", "0.0", "# + 0.0 removes the sign of zeros.", "\n", "", "else", ":", "\n", "            ", "gaussian_mask", "=", "torch", ".", "linspace", "(", "-", "1", ",", "1", ",", "kspace_data", ".", "size", "(", "width_dim", ")", ",", "dtype", "=", "kspace_data", ".", "dtype", ")", "\n", "gaussian_mask", "=", "torch", ".", "exp", "(", "-", "(", "(", "gaussian_mask", "/", "self", ".", "gaussian_sigma", ")", "**", "2", ")", ")", "\n", "gaussian_mask_shape", "=", "torch", ".", "ones", "(", "len", "(", "kspace_data", ".", "shape", ")", ")", ".", "int", "(", ")", "\n", "gaussian_mask_shape", "[", "width_dim", "]", "=", "kspace_data", ".", "size", "(", "width_dim", ")", "\n", "gaussian_mask", "=", "gaussian_mask", ".", "reshape", "(", "tuple", "(", "gaussian_mask_shape", ")", ")", "\n", "kspace_acs", "=", "kspace_data", "*", "sample", "[", "\"acs_mask\"", "]", "*", "gaussian_mask", "+", "0.0", "\n", "\n", "# Get complex-valued data solution", "\n", "# Shape (coil, [slice], height, width, complex=2)", "\n", "", "acs_image", "=", "self", ".", "backward_operator", "(", "kspace_acs", ")", "\n", "\n", "return", "acs_image", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.EstimateSensitivityMap.__call__": [[501, 537], ["torch.zeros().float", "direct.utils.asserts.assert_complex", "torch.zeros().float.to", "mri_transforms.EstimateSensitivityMap.estimate_acs_image", "direct.data.transforms.root_sum_of_squares", "acs_image_rss.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "direct.data.transforms.safe_divide", "torch.zeros", "acs_image_rss.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.EstimateSensitivityMap.estimate_acs_image", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.safe_divide"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ",", "coil_dim", ":", "int", "=", "0", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calculates sensitivity maps for the input sample.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Must contain key matching kspace_key with value a (complex) torch.Tensor\n            of shape (coil, height, width, complex=2).\n        coil_dim: int\n            Coil dimension. Default: 0.\n\n        Returns\n        -------\n        sample: Dict[str, Any]\n            Sample with key \"sensitivity_map\" with value the estimated sensitivity map.\n        \"\"\"", "\n", "if", "self", ".", "type_of_map", "==", "\"unit\"", ":", "\n", "            ", "kspace", "=", "sample", "[", "self", ".", "kspace_key", "]", "\n", "sensitivity_map", "=", "torch", ".", "zeros", "(", "kspace", ".", "shape", ")", ".", "float", "(", ")", "\n", "# Assumes complex channel is last", "\n", "assert_complex", "(", "kspace", ",", "complex_last", "=", "True", ")", "\n", "sensitivity_map", "[", "...", ",", "0", "]", "=", "1.0", "\n", "# Shape (coil, [slice], height, width, complex=2)", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "sensitivity_map", ".", "to", "(", "kspace", ".", "device", ")", "\n", "\n", "", "elif", "self", ".", "type_of_map", "==", "\"rss_estimate\"", ":", "\n", "# Shape (coil, [slice], height, width, complex=2)", "\n", "            ", "acs_image", "=", "self", ".", "estimate_acs_image", "(", "sample", ")", "\n", "# Shape ([slice], height, width)", "\n", "acs_image_rss", "=", "T", ".", "root_sum_of_squares", "(", "acs_image", ",", "dim", "=", "coil_dim", ")", "\n", "# Shape (1, [slice], height, width, 1)", "\n", "acs_image_rss", "=", "acs_image_rss", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# Shape (coil, [slice], height, width, complex=2)", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "T", ".", "safe_divide", "(", "acs_image", ",", "acs_image_rss", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.DeleteKeys.__init__": [[542, 552], ["direct.utils.DirectModule.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "keys", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "\"\"\"Inits :class:`DeleteKeys`.\n\n        Parameters\n        ----------\n        keys: List[str]\n            Key(s) to delete.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "keys", "=", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.DeleteKeys.__call__": [[553, 571], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`DeleteKeys`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Dictionary to look for keys and remove them.\n\n        Returns\n        -------\n        Dict[str, Any]\n            Dictionary with deleted specified keys.\n        \"\"\"", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "if", "key", "in", "sample", ":", "\n", "                ", "del", "sample", "[", "key", "]", "\n", "\n", "", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.PadCoilDimension.__init__": [[579, 595], ["direct.utils.DirectModule.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "pad_coils", ":", "Optional", "[", "int", "]", "=", "None", ",", "key", ":", "str", "=", "\"masked_kspace\"", ",", "coil_dim", ":", "int", "=", "0", ")", ":", "\n", "        ", "\"\"\"Inits :class:`PadCoilDimension`.\n\n        Parameters\n        ----------\n        pad_coils: int, optional\n            Number of coils to pad to. Default: None.\n        key: str\n            Key to pad in sample. Default: \"masked_kspace\".\n        coil_dim: int\n            Coil dimension along which the pad will be done. Default: 0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_coils", "=", "pad_coils", "\n", "self", ".", "key", "=", "key", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.PadCoilDimension.__call__": [[596, 634], ["list().copy", "max", "torch.zeros", "torch.cat", "ValueError", "list"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`PadCoilDimension`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Dictionary with key `self.key`.\n\n        Returns\n        -------\n        sample: Dict[str, Any]\n            Dictionary with padded coils of sample[self.key] if self.num_coils is not None.\n        \"\"\"", "\n", "if", "not", "self", ".", "num_coils", ":", "\n", "            ", "return", "sample", "\n", "\n", "", "if", "self", ".", "key", "not", "in", "sample", ":", "\n", "            ", "return", "sample", "\n", "\n", "", "data", "=", "sample", "[", "self", ".", "key", "]", "\n", "\n", "curr_num_coils", "=", "data", ".", "shape", "[", "self", ".", "coil_dim", "]", "\n", "if", "curr_num_coils", ">", "self", ".", "num_coils", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Tried to pad to {self.num_coils} coils, but already have {curr_num_coils} for \"", "\n", "f\"{sample['filename']}.\"", "\n", ")", "\n", "", "if", "curr_num_coils", "==", "self", ".", "num_coils", ":", "\n", "            ", "return", "sample", "\n", "\n", "", "shape", "=", "data", ".", "shape", "\n", "num_coils", "=", "shape", "[", "self", ".", "coil_dim", "]", "\n", "padding_data_shape", "=", "list", "(", "shape", ")", ".", "copy", "(", ")", "\n", "padding_data_shape", "[", "self", ".", "coil_dim", "]", "=", "max", "(", "self", ".", "num_coils", "-", "num_coils", ",", "0", ")", "\n", "zeros", "=", "torch", ".", "zeros", "(", "padding_data_shape", ",", "dtype", "=", "data", ".", "dtype", ")", "\n", "sample", "[", "self", ".", "key", "]", "=", "torch", ".", "cat", "(", "[", "zeros", ",", "data", "]", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.Normalize.__init__": [[639, 661], ["direct.utils.DirectModule.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "normalize_key", ":", "str", "=", "\"masked_kspace\"", ",", "percentile", ":", "Union", "[", "None", ",", "float", "]", "=", "0.99", ")", ":", "\n", "        ", "\"\"\"Inits :class:`Normalize`.\n\n        Parameters\n        ----------\n        normalize_key: str\n            Key name to compute the data for. If the maximum has to be computed on the ACS, ensure the reconstruction\n            on the ACS is available (typically `body_coil_image`). Default: \"masked_kspace\".\n        percentile: float or None\n            Rescale data with the given percentile. If None, the division is done by the maximum. Default: 0.99.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalize_key", "=", "normalize_key", "\n", "self", ".", "percentile", "=", "percentile", "\n", "\n", "self", ".", "_other_keys", "=", "[", "\n", "\"masked_kspace\"", ",", "\n", "\"target\"", ",", "\n", "\"kspace\"", ",", "\n", "\"body_coil_image\"", ",", "# sensitivity_map does not require normalization.", "\n", "\"initial_image\"", ",", "\n", "\"initial_kspace\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.Normalize.__call__": [[663, 701], ["sample.keys", "torch.kthvalue", "direct.data.transforms.modulus().max", "direct.data.transforms.modulus().view", "int", "direct.data.transforms.modulus", "direct.data.transforms.modulus", "tview.size"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`Normalize`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Sample to normalize with key \"masked_kspace\".\n\n        Returns\n        -------\n        sample: Dict[str, Any]\n            Sample with normalized values if their respective key is not in `self._other_keys`.\n        \"\"\"", "\n", "if", "self", ".", "normalize_key", "==", "\"scaling_factor\"", ":", "# This is a real-valued given number", "\n", "            ", "scaling_factor", "=", "sample", "[", "\"scaling_factor\"", "]", "\n", "", "elif", "not", "self", ".", "normalize_key", ":", "\n", "            ", "scaling_factor", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "data", "=", "sample", "[", "self", ".", "normalize_key", "]", "\n", "\n", "# Compute the maximum and scale the input", "\n", "if", "self", ".", "percentile", ":", "\n", "                ", "tview", "=", "-", "1.0", "*", "T", ".", "modulus", "(", "data", ")", ".", "view", "(", "-", "1", ")", "\n", "scaling_factor", ",", "_", "=", "torch", ".", "kthvalue", "(", "tview", ",", "int", "(", "(", "1", "-", "self", ".", "percentile", ")", "*", "tview", ".", "size", "(", ")", "[", "0", "]", ")", "+", "1", ")", "\n", "scaling_factor", "=", "-", "1.0", "*", "scaling_factor", "\n", "", "else", ":", "\n", "                ", "scaling_factor", "=", "T", ".", "modulus", "(", "data", ")", ".", "max", "(", ")", "\n", "\n", "# Normalize data", "\n", "", "", "if", "self", ".", "normalize_key", ":", "\n", "            ", "for", "key", "in", "sample", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "!=", "self", ".", "normalize_key", "and", "key", "not", "in", "self", ".", "_other_keys", ":", "\n", "                    ", "continue", "\n", "", "sample", "[", "key", "]", "=", "sample", "[", "key", "]", "/", "scaling_factor", "\n", "\n", "", "", "sample", "[", "\"scaling_diff\"", "]", "=", "0.0", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "scaling_factor", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.WhitenData.__init__": [[706, 719], ["direct.utils.DirectModule.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "self", ",", "epsilon", ":", "float", "=", "1e-10", ",", "key", ":", "str", "=", "\"complex_image\"", ")", ":", "\n", "        ", "\"\"\"Inits :class:`WhitenData`.\n\n        Parameters\n        ----------\n        epsilon: float\n            Default: 1e-10.\n        key: str\n            Key to whiten. Default: \"complex_image\".\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "key", "=", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.WhitenData.complex_whiten": [[720, 756], ["complex_image.mean", "real.nelement", "torch.Tensor", "torch.eig", "torch.matmul", "real.mul().sum", "real.mean().mul", "real.mul().sum", "real.mean().mul", "imag.mul().sum", "imag.mean().mul", "real.mean", "imag.mean", "imag.mean", "real.mul", "real.mean", "real.mul", "real.mean", "imag.mul", "imag.mean"], "methods", ["None"], ["", "def", "complex_whiten", "(", "self", ",", "complex_image", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Whiten complex image.\n\n        Parameters\n        ----------\n        complex_image: torch.Tensor\n            Complex image tensor to whiten.\n\n        Returns\n        -------\n        mean, std, whitened_image: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n        \"\"\"", "\n", "# From: https://github.com/facebookresearch/fastMRI", "\n", "#       blob/da1528585061dfbe2e91ebbe99a5d4841a5c3f43/banding_removal/fastmri/data/transforms.py#L464  # noqa", "\n", "real", "=", "complex_image", "[", "...", ",", "0", "]", "\n", "imag", "=", "complex_image", "[", "...", ",", "1", "]", "\n", "\n", "# Center around mean.", "\n", "mean", "=", "complex_image", ".", "mean", "(", ")", "\n", "centered_complex_image", "=", "complex_image", "-", "mean", "\n", "\n", "# Determine covariance between real and imaginary.", "\n", "n_elements", "=", "real", ".", "nelement", "(", ")", "\n", "real_real", "=", "(", "real", ".", "mul", "(", "real", ")", ".", "sum", "(", ")", "-", "real", ".", "mean", "(", ")", ".", "mul", "(", "real", ".", "mean", "(", ")", ")", ")", "/", "n_elements", "\n", "real_imag", "=", "(", "real", ".", "mul", "(", "imag", ")", ".", "sum", "(", ")", "-", "real", ".", "mean", "(", ")", ".", "mul", "(", "imag", ".", "mean", "(", ")", ")", ")", "/", "n_elements", "\n", "imag_imag", "=", "(", "imag", ".", "mul", "(", "imag", ")", ".", "sum", "(", ")", "-", "imag", ".", "mean", "(", ")", ".", "mul", "(", "imag", ".", "mean", "(", ")", ")", ")", "/", "n_elements", "\n", "eig_input", "=", "torch", ".", "Tensor", "(", "[", "[", "real_real", ",", "real_imag", "]", ",", "[", "real_imag", ",", "imag_imag", "]", "]", ")", "\n", "\n", "# Remove correlation by rotating around covariance eigenvectors.", "\n", "eig_values", ",", "eig_vecs", "=", "torch", ".", "eig", "(", "eig_input", ",", "eigenvectors", "=", "True", ")", "\n", "\n", "# Scale by eigenvalues for unit variance.", "\n", "std", "=", "(", "eig_values", "[", ":", ",", "0", "]", "+", "self", ".", "epsilon", ")", ".", "sqrt", "(", ")", "\n", "whitened_image", "=", "torch", ".", "matmul", "(", "centered_complex_image", ",", "eig_vecs", ")", "/", "std", "\n", "\n", "return", "mean", ",", "std", ",", "whitened_image", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.WhitenData.__call__": [[757, 773], ["mri_transforms.WhitenData.complex_whiten"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.WhitenData.complex_whiten"], ["", "def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`WhitenData`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n            Sample with key `key`.\n\n        Returns\n        -------\n        sample: Dict[str, Any]\n            Sample with value of `key` whitened.\n        \"\"\"", "\n", "_", ",", "_", ",", "whitened_image", "=", "self", ".", "complex_whiten", "(", "sample", "[", "self", ".", "key", "]", ")", "\n", "sample", "[", "self", ".", "key", "]", "=", "whitened_image", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.ToTensor.__call__": [[778, 826], ["direct.data.transforms.to_tensor().float", "ValueError", "direct.data.transforms.to_tensor().float", "direct.data.transforms.to_tensor().float", "direct.data.transforms.to_tensor().float", "torch.from_numpy().byte", "torch.from_numpy", "torch.tensor().float", "torch.from_numpy().float", "direct.data.transforms.to_tensor", "direct.data.transforms.to_tensor", "direct.data.transforms.to_tensor", "direct.data.transforms.to_tensor", "torch.from_numpy", "torch.tensor", "torch.from_numpy", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor"], ["def", "__call__", "(", "self", ",", "sample", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Calls :class:`ToTensor`.\n\n        Parameters\n        ----------\n        sample: Dict[str, Any]\n             Contains key 'kspace' with value a np.array of shape (coil, height, width) (2D)\n             or (coil, slice, height, width) (3D)\n\n        Returns\n        -------\n        sample: Dict[str, Any]\n             Contains key 'kspace' with value a torch.Tensor of shape (coil, height, width) (2D)\n             or (coil, slice, height, width) (3D)\n        \"\"\"", "\n", "\n", "ndim", "=", "sample", "[", "\"kspace\"", "]", ".", "ndim", "-", "1", "\n", "\n", "if", "ndim", "not", "in", "[", "2", ",", "3", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Can only cast 2D and 3D data (+coil) to tensor. Got {ndim}.\"", ")", "\n", "\n", "# Shape:    2D: (coil, height, width, complex=2), 3D: (coil, slice, height, width, complex=2)", "\n", "", "sample", "[", "\"kspace\"", "]", "=", "T", ".", "to_tensor", "(", "sample", "[", "\"kspace\"", "]", ")", ".", "float", "(", ")", "\n", "# Sensitivity maps are not necessarily available in the dataset.", "\n", "if", "\"initial_kspace\"", "in", "sample", ":", "\n", "# Shape:    2D: (coil, height, width, complex=2), 3D: (coil, slice, height, width, complex=2)", "\n", "            ", "sample", "[", "\"initial_kspace\"", "]", "=", "T", ".", "to_tensor", "(", "sample", "[", "\"initial_kspace\"", "]", ")", ".", "float", "(", ")", "\n", "", "if", "\"initial_image\"", "in", "sample", ":", "\n", "# Shape:    2D: (height, width), 3D: (slice, height, width)", "\n", "            ", "sample", "[", "\"initial_image\"", "]", "=", "T", ".", "to_tensor", "(", "sample", "[", "\"initial_image\"", "]", ")", ".", "float", "(", ")", "\n", "\n", "", "if", "\"sensitivity_map\"", "in", "sample", ":", "\n", "# Shape:    2D: (coil, height, width, complex=2), 3D: (coil, slice, height, width, complex=2)", "\n", "            ", "sample", "[", "\"sensitivity_map\"", "]", "=", "T", ".", "to_tensor", "(", "sample", "[", "\"sensitivity_map\"", "]", ")", ".", "float", "(", ")", "\n", "", "if", "\"target\"", "in", "sample", ":", "\n", "# Shape:    2D: (coil, height, width), 3D: (coil, slice, height, width)", "\n", "            ", "sample", "[", "\"target\"", "]", "=", "sample", "[", "\"target\"", "]", "\n", "", "if", "\"sampling_mask\"", "in", "sample", ":", "\n", "            ", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "sample", "[", "\"sampling_mask\"", "]", ")", ".", "byte", "(", ")", "\n", "", "if", "\"acs_mask\"", "in", "sample", ":", "\n", "            ", "sample", "[", "\"acs_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "sample", "[", "\"acs_mask\"", "]", ")", "\n", "", "if", "\"scaling_factor\"", "in", "sample", ":", "\n", "            ", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "sample", "[", "\"scaling_factor\"", "]", ")", ".", "float", "(", ")", "\n", "", "if", "\"loglikelihood_scaling\"", "in", "sample", ":", "\n", "# Shape: (coil, )", "\n", "            ", "sample", "[", "\"loglikelihood_scaling\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "sample", "[", "\"loglikelihood_scaling\"", "]", ")", ")", ".", "float", "(", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.build_mri_transforms": [[828, 934], ["mri_transforms.Compose", "mri_transforms.ToTensor", "mri_transforms.EstimateSensitivityMap", "mri_transforms.DeleteKeys", "mri_transforms.ComputeImage", "mri_transforms.ApplyMask", "mri_transforms.append", "mri_transforms.Normalize", "mri_transforms.PadCoilDimension", "mri_transforms.PadCoilDimension", "mri_transforms.DeleteKeys", "mri_transforms.CropKspace", "mri_transforms.CreateSamplingMask", "mri_transforms.EstimateBodyCoilImage", "isinstance"], "function", ["None"], ["", "", "def", "build_mri_transforms", "(", "\n", "forward_operator", ":", "Callable", ",", "\n", "backward_operator", ":", "Callable", ",", "\n", "mask_func", ":", "Optional", "[", "Callable", "]", ",", "\n", "crop", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", "=", "None", ",", "\n", "crop_type", ":", "Optional", "[", "str", "]", "=", "\"uniform\"", ",", "\n", "image_center_crop", ":", "bool", "=", "False", ",", "\n", "estimate_sensitivity_maps", ":", "bool", "=", "True", ",", "\n", "estimate_body_coil_image", ":", "bool", "=", "False", ",", "\n", "sensitivity_maps_gaussian", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "pad_coils", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "scaling_key", ":", "str", "=", "\"scaling_factor\"", ",", "\n", "use_seed", ":", "bool", "=", "True", ",", "\n", ")", "->", "object", ":", "\n", "    ", "\"\"\"Build transforms for MRI.\n\n    - Converts input to (complex-valued) tensor.\n    - Adds a sampling mask if `mask_func` is defined.\n    - Adds coil sensitivities and / or the body coil_image\n    - Crops the input data if needed and masks the fully sampled k-space.\n    - Add a target.\n    - Normalize input data.\n    - Pads the coil dimension.\n\n    Parameters\n    ----------\n    forward_operator: Callable\n        The forward operator, e.g. some form of FFT (centered or uncentered).\n    backward_operator: Callable\n        The backward operator, e.g. some form of inverse FFT (centered or uncentered).\n    mask_func: Callable or None\n        A function which creates a sampling mask of the appropriate shape.\n    crop: Tuple[int] or None\n    crop_type: Optional[str]\n        Type of cropping, either \"gaussian\" or \"uniform\". Default: \"uniform\".\n    image_center_crop: bool\n    estimate_sensitivity_maps: bool\n    estimate_body_coil_image: bool\n    sensitivity_maps_gaussian: float\n        Optional sigma for gaussian weighting of sensitivity map.\n    pad_coils: int\n        Number of coils to pad data to.\n    scaling_key: str\n    use_seed: bool\n        If true, a pseudo-random number based on the filename is computed so that every slice of the volume get\n        the same mask every time. Default: True.\n\n    Returns\n    -------\n    object: Callable\n        A transformation object.\n    \"\"\"", "\n", "# TODO: Use seed", "\n", "\n", "mri_transforms", ":", "List", "[", "Callable", "]", "=", "[", "ToTensor", "(", ")", "]", "\n", "if", "crop", ":", "\n", "        ", "mri_transforms", "+=", "[", "\n", "CropKspace", "(", "\n", "crop", "=", "crop", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "image_space_center_crop", "=", "image_center_crop", ",", "\n", "random_crop_sampler_type", "=", "crop_type", ",", "\n", "random_crop_sampler_use_seed", "=", "use_seed", ",", "\n", ")", "\n", "]", "\n", "", "if", "mask_func", ":", "\n", "        ", "mri_transforms", "+=", "[", "\n", "CreateSamplingMask", "(", "\n", "mask_func", ",", "\n", "shape", "=", "(", "None", "if", "(", "isinstance", "(", "crop", ",", "str", ")", ")", "else", "crop", ")", ",", "\n", "use_seed", "=", "use_seed", ",", "\n", "return_acs", "=", "estimate_sensitivity_maps", ",", "\n", ")", "\n", "]", "\n", "\n", "", "mri_transforms", "+=", "[", "\n", "EstimateSensitivityMap", "(", "\n", "kspace_key", "=", "\"kspace\"", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "type_of_map", "=", "\"unit\"", "if", "not", "estimate_sensitivity_maps", "else", "\"rss_estimate\"", ",", "\n", "gaussian_sigma", "=", "sensitivity_maps_gaussian", ",", "\n", ")", ",", "\n", "DeleteKeys", "(", "keys", "=", "[", "\"acs_mask\"", "]", ")", ",", "\n", "ComputeImage", "(", "\n", "kspace_key", "=", "\"kspace\"", ",", "\n", "target_key", "=", "\"target\"", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "type_reconstruction", "=", "\"rss\"", ",", "\n", ")", ",", "\n", "ApplyMask", "(", ")", ",", "\n", "]", "\n", "if", "estimate_body_coil_image", "and", "mask_func", "is", "not", "None", ":", "\n", "        ", "mri_transforms", ".", "append", "(", "EstimateBodyCoilImage", "(", "mask_func", ",", "backward_operator", "=", "backward_operator", ",", "use_seed", "=", "use_seed", ")", ")", "\n", "\n", "", "mri_transforms", "+=", "[", "\n", "Normalize", "(", "\n", "normalize_key", "=", "scaling_key", ",", "\n", "percentile", "=", "0.99", ",", "\n", ")", ",", "\n", "PadCoilDimension", "(", "pad_coils", "=", "pad_coils", ",", "key", "=", "\"masked_kspace\"", ")", ",", "\n", "PadCoilDimension", "(", "pad_coils", "=", "pad_coils", ",", "key", "=", "\"sensitivity_map\"", ")", ",", "\n", "DeleteKeys", "(", "keys", "=", "[", "\"kspace\"", "]", ")", ",", "\n", "]", "\n", "\n", "return", "Compose", "(", "mri_transforms", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.LRScheduler.__init__": [[29, 32], ["super().__init__", "logging.getLogger", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "optimizer", ",", "last_epoch", "=", "-", "1", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ",", "verbose", ")", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.LRScheduler.state_dict": [[33, 40], ["lr_scheduler.LRScheduler.__dict__.items"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the state of the scheduler as a :class:`dict`.\n\n        It contains an entry for every variable in self.__dict__ which is not the optimizer or logger.\n        \"\"\"", "\n", "state_dict", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "self", ".", "__dict__", ".", "items", "(", ")", "if", "key", "not", "in", "[", "\"optimizer\"", ",", "\"logger\"", "]", "}", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupMultiStepLR.__init__": [[43, 63], ["super().__init__", "ValueError", "list", "sorted"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "milestones", ":", "List", "[", "int", "]", ",", "\n", "gamma", ":", "float", "=", "0.1", ",", "\n", "warmup_factor", ":", "float", "=", "0.001", ",", "\n", "warmup_iterations", ":", "int", "=", "1000", ",", "\n", "warmup_method", ":", "str", "=", "\"linear\"", ",", "\n", "last_epoch", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "if", "not", "list", "(", "milestones", ")", "==", "sorted", "(", "milestones", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Milestones should be a list of\"", "\" increasing integers. Got {milestones}\"", ",", "\n", ")", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iterations", "=", "warmup_iterations", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupMultiStepLR.get_lr": [[64, 74], ["lr_scheduler._get_warmup_factor_at_iter", "bisect.bisect_right"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler._get_warmup_factor_at_iter"], ["", "def", "get_lr", "(", "self", ")", "->", "List", "[", "float", "]", ":", "# type: ignore", "\n", "        ", "warmup_factor", "=", "_get_warmup_factor_at_iter", "(", "\n", "self", ".", "warmup_method", ",", "\n", "self", ".", "last_epoch", ",", "# type: ignore", "\n", "self", ".", "warmup_iterations", ",", "\n", "self", ".", "warmup_factor", ",", "\n", ")", "\n", "return", "[", "\n", "base_lr", "*", "warmup_factor", "*", "self", ".", "gamma", "**", "bisect_right", "(", "self", ".", "milestones", ",", "self", ".", "last_epoch", ")", "# type: ignore", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupMultiStepLR._compute_values": [[76, 79], ["lr_scheduler.WarmupMultiStepLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupCosineLR.get_lr"], ["", "def", "_compute_values", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "# The new interface", "\n", "        ", "return", "self", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupCosineLR.__init__": [[82, 96], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "max_iters", ":", "int", ",", "\n", "warmup_factor", ":", "float", "=", "0.001", ",", "\n", "warmup_iterations", ":", "int", "=", "1000", ",", "\n", "warmup_method", ":", "str", "=", "\"linear\"", ",", "\n", "last_epoch", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "self", ".", "max_iters", "=", "max_iters", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iterations", "=", "warmup_iterations", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupCosineLR.get_lr": [[97, 112], ["lr_scheduler._get_warmup_factor_at_iter", "math.cos"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler._get_warmup_factor_at_iter"], ["", "def", "get_lr", "(", "self", ")", "->", "List", "[", "float", "]", ":", "# type: ignore", "\n", "        ", "warmup_factor", "=", "_get_warmup_factor_at_iter", "(", "\n", "self", ".", "warmup_method", ",", "\n", "self", ".", "last_epoch", ",", "# type: ignore", "\n", "self", ".", "warmup_iterations", ",", "\n", "self", ".", "warmup_factor", ",", "\n", ")", "\n", "# Different definitions of half-cosine with warmup are possible. For", "\n", "# simplicity we multiply the standard half-cosine schedule by the warmup", "\n", "# factor. An alternative is to start the period of the cosine at warmup_iterations", "\n", "# instead of at 0. In the case that warmup_iterations << max_iters the two are", "\n", "# very close to each other.", "\n", "return", "[", "\n", "base_lr", "*", "warmup_factor", "*", "0.5", "*", "(", "1.0", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "self", ".", "last_epoch", "/", "self", ".", "max_iters", ")", ")", "# type: ignore", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "# type: ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupCosineLR._compute_values": [[114, 117], ["lr_scheduler.WarmupCosineLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupCosineLR.get_lr"], ["", "def", "_compute_values", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "# The new interface", "\n", "        ", "return", "self", ".", "get_lr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler._get_warmup_factor_at_iter": [[119, 146], ["ValueError"], "function", ["None"], ["", "", "def", "_get_warmup_factor_at_iter", "(", "method", ":", "str", ",", "curr_iter", ":", "int", ",", "warmup_iters", ":", "int", ",", "warmup_factor", ":", "float", ")", "->", "float", ":", "\n", "    ", "\"\"\"Return the learning rate warmup factor at a specific iteration.\n\n    Parameters\n    ----------\n    method: str\n        Warmup method; either \"constant\" or \"linear\".\n    curr_iter: int\n        Iteration at which to calculate the warmup factor.\n    warmup_iters: int\n        The length of the warmup phases.\n    warmup_factor: float\n        The base warmup factor (the meaning changes according to the method used).\n\n    Returns\n    -------\n    float: The effective warmup factor at the given iteration.\n    \"\"\"", "\n", "if", "curr_iter", ">=", "warmup_iters", ":", "\n", "        ", "return", "1.0", "\n", "\n", "", "if", "method", "==", "\"constant\"", ":", "\n", "        ", "return", "warmup_factor", "\n", "", "if", "method", "==", "\"linear\"", ":", "\n", "        ", "alpha", "=", "curr_iter", "/", "warmup_iters", "\n", "return", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "", "raise", "ValueError", "(", "f\"Unknown warmup method: {method}\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.__init__": [[22, 145], ["logging.getLogger", "pathlib.Path", "h5_data.H5SliceData.parse_filenames_data", "direct.utils.cast_as_path", "h5_data.H5SliceData.logger.info", "len", "h5_data.H5SliceData.logger.warning", "h5_data.H5SliceData.logger.info", "h5_data.H5SliceData.logger.info", "type", "direct.utils.dataset.get_filenames_for_datasets", "h5_data.H5SliceData.logger.info", "h5_data.H5SliceData.logger.info", "list", "len", "len", "h5_data.H5SliceData.logger.error", "ValueError", "len", "h5_data.H5SliceData.root.glob", "re.match", "str"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset.parse_filenames_data", "home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.cast_as_path", "home.repos.pwc.inspect_result.directgroup_direct.utils.dataset.get_filenames_for_datasets"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "pathlib", ".", "Path", ",", "\n", "filenames_filter", ":", "Union", "[", "List", "[", "PathOrString", "]", ",", "None", "]", "=", "None", ",", "\n", "filenames_lists", ":", "Union", "[", "List", "[", "PathOrString", "]", ",", "None", "]", "=", "None", ",", "\n", "filenames_lists_root", ":", "Union", "[", "PathOrString", ",", "None", "]", "=", "None", ",", "\n", "regex_filter", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "dataset_description", ":", "Optional", "[", "Dict", "[", "PathOrString", ",", "Any", "]", "]", "=", "None", ",", "\n", "metadata", ":", "Optional", "[", "Dict", "[", "PathOrString", ",", "Dict", "]", "]", "=", "None", ",", "\n", "sensitivity_maps", ":", "Optional", "[", "PathOrString", "]", "=", "None", ",", "\n", "extra_keys", ":", "Optional", "[", "Tuple", "]", "=", "None", ",", "\n", "pass_attrs", ":", "bool", "=", "False", ",", "\n", "text_description", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "kspace_context", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "pass_dictionaries", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "]", "]", "=", "None", ",", "\n", "pass_h5s", ":", "Optional", "[", "Dict", "[", "str", ",", "List", "]", "]", "=", "None", ",", "\n", "slice_data", ":", "Optional", "[", "slice", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Initialize the dataset.\n\n        Parameters\n        ----------\n        root: pathlib.Path\n            Root directory to data.\n        filenames_filter: Union[List[PathOrString], None]\n            List of filenames to include in the dataset, should be the same as the ones that can be derived from a glob\n            on the root. If set, will skip searching for files in the root. Default: None.\n        filenames_lists: Union[List[PathOrString], None]\n            List of paths pointing to `.lst` file(s) that contain file-names in `root` to filter.\n            Should be the same as the ones that can be derived from a glob on the root. If this is set,\n            this will override the `filenames_filter` option if not None. Defualt: None.\n        filenames_lists_root: Union[PathOrString, None]\n            Root of `filenames_lists`. Ignored if `filename_lists` is None. Default: None.\n        regex_filter: str\n            Regular expression filter on the absolute filename. Will be applied after any filenames filter.\n        metadata: dict\n            If given, this dictionary will be passed to the output transform.\n        sensitivity_maps: [pathlib.Path, None]\n            Path to sensitivity maps, or None.\n        extra_keys: Tuple\n            Add extra keys in h5 file to output.\n        pass_attrs: bool\n            Pass the attributes saved in the h5 file.\n        text_description: str\n            Description of dataset, can be useful for logging.\n        pass_dictionaries: dict\n            Pass a dictionary of dictionaries, e.g. if {\"name\": {\"filename_0\": val}}, then to `filename_0`s sample dict,\n            a key with name `name` and value `val` will be added.\n        pass_h5s: dict\n            Pass a dictionary of paths. If {\"name\": path} is given then to the sample of `filename` the same slice\n            of path / filename will be added to the sample dictionary and will be asigned key `name`. This can first\n            instance be convenient when you want to pass sensitivity maps as well. So for instance:\n\n            >>> pass_h5s = {\"sensitivity_map\": \"/data/sensitivity_maps\"}\n\n            will add to each output sample a key `sensitivity_map` with value a numpy array containing the same slice\n            of /data/sensitivity_maps/filename.h5 as the one of the original filename filename.h5.\n        slice_data : Optional[slice]\n            If set, for instance to slice(50,-50) only data within this slide will be added to the dataset. This\n            is for instance convenient in the validation set of the public Calgary-Campinas dataset as the first 50\n            and last 50 slices are excluded in the evaluation.\n        \"\"\"", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n", "self", ".", "root", "=", "pathlib", ".", "Path", "(", "root", ")", "\n", "self", ".", "filenames_filter", "=", "filenames_filter", "\n", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n", "self", ".", "dataset_description", "=", "dataset_description", "\n", "self", ".", "text_description", "=", "text_description", "\n", "\n", "self", ".", "data", ":", "List", "[", "Tuple", "]", "=", "[", "]", "\n", "\n", "self", ".", "volume_indices", ":", "Dict", "[", "pathlib", ".", "Path", ",", "range", "]", "=", "{", "}", "\n", "\n", "# If filenames_filter and filenames_lists are given, it will load files in filenames_filter", "\n", "# and filenames_lists will be ignored.", "\n", "if", "filenames_filter", "is", "None", ":", "\n", "            ", "if", "filenames_lists", "is", "not", "None", ":", "\n", "                ", "if", "filenames_lists_root", "is", "None", ":", "\n", "                    ", "e", "=", "\"`filenames_lists` is passed but `filenames_lists_root` is None.\"", "\n", "self", ".", "logger", ".", "error", "(", "e", ")", "\n", "raise", "ValueError", "(", "e", ")", "\n", "", "filenames", "=", "get_filenames_for_datasets", "(", "\n", "lists", "=", "filenames_lists", ",", "files_root", "=", "filenames_lists_root", ",", "data_root", "=", "root", "\n", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Attempting to load %s filenames from list(s).\"", ",", "len", "(", "filenames", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\"Parsing directory %s for h5 files.\"", ",", "self", ".", "root", ")", "\n", "filenames", "=", "list", "(", "self", ".", "root", ".", "glob", "(", "\"*.h5\"", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Attempting to load %s filenames.\"", ",", "len", "(", "filenames_filter", ")", ")", "\n", "filenames", "=", "filenames_filter", "\n", "\n", "", "if", "regex_filter", ":", "\n", "            ", "filenames", "=", "[", "_", "for", "_", "in", "filenames", "if", "re", ".", "match", "(", "regex_filter", ",", "str", "(", "_", ")", ")", "]", "\n", "\n", "", "if", "len", "(", "filenames", ")", "==", "0", ":", "\n", "            ", "warn", "=", "(", "\n", "f\"Found 0 h5 files in directory {self.root}.\"", "\n", "if", "not", "self", ".", "text_description", "\n", "else", "f\"Found 0 h5 files in directory {self.root} for dataset {self.text_description}.\"", "\n", ")", "\n", "self", ".", "logger", ".", "warning", "(", "warn", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Using %s h5 files in %s.\"", ",", "len", "(", "filenames", ")", ",", "self", ".", "root", ")", "\n", "\n", "", "self", ".", "parse_filenames_data", "(", "\n", "filenames", ",", "extra_h5s", "=", "pass_h5s", ",", "filter_slice", "=", "slice_data", "\n", ")", "# Collect information on the image masks_dict.", "\n", "self", ".", "pass_h5s", "=", "pass_h5s", "\n", "\n", "self", ".", "sensitivity_maps", "=", "cast_as_path", "(", "sensitivity_maps", ")", "\n", "self", ".", "pass_attrs", "=", "pass_attrs", "\n", "self", ".", "extra_keys", "=", "extra_keys", "\n", "self", ".", "pass_dictionaries", "=", "pass_dictionaries", "\n", "\n", "self", ".", "kspace_context", "=", "kspace_context", "if", "kspace_context", "else", "0", "\n", "self", ".", "ndim", "=", "2", "if", "self", ".", "kspace_context", "==", "0", "else", "3", "\n", "\n", "if", "self", ".", "text_description", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Dataset description: %s.\"", ",", "self", ".", "text_description", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.parse_filenames_data": [[146, 175], ["enumerate", "range", "h5_data.H5SliceData.logger.info", "h5_data.H5SliceData.verify_extra_h5_integrity", "isinstance", "len", "len", "h5_data.H5SliceData.logger.warning", "range", "len", "h5py.File", "range", "len", "filter_slice.indices", "range", "len"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.verify_extra_h5_integrity"], ["", "", "def", "parse_filenames_data", "(", "self", ",", "filenames", ",", "extra_h5s", "=", "None", ",", "filter_slice", "=", "None", ")", ":", "\n", "        ", "current_slice_number", "=", "0", "# This is required to keep track of where a volume is in the dataset", "\n", "\n", "for", "idx", ",", "filename", "in", "enumerate", "(", "filenames", ")", ":", "\n", "            ", "if", "len", "(", "filenames", ")", "<", "5", "or", "idx", "%", "(", "len", "(", "filenames", ")", "//", "5", ")", "==", "0", "or", "len", "(", "filenames", ")", "==", "(", "idx", "+", "1", ")", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "f\"Parsing: {(idx + 1) / len(filenames) * 100:.2f}%.\"", ")", "\n", "", "try", ":", "\n", "                ", "kspace_shape", "=", "h5py", ".", "File", "(", "filename", ",", "\"r\"", ")", "[", "\"kspace\"", "]", ".", "shape", "# pylint: disable = E1101", "\n", "self", ".", "verify_extra_h5_integrity", "(", "filename", ",", "kspace_shape", ",", "extra_h5s", "=", "extra_h5s", ")", "# pylint: disable = E1101", "\n", "\n", "", "except", "OSError", "as", "exc", ":", "\n", "                ", "self", ".", "logger", ".", "warning", "(", "\"%s failed with OSError: %s. Skipping...\"", ",", "filename", ",", "exc", ")", "\n", "continue", "\n", "\n", "", "num_slices", "=", "kspace_shape", "[", "0", "]", "\n", "if", "not", "filter_slice", ":", "\n", "                ", "self", ".", "data", "+=", "[", "(", "filename", ",", "_", ")", "for", "_", "in", "range", "(", "num_slices", ")", "]", "\n", "\n", "", "elif", "isinstance", "(", "filter_slice", ",", "slice", ")", ":", "\n", "                ", "admissible_indices", "=", "range", "(", "*", "filter_slice", ".", "indices", "(", "num_slices", ")", ")", "\n", "self", ".", "data", "+=", "[", "(", "filename", ",", "_", ")", "for", "_", "in", "range", "(", "num_slices", ")", "if", "_", "in", "admissible_indices", "]", "\n", "num_slices", "=", "len", "(", "admissible_indices", ")", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "volume_indices", "[", "filename", "]", "=", "range", "(", "current_slice_number", ",", "current_slice_number", "+", "num_slices", ")", "\n", "\n", "current_slice_number", "+=", "num_slices", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.verify_extra_h5_integrity": [[176, 191], ["h5py.File", "ValueError"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "verify_extra_h5_integrity", "(", "image_fn", ",", "_", ",", "extra_h5s", ")", ":", "\n", "# TODO: This function is not doing much right now, and can be removed or should be refactored to something else", "\n", "# TODO: For instance a `direct verify-dataset`?", "\n", "        ", "if", "not", "extra_h5s", ":", "\n", "            ", "return", "\n", "\n", "", "for", "key", "in", "extra_h5s", ":", "\n", "            ", "h5_key", ",", "path", "=", "extra_h5s", "[", "key", "]", "\n", "extra_fn", "=", "path", "/", "image_fn", ".", "name", "\n", "try", ":", "\n", "                ", "with", "h5py", ".", "File", "(", "extra_fn", ",", "\"r\"", ")", "as", "file", ":", "\n", "                    ", "_", "=", "file", "[", "h5_key", "]", ".", "shape", "\n", "", "", "except", "(", "OSError", ",", "TypeError", ")", "as", "exc", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Reading of {extra_fn} for key {h5_key} failed: {exc}.\"", ")", "from", "exc", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.__len__": [[197, 199], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.__getitem__": [[200, 239], ["pathlib.Path", "h5_data.H5SliceData.get_slice_data", "sample.update", "str", "h5_data.H5SliceData.get_slice_data", "h5_data.H5SliceData.pass_h5s.items", "h5_data.H5SliceData.get_slice_data", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.get_slice_data", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.get_slice_data", "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.get_slice_data"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "filename", ",", "slice_no", "=", "self", ".", "data", "[", "idx", "]", "\n", "filename", "=", "pathlib", ".", "Path", "(", "filename", ")", "\n", "metadata", "=", "None", "if", "not", "self", ".", "metadata", "else", "self", ".", "metadata", "[", "filename", ".", "name", "]", "\n", "\n", "kspace", ",", "extra_data", "=", "self", ".", "get_slice_data", "(", "\n", "filename", ",", "slice_no", ",", "pass_attrs", "=", "self", ".", "pass_attrs", ",", "extra_keys", "=", "self", ".", "extra_keys", "\n", ")", "\n", "\n", "if", "kspace", ".", "ndim", "==", "2", ":", "# Singlecoil data does not always have coils at the first axis.", "\n", "            ", "kspace", "=", "kspace", "[", "np", ".", "newaxis", ",", "...", "]", "\n", "\n", "# TODO: Write a custom collate function which disables batching for certain keys", "\n", "", "sample", "=", "{", "\"kspace\"", ":", "kspace", ",", "\"filename\"", ":", "str", "(", "filename", ")", ",", "\"slice_no\"", ":", "slice_no", "}", "\n", "\n", "# If the sensitivity maps exist, load these", "\n", "if", "self", ".", "sensitivity_maps", ":", "\n", "            ", "sensitivity_map", ",", "_", "=", "self", ".", "get_slice_data", "(", "self", ".", "sensitivity_maps", "/", "filename", ".", "name", ",", "slice_no", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "sensitivity_map", "\n", "\n", "", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "sample", "[", "\"metadata\"", "]", "=", "metadata", "\n", "\n", "", "sample", ".", "update", "(", "extra_data", ")", "\n", "\n", "if", "self", ".", "pass_dictionaries", ":", "\n", "            ", "for", "key", "in", "self", ".", "pass_dictionaries", ":", "\n", "                ", "if", "key", "in", "sample", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Trying to add key {key} to sample dict, but this key already exists.\"", ")", "\n", "", "sample", "[", "key", "]", "=", "self", ".", "pass_dictionaries", "[", "key", "]", "[", "filename", ".", "name", "]", "\n", "\n", "", "", "if", "self", ".", "pass_h5s", ":", "\n", "            ", "for", "key", ",", "(", "h5_key", ",", "path", ")", "in", "self", ".", "pass_h5s", ".", "items", "(", ")", ":", "\n", "                ", "curr_slice", ",", "_", "=", "self", ".", "get_slice_data", "(", "path", "/", "filename", ".", "name", ",", "slice_no", ",", "key", "=", "h5_key", ")", "\n", "if", "key", "in", "sample", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Trying to add key {key} to sample dict, but this key already exists.\"", ")", "\n", "", "sample", "[", "key", "]", "=", "curr_slice", "\n", "\n", "", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.get_slice_data": [[240, 287], ["h5py.File.close", "filename.exists", "OSError", "h5py.File", "h5_data.H5SliceData.get_num_slices", "numpy.swapaxes", "dict", "Exception", "list().copy", "numpy.concatenate", "list().copy", "numpy.concatenate", "ValueError", "max", "min", "list", "numpy.zeros", "list", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close", "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.get_num_slices"], ["", "def", "get_slice_data", "(", "self", ",", "filename", ",", "slice_no", ",", "key", "=", "\"kspace\"", ",", "pass_attrs", "=", "False", ",", "extra_keys", "=", "None", ")", ":", "\n", "        ", "extra_data", "=", "{", "}", "\n", "if", "not", "filename", ".", "exists", "(", ")", ":", "\n", "            ", "raise", "OSError", "(", "f\"{filename} does not exist.\"", ")", "\n", "\n", "", "try", ":", "\n", "            ", "data", "=", "h5py", ".", "File", "(", "filename", ",", "\"r\"", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "f\"Reading filename {filename} caused exception: {e}\"", ")", "\n", "\n", "", "if", "self", ".", "kspace_context", "==", "0", ":", "\n", "            ", "curr_data", "=", "data", "[", "key", "]", "[", "slice_no", "]", "\n", "", "else", ":", "\n", "# This can be useful for getting stacks of slices.", "\n", "            ", "num_slices", "=", "self", ".", "get_num_slices", "(", "filename", ")", "\n", "curr_data", "=", "data", "[", "key", "]", "[", "\n", "max", "(", "0", ",", "slice_no", "-", "self", ".", "kspace_context", ")", ":", "min", "(", "slice_no", "+", "self", ".", "kspace_context", "+", "1", ",", "num_slices", ")", ",", "\n", "]", "\n", "curr_shape", "=", "curr_data", ".", "shape", "\n", "if", "curr_shape", "[", "0", "]", "<", "num_slices", "-", "1", ":", "\n", "                ", "if", "slice_no", "-", "self", ".", "kspace_context", "<", "0", ":", "\n", "                    ", "new_shape", "=", "list", "(", "curr_shape", ")", ".", "copy", "(", ")", "\n", "new_shape", "[", "0", "]", "=", "self", ".", "kspace_context", "-", "slice_no", "\n", "curr_data", "=", "np", ".", "concatenate", "(", "\n", "[", "np", ".", "zeros", "(", "new_shape", ",", "dtype", "=", "curr_data", ".", "dtype", ")", ",", "curr_data", "]", ",", "\n", "axis", "=", "0", ",", "\n", ")", "\n", "", "if", "self", ".", "kspace_context", "+", "slice_no", ">", "num_slices", "-", "1", ":", "\n", "                    ", "new_shape", "=", "list", "(", "curr_shape", ")", ".", "copy", "(", ")", "\n", "new_shape", "[", "0", "]", "=", "slice_no", "+", "self", ".", "kspace_context", "-", "num_slices", "+", "1", "\n", "curr_data", "=", "np", ".", "concatenate", "(", "\n", "[", "curr_data", ",", "np", ".", "zeros", "(", "new_shape", ",", "dtype", "=", "curr_data", ".", "dtype", ")", "]", ",", "\n", "axis", "=", "0", ",", "\n", ")", "\n", "# Move the depth axis to the second spot.", "\n", "", "", "curr_data", "=", "np", ".", "swapaxes", "(", "curr_data", ",", "0", ",", "1", ")", "\n", "\n", "", "if", "pass_attrs", ":", "\n", "            ", "extra_data", "[", "\"attrs\"", "]", "=", "dict", "(", "data", ".", "attrs", ")", "\n", "\n", "", "if", "extra_keys", ":", "\n", "            ", "for", "extra_key", "in", "self", ".", "extra_keys", ":", "\n", "                ", "if", "extra_key", "==", "\"attrs\"", ":", "\n", "                    ", "raise", "ValueError", "(", "\"attrs need to be passed by setting `pass_attrs = True`.\"", ")", "\n", "", "extra_data", "[", "extra_key", "]", "=", "data", "[", "extra_key", "]", "[", "(", ")", "]", "\n", "", "", "data", ".", "close", "(", ")", "\n", "return", "curr_data", ",", "extra_data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.h5_data.H5SliceData.get_num_slices": [[288, 291], ["None"], "methods", ["None"], ["", "def", "get_num_slices", "(", "self", ",", "filename", ")", ":", "\n", "        ", "num_slices", "=", "self", ".", "volume_indices", "[", "filename", "]", ".", "stop", "-", "self", ".", "volume_indices", "[", "filename", "]", ".", "start", "\n", "return", "num_slices", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset.__init__": [[88, 167], ["logging.getLogger", "direct.data.fake.FakeMRIData", "numpy.random.RandomState", "len", "NotImplementedError", "datasets.FakeMRIBlobsDataset.logger.info", "datasets.temp_seed", "NotImplementedError", "type", "len", "kwargs.get", "kwargs.get", "zip", "range", "datasets.FakeMRIBlobsDataset.parse_filenames_data", "list", "datasets.FakeMRIBlobsDataset.rng.choice", "len", "range", "int"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.temp_seed", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset.parse_filenames_data"], ["def", "__init__", "(", "\n", "self", ",", "\n", "sample_size", ":", "int", ",", "\n", "num_coils", ":", "int", ",", "\n", "spatial_shape", ":", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", "]", "]", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "filenames", ":", "Optional", "[", "Union", "[", "List", "[", "str", "]", ",", "str", "]", "]", "=", "None", ",", "\n", "pass_attrs", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "text_description", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "kspace_context", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Dataset initialisation.\n\n        Parameters\n        ----------\n        sample_size: int\n            Size of the dataset.\n        num_coils: int\n            Number of coils for the fake k-space data.\n        spatial_shape: List or Tuple of ints.\n            Shape of the reconstructed fake data. Should be (height, width) or (slice, height, width), corresponding\n            to ndim = 2 and ndim = 3.\n        transform: Optional[Callable]\n            A list of transforms to be performed on the generated samples. Default is None.\n        seed: int\n            Seed. Default is None.\n        filenames: List of strings or string.\n            Names for the generated samples. If string is given, a number order starting from \"00001\" is appended\n            to the name of each sample.\n        pass_attrs: bool\n            Pass the attributes of the generated sample.\n        text_description: str\n            Description of dataset, can be useful for logging.\n        kspace_context: bool\n            If true corresponds to 3D reconstruction, else reconstruction is 2D.\n        \"\"\"", "\n", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n", "if", "len", "(", "spatial_shape", ")", "not", "in", "[", "2", ",", "3", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"Currently FakeDataset is implemented only for 2D or 3D data. \"", "\n", "f\"Spatial shape must have 2 or 3 dimensions. Got shape {spatial_shape}.\"", "\n", ")", "\n", "", "self", ".", "sample_size", "=", "sample_size", "\n", "self", ".", "num_coils", "=", "num_coils", "\n", "self", ".", "spatial_shape", "=", "spatial_shape", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "pass_attrs", "=", "pass_attrs", "if", "pass_attrs", "is", "not", "None", "else", "True", "\n", "self", ".", "text_description", "=", "text_description", "\n", "if", "self", ".", "text_description", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Dataset description: %s.\"", ",", "self", ".", "text_description", ")", "\n", "\n", "", "self", ".", "fake_data", ":", "Callable", "=", "FakeMRIData", "(", "\n", "ndim", "=", "len", "(", "self", ".", "spatial_shape", ")", ",", "\n", "blobs_n_samples", "=", "kwargs", ".", "get", "(", "\"blobs_n_samples\"", ",", "None", ")", ",", "\n", "blobs_cluster_std", "=", "kwargs", ".", "get", "(", "\"blobs_cluster_std\"", ",", "None", ")", ",", "\n", ")", "\n", "self", ".", "volume_indices", ":", "Dict", "[", "str", ",", "range", "]", "=", "{", "}", "\n", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "# size = sample_size * num_slices if data is 3D", "\n", "            ", "self", ".", "data", "=", "[", "\n", "(", "filename", ",", "slice_no", ",", "seed", ")", "\n", "for", "(", "filename", ",", "seed", ")", "in", "zip", "(", "\n", "self", ".", "parse_filenames_data", "(", "filenames", ")", ",", "\n", "list", "(", "self", ".", "rng", ".", "choice", "(", "a", "=", "range", "(", "int", "(", "1e5", ")", ")", ",", "size", "=", "self", ".", "sample_size", ",", "replace", "=", "False", ")", ")", ",", "\n", ")", "# ensure reproducibility", "\n", "for", "slice_no", "in", "range", "(", "self", ".", "spatial_shape", "[", "0", "]", "if", "len", "(", "spatial_shape", ")", "==", "3", "else", "1", ")", "\n", "]", "\n", "", "self", ".", "kspace_context", "=", "kspace_context", "if", "kspace_context", "else", "0", "\n", "self", ".", "ndim", "=", "2", "if", "self", ".", "kspace_context", "==", "0", "else", "3", "\n", "\n", "if", "self", ".", "kspace_context", "!=", "0", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"3D reconstruction is not yet supported with FakeMRIBlobsDataset.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset.parse_filenames_data": [[168, 191], ["isinstance", "enumerate", "len", "range", "datasets.FakeMRIBlobsDataset.logger.info", "range", "len", "len", "len", "pathlib.PosixPath", "len", "len"], "methods", ["None"], ["", "", "def", "parse_filenames_data", "(", "self", ",", "filenames", ")", ":", "\n", "        ", "if", "filenames", "is", "None", ":", "\n", "            ", "filenames", "=", "[", "\"sample\"", "]", "\n", "\n", "", "if", "isinstance", "(", "filenames", ",", "str", ")", ":", "\n", "            ", "filenames", "=", "[", "filenames", "]", "\n", "\n", "", "if", "len", "(", "filenames", ")", "!=", "self", ".", "sample_size", ":", "\n", "            ", "filenames", "=", "[", "filenames", "[", "0", "]", "+", "f\"{_:05}\"", "for", "_", "in", "range", "(", "1", ",", "self", ".", "sample_size", "+", "1", ")", "]", "\n", "\n", "", "current_slice_number", "=", "0", "\n", "for", "idx", ",", "filename", "in", "enumerate", "(", "filenames", ")", ":", "\n", "            ", "if", "len", "(", "filenames", ")", "<", "5", "or", "idx", "%", "(", "len", "(", "filenames", ")", "//", "5", ")", "==", "0", "or", "len", "(", "filenames", ")", "==", "(", "idx", "+", "1", ")", ":", "\n", "# pylint: disable=logging-fstring-interpolation", "\n", "                ", "self", ".", "logger", ".", "info", "(", "f\"Parsing: {(idx + 1) / len(filenames) * 100:.2f}%.\"", ")", "\n", "\n", "", "num_slices", "=", "self", ".", "spatial_shape", "[", "0", "]", "if", "len", "(", "self", ".", "spatial_shape", ")", "==", "3", "else", "1", "\n", "self", ".", "volume_indices", "[", "pathlib", ".", "PosixPath", "(", "filename", ")", "]", "=", "range", "(", "\n", "current_slice_number", ",", "current_slice_number", "+", "num_slices", "\n", ")", "\n", "current_slice_number", "+=", "num_slices", "\n", "\n", "", "return", "filenames", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset._get_metadata": [[192, 201], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_metadata", "(", "metadata", ")", ":", "\n", "        ", "encoding_size", "=", "metadata", "[", "\"encoding_size\"", "]", "\n", "reconstruction_size", "=", "metadata", "[", "\"reconstruction_size\"", "]", "\n", "metadata", "=", "{", "\n", "\"encoding_size\"", ":", "encoding_size", ",", "\n", "\"reconstruction_size\"", ":", "reconstruction_size", ",", "\n", "}", "\n", "return", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset.__len__": [[202, 204], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset.__getitem__": [[205, 234], ["datasets.FakeMRIBlobsDataset.fake_data", "datasets.FakeMRIBlobsDataset._get_metadata", "datasets.FakeMRIBlobsDataset.update", "datasets.FakeMRIBlobsDataset.transform"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FakeMRIBlobsDataset._get_metadata", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "filename", ",", "slice_no", ",", "sample_seed", "=", "self", ".", "data", "[", "idx", "]", "\n", "\n", "sample", "=", "self", ".", "fake_data", "(", "\n", "sample_size", "=", "1", ",", "\n", "num_coils", "=", "self", ".", "num_coils", ",", "\n", "spatial_shape", "=", "self", ".", "spatial_shape", ",", "\n", "name", "=", "[", "filename", "]", ",", "\n", "seed", "=", "sample_seed", ",", "\n", ")", "[", "0", "]", "\n", "sample", "[", "\"kspace\"", "]", "=", "sample", "[", "\"kspace\"", "]", "[", "slice_no", "]", "\n", "\n", "if", "\"attrs\"", "in", "sample", ":", "\n", "            ", "metadata", "=", "self", ".", "_get_metadata", "(", "sample", "[", "\"attrs\"", "]", ")", "\n", "sample", ".", "update", "(", "metadata", ")", "\n", "\n", "if", "self", ".", "pass_attrs", ":", "\n", "                ", "sample", "[", "\"scaling_factor\"", "]", "=", "sample", "[", "\"attrs\"", "]", "[", "\"max\"", "]", "\n", "\n", "", "del", "sample", "[", "\"attrs\"", "]", "\n", "\n", "", "sample", "[", "\"slice_no\"", "]", "=", "slice_no", "\n", "if", "sample", "[", "\"kspace\"", "]", ".", "ndim", "==", "2", ":", "# Singlecoil data does not always have coils at the first axis.", "\n", "            ", "sample", "[", "\"kspace\"", "]", "=", "sample", "[", "\"kspace\"", "]", "[", "np", ".", "newaxis", ",", "...", "]", "\n", "\n", "", "if", "self", ".", "transform", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.__init__": [[274, 326], ["extra_keys.append", "direct.data.h5_data.H5SliceData.__init__", "NotImplementedError", "tuple", "kwargs.get", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "data_root", ":", "pathlib", ".", "Path", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "filenames_filter", ":", "Optional", "[", "List", "[", "PathOrString", "]", "]", "=", "None", ",", "\n", "filenames_lists", ":", "Union", "[", "List", "[", "PathOrString", "]", ",", "None", "]", "=", "None", ",", "\n", "filenames_lists_root", ":", "Union", "[", "PathOrString", ",", "None", "]", "=", "None", ",", "\n", "regex_filter", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "pass_mask", ":", "bool", "=", "False", ",", "\n", "pass_max", ":", "bool", "=", "True", ",", "\n", "initial_images", ":", "Union", "[", "List", "[", "pathlib", ".", "Path", "]", ",", "None", "]", "=", "None", ",", "\n", "initial_images_key", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "noise_data", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "pass_h5s", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "None", ":", "\n", "\n", "# TODO: Clean up Dataset class such that only **kwargs need to get parsed.", "\n", "# BODY: Additional keysneeded for this dataset can be popped if needed.", "\n", "        ", "self", ".", "pass_mask", "=", "pass_mask", "\n", "extra_keys", "=", "[", "\"mask\"", "]", "if", "pass_mask", "else", "[", "]", "\n", "extra_keys", ".", "append", "(", "\"ismrmrd_header\"", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "root", "=", "data_root", ",", "\n", "filenames_filter", "=", "filenames_filter", ",", "\n", "filenames_lists", "=", "filenames_lists", ",", "\n", "filenames_lists_root", "=", "filenames_lists_root", ",", "\n", "regex_filter", "=", "regex_filter", ",", "\n", "metadata", "=", "None", ",", "\n", "extra_keys", "=", "tuple", "(", "extra_keys", ")", ",", "\n", "pass_attrs", "=", "pass_max", ",", "\n", "text_description", "=", "kwargs", ".", "get", "(", "\"text_description\"", ",", "None", ")", ",", "\n", "pass_h5s", "=", "pass_h5s", ",", "\n", "pass_dictionaries", "=", "kwargs", ".", "get", "(", "\"pass_dictionaries\"", ",", "None", ")", ",", "\n", ")", "\n", "if", "self", ".", "sensitivity_maps", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"Sensitivity maps are not supported in the current \"", "f\"{self.__class__.__name__} class.\"", "\n", ")", "\n", "\n", "# TODO: Make exclusive or to give error when one of the two keys is not set.", "\n", "# TODO: Convert into mixin, and add support to main image", "\n", "# TODO: Such a support would also work for the sensitivity maps", "\n", "", "self", ".", "initial_images_key", "=", "initial_images_key", "\n", "self", ".", "initial_images", "=", "{", "}", "\n", "\n", "if", "initial_images", ":", "\n", "            ", "self", ".", "initial_images", "=", "{", "k", ".", "name", ":", "k", "for", "k", "in", "initial_images", "}", "\n", "\n", "", "self", ".", "noise_data", "=", "noise_data", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.__getitem__": [[327, 368], ["direct.data.h5_data.H5SliceData.__getitem__", "datasets.FastMRIDataset.update", "datasets.FastMRIDataset.explicit_zero_padding", "datasets._parse_fastmri_header", "sampling_mask.reshape.reshape.reshape", "datasets.FastMRIDataset.__broadcast_mask", "datasets.FastMRIDataset.__broadcast_mask", "datasets.FastMRIDataset.transform", "datasets.FastMRIDataset.__get_acs_from_fastmri_mask"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__getitem__", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.explicit_zero_padding", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._parse_fastmri_header", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.__broadcast_mask", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.__broadcast_mask", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.__get_acs_from_fastmri_mask"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "sample", "=", "super", "(", ")", ".", "__getitem__", "(", "idx", ")", "\n", "\n", "if", "self", ".", "pass_attrs", ":", "\n", "            ", "sample", "[", "\"scaling_factor\"", "]", "=", "sample", "[", "\"attrs\"", "]", "[", "\"max\"", "]", "\n", "del", "sample", "[", "\"attrs\"", "]", "\n", "\n", "", "sample", ".", "update", "(", "_parse_fastmri_header", "(", "sample", "[", "\"ismrmrd_header\"", "]", ")", ")", "\n", "del", "sample", "[", "\"ismrmrd_header\"", "]", "\n", "# Some images have strange behavior, e.g. FLAIR 203.", "\n", "image_shape", "=", "sample", "[", "\"kspace\"", "]", ".", "shape", "\n", "if", "image_shape", "[", "-", "1", "]", "<", "sample", "[", "\"reconstruction_size\"", "]", "[", "-", "2", "]", ":", "# reconstruction size is (x, y, z)", "\n", "            ", "sample", "[", "\"reconstruction_size\"", "]", "=", "(", "image_shape", "[", "-", "1", "]", ",", "image_shape", "[", "-", "1", "]", ",", "1", ")", "\n", "\n", "", "if", "self", ".", "pass_mask", ":", "\n", "# mask should be shape (1, h, w, 1) mask provided is only w", "\n", "            ", "kspace_shape", "=", "sample", "[", "\"kspace\"", "]", ".", "shape", "\n", "sampling_mask", "=", "sample", "[", "\"mask\"", "]", "\n", "\n", "# Mask needs to be padded.", "\n", "sampling_mask", "[", ":", "sample", "[", "\"padding_left\"", "]", "]", "=", "0", "\n", "sampling_mask", "[", "sample", "[", "\"padding_right\"", "]", ":", "]", "=", "0", "\n", "\n", "sampling_mask", "=", "sampling_mask", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "del", "sample", "[", "\"mask\"", "]", "\n", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "self", ".", "__broadcast_mask", "(", "kspace_shape", ",", "sampling_mask", ")", "\n", "sample", "[", "\"acs_mask\"", "]", "=", "self", ".", "__broadcast_mask", "(", "kspace_shape", ",", "self", ".", "__get_acs_from_fastmri_mask", "(", "sampling_mask", ")", ")", "\n", "\n", "# Explicitly zero-out the outer parts of kspace which are padded", "\n", "", "sample", "[", "\"kspace\"", "]", "=", "self", ".", "explicit_zero_padding", "(", "\n", "sample", "[", "\"kspace\"", "]", ",", "sample", "[", "\"padding_left\"", "]", ",", "sample", "[", "\"padding_right\"", "]", "\n", ")", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "\n", "", "if", "self", ".", "noise_data", ":", "\n", "            ", "sample", "[", "\"loglikelihood_scaling\"", "]", "=", "self", ".", "noise_data", "[", "sample", "[", "\"slice_no\"", "]", "]", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.explicit_zero_padding": [[369, 377], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "explicit_zero_padding", "(", "kspace", ",", "padding_left", ",", "padding_right", ")", ":", "\n", "        ", "if", "padding_left", ">", "0", ":", "\n", "            ", "kspace", "[", "...", ",", "0", ":", "padding_left", "]", "=", "0", "+", "0", "*", "1j", "\n", "", "if", "padding_right", ">", "0", ":", "\n", "            ", "kspace", "[", "...", ",", "padding_right", ":", "]", "=", "0", "+", "0", "*", "1j", "\n", "\n", "", "return", "kspace", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.__get_acs_from_fastmri_mask": [[378, 388], ["numpy.zeros_like"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "__get_acs_from_fastmri_mask", "(", "mask", ")", ":", "\n", "        ", "left", "=", "right", "=", "mask", ".", "shape", "[", "-", "1", "]", "//", "2", "\n", "while", "mask", "[", "...", ",", "right", "]", ":", "\n", "            ", "right", "+=", "1", "\n", "", "while", "mask", "[", "...", ",", "left", "]", ":", "\n", "            ", "left", "-=", "1", "\n", "", "acs_mask", "=", "np", ".", "zeros_like", "(", "mask", ")", "\n", "acs_mask", "[", ":", ",", "left", "+", "1", ":", "right", "]", "=", "1", "\n", "return", "acs_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.FastMRIDataset.__broadcast_mask": [[389, 397], ["numpy.broadcast_to", "numpy.broadcast_to"], "methods", ["None"], ["", "def", "__broadcast_mask", "(", "self", ",", "kspace_shape", ",", "mask", ")", ":", "\n", "        ", "if", "self", ".", "ndim", "==", "2", ":", "\n", "            ", "mask", "=", "np", ".", "broadcast_to", "(", "mask", ",", "[", "kspace_shape", "[", "1", "]", ",", "mask", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "mask", "=", "mask", "[", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "\n", "", "elif", "self", ".", "ndim", "==", "3", ":", "\n", "            ", "mask", "=", "np", ".", "broadcast_to", "(", "mask", ",", "[", "kspace_shape", "[", "2", "]", ",", "mask", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "mask", "=", "mask", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.CalgaryCampinasDataset.__init__": [[402, 438], ["direct.data.h5_data.H5SliceData.__init__", "NotImplementedError", "kwargs.get", "kwargs.get", "slice"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "data_root", ":", "pathlib", ".", "Path", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "regex_filter", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "filenames_filter", ":", "Optional", "[", "List", "[", "PathOrString", "]", "]", "=", "None", ",", "\n", "filenames_lists", ":", "Union", "[", "List", "[", "PathOrString", "]", ",", "None", "]", "=", "None", ",", "\n", "filenames_lists_root", ":", "Union", "[", "PathOrString", ",", "None", "]", "=", "None", ",", "\n", "pass_mask", ":", "bool", "=", "False", ",", "\n", "crop_outer_slices", ":", "bool", "=", "False", ",", "\n", "pass_h5s", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "root", "=", "data_root", ",", "\n", "filenames_filter", "=", "filenames_filter", ",", "\n", "filenames_lists", "=", "filenames_lists", ",", "\n", "filenames_lists_root", "=", "filenames_lists_root", ",", "\n", "regex_filter", "=", "regex_filter", ",", "\n", "metadata", "=", "None", ",", "\n", "extra_keys", "=", "None", ",", "\n", "slice_data", "=", "slice", "(", "50", ",", "-", "50", ")", "if", "crop_outer_slices", "else", "None", ",", "\n", "text_description", "=", "kwargs", ".", "get", "(", "\"text_description\"", ",", "None", ")", ",", "\n", "pass_h5s", "=", "pass_h5s", ",", "\n", "pass_dictionaries", "=", "kwargs", ".", "get", "(", "\"pass_dictionaries\"", ",", "None", ")", ",", "\n", ")", "\n", "\n", "if", "self", ".", "sensitivity_maps", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"Sensitivity maps are not supported in the current \"", "f\"{self.__class__.__name__} class.\"", "\n", ")", "\n", "\n", "# Sampling rate in the slice-encode direction", "\n", "", "self", ".", "sampling_rate_slice_encode", ":", "float", "=", "0.85", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "pass_mask", ":", "bool", "=", "pass_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.CalgaryCampinasDataset.__getitem__": [[439, 460], ["direct.data.h5_data.H5SliceData.__getitem__", "numpy.ascontiguousarray", "kspace.transpose", "datasets.CalgaryCampinasDataset.transform", "numpy.ones().astype", "int", "numpy.ceil", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "sample", "=", "super", "(", ")", ".", "__getitem__", "(", "idx", ")", "\n", "kspace", "=", "sample", "[", "\"kspace\"", "]", "\n", "\n", "# TODO: use broadcasting function.", "\n", "if", "self", ".", "pass_mask", ":", "\n", "# # In case the data is already masked, the sampling mask can be recovered by finding the zeros.", "\n", "# This needs to be done in the primary function!", "\n", "# sampling_mask = ~(np.abs(kspace).sum(axis=(0, -1)) == 0)", "\n", "            ", "sample", "[", "\"mask\"", "]", "=", "(", "sample", "[", "\"mask\"", "]", "*", "np", ".", "ones", "(", "kspace", ".", "shape", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "\n", "", "kspace", "=", "kspace", "[", "...", ",", ":", ":", "2", "]", "+", "1j", "*", "kspace", "[", "...", ",", "1", ":", ":", "2", "]", "# Convert real-valued to complex-valued data.", "\n", "num_z", "=", "kspace", ".", "shape", "[", "1", "]", "\n", "kspace", "[", ":", ",", "int", "(", "np", ".", "ceil", "(", "num_z", "*", "self", ".", "sampling_rate_slice_encode", ")", ")", ":", ",", ":", "]", "=", "0.0", "+", "0.0", "*", "1j", "\n", "\n", "# Downstream code expects the coils to be at the first axis.", "\n", "sample", "[", "\"kspace\"", "]", "=", "np", ".", "ascontiguousarray", "(", "kspace", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.cumsum": [[474, 482], ["len", "out_sequence.append"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "cumsum", "(", "sequence", ")", ":", "\n", "        ", "out_sequence", ",", "total", "=", "[", "]", ",", "0", "\n", "for", "item", "in", "sequence", ":", "\n", "            ", "length", "=", "len", "(", "item", ")", "\n", "out_sequence", ".", "append", "(", "length", "+", "total", ")", "\n", "total", "+=", "length", "\n", "", "return", "out_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.__init__": [[483, 494], ["torch.utils.data.Dataset.__init__", "list", "datasets.ConcatDataset.cumsum", "logging.getLogger", "len", "AssertionError", "isinstance", "AssertionError", "type"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.cumsum"], ["", "def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "len", "(", "datasets", ")", "<=", "0", ":", "\n", "            ", "raise", "AssertionError", "(", "\"datasets should not be an empty iterable\"", ")", "\n", "", "self", ".", "datasets", "=", "list", "(", "datasets", ")", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "if", "isinstance", "(", "dataset", ",", "IterableDataset", ")", ":", "\n", "                ", "raise", "AssertionError", "(", "\"ConcatDataset does not support IterableDataset\"", ")", "\n", "", "", "self", ".", "cumulative_sizes", "=", "self", ".", "cumsum", "(", "self", ".", "datasets", ")", "\n", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.__len__": [[495, 497], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cumulative_sizes", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.__getitem__": [[498, 506], ["bisect.bisect_right", "len", "ValueError", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "0", ":", "\n", "            ", "if", "-", "idx", ">", "len", "(", "self", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"absolute value of index should not exceed dataset length\"", ")", "\n", "", "idx", "=", "len", "(", "self", ")", "+", "idx", "\n", "", "dataset_idx", "=", "bisect", ".", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "idx", ")", "\n", "sample_idx", "=", "idx", "if", "dataset_idx", "==", "0", "else", "idx", "-", "self", ".", "cumulative_sizes", "[", "dataset_idx", "-", "1", "]", "\n", "return", "self", ".", "datasets", "[", "dataset_idx", "]", "[", "sample_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.__init__": [[534, 604], ["logging.getLogger", "datasets.SheppLoganDataset._set_params", "numpy.random.RandomState", "range", "isinstance", "tuple", "len", "datasets.temp_seed", "list", "datasets.SheppLoganDataset.logger.info", "datasets.SheppLoganDataset.__len__", "type", "datasets.SheppLoganDataset.rng.choice", "pathlib.Path", "range", "int"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset._set_params", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.temp_seed", "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__len__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "shape", ":", "Union", "[", "int", ",", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "int", ",", "int", "]", "]", "]", ",", "\n", "num_coils", ":", "int", ",", "\n", "intensity", ":", "ImageIntensityMode", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "ellipsoids", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "B0", ":", "float", "=", "3.0", ",", "\n", "T2_star", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "zlimits", ":", "Tuple", "[", "float", ",", "float", "]", "=", "(", "-", "1", ",", "1", ")", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "text_description", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "r\"\"\"Inits :class:`SheppLoganDataset`.\n\n        Parameters\n        ----------\n        shape: Union[int, Union[List[int], Tuple[int, int, int]]]\n            Shape of Shepp Logan phantom (3-dimensional).\n        num_coils: int\n            Number of simulated coils.\n        intensity: ImageIntensityMode\n            Can be `PROTON` to return the proton density dataset, `T1` or `T2`.\n        seed: Optional[Union[int, List[int]]]\n            Seed to be used for coil sensitivity maps. Default: None.\n        ellipsoids: np.ndarray\n            Ellipsoids parameters. If None, it will used the default parameters as per the paper. Default: None.\n        B0: float\n            Magnetic field. Default: 3.0.\n        T2_star: Optional[bool]\n            If True, a T2^{*} dataset will be output. Only valid for intensity = `T2`. Default: None.\n        zlimits: Tuple[float, float]\n            Limits of z-axis. Default: (-1, 1).\n        transform: Optional[Callable]\n            A list of transforms to be applied on the generated samples. Default is None.\n        text_description: Optional[str]\n            Description of dataset, can be useful for logging. Default: None.\n        \"\"\"", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "type", "(", "self", ")", ".", "__name__", ")", "\n", "\n", "(", "self", ".", "nx", ",", "self", ".", "ny", ",", "self", ".", "nz", ")", "=", "(", "shape", ",", "shape", ",", "shape", ")", "if", "isinstance", "(", "shape", ",", "int", ")", "else", "tuple", "(", "shape", ")", "\n", "self", ".", "num_coils", "=", "num_coils", "\n", "\n", "assert", "(", "\n", "intensity", "in", "self", ".", "IMAGE_INTENSITIES", "\n", ")", ",", "f\"Intensity should be in {self.IMAGE_INTENSITIES}. Received {intensity}.\"", "\n", "self", ".", "intensity", "=", "intensity", "\n", "\n", "assert", "len", "(", "zlimits", ")", "==", "2", ",", "\"`zlimits` must be a tuple with 2 entries: upper and lower \"", "\"bounds!\"", "\n", "assert", "zlimits", "[", "0", "]", "<=", "zlimits", "[", "1", "]", ",", "\"`zlimits`: lower bound must be first entry!\"", "\n", "self", ".", "zlimits", "=", "zlimits", "\n", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "B0", "=", "B0", "\n", "self", ".", "T2_star", "=", "T2_star", "\n", "\n", "self", ".", "_set_params", "(", "ellipsoids", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "            ", "self", ".", "seed", "=", "list", "(", "self", ".", "rng", ".", "choice", "(", "a", "=", "range", "(", "int", "(", "1e5", ")", ")", ",", "size", "=", "self", ".", "nz", ",", "replace", "=", "False", ")", ")", "\n", "", "self", ".", "text_description", "=", "text_description", "\n", "if", "self", ".", "text_description", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Dataset description: %s.\"", ",", "self", ".", "text_description", ")", "\n", "\n", "", "self", ".", "name", "=", "\"shepp_loggan\"", "+", "\"_\"", "+", "self", ".", "intensity", "\n", "self", ".", "ndim", "=", "2", "\n", "self", ".", "volume_indices", "=", "{", "}", "\n", "self", ".", "volume_indices", "[", "pathlib", ".", "Path", "(", "self", ".", "name", ")", "]", "=", "range", "(", "self", ".", "__len__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset._set_params": [[605, 627], ["datasets.SheppLoganDataset.default_mr_ellipsoid_parameters"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.default_mr_ellipsoid_parameters"], ["", "def", "_set_params", "(", "self", ",", "ellipsoids", "=", "None", ")", "->", "None", ":", "\n", "\n", "# Get parameters from paper if None provided", "\n", "        ", "if", "ellipsoids", "is", "None", ":", "\n", "            ", "ellipsoids", "=", "self", ".", "default_mr_ellipsoid_parameters", "(", ")", "\n", "\n", "# Extract some parameters so we can use them", "\n", "", "self", ".", "center_xs", "=", "ellipsoids", "[", ":", ",", "0", "]", "\n", "self", ".", "center_ys", "=", "ellipsoids", "[", ":", ",", "1", "]", "\n", "self", ".", "center_zs", "=", "ellipsoids", "[", ":", ",", "2", "]", "\n", "self", ".", "half_ax_as", "=", "ellipsoids", "[", ":", ",", "3", "]", "\n", "self", ".", "half_ax_bs", "=", "ellipsoids", "[", ":", ",", "4", "]", "\n", "self", ".", "half_ax_cs", "=", "ellipsoids", "[", ":", ",", "5", "]", "\n", "self", ".", "theta", "=", "ellipsoids", "[", ":", ",", "6", "]", "\n", "self", ".", "M0", "=", "ellipsoids", "[", ":", ",", "7", "]", "\n", "self", ".", "As", "=", "ellipsoids", "[", ":", ",", "8", "]", "\n", "self", ".", "Cs", "=", "ellipsoids", "[", ":", ",", "9", "]", "\n", "self", ".", "T1", "=", "ellipsoids", "[", ":", ",", "10", "]", "\n", "self", ".", "T2", "=", "ellipsoids", "[", ":", ",", "11", "]", "\n", "self", ".", "chis", "=", "ellipsoids", "[", ":", ",", "12", "]", "\n", "\n", "self", ".", "ellipsoids", "=", "ellipsoids", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.sample_image": [[628, 671], ["numpy.meshgrid", "numpy.cos", "numpy.sin", "numpy.sign", "numpy.zeros", "range", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.isnan", "numpy.abs"], "methods", ["None"], ["", "def", "sample_image", "(", "self", ",", "idx", ":", "int", ")", "->", "np", ".", "ndarray", ":", "# pylint: disable=too-many-locals", "\n", "# meshgrid does X, Y backwards", "\n", "        ", "X", ",", "Y", ",", "Z", "=", "np", ".", "meshgrid", "(", "\n", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "self", ".", "ny", ")", ",", "\n", "np", ".", "linspace", "(", "-", "1", ",", "1", ",", "self", ".", "nx", ")", ",", "\n", "np", ".", "linspace", "(", "self", ".", "zlimits", "[", "0", "]", ",", "self", ".", "zlimits", "[", "1", "]", ",", "self", ".", "nz", ")", "[", "idx", "%", "self", ".", "nz", "]", ",", "\n", ")", "\n", "\n", "ct", "=", "np", ".", "cos", "(", "self", ".", "theta", ")", "\n", "st", "=", "np", ".", "sin", "(", "self", ".", "theta", ")", "\n", "sgn", "=", "np", ".", "sign", "(", "self", ".", "M0", ")", "\n", "\n", "image", "=", "np", ".", "zeros", "(", "(", "self", ".", "nx", ",", "self", ".", "ny", ",", "1", ")", ")", "\n", "\n", "# Put ellipses where they need to be", "\n", "for", "j", "in", "range", "(", "self", ".", "ellipsoids", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "center_x", ",", "center_y", ",", "center_z", "=", "self", ".", "center_xs", "[", "j", "]", ",", "self", ".", "center_ys", "[", "j", "]", ",", "self", ".", "center_zs", "[", "j", "]", "\n", "a", ",", "b", ",", "c", "=", "self", ".", "half_ax_as", "[", "j", "]", ",", "self", ".", "half_ax_bs", "[", "j", "]", ",", "self", ".", "half_ax_cs", "[", "j", "]", "\n", "ct0", ",", "st0", "=", "ct", "[", "j", "]", ",", "st", "[", "j", "]", "\n", "\n", "# Find indices falling inside the ellipsoid, ellipses only", "\n", "# rotated in xy plane", "\n", "indices", "=", "(", "(", "X", "-", "center_x", ")", "*", "ct0", "+", "(", "Y", "-", "center_y", ")", "*", "st0", ")", "**", "2", "/", "a", "**", "2", "+", "(", "\n", "(", "X", "-", "center_x", ")", "*", "st0", "-", "(", "Y", "-", "center_y", ")", "*", "ct0", "\n", ")", "**", "2", "/", "b", "**", "2", "+", "(", "Z", "-", "center_z", ")", "**", "2", "/", "c", "**", "2", "<=", "1", "\n", "# T1 | Use T1 model if not given explicit T1 value", "\n", "if", "self", ".", "intensity", "==", "\"T1\"", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "self", ".", "T1", "[", "j", "]", ")", ":", "\n", "                    ", "image", "[", "indices", "]", "+=", "sgn", "[", "j", "]", "*", "self", ".", "As", "[", "j", "]", "*", "(", "self", ".", "B0", "**", "self", ".", "Cs", "[", "j", "]", ")", "\n", "", "else", ":", "\n", "                    ", "image", "[", "indices", "]", "+=", "sgn", "[", "j", "]", "*", "self", ".", "T1", "[", "j", "]", "\n", "# T2", "\n", "", "", "elif", "self", ".", "intensity", "==", "\"T2\"", ":", "\n", "                ", "if", "self", ".", "T2_star", ":", "\n", "                    ", "image", "[", "indices", "]", "+=", "sgn", "[", "j", "]", "/", "(", "\n", "1", "/", "self", ".", "T2", "[", "j", "]", "+", "self", ".", "GYROMAGNETIC_RATIO", "*", "np", ".", "abs", "(", "self", ".", "B0", "*", "self", ".", "chis", "[", "j", "]", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "image", "[", "indices", "]", "+=", "sgn", "[", "j", "]", "*", "self", ".", "T2", "[", "j", "]", "\n", "# M0 | Add ellipses together -- subtract of M0 is negative", "\n", "", "", "else", ":", "\n", "                ", "image", "[", "indices", "]", "+=", "self", ".", "M0", "[", "j", "]", "\n", "", "", "return", "(", "image", "+", "0.0j", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.__len__": [[672, 674], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "nz", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.__getitem__": [[675, 692], ["datasets.SheppLoganDataset.sample_image", "direct.data.sens.simulate_sensitivity_maps", "numpy.allclose", "datasets.SheppLoganDataset.fft", "numpy.zeros", "datasets.SheppLoganDataset.transform", "numpy.random.randn"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.sample_image", "home.repos.pwc.inspect_result.directgroup_direct.data.sens.simulate_sensitivity_maps", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.fft"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "image", "=", "self", ".", "sample_image", "(", "idx", ")", "\n", "sensitivity_map", "=", "simulate_sensitivity_maps", "(", "(", "self", ".", "nx", ",", "self", ".", "ny", ")", ",", "self", ".", "num_coils", ",", "seed", "=", "self", ".", "seed", "[", "idx", "]", ")", "\n", "\n", "image", "=", "image", "[", "None", "]", "*", "sensitivity_map", "\n", "\n", "# Outer slices might be zeros. These will cause nans/infs. Add random normal noise.", "\n", "if", "np", ".", "allclose", "(", "image", ",", "np", ".", "zeros", "(", "1", ")", ")", ":", "\n", "            ", "image", "+=", "np", ".", "random", ".", "randn", "(", "*", "image", ".", "shape", ")", "*", "sys", ".", "float_info", ".", "epsilon", "\n", "\n", "", "kspace", "=", "self", ".", "fft", "(", "image", ")", "\n", "\n", "sample", "=", "{", "\"kspace\"", ":", "kspace", ",", "\"filename\"", ":", "self", ".", "name", ",", "\"slice_no\"", ":", "idx", "}", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.default_mr_ellipsoid_parameters": [[693, 761], ["datasets._mr_relaxation_parameters", "numpy.zeros", "numpy.zeros", "range", "numpy.concatenate", "numpy.deg2rad", "numpy.deg2rad", "numpy.deg2rad", "numpy.deg2rad", "numpy.deg2rad"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets._mr_relaxation_parameters"], ["", "@", "staticmethod", "\n", "def", "default_mr_ellipsoid_parameters", "(", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"Returns default parameters of ellipsoids as in [1]_.\n\n        Returns\n        -------\n        ellipsoids : np.ndarray\n            Array containing the parameters for the ellipsoids used to construct the phantom.\n            Each row of the form [x, y, z, a, b, c, \\theta, m_0, A, C, T1, T2, \\chi] represents an ellipsoid, where:\n            * (x, y, z): denotes the center of the ellipsoid\n            * (a, b, c): denote the lengths of the semi-major axis aligned with the x, y, z-axis, respectively\n            * \\theta: denotes the rotation angle of the ellipsoid in rads\n            * m_0: denotes the spin density\n            * (A, C): denote the T1 parameters\n            * T1: denotes the T1 value if explicit, otherwise T1 = A \\times B_0^{C}\n            * T2: denotes the T2 value\n            * \\chi: denotes the \\chi value\n\n        References\n        ----------\n        .. [1] Gach, H. Michael, Costin Tanase, and Fernando Boada. \"2D & 3D Shepp-Logan phantom standards for MRI.\"\n            2008 19th International Conference on Systems Engineering. IEEE, 2008.\n        \"\"\"", "\n", "params", "=", "_mr_relaxation_parameters", "(", ")", "\n", "\n", "ellipsoids", "=", "np", ".", "zeros", "(", "(", "SheppLoganDataset", ".", "DEFAULT_NUM_ELLIPSOIDS", ",", "SheppLoganDataset", ".", "ELLIPSOID_NUM_PARAMS", ")", ")", "\n", "\n", "ellipsoids", "[", "0", ",", ":", "]", "=", "[", "0", ",", "0", ",", "0", ",", "0.72", ",", "0.95", ",", "0.93", ",", "0", ",", "0.8", ",", "*", "params", "[", "\"scalp\"", "]", "]", "\n", "ellipsoids", "[", "1", ",", ":", "]", "=", "[", "0", ",", "0", ",", "0", ",", "0.69", ",", "0.92", ",", "0.9", ",", "0", ",", "0.12", ",", "*", "params", "[", "\"marrow\"", "]", "]", "\n", "ellipsoids", "[", "2", ",", ":", "]", "=", "[", "0", ",", "-", "0.0184", ",", "0", ",", "0.6624", ",", "0.874", ",", "0.88", ",", "0", ",", "0.98", ",", "*", "params", "[", "\"csf\"", "]", "]", "\n", "ellipsoids", "[", "3", ",", ":", "]", "=", "[", "0", ",", "-", "0.0184", ",", "0", ",", "0.6524", ",", "0.864", ",", "0.87", ",", "0", ",", "0.745", ",", "*", "params", "[", "\"gray-matter\"", "]", "]", "\n", "ellipsoids", "[", "4", ",", ":", "]", "=", "[", "-", "0.22", ",", "0", ",", "-", "0.25", ",", "0.41", ",", "0.16", ",", "0.21", ",", "np", ".", "deg2rad", "(", "-", "72", ")", ",", "0.98", ",", "*", "params", "[", "\"csf\"", "]", "]", "\n", "ellipsoids", "[", "5", ",", ":", "]", "=", "[", "0.22", ",", "0", ",", "-", "0.25", ",", "0.31", ",", "0.11", ",", "0.22", ",", "np", ".", "deg2rad", "(", "72", ")", ",", "0.98", ",", "*", "params", "[", "\"csf\"", "]", "]", "\n", "ellipsoids", "[", "6", ",", ":", "]", "=", "[", "0", ",", "0.35", ",", "-", "0.25", ",", "0.21", ",", "0.25", ",", "0.35", ",", "0", ",", "0.617", ",", "*", "params", "[", "\"white-matter\"", "]", "]", "\n", "ellipsoids", "[", "7", ",", ":", "]", "=", "[", "0", ",", "0.1", ",", "-", "0.25", ",", "0.046", ",", "0.046", ",", "0.046", ",", "0", ",", "0.95", ",", "*", "params", "[", "\"tumor\"", "]", "]", "\n", "ellipsoids", "[", "8", ",", ":", "]", "=", "[", "-", "0.08", ",", "-", "0.605", ",", "-", "0.25", ",", "0.046", ",", "0.023", ",", "0.02", ",", "0", ",", "0.95", ",", "*", "params", "[", "\"tumor\"", "]", "]", "\n", "ellipsoids", "[", "9", ",", ":", "]", "=", "[", "0.06", ",", "-", "0.605", ",", "-", "0.25", ",", "0.046", ",", "0.023", ",", "0.02", ",", "np", ".", "deg2rad", "(", "-", "90", ")", ",", "0.95", ",", "*", "params", "[", "\"tumor\"", "]", "]", "\n", "ellipsoids", "[", "10", ",", ":", "]", "=", "[", "0", ",", "-", "0.1", ",", "-", "0.25", ",", "0.046", ",", "0.046", ",", "0.046", ",", "0", ",", "0.95", ",", "*", "params", "[", "\"tumor\"", "]", "]", "\n", "ellipsoids", "[", "11", ",", ":", "]", "=", "[", "0", ",", "-", "0.605", ",", "-", "0.25", ",", "0.023", ",", "0.023", ",", "0.023", ",", "0", ",", "0.95", ",", "*", "params", "[", "\"tumor\"", "]", "]", "\n", "ellipsoids", "[", "12", ",", ":", "]", "=", "[", "0.06", ",", "-", "0.105", ",", "0.0625", ",", "0.056", ",", "0.04", ",", "0.1", ",", "np", ".", "deg2rad", "(", "-", "90", ")", ",", "0.93", ",", "*", "params", "[", "\"tumor\"", "]", "]", "\n", "ellipsoids", "[", "13", ",", ":", "]", "=", "[", "0", ",", "0.1", ",", "0.625", ",", "0.056", ",", "0.056", ",", "0.1", ",", "0", ",", "0.98", ",", "*", "params", "[", "\"csf\"", "]", "]", "\n", "ellipsoids", "[", "14", ",", ":", "]", "=", "[", "0.56", ",", "-", "0.4", ",", "-", "0.25", ",", "0.2", ",", "0.03", ",", "0.1", ",", "np", ".", "deg2rad", "(", "70", ")", ",", "0.85", ",", "*", "params", "[", "\"blood-clot\"", "]", "]", "\n", "\n", "# Need to subtract some ellipses here...", "\n", "ellipsoids_neg", "=", "np", ".", "zeros", "(", "ellipsoids", ".", "shape", ")", "\n", "for", "ii", "in", "range", "(", "ellipsoids", ".", "shape", "[", "0", "]", ")", ":", "\n", "\n", "# Ellipsoid geometry", "\n", "            ", "ellipsoids_neg", "[", "ii", ",", ":", "7", "]", "=", "ellipsoids", "[", "ii", ",", ":", "7", "]", "\n", "\n", "# Tissue property differs after 4th subtracted ellipsoid", "\n", "if", "ii", ">", "3", ":", "\n", "                ", "ellipsoids_neg", "[", "ii", ",", "7", ":", "]", "=", "ellipsoids", "[", "3", ",", "7", ":", "]", "\n", "", "else", ":", "\n", "                ", "ellipsoids_neg", "[", "ii", ",", "7", ":", "]", "=", "ellipsoids", "[", "ii", "-", "1", ",", "7", ":", "]", "\n", "\n", "# Throw out first as we skip this one in the paper's table", "\n", "", "", "ellipsoids_neg", "=", "ellipsoids_neg", "[", "1", ":", ",", ":", "]", "\n", "\n", "# Spin density is negative for subtraction", "\n", "ellipsoids_neg", "[", ":", ",", "7", "]", "*=", "-", "1", "\n", "\n", "# Paper doesn't use last blood-clot ellipsoid", "\n", "ellipsoids", "=", "ellipsoids", "[", ":", "-", "1", ",", ":", "]", "\n", "ellipsoids_neg", "=", "ellipsoids_neg", "[", ":", "-", "1", ",", ":", "]", "\n", "\n", "# Put both ellipsoid groups together", "\n", "return", "np", ".", "concatenate", "(", "(", "ellipsoids", ",", "ellipsoids_neg", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganDataset.fft": [[762, 765], ["numpy.fft.ifftshift", "numpy.fft.fft2", "numpy.fft.fftshift"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift"], ["", "@", "staticmethod", "\n", "def", "fft", "(", "x", ")", ":", "\n", "        ", "return", "np", ".", "fft", ".", "ifftshift", "(", "np", ".", "fft", ".", "fft2", "(", "np", ".", "fft", ".", "fftshift", "(", "x", ")", ",", "axes", "=", "(", "1", ",", "2", ")", ",", "norm", "=", "\"ortho\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganProtonDataset.__init__": [[805, 847], ["datasets.SheppLoganDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "shape", ":", "Union", "[", "int", ",", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "int", ",", "int", "]", "]", "]", ",", "\n", "num_coils", ":", "int", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "ellipsoids", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "B0", ":", "float", "=", "3.0", ",", "\n", "zlimits", ":", "Tuple", "[", "float", ",", "float", "]", "=", "(", "-", "0.929", ",", "0.929", ")", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "text_description", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "r\"\"\"Inits :class:`SheppLoganProtonDataset`.\n\n        Parameters\n        ----------\n        shape: Union[int, Union[List[int], Tuple[int, int, int]]]\n            Shape of Shepp Logan phantom (3-dimensional).\n        num_coils: int\n            Number of simulated coils.\n        seed: Optional[Union[int, List[int]]]\n            Seed to be used for coil sensitivity maps. Default: None.\n        ellipsoids: np.ndarray\n            Ellipsoids parameters. If None, it will used the default parameters as per the paper. Default: None.\n        B0: float\n            Magnetic field. Default: 3.0.\n        zlimits: Tuple[float, float]\n            Limits of z-axis. Default: (-0.929, 0.929).\n        transform: Optional[Callable]\n            A list of transforms to be applied on the generated samples. Default is None.\n        text_description: Optional[str]\n            Description of dataset, can be useful for logging. Default: None.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "shape", "=", "shape", ",", "\n", "num_coils", "=", "num_coils", ",", "\n", "intensity", "=", "ImageIntensityMode", ".", "proton", ",", "\n", "seed", "=", "seed", ",", "\n", "ellipsoids", "=", "ellipsoids", ",", "\n", "B0", "=", "B0", ",", "\n", "zlimits", "=", "zlimits", ",", "\n", "transform", "=", "transform", ",", "\n", "text_description", "=", "text_description", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganT1Dataset.__init__": [[853, 895], ["datasets.SheppLoganDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "shape", ":", "Union", "[", "int", ",", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "int", ",", "int", "]", "]", "]", ",", "\n", "num_coils", ":", "int", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "ellipsoids", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "B0", ":", "float", "=", "3.0", ",", "\n", "zlimits", ":", "Tuple", "[", "float", ",", "float", "]", "=", "(", "-", "0.929", ",", "0.929", ")", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "text_description", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "r\"\"\"Inits :class:`SheppLoganT1Dataset`.\n\n        Parameters\n        ----------\n        shape: Union[int, Union[List[int], Tuple[int, int, int]]]\n            Shape of Shepp Logan phantom (3-dimensional).\n        num_coils: int\n            Number of simulated coils.\n        seed: Optional[Union[int, List[int]]]\n            Seed to be used for coil sensitivity maps. Default: None.\n        ellipsoids: np.ndarray\n            Ellipsoids parameters. If None, it will used the default parameters as per the paper. Default: None.\n        B0: float\n            Magnetic field. Default: 3.0.\n        zlimits: Tuple[float, float]\n            Limits of z-axis. Default: (-0.929, 0.929).\n        transform: Optional[Callable]\n            A list of transforms to be applied on the generated samples. Default is None.\n        text_description: Optional[str]\n            Description of dataset, can be useful for logging. Default: None.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "shape", "=", "shape", ",", "\n", "num_coils", "=", "num_coils", ",", "\n", "intensity", "=", "ImageIntensityMode", ".", "t1", ",", "\n", "seed", "=", "seed", ",", "\n", "ellipsoids", "=", "ellipsoids", ",", "\n", "B0", "=", "B0", ",", "\n", "zlimits", "=", "zlimits", ",", "\n", "transform", "=", "transform", ",", "\n", "text_description", "=", "text_description", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.SheppLoganT2Dataset.__init__": [[901, 947], ["datasets.SheppLoganDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "shape", ":", "Union", "[", "int", ",", "Union", "[", "List", "[", "int", "]", ",", "Tuple", "[", "int", ",", "int", ",", "int", "]", "]", "]", ",", "\n", "num_coils", ":", "int", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "ellipsoids", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "B0", ":", "float", "=", "3.0", ",", "\n", "T2_star", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "zlimits", ":", "Tuple", "[", "float", ",", "float", "]", "=", "(", "-", "0.929", ",", "0.929", ")", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "text_description", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "r\"\"\"Inits :class:`SheppLoganT2Dataset`.\n\n        Parameters\n        ----------\n        shape: Union[int, Union[List[int], Tuple[int, int, int]]]\n            Shape of Shepp Logan phantom (3-dimensional).\n        num_coils: int\n            Number of simulated coils.\n        seed: Optional[Union[int, List[int]]]\n            Seed to be used for coil sensitivity maps. Default: None.\n        ellipsoids: np.ndarray\n            Ellipsoids parameters. If None, it will used the default parameters as per the paper. Default: None.\n        B0: float\n            Magnetic field. Default: 3.0.\n        T2_star: Optional[bool]\n            If True, a T2^{*} dataset will be output. Only valid for intensity = `T2`. Default: None.\n        zlimits: Tuple[float, float]\n            Limits of z-axis. Default: (-0.929, 0.929).\n        transform: Optional[Callable]\n            A list of transforms to be applied on the generated samples. Default is None.\n        text_description: Optional[str]\n            Description of dataset, can be useful for logging. Default: None.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "shape", "=", "shape", ",", "\n", "num_coils", "=", "num_coils", ",", "\n", "intensity", "=", "ImageIntensityMode", ".", "t2", ",", "\n", "seed", "=", "seed", ",", "\n", "ellipsoids", "=", "ellipsoids", ",", "\n", "B0", "=", "B0", ",", "\n", "T2_star", "=", "T2_star", ",", "\n", "zlimits", "=", "zlimits", ",", "\n", "transform", "=", "transform", ",", "\n", "text_description", "=", "text_description", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.temp_seed": [[39, 47], ["rng.get_state", "rng.seed", "rng.set_state"], "function", ["None"], ["@", "contextlib", ".", "contextmanager", "\n", "def", "temp_seed", "(", "rng", ",", "seed", ")", ":", "\n", "    ", "state", "=", "rng", ".", "get_state", "(", ")", "\n", "rng", ".", "seed", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "rng", ".", "set_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query": [[49, 83], ["root.find", "str", "RuntimeError"], "function", ["None"], ["", "", "def", "_et_query", "(", "\n", "root", ":", "etree", ".", "Element", ",", "\n", "qlist", ":", "Sequence", "[", "str", "]", ",", "\n", "namespace", ":", "str", "=", "\"http://www.ismrm.org/ISMRMRD\"", ",", "\n", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    ElementTree query function.\n    This can be used to query an xml document via ElementTree. It uses qlist\n    for nested queries.\n    Args:\n        root: Root of the xml to search through.\n        qlist: A list of strings for nested searches, e.g. [\"Encoding\",\n            \"matrixSize\"]\n        namespace: Optional; xml namespace to prepend query.\n    Returns:\n        The retrieved data as a string.\n\n    From:\n    https://github.com/facebookresearch/fastMRI/blob/13560d2f198cc72f06e01675e9ecee509ce5639a/fastmri/data/mri_data.py#L23\n\n    \"\"\"", "\n", "s", "=", "\".\"", "\n", "prefix", "=", "\"ismrmrd_namespace\"", "\n", "\n", "ns", "=", "{", "prefix", ":", "namespace", "}", "\n", "\n", "for", "el", "in", "qlist", ":", "\n", "        ", "s", "=", "s", "+", "f\"//{prefix}:{el}\"", "\n", "\n", "", "value", "=", "root", ".", "find", "(", "s", ",", "ns", ")", "\n", "if", "value", "is", "None", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Element not found\"", ")", "\n", "\n", "", "return", "str", "(", "value", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._parse_fastmri_header": [[236, 269], ["xml.fromstring", "int", "int", "int", "int", "int", "int", "int", "datasets._et_query", "int", "datasets._et_query", "datasets._et_query", "datasets._et_query", "datasets._et_query", "datasets._et_query", "datasets._et_query", "datasets._et_query"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._et_query"], ["", "", "def", "_parse_fastmri_header", "(", "xml_header", ":", "str", ")", "->", "Dict", ":", "\n", "# Borrowed from: https://github.com/facebookresearch/\\", "\n", "# fastMRI/blob/13560d2f198cc72f06e01675e9ecee509ce5639a/fastmri/data/mri_data.py#L23", "\n", "    ", "et_root", "=", "etree", ".", "fromstring", "(", "xml_header", ")", "# nosec", "\n", "\n", "encodings", "=", "[", "\"encoding\"", ",", "\"encodedSpace\"", ",", "\"matrixSize\"", "]", "\n", "encoding_size", "=", "(", "\n", "int", "(", "_et_query", "(", "et_root", ",", "encodings", "+", "[", "\"x\"", "]", ")", ")", ",", "\n", "int", "(", "_et_query", "(", "et_root", ",", "encodings", "+", "[", "\"y\"", "]", ")", ")", ",", "\n", "int", "(", "_et_query", "(", "et_root", ",", "encodings", "+", "[", "\"z\"", "]", ")", ")", ",", "\n", ")", "\n", "reconstructions", "=", "[", "\"encoding\"", ",", "\"reconSpace\"", ",", "\"matrixSize\"", "]", "\n", "reconstruction_size", "=", "(", "\n", "int", "(", "_et_query", "(", "et_root", ",", "reconstructions", "+", "[", "\"x\"", "]", ")", ")", ",", "\n", "int", "(", "_et_query", "(", "et_root", ",", "reconstructions", "+", "[", "\"y\"", "]", ")", ")", ",", "\n", "int", "(", "_et_query", "(", "et_root", ",", "reconstructions", "+", "[", "\"z\"", "]", ")", ")", ",", "\n", ")", "\n", "\n", "limits", "=", "[", "\"encoding\"", ",", "\"encodingLimits\"", ",", "\"kspace_encoding_step_1\"", "]", "\n", "encoding_limits_center", "=", "int", "(", "_et_query", "(", "et_root", ",", "limits", "+", "[", "\"center\"", "]", ")", ")", "\n", "encoding_limits_max", "=", "int", "(", "_et_query", "(", "et_root", ",", "limits", "+", "[", "\"maximum\"", "]", ")", ")", "+", "1", "\n", "\n", "padding_left", "=", "encoding_size", "[", "1", "]", "//", "2", "-", "encoding_limits_center", "\n", "padding_right", "=", "padding_left", "+", "encoding_limits_max", "\n", "\n", "metadata", "=", "{", "\n", "\"padding_left\"", ":", "padding_left", ",", "\n", "\"padding_right\"", ":", "padding_right", ",", "\n", "\"encoding_size\"", ":", "encoding_size", ",", "\n", "\"reconstruction_size\"", ":", "reconstruction_size", ",", "\n", "}", "\n", "\n", "return", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets._mr_relaxation_parameters": [[767, 800], ["None"], "function", ["None"], ["", "", "def", "_mr_relaxation_parameters", "(", ")", ":", "\n", "    ", "r\"\"\"Returns MR relaxation parameters for certain tissues as defined in [1]_.\n\n    Returns\n    -------\n    params : dict\n        Tissue properties of scalp, marrow, csf, white/gray matter, tumor and blood clot.\n        More specifically, these properties are [A, C, T1, T2, \\chi], where:\n            * (A, C): denote the T1 parameters\n            * T1: denotes the T1 value if explicit, otherwise T1 = A \\times B_0^{C}\n            * T2: denotes the T2 value\n            * \\chi: denotes the \\chi value\n\n    Notes\n    -----\n    If T1 is np.nan, T1 = A \\times B_0^{C} will be used.\n\n    References\n    ----------\n    .. [1] Gach, H. Michael, Costin Tanase, and Fernando Boada. \"2D & 3D Shepp-Logan phantom standards for MRI.\"\n        2008 19th International Conference on Systems Engineering. IEEE, 2008.\n    \"\"\"", "\n", "\n", "# params['tissue-name'] = [A, C, (t1 value if explicit), t2, chi]", "\n", "params", "=", "{", "}", "\n", "params", "[", "\"scalp\"", "]", "=", "[", "0.324", ",", "0.137", ",", "np", ".", "nan", ",", "0.07", ",", "-", "7.5e-6", "]", "\n", "params", "[", "\"marrow\"", "]", "=", "[", "0.533", ",", "0.088", ",", "np", ".", "nan", ",", "0.05", ",", "-", "8.85e-6", "]", "\n", "params", "[", "\"csf\"", "]", "=", "[", "np", ".", "nan", ",", "np", ".", "nan", ",", "4.2", ",", "1.99", ",", "-", "9e-6", "]", "\n", "params", "[", "\"blood-clot\"", "]", "=", "[", "1.35", ",", "0.34", ",", "np", ".", "nan", ",", "0.2", ",", "-", "9e-6", "]", "\n", "params", "[", "\"gray-matter\"", "]", "=", "[", "0.857", ",", "0.376", ",", "np", ".", "nan", ",", "0.1", ",", "-", "9e-6", "]", "\n", "params", "[", "\"white-matter\"", "]", "=", "[", "0.583", ",", "0.382", ",", "np", ".", "nan", ",", "0.08", ",", "-", "9e-6", "]", "\n", "params", "[", "\"tumor\"", "]", "=", "[", "0.926", ",", "0.217", ",", "np", ".", "nan", ",", "0.1", ",", "-", "9e-6", "]", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.build_dataset": [[950, 992], ["logger.info", "direct.utils.str_to_class", "logger.debug", "dataset_class", "logger.debug", "str"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["", "", "def", "build_dataset", "(", "\n", "name", ":", "str", ",", "\n", "transforms", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "**", "kwargs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", ")", "->", "Dataset", ":", "\n", "    ", "\"\"\"Builds dataset with name :class:`name + \"Dataset\"` from keyword arguments.\n\n    Only `name` and `transforms` arguments are common for all Datasets.\n    ALL other keyword arguments should be passed in **kwargs.\n\n    Parameters\n    ----------\n    name: str\n        Name of dataset class (without `Dataset`) in direct.data.datasets.\n    transforms: Callable\n        Transformation object. Default: None.\n    kwargs: Dict[str, Any]\n        Keyword arguments. Can include:\n            * data_root: pathlib.Path or str\n                Root path to the data for the dataset class (:class:`FastMRIDataset` and :class:`CalgaryCampinasDataset`).\n            * filenames_filter: List\n                List of filenames to include in the dataset, should be the same as the ones that can be derived from a glob\n                on the root. If set, will skip searching for files in the root.\n            * sensitivity_maps: pathlib.Path\n                Path to sensitivity maps.\n            * text_description: str\n                Description of dataset, can be used for logging.\n            * kspace_context: int\n                If set, output will be of shape -kspace_context:kspace_context.\n\n    Returns\n    -------\n    Dataset\n    \"\"\"", "\n", "logger", ".", "info", "(", "\"Building dataset for: %s\"", ",", "name", ")", "\n", "dataset_class", ":", "Callable", "=", "str_to_class", "(", "\"direct.data.datasets\"", ",", "name", "+", "\"Dataset\"", ")", "\n", "logger", ".", "debug", "(", "\"Dataset class: %s\"", ",", "dataset_class", ")", "\n", "dataset", "=", "dataset_class", "(", "transform", "=", "transforms", ",", "**", "kwargs", ")", "\n", "\n", "logger", ".", "debug", "(", "\"Dataset: %s\"", ",", "str", "(", "dataset", ")", ")", "\n", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.build_dataset_from_input": [[994, 1055], ["direct.utils.remove_keys", "datasets.build_dataset", "ValueError", "kwargs.update", "dict", "list", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.keys", "dict().keys", "dict"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.remove_keys", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.build_dataset", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "def", "build_dataset_from_input", "(", "\n", "transforms", ":", "Callable", ",", "\n", "dataset_config", ":", "DictConfig", ",", "\n", "**", "kwargs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", ")", "->", "Dataset", ":", "\n", "    ", "\"\"\"Builds dataset from input keyword arguments and configuration file.\n\n    Only `transforms` is common for all Datasets. ALL other keyword arguments should be passed in `**kwargs`.\n\n    Parameters\n    ----------\n    transforms: object, Callable\n        Transformation object.\n    dataset_config: DictConfig\n        Dataset configuration file.\n    kwargs: Dict[str, Any]\n        Can include:\n            * initial_images: List[pathlib.Path]\n                Path to initial_images.\n            * initial_kspaces: pathlib.Path\n                Path to initial kspace images.\n            * filenames_filter: Optional[List[PathOrString]]\n                List of filenames to include in the dataset, should be the same as the ones that can be derived from a glob\n                on the root. If set, will skip searching for files in the root.\n            * data_root: pathlib.Path or str\n                Root path to the data for the dataset class.\n            * pass_dictionaries: Optional[Dict[str, Dict]]\n\n    Returns\n    -------\n    Dataset\n    \"\"\"", "\n", "# Some datasets require `pass_h5s` argument.", "\n", "pass_h5s", "=", "None", "\n", "if", "\"initial_images\"", "in", "kwargs", "and", "\"initial_kspaces\"", "in", "kwargs", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"initial_images and initial_kspaces are mutually exclusive. \"", "\n", "f\"Got {kwargs.get('initial_images')} and {kwargs.get('initial_kspaces')}.\"", "\n", ")", "\n", "", "if", "\"initial_images\"", "in", "kwargs", ":", "\n", "        ", "pass_h5s", "=", "{", "\"initial_image\"", ":", "(", "dataset_config", ".", "input_image_key", ",", "kwargs", ".", "get", "(", "\"initial_images\"", ")", ")", "}", "\n", "del", "kwargs", "[", "\"initial_images\"", "]", "\n", "", "elif", "\"initial_kspaces\"", "in", "kwargs", ":", "\n", "        ", "pass_h5s", "=", "{", "\"initial_kspace\"", ":", "(", "dataset_config", ".", "input_kspace_key", ",", "kwargs", ".", "get", "(", "\"initial_kspaces\"", ")", ")", "}", "\n", "del", "kwargs", "[", "\"initial_kspaces\"", "]", "\n", "", "if", "pass_h5s", "is", "not", "None", ":", "\n", "        ", "kwargs", ".", "update", "(", "{", "\"pass_h5s\"", ":", "pass_h5s", "}", ")", "\n", "\n", "# This will remove double arguments passed both in kwargs and in the dataset configuration, keeping only in that", "\n", "# case the arguments in kwargs.", "\n", "# For example, `data_root` can be passed both from the command line and in the configuration file.", "\n", "", "config_kwargs", "=", "remove_keys", "(", "\n", "dict", "(", "dataset_config", ")", ",", "[", "\"name\"", ",", "\"transforms\"", "]", "+", "list", "(", "kwargs", ".", "keys", "(", ")", "&", "dict", "(", "dataset_config", ")", ".", "keys", "(", ")", ")", "\n", ")", "\n", "dataset", "=", "build_dataset", "(", "\n", "name", "=", "dataset_config", ".", "name", ",", "# type: ignore", "\n", "transforms", "=", "transforms", ",", "\n", "**", "kwargs", ",", "\n", "**", "config_kwargs", ",", "\n", ")", "\n", "return", "dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.__init__": [[42, 74], ["numpy.random.RandomState", "len", "len", "ValueError", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "accelerations", ":", "Optional", "[", "Tuple", "[", "Number", ",", "...", "]", "]", ",", "\n", "center_fractions", ":", "Optional", "[", "Tuple", "[", "float", ",", "...", "]", "]", "=", "None", ",", "\n", "uniform_range", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        center_fractions: List([float])\n            Fraction of low-frequency columns to be retained.\n            If multiple values are provided, then one of these numbers is chosen uniformly each time. If uniform_range\n            is True, then two values should be given.\n        accelerations: List([int])\n            Amount of under-sampling_mask. An acceleration of 4 retains 25% of the k-space, the method is given by\n            mask_type. Has to be the same length as center_fractions if uniform_range is True.\n        uniform_range: bool\n            If True then an acceleration will be uniformly sampled between the two values.\n        \"\"\"", "\n", "if", "center_fractions", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "[", "center_fractions", "]", ")", "!=", "len", "(", "[", "accelerations", "]", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Number of center fractions should match number of accelerations. \"", "\n", "f\"Got {len([center_fractions])} {len([accelerations])}.\"", "\n", ")", "\n", "\n", "", "", "self", ".", "center_fractions", "=", "center_fractions", "\n", "self", ".", "accelerations", "=", "accelerations", "\n", "\n", "self", ".", "uniform_range", "=", "uniform_range", "\n", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.choose_acceleration": [[75, 88], ["NotImplementedError", "subsample.BaseMaskFunc.rng.randint", "len"], "methods", ["None"], ["", "def", "choose_acceleration", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "accelerations", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "not", "self", ".", "uniform_range", ":", "\n", "            ", "choice", "=", "self", ".", "rng", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "accelerations", ")", ")", "\n", "acceleration", "=", "self", ".", "accelerations", "[", "choice", "]", "\n", "if", "self", ".", "center_fractions", "is", "None", ":", "\n", "                ", "return", "acceleration", "\n", "\n", "", "center_fraction", "=", "self", ".", "center_fractions", "[", "choice", "]", "\n", "return", "center_fraction", ",", "acceleration", "\n", "", "raise", "NotImplementedError", "(", "\"Uniform range is not yet implemented.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.mask_func": [[89, 92], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "mask_func", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"This method should be implemented by a child class.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.__call__": [[93, 108], ["subsample.BaseMaskFunc.mask_func"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.DictionaryMaskFunc.mask_func"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Produces a sampling mask by calling class method :meth:`mask_func`.\n\n        Parameters\n        ----------\n        *args\n        **kwargs\n\n        Returns\n        -------\n        mask: torch.Tensor\n            Sampling mask.\n        \"\"\"", "\n", "mask", "=", "self", ".", "mask_func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.FastMRIRandomMaskFunc.__init__": [[111, 121], ["subsample.BaseMaskFunc.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "accelerations", ":", "Tuple", "[", "Number", ",", "...", "]", ",", "\n", "center_fractions", ":", "Optional", "[", "Tuple", "[", "float", ",", "...", "]", "]", "=", "None", ",", "\n", "uniform_range", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", "center_fractions", "=", "center_fractions", ",", "\n", "uniform_range", "=", "uniform_range", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.FastMRIRandomMaskFunc.mask_func": [[123, 189], ["torch.from_numpy", "len", "ValueError", "subsample.temp_seed", "subsample.FastMRIRandomMaskFunc.choose_acceleration", "int", "[].copy.reshape().astype", "[].copy", "round", "subsample.FastMRIRandomMaskFunc.rng.uniform", "numpy.zeros_like", "torch.from_numpy", "[].copy.reshape", "numpy.broadcast_to"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.temp_seed", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.choose_acceleration"], ["", "def", "mask_func", "(", "self", ",", "shape", ",", "return_acs", "=", "False", ",", "seed", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Creates vertical line mask.\n\n        The mask selects a subset of columns from the input k-space data. If the k-space data has N\n        columns, the mask picks out:\n\n            #.  :math:`N_{\\text{low freqs}} = (N \\times \\text{center_fraction})`  columns in the center corresponding\n                to low-frequencies.\n            #.  The other columns are selected uniformly at random with a probability equal to:\n                :math:`\\text{prob} = (N / \\text{acceleration} - N_{\\text{low freqs}}) / (N - N_{\\text{low freqs}})`.\n                This ensures that the expected number of columns selected is equal to (N / acceleration).\n\n        It is possible to use multiple center_fractions and accelerations, in which case one possible\n        (center_fraction, acceleration) is chosen uniformly at random each time the MaskFunc object is\n        called.\n\n        For example, if accelerations = [4, 8] and center_fractions = [0.08, 0.04], then there\n        is a 50% probability that 4-fold acceleration with 8% center fraction is selected and a 50%\n        probability that 8-fold acceleration with 4% center fraction is selected.\n\n        Parameters\n        ----------\n        shape: iterable[int]\n            The shape of the mask to be created. The shape should at least 3 dimensions.\n            Samples are drawn along the second last dimension.\n        seed: int (optional)\n            Seed for the random number generator. Setting the seed ensures the same mask is generated\n             each time for the same shape.\n        return_acs: bool\n            Return the autocalibration signal region as a mask.\n\n        Returns\n        -------\n        mask: torch.Tensor\n            The sampling mask.\n        \"\"\"", "\n", "if", "len", "(", "shape", ")", "<", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"Shape should have 3 or more dimensions\"", ")", "\n", "\n", "", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "            ", "num_rows", "=", "shape", "[", "-", "3", "]", "\n", "num_cols", "=", "shape", "[", "-", "2", "]", "\n", "center_fraction", ",", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "\n", "# Create the mask", "\n", "num_low_freqs", "=", "int", "(", "round", "(", "num_cols", "*", "center_fraction", ")", ")", "\n", "prob", "=", "(", "num_cols", "/", "acceleration", "-", "num_low_freqs", ")", "/", "(", "num_cols", "-", "num_low_freqs", ")", "\n", "mask", "=", "self", ".", "rng", ".", "uniform", "(", "size", "=", "num_cols", ")", "<", "prob", "\n", "pad", "=", "(", "num_cols", "-", "num_low_freqs", "+", "1", ")", "//", "2", "\n", "mask", "[", "pad", ":", "pad", "+", "num_low_freqs", "]", "=", "True", "\n", "\n", "# Reshape the mask", "\n", "mask_shape", "=", "[", "1", "for", "_", "in", "shape", "]", "\n", "mask_shape", "[", "-", "2", "]", "=", "num_cols", "\n", "mask", "=", "mask", ".", "reshape", "(", "*", "mask_shape", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "mask_shape", "[", "-", "3", "]", "=", "num_rows", "\n", "\n", "mask", "=", "np", ".", "broadcast_to", "(", "mask", ",", "mask_shape", ")", "[", "np", ".", "newaxis", ",", "...", "]", ".", "copy", "(", ")", "# Add coil axis, make array writable.", "\n", "\n", "# TODO: Think about making this more efficient.", "\n", "if", "return_acs", ":", "\n", "                ", "acs_mask", "=", "np", ".", "zeros_like", "(", "mask", ")", "\n", "acs_mask", "[", ":", ",", ":", ",", "pad", ":", "pad", "+", "num_low_freqs", ",", "...", "]", "=", "1", "\n", "return", "torch", ".", "from_numpy", "(", "acs_mask", ")", "\n", "\n", "", "", "return", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.FastMRIEquispacedMaskFunc.__init__": [[192, 202], ["subsample.BaseMaskFunc.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "accelerations", ":", "Tuple", "[", "Number", ",", "...", "]", ",", "\n", "center_fractions", ":", "Optional", "[", "Tuple", "[", "float", ",", "...", "]", "]", "=", "None", ",", "\n", "uniform_range", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", "center_fractions", "=", "center_fractions", ",", "\n", "uniform_range", "=", "uniform_range", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.FastMRIEquispacedMaskFunc.mask_func": [[204, 275], ["torch.from_numpy", "len", "ValueError", "subsample.temp_seed", "subsample.FastMRIEquispacedMaskFunc.choose_acceleration", "int", "numpy.zeros", "subsample.FastMRIEquispacedMaskFunc.rng.randint", "numpy.arange", "numpy.around().astype", "[].copy.reshape().astype", "[].copy", "round", "round", "numpy.zeros_like", "torch.from_numpy", "numpy.around", "[].copy.reshape", "numpy.broadcast_to"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.temp_seed", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.choose_acceleration"], ["", "def", "mask_func", "(", "self", ",", "shape", ",", "return_acs", "=", "False", ",", "seed", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Creates equispaced vertical line mask.\n\n        FastMRIEquispacedMaskFunc creates a sub-sampling mask of a given shape. The mask selects a subset of columns\n        from the input k-space data. If the k-space data has N columns, the mask picks out:\n\n            #.  :math:`N_{\\text{low freqs}} = (N \\times \\text{center_fraction})` columns in the center corresponding\n                to low-frequencies.\n            #.  The other columns are selected with equal spacing at a proportion that reaches the desired acceleration\n                rate taking into consideration the number of low frequencies. This ensures that the expected number of\n                columns selected is equal to :math:`\\frac{N}{\\text{acceleration}}`.\n\n        It is possible to use multiple center_fractions and accelerations, in which case one possible\n        (center_fraction, acceleration) is chosen uniformly at random each time the EquispacedMaskFunc object is called.\n\n        Note that this function may not give equispaced samples (documented in\n        https://github.com/facebookresearch/fastMRI/issues/54), which will require modifications to standard GRAPPA\n        approaches. Nonetheless, this aspect of the function has been preserved to match the public multicoil data.\n\n        Parameters\n        ----------\n        shape: iterable[int]\n            The shape of the mask to be created. The shape should at least 3 dimensions.\n            Samples are drawn along the second last dimension.\n        seed: int (optional)\n            Seed for the random number generator. Setting the seed ensures the same mask is generated\n             each time for the same shape.\n        return_acs: bool\n            Return the autocalibration signal region as a mask.\n\n        Returns\n        -------\n        mask: torch.Tensor\n            The sampling mask.\n        \"\"\"", "\n", "if", "len", "(", "shape", ")", "<", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"Shape should have 3 or more dimensions\"", ")", "\n", "\n", "", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "            ", "center_fraction", ",", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "num_cols", "=", "shape", "[", "-", "2", "]", "\n", "num_rows", "=", "shape", "[", "-", "3", "]", "\n", "num_low_freqs", "=", "int", "(", "round", "(", "num_cols", "*", "center_fraction", ")", ")", "\n", "\n", "# create the mask", "\n", "mask", "=", "np", ".", "zeros", "(", "num_cols", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "pad", "=", "(", "num_cols", "-", "num_low_freqs", "+", "1", ")", "//", "2", "\n", "mask", "[", "pad", ":", "pad", "+", "num_low_freqs", "]", "=", "True", "\n", "\n", "# determine acceleration rate by adjusting for the number of low frequencies", "\n", "adjusted_accel", "=", "(", "acceleration", "*", "(", "num_low_freqs", "-", "num_cols", ")", ")", "/", "(", "num_low_freqs", "*", "acceleration", "-", "num_cols", ")", "\n", "offset", "=", "self", ".", "rng", ".", "randint", "(", "0", ",", "round", "(", "adjusted_accel", ")", ")", "\n", "\n", "accel_samples", "=", "np", ".", "arange", "(", "offset", ",", "num_cols", "-", "1", ",", "adjusted_accel", ")", "\n", "accel_samples", "=", "np", ".", "around", "(", "accel_samples", ")", ".", "astype", "(", "np", ".", "uint", ")", "\n", "mask", "[", "accel_samples", "]", "=", "True", "\n", "\n", "# Reshape the mask", "\n", "mask_shape", "=", "[", "1", "for", "_", "in", "shape", "]", "\n", "mask_shape", "[", "-", "2", "]", "=", "num_cols", "\n", "mask", "=", "mask", ".", "reshape", "(", "*", "mask_shape", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "mask_shape", "[", "-", "3", "]", "=", "num_rows", "\n", "\n", "mask", "=", "np", ".", "broadcast_to", "(", "mask", ",", "mask_shape", ")", "[", "np", ".", "newaxis", ",", "...", "]", ".", "copy", "(", ")", "# Add coil axis, make array writable.", "\n", "\n", "if", "return_acs", ":", "\n", "                ", "acs_mask", "=", "np", ".", "zeros_like", "(", "mask", ")", "\n", "acs_mask", "[", ":", ",", ":", ",", "pad", ":", "pad", "+", "num_low_freqs", ",", "...", "]", "=", "1", "\n", "return", "torch", ".", "from_numpy", "(", "acs_mask", ")", "\n", "\n", "", "", "return", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CalgaryCampinasMaskFunc.__init__": [[289, 300], ["subsample.BaseMaskFunc.__init__", "all", "ValueError", "subsample.CalgaryCampinasMaskFunc.__load_masks"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CalgaryCampinasMaskFunc.__load_masks"], ["def", "__init__", "(", "self", ",", "accelerations", ":", "Tuple", "[", "int", ",", "...", "]", ",", "**", "kwargs", ")", ":", "# noqa", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "accelerations", "=", "accelerations", ",", "uniform_range", "=", "False", ")", "\n", "\n", "if", "not", "all", "(", "_", "in", "[", "5", ",", "10", "]", "for", "_", "in", "accelerations", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"CalgaryCampinas only provide 5x and 10x acceleration masks.\"", ")", "\n", "\n", "", "self", ".", "masks", "=", "{", "}", "\n", "self", ".", "shapes", ":", "List", "[", "Number", "]", "=", "[", "]", "\n", "\n", "for", "acceleration", "in", "accelerations", ":", "\n", "            ", "self", ".", "masks", "[", "acceleration", "]", "=", "self", ".", "__load_masks", "(", "acceleration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CalgaryCampinasMaskFunc.circular_centered_mask": [[301, 308], ["numpy.sqrt", "numpy.asarray", "numpy.ones"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "circular_centered_mask", "(", "shape", ",", "radius", ")", ":", "\n", "        ", "center", "=", "np", ".", "asarray", "(", "shape", ")", "//", "2", "\n", "Y", ",", "X", "=", "np", ".", "ogrid", "[", ":", "shape", "[", "0", "]", ",", ":", "shape", "[", "1", "]", "]", "\n", "dist_from_center", "=", "np", ".", "sqrt", "(", "(", "X", "-", "center", "[", "1", "]", ")", "**", "2", "+", "(", "Y", "-", "center", "[", "0", "]", ")", "**", "2", ")", "\n", "mask", "=", "(", "(", "dist_from_center", "<=", "radius", ")", "*", "np", ".", "ones", "(", "shape", ")", ")", ".", "astype", "(", "bool", ")", "\n", "return", "mask", "[", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CalgaryCampinasMaskFunc.mask_func": [[309, 347], ["torch.from_numpy", "tuple", "torch.from_numpy", "ValueError", "subsample.temp_seed", "subsample.CalgaryCampinasMaskFunc.choose_acceleration", "subsample.CalgaryCampinasMaskFunc.rng.randint", "subsample.CalgaryCampinasMaskFunc.circular_centered_mask"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.temp_seed", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.choose_acceleration", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circular_centered_mask"], ["", "def", "mask_func", "(", "self", ",", "shape", ",", "return_acs", "=", "False", ",", "seed", "=", "None", ")", ":", "\n", "        ", "r\"\"\"Downloads and loads pre-computed Poisson masks.\n\n        Currently supports shapes of :math`218 \\times 170/174/180` and acceleration factors of `5` or `10`.\n\n        Parameters\n        ----------\n\n        shape: iterable[int]\n            The shape of the mask to be created. The shape should at least 3 dimensions.\n            Samples are drawn along the second last dimension.\n        seed: int (optional)\n            Seed for the random number generator. Setting the seed ensures the same mask is generated\n             each time for the same shape.\n        return_acs: bool\n            Return the autocalibration signal region as a mask.\n\n        Returns\n        -------\n        mask: torch.Tensor\n            The sampling mask.\n        \"\"\"", "\n", "shape", "=", "tuple", "(", "shape", ")", "[", ":", "-", "1", "]", "\n", "if", "return_acs", ":", "\n", "            ", "return", "torch", ".", "from_numpy", "(", "self", ".", "circular_centered_mask", "(", "shape", ",", "18", ")", ")", "\n", "\n", "", "if", "shape", "not", "in", "self", ".", "shapes", ":", "\n", "            ", "raise", "ValueError", "(", "f\"No mask of shape {shape} is available in the CalgaryCampinas dataset.\"", ")", "\n", "\n", "", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "            ", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "masks", "=", "self", ".", "masks", "[", "acceleration", "]", "\n", "\n", "mask", ",", "num_masks", "=", "masks", "[", "shape", "]", "\n", "# Randomly pick one example", "\n", "choice", "=", "self", ".", "rng", ".", "randint", "(", "0", ",", "num_masks", ")", "\n", "\n", "", "return", "torch", ".", "from_numpy", "(", "mask", "[", "choice", "]", "[", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CalgaryCampinasMaskFunc.__load_masks": [[348, 368], ["all", "RuntimeError", "subsample.CalgaryCampinasMaskFunc.shapes.append", "numpy.load", "direct.utils.io.download_url", "int", "tuple", "[].split", "tuple", "path.split"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.download_url"], ["", "def", "__load_masks", "(", "self", ",", "acceleration", ")", ":", "\n", "        ", "masks_path", "=", "DIRECT_CACHE_DIR", "/", "\"calgary_campinas_masks\"", "\n", "paths", "=", "[", "\n", "f\"R{acceleration}_218x170.npy\"", ",", "\n", "f\"R{acceleration}_218x174.npy\"", ",", "\n", "f\"R{acceleration}_218x180.npy\"", ",", "\n", "]", "\n", "\n", "downloaded", "=", "[", "download_url", "(", "self", ".", "BASE_URL", "+", "_", ",", "masks_path", ",", "md5", "=", "self", ".", "MASK_MD5S", "[", "_", "]", ")", "is", "None", "for", "_", "in", "paths", "]", "\n", "if", "not", "all", "(", "downloaded", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"Failed to download all Calgary-Campinas masks from {self.BASE_URL}.\"", ")", "\n", "\n", "", "output", "=", "{", "}", "\n", "for", "path", "in", "paths", ":", "\n", "            ", "shape", "=", "[", "int", "(", "_", ")", "for", "_", "in", "path", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ".", "split", "(", "\"x\"", ")", "]", "\n", "self", ".", "shapes", ".", "append", "(", "tuple", "(", "shape", ")", ")", "\n", "mask_array", "=", "np", ".", "load", "(", "masks_path", "/", "path", ")", "\n", "output", "[", "tuple", "(", "shape", ")", "]", "=", "mask_array", ",", "mask_array", ".", "shape", "[", "0", "]", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.__init__": [[388, 406], ["subsample.BaseMaskFunc.__init__", "NotImplementedError", "tuple", "range", "len"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "accelerations", ",", "\n", "subsampling_scheme", ":", "CIRCUSSamplingMode", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", "center_fractions", "=", "tuple", "(", "0", "for", "_", "in", "range", "(", "len", "(", "accelerations", ")", ")", ")", ",", "\n", "uniform_range", "=", "False", ",", "\n", ")", "\n", "if", "subsampling_scheme", "not", "in", "[", "\"circus-spiral\"", ",", "\"circus-radial\"", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"Currently CIRCUSMaskFunc is only implemented for 'circus-radial' or 'circus-spiral' \"", "\n", "f\"as a subsampling_scheme. Got subsampling_scheme={subsampling_scheme}.\"", "\n", ")", "\n", "\n", "", "self", ".", "subsampling_scheme", "=", "\"circus-radial\"", "if", "subsampling_scheme", "is", "None", "else", "subsampling_scheme", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.get_square_ordered_idxs": [[407, 441], ["list", "range", "range", "range", "range", "tuple", "range", "list.append", "list.append", "list.append", "list.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_square_ordered_idxs", "(", "square_side_size", ":", "int", ",", "square_id", ":", "int", ")", "->", "Tuple", "[", "Tuple", ",", "...", "]", ":", "\n", "        ", "\"\"\"Returns ordered (clockwise) indices of a sub-square of a square matrix.\n\n        Parameters\n        ----------\n        square_side_size: int\n            Square side size. Dim of array.\n        square_id: int\n            Number of sub-square. Can be 0, ..., square_side_size // 2.\n\n        Returns\n        -------\n        ordered_idxs: List of tuples.\n            Indices of each point that belongs to the square_id-th sub-square\n            starting from top-left point clockwise.\n        \"\"\"", "\n", "assert", "square_id", "in", "range", "(", "square_side_size", "//", "2", ")", "\n", "\n", "ordered_idxs", "=", "list", "(", ")", "\n", "\n", "for", "col", "in", "range", "(", "square_id", ",", "square_side_size", "-", "square_id", ")", ":", "\n", "            ", "ordered_idxs", ".", "append", "(", "(", "square_id", ",", "col", ")", ")", "\n", "\n", "", "for", "row", "in", "range", "(", "square_id", "+", "1", ",", "square_side_size", "-", "(", "square_id", "+", "1", ")", ")", ":", "\n", "            ", "ordered_idxs", ".", "append", "(", "(", "row", ",", "square_side_size", "-", "(", "square_id", "+", "1", ")", ")", ")", "\n", "\n", "", "for", "col", "in", "range", "(", "square_side_size", "-", "(", "square_id", "+", "1", ")", ",", "square_id", ",", "-", "1", ")", ":", "\n", "            ", "ordered_idxs", ".", "append", "(", "(", "square_side_size", "-", "(", "square_id", "+", "1", ")", ",", "col", ")", ")", "\n", "\n", "", "for", "row", "in", "range", "(", "square_side_size", "-", "(", "square_id", "+", "1", ")", ",", "square_id", ",", "-", "1", ")", ":", "\n", "            ", "ordered_idxs", ".", "append", "(", "(", "row", ",", "square_id", ")", ")", "\n", "\n", "", "return", "tuple", "(", "ordered_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circus_radial_mask": [[442, 473], ["int", "numpy.zeros", "subsample.CIRCUSMaskFunc.rng.randint().item", "range", "numpy.pad", "direct.center_crop", "max", "min", "subsample.CIRCUSMaskFunc.get_square_ordered_idxs", "range", "torch.from_numpy", "max", "min", "numpy.prod", "subsample.CIRCUSMaskFunc.rng.randint", "int", "direct.center_crop.astype", "numpy.floor", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.center_crop", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.get_square_ordered_idxs"], ["", "def", "circus_radial_mask", "(", "self", ",", "shape", ",", "acceleration", ")", ":", "\n", "        ", "\"\"\"Implements CIRCUS radial undersampling.\"\"\"", "\n", "max_dim", "=", "max", "(", "shape", ")", "-", "max", "(", "shape", ")", "%", "2", "\n", "min_dim", "=", "min", "(", "shape", ")", "-", "min", "(", "shape", ")", "%", "2", "\n", "num_nested_squares", "=", "max_dim", "//", "2", "\n", "M", "=", "int", "(", "np", ".", "prod", "(", "shape", ")", "/", "(", "acceleration", "*", "(", "max_dim", "/", "2", "-", "(", "max_dim", "-", "min_dim", ")", "*", "(", "1", "+", "min_dim", "/", "max_dim", ")", "/", "4", ")", ")", ")", "\n", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "max_dim", ",", "max_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "t", "=", "self", ".", "rng", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "1e4", ",", "size", "=", "1", ",", "dtype", "=", "int", ")", ".", "item", "(", ")", "\n", "\n", "for", "square_id", "in", "range", "(", "num_nested_squares", ")", ":", "\n", "            ", "ordered_indices", "=", "self", ".", "get_square_ordered_idxs", "(", "\n", "square_side_size", "=", "max_dim", ",", "\n", "square_id", "=", "square_id", ",", "\n", ")", "\n", "# J: size of the square, J=2,\u2026,N, i.e., the number of points along one side of the square", "\n", "J", "=", "2", "*", "(", "num_nested_squares", "-", "square_id", ")", "\n", "# K: total number of points along the perimeter of the square K=4\u00b7J-4;", "\n", "K", "=", "4", "*", "(", "J", "-", "1", ")", "\n", "\n", "for", "m", "in", "range", "(", "M", ")", ":", "\n", "                ", "indices_idx", "=", "int", "(", "np", ".", "floor", "(", "np", ".", "mod", "(", "(", "m", "+", "t", "*", "M", ")", "/", "GOLDEN_RATIO", ",", "1", ")", "*", "K", ")", ")", "\n", "mask", "[", "ordered_indices", "[", "indices_idx", "]", "]", "=", "1.0", "\n", "\n", "", "", "pad", "=", "(", "(", "shape", "[", "0", "]", "%", "2", ",", "0", ")", ",", "(", "shape", "[", "1", "]", "%", "2", ",", "0", ")", ")", "\n", "\n", "mask", "=", "np", ".", "pad", "(", "mask", ",", "pad", ",", "constant_values", "=", "0", ")", "\n", "mask", "=", "T", ".", "center_crop", "(", "torch", ".", "from_numpy", "(", "mask", ".", "astype", "(", "bool", ")", ")", ",", "shape", ")", "\n", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circus_spiral_mask": [[474, 511], ["int", "numpy.zeros", "subsample.CIRCUSMaskFunc.rng.uniform().item", "range", "numpy.pad", "direct.center_crop", "max", "min", "subsample.CIRCUSMaskFunc.get_square_ordered_idxs", "range", "torch.from_numpy", "max", "min", "numpy.prod", "subsample.CIRCUSMaskFunc.rng.uniform", "numpy.floor", "int", "direct.center_crop.astype", "numpy.mod", "numpy.mod", "numpy.ceil"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.unet.unet_2d.NormUnetModel2d.pad", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.center_crop", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.get_square_ordered_idxs"], ["", "def", "circus_spiral_mask", "(", "self", ",", "shape", ",", "acceleration", ")", ":", "\n", "        ", "\"\"\"Implements CIRCUS spiral undersampling.\"\"\"", "\n", "max_dim", "=", "max", "(", "shape", ")", "-", "max", "(", "shape", ")", "%", "2", "\n", "min_dim", "=", "min", "(", "shape", ")", "-", "min", "(", "shape", ")", "%", "2", "\n", "\n", "num_nested_squares", "=", "max_dim", "//", "2", "\n", "\n", "M", "=", "int", "(", "np", ".", "prod", "(", "shape", ")", "/", "(", "acceleration", "*", "(", "max_dim", "/", "2", "-", "(", "max_dim", "-", "min_dim", ")", "*", "(", "1", "+", "min_dim", "/", "max_dim", ")", "/", "4", ")", ")", ")", "\n", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "max_dim", ",", "max_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "c", "=", "self", ".", "rng", ".", "uniform", "(", "low", "=", "1.1", ",", "high", "=", "1.3", ",", "size", "=", "1", ")", ".", "item", "(", ")", "\n", "\n", "for", "square_id", "in", "range", "(", "num_nested_squares", ")", ":", "\n", "\n", "            ", "ordered_indices", "=", "self", ".", "get_square_ordered_idxs", "(", "\n", "square_side_size", "=", "max_dim", ",", "\n", "square_id", "=", "square_id", ",", "\n", ")", "\n", "\n", "# J: size of the square, J=2,\u2026,N, i.e., the number of points along one side of the square", "\n", "J", "=", "2", "*", "(", "num_nested_squares", "-", "square_id", ")", "\n", "# K: total number of points along the perimeter of the square K=4\u00b7J-4;", "\n", "K", "=", "4", "*", "(", "J", "-", "1", ")", "\n", "\n", "for", "m", "in", "range", "(", "M", ")", ":", "\n", "                ", "i", "=", "np", ".", "floor", "(", "np", ".", "mod", "(", "m", "/", "GOLDEN_RATIO", ",", "1", ")", "*", "K", ")", "\n", "indices_idx", "=", "int", "(", "np", ".", "mod", "(", "(", "i", "+", "np", ".", "ceil", "(", "J", "**", "c", ")", "-", "1", ")", ",", "K", ")", ")", "\n", "\n", "mask", "[", "ordered_indices", "[", "indices_idx", "]", "]", "=", "1.0", "\n", "\n", "", "", "pad", "=", "(", "(", "shape", "[", "0", "]", "%", "2", ",", "0", ")", ",", "(", "shape", "[", "1", "]", "%", "2", ",", "0", ")", ")", "\n", "\n", "mask", "=", "np", ".", "pad", "(", "mask", ",", "pad", ")", "\n", "mask", "=", "T", ".", "center_crop", "(", "torch", ".", "from_numpy", "(", "mask", ".", "astype", "(", "bool", ")", ")", ",", "shape", ")", "\n", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circular_centered_mask": [[512, 529], ["numpy.asarray", "torch.tensor", "torch.tensor", "disk.sum", "intersection.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "circular_centered_mask", "(", "mask", ",", "eps", "=", "0.1", ")", ":", "\n", "        ", "shape", "=", "mask", ".", "shape", "\n", "center", "=", "np", ".", "asarray", "(", "shape", ")", "//", "2", "\n", "Y", ",", "X", "=", "np", ".", "ogrid", "[", ":", "shape", "[", "0", "]", ",", ":", "shape", "[", "1", "]", "]", "\n", "Y", ",", "X", "=", "torch", ".", "tensor", "(", "Y", ")", ",", "torch", ".", "tensor", "(", "X", ")", "\n", "radius", "=", "1", "\n", "\n", "# Finds the maximum (unmasked) disk in mask given a tolerance.", "\n", "while", "True", ":", "\n", "# Creates a disk with R=radius and finds intersection with mask", "\n", "            ", "disk", "=", "(", "Y", "-", "center", "[", "0", "]", ")", "**", "2", "+", "(", "X", "-", "center", "[", "1", "]", ")", "**", "2", "<=", "radius", "**", "2", "\n", "intersection", "=", "disk", "&", "mask", "\n", "ratio", "=", "disk", ".", "sum", "(", ")", "/", "intersection", ".", "sum", "(", ")", "\n", "if", "ratio", ">", "1.0", "+", "eps", ":", "\n", "                ", "return", "intersection", "\n", "", "radius", "+=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.mask_func": [[530, 555], ["len", "ValueError", "subsample.temp_seed", "subsample.CIRCUSMaskFunc.unsqueeze().unsqueeze", "subsample.CIRCUSMaskFunc.choose_acceleration", "subsample.CIRCUSMaskFunc.circus_radial_mask", "subsample.CIRCUSMaskFunc.circular_centered_mask().unsqueeze().unsqueeze", "subsample.CIRCUSMaskFunc.circus_spiral_mask", "subsample.CIRCUSMaskFunc.unsqueeze", "subsample.CIRCUSMaskFunc.circular_centered_mask().unsqueeze", "subsample.CIRCUSMaskFunc.circular_centered_mask"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.temp_seed", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.BaseMaskFunc.choose_acceleration", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circus_radial_mask", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circus_spiral_mask", "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circular_centered_mask"], ["", "", "def", "mask_func", "(", "self", ",", "shape", ",", "return_acs", "=", "False", ",", "seed", "=", "None", ")", ":", "\n", "\n", "        ", "if", "len", "(", "shape", ")", "<", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"Shape should have 3 or more dimensions\"", ")", "\n", "\n", "", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "            ", "num_rows", "=", "shape", "[", "-", "3", "]", "\n", "num_cols", "=", "shape", "[", "-", "2", "]", "\n", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "[", "1", "]", "\n", "\n", "if", "self", ".", "subsampling_scheme", "==", "\"circus-radial\"", ":", "\n", "                ", "mask", "=", "self", ".", "circus_radial_mask", "(", "\n", "shape", "=", "(", "num_rows", ",", "num_cols", ")", ",", "\n", "acceleration", "=", "acceleration", ",", "\n", ")", "\n", "", "elif", "self", ".", "subsampling_scheme", "==", "\"circus-spiral\"", ":", "\n", "                ", "mask", "=", "self", ".", "circus_spiral_mask", "(", "\n", "shape", "=", "(", "num_rows", ",", "num_cols", ")", ",", "\n", "acceleration", "=", "acceleration", ",", "\n", ")", "\n", "\n", "", "if", "return_acs", ":", "\n", "                ", "return", "self", ".", "circular_centered_mask", "(", "mask", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "return", "mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.RadialMaskFunc.__init__": [[560, 569], ["subsample.CIRCUSMaskFunc.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "accelerations", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", "subsampling_scheme", "=", "CIRCUSSamplingMode", ".", "circus_radial", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.SpiralMaskFunc.__init__": [[575, 584], ["subsample.CIRCUSMaskFunc.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "accelerations", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", "subsampling_scheme", "=", "CIRCUSSamplingMode", ".", "circus_spiral", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.DictionaryMaskFunc.__init__": [[588, 592], ["subsample.BaseMaskFunc.__init__"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_dictionary", ",", "**", "kwargs", ")", ":", "# noqa", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "accelerations", "=", "None", ")", "\n", "\n", "self", ".", "data_dictionary", "=", "data_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.DictionaryMaskFunc.mask_func": [[593, 595], ["None"], "methods", ["None"], ["", "def", "mask_func", "(", "self", ",", "data", ",", "return_acs", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "data_dictionary", "[", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.temp_seed": [[29, 37], ["rng.get_state", "rng.seed", "rng.set_state"], "function", ["None"], ["@", "contextlib", ".", "contextmanager", "\n", "def", "temp_seed", "(", "rng", ",", "seed", ")", ":", "\n", "    ", "state", "=", "rng", ".", "get_state", "(", ")", "\n", "rng", ".", "seed", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "rng", ".", "set_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.common.subsample.build_masking_function": [[597, 606], ["direct.utils.str_to_class", "MaskFunc"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.str_to_class"], ["", "", "def", "build_masking_function", "(", "name", ",", "accelerations", ",", "center_fractions", "=", "None", ",", "uniform_range", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "MaskFunc", ":", "BaseMaskFunc", "=", "str_to_class", "(", "\"direct.common.subsample\"", ",", "name", "+", "\"MaskFunc\"", ")", "# noqa", "\n", "mask_func", "=", "MaskFunc", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", "center_fractions", "=", "center_fractions", ",", "\n", "uniform_range", "=", "uniform_range", ",", "\n", ")", "\n", "\n", "return", "mask_func", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.docs.conf.linkcode_resolve": [[245, 287], ["sys.modules.get", "fullname.split", "inspect.unwrap", "os.path.relpath", "inspect.getsourcefile", "inspect.getsourcelines", "getattr", "os.path.dirname", "len"], "function", ["None"], ["def", "linkcode_resolve", "(", "domain", ",", "info", ")", ":", "\n", "    ", "\"\"\"Determine the URL corresponding to Python object.\"\"\"", "\n", "if", "domain", "!=", "\"py\"", ":", "\n", "        ", "return", "None", "\n", "\n", "", "modname", "=", "info", "[", "\"module\"", "]", "\n", "fullname", "=", "info", "[", "\"fullname\"", "]", "\n", "\n", "submod", "=", "sys", ".", "modules", ".", "get", "(", "modname", ")", "\n", "if", "submod", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "obj", "=", "submod", "\n", "for", "part", "in", "fullname", ".", "split", "(", "\".\"", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "obj", "=", "getattr", "(", "obj", ",", "part", ")", "\n", "", "except", ":", "\n", "            ", "return", "None", "\n", "\n", "# Strip decorators which would resolve to the source of the decorator", "\n", "", "", "obj", "=", "inspect", ".", "unwrap", "(", "obj", ")", "\n", "\n", "try", ":", "\n", "        ", "fn", "=", "inspect", ".", "getsourcefile", "(", "obj", ")", "\n", "", "except", ":", "\n", "        ", "fn", "=", "None", "\n", "", "if", "not", "fn", ":", "\n", "        ", "return", "None", "\n", "\n", "", "try", ":", "\n", "        ", "source", ",", "start_line", "=", "inspect", ".", "getsourcelines", "(", "obj", ")", "\n", "", "except", ":", "\n", "        ", "linespec", "=", "\"\"", "\n", "", "else", ":", "\n", "        ", "stop_line", "=", "start_line", "+", "len", "(", "source", ")", "-", "1", "\n", "linespec", "=", "f\"#L{start_line}-L{stop_line}\"", "\n", "\n", "", "fn", "=", "relpath", "(", "fn", ",", "start", "=", "dirname", "(", "direct", ".", "__file__", ")", ")", "\n", "\n", "if", "\"dev\"", "in", "direct", ".", "__version__", ":", "\n", "        ", "return", "\"https://github.com/NKI-AI/direct/blob/\"", "\"main/direct/%s%s\"", "%", "(", "fn", ",", "linespec", ")", "\n", "", "return", "\"https://github.com/NKI-AI/direct/blob/\"", "\"v%s/direct/%s%s\"", "%", "(", "direct", ".", "__version__", ",", "fn", ",", "linespec", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.ext.doi_role.doi_role": [[23, 31], ["docutils.utils.unescape", "sphinx.util.nodes.split_explicit_title", "docutils.nodes.reference"], "function", ["None"], ["def", "doi_role", "(", "typ", ",", "rawtext", ",", "text", ",", "lineno", ",", "inliner", ",", "options", "=", "{", "}", ",", "content", "=", "[", "]", ")", ":", "\n", "    ", "text", "=", "utils", ".", "unescape", "(", "text", ")", "\n", "has_explicit_title", ",", "title", ",", "part", "=", "split_explicit_title", "(", "text", ")", "\n", "full_url", "=", "\"https://doi.org/\"", "+", "part", "\n", "if", "not", "has_explicit_title", ":", "\n", "        ", "title", "=", "\"DOI:\"", "+", "part", "\n", "", "pnode", "=", "nodes", ".", "reference", "(", "title", ",", "title", ",", "internal", "=", "False", ",", "refuri", "=", "full_url", ")", "\n", "return", "[", "pnode", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.ext.doi_role.arxiv_role": [[33, 41], ["docutils.utils.unescape", "sphinx.util.nodes.split_explicit_title", "docutils.nodes.reference"], "function", ["None"], ["", "def", "arxiv_role", "(", "typ", ",", "rawtext", ",", "text", ",", "lineno", ",", "inliner", ",", "options", "=", "{", "}", ",", "content", "=", "[", "]", ")", ":", "\n", "    ", "text", "=", "utils", ".", "unescape", "(", "text", ")", "\n", "has_explicit_title", ",", "title", ",", "part", "=", "split_explicit_title", "(", "text", ")", "\n", "full_url", "=", "\"https://arxiv.org/abs/\"", "+", "part", "\n", "if", "not", "has_explicit_title", ":", "\n", "        ", "title", "=", "\"arXiv:\"", "+", "part", "\n", "", "pnode", "=", "nodes", ".", "reference", "(", "title", ",", "title", ",", "internal", "=", "False", ",", "refuri", "=", "full_url", ")", "\n", "return", "[", "pnode", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.ext.doi_role.setup_link_role": [[43, 48], ["app.add_role", "app.add_role", "app.add_role", "app.add_role"], "function", ["None"], ["", "def", "setup_link_role", "(", "app", ")", ":", "\n", "    ", "app", ".", "add_role", "(", "\"doi\"", ",", "doi_role", ",", "override", "=", "True", ")", "\n", "app", ".", "add_role", "(", "\"DOI\"", ",", "doi_role", ",", "override", "=", "True", ")", "\n", "app", ".", "add_role", "(", "\"arXiv\"", ",", "arxiv_role", ",", "override", "=", "True", ")", "\n", "app", ".", "add_role", "(", "\"arxiv\"", ",", "arxiv_role", ",", "override", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.ext.doi_role.setup": [[50, 53], ["app.connect"], "function", ["None"], ["", "def", "setup", "(", "app", ")", ":", "\n", "    ", "app", ".", "connect", "(", "\"builder-inited\"", ",", "setup_link_role", ")", "\n", "return", "{", "\"version\"", ":", "\"0.1\"", ",", "\"parallel_read_safe\"", ":", "True", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.projects.predict_val._get_transforms": [[22, 27], ["direct.common.subsample.build_masking_function", "direct.inference.build_inference_transforms"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.build_masking_function", "home.repos.pwc.inspect_result.directgroup_direct.direct.inference.build_inference_transforms"], ["def", "_get_transforms", "(", "validation_index", ",", "env", ")", ":", "\n", "    ", "dataset_cfg", "=", "env", ".", "cfg", ".", "validation", ".", "datasets", "[", "validation_index", "]", "\n", "mask_func", "=", "build_masking_function", "(", "**", "dataset_cfg", ".", "transforms", ".", "masking", ")", "\n", "transforms", "=", "build_inference_transforms", "(", "env", ",", "mask_func", ",", "dataset_cfg", ")", "\n", "return", "dataset_cfg", ",", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.calgary_campinas.predict_test.CreateSamplingMask.__init__": [[26, 28], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "masks_dict", ")", ":", "\n", "        ", "self", ".", "masks_dict", "=", "masks_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.calgary_campinas.predict_test.CreateSamplingMask.__call__": [[29, 36], ["direct.common.subsample.CalgaryCampinasMaskFunc().circular_centered_mask", "direct.common.subsample.CalgaryCampinasMaskFunc"], "methods", ["home.repos.pwc.inspect_result.directgroup_direct.common.subsample.CIRCUSMaskFunc.circular_centered_mask"], ["", "def", "__call__", "(", "self", ",", "sample", ",", "**", "kwargs", ")", ":", "\n", "        ", "sample", "[", "\"sampling_mask\"", "]", "=", "self", ".", "masks_dict", "[", "sample", "[", "\"filename\"", "]", "]", "[", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "\n", "sample", "[", "\"acs_mask\"", "]", "=", "CalgaryCampinasMaskFunc", "(", "accelerations", "=", "[", "]", ")", ".", "circular_centered_mask", "(", "\n", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "1", ":", "]", ",", "18", "\n", ")", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.calgary_campinas.predict_test.inference_cfg_validation": [[38, 62], ["logger.warning", "logger.warning", "logger.warning"], "function", ["None"], ["", "", "def", "inference_cfg_validation", "(", "cfg", ")", ":", "\n", "# Some checks for the inference", "\n", "    ", "if", "cfg", ".", "inference", ".", "dataset", ".", "transforms", ".", "crop", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"cfg.inference.dataset.transforms.crop has to be None in inference. \"", "\n", "f\"Got {cfg.inference.dataset.transforms.crop}.\"", "\n", ")", "\n", "cfg", ".", "inference", ".", "dataset", ".", "transforms", ".", "crop", "=", "None", "\n", "\n", "", "if", "cfg", ".", "inference", ".", "dataset", ".", "transforms", ".", "image_center_crop", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"cfg.inference.dataset.transforms.image_center_crop has to be None in inference. \"", "\n", "f\"Got {cfg.inference.dataset.transforms.image_center_crop}.\"", "\n", ")", "\n", "cfg", ".", "inference", ".", "dataset", ".", "transforms", ".", "image_center_crop", "=", "None", "\n", "\n", "", "if", "cfg", ".", "inference", ".", "dataset", ".", "transforms", ".", "masking", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"cfg.inference.dataset.transforms.masking does not make sense in inference, but is set. \"", "\n", "f\"Got {cfg.inference.dataset.transforms.masking}.\"", "\n", ")", "\n", "cfg", ".", "inference", ".", "dataset", ".", "transforms", ".", "masking", "=", "None", "\n", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.calgary_campinas.predict_test._get_transforms": [[64, 69], ["direct.inference.build_inference_transforms", "direct.data.mri_transforms.Compose", "predict_test.CreateSamplingMask"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.inference.build_inference_transforms"], ["", "def", "_get_transforms", "(", "masks_dict", ",", "env", ")", ":", "\n", "    ", "dataset_cfg", "=", "env", ".", "cfg", ".", "inference", ".", "dataset", "\n", "transforms", "=", "build_inference_transforms", "(", "env", ",", "None", ",", "dataset_cfg", ")", "\n", "transforms", "=", "Compose", "(", "[", "CreateSamplingMask", "(", "masks_dict", ")", ",", "transforms", "]", ")", "\n", "return", "dataset_cfg", ",", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.calgary_campinas.compute_masks.extract_mask": [[11, 32], ["h5py.File", "numpy.abs", "range", "numpy.abs", "numpy.abs().sum", "numpy.abs"], "function", ["None"], ["def", "extract_mask", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Extract the mask from masked k-space data, these are not explicitly given.\n\n    Parameters\n    ----------\n    filename : pathlib.Path\n\n    Returns\n    -------\n    np.ndarray\n    \"\"\"", "\n", "with", "h5py", ".", "File", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "kspace", "=", "f", "[", "\"kspace\"", "]", "\n", "size", "=", "kspace", ".", "shape", "[", "0", "]", "\n", "out", "=", "np", ".", "abs", "(", "kspace", "[", "0", "]", ")", "\n", "for", "idx", "in", "range", "(", "1", ",", "size", ")", ":", "\n", "            ", "out", "+=", "np", ".", "abs", "(", "kspace", "[", "idx", "]", ")", "\n", "\n", "", "", "sampling_mask", "=", "~", "(", "np", ".", "abs", "(", "out", ")", ".", "sum", "(", "axis", "=", "-", "1", ")", "==", "0", ")", "\n", "\n", "return", "sampling_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.spie2022_radial_subsampling.compute_metrics._get_filenames_from_lists": [[19, 26], ["glob.glob", "os.path.join", "pathlib.Path", "open", "names.extend", "name.strip", "os.path.join", "f.readlines", "os.getcwd"], "function", ["None"], ["def", "_get_filenames_from_lists", "(", "path_to_lst", ")", ":", "\n", "    ", "names", "=", "[", "]", "\n", "for", "list_name", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_to_lst", ",", "\"*.lst\"", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "list_name", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "names", ".", "extend", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n", "", "", "return", "[", "pathlib", ".", "Path", "(", "name", ".", "strip", "(", "\"\\n\"", ")", ")", "for", "name", "in", "names", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.spie2022_radial_subsampling.compute_metrics._get_file_from_h5": [[28, 40], ["h5py.File", "h5py.File", "np.array", "to_tensor", "compute_metrics._get_reconstruction", "torch.tensor", "to_tensor.permute"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.spie2022_radial_subsampling.compute_metrics._get_reconstruction"], ["", "def", "_get_file_from_h5", "(", "pred_filename", ",", "target_filename", ")", ":", "\n", "    ", "pred_rec", "=", "h5py", ".", "File", "(", "pred_filename", ",", "\"r\"", ")", "\n", "pred_rec", "=", "torch", ".", "tensor", "(", "pred_rec", "[", "\"reconstruction\"", "]", ")", "[", ":", ",", "np", ".", "newaxis", ",", ":", ",", ":", "]", "\n", "\n", "target", "=", "h5py", ".", "File", "(", "target_filename", ",", "\"r\"", ")", "\n", "\n", "target_kspace", "=", "np", ".", "array", "(", "target", "[", "\"kspace\"", "]", "[", "50", ":", "-", "50", "]", ")", "\n", "target_kspace", "=", "to_tensor", "(", "target_kspace", "[", "...", ",", ":", ":", "2", "]", "+", "1j", "*", "target_kspace", "[", "...", ",", "1", ":", ":", "2", "]", ")", "\n", "\n", "target_rec", "=", "_get_reconstruction", "(", "target_kspace", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ",", "4", ")", ")", "\n", "\n", "return", "pred_rec", ",", "target_rec", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.spie2022_radial_subsampling.compute_metrics._get_reconstruction": [[42, 48], ["ifft2", "root_sum_of_squares"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifft2", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares"], ["", "def", "_get_reconstruction", "(", "kspace", ")", ":", "\n", "\n", "    ", "rec", "=", "ifft2", "(", "kspace", ",", "dim", "=", "(", "2", ",", "3", ")", ",", "centered", "=", "False", ")", "\n", "rec", "=", "root_sum_of_squares", "(", "rec", ",", "1", ")", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "\n", "return", "rec", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.spie2022_radial_subsampling.compute_metrics._get_metrics": [[50, 60], ["calgary_campinas_ssim().item", "calgary_campinas_psnr().item", "calgary_campinas_vif().item", "calgary_campinas_ssim", "calgary_campinas_psnr", "calgary_campinas_vif"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_ssim", "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_psnr", "home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_vif"], ["", "def", "_get_metrics", "(", "pred_rec", ",", "target_rec", ")", ":", "\n", "\n", "    ", "ssim", "=", "calgary_campinas_ssim", "(", "target_rec", ",", "pred_rec", ")", ".", "item", "(", ")", "\n", "psnr", "=", "calgary_campinas_psnr", "(", "target_rec", ",", "pred_rec", ")", ".", "item", "(", ")", "\n", "vif", "=", "calgary_campinas_vif", "(", "target_rec", ",", "pred_rec", ")", ".", "item", "(", ")", "\n", "\n", "return", "{", "\n", "\"calgary_campinas_psnr_metric\"", ":", "psnr", ",", "\n", "\"calgary_campinas_ssim_metric\"", ":", "ssim", ",", "\n", "\"calgary_campinas_vif_metric\"", ":", "vif", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.spie2022_radial_subsampling.plot_zoomed.zoom_in_rectangle": [[5, 75], ["mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes", "matplotlib.Rectangle", "mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.set_xlim", "mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.set_ylim", "mpl_toolkits.axes_grid1.inset_locator.mark_inset", "mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.imshow", "mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.set_xticklabels", "mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.set_yticklabels", "patches.Rectangle.get_x", "patches.Rectangle.get_y", "mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.spines[].set_linewidth", "mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.spines[].set_color", "kwargs.get", "patches.Rectangle.get_x", "patches.Rectangle.get_width", "patches.Rectangle.get_y", "patches.Rectangle.get_height", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "function", ["None"], ["def", "zoom_in_rectangle", "(", "img", ",", "ax", ",", "zoom", ",", "rectangle_xy", ",", "rectangle_width", ",", "rectangle_height", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Parameters\n    ----------\n    img: array-like\n        The image data.\n    ax: Axes\n        Axes to place the inset axes.\n    zoom: float\n        Scaling factor of the data axes. zoom > 1 will enlargen the coordinates (i.e., \"zoomed in\"),\n            while zoom < 1 will shrink the coordinates (i.e., \"zoomed out\").\n    rectangle_xy: (float or int, float or int)\n        The anchor point of the rectangle to be zoomed.\n    rectangle_width: float or int\n        Rectangle to be zoomed width.\n    rectangle_height: float or int\n        Rectangle to be zoomed height.\n\n    Other Parameters\n    ----------------\n    cmap: str or Colormap, default 'gray'\n        The Colormap instance or registered colormap name used to map scalar data to colors.\n    zoomed_inset_loc: int or str, default: 'upper right'\n        Location to place the inset axes.\n    zoomed_inset_lw: float or None, default 1\n        Zoomed inset axes linewidth.\n    zoomed_inset_col: float or None, default black\n        Zoomed inset axes color.\n    mark_inset_loc1: int or str, default is 1\n        First location to place line connecting box and inset axes.\n    mark_inset_loc2:  int or str, default is 3\n        Second location to place line connecting box and inset axes.\n    mark_inset_lw: float or None, default None\n        Linewidth of lines connecting box and inset axes.\n    mark_inset_ec: color or None\n        Color of lines connecting box and inset axes.\n\n    \"\"\"", "\n", "axins", "=", "zoomed_inset_axes", "(", "ax", ",", "zoom", ",", "loc", "=", "kwargs", ".", "get", "(", "\"zoomed_inset_loc\"", ",", "1", ")", ")", "\n", "\n", "rect", "=", "patches", ".", "Rectangle", "(", "xy", "=", "rectangle_xy", ",", "width", "=", "rectangle_width", ",", "height", "=", "rectangle_height", ")", "\n", "x1", ",", "x2", "=", "rect", ".", "get_x", "(", ")", ",", "rect", ".", "get_x", "(", ")", "+", "rect", ".", "get_width", "(", ")", "\n", "y1", ",", "y2", "=", "rect", ".", "get_y", "(", ")", ",", "rect", ".", "get_y", "(", ")", "+", "rect", ".", "get_height", "(", ")", "\n", "\n", "axins", ".", "set_xlim", "(", "x1", ",", "x2", ")", "\n", "axins", ".", "set_ylim", "(", "y1", ",", "y2", ")", "\n", "\n", "mark_inset", "(", "\n", "ax", ",", "\n", "axins", ",", "\n", "loc1", "=", "kwargs", ".", "get", "(", "\"mark_inset_loc1\"", ",", "1", ")", ",", "\n", "loc2", "=", "kwargs", ".", "get", "(", "\"mark_inset_loc2\"", ",", "3", ")", ",", "\n", "lw", "=", "kwargs", ".", "get", "(", "\"mark_inset_lw\"", ",", "None", ")", ",", "\n", "ec", "=", "kwargs", ".", "get", "(", "\"mark_inset_ec\"", ",", "\"1.0\"", ")", ",", "\n", ")", "\n", "\n", "axins", ".", "imshow", "(", "\n", "img", ",", "\n", "cmap", "=", "kwargs", ".", "get", "(", "\"cmap\"", ",", "\"gray\"", ")", ",", "\n", "origin", "=", "\"lower\"", ",", "\n", "vmin", "=", "kwargs", ".", "get", "(", "\"vmin\"", ",", "None", ")", ",", "\n", "vmax", "=", "kwargs", ".", "get", "(", "\"vmax\"", ",", "None", ")", ",", "\n", ")", "\n", "\n", "for", "axis", "in", "[", "\"top\"", ",", "\"bottom\"", ",", "\"left\"", ",", "\"right\"", "]", ":", "\n", "        ", "axins", ".", "spines", "[", "axis", "]", ".", "set_linewidth", "(", "kwargs", ".", "get", "(", "\"zoomed_inset_lw\"", ",", "1", ")", ")", "\n", "axins", ".", "spines", "[", "axis", "]", ".", "set_color", "(", "kwargs", ".", "get", "(", "\"zoomed_inset_col\"", ",", "\"k\"", ")", ")", "\n", "\n", "", "axins", ".", "set_xticklabels", "(", "[", "]", ")", "\n", "axins", ".", "set_yticklabels", "(", "[", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests.test_checkpointer.create_checkpointables": [[15, 38], ["dict", "torch.Linear", "torch.optim.Adam", "torch.optim.Adam", "torch.Linear", "checkpointables[].parameters", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "create_checkpointables", "(", "*", "keys", ")", ":", "\n", "    ", "checkpointables", "=", "dict", "(", ")", "\n", "checkpointables", "[", "\"model\"", "]", "=", "nn", ".", "Linear", "(", "2", ",", "2", ")", "\n", "\n", "if", "\"optimizer\"", "in", "keys", ":", "\n", "        ", "checkpointables", "[", "\"optimizer\"", "]", "=", "torch", ".", "optim", ".", "Adam", "(", "checkpointables", "[", "\"model\"", "]", ".", "parameters", "(", ")", ")", "\n", "\n", "", "if", "\"sensitivity_model\"", "in", "keys", ":", "\n", "        ", "checkpointables", "[", "\"sensitivity_model\"", "]", "=", "nn", ".", "Linear", "(", "2", ",", "2", ")", "\n", "\n", "", "if", "\"__author__\"", "in", "keys", ":", "\n", "        ", "checkpointables", "[", "\"__author__\"", "]", "==", "\"Jane Doe\"", "\n", "\n", "", "if", "\"__datetime__\"", "in", "keys", ":", "\n", "        ", "checkpointables", "[", "\"__datetime__\"", "]", "==", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "\n", "", "if", "\"__version__\"", "in", "keys", ":", "\n", "        ", "checkpointables", "[", "\"__version__\"", "]", "==", "\"0.0.0\"", "\n", "\n", "", "if", "\"__mixed_precision__\"", "in", "keys", ":", "\n", "        ", "checkpointables", "[", "\"__mixed_precision__\"", "]", "=", "False", "\n", "\n", "", "return", "checkpointables", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests.test_checkpointer.test_checkpointer": [[40, 73], ["pytest.mark.parametrize", "pytest.mark.parametrize", "tempfile.TemporaryDirectory", "direct.checkpointer.Checkpointer.load", "test_checkpointer.create_checkpointables", "direct.checkpointer.Checkpointer", "direct.checkpointer.Checkpointer.save", "direct.checkpointer.Checkpointer.load", "isinstance", "direct.checkpointer.Checkpointer.load", "torch.allclose", "torch.allclose", "pathlib.Path", "direct.checkpointer.Checkpointer.load"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.tests.test_checkpointer.create_checkpointables", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.save", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load", "home.repos.pwc.inspect_result.directgroup_direct.direct.checkpointer.Checkpointer.load"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"checkpoint_ids\"", ",", "\n", "[", "\n", "[", "10", "]", ",", "\n", "[", "20", ",", "40", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"checkpointables_keys\"", ",", "\n", "[", "\n", "[", "]", ",", "\n", "[", "\"sensitivity_model\"", ",", "\"optimizer\"", ",", "\"something_which_is_not_stored\"", "]", ",", "\n", "[", "\"sensitivity_model\"", ",", "\"optimizer\"", "]", ",", "\n", "[", "\"sensitivity_model\"", ",", "\"optimizer\"", ",", "\"__author__\"", ",", "\"__version__\"", ",", "\"__datetime__\"", ",", "\"__mixed_precision__\"", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_checkpointer", "(", "checkpoint_ids", ",", "checkpointables_keys", ")", ":", "\n", "    ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "\n", "        ", "for", "checkpoint_id", "in", "checkpoint_ids", ":", "\n", "            ", "checkpointables", "=", "create_checkpointables", "(", "checkpointables_keys", ")", "\n", "\n", "checkpointer", "=", "Checkpointer", "(", "save_directory", "=", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "save_to_disk", "=", "True", ",", "**", "checkpointables", ")", "\n", "# Test save function", "\n", "checkpointer", ".", "save", "(", "iteration", "=", "checkpoint_id", ")", "\n", "# Test load function", "\n", "checkpointer", ".", "load", "(", "iteration", "=", "checkpoint_id", ")", "\n", "\n", "# Test that '-1' option loads the same checkpoint as the 'latest' option", "\n", "", "last_checkpoint", "=", "checkpointer", ".", "load", "(", "iteration", "=", "-", "1", ")", "\n", "for", "key", "in", "last_checkpoint", ":", "\n", "            ", "assert", "key", "in", "checkpointer", ".", "load", "(", "\"latest\"", ")", "\n", "if", "isinstance", "(", "last_checkpoint", "[", "key", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "torch", ".", "allclose", "(", "checkpointer", ".", "load", "(", "iteration", "=", "\"latest\"", ")", "[", "key", "]", ",", "last_checkpoint", "[", "key", "]", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests.test_train.create_test_cfg": [[23, 95], ["direct.data.datasets_config.TransformsConfig", "dataclasses.make_dataclass", "direct.data.datasets_config.DatasetConfig", "direct.data.datasets_config.DatasetConfig", "direct.config.defaults.CheckpointerConfig", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.InferenceConfig", "direct.config.defaults.ModelConfig", "direct.config.defaults.DefaultConfig", "dataclasses.make_dataclass", "omegaconf.DictConfig", "omegaconf.OmegaConf.create", "direct.data.datasets_config.MaskingConfig", "direct.data.datasets_config.DatasetConfig", "direct.config.defaults.ModelConfig", "direct.config.defaults.FunctionConfig", "dataclasses.field", "dataclasses.field", "dataclasses.field", "dataclasses.field"], "function", ["None"], ["def", "create_test_cfg", "(", "\n", "train_dataset_shape", ",", "\n", "val_dataset_shape", ",", "\n", "train_batch_size", ",", "\n", "val_batch_size", ",", "\n", "loss_fns", ",", "\n", "train_iters", ",", "\n", "val_iters", ",", "\n", "checkpointer_iters", ",", "\n", "inference_batch_size", ",", "\n", ")", ":", "\n", "# Configs", "\n", "    ", "transforms_config", "=", "TransformsConfig", "(", "\n", "estimate_sensitivity_maps", "=", "True", ",", "\n", "scaling_key", "=", "\"masked_kspace\"", ",", "\n", "masking", "=", "MaskingConfig", "(", "name", "=", "\"FastMRIRandom\"", ")", ",", "\n", "crop", "=", "(", "64", ",", "64", ")", ",", "\n", ")", "\n", "\n", "new_class", "=", "make_dataclass", "(", "\n", "\"\"", ",", "\n", "fields", "=", "[", "\n", "(", "\"sample_size\"", ",", "int", ",", "field", "(", "init", "=", "False", ")", ")", ",", "\n", "(", "\"spatial_shape\"", ",", "list", ",", "field", "(", "init", "=", "False", ")", ")", ",", "\n", "(", "\"num_coils\"", ",", "int", ",", "field", "(", "init", "=", "False", ")", ")", ",", "\n", "]", ",", "\n", "bases", "=", "(", "DatasetConfig", ",", ")", ",", "\n", ")", "\n", "\n", "train_dataset_config", "=", "DatasetConfig", "(", "\n", "name", "=", "\"FakeMRIBlobs\"", ",", "transforms", "=", "transforms_config", ",", "text_description", "=", "\"training\"", "\n", ")", "\n", "train_dataset_config", ".", "__class__", "=", "new_class", "\n", "train_dataset_config", ".", "sample_size", "=", "train_dataset_shape", "[", "0", "]", "\n", "train_dataset_config", ".", "num_coils", "=", "train_dataset_shape", "[", "2", "]", "\n", "train_dataset_config", ".", "spatial_shape", "=", "(", "train_dataset_shape", "[", "1", "]", ",", ")", "+", "train_dataset_shape", "[", "3", ":", "]", "\n", "\n", "val_dataset_config", "=", "DatasetConfig", "(", "\n", "name", "=", "\"FakeMRIBlobs\"", ",", "transforms", "=", "transforms_config", ",", "text_description", "=", "\"validation\"", "\n", ")", "\n", "val_dataset_config", ".", "__class__", "=", "new_class", "\n", "val_dataset_config", ".", "sample_size", "=", "val_dataset_shape", "[", "0", "]", "\n", "val_dataset_config", ".", "num_coils", "=", "val_dataset_shape", "[", "2", "]", "\n", "val_dataset_config", ".", "spatial_shape", "=", "(", "val_dataset_shape", "[", "1", "]", ",", ")", "+", "val_dataset_shape", "[", "3", ":", "]", "\n", "\n", "checkpointer_config", "=", "CheckpointerConfig", "(", "checkpoint_steps", "=", "checkpointer_iters", ")", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "\n", "training_config", "=", "TrainingConfig", "(", "\n", "loss", "=", "loss_config", ",", "\n", "checkpointer", "=", "checkpointer_config", ",", "\n", "num_iterations", "=", "train_iters", ",", "\n", "validation_steps", "=", "val_iters", ",", "\n", "datasets", "=", "[", "train_dataset_config", "]", ",", "\n", "batch_size", "=", "train_batch_size", ",", "\n", ")", "\n", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ",", "datasets", "=", "[", "val_dataset_config", "]", ",", "batch_size", "=", "val_batch_size", ")", "\n", "\n", "inference_config", "=", "InferenceConfig", "(", "dataset", "=", "DatasetConfig", "(", "name", "=", "\"FakeMRIBlobs\"", ")", ",", "batch_size", "=", "inference_batch_size", ")", "\n", "\n", "model", "=", "ModelConfig", "(", "model_name", "=", "\"unet.unet_2d.Unet2d\"", ")", "\n", "config", "=", "DefaultConfig", "(", "\n", "training", "=", "training_config", ",", "validation", "=", "validation_config", ",", "inference", "=", "inference_config", ",", "model", "=", "model", "\n", ")", "\n", "config", ".", "__class__", "=", "make_dataclass", "(", "\n", "\"\"", ",", "\n", "fields", "=", "[", "(", "\"additional_models\"", ",", "DictConfig", ",", "field", "(", "init", "=", "False", ")", ")", "]", ",", "\n", "bases", "=", "(", "DefaultConfig", ",", ")", ",", "\n", ")", "\n", "config", ".", "additional_models", "=", "DictConfig", "(", "{", "\"senistivity_model\"", ":", "ModelConfig", "(", "model_name", "=", "\"unet.unet_2d.UnetModel2d\"", ")", "}", ")", "\n", "return", "OmegaConf", ".", "create", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests.test_train.test_setup_train": [[97, 191], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "test_train.create_test_cfg", "tempfile.TemporaryDirectory", "direct.launch.launch", "cfg_filename.is_file", "range", "range", "pathlib.Path", "open", "f.write", "pathlib.Path", "omegaconf.OmegaConf.to_yaml"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests.test_train.create_test_cfg", "home.repos.pwc.inspect_result.directgroup_direct.direct.launch.launch", "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.is_file", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"train_dataset_shape, val_dataset_shape,\"", ",", "\n", "[", "[", "(", "6", ",", "5", ",", "3", ",", "120", ",", "120", ")", ",", "(", "6", ",", "5", ",", "3", ",", "120", ",", "120", ")", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"train_batch_size, val_batch_size, inference_batch_size\"", ",", "\n", "[", "[", "3", ",", "3", ",", "5", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"train_iters, val_iters, checkpointer_iters\"", ",", "\n", "[", "[", "41", ",", "20", ",", "20", "]", "]", ",", "\n", ")", "\n", "def", "test_setup_train", "(", "\n", "train_dataset_shape", ",", "\n", "val_dataset_shape", ",", "\n", "train_batch_size", ",", "\n", "val_batch_size", ",", "\n", "loss_fns", ",", "\n", "train_iters", ",", "\n", "val_iters", ",", "\n", "checkpointer_iters", ",", "\n", "inference_batch_size", ",", "\n", ")", ":", "\n", "\n", "    ", "cfg", "=", "create_test_cfg", "(", "\n", "train_dataset_shape", ",", "\n", "val_dataset_shape", ",", "\n", "train_batch_size", ",", "\n", "val_batch_size", ",", "\n", "loss_fns", ",", "\n", "train_iters", ",", "\n", "val_iters", ",", "\n", "checkpointer_iters", ",", "\n", "inference_batch_size", ",", "\n", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "\n", "        ", "cfg_filename", "=", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "\"cfg_test.yaml\"", "\n", "with", "open", "(", "cfg_filename", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "OmegaConf", ".", "to_yaml", "(", "cfg", ")", ")", "\n", "\n", "", "run_name", "=", "\"test\"", "\n", "training_root", "=", "None", "\n", "validation_root", "=", "None", "\n", "base_directory", "=", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "\"base_dir\"", "\n", "num_machines", "=", "1", "\n", "num_gpus", "=", "0", "\n", "dist_url", "=", "\"tcp://127.0.0.1:1234\"", "\n", "force_validation", "=", "False", "\n", "initialization_checkpoint", "=", "None", "\n", "initialization_images", "=", "None", "\n", "initialization_kspace", "=", "None", "\n", "noise", "=", "None", "\n", "device", "=", "\"cpu\"", "\n", "num_workers", "=", "1", "\n", "resume", "=", "False", "\n", "machine_rank", "=", "0", "\n", "mixed_precision", "=", "False", "\n", "debug", "=", "False", "\n", "\n", "launch", "(", "\n", "setup_train", ",", "\n", "num_machines", ",", "\n", "num_gpus", ",", "\n", "machine_rank", ",", "\n", "dist_url", ",", "\n", "run_name", ",", "\n", "training_root", ",", "\n", "validation_root", ",", "\n", "base_directory", ",", "\n", "cfg_filename", ",", "\n", "force_validation", ",", "\n", "initialization_checkpoint", ",", "\n", "initialization_images", ",", "\n", "initialization_kspace", ",", "\n", "noise", ",", "\n", "device", ",", "\n", "num_workers", ",", "\n", "resume", ",", "\n", "machine_rank", ",", "\n", "mixed_precision", ",", "\n", "debug", ",", "\n", ")", "\n", "save_directory", "=", "base_directory", "/", "run_name", "\n", "assert", "cfg_filename", ".", "is_file", "(", ")", "\n", "\n", "for", "idx", "in", "range", "(", "checkpointer_iters", ",", "train_iters", "+", "1", ",", "checkpointer_iters", ")", ":", "\n", "            ", "assert", "(", "save_directory", "/", "f\"model_{idx}.pt\"", ")", ".", "is_file", "(", ")", "\n", "", "for", "idx", "in", "range", "(", "val_iters", ",", "train_iters", "+", "1", ",", "val_iters", ")", ":", "\n", "            ", "assert", "(", "save_directory", "/", "f\"metrics_val_validation_{idx}.json\"", ")", ".", "is_file", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_functionals.test_psnr.test_psnr": [[19, 54], ["pytest.mark.parametrize", "range", "numpy.mean", "torch.cat", "torch.cat", "direct.functionals.psnr.PSNRLoss().forward", "numpy.allclose", "skimage.metrics.peak_signal_noise_ratio", "torch.from_numpy().unsqueeze().float", "torch.from_numpy().unsqueeze().float", "torch.cat.append", "torch.cat.append", "direct.functionals.psnr.PSNRLoss().forward", "psnr_torch.numpy().item.numpy().item", "single_image_psnr.append", "numpy.allclose", "numpy.random.rand", "direct.functionals.psnr.PSNRLoss", "image_noise.max", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "direct.functionals.psnr.PSNRLoss", "psnr_torch.numpy().item.numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ComplexMultiplicationONNX.forward", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ComplexMultiplicationONNX.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image\"", ",", "[", "flower", ",", "china", "]", ")", "\n", "def", "test_psnr", "(", "image", ")", ":", "\n", "\n", "    ", "image_batch", "=", "[", "]", "\n", "image_noise_batch", "=", "[", "]", "\n", "single_image_psnr", "=", "[", "]", "\n", "\n", "for", "sigma", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "noise", "=", "sigma", "*", "np", ".", "random", ".", "rand", "(", "*", "image", ".", "shape", ")", "\n", "image_noise", "=", "(", "image", "+", "noise", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "clip", "(", "0", ",", "255", ")", "\n", "\n", "psnr_skimage", "=", "peak_signal_noise_ratio", "(", "image_true", "=", "image", ",", "image_test", "=", "image_noise", ",", "data_range", "=", "image_noise", ".", "max", "(", ")", ")", "\n", "\n", "image_torch", "=", "(", "torch", ".", "from_numpy", "(", "image", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "# 1, C, H, W", "\n", "image_noise_torch", "=", "(", "torch", ".", "from_numpy", "(", "image_noise", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "# 1, C, H, W", "\n", "\n", "image_batch", ".", "append", "(", "image_torch", ")", "\n", "image_noise_batch", ".", "append", "(", "image_noise_torch", ")", "\n", "\n", "psnr_torch", "=", "PSNRLoss", "(", "reduction", "=", "\"none\"", ")", ".", "forward", "(", "image_noise_torch", ",", "image_torch", ")", "\n", "\n", "psnr_torch", "=", "psnr_torch", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "single_image_psnr", ".", "append", "(", "psnr_skimage", ")", "\n", "# Assert that single slice psnr matches", "\n", "assert", "np", ".", "allclose", "(", "psnr_torch", ",", "psnr_skimage", ",", "atol", "=", "5e-4", ")", "\n", "\n", "", "psnr_skimage_batch", "=", "np", ".", "mean", "(", "single_image_psnr", ")", "\n", "\n", "image_batch", "=", "torch", ".", "cat", "(", "image_batch", ",", "dim", "=", "0", ")", "\n", "image_noise_batch", "=", "torch", ".", "cat", "(", "image_noise_batch", ",", "dim", "=", "0", ")", "\n", "psnr_batch", "=", "PSNRLoss", "(", "reduction", "=", "\"mean\"", ")", ".", "forward", "(", "\n", "image_noise_batch", ",", "\n", "image_batch", ",", "\n", ")", "\n", "assert", "np", ".", "allclose", "(", "psnr_batch", ",", "psnr_skimage_batch", ",", "atol", "=", "5e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_functionals.test_psnr.test_calgary_campinas_psnr": [[56, 89], ["pytest.mark.parametrize", "range", "numpy.mean", "torch.cat", "torch.cat", "direct.functionals.challenges.calgary_campinas_psnr", "numpy.allclose", "skimage.metrics.peak_signal_noise_ratio", "torch.from_numpy().unsqueeze().float", "torch.from_numpy().unsqueeze().float", "torch.cat.append", "torch.cat.append", "single_image_psnr.append", "numpy.random.rand", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "numpy.maximum", "numpy.minimum", "image.max", "image_noise.max", "image.min", "image_noise.min", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_psnr"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image\"", ",", "[", "flower", ",", "china", "]", ")", "\n", "def", "test_calgary_campinas_psnr", "(", "image", ")", ":", "\n", "\n", "    ", "image_batch", "=", "[", "]", "\n", "image_noise_batch", "=", "[", "]", "\n", "single_image_psnr", "=", "[", "]", "\n", "\n", "for", "sigma", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "noise", "=", "sigma", "*", "np", ".", "random", ".", "rand", "(", "*", "image", ".", "shape", ")", "\n", "image_noise", "=", "(", "image", "+", "noise", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "clip", "(", "0", ",", "255", ")", "\n", "\n", "psnr_skimage", "=", "peak_signal_noise_ratio", "(", "\n", "image_true", "=", "image", ",", "\n", "image_test", "=", "image_noise", ",", "\n", "data_range", "=", "np", ".", "maximum", "(", "image", ".", "max", "(", ")", ",", "image_noise", ".", "max", "(", ")", ")", "-", "np", ".", "minimum", "(", "image", ".", "min", "(", ")", ",", "image_noise", ".", "min", "(", ")", ")", ",", "\n", ")", "\n", "\n", "image_torch", "=", "(", "torch", ".", "from_numpy", "(", "image", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "# 1, C, H, W", "\n", "image_noise_torch", "=", "(", "torch", ".", "from_numpy", "(", "image_noise", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "# 1, C, H, W", "\n", "\n", "image_batch", ".", "append", "(", "image_torch", ")", "\n", "image_noise_batch", ".", "append", "(", "image_noise_torch", ")", "\n", "\n", "single_image_psnr", ".", "append", "(", "psnr_skimage", ")", "\n", "\n", "", "psnr_skimage_batch", "=", "np", ".", "mean", "(", "single_image_psnr", ")", "\n", "\n", "image_batch", "=", "torch", ".", "cat", "(", "image_batch", ",", "dim", "=", "0", ")", "\n", "image_noise_batch", "=", "torch", ".", "cat", "(", "image_noise_batch", ",", "dim", "=", "0", ")", "\n", "\n", "calgary_campinas_psnr_batch", "=", "calgary_campinas_psnr", "(", "image_batch", ",", "image_noise_batch", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "calgary_campinas_psnr_batch", ",", "psnr_skimage_batch", ",", "atol", "=", "5e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_functionals.test_psnr.test_fastmri_psnr": [[91, 115], ["pytest.mark.parametrize", "range", "numpy.stack", "numpy.stack", "skimage.metrics.peak_signal_noise_ratio", "torch.tensor", "torch.tensor", "direct.functionals.challenges.fastmri_psnr", "numpy.allclose", "np.stack.append", "np.stack.append", "numpy.random.rand", "np.stack.max"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.fastmri_psnr"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image\"", ",", "[", "flower", ",", "china", "]", ")", "\n", "def", "test_fastmri_psnr", "(", "image", ")", ":", "\n", "\n", "    ", "image_batch", "=", "[", "]", "\n", "image_noise_batch", "=", "[", "]", "\n", "single_image_psnr", "=", "[", "]", "\n", "\n", "for", "sigma", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "noise", "=", "sigma", "*", "np", ".", "random", ".", "rand", "(", "*", "image", ".", "shape", ")", "\n", "image_noise", "=", "(", "image", "+", "noise", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "clip", "(", "0", ",", "255", ")", "\n", "\n", "image_batch", ".", "append", "(", "image", ")", "\n", "image_noise_batch", ".", "append", "(", "image_noise", ")", "\n", "\n", "", "image_batch", "=", "np", ".", "stack", "(", "image_batch", ")", "\n", "image_noise_batch", "=", "np", ".", "stack", "(", "image_noise_batch", ")", "\n", "\n", "psnr_skimage_batch", "=", "peak_signal_noise_ratio", "(", "image_batch", ",", "image_noise_batch", ",", "data_range", "=", "image_batch", ".", "max", "(", ")", ")", "\n", "image_batch_torch", "=", "torch", ".", "tensor", "(", "image_batch", ")", "\n", "image_noise_batch_torch", "=", "torch", ".", "tensor", "(", "image_noise_batch", ")", "\n", "\n", "fastmri_psnr_batch", "=", "fastmri_psnr", "(", "image_batch_torch", ",", "image_noise_batch_torch", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "fastmri_psnr_batch", ",", "psnr_skimage_batch", ",", "atol", "=", "5e-4", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_functionals.test_ssim.test_ssim": [[19, 69], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "range", "numpy.mean", "torch.cat", "torch.cat", "numpy.allclose", "skimage.metrics.structural_similarity", "torch.from_numpy().unsqueeze().float", "torch.from_numpy().unsqueeze().float", "torch.cat.append", "torch.cat.append", "ssim_torch.numpy.numpy", "single_image_ssim.append", "numpy.allclose", "direct.functionals.ssim.SSIMLoss().forward", "numpy.random.rand", "direct.functionals.ssim.SSIMLoss().forward", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "direct.functionals.ssim.SSIMLoss", "image.max", "direct.functionals.ssim.SSIMLoss", "torch.tensor", "torch.tensor", "torch.cat.amax", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().unsqueeze().float.max"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ComplexMultiplicationONNX.forward", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ComplexMultiplicationONNX.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image\"", ",", "[", "flower", ",", "china", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"data_range_255\"", ",", "[", "True", ",", "False", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"win_size\"", ",", "[", "7", ",", "11", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"k1, k2\"", ",", "[", "[", "0.01", ",", "0.03", "]", ",", "[", "0.05", ",", "0.1", "]", "]", ")", "\n", "def", "test_ssim", "(", "image", ",", "data_range_255", ",", "win_size", ",", "k1", ",", "k2", ")", ":", "\n", "\n", "    ", "image_batch", "=", "[", "]", "\n", "image_noise_batch", "=", "[", "]", "\n", "single_image_ssim", "=", "[", "]", "\n", "\n", "for", "sigma", "in", "range", "(", "0", ",", "101", ",", "20", ")", ":", "\n", "        ", "noise", "=", "sigma", "*", "np", ".", "random", ".", "rand", "(", "*", "image", ".", "shape", ")", "\n", "image_noise", "=", "(", "image", "+", "noise", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "clip", "(", "0", ",", "255", ")", "\n", "\n", "ssim_skimage", "=", "structural_similarity", "(", "\n", "im1", "=", "image", ",", "\n", "im2", "=", "image_noise", ",", "\n", "win_size", "=", "win_size", ",", "\n", "channel_axis", "=", "0", ",", "\n", "data_range", "=", "255", "if", "data_range_255", "else", "image", ".", "max", "(", ")", ",", "\n", "K1", "=", "k1", ",", "\n", "K2", "=", "k2", ",", "\n", ")", "\n", "\n", "image_torch", "=", "(", "torch", ".", "from_numpy", "(", "image", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "# 1, C, H, W", "\n", "image_noise_torch", "=", "(", "torch", ".", "from_numpy", "(", "image_noise", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "\n", "image_batch", ".", "append", "(", "image_torch", ")", "\n", "image_noise_batch", ".", "append", "(", "image_noise_torch", ")", "\n", "\n", "ssim_torch", "=", "1", "-", "SSIMLoss", "(", "win_size", "=", "win_size", ",", "k1", "=", "k1", ",", "k2", "=", "k2", ")", ".", "forward", "(", "\n", "image_noise_torch", ",", "image_torch", ",", "data_range", "=", "torch", ".", "tensor", "(", "[", "255", "if", "data_range_255", "else", "image_torch", ".", "max", "(", ")", "]", ")", "\n", ")", "\n", "\n", "ssim_torch", "=", "ssim_torch", ".", "numpy", "(", ")", "\n", "single_image_ssim", ".", "append", "(", "ssim_torch", ")", "\n", "# Assert that single slice ssim matches", "\n", "assert", "np", ".", "allclose", "(", "ssim_torch", ",", "ssim_skimage", ",", "atol", "=", "5e-4", ")", "\n", "\n", "", "ssim_skimage_batch", "=", "np", ".", "mean", "(", "single_image_ssim", ")", "\n", "\n", "image_batch", "=", "torch", ".", "cat", "(", "image_batch", ",", "dim", "=", "0", ")", "\n", "image_noise_batch", "=", "torch", ".", "cat", "(", "image_noise_batch", ",", "dim", "=", "0", ")", "\n", "ssim_batch", "=", "1", "-", "SSIMLoss", "(", "win_size", "=", "win_size", ",", "k1", "=", "k1", ",", "k2", "=", "k2", ")", ".", "forward", "(", "\n", "X", "=", "image_noise_batch", ",", "\n", "Y", "=", "image_batch", ",", "\n", "data_range", "=", "torch", ".", "tensor", "(", "[", "255", "]", ")", "if", "data_range_255", "else", "image_batch", ".", "amax", "(", "(", "1", ",", "2", ",", "3", ")", ")", ",", "\n", ")", "\n", "# Assert that batch ssim matches", "\n", "assert", "np", ".", "allclose", "(", "ssim_batch", ",", "ssim_skimage_batch", ",", "atol", "=", "5e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_functionals.test_ssim.test_calgary_campinas_ssim": [[71, 103], ["pytest.mark.parametrize", "range", "numpy.mean", "torch.cat", "torch.cat", "direct.functionals.challenges.calgary_campinas_ssim", "numpy.allclose", "skimage.metrics.structural_similarity", "torch.from_numpy().unsqueeze().float", "torch.from_numpy().unsqueeze().float", "torch.cat.append", "torch.cat.append", "single_image_ssim.append", "numpy.random.rand", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "numpy.maximum", "numpy.minimum", "image.max", "image_noise.max", "image.min", "image_noise.min", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.calgary_campinas_ssim"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image\"", ",", "[", "flower", ",", "china", "]", ")", "\n", "def", "test_calgary_campinas_ssim", "(", "image", ")", ":", "\n", "    ", "image_batch", "=", "[", "]", "\n", "image_noise_batch", "=", "[", "]", "\n", "single_image_ssim", "=", "[", "]", "\n", "\n", "for", "sigma", "in", "range", "(", "0", ",", "101", ",", "20", ")", ":", "\n", "        ", "noise", "=", "sigma", "*", "np", ".", "random", ".", "rand", "(", "*", "image", ".", "shape", ")", "\n", "image_noise", "=", "(", "image", "+", "noise", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "clip", "(", "0", ",", "255", ")", "\n", "\n", "ssim_skimage", "=", "structural_similarity", "(", "\n", "im1", "=", "image", ",", "\n", "im2", "=", "image_noise", ",", "\n", "channel_axis", "=", "0", ",", "\n", "data_range", "=", "np", ".", "maximum", "(", "image", ".", "max", "(", ")", ",", "image_noise", ".", "max", "(", ")", ")", "-", "np", ".", "minimum", "(", "image", ".", "min", "(", ")", ",", "image_noise", ".", "min", "(", ")", ")", ",", "\n", ")", "\n", "\n", "image_torch", "=", "(", "torch", ".", "from_numpy", "(", "image", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "# 1, C, H, W", "\n", "image_noise_torch", "=", "(", "torch", ".", "from_numpy", "(", "image_noise", ")", ".", "unsqueeze", "(", "0", ")", ")", ".", "float", "(", ")", "# 1, C, H, W", "\n", "\n", "image_batch", ".", "append", "(", "image_torch", ")", "\n", "image_noise_batch", ".", "append", "(", "image_noise_torch", ")", "\n", "\n", "single_image_ssim", ".", "append", "(", "ssim_skimage", ")", "\n", "", "ssim_skimage_batch", "=", "np", ".", "mean", "(", "single_image_ssim", ")", "\n", "\n", "image_batch", "=", "torch", ".", "cat", "(", "image_batch", ",", "dim", "=", "0", ")", "\n", "image_noise_batch", "=", "torch", ".", "cat", "(", "image_noise_batch", ",", "dim", "=", "0", ")", "\n", "\n", "calgary_campinas_ssim_batch", "=", "calgary_campinas_ssim", "(", "image_batch", ",", "image_noise_batch", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "calgary_campinas_ssim_batch", ",", "ssim_skimage_batch", ",", "atol", "=", "5e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_functionals.test_ssim.test_fastmri_ssim": [[105, 133], ["pytest.mark.parametrize", "range", "numpy.stack", "numpy.stack", "skimage.metrics.structural_similarity", "torch.tensor", "torch.tensor", "direct.functionals.challenges.fastmri_ssim", "numpy.allclose", "np.stack.append", "np.stack.append", "np.stack.squeeze", "np.stack.squeeze", "numpy.random.rand", "np.stack.max"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.fastmri_ssim"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image\"", ",", "[", "flower", ",", "china", "]", ")", "\n", "def", "test_fastmri_ssim", "(", "image", ")", ":", "\n", "    ", "image_batch", "=", "[", "]", "\n", "image_noise_batch", "=", "[", "]", "\n", "single_image_ssim", "=", "[", "]", "\n", "\n", "for", "sigma", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "noise", "=", "sigma", "*", "np", ".", "random", ".", "rand", "(", "*", "image", ".", "shape", ")", "\n", "image_noise", "=", "(", "image", "+", "noise", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "clip", "(", "0", ",", "255", ")", "\n", "\n", "image_batch", ".", "append", "(", "image", ")", "\n", "image_noise_batch", ".", "append", "(", "image_noise", ")", "\n", "\n", "", "image_batch", "=", "np", ".", "stack", "(", "image_batch", ")", "\n", "image_noise_batch", "=", "np", ".", "stack", "(", "image_noise_batch", ")", "\n", "\n", "ssim_skimage_batch", "=", "structural_similarity", "(", "\n", "image_batch", ".", "squeeze", "(", ")", ",", "\n", "image_noise_batch", ".", "squeeze", "(", ")", ",", "\n", "channel_axis", "=", "0", ",", "\n", "data_range", "=", "image_batch", ".", "max", "(", ")", ",", "\n", ")", "\n", "image_batch_torch", "=", "torch", ".", "tensor", "(", "image_batch", ")", "\n", "image_noise_batch_torch", "=", "torch", ".", "tensor", "(", "image_noise_batch", ")", "\n", "\n", "fastmri_ssim_batch", "=", "fastmri_ssim", "(", "image_batch_torch", ",", "image_noise_batch_torch", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "fastmri_ssim_batch", ",", "ssim_skimage_batch", ",", "atol", "=", "5e-4", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_functionals.test_nmse.test_fastmri_nmse": [[18, 46], ["pytest.mark.parametrize", "range", "numpy.stack", "numpy.stack", "skimage.metrics.normalized_root_mse", "torch.tensor", "torch.tensor", "direct.functionals.challenges.fastmri_nmse", "numpy.allclose", "np.stack.append", "np.stack.append", "np.stack.squeeze", "np.stack.squeeze", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.functionals.challenges.fastmri_nmse"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image\"", ",", "[", "flower", ",", "china", "]", ")", "\n", "def", "test_fastmri_nmse", "(", "image", ")", ":", "\n", "    ", "image_batch", "=", "[", "]", "\n", "image_noise_batch", "=", "[", "]", "\n", "single_image_nmse", "=", "[", "]", "\n", "\n", "for", "sigma", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "noise", "=", "sigma", "*", "np", ".", "random", ".", "rand", "(", "*", "image", ".", "shape", ")", "\n", "image_noise", "=", "(", "image", "+", "noise", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "clip", "(", "0", ",", "255", ")", "\n", "\n", "image_batch", ".", "append", "(", "image", ")", "\n", "image_noise_batch", ".", "append", "(", "image_noise", ")", "\n", "\n", "", "image_batch", "=", "np", ".", "stack", "(", "image_batch", ")", "\n", "image_noise_batch", "=", "np", ".", "stack", "(", "image_noise_batch", ")", "\n", "\n", "skimage_nrmse", "=", "nrmse", "(", "\n", "image_batch", ".", "squeeze", "(", ")", ",", "\n", "image_noise_batch", ".", "squeeze", "(", ")", ",", "\n", ")", "\n", "skimage_nmse", "=", "skimage_nrmse", "**", "2", "\n", "\n", "image_batch_torch", "=", "torch", ".", "tensor", "(", "image_batch", ")", "\n", "image_noise_batch_torch", "=", "torch", ".", "tensor", "(", "image_noise_batch", ")", "\n", "\n", "fastmri_nmse_batch", "=", "fastmri_nmse", "(", "image_batch_torch", ",", "image_noise_batch_torch", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "fastmri_nmse_batch", ",", "skimage_nmse", ",", "atol", "=", "5e-4", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_imports.test_module_available": [[9, 20], ["pytest.mark.parametrize", "direct.utils.imports._module_available"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.imports._module_available"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "[", "\"module\"", ",", "\"is_available\"", "]", ",", "\n", "[", "\n", "(", "\"torch\"", ",", "True", ")", ",", "\n", "(", "\"numpy\"", ",", "True", ")", ",", "\n", "(", "\"non-existent\"", ",", "False", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_module_available", "(", "module", ",", "is_available", ")", ":", "\n", "\n", "    ", "assert", "_module_available", "(", "module", ")", "==", "is_available", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.create_input": [[18, 23], ["numpy.random.randn().copy", "torch.from_numpy().float", "numpy.random.randn", "torch.from_numpy"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ".", "copy", "(", ")", "\n", "data", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.mock_cfg": [[25, 32], ["Config", "super().__init__"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["", "def", "mock_cfg", "(", "**", "kwargs", ")", ":", "\n", "    ", "class", "Config", "(", "dict", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "super", "(", "Config", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "__dict__", "=", "self", "\n", "\n", "", "", "return", "Config", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.test_is_complex_data": [[34, 51], ["pytest.mark.parametrize", "test_utils.create_input", "direct.utils.asserts.assert_complex"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.utils.asserts.assert_complex"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, complex_axis, complex_last\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "3", ",", "2", "]", ",", "None", ",", "True", "]", ",", "\n", "[", "[", "5", ",", "8", ",", "4", ",", "2", "]", ",", "-", "1", ",", "None", "]", ",", "\n", "[", "[", "5", ",", "2", ",", "8", ",", "4", "]", ",", "1", ",", "None", "]", ",", "\n", "[", "[", "3", ",", "5", ",", "8", ",", "4", ",", "2", "]", ",", "None", ",", "True", "]", ",", "\n", "[", "[", "3", ",", "5", ",", "2", ",", "8", ",", "4", "]", ",", "-", "3", ",", "None", "]", ",", "\n", "[", "[", "3", ",", "2", ",", "5", ",", "8", ",", "4", "]", ",", "1", ",", "None", "]", ",", "\n", "[", "[", "3", ",", "3", ",", "5", ",", "8", ",", "4", ",", "2", "]", ",", "None", ",", "True", "]", ",", "\n", "[", "[", "3", ",", "3", ",", "2", ",", "5", ",", "8", ",", "4", "]", ",", "2", ",", "None", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_is_complex_data", "(", "shape", ",", "complex_axis", ",", "complex_last", ")", ":", "\n", "    ", "data", "=", "create_input", "(", "shape", ")", "\n", "\n", "assert_complex", "(", "data", ",", "complex_axis", "=", "complex_axis", ",", "complex_last", "=", "complex_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.test_is_power_of_two": [[53, 60], ["pytest.mark.parametrize", "direct.utils.is_power_of_two"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.is_power_of_two"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num\"", ",", "\n", "[", "1", ",", "2", ",", "4", ",", "32", ",", "128", ",", "1024", "]", ",", "\n", ")", "\n", "def", "test_is_power_of_two", "(", "num", ")", ":", "\n", "\n", "    ", "assert", "is_power_of_two", "(", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.test_crop_to_largest": [[62, 79], ["pytest.mark.parametrize", "pytest.mark.parametrize", "direct.utils.bbox.crop_to_largest", "tuple", "all", "test_utils.create_input", "_.numpy", "max", "range", "tuple", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.bbox.crop_to_largest", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shapes\"", ",", "\n", "[", "\n", "[", "[", "5", ",", "4", ",", "2", "]", ",", "[", "4", ",", "3", ",", "2", "]", "]", ",", "\n", "[", "[", "5", ",", "8", ",", "4", ",", "2", "]", ",", "[", "6", ",", "7", ",", "3", ",", "2", "]", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"to_numpy\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_crop_to_largest", "(", "shapes", ",", "to_numpy", ")", ":", "\n", "    ", "data", "=", "[", "create_input", "(", "shape", ")", "for", "shape", "in", "shapes", "]", "\n", "if", "to_numpy", ":", "\n", "        ", "data", "=", "[", "_", ".", "numpy", "(", ")", "for", "_", "in", "data", "]", "\n", "\n", "", "cropped_data", "=", "crop_to_largest", "(", "data", ")", "\n", "crop_to_largest_shape", "=", "tuple", "(", "max", "(", "[", "shape", "[", "i", "]", "for", "shape", "in", "shapes", "]", ")", "for", "i", "in", "range", "(", "len", "(", "shapes", "[", "0", "]", ")", ")", ")", "\n", "\n", "assert", "all", "(", "tuple", "(", "_", ".", "shape", ")", "==", "crop_to_largest_shape", "for", "_", "in", "cropped_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.test_get_filenames_for_datasets": [[81, 103], ["pytest.mark.parametrize", "pytest.mark.parametrize", "tempfile.TemporaryDirectory", "data_root.mkdir", "range", "path_to_list.mkdir", "range", "direct.utils.dataset.get_filenames_for_datasets_from_config", "pathlib.Path", "pathlib.Path", "test_utils.mock_cfg", "test_utils.mock_cfg", "open", "f.write", "open", "f.write", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.dataset.get_filenames_for_datasets_from_config", "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.mock_cfg", "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.mock_cfg", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"file_list\"", ",", "[", "True", ",", "None", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_samples\"", ",", "[", "3", ",", "4", "]", ")", "\n", "def", "test_get_filenames_for_datasets", "(", "file_list", ",", "num_samples", ")", ":", "\n", "\n", "    ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "\n", "        ", "data_root", "=", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "\"data\"", "\n", "data_root", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "with", "open", "(", "data_root", "/", "f\"file_{_}.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"Fake file.\"", ")", "\n", "", "", "path_to_list", "=", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "\"lists\"", "\n", "path_to_list", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "with", "open", "(", "path_to_list", "/", "\"mock_list.lst\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "f\"file_{_}.txt\"", "+", "\"\\n\"", ")", "\n", "\n", "", "", "cfg", "=", "mock_cfg", "(", "filenames_lists", "=", "[", "\"mock_list.lst\"", "]", ")", "if", "file_list", "else", "mock_cfg", "(", ")", "\n", "filenames", "=", "get_filenames_for_datasets_from_config", "(", "cfg", ",", "files_root", "=", "path_to_list", ",", "data_root", "=", "data_root", ")", "\n", "if", "file_list", ":", "\n", "            ", "assert", "len", "(", "filenames", ")", "==", "num_samples", "\n", "", "else", ":", "\n", "            ", "assert", "filenames", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.test_set_all_seeds": [[105, 115], ["pytest.mark.parametrize", "pytest.mark.parametrize", "range", "arrays.append", "numpy.allclose", "direct.utils.set_all_seeds", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.set_all_seeds"], ["", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"seed\"", ",", "[", "100", ",", "10", ",", "None", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", ",", "2", "]", ",", "[", "5", ",", "8", ",", "4", ",", "2", "]", "]", ")", "\n", "def", "test_set_all_seeds", "(", "seed", ",", "shape", ")", ":", "\n", "    ", "arrays", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "if", "seed", "is", "not", "None", ":", "\n", "            ", "set_all_seeds", "(", "seed", ")", "\n", "", "arrays", ".", "append", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", "\n", "\n", "", "assert", "np", ".", "allclose", "(", "arrays", "[", "0", "]", ",", "arrays", "[", "1", "]", ")", "==", "(", "seed", "is", "not", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.test_remove_keys": [[117, 123], ["pytest.mark.parametrize", "pytest.mark.parametrize", "direct.utils.remove_keys", "set", "direct.utils.remove_keys.keys", "set", "set"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.remove_keys"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"keys\"", ",", "[", "[", "\"test_key1\"", ",", "\"test_key2\"", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"del_keys\"", ",", "[", "[", "\"test_key1\"", "]", ",", "[", "]", "]", ")", "\n", "def", "test_remove_keys", "(", "keys", ",", "del_keys", ")", ":", "\n", "    ", "dictionary", "=", "{", "k", ":", "None", "for", "k", "in", "keys", "}", "\n", "dictionary", "=", "remove_keys", "(", "dictionary", ",", "del_keys", ")", "\n", "assert", "set", "(", "dictionary", ".", "keys", "(", ")", ")", "==", "(", "set", "(", "keys", ")", "-", "set", "(", "del_keys", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_utils.test_normalize_image": [[125, 131], ["pytest.mark.parametrize", "pytest.mark.parametrize", "numpy.random.randn", "direct.utils.normalize_image", "direct.utils.normalize_image.min", "direct.utils.normalize_image.max"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.__init__.normalize_image"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "4", ",", "3", ",", "3", ",", "2", "]", ",", "[", "5", ",", "8", ",", "2", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"eps\"", ",", "[", "0.00001", ",", "0.0001", "]", ")", "\n", "def", "test_normalize_image", "(", "shape", ",", "eps", ")", ":", "\n", "    ", "img", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", "\n", "normalized_img", "=", "normalize_image", "(", "img", ",", "eps", ")", "\n", "assert", "normalized_img", ".", "min", "(", ")", ">=", "0.0", "and", "normalized_img", ".", "max", "(", ")", "<=", "1.0", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_utils.test_io.test_check_valid_url": [[9, 24], ["pytest.mark.parametrize", "direct.utils.io.check_is_valid_url", "direct.utils.io.check_is_valid_url"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url", "home.repos.pwc.inspect_result.directgroup_direct.utils.io.check_is_valid_url"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "[", "\"path\"", ",", "\"is_url\"", "]", ",", "\n", "[", "\n", "(", "\"https://s3.aiforoncology.nl/checkpoint.ckpt\"", ",", "True", ")", ",", "\n", "(", "\"http://localhost:8000/checkpoint.ckpt\"", ",", "True", ")", ",", "\n", "(", "\"ftp://aiforoncology.nl/checkpoint.ckpt\"", ",", "True", ")", ",", "\n", "(", "\"checkpoint.ckpt\"", ",", "False", ")", ",", "\n", "(", "\"/mnt/checkpoint.ckpt\"", ",", "False", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_check_valid_url", "(", "path", ",", "is_url", ")", ":", "\n", "    ", "if", "is_url", ":", "\n", "        ", "assert", "check_is_valid_url", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "assert", "not", "check_is_valid_url", "(", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.test_cli.test_utils.test_is_file": [[13, 21], ["pytest.mark.parametrize", "tempfile.NamedTemporaryFile", "pytest.raises", "direct.cli.utils.is_file", "pathlib.Path", "direct.cli.utils.is_file"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.cli.utils.is_file", "home.repos.pwc.inspect_result.directgroup_direct.cli.utils.is_file"], ["from", "direct", ".", "utils", ".", "asserts", "import", "assert_complex", "\n", "from", "direct", ".", "utils", ".", "bbox", "import", "crop_to_largest", "\n", "from", "direct", ".", "utils", ".", "dataset", "import", "get_filenames_for_datasets_from_config", "\n", "\n", "\n", "def", "create_input", "(", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ".", "copy", "(", ")", "\n", "data", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.create_input": [[14, 19], ["numpy.random.randn().copy", "torch.from_numpy().float", "numpy.random.randn", "torch.from_numpy"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ".", "copy", "(", ")", "\n", "data", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_fft2": [[21, 42], ["pytest.mark.parametrize", "test_transforms.create_input", "direct.data.transforms.fft2().numpy", "direct.data.transforms.tensor_to_complex_numpy", "numpy.fft.ifftshift", "numpy.fft.fft2", "numpy.fft.fftshift", "numpy.allclose", "direct.data.transforms.fft2"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fft2"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, dim\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "3", "]", ",", "(", "0", ",", "1", ")", "]", ",", "\n", "[", "[", "4", ",", "6", "]", ",", "(", "0", ",", "1", ")", "]", ",", "\n", "[", "[", "10", ",", "8", ",", "4", "]", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "[", "3", ",", "4", ",", "2", ",", "2", "]", ",", "(", "2", ",", "3", ")", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_fft2", "(", "shape", ",", "dim", ")", ":", "\n", "    ", "shape", "=", "shape", "+", "[", "2", "]", "\n", "data", "=", "create_input", "(", "shape", ")", "\n", "\n", "out_torch", "=", "transforms", ".", "fft2", "(", "data", ",", "dim", "=", "dim", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "data_numpy", "=", "tensor_to_complex_numpy", "(", "data", ")", "\n", "data_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "data_numpy", ",", "dim", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fft2", "(", "data_numpy", ",", "norm", "=", "\"ortho\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "dim", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_ifft2": [[44, 69], ["pytest.mark.parametrize", "test_transforms.create_input", "any", "direct.data.transforms.ifft2().numpy", "direct.data.transforms.tensor_to_complex_numpy", "numpy.fft.ifftshift", "numpy.fft.ifft2", "numpy.fft.fftshift", "numpy.allclose", "pytest.raises", "direct.data.transforms.ifft2().numpy", "direct.data.transforms.ifft2", "direct.data.transforms.ifft2"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifft2"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, dim\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "3", "]", ",", "(", "0", ",", "1", ")", "]", ",", "\n", "[", "[", "3", ",", "3", "]", ",", "(", "-", "2", ",", "-", "1", ")", "]", ",", "\n", "[", "[", "4", ",", "6", "]", ",", "(", "0", ",", "1", ")", "]", ",", "\n", "[", "[", "10", ",", "8", ",", "4", "]", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "[", "3", ",", "4", ",", "2", ",", "2", "]", ",", "(", "2", ",", "3", ")", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_ifft2", "(", "shape", ",", "dim", ")", ":", "\n", "    ", "shape", "=", "shape", "+", "[", "2", "]", "\n", "data", "=", "create_input", "(", "shape", ")", "\n", "if", "any", "(", "_", "<", "0", "for", "_", "in", "dim", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "            ", "out_torch", "=", "transforms", ".", "ifft2", "(", "data", ",", "dim", "=", "dim", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "out_torch", "=", "transforms", ".", "ifft2", "(", "data", ",", "dim", "=", "dim", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_numpy", "(", "data", ")", "\n", "input_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "input_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "ifft2", "(", "input_numpy", ",", "norm", "=", "\"ortho\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_modulus": [[71, 87], ["pytest.mark.parametrize", "test_transforms.create_input", "direct.data.transforms.modulus().numpy", "direct.data.transforms.tensor_to_complex_numpy", "numpy.abs", "numpy.allclose", "direct.data.transforms.modulus"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "3", "]", ",", "\n", "[", "4", ",", "6", "]", ",", "\n", "[", "10", ",", "8", ",", "4", "]", ",", "\n", "[", "3", ",", "4", ",", "2", ",", "2", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_modulus", "(", "shape", ")", ":", "\n", "    ", "shape", "=", "shape", "+", "[", "2", "]", "\n", "data", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "transforms", ".", "modulus", "(", "data", ")", ".", "numpy", "(", ")", "\n", "input_numpy", "=", "tensor_to_complex_numpy", "(", "data", ")", "\n", "out_numpy", "=", "np", ".", "abs", "(", "input_numpy", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_modulus_if_complex": [[89, 124], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_transforms.create_input", "direct.data.transforms.modulus_if_complex", "shape.pop", "direct.data.transforms.modulus_if_complex", "print", "list", "shape.append"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus_if_complex", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.modulus_if_complex"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "3", "]", ",", "\n", "[", "4", ",", "6", "]", ",", "\n", "[", "\n", "3", ",", "\n", "4", ",", "\n", "8", ",", "\n", "]", ",", "\n", "[", "3", ",", "4", ",", "8", ",", "5", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"complex_axis\"", ",", "[", "0", ",", "1", ",", "2", ",", "-", "1", ",", "None", "]", ")", "\n", "def", "test_modulus_if_complex", "(", "shape", ",", "complex_axis", ")", ":", "\n", "    ", "if", "complex_axis", "is", "not", "None", ":", "\n", "        ", "if", "complex_axis", "!=", "-", "1", ":", "\n", "            ", "shape", "=", "(", "\n", "shape", "[", ":", "complex_axis", "]", "\n", "+", "[", "\n", "2", ",", "\n", "]", "\n", "+", "shape", "[", "complex_axis", ":", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "shape", ".", "append", "(", "2", ")", "\n", "", "", "data", "=", "create_input", "(", "shape", ")", "\n", "if", "complex_axis", "is", "not", "None", ":", "\n", "        ", "data", "=", "transforms", ".", "modulus_if_complex", "(", "data", ",", "complex_axis", ")", "\n", "shape", ".", "pop", "(", "complex_axis", ")", "\n", "", "else", ":", "\n", "        ", "data", "=", "transforms", ".", "modulus_if_complex", "(", "data", ")", "\n", "print", "(", "data", ".", "shape", ")", "\n", "\n", "", "assert", "list", "(", "data", ".", "shape", ")", "==", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_root_sum_of_squares_real": [[126, 138], ["pytest.mark.parametrize", "test_transforms.create_input", "direct.data.transforms.root_sum_of_squares().numpy", "numpy.sqrt", "numpy.allclose", "numpy.sum", "direct.data.transforms.root_sum_of_squares", "create_input.numpy"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, dims\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "3", "]", ",", "0", "]", ",", "\n", "[", "[", "4", ",", "6", "]", ",", "1", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_root_sum_of_squares_real", "(", "shape", ",", "dims", ")", ":", "\n", "    ", "data", "=", "create_input", "(", "shape", ")", "# noqa", "\n", "out_torch", "=", "transforms", ".", "root_sum_of_squares", "(", "data", ",", "dims", ")", ".", "numpy", "(", ")", "\n", "out_numpy", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "data", ".", "numpy", "(", ")", "**", "2", ",", "dims", ")", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_root_sum_of_squares_complex": [[143, 161], ["pytest.mark.parametrize", "test_transforms.create_input", "direct.data.transforms.root_sum_of_squares().numpy", "direct.data.transforms.tensor_to_complex_numpy", "numpy.sqrt", "numpy.allclose", "numpy.sum", "direct.data.transforms.root_sum_of_squares", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.fake.root_sum_of_squares"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, dims\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "3", ",", "9", "]", ",", "coils_dim", "]", ",", "\n", "[", "[", "4", ",", "6", ",", "4", "]", ",", "coils_dim", "]", ",", "\n", "[", "[", "15", ",", "66", ",", "43", "]", ",", "coils_dim", "]", ",", "\n", "[", "[", "15", ",", "36", ",", "23", ",", "2", "]", ",", "coils_dim", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_root_sum_of_squares_complex", "(", "shape", ",", "dims", ")", ":", "\n", "    ", "shape", "=", "shape", "+", "[", "\n", "2", ",", "\n", "]", "\n", "data", "=", "create_input", "(", "shape", ")", "# noqa", "\n", "out_torch", "=", "transforms", ".", "root_sum_of_squares", "(", "data", ",", "dims", ")", ".", "numpy", "(", ")", "\n", "input_numpy", "=", "tensor_to_complex_numpy", "(", "data", ")", "\n", "out_numpy", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "input_numpy", ")", "**", "2", ",", "dims", ")", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_center_crop": [[163, 175], ["pytest.mark.parametrize", "test_transforms.create_input", "direct.data.transforms.center_crop().numpy", "list", "direct.data.transforms.center_crop"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.center_crop"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, target_shape\"", ",", "\n", "[", "\n", "[", "[", "10", ",", "10", "]", ",", "[", "4", ",", "4", "]", "]", ",", "\n", "[", "[", "4", ",", "6", "]", ",", "[", "2", ",", "4", "]", "]", ",", "\n", "[", "[", "8", ",", "4", "]", ",", "[", "4", ",", "4", "]", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_center_crop", "(", "shape", ",", "target_shape", ")", ":", "\n", "    ", "input", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "transforms", ".", "center_crop", "(", "input", ",", "target_shape", ")", ".", "numpy", "(", ")", "\n", "assert", "list", "(", "out_torch", ".", "shape", ")", "==", "target_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_complex_center_crop": [[465, 484], ["pytest.mark.parametrize", "pytest.mark.parametrize", "direct.data.transforms.complex_center_crop", "all", "test_transforms.create_input", "all", "range", "numpy.random.randint", "tuple", "data.is_contiguous"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_center_crop", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, crop_shape\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "7", ",", "9", "]", ",", "[", "4", ",", "5", "]", "]", ",", "\n", "[", "[", "3", ",", "6", ",", "6", "]", ",", "[", "4", ",", "4", "]", "]", ",", "\n", "[", "[", "3", ",", "6", ",", "6", ",", "7", "]", ",", "[", "3", ",", "4", ",", "4", "]", "]", ",", "\n", "[", "[", "3", ",", "8", ",", "6", ",", "8", "]", ",", "[", "3", ",", "4", ",", "4", "]", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"contiguous\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_complex_center_crop", "(", "shape", ",", "crop_shape", ",", "contiguous", ")", ":", "\n", "    ", "data_list", "=", "[", "create_input", "(", "shape", "+", "[", "2", "]", ")", "for", "_", "in", "range", "(", "np", ".", "random", ".", "randint", "(", "2", ",", "5", ")", ")", "]", "\n", "data_list", "=", "transforms", ".", "complex_center_crop", "(", "data_list", ",", "crop_shape", ",", "contiguous", "=", "contiguous", ")", "\n", "assert", "all", "(", "data", ".", "shape", "==", "tuple", "(", "[", "data", ".", "shape", "[", "0", "]", "]", "+", "crop_shape", "+", "[", "2", "]", ")", "for", "data", "in", "data_list", ")", "\n", "if", "contiguous", ":", "\n", "        ", "assert", "all", "(", "data", ".", "is_contiguous", "(", ")", "for", "data", "in", "data_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_roll": [[195, 224], ["pytest.mark.parametrize", "pytest.mark.parametrize", "numpy.arange().reshape", "torch.from_numpy", "direct.data.transforms.roll().numpy", "numpy.roll", "numpy.allclose", "numpy.arange", "isinstance", "isinstance", "len", "len", "pytest.raises", "direct.data.transforms.roll().numpy", "numpy.product", "direct.data.transforms.roll", "direct.data.transforms.roll"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.roll"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shift, dims\"", ",", "\n", "[", "\n", "(", "(", "0", ",", ")", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "(", "1", ",", ")", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "(", "-", "1", ",", ")", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "(", "100", ",", ")", ",", "(", "0", ",", ")", ")", ",", "\n", "(", "(", "1", ",", "2", ")", ",", "(", "1", ",", ")", ")", ",", "\n", "(", "(", "1", ",", "2", ")", ",", "(", "1", ",", "2", ")", ")", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "5", ",", "6", ",", "2", "]", ",", "\n", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "[", "3", ",", "11", ",", "4", ",", "5", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_roll", "(", "shift", ",", "dims", ",", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "\n", "torch_tensor", "=", "torch", ".", "from_numpy", "(", "data", ")", "\n", "if", "not", "isinstance", "(", "shift", ",", "int", ")", "and", "not", "isinstance", "(", "dims", ",", "int", ")", "and", "len", "(", "shift", ")", "!=", "len", "(", "dims", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "out_torch", "=", "transforms", ".", "roll", "(", "torch_tensor", ",", "shift", ",", "dims", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "out_torch", "=", "transforms", ".", "roll", "(", "torch_tensor", ",", "shift", ",", "dims", ")", ".", "numpy", "(", ")", "\n", "out_numpy", "=", "np", ".", "roll", "(", "data", ",", "shift", ",", "dims", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_complex_multiplication": [[226, 243], ["pytest.mark.parametrize", "direct.data.transforms.to_tensor", "direct.data.transforms.to_tensor", "direct.data.transforms.tensor_to_complex_numpy", "numpy.allclose", "numpy.arange().reshape", "direct.data.transforms.complex_multiplication", "numpy.arange", "numpy.arange().reshape", "numpy.product", "numpy.arange", "numpy.product"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_multiplication"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "7", "]", ",", "\n", "[", "5", ",", "6", ",", "2", "]", ",", "\n", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_complex_multiplication", "(", "shape", ")", ":", "\n", "    ", "data_0", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "+", "1j", "*", "(", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "+", "1", ")", "\n", "data_1", "=", "data_0", "+", "0.5", "+", "1j", "\n", "torch_tensor_0", "=", "transforms", ".", "to_tensor", "(", "data_0", ")", "\n", "torch_tensor_1", "=", "transforms", ".", "to_tensor", "(", "data_1", ")", "\n", "\n", "out_torch", "=", "tensor_to_complex_numpy", "(", "transforms", ".", "complex_multiplication", "(", "torch_tensor_0", ",", "torch_tensor_1", ")", ")", "\n", "out_numpy", "=", "data_0", "*", "data_1", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_complex_matrix_multiplication": [[278, 300], ["pytest.mark.parametrize", "direct.data.transforms.complex_mm", "torch.view_as_complex", "torch.allclose", "torch.randn", "torch.randn", "torch.stack", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_mm", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_complex"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shapes\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "7", "]", ",", "[", "7", ",", "4", "]", "]", ",", "\n", "[", "[", "5", ",", "6", "]", ",", "[", "6", ",", "3", "]", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_complex_matrix_multiplication", "(", "shapes", ")", ":", "\n", "    ", "data_0", "=", "torch", ".", "randn", "(", "*", "shapes", "[", "0", "]", ")", "+", "1.0j", "*", "torch", ".", "randn", "(", "*", "shapes", "[", "0", "]", ")", "\n", "data_1", "=", "torch", ".", "randn", "(", "*", "shapes", "[", "1", "]", ")", "+", "1.0j", "*", "torch", ".", "randn", "(", "*", "shapes", "[", "1", "]", ")", "\n", "\n", "out", "=", "transforms", ".", "complex_mm", "(", "data_0", ",", "data_1", ")", "\n", "out_torch", "=", "torch", ".", "view_as_complex", "(", "\n", "torch", ".", "stack", "(", "\n", "(", "\n", "data_0", ".", "real", "@", "data_1", ".", "real", "-", "data_0", ".", "imag", "@", "data_1", ".", "imag", ",", "\n", "data_0", ".", "real", "@", "data_1", ".", "imag", "+", "data_0", ".", "imag", "@", "data_1", ".", "real", ",", "\n", ")", ",", "\n", "dim", "=", "2", ",", "\n", ")", "\n", ")", "\n", "assert", "torch", ".", "allclose", "(", "out", ",", "out_torch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_complex_bmm": [[302, 334], ["pytest.mark.parametrize", "pytest.mark.parametrize", "direct.data.transforms.complex_bmm", "torch.stack", "torch.allclose", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.view_as_complex", "torch.stack", "range"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_bmm", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.view_as_complex"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shapes\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "7", "]", ",", "[", "7", ",", "4", "]", "]", ",", "\n", "[", "[", "5", ",", "6", "]", ",", "[", "6", ",", "3", "]", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"batch_size\"", ",", "\n", "[", "3", ",", "4", "]", ",", "\n", ")", "\n", "def", "test_complex_bmm", "(", "shapes", ",", "batch_size", ")", ":", "\n", "    ", "data_0", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "shapes", "[", "0", "]", ")", "+", "1.0j", "*", "torch", ".", "randn", "(", "batch_size", ",", "*", "shapes", "[", "0", "]", ")", "\n", "data_1", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "shapes", "[", "1", "]", ")", "+", "1.0j", "*", "torch", ".", "randn", "(", "batch_size", ",", "*", "shapes", "[", "1", "]", ")", "\n", "\n", "out", "=", "transforms", ".", "complex_bmm", "(", "data_0", ",", "data_1", ")", "\n", "out_torch", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "torch", ".", "view_as_complex", "(", "\n", "torch", ".", "stack", "(", "\n", "(", "\n", "data_0", "[", "_", "]", ".", "real", "@", "data_1", "[", "_", "]", ".", "real", "-", "data_0", "[", "_", "]", ".", "imag", "@", "data_1", "[", "_", "]", ".", "imag", ",", "\n", "data_0", "[", "_", "]", ".", "real", "@", "data_1", "[", "_", "]", ".", "imag", "+", "data_0", "[", "_", "]", ".", "imag", "@", "data_1", "[", "_", "]", ".", "real", ",", "\n", ")", ",", "\n", "dim", "=", "2", ",", "\n", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "assert", "torch", ".", "allclose", "(", "out", ",", "out_torch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_conjugate": [[336, 351], ["pytest.mark.parametrize", "direct.data.transforms.to_tensor", "direct.data.transforms.tensor_to_complex_numpy", "numpy.conjugate", "numpy.allclose", "numpy.arange().reshape", "direct.data.transforms.conjugate", "numpy.arange", "numpy.arange().reshape", "numpy.product", "numpy.arange", "numpy.product"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.to_tensor", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.conjugate"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "7", "]", ",", "\n", "[", "5", ",", "6", ",", "2", "]", ",", "\n", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_conjugate", "(", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "+", "1j", "*", "(", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "+", "1", ")", "\n", "torch_tensor", "=", "transforms", ".", "to_tensor", "(", "data", ")", "\n", "\n", "out_torch", "=", "tensor_to_complex_numpy", "(", "transforms", ".", "conjugate", "(", "torch_tensor", ")", ")", "\n", "out_numpy", "=", "np", ".", "conjugate", "(", "data", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_fftshift": [[353, 360], ["pytest.mark.parametrize", "numpy.arange().reshape", "torch.from_numpy", "direct.data.transforms.fftshift().numpy", "numpy.fft.fftshift", "numpy.allclose", "numpy.arange", "direct.data.transforms.fftshift", "numpy.product"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "5", ",", "3", "]", ",", "[", "2", ",", "4", ",", "6", "]", ",", "[", "2", ",", "11", ",", "4", ",", "7", "]", "]", ")", "\n", "def", "test_fftshift", "(", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "\n", "torch_tensor", "=", "torch", ".", "from_numpy", "(", "data", ")", "\n", "out_torch", "=", "transforms", ".", "fftshift", "(", "torch_tensor", ")", ".", "numpy", "(", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "data", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_ifftshift": [[362, 376], ["pytest.mark.parametrize", "numpy.arange().reshape", "torch.from_numpy", "direct.data.transforms.ifftshift().numpy", "numpy.fft.ifftshift", "numpy.allclose", "numpy.arange", "direct.data.transforms.ifftshift", "numpy.product"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "5", ",", "3", "]", ",", "\n", "[", "2", ",", "4", ",", "5", "]", ",", "\n", "[", "2", ",", "11", ",", "7", ",", "5", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_ifftshift", "(", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "\n", "torch_tensor", "=", "torch", ".", "from_numpy", "(", "data", ")", "\n", "out_torch", "=", "transforms", ".", "ifftshift", "(", "torch_tensor", ")", ".", "numpy", "(", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "data", ")", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_expand_operator": [[378, 402], ["pytest.mark.parametrize", "test_transforms.create_input", "test_transforms.create_input", "direct.data.transforms.tensor_to_complex_numpy", "numpy.expand_dims", "direct.data.transforms.tensor_to_complex_numpy", "numpy.allclose", "direct.data.transforms.expand_operator", "direct.data.transforms.tensor_to_complex_numpy"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.expand_operator", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, dim\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "4", ",", "5", "]", ",", "0", "]", ",", "\n", "[", "[", "3", ",", "3", ",", "4", ",", "5", "]", ",", "1", "]", ",", "\n", "[", "[", "3", ",", "6", ",", "4", ",", "5", "]", ",", "0", "]", ",", "\n", "[", "[", "3", ",", "3", ",", "6", ",", "4", ",", "5", "]", ",", "1", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_expand_operator", "(", "shape", ",", "dim", ")", ":", "\n", "    ", "shape", "=", "shape", "+", "[", "\n", "2", ",", "\n", "]", "\n", "data", "=", "create_input", "(", "shape", ")", "# noqa", "\n", "shape", "=", "shape", "[", ":", "dim", "]", "+", "shape", "[", "dim", "+", "1", ":", "]", "\n", "sens", "=", "create_input", "(", "shape", ")", "# noqa", "\n", "\n", "out_torch", "=", "tensor_to_complex_numpy", "(", "transforms", ".", "expand_operator", "(", "data", ",", "sens", ",", "dim", ")", ")", "\n", "\n", "input_numpy", "=", "np", ".", "expand_dims", "(", "tensor_to_complex_numpy", "(", "data", ")", ",", "dim", ")", "\n", "input_sens_numpy", "=", "tensor_to_complex_numpy", "(", "sens", ")", "\n", "out_numpy", "=", "input_sens_numpy", "*", "input_numpy", "\n", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_reduce_operator": [[404, 426], ["pytest.mark.parametrize", "test_transforms.create_input", "test_transforms.create_input", "direct.data.transforms.tensor_to_complex_numpy", "direct.data.transforms.tensor_to_complex_numpy", "direct.data.transforms.tensor_to_complex_numpy", "numpy.allclose", "direct.data.transforms.reduce_operator", "direct.data.transforms.tensor_to_complex_numpy.conj"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.tensor_to_complex_numpy", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.reduce_operator"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, dim\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "4", ",", "5", "]", ",", "0", "]", ",", "\n", "[", "[", "3", ",", "3", ",", "4", ",", "5", "]", ",", "1", "]", ",", "\n", "[", "[", "3", ",", "6", ",", "4", ",", "5", "]", ",", "0", "]", ",", "\n", "[", "[", "3", ",", "3", ",", "6", ",", "4", ",", "5", "]", ",", "1", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_reduce_operator", "(", "shape", ",", "dim", ")", ":", "\n", "    ", "shape", "=", "shape", "+", "[", "\n", "2", ",", "\n", "]", "\n", "coil_data", "=", "create_input", "(", "shape", ")", "# noqa", "\n", "sens", "=", "create_input", "(", "shape", ")", "# noqa", "\n", "out_torch", "=", "tensor_to_complex_numpy", "(", "transforms", ".", "reduce_operator", "(", "coil_data", ",", "sens", ",", "dim", ")", ")", "\n", "\n", "input_numpy", "=", "tensor_to_complex_numpy", "(", "coil_data", ")", "\n", "input_sens_numpy", "=", "tensor_to_complex_numpy", "(", "sens", ")", "\n", "out_numpy", "=", "(", "input_sens_numpy", ".", "conj", "(", ")", "*", "input_numpy", ")", ".", "sum", "(", "dim", ")", "\n", "\n", "assert", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_transforms.test_complex_random_crop": [[428, 463], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_transforms.create_input", "direct.data.transforms.complex_random_crop", "all", "pytest.raises", "direct.data.transforms.complex_random_crop", "all", "range", "data.is_contiguous", "len"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_random_crop", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.complex_random_crop"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shapes, crop_shape, sampler, sigma, expect_error\"", ",", "\n", "[", "\n", "[", "[", "[", "2", ",", "7", ",", "7", "]", "]", "*", "2", ",", "(", "8", ",", "8", ")", ",", "\"uniform\"", ",", "None", ",", "True", "]", ",", "\n", "[", "[", "[", "2", ",", "7", ",", "7", "]", "]", "*", "2", ",", "(", "4", ",", "3", ")", ",", "\"uniform\"", ",", "None", ",", "False", "]", ",", "\n", "[", "[", "[", "2", ",", "7", ",", "7", "]", "]", "*", "2", ",", "(", "4", ",", "3", ")", ",", "\"uniform\"", ",", "0.2", ",", "True", "]", ",", "\n", "[", "[", "[", "2", ",", "7", ",", "7", "]", "]", "*", "2", ",", "(", "4", ",", "3", ")", ",", "\"gaussian\"", ",", "0.2", ",", "False", "]", ",", "\n", "[", "[", "[", "2", ",", "7", ",", "7", "]", "]", "*", "2", ",", "(", "4", ",", "3", ")", ",", "\"gaussian\"", ",", "[", "0.1", ",", "0.2", "]", ",", "False", "]", ",", "\n", "[", "[", "[", "2", ",", "7", ",", "7", "]", ",", "[", "3", ",", "8", ",", "6", "]", "]", ",", "(", "4", ",", "3", ")", ",", "\"gaussian\"", ",", "0.2", ",", "True", "]", ",", "\n", "[", "[", "[", "2", ",", "7", ",", "7", "]", "]", "*", "2", ",", "(", "4", ",", "3", ")", ",", "\"invalid_sampler\"", ",", "False", ",", "True", "]", ",", "\n", "[", "[", "[", "3", ",", "4", ",", "8", ",", "6", "]", "]", "*", "2", ",", "(", "2", ",", "6", ",", "4", ")", ",", "\"uniform\"", ",", "None", ",", "False", "]", ",", "\n", "[", "[", "[", "3", ",", "4", ",", "8", ",", "6", "]", "]", "*", "2", ",", "(", "2", ",", "6", ",", "4", ")", ",", "\"uniform\"", ",", "0.2", ",", "True", "]", ",", "\n", "[", "[", "[", "3", ",", "4", ",", "8", ",", "6", "]", "]", "*", "2", ",", "(", "2", ",", "6", ",", "4", ")", ",", "\"gaussian\"", ",", "0.2", ",", "False", "]", ",", "\n", "[", "[", "[", "3", ",", "4", ",", "8", ",", "6", "]", "]", "*", "2", ",", "(", "2", ",", "6", ",", "4", ")", ",", "\"gaussian\"", ",", "[", "0.1", ",", "0.2", "]", ",", "True", "]", ",", "\n", "[", "[", "[", "3", ",", "4", ",", "8", ",", "6", "]", "]", "*", "2", ",", "(", "2", ",", "6", ",", "4", ")", ",", "\"invalid_sampler\"", ",", "False", ",", "True", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"contiguous\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_complex_random_crop", "(", "shapes", ",", "crop_shape", ",", "sampler", ",", "sigma", ",", "expect_error", ",", "contiguous", ")", ":", "\n", "    ", "data_list", "=", "[", "create_input", "(", "shape", "+", "[", "2", "]", ")", "for", "shape", "in", "shapes", "]", "\n", "if", "expect_error", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "samples", "=", "transforms", ".", "complex_random_crop", "(", "\n", "data_list", ",", "crop_shape", ",", "sampler", "=", "sampler", ",", "sigma", "=", "sigma", ",", "contiguous", "=", "contiguous", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "data_list", "=", "transforms", ".", "complex_random_crop", "(", "\n", "data_list", ",", "crop_shape", ",", "sampler", "=", "sampler", ",", "sigma", "=", "sigma", ",", "contiguous", "=", "contiguous", "\n", ")", "\n", "assert", "all", "(", "data_list", "[", "i", "]", ".", "shape", "==", "(", "shapes", "[", "i", "]", "[", "0", "]", ",", ")", "+", "crop_shape", "+", "(", "2", ",", ")", "for", "i", "in", "range", "(", "len", "(", "data_list", ")", ")", ")", "\n", "if", "contiguous", ":", "\n", "            ", "assert", "all", "(", "data", ".", "is_contiguous", "(", ")", "for", "data", "in", "data_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__": [[22, 34], ["range", "test_samplers._TestDS.volume_indices.items", "range", "list", "random.randint"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_samples", ")", ":", "\n", "        ", "self", ".", "volume_indices", "=", "{", "}", "\n", "lower_number", "=", "0", "\n", "for", "idx", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "upper_number", "=", "lower_number", "+", "random", ".", "randint", "(", "1", ",", "25", ")", "\n", "self", ".", "volume_indices", "[", "f\"label_{idx}\"", "]", "=", "range", "(", "lower_number", ",", "upper_number", ")", "\n", "lower_number", "=", "upper_number", "\n", "\n", "", "self", ".", "reverse_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "volume_indices", ".", "items", "(", ")", ":", "\n", "            ", "for", "_", "in", "list", "(", "v", ")", ":", "\n", "                ", "self", ".", "reverse_dict", "[", "_", "]", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__getitem__": [[35, 37], ["None"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__len__": [[38, 40], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "volume_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers.test_distributed_sequential_sampler": [[42, 54], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_samplers._TestDS", "range", "direct.data.samplers.DistributedSequentialSampler", "len", "len", "len", "len", "set", "set"], "function", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_samples\"", ",", "[", "10", ",", "31", ",", "68", ",", "811", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_replicas\"", ",", "[", "1", ",", "3", ",", "4", ",", "6", ",", "8", "]", ")", "\n", "def", "test_distributed_sequential_sampler", "(", "num_samples", ",", "num_replicas", ")", ":", "\n", "    ", "\"\"\"Tests if all samples are disjoint and unique.\"\"\"", "\n", "ds", "=", "_TestDS", "(", "num_samples", ")", "\n", "indices_per_process", "=", "[", "]", "\n", "for", "rank", "in", "range", "(", "num_replicas", ")", ":", "\n", "        ", "sampler", "=", "DistributedSequentialSampler", "(", "ds", ",", "num_replicas", "=", "num_replicas", ",", "rank", "=", "rank", ")", "\n", "indices", "=", "[", "_", "for", "_", "in", "sampler", "]", "\n", "assert", "len", "(", "indices", ")", "==", "len", "(", "set", "(", "indices", ")", ")", "\n", "indices_per_process", "+=", "indices", "\n", "", "assert", "len", "(", "indices_per_process", ")", "==", "len", "(", "set", "(", "indices_per_process", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers.test_batch_volume_sampler": [[56, 74], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "test_samplers._TestDS", "range", "direct.data.samplers.DistributedSequentialSampler", "direct.data.samplers.BatchVolumeSampler", "all", "output.append", "names.append", "set", "len"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "3", ",", "5", ",", "8", ",", "16", ",", "32", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_samples\"", ",", "[", "10", ",", "31", ",", "68", ",", "811", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_replicas\"", ",", "[", "1", ",", "3", ",", "4", ",", "6", ",", "8", "]", ")", "\n", "def", "test_batch_volume_sampler", "(", "batch_size", ",", "num_samples", ",", "num_replicas", ")", ":", "\n", "    ", "ds", "=", "_TestDS", "(", "num_samples", ")", "\n", "\n", "for", "rank", "in", "range", "(", "num_replicas", ")", ":", "\n", "        ", "sampler", "=", "DistributedSequentialSampler", "(", "ds", ",", "num_replicas", "=", "num_replicas", ",", "rank", "=", "rank", ")", "\n", "batch_sampler", "=", "BatchVolumeSampler", "(", "sampler", ",", "batch_size", ")", "\n", "batches", "=", "[", "_", "for", "_", "in", "batch_sampler", "]", "\n", "output", "=", "[", "]", "\n", "for", "batch", "in", "batches", ":", "\n", "            ", "names", "=", "[", "]", "\n", "for", "idx", "in", "batch", ":", "\n", "                ", "names", ".", "append", "(", "ds", ".", "reverse_dict", "[", "idx", "]", ")", "\n", "", "output", ".", "append", "(", "(", "batch", ",", "set", "(", "names", ")", ")", ")", "\n", "\n", "", "assert", "all", "(", "[", "len", "(", "_", "[", "1", "]", ")", "==", "1", "for", "_", "in", "output", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers.test_concat_dataset_batch_sampler": [[76, 107], ["pytest.mark.parametrize", "pytest.mark.parametrize", "torch.utils.data.ConcatDataset", "range", "direct.data.samplers.DistributedSampler", "direct.data.samplers.ConcatDatasetBatchSampler", "test_samplers._TestDS", "len", "list", "len", "batches.append", "list", "range", "set", "len", "int", "_.numpy"], "function", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dataset_sizes\"", ",", "[", "[", "1", "]", ",", "[", "1", ",", "9", "]", ",", "[", "19", ",", "111", ",", "7787", ",", "2939", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "3", ",", "7", ",", "16", "]", ")", "\n", "def", "test_concat_dataset_batch_sampler", "(", "dataset_sizes", ",", "batch_size", ")", ":", "\n", "# Create a list of datasets", "\n", "    ", "datasets", "=", "[", "_TestDS", "(", "num_samples", ")", "for", "num_samples", "in", "dataset_sizes", "]", "\n", "\n", "dataset", "=", "ConcatDataset", "(", "datasets", ")", "\n", "\n", "dataset_indices", "=", "{", "}", "\n", "curr_val", "=", "0", "\n", "for", "idx", "in", "range", "(", "len", "(", "dataset_sizes", ")", ")", ":", "\n", "        ", "indices_for_curr_dataset", "=", "list", "(", "range", "(", "curr_val", ",", "dataset", ".", "cumulative_sizes", "[", "idx", "]", ")", ")", "\n", "curr_val", "=", "dataset", ".", "cumulative_sizes", "[", "idx", "]", "\n", "for", "_", "in", "indices_for_curr_dataset", ":", "\n", "            ", "dataset_indices", "[", "_", "]", "=", "idx", "\n", "\n", "", "", "sampler", "=", "DistributedSampler", "(", "len", "(", "dataset", ")", ",", "shuffle", "=", "True", ")", "\n", "batch_sampler", "=", "ConcatDatasetBatchSampler", "(", "datasets", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "idx", "=", "0", "\n", "batches", "=", "[", "]", "\n", "for", "batch", "in", "batch_sampler", ":", "\n", "        ", "batches", ".", "append", "(", "[", "int", "(", "_", ".", "numpy", "(", ")", ")", "for", "_", "in", "batch", "]", ")", "\n", "if", "idx", ">", "1001", ":", "\n", "            ", "break", "\n", "", "idx", "+=", "1", "\n", "\n", "# Make sure each batch comes from precisely one dataset", "\n", "", "for", "batch", "in", "batches", ":", "\n", "        ", "indices", "=", "list", "(", "set", "(", "[", "dataset_indices", "[", "_", "]", "for", "_", "in", "batch", "]", ")", ")", "\n", "assert", "len", "(", "indices", ")", "==", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_datasets.create_fastmri_h5file": [[25, 92], ["ismrmrd.xsd.ismrmrdHeader", "ismrmrd.xsd.encodingType", "ismrmrd.xsd.matrixSizeType", "ismrmrd.xsd.matrixSizeType", "ismrmrd.xsd.matrixSizeType", "ismrmrd.xsd.matrixSizeType", "ismrmrd.xsd.encodingSpaceType", "ismrmrd.xsd.encodingSpaceType", "ismrmrd.xsd.encodingLimitsType", "ismrmrd.xsd.limitType", "round", "ismrmrd.xsd.limitType", "ismrmrd.xsd.limitType", "ismrmrd.xsd.ismrmrdHeader.encoding.append", "numpy.random.rand", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "numpy.linalg.norm", "numpy.abs().max", "h5py.File.close", "numpy.random.rand", "numpy.random.rand", "ismrmrd.xsd.ismrmrdHeader.toXML", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset", "home.repos.pwc.inspect_result.directgroup_direct.recurrent.recurrent.NormConv2dGRU.norm", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close"], ["def", "create_fastmri_h5file", "(", "filename", ",", "shape", ",", "recon_shape", ")", ":", "\n", "    ", "header", "=", "ismrmrd", ".", "xsd", ".", "ismrmrdHeader", "(", ")", "\n", "encoding", "=", "ismrmrd", ".", "xsd", ".", "encodingType", "(", ")", "\n", "\n", "ematrix", "=", "ismrmrd", ".", "xsd", ".", "matrixSizeType", "(", ")", "\n", "rmatrix", "=", "ismrmrd", ".", "xsd", ".", "matrixSizeType", "(", ")", "\n", "\n", "ematrix", "=", "ismrmrd", ".", "xsd", ".", "matrixSizeType", "(", ")", "\n", "ematrix", ".", "x", "=", "shape", "[", "2", "]", "\n", "ematrix", ".", "y", "=", "shape", "[", "3", "]", "\n", "ematrix", ".", "z", "=", "shape", "[", "0", "]", "\n", "rmatrix", "=", "ismrmrd", ".", "xsd", ".", "matrixSizeType", "(", ")", "\n", "rmatrix", ".", "x", "=", "recon_shape", "[", "1", "]", "\n", "rmatrix", ".", "y", "=", "recon_shape", "[", "2", "]", "\n", "rmatrix", ".", "z", "=", "recon_shape", "[", "0", "]", "\n", "\n", "espace", "=", "ismrmrd", ".", "xsd", ".", "encodingSpaceType", "(", ")", "\n", "espace", ".", "matrixSize", "=", "ematrix", "\n", "\n", "rspace", "=", "ismrmrd", ".", "xsd", ".", "encodingSpaceType", "(", ")", "\n", "rspace", ".", "matrixSize", "=", "rmatrix", "\n", "\n", "# Set encoded and recon spaces", "\n", "encoding", ".", "encodedSpace", "=", "espace", "\n", "encoding", ".", "reconSpace", "=", "rspace", "\n", "\n", "# Encoding limits", "\n", "limits", "=", "ismrmrd", ".", "xsd", ".", "encodingLimitsType", "(", ")", "\n", "limits1", "=", "ismrmrd", ".", "xsd", ".", "limitType", "(", ")", "\n", "limits1", ".", "minimum", "=", "0", "\n", "limits1", ".", "center", "=", "round", "(", "shape", "[", "3", "]", "/", "2", ")", "\n", "limits1", ".", "maximum", "=", "shape", "[", "3", "]", "-", "1", "\n", "limits", ".", "kspace_encoding_step_1", "=", "limits1", "\n", "\n", "limits_rep", "=", "ismrmrd", ".", "xsd", ".", "limitType", "(", ")", "\n", "limits_rep", ".", "minimum", "=", "0", "\n", "limits_rep", ".", "center", "=", "0", "\n", "limits_rep", ".", "maximum", "=", "0", "\n", "limits", ".", "repetition", "=", "limits_rep", "\n", "\n", "limits_rest", "=", "ismrmrd", ".", "xsd", ".", "limitType", "(", ")", "\n", "limits_rest", ".", "minimum", "=", "0", "\n", "limits_rest", ".", "center", "=", "0", "\n", "limits_rest", ".", "maximum", "=", "0", "\n", "limits", ".", "kspace_encoding_step_0", "=", "limits_rest", "\n", "limits", ".", "slice", "=", "limits_rest", "\n", "limits", ".", "average", "=", "limits_rest", "\n", "limits", ".", "contrast", "=", "limits_rest", "\n", "limits", ".", "kspaceEncodingStep2", "=", "limits_rest", "\n", "limits", ".", "phase", "=", "limits_rest", "\n", "limits", ".", "segment", "=", "limits_rest", "\n", "limits", ".", "set", "=", "limits_rest", "\n", "\n", "encoding", ".", "encodingLimits", "=", "limits", "\n", "header", ".", "encoding", ".", "append", "(", "encoding", ")", "\n", "\n", "kspace", "=", "np", ".", "random", ".", "rand", "(", "*", "shape", ")", "+", "1.0j", "*", "np", ".", "random", ".", "rand", "(", "*", "shape", ")", "\n", "rss", "=", "np", ".", "random", ".", "rand", "(", "shape", "[", "0", "]", ",", "*", "shape", "[", "2", ":", "]", ")", "\n", "h5file", "=", "h5py", ".", "File", "(", "filename", ",", "\"w\"", ")", "\n", "h5file", ".", "create_dataset", "(", "\"kspace\"", ",", "data", "=", "kspace", ")", "\n", "h5file", ".", "create_dataset", "(", "\"reconstruction_rss\"", ",", "data", "=", "rss", ")", "\n", "h5file", ".", "create_dataset", "(", "\"ismrmrd_header\"", ",", "data", "=", "header", ".", "toXML", "(", ")", ")", "\n", "\n", "h5file", ".", "attrs", "[", "\"norm\"", "]", "=", "np", ".", "linalg", ".", "norm", "(", "kspace", ")", "\n", "h5file", ".", "attrs", "[", "\"max\"", "]", "=", "np", ".", "abs", "(", "kspace", ")", ".", "max", "(", ")", "\n", "\n", "h5file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_datasets.test_FastMRIDataset": [[94, 148], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "tempfile.TemporaryDirectory", "range", "direct.data.datasets.FastMRIDataset", "all", "test_datasets.create_fastmri_h5file", "open", "open.close", "pathlib.Path", "len", "direct.data.datasets.FastMRIDataset", "all", "open.write", "FASTMRI_KEYS.issubset", "pathlib.Path", "len", "pathlib.Path", "pathlib.Path", "len", "range", "pathlib.Path", "len", "pathlib.Path", "len", "_.keys", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_datasets.create_fastmri_h5file", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_samples\"", ",", "\n", "[", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, recon_shape\"", ",", "\n", "[", "[", "(", "6", ",", "12", ",", "20", ",", "10", ")", ",", "(", "6", ",", "15", ",", "8", ")", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"transform\"", ",", "\n", "[", "None", ",", "lambda", "x", ":", "x", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"filter\"", ",", "\n", "[", "None", ",", "[", "\"file0.h5\"", ",", "\"file1.h5\"", "]", "]", ",", "\n", ")", "\n", "def", "test_FastMRIDataset", "(", "num_samples", ",", "shape", ",", "recon_shape", ",", "transform", ",", "filter", ")", ":", "\n", "    ", "FASTMRI_KEYS", "=", "{", "\n", "\"kspace\"", ",", "\n", "\"filename\"", ",", "\n", "\"slice_no\"", ",", "\n", "\"scaling_factor\"", ",", "\n", "\"padding_left\"", ",", "\n", "\"padding_right\"", ",", "\n", "\"encoding_size\"", ",", "\n", "\"reconstruction_size\"", ",", "\n", "}", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "\n", "        ", "for", "_", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "create_fastmri_h5file", "(", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "f\"file{_}.h5\"", ",", "shape", ",", "recon_shape", ")", "\n", "", "if", "filter", ":", "\n", "            ", "f", "=", "open", "(", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "\"filter.lst\"", ",", "\"w\"", ")", "\n", "for", "filename", "in", "filter", ":", "\n", "                ", "f", ".", "write", "(", "filename", "+", "\"\\n\"", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "", "dataset", "=", "FastMRIDataset", "(", "\n", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "\n", "filenames_filter", "=", "[", "pathlib", ".", "Path", "(", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "f", ")", "for", "f", "in", "filter", "]", "if", "filter", "else", "None", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "(", "num_samples", "if", "not", "filter", "else", "len", "(", "filter", ")", ")", "*", "shape", "[", "0", "]", "\n", "assert", "all", "(", "FASTMRI_KEYS", ".", "issubset", "(", "dataset", "[", "_", "]", ")", "for", "_", "in", "range", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "# Test with filenames_lists", "\n", "if", "filter", ":", "\n", "            ", "dataset", "=", "FastMRIDataset", "(", "\n", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "\n", "filenames_filter", "=", "None", ",", "\n", "filenames_lists", "=", "[", "\"filter.lst\"", "]", ",", "\n", "filenames_lists_root", "=", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "len", "(", "filter", ")", "*", "shape", "[", "0", "]", "\n", "assert", "all", "(", "\"kspace\"", "in", "_", ".", "keys", "(", ")", "for", "_", "in", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_datasets.test_CalgaryCampinasDataset": [[150, 199], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "tempfile.TemporaryDirectory", "range", "direct.data.datasets.CalgaryCampinasDataset", "all", "numpy.random.rand", "h5py.File", "h5py.File.create_dataset", "h5py.File.close", "open", "open.close", "pathlib.Path", "len", "direct.data.datasets.CalgaryCampinasDataset", "all", "open.write", "pathlib.Path", "len", "pathlib.Path", "pathlib.Path", "len", "_.keys", "pathlib.Path", "len", "pathlib.Path", "_.keys", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.TensorboardWriter.close", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.CommonMetricPrinter.write"], ["", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_samples\"", ",", "\n", "[", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "160", ",", "3", ",", "5", ",", "6", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"transform\"", ",", "\n", "[", "None", ",", "lambda", "x", ":", "x", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"filter\"", ",", "\n", "[", "None", ",", "[", "\"file0.h5\"", ",", "\"file1.h5\"", "]", "]", ",", "\n", ")", "\n", "def", "test_CalgaryCampinasDataset", "(", "num_samples", ",", "shape", ",", "transform", ",", "filter", ")", ":", "\n", "    ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "\n", "        ", "for", "_", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "kspace", "=", "np", ".", "random", ".", "rand", "(", "*", "shape", ")", "\n", "h5file", "=", "h5py", ".", "File", "(", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "f\"file{_}.h5\"", ",", "\"w\"", ")", "\n", "h5file", ".", "create_dataset", "(", "\"kspace\"", ",", "data", "=", "kspace", ")", "\n", "h5file", ".", "close", "(", ")", "\n", "", "if", "filter", ":", "\n", "            ", "f", "=", "open", "(", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "\"filter.lst\"", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "for", "filename", "in", "filter", ":", "\n", "                ", "f", ".", "write", "(", "filename", "+", "\"\\n\"", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "", "dataset", "=", "CalgaryCampinasDataset", "(", "\n", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "\n", "crop_outer_slices", "=", "True", ",", "\n", "filenames_filter", "=", "[", "pathlib", ".", "Path", "(", "pathlib", ".", "Path", "(", "tempdir", ")", "/", "f", ")", "for", "f", "in", "filter", "]", "if", "filter", "else", "None", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "(", "num_samples", "if", "not", "filter", "else", "len", "(", "filter", ")", ")", "*", "(", "shape", "[", "0", "]", "-", "100", ")", "\n", "assert", "all", "(", "\"kspace\"", "in", "_", ".", "keys", "(", ")", "for", "_", "in", "dataset", ")", "\n", "\n", "# Test with filenames_lists", "\n", "if", "filter", ":", "\n", "            ", "dataset", "=", "CalgaryCampinasDataset", "(", "\n", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "\n", "crop_outer_slices", "=", "True", ",", "\n", "filenames_filter", "=", "None", ",", "\n", "filenames_lists", "=", "[", "\"filter.lst\"", "]", ",", "\n", "filenames_lists_root", "=", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "len", "(", "filter", ")", "*", "(", "shape", "[", "0", "]", "-", "100", ")", "\n", "assert", "all", "(", "\"kspace\"", "in", "_", ".", "keys", "(", ")", "for", "_", "in", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_datasets.test_shepp_logan_datasets": [[201, 220], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "d", "len"], "function", ["None"], ["", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, num_coils\"", ",", "\n", "[", "[", "(", "6", ",", "20", ",", "10", ")", ",", "8", "]", ",", "[", "(", "20", ",", "20", ",", "20", ")", ",", "5", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"transform\"", ",", "\n", "[", "None", ",", "lambda", "x", ":", "x", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"T2_star\"", ",", "\n", "[", "False", ",", "True", "]", ",", "\n", ")", "\n", "def", "test_shepp_logan_datasets", "(", "shape", ",", "num_coils", ",", "transform", ",", "T2_star", ")", ":", "\n", "    ", "datasets", "=", "[", "SheppLoganT1Dataset", ",", "SheppLoganT2Dataset", ",", "SheppLoganProtonDataset", "]", "\n", "args", "=", "{", "\"shape\"", ":", "shape", ",", "\"num_coils\"", ":", "num_coils", ",", "\"transform\"", ":", "transform", ",", "\"text_description\"", ":", "\"test\"", "}", "\n", "for", "d", "in", "datasets", ":", "\n", "        ", "dataset", "=", "d", "(", "**", "(", "{", "**", "args", ",", "**", "{", "\"T2_star\"", ":", "T2_star", "}", "}", "if", "d", "==", "SheppLoganT2Dataset", "else", "args", ")", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "shape", "[", "-", "1", "]", "\n", "assert", "dataset", "[", "0", "]", "[", "\"kspace\"", "]", ".", "shape", "==", "(", "num_coils", ",", ")", "+", "shape", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_datasets.test_FakeMRIBlobsDataset": [[222, 258], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "len", "direct.data.datasets.FakeMRIBlobsDataset", "all", "pytest.raises", "direct.data.datasets.FakeMRIBlobsDataset", "FAKE_KEYS.issubset", "range", "len"], "function", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_samples\"", ",", "\n", "[", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, num_coils\"", ",", "\n", "[", "[", "(", "6", ",", "20", ",", "10", ")", ",", "5", "]", ",", "[", "(", "20", ",", "10", ")", ",", "3", "]", ",", "[", "(", "2", ",", "3", ",", "20", ",", "10", ")", ",", "None", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"transform\"", ",", "\n", "[", "None", ",", "lambda", "x", ":", "x", "]", ",", "\n", ")", "\n", "def", "test_FakeMRIBlobsDataset", "(", "num_samples", ",", "num_coils", ",", "shape", ",", "transform", ")", ":", "\n", "    ", "FAKE_KEYS", "=", "{", "\n", "\"kspace\"", ",", "\n", "\"filename\"", ",", "\n", "\"slice_no\"", ",", "\n", "\"scaling_factor\"", ",", "\n", "\"encoding_size\"", ",", "\n", "\"reconstruction_size\"", ",", "\n", "}", "\n", "if", "len", "(", "shape", ")", "not", "in", "[", "2", ",", "3", "]", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "            ", "dataset", "=", "FakeMRIBlobsDataset", "(", "num_samples", ",", "num_coils", ",", "shape", ",", "transform", ")", "\n", "", "", "else", ":", "\n", "        ", "dataset", "=", "FakeMRIBlobsDataset", "(", "\n", "num_samples", ",", "\n", "num_coils", ",", "\n", "shape", ",", "\n", "transform", ",", "\n", "pass_attrs", "=", "True", ",", "\n", "text_description", "=", "\"test\"", ",", "\n", "filenames", "=", "\"file\"", ",", "\n", "seed", "=", "0", ",", "\n", ")", "\n", "assert", "all", "(", "FAKE_KEYS", ".", "issubset", "(", "dataset", "[", "_", "]", ")", "for", "_", "in", "range", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_datasets.test_ConcatDataset": [[260, 283], ["pytest.mark.parametrize", "zip", "direct.data.datasets.ConcatDataset", "enumerate", "datasets.append", "len", "sum", "numpy.allclose", "pytest.raises", "FakeData", "numpy.cumsum", "numpy.cumsum"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.cumsum", "home.repos.pwc.inspect_result.directgroup_direct.data.datasets.ConcatDataset.cumsum"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_samples, shapes\"", ",", "\n", "[", "\n", "[", "[", "3", ",", "5", "]", ",", "[", "(", "5", ",", "3", ")", ",", "(", "5", ",", "4", ")", "]", "]", ",", "\n", "[", "[", "4", ",", "7", "]", ",", "[", "(", "2", ",", "5", ",", "3", ")", ",", "(", "4", ",", "5", ",", "4", ")", "]", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_ConcatDataset", "(", "num_samples", ",", "shapes", ")", ":", "\n", "    ", "from", "torchvision", ".", "datasets", "import", "FakeData", "\n", "\n", "datasets", "=", "[", "]", "\n", "for", "num", ",", "shape", "in", "zip", "(", "num_samples", ",", "shapes", ")", ":", "\n", "        ", "datasets", ".", "append", "(", "FakeData", "(", "num", ",", "image_size", "=", "shape", ",", "random_offset", "=", "0", ")", ")", "\n", "", "dataset", "=", "ConcatDataset", "(", "datasets", ")", "\n", "\n", "assert", "len", "(", "dataset", ")", "==", "sum", "(", "num_samples", ")", "\n", "\n", "for", "dataset_idx", ",", "num", "in", "enumerate", "(", "num_samples", ")", ":", "\n", "\n", "        ", "assert", "np", ".", "allclose", "(", "datasets", "[", "dataset_idx", "]", "[", "num", "-", "1", "]", "[", "0", "]", ",", "dataset", "[", "np", ".", "cumsum", "(", "num_samples", ")", "[", "dataset_idx", "]", "-", "1", "]", "[", "0", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "dataset", "[", "-", "(", "np", ".", "cumsum", "(", "num_samples", ")", "+", "1", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.create_sample": [[30, 40], ["any", "dict", "torch.from_numpy().float", "numpy.random.randint", "[].items", "tuple", "str", "torch.from_numpy", "numpy.random.randint", "numpy.random.randn", "locals", "numpy.random.randint"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "any", "(", "_", "is", "None", "for", "_", "in", "shape", ")", ":", "\n", "        ", "shape", "=", "tuple", "(", "_", "if", "_", "else", "np", ".", "random", ".", "randint", "(", "0", ",", "10", ")", "for", "_", "in", "shape", ")", "\n", "", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"filename\"", "]", "=", "\"filename\"", "+", "str", "(", "np", ".", "random", ".", "randint", "(", "100", ",", "10000", ")", ")", "\n", "sample", "[", "\"slice_no\"", "]", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "1000", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms._mask_func": [[42, 56], ["torch.zeros().bool", "torch.zeros().bool.unsqueeze().unsqueeze", "torch.zeros().bool.unsqueeze().unsqueeze", "numpy.random.RandomState", "np.random.RandomState.seed", "torch.from_numpy().round().bool", "torch.zeros", "torch.zeros().bool.unsqueeze", "torch.zeros().bool.unsqueeze", "torch.from_numpy().round", "torch.from_numpy", "numpy.random.rand"], "function", ["None"], ["", "def", "_mask_func", "(", "shape", ",", "seed", "=", "None", ",", "return_acs", "=", "False", ")", ":", "\n", "    ", "shape", "=", "shape", "[", ":", "-", "1", "]", "\n", "mask", "=", "torch", ".", "zeros", "(", "shape", ")", ".", "bool", "(", ")", "\n", "mask", "[", "\n", "shape", "[", "0", "]", "//", "2", "-", "shape", "[", "0", "]", "//", "4", ":", "shape", "[", "0", "]", "//", "2", "+", "shape", "[", "0", "]", "//", "4", ",", "\n", "shape", "[", "1", "]", "//", "2", "-", "shape", "[", "1", "]", "//", "4", ":", "shape", "[", "1", "]", "//", "2", "+", "shape", "[", "1", "]", "//", "4", ",", "\n", "]", "=", "True", "\n", "if", "return_acs", ":", "\n", "        ", "return", "mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "if", "seed", ":", "\n", "        ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "rng", ".", "seed", "(", "seed", ")", "\n", "", "mask", "=", "mask", "|", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "rand", "(", "*", "shape", ")", ")", ".", "round", "(", ")", ".", "bool", "(", ")", "\n", "return", "mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_Compose": [[58, 78], ["pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.Compose", "all", "torch.manual_seed", "direct.data.mri_transforms.Compose.", "torch.manual_seed", "torch.allclose", "CenterCrop", "RandomVerticalFlip", "t", "repr", "repr"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "4", ",", "7", ",", "6", ")", ",", "(", "3", ",", "10", ",", "8", ")", "]", ",", "\n", ")", "\n", "def", "test_Compose", "(", "shape", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "shape", "+", "(", "2", ",", ")", ")", "\n", "\n", "from", "torchvision", ".", "transforms", "import", "CenterCrop", ",", "RandomVerticalFlip", "\n", "\n", "transforms", "=", "[", "CenterCrop", "(", "[", "_", "//", "2", "for", "_", "in", "shape", "[", "1", ":", "]", "]", ")", ",", "RandomVerticalFlip", "(", "0.5", ")", "]", "\n", "transform", "=", "Compose", "(", "transforms", ")", "\n", "assert", "all", "(", "repr", "(", "t", ")", "in", "repr", "(", "transform", ")", "for", "t", "in", "transforms", ")", "\n", "torch", ".", "manual_seed", "(", "0", ")", "\n", "compose_out", "=", "transform", "(", "sample", "[", "\"kspace\"", "]", ")", "\n", "kspace", "=", "sample", "[", "\"kspace\"", "]", "\n", "\n", "torch", ".", "manual_seed", "(", "0", ")", "\n", "for", "t", "in", "transforms", ":", "\n", "        ", "kspace", "=", "t", "(", "kspace", ")", "\n", "", "assert", "torch", ".", "allclose", "(", "compose_out", ",", "kspace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_CreateSamplingMask": [[80, 111], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.CreateSamplingMask", "transform.update", "direct.data.mri_transforms.CreateSamplingMask.", "len", "pytest.raises", "direct.data.mri_transforms.CreateSamplingMask.", "tuple"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "1", ",", "4", ",", "6", ")", ",", "(", "5", ",", "7", ",", "6", ")", ",", "(", "2", ",", "None", ",", "None", ")", ",", "(", "3", ",", "4", ",", "6", ",", "4", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"return_acs\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"padding\"", ",", "\n", "[", "None", ",", "[", "2", ",", "2", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"use_shape\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_CreateSamplingMask", "(", "shape", ",", "return_acs", ",", "padding", ",", "use_shape", ")", ":", "\n", "\n", "    ", "sample", "=", "create_sample", "(", "shape", "+", "(", "2", ",", ")", ")", "\n", "if", "padding", ":", "\n", "        ", "sample", ".", "update", "(", "{", "\"padding_right\"", ":", "padding", "[", "0", "]", ",", "\"padding_left\"", ":", "padding", "[", "1", "]", "}", ")", "\n", "", "transform", "=", "CreateSamplingMask", "(", "mask_func", "=", "_mask_func", ",", "shape", "=", "shape", "[", "1", ":", "]", "if", "use_shape", "else", "None", ",", "return_acs", "=", "return_acs", ")", "\n", "if", "padding", "and", "len", "(", "shape", ")", ">", "3", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "sample", "=", "transform", "(", "sample", ")", "\n", "", "", "else", ":", "\n", "        ", "sample", "=", "transform", "(", "sample", ")", "\n", "assert", "\"sampling_mask\"", "in", "sample", "\n", "assert", "tuple", "(", "sample", "[", "\"sampling_mask\"", "]", ".", "shape", ")", "==", "(", "1", ",", ")", "+", "sample", "[", "\"kspace\"", "]", ".", "shape", "[", "1", ":", "-", "1", "]", "+", "(", "1", ",", ")", "\n", "if", "return_acs", ":", "\n", "            ", "assert", "\"acs_mask\"", "in", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_ApplyMask": [[113, 129], ["pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.ApplyMask", "transform.update", "direct.data.mri_transforms.ApplyMask.", "torch.allclose", "pytest.raises", "direct.data.mri_transforms.ApplyMask.", "sample[].squeeze().bool", "torch.rand().round().unsqueeze().unsqueeze", "torch.abs().sum", "sample[].squeeze", "torch.rand().round().unsqueeze", "torch.abs", "torch.rand().round", "torch.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "4", ",", "32", ",", "32", ")", ",", "(", "3", ",", "10", ",", "16", ")", "]", ",", "\n", ")", "\n", "def", "test_ApplyMask", "(", "shape", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "shape", "=", "shape", "+", "(", "2", ",", ")", ")", "\n", "transform", "=", "ApplyMask", "(", ")", "\n", "# Check error raise when sampling mask not present in sample", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "sample", "=", "transform", "(", "sample", ")", "\n", "", "sample", ".", "update", "(", "{", "\"sampling_mask\"", ":", "torch", ".", "rand", "(", "shape", "[", "1", ":", "]", ")", ".", "round", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "}", ")", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "assert", "\"masked_kspace\"", "in", "sample", "\n", "\n", "mask", "=", "~", "(", "torch", ".", "abs", "(", "sample", "[", "\"masked_kspace\"", "]", ")", ".", "sum", "(", "dim", "=", "(", "0", ",", "-", "1", ")", ")", "==", "0", ")", "\n", "assert", "torch", ".", "allclose", "(", "mask", ",", "sample", "[", "\"sampling_mask\"", "]", ".", "squeeze", "(", ")", ".", "bool", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_CropKspace": [[131, 194], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "torch.rand", "torch.rand().round().unsqueeze().unsqueeze", "torch.rand", "pytest.raises", "direct.data.mri_transforms.CropKspace", "direct.data.mri_transforms.CropKspace", "direct.data.mri_transforms.CropKspace.", "pytest.raises", "direct.data.mri_transforms.CropKspace", "direct.data.mri_transforms.CropKspace.", "tuple", "transform.update", "torch.rand().round().unsqueeze", "torch.rand().round", "torch.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "3", ",", "10", ",", "16", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"crop\"", ",", "\n", "[", "(", "5", ",", "6", ")", ",", "\"reconstruction_size\"", ",", "None", ",", "\"invalid_key\"", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"image_space_center_crop\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"random_crop_sampler_type, random_crop_sampler_gaussian_sigma\"", ",", "\n", "[", "\n", "[", "\"uniform\"", ",", "None", "]", ",", "\n", "[", "\"gaussian\"", ",", "None", "]", ",", "\n", "[", "\"gaussian\"", ",", "[", "1.0", ",", "2.0", "]", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"random_crop_sampler_use_seed\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_CropKspace", "(", "\n", "shape", ",", "\n", "crop", ",", "\n", "image_space_center_crop", ",", "\n", "random_crop_sampler_type", ",", "\n", "random_crop_sampler_use_seed", ",", "\n", "random_crop_sampler_gaussian_sigma", ",", "\n", ")", ":", "\n", "\n", "    ", "sample", "=", "create_sample", "(", "\n", "shape", "=", "shape", "+", "(", "2", ",", ")", ",", "\n", "sensitivity_map", "=", "torch", ".", "rand", "(", "shape", "+", "(", "2", ",", ")", ")", ",", "\n", "sampling_mask", "=", "torch", ".", "rand", "(", "shape", "[", "1", ":", "]", ")", ".", "round", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "input_image", "=", "torch", ".", "rand", "(", "(", "1", ",", ")", "+", "shape", "[", "1", ":", "]", "+", "(", "2", ",", ")", ")", ",", "\n", ")", "\n", "args", "=", "{", "\n", "\"crop\"", ":", "crop", ",", "\n", "\"image_space_center_crop\"", ":", "image_space_center_crop", ",", "\n", "\"random_crop_sampler_type\"", ":", "random_crop_sampler_type", ",", "\n", "\"random_crop_sampler_use_seed\"", ":", "random_crop_sampler_use_seed", ",", "\n", "\"random_crop_sampler_gaussian_sigma\"", ":", "random_crop_sampler_gaussian_sigma", ",", "\n", "}", "\n", "crop_shape", "=", "crop", "\n", "if", "crop", "is", "None", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "transform", "=", "CropKspace", "(", "**", "args", ")", "\n", "", "", "elif", "crop", "==", "\"invalid_key\"", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "transform", "=", "CropKspace", "(", "**", "args", ")", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "crop", "==", "\"reconstruction_size\"", ":", "\n", "            ", "crop_shape", "=", "tuple", "(", "(", "d", "//", "2", "for", "d", "in", "shape", "[", "1", ":", "]", ")", ")", "\n", "sample", ".", "update", "(", "{", "\"reconstruction_size\"", ":", "crop_shape", "}", ")", "\n", "\n", "", "transform", "=", "CropKspace", "(", "**", "args", ")", "\n", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "assert", "sample", "[", "\"kspace\"", "]", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "crop_shape", "+", "(", "2", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_ComputeImage": [[196, 228], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.ComputeImage", "direct.data.mri_transforms.ComputeImage.", "pytest.raises", "direct.data.mri_transforms.ComputeImage", "transform.update", "pytest.raises", "direct.data.mri_transforms.ComputeImage.", "torch.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, spatial_dims\"", ",", "\n", "[", "\n", "[", "(", "1", ",", "4", ",", "6", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "5", ",", "7", ",", "6", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "4", ",", "5", ",", "5", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "3", ",", "4", ",", "6", ",", "4", ")", ",", "(", "2", ",", "3", ")", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"type_recon, complex_output, expect_error\"", ",", "\n", "[", "\n", "[", "\"complex\"", ",", "True", ",", "False", "]", ",", "\n", "[", "\"sense\"", ",", "True", ",", "False", "]", ",", "\n", "[", "\"rss\"", ",", "False", ",", "False", "]", ",", "\n", "[", "\"invalid\"", ",", "None", ",", "True", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_ComputeImage", "(", "shape", ",", "spatial_dims", ",", "type_recon", ",", "complex_output", ",", "expect_error", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "shape", "=", "shape", "+", "(", "2", ",", ")", ")", "\n", "if", "expect_error", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "transform", "=", "ComputeImage", "(", "\"kspace\"", ",", "\"target\"", ",", "ifft2", ",", "type_reconstruction", "=", "type_recon", ")", "\n", "", "", "else", ":", "\n", "        ", "transform", "=", "ComputeImage", "(", "\"kspace\"", ",", "\"target\"", ",", "ifft2", ",", "type_reconstruction", "=", "type_recon", ")", "\n", "if", "type_recon", "==", "\"sense\"", ":", "\n", "            ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "                ", "sample", "=", "transform", "(", "sample", ",", "coil_dim", "=", "0", ",", "spatial_dims", "=", "spatial_dims", ")", "\n", "", "sample", ".", "update", "(", "{", "\"sensitivity_map\"", ":", "torch", ".", "rand", "(", "shape", "+", "(", "2", ",", ")", ")", "}", ")", "\n", "", "sample", "=", "transform", "(", "sample", ",", "coil_dim", "=", "0", ",", "spatial_dims", "=", "spatial_dims", ")", "\n", "assert", "\"target\"", "in", "sample", "\n", "assert", "sample", "[", "\"target\"", "]", ".", "shape", "==", "(", "shape", "[", "1", ":", "]", "+", "(", "2", ",", ")", "if", "complex_output", "else", "shape", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_EstimateBodyCoilImage": [[230, 249], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.EstimateBodyCoilImage", "direct.data.mri_transforms.EstimateBodyCoilImage.", "torch.rand", "functools.partial"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, spatial_dims\"", ",", "\n", "[", "\n", "[", "(", "1", ",", "4", ",", "6", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "5", ",", "7", ",", "6", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "4", ",", "5", ",", "5", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "3", ",", "4", ",", "6", ",", "4", ")", ",", "(", "2", ",", "3", ")", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"use_seed\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_EstimateBodyCoilImage", "(", "shape", ",", "spatial_dims", ",", "use_seed", ")", ":", "\n", "\n", "    ", "sample", "=", "create_sample", "(", "shape", "=", "shape", "+", "(", "2", ",", ")", ",", "sensitivity_map", "=", "torch", ".", "rand", "(", "shape", "+", "(", "2", ",", ")", ")", ")", "\n", "transform", "=", "EstimateBodyCoilImage", "(", "\n", "mask_func", "=", "_mask_func", ",", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "dim", "=", "spatial_dims", ")", ",", "use_seed", "=", "use_seed", "\n", ")", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "assert", "\"body_coil_image\"", "in", "sample", "\n", "assert", "sample", "[", "\"body_coil_image\"", "]", ".", "shape", "==", "shape", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_EstimateSensitivityMap": [[251, 298], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "transform.update", "functools.partial", "direct.data.mri_transforms.EstimateSensitivityMap", "torch.rand().round", "torch.rand().round", "pytest.raises", "direct.data.mri_transforms.EstimateSensitivityMap", "direct.data.mri_transforms.EstimateSensitivityMap.", "direct.data.mri_transforms.EstimateSensitivityMap.", "torch.rand", "pytest.warns", "direct.data.mri_transforms.EstimateSensitivityMap.", "torch.rand", "torch.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.HistoryBuffer.update"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, spatial_dims\"", ",", "\n", "[", "\n", "[", "(", "1", ",", "4", ",", "6", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "5", ",", "7", ",", "6", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "4", ",", "5", ",", "5", ")", ",", "(", "1", ",", "2", ")", "]", ",", "\n", "[", "(", "3", ",", "4", ",", "6", ",", "4", ")", ",", "(", "2", ",", "3", ")", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"type_of_map, gaussian_sigma, expect_error, sense_map_in_sample\"", ",", "\n", "[", "\n", "[", "\"unit\"", ",", "None", ",", "False", ",", "False", "]", ",", "\n", "[", "\"rss_estimate\"", ",", "0.5", ",", "False", ",", "False", "]", ",", "\n", "[", "\"rss_estimate\"", ",", "None", ",", "False", ",", "False", "]", ",", "\n", "[", "\"rss_estimate\"", ",", "None", ",", "False", ",", "True", "]", ",", "\n", "[", "\"invalid\"", ",", "None", ",", "True", ",", "False", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_EstimateSensitivityMap", "(", "shape", ",", "spatial_dims", ",", "type_of_map", ",", "gaussian_sigma", ",", "expect_error", ",", "sense_map_in_sample", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "\n", "shape", "=", "shape", "+", "(", "2", ",", ")", ",", "\n", "acs_mask", "=", "torch", ".", "rand", "(", "(", "1", ",", ")", "+", "shape", "[", "1", ":", "]", "+", "(", "1", ",", ")", ")", ".", "round", "(", ")", ",", "\n", "sampling_mask", "=", "torch", ".", "rand", "(", "(", "1", ",", ")", "+", "shape", "[", "1", ":", "]", "+", "(", "1", ",", ")", ")", ".", "round", "(", ")", ",", "\n", ")", "\n", "if", "sense_map_in_sample", ":", "\n", "        ", "sample", ".", "update", "(", "{", "\"sensitivity_map\"", ":", "torch", ".", "rand", "(", "shape", "+", "(", "2", ",", ")", ")", "}", ")", "\n", "\n", "", "args", "=", "{", "\n", "\"kspace_key\"", ":", "\"kspace\"", ",", "\n", "\"backward_operator\"", ":", "functools", ".", "partial", "(", "ifft2", ",", "dim", "=", "spatial_dims", ")", ",", "\n", "\"type_of_map\"", ":", "type_of_map", ",", "\n", "\"gaussian_sigma\"", ":", "gaussian_sigma", ",", "\n", "}", "\n", "if", "expect_error", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "transform", "=", "EstimateSensitivityMap", "(", "**", "args", ")", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "", "", "else", ":", "\n", "        ", "transform", "=", "EstimateSensitivityMap", "(", "**", "args", ")", "\n", "if", "shape", "[", "0", "]", "==", "1", "or", "sense_map_in_sample", ":", "\n", "            ", "with", "pytest", ".", "warns", "(", "None", ")", ":", "\n", "                ", "sample", "=", "transform", "(", "sample", ")", "\n", "", "", "else", ":", "\n", "            ", "sample", "=", "transform", "(", "sample", ")", "\n", "", "assert", "\"sensitivity_map\"", "in", "sample", "\n", "assert", "sample", "[", "\"sensitivity_map\"", "]", ".", "shape", "==", "shape", "+", "(", "2", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_DeleteKeys": [[300, 319], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.DeleteKeys", "direct.data.mri_transforms.DeleteKeys.", "torch.rand", "torch.rand().round", "torch.rand().round", "torch.rand", "torch.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "5", ",", "3", ",", "4", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"delete_keys\"", ",", "\n", "[", "[", "\"kspace\"", "]", ",", "[", "\"sensitivity_map\"", ",", "\"acs_mask\"", ",", "\"sampling_mask\"", "]", "]", ",", "\n", ")", "\n", "def", "test_DeleteKeys", "(", "shape", ",", "delete_keys", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "\n", "shape", "=", "shape", "+", "(", "2", ",", ")", ",", "\n", "sensitivity_map", "=", "torch", ".", "rand", "(", "shape", "+", "(", "2", ",", ")", ")", ",", "\n", "acs_mask", "=", "torch", ".", "rand", "(", "(", "1", ",", ")", "+", "shape", "[", "1", ":", "]", "+", "(", "1", ",", ")", ")", ".", "round", "(", ")", ",", "\n", "sampling_mask", "=", "torch", ".", "rand", "(", "(", "1", ",", ")", "+", "shape", "[", "1", ":", "]", "+", "(", "1", ",", ")", ")", ".", "round", "(", ")", ",", "\n", ")", "\n", "transform", "=", "DeleteKeys", "(", "delete_keys", ")", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "for", "key", "in", "delete_keys", ":", "\n", "        ", "assert", "key", "not", "in", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_PadCoilDimension": [[321, 347], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.PadCoilDimension", "direct.data.mri_transforms.PadCoilDimension.", "torch.all", "direct.data.mri_transforms.PadCoilDimension.", "pytest.raises", "direct.data.mri_transforms.PadCoilDimension.", "torch.all"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, pad_coils\"", ",", "\n", "[", "[", "(", "3", ",", "10", ",", "16", ")", ",", "5", "]", ",", "[", "(", "5", ",", "7", ",", "6", ")", ",", "5", "]", ",", "[", "(", "4", ",", "5", ",", "5", ")", ",", "2", "]", ",", "[", "(", "4", ",", "5", ",", "5", ")", ",", "None", "]", ",", "[", "(", "3", ",", "4", ",", "6", ",", "4", ")", ",", "4", "]", ",", "[", "(", "5", ",", "3", ",", "3", ",", "4", ")", ",", "3", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"key\"", ",", "\n", "[", "\"kspace\"", ",", "\"masked_kspace\"", "]", ",", "\n", ")", "\n", "def", "test_PadCoilDimension", "(", "shape", ",", "pad_coils", ",", "key", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "shape", "=", "shape", "+", "(", "2", ",", ")", ")", "\n", "transform", "=", "PadCoilDimension", "(", "pad_coils", "=", "pad_coils", ",", "key", "=", "key", ")", "\n", "if", "key", "not", "in", "sample", ":", "\n", "        ", "kspace", "=", "sample", "[", "\"kspace\"", "]", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "assert", "torch", ".", "all", "(", "sample", "[", "\"kspace\"", "]", "==", "kspace", ")", "\n", "", "else", ":", "\n", "        ", "if", "pad_coils", "and", "shape", "[", "0", "]", ">", "pad_coils", ":", "\n", "            ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "                ", "sample", "=", "transform", "(", "sample", ")", "\n", "", "", "else", ":", "\n", "            ", "kspace", "=", "sample", "[", "\"kspace\"", "]", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "if", "pad_coils", "is", "None", "or", "shape", "[", "0", "]", "==", "pad_coils", ":", "\n", "                ", "assert", "torch", ".", "all", "(", "sample", "[", "\"kspace\"", "]", "==", "kspace", ")", "\n", "", "else", ":", "\n", "                ", "assert", "sample", "[", "\"kspace\"", "]", ".", "shape", "==", "(", "pad_coils", ",", ")", "+", "shape", "[", "1", ":", "]", "+", "(", "2", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_Normalize": [[349, 374], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.Normalize", "direct.data.mri_transforms.Normalize.", "torch.rand", "torch.rand", "torch.rand().round().unsqueeze().unsqueeze", "torch.rand", "torch.rand().round().unsqueeze", "torch.rand().round", "torch.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "", "", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "3", ",", "4", ")", ",", "(", "5", ",", "3", ",", "4", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalize_key\"", ",", "\n", "[", "None", ",", "\"masked_kspace\"", ",", "\"kspace\"", ",", "\"scaling_factor\"", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"percentile\"", ",", "\n", "[", "None", ",", "0.9", "]", ",", "\n", ")", "\n", "def", "test_Normalize", "(", "shape", ",", "normalize_key", ",", "percentile", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "\n", "shape", "=", "shape", "+", "(", "2", ",", ")", ",", "\n", "masked_kspace", "=", "torch", ".", "rand", "(", "shape", "+", "(", "2", ",", ")", ")", ",", "\n", "sensitivity_map", "=", "torch", ".", "rand", "(", "shape", "+", "(", "2", ",", ")", ")", ",", "\n", "sampling_mask", "=", "torch", ".", "rand", "(", "shape", "[", "1", ":", "]", ")", ".", "round", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "rand", "(", "1", ")", ",", "\n", ")", "\n", "transform", "=", "Normalize", "(", "normalize_key", ",", "percentile", ")", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "\n", "assert", "\"scaling_diff\"", "in", "sample", "\n", "assert", "\"scaling_factor\"", "in", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_WhitenData": [[376, 388], ["pytest.mark.parametrize", "test_mri_transforms.create_sample", "direct.data.mri_transforms.WhitenData", "direct.data.mri_transforms.WhitenData.", "torch.rand"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "3", ",", "4", ")", ",", "(", "5", ",", "3", ",", "4", ")", "]", ",", "\n", ")", "\n", "def", "test_WhitenData", "(", "shape", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "\n", "shape", "=", "shape", "+", "(", "2", ",", ")", ",", "\n", "input_image", "=", "torch", ".", "rand", "(", "shape", "[", "1", ":", "]", "+", "(", "2", ",", ")", ")", ",", "\n", ")", "\n", "transform", "=", "WhitenData", "(", "key", "=", "\"input_image\"", ")", "\n", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_ToTensor": [[390, 428], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_mri_transforms.create_sample", "numpy.random.randn", "direct.data.mri_transforms.ToTensor", "direct.data.mri_transforms.ToTensor.", "isinstance", "len", "pytest.raises", "direct.data.mri_transforms.ToTensor.", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "5", ",", "3", ")", ",", "(", "5", ",", "3", ",", "4", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"key, is_multicoil, is_complex, is_scalar\"", ",", "\n", "[", "\n", "[", "\"sensitivity_map\"", ",", "True", ",", "True", ",", "False", "]", ",", "\n", "[", "\"acs_mask\"", ",", "False", ",", "False", ",", "False", "]", ",", "\n", "[", "\"sampling_mask\"", ",", "False", ",", "False", ",", "False", "]", ",", "\n", "[", "\"initial_kspace\"", ",", "True", ",", "True", ",", "False", "]", ",", "\n", "[", "\"initial_image\"", ",", "True", ",", "False", ",", "False", "]", ",", "\n", "[", "\"target\"", ",", "False", ",", "False", ",", "False", "]", ",", "\n", "[", "\"scaling_factor\"", ",", "False", ",", "False", ",", "True", "]", ",", "\n", "[", "\"loglikelihood_scaling\"", ",", "False", ",", "False", ",", "True", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_ToTensor", "(", "shape", ",", "key", ",", "is_multicoil", ",", "is_complex", ",", "is_scalar", ")", ":", "\n", "    ", "sample", "=", "create_sample", "(", "shape", ",", "kspace", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", "+", "1.0j", "*", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", "\n", "\n", "if", "is_scalar", ":", "\n", "        ", "key_shape", "=", "(", "1", ",", ")", "\n", "", "else", ":", "\n", "        ", "key_shape", "=", "shape", "[", "1", ":", "]", "if", "not", "is_multicoil", "else", "shape", "\n", "", "sample", "[", "key", "]", "=", "np", ".", "random", ".", "randn", "(", "*", "key_shape", ")", "\n", "if", "is_complex", ":", "\n", "        ", "sample", "[", "key", "]", "=", "sample", "[", "key", "]", "+", "1.0j", "*", "np", ".", "random", ".", "randn", "(", "*", "key_shape", ")", "\n", "key_shape", "+=", "(", "2", ",", ")", "\n", "\n", "", "transform", "=", "ToTensor", "(", ")", "\n", "if", "len", "(", "shape", ")", "-", "1", "not", "in", "[", "2", ",", "3", "]", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "sample", "=", "transform", "(", "sample", ")", "\n", "", "", "else", ":", "\n", "        ", "sample", "=", "transform", "(", "sample", ")", "\n", "assert", "isinstance", "(", "sample", "[", "\"kspace\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "sample", "[", "\"kspace\"", "]", ".", "shape", "==", "shape", "+", "(", "2", ",", ")", "\n", "assert", "sample", "[", "key", "]", ".", "shape", "==", "key_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_mri_transforms.test_build_mri_transforms": [[430, 465], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.data.mri_transforms.build_mri_transforms", "test_mri_transforms.create_sample", "direct.data.mri_transforms.build_mri_transforms.", "all", "functools.partial", "functools.partial", "numpy.random.randn", "transform.keys", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.mri_transforms.build_mri_transforms", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, spatial_dims\"", ",", "\n", "[", "[", "(", "5", ",", "3", ",", "4", ")", ",", "(", "1", ",", "2", ")", "]", ",", "[", "(", "5", ",", "4", ",", "5", ",", "6", ")", ",", "(", "2", ",", "3", ")", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"estimate_body_coil_image\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"image_center_crop\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_build_mri_transforms", "(", "shape", ",", "spatial_dims", ",", "estimate_body_coil_image", ",", "image_center_crop", ")", ":", "\n", "    ", "transform", "=", "build_mri_transforms", "(", "\n", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "dim", "=", "spatial_dims", ")", ",", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "dim", "=", "spatial_dims", ")", ",", "\n", "mask_func", "=", "_mask_func", ",", "\n", "crop", "=", "None", ",", "\n", "crop_type", "=", "\"uniform\"", ",", "\n", "scaling_key", "=", "\"masked_kspace\"", ",", "\n", "estimate_body_coil_image", "=", "estimate_body_coil_image", ",", "\n", "image_center_crop", "=", "image_center_crop", ",", "\n", ")", "\n", "sample", "=", "create_sample", "(", "shape", ",", "kspace", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", "+", "1.0j", "*", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", "\n", "\n", "sample", "=", "transform", "(", "sample", ")", "\n", "\n", "assert", "all", "(", "\n", "key", "in", "sample", ".", "keys", "(", ")", "\n", "for", "key", "in", "[", "\"sampling_mask\"", ",", "\"sensitivity_map\"", ",", "\"target\"", ",", "\"masked_kspace\"", ",", "\"scaling_diff\"", ",", "\"scaling_factor\"", "]", "\n", ")", "\n", "assert", "sample", "[", "\"masked_kspace\"", "]", ".", "shape", "==", "shape", "+", "(", "2", ",", ")", "\n", "assert", "sample", "[", "\"sensitivity_map\"", "]", ".", "shape", "==", "shape", "+", "(", "2", ",", ")", "\n", "assert", "sample", "[", "\"sampling_mask\"", "]", ".", "shape", "==", "(", "1", ",", ")", "+", "shape", "[", "1", ":", "]", "+", "(", "1", ",", ")", "\n", "assert", "sample", "[", "\"target\"", "]", ".", "shape", "==", "shape", "[", "1", ":", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_sens.test_simulate_sens_maps": [[9, 30], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.data.sens.simulate_sensitivity_maps", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.sens.simulate_sensitivity_maps"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_coils\"", ",", "\n", "[", "1", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "32", ",", "32", ")", ",", "(", "10", ",", "32", ",", "32", ")", ",", "(", "11", ",", "12", ",", "13", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"var\"", ",", "\n", "[", "0.5", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"seed\"", ",", "\n", "[", "None", ",", "0", "]", ",", "\n", ")", "\n", "def", "test_simulate_sens_maps", "(", "num_coils", ",", "shape", ",", "var", ",", "seed", ")", ":", "\n", "\n", "    ", "sensitivity_map", "=", "simulate_sensitivity_maps", "(", "shape", ",", "num_coils", ",", "var", ",", "seed", ")", "\n", "\n", "assert", "tuple", "(", "sensitivity_map", ".", "shape", ")", "==", "(", "num_coils", ",", ")", "+", "tuple", "(", "shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_lr_scheduler.create_model": [[13, 15], ["torch.nn.Linear"], "function", ["None"], ["def", "create_model", "(", ")", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "Linear", "(", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_lr_scheduler.create_optimizer": [[17, 19], ["torch.optim.Adam", "model.parameters"], "function", ["None"], ["", "def", "create_optimizer", "(", "model", ")", ":", "\n", "    ", "return", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_lr_scheduler.test_WarmupMultiStepLR": [[21, 53], ["pytest.mark.parametrize", "pytest.mark.parametrize", "test_lr_scheduler.create_model", "test_lr_scheduler.create_optimizer", "direct.data.lr_scheduler.WarmupMultiStepLR", "direct.data.lr_scheduler.WarmupMultiStepLR.get_lr", "range", "create_optimizer.step", "direct.data.lr_scheduler.WarmupMultiStepLR.step", "direct.data.lr_scheduler.WarmupMultiStepLR.get_lr", "pytest.raises", "direct.data.lr_scheduler.WarmupMultiStepLR", "numpy.allclose"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_lr_scheduler.create_model", "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_lr_scheduler.create_optimizer", "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupCosineLR.get_lr", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.directgroup_direct.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.directgroup_direct.data.lr_scheduler.WarmupCosineLR.get_lr"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"gamma, milestones, warm_up_iters\"", ",", "\n", "[", "[", "0.25", ",", "[", "10", ",", "20", ",", "25", ",", "30", "]", ",", "15", "]", ",", "[", "0.1", ",", "[", "10", ",", "20", ",", "25", ",", "30", "]", ",", "45", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"method\"", ",", "\n", "[", "\"constant\"", ",", "\"linear\"", ",", "None", "]", ",", "\n", ")", "\n", "def", "test_WarmupMultiStepLR", "(", "milestones", ",", "warm_up_iters", ",", "gamma", ",", "method", ")", ":", "\n", "    ", "model", "=", "create_model", "(", ")", "\n", "optimizer", "=", "create_optimizer", "(", "model", ")", "\n", "if", "method", ":", "\n", "        ", "scheduler", "=", "WarmupMultiStepLR", "(", "\n", "optimizer", ",", "milestones", ",", "warmup_iterations", "=", "warm_up_iters", ",", "gamma", "=", "gamma", ",", "warmup_method", "=", "method", "\n", ")", "\n", "tmp", "=", "scheduler", ".", "get_lr", "(", ")", "\n", "for", "iter", "in", "range", "(", "1", ",", "milestones", "[", "-", "1", "]", "*", "2", ")", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "lr", "=", "scheduler", ".", "get_lr", "(", ")", "\n", "if", "iter", ">=", "warm_up_iters", ":", "\n", "                ", "if", "iter", "in", "milestones", ":", "\n", "                    ", "assert", "np", ".", "allclose", "(", "lr", "[", "0", "]", "/", "tmp", "[", "0", "]", ",", "gamma", ")", "\n", "", "elif", "(", "iter", "-", "1", ")", "in", "milestones", "and", "iter", "not", "in", "milestones", "and", "(", "iter", "+", "1", ")", "not", "in", "milestones", ":", "\n", "                    ", "assert", "tmp", "==", "lr", "\n", "", "", "else", ":", "\n", "                ", "if", "iter", "in", "milestones", ":", "\n", "                    ", "assert", "lr", "[", "0", "]", "<", "tmp", "[", "0", "]", "\n", "", "", "tmp", "=", "lr", "\n", "", "", "else", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "scheduler", "=", "WarmupMultiStepLR", "(", "optimizer", ",", "milestones", ",", "warmup_method", "=", "method", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_fake.test_fake": [[12, 51], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.data.fake.FakeMRIData", "direct.data.fake.FakeMRIData.", "all", "all", "all", "all", "all", "all", "all", "len", "len", "len", "numpy.allclose", "samples[].keys", "test_fake.rss", "tuple", "tuple", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_fake.rss"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"size\"", ",", "\n", "[", "\n", "1", ",", "\n", "3", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_coils\"", ",", "\n", "[", "\n", "1", ",", "\n", "8", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"spatial_shape\"", ",", "\n", "[", "(", "32", ",", "32", ")", ",", "(", "10", ",", "32", ",", "32", ")", ",", "[", "10", ",", "32", ",", "32", "]", "]", ",", "\n", ")", "\n", "def", "test_fake", "(", "size", ",", "num_coils", ",", "spatial_shape", ")", ":", "\n", "\n", "    ", "fake_data", "=", "FakeMRIData", "(", "ndim", "=", "len", "(", "spatial_shape", ")", ")", "\n", "\n", "samples", "=", "fake_data", "(", "size", ",", "num_coils", ",", "spatial_shape", ")", "\n", "keys", "=", "[", "\"kspace\"", ",", "\"reconstruction_rss\"", ",", "\"attrs\"", "]", "\n", "\n", "assert", "all", "(", "_", "in", "samples", "[", "0", "]", ".", "keys", "(", ")", "for", "_", "in", "keys", ")", "\n", "\n", "assert", "len", "(", "samples", ")", "==", "size", "\n", "\n", "assert", "all", "(", "sample", "[", "keys", "[", "0", "]", "]", ".", "shape", "[", "1", "]", "==", "num_coils", "for", "sample", "in", "samples", ")", "\n", "\n", "assert", "all", "(", "tuple", "(", "sample", "[", "keys", "[", "0", "]", "]", ".", "shape", ")", "[", "-", "2", ":", "]", "==", "tuple", "(", "spatial_shape", ")", "[", "-", "2", ":", "]", "for", "sample", "in", "samples", ")", "\n", "assert", "all", "(", "tuple", "(", "sample", "[", "keys", "[", "1", "]", "]", ".", "shape", ")", "[", "-", "2", ":", "]", "==", "tuple", "(", "spatial_shape", ")", "[", "-", "2", ":", "]", "for", "sample", "in", "samples", ")", "\n", "\n", "slice_num", "=", "1", "if", "len", "(", "spatial_shape", ")", "==", "2", "else", "spatial_shape", "[", "0", "]", "\n", "assert", "all", "(", "sample", "[", "keys", "[", "0", "]", "]", ".", "shape", "[", "0", "]", "==", "slice_num", "for", "sample", "in", "samples", ")", "\n", "assert", "all", "(", "sample", "[", "keys", "[", "1", "]", "]", ".", "shape", "[", "0", "]", "==", "slice_num", "for", "sample", "in", "samples", ")", "\n", "\n", "assert", "all", "(", "np", ".", "allclose", "(", "rss", "(", "sample", "[", "keys", "[", "0", "]", "]", ")", ",", "sample", "[", "keys", "[", "1", "]", "]", ")", "for", "sample", "in", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_fake.ifft": [[53, 58], ["numpy.fft.ifftshift", "numpy.fft.ifft2", "numpy.fft.fftshift"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifftshift", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.ifft2", "home.repos.pwc.inspect_result.directgroup_direct.data.transforms.fftshift"], ["", "def", "ifft", "(", "data", ",", "dims", "=", "(", "-", "2", ",", "-", "1", ")", ")", ":", "\n", "    ", "data", "=", "np", ".", "fft", ".", "ifftshift", "(", "data", ",", "dims", ")", "\n", "out", "=", "np", ".", "fft", ".", "ifft2", "(", "data", ",", "norm", "=", "\"ortho\"", ")", "\n", "out", "=", "np", ".", "fft", ".", "fftshift", "(", "out", ",", "dims", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_fake.rss": [[60, 62], ["numpy.sqrt", "numpy.abs", "test_fake.ifft"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_fake.ifft"], ["", "def", "rss", "(", "data", ",", "coil_dim", "=", "1", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "(", "np", ".", "abs", "(", "ifft", "(", "data", ")", ")", "**", "2", ")", ".", "sum", "(", "coil_dim", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_multidomainnet.create_input": [[12, 17], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_multidomainnet.test_multidomainunet2d": [[19, 52], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.multidomainnet.multidomain.MultiDomainUnet2d().cpu", "create_input().cpu", "MultiDomainUnet2d().cpu.", "list", "direct.nn.multidomainnet.multidomain.MultiDomainUnet2d", "test_multidomainnet.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "2", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "[", "4", ",", "2", ",", "16", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "40", ",", "20", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_filters\"", ",", "\n", "[", "4", ",", "8", ",", "16", "]", ",", "# powers of 2", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_pool_layers\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "def", "test_multidomainunet2d", "(", "shape", ",", "num_filters", ",", "num_pool_layers", ")", ":", "\n", "    ", "model", "=", "MultiDomainUnet2d", "(", "\n", "fft2", ",", "\n", "ifft2", ",", "\n", "shape", "[", "1", "]", ",", "\n", "shape", "[", "1", "]", ",", "\n", "num_filters", "=", "num_filters", ",", "\n", "num_pool_layers", "=", "num_pool_layers", ",", "\n", "dropout_probability", "=", "0.05", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_multidomainnet.test_multidomainnet": [[54, 84], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.multidomainnet.multidomainnet.MultiDomainNet", "create_input().cpu", "create_input().cpu", "direct.nn.multidomainnet.multidomainnet.MultiDomainNet.", "list", "test_multidomainnet.create_input", "test_multidomainnet.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "2", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "[", "4", ",", "2", ",", "16", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "40", ",", "20", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"standardization\"", ",", "[", "True", ",", "False", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_filters\"", ",", "\n", "[", "4", ",", "8", "]", ",", "# powers of 2", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_pool_layers\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "def", "test_multidomainnet", "(", "shape", ",", "standardization", ",", "num_filters", ",", "num_pool_layers", ")", ":", "\n", "\n", "    ", "model", "=", "MultiDomainNet", "(", "fft2", ",", "ifft2", ",", "standardization", ",", "num_filters", ",", "num_pool_layers", ")", "\n", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "\n", "kspace", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "kspace", ",", "sens", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "shape", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_kikinet.create_input": [[11, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_kikinet.test_kikinet": [[18, 57], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.kikinet.kikinet.KIKINet().cpu", "create_input().cpu", "create_input().round().int().cpu", "create_input().cpu", "KIKINet().cpu.", "list", "direct.nn.kikinet.kikinet.KIKINet", "test_kikinet.create_input", "create_input().round().int", "test_kikinet.create_input", "create_input().round", "test_kikinet.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "3", ",", "32", ",", "32", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_iter\"", ",", "\n", "[", "1", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"image_model_architecture\"", ",", "\n", "[", "\"MWCNN\"", ",", "\"UNET\"", ",", "\"NORMUNET\"", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"kspace_model_architecture\"", ",", "\n", "[", "\"CONV\"", ",", "\"DIDN\"", ",", "\"UNET\"", ",", "\"NORMUNET\"", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalize\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_kikinet", "(", "shape", ",", "num_iter", ",", "image_model_architecture", ",", "kspace_model_architecture", ",", "normalize", ")", ":", "\n", "    ", "model", "=", "KIKINet", "(", "\n", "fft2", ",", "\n", "ifft2", ",", "\n", "num_iter", "=", "num_iter", ",", "\n", "image_model_architecture", "=", "image_model_architecture", ",", "\n", "kspace_model_architecture", "=", "kspace_model_architecture", ",", "\n", "normalize", "=", "normalize", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "kspace", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "mask", "=", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "1", "]", ")", ".", "round", "(", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "kspace", ",", "mask", ",", "sens", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "2", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_jointicnet_engine.create_sample": [[23, 33], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_jointicnet_engine.test_jointicnet_engine": [[35, 79], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.jointicnet.jointicnet.JointICNet", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.InferenceConfig", "direct.config.defaults.DefaultConfig", "direct.nn.jointicnet.jointicnet_engine.JointICNetEngine", "test_jointicnet_engine.create_sample", "direct.nn.jointicnet.jointicnet_engine.JointICNetEngine.build_loss", "direct.nn.jointicnet.jointicnet_engine.JointICNetEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"loss_fns\"", ",", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_iter\"", ",", "[", "2", ",", "3", "]", ")", "\n", "def", "test_jointicnet_engine", "(", "\n", "shape", ",", "\n", "loss_fns", ",", "\n", "num_iter", ",", "\n", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "\n", "# Models", "\n", "kwargs", "=", "{", "\n", "\"forward_operator\"", ":", "fft2", ",", "\n", "\"backward_operator\"", ":", "ifft2", ",", "\n", "\"num_iter\"", ":", "num_iter", ",", "\n", "\"image_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"kspace_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"sens_unet_num_pool_layers\"", ":", "2", ",", "\n", "}", "\n", "\n", "model", "=", "JointICNet", "(", "**", "kwargs", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "inference_config", "=", "InferenceConfig", "(", "batch_size", "=", "shape", "[", "0", "]", "//", "2", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ",", "inference", "=", "inference_config", ")", "\n", "# Define engine", "\n", "engine", "=", "JointICNetEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_jointicnet.create_input": [[11, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_jointicnet.test_jointicnet": [[18, 51], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.jointicnet.jointicnet.JointICNet().cpu", "create_input().cpu", "create_input().round().int().cpu", "create_input().cpu", "JointICNet().cpu.", "list", "direct.nn.jointicnet.jointicnet.JointICNet", "test_jointicnet.create_input", "create_input().round().int", "test_jointicnet.create_input", "create_input().round", "test_jointicnet.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "3", ",", "16", ",", "16", "]", ",", "\n", "[", "2", ",", "5", ",", "16", ",", "32", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_iter\"", ",", "\n", "[", "2", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"use_norm_unet\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_jointicnet", "(", "shape", ",", "num_iter", ",", "use_norm_unet", ")", ":", "\n", "    ", "model", "=", "JointICNet", "(", "\n", "fft2", ",", "\n", "ifft2", ",", "\n", "num_iter", ",", "\n", "use_norm_unet", ",", "\n", "image_unet_num_pool_layers", "=", "2", ",", "\n", "kspace_unet_num_pool_layers", "=", "2", ",", "\n", "sens_unet_num_pool_layers", "=", "2", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "kspace", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "mask", "=", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "1", "]", ")", ".", "round", "(", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "kspace", ",", "mask", ",", "sens", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "2", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_lpd_engine.create_sample": [[16, 27], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_lpd_engine.test_lpd_engine": [[29, 63], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.lpd.lpd.LPDNet", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.DefaultConfig", "direct.nn.lpd.lpd_engine.LPDNetEngine", "test_lpd_engine.create_sample", "direct.nn.lpd.lpd_engine.LPDNetEngine.build_loss", "direct.nn.lpd.lpd_engine.LPDNetEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_iter, num_primal, num_dual\"", ",", "\n", "[", "[", "3", ",", "3", ",", "2", "]", "]", ",", "\n", ")", "\n", "def", "test_lpd_engine", "(", "shape", ",", "loss_fns", ",", "num_iter", ",", "num_primal", ",", "num_dual", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Models", "\n", "model", "=", "LPDNet", "(", "forward_operator", ",", "backward_operator", ",", "num_iter", "=", "num_iter", ",", "num_primal", "=", "num_primal", ",", "num_dual", "=", "num_dual", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ")", "\n", "# Define engine", "\n", "engine", "=", "LPDNetEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_kikinet_engine.create_sample": [[25, 36], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_kikinet_engine.test_kikinet_engine": [[38, 82], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.kikinet.kikinet.KIKINet", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.InferenceConfig", "direct.config.defaults.DefaultConfig", "direct.nn.kikinet.kikinet_engine.KIKINetEngine", "test_kikinet_engine.create_sample", "direct.nn.kikinet.kikinet_engine.KIKINetEngine.build_loss", "direct.nn.kikinet.kikinet_engine.KIKINetEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "5", ",", "3", ",", "10", ",", "16", ",", "2", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_iter\"", ",", "\n", "[", "2", "]", ",", "\n", ")", "\n", "def", "test_kikinet_engine", "(", "shape", ",", "loss_fns", ",", "num_iter", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "\n", "# Models", "\n", "model", "=", "KIKINet", "(", "\n", "forward_operator", ",", "\n", "backward_operator", ",", "\n", "num_iter", "=", "num_iter", ",", "\n", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "inference_config", "=", "InferenceConfig", "(", "batch_size", "=", "shape", "[", "0", "]", "//", "2", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ",", "inference", "=", "inference_config", ")", "\n", "# Define engine", "\n", "engine", "=", "KIKINetEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_conv.create_input": [[11, 16], ["torch.rand().float", "torch.rand().float", "torch.rand", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_conv.test_conv": [[18, 53], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.conv.conv.Conv2d", "create_input().cpu", "direct.nn.conv.conv.Conv2d.", "list", "torch.ReLU", "torch.PReLU", "test_conv.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"out_channels\"", ",", "\n", "[", "3", ",", "5", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"hidden_channels\"", ",", "\n", "[", "16", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"n_convs\"", ",", "\n", "[", "2", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"act\"", ",", "\n", "[", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "PReLU", "(", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"batchnorm\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_conv", "(", "shape", ",", "out_channels", ",", "hidden_channels", ",", "n_convs", ",", "act", ",", "batchnorm", ")", ":", "\n", "    ", "model", "=", "Conv2d", "(", "shape", "[", "1", "]", ",", "out_channels", ",", "hidden_channels", ",", "n_convs", ",", "act", ",", "batchnorm", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "[", "out_channels", "]", "+", "shape", "[", "2", ":", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mwcnn.create_input": [[11, 16], ["torch.rand().float", "torch.rand().float", "torch.rand", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mwcnn.test_mwcnn": [[18, 53], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.mwcnn.mwcnn.MWCNN", "create_input().cpu", "direct.nn.mwcnn.mwcnn.MWCNN.", "list", "torch.ReLU", "torch.PReLU", "test_mwcnn.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "20", ",", "34", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"first_conv_hidden_channels\"", ",", "\n", "[", "4", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"n_scales\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"bias\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"batchnorm\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"act\"", ",", "\n", "[", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "PReLU", "(", ")", "]", ",", "\n", ")", "\n", "def", "test_mwcnn", "(", "shape", ",", "first_conv_hidden_channels", ",", "n_scales", ",", "bias", ",", "batchnorm", ",", "act", ")", ":", "\n", "    ", "model", "=", "MWCNN", "(", "shape", "[", "1", "]", ",", "first_conv_hidden_channels", ",", "n_scales", ",", "bias", ",", "batchnorm", ",", "act", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "shape", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_rim.create_input": [[18, 23], ["torch.rand().float", "torch.rand"], "function", ["None"], ["", "def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_rim.test_rim": [[25, 128], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.rim.rim.RIM().cpu", "create_input().cpu", "create_input().cpu", "create_input().round().int().cpu", "RIM().cpu.", "OpenVINOModel", "OpenVINOModel.", "direct.nn.rim.rim.RIM", "create_input().cpu", "create_input().cpu", "pytest.raises", "list", "torch.max", "torch.max", "test_rim.create_input", "test_rim.create_input", "create_input().round().int", "create_input().cpu", "torch.abs", "torch.abs", "test_rim.create_input", "test_rim.create_input", "RIM().cpu.", "create_input().round", "test_rim.create_input", "test_rim.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "2", ",", "3", ",", "11", ",", "12", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"hidden_channels\"", ",", "\n", "[", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"length\"", ",", "\n", "[", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"depth\"", ",", "\n", "[", "2", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"no_parameter_sharing\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"instance_norm\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"dense_connect\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"skip_connections\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"image_init\"", ",", "\n", "[", "\"zero_filled\"", ",", "\"sense\"", ",", "\"input_kspace\"", ",", "\"input_image\"", ",", "None", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"learned_initializer\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"input_image_is_None\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalized\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_rim", "(", "\n", "shape", ",", "\n", "hidden_channels", ",", "\n", "length", ",", "\n", "depth", ",", "\n", "no_parameter_sharing", ",", "\n", "instance_norm", ",", "\n", "dense_connect", ",", "\n", "skip_connections", ",", "\n", "image_init", ",", "\n", "learned_initializer", ",", "\n", "input_image_is_None", ",", "\n", "normalized", ",", "\n", ")", ":", "\n", "    ", "model", "=", "RIM", "(", "\n", "fft2", ",", "\n", "ifft2", ",", "\n", "hidden_channels", "=", "hidden_channels", ",", "\n", "length", "=", "length", ",", "\n", "depth", "=", "depth", ",", "\n", "no_parameter_sharing", "=", "no_parameter_sharing", ",", "\n", "instance_norm", "=", "instance_norm", ",", "\n", "dense_connect", "=", "dense_connect", ",", "\n", "skip_connections", "=", "skip_connections", ",", "\n", "image_initialization", "=", "image_init", ",", "\n", "learned_initializer", "=", "learned_initializer", ",", "\n", "normalized", "=", "normalized", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "inputs", "=", "{", "\n", "\"input_image\"", ":", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "if", "not", "input_image_is_None", "else", "None", ",", "\n", "\"masked_kspace\"", ":", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", ",", "\n", "\"sensitivity_map\"", ":", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", ",", "\n", "\"sampling_mask\"", ":", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "1", "]", ")", ".", "round", "(", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "}", "\n", "if", "input_image_is_None", ":", "\n", "        ", "if", "image_init", "==", "\"input_image\"", ":", "\n", "            ", "inputs", "[", "\"initial_image\"", "]", "=", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "", "elif", "image_init", "==", "\"input_kspace\"", ":", "\n", "            ", "inputs", "[", "\"initial_kspace\"", "]", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "", "", "if", "image_init", "is", "None", "and", "input_image_is_None", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "out", "=", "model", "(", "**", "inputs", ")", "[", "0", "]", "[", "-", "1", "]", "\n", "", "", "else", ":", "\n", "        ", "out", "=", "model", "(", "**", "inputs", ")", "\n", "assert", "list", "(", "out", "[", "0", "]", "[", "-", "1", "]", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "[", "2", "]", "+", "shape", "[", "2", ":", "]", "\n", "\n", "", "if", "openvino_available", "and", "not", "input_image_is_None", "and", "skip_connections", ":", "\n", "        ", "ov_model", "=", "OpenVINOModel", "(", "model", ")", "\n", "ov_out", "=", "ov_model", "(", "**", "inputs", ")", "\n", "\n", "assert", "torch", ".", "max", "(", "torch", ".", "abs", "(", "out", "[", "0", "]", "[", "-", "1", "]", "-", "ov_out", "[", "0", "]", "[", "-", "1", "]", ")", ")", "<", "1e-5", "\n", "assert", "torch", ".", "max", "(", "torch", ".", "abs", "(", "out", "[", "1", "]", "-", "ov_out", "[", "1", "]", ")", ")", "<", "1e-4", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet_engine.create_sample": [[16, 26], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet_engine.test_lpd_engine": [[28, 70], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.varnet.varnet.EndToEndVarNet", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.DefaultConfig", "direct.nn.varnet.varnet_engine.EndToEndVarNetEngine", "test_varnet_engine.create_sample", "direct.nn.varnet.varnet_engine.EndToEndVarNetEngine.build_loss", "direct.nn.varnet.varnet_engine.EndToEndVarNetEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_layers, num_filters, num_pull_layers\"", ",", "\n", "[", "[", "3", ",", "4", ",", "2", "]", "]", ",", "\n", ")", "\n", "def", "test_lpd_engine", "(", "shape", ",", "loss_fns", ",", "num_layers", ",", "num_filters", ",", "num_pull_layers", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Models", "\n", "model", "=", "EndToEndVarNet", "(", "\n", "forward_operator", ",", "\n", "backward_operator", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "regularizer_num_filters", "=", "num_filters", ",", "\n", "regularizer_num_pull_layers", "=", "num_pull_layers", ",", "\n", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ")", "\n", "# Define engine", "\n", "engine", "=", "EndToEndVarNetEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_sample": [[26, 37], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset": [[39, 67], ["Dataset", "range", "tuple", "numpy.random.seed", "test_mri_models.create_sample", "pathlib.PosixPath", "range", "str", "map", "numpy.random.randint", "str", "str"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample"], ["", "def", "create_dataset", "(", "num_samples", ",", "shape", ",", "text_description", "=", "\"training\"", ")", ":", "\n", "    ", "class", "Dataset", "(", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "num_samples", ",", "shape", ",", "text_description", ")", ":", "\n", "            ", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "ndim", "=", "2", "\n", "self", ".", "volume_indices", "=", "{", "}", "\n", "current_slice_number", "=", "0", "\n", "for", "idx", "in", "range", "(", "num_samples", ")", ":", "\n", "                ", "filename", "=", "pathlib", ".", "PosixPath", "(", "f\"file_{idx}\"", ")", "\n", "self", ".", "volume_indices", "[", "filename", "]", "=", "range", "(", "current_slice_number", ",", "current_slice_number", "+", "shape", "[", "0", "]", ")", "\n", "current_slice_number", "+=", "shape", "[", "0", "]", "\n", "", "self", ".", "text_description", "=", "text_description", "+", "str", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "1000", ")", ")", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "num_samples", "*", "self", ".", "shape", "[", "0", "]", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "            ", "sample", "=", "{", "}", "\n", "filename", "=", "f\"file_{idx // self.shape[0]}\"", "\n", "slice_no", "=", "idx", "%", "shape", "[", "0", "]", "\n", "\n", "seed", "=", "tuple", "(", "map", "(", "ord", ",", "str", "(", "filename", "+", "str", "(", "slice_no", ")", ")", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "return", "create_sample", "(", "self", ".", "shape", "[", "1", ":", "]", ",", "filename", "=", "filename", ",", "slice_no", "=", "slice_no", ")", "\n", "\n", "", "", "return", "Dataset", "(", "num_samples", ",", "shape", ",", "text_description", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_eninge": [[69, 104], ["super().__init__", "test_mri_models..model().permute", "output_image.sum.sum", "direct.engine.DoIterationOutput", "test_mri_models..model", "data[].sum().permute", "data[].sum"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_data.test_samplers._TestDS.__init__"], ["", "def", "create_eninge", "(", ")", ":", "\n", "    ", "class", "TestEngine", "(", "MRIModelEngine", ")", ":", "\n", "        ", "def", "__init__", "(", "\n", "self", ",", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", ",", "\n", "backward_operator", ",", "\n", "mixed_precision", "=", "False", ",", "\n", "**", "models", ",", "\n", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", "\n", "cfg", ",", "\n", "model", ",", "\n", "device", ",", "\n", "forward_operator", "=", "forward_operator", ",", "\n", "backward_operator", "=", "backward_operator", ",", "\n", "mixed_precision", "=", "mixed_precision", ",", "\n", "**", "models", ",", "\n", ")", "\n", "\n", "", "def", "_do_iteration", "(", "self", ",", "data", ",", "loss_fns", "=", "None", ",", "regularizer_fns", "=", "None", ")", ":", "\n", "            ", "output_image", "=", "self", ".", "model", "(", "data", "[", "\"masked_kspace\"", "]", ".", "sum", "(", "self", ".", "_coil_dim", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "\n", "0", ",", "2", ",", "3", ",", "1", "\n", ")", "\n", "output_image", "=", "output_image", ".", "sum", "(", "self", ".", "_complex_dim", ")", "\n", "\n", "return", "DoIterationOutput", "(", "\n", "output_image", "=", "output_image", ",", "\n", "sensitivity_map", "=", "data", "[", "\"sensitivity_map\"", "]", ",", "\n", "data_dict", "=", "{", "}", ",", "\n", ")", "\n", "\n", "", "", "return", "TestEngine", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.test_mri_model_engine": [[106, 188], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "torch.nn.Conv2d", "torch.nn.Conv2d", "direct.config.defaults.CheckpointerConfig", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.InferenceConfig", "direct.config.defaults.DefaultConfig", "test_mri_models.create_sample", "engine.build_loss", "engine._do_iteration", "test_mri_models.create_dataset", "engine.build_batch_sampler", "engine.build_loader", "engine.evaluate", "torch.optim.Adam", "torch.optim.lr_scheduler.StepLR", "test_mri_models.create_eninge", "tempfile.TemporaryDirectory", "engine.predict", "len", "min", "torch.nn.Conv2d.parameters", "tempfile.TemporaryDirectory", "engine.train", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "pathlib.Path", "len", "pathlib.Path", "direct.config.defaults.FunctionConfig", "test_mri_models.create_dataset", "test_mri_models.create_dataset", "torch.from_numpy", "torch.from_numpy", "test_mri_models.create_dataset", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_batch_sampler", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.build_loader", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.evaluate", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_eninge", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.predict", "home.repos.pwc.inspect_result.directgroup_direct.direct.engine.Engine.train", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_mri_models.create_dataset"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "5", ",", "3", ",", "10", ",", "16", ",", "2", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"dataset_num_samples\"", ",", "\n", "[", "3", ",", "9", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"train_iters, val_iters, checkpointer_iters\"", ",", "\n", "[", "[", "20", ",", "10", ",", "10", "]", "]", ",", "\n", ")", "\n", "def", "test_mri_model_engine", "(", "shape", ",", "loss_fns", ",", "dataset_num_samples", ",", "train_iters", ",", "val_iters", ",", "checkpointer_iters", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Models", "\n", "model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "\n", "# Configs", "\n", "checkpointer_config", "=", "CheckpointerConfig", "(", "checkpoint_steps", "=", "checkpointer_iters", ")", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "\n", "loss", "=", "loss_config", ",", "checkpointer", "=", "checkpointer_config", ",", "num_iterations", "=", "train_iters", ",", "validation_steps", "=", "val_iters", "\n", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "inference_config", "=", "InferenceConfig", "(", "batch_size", "=", "shape", "[", "0", "]", "//", "2", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ",", "inference", "=", "inference_config", ")", "\n", "\n", "# Define engine", "\n", "engine", "=", "create_eninge", "(", ")", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "\n", "# Test predict function.", "\n", "# We have to mock a dataset here.", "\n", "dataset", "=", "create_dataset", "(", "dataset_num_samples", ",", "shape", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "\n", "        ", "out", "=", "engine", ".", "predict", "(", "dataset", ",", "pathlib", ".", "Path", "(", "tempdir", ")", ")", "\n", "assert", "len", "(", "out", ")", "==", "dataset_num_samples", "\n", "for", "data", "in", "out", ":", "\n", "            ", "assert", "data", "[", "0", "]", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", "1", ")", "+", "shape", "[", "2", ":", "-", "1", "]", "\n", "\n", "", "", "batch_sampler", "=", "engine", ".", "build_batch_sampler", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "config", ".", "inference", ".", "batch_size", ",", "\n", "sampler_type", "=", "\"sequential\"", ",", "\n", "limit_number_of_volumes", "=", "None", ",", "\n", ")", "\n", "data_loader", "=", "engine", ".", "build_loader", "(", "\n", "dataset", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", ")", "\n", "_", ",", "_", ",", "visualize_imgs", ",", "_", "=", "engine", ".", "evaluate", "(", "data_loader", ",", "loss_fns", ")", "\n", "assert", "(", "len", "(", "visualize_imgs", ")", ")", "==", "min", "(", "dataset_num_samples", ",", "config", ".", "logging", ".", "tensorboard", ".", "num_images", ")", "\n", "\n", "# Test train method.", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "2", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tempdir", ":", "\n", "        ", "engine", ".", "train", "(", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "[", "create_dataset", "(", "dataset_num_samples", ",", "shape", ")", ",", "create_dataset", "(", "dataset_num_samples", ",", "shape", ")", "]", ",", "\n", "pathlib", ".", "Path", "(", "tempdir", ")", ",", "\n", "validation_datasets", "=", "[", "create_dataset", "(", "dataset_num_samples", ",", "shape", ")", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_recurrentvarnet_engine.create_sample": [[16, 26], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_recurrentvarnet_engine.test_recurrentvarnet_engine": [[28, 71], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.recurrentvarnet.recurrentvarnet.RecurrentVarNet", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.DefaultConfig", "direct.nn.recurrentvarnet.recurrentvarnet_engine.RecurrentVarNetEngine", "test_recurrentvarnet_engine.create_sample", "direct.nn.recurrentvarnet.recurrentvarnet_engine.RecurrentVarNetEngine.build_loss", "direct.nn.recurrentvarnet.recurrentvarnet_engine.RecurrentVarNetEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_steps\"", ",", "\n", "[", "3", "]", ",", "\n", ")", "\n", "def", "test_recurrentvarnet_engine", "(", "shape", ",", "loss_fns", ",", "num_steps", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Models", "\n", "model", "=", "RecurrentVarNet", "(", "\n", "forward_operator", ",", "\n", "backward_operator", ",", "\n", "num_steps", "=", "num_steps", ",", "\n", "recurrent_hidden_channels", "=", "8", ",", "\n", "recurrent_num_layers", "=", "2", ",", "\n", "no_parameter_sharing", "=", "False", ",", "\n", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ")", "\n", "# Define engine", "\n", "engine", "=", "RecurrentVarNetEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_multidomainnet_engine.create_sample": [[23, 33], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_multidomainnet_engine.test_multidomainnet_engine": [[35, 84], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.multidomainnet.multidomainnet.MultiDomainNet", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.InferenceConfig", "direct.config.defaults.DefaultConfig", "direct.nn.multidomainnet.multidomainnet_engine.MultiDomainNetEngine", "test_multidomainnet_engine.create_sample", "direct.nn.multidomainnet.multidomainnet_engine.MultiDomainNetEngine.build_loss", "direct.nn.multidomainnet.multidomainnet_engine.MultiDomainNetEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"loss_fns\"", ",", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"standardization\"", ",", "[", "True", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_filters\"", ",", "\n", "[", "4", ",", "8", "]", ",", "# powers of 2", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_pool_layers\"", ",", "\n", "[", "2", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"dataset_num_samples\"", ",", "\n", "[", "3", ",", "9", "]", ",", "\n", ")", "\n", "def", "test_multidomainnet_engine", "(", "shape", ",", "loss_fns", ",", "standardization", ",", "num_filters", ",", "num_pool_layers", ",", "dataset_num_samples", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Models", "\n", "kwargs", "=", "{", "\n", "\"forward_operator\"", ":", "fft2", ",", "\n", "\"backward_operator\"", ":", "ifft2", ",", "\n", "\"standardization\"", ":", "standardization", ",", "\n", "\"num_filters\"", ":", "num_filters", ",", "\n", "\"num_pool_layers\"", ":", "num_pool_layers", ",", "\n", "}", "\n", "model", "=", "MultiDomainNet", "(", "**", "kwargs", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "inference_config", "=", "InferenceConfig", "(", "batch_size", "=", "shape", "[", "0", "]", "//", "2", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ",", "inference", "=", "inference_config", ")", "\n", "# Define engine", "\n", "engine", "=", "MultiDomainNetEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_rim_engine.create_sample": [[17, 29], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "shape", "[", "0", "]", ")", "\n", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_rim_engine.test_lpd_engine": [[31, 75], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.rim.rim.RIM", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.nn.rim.config.RIMConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.DefaultConfig", "direct.nn.rim.rim_engine.RIMEngine", "test_rim_engine.create_sample", "direct.nn.rim.rim_engine.RIMEngine.build_loss", "direct.nn.rim.rim_engine.RIMEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"length, depth\"", ",", "\n", "[", "[", "3", ",", "2", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"scale_log\"", ",", "\n", "[", "None", ",", "0.2", "]", ",", "\n", ")", "\n", "def", "test_lpd_engine", "(", "shape", ",", "loss_fns", ",", "length", ",", "depth", ",", "scale_log", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Models", "\n", "model", "=", "RIM", "(", "\n", "forward_operator", ",", "backward_operator", ",", "hidden_channels", "=", "4", ",", "length", "=", "length", ",", "depth", "=", "depth", ",", "no_parameter_sharing", "=", "False", "\n", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "model_config", "=", "RIMConfig", "(", "scale_loglikelihood", "=", "scale_log", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ",", "model", "=", "model_config", ")", "\n", "# Define engine", "\n", "engine", "=", "RIMEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "engine", ".", "ndim", "=", "2", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "1", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_recurrent.create_input": [[10, 15], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_recurrent.test_conv2dgru": [[17, 44], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "create_input().cpu", "direct.nn.recurrent.recurrent.NormConv2dGRU", "direct.nn.recurrent.recurrent.Conv2dGRU", "model", "list", "test_recurrent.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "[", "3", ",", "2", ",", "15", ",", "17", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"hidden_channels\"", ",", "\n", "[", "4", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalized\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_conv2dgru", "(", "shape", ",", "hidden_channels", ",", "normalized", ")", ":", "\n", "    ", "model", "=", "(", "\n", "NormConv2dGRU", "(", "shape", "[", "1", "]", ",", "hidden_channels", ",", "shape", "[", "1", "]", ")", "\n", "if", "normalized", "\n", "else", "Conv2dGRU", "(", "shape", "[", "1", "]", ",", "hidden_channels", ",", "shape", "[", "1", "]", ")", "\n", ")", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ",", "None", ")", "[", "0", "]", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "shape", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet.create_input": [[11, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet.test_xpdnet": [[18, 83], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "create_input().cpu", "create_input().cpu", "create_input().round().int().cpu", "direct.nn.xpdnet.xpdnet.XPDNet", "direct.nn.xpdnet.xpdnet.XPDNet.", "test_xpdnet.create_input", "test_xpdnet.create_input", "create_input().round().int", "pytest.raises", "direct.nn.xpdnet.xpdnet.XPDNet", "direct.nn.xpdnet.xpdnet.XPDNet.", "list", "create_input().round", "test_xpdnet.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "3", ",", "32", ",", "32", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_iter\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_primal\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"image_model_architecture\"", ",", "\n", "[", "\"MWCNN\"", ",", "None", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"primal_only, kspace_model_architecture, num_dual\"", ",", "\n", "[", "\n", "[", "True", ",", "None", ",", "1", "]", ",", "\n", "[", "False", ",", "\"CONV\"", ",", "3", "]", ",", "\n", "[", "False", ",", "\"DIDN\"", ",", "2", "]", ",", "\n", "[", "False", ",", "None", ",", "2", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalize\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_xpdnet", "(", "\n", "shape", ",", "\n", "num_iter", ",", "\n", "num_primal", ",", "\n", "num_dual", ",", "\n", "image_model_architecture", ",", "\n", "kspace_model_architecture", ",", "\n", "primal_only", ",", "\n", "normalize", ",", "\n", ")", ":", "\n", "    ", "kwargs", "=", "{", "\n", "\"forward_operator\"", ":", "fft2", ",", "\n", "\"backward_operator\"", ":", "ifft2", ",", "\n", "\"num_iter\"", ":", "num_iter", ",", "\n", "\"num_primal\"", ":", "num_primal", ",", "\n", "\"num_dual\"", ":", "num_dual", ",", "\n", "\"image_model_architecture\"", ":", "image_model_architecture", ",", "\n", "\"kspace_model_architecture\"", ":", "kspace_model_architecture", ",", "\n", "\"use_primal_only\"", ":", "primal_only", ",", "\n", "\"normalize\"", ":", "normalize", ",", "\n", "}", "\n", "\n", "kspace", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "mask", "=", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "1", "]", ")", ".", "round", "(", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "if", "(", "not", "image_model_architecture", "==", "\"MWCNN\"", ")", "or", "(", "not", "primal_only", "and", "not", "kspace_model_architecture", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "            ", "model", "=", "XPDNet", "(", "**", "kwargs", ")", "\n", "out", "=", "model", "(", "kspace", ",", "mask", ",", "sens", ")", "\n", "", "", "else", ":", "\n", "        ", "model", "=", "XPDNet", "(", "**", "kwargs", ")", "\n", "out", "=", "model", "(", "kspace", ",", "mask", ",", "sens", ")", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "2", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_unet_2d.create_input": [[20, 25], ["numpy.random.randn().copy", "torch.from_numpy().float", "numpy.random.randn", "torch.from_numpy"], "function", ["None"], ["", "def", "create_input", "(", "shape", ")", ":", "\n", "    ", "data", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ".", "copy", "(", ")", "\n", "data", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_unet_2d.test_unet_2d": [[27, 77], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.unet.unet_2d.Unet2d().cpu", "create_input().cpu", "create_input().cpu", "Unet2d().cpu.eval", "Unet2d().cpu.", "OpenVINOModel", "OpenVINOModel.", "list", "direct.nn.unet.unet_2d.Unet2d", "test_unet_2d.create_input", "test_unet_2d.create_input", "torch.max", "torch.abs"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "2", ",", "3", ",", "16", ",", "16", "]", ",", "\n", "[", "4", ",", "5", ",", "16", ",", "32", "]", ",", "\n", "[", "3", ",", "4", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "4", ",", "40", ",", "20", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_filters\"", ",", "\n", "[", "4", ",", "6", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_pool_layers\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"skip\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalized\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_unet_2d", "(", "shape", ",", "num_filters", ",", "num_pool_layers", ",", "skip", ",", "normalized", ")", ":", "\n", "    ", "model", "=", "Unet2d", "(", "\n", "fft2", ",", "\n", "ifft2", ",", "\n", "num_filters", "=", "num_filters", ",", "\n", "num_pool_layers", "=", "num_pool_layers", ",", "\n", "skip_connection", "=", "skip", ",", "\n", "normalized", "=", "normalized", ",", "\n", "dropout_probability", "=", "0.05", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ",", "sens", ")", "\n", "\n", "if", "openvino_available", ":", "\n", "        ", "ov_model", "=", "OpenVINOModel", "(", "model", ")", "\n", "ov_out", "=", "ov_model", "(", "data", ",", "sens", ")", "\n", "\n", "assert", "torch", ".", "max", "(", "torch", ".", "abs", "(", "out", "[", "0", "]", "[", "-", "1", "]", "-", "ov_out", "[", "0", "]", "[", "-", "1", "]", ")", ")", "<", "1e-5", "\n", "\n", "", "assert", "list", "(", "out", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "2", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_lpd.create_input": [[11, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_lpd.test_lpd": [[18, 74], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.lpd.lpd.LPDNet().cpu", "create_input().cpu", "create_input().cpu", "create_input().round().int().cpu", "LPDNet().cpu.", "pytest.raises", "direct.nn.lpd.lpd.LPDNet().cpu", "list", "direct.nn.lpd.lpd.LPDNet", "test_lpd.create_input", "test_lpd.create_input", "create_input().round().int", "direct.nn.lpd.lpd.LPDNet", "create_input().round", "test_lpd.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "3", ",", "32", ",", "32", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_iter\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_primal\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_dual\"", ",", "\n", "[", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"primal_model_architecture\"", ",", "\n", "[", "\"MWCNN\"", ",", "\"UNET\"", ",", "\"NORMUNET\"", ",", "None", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"dual_model_architecture\"", ",", "\n", "[", "\"CONV\"", ",", "\"DIDN\"", ",", "\"UNET\"", ",", "\"NORMUNET\"", ",", "None", "]", ",", "\n", ")", "\n", "def", "test_lpd", "(", "\n", "shape", ",", "\n", "num_iter", ",", "\n", "num_primal", ",", "\n", "num_dual", ",", "\n", "primal_model_architecture", ",", "\n", "dual_model_architecture", ",", "\n", ")", ":", "\n", "    ", "kwargs", "=", "{", "\n", "\"forward_operator\"", ":", "fft2", ",", "\n", "\"backward_operator\"", ":", "ifft2", ",", "\n", "\"num_iter\"", ":", "num_iter", ",", "\n", "\"num_primal\"", ":", "num_primal", ",", "\n", "\"num_dual\"", ":", "num_dual", ",", "\n", "\"primal_model_architecture\"", ":", "primal_model_architecture", ",", "\n", "\"dual_model_architecture\"", ":", "dual_model_architecture", ",", "\n", "}", "\n", "if", "primal_model_architecture", "is", "None", "or", "dual_model_architecture", "is", "None", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "            ", "model", "=", "LPDNet", "(", "**", "kwargs", ")", ".", "cpu", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "model", "=", "LPDNet", "(", "**", "kwargs", ")", ".", "cpu", "(", ")", "\n", "\n", "kspace", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "mask", "=", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "1", "]", ")", ".", "round", "(", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "kspace", ",", "sens", ",", "mask", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "2", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_unet_engine.create_sample": [[17, 27], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_unet_engine.test_unet_engine": [[29, 79], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.nn.unet.config.Unet2dConfig", "direct.config.defaults.DefaultConfig", "direct.nn.unet.unet_2d.Unet2d", "torch.nn.Conv2d", "direct.nn.unet.unet_engine.Unet2dEngine", "test_unet_engine.create_sample", "direct.nn.unet.unet_engine.Unet2dEngine.build_loss", "direct.nn.unet.unet_engine.Unet2dEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"loss_fns\"", ",", "\n", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_filters, num_pool_layers, image_initialization\"", ",", "\n", "[", "[", "4", ",", "2", ",", "\"sense\"", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalized\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_unet_engine", "(", "shape", ",", "loss_fns", ",", "num_filters", ",", "num_pool_layers", ",", "normalized", ",", "image_initialization", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "model_config", "=", "Unet2dConfig", "(", "\n", "num_filters", "=", "num_filters", ",", "num_pool_layers", "=", "num_pool_layers", ",", "image_initialization", "=", "image_initialization", "\n", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ",", "model", "=", "model_config", ")", "\n", "# Models", "\n", "model", "=", "Unet2d", "(", "\n", "forward_operator", ",", "\n", "backward_operator", ",", "\n", "num_filters", "=", "model_config", ".", "num_filters", ",", "\n", "num_pool_layers", "=", "model_config", ".", "num_pool_layers", ",", "\n", "dropout_probability", "=", "model_config", ".", "dropout_probability", ",", "\n", "image_initialization", "=", "model_config", ".", "image_initialization", ",", "\n", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "# Define engine", "\n", "engine", "=", "Unet2dEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_didn.create_input": [[10, 15], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_didn.test_didn": [[17, 52], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.didn.didn.DIDN", "create_input().cpu", "direct.nn.didn.didn.DIDN.", "list", "test_didn.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"out_channels\"", ",", "\n", "[", "3", ",", "5", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"hidden_channels\"", ",", "\n", "[", "16", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"n_dubs\"", ",", "\n", "[", "3", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_convs_recon\"", ",", "\n", "[", "3", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"skip\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_didn", "(", "shape", ",", "out_channels", ",", "hidden_channels", ",", "n_dubs", ",", "num_convs_recon", ",", "skip", ")", ":", "\n", "    ", "model", "=", "DIDN", "(", "shape", "[", "1", "]", ",", "out_channels", ",", "hidden_channels", ",", "n_dubs", ",", "num_convs_recon", ",", "skip", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "[", "shape", "[", "0", "]", "]", "+", "[", "out_channels", "]", "+", "shape", "[", "2", ":", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample": [[16, 26], ["dict", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.tensor", "[].items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "locals"], "function", ["None"], ["def", "create_sample", "(", "shape", ",", "**", "kwargs", ")", ":", "\n", "    ", "sample", "=", "dict", "(", ")", "\n", "sample", "[", "\"masked_kspace\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sensitivity_map\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"sampling_mask\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"target\"", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "float", "(", ")", "\n", "sample", "[", "\"scaling_factor\"", "]", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", "\n", "for", "k", ",", "v", "in", "locals", "(", ")", "[", "\"kwargs\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "sample", "[", "k", "]", "=", "v", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.test_xpdnet_engine": [[28, 77], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "functools.partial", "functools.partial", "direct.nn.xpdnet.xpdnet.XPDNet", "torch.nn.Conv2d", "direct.config.defaults.LossConfig", "direct.config.defaults.TrainingConfig", "direct.config.defaults.ValidationConfig", "direct.config.defaults.DefaultConfig", "direct.nn.xpdnet.xpdnet_engine.XPDNetEngine", "test_xpdnet_engine.create_sample", "direct.nn.xpdnet.xpdnet_engine.XPDNetEngine.build_loss", "direct.nn.xpdnet.xpdnet_engine.XPDNetEngine._do_iteration", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "tuple", "direct.config.defaults.FunctionConfig", "torch.from_numpy", "torch.from_numpy", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_xpdnet_engine.create_sample", "home.repos.pwc.inspect_result.directgroup_direct.nn.mri_models.MRIModelEngine.build_loss", "home.repos.pwc.inspect_result.directgroup_direct.rim.rim_engine.RIMEngine._do_iteration"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "(", "4", ",", "3", ",", "10", ",", "16", ",", "2", ")", ",", "(", "5", ",", "1", ",", "10", ",", "12", ",", "2", ")", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"loss_fns\"", ",", "[", "[", "\"l1_loss\"", ",", "\"ssim_loss\"", ",", "\"l2_loss\"", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_iter\"", ",", "[", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"num_primal\"", ",", "[", "3", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"image_model_architecture\"", ",", "[", "\"MWCNN\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"primal_only, kspace_model_architecture, num_dual\"", ",", "[", "[", "True", ",", "None", ",", "1", "]", "]", ")", "\n", "def", "test_xpdnet_engine", "(", "\n", "shape", ",", "\n", "loss_fns", ",", "\n", "num_iter", ",", "\n", "num_primal", ",", "\n", "image_model_architecture", ",", "\n", "primal_only", ",", "\n", "kspace_model_architecture", ",", "\n", "num_dual", ",", "\n", ")", ":", "\n", "# Operators", "\n", "    ", "forward_operator", "=", "functools", ".", "partial", "(", "fft2", ",", "centered", "=", "True", ")", "\n", "backward_operator", "=", "functools", ".", "partial", "(", "ifft2", ",", "centered", "=", "True", ")", "\n", "# Models", "\n", "kwargs", "=", "{", "\n", "\"forward_operator\"", ":", "forward_operator", ",", "\n", "\"backward_operator\"", ":", "backward_operator", ",", "\n", "\"num_iter\"", ":", "num_iter", ",", "\n", "\"num_primal\"", ":", "num_primal", ",", "\n", "\"num_dual\"", ":", "num_dual", ",", "\n", "\"image_model_architecture\"", ":", "image_model_architecture", ",", "\n", "\"kspace_model_architecture\"", ":", "kspace_model_architecture", ",", "\n", "\"use_primal_only\"", ":", "primal_only", ",", "\n", "}", "\n", "model", "=", "XPDNet", "(", "**", "kwargs", ")", "\n", "sensitivity_model", "=", "torch", ".", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "# Configs", "\n", "loss_config", "=", "LossConfig", "(", "losses", "=", "[", "FunctionConfig", "(", "loss", ")", "for", "loss", "in", "loss_fns", "]", ")", "\n", "training_config", "=", "TrainingConfig", "(", "loss", "=", "loss_config", ")", "\n", "validation_config", "=", "ValidationConfig", "(", "crop", "=", "None", ")", "\n", "config", "=", "DefaultConfig", "(", "training", "=", "training_config", ",", "validation", "=", "validation_config", ")", "\n", "# Define engine", "\n", "engine", "=", "XPDNetEngine", "(", "config", ",", "model", ",", "\"cpu\"", ",", "fft2", ",", "ifft2", ",", "sensitivity_model", "=", "sensitivity_model", ")", "\n", "# Test _do_iteration function with a single data batch", "\n", "data", "=", "create_sample", "(", "\n", "shape", ",", "\n", "sampling_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "1", ",", "1", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "target", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", ")", ")", ".", "float", "(", ")", ",", "\n", "scaling_factor", "=", "torch", ".", "ones", "(", "shape", "[", "0", "]", ")", ",", "\n", ")", "\n", "loss_fns", "=", "engine", ".", "build_loss", "(", ")", "\n", "out", "=", "engine", ".", "_do_iteration", "(", "data", ",", "loss_fns", ")", "\n", "assert", "out", ".", "output_image", ".", "shape", "==", "(", "shape", "[", "0", "]", ",", ")", "+", "tuple", "(", "shape", "[", "2", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_recurrentvarnet.create_input": [[11, 14], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_recurrentvarnet.test_recurrentvarnet": [[16, 84], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.recurrentvarnet.recurrentvarnet.RecurrentVarNet().cpu", "create_input().cpu", "create_input().cpu", "create_input().round().int().cpu", "RecurrentVarNet().cpu.", "list", "direct.nn.recurrentvarnet.recurrentvarnet.RecurrentVarNet", "test_recurrentvarnet.create_input", "test_recurrentvarnet.create_input", "create_input().round().int", "create_input().round", "test_recurrentvarnet.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "3", ",", "16", ",", "16", "]", ",", "\n", "[", "2", ",", "5", ",", "16", ",", "32", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_steps\"", ",", "\n", "[", "3", ",", "5", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"recurrent_hidden_channels\"", ",", "\n", "[", "4", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"recurrent_num_layers\"", ",", "\n", "[", "1", ",", "2", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"no_parameter_sharing\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"learned_initializer, initializer_initialization, initializer_channels, initializer_dilations\"", ",", "\n", "[", "\n", "[", "True", ",", "\"sense\"", ",", "(", "4", ",", "4", ",", "8", ",", "8", ")", ",", "(", "1", ",", "1", ",", "1", ",", "2", ")", "]", ",", "\n", "[", "True", ",", "\"zero_filled\"", ",", "(", "2", ",", "4", ",", "2", ",", "4", ")", ",", "(", "1", ",", "2", ",", "1", ",", "3", ")", "]", ",", "\n", "[", "False", ",", "None", ",", "None", ",", "None", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"normalized\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_recurrentvarnet", "(", "\n", "shape", ",", "\n", "num_steps", ",", "\n", "recurrent_hidden_channels", ",", "\n", "recurrent_num_layers", ",", "\n", "no_parameter_sharing", ",", "\n", "learned_initializer", ",", "\n", "initializer_initialization", ",", "\n", "initializer_channels", ",", "\n", "initializer_dilations", ",", "\n", "normalized", ",", "\n", ")", ":", "\n", "    ", "model", "=", "RecurrentVarNet", "(", "\n", "fft2", ",", "\n", "ifft2", ",", "\n", "num_steps", "=", "num_steps", ",", "\n", "recurrent_hidden_channels", "=", "recurrent_hidden_channels", ",", "\n", "recurrent_num_layers", "=", "recurrent_num_layers", ",", "\n", "no_parameter_sharing", "=", "no_parameter_sharing", ",", "\n", "learned_initializer", "=", "learned_initializer", ",", "\n", "initializer_initialization", "=", "initializer_initialization", ",", "\n", "initializer_channels", "=", "initializer_channels", ",", "\n", "initializer_dilations", "=", "initializer_dilations", ",", "\n", "normalized", "=", "normalized", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "kspace", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "mask", "=", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "1", "]", ")", ".", "round", "(", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "out_kspace", "=", "model", "(", "kspace", ",", "mask", ",", "sens", ")", "\n", "\n", "assert", "list", "(", "out_kspace", ".", "shape", ")", "==", "shape", "+", "[", "2", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input": [[11, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "\n", "    ", "data", "=", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.test_varnet": [[18, 44], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "direct.nn.varnet.varnet.EndToEndVarNet().cpu", "create_input().cpu", "create_input().round().int().cpu", "create_input().cpu", "EndToEndVarNet().cpu.", "list", "direct.nn.varnet.varnet.EndToEndVarNet", "test_varnet.create_input", "create_input().round().int", "test_varnet.create_input", "create_input().round", "test_varnet.create_input"], "function", ["home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input", "home.repos.pwc.inspect_result.directgroup_direct.tests_nn.test_varnet.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "[", "4", ",", "3", ",", "32", ",", "32", "]", ",", "[", "4", ",", "5", ",", "40", ",", "20", "]", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_layers\"", ",", "\n", "[", "2", ",", "3", ",", "6", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_filters\"", ",", "\n", "[", "2", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_pull_layers\"", ",", "\n", "[", "2", ",", "4", "]", ",", "\n", ")", "\n", "def", "test_varnet", "(", "shape", ",", "num_layers", ",", "num_filters", ",", "num_pull_layers", ")", ":", "\n", "    ", "model", "=", "EndToEndVarNet", "(", "fft2", ",", "ifft2", ",", "num_layers", ",", "num_filters", ",", "num_pull_layers", ",", "in_channels", "=", "2", ")", ".", "cpu", "(", ")", "\n", "\n", "kspace", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "mask", "=", "create_input", "(", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "+", "shape", "[", "2", ":", "]", "+", "[", "1", "]", ")", ".", "round", "(", ")", ".", "int", "(", ")", ".", "cpu", "(", ")", "\n", "sens", "=", "create_input", "(", "shape", "+", "[", "2", "]", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "kspace", ",", "mask", ",", "sens", ")", "\n", "\n", "assert", "list", "(", "out", ".", "shape", ")", "==", "shape", "+", "[", "2", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_fastmri_random_mask_reuse": [[17, 32], ["pytest.mark.parametrize", "direct.common.subsample.FastMRIRandomMaskFunc", "direct.common.subsample.FastMRIRandomMaskFunc.", "direct.common.subsample.FastMRIRandomMaskFunc.", "direct.common.subsample.FastMRIRandomMaskFunc.", "torch.all", "torch.all"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"center_fracs, accelerations, batch_size, dim\"", ",", "\n", "[", "\n", "(", "[", "0.2", "]", ",", "[", "4", "]", ",", "4", ",", "320", ")", ",", "\n", "(", "[", "0.2", ",", "0.4", "]", ",", "[", "4", ",", "8", "]", ",", "2", ",", "368", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_fastmri_random_mask_reuse", "(", "center_fracs", ",", "accelerations", ",", "batch_size", ",", "dim", ")", ":", "\n", "    ", "mask_func", "=", "FastMRIRandomMaskFunc", "(", "center_fracs", ",", "accelerations", ")", "\n", "shape", "=", "(", "batch_size", ",", "dim", ",", "dim", ",", "2", ")", "\n", "mask1", "=", "mask_func", "(", "shape", ",", "seed", "=", "123", ")", "\n", "mask2", "=", "mask_func", "(", "shape", ",", "seed", "=", "123", ")", "\n", "mask3", "=", "mask_func", "(", "shape", ",", "seed", "=", "123", ")", "\n", "assert", "torch", ".", "all", "(", "mask1", "==", "mask2", ")", "\n", "assert", "torch", ".", "all", "(", "mask2", "==", "mask3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_fastmri_random_mask_low_freqs": [[34, 58], ["pytest.mark.parametrize", "direct.common.subsample.FastMRIRandomMaskFunc", "direct.common.subsample.FastMRIRandomMaskFunc.", "list", "int", "numpy.all", "len", "round", "mask[].numpy"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"center_fracs, accelerations, batch_size, dim\"", ",", "\n", "[", "\n", "(", "[", "0.2", "]", ",", "[", "4", "]", ",", "4", ",", "320", ")", ",", "\n", "(", "[", "0.2", ",", "0.4", "]", ",", "[", "4", ",", "8", "]", ",", "2", ",", "368", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_fastmri_random_mask_low_freqs", "(", "center_fracs", ",", "accelerations", ",", "batch_size", ",", "dim", ")", ":", "\n", "    ", "mask_func", "=", "FastMRIRandomMaskFunc", "(", "center_fracs", ",", "accelerations", ")", "\n", "shape", "=", "(", "batch_size", ",", "dim", ",", "dim", ",", "2", ")", "\n", "mask", "=", "mask_func", "(", "shape", ",", "seed", "=", "123", ")", "\n", "mask_shape", "=", "[", "1", "]", "*", "(", "len", "(", "shape", ")", "+", "1", ")", "\n", "mask_shape", "[", "-", "2", "]", "=", "dim", "\n", "mask_shape", "[", "-", "3", "]", "=", "dim", "\n", "\n", "assert", "list", "(", "mask", ".", "shape", ")", "==", "mask_shape", "\n", "\n", "num_low_freqs_matched", "=", "False", "\n", "for", "center_frac", "in", "center_fracs", ":", "\n", "        ", "num_low_freqs", "=", "int", "(", "round", "(", "dim", "*", "center_frac", ")", ")", "\n", "pad", "=", "(", "dim", "-", "num_low_freqs", "+", "1", ")", "//", "2", "\n", "if", "np", ".", "all", "(", "mask", "[", "pad", ":", "pad", "+", "num_low_freqs", "]", ".", "numpy", "(", ")", "==", "1", ")", ":", "\n", "            ", "num_low_freqs_matched", "=", "True", "\n", "", "", "assert", "num_low_freqs_matched", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_apply_mask_fastmri": [[60, 81], ["pytest.mark.parametrize", "direct.common.subsample.FastMRIRandomMaskFunc", "direct.common.subsample.FastMRIRandomMaskFunc.", "direct.common.subsample.FastMRIRandomMaskFunc.", "numpy.allclose", "mask_func.max", "mask_func.min"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "[", "4", ",", "32", ",", "32", ",", "2", "]", ",", "[", "0.08", "]", ",", "[", "4", "]", ")", ",", "\n", "(", "[", "2", ",", "64", ",", "64", ",", "2", "]", ",", "[", "0.04", ",", "0.08", "]", ",", "[", "8", ",", "4", "]", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_apply_mask_fastmri", "(", "shape", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "mask_func", "=", "FastMRIRandomMaskFunc", "(", "\n", "center_fractions", "=", "center_fractions", ",", "\n", "accelerations", "=", "accelerations", ",", "\n", "uniform_range", "=", "False", ",", "\n", ")", "\n", "mask", "=", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ")", "\n", "acs_mask", "=", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ",", "return_acs", "=", "True", ")", "\n", "expected_mask_shape", "=", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", "\n", "\n", "assert", "mask", ".", "max", "(", ")", "==", "1", "\n", "assert", "mask", ".", "min", "(", ")", "==", "0", "\n", "assert", "mask", ".", "shape", "==", "expected_mask_shape", "\n", "assert", "np", ".", "allclose", "(", "mask", "&", "acs_mask", ",", "acs_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_same_across_volumes_mask_fastmri": [[83, 100], ["pytest.mark.parametrize", "direct.common.subsample.FastMRIRandomMaskFunc", "all", "direct.common.subsample.FastMRIRandomMaskFunc.", "range", "numpy.allclose", "range"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "[", "4", ",", "32", ",", "32", ",", "2", "]", ",", "[", "0.08", "]", ",", "[", "4", "]", ")", ",", "\n", "(", "[", "2", ",", "64", ",", "64", ",", "2", "]", ",", "[", "0.04", ",", "0.08", "]", ",", "[", "8", ",", "4", "]", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_same_across_volumes_mask_fastmri", "(", "shape", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "mask_func", "=", "FastMRIRandomMaskFunc", "(", "\n", "center_fractions", "=", "center_fractions", ",", "\n", "accelerations", "=", "accelerations", ",", "\n", "uniform_range", "=", "False", ",", "\n", ")", "\n", "num_slices", "=", "shape", "[", "0", "]", "\n", "masks", "=", "[", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ")", "for", "_", "in", "range", "(", "num_slices", ")", "]", "\n", "\n", "assert", "all", "(", "np", ".", "allclose", "(", "masks", "[", "_", "]", ",", "masks", "[", "_", "+", "1", "]", ")", "for", "_", "in", "range", "(", "num_slices", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_apply_mask_radial": [[102, 121], ["pytest.mark.parametrize", "direct.common.subsample.RadialMaskFunc", "direct.common.subsample.RadialMaskFunc.", "direct.common.subsample.RadialMaskFunc.", "numpy.allclose", "mask_func.max", "mask_func.min"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, accelerations\"", ",", "\n", "[", "\n", "(", "[", "4", ",", "32", ",", "32", ",", "2", "]", ",", "[", "4", "]", ")", ",", "\n", "(", "[", "2", ",", "64", ",", "64", ",", "2", "]", ",", "[", "8", ",", "4", "]", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_apply_mask_radial", "(", "shape", ",", "accelerations", ")", ":", "\n", "    ", "mask_func", "=", "RadialMaskFunc", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", ")", "\n", "mask", "=", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ")", "\n", "acs_mask", "=", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ",", "return_acs", "=", "True", ")", "\n", "expected_mask_shape", "=", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", "\n", "\n", "assert", "mask", ".", "max", "(", ")", "==", "1", "\n", "assert", "mask", ".", "min", "(", ")", "==", "0", "\n", "assert", "mask", ".", "shape", "==", "expected_mask_shape", "\n", "assert", "np", ".", "allclose", "(", "mask", "&", "acs_mask", ",", "acs_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_same_across_volumes_mask_radial": [[123, 138], ["pytest.mark.parametrize", "direct.common.subsample.RadialMaskFunc", "all", "direct.common.subsample.RadialMaskFunc.", "range", "numpy.allclose", "range"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, accelerations\"", ",", "\n", "[", "\n", "(", "[", "4", ",", "32", ",", "32", ",", "2", "]", ",", "[", "4", "]", ")", ",", "\n", "(", "[", "2", ",", "64", ",", "64", ",", "2", "]", ",", "[", "8", ",", "4", "]", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_same_across_volumes_mask_radial", "(", "shape", ",", "accelerations", ")", ":", "\n", "    ", "mask_func", "=", "RadialMaskFunc", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", ")", "\n", "num_slices", "=", "shape", "[", "0", "]", "\n", "masks", "=", "[", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ")", "for", "_", "in", "range", "(", "num_slices", ")", "]", "\n", "\n", "assert", "all", "(", "np", ".", "allclose", "(", "masks", "[", "_", "]", ",", "masks", "[", "_", "+", "1", "]", ")", "for", "_", "in", "range", "(", "num_slices", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_apply_mask_spiral": [[140, 159], ["pytest.mark.parametrize", "direct.common.subsample.SpiralMaskFunc", "direct.common.subsample.SpiralMaskFunc.", "direct.common.subsample.SpiralMaskFunc.", "numpy.allclose", "mask_func.max", "mask_func.min"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, accelerations\"", ",", "\n", "[", "\n", "(", "[", "4", ",", "32", ",", "32", ",", "2", "]", ",", "[", "4", "]", ")", ",", "\n", "(", "[", "2", ",", "64", ",", "64", ",", "2", "]", ",", "[", "8", ",", "4", "]", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_apply_mask_spiral", "(", "shape", ",", "accelerations", ")", ":", "\n", "    ", "mask_func", "=", "SpiralMaskFunc", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", ")", "\n", "mask", "=", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ")", "\n", "acs_mask", "=", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ",", "return_acs", "=", "True", ")", "\n", "expected_mask_shape", "=", "(", "1", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ",", "1", ")", "\n", "\n", "assert", "mask", ".", "max", "(", ")", "==", "1", "\n", "assert", "mask", ".", "min", "(", ")", "==", "0", "\n", "assert", "mask", ".", "shape", "==", "expected_mask_shape", "\n", "assert", "np", ".", "allclose", "(", "mask", "&", "acs_mask", ",", "acs_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.directgroup_direct.tests_common.test_subsample.test_same_across_volumes_mask_spiral": [[161, 176], ["pytest.mark.parametrize", "direct.common.subsample.SpiralMaskFunc", "all", "direct.common.subsample.SpiralMaskFunc.", "range", "numpy.allclose", "range"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, accelerations\"", ",", "\n", "[", "\n", "(", "[", "4", ",", "32", ",", "32", ",", "2", "]", ",", "[", "4", "]", ")", ",", "\n", "(", "[", "2", ",", "64", ",", "64", ",", "2", "]", ",", "[", "8", ",", "4", "]", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_same_across_volumes_mask_spiral", "(", "shape", ",", "accelerations", ")", ":", "\n", "    ", "mask_func", "=", "SpiralMaskFunc", "(", "\n", "accelerations", "=", "accelerations", ",", "\n", ")", "\n", "num_slices", "=", "shape", "[", "0", "]", "\n", "masks", "=", "[", "mask_func", "(", "shape", "[", "1", ":", "]", ",", "seed", "=", "123", ")", "for", "_", "in", "range", "(", "num_slices", ")", "]", "\n", "\n", "assert", "all", "(", "np", ".", "allclose", "(", "masks", "[", "_", "]", ",", "masks", "[", "_", "+", "1", "]", ")", "for", "_", "in", "range", "(", "num_slices", "-", "1", ")", ")", "\n", "", ""]]}